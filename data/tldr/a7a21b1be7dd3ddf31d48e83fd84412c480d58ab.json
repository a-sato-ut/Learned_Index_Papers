{
  "paperId": "a7a21b1be7dd3ddf31d48e83fd84412c480d58ab",
  "title": "Adversary Resilient Learned Bloom Filters",
  "abstract": "A learned Bloom filter (LBF) combines a classical Bloom filter (CBF) with a learning model to reduce the amount of memory needed to represent a given set while achieving a target false positive rate (FPR). Provable security against adaptive adversaries that advertently attempt to increase FPR has been studied for CBFs, but not for LBFs. In this paper, we close this gap and show how to achieve adaptive security for LBFs. In particular, we define several adaptive security notions capturing varying degrees of adversarial control, including full and partial adaptivity, in addition to LBF extensions of existing adversarial models for CBFs, including the Always-Bet and Bet-or-Pass notions. We propose two secure LBF constructions, PRP-LBF and Cuckoo-LBF, and formally prove their security under these models assuming the existence of one-way functions. Based on our analysis and use case evaluations, our constructions achieve strong security guarantees while maintaining competitive FPR and memory overhead.",
  "tldr": "This paper presents adversary resilient learned Bloom filters (LBFs) that enhance security against adaptive attacks, addressing a gap in existing research. It introduces two secure LBF constructions, PRP-LBF and Cuckoo-LBF, proving their effectiveness while ensuring low false positive rates and memory use."
}