{
  "paperId": "9c7b57cf0910f6e95236f000db2764992c59b4c0",
  "title": "BitTuner: A Toolbox for Automatically Configuring Learned Data Compressors",
  "abstract": "Compressing sorted keys is a fundamental operation in data management and information retrieval. Inspired by the success of learned index, recent studies apply simple ML models to compress large-scale sorted keys, leading to the concept of learned compressor. Intuitively, learned compressors losslessly encode sorted keys by approximating them with an error-bounded ML model (e.g., a piecewise linear function) and a residual array to ensure lossless key restoration. However, determining the optimal configuration of underlying ML models to maximize compression efficacy is nontrivial. To address this, by analyzing the distribution characteristics of input keys, we propose BitTuner, a novel framework that automatically sets model hyper-parameters to provably achieve the best compression ratio. We demonstrate BitTuner on two real-world scenarios: inverted list compression and vectorDB codebook compression. The results show that BitTuner automates the parameter tuning procedure and achieves superior compression efficacy when compared to generic compressors such as LZ4 and LZMA.",
  "tldr": "BitTuner is a framework that automatically configures hyper-parameters for learned data compressors, optimizing compression ratios for sorted keys and outperforming traditional compressors like LZ4 and LZMA in real-world applications."
}