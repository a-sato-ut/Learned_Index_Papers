{
  "paperId": "1b28a7e49f718e5b5612c8fb28096bab0d69ebbd",
  "title": "Memory-Efficient RkNN Retrieval by Nonlinear k-Distance Approximation",
  "abstract": "The reverse k-nearest neighbor (RkNN) query is an established query type with various applications reaching from identifying highly influential objects over incrementally updating kNN graphs to optimizing sensor communication and outlier detection. State-of-the-art solutions exploit that the k-distances in real-world datasets often follow the power-law distribution, and bound them with linear lines in log-log space. In this work, we investigate this assumption and uncover that it is violated in regions of changing density, which we show are typical for real-life datasets. Towards a generic solution, we pose the estimation of k-distances as a regression problem. Thereby, we enable harnessing the power of the abundance of available Machine Learning models and profiting from their advancement. We propose a flexible approach which allows steering the performance-memory consumption trade-off, and in particular to find good solutions with a fixed memory budget crucial in the context of edge computing. Moreover, we show how to obtain and improve guaranteed bounds essential to exact query processing. In experiments on real-world datasets, we demonstrate how this framework can significantly reduce the index memory consumption, and strongly reduce the candidate set size. We publish our code at https://github.com/sobermeier/nonlinear-kdist, and a detailed technical report at https://arxiv.org/abs/2011.01773.",
  "tldr": "This paper presents a memory-efficient method for reverse k-nearest neighbor (RkNN) retrieval by addressing the limitations of linear k-distance approximations in varying density regions of real-world datasets, proposing a regression-based approach that leverages machine learning models to optimize performance and memory usage, particularly for edge computing applications."
}