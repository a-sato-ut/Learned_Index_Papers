{
    "paperId": "7a6bbc2ffcddf8ef19216ccd6489ee78b0016eb4",
    "title": "Multi-Concept Learning for Scene Graph Generation",
    "year": 2025,
    "venue": "IEEE Transactions on Image Processing",
    "authors": [
        "Xinyu Lyu",
        "Lianli Gao",
        "Junlin Xie",
        "Pengpeng Zeng",
        "Yulu Tian",
        "Jie Shao",
        "Hengtao Shen"
    ],
    "doi": "10.1109/TIP.2025.3540296",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/7a6bbc2ffcddf8ef19216ccd6489ee78b0016eb4",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Existing Unbiased Scene Graph Generation (USGG) methods only focus on addressing the predicate-level imbalance that high-frequency classes dominate predictions of rare ones, while overlooking the concept-level imbalance. Actually, even if predicates themselves are balanced, there is still a significant concept-imbalance within them due to the long-tailed distribution of contexts (i.e., subject-object combinations). This concept-level imbalance poses a more pervasive and challenging issue compared to the predicate-level imbalance since subject-object pairs are inherently complex in combinations. To address the issue, we propose Multi-Concept Learning (MCL), a novel concept-level balanced learning framework orthogonal to existing SGG methods. MCL first quantifies the concept-level imbalance across predicates in terms of different amounts of concepts, representing as multiple concept-prototypes within the same class. Then, to achieve balanced learning across different concepts (i.e., concept-prototypes), we introduce the Concept-based Balanced Memory (CBM), which guides SGG models in generating balanced representations for concept-prototypes. Furthermore, the Concept Regularization (CR) technique is proposed to effectively help models in aligning relation features to their corresponding concept-prototypes, thereby generating concept-level compact and predicate-level distinctive representations for robust relation recognition. Finally, we introduce a novel metric, mean Context Recall (mCR@K), as a complement to mean Recall (mR@K), to evaluate the modelâ€™s performance across concepts (determined by contexts) within the same predicate. Extensive experiments demonstrate the remarkable efficacy of our model-agnostic strategy in enhancing the performance of benchmark models on both VG-SGG and OI-SGG datasets, leading to new state-of-the-art achievements in two key aspects: predicate-level unbiased relation recognition and concept-level compositional generability. Code is available at https://github.com/XinyuLyu/G-USGG.",
    "citationCount": 0,
    "referenceCount": 76
}