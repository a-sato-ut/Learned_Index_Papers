{
    "paperId": "68bfd53fae324adfb027e0bdec03b38b9daba115",
    "title": "Rambda: RDMA-driven Acceleration Framework for Memory-intensive µs-scale Datacenter Applications",
    "year": 2023,
    "venue": "International Symposium on High-Performance Computer Architecture",
    "authors": [
        "Yifan Yuan",
        "Jinghan Huang",
        "Y. Sun",
        "Tianchen Wang",
        "Jacob Nelson",
        "Dan R. K. Ports",
        "Yipeng Wang",
        "Ren Wang",
        "Charlie Tai",
        "Nam Sung Kim"
    ],
    "doi": "10.1109/HPCA56546.2023.10071127",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/68bfd53fae324adfb027e0bdec03b38b9daba115",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Responding to the \"datacenter tax\" and \"killer microseconds\" problems for memory-intensive datacenter applications, diverse solutions including Smart NIC-based ones have been proposed. Nonetheless, they often suffer from high overhead of communications over network and/or PCIe links. To tackle the limitations of the current solutions, this paper proposes RAMBDA, a holistic network and architecture co-design solution that leverages current RDMA and emerging cache-coherent off-chip interconnect technologies. Specifically, RAMBDA consists of four hardware and software components: (1) unified abstraction of inter- and intra-machine communications synergistically managed by one-sided RDMA write and cache-coherent memory write; (2) efficient notification of requests to accelerators assisted by cache coherence; (3) cache-coherent accelerator architecture directly interacting with NIC; and (4) adaptive device-to-host data transfer for modern server memory systems comprising both DRAM and NVM exploiting state-of-the-art features in CPUs and PCIe. We prototype RAMBDA with a commercial system and evaluate three popular datacenter applications: (1) in-memory key-value store, (2) chain replication-based distributed transaction system, and (3) deep learning recommendation model inference. The evaluation shows that RAMBDA provides 30.1~69.1% lower latency, 0.2~2.5× throughput, and ~ 3× higher energy efficiency than the current state-of-the-art solutions, including Smart NIC. For those cases where Rambda performs poorly, we also envision future architecture to improve it.",
    "citationCount": 23,
    "referenceCount": 183
}