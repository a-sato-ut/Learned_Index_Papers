{
    "paperId": "ed1aaad1beac180a33d74a539300a1fcb62a15ec",
    "title": "Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models",
    "year": 2024,
    "venue": "International Conference on Machine Learning",
    "authors": [
        "Dennis Wu",
        "Jerry Yao-Chieh Hu",
        "Teng-Yun Hsiao",
        "Han Liu"
    ],
    "doi": "10.48550/arXiv.2404.03827",
    "arxivId": "2404.03827",
    "url": "https://www.semanticscholar.org/paper/ed1aaad1beac180a33d74a539300a1fcb62a15ec",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We propose a two-stage memory retrieval dynamics for modern Hopfield models, termed $\\mathtt{U\\text{-}Hop}$, with enhanced memory capacity. Our key contribution is a learnable feature map $\\Phi$ which transforms the Hopfield energy function into kernel space. This transformation ensures convergence between the local minima of energy and the fixed points of retrieval dynamics within the kernel space. Consequently, the kernel norm induced by $\\Phi$ serves as a novel similarity measure. It utilizes the stored memory patterns as learning data to enhance memory capacity across all modern Hopfield models. Specifically, we accomplish this by constructing a separation loss $\\mathcal{L}_\\Phi$ that separates the local minima of kernelized energy by separating stored memory patterns in kernel space. Methodologically, $\\mathtt{U\\text{-}Hop}$ memory retrieval process consists of: (Stage I) minimizing separation loss for a more uniform memory (local minimum) distribution, followed by (Stage II) standard Hopfield energy minimization for memory retrieval. This results in a significant reduction of possible metastable states in the Hopfield energy function, thus enhancing memory capacity by preventing memory confusion. Empirically, with real-world datasets, we demonstrate that $\\mathtt{U\\text{-}Hop}$ outperforms all existing modern Hopfield models and state-of-the-art similarity measures, achieving substantial improvements in both associative memory retrieval and deep learning tasks. Code is available at https://github.com/MAGICS-LAB/UHop ; future updates are on arXiv:2404.03827",
    "citationCount": 37,
    "referenceCount": 64
}