{
    "paperId": "8e5ee8106cbdd61d840d1946ec7d053127958f91",
    "title": "Deep learning control of artificial avatars in group coordination tasks",
    "year": 2019,
    "venue": "IEEE International Conference on Systems, Man and Cybernetics",
    "authors": [
        "M. Lombardi",
        "D. Liuzza",
        "M. Bernardo"
    ],
    "doi": "10.1109/SMC.2019.8914294",
    "arxivId": "1906.04656",
    "url": "https://www.semanticscholar.org/paper/8e5ee8106cbdd61d840d1946ec7d053127958f91",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/1906.04656",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In many joint-action scenarios, humans and robots have to coordinate their movements to accomplish a given shared task. Examples include lifting an object together, sawing a wood log, transferring objects from a point to another. While dyadic coordination between a human and a robot has been studied in previous investigations, the multi-agent scenario in which a robot has to be integrated into a human group still remains a less explored field of research. In this paper we discuss how to synthesise an artificial agent, driven by a control architecture based on deep reinforcement learning, able to coordinate its motion in human ensembles. As a paradigmatic coordination task we take a group version of the so called mirror game from the human movement literature.",
    "citationCount": 8,
    "referenceCount": 22
}