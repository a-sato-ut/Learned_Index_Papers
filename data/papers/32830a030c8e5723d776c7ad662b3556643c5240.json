{
    "paperId": "32830a030c8e5723d776c7ad662b3556643c5240",
    "title": "Boosting Cloud Data Analytics using Multi-Objective Optimization",
    "year": 2020,
    "venue": "arXiv.org",
    "authors": [
        "Fei Song",
        "Khaled Zaouk",
        "Chenghao Lyu",
        "Arnab Sinha",
        "Qi Fan",
        "Y. Diao",
        "Prashant J. Shenoy"
    ],
    "doi": null,
    "arxivId": "2005.03314",
    "url": "https://www.semanticscholar.org/paper/32830a030c8e5723d776c7ad662b3556643c5240",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Data analytics in the cloud has become an integral part of enterprise businesses. Big data analytics systems, however, still lack the ability to take user performance goals and budgetary constraints for a task, collectively referred to as task objectives, and automatically configure an analytic job to achieve these objectives. This paper presents a data analytics optimizer that can automatically determine a cluster configuration with a suitable number of cores as well as other system parameters that best meet the task objectives. At a core of our work is a principled multi-objective optimization (MOO) approach that computes a Pareto optimal set of job configurations to reveal tradeoffs between different user objectives, recommends a new job configuration that best explores such tradeoffs, and employs novel optimizations to enable such recommendations within a few seconds. We present efficient incremental algorithms based on the notion of a Progressive Frontier for realizing our MOO approach and implement them into a Spark-based prototype. Detailed experiments using benchmark workloads show that our MOO techniques provide a 2-50x speedup over existing MOO methods, while offering good coverage of the Pareto frontier. When compared to Ottertune, a state-of-the-art performance tuning system, our approach recommends configurations that yield 26%-49% reduction of running time of the TPCx-BB benchmark while adapting to different application preferences on multiple objectives.",
    "citationCount": 2,
    "referenceCount": 49
}