{
    "paperId": "6b74e7097e6bf5e51f1391656df98c0c04de0d93",
    "title": "Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning",
    "year": 2024,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Frederik Hoppe",
        "C. M. Verdun",
        "Hannah Laus",
        "Felix Krahmer",
        "Holger Rauhut"
    ],
    "doi": "10.48550/arXiv.2407.13666",
    "arxivId": "2407.13666",
    "url": "https://www.semanticscholar.org/paper/6b74e7097e6bf5e51f1391656df98c0c04de0d93",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Engineering",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Uncertainty quantification (UQ) is a crucial but challenging task in many high-dimensional regression or learning problems to increase the confidence of a given predictor. We develop a new data-driven approach for UQ in regression that applies both to classical regression approaches such as the LASSO as well as to neural networks. One of the most notable UQ techniques is the debiased LASSO, which modifies the LASSO to allow for the construction of asymptotic confidence intervals by decomposing the estimation error into a Gaussian and an asymptotically vanishing bias component. However, in real-world problems with finite-dimensional data, the bias term is often too significant to be neglected, resulting in overly narrow confidence intervals. Our work rigorously addresses this issue and derives a data-driven adjustment that corrects the confidence intervals for a large class of predictors by estimating the means and variances of the bias terms from training data, exploiting high-dimensional concentration phenomena. This gives rise to non-asymptotic confidence intervals, which can help avoid overestimating uncertainty in critical applications such as MRI diagnosis. Importantly, our analysis extends beyond sparse regression to data-driven predictors like neural networks, enhancing the reliability of model-based deep learning. Our findings bridge the gap between established theory and the practical applicability of such debiased methods.",
    "citationCount": 1,
    "referenceCount": 92
}