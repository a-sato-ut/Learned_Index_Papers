{
    "paperId": "9f014b6fd73d01fa6a101fc22977b9635efd9888",
    "title": "Effective Lightweight Learning-to-Rank Method Using Unified Term Impacts",
    "year": 2020,
    "venue": "IEEE Access",
    "authors": [
        "S. D. N. Silva",
        "Edleno Silva De Moura",
        "P. Calado",
        "Altigran Soares da Silva"
    ],
    "doi": "10.1109/ACCESS.2020.2986943",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/9f014b6fd73d01fa6a101fc22977b9635efd9888",
    "isOpenAccess": true,
    "openAccessPdf": "https://doi.org/10.1109/access.2020.2986943",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In this study, we propose and evaluate a novel learning-to-rank (L2R) approach that produces results on par with those of the state-of-the-art L2R methods while being computationally effective. We start by presenting a modified gradient boosted regression tree algorithm to generate unified term impact (UTI) values at indexing time. Each unified term impact replaces several features with a single value in the document index, thereby reducing the effort to compute the document scores at query processing time because the system fetches and processes fewer values. The adoption of UTI values produces competitive ranking results. However, the lack of features available only at query time might lead to accuracy loss. To solve this problem, we propose a hybrid model that uses UTI values with query-dependent features. We demonstrate that our hybrid methods can deliver high-quality results on par with those of the existing state-of-the-art neural ranking models. Our methods can also reduce the computational costs for processing queries, serving as an interesting alternative for L2R practical applications. Our best hybrid, HLambdaMART, achieves an NDCG@10 value of 0.495 using only 36 features at query processing time when applied to the MQ2007 collection, while the best baseline achieves 0.490 using a larger set of features at query processing time. The use of our hybrid framework reduces the time to run LambdaMART to about 35% of the time to run it without using our proposals. In summary, we present a competitive and lightweight alternative L2R approach to be adopted in search systems.",
    "citationCount": 3,
    "referenceCount": 50
}