{
    "paperId": "254358ae87293bd6862ca8a929b16ef0ee7cd336",
    "title": "Towards Making Deep Learning-based Vulnerability Detectors Robust",
    "year": 2021,
    "venue": "arXiv.org",
    "authors": [
        "Zhen Li",
        "Jing Tang",
        "Deqing Zou",
        "Qian Chen",
        "Shouhuai Xu",
        "Chao Zhang",
        "Yichen Li",
        "Hai Jin"
    ],
    "doi": null,
    "arxivId": "2108.00669",
    "url": "https://www.semanticscholar.org/paper/254358ae87293bd6862ca8a929b16ef0ee7cd336",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Automatically detecting software vulnerabilities in source code is an important problem that has attracted much attention. In particular, deep learning-based vulnerability detectors, or DL-based detectors, are attractive because they do not need human experts to define features or patterns of vulnerabilities. However, such detectors' robustness is unclear. In this paper, we initiate the study in this aspect by demonstrating that DL-based detectors are not robust against simple code transformations, dubbed attacks in this paper, as these transformations may be leveraged for malicious purposes. As a first step towards making DL-based detectors robust against such attacks, we propose an innovative framework, dubbed ZigZag, which is centered at (i) decoupling feature learning and classifier learning and (ii) using a ZigZag-style strategy to iteratively refine them until they converge to robust features and robust classifiers. Experimental results show that the ZigZag framework can substantially improve the robustness of DL-based detectors.",
    "citationCount": 8,
    "referenceCount": 73
}