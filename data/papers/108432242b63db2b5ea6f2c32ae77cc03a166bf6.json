{
    "paperId": "108432242b63db2b5ea6f2c32ae77cc03a166bf6",
    "title": "Compilation as a Defense: Enhancing DL Model Attack Robustness via Tensor Optimization",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "Stefan Trawicki",
        "William Hackett",
        "Lewis Birch",
        "Neeraj Suri",
        "Peter Garraghan"
    ],
    "doi": "10.48550/arXiv.2309.16577",
    "arxivId": "2309.16577",
    "url": "https://www.semanticscholar.org/paper/108432242b63db2b5ea6f2c32ae77cc03a166bf6",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2309.16577",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Adversarial Machine Learning (AML) is a rapidly growing field of security research, with an often overlooked area being model attacks through side-channels. Previous works show such attacks to be serious threats, though little progress has been made on efficient remediation strategies that avoid costly model re-engineering. This work demonstrates a new defense against AML side-channel attacks using model compilation techniques, namely tensor optimization. We show relative model attack effectiveness decreases of up to 43% using tensor optimization, discuss the implications, and direction of future work.",
    "citationCount": 0,
    "referenceCount": 18
}