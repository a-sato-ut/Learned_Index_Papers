{
    "paperId": "25984f671c083ef27b1502b480ad1965b4633192",
    "title": "A Review on Meta-Learning: How Artificial Intelligence and Machine Learning Can Learn to Adapt Quickly",
    "year": 2025,
    "venue": "2025 International Conference on Electronics and Renewable Systems (ICEARS)",
    "authors": [
        "Shrikant Khadse",
        "Palash M. Gourshettiwar",
        "Adesh Pawar"
    ],
    "doi": "10.1109/ICEARS64219.2025.10941123",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/25984f671c083ef27b1502b480ad1965b4633192",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Meta-learning aims to create Artificial Intelligence (AI) systems that can adapt to new tasks and improve their performance over time without extensive retraining. The advent of meta-learning paradigms has fundamentally changed how Artificial Intelligence (AI) and Machine Learning (ML) are handled, constantly reshaping these fields. Research study reviews the broad field of meta-learning, highlighting its critical function in bridging the AI-ML divide to improve adaptability. The study starts with a review of past developments, following the development of meta-learning algorithms and their underpinning theories. The historical view lays the groundwork for understanding the course of this dynamic regulation, spanning from early efforts in probabilistic program induction to modern discoveries in model-agnostic meta-learning. The study explores multiple meta-learning applications in AI and ML, revealing how they affect financial forecasting, computer vision, natural language processing, autonomous cars, health informatics, robotics, and personalized recommendation systems. When seen from the perspective of adaptive intelligence, meta-learning may be effectively applied to conditions with limited data, hyperparameter optimization, few-shot learning, and quick adaption in reinforcement learning settings.",
    "citationCount": 0,
    "referenceCount": 21
}