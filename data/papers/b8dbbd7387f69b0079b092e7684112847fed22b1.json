{
    "paperId": "b8dbbd7387f69b0079b092e7684112847fed22b1",
    "title": "TabulaX: Leveraging Large Language Models for Multi-Class Table Transformations",
    "year": 2024,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Arash Dargahi Nobari",
        "Davood Rafiei"
    ],
    "doi": "10.14778/3749646.3749657",
    "arxivId": "2411.17110",
    "url": "https://www.semanticscholar.org/paper/b8dbbd7387f69b0079b092e7684112847fed22b1",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The integration of tabular data from diverse sources is often hindered by inconsistencies in formatting and representation, posing significant challenges for data analysts and personal digital assistants. Existing methods for automating tabular data transformations are limited in scope, often focusing on specific types of transformations or lacking interpretability. In this paper, we introduce TabulaX, a novel framework that leverages Large Language Models (LLMs) for multi-class column-level tabular transformations. TabulaX first classifies input columns into four transformation types—string-based, numerical, algorithmic, and general—and then applies tailored methods to generate human-interpretable transformation functions, such as numeric formulas or programming code. This approach enhances transparency and allows users to understand and modify the mappings. Through extensive experiments on real-world datasets from various domains, we demonstrate that TabulaX outperforms existing state-of-the-art approaches in terms of accuracy, supports a broader class of transformations, and generates interpretable transformations that can be efficiently applied.",
    "citationCount": 2,
    "referenceCount": 51
}