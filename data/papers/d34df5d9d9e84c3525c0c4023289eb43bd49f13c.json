{
    "paperId": "d34df5d9d9e84c3525c0c4023289eb43bd49f13c",
    "title": "Unifying Generative and Dense Retrieval for Sequential Recommendation",
    "year": 2024,
    "venue": "Trans. Mach. Learn. Res.",
    "authors": [
        "Liu Yang",
        "Fabian Paischer",
        "Kaveh Hassani",
        "Jiacheng Li",
        "Shuai Shao",
        "Zhang Gabriel Li",
        "Yun He",
        "Xue Feng",
        "Nima Noorshams",
        "Sem Park",
        "Bo Long",
        "Robert Nowak",
        "Xiaoli Gao",
        "Hamid Eghbalzadeh"
    ],
    "doi": "10.48550/arXiv.2411.18814",
    "arxivId": "2411.18814",
    "url": "https://www.semanticscholar.org/paper/d34df5d9d9e84c3525c0c4023289eb43bd49f13c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Sequential dense retrieval models utilize advanced sequence learning techniques to compute item and user representations, which are then used to rank relevant items for a user through inner product computation between the user and all item representations. However, this approach requires storing a unique representation for each item, resulting in significant memory requirements as the number of items grow. In contrast, the recently proposed generative retrieval paradigm offers a promising alternative by directly predicting item indices using a generative model trained on semantic IDs that encapsulate items' semantic information. Despite its potential for large-scale applications, a comprehensive comparison between generative retrieval and sequential dense retrieval under fair conditions is still lacking, leaving open questions regarding performance, and computation trade-offs. To address this, we compare these two approaches under controlled conditions on academic benchmarks and propose LIGER (LeveragIng dense retrieval for GEnerative Retrieval), a hybrid model that combines the strengths of these two widely used methods. LIGER integrates sequential dense retrieval into generative retrieval, mitigating performance differences and enhancing cold-start item recommendation in the datasets evaluated. This hybrid approach provides insights into the trade-offs between these approaches and demonstrates improvements in efficiency and effectiveness for recommendation systems in small-scale benchmarks.",
    "citationCount": 12,
    "referenceCount": 41
}