{
    "paperId": "f3a68e2b86cbbc3efe40292750d5f212ba54c07f",
    "title": "A Cross-Language Information Retrieval Method Based on Multi-Task Learning",
    "year": 2024,
    "venue": "MALCOM: Indonesian Journal of Machine Learning and Computer Science",
    "authors": [
        "Peng Linli"
    ],
    "doi": "10.57152/malcom.v4i3.1384",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/f3a68e2b86cbbc3efe40292750d5f212ba54c07f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This study introduces a novel Cross-Language Information Retrieval (CLIR) method employing multi-task learning and soft parameter sharing to enhance neural retrieval models' feature extraction across languages. The approach integrates an interaction-based neural retrieval model with a semantic-based text classification model, exchanging hidden vectors for richer feature representation. Experimental results across four language pairs—English-Chinese, English-Arabic, English-French, and English-German—demonstrate significant performance improvements. The proposed method achieved the highest Mean Average Precision (MAP) scores: 0.419 for EN-ZH, 0.403 for EN-AR, 0.427 for EN-FR, and 0.441 for EN-DE, surpassing other models like BM25, BPNRM, KNRM, KNRM-Trans, and KNRM-Embed. This research underscores the potential of multi-task learning for CLIR, showcasing improved retrieval performance through semantic information and knowledge transfer.",
    "citationCount": 1,
    "referenceCount": 48
}