{
    "paperId": "fb387c0576f355b37bc2739dc183cf7b37b2a52c",
    "title": "Explaining Deep Learning-Based Networked Systems",
    "year": 2019,
    "venue": "arXiv.org",
    "authors": [
        "Zili Meng",
        "Minhu Wang",
        "Mingwei Xu",
        "Hongzi Mao",
        "Jia-Ju Bai",
        "Hongxin Hu"
    ],
    "doi": null,
    "arxivId": "1910.03835",
    "url": "https://www.semanticscholar.org/paper/fb387c0576f355b37bc2739dc183cf7b37b2a52c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "While many deep learning (DL)-based networking systems have demonstrated superior performance, the underlying Deep Neural Networks (DNNs) remain blackboxes and stay uninterpretable for network operators. The lack of interpretability makes DL-based networking systems prohibitive to deploy in practice. In this paper, we propose Metis, a framework that provides interpretability for two general categories of networking problems spanning local and global control. Accordingly, Metis introduces two different interpretation methods based on decision tree and hypergraph, where it converts DNN policies to interpretable rule-based controllers and highlight critical components based on analysis over hypergraph. We evaluate Metis over several state-of-the-art DL-based networking systems and show that Metis provides human-readable interpretations while preserving nearly no degradation in performance. We further present four concrete use cases of Metis, showcasing how Metis helps network operators to design, debug, deploy, and ad-hoc adjust DL-based networking systems.",
    "citationCount": 3,
    "referenceCount": 114
}