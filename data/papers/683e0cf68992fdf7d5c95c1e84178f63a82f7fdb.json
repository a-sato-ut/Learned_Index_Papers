{
    "paperId": "683e0cf68992fdf7d5c95c1e84178f63a82f7fdb",
    "title": "A Zero-Positive Learning Approach for Diagnosing Software Performance Regressions",
    "year": 2017,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Mejbah Alam",
        "Justin Emile Gottschlich",
        "Nesime Tatbul",
        "Javier Turek",
        "T. Mattson",
        "Abdullah Muzahid"
    ],
    "doi": null,
    "arxivId": "1709.07536",
    "url": "https://www.semanticscholar.org/paper/683e0cf68992fdf7d5c95c1e84178f63a82f7fdb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The field of machine programming (MP), the automation of the development of software, is making notable research advances. This is, in part, due to the emergence of a wide range of novel techniques in machine learning. In this paper, we apply MP to the automation of software performance regression testing. A performance regression is a software performance degradation caused by a code change. We present AutoPerf - a novel approach to automate regression testing that utilizes three core techniques: (i) zero-positive learning, (ii) autoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf's generality and efficacy against 3 types of performance regressions across 10 real performance bugs in 7 benchmark and open-source programs. On average, AutoPerf exhibits 4% profiling overhead and accurately diagnoses more performance bugs than prior state-of-the-art approaches. Thus far, AutoPerf has produced no false negatives.",
    "citationCount": 29,
    "referenceCount": 60
}