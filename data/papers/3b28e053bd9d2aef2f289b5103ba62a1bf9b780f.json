{
    "paperId": "3b28e053bd9d2aef2f289b5103ba62a1bf9b780f",
    "title": "Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions",
    "year": 2023,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Dongjie Wang",
        "Meng Xiao",
        "Min Wu",
        "P. Wang",
        "Yuanchun Zhou",
        "Yanjie Fu"
    ],
    "doi": "10.48550/arXiv.2309.13618",
    "arxivId": "2309.13618",
    "url": "https://www.semanticscholar.org/paper/3b28e053bd9d2aef2f289b5103ba62a1bf9b780f",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2309.13618",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Feature transformation aims to generate new pattern-discriminative feature space from original features to improve downstream machine learning (ML) task performances. However, the discrete search space for the optimal feature explosively grows on the basis of combinations of features and operations from low-order forms to high-order forms. Existing methods, such as exhaustive search, expansion reduction, evolutionary algorithms, reinforcement learning, and iterative greedy, suffer from large search space. Overly emphasizing efficiency in algorithm design usually sacrifices stability or robustness. To fundamentally fill this gap, we reformulate discrete feature transformation as a continuous space optimization task and develop an embedding-optimization-reconstruction framework. This framework includes four steps: 1) reinforcement-enhanced data preparation, aiming to prepare high-quality transformation-accuracy training data; 2) feature transformation operation sequence embedding, intending to encapsulate the knowledge of prepared training data within a continuous space; 3) gradient-steered optimal embedding search, dedicating to uncover potentially superior embeddings within the learned space; 4) transformation operation sequence reconstruction, striving to reproduce the feature transformation solution to pinpoint the optimal feature space.",
    "citationCount": 25,
    "referenceCount": 34
}