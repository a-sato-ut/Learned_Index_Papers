{
    "paperId": "b1189c2f9204a149b627f6a353118def45b3efd7",
    "title": "CCNx Router on FPGA Accelerator Achieving Predictable Performance",
    "year": 2023,
    "venue": "Information-Centric Networking",
    "authors": [
        "Atsushi Ooka",
        "H. Asaeda"
    ],
    "doi": "10.1145/3623565.3623710",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/b1189c2f9204a149b627f6a353118def45b3efd7",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Information-centric networking (ICN) is a prominent architecture that realizes content-aware network services through name-based communications. A programmable ICN router implemented on a field-programmable gate array (FPGA) accelerator can achieve predictable performance for advanced service requirements, such as low latency and high throughput. However, owing to the tight resource constraints, implementing ICN functions on an FPGA is a huge challenge, as ICN requires frequent update tables for maintaining long and variable-length content names and access to caching devices capable of storing large-volume content. In this study, we designed and implemented an FPGA router that incorporates an ICN by applying the CCNx v1.0 protocol specification. The FPGA router implemented a unified status table on a large-capacity DRAM that stored 10 million variable-length content name prefixes. Additionally, we introduced a DRAM bank allocation that is unaffected by slow random accesses and reduces table access latency, and a Row-Bank-Column memory address mapping scheme that reduces the access time to heavily loaded in-network cache storage. We present the evaluation results of the proposed architecture implemented on the NetFPGA-SUME board, revealing 10 Gbps or 2.8 Mpps throughput and â‰¤ 300 ns jitter.",
    "citationCount": 2,
    "referenceCount": 6
}