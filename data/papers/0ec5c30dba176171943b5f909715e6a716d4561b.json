{
    "paperId": "0ec5c30dba176171943b5f909715e6a716d4561b",
    "title": "Learned garbage collection",
    "year": 2020,
    "venue": "MAPL@PLDI",
    "authors": [
        "Lujing Cen",
        "Ryan Marcus",
        "Hongzi Mao",
        "Justin Emile Gottschlich",
        "Mohammad Alizadeh",
        "Tim Kraska"
    ],
    "doi": "10.1145/3394450.3397469",
    "arxivId": "2004.13301",
    "url": "https://www.semanticscholar.org/paper/0ec5c30dba176171943b5f909715e6a716d4561b",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3394450.3397469",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Several programming languages use garbage collectors (GCs) to automatically manage memory for the programmer. Such collectors must decide when to look for unreachable objects to free, which can have a large performance impact on some applications. In this preliminary work, we propose a design for a learned garbage collector that autonomously learns over time when to perform collections. By using reinforcement learning, our design can incorporate user-defined reward functions, allowing an autonomous garbage collector to learn to optimize the exact metric the user desires (e.g., request latency or queries per second). We conduct an initial experimental study on a prototype, demonstrating that an approach based on tabular Q learning may be promising.",
    "citationCount": 15,
    "referenceCount": 39
}