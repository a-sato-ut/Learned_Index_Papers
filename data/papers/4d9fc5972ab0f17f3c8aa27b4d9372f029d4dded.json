{
    "paperId": "4d9fc5972ab0f17f3c8aa27b4d9372f029d4dded",
    "title": "Adversarial Attacks on Large Language Model-Based System and Mitigating Strategies: A Case Study on ChatGPT",
    "year": 2023,
    "venue": "Security and Communication Networks",
    "authors": [
        "Bowen Liu",
        "Boao Xiao",
        "Xutong Jiang",
        "Siyuan Cen",
        "Xin He",
        "Wanchun Dou"
    ],
    "doi": "10.1155/2023/8691095",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/4d9fc5972ab0f17f3c8aa27b4d9372f029d4dded",
    "isOpenAccess": true,
    "openAccessPdf": "https://downloads.hindawi.com/journals/scn/2023/8691095.pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Machine learning algorithms are at the forefront of the development of advanced information systems. The rapid progress in machine learning technology has enabled cutting-edge large language models (LLMs), represented by GPT-3 and ChatGPT, to perform a wide range of NLP tasks with a stunning performance. However, research on adversarial machine learning highlights the need for these intelligent systems to be more robust. Adversarial machine learning aims to evaluate attack and defense mechanisms to prevent the malicious exploitation of these systems. In the case of ChatGPT, adversarial induction prompt can cause the model to generate toxic texts that could pose serious security risks or propagate false information. To address this challenge, we first analyze the effectiveness of inducing attacks on ChatGPT. Then, two effective mitigating mechanisms are proposed. The first is a training-free prefix prompt mechanism to detect and prevent the generation of toxic texts. The second is a RoBERTa-based mechanism that identifies manipulative or misleading input text via external detection models. The availability of this method is demonstrated through experiments.",
    "citationCount": 44,
    "referenceCount": 36
}