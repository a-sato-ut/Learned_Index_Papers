{
    "paperId": "a0df462ee5d0973a33ba6259a172e0017ae87dd5",
    "title": "Generative Retrieval Meets Multi-Graded Relevance",
    "year": 2024,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Yubao Tang",
        "Ruqing Zhang",
        "J. Guo",
        "M. D. Rijke",
        "Wei Chen",
        "Xueqi Cheng"
    ],
    "doi": "10.48550/arXiv.2409.18409",
    "arxivId": "2409.18409",
    "url": "https://www.semanticscholar.org/paper/a0df462ee5d0973a33ba6259a172e0017ae87dd5",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Generative retrieval represents a novel approach to information retrieval. It uses an encoder-decoder architecture to directly produce relevant document identifiers (docids) for queries. While this method offers benefits, current approaches are limited to scenarios with binary relevance data, overlooking the potential for documents to have multi-graded relevance. Extending generative retrieval to accommodate multi-graded relevance poses challenges, including the need to reconcile likelihood probabilities for docid pairs and the possibility of multiple relevant documents sharing the same identifier. To address these challenges, we introduce a framework called GRaded Generative Retrieval (GR$^2$). GR$^2$ focuses on two key components: ensuring relevant and distinct identifiers, and implementing multi-graded constrained contrastive training. First, we create identifiers that are both semantically relevant and sufficiently distinct to represent individual documents effectively. This is achieved by jointly optimizing the relevance and distinctness of docids through a combination of docid generation and autoencoder models. Second, we incorporate information about the relationship between relevance grades to guide the training process. We use a constrained contrastive training strategy to bring the representations of queries and the identifiers of their relevant documents closer together, based on their respective relevance grades. Extensive experiments on datasets with both multi-graded and binary relevance demonstrate the effectiveness of GR$^2$.",
    "citationCount": 4,
    "referenceCount": 105
}