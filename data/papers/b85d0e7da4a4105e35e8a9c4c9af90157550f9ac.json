{
    "paperId": "b85d0e7da4a4105e35e8a9c4c9af90157550f9ac",
    "title": "From array algebra to energy efficiency on GPUs: Data and hardware shapes with dimension-lifting to optimize memory-processor layouts",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "L. Mullin"
    ],
    "doi": "10.48550/arXiv.2306.11148",
    "arxivId": "2306.11148",
    "url": "https://www.semanticscholar.org/paper/b85d0e7da4a4105e35e8a9c4c9af90157550f9ac",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2306.11148",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We present a new formulation for parallel matrix multiplication (MM) to out-perform the standard row-column code design. This algorithm is formulated in the MoA formalism (A Mathematics of Arrays) and combines an array view of hardware (dimension-lifting) to extend indexing to physical memory/processing units, with a contiguous data layout derived from static transformations. This view of a hardware-software model is thus a bridging model in the sense of Valiant's BSP. OpenACCcode was derived from the MoA expressions's normal form, producing optimal block sizes using the static information of types and shapes. Experiments were run on Nvidia V100 GPUs and reveal energy consumption which is quadratic in N, i.e. linear in the size of matrix. More generally this approach may be an ideal way of formulating, optimizing, and mapping array algorithms to embedded hardware. This work builds upon recently published results of NREL scientists. .",
    "citationCount": 1,
    "referenceCount": 35
}