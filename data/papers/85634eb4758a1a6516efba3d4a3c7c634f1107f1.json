{
    "paperId": "85634eb4758a1a6516efba3d4a3c7c634f1107f1",
    "title": "Elimination (a,b)-trees with fast, durable updates",
    "year": 2021,
    "venue": "ACM SIGPLAN Symposium on Principles & Practice of Parallel Programming",
    "authors": [
        "Anubhav Srivastava",
        "Trevor Brown"
    ],
    "doi": "10.1145/3503221.3508441",
    "arxivId": "2112.15259",
    "url": "https://www.semanticscholar.org/paper/85634eb4758a1a6516efba3d4a3c7c634f1107f1",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2112.15259",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Many concurrent dictionary implementations are designed and optimized for read-mostly workloads with uniformly distributed keys, and often perform poorly on update-heavy workloads. In this work, we first present a concurrent (a,b)-tree, the OCC-ABtree, which outperforms its fastest competitor by up to 2x on uniform update-heavy workloads, and is competitive on other workloads. We then turn our attention to skewed update-heavy workloads (which feature many inserts/deletes on the same key) and introduce the Elim-ABtree, which features a new optimization called publishing elimination. In publishing elimination, concurrent inserts and deletes to a key are reordered to eliminate them. This reduces the number of writes in the data structure. The Elim-ABtree achieves up to 2.5x the performance of its fastest competitor (including the OCC-ABtree). The OCC-ABtree and Elim-ABtree are linearizable. We also introduce durable linearizable versions1 for systems with Intel Optane DCPMM non-volatile main memory that are nearly as fast.",
    "citationCount": 16,
    "referenceCount": 73
}