{
    "paperId": "4e042409c4dc5210787fcd149485a59be3eef0f6",
    "title": "Lecture Notes on Neural Information Retrieval",
    "year": 2022,
    "venue": "arXiv.org",
    "authors": [
        "N. Tonellotto"
    ],
    "doi": "10.48550/arXiv.2207.13443",
    "arxivId": "2207.13443",
    "url": "https://www.semanticscholar.org/paper/4e042409c4dc5210787fcd149485a59be3eef0f6",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2207.13443",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "These lecture notes focus on the recent advancements in neural information retrieval, with particular emphasis on the systems and models exploiting transformer networks. These networks, originally proposed by Google in 2017, have seen a large success in many natural language processing and information retrieval tasks. While there are many fantastic textbook on information retrieval and natural language processing as well as specialised books for a more advanced audience, these lecture notes target people aiming at developing a basic understanding of the main information retrieval techniques and approaches based on deep learning. These notes have been prepared for a IR graduate course of the MSc program in Artificial Intelligence and Data Engineering at the University of Pisa, Italy.",
    "citationCount": 19,
    "referenceCount": 104
}