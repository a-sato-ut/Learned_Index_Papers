{
    "paperId": "0c82e92f8a47aa70e4d64a85d936a4a36be56dd6",
    "title": "A Multi-level Compiler Backend for Accelerated Micro-kernels Targeting RISC-V ISA Extensions",
    "year": 2025,
    "venue": "IEEE/ACM International Symposium on Code Generation and Optimization",
    "authors": [
        "Alexandre Lopoukhine",
        "F. Ficarelli",
        "Christos Vasiladiotis",
        "Anton Lydike",
        "Josse Van Delm",
        "Alban Dutilleul",
        "Luca Benini",
        "Marian Verhelst",
        "Tobias Grosser"
    ],
    "doi": "10.1145/3696443.3708952",
    "arxivId": "2502.04063",
    "url": "https://www.semanticscholar.org/paper/0c82e92f8a47aa70e4d64a85d936a4a36be56dd6",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2502.04063",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "High-performance micro-kernels must fully exploit todayâ€™s diverse and specialized hardware to deliver peak performance to deep neural networks (DNNs). While higher-level optimizations for DNNs are offered by numerous compilers (e.g., MLIR, TVM, OpenXLA), performance-critical micro-kernels are left to specialized code generators or handwritten assembly. Even though widely-adopted compilers (e.g., LLVM, GCC) offer tuned backends, their CPU-focused input abstraction, unstructured intermediate representation (IR) and general-purpose best-effort design inhibit tailored code generation for innovative hardware. We think it is time to widen the classical hourglass backend and embrace progressive lowering across a diverse set of structured abstractions to bring domain-specific code generation to compiler backends. We demonstrate this concept by implementing a custom backend for a RISC-V-based accelerator with hardware loops and streaming registers, leveraging knowledge about the hardware at levels of abstraction that match its custom instruction set architecture (ISA). We use incremental register allocation over structured IRs, while dropping classical spilling heuristics, and show up to 90% floating-point unit (FPU) utilization across key DNN kernels. By breaking the backend hourglass model, we reopen the path from domain-specific abstractions to specialized hardware.",
    "citationCount": 3,
    "referenceCount": 73
}