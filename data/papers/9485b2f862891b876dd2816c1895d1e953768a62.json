{
    "paperId": "9485b2f862891b876dd2816c1895d1e953768a62",
    "title": "CorDEL: A Contrastive Deep Learning Approach for Entity Linkage",
    "year": 2020,
    "venue": "Industrial Conference on Data Mining",
    "authors": [
        "Zhengyang Wang",
        "Bunyamin Sisman",
        "Hao Wei",
        "Xin Dong",
        "Shuiwang Ji"
    ],
    "doi": "10.1109/ICDM50108.2020.00171",
    "arxivId": "2009.07203",
    "url": "https://www.semanticscholar.org/paper/9485b2f862891b876dd2816c1895d1e953768a62",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2009.07203",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Entity linkage (EL) is a critical problem in data cleaning and integration. In the past several decades, EL has typically been done by rule-based systems or traditional machine learning models with hand-curated features, both of which heavily depend on manual human inputs. With the ever-increasing growth of new data, deep learning (DL) based approaches have been proposed to alleviate the high cost of EL associated with the traditional models. Existing exploration of DL models for EL strictly follows the well-known twin-network architecture. However, we argue that the twin-network architecture is sub-optimal to EL, leading to inherent drawbacks of existing models. In order to address the drawbacks, we propose a novel and generic contrastive DL framework for EL. The proposed framework is able to capture both syntactic and semantic matching signals and pays attention to subtle but critical differences. Based on the framework, we develop a contrastive DL approach for EL, CorDEL, with a simple yet powerful variant called CorDEL-Sum. We evaluate CorDEL with extensive experiments conducted on both public benchmark datasets and a real-world dataset. CorDEL outperforms previous state-of-the-art models by 5.2% on public benchmark datasets. Moreover, CorDEL yields a 29.4% improvement over the current best DL model on the real-world dataset, while reducing the number of training parameters by 96.8%.",
    "citationCount": 21,
    "referenceCount": 54
}