{
    "paperId": "c605cec07d7d190510e5487add246e1b52de423f",
    "title": "TAPS: Connecting Certified and Adversarial Training",
    "year": 2023,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Yuhao Mao",
        "Mark Niklas Muller",
        "Marc Fischer",
        "Martin T. Vechev"
    ],
    "doi": "10.48550/arXiv.2305.04574",
    "arxivId": "2305.04574",
    "url": "https://www.semanticscholar.org/paper/c605cec07d7d190510e5487add246e1b52de423f",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2305.04574",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Training certifiably robust neural networks remains a notoriously hard problem. On one side, adversarial training optimizes under-approximations of the worst-case loss, which leads to insufficient regularization for certification, while on the other, sound certified training methods optimize loose over-approximations, leading to over-regularization and poor (standard) accuracy. In this work we propose TAPS, an (unsound) certified training method that combines IBP and PGD training to yield precise, although not necessarily sound, worst-case loss approximations, reducing over-regularization and increasing certified and standard accuracies. Empirically, TAPS achieves a new state-of-the-art in many settings, e.g., reaching a certified accuracy of $22\\%$ on TinyImageNet for $\\ell_\\infty$-perturbations with radius $\\epsilon=1/255$. We make our implementation and networks public at https://github.com/eth-sri/taps.",
    "citationCount": 11,
    "referenceCount": 51
}