{
    "paperId": "e7e1feff05edf89cac6c2e6de46815a3f89144ef",
    "title": "Tensor Program Optimization with Probabilistic Programs",
    "year": 2022,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Junru Shao",
        "Xiyou Zhou",
        "Siyuan Feng",
        "Bohan Hou",
        "Ruihang Lai",
        "Hongyi Jin",
        "Wuwei Lin",
        "Masahiro Masuda",
        "Cody Hao Yu",
        "Tianqi Chen"
    ],
    "doi": "10.48550/arXiv.2205.13603",
    "arxivId": "2205.13603",
    "url": "https://www.semanticscholar.org/paper/e7e1feff05edf89cac6c2e6de46815a3f89144ef",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2205.13603",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Automatic optimization for tensor programs becomes increasingly important as we deploy deep learning in various environments, and efficient optimization relies on a rich search space and effective search. Most existing efforts adopt a search space which lacks the ability to efficiently enable domain experts to grow the search space. This paper introduces MetaSchedule, a domain-specific probabilistic programming language abstraction to construct a rich search space of tensor programs. Our abstraction allows domain experts to analyze the program, and easily propose stochastic choices in a modular way to compose program transformation accordingly. We also build an end-to-end learning-driven framework to find an optimized program for a given search space. Experimental results show that MetaSchedule can cover the search space used in the state-of-the-art tensor program optimization frameworks in a modular way. Additionally, it empowers domain experts to conveniently grow the search space and modularly enhance the system, which brings 48% speedup on end-to-end deep learning workloads.",
    "citationCount": 40,
    "referenceCount": 61
}