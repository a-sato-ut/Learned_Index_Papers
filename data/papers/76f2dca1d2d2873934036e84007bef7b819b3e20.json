{
    "paperId": "76f2dca1d2d2873934036e84007bef7b819b3e20",
    "title": "Comprehend Then Predict: Prompting Large Language Models for Recommendation with Semantic and Collaborative Data",
    "year": 2025,
    "venue": "ACM Trans. Inf. Syst.",
    "authors": [
        "Zhiang Dong",
        "Liya Hu",
        "Jingyuan Chen",
        "Zhihua Wang",
        "Fei Wu"
    ],
    "doi": "10.1145/3716499",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/76f2dca1d2d2873934036e84007bef7b819b3e20",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recommender systems primarily utilize userâ€“item interactions (i.e., collaborative information) and auxiliary textual information (i.e., semantic information) to infer user preferences and provide recommendations. With the advancement in large language models (LLMs), attempts have been made to incorporate their remarkable language comprehension capabilities into recommendation tasks. However, existing LLM4Rec methods face challenges in seamlessly integrating both collaborative and semantic information, as there is an inherent gap between these two types of data. Moreover, these methods struggle to capture the fine-grained distinctions in user preferences, which are essential in recommendation tasks, due to the loss design of LLMs. To address these issues, we propose a multi-stage prompt-tuning method for leveraging pre-trained LLMs in various recommendation tasks, named SCRec. Specifically, SCRec leverages Semantic and Collaborative information as supervision signals in two distinct stages: the semantic prompt-tuning stage and the collaborative prompt-tuning stage. This method breaks down user and item representations into semantic and collaborative perspectives, enabling a pre-trained LLM to first deduce the qualitative preferences of users over items from semantic information, and then generate quantitative recommendations from collaborative information. In addition, we propose a meta-mapping approach to provide personalized mapping functions for encoding collaborative information and integrate a novel numeric-informed head based on MSE loss for LLM in the second stage, which helps to better capture fine-grained distinctions in user preferences. Experiments on three public datasets for rating prediction and top-N recommendation tasks demonstrate that our method surpasses both conventional and LLM-based techniques, showing the strength of sequentially merging semantic and collaborative information in recommendation tasks.",
    "citationCount": 8,
    "referenceCount": 87
}