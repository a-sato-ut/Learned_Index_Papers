{
    "paperId": "6112ff23be3c9e3c81f19bea90575cbac900f5ba",
    "title": "Towards Light‐Weight Portrait Matting via Parameter Sharing",
    "year": 2020,
    "venue": "Computer graphics forum (Print)",
    "authors": [
        "Yutong Dai",
        "Hao Lu",
        "Chunhua Shen"
    ],
    "doi": "10.1111/cgf.14179",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/6112ff23be3c9e3c81f19bea90575cbac900f5ba",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Traditional portrait matting methods typically consist of a trimap estimation network and a matting network. Here, we propose a new light‐weight portrait matting approach, termed parameter‐sharing portrait matting (PSPM). Different from conventional portrait matting models where the encoder and decoder networks in two tasks are often separately designed, here a single encoder is employed for the two tasks in PSPM, while each task still has its task‐specific decoder. Thus, the role of the encoder is to extract semantic features and two decoders function as a bridge between low‐resolution feature maps generated by the encoder and high‐resolution feature maps for pixel‐wise classification/regression. In particular, three variants capable of implementing the parameter‐sharing portrait matting network are proposed and investigated, respectively. As demonstrated in our experiments, model capacity and computation costs can be reduced significantly, by up to 57.8% and 40.5% , respectively, with PSPM, whereas the matting accuracy only slightly deteriorates. In addition, qualitative and quantitative evaluations show that sharing the encoder is an effective way to achieve portrait matting with limited computational budgets, indicating a promising direction for applications of real‐time portrait matting on mobile devices.",
    "citationCount": 6,
    "referenceCount": 40
}