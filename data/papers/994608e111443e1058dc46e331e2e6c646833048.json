{
    "paperId": "994608e111443e1058dc46e331e2e6c646833048",
    "title": "Prototypical Extreme Multi-label Classification with a Dynamic Margin Loss",
    "year": 2024,
    "venue": "North American Chapter of the Association for Computational Linguistics",
    "authors": [
        "Kunal Dahiya",
        "Diego Ortego",
        "David Jim'enez"
    ],
    "doi": "10.48550/arXiv.2410.20401",
    "arxivId": "2410.20401",
    "url": "https://www.semanticscholar.org/paper/994608e111443e1058dc46e331e2e6c646833048",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Extreme Multi-label Classification (XMC) methods predict relevant labels for a given query in an extremely large label space. Recent works in XMC address this problem using deep encoders that project text descriptions to an embedding space suitable for recovering the closest labels. However, learning deep models can be computationally expensive in large output spaces, resulting in a trade-off between high performing brute-force approaches and efficient solutions. In this paper, we propose PRIME, a XMC method that employs a novel prototypical contrastive learning technique to reconcile efficiency and performance surpassing brute-force approaches. We frame XMC as a data-to-prototype prediction task where label prototypes aggregate information from related queries. More precisely, we use a shallow transformer encoder that we coin as Label Prototype Network, which enriches label representations by aggregating text-based embeddings, label centroids and learnable free vectors. We jointly train a deep encoder and the Label Prototype Network using an adaptive triplet loss objective that better adapts to the high granularity and ambiguity of extreme label spaces. PRIME achieves state-of-the-art results in several public benchmarks of different sizes and domains, while keeping the model efficient.",
    "citationCount": 1,
    "referenceCount": 56
}