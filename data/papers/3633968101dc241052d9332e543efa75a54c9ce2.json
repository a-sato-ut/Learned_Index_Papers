{
    "paperId": "3633968101dc241052d9332e543efa75a54c9ce2",
    "title": "Better Private Distribution Testing by Leveraging Unverified Auxiliary Data",
    "year": 2025,
    "venue": "Annual Conference Computational Learning Theory",
    "authors": [
        "M. Aliakbarpour",
        "Arnav Burudgunte",
        "Cl'ement Cannone",
        "R. Rubinfeld"
    ],
    "doi": "10.48550/arXiv.2503.14709",
    "arxivId": "2503.14709",
    "url": "https://www.semanticscholar.org/paper/3633968101dc241052d9332e543efa75a54c9ce2",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We extend the framework of augmented distribution testing (Aliakbarpour, Indyk, Rubinfeld, and Silwal, NeurIPS 2024) to the differentially private setting. This captures scenarios where a data analyst must perform hypothesis testing tasks on sensitive data, but is able to leverage prior knowledge (public, but possibly erroneous or untrusted) about the data distribution. We design private algorithms in this augmented setting for three flagship distribution testing tasks, uniformity, identity, and closeness testing, whose sample complexity smoothly scales with the claimed quality of the auxiliary information. We complement our algorithms with information-theoretic lower bounds, showing that their sample complexity is optimal (up to logarithmic factors).",
    "citationCount": 0,
    "referenceCount": 8
}