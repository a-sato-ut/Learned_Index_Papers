{
    "paperId": "a8e2410db0243aed9bd718e853e0aa2058fa5698",
    "title": "Trust in Machine Learning Models: Global and Individual Assessment",
    "year": 2024,
    "venue": "2024 IEEE International Conference on Data Mining Workshops (ICDMW)",
    "authors": [
        "Simão Paredes",
        "T. Rocha",
        "Sónia Sousa",
        "J. Henriques",
        "José Sousa",
        "Lino Gonçalves"
    ],
    "doi": "10.1109/ICDMW65004.2024.00074",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/a8e2410db0243aed9bd718e853e0aa2058fa5698",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Medicine",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Machine Learning (ML) models are frequently developed for application in the healthcare domain, particularly to support clinical decision-making. Despite their potential utility, their effective application in real-world scenarios remains quite limited. This apparent contradiction is primarily due to a significant lack of trust, since ML models are often \"black box\" systems, which may be critical in clinical decision with significant impact on users.To address this problem, trust assessment is proposed at two distinct levels: i) global (ML model) evaluation; ii) individual (instance) assessment.Global assessment is based on three different parameters: i) model robustness (stability assessment); ii) confidence (95% CI of geometric mean of the model); iii) interpretability (comparison of respective features ranking with clinical evidence). Naturally, the global performance of the model has also to be considered.The individual (pointwise) evaluation is based on a metric of reliability applied in the prediction of a specific instance.The proposed strategy was applied to cardiovascular disease context. A dataset of patients with Acute Coronary Syndrome (ACS) was used for validation. This dataset includes N=1544 patients and was provided by a Portuguese hospital.The obtained results suggest that global trust assessment can be successfully implemented, enhancing physicians' trust in a specific model. Meanwhile, individual assessment demonstrates the ability to distinguish between reliable and unreliable predictions (instance level). The potential combination of these two complementary perspectives could be a valuable tool in the support to clinical decision.",
    "citationCount": 0,
    "referenceCount": 19
}