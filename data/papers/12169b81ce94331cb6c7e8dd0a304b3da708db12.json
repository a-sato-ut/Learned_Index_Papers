{
    "paperId": "12169b81ce94331cb6c7e8dd0a304b3da708db12",
    "title": "Accelerating the Inference of Deep Learning-based CSI Feedback on a General-purpose CPU",
    "year": 2024,
    "venue": "International Conference on Innovative Computing and Cloud Computing",
    "authors": [
        "Jieting Xiao",
        "Yilun Jiang",
        "Pengpeng Song",
        "Xiaojun Hei"
    ],
    "doi": "10.1109/ICCC62479.2024.10682041",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/12169b81ce94331cb6c7e8dd0a304b3da708db12",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) are transforming industries worldwide and the telecom industry is no exception. Nowadays, AI/ML technologies have been applied in 5G systems, mostly in network automation and non-real-time functionalities such as energy savings, load balancing, and mobility optimization. For future radio access networks, it is even more critical to investigate $\\mathrm{AI} / \\mathrm{ML}$ applications in real-time processing, where the AI/ML-assisted channel state information (CSI) feedback has been one of the 3GPP Rel-18 recommended use cases for AI-native radio access networks (RAN). In this paper, we investigate the feasibility and performance of a Transformer-based CSI feedback scheme on a general purpose CPU platform. We also propose acceleration schemes for this Transformer model. Our experiment results show that our proposed optimization techniques such as operator fusion, weight pre-packing, and automatic precision conversion, together with the advanced matrix extension (AMX) hardware accelerator, can significantly reduce the inference latency by $\\mathbf{4 6. 8 \\%}$. Our study also demonstrates that a general-purpose $\\mathbf{x 6 6}$ CPU platform can support the real-time inference of AI models in 5G vRAN. In comparison to the GPU platform, we demonstrate that the CPU platform with hardware accelerator and software optimizations can achieve comparable $\\mathrm{AI} / \\mathrm{ML}$ inference performance; in small batch size scenarios, the CPU platform can even outperform GPU.",
    "citationCount": 0,
    "referenceCount": 18
}