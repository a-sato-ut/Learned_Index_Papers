{
    "paperId": "b944a8f2cddbc4cae1224eab84673f034284881c",
    "title": "TOME: A Two-stage Approach for Model-based Retrieval",
    "year": 2023,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "authors": [
        "Ruiyang Ren",
        "Wayne Xin Zhao",
        "J. Liu",
        "Huaqin Wu",
        "Ji-rong Wen",
        "Haifeng Wang"
    ],
    "doi": "10.48550/arXiv.2305.11161",
    "arxivId": "2305.11161",
    "url": "https://www.semanticscholar.org/paper/b944a8f2cddbc4cae1224eab84673f034284881c",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2305.11161",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recently, model-based retrieval has emerged as a new paradigm in text retrieval that discards the index in the traditional retrieval model and instead memorizes the candidate corpora using model parameters. This design employs a sequence-to-sequence paradigm to generate document identifiers, which enables the complete capture of the relevance between queries and documents and simplifies the classic index-retrieval-rerank pipeline. Despite its attractive qualities, there remain several major challenges in model-based retrieval, including the discrepancy between pre-training and fine-tuning, and the discrepancy between training and inference. To deal with the above challenges, we propose a novel two-stage model-based retrieval approach called TOME, which makes two major technical contributions, including the utilization of tokenized URLs as identifiers and the design of a two-stage generation architecture. We also propose a number of training strategies to deal with the training difficulty as the corpus size increases. Extensive experiments and analysis on MS MARCO and Natural Questions demonstrate the effectiveness of our proposed approach, and we investigate the scaling laws of TOME by examining various influencing factors.",
    "citationCount": 32,
    "referenceCount": 36
}