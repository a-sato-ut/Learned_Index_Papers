{
    "paperId": "79f98a5324ad4e7121ff6d6be96057590bcdb4c2",
    "title": "Neura: a specialized large language model solution in neurology",
    "year": 2024,
    "venue": "medRxiv",
    "authors": [
        "MD Sami Barrit",
        "MD Nathan Torcida",
        "MD PhD Aur´elien Mazeraud",
        "MD PhD S´ebastien Boulogne",
        "MD Jeanne Benoit",
        "MD Timoth´ee Carette",
        "PhD Thibault Carron",
        "MD Bertil Delsaut",
        "MD Eva Diab",
        "MD Hugo Kermorvant",
        "MD PhD Adil Maarouf",
        "Sofia",
        "MD Maldonado Slootjes",
        "MD Sylvain Redon",
        "MD Alexis Robin",
        "MD Sofiene Hadidane",
        "MD Vincent Harlay",
        "MD Vito Tota",
        "MD Tanguy Madec",
        "MD Alexandre Niset",
        "Salim",
        "MD El Hadwe",
        "MD PhD Nicolas Massager",
        "MD PhD Stanislas Lagarde",
        "MD PhD Romain Carron"
    ],
    "doi": "10.1101/2024.02.11.24302658",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/79f98a5324ad4e7121ff6d6be96057590bcdb4c2",
    "isOpenAccess": true,
    "openAccessPdf": "https://www.medrxiv.org/content/medrxiv/early/2024/02/13/2024.02.11.24302658.full.pdf",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Medicine",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Large language models (LLM) ability in natural language processing holds promise for diverse applications, yet their deployment in fields such as neurology faces domain-specific challenges. Hence, we introduce Neura: a scalable, explainable solution to specialize LLM. Blindly evaluated on a select set of five complex clinical cases compared to a cohort of 13 neurologists, Neura achieved normalized scores of 86.17% overall, 85% for differential diagnoses, and 88.24% for final diagnoses (55.11%, 46.15%, and 70.93% for neurologists) with rapid response times of 28.8 and 19 seconds (9 minutes and 37.2 seconds and 8 minutes and 51 seconds for neurologists) while consistently providing relevant, accurately cited information. These findings support the emerging role of LLM-driven applications to articulate human-acquired and integrated data with a vast corpus of knowledge, augmenting human experiential reasoning for clinical and research purposes.",
    "citationCount": 6,
    "referenceCount": 25
}