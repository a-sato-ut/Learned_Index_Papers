{
    "paperId": "ca0060ae78cf981323898382356b845fba9a5133",
    "title": "FactorMatte: Redefining Video Matting for Re-Composition Tasks",
    "year": 2022,
    "venue": "ACM Transactions on Graphics",
    "authors": [
        "Zeqi Gu",
        "Wenqi Xian",
        "Noah Snavely",
        "Abe Davis"
    ],
    "doi": "10.1145/3592423",
    "arxivId": "2211.02145",
    "url": "https://www.semanticscholar.org/paper/ca0060ae78cf981323898382356b845fba9a5133",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2211.02145",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We propose Factor Matting, an alternative formulation of the video matting problem in terms of counterfactual video synthesis that is better suited for re-composition tasks. The goal of factor matting is to separate the contents of a video into independent components, each representing a counterfactual version of the scene where the contents of other components have been removed. We show that factor matting maps well to a more general Bayesian framing of the matting problem that accounts for complex conditional interactions between layers. Based on this observation, we present a method for solving the factor matting problem that learns augmented patch-based appearance priors to produce useful decompositions even for video with complex cross-layer interactions like splashes, shadows, and reflections. Our method is trained per-video and does not require external training data or any knowledge about the 3D structure of the scene. Through extensive experiments, we show that it is able to produce useful decompositions of scenes with such complex interactions while performing competitively on classical matting tasks as well. We also demonstrate the benefits of our approach on a wide range of downstream video editing tasks. Our project website is at: https://factormatte.github.io/.",
    "citationCount": 13,
    "referenceCount": 52
}