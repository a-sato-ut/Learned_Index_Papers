{
    "paperId": "a509670659e8b054e2b7d1b6f8a0bc722398fa62",
    "title": "PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation",
    "year": 2024,
    "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems",
    "authors": [
        "Jason Ansel",
        "Edward Yang",
        "Horace He",
        "N. Gimelshein",
        "Animesh Jain",
        "Michael Voznesensky",
        "Bin Bao",
        "Peter Bell",
        "David Berard",
        "Evgeni Burovski",
        "Geeta Chauhan",
        "Anjali Chourdia",
        "Will Constable",
        "Alban Desmaison",
        "Zachary DeVito",
        "Elias Ellison",
        "Will Feng",
        "Jiong Gong",
        "Michael Gschwind",
        "Brian Hirsh",
        "Sherlock Huang",
        "Kshiteej Kalambarkar",
        "Laurent Kirsch",
        "Michael Lazos",
        "Mario Lezcano",
        "Yanbo Liang",
        "Jason Liang",
        "Yinghai Lu",
        "C. K. Luk",
        "Bert Maher",
        "Yunjie Pan",
        "Christian Puhrsch",
        "Matthias Reso",
        "Mark-Albert Saroufim",
        "Marcos Yukio Siraichi",
        "Helen Suk",
        "Shunting Zhang",
        "Michael Suo",
        "P. Tillet",
        "Xu Zhao",
        "Eikan Wang",
        "Keren Zhou",
        "Richard Zou",
        "Xiaodong Wang",
        "Ajit Mathews",
        "William Wen",
        "Gregory Chanan",
        "Peng Wu",
        "Soumith Chintala"
    ],
    "doi": "10.1145/3620665.3640366",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/a509670659e8b054e2b7d1b6f8a0bc722398fa62",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This paper introduces two extensions to the popular PyTorch machine learning framework, TorchDynamo and TorchInductor, which implement the torch.compile feature released in PyTorch 2. TorchDynamo is a Python-level just-in-time (JIT) compiler that enables graph compilation in PyTorch programs without sacrificing the flexibility of Python. It achieves this by dynamically modifying Python bytecode before execution and extracting sequences of PyTorch operations into an FX graph, which is then JIT compiled using one of many extensible backends. TorchInductor is the default compiler backend for TorchDynamo, which translates PyTorch programs into OpenAI's Triton for GPUs and C++ for CPUs. Results show that TorchDynamo is able to capture graphs more robustly than prior approaches while adding minimal overhead, and TorchInductor is able to provide a 2.27× inference and 1.41× training geometric mean speedup on an NVIDIA A100 GPU across 180+ real-world models, which outperforms six other compilers. These extensions provide a new way to apply optimizations through compilers in eager mode frameworks like PyTorch.",
    "citationCount": 711,
    "referenceCount": 53
}