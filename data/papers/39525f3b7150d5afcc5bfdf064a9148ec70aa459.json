{
    "paperId": "39525f3b7150d5afcc5bfdf064a9148ec70aa459",
    "title": "Fast polynomial multiplication using matrix multiplication accelerators with applications to NTRU on Apple M1/M3 SoCs",
    "year": 2024,
    "venue": "IACR Cryptology ePrint Archive",
    "authors": [
        "Décio Luiz Gazzoni Filho",
        "Guilherme Brandão",
        "Julio López"
    ],
    "doi": "10.62056/a3txommol",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/39525f3b7150d5afcc5bfdf064a9148ec70aa459",
    "isOpenAccess": true,
    "openAccessPdf": "https://cic.iacr.org/p/1/1/9/pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Efficient polynomial multiplication routines are critical to the performance of lattice-based post-quantum cryptography (PQC). As PQC standards only recently started to emerge, CPUs still lack specialized instructions to accelerate such routines. Meanwhile, deep learning has grown immeasurably in importance. Its workloads call for teraflops-level of processing power for linear algebra operations, mainly matrix multiplication. Computer architects have responded by introducing ISA extensions, coprocessors and special-purpose cores to accelerate such operations. In particular, Apple ships an undocumented matrix-multiplication coprocessor, AMX, in hundreds of millions of mobile phones, tablets and personal computers. Our work repurposes AMX to implement polynomial multiplication and applies it to the NTRU cryptosystem, setting new speed records on the Apple M1 and M3 systems-on-chip (SoCs): polynomial multiplication, key generation, encapsulation and decapsulation are sped up by \n \n 1.54\n \n –\n \n 3.07\n ×\n \n , \n \n 1.08\n \n –\n \n 1.33\n ×\n \n , \n \n 1.11\n \n –\n \n 1.50\n ×\n \n and \n \n 1.20\n \n –\n \n 1.98\n ×\n \n , respectively, over the previous state-of-the-art.",
    "citationCount": 3,
    "referenceCount": 45
}