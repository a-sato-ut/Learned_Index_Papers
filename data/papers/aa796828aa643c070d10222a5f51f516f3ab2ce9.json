{
    "paperId": "aa796828aa643c070d10222a5f51f516f3ab2ce9",
    "title": "Efficient Object Embedding for Spliced Image Retrieval",
    "year": 2021,
    "venue": "Computer Vision and Pattern Recognition",
    "authors": [
        "Bor-Chun Chen",
        "Zuxuan Wu",
        "Larry S. Davis",
        "S. Lim"
    ],
    "doi": "10.1109/CVPR46437.2021.01472",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/aa796828aa643c070d10222a5f51f516f3ab2ce9",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/1905.11903",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Detecting spliced images is one of the emerging challenges in computer vision. Unlike prior methods that focus on detecting low-level artifacts generated during the manipulation process, we use an image retrieval approach to tackle this problem. When given a spliced query image, our goal is to retrieve the original image from a database of authentic images. To achieve this goal, we propose representing an image by its constituent objects based on the intuition that the finest granularity of manipulations is oftentimes at the object-level. We introduce a framework, object embeddings for spliced image retrieval (OE-SIR), that utilizes modern object detectors to localize object regions. Each region is then embedded and collectively used to represent the image. Further, we propose a student-teacher training paradigm for learning discriminative embeddings within object regions to avoid expensive multiple forward passes. Detailed analysis of the efficacy of different feature embedding models is also provided in this study. Extensive experimental results show that the OE-SIR achieves state-of-the-art performance in spliced image retrieval.",
    "citationCount": 13,
    "referenceCount": 78
}