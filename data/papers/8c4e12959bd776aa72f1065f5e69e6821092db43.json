{
    "paperId": "8c4e12959bd776aa72f1065f5e69e6821092db43",
    "title": "ECAsT: a large dataset for conversational search and an evaluation of metric robustness",
    "year": 2023,
    "venue": "PeerJ Computer Science",
    "authors": [
        "Haya Al-Thani",
        "B. Jansen",
        "Tamer Elsayed"
    ],
    "doi": "10.7717/peerj-cs.1328",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/8c4e12959bd776aa72f1065f5e69e6821092db43",
    "isOpenAccess": true,
    "openAccessPdf": "https://doi.org/10.7717/peerj-cs.1328",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The Text REtrieval Conference Conversational assistance track (CAsT) is an annual conversational passage retrieval challenge to create a large-scale open-domain conversational search benchmarking. However, as of yet, the datasets used are small, with just more than 1,000 turns and 100 conversation topics. In the first part of this research, we address the dataset limitation by building a much larger novel multi-turn conversation dataset for conversation search benchmarking called Expanded-CAsT (ECAsT). ECAsT is built using a multi-stage solution that uses a combination of conversational query reformulation and neural paraphrasing and also includes a new model to create multi-turn paraphrases. The meaning and diversity of paraphrases are evaluated with human and automatic evaluation. Using this methodology, we produce and release to the research community a conversational search dataset that is 665% more extensive in terms of size and language diversity than is available at the time of this study, with more than 9,200 turns. The augmented dataset not only provides more data but also more language diversity to improve conversational search neural model training and testing. In the second part of the research, we use ECAsT to assess the robustness of traditional metrics for conversational evaluation used in CAsT and identify its bias toward language diversity. Results show the benefits of adding language diversity for improving the collection of pooled passages and reducing evaluation bias. We found that introducing language diversity via paraphrases returned up to 24% new passages compared to only 2% using CAsT baseline.",
    "citationCount": 1,
    "referenceCount": 68
}