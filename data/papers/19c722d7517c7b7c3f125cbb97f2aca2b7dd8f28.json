{
    "paperId": "19c722d7517c7b7c3f125cbb97f2aca2b7dd8f28",
    "title": "Multi-hop Database Reasoning with Virtual Knowledge Graph",
    "year": 2024,
    "venue": "KALLM",
    "authors": [
        "Juhee Son",
        "Yeon Seonwoo",
        "Alice Oh",
        "James Thorne",
        "Seunghyun Yoon"
    ],
    "doi": "10.18653/v1/2024.kallm-1.1",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/19c722d7517c7b7c3f125cbb97f2aca2b7dd8f28",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Application of LLM to database queries on natural language sentences has demonstrated impressive results in both single and multi-hop scenarios.In the existing methodologies, the requirement to re-encode query vectors at each stage for processing multi-hop queries presents a significant bottleneck to the inference speed.This paper proposes VKGFR (Virtual Knowledge Graph based Fact Retriever) that leverages large language models to extract representations corresponding to a sentenceâ€™s knowledge graph, significantly enhancing inference speed for multi-hop reasoning without performance loss.Given that both the queries and natural language database sentences can be structured as a knowledge graph, we suggest extracting a Virtual Knowledge Graph (VKG) representation from sentences with LLM.Over the pre-constructed VKG, our VKGFR conducts retrieval with a tiny model structure, showing performance improvements with higher computational efficiency. We evaluate VKGFR on the WikiNLDB and MetaQA dataset, designed for multi-hop database reasoning over text. The results indicate 13x faster inference speed on the WikiNLDB dataset without performance loss.",
    "citationCount": 1,
    "referenceCount": 28
}