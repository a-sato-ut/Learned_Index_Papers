{
    "paperId": "97f94598e6c110a4a5d4f59ce0b8312f6c60b17e",
    "title": "Caching and Prefetching for Improving ORAM Performance",
    "year": 2024,
    "venue": "2024 54th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)",
    "authors": [
        "Naohiro Hayashibara",
        "Kazuaki Kawabata"
    ],
    "doi": "10.1109/DSN-W60302.2024.00016",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/97f94598e6c110a4a5d4f59ce0b8312f6c60b17e",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Oblivious RAM (ORAM) provides secure data storage by hiding memory access patterns. This technique is fundamental to numerous secure applications. Despite extensive endeavors, while established ORAM schemes offer optimal asymptotic complexity, their actual costs remain excessively high for many compelling applications. This arises due to ORAM's access strategy, which involves interacting with multiple locations to retrieve a single required data block. While existing approaches often focus on optimizing the locations of data, queries, and memory accesses through architectural improvements, there is less focus on data caching and prefetching. Through our experiment, we identify that data caching is essential for improving the latency of ORAM and show that data prefetching can contribute to further improvement of ORAM performance. We then discuss the integration of ORAM with the existing caching and prefetching techniques.",
    "citationCount": 1,
    "referenceCount": 22
}