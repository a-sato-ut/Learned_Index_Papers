{
    "paperId": "42731d0491c279a6481a6fd1a67428f0d18d44c5",
    "title": "Learning the local density of states of a bilayer moir\\'e material in one dimension",
    "year": 2024,
    "venue": "",
    "authors": [
        "Diyi Liu",
        "Alexander B. Watson",
        "Stephen Carr",
        "Mitchell Luskin"
    ],
    "doi": null,
    "arxivId": "2405.06688",
    "url": "https://www.semanticscholar.org/paper/42731d0491c279a6481a6fd1a67428f0d18d44c5",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Physics",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Physics",
            "source": "s2-fos-model"
        },
        {
            "category": "Materials Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recent work of three of the authors showed that the operator which maps the local density of states of a one-dimensional untwisted bilayer material to the local density of states of the same bilayer material at non-zero twist, known as the twist operator, can be learned by a neural network. In this work, we first provide a mathematical formulation of that work, making the relevant models and operator learning problem precise. We then prove that the operator learning problem is well-posed for a family of one-dimensional models. To do this, we first prove existence and regularity of the twist operator by solving an inverse problem. We then invoke the universal approximation theorem for operators to prove existence of a neural network capable of approximating the twist operator.",
    "citationCount": 1,
    "referenceCount": 56
}