{
    "paperId": "673f7886b514254a47a397b0bdc4a350c9a670de",
    "title": "Improving DNN Inference Throughput Using Practical, Per-Input Compute Adaptation",
    "year": 2024,
    "venue": "Symposium on Operating Systems Principles",
    "authors": [
        "Anand Padmanabha Iyer",
        "Mingyu Guan",
        "Yinwei Dai",
        "Rui Pan",
        "Swapnil Gandhi",
        "Ravi Netravali"
    ],
    "doi": "10.1145/3694715.3695978",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/673f7886b514254a47a397b0bdc4a350c9a670de",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3694715.3695978",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Machine learning inference platforms continue to face high request rates and strict latency constraints. Existing solutions largely focus on compressing models to substantially lower compute costs (and time) with mild accuracy degradations. This paper explores an alternate (but complementary) technique that trades off accuracy and resource costs on a perinput granularity: early exit models, which selectively allow certain inputs to exit a model from an intermediate layer. Though intuitive, early exits face fundamental deployment challenges, largely owing to the effects that exiting inputs have on batch size (and resource utilization) throughout model execution. We present E3, the first system that makes early exit models practical for realistic inference deployments. Our key insight is to split and replicate blocks of layers in models in a manner that maintains a constant batch size throughout execution, all the while accounting for resource requirements and communication overheads. Evaluations with NLP and vision models show that E3 can deliver up to 1.74× improvement in goodput (for a fixed cost) or 1.78× reduction in cost (for a fixed goodput). Additionally, E3's goodput wins generalize to autoregressive LLMs (2.8--3.8×) and compressed models (1.67×).",
    "citationCount": 3,
    "referenceCount": 72
}