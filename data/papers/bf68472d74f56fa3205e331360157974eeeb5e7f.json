{
    "paperId": "bf68472d74f56fa3205e331360157974eeeb5e7f",
    "title": "Meta-Learning in Games",
    "year": 2022,
    "venue": "International Conference on Learning Representations",
    "authors": [
        "Keegan Harris",
        "Ioannis Anagnostides",
        "Gabriele Farina",
        "M. Khodak",
        "Zhiwei Steven Wu",
        "T. Sandholm"
    ],
    "doi": "10.48550/arXiv.2209.14110",
    "arxivId": "2209.14110",
    "url": "https://www.semanticscholar.org/paper/bf68472d74f56fa3205e331360157974eeeb5e7f",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2209.14110",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In the literature on game-theoretic equilibrium finding, focus has mainly been on solving a single game in isolation. In practice, however, strategic interactions -- ranging from routing problems to online advertising auctions -- evolve dynamically, thereby leading to many similar games to be solved. To address this gap, we introduce meta-learning for equilibrium finding and learning to play games. We establish the first meta-learning guarantees for a variety of fundamental and well-studied classes of games, including two-player zero-sum games, general-sum games, and Stackelberg games. In particular, we obtain rates of convergence to different game-theoretic equilibria that depend on natural notions of similarity between the sequence of games encountered, while at the same time recovering the known single-game guarantees when the sequence of games is arbitrary. Along the way, we prove a number of new results in the single-game regime through a simple and unified framework, which may be of independent interest. Finally, we evaluate our meta-learning algorithms on endgames faced by the poker agent Libratus against top human professionals. The experiments show that games with varying stack sizes can be solved significantly faster using our meta-learning techniques than by solving them separately, often by an order of magnitude.",
    "citationCount": 14,
    "referenceCount": 129
}