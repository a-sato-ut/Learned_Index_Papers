{
    "paperId": "634e63e114d505af8e9c05546e4836dcb7befeff",
    "title": "Classification of Information Display Types Using Graph Neural Networks",
    "year": 2023,
    "venue": "2023 International Conference on Computational Science and Computational Intelligence (CSCI)",
    "authors": [
        "Yuehan Yin",
        "Michael P. McGuire",
        "Yahya Alqahtani",
        "J. Feng",
        "Joyram Chakraborty"
    ],
    "doi": "10.1109/CSCI62032.2023.00027",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/634e63e114d505af8e9c05546e4836dcb7befeff",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Eye-tracking technology has been applied in many studies, such as visual behavior and usability studies. The collected eye-tracking data has been increasingly utilized with deep learning techniques to solve various machine learning tasks. The aim of this study is to classify eye-tracking data collected from two visual information processing studies using graph neural networks (GNNs) to identify three types of information display. Additionallyâ€™ data-preprocessing and feature engineering techniques are applied to convert the eye-tracking data into graphs with a certain number of features. This study also explores how feature engineering affects the evaluation metrics of the neural network models used in the study. The best results came from our GNN model trained using feature engineered input, which achieved a test accuracy of 90.14%, a precisiontotal of 90.92%, a recalltotal of 88.97%, and an F1 scoretotal of 89.82%. Furthermore, it demon-strates the promise of GNNs in eye-tracking data analysis by allowing the classification of large numbers of eye-tracking results.",
    "citationCount": 0,
    "referenceCount": 23
}