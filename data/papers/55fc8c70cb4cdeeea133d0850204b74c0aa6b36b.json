{
    "paperId": "55fc8c70cb4cdeeea133d0850204b74c0aa6b36b",
    "title": "Flash Crashes in Multi-Agent Systems Using Minority Games And Reinforcement Learning to Test AI Safety",
    "year": 2019,
    "venue": "Online World Conference on Soft Computing in Industrial Applications",
    "authors": [
        "L. Canonico",
        "Nathan J. Mcneese"
    ],
    "doi": "10.1109/WSC40007.2019.9004675",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/55fc8c70cb4cdeeea133d0850204b74c0aa6b36b",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        },
        {
            "category": "Environmental Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "As AI advances and becomes more complicated, it becomes necessary to study the safety implications of its behavior. This paper expands upon prior AI-safety research to create a model to study the harmful outcomes of multi-agent systems. In this paper, we outline previous work that has highlighted multiple aspects of AI-safety research and focus on AI-safety systems in multi-agent systems. After overviewing previous literature, we present a model focused on flash crashes, a concept often found in economics. The model was constructed using an interdisciplinary approach that includes game theory, machine learning, cognitive science and systems theory to study flash crashes in complex human-AI systems. We use the model to study a complex interaction between AI-agents, and our results indicate the multi-agent system in question is prone to cause flash crashes.",
    "citationCount": 4,
    "referenceCount": 37
}