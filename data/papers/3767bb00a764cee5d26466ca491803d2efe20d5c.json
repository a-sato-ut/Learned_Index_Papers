{
    "paperId": "3767bb00a764cee5d26466ca491803d2efe20d5c",
    "title": "A deep learning runoff prediction model based on wavelet decomposition and dynamic feature fusion",
    "year": 2025,
    "venue": "Scientific Reports",
    "authors": [
        "Dong-mei Xu",
        "Qi-qi Zeng",
        "Wen-chuan Wang",
        "Xu-tong Zhang",
        "Yi-yang Wang",
        "Hong-fei Zang"
    ],
    "doi": "10.1038/s41598-025-21007-4",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/3767bb00a764cee5d26466ca491803d2efe20d5c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Environmental Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "To address the stochasticity, time-varying characteristics, and nonlinear dynamics of runoff series, this research proposes a novel deep learning architecture, BWDformer, based on wavelet decomposition and dynamic feature fusion, to enhance the precision of streamflow forecasting. Based on Informer, the model innovatively integrates wavelet decomposition, a dynamic feature fusion module (DFF), and Bayesian optimization to address the limitations of conventional deep learning models in multi-scale feature integration, long-term dependency capture, and dynamic feature adjustment. Specifically, wavelet decomposition is first applied to extract multi-scale features through adaptive time windows, accurately capturing short-term fluctuations, seasonal variations, and long-term trends in runoff data. Then, based on DFF, the feature weights are dynamically adjusted using the attention mechanism to optimize the feature combination, thereby enhancing the model’s ability to analyze complex runoff sequences. Finally, Bayesian optimization is used to efficiently search for hyperparameters, significantly improving the model’s training efficiency. To verify the model’s effectiveness, this study tested it at four hydrological stations: Hongshanhe, Manwan, Baihe, and Tangnaihai. The results show that BWDformer significantly outperforms benchmark models, such as CNN, LSTM, Transformer, and Informer, in terms of MAE, RMSE, R, NSE, and KGE. For example, in Hongshanhe, the MAE is 0.1921, a decrease of 18.82% compared to CNN (0.2366), 4.65% compared to LSTM (0.2014), 15.63% compared to Transformer (0.2277), and 7.87% compared to Informer (0.2086). RMSE decreased by 25.46% compared to CNN, KGE was 0.9651, increased by 18.51% compared to Transformer (0.8143), and increased by 13.43% compared to Informer (0.8506). In Baihe, the MAE is 228.6971 m ³/s, a decrease of about 2.35% compared to CNN (243.0662), and the R value reaches 0.9998, an increase of 4.26% compared to CNN (0.9591). NSE is 0.9972, an increase of 18.73% compared to Transformer (0.8398), KGE is 0.9934, an increase of 9.79% compared to Informer (0.9048). These results verify the excellent performance of BWDformer in improving prediction accuracy, robustness, and practicality. Supplementary Information The online version contains supplementary material available at 10.1038/s41598-025-21007-4.",
    "citationCount": 0,
    "referenceCount": 87
}