{
    "paperId": "9f617ea70b8bce960e5f74faa11b051711fdb828",
    "title": "Learning to Rank in the Age of Muppets: Effectiveness–Efficiency Tradeoffs in Multi-Stage Ranking",
    "year": 2021,
    "venue": "SUSTAINLP",
    "authors": [
        "Yue Zhang",
        "Chengcheng Hu",
        "Yuqi Liu",
        "Hui Fang",
        "Jimmy J. Lin"
    ],
    "doi": "10.18653/v1/2021.sustainlp-1.8",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/9f617ea70b8bce960e5f74faa11b051711fdb828",
    "isOpenAccess": true,
    "openAccessPdf": "https://aclanthology.org/2021.sustainlp-1.8.pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "It is well known that rerankers built on pretrained transformer models such as BERT have dramatically improved retrieval effectiveness in many tasks. However, these gains have come at substantial costs in terms of efficiency, as noted by many researchers. In this work, we show that it is possible to retain the benefits of transformer-based rerankers in a multi-stage reranking pipeline by first using feature-based learning-to-rank techniques to reduce the number of candidate documents under consideration without adversely affecting their quality in terms of recall. Applied to the MS MARCO passage and document ranking tasks, we are able to achieve the same level of effectiveness, but with up to 18× increase in efficiency. Furthermore, our techniques are orthogonal to other methods focused on accelerating transformer inference, and thus can be combined for even greater efficiency gains. A higher-level message from our work is that, even though pretrained transformers dominate the modern IR landscape, there are still important roles for “traditional” LTR techniques, and that we should not forget history.",
    "citationCount": 16,
    "referenceCount": 37
}