{
    "paperId": "2944bb6b684428d5c1413ca5c708eb8dcf9da23f",
    "title": "Query Optimization for Faster Deep CNN Explanations",
    "year": 2020,
    "venue": "SIGMOD record",
    "authors": [
        "Supun Nakandala",
        "Arun Kumar",
        "Y. Papakonstantinou"
    ],
    "doi": "10.1145/3422648.3422663",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/2944bb6b684428d5c1413ca5c708eb8dcf9da23f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Deep Convolutional Neural Networks (CNNs) now match human accuracy in many image prediction tasks, resulting in a growing adoption in e-commerce, radiology, and other domains. Naturally, \"explaining\" CNN predictions is a key concern for many users. Since the internal workings of CNNs are unintuitive for most users, occlusion-based explanations (OBE) are popular for understanding which parts of an image matter most for a prediction. One occludes a region of the image using a patch and moves it around to produce a heatmap of changes to the prediction probability. This approach is computationally expensive due to the large number of re-inference requests produced, which wastes time and raises resource costs. We tackle this issue by casting the OBE task as a new instance of the classical incremental view maintenance problem. We create a novel and comprehensive algebraic framework for incremental CNN inference combining materialized views with multi-query optimization to reduce computational costs. We then present two novel approximate inference optimizations that exploit the semantics of CNNs and the OBE task to further reduce runtimes. We prototype our ideas in a tool we call Krypton. Experiments with real data and CNNs show that Krypton reduces runtimes by up to 5x (resp. 35x) to produce exact (resp. high-quality approximate) results without raising resource requirements.",
    "citationCount": 6,
    "referenceCount": 31
}