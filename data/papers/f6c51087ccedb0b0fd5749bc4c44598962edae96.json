{
    "paperId": "f6c51087ccedb0b0fd5749bc4c44598962edae96",
    "title": "Hierarchical and Progressive Image Matting",
    "year": 2022,
    "venue": "ACM Trans. Multim. Comput. Commun. Appl.",
    "authors": [
        "Y. Qiao",
        "Yuhao Liu",
        "Ziqi Wei",
        "Yuxin Wang",
        "Qiang Cai",
        "Guofeng Zhang",
        "Xingbin Yang"
    ],
    "doi": "10.1145/3540201",
    "arxivId": "2210.06906",
    "url": "https://www.semanticscholar.org/paper/f6c51087ccedb0b0fd5749bc4c44598962edae96",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2210.06906",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Most matting research resorts to advanced semantics to achieve high-quality alpha mattes, and a direct low-level features combination is usually explored to complement alpha details. However, we argue that appearance-agnostic integration can only provide biased foreground (FG) details and that alpha mattes require different-level feature aggregation for better pixel-wise opacity perception. In this article, we propose an end-to-end hierarchical and progressive attention matting network (HAttMatting++), which can better predict the opacity of the FG from single RGB images without additional input. Specifically, we utilize channel-wise attention (CA) to distill pyramidal features and employ spatial attention (SA) at different levels to filter appearance cues. This progressive attention mechanism can estimate alpha mattes from adaptive semantics and semantics-indicated boundaries. We also introduce a hybrid loss function fusing structural similarity, mean square error, adversarial loss, and sentry supervision to guide the network to further improve the overall FG structure. In addition, we construct a large-scale and challenging image matting dataset comprised of 59,000 training images and 1,000 test images (a total of 646 distinct FG alpha mattes), which can further improve the robustness of our hierarchical and progressive aggregation model. Extensive experiments demonstrate that the proposed HAttMatting++ can capture sophisticated FG structures and achieve state-of-the-art performance with single RGB images as input.",
    "citationCount": 13,
    "referenceCount": 62
}