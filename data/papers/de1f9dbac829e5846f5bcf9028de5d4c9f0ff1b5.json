{
    "paperId": "de1f9dbac829e5846f5bcf9028de5d4c9f0ff1b5",
    "title": "A Trainable Optimizer",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Ruiqi Wang",
        "Diego Klabjan"
    ],
    "doi": "10.48550/arXiv.2508.01764",
    "arxivId": "2508.01764",
    "url": "https://www.semanticscholar.org/paper/de1f9dbac829e5846f5bcf9028de5d4c9f0ff1b5",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The concept of learning to optimize involves utilizing a trainable optimization strategy rather than relying on manually defined full gradient estimations such as ADAM. We present a framework that jointly trains the full gradient estimator and the trainable weights of the model. Specifically, we prove that pseudo-linear TO (Trainable Optimizer), a linear approximation of the full gradient, matches SGD's convergence rate while effectively reducing variance. Pseudo-linear TO incurs negligible computational overhead, requiring only minimal additional tensor multiplications. To further improve computational efficiency, we introduce two simplified variants of Pseudo-linear TO. Experiments demonstrate that TO methods converge faster than benchmark algorithms (e.g., ADAM) in both strongly convex and non-convex settings, and fine tuning of an LLM.",
    "citationCount": 0,
    "referenceCount": 17
}