{
    "paperId": "e395dd5d9501fd99ebe31125e1dffb2efcf430f0",
    "title": "MMGRec: Multimodal Generative Recommendation with Transformer Model",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Han Liu",
        "Yin-wei Wei",
        "Xuemeng Song",
        "Weili Guan",
        "Yuanfang Li",
        "Liqiang Nie"
    ],
    "doi": "10.48550/arXiv.2404.16555",
    "arxivId": "2404.16555",
    "url": "https://www.semanticscholar.org/paper/e395dd5d9501fd99ebe31125e1dffb2efcf430f0",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Multimodal recommendation aims to recommend user-preferred candidates based on her/his historically interacted items and associated multimodal information. Previous studies commonly employ an embed-and-retrieve paradigm: learning user and item representations in the same embedding space, then retrieving similar candidate items for a user via embedding inner product. However, this paradigm suffers from inference cost, interaction modeling, and false-negative issues. Toward this end, we propose a new MMGRec model to introduce a generative paradigm into multimodal recommendation. Specifically, we first devise a hierarchical quantization method Graph RQ-VAE to assign Rec-ID for each item from its multimodal and CF information. Consisting of a tuple of semantically meaningful tokens, Rec-ID serves as the unique identifier of each item. Afterward, we train a Transformer-based recommender to generate the Rec-IDs of user-preferred items based on historical interaction sequences. The generative paradigm is qualified since this model systematically predicts the tuple of tokens identifying the recommended item in an autoregressive manner. Moreover, a relation-aware self-attention mechanism is devised for the Transformer to handle non-sequential interaction sequences, which explores the element pairwise relation to replace absolute positional encoding. Extensive experiments evaluate MMGRec's effectiveness compared with state-of-the-art methods.",
    "citationCount": 31,
    "referenceCount": 42
}