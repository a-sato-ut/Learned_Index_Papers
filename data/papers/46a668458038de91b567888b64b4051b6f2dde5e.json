{
    "paperId": "46a668458038de91b567888b64b4051b6f2dde5e",
    "title": "MVIGER: Multi-View Variational Integration of Complementary Knowledge for Generative Recommender",
    "year": 2024,
    "venue": "",
    "authors": [
        "Tongyoung Kim",
        "Soojin Yoon",
        "SeongKu Kang",
        "Jinyoung Yeo",
        "Dongha Lee"
    ],
    "doi": null,
    "arxivId": "2408.08686",
    "url": "https://www.semanticscholar.org/paper/46a668458038de91b567888b64b4051b6f2dde5e",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Language Models (LMs) have been widely used in recommender systems to incorporate textual information of items into item IDs, leveraging their advanced language understanding and generation capabilities. Recently, generative recommender systems have utilized the reasoning abilities of LMs to directly generate index tokens for potential items of interest based on the user's interaction history. To inject diverse item knowledge into LMs, prompt templates with detailed task descriptions and various indexing techniques derived from diverse item information have been explored. This paper focuses on the inconsistency in outputs generated by variations in input prompt templates and item index types, even with the same user's interaction history. Our in-depth quantitative analysis reveals that preference knowledge learned from diverse prompt templates and heterogeneous indices differs significantly, indicating a high potential for complementarity. To fully exploit this complementarity and provide consistent performance under varying prompts and item indices, we propose MVIGER, a unified variational framework that models selection among these information sources as a categorical latent variable with a learnable prior. During inference, this prior enables the model to adaptively select the most relevant source or aggregate predictions across multiple sources, thereby ensuring high-quality recommendation across diverse template-index combinations. We validate the effectiveness of MVIGER on three real-world datasets, demonstrating its superior performance over existing generative recommender baselines through the effective integration of complementary knowledge.",
    "citationCount": 6,
    "referenceCount": 44
}