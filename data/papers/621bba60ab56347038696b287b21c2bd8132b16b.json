{
    "paperId": "621bba60ab56347038696b287b21c2bd8132b16b",
    "title": "A Semidefinite Relaxation Based Branch-and-Bound Method for Tight Neural Network Verification",
    "year": 2023,
    "venue": "AAAI Conference on Artificial Intelligence",
    "authors": [
        "Jianglin Lan",
        "Benedikt Br√ºckner",
        "A. Lomuscio"
    ],
    "doi": "10.1609/aaai.v37i12.26745",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/621bba60ab56347038696b287b21c2bd8132b16b",
    "isOpenAccess": true,
    "openAccessPdf": "https://ojs.aaai.org/index.php/AAAI/article/download/26745/26517",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We introduce a novel method based on semidefinite program (SDP) for the tight and efficient verification of neural networks. The proposed SDP relaxation advances the present state of the art in SDP-based neural network verification by adding a set of linear constraints based on eigenvectors. We extend this novel SDP relaxation by combining it with a branch-and-bound method that can provably close the relaxation gap up to zero. We show formally that the proposed approach leads to a provably tighter solution than the present state of the art. We report experimental results showing that the proposed method outperforms baselines in terms of verified accuracy while retaining an acceptable computational overhead.",
    "citationCount": 3,
    "referenceCount": 59
}