{
    "paperId": "595101f13b961d69c553ce1ed24f60f3f1085e02",
    "title": "RecSSD: near data processing for solid state drive based recommendation inference",
    "year": 2021,
    "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems",
    "authors": [
        "Mark Wilkening",
        "Udit Gupta",
        "Samuel Hsia",
        "Caroline Trippel",
        "Carole-Jean Wu",
        "D. Brooks",
        "Gu-Yeon Wei"
    ],
    "doi": "10.1145/3445814.3446763",
    "arxivId": "2102.00075",
    "url": "https://www.semanticscholar.org/paper/595101f13b961d69c553ce1ed24f60f3f1085e02",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2102.00075",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Neural personalized recommendation models are used across a wide variety of datacenter applications including search, social media, and entertainment. State-of-the-art models comprise large embedding tables that have billions of parameters requiring large memory capacities. Unfortunately, large and fast DRAM-based memories levy high infrastructure costs. Conventional SSD-based storage solutions offer an order of magnitude larger capacity, but have worse read latency and bandwidth, degrading inference performance. RecSSD is a near data processing based SSD memory system customized for neural recommendation inference that reduces end-to-end model inference latency by 2Ã— compared to using COTS SSDs across eight industry-representative models.",
    "citationCount": 124,
    "referenceCount": 44
}