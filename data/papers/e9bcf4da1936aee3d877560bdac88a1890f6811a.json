{
    "paperId": "e9bcf4da1936aee3d877560bdac88a1890f6811a",
    "title": "Optimizing Video Queries with Declarative Clues",
    "year": 2024,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Daren Chao",
        "Yueting Chen",
        "Nick Koudas",
        "Xiaohui Yu"
    ],
    "doi": "10.14778/3681954.3681998",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/e9bcf4da1936aee3d877560bdac88a1890f6811a",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Video Database Management Systems (VDBMS) leverage advancements in computer vision and deep learning for efficient video data analysis and retrieval. This paper introduces the concept of user-specified Clues, allowing users to incorporate domain-specific knowledge, referred to as Clues, into query optimization. Clues are expressed as Clue types, each associated with optimization rules, and applied to queries through Clue instances. The extensible ClueVQS system we present to incorporate these ideas, optimizes queries automatically, utilizing Clues to improve processing efficiency. We also introduce algorithms to optimize queries using Clues allowing for trade-offs between speed and query accuracy. Our proposals and system address challenges such as data-dependent Clue effectiveness, limiting search space, and accuracy-efficiency trade-offs. Detailed experimental results demonstrate query speedups of up to two orders of magnitude compared to other applicable approaches, and a reduction of the query optimizer time by up to 95% while respecting user-specified accuracy constraints, showcasing the effectiveness of the proposed framework.",
    "citationCount": 4,
    "referenceCount": 46
}