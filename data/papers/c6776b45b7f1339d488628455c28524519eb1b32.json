{
    "paperId": "c6776b45b7f1339d488628455c28524519eb1b32",
    "title": "Moses: Efficient Exploitation of Cross-device Transferable Features for Tensor Program Optimization",
    "year": 2022,
    "venue": "arXiv.org",
    "authors": [
        "Zhihe Zhao",
        "Xian Shuai",
        "Yang Bai",
        "Neiwen Ling",
        "Nan Guan",
        "Zhenyu Yan",
        "Guoliang Xing"
    ],
    "doi": null,
    "arxivId": "2201.05752",
    "url": "https://www.semanticscholar.org/paper/c6776b45b7f1339d488628455c28524519eb1b32",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Achieving efficient execution of machine learning models has attracted significant attention recently. To generate tensor programs efficiently, a key component of DNN compilers is the cost model that can predict the performance of each configuration on specific devices. However, due to the rapid emergence of hardware platforms, it is increasingly labor-intensive to train domain-specific predictors for every new platform. Besides, current design of cost models cannot provide transferable features between different hardware accelerators efficiently and effectively. In this paper, we propose Moses, a simple and efficient design based on the lottery ticket hypothesis, which fully takes advantage of the features transferable to the target device via domain adaptation. Compared with state-of-the-art approaches, Moses achieves up to 1.53X efficiency gain in the search stage and 1.41X inference speedup on challenging DNN benchmarks.",
    "citationCount": 7,
    "referenceCount": 22
}