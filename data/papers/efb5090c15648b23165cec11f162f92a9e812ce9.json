{
    "paperId": "efb5090c15648b23165cec11f162f92a9e812ce9",
    "title": "Overcoming the curse of dimensionality for some Hamilton–Jacobi partial differential equations via neural network architectures",
    "year": 2019,
    "venue": "Research in the Mathematical Sciences",
    "authors": [
        "J. Darbon",
        "G. P. Langlois",
        "Tingwei Meng"
    ],
    "doi": "10.1007/s40687-020-00215-6",
    "arxivId": "1910.09045",
    "url": "https://www.semanticscholar.org/paper/efb5090c15648b23165cec11f162f92a9e812ce9",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We propose new and original mathematical connections between Hamilton–Jacobi (HJ) partial differential equations (PDEs) with initial data and neural network architectures. Specifically, we prove that some classes of neural networks correspond to representation formulas of HJ PDE solutions whose Hamiltonians and initial data are obtained from the parameters of the neural networks. These results do not rely on universal approximation properties of neural networks; rather, our results show that some classes of neural network architectures naturally encode the physics contained in some HJ PDEs. Our results naturally yield efficient neural network-based methods for evaluating solutions of some HJ PDEs in high dimension without using grids or numerical approximations. We also present some numerical results for solving some inverse problems involving HJ PDEs using our proposed architectures.",
    "citationCount": 106,
    "referenceCount": 171
}