{
    "paperId": "3ab05ea2bcf9410f5f4fb3d1b86d840a60cb1ec7",
    "title": "Context-Aware Parse Trees",
    "year": 2020,
    "venue": "arXiv.org",
    "authors": [
        "Fangke Ye",
        "Sheng-Tian Zhou",
        "Anand Venkat",
        "Ryan Marcus",
        "Paul Petersen",
        "Jesmin Jahan Tithi",
        "T. Mattson",
        "Tim Kraska",
        "P. Dubey",
        "Vivek Sarkar",
        "Justin Emile Gottschlich"
    ],
    "doi": null,
    "arxivId": "2003.11118",
    "url": "https://www.semanticscholar.org/paper/3ab05ea2bcf9410f5f4fb3d1b86d840a60cb1ec7",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The simplified parse tree (SPT) presented in Aroma, a state-of-the-art code recommendation system, is a tree-structured representation used to infer code semantics by capturing program \\emph{structure} rather than program \\emph{syntax}. This is a departure from the classical abstract syntax tree, which is principally driven by programming language syntax. While we believe a semantics-driven representation is desirable, the specifics of an SPT's construction can impact its performance. We analyze these nuances and present a new tree structure, heavily influenced by Aroma's SPT, called a \\emph{context-aware parse tree} (CAPT). CAPT enhances SPT by providing a richer level of semantic representation. Specifically, CAPT provides additional binding support for language-specific techniques for adding semantically-salient features, and language-agnostic techniques for removing syntactically-present but semantically-irrelevant features. Our research quantitatively demonstrates the value of our proposed semantically-salient features, enabling a specific CAPT configuration to be 39\\% more accurate than SPT across the 48,610 programs we analyzed.",
    "citationCount": 2,
    "referenceCount": 39
}