{
    "paperId": "26f42484a3028ca65100eed08b872d97af102c7b",
    "title": "Dynamic Superblock Pruning for Fast Learned Sparse Retrieval",
    "year": 2025,
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "authors": [
        "Parker Carlson",
        "Wentai Xie",
        "Shanxiu He",
        "Tao Yang"
    ],
    "doi": "10.1145/3726302.3730183",
    "arxivId": "2504.17045",
    "url": "https://www.semanticscholar.org/paper/26f42484a3028ca65100eed08b872d97af102c7b",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This paper proposes superblock pruning (SP) during top-k online document retrieval for learned sparse representations. SP structures the sparse index as a set of superblocks on a sequence of document blocks and conducts a superblock-level selection to decide if some superblocks can be pruned before visiting their child blocks. SP generalizes the previous flat block or cluster-based pruning, allowing the early detection of groups of documents that cannot or are less likely to appear in the final top-k list. SP can accelerate sparse retrieval in a rank-safe or approximate manner under a high-relevance competitiveness constraint. Our experiments show that the proposed scheme significantly outperforms state-of-the-art baselines on MS MARCO passages on a single-threaded CPU.",
    "citationCount": 1,
    "referenceCount": 42
}