{
    "paperId": "779bf51c1bba618be6d0330a4cd5b714b059b37f",
    "title": "Online Covering with Multiple Experts",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "EnikHo Kevi",
        "Kim-Thang Nguyen"
    ],
    "doi": "10.48550/arXiv.2312.14564",
    "arxivId": "2312.14564",
    "url": "https://www.semanticscholar.org/paper/779bf51c1bba618be6d0330a4cd5b714b059b37f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Designing online algorithms with machine learning predictions is a recent technique beyond the worst-case paradigm for various practically relevant online problems (scheduling, caching, clustering, ski rental, etc.). While most previous learning-augmented algorithm approaches focus on integrating the predictions of a single oracle, we study the design of online algorithms with \\emph{multiple} experts. To go beyond the popular benchmark of a static best expert in hindsight, we propose a new \\emph{dynamic} benchmark (linear combinations of predictions that change over time). We present a competitive algorithm in the new dynamic benchmark with a performance guarantee of $O(\\log K)$, where $K$ is the number of experts, for $0-1$ online optimization problems. Furthermore, our multiple-expert approach provides a new perspective on how to combine in an online manner several online algorithms - a long-standing central subject in the online algorithm research community.",
    "citationCount": 1,
    "referenceCount": 25
}