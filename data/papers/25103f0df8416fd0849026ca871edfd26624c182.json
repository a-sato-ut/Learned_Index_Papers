{
    "paperId": "25103f0df8416fd0849026ca871edfd26624c182",
    "title": "Learning to accelerate distributed ADMM using graph neural networks",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Henri Doerks",
        "Paul Häusner",
        "Daniel Hern'andez Escobar",
        "Jens Sjölund"
    ],
    "doi": "10.48550/arXiv.2509.05288",
    "arxivId": "2509.05288",
    "url": "https://www.semanticscholar.org/paper/25103f0df8416fd0849026ca871edfd26624c182",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Distributed optimization is fundamental in large-scale machine learning and control applications. Among existing methods, the Alternating Direction Method of Multipliers (ADMM) has gained popularity due to its strong convergence guarantees and suitability for decentralized computation. However, ADMM often suffers from slow convergence and sensitivity to hyperparameter choices. In this work, we show that distributed ADMM iterations can be naturally represented within the message-passing framework of graph neural networks (GNNs). Building on this connection, we propose to learn adaptive step sizes and communication weights by a graph neural network that predicts the hyperparameters based on the iterates. By unrolling ADMM for a fixed number of iterations, we train the network parameters end-to-end to minimize the final iterates error for a given problem class, while preserving the algorithm's convergence properties. Numerical experiments demonstrate that our learned variant consistently improves convergence speed and solution quality compared to standard ADMM. The code is available at https://github.com/paulhausner/learning-distributed-admm.",
    "citationCount": 0,
    "referenceCount": 42
}