{
    "paperId": "22cc1f1f8663a1d609e1892db9af4414024e5af8",
    "title": "Optimizing Large Language Models to Expedite the Development of Smart Contracts",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "Nii Osae Osae Dade",
        "Margaret Lartey-Quaye",
        "Emmanuel Teye-Kofi Odonkor",
        "Paul Ammah"
    ],
    "doi": "10.48550/arXiv.2310.05178",
    "arxivId": "2310.05178",
    "url": "https://www.semanticscholar.org/paper/22cc1f1f8663a1d609e1892db9af4414024e5af8",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2310.05178",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Programming has always been at the heart of technological innovation in the 21st century. With the advent of blockchain technologies and the proliferation of web3 paradigms of decentralised applications, smart contracts have been very instrumental in enabling developers to build applications that reside on decentralised blockchains. Despite the huge interest and potential of smart contracts, there is still a significant knowledge and skill gap that developers need to cross in order to build web3 applications. In light of this, we introduce MazzumaGPT, a large language model that has been optimised to generate smart contract code and aid developers to scaffold development and improve productivity. As part of this research, we outline the optimisation and fine-tuning parameters, evaluate the model's performance on functional correctness and address the limitations and broader impacts of our research.",
    "citationCount": 6,
    "referenceCount": 49
}