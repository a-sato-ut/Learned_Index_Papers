{
    "paperId": "90a1800882262ba9fafd36f69a38c5b96521b1c4",
    "title": "HyperMR: Efficient Hypergraph-enhanced Matrix Storage on Compute-in-Memory Architecture",
    "year": 2025,
    "venue": "Proc. ACM Manag. Data",
    "authors": [
        "Yifan Wu",
        "Ke Chen",
        "Gang Chen",
        "Dawei Jiang",
        "Huan Li",
        "Lidan Shou"
    ],
    "doi": "10.1145/3709695",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/90a1800882262ba9fafd36f69a38c5b96521b1c4",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Matrix-vector multiplication (MVM) operations, essential for modern hardware architectures, suffer from heavy I/O overheads and costly serial multiply-add operations. The emerging Compute-in-Memory (CIM) architecture alleviates these issues by enabling in situ MVM operations with O(1) time complexity, eliminating the need to move matrices. However, current storage schemes are still inefficient on CIM due to limited optimization objectives and inflexible support for various access patterns and matrix structures. To address this, we propose HyperMR, a hypergraph-enhanced matrix storage scheme for CIM architectures. First, we identify two performance optimization objectives that are tailored to CIM and prove their NP-hardness. We then introduce a hypergraph modeling approach with a novel access-aware hypergraph generation algorithm to handle diverse matrix structures and access patterns. Moreover, we present a two-phase hypergraph partitioning method to efficiently tackle the NP-hard optimization objectives. Experimental results show that HyperMR outperforms multiple state-of-the-art storage schemes, offering valid optimization for all evaluated matrices, compared to the best-performing baseline which optimizes only 75%. HyperMR also achieves the best average optimization performance for matrix storage layouts, significantly improving efficiency in varied workload scenarios, with a 29.65% improvement on synthetic queries and up to 34.9% on scientific image filtering.",
    "citationCount": 0,
    "referenceCount": 64
}