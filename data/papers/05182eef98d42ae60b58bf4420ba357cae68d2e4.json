{
    "paperId": "05182eef98d42ae60b58bf4420ba357cae68d2e4",
    "title": "A Generative Framework for Personalized Sticker Retrieval",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Changjiang Zhou",
        "Ruqing Zhang",
        "Jiafeng Guo",
        "Yuansan Liu",
        "Fan Zhang",
        "Ganyuan Luo",
        "Xueqi Cheng"
    ],
    "doi": "10.48550/arXiv.2509.17749",
    "arxivId": "2509.17749",
    "url": "https://www.semanticscholar.org/paper/05182eef98d42ae60b58bf4420ba357cae68d2e4",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Formulating information retrieval as a variant of generative modeling, specifically using autoregressive models to generate relevant identifiers for a given query, has recently attracted considerable attention. However, its application to personalized sticker retrieval remains largely unexplored and presents unique challenges: existing relevance-based generative retrieval methods typically lack personalization, leading to a mismatch between diverse user expectations and the retrieved results. To address this gap, we propose PEARL, a novel generative framework for personalized sticker retrieval, and make two key contributions: (i) To encode user-specific sticker preferences, we design a representation learning model to learn discriminative user representations. It is trained on three prediction tasks that leverage personal information and click history; and (ii) To generate stickers aligned with a user's query intent, we propose a novel intent-aware learning objective that prioritizes stickers associated with higher-ranked intents. Empirical results from both offline evaluations and online tests demonstrate that PEARL significantly outperforms state-of-the-art methods.",
    "citationCount": 0,
    "referenceCount": 32
}