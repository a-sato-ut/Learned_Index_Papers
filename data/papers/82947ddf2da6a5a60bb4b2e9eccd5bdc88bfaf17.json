{
    "paperId": "82947ddf2da6a5a60bb4b2e9eccd5bdc88bfaf17",
    "title": "PipeSSD: A Lock-free Pipelined SSD Firmware Design for Multi-core Architecture",
    "year": 2024,
    "venue": "Design Automation Conference",
    "authors": [
        "Zelin Du",
        "Shaoqi Li",
        "Zixuan Huang",
        "Jin Xue",
        "Kecheng Huang",
        "Tianyu Wang",
        "Zili Shao"
    ],
    "doi": "10.1145/3649329.3657384",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/82947ddf2da6a5a60bb4b2e9eccd5bdc88bfaf17",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Modern SSD firmware is continuously optimized for higher parallelism to match the growing frontend PCIe bandwidth with more backend flash channels. Although a multi-core microprocessor is typically adopted to concurrently process independent NVMe requests from multiple NVMe queues, the existing one-to-many thread-request mapping model with each thread serving one or more incoming I/O requests has poor scalability due to severe lock contention problem, especially in cache management. In this paper, we first conduct experiments on an open-channel NVMe SSD to exhibit the lock contention problem in the one-to-many thread-request mapping model when multiple threads compete for the cacheline, which occupies more than 50% of the long-tail request latency. To mitigate this, we propose PipeSSD, a lock-free pipeline-based SSD firmware design with a many-to-one thread-request mapping model that assigns multiple threads to serve different stages of each I/O request in a pipelined way. Three novel designs are introduced in PipeSSD: 1) a loop-free request processing pipeline with a postponed cache stage to reduce cacheline competition; 2) a lock-free cache management scheme to ensure consistent cache behavior; and 3) a FIFO-based inter-stage request flow for correct request dependencies. We implement PipeSSD on real hardware and evaluate its performance on a multi-core NVMe SSD prototype. The evaluation results show that PipeSSD has a significant throughput improvement compared to the state-of-the-art multi-core SSD firmware.",
    "citationCount": 0,
    "referenceCount": 11
}