{
    "paperId": "5fc242a5b4ed7837cbb57174bf390abfa6440b2a",
    "title": "MixRec: Orchestrating Concurrent Recommendation Model Training on CPU-GPU platform",
    "year": 2023,
    "venue": "ICCD",
    "authors": [
        "Jiazhi Jiang",
        "Rui Tian",
        "Jiangsu Du",
        "Dan-E Huang",
        "Yutong Lu"
    ],
    "doi": "10.1109/ICCD58817.2023.00062",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/5fc242a5b4ed7837cbb57174bf390abfa6440b2a",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The development of deep learning recommendation models (DLRM) and recommendation systems has significantly improved the precision of information matching. Due to distinct computation, data access, and memory usage characteristics of recommendation models, they may suffer from low resource utilization on prevalent heterogeneous CPU-GPU hardware platforms. Existing concurrent training solutions cannot be directly applied to DLRM due to various factors, such as insufficient fine-grained memory management and the lack of collaborative CPU-GPU scheduling. In this paper, we introduce MixRec, a scheduling framework that addresses these challenges by pro-viding an efficient job management and scheduling mechanism for DLRM training jobs on heterogeneous CPU-GPU platforms. To facilitate training co-location, we first estimate the peak memory consumption of each job. Additionally, we track and collect resource utilization for DLRM training jobs. Based on the information of resource usage, a batched job dispatcher with dynamic resource-complementary scheduling policy is proposed to co-locate DLRM training jobs on CPU-GPU platform. Experimental results demonstrate that our implementation achieved up to 4.42× higher throughput and 3.97× higher resource utilization for training jobs involving various recommendation models.",
    "citationCount": 0,
    "referenceCount": 26
}