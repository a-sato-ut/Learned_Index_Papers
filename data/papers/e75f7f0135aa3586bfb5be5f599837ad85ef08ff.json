{
    "paperId": "e75f7f0135aa3586bfb5be5f599837ad85ef08ff",
    "title": "SpaceFusion: Advanced Deep Learning Operator Fusion via Space-Mapping Graph",
    "year": 2025,
    "venue": "European Conference on Computer Systems",
    "authors": [
        "Liang Zhu",
        "Jianguo Yao",
        "Haibing Guan"
    ],
    "doi": "10.1145/3689031.3696087",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/e75f7f0135aa3586bfb5be5f599837ad85ef08ff",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This work proposes SpaceFusion, an advanced scheduler for efficient deep learning operator fusion. First, we develop a novel abstraction, the Space-Mapping Graph (SMG), to holistically model the spatial information of both inter- and intra-operator dependencies. Subsequently, we introduce the spatial and temporal slicers to decompose the fused spaces defined in SMGs, generating fusion schedules by analyzing and transforming dependencies. Finally, we present auto-scheduling methods that use the slicers to automatically create high-performance fusion schedules tailored to specific hardware resource configurations. End-to-end performance evaluations reveal that SpaceFusion achieves up to 8.79x speedup (3.54x on average) over baseline implementations from Huggingface for Transformer models, and a maximum of 2.21x speedup compared to the state-of-the-art manually-tuned implementations powered by FlashAttention.",
    "citationCount": 1,
    "referenceCount": 67
}