{
    "paperId": "7ae66126e118ae49351fd2c5740c7f20eb26576c",
    "title": "Nearest Neighbor Search with Compact Codes: A Decoder Perspective",
    "year": 2021,
    "venue": "International Conference on Multimedia Retrieval",
    "authors": [
        "Kenza Amara",
        "Matthijs Douze",
        "Alexandre Sablayrolles",
        "Herv'e J'egou"
    ],
    "doi": "10.1145/3512527.3531408",
    "arxivId": "2112.09568",
    "url": "https://www.semanticscholar.org/paper/7ae66126e118ae49351fd2c5740c7f20eb26576c",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2112.09568",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Modern approaches for fast retrieval of similar vectors on billion-scaled datasets rely on compressed-domain approaches such as binary sketches or product quantization. These methods minimize a certain loss, typically the Mean Squared Error or other objective functions tailored to the retrieval problem. In this paper, we re-interpret popular methods such as binary hashing or product quantizers as auto-encoders, and point out that they implicitly make suboptimal assumptions on the form of the decoder. We design backward-compatible decoders that improve the reconstruction of the vectors from the same codes, which translates to a better performance in nearest neighbor search. Our method significantly improves over binary hashing methods and product quantization on popular benchmarks.",
    "citationCount": 6,
    "referenceCount": 27
}