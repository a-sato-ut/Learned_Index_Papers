{
    "paperId": "33b52ed2358bee0d03427c6705029b73b9d776a1",
    "title": "Comparative Study on Model Emotion Identification Through Facial Expressions",
    "year": 2025,
    "venue": "Journal of Information Systems Engineering & Management",
    "authors": [
        "Ingrid Nurtanio",
        "F. A. Samman"
    ],
    "doi": "10.52783/jisem.v10i30s.4853",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/33b52ed2358bee0d03427c6705029b73b9d776a1",
    "isOpenAccess": true,
    "openAccessPdf": "https://doi.org/10.52783/jisem.v10i30s.4853",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Psychology",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Facial expressions play a crucial role in human communication because they may convey a wide spectrum of emotions. The act of communicating or expressing particular feelings, objectives, or ideas is called expression. The tremendous advancements in technology, particularly in the domains of computer vision and artificial intelligence, have expedited efforts to develop suitable models for emotion recognition from facial expressions. This systematic literature review aims to provide an in-depth analysis of the models that are being utilized for this project. A thorough search turned up a number of research that were looked at in order to gather information about improving face recognition. This paper covers a wide range of approaches, from simple deep learning frameworks to sophisticated machine learning algorithms. The findings provide insight into the evolution of techniques, challenges faced, and future directions in the field of facial expression-based emotion recognition. These data will subsequently serve as the foundation for additional study that examines participant emotions or expressions throughout a training exercise.",
    "citationCount": 0,
    "referenceCount": 69
}