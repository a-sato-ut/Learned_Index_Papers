{
    "paperId": "d1ccd4f79a834c6cf1cc01fdbe74ea440333383f",
    "title": "Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search",
    "year": 2024,
    "venue": "The Web Conference",
    "authors": [
        "Yifei Yuan",
        "Clemencia Siro",
        "Mohammad Aliannejadi",
        "M. D. Rijke",
        "Wai Lam"
    ],
    "doi": "10.1145/3589334.3645483",
    "arxivId": "2402.07742",
    "url": "https://www.semanticscholar.org/paper/d1ccd4f79a834c6cf1cc01fdbe74ea440333383f",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2402.07742",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In mixed-initiative conversational search systems, clarifying questions aid users who struggle to express their intentions in a single query. These questions aim to uncover user's information needs and resolve query ambiguities. We hypothesize that in scenarios where multimodal information is pertinent, the clarification process can be improved by using non-textual information. Therefore, we propose to add images to clarifying questions and formulate the novel task of asking multimodal clarifying questions in open-domain, mixed-initiative conversational search systems. To facilitate research into this task, we collect a dataset named Melon that contains over 4k multimodal clarifying questions, enriched with over 14k images. We also propose a multimodal query clarification model named Marto and adopt a prompt-based, generative fine-tuning strategy to perform the training of different stages with different prompts. Several analyses are conducted to understand the importance of multimodal contents during the query clarification phase. Experimental results indicate that the addition of images leads to significant improvements of up to 90% in retrieval performance when selecting the relevant images. Extensive analyses are also performed to show the superiority of Marto compared with discriminative baselines.",
    "citationCount": 12,
    "referenceCount": 79
}