{
    "paperId": "b31100356a6a1ed21cc5643cd1ef83eb415a4a42",
    "title": "GEX: Guiding Expert Tuning with eXplainable AI",
    "year": 2025,
    "venue": "IEEE International Conference on Data Engineering",
    "authors": [
        "Andrew Chai",
        "Alexander Bianchi",
        "Vincent Corvinelli",
        "P. Godfrey",
        "Jaroslaw Szlichta",
        "C. Zuzarte"
    ],
    "doi": "10.1109/ICDE65448.2025.00319",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/b31100356a6a1ed21cc5643cd1ef83eb415a4a42",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Modern database systems, such as IBM Db2, rely on cost-based optimizers to improve workload performance. However, their decision-making processes are difficult to interpret. Tuning them for specific workloads remains challenging due to their complexity and numerous configuration options. Automatic tuning tools often rely on black-box machine-learning models, which lack interpretability, hindering expert trust and debugging. We present GEX, a system that provides interpretable insights into database optimizer behavior using explainable AI techniques. By employing saliency maps generated from surrogate models, GEX guides experts in system tuning tasks such as statistical view creation, configuration parameter adjustment, and query rewrite. Our experimental results demonstrate that GEX enhances performance and ensures transparency, addressing key challenges in data systems tuning.",
    "citationCount": 0,
    "referenceCount": 42
}