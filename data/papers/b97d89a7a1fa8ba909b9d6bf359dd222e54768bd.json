{
    "paperId": "b97d89a7a1fa8ba909b9d6bf359dd222e54768bd",
    "title": "First Place Solution to the MLCAS 2025 GWFSS Challenge: The Devil is in the Detail and Minority",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Songliang Cao",
        "Tianqi Hu",
        "Hao Lu"
    ],
    "doi": "10.48550/arXiv.2508.17305",
    "arxivId": "2508.17305",
    "url": "https://www.semanticscholar.org/paper/b97d89a7a1fa8ba909b9d6bf359dd222e54768bd",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In this report, we present our solution during the participation of the MLCAS 2025 GWFSS Challenge. This challenge hosts a semantic segmentation competition specific to wheat plants, which requires to segment three wheat organs including the head, leaf, and stem, and another background class. In 2025, participating a segmentation competition is significantly different from that in previous years where many tricks can play important roles. Nowadays most segmentation tricks have been well integrated into existing codebases such that our naive ViT-Adapter baseline has already achieved sufficiently good performance. Hence, we believe the key to stand out among other competitors is to focus on the problem nature of wheat per se. By probing visualizations, we identify the key -- the stem matters. In contrast to heads and leaves, stems exhibit fine structure and occupy only few pixels, which suffers from fragile predictions and class imbalance. Building on our baseline, we present three technical improvements tailored to stems: i) incorporating a dynamic upsampler SAPA used to enhance detail delineation; ii) leveraging semi-supervised guided distillation with stem-aware sample selection to mine the treasure beneath unlabeled data; and iii) applying a test-time scaling strategy to zoom in and segment twice the image. Despite being simple, the three improvements bring us to the first place of the competition, outperforming the second place by clear margins. Code and models will be released at https://github.com/tiny-smart/gwfss25.",
    "citationCount": 0,
    "referenceCount": 20
}