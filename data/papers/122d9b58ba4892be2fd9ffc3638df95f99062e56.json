{
    "paperId": "122d9b58ba4892be2fd9ffc3638df95f99062e56",
    "title": "A Critical Review of Methods and Challenges in Large Language Models",
    "year": 2024,
    "venue": "Computers, Materials &amp; Continua",
    "authors": [
        "M. Moradi",
        "Ke Yan",
        "David Colwell",
        "Matthias Samwald",
        "Rhona Asgari"
    ],
    "doi": "10.32604/cmc.2025.061263",
    "arxivId": "2404.11973",
    "url": "https://www.semanticscholar.org/paper/122d9b58ba4892be2fd9ffc3638df95f99062e56",
    "isOpenAccess": true,
    "openAccessPdf": "https://doi.org/10.32604/cmc.2025.061263",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Linguistics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This critical review provides an in-depth analysis of Large Language Models (LLMs), encompassing their foundational principles, diverse applications, and advanced training methodologies. We critically examine the evolution from Recurrent Neural Networks (RNNs) to Transformer models, highlighting the significant advancements and innovations in LLM architectures. The review explores state-of-the-art techniques such as in-context learning and various fine-tuning approaches, with an emphasis on optimizing parameter efficiency. We also discuss methods for aligning LLMs with human preferences, including reinforcement learning frameworks and human feedback mechanisms. The emerging technique of retrieval-augmented generation, which integrates external knowledge into LLMs, is also evaluated. Additionally, we address the ethical considerations of deploying LLMs, stressing the importance of responsible and mindful application. By identifying current gaps and suggesting future research directions, this review provides a comprehensive and critical overview of the present state and potential advancements in LLMs. This work serves as an insightful guide for researchers and practitioners in artificial intelligence, offering a unified perspective on the strengths, limitations, and future prospects of LLMs.",
    "citationCount": 3,
    "referenceCount": 72
}