{
    "paperId": "6474d7436af90bc6e49001a60c3f519face7c1ac",
    "title": "Increment - and - Freeze: Every Cache, Everywhere, All of the Time",
    "year": 2023,
    "venue": "ACM Symposium on Parallelism in Algorithms and Architectures",
    "authors": [
        "M. A. Bender",
        "Daniel Delayo",
        "Bradley C. Kuszmaul",
        "William Kuszmaul",
        "Evan West"
    ],
    "doi": "10.1145/3558481.3591085",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/6474d7436af90bc6e49001a60c3f519face7c1ac",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "One of the most basic algorithmic problems concerning caches is to compute the LRU hit-rate curve on a given trace. Unfortunately, the known algorithms exhibit poor data locality and fail to scale to large caches. It is widely believed that the LRU hit-rate curve cannot be computed efficiently enough to be used in online production settings. This has led to a large literature on heuristics that aim to approximate the curve efficiently. In this paper, we show that the poor data locality of past algorithms can be avoided. We introduce a new algorithm, called Increment-and-Freeze, for computing exact LRU hit-rate curves. The algorithm achieves RAM-model complexity O(n log n), external-memory complexity O(n over B log n), and parallelism Î˜(log n). We also present two theoretical extensions of Increment-and-Freeze, one that achieves SORT complexity in the external-memory model, and one that achieves a parallel span of O(log2 n) which is near linear parallelism, while maintaining work efficiency. We implement Increment-and-Freeze and obtain a speedup of up to 9x over the classical augmented-tree algorithm on a single processor. On 16 threads, the speedup becomes as large as 60x. In comparison to the previous state-of-the-art parallel algorithm, Increment-and-Freeze achieves a speedup of up to 10x when both algorithms use the same number of threads.",
    "citationCount": 0,
    "referenceCount": 33
}