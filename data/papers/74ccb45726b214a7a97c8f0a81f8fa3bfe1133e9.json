{
    "paperId": "74ccb45726b214a7a97c8f0a81f8fa3bfe1133e9",
    "title": "Is it Bigger than a Breadbox: Efficient Cardinality Estimation for Real World Workloads",
    "year": 2025,
    "venue": "",
    "authors": [
        "Zixuan Yi",
        "Sami Abu-el-haija",
        "Yawen Wang",
        "Teja Vemparala",
        "Yannis Chronis",
        "Yu Gan",
        "Michael Burrows",
        "Carsten Binnig",
        "Bryan Perozzi",
        "Ryan Marcus",
        "Fatma Ozcan"
    ],
    "doi": null,
    "arxivId": "2510.03386",
    "url": "https://www.semanticscholar.org/paper/74ccb45726b214a7a97c8f0a81f8fa3bfe1133e9",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "DB engines produce efficient query execution plans by relying on cost models. Practical implementations estimate cardinality of queries using heuristics, with magic numbers tuned to improve average performance on benchmarks. Empirically, estimation error significantly grows with query complexity. Alternatively, learning-based estimators offer improved accuracy, but add operational complexity preventing their adoption in-practice. Recognizing that query workloads contain highly repetitive subquery patterns, we learn many simple regressors online, each localized to a pattern. The regressor corresponding to a pattern can be randomly-accessed using hash of graph structure of the subquery. Our method has negligible overhead and competes with SoTA learning-based approaches on error metrics. Further, amending PostgreSQL with our method achieves notable accuracy and runtime improvements over traditional methods and drastically reduces operational costs compared to other learned cardinality estimators, thereby offering the most practical and efficient solution on the Pareto frontier. Concretely, simulating JOB-lite workload on IMDb speeds-up execution by 7.5 minutes (>30%) while incurring only 37 seconds overhead for online learning.",
    "citationCount": 0,
    "referenceCount": 33
}