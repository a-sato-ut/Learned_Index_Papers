{
    "paperId": "bd0ed34897bcf69d482caf16e7baab1b725d8b88",
    "title": "PerfRL: A Small Language Model Framework for Efficient Code Optimization",
    "year": 2023,
    "venue": "",
    "authors": [
        "Shukai Duan",
        "Nikos Kanakaris",
        "Xiongye Xiao",
        "Heng Ping",
        "Chenyu Zhou",
        "Nesreen K. Ahmed",
        "Guixiang Ma",
        "M. CapotÄƒ",
        "T. Willke",
        "Shahin Nazarian",
        "Paul Bogdan"
    ],
    "doi": null,
    "arxivId": "2312.05657",
    "url": "https://www.semanticscholar.org/paper/bd0ed34897bcf69d482caf16e7baab1b725d8b88",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Code optimization is a challenging task requiring a substantial level of expertise from developers. Nonetheless, this level of human capacity is not sufficient considering the rapid evolution of new hardware architectures and software environments. In light of this, recent research proposes adopting machine learning and artificial intelligence techniques to automate the code optimization process. In this paper, we introduce PerfRL, an innovative framework designed to tackle the problem of code optimization. Our framework leverages the capabilities of small language models (SLMs) and reinforcement learning (RL), facilitating a system where SLMs can assimilate feedback from their environment during the fine-tuning phase, notably through unit tests. When benchmarked against existing models, PerfRL demonstrates superior efficiency in terms of speed and computational resource usage, attributed to its reduced need for training steps and its compatibility with SLMs. Furthermore, it substantially diminishes the risk of logical and syntactical errors. To evaluate our framework, we conduct experiments on the PIE dataset using a lightweight large language model (i.e., CodeT5) and a new reinforcement learning algorithm, namely RRHF. For evaluation purposes, we use a list of evaluation metrics related to optimization quality and speedup. The evaluation results show that our approach achieves similar or better results compared to state-of-the-art models using shorter training times and smaller pre-trained models.",
    "citationCount": 6,
    "referenceCount": 18
}