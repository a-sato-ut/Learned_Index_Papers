{
    "paperId": "2f092b5cdb978d5220ce06ba7836f83d29839363",
    "title": "Regularized Contrastive Partial Multi-view Outlier Detection",
    "year": 2024,
    "venue": "ACM Multimedia",
    "authors": [
        "Yijia Wang",
        "Qianqian Xu",
        "Yangbangyan Jiang",
        "Siran Dai",
        "Qingming Huang"
    ],
    "doi": "10.1145/3664647.3681125",
    "arxivId": "2408.07819",
    "url": "https://www.semanticscholar.org/paper/2f092b5cdb978d5220ce06ba7836f83d29839363",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2408.07819",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In recent years, multi-view outlier detection (MVOD) methods have advanced significantly, aiming to identify outliers within multi-view datasets. A key point is to better detect class outliers and class-attribute outliers, which only exist in multi-view data. However, existing methods either is not able to reduce the impact of outliers when learning view-consistent information, or struggle in cases with varying neighborhood structures. Moreover, most of them do not apply to partial multi-view data in real-world scenarios. To overcome these drawbacks, we propose a novel method named Regularized Contrastive Partial Multi-view Outlier Detection (RCPMOD). In this framework, we utilize contrastive learning to learn view-consistent information and distinguish outliers by the degree of consistency. Specifically, we propose (1) An outlier-aware contrastive loss with a potential outlier memory bank to eliminate their bias motivated by a theoretical analysis. (2) A neighbor alignment contrastive loss to capture the view-shared local structural correlation. (3) A spreading regularization loss to prevent the model from overfitting over outliers. With the Cross-view Relation Transfer technique, we could easily impute the missing view samples based on the features of neighbors. Experimental results on four benchmark datasets demonstrate that our proposed approach could outperform state-of-the-art competitors under different settings.",
    "citationCount": 1,
    "referenceCount": 52
}