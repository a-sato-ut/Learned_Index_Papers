{
    "paperId": "01ba9e0be47e688aa36b759745bd32ba688d43c3",
    "title": "ArchGym: An Open-Source Gymnasium for Machine Learning Assisted Architecture Design",
    "year": 2023,
    "venue": "International Symposium on Computer Architecture",
    "authors": [
        "Srivatsan Krishnan",
        "Amir Yazdanbaksh",
        "Shvetank Prakash",
        "Jason J. Jabbour",
        "Ikechukwu Uchendu",
        "Susobhan Ghosh",
        "Behzad Boroujerdian",
        "Daniel Richins",
        "Devashree Tripathy",
        "Aleksandra Faust",
        "V. Reddi"
    ],
    "doi": "10.1145/3579371.3589049",
    "arxivId": "2306.08888",
    "url": "https://www.semanticscholar.org/paper/01ba9e0be47e688aa36b759745bd32ba688d43c3",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3579371.3589049",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Machine learning (ML) has become a prevalent approach to tame the complexity of design space exploration for domain-specific architectures. While appealing, using ML for design space exploration poses several challenges. First, it is not straightforward to identify the most suitable algorithm from an ever-increasing pool of ML methods. Second, assessing the trade-offs between performance and sample efficiency across these methods is inconclusive. Finally, the lack of a holistic framework for fair, reproducible, and objective comparison across these methods hinders the progress of adopting ML-aided architecture design space exploration and impedes creating repeatable artifacts. To mitigate these challenges, we introduce ArchGym, an open-source gymnasium and easy-to-extend framework that connects a diverse range of search algorithms to architecture simulators. To demonstrate its utility, we evaluate ArchGym across multiple vanilla and domain-specific search algorithms in the design of a custom memory controller, deep neural network accelerators, and a custom SoC for AR/VR workloads, collectively encompassing over 21K experiments. The results suggest that with an unlimited number of samples, ML algorithms are equally favorable to meet the user-defined target specification if its hyperparameters are tuned thoroughly; no one solution is necessarily better than another (e.g., reinforcement learning vs. Bayesian methods). We coin the term \"hyperparameter lottery\" to describe the relatively probable chance for a search algorithm to find an optimal design provided meticulously selected hyperparameters. Additionally, the ease of data collection and aggregation in ArchGym facilitates research in ML-aided architecture design space exploration. As a case study, we show this advantage by developing a proxy cost model with an RMSE of 0.61% that offers a 2,000-fold reduction in simulation time. Code and data for ArchGym is available at https://bit.ly/ArchGym.",
    "citationCount": 17,
    "referenceCount": 115
}