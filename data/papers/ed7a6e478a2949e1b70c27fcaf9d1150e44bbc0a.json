{
    "paperId": "ed7a6e478a2949e1b70c27fcaf9d1150e44bbc0a",
    "title": "Learning to Reason from Feedback at Test-Time",
    "year": 2025,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "authors": [
        "Yanyang Li",
        "Michael R. Lyu",
        "Liwei Wang"
    ],
    "doi": "10.48550/arXiv.2502.15771",
    "arxivId": "2502.15771",
    "url": "https://www.semanticscholar.org/paper/ed7a6e478a2949e1b70c27fcaf9d1150e44bbc0a",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Solving complex tasks in a single attempt is challenging for large language models (LLMs). Iterative interaction with the environment and feedback is often required to achieve success, making effective feedback utilization a critical topic. Existing approaches either struggle with length generalization or rely on naive retries without leveraging prior information. In this paper, we introduce FTTT, a novel paradigm that formulates feedback utilization as an optimization problem at test time. Additionally, we propose a learnable test-time optimizer, OpTune, to effectively exploit feedback. Experiments on two LLMs across four reasoning datasets demonstrate that FTTT and OpTune achieve superior scalability and performance.",
    "citationCount": 6,
    "referenceCount": 56
}