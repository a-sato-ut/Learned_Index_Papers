{
    "paperId": "5bc7859b0c1e75e12fe3dfb14e5c2edfa387f731",
    "title": "Understanding Human-AI Cooperation Through Game-Theory and Reinforcement Learning Models",
    "year": 2021,
    "venue": "Hawaii International Conference on System Sciences",
    "authors": [
        "Beau G. Schelble",
        "Christopher Flathmann",
        "L. Canonico",
        "Nathan J. Mcneese"
    ],
    "doi": "10.24251/HICSS.2021.041",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/5bc7859b0c1e75e12fe3dfb14e5c2edfa387f731",
    "isOpenAccess": true,
    "openAccessPdf": "http://scholarspace.manoa.hawaii.edu/bitstream/10125/70652/1/0035.pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Psychology",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "For years, researchers have demonstrated the viability and applicability of game theory principles to the ﬁeld of artiﬁcial intelligence. Furthermore, game theory has been shown as a useful tool for researching human-machine interaction, speciﬁcally their cooperation, by creating an environment where cooperation can initially form before reaching a continuous and stable presence in a human-machine system. Additionally, recent developments in reinforcement learning artiﬁcial intelligence have led to artiﬁcial agents cooperating more efﬁciently with humans, especially in more complex environments. This research conducts an empirical study to understand how different modern reinforcement learning algorithms and game theory scenarios could create different cooperation levels in human-machine teams. Three different reinforcement learning algorithms (Vanilla Policy Gradient, Proximal Policy Optimization, and Deep Q-Network) and two different game theory scenarios (Hawk Dove and Prisoners dilemma) were examined in a large-scale experiment. The results indicated that different reinforcement learning models interact differently with humans with Deep-Q engendering higher cooperation levels. The Hawk Dove game theory scenario elicited signiﬁcantly higher levels of cooperation in the human-artiﬁcial intelligence system. A multiple regression using these two independent variables also found a signiﬁcant ability to predict cooperation in the human-artiﬁcial intelligence systems. The results highlight the importance of social and task framing in human-artiﬁcial intelligence systems and noted the importance of choosing reinforcement learning models.",
    "citationCount": 6,
    "referenceCount": 38
}