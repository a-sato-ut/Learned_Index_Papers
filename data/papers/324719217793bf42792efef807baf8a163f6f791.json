{
    "paperId": "324719217793bf42792efef807baf8a163f6f791",
    "title": "A novel mobile robot navigation method based on deep reinforcement learning",
    "year": 2020,
    "venue": "International Journal of Advanced Robotic Systems",
    "authors": [
        "Hao Quan",
        "Yansheng Li",
        "Yi Zhang"
    ],
    "doi": "10.1177/1729881420921672",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/324719217793bf42792efef807baf8a163f6f791",
    "isOpenAccess": true,
    "openAccessPdf": "https://journals.sagepub.com/doi/pdf/10.1177/1729881420921672",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "At present, the application of mobile robots is more and more extensive, and the movement of mobile robots cannot be separated from effective navigation, especially path exploration. Aiming at navigation problems, this article proposes a method based on deep reinforcement learning and recurrent neural network, which combines double net and recurrent neural network modules with reinforcement learning ideas. At the same time, this article designed the corresponding parameter function to improve the performance of the model. In order to test the effectiveness of this method, based on the grid map model, this paper trains in a two-dimensional simulation environment, a three-dimensional TurtleBot simulation environment, and a physical robot environment, and obtains relevant data for peer-to-peer analysis. The experimental results show that the proposed algorithm has a good improvement in path finding efficiency and path length.",
    "citationCount": 44,
    "referenceCount": 26
}