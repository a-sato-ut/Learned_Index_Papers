{
    "paperId": "2b1ab5326f39f26a05ab433b30434276bc04f2d0",
    "title": "SecureBoost Hyperparameter Tuning via Multi-Objective Federated Learning",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "Ziyao Ren",
        "Yan Kang",
        "Lixin Fan",
        "Linghua Yang",
        "Tao Fan",
        "Yongxin Tong",
        "Qiang Yang"
    ],
    "doi": "10.48550/arXiv.2307.10579",
    "arxivId": "2307.10579",
    "url": "https://www.semanticscholar.org/paper/2b1ab5326f39f26a05ab433b30434276bc04f2d0",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2307.10579",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "SecureBoost is a tree-boosting algorithm leveraging homomorphic encryption to protect data privacy in vertical federated learning setting. It is widely used in fields such as finance and healthcare due to its interpretability, effectiveness, and privacy-preserving capability. However, SecureBoost suffers from high computational complexity and risk of label leakage. To harness the full potential of SecureBoost, hyperparameters of SecureBoost should be carefully chosen to strike an optimal balance between utility, efficiency, and privacy. Existing methods either set hyperparameters empirically or heuristically, which are far from optimal. To fill this gap, we propose a Constrained Multi-Objective SecureBoost (CMOSB) algorithm to find Pareto optimal solutions that each solution is a set of hyperparameters achieving optimal tradeoff between utility loss, training cost, and privacy leakage. We design measurements of the three objectives. In particular, the privacy leakage is measured using our proposed instance clustering attack. Experimental results demonstrate that the CMOSB yields not only hyperparameters superior to the baseline but also optimal sets of hyperparameters that can support the flexible requirements of FL participants.",
    "citationCount": 3,
    "referenceCount": 23
}