{
    "paperId": "e4aed7d31222080ba4931e0fff6f696bf5c67a8f",
    "title": "Explainable Deep Learning for False Information Identification: An Argumentation Theory Approach",
    "year": 2023,
    "venue": "Information systems research",
    "authors": [
        "Kyuhan Lee",
        "S. Ram"
    ],
    "doi": "10.1287/isre.2020.0097",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/e4aed7d31222080ba4931e0fff6f696bf5c67a8f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "To combat false information, social media sites have heavily relied on content moderation, mostly performed by human workers. However, human content moderation entails multiple problems, including huge labor costs, ineffectiveness, and ethical issues. To overcome these concerns, social media companies are aggressively investing in the development of artificial intelligence-powered false information detection systems. Extant efforts, however, have failed to understand the nature of human argumentation, delegating the process of making inferences of the truth to the black box of neural networks. They fail to attend to important aspects of how humans make judgments on the veracity of an argument, creating important challenges. To this end, based on Toulminâ€™s model of argumentation, we propose a computational framework that helps machine learning for false information identification understand the connection between a claim (whose veracity needs to be verified) and evidence (which contains information to support or refute the claim). The two experiments for testing model performance and explainability reveal that our framework shows stronger performance and better explainability, outperforming cutting-edge machine learning methods and presenting positive effects on human task performance, trust in algorithms, and confidence in decision making. Our results shed new light on the growing field of automated false information identification.",
    "citationCount": 12,
    "referenceCount": 24
}