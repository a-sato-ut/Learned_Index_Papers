{
    "paperId": "3619a630dc5e372e14763da24fbedf35b46dd6e6",
    "title": "Efficient Vector Search on Disaggregated Memory with d-HNSW",
    "year": 2025,
    "venue": "USENIX Workshop on Hot Topics in Storage and File Systems",
    "authors": [
        "Yi Liu",
        "Fei Fang",
        "Chen Qian"
    ],
    "doi": "10.1145/3736548.3737822",
    "arxivId": "2505.11783",
    "url": "https://www.semanticscholar.org/paper/3619a630dc5e372e14763da24fbedf35b46dd6e6",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Efficient vector query processing is essential for powering large-scale AI applications, such as LLMs. However, existing solutions struggle with growing vector datasets that exceed the memory capacity of a single machine, leading to excessive data movement and resource underutilization in monolithic architectures. We introduce d-HNSW, the first vector search engine for RDMA-based disaggregated memory systems. d-HNSW achieves high performance by supporting efficient data indexing with minimal network communication overhead. At its core, d-HNSW introduces a novel disaggregation of the HNSW graph-based vector index, leveraging the properties of greedy search to coordinate data transfers efficiently between the memory and compute pools. Specifically, d-HNSW incorporates three key techniques: (i) Representative index caching, which constructs a lightweight index from a sampled subset of the data and caches it in the compute pool to minimize frequent access to critical components of the hierarchical graph index; (ii) RDMA-friendly data layout, which optimizes data placement to reduce networking round trips for both vector queries and insertions; and (iii) Batched query-aware data loading, which mitigates bandwidth usage between memory and compute pools, addressing the limited cache capacity of compute nodes. The experimental results demonstrate that d-HNSW outperforms Naive d-HNSW implementation by up to 117Ã— in query latency while maintaining a recall of 0.87 on the SIFT1M dataset.",
    "citationCount": 3,
    "referenceCount": 53
}