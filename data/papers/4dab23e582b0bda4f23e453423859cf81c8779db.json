{
    "paperId": "4dab23e582b0bda4f23e453423859cf81c8779db",
    "title": "MoM: Continual Generative Retrieval via Mixture of Memories",
    "year": 2025,
    "venue": "2025 7th International Conference on Information Science, Electrical and Automation Engineering (ISEAE)",
    "authors": [
        "Yihan Guo",
        "Yilong Chen",
        "Jiawei Sheng",
        "Tingwen Liu"
    ],
    "doi": "10.1109/ISEAE64934.2025.11041730",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/4dab23e582b0bda4f23e453423859cf81c8779db",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Generative Retrieval aims to predict the identifiers of relevant documents for a given query using a parametric model. Prior research predominantly examines static document collections, neglecting the continuous integration of new data in real-world settings. To index these newly added collections, the parameters corresponding to the original documents in the model may be disrupted during continued training, leading to catastrophic forgetting. In this paper, based on the relationship between documents and parameters, we introduce the Mixture-of-Experts(MoE) structure into incremental generative retrieval scenarios, namely Mixture of Memories for Continual Generative Retrieval(MoM). Our method dynamically expands generative models via MoE-adapters for adapting to new document collections. To mitigate the impact of irrelevant document-specific parameters during the retrieval phase on docid generation, which is typically caused by queries that do not specify a target collection, we further introduce Reference Contrastive Decoding(RCD). It achieves denoising the irrelevant collections without explicitly specifying the target collection by introducing a gating with random weights as a reference for unrelated collections. The experimental results demonstrate the effectiveness and efficiency of the proposed model.",
    "citationCount": 0,
    "referenceCount": 21
}