{
    "paperId": "d15f5eada70eeb4c44c24c23641675ac08487f51",
    "title": "A General Framework for Learning-Augmented Online Allocation",
    "year": 2023,
    "venue": "International Colloquium on Automata, Languages and Programming",
    "authors": [
        "I. Cohen",
        "Debmalya Panigrahi"
    ],
    "doi": "10.48550/arXiv.2305.18861",
    "arxivId": "2305.18861",
    "url": "https://www.semanticscholar.org/paper/d15f5eada70eeb4c44c24c23641675ac08487f51",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2305.18861",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Online allocation is a broad class of problems where items arriving online have to be allocated to agents who have a fixed utility/cost for each assigned item so to maximize/minimize some objective. This framework captures a broad range of fundamental problems such as the Santa Claus problem (maximizing minimum utility), Nash welfare maximization (maximizing geometric mean of utilities), makespan minimization (minimizing maximum cost), minimization of $\\ell_p$-norms, and so on. We focus on divisible items (i.e., fractional allocations) in this paper. Even for divisible items, these problems are characterized by strong super-constant lower bounds in the classical worst-case online model. In this paper, we study online allocations in the {\\em learning-augmented} setting, i.e., where the algorithm has access to some additional (machine-learned) information about the problem instance. We introduce a {\\em general} algorithmic framework for learning-augmented online allocation that produces nearly optimal solutions for this broad range of maximization and minimization objectives using only a single learned parameter for every agent. As corollaries of our general framework, we improve prior results of Lattanzi et al. (SODA 2020) and Li and Xian (ICML 2021) for learning-augmented makespan minimization, and obtain the first learning-augmented nearly-optimal algorithms for the other objectives such as Santa Claus, Nash welfare, $\\ell_p$-minimization, etc. We also give tight bounds on the resilience of our algorithms to errors in the learned parameters, and study the learnability of these parameters.",
    "citationCount": 8,
    "referenceCount": 29
}