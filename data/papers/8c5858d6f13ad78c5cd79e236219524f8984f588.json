{
    "paperId": "8c5858d6f13ad78c5cd79e236219524f8984f588",
    "title": "Interactive Volume Visualization via Multi-Resolution Hash Encoding Based Neural Representation",
    "year": 2022,
    "venue": "IEEE Transactions on Visualization and Computer Graphics",
    "authors": [
        "Qi Wu",
        "David Bauer",
        "Michael J. Doyle",
        "Kwan-Liu Ma"
    ],
    "doi": "10.1109/TVCG.2023.3293121",
    "arxivId": "2207.11620",
    "url": "https://www.semanticscholar.org/paper/8c5858d6f13ad78c5cd79e236219524f8984f588",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2207.11620",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Implicit neural networks have demonstrated immense potential in compressing volume data for visualization. However, despite their advantages, the high costs of training and inference have thus far limited their application to offline data processing and non-interactive rendering. In this article, we present a novel solution that leverages modern GPU tensor cores, a well-implemented CUDA machine learning framework, an optimized global-illumination-capable volume rendering algorithm, and a suitable acceleration data structure to enable real-time direct ray tracing of volumetric neural representations. Our approach produces high-fidelity neural representations with a peak signal-to-noise ratio (PSNR) exceeding 30 dB, while reducing their size by up to three orders of magnitude. Remarkably, we show that the entire training step can fit within a rendering loop, bypassing the need for pre-training. Additionally, we introduce an efficient out-of-core training strategy to support extreme-scale volume data, making it possible for our volumetric neural representation training to scale up to terascale on a workstation with an NVIDIA RTX 3090 GPU. Our method significantly outperforms state-of-the-art techniques in terms of training time, reconstruction quality, and rendering performance, making it an ideal choice for applications where fast and accurate visualization of large-scale volume data is paramount.",
    "citationCount": 25,
    "referenceCount": 61
}