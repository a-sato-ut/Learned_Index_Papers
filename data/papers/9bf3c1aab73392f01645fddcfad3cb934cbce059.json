{
    "paperId": "9bf3c1aab73392f01645fddcfad3cb934cbce059",
    "title": "Comparative analysis of self-supervised pre-trained vision transformers and convolutional neural networks with CheXNet in classifying lung conditions",
    "year": 2025,
    "venue": "Communications in Mathematical Biology and Neuroscience",
    "authors": [
        "G. N. Elwirehardja",
        "S. Liem",
        "Maria Linneke Adjie",
        "Farrel Alexander Tjan",
        "Joselyn Setiawan",
        "Muhammad Edo Syahputra",
        "H. H. Muljo"
    ],
    "doi": "10.28919/cmbn/9048",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/9bf3c1aab73392f01645fddcfad3cb934cbce059",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Medicine",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": ". Classifying lung diseases from images has been a challenging task for Deep Learning (DL) methods. Self-Supervised Learning (SSL) in particular has been widely recognized to be effective for pre-training, especially new methods such as DINOV2 ViT/S-14 and ConvNeXt-V2. In this research, Transfer Learning (TL) was conducted on the two models by using the NIH CXR-14 dataset to perform 15-class classiﬁcation. Additionally, SwAV ResNet-50, DINO ViT-S/16, and CheXNet were adopted as the baselines. Evaluation results showed that DINOV2 ViT-S/14 is superior to the other three models pre-trained on ImageNet with 0.743 macro-averaged AUC, but is inferior to CheXNet which was pre-trained using the same NIH CXR-14 dataset albeit without the ”No Finding” class. However, the CheXNet only obtained 0.773 AUC with 0.328 recall. Further analysis on feature separability showed that both CheXNet and DINOV2 ViT-S/14 were unable to extract",
    "citationCount": 0,
    "referenceCount": 38
}