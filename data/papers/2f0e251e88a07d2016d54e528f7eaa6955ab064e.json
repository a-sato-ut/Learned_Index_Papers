{
    "paperId": "2f0e251e88a07d2016d54e528f7eaa6955ab064e",
    "title": "A survey on federated learning: a perspective from multi-party computation",
    "year": 2023,
    "venue": "Frontiers of Computer Science",
    "authors": [
        "Fengxia Liu",
        "Zhiming Zheng",
        "Yexuan Shi",
        "Yongxin Tong",
        "Yi Zhang"
    ],
    "doi": "10.1007/s11704-023-3282-7",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/2f0e251e88a07d2016d54e528f7eaa6955ab064e",
    "isOpenAccess": true,
    "openAccessPdf": "https://link.springer.com/content/pdf/10.1007/s11704-023-3282-7.pdf",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Federated learning is a promising learning paradigm that allows collaborative training of models across multiple data owners without sharing their raw datasets. To enhance privacy in federated learning, multi-party computation can be leveraged for secure communication and computation during model training. This survey provides a comprehensive review on how to integrate mainstream multi-party computation techniques into diverse federated learning setups for guaranteed privacy, as well as the corresponding optimization techniques to improve model accuracy and training efficiency. We also pinpoint future directions to deploy federated learning to a wider range of applications.",
    "citationCount": 50,
    "referenceCount": 93
}