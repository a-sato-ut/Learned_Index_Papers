{
    "paperId": "b4ac6825a237beb0febd2abb9047da31f5e7cdf7",
    "title": "BitE : Accelerating Learned Query Optimization in a Mixed-Workload Environment",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "Yuri Kim",
        "Yewon Choi",
        "Yujung Gil",
        "Sanghee Lee",
        "Heesik Shin",
        "Jaehyok Chong"
    ],
    "doi": "10.48550/arXiv.2306.00845",
    "arxivId": "2306.00845",
    "url": "https://www.semanticscholar.org/paper/b4ac6825a237beb0febd2abb9047da31f5e7cdf7",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2306.00845",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Although the many efforts to apply deep reinforcement learning to query optimization in recent years, there remains room for improvement as query optimizers are complex entities that require hand-designed tuning of workloads and datasets. Recent research present learned query optimizations results mostly in bulks of single workloads which focus on picking up the unique traits of the specific workload. This proves to be problematic in scenarios where the different characteristics of multiple workloads and datasets are to be mixed and learned together. Henceforth, in this paper, we propose BitE, a novel ensemble learning model using database statistics and metadata to tune a learned query optimizer for enhancing performance. On the way, we introduce multiple revisions to solve several challenges: we extend the search space for the optimal Abstract SQL Plan(represented as a JSON object called ASP) by expanding hintsets, we steer the model away from the default plans that may be biased by configuring the experience with all unique plans of queries, and we deviate from the traditional loss functions and choose an alternative method to cope with underestimation and overestimation of reward. Our model achieves 19.6% more improved queries and 15.8% less regressed queries compared to the existing traditional methods whilst using a comparable level of resources.",
    "citationCount": 0,
    "referenceCount": 22
}