{
    "paperId": "f0067718d51a208a6797b365cbc65bd1527bbe0e",
    "title": "Pegasus: A Universal Framework for Scalable Deep Learning Inference on the Dataplane",
    "year": 2025,
    "venue": "Conference on Applications, Technologies, Architectures, and Protocols for Computer Communication",
    "authors": [
        "Yinchao Zhang",
        "Su Yao",
        "Yong Feng",
        "Kang Chen",
        "Tong Li",
        "Zhuotao Liu",
        "Yi Zhao",
        "Lexuan Zhang",
        "Xiangyu Gao",
        "Feng Xiong",
        "Qi Li",
        "Ke Xu"
    ],
    "doi": "10.1145/3718958.3750529",
    "arxivId": "2506.05779",
    "url": "https://www.semanticscholar.org/paper/f0067718d51a208a6797b365cbc65bd1527bbe0e",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The paradigm of Intelligent DataPlane (IDP) embeds deep learning (DL) models on the network dataplane to enable intelligent traffic analysis at line-speed. However, the current use of the match-action table (MAT) abstraction on the dataplane is misaligned with DL inference, leading to several key limitations, including accuracy degradation, limited scale, and lack of generality. This paper proposes Pegasus to address these limitations. Pegasus translates DL operations into three dataplane-oriented primitives to achieve generality: Partition, Map, and SumReduce. Specifically, Partition \"divides\" high-dimensional features into multiple low-dimensional vectors, making them more suitable for the dataplane; Map \"conquers\" computations on the low-dimensional vectors in parallel with the technique of Fuzzy Matching, while SumReduce \"combines\" the computation results. Additionally, Pegasus employs Primitive Fusion to merge computations, improving scalability. Finally, Pegasus adopts full-precision weights with fixed-point activations to improve accuracy. Our implementation on a P4 switch demonstrates that Pegasus can effectively support various types of DL models, including Multi-Layer Perceptron (MLP), Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and AutoEncoder models on the dataplane. Meanwhile, Pegasus outperforms state-of-the-art approaches with an average accuracy improvement of up to 22.8%, along with up to 248× larger model size and 212× larger input scale.",
    "citationCount": 0,
    "referenceCount": 72
}