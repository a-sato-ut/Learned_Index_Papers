{
    "paperId": "5fdcbe05482fed7dd504e2078d22f05a3d5c985d",
    "title": "Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "David Boetius",
        "Stefan Leue"
    ],
    "doi": "10.48550/arXiv.2405.15430",
    "arxivId": "2405.15430",
    "url": "https://www.semanticscholar.org/paper/5fdcbe05482fed7dd504e2078d22f05a3d5c985d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Naively trained Deep Reinforcement Learning agents may fail to satisfy vital safety constraints. To avoid costly retraining, we may desire to repair a previously trained reinforcement learning agent to obviate unsafe behaviour. We devise a counterexample-guided repair algorithm for repairing reinforcement learning systems leveraging safety critics. The algorithm jointly repairs a reinforcement learning agent and a safety critic using gradient-based constrained optimisation.",
    "citationCount": 0,
    "referenceCount": 38
}