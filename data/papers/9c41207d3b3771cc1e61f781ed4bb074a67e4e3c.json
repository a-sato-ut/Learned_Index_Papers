{
    "paperId": "9c41207d3b3771cc1e61f781ed4bb074a67e4e3c",
    "title": "Efficient Compilation Method for Remote Sensing Deep Learning Models Based on Search Optimization and Adaptive Clustering",
    "year": 2025,
    "venue": "IEEE Transactions on Geoscience and Remote Sensing",
    "authors": [
        "Yongsheng Zhou",
        "Long Chen",
        "Yingbing Liu",
        "Fei Ma",
        "Fan Zhang"
    ],
    "doi": "10.1109/TGRS.2025.3560604",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/9c41207d3b3771cc1e61f781ed4bb074a67e4e3c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Environmental Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Deploying deep learning (DL)-based remote sensing image interpretation models in orbit can alleviate data downlink pressure and enhance processing efficiency. To adapt to the arithmetic conditions of on-orbit platforms, DL models must undergo compilation before deployment, where the search and measurement of operator scheduling are critical aspects. The existing compilation methods related to the tensor virtual machine (TVM) compiler suffer from inefficiencies caused by suboptimal starting point selection and extensive search spaces during the search process. Additionally, the clustering algorithm employed during the measurement of candidate scheduling relies on fixed dimensions and lacks flexible application management, resulting in slow convergence. This article proposes corresponding optimization methods built upon the TVM framework to address these two challenges. In the search aspect, techniques such as starting point planning, salient reduction, and model sharing considerably reduce search time. In the measurement aspect, the clustering process is optimized through adaptive scheduling management and dimension adaptation, enhancing measurement efficiency. Experimental results indicate that, compared to current state-of-the-art DL compilers, the proposed method increases compilation speed by an average of $2.6\\times $ while maintaining consistent inference speed. Our code is available at https://github.com/DormivegliaD/RLCT",
    "citationCount": 0,
    "referenceCount": 66
}