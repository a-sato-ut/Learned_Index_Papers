{
    "paperId": "f649bb36204d6fa8420615d33a58b0e11368f162",
    "title": "Cardinality estimator based on attention mechanism and tree structure LSTM",
    "year": 2025,
    "venue": "Conference on Computer Graphics, Artificial Intelligence, and Data Processing",
    "authors": [
        "Yanming Zhang",
        "Zhoufei Mao"
    ],
    "doi": "10.1117/12.3061184",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/f649bb36204d6fa8420615d33a58b0e11368f162",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Engineering",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In database query processing, the query optimizer is a key component of the database system. For the query optimizer, accurate cardinality estimation is one of the key factors in selecting the optimal query plan. However, traditional cardinality estimation methods often struggle to provide more accurate cardinality, mainly because they do not effectively capture correlations between multiple tables or multiple columns. The latest research indicates that learning-based cardinality estimation methods have significant advantages over traditional methods. Nevertheless, the current learning-based methods have some limitations. They usually have difficulties in modeling long information flow paths in query plans, as well as in capturing parent-child dependencies in query plans, and their prediction accuracy decrease dramatically when faced with more complex query scenarios involving multi-table joins. To overcome these limitations, we design a cardinality estimator capable of handling tree structure data, which consists of an encoder module and a tree structure model. In the encoder module, we adopt effective feature extraction and encoding methods, taking into account both the query plan and database statistical information during the feature extraction stage. In the tree structure model, we propose an Attention-Tree-LSTM (ATLSTM) model based on the attention mechanism and the tree structure long short-term memory network (LSTM), which can effectively model the long information flow paths in the query plan, and the attention mechanism can well capture the dependencies in the query plan. The experimental results show that our method can obtain higher cardinality estimation accuracy when dealing with complex multi-table join query scenarios.",
    "citationCount": 0,
    "referenceCount": 14
}