{
    "paperId": "3ed2c3d7f552f32741a1fec86afb7c9e2b7b8ffa",
    "title": "SMURF: Federated Multimodal Retrieval for Scientific Data via Embedding Alignment",
    "year": 2025,
    "venue": "eScience",
    "authors": [
        "Song Young Oh",
        "Arham Khan",
        "Ian T. Foster",
        "Kyle Chard"
    ],
    "doi": "10.1109/eScience65000.2025.00091",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/3ed2c3d7f552f32741a1fec86afb7c9e2b7b8ffa",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Scientific data spans heterogeneous modalities and is distributed across diverse storage systems. Vector databases have emerged as powerful tools to index high-dimensional embeddings for semantic search, but most existing systems are centralized and focus on indexing a single modality. We introduce SMURF, a system for federated multimodal indexing and retrieval. SMURF aligns pre-computed embeddings from different scientific modalities into a unified embedding space. Our method extends semi-supervised learning techniques to connect disparate embeddings by combining geometry-preserving alignment with weak supervision using a small set of semantically matched data. We evaluate SMURF on cross-modal retrieval tasks using scientific datasets and find that aligned embeddings substantially improve performance—on average, top-5 accuracy nearly doubles (19.18%→38.82%), and nDCG@10, a ranking quality metric, increases by 78% (0.18→0.32) across various retrieval settings. These results highlight the promise of bridging modality gaps to support more effective scientific discovery in federated environments.",
    "citationCount": 0,
    "referenceCount": 47
}