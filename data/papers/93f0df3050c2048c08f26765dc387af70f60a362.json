{
    "paperId": "93f0df3050c2048c08f26765dc387af70f60a362",
    "title": "AMOS: enabling automatic mapping for tensor computations on spatial accelerators with hardware abstraction",
    "year": 2022,
    "venue": "International Symposium on Computer Architecture",
    "authors": [
        "Size Zheng",
        "Renze Chen",
        "Anjiang Wei",
        "Yicheng Jin",
        "Qin Han",
        "Liqiang Lu",
        "Bingyang Wu",
        "Xiuhong Li",
        "Shengen Yan",
        "Yun Liang"
    ],
    "doi": "10.1145/3470496.3527440",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/93f0df3050c2048c08f26765dc387af70f60a362",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3470496.3527440",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Hardware specialization is a promising trend to sustain performance growth. Spatial hardware accelerators that employ specialized and hierarchical computation and memory resources have recently shown high performance gains for tensor applications such as deep learning, scientific computing, and data mining. To harness the power of these hardware accelerators, programmers have to use specialized instructions with certain hardware constraints. However, these hardware accelerators and instructions are quite new and there is a lack of understanding of the hardware abstraction, performance optimization space, and automatic methodologies to explore the space. Existing compilers use hand-tuned computation implementations and optimization templates, resulting in sub-optimal performance and heavy development costs. In this paper, we propose AMOS, which is an automatic compilation framework for spatial hardware accelerators. Central to this framework is the hardware abstraction that not only clearly specifies the behavior of spatial hardware instructions, but also formally defines the mapping problem from software to hardware. Based on the abstraction, we develop algorithms and performance models to explore various mappings automatically. Finally, we build a compilation framework that uses the hardware abstraction as compiler intermediate representation (IR), explores both compute mappings and memory mappings, and generates high-performance code for different hardware backends. Our experiments show that AMOS achieves more than 2.50× speedup to hand-optimized libraries on Tensor Core, 1.37× speedup to TVM on vector units of Intel CPU for AVX-512, and up to 25.04× speedup to AutoTVM on dot units of Mali GPU. The source code of AMOS is publicly available.",
    "citationCount": 79,
    "referenceCount": 66
}