{
    "paperId": "b165b8f2f713735a5d3c5934db2cf19a74288f08",
    "title": "In-Forest: Distributed In-Network Classification with Ensemble Models",
    "year": 2023,
    "venue": "IEEE International Conference on Network Protocols",
    "authors": [
        "Jiaye Lin",
        "Qing Li",
        "Guorui Xie",
        "Yong Jiang",
        "Zhenhui Yuan",
        "Changlin Jiang",
        "Yuan Yang"
    ],
    "doi": "10.1109/ICNP59255.2023.10355602",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/b165b8f2f713735a5d3c5934db2cf19a74288f08",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "A variety of model representation methods have been used in recent works to translate machine learning models into programmable switch rules to address network classification tasks at line-speed, i.e., in-network classification. These works generally deploy a complete but heavy model on a switch with limited hardware resources, causing both network-wide waste of resources and unsatisfactory accuracy. Therefore, we propose In-Forest, a general distributed in-network classification framework. Firstly, to improve accuracy with limited resources, we develop a Lightweight Ensemble Generic Optional Model (LEGO), which can be further enhanced into multiple enhanced base models with full functionality. Each switch only needs to deploy a simple base model, rather than the complete ensemble model. Thus, hardware resources required for both switches and the entire network can be significantly reduced. Secondly, as traffic traverses multiple switches, In-Forest aggregates the classification results from different enhanced base models for higher accuracy. Furthermore, we design a two-phase resource-aware model allocation strategy that assigns enhanced base models to switches under different scenarios. We use stable deep reinforcement learning to respond to dynamic traffic changes. Experimental results show that when compared to SwitchTree, Planter, and Netbeacon in two real network topologies, In-Forest can increase accuracy by up to 19.31%, while reducing the number of switch rules by 89.98%.",
    "citationCount": 0,
    "referenceCount": 54
}