{
    "paperId": "4deb6baeb22a1744a9ae1ff1de65a94c5ef0f93d",
    "title": "Experience-Enhanced Learning: One Size Still does not Fit All in Automatic Database",
    "year": 2021,
    "venue": "arXiv.org",
    "authors": [
        "Yu Yan",
        "Hongzhi Wang",
        "Jian Ma",
        "Jian Geng",
        "Yuzhuo Wang"
    ],
    "doi": null,
    "arxivId": "2111.10813",
    "url": "https://www.semanticscholar.org/paper/4deb6baeb22a1744a9ae1ff1de65a94c5ef0f93d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recent years, the database committee has attempted to develop automatic database management systems. Although some researches show that the applying AI to data management is a significant and promising direction, there still exists many problems in implementing these techniques to real applications (long training time, various environments and unstable performance). In this paper, we discover that traditional rule based methods have the potential to solve the above problems. We propose three methodologies for improving learned methods, i.e. label collection for efficiently pre-training, knowledge base for model transfer and theoretical guarantee for stable performance. We implement our methodologies on two widely used learning approaches, deep learning and reinforcement learning. Firstly, the novel experience enhanced deep learning (EEDL) could achieve efficient training and stable performance. We evaluate EEDL with cardinality estimation, an essential database management. The experimental results on four real dataset [1] show that our EEDL could outperforms the general DL model [2]. Secondly, we design a novel experience-enhanced reinforcement learning (EERL), which could efficiently converge and has better performance than general RL models [3]. We test EERL with online index tuning task. The experiments on TPC-H shows that EERL could accelerate the convergence of agent and generate better solution that generalizes the reinforcement learning.",
    "citationCount": 0,
    "referenceCount": 35
}