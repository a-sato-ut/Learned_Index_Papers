{
    "paperId": "5728a309dc7d16e12432aeb6570512440aa1d9bb",
    "title": "Uncertainty Quantification and Decomposition for LLM-based Recommendation",
    "year": 2025,
    "venue": "The Web Conference",
    "authors": [
        "Wonbin Kweon",
        "Sanghwan Jang",
        "SeongKu Kang",
        "Hwanjo Yu"
    ],
    "doi": "10.1145/3696410.3714601",
    "arxivId": "2501.17630",
    "url": "https://www.semanticscholar.org/paper/5728a309dc7d16e12432aeb6570512440aa1d9bb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Despite the widespread adoption of large language models (LLMs) for recommendation, we demonstrate that LLMs often exhibit uncertainty in their recommendations. To ensure the trustworthy use of LLMs in generating recommendations, we emphasize the importance of assessing the reliability of recommendations generated by LLMs. We start by introducing a novel framework for estimating the predictive uncertainty to quantitatively measure the reliability of LLM-based recommendations. We further propose to decompose the predictive uncertainty into recommendation uncertainty and prompt uncertainty, enabling in-depth analyses of the primary source of uncertainty. Through extensive experiments, we (1) demonstrate predictive uncertainty effectively indicates the reliability of LLM-based recommendations, (2) investigate the origins of uncertainty with decomposed uncertainty measures, and (3) propose uncertainty-aware prompting for a lower predictive uncertainty and enhanced recommendation. Our source code and model weights are available at https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025",
    "citationCount": 4,
    "referenceCount": 83
}