{
    "paperId": "a3b5f370da76b5192aaa666a85361ba7207f6f8b",
    "title": "Flow-Loss: Learning Cardinality Estimates That Matter",
    "year": 2021,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Parimarjan Negi",
        "Ryan Marcus",
        "Andreas Kipf",
        "Hongzi Mao",
        "N. Tatbul",
        "Tim Kraska",
        "Mohammad Alizadeh"
    ],
    "doi": "10.14778/3476249.3476259",
    "arxivId": "2101.04964",
    "url": "https://www.semanticscholar.org/paper/a3b5f370da76b5192aaa666a85361ba7207f6f8b",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "\n Recently there has been significant interest in using machine learning to improve the accuracy of cardinality estimation. This work has focused on improving average estimation error, but not all estimates matter equally for downstream tasks like query optimization. Since learned models inevitably make mistakes, the goal should be to improve the estimates that make the biggest difference to an optimizer. We introduce a new loss function, Flow-Loss, for learning cardinality estimation models. Flow-Loss approximates the optimizer's cost model and search algorithm with analytical functions, which it uses to optimize explicitly for better query plans. At the heart of Flow-Loss is a reduction of query optimization to a flow routing problem on a certain \"plan graph\", in which different paths correspond to different query plans. To evaluate our approach, we introduce the Cardinality Estimation Benchmark (CEB) which contains the ground truth cardinalities for sub-plans of over 16\n K\n queries from 21 templates with up to 15 joins. We show that across different architectures and databases, a model trained with Flow-Loss improves the plan costs and query runtimes despite having worse estimation accuracy than a model trained with Q-Error. When the test set queries closely match the training queries, models trained with both loss functions perform well. However, the Q-Error-trained model degrades significantly when evaluated on slightly different queries (e.g., similar but unseen query templates), while the Flow-Loss-trained model generalizes better to such situations, achieving 4 -- 8Ã— better 99th percentile runtimes on unseen templates with the same model architecture and training data.\n",
    "citationCount": 84,
    "referenceCount": 64
}