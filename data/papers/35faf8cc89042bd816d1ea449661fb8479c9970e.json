{
    "paperId": "35faf8cc89042bd816d1ea449661fb8479c9970e",
    "title": "Multigrid-Augmented Deep Learning Preconditioners for the Helmholtz Equation Using Compact Implicit Layers",
    "year": 2023,
    "venue": "SIAM Journal on Scientific Computing",
    "authors": [
        "Bar Lerer",
        "Ido Ben-Yair",
        "Eran Treister"
    ],
    "doi": "10.1137/23M1583302",
    "arxivId": "2306.17486",
    "url": "https://www.semanticscholar.org/paper/35faf8cc89042bd816d1ea449661fb8479c9970e",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2306.17486",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        },
        {
            "category": "Physics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We present a deep learning-based iterative approach to solve the discrete heterogeneous Helmholtz equation for high wavenumbers. Combining classical iterative multigrid solvers and convolutional neural networks (CNNs) via preconditioning, we obtain a learned neural solver that is faster and scales better than a standard multigrid solver. Our approach offers three main contributions over previous neural methods of this kind. First, we construct a multilevel U-Net-like encoder-solver CNN with an implicit layer on the coarsest grid of the U-Net, where convolution kernels are inverted. This alleviates the field of view problem in CNNs and allows better scalability. Second, we improve upon the previous CNN preconditioner in terms of the number of parameters, computation time, and convergence rates. Third, we propose a multiscale training approach that enables the network to scale to problems of previously unseen dimensions while still maintaining a reasonable training procedure. Our encoder-solver architecture can be used to generalize over different slowness models of various difficulties and is efficient at solving for many right-hand sides per slowness model. We demonstrate the benefits of our novel architecture with numerical experiments on a variety of heterogeneous two-dimensional problems at high wavenumbers.",
    "citationCount": 7,
    "referenceCount": 78
}