{
    "paperId": "178f14eddfd870eeeb7ab87e4368f66ed580f98d",
    "title": "A Spark Optimizer for Adaptive, Fine-Grained Parameter Tuning",
    "year": 2024,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Chenghao Lyu",
        "Qi Fan",
        "Philippe Guyard",
        "Yanlei Diao"
    ],
    "doi": "10.14778/3681954.3682021",
    "arxivId": "2403.00995",
    "url": "https://www.semanticscholar.org/paper/178f14eddfd870eeeb7ab87e4368f66ed580f98d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "\n As Spark becomes a common big data analytics platform, its growing complexity makes automatic tuning of numerous parameters critical for performance. Our work on Spark parameter tuning is particularly motivated by two recent trends: Spark's\n Adaptive Query Execution\n (AQE) based on runtime statistics, and the increasingly popular\n Spark cloud deployments\n that make cost-performance reasoning crucial for the end user. This paper presents our design of\n a Spark optimizer that controls all tunable parameters of each query in the new AQE architecture to explore its performance benefits and, at the same time, casts the tuning problem in the theoretically sound multi-objective optimization (MOO) setting to better adapt to user cost-performance preferences.\n To this end, we propose a novel hybrid compile-time/runtime approach to multi-granularity tuning of diverse, correlated Spark parameters, as well as a suite of modeling and optimization techniques to solve the tuning problem in the MOO setting while meeting the stringent time constraint of 1--2 seconds for cloud use. Evaluation results using TPC-H and TPC-DS benchmarks demonstrate the superior performance of our approach:\n (i\n ) When prioritizing latency, it achieves 63% and 65% reduction for TPC-H and TPC-DS, respectively, under an average solving time of 0.7--0.8 sec, outperforming the most competitive MOO method that reduces only 18--25% latency with 2.6--15 sec solving time.\n (ii)\n When shifting preferences between latency and cost, our approach dominates the solutions of alternative methods, exhibiting superior adaptability to varying preferences.\n",
    "citationCount": 5,
    "referenceCount": 78
}