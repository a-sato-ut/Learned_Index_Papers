{
    "paperId": "73bac2bf125f6d21d2eec79aa2fc31bcddbb1b7d",
    "title": "Equivariant Hypergraph Diffusion Neural Operators",
    "year": 2022,
    "venue": "International Conference on Learning Representations",
    "authors": [
        "Peihao Wang",
        "Shenghao Yang",
        "Yunyu Liu",
        "Zhangyang Wang",
        "Pan Li"
    ],
    "doi": "10.48550/arXiv.2207.06680",
    "arxivId": "2207.06680",
    "url": "https://www.semanticscholar.org/paper/73bac2bf125f6d21d2eec79aa2fc31bcddbb1b7d",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2207.06680",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Hypergraph neural networks (HNNs) using neural networks to encode hypergraphs provide a promising way to model higher-order relations in data and further solve relevant prediction tasks built upon such higher-order relations. However, higher-order relations in practice contain complex patterns and are often highly irregular. So, it is often challenging to design an HNN that suffices to express those relations while keeping computational efficiency. Inspired by hypergraph diffusion algorithms, this work proposes a new HNN architecture named ED-HNN, which provably represents any continuous equivariant hypergraph diffusion operators that can model a wide range of higher-order relations. ED-HNN can be implemented efficiently by combining star expansions of hypergraphs with standard message passing neural networks. ED-HNN further shows great superiority in processing heterophilic hypergraphs and constructing deep models. We evaluate ED-HNN for node classification on nine real-world hypergraph datasets. ED-HNN uniformly outperforms the best baselines over these nine datasets and achieves more than 2\\%$\\uparrow$ in prediction accuracy over four datasets therein.",
    "citationCount": 44,
    "referenceCount": 135
}