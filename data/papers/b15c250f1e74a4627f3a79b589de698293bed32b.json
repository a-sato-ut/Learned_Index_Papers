{
    "paperId": "b15c250f1e74a4627f3a79b589de698293bed32b",
    "title": "A Survey of Explainable Reinforcement Learning",
    "year": 2022,
    "venue": "arXiv.org",
    "authors": [
        "Stephanie Milani",
        "Nicholay Topin",
        "M. Veloso",
        "Fei Fang"
    ],
    "doi": null,
    "arxivId": "2202.08434",
    "url": "https://www.semanticscholar.org/paper/b15c250f1e74a4627f3a79b589de698293bed32b",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Explainable reinforcement learning (XRL) is an emerging subfield of explainable machine learning that has attracted considerable attention in recent years. The goal of XRL is to elucidate the decision-making process of learning agents in sequential decision-making settings. In this survey, we propose a novel taxonomy for organizing the XRL literature that prioritizes the RL setting. We overview techniques according to this taxonomy. We point out gaps in the literature, which we use to motivate and outline a roadmap for future work.",
    "citationCount": 57,
    "referenceCount": 74
}