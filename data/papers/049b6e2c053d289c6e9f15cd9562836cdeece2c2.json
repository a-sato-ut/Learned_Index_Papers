{
    "paperId": "049b6e2c053d289c6e9f15cd9562836cdeece2c2",
    "title": "Better Generalization with Semantic IDs: A Case Study in Ranking for Recommendations",
    "year": 2023,
    "venue": "ACM Conference on Recommender Systems",
    "authors": [
        "Anima Singh",
        "Trung Vu",
        "Raghunandan H. Keshavan",
        "Nikhil Mehta",
        "Xinyang Yi",
        "Lichan Hong",
        "L. Heldt",
        "Li Wei",
        "Ed H. Chi",
        "M. Sathiamoorthy"
    ],
    "doi": "10.1145/3640457.3688190",
    "arxivId": "2306.08121",
    "url": "https://www.semanticscholar.org/paper/049b6e2c053d289c6e9f15cd9562836cdeece2c2",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3640457.3688190",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Randomly-hashed item ids are used ubiquitously in recommendation models. However, the learned representations from random hashing prevents generalization across similar items, causing problems of learning unseen and long-tail items, especially when item corpus is large, power-law distributed, and evolving dynamically. In this paper, we propose using content-derived features as a replacement for random ids. We show that simply replacing ID features with content-based embeddings can cause a drop in quality due to reduced memorization capability. To strike a good balance of memorization and generalization, we propose to use Semantic IDs [15], a compact and discrete item representation, as a replacement for random item ids. Semantic IDs are learned from frozen content embeddings using RQ-VAE and thus can capture the hierarchy of concepts in items. Similar to content embeddings, the compactness of Semantic IDs poses a problem of adaption in recommendation models. We propose novel methods for adapting Semantic IDs in industry-scale ranking models, through hashing sub-pieces of of the Semantic-ID sequences. In particular, we find that the SentencePiece model [10] that is commonly used in LLM tokenization outperforms manually crafted pieces such as N-grams. To the end, we evaluate our approaches in a real-world ranking model for YouTube recommendations. Our experiments demonstrate that Semantic IDs can replace the direct use of video IDs by improving the generalization ability on new and long-tail item slices without sacrificing overall model quality.",
    "citationCount": 40,
    "referenceCount": 36
}