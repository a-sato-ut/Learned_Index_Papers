{
    "paperId": "615e9ea808f92549e057eff4c75f0438863da17c",
    "title": "ReAAP: A Reconfigurable and Algorithm-Oriented Array Processor With Compiler-Architecture Co-Design",
    "year": 2022,
    "venue": "IEEE transactions on computers",
    "authors": [
        "Jianwei Zheng",
        "Yu Liu",
        "Xuejiao Liu",
        "Luhong Liang",
        "Deming Chen",
        "Kwang-Ting Cheng"
    ],
    "doi": "10.1109/TC.2022.3213177",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/615e9ea808f92549e057eff4c75f0438863da17c",
    "isOpenAccess": true,
    "openAccessPdf": "https://doi.org/10.1109/tc.2022.3213177",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Parallelism and data reuse are the most critical issues for the design of hardware acceleration in a deep learning processor. Besides, abundant on-chip memories and precise data management are intrinsic design requirements because most of deep learning algorithms are data-driven and memory-bound. In this paper, we propose a compiler-architecture co-design scheme targeting a reconfigurable and algorithm-oriented array processor, named ReAAP. Given specific deep neural networks, the proposed co-design scheme is effective to perform parallelism and data reuse optimization on compute-intensive layers for guiding reconfigurable computing in hardware. Especially, the systemic optimization is performed in our proposed domain-specific compiler to deal with the intrinsic tensions between parallelism and data locality, for the purpose of automatically mapping diverse layer-level workloads onto our proposed reconfigurable array architecture. In this architecture, abundant on-chip memories are software-controlled and its massive data access is precisely handled by compiler-generated instructions. In our experiments, the ReAAP is implemented on an embedded FPGA platform. Experimental results demonstrate that our proposed co-design scheme is effective to integrate software flexibility with hardware parallelism for accelerating diverse deep learning workloads. As a whole system, ReAAP achieves a consistently high utilization of hardware resource for accelerating all the diverse compute-intensive layers in ResNet, MobileNet, and BERT.",
    "citationCount": 1,
    "referenceCount": 47
}