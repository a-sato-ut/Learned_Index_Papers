{
    "paperId": "ef68ac57708ab2745ea71e066868e0d4f1da8d6c",
    "title": "Zero-shot Clarifying Question Generation for Conversational Search",
    "year": 2023,
    "venue": "The Web Conference",
    "authors": [
        "Zhenduo Wang",
        "Yuancheng Tu",
        "Corby Rosset",
        "Nick Craswell",
        "Ming Wu",
        "Qingyao Ai"
    ],
    "doi": "10.1145/3543507.3583420",
    "arxivId": "2301.12660",
    "url": "https://www.semanticscholar.org/paper/ef68ac57708ab2745ea71e066868e0d4f1da8d6c",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3543507.3583420",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "A long-standing challenge for search and conversational assistants is query intention detection in ambiguous queries. Asking clarifying questions in conversational search has been widely studied and considered an effective solution to resolve query ambiguity. Existing work have explored various approaches for clarifying question ranking and generation. However, due to the lack of real conversational search data, they have to use artificial datasets for training, which limits their generalizability to real-world search scenarios. As a result, the industry has shown reluctance to implement them in reality, further suspending the availability of real conversational search interaction data. The above dilemma can be formulated as a cold start problem of clarifying question generation and conversational search in general. Furthermore, even if we do have large-scale conversational logs, it is not realistic to gather training data that can comprehensively cover all possible queries and topics in open-domain search scenarios. The risk of fitting bias when training a clarifying question retrieval/generation model on incomprehensive dataset is thus another important challenge. In this work, we innovatively explore generating clarifying questions in a zero-shot setting to overcome the cold start problem and we propose a constrained clarifying question generation system which uses both question templates and query facets to guide the effective and precise question generation. The experiment results show that our method outperforms existing state-of-the-art zero-shot baselines by a large margin. Human annotations to our model outputs also indicate our method generates 25.2% more natural questions, 18.1% more useful questions, 6.1% less unnatural and 4% less useless questions.",
    "citationCount": 26,
    "referenceCount": 70
}