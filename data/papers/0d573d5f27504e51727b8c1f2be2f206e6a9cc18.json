{
    "paperId": "0d573d5f27504e51727b8c1f2be2f206e6a9cc18",
    "title": "In-network Neural Networks",
    "year": 2018,
    "venue": "arXiv.org",
    "authors": [
        "G. Siracusano",
        "R. Bifulco"
    ],
    "doi": null,
    "arxivId": "1801.05731",
    "url": "https://www.semanticscholar.org/paper/0d573d5f27504e51727b8c1f2be2f206e6a9cc18",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We present N2Net, a system that implements binary neural networks using commodity switching chips deployed in network switches and routers. Our system shows that these devices can run simple neural network models, whose input is encoded in the network packets' header, at packet processing speeds (billions of packets per second). Furthermore, our experience highlights that switching chips could support even more complex models, provided that some minor and cheap modifications to the chip's design are applied. We believe N2Net provides an interesting building block for future end-to-end networked systems.",
    "citationCount": 54,
    "referenceCount": 18
}