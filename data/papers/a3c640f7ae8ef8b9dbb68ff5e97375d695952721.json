{
    "paperId": "a3c640f7ae8ef8b9dbb68ff5e97375d695952721",
    "title": "SLO-Aware Scheduling Deep Learning Inference for Digital Twin-Enabled Serverless Edge",
    "year": 2025,
    "venue": "IEEE Internet of Things Journal",
    "authors": [
        "Mingyuan Ding",
        "Guangping Xu",
        "Kang Liu"
    ],
    "doi": "10.1109/JIOT.2025.3565576",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/a3c640f7ae8ef8b9dbb68ff5e97375d695952721",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The digital twin (DT) technique employs virtual models to accurately represent physical entities and their dynamic behaviors, enabling applications in prediction, optimization, and real-time monitoring. When integrated with deep learning (DL) and offered as a service, DTs significantly enhance system intelligence and operational efficiency. However, resource constraints in edge environments pose significant challenges for GPU resource scheduling, particularly under concurrent execution of DLI tasks for DT services. To address these challenges, this article introduces an service level objective (SLO)-aware scheduling framework designed to optimize DL inference for DT-enabled intelligent edge systems, which combines accurate task processing latency prediction with a dynamic synchronization strategy. The proposed strategy optimizes GPU resource allocation to meet task-specific performance objectives, thereby improving system productivity and efficiency. Comprehensive evaluations show that our method significantly reduces SLO violations by 31.2%–90.1% and JCT by 16.2%–80.3% compared to baseline methods, demonstrating its effectiveness in resource-limited edge computing environments under high workload scenarios.",
    "citationCount": 0,
    "referenceCount": 49
}