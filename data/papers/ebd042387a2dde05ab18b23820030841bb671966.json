{
    "paperId": "ebd042387a2dde05ab18b23820030841bb671966",
    "title": "Lie Point Symmetry Data Augmentation for Neural PDE Solvers",
    "year": 2022,
    "venue": "International Conference on Machine Learning",
    "authors": [
        "Johannes Brandstetter",
        "M. Welling",
        "Daniel E. Worrall"
    ],
    "doi": null,
    "arxivId": "2202.07643",
    "url": "https://www.semanticscholar.org/paper/ebd042387a2dde05ab18b23820030841bb671966",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        },
        {
            "category": "Physics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Neural networks are increasingly being used to solve partial differential equations (PDEs), replacing slower numerical solvers. However, a critical issue is that neural PDE solvers require high-quality ground truth data, which usually must come from the very solvers they are designed to replace. Thus, we are presented with a proverbial chicken-and-egg problem. In this paper, we present a method, which can partially alleviate this problem, by improving neural PDE solver sample complexity -- Lie point symmetry data augmentation (LPSDA). In the context of PDEs, it turns out that we are able to quantitatively derive an exhaustive list of data transformations, based on the Lie point symmetry group of the PDEs in question, something not possible in other application areas. We present this framework and demonstrate how it can easily be deployed to improve neural PDE solver sample complexity by an order of magnitude.",
    "citationCount": 73,
    "referenceCount": 63
}