{
    "paperId": "e2780f4bb140b80aed044e62268016f9fe04decb",
    "title": "VARIUM: Variational Autoencoder for Multi-Interest Representation with Inter-User Memory",
    "year": 2025,
    "venue": "Web Search and Data Mining",
    "authors": [
        "Nhu-Thuat Tran",
        "Hady W. Lauw"
    ],
    "doi": "10.1145/3701551.3703558",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/e2780f4bb140b80aed044e62268016f9fe04decb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Frameworks for discovering multiple user interest factors based on Variational AutoEncoder (VAE) has demonstrated competitive recommendation performance. However, as VAE only considers one user as input at a time, sharing across like-minded users may not be adequately facilitated. Moreover, interest sharing between users is not always available and thus, poses a challenge for VAE to explicitly model this information. To resolve this, we introduce an inter-user memory-based mechanism to unsupervisedly discover latent interest sharing between users under VAE framework. Concretely, we design a memory including an array of prototypes, each hypothetically representing a group of users sharing a particular interest. These memory prototypes are jointly trained with the backbone VAE-based recommendation model. For each user, we first discover multiple intra-user interest factors behind their item adoptions. Next, intra-user interest factors query to memory to retrieve the inter-user interest clues from like-minded users. This query-retrieve process is performed sequentially via a series of attention-transformation steps. Then, interest clues retrieved from memory are incorporated into interest factor representations of each user to increase their expressiveness. Thorough experiments on real-world datasets verify the strength of our method over an array of baselines. We further conduct qualitative analysis to understand the inner working of our memory-based refinement approach.",
    "citationCount": 0,
    "referenceCount": 40
}