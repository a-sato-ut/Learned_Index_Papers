{
    "paperId": "3431bef845f3719702e1fcc7486bed2718d8f77c",
    "title": "Temporally-aware node embeddings for evolving networks topologies",
    "year": 2024,
    "venue": "AI Communications",
    "authors": [
        "Karen Braga Enes",
        "Matheus Nunes",
        "Fabricio Murai",
        "G. Pappa"
    ],
    "doi": "10.3233/AIC-230028",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/3431bef845f3719702e1fcc7486bed2718d8f77c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Static node embedding algorithms applied to snapshots of real-world applications graphs are unable to capture their evolving process. As a result, the absence of information about the dynamics in these node representations can harm the accuracy and increase processing time of machine learning tasks related to these applications. Aiming at fill the gap regarding the inability of static methods to capture evolving processes on dynamic networks, we propose a biased random walk method named Evolving Node Embedding (EVNE). EVNE leverages the sequential relationship of graph snapshots by incorporating historic information when generating embeddings for the next snapshot. It learns node representations through a neural network, but differs from existing methods as it: (i) incorporates previously run walks at each step; (ii) starts the optimization of the current embedding from the parameters obtained in the previous iteration; and (iii) uses two time-varying parameters to regulate the behavior of the biased random walks over the process of graph exploration. Through a wide set of experiments we show that our approach generates better embeddings, outperforming baselines by up to 20% in a downstream node classification task. EVNE’s embeddings achieve better performance than others, based on experiments with four classifiers and five datasets. In addition, we present seven variations of our model to show the impact of each of EVNE’s mechanisms.",
    "citationCount": 0,
    "referenceCount": 33
}