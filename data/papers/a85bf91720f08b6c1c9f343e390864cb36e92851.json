{
    "paperId": "a85bf91720f08b6c1c9f343e390864cb36e92851",
    "title": "Stripe: Tensor Compilation via the Nested Polyhedral Model",
    "year": 2019,
    "venue": "arXiv.org",
    "authors": [
        "Tim Zerrell",
        "J. Bruestle"
    ],
    "doi": null,
    "arxivId": "1903.06498",
    "url": "https://www.semanticscholar.org/paper/a85bf91720f08b6c1c9f343e390864cb36e92851",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Hardware architectures and machine learning (ML) libraries evolve rapidly. Traditional compilers often fail to generate high-performance code across the spectrum of new hardware offerings. To mitigate, engineers develop hand-tuned kernels for each ML library update and hardware upgrade. Unfortunately, this approach requires excessive engineering effort to scale or maintain with any degree of state-of-the-art performance. Here we present a Nested Polyhedral Model for representing highly parallelizable computations with limited dependencies between iterations. This model provides an underlying framework for an intermediate representation (IR) called Stripe, amenable to standard compiler techniques while naturally modeling key aspects of modern ML computing. Stripe represents parallelism, efficient memory layout, and multiple compute units at a level of abstraction amenable to automatic optimization. We describe how Stripe enables a compiler for ML in the style of LLVM that allows independent development of algorithms, optimizations, and hardware accelerators. We also discuss the design exploration advantages of Stripe over kernel libraries and schedule-based or schedule-space-based code generation.",
    "citationCount": 33,
    "referenceCount": 34
}