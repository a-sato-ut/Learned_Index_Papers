{
    "paperId": "6fd7d8082cfac51d75bb2d885e6266d09acc3736",
    "title": "Attitude Control of Fixed-wing UAV Based on DDQN",
    "year": 2019,
    "venue": "ACM Cloud and Autonomic Computing Conference",
    "authors": [
        "Xu Huang",
        "Wuyi Luo",
        "Jiarun Liu"
    ],
    "doi": "10.1109/CAC48633.2019.8996970",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/6fd7d8082cfac51d75bb2d885e6266d09acc3736",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In this paper, the Double Deep Q-Learning (DDQN) which is one of the deep reinforcement learning (DRL) algorithms, is used to train an agent to control the pitch channel attitude of a fixed-wing unmanned aerial vehicle (UAV) in the laboratory. Non-linear attitude dynamics model of the UAVâ€™s pitch channel and the corresponding Markov decision process (MDP) have been established. On this basis, agent training and testing are carried out. The results show that the trained agent has a certain attitude control ability, which means the research direction has a certain value and potential.",
    "citationCount": 7,
    "referenceCount": 10
}