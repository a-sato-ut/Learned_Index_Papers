{
    "paperId": "854dedde4c59c4180a04cd3076a36e760dcdf5fc",
    "title": "G-MAP: A Graph Neural Network-Based Framework for Memory Access Prediction",
    "year": 2023,
    "venue": "IEEE Conference on High Performance Extreme Computing",
    "authors": [
        "A. Gorle",
        "Pengmiao Zhang",
        "Rajgopal Kannan",
        "Viktor K. Prasanna"
    ],
    "doi": "10.1109/HPEC58863.2023.10363605",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/854dedde4c59c4180a04cd3076a36e760dcdf5fc",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Memory access prediction is a crucial problem in data prefetchers, as it helps us improve memory performance and reduce latency in computing systems. Existing works model the problem as a sequence prediction problem. This can be limited in its ability to capture complex patterns and dependencies in memory access behavior. In recent years, Graph Neural Networks (GNNs) have emerged as a promising technique for modeling and predicting complex relationships in graph-structured data. In this paper, we introduce G-MAP, a novel Graph Neural Network-based framework for Memory Access Prediction. First, we propose Me $m2Graph$, a novel approach mapping a memory access sequence to a graph representation, capturing both the spatial and temporal locality in the sequence. Second, we implement various GNNs for G-MAP, including Graph Convolutional Network (GCN), Gated Graph Sequence Neural Network (GG-NN), and Graph Attention Network (GAT). Those models take the graph generated from Mem2Graph as input and predict future memory address jumps (deltas). We evaluate the effectiveness of G-MAP using the SPEC 2006 benchmark. G-MAP using GG-NN shows the highest performance among all models, achieving 0.7526 F1-Score on the average, which is 10.77% higher than the Multi-Layer Perceptron baseline.",
    "citationCount": 0,
    "referenceCount": 33
}