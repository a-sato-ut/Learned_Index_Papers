{
    "paperId": "8ccbfb12fdbb630fe1557db7f3ce7fc29703d9cb",
    "title": "Wound Image Classification with Vision Transformer and Feature Embeddings",
    "year": 2025,
    "venue": "International Conference on Recent Advances in Information Technology",
    "authors": [
        "Trishaani Acharjee",
        "Rajdeep Chatterjee"
    ],
    "doi": "10.1109/RAIT65068.2025.11088955",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/8ccbfb12fdbb630fe1557db7f3ce7fc29703d9cb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Image embedding is an elementary method in computer vision for transforming images into high-dimensional feature vectors representative of their semantic meaning. Normally, CNNs have worked very well in this domain through hierarchical feature extraction. On the other hand, ViTs extend the Transformer design to process images as a succession of patches-a transformative approach. This novel approach allows them to learn both localized and global background information using self-attention mechanisms, making it far easier to extract rich semantic representations from images. Our work explores the effectiveness of image embedding methods based on the ViT model, underscoring how they can transform a wide range of computer vision applications by providing a whole new perspective on how to best approach image processing. We also introduce an image analysis pipeline that combines the capabilities of traditional machine learning, like LocalitySensitive Hashing (LSH), with deep learning. Large-scale image datasets enable a variety of activities such as hashing, similarity search, and image classification.",
    "citationCount": 0,
    "referenceCount": 16
}