{
    "paperId": "95c845a1d40efb9685751bfb2ad51dd048235b15",
    "title": "Diaspora: Resilience-Enabling Services for Real-Time Distributed Workflows",
    "year": 2024,
    "venue": "IEEE International Conference on e-Science",
    "authors": [
        "Bogdan Nicolae",
        "Justin M. Wozniak",
        "Tekin Bicer",
        "H. Nguyen",
        "Parth Patel",
        "Haochen Pan",
        "Amal Gueroudji",
        "Maxime Gonthier",
        "Val√©rie Hayot-Sasson",
        "E. Huerta",
        "Kyle Chard",
        "Ryan Chard",
        "Matthieu Dorier",
        "Nageswara S. V. Rao",
        "Anees Al-Najjar",
        "A. Corsi",
        "Ian T. Foster"
    ],
    "doi": "10.1109/e-Science62913.2024.10678669",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/95c845a1d40efb9685751bfb2ad51dd048235b15",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The need for real-time processing to enable automated decision making and experimental steering has driven a shift from high-performance computing workflows on a centralized system to a distributed approach that integrates remote data sources, edge devices, and diverse compute facilities. Under this paradigm, data can be processed close to the source where it is generated, thus reducing latency and bandwidth usage. System resilience is thus a key challenge, requiring distributed workflows to survive component failures and to meet stringent quality-of-service requirements, which results in the need to mitigate anomalies such as congestion and low availability of resources. To address these challenges, we propose Diaspora, a unified resilience framework that is inspired by event-driven communication patterns used in public clouds. Specifically, we propose an event fabric that extends across sites, facilities, and computations to provide timely, reliable, and accurate information about data, application, and resource status. On top of the event fabric, we build resilience-enabling services that combine QoS-aware data streaming, resilient data views, resilient compute and data resources, and anomaly detection and prediction, all of which collectively enhance workflow resilience for these scientific cases.",
    "citationCount": 1,
    "referenceCount": 90
}