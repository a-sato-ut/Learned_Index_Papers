{
    "paperId": "cbf6664c014be483ce049141bcb40a3ca02a8e6b",
    "title": "BlinkViz: Fast and Scalable Approximate Visualization on Very Large Datasets using Neural-Enhanced Mixed Sum-Product Networks",
    "year": 2023,
    "venue": "The Web Conference",
    "authors": [
        "Yimeng Qiao",
        "Yinan Jing",
        "Hanbing Zhang",
        "Zhenying He",
        "Kai Zhang",
        "X. Wang"
    ],
    "doi": "10.1145/3543507.3583411",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/cbf6664c014be483ce049141bcb40a3ca02a8e6b",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Web-based online interactive visual analytics enjoys popularity in recent years. Traditionally, visualizations are produced directly from querying the underlying data. However, for a very large dataset, this way is so time-consuming that it cannot meet the low-latency requirements of interactive visual analytics. In this paper, we propose a learning-based visualization approach called BlinkViz, which uses a learned model to produce approximate visualizations by leveraging mixed sum-product networks to learn the distribution of the original data. In such a way, it makes visualization faster and more scalable by decoupling visualization and data. In addition, to improve the accuracy of approximate visualizations, we propose an enhanced model by incorporating a neural network with residual structures, which can refine prediction results, especially for visual requests with low selectivity. Extensive experiments show that BlinkViz is extremely fast even on a large dataset with hundreds of millions of data records (over 30GB), responding in sub-seconds (from 2ms to less than 500ms for different requests) while keeping a low error rate. Furthermore, our approach remains scalable on latency and memory footprint size regardless of data size.",
    "citationCount": 1,
    "referenceCount": 35
}