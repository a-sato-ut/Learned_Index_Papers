{
    "paperId": "1a24c19434dd819f48408054321b2eefa799b86f",
    "title": "Deep Policies for Online Bipartite Matching: A Reinforcement Learning Approach",
    "year": 2021,
    "venue": "Trans. Mach. Learn. Res.",
    "authors": [
        "Mohammad Ali Alomrani",
        "Reza Moravej",
        "Elias Boutros Khalil"
    ],
    "doi": null,
    "arxivId": "2109.10380",
    "url": "https://www.semanticscholar.org/paper/1a24c19434dd819f48408054321b2eefa799b86f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The challenge in the widely applicable online matching problem lies in making irrevocable assignments while there is uncertainty about future inputs. Most theoretically-grounded policies are myopic or greedy in nature. In real-world applications where the matching process is repeated on a regular basis, the underlying data distribution can be leveraged for better decision-making. We present an end-to-end Reinforcement Learning framework for deriving better matching policies based on trial-and-error on historical data. We devise a set of neural network architectures, design feature representations, and empirically evaluate them across two online matching problems: Edge-Weighted Online Bipartite Matching and Online Submodular Bipartite Matching. We show that most of the learning approaches perform consistently better than classical baseline algorithms on four synthetic and real-world datasets. On average, our proposed models improve the matching quality by 3--10\\% on a variety of synthetic and real-world datasets. Our code is publicly available at https://github.com/lyeskhalil/CORL.",
    "citationCount": 22,
    "referenceCount": 42
}