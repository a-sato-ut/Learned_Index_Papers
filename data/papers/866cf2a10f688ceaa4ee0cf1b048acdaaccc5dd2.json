{
    "paperId": "866cf2a10f688ceaa4ee0cf1b048acdaaccc5dd2",
    "title": "Debugging large-scale data science pipelines using dagger",
    "year": 2020,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "E. Rezig",
        "Ashrita Brahmaroutu",
        "Nesime Tatbul",
        "M. Ouzzani",
        "N. Tang",
        "T. Mattson",
        "S. Madden",
        "M. Stonebraker"
    ],
    "doi": "10.14778/3415478.3415527",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/866cf2a10f688ceaa4ee0cf1b048acdaaccc5dd2",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Data pipelines are the new code. Consequently, data scientists need new tools to support the often time-consuming process of debugging their pipelines. We introduce Dagger, an end-to-end system to debug and mitigate data-centric errors in data pipelines, such as a data transformation gone wrong or a classifier underperforming due to noisy training data. Dagger supports inter-module debugging, where the pipeline blocks are treated as black boxes, as well as intra-module debugging, where users can debug data objects in Python scripts (e.g., DataFrames). In this demo, we will walk the audience through a rich, real-world business intelligence use case from our industrial collaborators at Intel, to highlight how Dagger enables data scientists to productively identify and mitigate data-centric problems at different stages of pipeline development.",
    "citationCount": 11,
    "referenceCount": 11
}