{
    "paperId": "85efd5550abea9d0331fb9b5fd2fa8c670cd64aa",
    "title": "IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Zijie Lin",
        "Yang Zhang",
        "Xiaoyan Zhao",
        "Fengbin Zhu",
        "Fuli Feng",
        "Tat-Seng Chua"
    ],
    "doi": "10.48550/arXiv.2506.13229",
    "arxivId": "2506.13229",
    "url": "https://www.semanticscholar.org/paper/85efd5550abea9d0331fb9b5fd2fa8c670cd64aa",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Large Language Models (LLMs) have shown strong potential for recommendation by framing item prediction as a token-by-token language generation task. However, existing methods treat all item tokens equally, simply pursuing likelihood maximization during both optimization and decoding. This overlooks crucial token-level differences in decisiveness-many tokens contribute little to item discrimination yet can dominate optimization or decoding. To quantify token decisiveness, we propose a novel perspective that models item generation as a decision process, measuring token decisiveness by the Information Gain (IG) each token provides in reducing uncertainty about the generated item. Our empirical analysis reveals that most tokens have low IG but often correspond to high logits, disproportionately influencing training loss and decoding, which may impair model performance. Building on these insights, we introduce an Information Gain-based Decisiveness-aware Token handling (IGD) strategy that integrates token decisiveness into both tuning and decoding. Specifically, IGD downweights low-IG tokens during tuning and rebalances decoding to emphasize tokens with high IG. In this way, IGD moves beyond pure likelihood maximization, effectively prioritizing high-decisiveness tokens. Extensive experiments on four benchmark datasets with two LLM backbones demonstrate that IGD consistently improves recommendation accuracy, achieving significant gains on widely used ranking metrics compared to strong baselines.",
    "citationCount": 3,
    "referenceCount": 42
}