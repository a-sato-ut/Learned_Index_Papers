{
    "paperId": "b195a0377f301bbedeb93920587f6c2fc961af3c",
    "title": "Wormhole Memory: A Rubik's Cube for Cross-Dialogue Retrieval",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Libo Wang"
    ],
    "doi": "10.48550/arXiv.2501.14846",
    "arxivId": "2501.14846",
    "url": "https://www.semanticscholar.org/paper/b195a0377f301bbedeb93920587f6c2fc961af3c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In view of the gap in the current large language model in sharing memory across dialogues, this research proposes a wormhole memory module (WMM) to realize memory as a Rubik's cube that can be arbitrarily retrieved between different dialogues. Through simulation experiments, the researcher built an experimental framework based on the Python environment and used setting memory barriers to simulate the current situation where memories between LLMs dialogues are difficult to share. The CoQA development data set was imported into the experiment, and the feasibility of its cross-dialogue memory retrieval function was verified for WMM's nonlinear indexing and dynamic retrieval, and a comparative analysis was conducted with the capabilities of Titans and MemGPT memory modules. Experimental results show that WMM demonstrated the ability to retrieve memory across dialogues and the stability of quantitative indicators in eight experiments. It contributes new technical approaches to the optimization of memory management of LLMs and provides experience for the practical application in the future.",
    "citationCount": 0,
    "referenceCount": 42
}