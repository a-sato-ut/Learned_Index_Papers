{
    "paperId": "93f6537bd2d1b55ec54493ac23bec94cb5547588",
    "title": "NPS: A Framework for Accurate Program Sampling Using Graph Neural Network",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "Yuanwei Fang",
        "Zihao Liu",
        "YanHeng Lu",
        "Jiawei Liu",
        "Jiajie Li",
        "Yingqi Jin",
        "Jing Chen",
        "Yen-Kuang Chen",
        "Hongzhong Zheng",
        "Yuan Xie"
    ],
    "doi": "10.48550/arXiv.2304.08880",
    "arxivId": "2304.08880",
    "url": "https://www.semanticscholar.org/paper/93f6537bd2d1b55ec54493ac23bec94cb5547588",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2304.08880",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "With the end of Moore's Law, there is a growing demand for rapid architectural innovations in modern processors, such as RISC-V custom extensions, to continue performance scaling. Program sampling is a crucial step in microprocessor design, as it selects representative simulation points for workload simulation. While SimPoint has been the de-facto approach for decades, its limited expressiveness with Basic Block Vector (BBV) requires time-consuming human tuning, often taking months, which impedes fast innovation and agile hardware development. This paper introduces Neural Program Sampling (NPS), a novel framework that learns execution embeddings using dynamic snapshots of a Graph Neural Network. NPS deploys AssemblyNet for embedding generation, leveraging an application's code structures and runtime states. AssemblyNet serves as NPS's graph model and neural architecture, capturing a program's behavior in aspects such as data computation, code path, and data flow. AssemblyNet is trained with a data prefetch task that predicts consecutive memory addresses. In the experiments, NPS outperforms SimPoint by up to 63%, reducing the average error by 38%. Additionally, NPS demonstrates strong robustness with increased accuracy, reducing the expensive accuracy tuning overhead. Furthermore, NPS shows higher accuracy and generality than the state-of-the-art GNN approach in code behavior learning, enabling the generation of high-quality execution embeddings.",
    "citationCount": 3,
    "referenceCount": 64
}