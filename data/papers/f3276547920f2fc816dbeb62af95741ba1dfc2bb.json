{
    "paperId": "f3276547920f2fc816dbeb62af95741ba1dfc2bb",
    "title": "ResTune: Resource Oriented Tuning Boosted by Meta-Learning for Cloud Databases",
    "year": 2021,
    "venue": "SIGMOD Conference",
    "authors": [
        "Xinyi Zhang",
        "Hong Wu",
        "Zhuonan Chang",
        "Shuowei Jin",
        "Jian Tan",
        "Feifei Li",
        "Tieying Zhang",
        "Bin Cui"
    ],
    "doi": "10.1145/3448016.3457291",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/f3276547920f2fc816dbeb62af95741ba1dfc2bb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Modern database management systems (DBMS) contain tens to hundreds of critical performance tuning knobs that determine the system runtime behaviors. To reduce the total cost of ownership, cloud database providers put in drastic effort to automatically optimize the resource utilization by tuning these knobs. There are two challenges. First, the tuning system should always abide by the service level agreement (SLA) while optimizing the resource utilization, which imposes strict constrains on the tuning process. Second, the tuning time should be reasonably acceptable since time-consuming tuning is not practical for production and online troubleshooting. In this paper, we design ResTune to automatically optimize the resource utilization without violating SLA constraints on the throughput and latency requirements. ResTune leverages the tuning experience from the history tasks and transfers the accumulated knowledge to accelerate the tuning process of the new tasks. The prior knowledge is represented from historical tuning tasks through an ensemble model. The model learns the similarity between the historical workloads and the target, which significantly reduces the tuning time by a meta-learning based approach. ResTune can efficiently handle different workloads and various hardware environments. We perform evaluations using benchmarks and real world workloads on different types of resources. The results show that, compared with the manually tuned configurations, ResTune reduces 65%, 87%, 39% of CPU utilization, I/O and memory on average, respectively. Compared with the state-of-the-art methods, ResTune finds better configurations with up to ~18x speedups.",
    "citationCount": 105,
    "referenceCount": 51
}