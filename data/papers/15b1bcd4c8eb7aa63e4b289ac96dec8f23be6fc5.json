{
    "paperId": "15b1bcd4c8eb7aa63e4b289ac96dec8f23be6fc5",
    "title": "RACE: A Reinforcement Learning Framework for Improved Adaptive Control of NoC Channel Buffers",
    "year": 2022,
    "venue": "ACM Great Lakes Symposium on VLSI",
    "authors": [
        "Kamil Khan",
        "S. Pasricha",
        "R. Kim"
    ],
    "doi": "10.1145/3526241.3530335",
    "arxivId": "2205.13130",
    "url": "https://www.semanticscholar.org/paper/15b1bcd4c8eb7aa63e4b289ac96dec8f23be6fc5",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2205.13130",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Network-on-chip (NoC) architectures rely on buffers to store flits to cope with contention for router resources during packet switching. Recently, reversible multi-function channel (RMC) buffers have been proposed to simultaneously reduce power and enable adaptive NoC buffering between adjacent routers. While adaptive buffering can improve NoC performance by maximizing buffer utilization, controlling the RMC buffer allocations requires a congestion-aware, scalable, and proactive policy. In this work, we present RACE, a novel reinforcement learning (RL) framework that utilizes better awareness of network congestion and a new reward metric (\"falsefulls\") to help guide the RL agent towards better RMC buffer control decisions. We show that RACE reduces NoC latency by up to 48.9%, and energy consumption by up to 47.1% against state-of-the-art NoC buffer control policies.",
    "citationCount": 5,
    "referenceCount": 18
}