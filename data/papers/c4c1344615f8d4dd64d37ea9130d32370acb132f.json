{
    "paperId": "c4c1344615f8d4dd64d37ea9130d32370acb132f",
    "title": "LLMConf: Knowledge-Enhanced Configuration Optimization for Large Language Model Inference",
    "year": 2025,
    "venue": "International Workshop on Quality of Service",
    "authors": [
        "Jingkai He",
        "Pengfei Chen",
        "Yilun Wang",
        "Haiyu Huang",
        "Chuanfu Zhang",
        "Haojia Huang",
        "Danwen Chen"
    ],
    "doi": "10.1109/IWQoS65803.2025.11143449",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/c4c1344615f8d4dd64d37ea9130d32370acb132f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": null,
    "citationCount": 0,
    "referenceCount": 30
}