{
    "paperId": "d88af85e84914d18f86f88afcf7b7d0d80f0b0c3",
    "title": "ORL: Reinforcement Learning Benchmarks for Online Stochastic Optimization Problems",
    "year": 2019,
    "venue": "arXiv.org",
    "authors": [
        "Bharathan Balaji",
        "Jordan Bell-Masterson",
        "Enes Bi̇lgi̇n",
        "Andreas C. Damianou",
        "Pablo Moreno Garcia",
        "Arpit Jain",
        "Runfei Luo",
        "Alvaro Maggiar",
        "Balakrishnan Narayanaswamy",
        "Chun Jimmie Ye"
    ],
    "doi": null,
    "arxivId": "1911.10641",
    "url": "https://www.semanticscholar.org/paper/d88af85e84914d18f86f88afcf7b7d0d80f0b0c3",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Reinforcement Learning (RL) has achieved state-of-the-art results in domains such as robotics and games. We build on this previous work by applying RL algorithms to a selection of canonical online stochastic optimization problems with a range of practical applications: Bin Packing, Newsvendor, and Vehicle Routing. While there is a nascent literature that applies RL to these problems, there are no commonly accepted benchmarks which can be used to compare proposed approaches rigorously in terms of performance, scale, or generalizability. This paper aims to fill that gap. For each problem we apply both standard approaches as well as newer RL algorithms and analyze results. In each case, the performance of the trained RL policy is competitive with or superior to the corresponding baselines, while not requiring much in the way of domain knowledge. This highlights the potential of RL in real-world dynamic resource allocation problems.",
    "citationCount": 34,
    "referenceCount": 61
}