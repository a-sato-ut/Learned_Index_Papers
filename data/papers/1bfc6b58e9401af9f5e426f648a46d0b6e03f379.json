{
    "paperId": "1bfc6b58e9401af9f5e426f648a46d0b6e03f379",
    "title": "A Data-Driven Defense Against Edge-Case Model Poisoning Attacks on Federated Learning",
    "year": 2023,
    "venue": "European Conference on Artificial Intelligence",
    "authors": [
        "Kiran Purohit",
        "Soumili Das",
        "Sourangshu Bhattacharya",
        "Santu Rana"
    ],
    "doi": "10.3233/FAIA240736",
    "arxivId": "2305.02022",
    "url": "https://www.semanticscholar.org/paper/1bfc6b58e9401af9f5e426f648a46d0b6e03f379",
    "isOpenAccess": true,
    "openAccessPdf": "https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA240736",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Federated Learning systems are increasingly subjected to a multitude of model poisoning attacks from clients. Among these, edge-case attacks that target a small fraction of the input space are nearly impossible to detect using existing defenses, leading to a high attack success rate. We propose an effective defense using an external defense dataset, which provides information about the attack target. The defense dataset contains a mix of poisoned and clean examples, with only a few known to be clean. The proposed method, DataDefense, uses this dataset to learn a poisoned data detector model which marks each example in the defense dataset as poisoned or clean. It also learns a client importance model that estimates the probability of a client update being malicious. The global model is then updated as a weighted average of the client models' updates. The poisoned data detector and the client importance model parameters are updated using an alternating minimization strategy over the Federated Learning rounds. Extensive experiments on standard attack scenarios demonstrate that DataDefense can defend against model poisoning attacks where other state-of-the-art defenses fail. In particular, DataDefense is able to reduce the attack success rate by at least ~ 40% on standard attack setups and by more than 80% on some setups. Furthermore, DataDefense requires very few defense examples (as few as five) to achieve a near-optimal reduction in attack success rate.",
    "citationCount": 1,
    "referenceCount": 44
}