{
    "paperId": "1add047298154e27d8ef732e6c73c2f1c91eba23",
    "title": "Optimizing Video Analytics with Declarative Model Relationships",
    "year": 2022,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Francisco Romero",
        "Johann Hauswald",
        "Aditi Partap",
        "Daniel Kang",
        "M. Zaharia",
        "Christos Kozyrakis"
    ],
    "doi": "10.14778/3570690.3570695",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/1add047298154e27d8ef732e6c73c2f1c91eba23",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The availability of vast video collections and the accuracy of ML models has generated significant interest in video analytics systems. Since naively processing all frames using expensive models is impractical, researchers have proposed optimizations such as selectively using faster but less accurate models to replace or filter frames for expensive models. However, these optimizations are difficult to apply on queries with multiple predicates and models, as users must manually explore a large optimization space. Without significant systems expertise or time investment, an analyst may manually create an execution plan that is unnecessarily expensive and/or terribly inaccurate.\n \n We propose\n Relational Hints\n , a declarative interface that allows users to suggest ML model relationships based on domain knowledge. Users can express two key relationships: when a model can replace another (CAN REPLACE) and when a model can be used to filter frames for another (CAN FILTER). We aim to design an interface to express\n model relationships informed by domain specific knowledge\n and define the constraints by which these relationships hold. We then present the\n VIVA video analytics system\n that uses relational hints to optimize SQL queries on video datasets. VIVA automatically selects and validates the hints applicable to the query, generates possible query plans using a formal set of transformations, and finds the best performance plan that meets a user's accuracy requirements. VIVA relieves users from rewriting and manually optimizing video queries as new models become available and execution environments evolve. We evaluate VIVA implemented on top of Spark and show that hints improve performance up to 16.6X without sacrificing accuracy.\n",
    "citationCount": 26,
    "referenceCount": 58
}