{
    "paperId": "1101cd5c0672821e8d4dee33bf3971b725e0b185",
    "title": "The Influence of Faulty Labels in Data Sets on Human Pose Estimation",
    "year": 2024,
    "venue": "Computer Science Research Notes",
    "authors": [
        "Arnold Schwarz",
        "Levente Hernadi",
        "Felix Biessmann",
        "Kristian Hildebrand"
    ],
    "doi": "10.24132/CSRN.2025-2",
    "arxivId": "2409.03887",
    "url": "https://www.semanticscholar.org/paper/1101cd5c0672821e8d4dee33bf3971b725e0b185",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In this study we provide empirical evidence demonstrating that the quality of training data impacts model performance in Human Pose Estimation (HPE). Inaccurate labels in widely used data sets, ranging from minor errors to severe mislabeling, can negatively influence learning and distort performance metrics. We perform an in-depth analysis of popular HPE data sets to show the extent and nature of label inaccuracies. Our findings suggest that accounting for the impact of faulty labels will facilitate the development of more robust and accurate HPE models for a variety of real-world applications. We show improved performance with cleansed data.",
    "citationCount": 0,
    "referenceCount": 53
}