{
    "paperId": "c50ded32e1c544ccc4cc480be32411e13ea5d1ca",
    "title": "Rapid Network Adaptation:Learning to Adapt Neural Networks Using Test-Time Feedback",
    "year": 2023,
    "venue": "IEEE International Conference on Computer Vision",
    "authors": [
        "Teresa Yeo",
        "OÄŸuzhan Fatih Kar",
        "Zahra Sodagar",
        "Amir Zamir"
    ],
    "doi": "10.1109/ICCV51070.2023.00431",
    "arxivId": "2309.15762",
    "url": "https://www.semanticscholar.org/paper/c50ded32e1c544ccc4cc480be32411e13ea5d1ca",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2309.15762",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We propose a method for adapting neural networks to distribution shifts at test-time. In contrast to training-time robustness mechanisms that attempt to anticipate and counter the shift, we create a closed-loop system and make use of test-time feedback signal to adapt a network on the fly. We show that this loop can be effectively implemented using a learning-based function, which realizes an amortized optimizer for the network. This leads to an adaptation method, named Rapid Network Adaptation (RNA), that is notably more flexible and orders of magnitude faster than the baselines. Through a broad set of experiments using various adaptation signals and target tasks, we study the generality, efficiency, and flexibility of this method. We perform the evaluations using various datasets (Taskonomy, Replica, ScanNet, Hypersim, COCO, ImageNet), tasks (depth, optical flow, semantic segmentation, classification), and distribution shifts (Cross-datasets, 2D and 3D Common Corruptions) with promising results.",
    "citationCount": 8,
    "referenceCount": 124
}