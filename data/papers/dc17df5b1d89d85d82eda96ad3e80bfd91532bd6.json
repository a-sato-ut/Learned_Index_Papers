{
    "paperId": "dc17df5b1d89d85d82eda96ad3e80bfd91532bd6",
    "title": "CAFE+: Towards Compact, Adaptive, and Fast Embedding for Large-scale Online Recommendation Models",
    "year": 2025,
    "venue": "ACM Trans. Inf. Syst.",
    "authors": [
        "Zirui Liu",
        "Hailin Zhang",
        "Boxuan Chen",
        "Zihan Jiang",
        "Yikai Zhao",
        "Yangyu Tao",
        "Tong Yang",
        "Bin Cui"
    ],
    "doi": "10.1145/3713072",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/dc17df5b1d89d85d82eda96ad3e80bfd91532bd6",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The growing memory demands of embedding tables in Deep Learning Recommendation Models (DLRMs) pose great challenges for model training and deployment. Existing embedding compression solutions cannot simultaneously achieve memory efficiency, low latency, and adaptability to dynamic data distribution. This article presents CAFE+, a Compact, Adaptive, and Fast Embedding compression framework that meets the above requirements. The design philosophy of CAFE+ is to dynamically allocate more memory to important features and less to unimportant ones. We assign unique embedding to important feature and allow multiple unimportant features sharing one embedding. We propose a fast and lightweight feature monitor, to real-time capture feature importance and report important features. We theoretically analyze the accuracy of our feature monitor and prove the superiority of CAFE+ from the aspect of model convergence. Extensive experiments show CAFE+ outperforms existing embedding compression methods, yielding \\(3.94\\%\\) and \\(3.94\\%\\) superior testing AUC on Criteo Kaggle dataset and CriteoTB dataset at a compression ratio of \\(10{,}000\\times\\) . Building on our conference version [114], this journal version introduces several novel designs (implicit importance attenuation, adaptive threshold adjustment, and ColdSifter) that enable CAFE+ to more effectively adapt to long-term online learning and achieve better model quality. All codes are available at GitHub [112].",
    "citationCount": 2,
    "referenceCount": 127
}