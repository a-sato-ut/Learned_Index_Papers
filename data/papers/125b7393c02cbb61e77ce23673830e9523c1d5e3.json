{
    "paperId": "125b7393c02cbb61e77ce23673830e9523c1d5e3",
    "title": "Clickbait Spoiling via Question Answering and Passage Retrieval",
    "year": 2022,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "authors": [
        "Matthias Hagen",
        "Maik Frobe",
        "Artur Jurk",
        "Martin Potthast"
    ],
    "doi": "10.48550/arXiv.2203.10282",
    "arxivId": "2203.10282",
    "url": "https://www.semanticscholar.org/paper/125b7393c02cbb61e77ce23673830e9523c1d5e3",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2203.10282",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We introduce and study the task of clickbait spoiling: generating a short text that satisfies the curiosity induced by a clickbait post. Clickbait links to a web page and advertises its contents by arousing curiosity instead of providing an informative summary. Our contributions are approaches to classify the type of spoiler needed (i.e., a phrase or a passage), and to generate appropriate spoilers. A large-scale evaluation and error analysis on a new corpus of 5,000 manually spoiled clickbait posts—the Webis Clickbait Spoiling Corpus 2022—shows that our spoiler type classifier achieves an accuracy of 80%, while the question answering model DeBERTa-large outperforms all others in generating spoilers for both types.",
    "citationCount": 35,
    "referenceCount": 48
}