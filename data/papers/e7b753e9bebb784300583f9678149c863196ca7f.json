{
    "paperId": "e7b753e9bebb784300583f9678149c863196ca7f",
    "title": "Adaptive Branch-and-Bound Tree Exploration for Neural Network Verification",
    "year": 2025,
    "venue": "Design, Automation and Test in Europe",
    "authors": [
        "Kota Fukuda",
        "Guanqin Zhang",
        "Zhenya Zhang",
        "Yulei Sui",
        "Jianjun Zhao"
    ],
    "doi": "10.23919/DATE64628.2025.10992738",
    "arxivId": "2505.00963",
    "url": "https://www.semanticscholar.org/paper/e7b753e9bebb784300583f9678149c863196ca7f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Formal verification is a rigorous approach that can provably ensure the quality of neural networks, and to date, Branch and Bound (BaB) is the state-of-the-art that performs verification by splitting the problem as needed and applying off-the-shelf verifiers to sub-problems for improved performance. However, existing BaB may not be efficient, due to its naive way of exploring the space of sub-problems that ignores the importance of different sub-problems. To bridge this gap, we first introduce a notion of “importance” that reflects how likely a counterexample can be found with a sub-problem, and then we devise a novel verification approach, called ABONN, that explores the sub-problem space of BaB adaptively, in a Monte-Carlo tree search (MCTS) style. The exploration is guided by the “importance” of different sub-problems, so it favors the sub-problems that are more likely to find counterexamples. As soon as it finds a counterexample, it can immediately terminate; even though it cannot find, after visiting all the sub-problems, it can still manage to verify the problem. We evaluate ABONN with 552 verification problems from commonlyused datasets and neural network models, and compare it with the state-of-the-art verifiers as baseline approaches. Experimental evaluation shows that ABONN demonstrates speedups of up to 15.2× on MNIST and 24.7× on CIFAR-10. We further study the influences of hyperparameters to the performance of ABONN, and the effectiveness of our adaptive tree exploration.",
    "citationCount": 1,
    "referenceCount": 43
}