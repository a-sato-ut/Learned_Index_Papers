{
    "paperId": "6fae1abe44c6e52a9920c4b92b88fe95fef8510d",
    "title": "Towards Scalable Semantic Representation for Recommendation",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Taolin Zhang",
        "Junwei Pan",
        "Jinpeng Wang",
        "Yaohua Zha",
        "Tao Dai",
        "Bin Chen",
        "Ruisheng Luo",
        "Xiaoxiang Deng",
        "Yuan Wang",
        "Ming Yue",
        "Jie Jiang",
        "Shu-Tao Xia"
    ],
    "doi": "10.48550/arXiv.2410.09560",
    "arxivId": "2410.09560",
    "url": "https://www.semanticscholar.org/paper/6fae1abe44c6e52a9920c4b92b88fe95fef8510d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "With recent advances in large language models (LLMs), there has been emerging numbers of research in developing Semantic IDs based on LLMs to enhance the performance of recommendation systems. However, the dimension of these embeddings needs to match that of the ID embedding in recommendation, which is usually much smaller than the original length. Such dimension compression results in inevitable losses in discriminability and dimension robustness of the LLM embeddings, which motivates us to scale up the semantic representation. In this paper, we propose Mixture-of-Codes, which first constructs multiple independent codebooks for LLM representation in the indexing stage, and then utilizes the Semantic Representation along with a fusion module for the downstream recommendation stage. Extensive analysis and experiments demonstrate that our method achieves superior discriminability and dimension robustness scalability, leading to the best scale-up performance in recommendations.",
    "citationCount": 4,
    "referenceCount": 27
}