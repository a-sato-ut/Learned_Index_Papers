{
    "paperId": "384f9d6e494c1fb46df47c29aa103406519ebc61",
    "title": "Mitigating Propensity Bias of Large Language Models for Recommender Systems",
    "year": 2024,
    "venue": "ACM Transactions on Information Systems",
    "authors": [
        "Guixian Zhang",
        "Guan Yuan",
        "Debo Cheng",
        "Lin Liu",
        "Jiuyong Li",
        "Shichao Zhang"
    ],
    "doi": "10.48550/arXiv.2409.20052",
    "arxivId": "2409.20052",
    "url": "https://www.semanticscholar.org/paper/384f9d6e494c1fb46df47c29aa103406519ebc61",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from historical interactions poses significant challenges. The inherent biases within LLMs can skew recommendations, resulting in distorted and potentially unfair user experiences. On the other hand, propensity bias causes side information to be aligned in such a way that it often tends to represent all inputs in a low-dimensional subspace, leading to a phenomenon known as dimensional collapse, which severely restricts the recommender systemâ€™s ability to capture user preferences and behaviors. To address these issues, we introduce a novel framework named Counterfactual LLM Recommendation (CLLMR). Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse. Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs. Extensive experiments demonstrate that our CLLMR approach consistently enhances the performance of various recommender models.",
    "citationCount": 16,
    "referenceCount": 82
}