{
    "paperId": "21ba49809c3c5e944a97e8bc529f6b5890f4a5fd",
    "title": "Blitzcrank: Fast Semantic Compression for In-memory Online Transaction Processing",
    "year": 2024,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Yiming Qiao",
        "Yihan Gao",
        "Huanchen Zhang"
    ],
    "doi": "10.14778/3675034.3675044",
    "arxivId": "2406.13107",
    "url": "https://www.semanticscholar.org/paper/21ba49809c3c5e944a97e8bc529f6b5890f4a5fd",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2406.13107",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We present Blitzcrank, a high-speed semantic compressor designed for OLTP databases. Previous solutions are inadequate for compressing row-stores: they suffer from either low compression factor due to a coarse compression granularity or suboptimal performance due to the inefficiency in handling dynamic data sets. To solve these problems, we first propose novel semantic models that support fast inferences and dynamic value set for both discrete and continuous data types. We then introduce a new entropy encoding algorithm, called delayed coding, that achieves significant improvement in the decoding speed compared to modern arithmetic coding implementations. We evaluate Blitzcrank in both standalone microbenchmarks and a multicore in-memory row-store using the TPC-C benchmark. Our results show that Blitzcrank achieves a sub-microsecond latency for decompressing a random tuple while obtaining high compression factors. This leads to an 85% memory reduction in the TPC-C evaluation with a moderate (19%) throughput degradation. For data sets larger than the available physical memory, Blitzcrank help the database sustain a high throughput for more transactions before the I/O overhead dominates.",
    "citationCount": 3,
    "referenceCount": 55
}