{
    "paperId": "f0524448eb3d6bb57e6caed5dc1d50c48c1fa8c4",
    "title": "Bottleneck-Minimal Indexing for Generative Document Retrieval",
    "year": 2024,
    "venue": "International Conference on Machine Learning",
    "authors": [
        "Xin Du",
        "Lixin Xiu",
        "Kumiko Tanaka-Ishii"
    ],
    "doi": "10.48550/arXiv.2405.10974",
    "arxivId": "2405.10974",
    "url": "https://www.semanticscholar.org/paper/f0524448eb3d6bb57e6caed5dc1d50c48c1fa8c4",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We apply an information-theoretic perspective to reconsider generative document retrieval (GDR), in which a document $x \\in X$ is indexed by $t \\in T$, and a neural autoregressive model is trained to map queries $Q$ to $T$. GDR can be considered to involve information transmission from documents $X$ to queries $Q$, with the requirement to transmit more bits via the indexes $T$. By applying Shannon's rate-distortion theory, the optimality of indexing can be analyzed in terms of the mutual information, and the design of the indexes $T$ can then be regarded as a {\\em bottleneck} in GDR. After reformulating GDR from this perspective, we empirically quantify the bottleneck underlying GDR. Finally, using the NQ320K and MARCO datasets, we evaluate our proposed bottleneck-minimal indexing method in comparison with various previous indexing methods, and we show that it outperforms those methods.",
    "citationCount": 2,
    "referenceCount": 57
}