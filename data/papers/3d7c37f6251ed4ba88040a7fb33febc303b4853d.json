{
    "paperId": "3d7c37f6251ed4ba88040a7fb33febc303b4853d",
    "title": "General Post-Processing Framework for Fairness Adjustment of Machine Learning Models",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "L'eandre Eberhard",
        "Nirek Sharma",
        "Filipp Shelobolin",
        "Aalok Shanbhag"
    ],
    "doi": "10.48550/arXiv.2504.16238",
    "arxivId": "2504.16238",
    "url": "https://www.semanticscholar.org/paper/3d7c37f6251ed4ba88040a7fb33febc303b4853d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "As machine learning increasingly influences critical domains such as credit underwriting, public policy, and talent acquisition, ensuring compliance with fairness constraints is both a legal and ethical imperative. This paper introduces a novel framework for fairness adjustments that applies to diverse machine learning tasks, including regression and classification, and accommodates a wide range of fairness metrics. Unlike traditional approaches categorized as pre-processing, in-processing, or post-processing, our method adapts in-processing techniques for use as a post-processing step. By decoupling fairness adjustments from the model training process, our framework preserves model performance on average while enabling greater flexibility in model development. Key advantages include eliminating the need for custom loss functions, enabling fairness tuning using different datasets, accommodating proprietary models as black-box systems, and providing interpretable insights into the fairness adjustments. We demonstrate the effectiveness of this approach by comparing it to Adversarial Debiasing, showing that our framework achieves a comparable fairness/accuracy tradeoff on real-world datasets.",
    "citationCount": 0,
    "referenceCount": 28
}