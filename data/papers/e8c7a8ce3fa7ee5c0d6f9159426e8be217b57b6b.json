{
    "paperId": "e8c7a8ce3fa7ee5c0d6f9159426e8be217b57b6b",
    "title": "A Linguistic Study on Relevance Modeling in Information Retrieval",
    "year": 2021,
    "venue": "The Web Conference",
    "authors": [
        "Yixing Fan",
        "Jiafeng Guo",
        "Xinyu Ma",
        "Ruqing Zhang",
        "Yanyan Lan",
        "Xueqi Cheng"
    ],
    "doi": "10.1145/3442381.3450009",
    "arxivId": "2103.00956",
    "url": "https://www.semanticscholar.org/paper/e8c7a8ce3fa7ee5c0d6f9159426e8be217b57b6b",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3442381.3450009",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Linguistics",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Relevance plays a central role in information retrieval (IR), which has received extensive studies starting from the 20th century. The definition and the modeling of relevance has always been critical challenges in both information science and computer science research areas. Along with the debate and exploration on relevance, IR has already become a core task in many real-world applications, such as Web search engines, question answering systems, conversational bots, and so on. While relevance acts as a unified concept in all these retrieval tasks, the inherent definitions are quite different due to the heterogeneity of these tasks. This raises a question to us: Do these different forms of relevance really lead to different modeling focuses? To answer this question, in this work, we conduct an empirical study on relevance modeling in three representative IR tasks, i.e., document retrieval, answer retrieval, and response retrieval. Specifically, we attempt to study the following two questions: 1) Does relevance modeling in these tasks really show differences in terms of natural language understanding (NLU)? We employ 16 linguistic tasks to probe a unified retrieval model over these three retrieval tasks to answer this question. 2) If there do exist differences, how can we leverage the findings to enhance the relevance modeling? We proposed three intervention methods to investigate how to leverage different modeling focuses of relevance to improve these IR tasks. We believe the way we study the problem as well as our findings would be beneficial to the IR community.",
    "citationCount": 15,
    "referenceCount": 71
}