{
    "paperId": "5370be9160cb9e8e841bb544d54c3f39314fdaac",
    "title": "Data Proportion Detection for Optimized Data Management for Large Language Models",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Hao Liang",
        "Keshi Zhao",
        "Yajie Yang",
        "Bin Cui",
        "Guosheng Dong",
        "Zenan Zhou",
        "Wentao Zhang"
    ],
    "doi": "10.48550/arXiv.2409.17527",
    "arxivId": "2409.17527",
    "url": "https://www.semanticscholar.org/paper/5370be9160cb9e8e841bb544d54c3f39314fdaac",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Large language models (LLMs) have demonstrated exceptional performance across a wide range of tasks and domains, with data preparation playing a critical role in achieving these results. Pre-training data typically combines information from multiple domains. To maximize performance when integrating data from various domains, determining the optimal data proportion is essential. However, state-of-the-art (SOTA) LLMs rarely disclose details about their pre-training data, making it difficult for researchers to identify ideal data proportions. In this paper, we introduce a new topic, \\textit{data proportion detection}, which enables the automatic estimation of pre-training data proportions by analyzing the generated outputs of LLMs. We provide rigorous theoretical proofs, practical algorithms, and preliminary experimental results for data proportion detection. Based on these findings, we offer valuable insights into the challenges and future directions for effective data proportion detection and data management.",
    "citationCount": 0,
    "referenceCount": 25
}