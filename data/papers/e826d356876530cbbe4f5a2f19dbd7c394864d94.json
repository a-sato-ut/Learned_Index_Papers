{
    "paperId": "e826d356876530cbbe4f5a2f19dbd7c394864d94",
    "title": "Learning to Embed Categorical Features without Embedding Tables for Recommendation",
    "year": 2020,
    "venue": "Knowledge Discovery and Data Mining",
    "authors": [
        "Wang-Cheng Kang",
        "D. Cheng",
        "Tiansheng Yao",
        "Xinyang Yi",
        "Ting-Li Chen",
        "Lichan Hong",
        "Ed H. Chi"
    ],
    "doi": "10.1145/3447548.3467304",
    "arxivId": "2010.10784",
    "url": "https://www.semanticscholar.org/paper/e826d356876530cbbe4f5a2f19dbd7c394864d94",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3447548.3467304",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Embedding learning of categorical features (e.g. user/item IDs) is at the core of various recommendation models. The standard approach creates an embedding table where each row represents a dedicated embedding vector for every unique feature value. However, this method fails to efficiently handle high-cardinality features and unseen feature values (e.g. new video ID) that are prevalent in real-world recommendation systems. In this paper, we propose an alternative embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a deep embedding network to compute embeddings on the fly. DHE first encodes the feature value to a unique identifier vector with multiple hashing functions and transformations, and then applies a DNN to convert the identifier vector to an embedding. The encoding module is deterministic, non-learnable, and free of storage, while the embedding network is updated during the training time to learn embedding generation. Empirical results show that DHE achieves comparable AUC against the standard one-hot full embedding, with smaller model sizes. Our work sheds light on the design of DNN-based alternative embedding schemes for categorical features without using embedding table lookup.",
    "citationCount": 78,
    "referenceCount": 38
}