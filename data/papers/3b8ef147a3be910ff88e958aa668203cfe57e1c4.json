{
    "paperId": "3b8ef147a3be910ff88e958aa668203cfe57e1c4",
    "title": "A Learning Approach for Discovering Cost-Efficient Integrated Sourcing and Routing Strategies in E-Commerce",
    "year": 2024,
    "venue": "COMAD/CODS",
    "authors": [
        "Omkar Shelke",
        "Pranavi Pathakota",
        "Anandsingh Chauhan",
        "Hardik Meisheri",
        "H. Khadilkar",
        "Balaraman Ravindran"
    ],
    "doi": "10.1145/3632410.3632426",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/3b8ef147a3be910ff88e958aa668203cfe57e1c4",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Business",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This paper presents an integrated algorithmic framework for minimising product delivery costs in e-commerce (known as the cost-to-serve or CTS). One of the major challenges plaguing is the large volume of dynamically generated orders from multiple customers, each of which has to be fulfilled from one of several warehouses using a fleet of vehicles. This results in two levels of decision-making: selection of a fulfillment node for each order (including the option of deferral to a future time), followed by routing of vehicles (each of which can carry multiple orders originating from the same warehouse). To handle this, we propose an approach that combines graph neural networks, reinforcement learning, and an existing vehicle routing heuristic. We include real-world constraints such as warehouse inventory capacity, vehicle characteristics such as travel times, service times, carrying capacity, and customer constraints including time windows for delivery. The complexity of this problem arises from the fact that outcomes (rewards) are driven both by the fulfillment node mapping as well as the routing algorithms, and are spatio-temporally distributed. The problem is formulated as a Markov Decision Process (MDP) and solved by using a Graph Auto Encoder (GAE) in combination with Deep Q-Learning for fulfillment node mapping. Our experiments show that this algorithmic pipeline outperforms pure heuristic policies.",
    "citationCount": 1,
    "referenceCount": 30
}