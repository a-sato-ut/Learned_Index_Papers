{
    "paperId": "3644a5eded01913133a8d82cd4c65c44e8f3bc29",
    "title": "autoGEMM: Pushing the Limits of Irregular Matrix Multiplication on Arm Architectures",
    "year": 2024,
    "venue": "International Conference for High Performance Computing, Networking, Storage and Analysis",
    "authors": [
        "Du Wu",
        "Jintao Meng",
        "Wenxi Zhu",
        "Minwen Deng",
        "Xiao Wang",
        "Tao Luo",
        "Mohamed Wahib",
        "Yanjie Wei"
    ],
    "doi": "10.1109/SC41406.2024.00027",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/3644a5eded01913133a8d82cd4c65c44e8f3bc29",
    "isOpenAccess": true,
    "openAccessPdf": "https://www.osti.gov/biblio/2480030",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This paper presents an open-source library that pushes the limits of performance portability for irregular General Matrix Multiplication (GEMM) on the widely-used Arm architectures. Our library, autoGEMM, is designed to support a wide range of Arm processors: from edge devices to HPCgrade CPUs. autoGEMM generates optimized kernels for various hardware configurations by auto-combining fragments of autogenerated micro-kernels that employ hand-written optimizations to maximize computational efficiency. We optimize the kernel pipeline by tuning the register reuse and the data load/store overlapping. In addition, we use a dynamic tiling scheme to generate balanced tile shapes. Finally, we position autoGEMM on top of the TVM framework where our dynamic tiling scheme prunes the search space for TVM to identify the optimal combination of parameters for code optimization. Evaluations on five different classes of Arm chips demonstrate the advantages of autoGEMM. For small matrices, autoGEMM achieves 98% of peak and up to 2.0x speedup over state-of-the-art libraries such as LIBXSMM and LibShalom. For irregular matrices (i.e. tall skinny and long rectangles), autoGEMM is 1.3-2.0x faster than widely-used libraries such as OpenBLAS and Eigen. autoGEMM is publicly available at: https://github.com/wudu98/autoGEMM.",
    "citationCount": 6,
    "referenceCount": 71
}