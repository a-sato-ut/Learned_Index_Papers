{
    "paperId": "ecf501f3bb184a727e9a754f7198a49e8d05d2ac",
    "title": "Can Users Detect Biases or Factual Errors in Generated Responses in Conversational Information-Seeking?",
    "year": 2024,
    "venue": "SIGIR-AP",
    "authors": [
        "Weronika ≈Åajewska",
        "K. Balog",
        "Damiano Spina",
        "Johanne Trippas"
    ],
    "doi": "10.1145/3673791.3698409",
    "arxivId": "2410.21529",
    "url": "https://www.semanticscholar.org/paper/ecf501f3bb184a727e9a754f7198a49e8d05d2ac",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3673791.3698409",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Information-seeking dialogues span a wide range of questions, from simple factoid to complex queries that require exploring multiple facets and viewpoints. When performing exploratory searches in unfamiliar domains, users may lack background knowledge and struggle to verify the system-provided information, making them vulnerable to misinformation. We investigate the limitations of response generation in conversational information-seeking systems, highlighting potential inaccuracies, pitfalls, and biases in the responses. The study addresses the problem of query answerability and the challenge of response incompleteness. Our user studies explore how these issues impact user experience, focusing on users' ability to identify biased, incorrect, or incomplete responses. We design two crowdsourcing tasks to assess user experience with different system response variants, highlighting critical issues to be addressed in future conversational information-seeking research. Our analysis reveals that it is easier for users to detect response incompleteness than query answerability and user satisfaction is mostly associated with response diversity, not factual correctness.",
    "citationCount": 5,
    "referenceCount": 60
}