{
    "paperId": "eb7c9316c7c26220483cb9315058ceb129b5c167",
    "title": "VIRT: Improving Representation-based Text Matching via Virtual Interaction",
    "year": 2021,
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "authors": [
        "Dan Li",
        "Yang Yang",
        "Hongyin Tang",
        "Jingang Wang",
        "Tong Xu",
        "Wei Wu",
        "Enhong Chen"
    ],
    "doi": "10.18653/v1/2022.emnlp-main.59",
    "arxivId": "2112.04195",
    "url": "https://www.semanticscholar.org/paper/eb7c9316c7c26220483cb9315058ceb129b5c167",
    "isOpenAccess": true,
    "openAccessPdf": "https://aclanthology.org/2022.emnlp-main.59.pdf",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Text matching is a fundamental research problem in natural language understanding. Interaction-based approaches treat the text pair as a single sequence and encode it through cross encoders, while representation-based models encode the text pair independently with siamese or dual encoders. Interaction-based models require dense computations and thus are impractical in real-world applications. Representation-based models have become the mainstream paradigm for efficient text matching. However, these models suffer from severe performance degradation due to the lack of interactions between the pair of texts. To remedy this, we propose a Virtual InteRacTion mechanism (VIRT) for improving representation-based text matching while maintaining its efficiency. In particular, we introduce an interactive knowledge distillation module that is only applied during training. It enables deep interaction between texts by effectively transferring knowledge from the interaction-based model. A light interaction strategy is designed to fully leverage the learned interactive knowledge. Experimental results on six text matching benchmarks demonstrate the superior performance of our method over several state-of-the-art representation-based models. We further show that VIRT can be integrated into existing methods as plugins to lift their performances.",
    "citationCount": 10,
    "referenceCount": 47
}