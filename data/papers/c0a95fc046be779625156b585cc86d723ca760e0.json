{
    "paperId": "c0a95fc046be779625156b585cc86d723ca760e0",
    "title": "Approximate partition selection for big-data workloads using summary statistics",
    "year": 2020,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Kexin Rong",
        "Yao Lu",
        "Peter Bailis",
        "Srikanth Kandula",
        "P. Levis"
    ],
    "doi": "10.14778/3407790.3407848",
    "arxivId": "2008.10569",
    "url": "https://www.semanticscholar.org/paper/c0a95fc046be779625156b585cc86d723ca760e0",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2008.10569",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Many big-data clusters store data in large partitions that support access at a coarse, partition-level granularity. As a result, approximate query processing via row-level sampling is inefficient, often requiring reads of many partitions. In this work, we seek to answer queries quickly and approximately by reading a subset of the data partitions and combining partial answers in a weighted manner without modifying the data layout. We illustrate how to efficiently perform this query processing using a set of pre-computed summary statistics, which inform the choice of partitions and weights. We develop novel means of using the statistics to assess the similarity and importance of partitions. Our experiments on several datasets and data layouts demonstrate that to achieve the same relative error compared to uniform partition sampling, our techniques offer from 2.7x to 70x reduction in the number of partitions read, and the statistics stored per partition require fewer than 100KB.",
    "citationCount": 8,
    "referenceCount": 57
}