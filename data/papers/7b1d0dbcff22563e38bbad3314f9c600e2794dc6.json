{
    "paperId": "7b1d0dbcff22563e38bbad3314f9c600e2794dc6",
    "title": "Anytime Ranking on Document-Ordered Indexes",
    "year": 2021,
    "venue": "ACM Trans. Inf. Syst.",
    "authors": [
        "J. Mackenzie",
        "M. Petri",
        "Alistair Moffat"
    ],
    "doi": "10.1145/3467890",
    "arxivId": "2104.08976",
    "url": "https://www.semanticscholar.org/paper/7b1d0dbcff22563e38bbad3314f9c600e2794dc6",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2104.08976",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Inverted indexes continue to be a mainstay of text search engines, allowing efficient querying of large document collections. While there are a number of possible organizations, document-ordered indexes are the most common, since they are amenable to various query types, support index updates, and allow for efficient dynamic pruning operations. One disadvantage with document-ordered indexes is that high-scoring documents can be distributed across the document identifier space, meaning that index traversal algorithms that terminate early might put search effectiveness at risk. The alternative is impact-ordered indexes, which primarily support top- disjunctions but also allow for anytime query processing, where the search can be terminated at any time, with search quality improving as processing latency increases. Anytime query processing can be used to effectively reduce high-percentile tail latency that is essential for operational scenarios in which a service level agreement (SLA) imposes response time requirements. In this work, we show how document-ordered indexes can be organized such that they can be queried in an anytime fashion, enabling strict latency control with effective early termination. Our experiments show that processing document-ordered topical segments selected by a simple score estimator outperforms existing anytime algorithms, and allows query runtimes to be accurately limited to comply with SLA requirements.",
    "citationCount": 24,
    "referenceCount": 79
}