{
    "paperId": "e039d474f15e6e60594b832f0d6609a2cdc863b8",
    "title": "Research on Multi-Core Cache Data Prefetching Strategy based on Deep Learning",
    "year": 2024,
    "venue": "International Conference on Computational Intelligence and Intelligent Systems",
    "authors": [
        "Xinyu Qiao",
        "Jianxun Zhang",
        "Binghui Lin"
    ],
    "doi": "10.1145/3708778.3708802",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/e039d474f15e6e60594b832f0d6609a2cdc863b8",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Currently, the research prospect of deep learning applied to data prefetching in multi-core architectures are very broad. In order to give full play to the performance of parallel computing in multi-core processor systems, based on an in-depth discussion of the research of multi-core cache prefetching neural network model based on deep learning, a new deep learning model is constructed by introducing Convolutional Neural Network (Text CNN) and CBAM (Convolutional Block Attention Module) attention layer and utilizing Long Short-Term Memory (LSTM) parallel computing. The model is able to operate efficiently in multi-core architectures and effectively predict data access patterns to improve the accuracy and efficiency of data prefetching, thus optimizing the performance of the overall system. In order to evaluate the performance improvement of the improved model in cache prefetching in a multi-core processor system, multiple sets of experiments were conducted for comparative analysis. Experimental results compared with Voyager, the improved model improves the prefetching page and offset accuracies by 5.5% and 5.3%, respectively, and the overall accuracy is improved by 5.8%, the loss rate is reduced by 1.5%, the coverage rate is improved by 8.4%, and the F1 score value is improved by 0.07, which indicates that the improved model achieves a significant enhancement in cache prefetching effectiveness.",
    "citationCount": 0,
    "referenceCount": 7
}