{
    "paperId": "f8a97eac3c05d6f09772b24a1a1f6e66a2c17033",
    "title": "Product Kanerva Machines: Factorized Bayesian Memory",
    "year": 2020,
    "venue": "arXiv.org",
    "authors": [
        "A. Marblestone",
        "Y. Wu",
        "Greg Wayne"
    ],
    "doi": null,
    "arxivId": "2002.02385",
    "url": "https://www.semanticscholar.org/paper/f8a97eac3c05d6f09772b24a1a1f6e66a2c17033",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "An ideal cognitively-inspired memory system would compress and organize incoming items. The Kanerva Machine (Wu et al, 2018) is a Bayesian model that naturally implements online memory compression. However, the organization of the Kanerva Machine is limited by its use of a single Gaussian random matrix for storage. Here we introduce the Product Kanerva Machine, which dynamically combines many smaller Kanerva Machines. Its hierarchical structure provides a principled way to abstract invariant features and gives scaling and capacity advantages over single Kanerva Machines. We show that it can exhibit unsupervised clustering, find sparse and combinatorial allocation patterns, and discover spatial tunings that approximately factorize simple images by object.",
    "citationCount": 9,
    "referenceCount": 59
}