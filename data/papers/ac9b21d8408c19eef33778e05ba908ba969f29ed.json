{
    "paperId": "ac9b21d8408c19eef33778e05ba908ba969f29ed",
    "title": "NAAS: Neural Accelerator Architecture Search",
    "year": 2021,
    "venue": "Design Automation Conference",
    "authors": [
        "Yujun Lin",
        "Mengtian Yang",
        "Song Han"
    ],
    "doi": "10.1109/dac18074.2021.9586250",
    "arxivId": "2105.13258",
    "url": "https://www.semanticscholar.org/paper/ac9b21d8408c19eef33778e05ba908ba969f29ed",
    "isOpenAccess": true,
    "openAccessPdf": "https://dspace.mit.edu/bitstream/1721.1/143672/2/2105.13258.pdf",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Data-driven, automatic design space exploration of neural accelerator architecture is desirable for specialization and productivity. Previous frameworks focus on sizing the numerical architectural hyper-parameters while neglect searching the PE connectivities and compiler mappings. To tackle this challenge, we propose Neural Accelerator Architecture Search (NAAS) that holistically searches the neural network architecture, accelerator architecture and compiler mapping in one optimization loop. NAAS composes highly matched architectures together with efficient mapping. As a data-driven approach, NAAS rivals the human design Eyeriss by $4.4 \\times$ EDP reduction with 2.7% accuracy improvement on ImageNet under the same computation resource, and offers $1.4 \\times$ to $3.5 \\times$ EDP reduction than only sizing the architectural hyper-parameters.",
    "citationCount": 66,
    "referenceCount": 31
}