{
    "paperId": "a9ae2bf20151247910fe8fc77cd4db8f35bfead0",
    "title": "Wield: Systematic Reinforcement Learning With Progressive Randomization",
    "year": 2019,
    "venue": "arXiv.org",
    "authors": [
        "Michael Schaarschmidt",
        "Kai Fricke",
        "Eiko Yoneki"
    ],
    "doi": null,
    "arxivId": "1909.06844",
    "url": "https://www.semanticscholar.org/paper/a9ae2bf20151247910fe8fc77cd4db8f35bfead0",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Reinforcement learning frameworks have introduced abstractions to implement and execute algorithms at scale. They assume standardized simulator interfaces but are not concerned with identifying suitable task representations. We present Wield, a first-of-its kind system to facilitate task design for practical reinforcement learning. Through software primitives, Wield enables practitioners to decouple system-interface and deployment-specific configuration from state and action design. To guide experimentation, Wield further introduces a novel task design protocol and classification scheme centred around staged randomization to incrementally evaluate model capabilities.",
    "citationCount": 2,
    "referenceCount": 36
}