{
    "paperId": "baf94317ce9041eee87b7c954f703f2c93d421c5",
    "title": "A Multi-Task Learning Framework for Reading Comprehension of Scientific Tabular Data",
    "year": 2024,
    "venue": "IEEE International Conference on Data Engineering",
    "authors": [
        "Xu Yang",
        "Meihui Zhang",
        "Ju Fan",
        "Zeyu Luo",
        "Yuxin Yang"
    ],
    "doi": "10.1109/ICDE60146.2024.00285",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/baf94317ce9041eee87b7c954f703f2c93d421c5",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Tabular data in scientific papers provides valuable structured information for knowledge discovery and validation. Although the language models such as BERT and ChatGPT have significantly advanced the research on general domain tables, challenges remain in scientific tables. Specifically, such models have limitations in understanding scientific entities, as well as lacks numerical representation and computation capabilities. Previous studies have focused on scientific tables, but they are limited to individual modules or tasks and lack a comprehensive framework. To address these issues, we introduce a reading comprehension framework for scientific tables, named NRTR, which uses a multi-task learning approach that shares a common encoder, achieves reasoning across various tasks, including question answering, cloze testing, and fact verification. It has the following characteristics: (1) utilizing entity linking and named entity recognition to extract key information from papers, which enhances the models' understanding of scientific entities; (2) injecting numerical representation capabilities into language models and promoting the model's understanding of the relative magnitude of numbers to better reason about maximum and difference values. Notably, the existing scientific corpus lacks tabular contexts or does not integrate computational reasoning, which hinders the evaluation of reasoning models in scientific tables. To this end, we release SciTab, a multi-task dataset that merges high-quality scientific tables with contextual information to provide a benchmark for future research. Our experimental results show that NRTR outperforms existing models on SciTab.",
    "citationCount": 1,
    "referenceCount": 102
}