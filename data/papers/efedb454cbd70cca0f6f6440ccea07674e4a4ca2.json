{
    "paperId": "efedb454cbd70cca0f6f6440ccea07674e4a4ca2",
    "title": "SVQ: Streaming Video Queries",
    "year": 2019,
    "venue": "SIGMOD Conference",
    "authors": [
        "Ioannis Xarchakos",
        "Nick Koudas"
    ],
    "doi": "10.1145/3299869.3320230",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/efedb454cbd70cca0f6f6440ccea07674e4a4ca2",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recent advances in video processing utilizing deep learning primitives achieved breakthroughs in fundamental problems in video analysis such as frame classification and object detection enabling an array of new applications. In this demo we present \\em SVQ a system capable of executing declarative queries on streaming video. The system utilizes a set of approximate filters to speed up queries that involve objects of specific type (e.g., cars, trucks, etc.) on video frames with associated spatial relationships among them (e.g., car left of truck). The resulting filters are able to assess quickly if the query predicates are true to proceed with further analysis of the frame or otherwise not consider the frame further avoiding costly object detection and localization operations. The filters utilize extensible deep neural architectures and are easy to deploy and utilize. We demonstrate that the application of our filtering techniques in the context of SVQ enable declarative queries on video streams increasing dramatically the frame processing rate and speed up query processing by at least two orders of magnitude depending on the query.",
    "citationCount": 34,
    "referenceCount": 16
}