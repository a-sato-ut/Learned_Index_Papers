{
    "paperId": "86a70a83dc311c4fa8b9206665b59d888286346a",
    "title": "Mobile Robot Navigation Using Deep Reinforcement Learning in Unknown Environments",
    "year": 2020,
    "venue": "International Journal of Electrical and Electronics Engineering",
    "authors": [
        "R. V. Hoa",
        "L. L. K",
        "Le Thi Hoan"
    ],
    "doi": "10.14445/23488379/ijeee-v7i8p104",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/86a70a83dc311c4fa8b9206665b59d888286346a",
    "isOpenAccess": true,
    "openAccessPdf": "https://doi.org/10.14445/23488379/ijeee-v7i8p104",
    "publicationTypes": null,
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Mobile robots can cover a large range of real world missions such as environment surveillance, delivery, search and rescue missions. Such missions require different levels of selfnavigation in order to react to the dynamic environment changes. However, most of the navigation methods rely on static obstacle map, and donâ€™t have the ability of autonomous learning. In this paper, we propose an end-to-end approach using deep reinforcement learning for the navigation of mobile robots in an unknown environment. Based on dueling network architectures for deep reinforcement learning (Dueling DQN) and deep reinforcement learning with double Q learning (Double DQN), a dueling architecture based double deep Q network (D3QN) is adapted in this paper. Simulation results on the Gazebo framework show the feasibility of the proposed method. The robot can complete navigation tasks safely in an unpredicted dynamic environment and becomes a truly intelligent system with strong self-learning and adaptive abilities.",
    "citationCount": 4,
    "referenceCount": 23
}