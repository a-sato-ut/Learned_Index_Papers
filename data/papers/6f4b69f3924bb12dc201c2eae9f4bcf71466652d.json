{
    "paperId": "6f4b69f3924bb12dc201c2eae9f4bcf71466652d",
    "title": "Separating k-Player from t-Player One-Way Communication, with Applications to Data Streams",
    "year": 2019,
    "venue": "International Colloquium on Automata, Languages and Programming",
    "authors": [
        "David P. Woodruff",
        "Guang Yang"
    ],
    "doi": "10.4230/LIPIcs.ICALP.2019.97",
    "arxivId": "1905.07135",
    "url": "https://www.semanticscholar.org/paper/6f4b69f3924bb12dc201c2eae9f4bcf71466652d",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/1905.07135",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In a $k$-party communication problem, the $k$ players with inputs $x_1, x_2, \\ldots, x_k$, respectively, want to evaluate a function $f(x_1, x_2, \\ldots, x_k)$ using as little communication as possible. We consider the message-passing model, in which the inputs are partitioned in an arbitrary, possibly worst-case manner, among a smaller number $t$ of players ($t<k$). The $t$-player communication cost of computing $f$ can only be smaller than the $k$-player communication cost, since the $t$ players can trivially simulate the $k$-player protocol. But how much smaller can it be? We study deterministic and randomized protocols in the one-way model, and provide separations for product input distributions, which are optimal for low error probability protocols. We also provide much stronger separations when the input distribution is non-product. \r\nA key application of our results is in proving lower bounds for data stream algorithms. In particular, we give an optimal $\\Omega(\\varepsilon^{-2}\\log(N) \\log \\log(mM))$ bits of space lower bound for the fundamental problem of $(1\\pm\\varepsilon)$-approximating the number $\\|x\\|_0$ of non-zero entries of an $n$-dimensional vector $x$ after $m$ updates each of magnitude $M$, and with success probability $\\ge 2/3$, in a strict turnstile stream. Our result matches the best known upper bound when $\\varepsilon\\ge 1/\\mathsf{polylog}(mM)$. It also improves on the prior $\\Omega(\\varepsilon^{-2}\\log(mM) )$ lower bound and separates the complexity of approximating $L_0$ from approximating the $p$-norm $L_p$ for $p$ bounded away from $0$, since the latter has an $O(\\varepsilon^{-2}\\log (mM))$ bit upper bound.",
    "citationCount": 4,
    "referenceCount": 34
}