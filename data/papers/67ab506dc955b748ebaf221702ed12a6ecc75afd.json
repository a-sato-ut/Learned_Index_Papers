{
    "paperId": "67ab506dc955b748ebaf221702ed12a6ecc75afd",
    "title": "Easing the path to deployment in ML4Sys through FPGAs",
    "year": 2025,
    "venue": "PACMI@SOSP",
    "authors": [
        "M. J. Heer",
        "Benjamin Ramhorst",
        "Gustavo Alonso"
    ],
    "doi": "10.1145/3766882.3767178",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/67ab506dc955b748ebaf221702ed12a6ecc75afd",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Machine Learning (ML) techniques are increasingly applied to optimize computer systems, but their integration into core low-level system mechanisms remains limited. A key barrier is the lack of accessible, high performance interfaces at the boundary between software and hardware as well as hardware-offloaded ML inference at full systems speed. In this position paper, we argue that Field Programmable Gate Arrays (FPGAs) are a key enabler for closing this very gap. The combination of mature FPGA shells, which represent full-fledged computer systems on reconfigurable fabric, and modern ML compilers for hardware-accelerated inference enables rapid prototyping and deployment of ML models directly at the interfaces of key system mechanisms. This approach allows for low latency, real-time decision making in system components such as memory management, scheduling logic, and network control. We outline a vision of a fully ML-optimized FPGA-based system, serving as a research platform for system optimization in both classic computer systems and next-generation accelerators.",
    "citationCount": 0,
    "referenceCount": 47
}