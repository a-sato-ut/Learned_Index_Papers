{
    "paperId": "4ecca3953d572b3a39565b7583450fc092a4597c",
    "title": "Exo 2: Growing a Scheduling Language",
    "year": 2024,
    "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems",
    "authors": [
        "Yuka Ikarashi",
        "Kevin Qian",
        "Samir Droubi",
        "Alex Reinking",
        "G. Bernstein",
        "Jonathan Ragan-Kelley"
    ],
    "doi": "10.1145/3669940.3707218",
    "arxivId": "2411.07211",
    "url": "https://www.semanticscholar.org/paper/4ecca3953d572b3a39565b7583450fc092a4597c",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2411.07211",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "User-schedulable languages (USLs) help programmers productively optimize programs by providing safe means of transforming them. Current USLs are designed to give programmers exactly the control they want, while automating all other concerns. However, there is no universal answer for what performance-conscious programmers want to control, how they want to control it, and what they want to automate, even in relatively narrow domains. We claim that USLs should, instead, be designed to grow. We present Exo 2, a scheduling language that enables users to define new scheduling operations externally to the compiler. By composing a set of trusted, fine-grained primitives, users can safely write their own scheduling library to build up desired automation. We identify actions (ways of modifying code), inspection (ways of interrogating code), and references (ways of pointing to code) as essential for any user-extensible USL. We fuse these ideas into a new mechanism called Cursors that enables the creation of scheduling libraries in user code. We demonstrate libraries that amortize scheduling effort across more than 80 high-performance kernels, reducing total scheduling code by an order of magnitude and delivering performance competitive with state-of-the-art implementations on three different platforms.",
    "citationCount": 0,
    "referenceCount": 80
}