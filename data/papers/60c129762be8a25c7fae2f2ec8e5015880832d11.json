{
    "paperId": "60c129762be8a25c7fae2f2ec8e5015880832d11",
    "title": "TensorMap: A Deep RL-Based Tensor Mapping Framework for Spatial Accelerators",
    "year": 2024,
    "venue": "IEEE transactions on computers",
    "authors": [
        "Fuyu Wang",
        "Minghua Shen",
        "Yutong Lu",
        "Nong Xiao"
    ],
    "doi": "10.1109/TC.2024.3398424",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/60c129762be8a25c7fae2f2ec8e5015880832d11",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The mapping of tensor computation is a complex and important process for spatial accelerators. Today's mapping works depend on hand-tuned kernel libraries or search-based heuristics from human experts. The former is time-intensive while the latter easily leads to sub-optimal performance. In this paper, we propose TensorMap, a deep reinforcement learning (RL)-based mapping framework for tensor computations on spatial accelerators. We propose a sequential generation mode for mapping optimization and construct a coarse-grained action space to reduce the complexity of the mapping search space. An efficient policy network is devised to optimize mapping primitives in the RL-based search. We then propose a stop signal that is sampled from <italic>Bernoulli</italic> distribution to facilitate multi-level loop unrolling for spatial accelerators. Finally, a genetic algorithm is employed to further refine the optimized mappings. In the experiments, we demonstrate TensorMap's ability for different spatial accelerators with various tensor computations. On TPU, TensorMap provides 2.6<inline-formula><tex-math notation=\"LaTeX\">$\\times$</tex-math><alternatives><mml:math><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq1-3398424.gif\"/></alternatives></inline-formula>, 2.7<inline-formula><tex-math notation=\"LaTeX\">$\\times$</tex-math><alternatives><mml:math><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq2-3398424.gif\"/></alternatives></inline-formula>, and 2.4<inline-formula><tex-math notation=\"LaTeX\">$\\times$</tex-math><alternatives><mml:math><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq3-3398424.gif\"/></alternatives></inline-formula> better energy-delay product (EDP) on average compared with FlexTensor, Ansor, and AMOS respectively. On Eyeriss, TensorMap provides 2.1<inline-formula><tex-math notation=\"LaTeX\">$\\times$</tex-math><alternatives><mml:math><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq4-3398424.gif\"/></alternatives></inline-formula>, 1.8<inline-formula><tex-math notation=\"LaTeX\">$\\times$</tex-math><alternatives><mml:math><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq5-3398424.gif\"/></alternatives></inline-formula>, and 1.7<inline-formula><tex-math notation=\"LaTeX\">$\\times$</tex-math><alternatives><mml:math><mml:mo>×</mml:mo></mml:math><inline-graphic xlink:href=\"wang-ieq6-3398424.gif\"/></alternatives></inline-formula> better EDP on average compared with FlexTensor, Ansor, and AMOS respectively.",
    "citationCount": 2,
    "referenceCount": 45
}