{
    "paperId": "c926f88272782df2f4377d6374fce1c7d609dd23",
    "title": "Tree-Convolutional-Transformer: A Hybrid Model for Query Plan Representation",
    "year": 2023,
    "venue": "CECCT",
    "authors": [
        "Wei Liu",
        "Rui Xi",
        "Mengshu Hou"
    ],
    "doi": "10.1145/3637494.3637516",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/c926f88272782df2f4377d6374fce1c7d609dd23",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Optimizing a physical execution plan is a crucial task in enhancing the query performance of a database. Especially, the efficient vectorization of a query plan is a pivotal challenging problem. Machine learning has risen as a dominant approach, but, two main limitations are still existing. Firstly, struggling to encapsulate the interdependencies among nodes within the plan. Secondly, underestimating the abundant database statistics. In this paper, we propose a novel tree-structured model, termed Tree-Convolutional-Transformer incorporating convolutional operations and attention mechanisms, to effectively learn interdependencies among nodes. Furthermore, in order to enrich the learned feature representation, statistical information gleaned from the database system is also integrated into the encoding of the query plan. Through comprehensive experiments on a real-world dataset (IMDb) and query workloads, results demonstrate the effectiveness and feasibility of the proposed model in capturing the dependencies among nodes within the physical execution plan tree.",
    "citationCount": 0,
    "referenceCount": 26
}