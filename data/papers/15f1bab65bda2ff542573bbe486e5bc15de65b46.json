{
    "paperId": "15f1bab65bda2ff542573bbe486e5bc15de65b46",
    "title": "Kolmogorovâ€”Arnold Networks: Overview of Architectures and Use Cases",
    "year": 2025,
    "venue": "IEEE International Conference on Circuits and Systems for Communications",
    "authors": [
        "Siham Essahraui",
        "Ismail Lamaakal",
        "K. Makkaoui",
        "Ibrahim Ouahbi",
        "Mouncef Filali Bouami",
        "Yassine Maleh"
    ],
    "doi": "10.1109/ICCSC66714.2025.11135248",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/15f1bab65bda2ff542573bbe486e5bc15de65b46",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) are an emerging class of neural network architectures grounded in the Kolmogorov-Arnold representation theorem, offering a sym-bolic and interpretable approach to modeling complex, high-dimensional functions. By replacing traditional activation functions with learnable univariate splines, KANs deliver enhanced expressiveness, parameter efficiency, and transparency. This survey provides a comprehensive overview of KAN developments, including foundational designs and specialized variants tailored to time series, graphs, scientific computing, image analysis, and biomedicine. We highlight the strengths of KANs in bridging the gap between symbolic reasoning and data-driven learning, while also discussing challenges such as computational overhead and spline optimization complexity. Through detailed architec-tural taxonomy and real-world application examples, this paper positions KANs as a compelling framework for interpretable, high-performance machine learning.",
    "citationCount": 0,
    "referenceCount": 71
}