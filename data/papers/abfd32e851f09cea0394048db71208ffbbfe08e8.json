{
    "paperId": "abfd32e851f09cea0394048db71208ffbbfe08e8",
    "title": "Deep Image Matting: A Comprehensive Survey",
    "year": 2023,
    "venue": "arXiv.org",
    "authors": [
        "Jizhizi Li",
        "Jing Zhang",
        "Dacheng Tao"
    ],
    "doi": "10.48550/arXiv.2304.04672",
    "arxivId": "2304.04672",
    "url": "https://www.semanticscholar.org/paper/abfd32e851f09cea0394048db71208ffbbfe08e8",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2304.04672",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Image matting refers to extracting precise alpha matte from natural images, and it plays a critical role in various downstream applications, such as image editing. Despite being an ill-posed problem, traditional methods have been trying to solve it for decades. The emergence of deep learning has revolutionized the field of image matting and given birth to multiple new techniques, including automatic, interactive, and referring image matting. This paper presents a comprehensive review of recent advancements in image matting in the era of deep learning. We focus on two fundamental sub-tasks: auxiliary input-based image matting, which involves user-defined input to predict the alpha matte, and automatic image matting, which generates results without any manual intervention. We systematically review the existing methods for these two tasks according to their task settings and network structures and provide a summary of their advantages and disadvantages. Furthermore, we introduce the commonly used image matting datasets and evaluate the performance of representative matting methods both quantitatively and qualitatively. Finally, we discuss relevant applications of image matting and highlight existing challenges and potential opportunities for future research. We also maintain a public repository to track the rapid development of deep image matting at https://github.com/JizhiziLi/matting-survey.",
    "citationCount": 15,
    "referenceCount": 212
}