{
    "paperId": "d5c2a4c5904a999b4c8a2f848ae91f4525c179d0",
    "title": "KEA: Tuning an Exabyte-Scale Data Infrastructure",
    "year": 2021,
    "venue": "SIGMOD Conference",
    "authors": [
        "Yiwen Zhu",
        "Subru Krishnan",
        "Konstantinos Karanasos",
        "Isha Tarte",
        "Conor Power",
        "Abhishek Modi",
        "Manoj Kumar",
        "Deli Zhang",
        "Kartheek Muthyala",
        "Nick Jurgens",
        "Sarvesh Sakalanaga",
        "Sudhir Darbha",
        "Minu Iyer",
        "A. Agarwal",
        "C. Curino"
    ],
    "doi": "10.1145/3448016.3457569",
    "arxivId": "2106.11445",
    "url": "https://www.semanticscholar.org/paper/d5c2a4c5904a999b4c8a2f848ae91f4525c179d0",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2106.11445",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Microsoft's internal big-data infrastructure is one of the largest in the world---with over 300k machines running billions of tasks from over 0.6M daily jobs. Operating this infrastructure is a costly and complex endeavor, and efficiency is paramount. In fact, for over 15 years, a dedicated engineering team has tuned almost every aspect of this infrastructure, achieving state-of-the-art efficiency (>60% average CPU utilization across all clusters). Despite rich telemetry and strong expertise, faced with evolving hardware/software/workloads this manual tuning approach had reached its limit---we had plateaued. In this paper, we present KEA, a multi-year effort to automate our tuning processes to be fully data/model-driven. KEA leverages a mix of domain knowledge and principled data science to capture the essence of our cluster dynamic behavior in a set of machine learning (ML) models based on collected system data. These models power automated optimization procedures for parameter tuning, and inform our leadership in critical decisions around engineering and capacity management (such as hardware and data center design, software investments, etc.). We combine \"observational'' tuning (i.e., using models to predict system behavior without direct experimentation) with judicious use of \"flighting'' (i.e., conservative testing in production). This allows us to support a broad range of applications that we discuss in this paper. KEA continuously tunes our cluster configurations and is on track to save Microsoft tens of millions of dollars per year. At the best of our knowledge, this paper is the first to discuss research challenges and practical learnings that emerge when tuning an exabyte-scale data infrastructure.",
    "citationCount": 21,
    "referenceCount": 62
}