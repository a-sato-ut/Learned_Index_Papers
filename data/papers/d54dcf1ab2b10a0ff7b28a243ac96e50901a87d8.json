{
    "paperId": "d54dcf1ab2b10a0ff7b28a243ac96e50901a87d8",
    "title": "Case-Enhanced Vision Transformer: Improving Explanations of Image Similarity with a ViT-based Similarity Metric",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Ziwei Zhao",
        "David B. Leake",
        "Xiaomeng Ye",
        "David Crandall"
    ],
    "doi": "10.48550/arXiv.2407.16981",
    "arxivId": "2407.16981",
    "url": "https://www.semanticscholar.org/paper/d54dcf1ab2b10a0ff7b28a243ac96e50901a87d8",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This short paper presents preliminary research on the Case-Enhanced Vision Transformer (CEViT), a similarity measurement method aimed at improving the explainability of similarity assessments for image data. Initial experimental results suggest that integrating CEViT into k-Nearest Neighbor (k-NN) classification yields classification accuracy comparable to state-of-the-art computer vision models, while adding capabilities for illustrating differences between classes. CEViT explanations can be influenced by prior cases, to illustrate aspects of similarity relevant to those cases.",
    "citationCount": 1,
    "referenceCount": 28
}