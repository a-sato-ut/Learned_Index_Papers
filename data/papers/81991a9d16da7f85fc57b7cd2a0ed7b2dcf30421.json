{
    "paperId": "81991a9d16da7f85fc57b7cd2a0ed7b2dcf30421",
    "title": "MAPA: Multi-Accelerator Pattern Allocation Policy for Multi-Tenant GPU Servers",
    "year": 2021,
    "venue": "International Conference for High Performance Computing, Networking, Storage and Analysis",
    "authors": [
        "K. Ranganath",
        "Joshua D. Suetterlein",
        "J. Manzano",
        "S. Song",
        "Daniel Wong"
    ],
    "doi": "10.1145/3458817.3480853",
    "arxivId": "2110.03214",
    "url": "https://www.semanticscholar.org/paper/81991a9d16da7f85fc57b7cd2a0ed7b2dcf30421",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3458817.3480853",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Multi-accelerator servers are increasingly being deployed in shared multi-tenant environments (such as in cloud data centers) in order to meet the demands of large-scale compute-intensive workloads. In addition, these accelerators are increasingly being inter-connected in complex topologies and workloads are exhibiting a wider variety of inter-accelerator communication patterns. However, existing allocation policies are ill-suited for these emerging use-cases. Specifically, this work identifies that multi-accelerator workloads are commonly fragmented leading to reduced bandwidth and increased latency for inter-accelerator communication. We propose Multi-Accelerator Pattern Allocation (MAPA), a graph pattern mining approach towards providing generalized allocation support for allocating multi-accelerator workloads on multi-accelerator servers. We demonstrate that MAPA is able to improve the execution time of multi-accelerator workloads and that MAPA is able to provide generalized benefits across various accelerator topologies. Finally, we demonstrate a speedup of 12.4% for 75th percentile of jobs with the worst case execution time reduced by up to 35% against baseline policy using MAPA.",
    "citationCount": 16,
    "referenceCount": 73
}