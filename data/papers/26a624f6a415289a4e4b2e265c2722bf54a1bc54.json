{
    "paperId": "26a624f6a415289a4e4b2e265c2722bf54a1bc54",
    "title": "Large Language Model Supply Chain: A Research Agenda",
    "year": 2024,
    "venue": "ACM Transactions on Software Engineering and Methodology",
    "authors": [
        "Shenao Wang",
        "Yanjie Zhao",
        "Xinyi Hou",
        "Haoyu Wang"
    ],
    "doi": "10.1145/3708531",
    "arxivId": "2404.12736",
    "url": "https://www.semanticscholar.org/paper/26a624f6a415289a4e4b2e265c2722bf54a1bc54",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3708531",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has revolutionized artificial intelligence, introducing unprecedented capabilities in natural language processing and multimodal content generation. However, the increasing complexity and scale of these models have given rise to a multifaceted supply chain that presents unique challenges across infrastructure, foundation models, and downstream applications. This article provides the first comprehensive research agenda of the LLM supply chain, offering a structured approach to identify critical challenges and opportunities through the dual lenses of software engineering (SE) and security and privacy (S&P). We begin by establishing a clear definition of the LLM supply chain, encompassing its components and dependencies. We then analyze each layer of the supply chain, presenting a vision for robust and secure LLM development, reviewing the current state of practices and technologies, and identifying key challenges and research opportunities. This work aims to bridge the existing research gap in systematically understanding the multifaceted issues within the LLM supply chain, offering valuable insights to guide future efforts in this rapidly evolving domain.",
    "citationCount": 29,
    "referenceCount": 345
}