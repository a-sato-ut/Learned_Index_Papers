{
    "paperId": "3b1b75350c00b01beb7321532be0de6a53306d9d",
    "title": "Hierarchical Opacity Propagation for Image Matting",
    "year": 2020,
    "venue": "arXiv.org",
    "authors": [
        "Yaoyi Li",
        "Qin Xu",
        "Hongtao Lu"
    ],
    "doi": null,
    "arxivId": "2004.03249",
    "url": "https://www.semanticscholar.org/paper/3b1b75350c00b01beb7321532be0de6a53306d9d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Natural image matting is a fundamental problem in computational photography and computer vision. Deep neural networks have seen the surge of successful methods in natural image matting in recent years. In contrast to traditional propagation-based matting methods, some top-tier deep image matting approaches tend to perform propagation in the neural network implicitly. A novel structure for more direct alpha matte propagation between pixels is in demand. To this end, this paper presents a hierarchical opacity propagation (HOP) matting method, where the opacity information is propagated in the neighborhood of each point at different semantic levels. The hierarchical structure is based on one global and multiple local propagation blocks. With the HOP structure, every feature point pair in high-resolution feature maps will be connected based on the appearance of input image. We further propose a scale-insensitive positional encoding tailored for image matting to deal with the unfixed size of input image and introduce the random interpolation augmentation into image matting. Extensive experiments and ablation study show that HOP matting is capable of outperforming state-of-the-art matting methods.",
    "citationCount": 13,
    "referenceCount": 49
}