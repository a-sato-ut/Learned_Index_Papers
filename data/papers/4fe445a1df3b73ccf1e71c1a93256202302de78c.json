{
    "paperId": "4fe445a1df3b73ccf1e71c1a93256202302de78c",
    "title": "Maximizing RAG efficiency: A comparative analysis of RAG methods",
    "year": 2024,
    "venue": "Natural Language Processing",
    "authors": [
        "Tolga Åžakar",
        "Hakan Emekci"
    ],
    "doi": "10.1017/nlp.2024.53",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/4fe445a1df3b73ccf1e71c1a93256202302de78c",
    "isOpenAccess": true,
    "openAccessPdf": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/D7B259BCD35586E04358DF06006E0A85/S2977042424000530a.pdf/div-class-title-maximizing-rag-efficiency-a-comparative-analysis-of-rag-methods-div.pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "\n This paper addresses the optimization of retrieval-augmented generation (RAG) processes by exploring various methodologies, including advanced RAG methods. The research, driven by the need to enhance RAG processes as highlighted by recent studies, involved a grid-search optimization of 23,625 iterations. We evaluated multiple RAG methods across different vectorstores, embedding models, and large language models, using cross-domain datasets and contextual compression filters. The findings emphasize the importance of balancing context quality with similarity-based ranking methods, as well as understanding tradeoffs between similarity scores, token usage, runtime, and hardware utilization. Additionally, contextual compression filters were found to be crucial for efficient hardware utilization and reduced token consumption, despite the evident impacts on similarity scores, which may be acceptable depending on specific use cases and RAG methods.",
    "citationCount": 23,
    "referenceCount": 21
}