{
    "paperId": "50d0d18d78ae80da0f83d0cc8356b2fd1ffccd5a",
    "title": "Sample- and Parameter-Efficient Auto-Regressive Image Models",
    "year": 2024,
    "venue": "Computer Vision and Pattern Recognition",
    "authors": [
        "Elad Amrani",
        "Leonid Karlinsky",
        "Alexander M. Bronstein"
    ],
    "doi": "10.1109/CVPR52734.2025.02804",
    "arxivId": "2411.15648",
    "url": "https://www.semanticscholar.org/paper/50d0d18d78ae80da0f83d0cc8356b2fd1ffccd5a",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We introduce XTRA, a vision model pre-trained with a novel auto-regressive objective that significantly enhances both sample and parameter efficiency compared to previous auto-regressive image models. Unlike contrastive or masked image modeling methods, which have not been demonstrated as having consistent scaling behavior on unbalanced internet data, auto-regressive vision models exhibit scalable and promising performance as model and dataset size increase. In contrast to standard auto-regressive models, XTRA employs a Block Causal Mask, where each Block represents k × k tokens rather than relying on a standard causal mask. By reconstructing pixel values block by block, XTRA captures higher-level structural patterns over larger image regions. Predicting on blocks allows the model to learn relationships across broader areas of pixels, enabling more abstract and semantically meaningful representations than traditional next-token prediction. This simple modification yields two key results. First, XTRA is sample- efficient. Despite being trained on 152 fewer samples (13.1M vs. 2B), XTRA ViT-H/14 surpasses the×top-1 average accuracy of the previous state-of-the-art auto-regressive model across 15 diverse image recognition benchmarks. Second, XTRA is parameter-efficient. Compared to auto-regressive models trained on ImageNet-1k, XTRA ViT-B/16 outperforms in linear and attentive probing tasks, using 7–16× fewer parameters (85M vs. 1.36B/0.63B).",
    "citationCount": 1,
    "referenceCount": 49
}