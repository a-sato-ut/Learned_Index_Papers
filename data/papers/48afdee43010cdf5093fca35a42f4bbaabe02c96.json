{
    "paperId": "48afdee43010cdf5093fca35a42f4bbaabe02c96",
    "title": "Federated Multi-Output Gaussian Processes",
    "year": 2023,
    "venue": "Technometrics",
    "authors": [
        "Seokhyun Chung",
        "R. Kontar"
    ],
    "doi": "10.1080/00401706.2023.2238834",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/48afdee43010cdf5093fca35a42f4bbaabe02c96",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Abstract Multi-output Gaussian process (MGP) regression plays an important role in the integrative analysis of different but interrelated systems/units. Existing MGP approaches assume that data from all units is collected and stored at a central location. This requires massive computing and storage power at the central location, induces significant communication traffic due to raw data exchange, and comprises privacy of units. However, recent advances in Internet of Things technologies, which have tremendously increased edge computing power, pose a significant opportunity to address such challenges. In this article, we propose FedMGP, a general federated analytics (FA) framework to learn an MGP in a decentralized manner that uses edge computing power to distribute model learning efforts. Specifically, we propose a hierarchical modeling approach where an MGP is built upon shared global latent functions. We then develop a variational inference FA algorithm that overcomes the need to share raw data. Instead, collaborative learning is achieved by only sharing global latent function statistics. Comprehensive simulation studies and a case study on battery degradation data highlight the superior predictive performance and versatility of FedMGP, achieved while distributing computing and storage demands, reducing communication burden, fostering privacy, and personalizing analysis.",
    "citationCount": 9,
    "referenceCount": 69
}