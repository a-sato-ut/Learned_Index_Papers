{
    "paperId": "c24d4a6f0e9978e6aa645d561b3f5ef60269a6e6",
    "title": "Disentangled Representation Learning for Unsupervised Neural Quantization",
    "year": 2023,
    "venue": "Computer Vision and Pattern Recognition",
    "authors": [
        "Hae-Chan Noh",
        "Sangeek Hyun",
        "Woojin Jeong",
        "Hanshin Lim",
        "Jae-Pil Heo"
    ],
    "doi": "10.1109/CVPR52729.2023.01155",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/c24d4a6f0e9978e6aa645d561b3f5ef60269a6e6",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The inverted index is a widely used data structure to avoid the infeasible exhaustive search. It accelerates retrieval significantly by splitting the database into multiple disjoint sets and restricts distance computation to a small fraction of the database. Moreover, it even improves search quality by allowing quantizers to exploit the compact distribution of residual vector space. However, we firstly point out a problem that an existing deep learning-based quantizer hardly benefits from the residual vector space, unlike conventional shallow quantizers. To cope with this problem, we introduce a novel disentangled representation learning for unsupervised neural quantization. Similar to the concept of residual vector space, the proposed method enables more compact latent space by disentangling information of the inverted index from the vectors. Experimental results on large-scale datasets confirm that our method outperforms the state-of-the-art retrieval systems by a large margin.",
    "citationCount": 2,
    "referenceCount": 40
}