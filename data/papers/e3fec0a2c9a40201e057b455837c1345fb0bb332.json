{
    "paperId": "e3fec0a2c9a40201e057b455837c1345fb0bb332",
    "title": "Training-Free Query Optimization via LLM-Based Plan Similarity",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Nikita Vasilenko",
        "Alexander Demin",
        "Vladimir Boorlakov"
    ],
    "doi": "10.48550/arXiv.2506.05853",
    "arxivId": "2506.05853",
    "url": "https://www.semanticscholar.org/paper/e3fec0a2c9a40201e057b455837c1345fb0bb332",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Large language model (LLM) embeddings offer a promising new avenue for database query optimization. In this paper, we explore how pre-trained execution plan embeddings can guide SQL query execution without the need for additional model training. We introduce LLM-PM (LLM-based Plan Mapping), a framework that embeds the default execution plan of a query, finds its k nearest neighbors among previously executed plans, and recommends database hintsets based on neighborhood voting. A lightweight consistency check validates the selected hint, while a fallback mechanism searches the full hint space when needed. Evaluated on the JOB-CEB benchmark using OpenGauss, LLM-PM achieves an average speed-up of 21% query latency reduction. This work highlights the potential of LLM-powered embeddings to deliver practical improvements in query performance and opens new directions for training-free, embedding-based optimizer guidance systems.",
    "citationCount": 1,
    "referenceCount": 16
}