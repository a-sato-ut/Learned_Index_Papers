{
    "paperId": "d19ae661d0f006a0813f66e6acbbde837cd22fc2",
    "title": "ALR2: A Retrieve-then-Reason Framework for Long-context Question Answering",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Huayang Li",
        "Pat Verga",
        "Priyanka Sen",
        "Bowen Yang",
        "Vijay Viswanathan",
        "Patrick Lewis",
        "Taro Watanabe",
        "Yixuan Su"
    ],
    "doi": "10.48550/arXiv.2410.03227",
    "arxivId": "2410.03227",
    "url": "https://www.semanticscholar.org/paper/d19ae661d0f006a0813f66e6acbbde837cd22fc2",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The context window of large language models (LLMs) has been extended significantly in recent years. However, while the context length that the LLM can process has grown, the capability of the model to accurately reason over that context degrades noticeably. This occurs because modern LLMs often become overwhelmed by the vast amount of information in the context; when answering questions, the model must identify and reason over relevant evidence sparsely distributed throughout the text. To alleviate the challenge of long-context reasoning, we develop a retrieve-then-reason framework, enabling LLMs to reason over relevant evidence collected during an intermediate retrieval step. We find that modern LLMs struggle to accurately retrieve relevant facts and instead, often hallucinate\"retrieved facts\", resulting in flawed reasoning and the production of incorrect answers. To address these issues, we introduce ALR$^2$, a method that augments the long-context reasoning capability of LLMs via an explicit two-stage procedure, i.e., aligning LLMs with the objectives of both retrieval and reasoning. We demonstrate the efficacy of ALR$^2$ for mitigating performance degradation in long-context reasoning tasks. Through extensive experiments on long-context QA benchmarks, we find our method to outperform competitive baselines by large margins, achieving at least 8.4 and 7.9 EM gains on the long-context versions of HotpotQA and SQuAD datasets, respectively.",
    "citationCount": 18,
    "referenceCount": 62
}