{
    "paperId": "425fb2f829d06d3a7b4f5936b4ee9dce71bb823f",
    "title": "Federated Recommendation via Hybrid Retrieval Augmented Generation",
    "year": 2024,
    "venue": "BigData Congress [Services Society]",
    "authors": [
        "Huimin Zeng",
        "Zhenrui Yue",
        "Qian Jiang",
        "Dong Wang"
    ],
    "doi": "10.1109/BigData62323.2024.10825302",
    "arxivId": "2403.04256",
    "url": "https://www.semanticscholar.org/paper/425fb2f829d06d3a7b4f5936b4ee9dce71bb823f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Federated Recommendation (FR) emerges as a novel paradigm that enables privacy-preserving recommendations. However, traditional FR systems usually represent users/items with discrete identities (IDs), suffering from performance degradation due to data sparsity and heterogeneity in FR. On the other hand, Large Language Models (LLMs) as recommenders have proven effective across various recommendation scenarios. Yet, LLM-based recommenders encounter challenges such as incomplete recommendation and potential hallucination, compromising their performance in real-world scenarios. To this end, we propose GPT-FedRec, a federated recommendation framework leveraging ChatGPT and a novel hybrid Retrieval Augmented Generation (RAG) mechanism. GPT-FedRec is a two-stage solution. The first stage is a hybrid retrieval process, mining ID-based user patterns and text-based item features. Next, in the second stage, the results returned by hybrid retrieval are converted into text prompts and fed into GPT for re-ranking. Under GPT-FedRec, the privacy of both local training data and global test data is well protected, as there is no data exchange across any clients or the global server. For test users, GPT-FedRec executes inference only on the global server: given the historical data of a test user, GPT-FedRec performs hybrid retrieval and GPT-based re-ranking, without exposing test data to any other clients. Our proposed hybrid retrieval mechanism and LLM-based re-ranking aim to extract generalized features from data and exploit pretrained knowledge within LLM, overcoming data sparsity and heterogeneity in FR. Finally, the RAG nature of GPT-FedRec also prevents LLM hallucination, improving the recommendation performance for real-world users. Experimental results on diverse benchmark datasets demonstrate the superior performance of GPT-FedRec against state-of-the-art baseline methods. Our code is available at https://github.com/huiminzeng/GPT-FedRec.git.",
    "citationCount": 17,
    "referenceCount": 43
}