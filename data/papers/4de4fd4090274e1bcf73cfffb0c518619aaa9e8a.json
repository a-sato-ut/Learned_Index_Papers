{
    "paperId": "4de4fd4090274e1bcf73cfffb0c518619aaa9e8a",
    "title": "Safe Exploitative Play with Untrusted Type Beliefs",
    "year": 2024,
    "venue": "Neural Information Processing Systems",
    "authors": [
        "Tongxin Li",
        "Tinashe Handina",
        "Shaolei Ren",
        "Adam Wierman"
    ],
    "doi": "10.48550/arXiv.2411.07679",
    "arxivId": "2411.07679",
    "url": "https://www.semanticscholar.org/paper/4de4fd4090274e1bcf73cfffb0c518619aaa9e8a",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The combination of the Bayesian game and learning has a rich history, with the idea of controlling a single agent in a system composed of multiple agents with unknown behaviors given a set of types, each specifying a possible behavior for the other agents. The idea is to plan an agent's own actions with respect to those types which it believes are most likely to maximize the payoff. However, the type beliefs are often learned from past actions and likely to be incorrect. With this perspective in mind, we consider an agent in a game with type predictions of other components, and investigate the impact of incorrect beliefs to the agent's payoff. In particular, we formally define a tradeoff between risk and opportunity by comparing the payoff obtained against the optimal payoff, which is represented by a gap caused by trusting or distrusting the learned beliefs. Our main results characterize the tradeoff by establishing upper and lower bounds on the Pareto front for both normal-form and stochastic Bayesian games, with numerical results provided.",
    "citationCount": 0,
    "referenceCount": 57
}