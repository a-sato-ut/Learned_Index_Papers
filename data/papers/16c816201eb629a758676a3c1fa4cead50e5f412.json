{
    "paperId": "16c816201eb629a758676a3c1fa4cead50e5f412",
    "title": "When Large Language Models Meet Vector Databases: A Survey",
    "year": 2024,
    "venue": "2025 Conference on Artificial Intelligence x Multimedia (AIxMM)",
    "authors": [
        "Zhi Jing",
        "Yongye Su",
        "Yikun Han",
        "Bo Yuan",
        "Haiyun Xu",
        "Chunjiang Liu",
        "Kehai Chen",
        "Min Zhang"
    ],
    "doi": "10.1109/AIxMM62960.2025.00008",
    "arxivId": "2402.01763",
    "url": "https://www.semanticscholar.org/paper/16c816201eb629a758676a3c1fa4cead50e5f412",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Linguistics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This survey explores the synergistic potential of Large Language Models (LLMs) and Vector Databases (VecDBs), a burgeoning but rapidly evolving research area. With the proliferation of LLMs comes a host of challenges, including hallucinations, outdated knowledge, prohibitive commercial application costs, and memory issues. VecDBs emerge as a compelling solution to these issues by offering an efficient means to store, retrieve, and manage the high-dimensional vector representations intrinsic to LLM operations. Through this nuanced review, we delineate the foundational principles of LLMs and VecDBs and critically analyze their integrationâ€™s impact on enhancing LLM functionalities. This discourse extends into a discussion on the speculative future developments in this domain, aiming to catalyze further research into optimizing the confluence of LLMs and VecDBs for advanced data handling and knowledge extraction capabilities.",
    "citationCount": 59,
    "referenceCount": 110
}