{
    "paperId": "03facddee15e686f0fb1e6acb8db134530add69d",
    "title": "Towards Robust Learning to Optimize with Theoretical Guarantees",
    "year": 2024,
    "venue": "Computer Vision and Pattern Recognition",
    "authors": [
        "Qingyu Song",
        "Wei Lin",
        "Juncheng Wang",
        "Hong Xu"
    ],
    "doi": "10.1109/CVPR52733.2024.02596",
    "arxivId": "2506.14263",
    "url": "https://www.semanticscholar.org/paper/03facddee15e686f0fb1e6acb8db134530add69d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Learning to optimize (L20) is an emerging technique to solve mathematical optimization problems with learning-based methods. Although with great success in many real-world scenarios such as wireless communications, computer networks, and electronic design, existing L2O works lack theoretical demonstration of their performance and robustness in out-of-distribution (OOD) scenarios. We address this gap by providing comprehensive proofs. First, we prove a sufficient condition for a robust L2O model with ho-mogeneous convergence rates over all In-Distribution (InD) instances. We assume an L2O model achieves robustness for an InD scenario. Based on our proposed methodology of aligning OOD problems to InD problems, we also demonstrate that the L2O model's convergence rate in OOD scenarios will deteriorate by an equation of the L2O model's input features. Moreover, we propose an L2O model with a concise gradient-only feature construction and a novel gradient-based history modeling method. Numerical simulation demonstrates that our proposed model outperforms the state-of-the-art baseline in both InD and OOD scenar-ios and achieves up to 10 Ã— convergence speedup. The code of our method can be found from https://github.com/NetX-lab/GoMathL2O-Official.",
    "citationCount": 3,
    "referenceCount": 30
}