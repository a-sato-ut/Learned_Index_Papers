{
    "paperId": "36875fbceeeb2cc2a38afc613eca8d2ebfb2411f",
    "title": "GRAgent: A Generative Retrieval Framework for Action Subspace Selection",
    "year": 2025,
    "venue": "International Conference on Computer Supported Cooperative Work in Design",
    "authors": [
        "Minxuan Lv",
        "Kun Li",
        "Wei Zhou",
        "Songlin Hu"
    ],
    "doi": "10.1109/CSCWD64889.2025.11033280",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/36875fbceeeb2cc2a38afc613eca8d2ebfb2411f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "As Large Language Models (LLMs) are increasingly deployed as autonomous agents to accomplish complex real-world tasks, they must select appropriate actions from massive action spaces. However, in open-domain settings, LLMs often generate hallucinations when selecting from large action spaces due to their lack of practical operation experience. While existing approaches attempt to reduce action spaces through external planning mechanisms, they heavily rely on substantial training data from executable environments. To address this challenge, we propose a generative retrieval-based methodology for identifying necessary action subspaces. Our approach leverages the autoregressive capabilities of pre-trained models, enabling better utilization of knowledge and superior performance in low-data scenarios, while providing interpretable retrieval results through generated action encodings. We design a two-phase training framework that combines self-learning generative retrieval with targeted optimization. Through comprehensive experiments on multiple benchmark datasets, our approach demonstrates superior retrieval performance while effectively reducing model hallucinations and enhancing plan feasibility. Results show that our method consistently outperforms existing approaches across various metrics.",
    "citationCount": 0,
    "referenceCount": 15
}