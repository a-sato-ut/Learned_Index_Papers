{
    "paperId": "41cc56820a02266ee53cead3dc1bf35751345d1f",
    "title": "Optimizing Large Language Models in Radiology and Mitigating Pitfalls: Prompt Engineering and Fine-tuning.",
    "year": 2025,
    "venue": "Radiographics",
    "authors": [
        "T. Kim",
        "Michael Makutonin",
        "Reza Sirous",
        "R. Javan"
    ],
    "doi": "10.1148/rg.240073",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/41cc56820a02266ee53cead3dc1bf35751345d1f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Review",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Medicine",
            "source": "external"
        },
        {
            "category": "Medicine",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Large language models (LLMs) such as generative pretrained transformers (GPTs) have had a major impact on society, and there is increasing interest in using these models for applications in medicine and radiology. This article presents techniques to optimize these models and describes their known challenges and limitations. Specifically, the authors explore how to best craft natural language prompts, a process known as prompt engineering, for these models to elicit more accurate and desirable responses. The authors also explain how fine-tuning is conducted, in which a more general model, such as GPT-4, is further trained on a more specific use case, such as summarizing clinical notes, to further improve reliability and relevance. Despite the enormous potential of these models, substantial challenges limit their widespread implementation. These tools differ substantially from traditional health technology in their complexity and their probabilistic and nondeterministic nature, and these differences lead to issues such as \"hallucinations,\" biases, lack of reliability, and security risks. Therefore, the authors provide radiologists with baseline knowledge of the technology underpinning these models and an understanding of how to use them, in addition to exploring best practices in prompt engineering and fine-tuning. Also discussed are current proof-of-concept use cases of LLMs in the radiology literature, such as in clinical decision support and report generation, and the limitations preventing their current adoption in medicine and radiology. Â©RSNA, 2025 See invited commentary by Chung and Mongan in this issue.",
    "citationCount": 10,
    "referenceCount": 28
}