{
    "paperId": "7538eb144a6dd28f9d8d4bddc915b746225beeca",
    "title": "Lava: Language Driven Scalable and Versatile Traffic Video Analytics",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Yanrui Yu",
        "Tianfei Zhou",
        "Jiaxin Sun",
        "Lianpeng Qiao",
        "Lizhong Ding",
        "Ye Yuan",
        "Guoren Wang"
    ],
    "doi": "10.1145/3746027.3754955",
    "arxivId": "2507.19821",
    "url": "https://www.semanticscholar.org/paper/7538eb144a6dd28f9d8d4bddc915b746225beeca",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In modern urban environments, camera networks generate massive amounts of operational footage -- reaching petabytes each day -- making scalable video analytics essential for efficient processing. Many existing approaches adopt an SQL-based paradigm for querying such large-scale video databases; however, this constrains queries to rigid patterns with predefined semantic categories, significantly limiting analytical flexibility. In this work, we explore a language-driven video analytics paradigm aimed at enabling flexible and efficient querying of high-volume video data driven by natural language. Particularly, we build Lava, a system that accepts natural language queries and retrieves traffic targets across multiple levels of granularity and arbitrary categories. Lava comprises three main components: 1) a multi-armed bandit-based efficient sampling method for video segment-level localization; 2) a video-specific open-world detection module for object-level retrieval; and 3) a long-term object trajectory extraction scheme for temporal object association, yielding complete trajectories for object-of-interests. To support comprehensive evaluation, we further develop a novel benchmark by providing diverse, semantically rich natural language predicates and fine-grained annotations for multiple videos. Experiments on this benchmark demonstrate that Lava improves F1-scores for selection queries by 14% reduces MPAE for aggregation queries by 0.39, and achieves top-k precision of 86% while processing videos 9.6x faster than the most accurate baseline. Our code and dataset are available at https://github.com/yuyanrui/LAVA.",
    "citationCount": 0,
    "referenceCount": 53
}