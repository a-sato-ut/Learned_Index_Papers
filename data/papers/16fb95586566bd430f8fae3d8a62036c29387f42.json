{
    "paperId": "16fb95586566bd430f8fae3d8a62036c29387f42",
    "title": "An All-Digital 8.6-nJ/Frame 65-nm Tsetlin Machine Image Classification Accelerator",
    "year": 2025,
    "venue": "IEEE Transactions on Circuits and Systems Part 1: Regular Papers",
    "authors": [
        "S. Tunheim",
        "Yujin Zheng",
        "Lei Jiao",
        "R. Shafik",
        "Alex Yakovlev",
        "Ole-Christoffer Granmo"
    ],
    "doi": "10.1109/TCSI.2025.3586698",
    "arxivId": "2501.19347",
    "url": "https://www.semanticscholar.org/paper/16fb95586566bd430f8fae3d8a62036c29387f42",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We present an all-digital programmable machine learning accelerator chip for image classification, underpinning on the Tsetlin machine (TM) principles. The TM is an emerging machine learning algorithm founded on propositional logic, utilizing sub-pattern recognition expressions called clauses. The accelerator implements the coalesced TM version with convolution, and classifies booleanized images of 28$\\times$28 pixels with 10 categories. A configuration with 128 clauses is used in a highly parallel architecture. Fast clause evaluation is achieved by keeping all clause weights and Tsetlin automata (TA) action signals in registers. The chip is implemented in a 65 nm low-leakage CMOS technology, and occupies an active area of 2.7 mm$^2$. At a clock frequency of 27.8 MHz, the accelerator achieves 60.3k classifications per second, and consumes 8.6 nJ per classification. This demonstrates the energy-efficiency of the TM, which was the main motivation for developing this chip. The latency for classifying a single image is 25.4 $\\mu$s which includes system timing overhead. The accelerator achieves 97.42%, 84.54% and 82.55% test accuracies for the datasets MNIST, Fashion-MNIST and Kuzushiji-MNIST, respectively, matching the TM software models.",
    "citationCount": 1,
    "referenceCount": 50
}