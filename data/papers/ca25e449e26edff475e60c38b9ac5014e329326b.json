{
    "paperId": "ca25e449e26edff475e60c38b9ac5014e329326b",
    "title": "Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning",
    "year": 2020,
    "venue": "AIDB@VLDB",
    "authors": [
        "Chi Zhang",
        "Ryan Marcus",
        "Anat Kleiman",
        "Olga Papaemmanouil"
    ],
    "doi": null,
    "arxivId": "2007.10568",
    "url": "https://www.semanticscholar.org/paper/ca25e449e26edff475e60c38b9ac5014e329326b",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In this extended abstract, we propose a new technique for query scheduling with the explicit goal of reducing disk reads and thus implicitly increasing query performance. We introduce \\system, a learned scheduler that leverages overlapping data reads among incoming queries and learns a scheduling strategy that improves cache hits. \\system relies on deep reinforcement learning to produce workload-specific scheduling strategies that focus on long-term performance benefits while being adaptive to previously-unseen data access patterns. We present results from a proof-of-concept prototype, demonstrating that learned schedulers can offer significant performance improvements over hand-crafted scheduling heuristics. Ultimately, we make the case that this is a promising research direction in the intersection of machine learning and databases.",
    "citationCount": 18,
    "referenceCount": 45
}