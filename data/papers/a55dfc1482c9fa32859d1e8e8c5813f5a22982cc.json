{
    "paperId": "a55dfc1482c9fa32859d1e8e8c5813f5a22982cc",
    "title": "OpenICL: An Open-Source Framework for In-context Learning",
    "year": 2023,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "authors": [
        "Zhenyu Wu",
        "Yaoxiang Wang",
        "Jiacheng Ye",
        "Jiangtao Feng",
        "Jingjing Xu",
        "Yu Qiao",
        "Zhiyong Wu"
    ],
    "doi": "10.48550/arXiv.2303.02913",
    "arxivId": "2303.02913",
    "url": "https://www.semanticscholar.org/paper/a55dfc1482c9fa32859d1e8e8c5813f5a22982cc",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2303.02913",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In recent years, In-context Learning (ICL) has gained increasing attentionand emerged as the new paradigm for large language model (LLM) evaluation. Unlike traditional fine-tuning methods, ICL instead adapts the pre-trained models to unseen tasks without any parameter updates.However, the implementation of ICL is sophisticated due to the diverse retrieval and inference methods involved, as well as the varying pre-processing requirements for different models, datasets, and tasks. A unified and flexible framework for ICL is urgently needed to ease the implementation of the aforementioned components.To facilitate ICL research, we introduce OpenICL, an open-source toolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highly flexible architecture that users can easily combine different components to suit their needs.It also provides various state-of-the-art retrieval and inference methods to streamline the process of adapting ICL to cutting-edge research.The effectiveness of OpenICL has been validated on a wide range of NLP tasks, including classification, QA, machine translation, and semantic parsing. As a side-product, we found OpenICL to be an efficient yet robust tool for LLMs evaluation. OpenICL is released at https://github.com/Shark-NLP/OpenICL.",
    "citationCount": 57,
    "referenceCount": 58
}