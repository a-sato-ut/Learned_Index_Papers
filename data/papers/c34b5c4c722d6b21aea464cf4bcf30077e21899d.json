{
    "paperId": "c34b5c4c722d6b21aea464cf4bcf30077e21899d",
    "title": "Does Generative Retrieval Overcome the Limitations of Dense Retrieval?",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Yingchen Zhang",
        "Ruqing Zhang",
        "Jiafeng Guo",
        "M. D. Rijke",
        "Yixing Fan",
        "Xueqi Cheng"
    ],
    "doi": "10.48550/arXiv.2509.22116",
    "arxivId": "2509.22116",
    "url": "https://www.semanticscholar.org/paper/c34b5c4c722d6b21aea464cf4bcf30077e21899d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Generative retrieval (GR) has emerged as a new paradigm in neural information retrieval, offering an alternative to dense retrieval (DR) by directly generating identifiers of relevant documents. In this paper, we theoretically and empirically investigate how GR fundamentally diverges from DR in both learning objectives and representational capacity. GR performs globally normalized maximum-likelihood optimization and encodes corpus and relevance information directly in the model parameters, whereas DR adopts locally normalized objectives and represents the corpus with external embeddings before computing similarity via a bilinear interaction. Our analysis suggests that, under scaling, GR can overcome the inherent limitations of DR, yielding two major benefits. First, with larger corpora, GR avoids the sharp performance degradation caused by the optimization drift induced by DR's local normalization. Second, with larger models, GR's representational capacity scales with parameter size, unconstrained by the global low-rank structure that limits DR. We validate these theoretical insights through controlled experiments on the Natural Questions and MS MARCO datasets, across varying negative sampling strategies, embedding dimensions, and model scales. But despite its theoretical advantages, GR does not universally outperform DR in practice. We outline directions to bridge the gap between GR's theoretical potential and practical performance, providing guidance for future research in scalable and robust generative retrieval.",
    "citationCount": 0,
    "referenceCount": 42
}