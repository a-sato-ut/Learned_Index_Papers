{
    "paperId": "77f733475cb309a553083d7ef7f6557fdd201d0c",
    "title": "A First-order Generative Bilevel Optimization Framework for Diffusion Models",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Quan Xiao",
        "Hui Yuan",
        "A. Saif",
        "Gaowen Liu",
        "R. Kompella",
        "Mengdi Wang",
        "Tianyi Chen"
    ],
    "doi": "10.48550/arXiv.2502.08808",
    "arxivId": "2502.08808",
    "url": "https://www.semanticscholar.org/paper/77f733475cb309a553083d7ef7f6557fdd201d0c",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Diffusion models, which iteratively denoise data samples to synthesize high-quality outputs, have achieved empirical success across domains. However, optimizing these models for downstream tasks often involves nested bilevel structures, such as tuning hyperparameters for fine-tuning tasks or noise schedules in training dynamics, where traditional bilevel methods fail due to the infinite-dimensional probability space and prohibitive sampling costs. We formalize this challenge as a generative bilevel optimization problem and address two key scenarios: (1) fine-tuning pre-trained models via an inference-only lower-level solver paired with a sample-efficient gradient estimator for the upper level, and (2) training diffusion model from scratch with noise schedule optimization by reparameterizing the lower-level problem and designing a computationally tractable gradient estimator. Our first-order bilevel framework overcomes the incompatibility of conventional bilevel methods with diffusion processes, offering theoretical grounding and computational practicality. Experiments demonstrate that our method outperforms existing fine-tuning and hyperparameter search baselines.",
    "citationCount": 2,
    "referenceCount": 84
}