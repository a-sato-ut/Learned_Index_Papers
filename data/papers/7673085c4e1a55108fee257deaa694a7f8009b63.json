{
    "paperId": "7673085c4e1a55108fee257deaa694a7f8009b63",
    "title": "Containerized In-Storage Processing and Computing-Enabled SSD Disaggregation",
    "year": 2025,
    "venue": "IEEE Micro",
    "authors": [
        "Miryeong Kwon",
        "Donghyun Gouk",
        "Eunjee Na",
        "Jiseon Kim",
        "Junhee Kim",
        "Hyein Woo",
        "Eojin Ryu",
        "Hyunkyu Choi",
        "Jinwoo Baek",
        "Hanyeoreum Bae",
        "Mahmut Kandemir",
        "Myoungsoo Jung"
    ],
    "doi": "10.1109/mm.2025.3574261",
    "arxivId": "2506.06769",
    "url": "https://www.semanticscholar.org/paper/7673085c4e1a55108fee257deaa694a7f8009b63",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "ISP minimizes data transfer for analytics but faces challenges in adaptation and disaggregation. We propose DockerSSD, an ISP model leveraging OS-level virtualization and lightweight firmware to enable containerized data processing directly on SSDs. Key features include Ethernet over NVMe for network-based ISP management and Virtual Firmware for secure, efficient container execution. DockerSSD supports disaggregated storage pools, reducing host overhead and enhancing large-scale services like LLM inference. It achieves up to 2.0x better performance for I/O-intensive workloads, and 7.9x improvement in distributed LLM inference.",
    "citationCount": 0,
    "referenceCount": 45
}