{
    "paperId": "6f0548d04b6029f048dd048c3311eefa0f238fa2",
    "title": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Yuzhe Yang",
        "Yipeng Du",
        "Ahmad Farhan",
        "Claudio Angione",
        "Yue Zhao",
        "Harry Yang",
        "Fielding Johnston",
        "James P. Buban",
        "Patrick Colangelo"
    ],
    "doi": "10.48550/arXiv.2410.21340",
    "arxivId": "2410.21340",
    "url": "https://www.semanticscholar.org/paper/6f0548d04b6029f048dd048c3311eefa0f238fa2",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The deployment of large-scale models, such as large language models (LLMs) and sophisticated image generation systems, incurs substantial costs due to their computational demands. To mitigate these costs and address challenges related to scalability and data security, there is a growing shift towards decentralized systems for deploying such models. In these decentralized environments, efficient inference acceleration becomes crucial to manage computational resources effectively and enhance system responsiveness. In this work, we address the challenge of selecting optimal acceleration methods in decentralized systems by introducing a meta-learning-based framework. This framework automates the selection process by learning from historical performance data of various acceleration techniques across different tasks. Unlike traditional methods that rely on random selection or expert intuition, our approach systematically identifies the best acceleration strategies based on the specific characteristics of each task. We demonstrate that our meta-learning framework not only streamlines the decision-making process but also consistently outperforms conventional methods in terms of efficiency and performance. Our results highlight the potential of meta-learning to revolutionize inference acceleration in decentralized AI systems, offering a path towards more democratic and economically feasible artificial intelligence solutions.",
    "citationCount": 0,
    "referenceCount": 52
}