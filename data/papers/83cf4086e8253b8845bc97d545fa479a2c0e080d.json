{
    "paperId": "83cf4086e8253b8845bc97d545fa479a2c0e080d",
    "title": "LLMulator: Generalizable Cost Modeling for Dataflow Accelerators with Input-Adaptive Control Flow",
    "year": 2025,
    "venue": "Proceedings of the 2025 58th IEEE/ACM International Symposium on Microarchitecture",
    "authors": [
        "Kaiyan Chang",
        "Wenlong Zhu",
        "Shengwen Liang",
        "Huawei Li",
        "Ying Wang"
    ],
    "doi": "10.1145/3725843.3756027",
    "arxivId": "2508.17826",
    "url": "https://www.semanticscholar.org/paper/83cf4086e8253b8845bc97d545fa479a2c0e080d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Precise and rapid performance prediction for dataflow-based accelerators is essential for efficient hardware design and design space exploration. However, existing methods often fall short due to limited generalization across hardware architectures, applications, and input-dependent control flows. Considering the rich program semantic knowledge contained in pre-trained large language models (LLMs), which is used for text and code generation, we propose a progressive numeric modeling paradigm based on pre-trained LLMs. This is an approach to achieve hardware, application, and control flow-sensitive generalization in dataflow accelerator performance prediction. Specifically, to make accurate performance estimates for unseen applications beyond the scope of the training data, we propose a numeric prediction model capable of estimating any performance range. This is achieved by treating the numerical data of the dataflow program as separate tokens and using categorical output for performance values, allowing us to observe confidence at each numerical position. Second, LLMulator supports input-adaptive performance prediction by introducing a reinforcement learning-based dynamic calibration framework, enabling accurate modeling of applications whose control flow varies with inputâ€”unlike prior methods that assume fixed execution paths. The cycles prediction error converges to within 11.2% after several iterations, reducing the error by 9.7% over static models. Finally, to generalize across diverse hardware architectures and configurations, we introduce a progressive data augmentation framework that systematically generates rich datasets spanning software and hardware variations. This includes multi-level dataflow structures and a structured representation of memory parameters and loop mapping primitives, significantly improving the performance of LLMulator for diverse hardware configurations. Experiments show that LLMulator achieves an average absolute percentage error (MAPE) of 12.2% in ASIC design scenarios, reducing errors by 16.7%-7.8% compared to existing SOTA methods (TLP, GNNHLS). These results establish LLMulator as a highly accurate and interpretable framework for performance prediction, showcasing new opportunities for applying pre-trained LLMs to hardware modeling.",
    "citationCount": 0,
    "referenceCount": 98
}