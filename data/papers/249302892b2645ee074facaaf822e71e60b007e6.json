{
    "paperId": "249302892b2645ee074facaaf822e71e60b007e6",
    "title": "Slipstream: Semantic-Based Training Acceleration for Recommendation Models",
    "year": 2025,
    "venue": "Design, Automation and Test in Europe",
    "authors": [
        "Yassaman Ebrahimzadeh Maboud",
        "Muhammad Adnan",
        "Divyat Mahajan",
        "Prashant J. Nair"
    ],
    "doi": "10.23919/DATE64628.2025.10992746",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/249302892b2645ee074facaaf822e71e60b007e6",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recommendation models play a crucial role in delivering accurate and tailored user experiences. However, training such models poses significant challenges regarding resource utilization and performance. Prior research has proposed an approach that categorizes embeddings into popular and non-popular classes to reduce the training time for recommendation models. We observe that, even among the popular embeddings, certain embeddings undergo rapid training and exhibit minimal subsequent variation, resulting in saturation. Consequently, updates to these embeddings become redundant. This paper presents Slipstream, a software framework that identifies stale embeddings on the fly and skips their updates to enhance performance. Our experiments demonstrate Slipstream's ability to maintain accuracy while effectively discarding updates to non-varying embeddings. This capability enables Slipstream to achieve substantial speedup, optimize CPU-GPU bandwidth usage, and eliminate unnecessary memory access. SlipStream showcases training time reductions of 2 x, 2.4 x, 1.2 x, and 1.175 x across real-world datasets and configurations, compared to Baseline XDL, Intel-optimized DRLM, FAE, and Hotline, respectively.",
    "citationCount": 0,
    "referenceCount": 32
}