{
    "paperId": "0db1bb71fe91ca7dda1129dc0702735dda8951e6",
    "title": "Accelerating Learned Sparse Indexes Via Term Impact Decomposition",
    "year": 2022,
    "venue": "Conference on Empirical Methods in Natural Language Processing",
    "authors": [
        "J. Mackenzie",
        "Alistair Moffat"
    ],
    "doi": "10.18653/v1/2022.findings-emnlp.205",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/0db1bb71fe91ca7dda1129dc0702735dda8951e6",
    "isOpenAccess": true,
    "openAccessPdf": "https://aclanthology.org/2022.findings-emnlp.205.pdf",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Novel inverted index-based learned sparse ranking models provide more effective, but less efﬁcient, retrieval performance compared to traditional ranking models like BM25. In this paper, we introduce a technique we call postings clipping to improve the query efﬁciency of learned representations. Our technique ampliﬁes the beneﬁt of dynamic pruning query processing techniques by accounting for changes in term importance distributions of learned ranking models. The new clipping mechanism accelerates top- k retrieval by up to 9 . 6 × without any loss in effectiveness.",
    "citationCount": 22,
    "referenceCount": 65
}