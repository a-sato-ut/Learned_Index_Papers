{
    "paperId": "e2ffa8496f3772e527ca34cf6cbaba62b5d7f490",
    "title": "MAGIS: Memory Optimization via Coordinated Graph Transformation and Scheduling for DNN",
    "year": 2024,
    "venue": "International Conference on Architectural Support for Programming Languages and Operating Systems",
    "authors": [
        "Renze Chen",
        "Zijian Ding",
        "Size Zheng",
        "Chengrui Zhang",
        "Jingwen Leng",
        "Xuanzhe Liu",
        "Yun Liang"
    ],
    "doi": "10.1145/3620666.3651330",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/e2ffa8496f3772e527ca34cf6cbaba62b5d7f490",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recently, memory consumption of Deep Neural Network (DNN) rapidly increases, mainly due to long lifetimes and large shapes of tensors. Graph scheduling has emerged as an effective memory optimization technique, which determines the optimal execution, re-computation, swap-out, and swap-in timings for each operator/tensor. However, it often hurts performance significantly and can only manipulate tensors' lifetimes but not shapes, limiting the optimization space. We find that graph transformation, which can change the tensor shapes and graph structure, creates a new trade-off space between memory and performance. Nevertheless, graph transformation are applied separately so far, with primary focus on optimizing performance and not memory. In this paper, we propose MAGIS, a DNN memory optimization framework that coordinates graph transformation with graph scheduling. MAGIS uses a hierarchical tree to represent Fission Transformation (F-Trans), a type of transformation which can effectively reduce tensor shapes in a sub-graph. To keep the complexity low, we build a light-weight search space based on graph structure analysis. MAGIS decomposes graph scheduling into graph transformation and re-ordering and designs an incremental scheduling algorithm to alleviate the scheduling overhead after each graph transformation step to efficiently coordinate them. Experimental results show that compared to state-of-the-art works, MAGIS only uses 15%~85% of their peak memory usage with the same latency1 constraint and obtains a better Pareto boundary in dual-objective optimization of memory and performance. Our code is now available at https://github.com/pku-liang/MAGIS.",
    "citationCount": 9,
    "referenceCount": 76
}