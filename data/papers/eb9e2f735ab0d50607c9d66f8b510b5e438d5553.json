{
    "paperId": "eb9e2f735ab0d50607c9d66f8b510b5e438d5553",
    "title": "Effect of Fine-tuning Transfer Learning Layers: A Case Study of Breast Cancer Classification",
    "year": 2025,
    "venue": "FUOYE Journal of Engineering and Technology",
    "authors": [
        "T. Adepoju",
        "M. Oladele",
        "M. O. Akintunde",
        "Afolake M. Ogunleye"
    ],
    "doi": "10.4314/fuoyejet.v9i4.15",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/eb9e2f735ab0d50607c9d66f8b510b5e438d5553",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Medicine",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Breast cancer is one of the leading causes of cancer-related mortality, specifically among women worldwide, necessitating the development of practical diagnostic tools. Much research has explored breast cancer classification using transfer learning approaches. However, despite notable success, a need remains to understand how fine-tuning different layers affects model performance, especially in tasks requiring high precision, such as breast cancer classification. This research investigates the optimization of fine-tuning strategies for transfer learning techniques, specifically the InceptionV3 and Xception architecture, to observe the effect of fine-tuning transfer learning layers in classifying breast cancer from mammographic images. The study used the CBIS-DDSM dataset and a comprehensive preprocessing pipeline that included image normalization, resizing, and data augmentation to prepare the dataset for model training. A systematic layer unfreezing strategy was implemented, allowing varying degrees of fine-tuning, from no fine-tuning to full fine-tuning of the model. The results reveal that InceptionV3 outperforms Xception, achieving a 0.65 accuracy without fine-tuning, compared to 0.64 for Xception. Performance improves with fine-tuning with the maximum value of 0.66 when fine-tuning the last two blocks of InceptionV3 and the last three blocks of Xception. However, full fine-tuning results in significant performance degradation, with InceptionV3 achieving a value of 0.61 and Xception 0.51 for accuracy. These findings emphasize the importance of selecting the right fine-tuning strategy to avoid overfitting and ensure the robustness of models for medical applications. Additional metrics, including precision, recall, and F1-score, also reflect similar trends, underscoring the critical role of fine-tuning in tailoring pre-trained models to specific tasks in medical imaging. This research contributes valuable insights into optimizing transfer learning approaches in breast cancer diagnosis, highlighting the potential for improved clinical decision-making through advanced machine-learning techniques.",
    "citationCount": 1,
    "referenceCount": 18
}