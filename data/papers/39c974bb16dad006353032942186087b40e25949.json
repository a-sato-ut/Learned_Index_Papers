{
    "paperId": "39c974bb16dad006353032942186087b40e25949",
    "title": "Synergistic Interplay between Search and Large Language Models for Information Retrieval",
    "year": 2023,
    "venue": "Annual Meeting of the Association for Computational Linguistics",
    "authors": [
        "Jiazhan Feng",
        "Chongyang Tao",
        "Xiubo Geng",
        "Tao Shen",
        "Can Xu",
        "Guodong Long",
        "Dongyan Zhao",
        "Daxin Jiang"
    ],
    "doi": "10.18653/v1/2024.acl-long.517",
    "arxivId": "2305.07402",
    "url": "https://www.semanticscholar.org/paper/39c974bb16dad006353032942186087b40e25949",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2305.07402",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Information retrieval (IR) plays a crucial role in locating relevant resources from vast amounts of data, and its applications have evolved from traditional knowledge bases to modern retrieval models (RMs). The emergence of large language models (LLMs) has further revolutionized the IR field by enabling users to interact with search systems in natural languages. In this paper, we explore the advantages and disadvantages of LLMs and RMs, highlighting their respective strengths in understanding user-issued queries and retrieving up-to-date information. To leverage the benefits of both paradigms while circumventing their limitations, we propose InteR, a novel framework that facilitates information refinement through synergy between RMs and LLMs. InteR allows RMs to expand knowledge in queries using LLM-generated knowledge collections and enables LLMs to enhance prompt formulation using retrieved documents. This iterative refinement process augments the inputs of RMs and LLMs, leading to more accurate retrieval. Experiments on large-scale retrieval benchmarks involving web search and low-resource retrieval tasks demonstrate that InteR achieves overall superior zero-shot retrieval performance compared to state-of-the-art methods, even those using relevance judgment. Source code is available at https://github.com/Cyril-JZ/InteR",
    "citationCount": 14,
    "referenceCount": 85
}