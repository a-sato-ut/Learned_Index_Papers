{
    "paperId": "57b2ac7cdb3c517a1e0eaaac6f24374ab43dfb55",
    "title": "ISA mapper: a compute and hardware agnostic deep learning compiler",
    "year": 2018,
    "venue": "ACM International Conference on Computing Frontiers",
    "authors": [
        "Matthew Sotoudeh",
        "Anand Venkat",
        "Michael J. Anderson",
        "E. Georganas",
        "A. Heinecke",
        "Jason Knight"
    ],
    "doi": "10.1145/3310273.3321559",
    "arxivId": "1810.09958",
    "url": "https://www.semanticscholar.org/paper/57b2ac7cdb3c517a1e0eaaac6f24374ab43dfb55",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3310273.3321559",
    "publicationTypes": [
        "JournalArticle",
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Domain specific accelerators present new challenges for code generation onto novel instruction sets, communication fabrics, and memory architectures. We introduce a shared intermediate representation to describe both deep learning programs and hardware capabilities, then formulate and apply instruction mapping to determine how a computation can be performed on a hardware system. Our scheduler chooses a specific mapping and determines data movement and computation order. With this system, we demonstrate automated extraction of matrix multiplication kernels from recent deep learning operations. We demonstrate 2--5X better performance on GEMM and GRU execution versus state-of-the-art on new hardware and up to 85% of state-of-the-art performance on existing hardware.",
    "citationCount": 9,
    "referenceCount": 18
}