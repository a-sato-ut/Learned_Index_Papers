{
    "paperId": "28f4d454359641f62944674ea085e84aff5ce023",
    "title": "Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting",
    "year": 2022,
    "venue": "AAAI Conference on Artificial Intelligence",
    "authors": [
        "Zixuan Ye",
        "Yutong Dai",
        "Chaoyi Hong",
        "Zhiguo Cao",
        "Hao Lu"
    ],
    "doi": "10.48550/arXiv.2212.13517",
    "arxivId": "2212.13517",
    "url": "https://www.semanticscholar.org/paper/28f4d454359641f62944674ea085e84aff5ce023",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2212.13517",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We study the composition style in deep image matting, a notion that characterizes a data generation flow on how to exploit limited foregrounds and random backgrounds to form a training dataset. Prior art executes this flow in a completely random manner by simply going through the foreground pool or by optionally combining two foregrounds before foreground-background composition. In this work, we first show that naive foreground combination can be problematic and therefore derive an alternative formulation to reasonably combine foregrounds. Our second contribution is an observation that matting performance can benefit from a certain occurrence frequency of combined foregrounds and their associated source foregrounds during training. Inspired by this, we introduce a novel composition style that binds the source and combined foregrounds in a definite triplet. In addition, we also find that different orders of foreground combination lead to different foreground patterns, which further inspires a quadruplet-based composition style. Results under controlled experiments on four matting baselines show that our composition styles outperform existing ones and invite consistent performance improvement on both composited and real-world datasets. Code is available at: https://github.com/coconuthust/composition_styles",
    "citationCount": 2,
    "referenceCount": 21
}