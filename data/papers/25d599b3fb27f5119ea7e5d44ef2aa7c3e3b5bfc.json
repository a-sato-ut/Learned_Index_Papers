{
    "paperId": "25d599b3fb27f5119ea7e5d44ef2aa7c3e3b5bfc",
    "title": "MLGO: a Machine Learning Guided Compiler Optimizations Framework",
    "year": 2021,
    "venue": "arXiv.org",
    "authors": [
        "Mircea Trofin",
        "Yundi Qian",
        "E. Brevdo",
        "Zinan Lin",
        "K. Choromanski",
        "D. Li"
    ],
    "doi": null,
    "arxivId": "2101.04808",
    "url": "https://www.semanticscholar.org/paper/25d599b3fb27f5119ea7e5d44ef2aa7c3e3b5bfc",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Leveraging machine-learning (ML) techniques for compiler optimizations has been widely studied and explored in academia. However, the adoption of ML in general-purpose, industry strength compilers has yet to happen. We propose MLGO, a framework for integrating ML techniques systematically in an industrial compiler -- LLVM. As a case study, we present the details and results of replacing the heuristics-based inlining-for-size optimization in LLVM with machine learned models. To the best of our knowledge, this work is the first full integration of ML in a complex compiler pass in a real-world setting. It is available in the main LLVM repository. We use two different ML algorithms: Policy Gradient and Evolution Strategies, to train the inlining-for-size model, and achieve up to 7\\% size reduction, when compared to state of the art LLVM -Oz. The same model, trained on one corpus, generalizes well to a diversity of real-world targets, as well as to the same set of targets after months of active development. This property of the trained models is beneficial to deploy ML techniques in real-world settings.",
    "citationCount": 72,
    "referenceCount": 33
}