{
    "paperId": "5bf7813028e533989dba3ba59d61f0e14fc0a8de",
    "title": "MITFAS: Mutual Information based Temporal Feature Alignment and Sampling for Aerial Video Action Recognition",
    "year": 2023,
    "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision",
    "authors": [
        "Ruiqi Xian",
        "Xijun Wang",
        "Dinesh Manocha"
    ],
    "doi": "10.1109/WACV57701.2024.00649",
    "arxivId": "2303.02575",
    "url": "https://www.semanticscholar.org/paper/5bf7813028e533989dba3ba59d61f0e14fc0a8de",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2303.02575",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We present a novel approach for action recognition in UAV videos. Our formulation is designed to handle occlusion and viewpoint changes caused by the movement of a UAV. We use the concept of mutual information to compute and align the regions corresponding to human action or motion in the temporal domain. This enables our recognition model to learn from the key features associated with the motion. We also propose a novel frame sampling method that uses joint mutual information to acquire the most informative frame sequence in UAV videos. We have integrated our approach with X3D and evaluated the performance on multiple datasets. In practice, we achieve 18.9% improvement in Top-1 accuracy over current state-of-the-art methods on UAV-Human [30], 7.3% improvement on Drone-Action [41], and 7.16% improvement on NEC Drones [7]. The code is available at https://github.com/Ricky-Xian/MITFAS",
    "citationCount": 11,
    "referenceCount": 60
}