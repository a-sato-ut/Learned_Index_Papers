{
    "paperId": "cef80880d7e2a0553f858e8f3a2fb6960b77d5ff",
    "title": "Scalable Exploration for Neural Online Learning to Rank with Perturbed Feedback",
    "year": 2022,
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "authors": [
        "Yiling Jia",
        "Hongning Wang"
    ],
    "doi": "10.1145/3477495.3532057",
    "arxivId": "2206.05954",
    "url": "https://www.semanticscholar.org/paper/cef80880d7e2a0553f858e8f3a2fb6960b77d5ff",
    "isOpenAccess": true,
    "openAccessPdf": "https://dl.acm.org/doi/pdf/10.1145/3477495.3532057",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Deep neural networks (DNNs) demonstrates significant advantages in improving ranking performance in retrieval tasks. Driven by the recent developments in optimization and generalization of DNNs, learning a neural ranking model online from its interactions with users becomes possible. However, the required exploration for model learning has to be performed in the entire neural network parameter space, which is prohibitively expensive and limits the application of such online solutions in practice. In this work, we propose an efficient exploration strategy for online interactive neural ranker learning based on bootstrapping. Our solution is based on an ensemble of ranking models trained with perturbed user click feedback. The proposed method eliminates explicit confidence set construction and the associated computational overhead, which enables the online neural rankers training to be efficiently executed in practice with theoretical guarantees. Extensive comparisons with an array of state-of-the-art OL2R algorithms on two public learning to rank benchmark datasets demonstrate the effectiveness and computational efficiency of our proposed neural OL2R solution.",
    "citationCount": 0,
    "referenceCount": 60
}