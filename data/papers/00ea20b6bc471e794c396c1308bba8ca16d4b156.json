{
    "paperId": "00ea20b6bc471e794c396c1308bba8ca16d4b156",
    "title": "FairGap: Fairness-Aware Recommendation via Generating Counterfactual Graph",
    "year": 2023,
    "venue": "ACM Trans. Inf. Syst.",
    "authors": [
        "Wei Chen",
        "Yiqing Wu",
        "Zhao Zhang",
        "Fuzhen Zhuang",
        "Zhongshi He",
        "Ruobing Xie",
        "Feng Xia"
    ],
    "doi": "10.1145/3638352",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/00ea20b6bc471e794c396c1308bba8ca16d4b156",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The emergence of Graph Neural Networks (GNNs) has greatly advanced the development of recommendation systems. Recently, many researchers have leveraged GNN-based models to learn fair representations for users and items. However, current GNN-based models suffer from biased user–item interaction data, which negatively impacts recommendation fairness. Although there have been several studies employing adversarial learning to mitigate this issue in recommendation systems, they mostly focus on modifying the model training approach with fairness regularization and neglect direct intervention of biased interaction. In contrast to these models, this article introduces a novel perspective by directly intervening in observed interactions to generate a counterfactual graph (called FairGap) that is not influenced by sensitive node attributes, enabling us to learn fair representations for users and items easily. We design FairGap to answer the key counterfactual question: “Would interactions with an item remain unchanged if a user’s sensitive attributes were concealed?”. We also provide theoretical proofs to show that our learning strategy via the counterfactual graph is unbiased in expectation. Moreover, we propose a fairness-enhancing mechanism to continuously improve user fairness in the graph-based recommendation. Extensive experimental results against state-of-the-art competitors and base models on three real-world datasets validate the effectiveness of our proposed model.",
    "citationCount": 22,
    "referenceCount": 82
}