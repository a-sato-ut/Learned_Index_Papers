{
    "paperId": "97c6529767968e63e68e8bc39ababf1a69f0e9e5",
    "title": "Large Language Model-based Recommendation System Agents",
    "year": 2025,
    "venue": "ACM Conference on Recommender Systems",
    "authors": [
        "Tommaso Carraro",
        "Brijraj Singh",
        "N. Pedanekar"
    ],
    "doi": "10.1145/3705328.3759334",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/97c6529767968e63e68e8bc39ababf1a69f0e9e5",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "A Large Language Model-based agent is an AI assistant that makes use of advanced Tool Calling (TC) and Retrieval Augmented Generation (RAG) techniques to access external tools (e.g., Python code, databases). This allows the agent to consult additional sources of information that are complementary to its pre-trained knowledge. By doing so, re-training or fine-tuning of the LLM each time new knowledge becomes available can be avoided, as the assistant can access this information thanks to the available tools. In this demo, we investigate this idea in the Recommendation Systems (RSs) scenario. In particular, we design an AI assistant for recommendation that can access (i) a pre-trained recommender system, (ii) a database, and (iii) a vector store. The demo shows how the assistant is able to interact with these tools to reply to complex recommendation and explanation queries that require reasoning on the toolâ€™s results. To the best of our knowledge, this is the first attempt at designing LLM-based recommendation system agents. The code for this demo paper is available at this URL1.",
    "citationCount": 0,
    "referenceCount": 22
}