{
    "paperId": "4daecbf5af5dc2511abc31eecbfc2d8adb54db10",
    "title": "AutoToken",
    "year": 2020,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Rathijit Sen",
        "Alekh Jindal",
        "Hiren Patel",
        "S. Qiao"
    ],
    "doi": "10.14778/3415478.3415554",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/4daecbf5af5dc2511abc31eecbfc2d8adb54db10",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Right-sizing resource allocation for big-data queries, particularly in serverless environments, is critical for improving infrastructure operational efficiency, capacity availability, query performance predictability, and for reducing unnecessary wait times. In this paper, we present AutoToken --- a simple and effective predictor for estimating the peak resource usage of recurring big data queries. It uses multiple query plan identifiers to identify recurring query templates and to learn models with the goal of reducing over-allocation in future instances of those queries. AutoToken is computationally light, for both training and scoring, is easily deployable at scale, and is integrated with the Peregrine workload optimization infrastructure at Microsoft. We extensively evaluate AutoToken on SCOPE jobs from our production clusters and show that it outperforms state-of-the-art solutions for peak resource estimation. We also discuss our plans towards supporting repeatable and extensible research on resource prediction for SCOPE jobs, including describing a simulation methodology for generating arbitrary-sized datasets with similar characteristics as the production datasets.",
    "citationCount": 15,
    "referenceCount": 42
}