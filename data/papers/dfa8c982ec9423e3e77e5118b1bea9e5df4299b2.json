{
    "paperId": "dfa8c982ec9423e3e77e5118b1bea9e5df4299b2",
    "title": "Solving Quadratic Programs via Deep Unrolled Douglas-Rachford Splitting",
    "year": 2025,
    "venue": "Trans. Mach. Learn. Res.",
    "authors": [
        "Jinxin Xiong",
        "Xi Gao",
        "Linxin Yang",
        "Jiang Xue",
        "Xiaodong Luo",
        "Akang Wang"
    ],
    "doi": null,
    "arxivId": "2508.11869",
    "url": "https://www.semanticscholar.org/paper/dfa8c982ec9423e3e77e5118b1bea9e5df4299b2",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Convex quadratic programs (QPs) are fundamental to numerous applications, including finance, engineering, and energy systems. Among the various methods for solving them, the Douglas-Rachford (DR) splitting algorithm is notable for its robust convergence properties. Concurrently, the emerging field of Learning-to-Optimize offers promising avenues for enhancing algorithmic performance, with algorithm unrolling receiving considerable attention due to its computational efficiency and interpretability. In this work, we propose an approach that unrolls a modified DR splitting algorithm to efficiently learn solutions for convex QPs. Specifically, we introduce a tailored DR splitting algorithm that replaces the computationally expensive linear system-solving step with a simplified gradient-based update, while retaining convergence guarantees. Consequently, we unroll the resulting DR splitting method and present a well-crafted neural network architecture to predict QP solutions. Our method achieves up to 50% reductions in iteration counts and 40% in solve time across benchmarks on both synthetic and real-world QP datasets, demonstrating its scalability and superior performance in enhancing computational efficiency across varying sizes.",
    "citationCount": 0,
    "referenceCount": 47
}