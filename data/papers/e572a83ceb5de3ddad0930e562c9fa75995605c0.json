{
    "paperId": "e572a83ceb5de3ddad0930e562c9fa75995605c0",
    "title": "Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation",
    "year": 2023,
    "venue": "Annual International ACM SIGIR Conference on Research and Development in Information Retrieval",
    "authors": [
        "Yang Zhang",
        "Tianhao Shi",
        "Fuli Feng",
        "Wenjie Wang",
        "Dingxian Wang",
        "Xiangnan He",
        "Yongdong Zhang"
    ],
    "doi": "10.1145/3539618.3591755",
    "arxivId": "2304.13643",
    "url": "https://www.semanticscholar.org/paper/e572a83ceb5de3ddad0930e562c9fa75995605c0",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2304.13643",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Click-Through Rate (CTR) prediction plays a core role in recommender systems, serving as the final-stage filter to rank items for a user. The key to addressing the CTR task is learning feature interactions that are useful for prediction, which is typically achieved by fitting historical click data with the Empirical Risk Minimization (ERM) paradigm. Representative methods include Factorization Machines and Deep Interest Network, which have achieved wide success in industrial applications. However, such a manner inevitably learns unstable feature interactions, i.e., the ones that exhibit strong correlations in historical data but generalize poorly for future serving. In this work, we reformulate the CTR task --- instead of pursuing ERM on historical data, we split the historical data chronologically into several periods (a.k.a, environments), aiming to learn feature interactions that are stable across periods. Such feature interactions are supposed to generalize better to predict future behavior data. Nevertheless, a technical challenge is that existing invariant learning solutions like Invariant Risk Minimization are not applicable, since the click data entangles both environment-invariant and environment-specific correlations. To address this dilemma, we propose Disentangled Invariant Learning (DIL) which disentangles feature embeddings to capture the two types of correlations separately. To improve the modeling efficiency, we further design LightDIL which performs the disentanglement at the higher level of the feature field. Extensive experiments demonstrate the effectiveness of DIL in learning stable feature interactions for CTR.",
    "citationCount": 16,
    "referenceCount": 48
}