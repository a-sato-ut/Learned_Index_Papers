{
    "paperId": "8ddb165278176f279ace760a8c14f5e0fcb652b0",
    "title": "GPTuner: A Manual-Reading Database Tuning System via GPT-Guided Bayesian Optimization",
    "year": 2023,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "Jiale Lao",
        "Yibo Wang",
        "Yufei Li",
        "Jianping Wang",
        "Yunjia Zhang",
        "Zhiyuan Cheng",
        "Wanghu Chen",
        "Mingjie Tang",
        "Jianguo Wang"
    ],
    "doi": "10.14778/3659437.3659449",
    "arxivId": "2311.03157",
    "url": "https://www.semanticscholar.org/paper/8ddb165278176f279ace760a8c14f5e0fcb652b0",
    "isOpenAccess": true,
    "openAccessPdf": "http://arxiv.org/pdf/2311.03157",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "\n Modern database management systems (DBMS) expose hundreds of configurable knobs to control system behaviours. Determining the appropriate values for these knobs to improve DBMS performance is a long-standing problem in the database community. As there is an increasing number of knobs to tune and each knob could be in continuous or categorical values, manual tuning becomes impractical. Recently, automatic tuning systems using machine learning methods have shown great potentials. However, existing approaches still incur significant tuning costs or only yield sub-optimal performance. This is because they either ignore the extensive domain knowledge available (e.g., DBMS manuals and forum discussions) and only rely on the runtime feedback of benchmark evaluations to guide the optimization, or they utilize the domain knowledge in a limited way. Hence, we propose GPTuner, a manual-reading database tuning system that leverages domain knowledge extensively and automatically to optimize search space and enhance the runtime feedback-based optimization process. Firstly, we develop a Large Language Model (LLM)-based pipeline to collect and refine heterogeneous knowledge, and propose a prompt ensemble algorithm to unify a structured view of the refined knowledge. Secondly, using the structured knowledge, we (1) design a workload-aware and training-free knob selection strategy, (2) develop a search space optimization technique considering the value range of each knob, and (3) propose a Coarse-to-Fine Bayesian Optimization Framework to explore the optimized space. Finally, we evaluate GPTuner under different benchmarks (TPC-C and TPC-H), metrics (throughput and latency) as well as DBMS (PostgreSQL and MySQL). Compared to the state-of-the-art approaches, GPTuner identifies better configurations in 16x less time on average. Moreover, GPTuner achieves up to 30% performance improvement (higher throughput or lower latency) over the\n best-performing\n alternative.\n",
    "citationCount": 54,
    "referenceCount": 69
}