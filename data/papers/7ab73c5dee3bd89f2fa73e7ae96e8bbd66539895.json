{
    "paperId": "7ab73c5dee3bd89f2fa73e7ae96e8bbd66539895",
    "title": "HotGPT: How to Make Software Documentation More Useful with a Large Language Model?",
    "year": 2023,
    "venue": "USENIX Workshop on Hot Topics in Operating Systems",
    "authors": [
        "Yiming Su",
        "Chengcheng Wan",
        "Utsav Sethi",
        "Shan Lu",
        "M. Musuvathi",
        "Suman Nath"
    ],
    "doi": "10.1145/3593856.3595910",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/7ab73c5dee3bd89f2fa73e7ae96e8bbd66539895",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "It is well known that valuable information is contained in the natural language components of software systems, like comments and manual, and such information can be used to improve system performance and reliability. Past research has attempted to extract such information through task-specific machine learning models and tool chains. Here, we investigate a general, one-model-fit-all solution through a state-of-the-art large language model (e.g., the GPT series). Our investigation covers three representative tasks: extracting locking rules from comments, synthesizing exception predicates from comments, and identifying performance-related configurations; it reveals challenges and opportunities in applying large language models to system maintenance tasks.",
    "citationCount": 19,
    "referenceCount": 25
}