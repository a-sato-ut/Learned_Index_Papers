{
    "paperId": "62ec69a974e96c9003bc888e4d5e87629a25c439",
    "title": "Revisiting Cache Freshness for Emerging Real-Time Applications",
    "year": 2024,
    "venue": "ACM Workshop on Hot Topics in Networks",
    "authors": [
        "Ziming Mao",
        "Rishabh Iyer",
        "S. Shenker",
        "Ion Stoica"
    ],
    "doi": "10.1145/3696348.3696858",
    "arxivId": "2412.20221",
    "url": "https://www.semanticscholar.org/paper/62ec69a974e96c9003bc888e4d5e87629a25c439",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book",
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Caching is widely used in industry to improve application performance by reducing data-access latency and taking the load off the backend infrastructure. TTLs have become the de-facto mechanism used to keep cached data reasonably fresh (i.e., not too out of date with the backend). However, the emergence of real-time applications requires tighter data freshness, which is impractical to achieve with TTLs. We discuss why this is the case, and propose a simple yet effective adaptive policy to achieve the desired freshness.",
    "citationCount": 0,
    "referenceCount": 30
}