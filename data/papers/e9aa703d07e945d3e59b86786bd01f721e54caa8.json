{
    "paperId": "e9aa703d07e945d3e59b86786bd01f721e54caa8",
    "title": "Neural ranking models for document retrieval",
    "year": 2021,
    "venue": "Information Retrieval Journal",
    "authors": [
        "M. Trabelsi",
        "Zhiyu Chen",
        "Brian D. Davison",
        "Jeff Heflin"
    ],
    "doi": "10.1007/s10791-021-09398-0",
    "arxivId": "2102.11903",
    "url": "https://www.semanticscholar.org/paper/e9aa703d07e945d3e59b86786bd01f721e54caa8",
    "isOpenAccess": true,
    "openAccessPdf": "https://link.springer.com/content/pdf/10.1007/s10791-021-09398-0.pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Ranking models are the main components of information retrieval systems. Several approaches to ranking are based on traditional machine learning algorithms using a set of hand-crafted features. Recently, researchers have leveraged deep learning models in information retrieval. These models are trained end-to-end to extract features from the raw data for ranking tasks, so that they overcome the limitations of hand-crafted features. A variety of deep learning models have been proposed, and each model presents a set of neural network components to extract features that are used for ranking. In this paper, we compare the proposed models in the literature along different dimensions in order to understand the major contributions and limitations of each model. In our discussion of the literature, we analyze the promising neural components, and propose future research directions. We also show the analogy between document retrieval and other retrieval tasks where the items to be ranked are structured documents, answers, images and videos.",
    "citationCount": 32,
    "referenceCount": 197
}