{
    "paperId": "59e8a4385baac0e03c42b129d3c600be9bd2898d",
    "title": "ModelVerification.jl: a Comprehensive Toolbox for Formally Verifying Deep Neural Networks",
    "year": 2024,
    "venue": "International Conference on Computer Aided Verification",
    "authors": [
        "Tianhao Wei",
        "Luca Marzari",
        "Kai S. Yun",
        "Hanjiang Hu",
        "Peizhi Niu",
        "Xusheng Luo",
        "Changliu Liu"
    ],
    "doi": "10.48550/arXiv.2407.01639",
    "arxivId": "2407.01639",
    "url": "https://www.semanticscholar.org/paper/59e8a4385baac0e03c42b129d3c600be9bd2898d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Deep Neural Networks (DNN) are crucial in approximating nonlinear functions across diverse applications, ranging from image classification to control. Verifying specific input-output properties can be a highly challenging task due to the lack of a single, self-contained framework that allows a complete range of verification types. To this end, we present \\texttt{ModelVerification.jl (MV)}, the first comprehensive, cutting-edge toolbox that contains a suite of state-of-the-art methods for verifying different types of DNNs and safety specifications. This versatile toolbox is designed to empower developers and machine learning practitioners with robust tools for verifying and ensuring the trustworthiness of their DNN models.",
    "citationCount": 2,
    "referenceCount": 53
}