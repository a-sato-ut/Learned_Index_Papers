{
    "paperId": "0e1bb511d6e74509a318536a3129d2d8c78b2200",
    "title": "Self-Tuning Query Scheduling for Analytical Workloads",
    "year": 2021,
    "venue": "SIGMOD Conference",
    "authors": [
        "Benjamin Wagner",
        "Andr√© Kohn",
        "Thomas Neumann"
    ],
    "doi": "10.1145/3448016.3457260",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/0e1bb511d6e74509a318536a3129d2d8c78b2200",
    "isOpenAccess": true,
    "openAccessPdf": "https://zenodo.org/record/5779551/files/scheduling.pdf",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Most database systems delegate scheduling decisions to the operating system. While such an approach simplifies the overall database design, it also entails problems. Adaptive resource allocation becomes hard in the face of concurrent queries. Furthermore, incorporating domain knowledge to improve query scheduling is difficult. To mitigate these problems, many modern systems employ forms of task-based parallelism. The execution of a single query is broken up into small, independent chunks of work (tasks). Now, fine-grained scheduling decisions based on these tasks are the responsibility of the database system. Despite being commonplace, little work has focused on the opportunities arising from this execution model. In this paper, we show how task-based scheduling in database systems opens up new areas for optimization. We present a novel lock-free, self-tuning stride scheduler that optimizes query latencies for analytical workloads. By adaptively managing query priorities and task granularity, we provide high scheduling elasticity. By incorporating domain knowledge into the scheduling decisions, our system is able to cope with workloads that other systems struggle with. Even at high load, we retain near optimal latencies for short running queries. Compared to traditional database systems, our design often improves tail latencies by more than 10x.",
    "citationCount": 32,
    "referenceCount": 33
}