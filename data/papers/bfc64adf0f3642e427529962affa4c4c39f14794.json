{
    "paperId": "bfc64adf0f3642e427529962affa4c4c39f14794",
    "title": "A Hardware–Software Blueprint for Flexible Deep Learning Specialization",
    "year": 2018,
    "venue": "IEEE Micro",
    "authors": [
        "T. Moreau",
        "Tianqi Chen",
        "Luis Vega",
        "Jared Roesch",
        "Eddie Q. Yan",
        "Lianmin Zheng",
        "Josh Fromm",
        "Ziheng Jiang",
        "L. Ceze",
        "Carlos Guestrin",
        "A. Krishnamurthy"
    ],
    "doi": "10.1109/MM.2019.2928962",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/bfc64adf0f3642e427529962affa4c4c39f14794",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/1807.04188",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This article describes the Versatile Tensor Accelerator (VTA), a programmable DL architecture designed to be extensible in the face of evolving workloads. VTA achieves “flexible specialization” via a parameterizable architecture, two-level Instruction Set Architecture (ISA), and a Just in Time (JIT) compiler.",
    "citationCount": 140,
    "referenceCount": 14
}