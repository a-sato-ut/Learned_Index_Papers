{
    "paperId": "896e5529de1da1e4494033404721b70339bb9557",
    "title": "Challenges of Real-World Reinforcement Learning",
    "year": 2019,
    "venue": "arXiv.org",
    "authors": [
        "Gabriel Dulac-Arnold",
        "D. Mankowitz",
        "Todd Hester"
    ],
    "doi": null,
    "arxivId": "1904.12901",
    "url": "https://www.semanticscholar.org/paper/896e5529de1da1e4494033404721b70339bb9557",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Reinforcement learning (RL) has proven its worth in a series of artificial domains, and is beginning to show some successes in real-world scenarios. However, much of the research advances in RL are often hard to leverage in real-world systems due to a series of assumptions that are rarely satisfied in practice. We present a set of nine unique challenges that must be addressed to productionize RL to real world problems. For each of these challenges, we specify the exact meaning of the challenge, present some approaches from the literature, and specify some metrics for evaluating that challenge. An approach that addresses all nine challenges would be applicable to a large number of real world problems. We also present an example domain that has been modified to present these challenges as a testbed for practical RL research.",
    "citationCount": 584,
    "referenceCount": 77
}