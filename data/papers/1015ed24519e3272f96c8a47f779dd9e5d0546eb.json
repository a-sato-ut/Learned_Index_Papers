{
    "paperId": "1015ed24519e3272f96c8a47f779dd9e5d0546eb",
    "title": "A Survey of Model Architectures in Information Retrieval",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Zhichao Xu",
        "Fengran Mo",
        "Zhiqi Huang",
        "Crystina Zhang",
        "Puxuan Yu",
        "Bei Wang",
        "Jimmy Lin",
        "Vivek Srikumar"
    ],
    "doi": "10.48550/arXiv.2502.14822",
    "arxivId": "2502.14822",
    "url": "https://www.semanticscholar.org/paper/1015ed24519e3272f96c8a47f779dd9e5d0546eb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Review"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The period from 2019 to the present has represented one of the biggest paradigm shifts in information retrieval (IR) and natural language processing (NLP), culminating in the emergence of powerful large language models (LLMs) from 2022 onward. Methods leveraging pretrained encoder-only models (e.g., BERT) and LLMs have outperformed many previous approaches, particularly excelling in zero-shot scenarios and complex reasoning tasks. This work surveys the evolution of model architectures in IR, focusing on two key aspects: backbone models for feature extraction and end-to-end system architectures for relevance estimation. The review intentionally separates architectural considerations from training methodologies to provide a focused analysis of structural innovations in IR systems. We trace the development from traditional term-based methods to modern neural approaches, particularly highlighting the impact of transformer-based models and subsequent large language models (LLMs). We conclude with a forward-looking discussion of emerging challenges and future directions, including architectural optimizations for performance and scalability, handling of multimodal, multilingual data, and adaptation to novel application domains such as autonomous search agents that is beyond traditional search paradigms.",
    "citationCount": 10,
    "referenceCount": 394
}