{
    "paperId": "8263f915cc3aec207e7ed6b9685ea7ba8bf4b4f3",
    "title": "Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "Yiyan Li",
        "Haoyang Li",
        "Pu Zhao",
        "Jing Zhang",
        "Xinyi Zhang",
        "Tao Ji",
        "Luming Sun",
        "Cuiping Li",
        "Hong Chen"
    ],
    "doi": "10.48550/arXiv.2408.02213",
    "arxivId": "2408.02213",
    "url": "https://www.semanticscholar.org/paper/8263f915cc3aec207e7ed6b9685ea7ba8bf4b4f3",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Knob tuning plays a crucial role in optimizing databases by adjusting knobs to enhance database performance. However, traditional tuning methods often follow a Try-Collect-Adjust approach, proving inefficient and database-specific. Moreover, these methods are often opaque, making it challenging for DBAs to grasp the underlying decision-making process. The emergence of large language models (LLMs) like GPT-4 and Claude-3 has excelled in complex natural language tasks, yet their potential in database knob tuning remains largely unexplored. This study harnesses LLMs as experienced DBAs for knob-tuning tasks with carefully designed prompts. We identify three key subtasks in the tuning system: knob pruning, model initialization, and knob recommendation, proposing LLM-driven solutions to replace conventional methods for each subtask. We conduct extensive experiments to compare LLM-driven approaches against traditional methods across the subtasks to evaluate LLMs' efficacy in the knob tuning domain. Furthermore, we explore the adaptability of LLM-based solutions in diverse evaluation settings, encompassing new benchmarks, database engines, and hardware environments. Our findings reveal that LLMs not only match or surpass traditional methods but also exhibit notable interpretability by generating responses in a coherent ``chain-of-thought'' manner. We further observe that LLMs exhibit remarkable generalizability through simple adjustments in prompts, eliminating the necessity for additional training or extensive code modifications. Drawing insights from our experimental findings, we identify several opportunities for future research aimed at advancing the utilization of LLMs in the realm of database management.",
    "citationCount": 7,
    "referenceCount": 52
}