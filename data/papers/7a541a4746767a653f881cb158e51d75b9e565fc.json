{
    "paperId": "7a541a4746767a653f881cb158e51d75b9e565fc",
    "title": "Ease.ml/snoopy in action",
    "year": 2020,
    "venue": "Proceedings of the VLDB Endowment",
    "authors": [
        "CÃ©dric Renggli",
        "Luka Rimanic",
        "Luka Kolar",
        "Wentao Wu",
        "Ce Zhang"
    ],
    "doi": "10.14778/3415478.3415488",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/7a541a4746767a653f881cb158e51d75b9e565fc",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We demonstrate ease.ml/snoopy, a data analytics system that performs feasibility analysis for machine learning (ML) applications before they are developed. Given a performance target of an ML application (e.g., accuracy above 0.95), ease.ml/snoopy provides a decisive answer to ML developers regarding whether the target is achievable or not. We formulate the feasibility analysis problem as an instance of Bayes error estimation. That is, for a data (distribution) on which the ML application should be performed, ease.ml/snoopy provides an estimate of the Bayes error - the minimum error rate that can be achieved by any classifier. It is well-known that estimating the Bayes error is a notoriously hard task. In ease.ml/snoopy we explore and employ estimators based on the combination of (1) nearest neighbor (NN) classifiers and (2) pre-trained feature transformations. To the best of our knowledge, this is the first work on Bayes error estimation that combines (1) and (2). In today's cost-driven business world, feasibility of an ML project is an ideal piece of information for ML application developers - ease.ml/snoopy plays the role of a reliable \"consultant.\"",
    "citationCount": 5,
    "referenceCount": 24
}