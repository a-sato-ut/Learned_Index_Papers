{
    "paperId": "23d52f3592446d23c9f0cf952399eb03aad70d8d",
    "title": "Using Lock-Free Design for Throughput-Optimized Cache Eviction",
    "year": 2025,
    "venue": "Measurement and Modeling of Computer Systems",
    "authors": [
        "Chaos Dong",
        "Fang Wang",
        "Hong Jiang",
        "Dan Feng"
    ],
    "doi": "10.1145/3727136",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/23d52f3592446d23c9f0cf952399eb03aad70d8d",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In large-scale information systems, storage device performance continues to improve while workloads expand in size and access characteristics. This growth puts tremendous pressure on caches and storage hierarchy in terms of concurrent throughput. However, existing cache eviction policies often struggle to provide adequate concurrent throughput due to their reliance on coarse-grained locking mechanisms and complex data structures. This paper presents a practical approach to cache eviction algorithm design, called Mobius, that optimizes the concurrent throughput of caches and reduces cache operation latency by utilizing lock-free data structures, while maintaining comparable hit ratios. Mobius includes two key designs. First, Mobius employs two lock-free FIFO queues to manage cache items, ensuring that all cache operations are executed efficiently in parallel. Second, Mobius integrates a consecutive detection mechanism that merges multiple modifications during eviction into a single operation, thereby reducing data races. Extensive evaluations using both synthetic and real-world workloads from high-concurrency clusters demonstrate that Mobius achieves a concurrent-throughput improvement ranging from 1.2× to 8.5× over state-of-the-art methods, while also maintaining lower latency and comparable cache hit ratios. The implementation of Mobius in CacheLib and RocksDB highlights its effectiveness in enhancing cache performance in practical scenarios.",
    "citationCount": 0,
    "referenceCount": 75
}