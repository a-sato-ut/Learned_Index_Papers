{
    "paperId": "248031105cc00737877ded134852d0edeb43b73c",
    "title": "FeatGraph: A Flexible and Efficient Backend for Graph Neural Network Systems",
    "year": 2020,
    "venue": "International Conference for High Performance Computing, Networking, Storage and Analysis",
    "authors": [
        "Yuwei Hu",
        "Zihao Ye",
        "Minjie Wang",
        "Jiali Yu",
        "Da Zheng",
        "Mu Li",
        "Zheng Zhang",
        "Zhiru Zhang",
        "Yida Wang"
    ],
    "doi": "10.1109/SC41405.2020.00075",
    "arxivId": "2008.11359",
    "url": "https://www.semanticscholar.org/paper/248031105cc00737877ded134852d0edeb43b73c",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2008.11359",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Graph neural networks (GNNs) are gaining popularity as a promising approach to machine learning on graphs. Unlike traditional graph workloads where each vertex/edge is associated with a scalar, GNNs attach a feature tensor to each vertex/edge. This additional feature dimension, along with consequently more complex vertex- and edge-wise computations, has enormous implications on locality and parallelism, which existing graph processing systems fail to exploit. This paper proposes FeatGraph to accelerate GNN workloads by co-optimizing graph traversal and feature dimension computation. FeatGraph provides a flexible programming interface to express diverse GNN models by composing coarse-grained sparse templates with fine-grained user-defined functions (UDFs) on each vertex/edge. FeatGraph incorporates optimizations for graph traversal into the sparse templates and allows users to specify optimizations for UDFs with a feature dimension schedule (FDS). FeatGraph speeds up end-to-end GNN training and inference by up to 32$\\times$ on CPU and 7$\\times$ on GPU.",
    "citationCount": 82,
    "referenceCount": 48
}