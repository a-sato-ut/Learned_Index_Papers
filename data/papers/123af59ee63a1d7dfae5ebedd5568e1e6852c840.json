{
    "paperId": "123af59ee63a1d7dfae5ebedd5568e1e6852c840",
    "title": "Efficient Neural Representation of Volumetric Data using Coordinate‐Based Networks.",
    "year": 2023,
    "venue": "Computer graphics forum (Print)",
    "authors": [
        "Sudarshan Devkota",
        "S. Pattanaik"
    ],
    "doi": "10.1111/cgf.14955",
    "arxivId": "2401.08840",
    "url": "https://www.semanticscholar.org/paper/123af59ee63a1d7dfae5ebedd5568e1e6852c840",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In this paper, we propose an efficient approach for the compression and representation of volumetric data utilizing coordinate‐based networks and multi‐resolution hash encoding. Efficient compression of volumetric data is crucial for various applications, such as medical imaging and scientific simulations. Our approach enables effective compression by learning a mapping between spatial coordinates and intensity values. We compare different encoding schemes and demonstrate the superiority of multiresolution hash encoding in terms of compression quality and training efficiency. Furthermore, we leverage optimization‐based meta‐learning, specifically using the Reptile algorithm, to learn weight initialization for neural representations tailored to volumetric data, enabling faster convergence during optimization. Additionally, we compare our approach with state‐of‐the‐art methods to showcase improved image quality and compression ratios. These findings highlight the potential of coordinate‐based networks and multi‐resolution hash encoding for an efficient and accurate representation of volumetric data, paving the way for advancements in large‐scale data visualization and other applications.",
    "citationCount": 4,
    "referenceCount": 58
}