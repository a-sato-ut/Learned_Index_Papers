{
    "paperId": "62d69ebf89b69dbcbf6bca18afbcf41f2d401a61",
    "title": "TKD: An Efficient Deep Learning Compiler with Cross-Device Knowledge Distillation",
    "year": 2025,
    "venue": "Design, Automation and Test in Europe",
    "authors": [
        "Yiming Ma",
        "Chaoyao Shen",
        "Linfeng Jiang",
        "Tao Xu",
        "Meng Zhang"
    ],
    "doi": "10.23919/DATE64628.2025.10993076",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/62d69ebf89b69dbcbf6bca18afbcf41f2d401a61",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Generating high-performance tensor programs on resource-constrained devices is challenging for current Deep Learning (DL) compilers that use learning-based cost models to predict the performance of tensor programs. Due to the inability of cost models to leverage cross-device information, it is extremely time-consuming to collect data and train a new cost model. To address this problem, this paper proposes TKD, a novel DL compiler that can be efficiently adapted to devices that are resource-constrained. TKD reduces the time budget by over 11x through an adaptive tensor program filter that eliminates redundant and unimportant measurements of tensor programs. Furthermore, by refining the cost model architecture with a multi-head attention module and distilling transferable knowledge from source devices, TKD outperforms state-of-the-art methods in prediction accuracy, compilation time, and compilation quality. We conducted experiments on the edge GPU, NVIDIA Jetson TX2, and the results show that compared to TenSet and TLP, TKD reduces compilation time by 1.58x and 1.16x, while achieving 1.40x and 1.27x speedups of the tensor programs, respectively.",
    "citationCount": 0,
    "referenceCount": 28
}