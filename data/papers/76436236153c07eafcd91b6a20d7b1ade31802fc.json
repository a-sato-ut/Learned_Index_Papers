{
    "paperId": "76436236153c07eafcd91b6a20d7b1ade31802fc",
    "title": "Learning with Small Data: Subgraph Counting Queries",
    "year": 2023,
    "venue": "Data Science and Engineering",
    "authors": [
        "Kangfei Zhao",
        "J. Yu",
        "Zongyan He",
        "Yu Rong"
    ],
    "doi": "10.1007/s41019-023-00223-w",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/76436236153c07eafcd91b6a20d7b1ade31802fc",
    "isOpenAccess": true,
    "openAccessPdf": "https://link.springer.com/content/pdf/10.1007/s41019-023-00223-w.pdf",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Deep Learning (DL) has been widely used in many applications, and its success is achieved with large training data. A key issue is how to provide a DL solution when there is no large training data to learn initially. In this paper, we explore a meta-learning approach for a specific problem, subgraph isomorphism counting, which is a fundamental problem in graph analysis to count the number of a given pattern graph, p , in a data graph, g , that matches p . There are various data graphs and pattern graphs. A subgraph isomorphism counting query is specified by a pair, ( g ,  p ). This problem is NP-hard and needs large training data to learn by DL in nature. We design a Gaussian Process (GP) model which combines Graph Neural Network with Bayesian nonparametric, and we train the GP by a meta-learning algorithm on a small set of training data. By meta-learning, we can obtain a generalized meta-model to better encode the information of data and pattern graphs and capture the prior of small tasks. With the meta-model learned, we handle a collection of pairs ( g ,  p ), as a task, where some pairs may be associated with the ground-truth, and some pairs are the queries to answer. There are two cases. One is there are some with ground-truth (few-shot), and one is there is none with ground-truth (zero-shot). We provide our solutions for both. In particular, for zero-shot, we propose a new data-driven approach to predict the count values. Note that zero-shot learning for our regression tasks is difficult, and there is no hands-on solution in the literature. We conducted extensive experimental studies to confirm that our approach is robust to model degeneration on small training data, and our meta-model can fast adapt to new queries by few-shot and zero-shot learning.",
    "citationCount": 2,
    "referenceCount": 66
}