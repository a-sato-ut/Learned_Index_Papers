{
    "paperId": "5927d5a2215038ed731da6e003a15c782fff5567",
    "title": "Advanced Detection and Forecasting of Fake News on Social Media Platforms Using Natural Language Processing and Artificial Intelligence",
    "year": 2025,
    "venue": "Journal of Posthumanism",
    "authors": [
        "Nipa Akter",
        "Md. Zainal Abedin",
        "Md Tanvir Rahman Tarafder",
        "Nabila Ahmed Nikita",
        "Sheikh Nusrat Jahan",
        "Nur Nahar Rimi",
        "Md. Tariqul Islam"
    ],
    "doi": "10.63332/joph.v5i6.2446",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/5927d5a2215038ed731da6e003a15c782fff5567",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Political Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "In the stage of pervasive digital communication, the rapid dissemination of fake news via social media platforms poses significant challenges to public discourse, societal trust, and institutional integrity. Fake news, characterized by fabricated or misleading content, spreads rapidly across platforms like Facebook, Twitter, WhatsApp, influencing political outcomes and public perceptions. Traditional methods of manual fact-checking cannot keep pace with the scale of misinformation, necessitating the use of advanced technologies such as Natural Language Processing (NLP) and Artificial Intelligence (AI).Â  NLP enables machines to interpret and analyze textual data, identifying linguistic patterns, sentiment, and deceptive cues associated with fake news. Meanwhile, AI, particularly through machine learning and deep learning techniques, improves the accuracy and scalability of detection systems. These technologies integrate textual analysis with social network dynamics to detect misinformation and forecast its propagation. However, challenges remain, including limited datasets with cultural and linguistic diversity, evolving tactics by fake news creators, and ethical concerns such as algorithmic bias and transparency. This research emphasizes the need for comprehensive solutions that combine robust datasets, multimodal data analysis, and predictive modeling. Integrating ethical frameworks ensures that AI-driven systems remain fair and accountable. By advancing real-time detection and forecasting mechanisms, NLP and AI provide a proactive approach to mitigating the societal impact of misinformation, fostering a healthier and more informed digital ecosystem",
    "citationCount": 1,
    "referenceCount": 107
}