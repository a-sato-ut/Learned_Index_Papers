{
    "paperId": "1e43cff50e40e8169bf87cdad611c85613a37b4f",
    "title": "DiffTune: Optimizing CPU Simulator Parameters with Learned Differentiable Surrogates",
    "year": 2020,
    "venue": "Micro",
    "authors": [
        "Alex Renda",
        "Yishen Chen",
        "Charith Mendis",
        "Michael Carbin"
    ],
    "doi": "10.1109/MICRO50266.2020.00045",
    "arxivId": "2010.04017",
    "url": "https://www.semanticscholar.org/paper/1e43cff50e40e8169bf87cdad611c85613a37b4f",
    "isOpenAccess": true,
    "openAccessPdf": "https://arxiv.org/pdf/2010.04017",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "CPU simulators are useful tools for modeling CPU execution behavior. However, they suffer from inaccuracies due to the cost and complexity of setting their fine-grained parameters, such as the latencies of individual instructions. This complexity arises from the expertise required to design benchmarks and measurement frameworks that can precisely measure the values of parameters at such fine granularity. In some cases, these parameters do not necessarily have a physical realization and are therefore fundamentally approximate, or even unmeasurable.In this paper we present DiffTune, a system for learning the parameters of x86 basic block CPU simulators from coarse-grained end-to-end measurements. Given a simulator, DiffTune learns its parameters by first replacing the original simulator with a differentiable surrogate, another function that approximates the original function; by making the surrogate differentiable, DiffTune is then able to apply gradient-based optimization techniques even when the original function is non-differentiable, such as is the case with CPU simulators. With this differentiable surrogate, DiffTune then applies gradient-based optimization to produce values of the simulator’s parameters that minimize the simulator’s error on a dataset of ground truth end-to-end performance measurements. Finally, the learned parameters are plugged back into the original simulator.DiffTune is able to automatically learn the entire set of microarchitecture-specific parameters within the Intel x86 simulation model of llvm-mca, a basic block CPU simulator based on LLVM’s instruction scheduling model. DiffTune’s learned parameters lead llvm-mca to an average error that not only matches but lowers that of its original, expert-provided parameter values.",
    "citationCount": 39,
    "referenceCount": 44
}