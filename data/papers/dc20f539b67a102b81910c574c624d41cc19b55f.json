{
    "paperId": "dc20f539b67a102b81910c574c624d41cc19b55f",
    "title": "Advanced Hyper-Tunning Strategies for Global Mean Based Feature Selection and Creation for enhanced Accuracy",
    "year": 2024,
    "venue": "2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)",
    "authors": [
        "Maradana Durga Venkata Prasad",
        "Srikanth T",
        "Durgesh Mishra"
    ],
    "doi": "10.1109/ICTBIG64922.2024.10911071",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/dc20f539b67a102b81910c574c624d41cc19b55f",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Clustering accuracy is crucial for effective data analysis in unsupervised learning tasks, with the usage of the simple and efficient cluster analysis technique named as K-means technique. However, standard K-means suffers from limitations such as sensitivity to random initialization and challenges in handling high-dimensional data with irrelevant features. This paper presents a hyper-tuned approach to improve K-means clustering accuracy by Unifying Global Mean-Based Nearest Feature Object Selection for robust Centroid initialization with a Feature Creation Method Based on Important Feature Selection. The proposed method first enhances Centroid initialization by selecting points close to global feature means, ensuring initial centroids are more representative of the data distribution. Additionally, it focuses on identifying and weighting the most important features while creating composite features that amplify cluster separability. Experimental results demonstrate a 1.36986% improvement in clustering accuracy, an increase in silhouette scores, faster convergence, and improved stability across multiple trials compared to traditional K-means.",
    "citationCount": 0,
    "referenceCount": 22
}