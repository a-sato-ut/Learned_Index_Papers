{
    "paperId": "8f5fa93bc809c2a230214cfba036afcca2a45406",
    "title": "ASQP-RL Demo: Learning Approximation Sets for Exploratory Queries",
    "year": 2024,
    "venue": "SIGMOD Conference Companion",
    "authors": [
        "Susan B. Davidson",
        "Tova Milo",
        "Kathy Razmadze",
        "Gal Zeevi"
    ],
    "doi": "10.1145/3626246.3654741",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/8f5fa93bc809c2a230214cfba036afcca2a45406",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We demonstrate the Approximate Selection Query Processing (ASQP-RL) system, which uses Reinforcement Learning to select a subset of a large external dataset to process locally in a notebook during data exploration. Given a query workload over an external database and notebook memory size, the system translates the workload to select-project-join (non-aggregate) queries and finds a subset of each relation such that the data subset - called the approximation set - fits into the notebook memory and maximizes query result quality. The data subset can then be loaded into the notebook, and rapidly queried by the analyst. Our demonstration shows how ASQP-RL can be used during data exploration and achieve comparable results to external queries over the large dataset at significantly reduced query times. It also shows how ASQP-RL can be used for aggregation queries, achieving surprisingly good results compared to state-of-the-art techniques.",
    "citationCount": 0,
    "referenceCount": 9
}