{
    "paperId": "359595ba5b1bda4b74c21c7d63fe064ca9eae0bb",
    "title": "DawnPiper: A Memory-scablable Pipeline Parallel Training Framework",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Xuan Peng",
        "Xuanhua Shi",
        "Haolin Zhang",
        "Yunfei Zhao",
        "Xuehai Qian"
    ],
    "doi": "10.48550/arXiv.2505.05856",
    "arxivId": "2505.05856",
    "url": "https://www.semanticscholar.org/paper/359595ba5b1bda4b74c21c7d63fe064ca9eae0bb",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Pipeline parallelism is a crucial paradigm for large-scale model training. However, imbalances in memory footprint across stages can lead to significant GPU memory wastage, limiting the model sizes that pipeline parallelism can effectively support. In this paper, we introduce DawnPiper, a memory-scalable pipeline parallel training framework. Firstly, we develop a DL compilation-based profiling method that transforms the model into a fine-grained computation graph. This refinement gives us a finer granularity of model partitioning and memory optimization while facilitating automatic code generation. Based on observed memory usage characteristics, we derive a performance-optimal theorem for pipeline parallel partitioning that substantially reduces the partition search space. Secondly, we propose a binary pipeline partitioning algorithm and utilize a cost-model based memory optimization approach to efficiently identify nearly optimal pipeline parallel strategy. DawnPiper achieves up to a 4x and 11x increase in trainable maximum batch size compared to vPipe and PipeDream, respectively, and provides up to a 1.5x performance speedup compared to vPipe.",
    "citationCount": 1,
    "referenceCount": 40
}