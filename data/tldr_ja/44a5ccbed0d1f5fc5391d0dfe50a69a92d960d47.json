{
  "paperId": "44a5ccbed0d1f5fc5391d0dfe50a69a92d960d47",
  "title": "The Potential of Learned Index Structures for Index Compression",
  "abstract": "Inverted indexes are vital in providing fast key-word-based search. For every term in the document collection, a list of identifiers of documents in which the term appears is stored, along with auxiliary information such as term frequency, and position offsets. While very effective, inverted indexes have large memory requirements for web-sized collections. Recently, the concept of learned index structures was introduced, where machine learned models replace common index structures such as B-tree-indexes, hash-indexes, and bloom-filters. These learned index structures require less memory, and can be computationally much faster than their traditional counterparts. In this paper, we consider whether such models may be applied to conjunctive Boolean querying. First, we investigate how a learned model can replace document postings of an inverted index, and then evaluate the compromises such an approach might have. Second, we evaluate the potential gains that can be achieved in terms of memory requirements. Our work shows that learned models have great potential in inverted indexing, and this direction seems to be a promising area for future research.",
  "tldr_ja": "逆インデックスは高速なキーワード検索に不可欠ですが、大規模なコレクションではメモリ消費が大きい。最近、機械学習モデルを用いた学習インデックス構造が提案され、従来のインデックスよりもメモリ効率が良く、計算速度も向上する可能性がある。本研究では、学習モデルが逆インデックスの文書投稿を置き換える方法とその妥協点を探り、メモリ要件の改善を評価した。学習モデルは逆インデックスにおいて大きな可能性を秘めており、今後の研究が期待される。"
}