{
  "paperId": "81f5c258beca404a70880f89d1f803f4c8063e73",
  "title": "DB-GPT: Large Language Model Meets Database",
  "abstract": "Large language models (LLMs) have shown superior performance in various areas. And LLMs have the potential to revolutionize data management by serving as the \"brain\" of next-generation database systems. However, there are several challenges that utilize LLMs to optimize databases. First, it is challenging to provide appropriate prompts (e.g., instructions and demonstration examples) to enable LLMs to understand the database optimization problems. Second, LLMs only capture the logical database characters (e.g., SQL semantics) but are not aware of physical characters (e.g., data distributions), and it requires to fine-tune LLMs to capture both physical and logical information. Third, LLMs are not well trained for databases with strict constraints (e.g., query plan equivalence) and privacy-preserving requirements, and it is challenging to train database-specific LLMs while ensuring database privacy. To overcome these challenges, this vision paper proposes a LLM-based database framework (), including automatic prompt generation, DB-specific model fine-tuning, and DB-specific model design and pre-training. Preliminary experiments show that achieves relatively good performance in database tasks like query rewrite and index tuning. The source code and datasets are available at github.com/TsinghuaDatabaseGroup/DB-GPT.",
  "tldr_ja": "DB-GPTは、大規模言語モデル（LLM）を活用した次世代データベースシステムの枠組みを提案します。データベース最適化における課題を克服するため、自動プロンプト生成やモデルの微調整を行い、初期実験ではクエリ再構築やインデックス調整で良好な性能を示しました。ソースコードとデータセットは公開されています。"
}