{
  "paperId": "3f247b9b9f12ac7ea7ea2d4b35780ef77c95f951",
  "title": "Opportunistic View Materialization with Deep Reinforcement Learning",
  "abstract": "Carefully selected materialized views can greatly improve the performance of OLAP workloads. We study using deep reinforcement learning to learn adaptive view materialization and eviction policies. Our insight is that such selection policies can be effectively trained with an asynchronous RL algorithm, that runs paired counter-factual experiments during system idle times to evaluate the incremental value of persisting certain views. Such a strategy obviates the need for accurate cardinality estimation or hand-designed scoring heuristics. We focus on inner-join views and modeling effects in a main-memory, OLAP system. Our research prototype system, called DQM, is implemented in SparkSQL and we experiment on several workloads including the Join Order Benchmark and the TPC-DS workload. Results suggest that: (1) DQM can outperform heuristic when their assumptions are not satisfied by the workload or there are temporal effects like period maintenance, (2) even with the cost of learning, DQM is more adaptive to changes in the workload, and (3) DQM is broadly applicable to different workloads and skews.",
  "tldr_ja": "深層強化学習を用いて、OLAPワークロードのための適応的なマテリアライズドビューの選択と削除ポリシーを学習する手法を提案。実験結果から、提案システムDQMは、従来のヒューリスティック手法よりも柔軟で、さまざまなワークロードに適用可能であることが示された。"
}