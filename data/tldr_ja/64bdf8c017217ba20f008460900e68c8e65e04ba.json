{
  "paperId": "64bdf8c017217ba20f008460900e68c8e65e04ba",
  "title": "Learned-Database Systems Security",
  "abstract": "A learned database system uses machine learning (ML) internally to improve performance. We can expect such systems to be vulnerable to some adversarial-ML attacks. Often, the learned component is shared between mutually-distrusting users or processes, much like microarchitectural resources such as caches, potentially giving rise to highly-realistic attacker models. However, compared to attacks on other ML-based systems, attackers face a level of indirection as they cannot interact directly with the learned model. Additionally, the difference between the attack surface of learned and non-learned versions of the same system is often subtle. These factors obfuscate the de-facto risks that the incorporation of ML carries. We analyze the root causes of potentially-increased attack surface in learned database systems and develop a framework for identifying vulnerabilities that stem from the use of ML. We apply our framework to a broad set of learned components currently being explored in the database community. To empirically validate the vulnerabilities surfaced by our framework, we choose 3 of them and implement and evaluate exploits against these. We show that the use of ML cause leakage of past queries in a database, enable a poisoning attack that causes exponential memory blowup in an index structure and crashes it in seconds, and enable index users to snoop on each others'key distributions by timing queries over their own keys. We find that adversarial ML is an universal threat against learned components in database systems, point to open research gaps in our understanding of learned-systems security, and conclude by discussing mitigations, while noting that data leakage is inherent in systems whose learned component is shared between multiple parties.",
  "tldr_ja": "学習データベースシステムは、機械学習を利用して性能を向上させるが、敵対的機械学習攻撃に対して脆弱である。特に、学習モデルが複数の不信なユーザー間で共有されることで、攻撃のリスクが高まる。研究では、学習データベースの脆弱性を特定するフレームワークを開発し、実際の攻撃を評価した結果、過去のクエリ漏洩やメモリの急増を引き起こす攻撃が可能であることを示した。学習コンポーネントのセキュリティに関する理解には未解決の問題があり、データ漏洩は共有された学習コンポーネントを持つシステムに内在するリスクである。"
}