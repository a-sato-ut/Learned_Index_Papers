{
  "paperId": "1b28a7e49f718e5b5612c8fb28096bab0d69ebbd",
  "title": "Memory-Efficient RkNN Retrieval by Nonlinear k-Distance Approximation",
  "abstract": "The reverse k-nearest neighbor (RkNN) query is an established query type with various applications reaching from identifying highly influential objects over incrementally updating kNN graphs to optimizing sensor communication and outlier detection. State-of-the-art solutions exploit that the k-distances in real-world datasets often follow the power-law distribution, and bound them with linear lines in log-log space. In this work, we investigate this assumption and uncover that it is violated in regions of changing density, which we show are typical for real-life datasets. Towards a generic solution, we pose the estimation of k-distances as a regression problem. Thereby, we enable harnessing the power of the abundance of available Machine Learning models and profiting from their advancement. We propose a flexible approach which allows steering the performance-memory consumption trade-off, and in particular to find good solutions with a fixed memory budget crucial in the context of edge computing. Moreover, we show how to obtain and improve guaranteed bounds essential to exact query processing. In experiments on real-world datasets, we demonstrate how this framework can significantly reduce the index memory consumption, and strongly reduce the candidate set size. We publish our code at https://github.com/sobermeier/nonlinear-kdist, and a detailed technical report at https://arxiv.org/abs/2011.01773.",
  "tldr_ja": "逆k近傍（RkNN）クエリの効率的な取得方法を提案し、実世界のデータセットにおけるk距離の非線形近似を用いてメモリ消費を削減するアプローチを示す。機械学習モデルを活用し、エッジコンピューティングにおける固定メモリ予算内での性能向上を図る。実験により、インデックスのメモリ消費と候補セットのサイズを大幅に削減できることを実証。"
}