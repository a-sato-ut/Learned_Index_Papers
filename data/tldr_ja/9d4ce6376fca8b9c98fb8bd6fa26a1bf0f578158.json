{
  "paperId": "9d4ce6376fca8b9c98fb8bd6fa26a1bf0f578158",
  "title": "Scalable k-nearest neighbor algorithms based on learned functions",
  "abstract": "Approximate k-Nearest Neighbor (kNN) is a fundamental problem in data science. A lot of traditional approaches have been devel- oped to solve this problem, yet none of them can achieve high accuracy, small memory usage and fast query speed. These methods can be in- efficient since they don’t improve with experience(learning from errors or heuristics employed). A recent trend in algorithm design consists of augmenting classic data structures with machine learning models. Mo- tivated by this, we present a learned index for kNN query in massive amounts of data, named LBF. It robustly combines a traditional index with a learned model. What’s more, a multiple feature extraction mod- ule is embedded into our model to make full use of the raw input. These make our method satisfies all the requirements of a good similarity in- dexing scheme. Theoretical proofs and experimental results on a variety of datasets show that compared to the state-of-the-art methods, we can achieve a comparable accuracy with much less memory usage.",
  "tldr_ja": "本論文では、従来のk近傍法(kNN)の限界を克服するため、機械学習モデルを組み合わせた新しいインデックス手法LBFを提案します。この手法は、従来のインデックスと学習モデルを融合し、複数の特徴抽出モジュールを組み込むことで、精度を保ちながらメモリ使用量を大幅に削減し、高速なクエリ処理を実現します。実験結果は、最新の手法と比較しても同等の精度を示しています。"
}