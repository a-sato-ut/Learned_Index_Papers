{
  "paperId": "71cfe54cb46cb01fc9310c900c5adb74f0d2a306",
  "title": "Learning-augmented private algorithms for multiple quantile release",
  "abstract": "When applying differential privacy to sensitive data, we can often improve performance using external information such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms with predictions) framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding robustness, and the provision of useful surrogate losses for two novel ``meta\"algorithms that learn predictions from other (potentially sensitive) data. We conclude with experiments on challenging tasks demonstrating that learning predictions across one or more instances can lead to large error reductions while preserving privacy.",
  "tldr_ja": "本論文では、差分プライバシーを適用する際に外部情報を活用することで性能を向上させる「学習強化アルゴリズム」を提案します。特に、複数の分位点をリリースするタスクに焦点を当て、予測の質に基づく誤差保証を導出しました。実験結果から、他のデータから予測を学習することで、プライバシーを保ちながら大幅な誤差削減が可能であることを示しています。"
}