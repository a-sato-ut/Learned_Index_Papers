{
  "paperId": "0fe6fcfbb5f090e0b8a5c5e8fce6d991bef0159e",
  "title": "A Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks",
  "abstract": "Counterexample-guided repair aims at creating neural networks with mathematical safety guarantees, facilitating the application of neural networks in safety-critical domains. However, whether counterexample-guided repair is guaranteed to terminate remains an open question. We approach this question by showing that counterexample-guided repair can be viewed as a robust optimisation algorithm. While termination guarantees for neural network repair itself remain beyond our reach, we prove termination for more restrained machine learning models and disprove termination in a general setting. We empirically study the practical implications of our theoretical results, demonstrating the suitability of common verifiers and falsifiers for repair despite a disadvantageous theoretical result. Additionally, we use our theoretical insights to devise a novel algorithm for repairing linear regression models based on quadratic programming, surpassing existing approaches.",
  "tldr_ja": "カウンター例に基づく修復は、神経ネットワークの安全性を保証する手法ですが、その終了保証は未解決です。本研究では、これをロバスト最適化アルゴリズムとして捉え、制約のある機械学習モデルでは終了を証明し、一般的な設定では終了を否定しました。また、理論的結果に基づき、線形回帰モデルの修復のための新しいアルゴリズムを提案し、既存のアプローチを上回ることを示しました。"
}