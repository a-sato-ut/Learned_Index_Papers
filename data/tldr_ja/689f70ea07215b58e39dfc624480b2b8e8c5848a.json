{
  "paperId": "689f70ea07215b58e39dfc624480b2b8e8c5848a",
  "title": "PerfGuard: Deploying ML-for-Systems without Performance Regressions, Almost!",
  "abstract": "\n Modern data processing systems require optimization at massive scale, and using machine learning to optimize these systems (ML-for-systems) has shown promising results. Unfortunately, ML-for-systems is subject to over generalizations that do not capture the large variety of workload patterns, and tend to augment the performance of certain subsets in the workload while regressing performance for others. In this paper, we introduce a performance safeguard system, called\n PerfGuard\n , that designs pre-production experiments for deploying ML-for-systems. Instead of searching the entire space of query plans (a well-known, intractable problem), we focus on query plan deltas (a significantly smaller space). PerfGuard formalizes these differences, and correlates plan deltas to important feedback signals, like execution cost. We describe the deep learning architecture and the end-to-end pipeline in PerfGuard that could be used with general relational databases. We show that this architecture improves on baseline models, and that our pipeline identifies key query plan components as major contributors to plan disparity. Offline experimentation shows PerfGuard as a promising approach, with many opportunities for future improvement.\n",
  "tldr_ja": "PerfGuardは、機械学習を用いたシステム最適化において、パフォーマンスの低下を防ぐための新しい手法を提案します。クエリプランの差分に焦点を当て、重要なフィードバック信号と関連付けることで、効率的な実験を設計します。実験結果は、PerfGuardが従来のモデルを上回る性能を示し、クエリプランの主要な要素を特定することに成功したことを示しています。"
}