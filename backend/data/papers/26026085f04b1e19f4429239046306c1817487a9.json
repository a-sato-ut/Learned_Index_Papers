{
    "paperId": "26026085f04b1e19f4429239046306c1817487a9",
    "title": "Algorithms for Caching and MTS with reduced number of predictions",
    "year": 2024,
    "venue": "International Conference on Learning Representations",
    "authors": [
        "Karim Abdel Sadek",
        "Marek Elias"
    ],
    "doi": "10.48550/arXiv.2404.06280",
    "arxivId": "2404.06280",
    "url": "https://www.semanticscholar.org/paper/26026085f04b1e19f4429239046306c1817487a9",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "ML-augmented algorithms utilize predictions to achieve performance beyond their worst-case bounds. Producing these predictions might be a costly operation -- this motivated Im et al. '22 to introduce the study of algorithms which use predictions parsimoniously. We design parsimonious algorithms for caching and MTS with action predictions, proposed by Antoniadis et al. '20, focusing on the parameters of consistency (performance with perfect predictions) and smoothness (dependence of their performance on the prediction error). Our algorithm for caching is 1-consistent, robust, and its smoothness deteriorates with the decreasing number of available predictions. We propose an algorithm for general MTS whose consistency and smoothness both scale linearly with the decreasing number of predictions. Without the restriction on the number of available predictions, both algorithms match the earlier guarantees achieved by Antoniadis et al. '20.",
    "citationCount": 10,
    "referenceCount": 55
}