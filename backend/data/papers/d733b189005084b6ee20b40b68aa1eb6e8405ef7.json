{
    "paperId": "d733b189005084b6ee20b40b68aa1eb6e8405ef7",
    "title": "A Practical Learning-Based FTL for Memory Constrained Mobile Flash Storage",
    "year": 2025,
    "venue": "Design, Automation and Test in Europe",
    "authors": [
        "Zelin Du",
        "Kecheng Huang",
        "Tianyu Wang",
        "Xin Yao",
        "Renhai Chen",
        "Zili Shao"
    ],
    "doi": "10.23919/DATE64628.2025.10992824",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/d733b189005084b6ee20b40b68aa1eb6e8405ef7",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The rapidly growing mobile market is pushing flash storage manufacturers to expand capacity into the terabyte range. However, this presents a significant challenge for mobile storage management: more logical-to-physical page mappings are desired to be efficiently managed and cached while the available caching space is extremely limited. This motivates us to shift toward a new learning-based paradigm: rather than maintaining mappings for individual pages, the learning-based approach can represent mapping relationships for a set of continuous pages. However, to construct linear models, existing methods that either consume the already-limited memory space or reuse flash garbage collection demonstrate poor model construction capabilities or significantly degrade flash performance, making them impractical for real-world use. In this paper, we propose LFTL, a practical, learning-based on-demand flash translation layer design for flash management in mobile devices. In contrast to prior work that centered around gathering sufficient mappings for linear model construction, our key insight is that linear patterns can be extracted and refined by leveraging the orderly, LPA-aligned write stream typical of mobile devices. By doing this, highly accurate linear models can be constructed regardless of the constraints of mobile device's cache limitation. We have implemented a fully functional prototype of LFTL based on FEMU. Our evaluation results show that LFTL is more adaptable to memory-constrained storage devices than state-of-the-art learning-based approaches.",
    "citationCount": 0,
    "referenceCount": 27
}