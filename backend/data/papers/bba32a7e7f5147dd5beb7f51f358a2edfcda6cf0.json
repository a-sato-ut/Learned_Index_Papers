{
    "paperId": "bba32a7e7f5147dd5beb7f51f358a2edfcda6cf0",
    "title": "A Unified Transferable Model for ML-Enhanced DBMS",
    "year": 2021,
    "venue": "Conference on Innovative Data Systems Research",
    "authors": [
        "Ziniu Wu",
        "Peilun Yang",
        "Pei Yu",
        "Rong Zhu",
        "Yuxing Han",
        "Yaliang Li",
        "Defu Lian",
        "K. Zeng",
        "Jingren Zhou"
    ],
    "doi": null,
    "arxivId": "2105.02418",
    "url": "https://www.semanticscholar.org/paper/bba32a7e7f5147dd5beb7f51f358a2edfcda6cf0",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Recently, the database management system (DBMS) community has witnessed the power of machine learning (ML) solutions for DBMS tasks. Despite their promising performance, these existing solutions can hardly be considered satisfactory. First, these ML-based methods in DBMS are not effective enough because they are optimized on each specific task, and cannot explore or understand the intrinsic connections between tasks. Second, the training process has serious limitations that hinder their practicality, because they need to retrain the entire model from scratch for a new DB. Moreover, for each retraining, they require an excessive amount of training data, which is very expensive to acquire and unavailable for a new DB. We propose to explore the transferabilities of the ML methods both across tasks and across DBs to tackle these fundamental drawbacks. In this paper, we propose a unified model MTMLF that uses a multi-task training procedure to capture the transferable knowledge across tasks and a pre-train fine-tune procedure to distill the transferable meta knowledge across DBs. We believe this paradigm is more suitable for cloud DB service, and has the potential to revolutionize the way how ML is used in DBMS. Furthermore, to demonstrate the predicting power and viability of MTMLF, we provide a concrete and very promising case study on query optimization tasks. Last but not least, we discuss several concrete research opportunities along this line of work.",
    "citationCount": 32,
    "referenceCount": 49
}