{
    "paperId": "e228ce01c4ee51cababd2102d23f0c620d02b289",
    "title": "The Second International Verification of Neural Networks Competition (VNN-COMP 2021): Summary and Results",
    "year": 2021,
    "venue": "arXiv.org",
    "authors": [
        "Stanley Bak",
        "Changliu Liu",
        "Taylor T. Johnson"
    ],
    "doi": null,
    "arxivId": "2109.00498",
    "url": "https://www.semanticscholar.org/paper/e228ce01c4ee51cababd2102d23f0c620d02b289",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "This report summarizes the second International Verification of Neural Networks Competition (VNN-COMP 2021), held as a part of the 4th Workshop on Formal Methods for ML-Enabled Autonomous Systems that was collocated with the 33rd International Conference on Computer-Aided Verification (CAV). Twelve teams participated in this competition. The goal of the competition is to provide an objective comparison of the state-of-the-art methods in neural network verification, in terms of scalability and speed. Along this line, we used standard formats (ONNX for neural networks and VNNLIB for specifications), standard hardware (all tools are run by the organizers on AWS), and tool parameters provided by the tool authors. This report summarizes the rules, benchmarks, participating tools, results, and lessons learned from this competition.",
    "citationCount": 113,
    "referenceCount": 53
}