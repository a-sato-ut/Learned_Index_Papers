{
    "paperId": "a83bc44ba4b8676c5f6848432487e4ec26d53252",
    "title": "Learning-Augmented Algorithms for MTS with Bandit Access to Multiple Predictors",
    "year": 2025,
    "venue": "arXiv.org",
    "authors": [
        "Matei Gabriel Cosa",
        "Marek Eli√°s"
    ],
    "doi": "10.48550/arXiv.2506.05479",
    "arxivId": "2506.05479",
    "url": "https://www.semanticscholar.org/paper/a83bc44ba4b8676c5f6848432487e4ec26d53252",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We consider the following problem: We are given $\\ell$ heuristics for Metrical Task Systems (MTS), where each might be tailored to a different type of input instances. While processing an input instance received online, we are allowed to query the action of only one of the heuristics at each time step. Our goal is to achieve performance comparable to the best of the given heuristics. The main difficulty of our setting comes from the fact that the cost paid by a heuristic at time $t$ cannot be estimated unless the same heuristic was also queried at time $t-1$. This is related to Bandit Learning against memory bounded adversaries (Arora et al., 2012). We show how to achieve regret of $O(\\text{OPT}^{2/3})$ and prove a tight lower bound based on the construction of Dekel et al. (2013).",
    "citationCount": 0,
    "referenceCount": 47
}