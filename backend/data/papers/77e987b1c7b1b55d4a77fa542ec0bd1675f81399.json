{
    "paperId": "77e987b1c7b1b55d4a77fa542ec0bd1675f81399",
    "title": "Leanor: A Learning-Based Accelerator for Efficient Approximate Nearest Neighbor Search via Reduced Memory Access",
    "year": 2024,
    "venue": "Design Automation Conference",
    "authors": [
        "Yi Wang",
        "Huan Liu",
        "Jianan Yuan",
        "Jiaxian Chen",
        "Tianyu Wang",
        "Chenlin Ma",
        "Rui Mao"
    ],
    "doi": "10.1145/3649329.3657357",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/77e987b1c7b1b55d4a77fa542ec0bd1675f81399",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Approximate Nearest Neighbor Search (ANNS) is a classical problem in data science. ANNS is both computationally-intensive and memory-intensive. As a typical implementation of ANNS, Inverted File with Product Quantization (IVFPQ) has the properties of high precision and rapid processing. However, the traversal of non-nearest neighbor vectors in IVFPQ leads to redundant memory accesses. This significantly impacts retrieval efficiency. A promising approach involves the utilization of learned indexes, leveraging insights from data distribution to optimize search efficiency. Existing learned indexes are primarily customized for low-dimensional data. How to tackle ANNS in high-dimensional vectors is a challenging issue. This paper introduces Leanor, a learned-index-based accelerator for the filtering of non-nearest neighbor vectors within the IVFPQ framework. Leanor minimizes redundant memory access, thereby enhancing retrieval efficiency. Leanor incorporates a dimension reduction component, mapping vectors to one-dimensional keys and organizing them in a specific order. Subsequently, the learned index leverages this ordered representation for rapid predictions. To enhance result accuracy, we conduct a thorough analysis of model errors and introduce a specialized index structure named Learned Index Forest (LIF). The experimental results show that, compared to representative approaches, Leanor can effectively filter out non-neighboring vectors within IVFPQ, leading to a substantial enhancement in retrieval efficiency.",
    "citationCount": 2,
    "referenceCount": 17
}