{
    "paperId": "555b889cf3a41368561ea87a58ec099ad8490c49",
    "title": "MAGIC: Memory Advanced General Index Compression for Learned Indexes",
    "year": 2024,
    "venue": "2024 Sixth International Conference on Next Generation Data-driven Networks (NGDN)",
    "authors": [
        "Na Guo",
        "Yaqi Wang",
        "Xiufeng Xia"
    ],
    "doi": "10.1109/NGDN61651.2024.10744056",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/555b889cf3a41368561ea87a58ec099ad8490c49",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "With the continuous evolution of data-driven networks, storage optimization has emerged as a critical challenge for achieving efficient data management and real-time queries. Storage optimization, employing techniques such as data compression, deduplication, and redundancy elimination, aims to reduce storage requirements, thereby enhancing overall storage efficiency. Learned indexes play a pivotal role in data-driven networks, utilizing learning algorithms to identify frequently queried data and hotspots. This optimization contributes to the refinement of index design, ultimately boosting query performance. While learned indexes have achieved lower memory consumption compared to traditional indexes, their unstable memory overhead limits their applicability in large-scale networks.To address this challenge, this paper introduces a framework for learned index memory compression. The framework presents both lossy and lossless parameter compression strategies tailored to two types of learned index structures: data-based and range-based. Lossless parameter compression seeks to reduce the memory consumption of the index with minimal impact on query performance. In contrast, lossy parameter compression further diminishes memory consumption by sacrificing a certain degree of query performance. These two strategies provide flexible choices for storage optimization, allowing for an ideal balance in different application scenarios. Extensive experiments on synthetic and real datasets demonstrate that both lossless and lossy compression techniques can significantly reduce the memory consumption of learned indexes by up to 98.88% and 96.3%, respectively, with a maximum loss of query performance limited to 2.081% and 20.6%.",
    "citationCount": 0,
    "referenceCount": 22
}