{
    "paperId": "7b1b8733a3720a2f988119daeb952a121a9b9528",
    "title": "Online bipartite matching with imperfect advice",
    "year": 2024,
    "venue": "International Conference on Machine Learning",
    "authors": [
        "Davin Choo",
        "Themis Gouleakis",
        "Chun Kai Ling",
        "Arnab Bhattacharyya"
    ],
    "doi": "10.48550/arXiv.2405.09784",
    "arxivId": "2405.09784",
    "url": "https://www.semanticscholar.org/paper/7b1b8733a3720a2f988119daeb952a121a9b9528",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We study the problem of online unweighted bipartite matching with $n$ offline vertices and $n$ online vertices where one wishes to be competitive against the optimal offline algorithm. While the classic RANKING algorithm of Karp et al. [1990] provably attains competitive ratio of $1-1/e>1/2$, we show that no learning-augmented method can be both 1-consistent and strictly better than $1/2$-robust under the adversarial arrival model. Meanwhile, under the random arrival model, we show how one can utilize methods from distribution testing to design an algorithm that takes in external advice about the online vertices and provably achieves competitive ratio interpolating between any ratio attainable by advice-free methods and the optimal ratio of 1, depending on the advice quality.",
    "citationCount": 3,
    "referenceCount": 51
}