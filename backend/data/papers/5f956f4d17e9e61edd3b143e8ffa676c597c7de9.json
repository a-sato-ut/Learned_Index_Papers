{
    "paperId": "5f956f4d17e9e61edd3b143e8ffa676c597c7de9",
    "title": "On Approximability of â„“22 Min-Sum Clustering",
    "year": 2024,
    "venue": "arXiv.org",
    "authors": [
        "S. KarthikC.",
        "Euiwoong Lee",
        "Y. Rabani",
        "Chris Schwiegelshohn",
        "Samson Zhou"
    ],
    "doi": "10.48550/arXiv.2412.03332",
    "arxivId": "2412.03332",
    "url": "https://www.semanticscholar.org/paper/5f956f4d17e9e61edd3b143e8ffa676c597c7de9",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The $\\ell_2^2$ min-sum $k$-clustering problem is to partition an input set into clusters $C_1,\\ldots,C_k$ to minimize $\\sum_{i=1}^k\\sum_{p,q\\in C_i}\\|p-q\\|_2^2$. Although $\\ell_2^2$ min-sum $k$-clustering is NP-hard, it is not known whether it is NP-hard to approximate $\\ell_2^2$ min-sum $k$-clustering beyond a certain factor. In this paper, we give the first hardness-of-approximation result for the $\\ell_2^2$ min-sum $k$-clustering problem. We show that it is NP-hard to approximate the objective to a factor better than $1.056$ and moreover, assuming a balanced variant of the Johnson Coverage Hypothesis, it is NP-hard to approximate the objective to a factor better than 1.327. We then complement our hardness result by giving a nearly linear time parameterized PTAS for $\\ell_2^2$ min-sum $k$-clustering running in time $O\\left(n^{1+o(1)}d\\cdot \\exp((k\\cdot\\varepsilon^{-1})^{O(1)})\\right)$, where $d$ is the underlying dimension of the input dataset. Finally, we consider a learning-augmented setting, where the algorithm has access to an oracle that outputs a label $i\\in[k]$ for input point, thereby implicitly partitioning the input dataset into $k$ clusters that induce an approximately optimal solution, up to some amount of adversarial error $\\alpha\\in\\left[0,\\frac{1}{2}\\right)$. We give a polynomial-time algorithm that outputs a $\\frac{1+\\gamma\\alpha}{(1-\\alpha)^2}$-approximation to $\\ell_2^2$ min-sum $k$-clustering, for a fixed constant $\\gamma>0$.",
    "citationCount": 3,
    "referenceCount": 80
}