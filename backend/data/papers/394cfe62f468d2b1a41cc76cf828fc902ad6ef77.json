{
    "paperId": "394cfe62f468d2b1a41cc76cf828fc902ad6ef77",
    "title": "Indices Matter: Learning to Index for Deep Image Matting",
    "year": 2019,
    "venue": "IEEE International Conference on Computer Vision",
    "authors": [
        "Hao Lu",
        "Yutong Dai",
        "Chunhua Shen",
        "Songcen Xu"
    ],
    "doi": "10.1109/ICCV.2019.00336",
    "arxivId": "1908.00672",
    "url": "https://www.semanticscholar.org/paper/394cfe62f468d2b1a41cc76cf828fc902ad6ef77",
    "isOpenAccess": true,
    "openAccessPdf": "https://digital.library.adelaide.edu.au/dspace/bitstream/2440/126124/3/hdl_126124.pdf",
    "publicationTypes": [
        "JournalArticle",
        "Conference"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "We show that existing upsampling operators can be unified using the notion of the index function. This notion is inspired by an observation in the decoding process of deep image matting where indices-guided unpooling can often recover boundary details considerably better than other upsampling operators such as bilinear interpolation. By viewing the indices as a function of the feature map, we introduce the concept of 'learning to index', and present a novel index-guided encoder-decoder framework where indices are self-learned adaptively from data and are used to guide the pooling and upsampling operators, without extra training supervision. At the core of this framework is a flexible network module, termed IndexNet, which dynamically generates indices conditioned on the feature map. Due to its flexibility, IndexNet can be used as a plug-in applying to almost all off-the-shelf convolutional networks that have coupled downsampling and upsampling stages. We demonstrate the effectiveness of IndexNet on the task of natural image matting where the quality of learned indices can be visually observed from predicted alpha mattes. Results on the Composition-1k matting dataset show that our model built on MobileNetv2 exhibits at least 16.1% improvement over the seminal VGG-16 based deep matting baseline, with less training data and lower model capacity. Code and models have been made available at: https://tinyurl.com/IndexNetV1.",
    "citationCount": 189,
    "referenceCount": 54
}