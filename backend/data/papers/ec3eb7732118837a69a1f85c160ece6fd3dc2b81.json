{
    "paperId": "ec3eb7732118837a69a1f85c160ece6fd3dc2b81",
    "title": "ML-native Dataplane Operating Systems",
    "year": 2025,
    "venue": "Proceedings of the 16th ACM SIGOPS Asia-Pacific Workshop on Systems",
    "authors": [
        "I. Choi",
        "Anand Bonde",
        "Jing Liu",
        "Joshua Fried",
        "Irene Zhang",
        "Jialin Li"
    ],
    "doi": "10.1145/3725783.3764392",
    "arxivId": null,
    "url": "https://www.semanticscholar.org/paper/ec3eb7732118837a69a1f85c160ece6fd3dc2b81",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "Book"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Engineering",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "Performance tuning has never been more critical in modern datacenters, where rapid advances in networking and I/O speeds expose potential bottlenecks in CPUs, memory, and operating systems. Yet, tuning remains notoriously complex, brittle, and opaque, especially at the microsecond-scale latencies demanded by modern dataplanes. We argue that there is a pressing need to unleash the power of machine learning in datacenter operating systems. We propose ML-native Dataplane Operating Systems, a radical design for ML-based performance tuning. Our design embraces real-time, microsecond-scale ML-based adaptation as a foundational principle, treating ML not as a byproduct but as the backbone, to continuously optimize dataplane performance under dynamic workloads and operating conditions. Our preliminary experiments show that a traditional static dataplane OS incurs severe queuing delays (over milliseconds) under dynamic and parallel workloads, whereas our adaptive approach sustains microsecond-scale tail latencies by dynamically tuning OS parameters in response to runtime signals.",
    "citationCount": 0,
    "referenceCount": 7
}