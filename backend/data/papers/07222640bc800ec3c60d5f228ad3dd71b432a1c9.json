{
    "paperId": "07222640bc800ec3c60d5f228ad3dd71b432a1c9",
    "title": "On Tradeoffs in Learning-Augmented Algorithms",
    "year": 2025,
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "authors": [
        "Ziyad Benomar",
        "Vianney Perchet"
    ],
    "doi": "10.48550/arXiv.2501.12770",
    "arxivId": "2501.12770",
    "url": "https://www.semanticscholar.org/paper/07222640bc800ec3c60d5f228ad3dd71b432a1c9",
    "isOpenAccess": false,
    "openAccessPdf": "",
    "publicationTypes": [
        "JournalArticle"
    ],
    "s2FieldsOfStudy": [
        {
            "category": "Computer Science",
            "source": "external"
        },
        {
            "category": "Computer Science",
            "source": "s2-fos-model"
        },
        {
            "category": "Mathematics",
            "source": "s2-fos-model"
        }
    ],
    "abstract": "The field of learning-augmented algorithms has gained significant attention in recent years. These algorithms, using potentially inaccurate predictions, must exhibit three key properties: consistency, robustness, and smoothness. In scenarios where distributional information about predictions is available, a strong expected performance is required. Typically, the design of these algorithms involves a natural tradeoff between consistency and robustness, and previous works aimed to achieve Pareto-optimal tradeoffs for specific problems. However, in some settings, this comes at the expense of smoothness. This paper demonstrates that certain problems involve multiple tradeoffs between consistency, robustness, smoothness, and average performance.",
    "citationCount": 4,
    "referenceCount": 41
}