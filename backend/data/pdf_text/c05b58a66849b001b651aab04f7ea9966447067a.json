{
  "paperId": "c05b58a66849b001b651aab04f7ea9966447067a",
  "title": "SSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index",
  "pdfPath": "c05b58a66849b001b651aab04f7ea9966447067a.pdf",
  "text": "arXiv:2505.24312v1  [cs.DB]  30 May 2025SSCard: Substring Cardinality Estimation using Suffix\nTree-Guided Learned FM-Index\nYirui Zhan\nPeking University\nBeijing, China\nzhanyirui@stu.pku.edu.cnWen Nie\nHuawei Company\nBeijing, China\nniewen2@huawei.comJun Gao\nPeking University\nBeijing, China\ngaojun@pku.edu.cn\nAbstract\nAccurate cardinality estimation of substring queries, which are\ncommonly expressed using the SQL LIKE predicate, is crucial for\nquery optimization in database systems. While both rule-based\nmethods and machine learning-based methods have been devel-\noped to optimize various aspects of cardinality estimation, their\nabsence of error bounds may result in substantial estimation errors,\nleading to suboptimal execution plans. In this paper, we propose\nSSCard, a novel SubString Card inality estimator that leverages a\nspace-efficient FM-Index into flexible database applications. SSCard\nfirst extends the FM-Index to support multiple strings naturally,\nand then organizes the FM-index using a pruned suffix tree. The\nsuffix tree structure enables precise cardinality estimation for short\npatterns and achieves high compression via a pushup operation,\nespecially on a large alphabet with skewed character distributions.\nFurthermore, SSCard incorporates a spline interpolation method\nwith an error bound to balance space usage and estimation accuracy.\nAdditional innovations include a bidirectional estimation algorithm\nand incremental update strategies. Extensive experimental results\nin five real-life datasets show that SSCard outperforms both tradi-\ntional methods and recent learning-based methods, which achieves\nan average reduction of 20% in the average q-error, 80% in the max-\nimum q-error, and 50% in the construction time, compared with\nsecond-best approaches.\nCCS Concepts\nâ€¢Information systems â†’DBMS engine architectures .\nKeywords\ncardinality estimation, substring query, learned estimator, query\noptimization\nACM Reference Format:\nYirui Zhan, Wen Nie, and Jun Gao. 2025. SSCard: Substring Cardinality\nEstimation using Suffix Tree-Guided Learned FM-Index. In Proceedings of\nProc. ACM Manag. Data (SIGMOD). ACM, New York, NY, USA, 15 pages.\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nSIGMOD,\nÂ©2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-x-xxxx-xxxx-x/YY/MM\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn1 Introduction\nAn effective query optimizer is a key factor in the success of a\ndatabase management system (DBMS), and accurate cardinality\nestimation results are fundamental for the optimizer to select the ef-\nficient plan. While substantial progress has been made in cardinality\nestimation [ 4,5,23,36,45], existing research has primarily focused\non numerical data, leaving textual data relatively understudied.\nIn this paper, we focus on estimating the substring cardinalities ,\nwhich are widely used for queries in textual data. For example, the\npredicate conference LIKE %SIGMOD% in a SQL query returns all\nrows with the column â€œ conference â€˜â€™ that contains â€œ SIGMOD â€ as a\nsubstring, regardless of the year or place where the conference is\nheld. This statement is widely used in real-life scenarios or query\nbenchmarks, as in the Join Order Benchmark [ 34], there are 81 out\nof 113 queries containing LIKE statements.\nTraditional methods choose suffix tree [ 21,30],ğ‘˜-gram [ 33] or\nhistograms [ 2] as summary data structures to support substring car-\ndinality estimation. While achieving precise results for short query\nstrings, they often depend on statistical assumptions when process-\ning long strings. For example, pruned suffix tree methods [ 21,30]\nassume that the probabilities of strings divided from the long query\nstring are independent, and the cardinality of the long string is com-\nputed as the total number of rows multiplied by the product of these\nprobabilities. Things are similar to the ğ‘˜-gram-based methods [ 33].\nFor strings longer than ğ‘˜, estimations are performed on the com-\nbined results of divided strings assuming individual distributions.\nAlthough these approaches are easy to interpret, accuracy drops\nsignificantly when the assumptions deviate significantly from the\nactual distribution of substring patterns.\nWith the rise of deep learning for database systems [ 7,40,49],\nlearning-based methods are used for cardinality estimation in string\nqueries [ 2,3,31,43,47,48]. They can be roughly divided into\ntwo categories, encoding the underlying data string and encoding\nthe pattern string. The former approaches attempt to capture the\ndistribution of substrings in embeddings, from which the cardinality\ncan be further learned [ 43]. The latter approaches, including the\nmost recent work [ 3], tend to directly predict the cardinality of\npatterns using the sequence model [ 2,3,31,47,48]. Learning-based\nmethods are better suited for handling large volumes of data, as\nthey can benefit from additional training data without requiring\nan increase in model size. However, they cannot provide error\nbounds for the cardinality estimation. Their performance may also\nbe severely affected when the model is not fully trained due to the\nlimited samples or the vast combination space with a large alphabet.\nThe string index to support substring occurrences has been ex-\ntensively studied in other domains [ 6,11,22,38], especially in\nbioinformatics [ 9,10]. Among these, FM-Index [ 11] is an interesting\n\nSIGMOD, Trovato et al.\nstructure which should receive more attention in the database field.\nAn FM-Index contains the Burrows-Wheeler transform (BWT) [ 6]\nof the input data and some auxiliary data structures, offering two\nkey advantages: i) high compressibility, as the BWT tends to group\ntogether characters which appears in similar text strings, and ii)\nsupport for arbitrary-length query strings, via the backward search\nalgorithm of BWT. These features align well with the requirements\nof substring cardinality estimation in DBMSs, where both space\nefficiency and flexible query capabilities are critical.\nHowever, substantial extensions to the FM-Index are required to\neffectively support substring cardinality estimation in DBMS. First,\nFM-Index is primarily designed for indexing a single long string,\nlike a DNA sequence [ 8,35,44], while DBMS needs to process\nmultiple various length strings. One straightforward approach is\nto process these strings in parallel, but this significantly increases\nthe time required for cardinality estimation.\nSecond, the extra structure in the FM-Index actually consumes\nhuge space cost, especially when the underlying alphabet set is\nlarge [ 12,15]. It divides the BWT into fixed-length segments and\nintroduces additional tables to record the cumulative occurrences\nof each character up to the current offset, eliminating expensive\ntop-down scans. We can see that all characters, whether frequent\nor rare, need to be cached in each segment. Although such an\nissue is not serious in bioinformatics as there are only 4 characters,\nthese costs obviously cannot be ignored when the alphabet set is\nlarge. We notice that for the rare occurrence of a character ğ‘, the\ncached data of ğ‘in different tables are similar, leading us to convert\nthe flat-organized segments into tree-organized segments. Thus,\ncumulative occurrences for rare characters can be recorded in the\nsegment linked from the high-level tree node, which may greatly\nreduce the space for the extra structure.\nThird, the FM-Index can be further reduced in the context of the\ncardinality estimation. A key point is that the estimated cardinality\ncould accept approximate results, which inspires us to use approxi-\nmation methods to fit the linear structure in the BWT. For example,\nwe can leverage learned functions with error bounds [ 13,14,26] to\nfurther compress the BWT.\nIn this paper, we attempt to combine the advantages of the suf-\nfix tree and the learning method to extend FM-Index over string\ncolumns in the database. Our primary contributions are as follows:\nâ€¢We propose SSCard, a SubString Card inality estimator, in-\ncluding i) an enhanced comparator to extend FM-Index to\nmultiple data strings setting naturally; iii) a pruned suffix\ntree to organize the segments in a hierarchical way as well\nas a pushup operation to handle the rare and frequent char-\nacters adaptively; ii) a learned representation with an error\nbound to reduce the space cost.\nâ€¢We devise several operations on SSCard including: i) a space\nand time efficient method to construct SSCard; ii) a bidi-\nrectional cardinality estimation method that combines the\nadvantages of suffix tree and FM-index; iii) incremental up-\ndate strategies to handle data changes. We perform the time,\nspace, and error bounds of cardinality estimation.\nâ€¢We conduct extensive experiments based on five datasets and\nreport results of accuracy, construction time, estimation time,\nand space cost compared to existing state-of-art approaches.The rest of the paper is organized as follows. Section 2 reviews\nthe basic idea of the FM-Index, and then formulates our problem.\nThen we extend the FM-Index to multiple strings, and describe the\nbasic structure of SSCard in Section 3, followed by its construction\nmethod in Section 4, and cardinality estimation as well as incre-\nmental update in Section 5. Section 6 reports experimental results.\nThe related work is reviewed in Section 7, and finally we make a\nconclusion and foresee the future work in Section 8.\n2 Preliminary\nWe first review the preliminary knowledge of the FM-Index and\nBWT, which is the basis for the following discussion, and then\nformulate the problem. The symbols frequently used in this paper\nare shown in Table 1.\n2.1 FM-Index and BWT\nFM-Index [ 11] is a string index which can count or locate the oc-\ncurrences of a substring pattern in a text, and BWT is the basic\nconcept of the FM-Index. As shown in Figure 1, after placing a\nspecial symbol #(#is smaller than any character in Î£) at the end of\nthe text string ğ‘‡=abcabc , BWT creates all its cyclic shifts ğ‘ğ‘ (ğ‘‡)\n(rotating the first character to the end |ğ‘‡|times) and sorts them in\nlexicographical order, forming a conceptual matrix M[6].\nğ‘‡=abcabc#ab1cab2c#\n#ab1cab2c\nc#ab1cab2\nb2c#ab1ca\nab2c#ab1c\ncab2c#ab1\nb1cab2c#acb2acb1a#1\ncb1a#cb2a2\n#cb2acb1a3\nacb1a#cb24\na#cb2acb15\nb2acb1a#c6\nb1a#cb2ac7F L ğ‘ğ‘ (ğ‘‡) â„³\nFigure 1: Burrows-Wheeler Transform.\nThe output of BWT are the ğ¹andğ¿-array, which are extracted\nfrom the first and last columns of M. Operations on the BWT do\nnot rely on the middle parts (gray area in Figure 1), which can\nbe discarded directly. The ğ¹andğ¿-array have the following two\nproperties:\n(1)In theğ‘–-th row,ğ¿[ğ‘–]represents the preceding character of\nğ¹[ğ‘–]inğ‘‡, e.g.ğ‘‡=Â·Â·Â·ğ¿[ğ‘–]ğ¹[ğ‘–]Â·Â·Â·.\n(2)Theğ‘–-th occurrence of a character ğ‘in theğ¿-array is the\nsame as the ğ‘–-th occurrence of ğ‘in theğ¹-array.\nProperty 1 is straightforward, while Property 2 is detailed in\nFigure 1. To clarify the ordering of the character bin the text string\nğ‘‡, we add subscripts to distinguish its two occurrences, labeled as\nb1andb2. In theğ¹-array, b2appears before b1, which is consistent\nwith their order in the ğ¿-array. This consistency arises from the\nsame sorting context: the substring following a character in the\nğ¹-array is the same as the substring preceding the character in the\nğ¿-array. More formal proof can be found in [ 6]. This property is\nthe key to counting the occurrences of patterns in ğ‘‡.\nThe BWT-based pattern counting is based on two core functions,\nin whichğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)returns the count of occurrences of ğ‘inğ¿[1...ğ‘–],\nandğ‘‚ğ‘ğ‘(ğ‘)is the position of the first occurrence of ğ‘inğ¹. Take\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\nFigure 1as an example, ğ‘…ğ‘ğ‘›ğ‘˜(â€˜ğ‘â€™,7)=2, meaning that boccurs\ntwice inğ¿[1...7], andğ‘‚ğ‘ğ‘(â€˜ğ‘â€™)=6, since cfirst appears in ğ¹[6].\nThe occurrences of a pattern ğ‘ƒcan be counted with these two\nstructures in a backward manner [ 11]. Take an example of pattern\nğ‘ƒ=abc. We first locate the index range [ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘,ğ‘’ğ‘›ğ‘‘ğ‘]forcin the\nğ¹-array. As the same characters are consecutive in the ğ¹-array,\nğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘=6andğ‘’ğ‘›ğ‘‘ğ‘=7can be computed efficiently. According to\nproperty 1, the character preceding cis stored in the same row of\ntheğ¿-array, which means that the occurrences of bcinğ‘‡are the\nsame as the occurrences of binğ¿[6...7]. This can be calculated\nbyğ¿.ğ‘…ğ‘ğ‘›ğ‘˜(â€˜ğ‘â€™,6)=1, andğ¿.ğ‘…ğ‘ğ‘›ğ‘˜(â€˜ğ‘â€™,7)=2. Then, to count the\noccurrences of abc, we can apply property 2 to locate the index\nrange of bcin theğ¹-array. That is, ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘ğ‘=4andğ‘’ğ‘›ğ‘‘ğ‘ğ‘=5\nasğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ğ‘ğ‘=ğ‘‚ğ‘ğ‘(â€˜ğ‘â€™)+ğ¿.ğ‘…ğ‘ğ‘›ğ‘˜(â€˜ğ‘â€™,6)âˆ’1andğ‘’ğ‘›ğ‘‘ğ‘ğ‘=ğ‘‚ğ‘ğ‘(â€˜ğ‘â€™)+\nğ¿.ğ‘…ğ‘ğ‘›ğ‘˜(â€˜ğ‘â€™,7)âˆ’1. Hence we further detect ainğ¿[4...5], and two\noccurrences can be found by taking the same process above. Finally,\nwe can conclude that there are 2 occurrences of the pattern ğ‘ƒ=\nabcinğ‘‡. The time complexity for counting the occurrences of the\npatternğ‘ƒisğ‘‚(|ğ‘ƒ|), assuming constant-time implementations of\nbothğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)andğ‘‚ğ‘ğ‘(ğ‘).\nThe FM-index implements ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)andğ‘‚ğ‘ğ‘(ğ‘)efficiently, but\nwith relatively high space cost. ğ‘‚ğ‘ğ‘(ğ‘)can be compressed into a\n|Î£|-sized array as the characters in the ğ¹-array are lexicographically\nsorted. Forğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–), a straightforward approach requires scanning\nall preceding characters. In order to lower the scanning cost, the\nFM-Index divides ğ¿into large segments of size log2|ğ‘‡|, each of\nwhich is further divided into smaller segments of size log|ğ‘‡|. With\nthe cumulative occurrences recorded in additional tables for these\ntwo segments, ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)can be implemented in ğ‘‚(1)time.\n2.2 Problem Formulation\nGiven an underlying data string set Dover an alphabet Î£, and any\npattern string ğ‘ƒ(ğ‘ƒâˆˆÎ£âˆ—), the cardinality of ğ‘ƒreturns the number\nof strings inDthat contain ğ‘ƒas a substring. Note that, unlike\ncounting total occurrences in a single string, each string ğ·âˆˆD is\ncounted at most once in the context of a DBMS, even if ğ‘ƒappears\nmultiple times in ğ·.\n3 SSCard\nIn this section, we first discuss how to extend the FM-Index to\nmultiple underlying data strings, and then present the data structure\nof SSCard.\n3.1 Extension of the FM-Index to Multiple\nStrings\nThe extensions to multiple strings are not straightforward. One sim-\nple method is to apply BWT to all strings concatenated with special\nsymbols. However, such a method requires high construction cost\nin sorting suffixes, and the final ğ¹andğ¿-array contains unnecessary\npatterns crossing special symbols. Another option is to leverage\nBWT for each string separately. The major issue lies in the fact that\neach FM-Index created by a single string has to be scanned during\nestimation, leading to high cost even with parallelization.\nHere, we expect to extend BWT on multiple strings naturally.\nThat is, we first build all the cyclic shifts ğ‘ğ‘ (ğ·ğ‘–)for each string\nğ·ğ‘–âˆˆD( 1â‰¤ğ‘–â‰¤|D|) separately, and then merge them together,Table 1: Frequently used symbols\nSymbols Meaning\nD a data string setD\nP a pattern string set P\nğ‘› the number of strings in D, same as|D|\nğ‘š the maximum length of strings in D\nğ‘ƒ,ğ· a patternğ‘ƒâˆˆP against a data string ğ·âˆˆD\nÎ£ the alphabet set Î£\nâ„ the height of the pruned suffix tree\nğ‘™ the length of a segment linked to a suffix tree node\nğ‘ğ‘š the minimum # of identical-character ğ¿-triples in a\nsegment\nğœ– error bound\nresulting in a sorted list. As shown in Figure 2, the ğ¹-array and\nğ¿-array are derived from the first and last characters of the list,\nrespectively. Unlike in the case of the single string, the sorted cyclic\nshifts may have varying lengths, which requires us to examine\nwhether the two properties discussed in Section 2.1 still hold.\nabc\nabbc\nbbbca\nbcabc#abc\nabc#\nbc#a\nc#ab\n#abbc\nabbc#\nbbc#a\nbc#ab\nc#abb\n#bbbca\na#bbbc\nbbbca#\nbbca#b\nbca#bb\nca#bbb\n#bcabc\nabc#bc\nbc#bca\nbcabc#\nc#bcab\ncabc#bc1bba#1\n#cbba6\na#cbb10#cba7acbbb#3\ncbbb#a5\n#acbbb9\nb#acbb11\nbb#acb15\nbbb#ac20cbacb#4\ncb#cba8\nacb#cb14\n#cbacb16\nbacb#c19\nb#cbac21F L\nc2ba#2\nb1ba#c117\nb2a#c218ba#cb112\na#cb21312\nFigure 2: Extension of the BWT to multiple strings.\nIt is easy to see that Property 1 still holds, as in the ğ‘–-th row,ğ¹[ğ‘–]\nandğ¿[ğ‘–]are the first and last characters of the same rotation, but\nProperty 2 may not always be preserved. We can see an example\nin Figure 2. In the 12-th and 13-th rows, there is no explicit lexi-\ncographical order between the string bc#a andbc#ab . When we\nplace these strings randomly, they obviously violate Property 2. A\nsimilar issue arises with c#abb in the 17-th row and c#ab in the\n18-th row. These cases indicate that lexicographical sorting alone\nis insufficient to preserve Property 2.\nBefore delving into the details, we introduce a sorting order be-\ntween two strings. Without loss of generality, let ğ‘‡1andğ‘‡2be two\nstrings with ğ‘‡1shorter than ğ‘‡2.ğ‘‡1andğ‘‡2follow the lexicograph-\nical order ifğ‘‡1is not the prefix of ğ‘‡2. Otherwise, if ğ‘‡1is a prefix\nofğ‘‡2, we iteratively rotate both strings simultaneously ğ‘˜times to\nobtainğ‘‡â€²\n1andğ‘‡â€²\n2untilğ‘‡â€²\n1is no longer a prefix of ğ‘‡â€²\n2for the first\ntime. The lexicographical order between ğ‘‡â€²\n1andğ‘‡â€²\n2is then defined\n\nSIGMOD, Trovato et al.\nas the first rotation-based lexicographical order ofğ‘‡1andğ‘‡2. It\nis easy to know that ğ‘˜is limited, since we place a special symbol #\n(#is smaller than any character in Î£) at the end of the each string,\nandğ‘‡1andğ‘‡2have different lengths.\nTo satisfy Property 2, the substrings following a character ğ‘in the\nğ¹-array must preserve the same order as the substrings preceding\nğ‘in theğ¿-array. We therefore focus on the case where two strings\nbegin with the same character ğ‘. Letğ‘‡1=ğ‘ğ´andğ‘‡2=ğ‘ğµ, where\nğ´andğµare the substrings following ğ‘inğ‘‡1andğ‘‡2, respectively.\nThe problem then reduces to finding an enhanced comparator, in\nwhich the order of ğ‘ğ´andğ‘ğµmatches that of ğ´ğ‘andğµğ‘. We can\nsee that when this condition holds, the order of the occurrences of\nğ‘inğ¹-array is consistent with that in the ğ¿-array.\nWe perform a detailed analysis between two strings ğ‘‡1=ğ‘ğ´and\nğ‘‡2=ğ‘ğµ, in which the relationship between ğ´andğµmust fall into\none of the following cases:\n(1)ğ´is not a prefix of ğµ: In this case, the lexicographical order\nbetweenğ‘ğ´andğ‘ğµis consistent with that between ğ´ğ‘and\nğµğ‘. For example, the 17-th and 19-th rows can be sorted\nexplicitly, and their order is consistent with that between\nthe1-st and 4-th rows.\n(2)ğ´is a prefix of ğµ, but not equal to ğµ: In such a case, we\napply the first rotation-based lexicographical order of ğ´and\nğµ. For example, the order of the 12-th and 13-th rows can be\ndetermined by that of the 17-th and 18-th rows, which can\nbe determined further by the 1-st and 2-nd rows. The ratio-\nnale can be explained in reverse: the 1-st and 2-nd rows are\ndirectly comparable lexicographically. To preserve Property\n2, the starting characters c1andc2in the 17-th and 18-th\nrows should follow the same order as the ending characters\nin the 1-st and 2-nd rows. Likewise, the 12-th and 13-th rows\nare ordered in the same manner.\n(3)ğ´is the same as ğµ: This case occurs when the two data strings\nare exactly the same. As the lexicographical order can place\nthese strings contiguously in both the ğ¹andğ¿-array, such a\ncase does not violate Property 2.\nFrom the above analysis, we conclude that the enhanced comparatorâ€”\ncombining the first rotation-based lexicographical order for pre-\nfix cases with the standard lexicographical order for other casesâ€”\nallows us to correctly handle cyclic shifts of all data strings, ensuring\ncompliance with Property 2. This approach offers a practical way\nto convert variable length strings into an extended BWT, on which\nboth properties hold and standard FM-Index operations can be per-\nformed. We leave the detailed construction of the extended BWT\nin the following section.\n3.2 Overview of SSCard\nSSCard proposed in this paper is based on the FM-Index but employs\ndifferent auxiliary data structures. We illustrate SSCard in Figure 3\nusing the same example in Figure 2. We can see that a pruned suffix\ntree (a tree with a height restriction) is used to represent ğ¹and also\norganizing the segments of ğ¿(Figure 3c). The segments are further\nrepresented by learned functions (Figure 3d).\nBefore delving into the structure for the ğ¹andğ¿-array, we first\ndefine theğ‘–-thğ¿-triple. Recall that the ğ¿-array in BWT is an ğ‘‚(ğ‘›ğ‘š)-\nsized character array, which implicitly reveals (ğ‘,ğ‘–,ğ‘Ÿ)indicatingthe character ğ‘in theğ‘–-th row being the ğ‘Ÿ-th occurrences. The in-\ntroduction of the ğ¿-triple carries the information explicitly, thereby\neliminating the need to store characters in the ğ¿-array sequentially\nand allowing them to be put in different places in the following.\nDefinition 1. theğ‘–-thğ¿-triple. Given theğ¿-array in BWT. The\nğ‘–-thğ¿-triple takes the form of (ğ¿[ğ‘–],ğ‘–,ğ‘Ÿ), whereğ‘Ÿis the rank (i.e., the\nnumber of prior occurrences) of ğ¿[ğ‘–]in theğ¿-array.\nWe next describe the structure of the pruned suffix tree for the\nğ¹-array, the pushup operation for ğ¿-triples in the pruned suffix tree,\nand the learned representation for the ğ¿-array.\nPruned Suffix Tree for ğ¹.In the FM-Index, the middle characters\nbetween the ğ¹-array andğ¿-array are removed, and the ğ¹-array\ncan be further compressed into a |Î£|-sized array. Through space\nefficiency, the ğ¹-array contains limited information. Since rows\nsharing the same prefix are adjacent in M, we can use a suffix tree\nto representM. However, a complete suffix tree takes up too much\nspace. Thus, we construct a pruned version taking only the first few\ncolumns ofM, subject to three constraints (detailed in Section 4.1).\nIn this way, ğ¿is divided into segments of ğ¿-triples and linked to\nleaf nodes in the suffix tree.\nThe pruned suffix tree not only organizes segments of ğ¿-triples\nin a hierarchical way, but introduces another advantage: estimating\ncardinalities independently and precisely. Specifically, each tree\nnodeğ‘¢can be annotated with the number of strings in Dthat\nmatch the path from the root to ğ‘¢, so as to provide the cardinality\nfor these patterns directly. In addition, we organize the segments\nby linking them to suffix tree nodes, enabling hierarchical searches\nand on-demand loading, which reduces access latency to segments.\nIn all, for each node ğ‘¢in the suffix tree, it is annotated with\n(ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ ,ğ‘’ğ‘›ğ‘‘,ğ‘ğ‘›ğ‘¡,ğ‘™ğ‘–ğ‘›ğ‘˜).ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ andğ‘’ğ‘›ğ‘‘are for the index intervals in\ntheğ¹-array (and also the ğ¿-array) with the same prefix from root\ntoğ‘¢.ğ‘ğ‘›ğ‘¡is for the cardinality of the pattern string from root to ğ‘¢,\nwhich can estimate the cardinality directly. ğ‘™ğ‘–ğ‘›ğ‘˜ is for the link from\nthe suffix tree nodes to the ğ¿-triple segments. Take Figure 3c as an\nexample,(2,16,3)in node 7indicates that the index interval in M\nspans from 12 to 16 (inclusive), and the cardinality of string ğ‘ğ‘is3.\nThe linkedğ¿-triples are illustrated in green boxes.\nThe Pushup Operation. To improve space efficiency in organiz-\ningğ¿-triples in the suffix tree, we introduce the pushup operation.\nSince the cumulative occurrences of rare characters may be dupli-\ncated across multiple FM-Index segments, the suffix tree provides\na chance to construct segments in a hierarchical way to reduce\nthis redundancy. As the ğ¿-triples explicitly carry all required at-\ntributes, rare ğ¿-triples can be pushed up to the segments linked\nto higher-level tree nodes, where learned functions are built over\nconsolidated occurrences rather than separately for each one. For\nexample, the 16-thğ¿-triple is not linked to the node 7, but to the\nnode 4in Figure 3. We will further discuss the pushup operation in\nSection 4.1.\nLearned Representation for ğ¿.In contrast to FM-Index, SSCard\nuses functions to represent the distribution of ğ¿-triples (Figure 3d).\nSupposeğ‘†be a segment of ğ¿-triples, SSCard groups ğ‘†according to\ndifferent characters in the nodes. For each character ğ‘, SSCard learns\na functionğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)to returnğ‘Ÿas the number of occurrences of ğ‘\nup toğ‘–. We expect that such a representation can further compress\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\na1cbbb#3c1bba#1\nc2ba#2\nb8#cbac21â€¦ â€¦\nc3c2c11 42\nc5c45 8\n#2#16 7#a b\nb cc1:(1,21,4)\n2:(1,4,4) 5:(17,21,4)\n6:(9,11,2)3:(5,8,4)\n7:(12,16,3)4:(9,16,4) abc\nabbc\nbbbca\nbcabcF L\nData stringsMultiple strings \nBWTBuilding the \nPruned Suffix Tree\n1 23 4123\nidxcâ€™s rankLearned \nRepresentationğ‘¢:(ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘’ğ‘›ğ‘‘,ğ‘ğ‘›ğ‘¡) ğ‘à¯¥ğ‘–\nSuffix tree node: L-triple:\n(c) (d) (a) (b)Segments of L-triple\nerror2:(1,4,4)Suffix tree edge: Link to segments:\na4a313 14\nb3b212 15#4#39 16\nb8b7b6b5b417 1918 20 21a2a13 10\nb111\nc3c2c11 42\nFigure 3: An illustration of SSCard with â„=2 andğ‘ğ‘š=2(The meanings of the symbols are in Table 1)\nthe space requirement for the ğ¿-array, as multiple ğ¿-triples are\ncompressed into a single learned function.\nLike the FM-Index, SSCard should support ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)andğ‘‚ğ‘ğ‘(ğ‘)\nefficiently.ğ‘‚ğ‘ğ‘(ğ‘)is actually the ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ value of the child node\nreached by following the edge labelled ğ‘from the root, denoted\nasğ‘‡[ğ‘].ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ . To compute ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–), we start from the root and\nrecursively locate the child node ğ‘¢such thatğ‘–âˆˆ[ğ‘¢.start,ğ‘¢.end],\ncontinuing this process until a leaf node is reached. Then run the\nfunctionğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)stored in the leaf-linked segment ğ‘†.\n4 Construction of SSCard\nThe construction of SSCard is roughly divided into two parts. We\nfirst build the pruned suffix tree of SSCard, including locating ğ¿-\ntriples into the segments linked to tree nodes and the pushup oper-\nation. We then construct the learned representations for the rank\norder ofğ¿-triples. Finally, we conduct the space-time analysis of\nthe construction of SSCard.\n4.1 Building the Pruned Suffix Tree for ğ¹\nWe provide a construction method for the data string set Din\nAlgorithm 1. The main function is ğµğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘†ğ‘¢ğ‘“ğ‘“ğ‘–ğ‘¥ _ğ‘‡ğ‘Ÿğ‘’ğ‘’ . The input\nparameters are defined as follows. The first three parameters are the\nconstraints of the pruned suffix tree, where â„limits the maximum\nheight of the tree. The segment size ğ‘™and the minimum number\nofğ¿-triples containing the same character within a segment ğ‘ğ‘š\nprevent constructing small segments with diverse characters. In\naddition, an error bound ğœ€is given for the learned representation\nto balance the estimation accuracy and the space overhead.\nFirst, we need to build the sorted cyclic shifts for all data strings\n(Figure 3b), as shown in line 2. We have different choices to achieve\nthe goal. The existing Ukkonen algorithm [ 46] can construct a suffix\ntree inğ‘‚(ğ‘š)space and time cost for a string of length ğ‘š. Thus, if\nwe concatenate all ğ‘›strings into a single large one, Ukkonen Algo-\nrithm can compute a generalized suffix tree for Dwithğ‘‚(ğ‘›ğ‘š)cost.\nHowever, the suffix tree generated in this way may contain useless\npatterns. Even worse, Ukkonen algorithm does not consider cyclic\nshifts, indicating that the ğ¿-array has to be located with additional\ncostly searching. In this paper, we adopt a straightforward approach\nto sort all the cyclic shifts. We apply radix sort on variable-length\nstrings to obtain the sorted cyclic shifts S, using the previously\ndefined comparator. Note that as explicit storage of all cyclic shifts\ntakesğ‘‚(ğ‘›ğ‘š2)space cost in the worst case, we record the start index\n#a b\nb c2:(1,4,4)\n6:(9,11,2)3:(5,8,4)\n7:(12,16,3)4:(9,16,4)\n#416\nb1a2#39 10 11b1a210 11c\n5:(17,21,4)a2a13 10\nb111\na4a313 14\nb3b212 15#4#39 161:(1,21,4)\nc3c2c11 42\na13Figure 4: An illustration of pushup with â„=2,ğ‘™=5and\nğ‘ğ‘š=2. Theğ¿-triples in node 6 are pushed up to node 4 as\ntheir occurrences are smaller than ğ‘ğ‘š. Similar cases apply to\nthe otherğ¿-triples shown in gray.\nand the length to implicitly represent the cyclic shifts in the space\ncostğ‘‚(ğ‘›ğ‘š).\nIn line 3, we locate the sequence [ğ‘¥[1],...,ğ‘¥[ğ‘›ğ‘š]], where each\nğ‘¥[ğ‘˜]is anğ¿-triple of the form (ğ‘,ğ‘–,ğ‘Ÿ). This sequence can be lo-\ncated by one-time scan with ğ‘‚(ğ‘›ğ‘š)time cost, as the rank or-\nderğ‘Ÿfor eachğ¿-triple can be computed using an extra |Î£|-sized\nstructure in the scan. As shown in Figure 3b, the ğ¿-triples are\n[(c,1,1),(c,2,2),...,(b,21,8)].\nLine 4-7 describe the procedure of constructing the pruned suffix\ntreeğ‘‡. In line 4, we scanSforâ„times, in which the ğ‘–-th level of the\nsuffix tree is constructed in the ğ‘–-th round. At each level, consecutive\nchars inS[ğ‘–]form the nodes in this layer. These character groups\nalso partition the ğ¿-array into segments, which are linked to the\ncorresponding suffix tree nodes and further subdivided in the next\nround. To control the space cost, we keep a suffix tree node only if\nits linked segment contains at least ğ‘™ ğ¿-triples with each identical\ncharacter occurring at least ğ‘ğ‘štimes. Lines 5-7 then perform a\none-time pre-order traversal to record the start/end indexes of\ntheğ¿-array for each tree node and to initialize an |Î£|-sized empty\nbucket listğ‘¢.ğµfor building learned functions. We also annotate\nthe frequency of each prefix at this stage for direct cardinality\nestimation. Take Figure 3c as an example, node 1 is divided into 4\nchildren, corresponding to 4groups of consecutive chars of S[1].\nHowever, only node 4 retains its children as its linked segment\ncontains at least 5ğ¿-triples.\n\nSIGMOD, Trovato et al.\nAlgorithm 1: Building SSCard\nInput: String SetD, the maximum height â„and segment\nsizeğ‘™of the pruned suffix tree, the minimum number\nğ‘ğ‘šofğ¿-triples with the same class in a segment,\nerror bound ğœ–\nOutput: SSCard\n1Function Build_Suffix_Tree(D,â„,ğ‘™):\n2 Build all cyclic shifts SfromDusing the enhanced\ncomparator mentioned in Section 3.1\n3 Derive theğ¿-array using last characters in S\n4 Construct an ordered suffix tree ğ‘‡fromSwith the\nmaximum height â„, and build suffix tree node ğ‘¢when\nğ‘¢â€™s segment contains at least ğ‘™ ğ¿-triples\n5 forğ‘¢âˆˆğ‘‡in a pre-order visit do\n6 Recordğ‘¢â€²ğ‘ start/end indexes in the ğ¿-array, and the\ncardinalityğ‘¢.ğ‘ğ‘›ğ‘¡\n7 Initialize an|Î£|-sized empty bucket list ğ‘¢.ğµforğ‘¢\n8 Traverse_Suffix_Tree( ğ‘‡.ğ‘Ÿğ‘œğ‘œğ‘¡ ,ğ‘ğ‘š,ğœ–)\n9 returnğ‘‡\n10Function Traverse_Suffix_Tree( ğ‘¢,ğ‘ğ‘š,ğœ–):\n11 ifğ‘¢is leaf then\n12 forğ‘–from u.start tou.end do\n13 Put theğ‘–-thğ¿-triple to bucket ğ‘¢.ğµ[ğ¿[ğ‘–]]\n14 forğ‘âˆˆÎ£âˆ§ğ‘¢.ğµ[ğ‘]â‰ âˆ…do\n15 ğ‘¢.ğ‘›ğ‘’ğ‘’ğ‘‘ğµğ‘¢ğ‘–ğ‘™ğ‘‘â†ğ‘¢.ğ‘›ğ‘’ğ‘’ğ‘‘ğµğ‘¢ğ‘–ğ‘™ğ‘‘âˆª{ğ‘}\n16 Algorithm 2: Pushup( ğ‘¢,ğ‘ğ‘š,ğœ–)\n17 forğ‘£âˆˆğ‘¢.ğ‘â„ğ‘–ğ‘™ğ‘‘ğ‘Ÿğ‘’ğ‘› do\n18 Traverse_Suffix_Tree( ğ‘£,ğ‘ğ‘š,ğœ–)\n19 Algorithm 2: Pushup( ğ‘¢,ğ‘ğ‘š,ğœ–)\nLines 9 to 18 outline the framework of pushup operation. We\nrecursively travel the tree and push the infrequent ğ¿-triples upward\nto the segments of the father nodes. In lines 10-15, if a node is a leaf,\nwe groupğ¿-triples from ğ‘¢.ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ toğ‘¢.ğ‘’ğ‘›ğ‘‘ into buckets according to\nthe character class. And the characters in ğ¿-triples will be labeled to\nindicate that they need to be represented by the learning functions\n(line 14). After that, the pushup operation will decide whether to\nbuild functions on these buckets or push them to father nodes (line\n15). Because this procedure is recursively executed, we will also\nperform the pushup operation in non-leaf nodes (line 18).\nAlgorithm 2 provides the details of pushup. For each character ğ‘,\nwe further check whether there are at least ğ‘ğ‘šğ¿-triples inğ‘¢.ğµ[ğ‘]\n(lines 2-3) if the ğ¿-triples ofğ‘need to be fitted. If both conditions\nare satisfied, we build functions to represent ğ‘¢.ğµ[ğ‘](lines 4-5).\nOtherwise, the ğ¿-triples are pushed up to the bucket of the father\nnodeğ‘¢.ğ‘“ğ‘.ğµ[ğ‘]. Note that the distribution of ğ‘¢.ğµ[ğ‘]also needs to\nbe pushed up in order to build functions for the sibling nodes. Since\nthe functions of these nodes have already been constructed, only\nthe first and last ğ¿-triples inğ‘¢.ğµ[ğ‘]need to be pushed up, i.e., a\ncompression form (line 5,9). Take Figure 4 as an example, the 9-th\nto11-thğ¿-triples in node 6are pushed up to node 4because they\nall appear once. Since the occurrences of the 10-th,11-thğ¿-triples\nin node 4are still smaller than ğ‘ğ‘š, they need to be further pushedAlgorithm 2: Pushup\nInput: Suffix tree node ğ‘¢, the minimum number ğ‘ğ‘šof\nğ¿-triples with the same class in a segment, error\nboundğœ–\n1forğ‘âˆˆÎ£do\n2 ifğ‘âˆˆğ‘¢.ğ‘›ğ‘’ğ‘’ğ‘‘ğµğ‘¢ğ‘–ğ‘™ğ‘‘ then\n3 if|ğ‘¢.ğµ[ğ‘]|>=ğ‘ğ‘šthen\n4 ğ‘¢.ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘)â† build fitting functions of ğ‘¢.ğµ[ğ‘]\nwithğœ–\n5 push the first and last ğ¿-triples inğ‘¢.ğµ[ğ‘]to\nğ‘¢.ğ‘“ğ‘.ğµ[ğ‘]\n6 else\n7 push allğ¿-triples inğ‘¢.ğµ[ğ‘]toğ‘¢.ğ‘“ğ‘.ğµ[ğ‘]\nğ‘¢.ğ‘“ğ‘.ğ‘›ğ‘’ğ‘’ğ‘‘ğµğ‘¢ğ‘–ğ‘™ğ‘‘â†ğ‘¢.ğ‘“ğ‘.ğ‘›ğ‘’ğ‘’ğ‘‘ğµğ‘¢ğ‘–ğ‘™ğ‘‘âˆª{ğ¶}\n8 else\n9 push the first and last ğ¿-triples inğ‘¢.ğµ[ğ‘]to\nğ‘¢.ğ‘“ğ‘.ğµ[ğ‘]\n10deleteğ‘¢.ğ‘›ğ‘’ğ‘’ğ‘‘ğµğ‘¢ğ‘–ğ‘™ğ‘‘,ğ‘¢.ğµ\nup to the root node. After node ğ‘¢is pushed up, the bucket and the\nlabels ofğ‘¢are no longer needed (line 10).\n4.2 Building the Learned Representation for ğ¿\nThis subsection discusses the details of building fitting functions\nfor buckets. Let ğ‘¥=(ğ‘,ğ‘–,ğ‘Ÿ)be anğ¿-triple,ğµ=[ğ‘¥[1],...,ğ‘¥[ğ‘˜]]be\nthe bucket of a ğ¿-triple sequence with the same character class ğ‘in\na segment. The learning representation for ğ¿is to find a function\nğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘¥[ğ‘—].ğ‘–), whose result is close to ğ‘¥[ğ‘—].ğ‘Ÿ. The problem is\nsimilar to that in the learned index [ 14,26], whereğ‘Ÿcan be seen as\nthe cumulative distribution function over ğ‘–. We use the following\ntwo strategies.\nLinear Fitting for ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘¥[ğ‘—].ğ‘–).SSCard can perform linear\nfitting over the bucket ğµ=[ğ‘¥[1],...,ğ‘¥[ğ‘˜]]with the objective of\nminimizing the mean squared error (MSE). For each ğ¿-triple in a\nbucket, the linear function takes the following form, where ğ‘˜ğ‘is\nthe slope and ğ‘ğ‘is the intercept:\nğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘¥[ğ‘—].ğ‘–)=ğ‘˜ğ‘Ã—ğ‘¥[ğ‘—].ğ‘–+ğ‘ğ‘ (1)\nThe loss functions are as follows:\nğ¿=âˆ‘ï¸\nğ‘—âˆˆ|ğµ|(ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘¥[ğ‘—].ğ‘–)âˆ’ğ‘¥[ğ‘—].ğ‘Ÿ)2(2)\nThe parameters can be efficiently optimized using the least squares\nmethod. When the learning convergences, we can discard the ex-\nplicitğ¿-triple directly and keep only two parameters ğ‘˜ğ‘andğ‘ğ‘for\neach bucket (character class) in a segment.\nGreedy Spline Interpolation for ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘¥[ğ‘—].ğ‘–).Another ap-\nproach to represent these ğ¿-triples takes the linear spline interpo-\nlation [ 13,14,26,41]. There are two differences from the previous\none. First, MSE as an objective function can lead to poor fitting\nresults when there are minor changes in ğµ=[ğ‘¥[1],...,ğ‘¥[ğ‘˜]][41].\nSecond, the previous method cannot ensure that the start node\nand the end node match exactly the results of the learned function,\nwhich may lead to large errors in the cardinality estimation. Thus\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\nwe introduce another loss function [41]\nğ¿=max\nğ‘—âˆˆ|ğµ|{ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘¥[ğ‘—].ğ‘–)âˆ’ğ‘¥[ğ‘—].ğ‘Ÿ} (3)\nas the Absolute Maximum Error (MAE), and this function may\nproduce more stable training.\nWe take the spline interpolation mentioned in [ 41] overğµ=\n[ğ‘¥[1],...,ğ‘¥[ğ‘˜]]to address these issues. The spline starts from the\nfirstğ¿-tripleğ‘¥[1], and the linear function ğ‘˜ğ‘Ã—(ğ‘¥[ğ‘—].ğ‘–âˆ’ğ‘¥[1].ğ‘–)+\nğ‘¥[1].ğ‘–can produce the exact matching at ğ‘¥[1]. Then the lower and\nupper bounds of the slope ğ‘˜ğ‘are computed to handle the next ğ¿-\ntriples with the given error bound. The slope bound of ğ‘˜ğ‘is further\nadjusted if the following ğ¿-triples can be represented by the same\nspline satisfying the error bound. Otherwise, the current spline\nis terminated, and another new spline is initialized. We can see\nthat multiple linear splines may be required to represent ğ¿-triples\nfor the same character class in one segment, and the given error\nbound balances space consumption and the quality of cardinality\nestimation. Such a greedy method can generate the interpolation\nusing a one-time scan of the ğ¿-triple sequence ğµ.\n4.3 Analysis\nWe perform the analysis of the SSCard construction method in\nterms of time/space complexity, using the symbols in Table 1.\nTime Complexity in Construction. The time complexity for\nthe major steps in building the SSCard is shown as follows: We\nhaveğ‘‚(ğ‘›ğ‘š)cyclic shifts with the implicit index representation\nfor each cyclic shift. The radix sort takes ğ‘‚(ğ‘›ğ‘š2)in the worst\ncase. The location of the ğ¿-triple sequence costs ğ‘‚(ğ‘›ğ‘š)time. The\nconstruction of the pruned suffix tree takes at most ğ‘‚(|Î£|â„)in the\nworst case. The pre-order traversal of the pruned suffix tree is equal\nto a one-time scan of the ğ¿-array using ğ‘‚(ğ‘›ğ‘š)time cost. Applying\npushup recursively and constructing the learned representation\nare also equivalent to a one-time scan of the ğ¿-triples. In total,\nthe construction of the SSCard takes ğ‘‚(max(ğ‘›ğ‘š2,|Î£|â„))time cost.\nUsually,â„is not large enough, and the time complexity in the\nconstruction of SSCard is reduced to ğ‘‚(ğ‘›ğ‘š2)in the worst case.\nSpace Complexity in Construction. With the similar steps above,\nwe perform analysis over the space complexity. All cyclic shifts\n(including the sorted results) take ğ‘‚(ğ‘›ğ‘š)space, as each one is\nrepresented by the start index and the string ID. The pruned suffix\ntree takes at most ğ‘‚(|Î£|â„)space cost as we put the restriction on\nthe tree height. SSCard needs not to store all ğ¿-triples explicitly but\nthe learned functions, which takes the space cost ğ‘‚(ğ‘›ğ‘š/ğ‘ğ‘š)in the\nworst case. In total, except for the intermediate space required in\nthe building process, the space cost of SSCard takes ğ‘‚(ğ‘›ğ‘š/ğ‘ğ‘š), as\nthe pruned suffix tree usually takes less space with a small â„(e.g.3).\n5 Operations on SSCard\nThis section proposes a bidirectional method over SSCard to esti-\nmate the pattern cardinality, discusses dynamic updates on SSCard,\nand then analyzes the complexity and error bounds of cardinality\nestimation.5.1 Bidirectional Estimation\nSSCard can be viewed as two pre-computed structures: i) The\npruned suffix tree, which records the cardinalities of strings with\nlengths smaller than â„; ii) the learned FM-Index, which supports ap-\nproximate cardinality estimation for arbitrary-length query strings.\nWe aim to develop a combination of these two structures to fully\nleverage the exact cardinality information from the suffix tree, even\nwhen the pattern length exceeds the tree height.\nIt is not easy to combine the results of the suffix tree and the\nFM-Index together as the pattern matching directions are different.\nFor the suffix tree, we need to perform a forward search, while\nwe perform a backward search using the FM-Index. However, we\ncannot directly combine the results from two directions, as the\ncharacter occurrences at the ğ‘–-th layer (ğ‘–â‰¥2) do not follow the\nsame order as those in the ğ¹andğ¿-array, and consequently, the\nintermediate results cannot further guide the next backward search.\nWe attempt to combine two structures from another viewpoint.\nFor a pattern ğ‘ƒ, we start with a middle char ğ‘ƒ[ğ‘–](1â‰¤ğ‘–â‰¤|ğ‘ƒ|)rather\nthanğ‘ƒ[0], where the suffix started from ğ‘ƒ[ğ‘–]can be fully matched\nin the suffix tree. This also indicates that there is a consecutive\nindex interval for the suffix ğ‘ƒ[ğ‘–]in theğ¹-array, from which the\nbackward search can be further performed in the FM-Index. We\ncan see the basic idea in Figure 5. The second bis the starting char,\nsince the suffix bcis the longest subpattern that can be matched\nin the pruned suffix tree in Figure 3. We can locate the valid index\nrange[12,16]in theğ¹-array for b, from which the prefix abbcan\nbe further matched with the backward search using the idea of the\nFM-Index. The results in the backward search are the results for\nthe overall pattern, which have considered both suffix and prefix\nsubpatterns.\nDefinition 2. Starting character in estimation. Given a pat-\ntern stringğ‘ƒand a pruned suffix tree ğ‘‡, a charğ‘ƒ[ğ‘–](1â‰¤ğ‘–â‰¤|ğ‘ƒ|)is\nthe starting character, if the suffix started from ğ‘ƒ[ğ‘–]matches a path\ninğ‘‡, and no suffix started from ğ‘ƒ[ğ‘˜](ğ‘˜<ğ‘–)matches any path in ğ‘‡.\nb\nb c1:(1,21,4)\n6:(9,11,2) 7:(12,16,3)4:(9,16,4)â€¦ â€¦\na4a313 14\nb3b212 15#4#39 16\n(a) Partial SSCard\nbb c aStarting Node 7:(12,16,3)\nBackward Searching \nin the FM-Index mannerForward Searching \nin Suffix Tree (b) Bidirectional Estimation\nFigure 5: Cardinaltity estimation using SSCard\nBefore giving the full method in the cardinality deestimation,\nwe first detail the ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)used in SSCard in Algorithm 3. Given\ntheğ‘–-th index and a character ğ‘, the major step is to locate the\nsegment that stores its learned function ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–), which can\nbe used to answer ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)directly. As we have performed the\npushup operation on rare characters, not all functions are stored\nin the segment linked by the leaf node in the suffix tree. However,\nwe know that the function must appear in the last segment that\ncontains the function with ğ‘, according to the pushup rules in the\n\nSIGMOD, Trovato et al.\nSSCard construction. Thus we first iteratively traverse ğ‘‡to a leaf\nnode by choosing the child node ğ‘£that satisfies ğ‘–âˆˆ[ğ‘£.ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘£.ğ‘’ğ‘›ğ‘‘]\n(lines 1-3), and then traceback to the father node of ğ‘¢ifğ‘¢does\nnot containğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)(lines 4-5). Take ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(#,11)as an example.\nAfter line 3, we reach node 6, but node 6 does not contain a learned\nfunction for #. Therefore, we backtrack to its parent, node 4, which\ncontains the required function, and compute ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(#,11)=3.\nAlgorithm 3: Rank Computation ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)\nInput: Characterğ‘, the indexğ‘–, SSCard\nOutput: Rank orderğ‘Ÿofğ‘in theğ¿-array\n1ğ‘¢â†ğ‘‡.ğ‘Ÿğ‘œğ‘œğ‘¡\n2whileğ‘¢is not leaf do\n3ğ‘¢â†ğ‘£, whereğ‘£âˆˆğ‘¢.ğ‘â„ğ‘–ğ‘™ğ‘‘ğ‘Ÿğ‘’ğ‘›âˆ§ğ‘–âˆˆ[ğ‘£.ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘£.ğ‘’ğ‘›ğ‘‘]\n4whileğ‘¢.ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘)=âˆ…âˆ§ğ‘¢â‰ ğ‘Ÿğ‘œğ‘œğ‘¡do\n5ğ‘¢â†ğ‘¢.ğ‘“ğ‘\n6Returnğ‘¢.ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)\nWith the introduction of the starting character and implementa-\ntion ofğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–), we give an overall bidirectional estimation of the\nSSCard in Algorithm 4. The main idea is similar to the FM-Index,\nwhich iteratively computes the index interval for the preceding\nchars on the ğ¿-array. First, we locate the starting node using a bi-\nnary search on ğ‘ƒand check whether the suffix is matched in the\npruned suffix tree ğ‘‡in line 1, as the height of some leaves in ğ‘‡is\nsmaller than â„. That is, we first choose a suffix from the middle\ncharğ‘ƒ[ğ‘˜]and attempt to match the suffix in ğ‘‡. If the suffix is not\npreserved in ğ‘‡, we change the starting char to the right suffix in\nğ‘ƒ. Otherwise, we change the starting char to the left suffix until\nthe suffix with the maximum length can be located in ğ‘‡. Second,\nwe use the approximate function ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)in Algorithm 3 to re-\nplace the exact ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)in lines 5-6, where ğ‘‡[ğ‘ğ‘˜âˆ’1].ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ is the\nimplementation of ğ‘‚ğ‘ğ‘(ğ‘ğ‘˜âˆ’1)mentioned in Section 3.2. As illus-\ntrated in Figure 5b, the starting character of abbc isğ‘ƒ[3]=b, and\nthe index interval is [12,16]. Then the backward procedure starts\nfrom[12,16](ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ =12andğ‘’ğ‘›ğ‘‘=16in Line 2) and continues to\nestimate abbin the same way as the FM-Index.\nAlgorithm 4: Cardinality Estimation by SSCard\nInput: A Patternğ‘ƒ, SSCard\nOutput: Estimated Cardinality of ğ‘ƒ\n1Determine the starting character ğ‘ƒ[ğ‘˜]using the binary\nsearch over the pruned suffix tree ğ‘‡\n2Locate the index interval [ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡,ğ‘’ğ‘›ğ‘‘]for the suffix\nsub-pattern from ğ‘ƒ[ğ‘˜]inğ‘‡\n3whileğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡â‰¤ğ‘’ğ‘›ğ‘‘andğ‘˜âˆ’1â‰¥2do\n4ğ‘ğ‘˜âˆ’1â†ğ‘ƒ[ğ‘˜âˆ’1]\n5ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡â†ğ‘‡[ğ‘ğ‘˜âˆ’1].ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡+ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘ğ‘˜âˆ’1,ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡)\n6ğ‘’ğ‘›ğ‘‘â†ğ‘‡[ğ‘ğ‘˜âˆ’1].ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡+ğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘ğ‘˜âˆ’1,ğ‘’ğ‘›ğ‘‘)\n7ğ‘˜â†ğ‘˜âˆ’1\n8Returnğ‘’ğ‘›ğ‘‘âˆ’ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡+15.2 Incremental Update\nIncremental updates to SSCard are non-trivial. For example, during\ninsertion, the pruned suffix tree lacks full information about the\ncyclic shifts, making it hard to directly place new ğ¿-triples into the\ncorrect segments. Moreover, inserting a new string alters the rank\nofğ¿-triples, thereby invalidating the existing learned functions.\nSSCard allocates a fixed-size main memory to cache a pruned\nsuffix tree for newly added data strings. That is, in addition to the\noriginal SSCard, we maintain a pruned suffix tree ğ‘‡ğ‘–specifically\nfor newly added data, as ğ‘‡ğ‘–can be efficiently updated and directly\nused for cardinality estimation. For each newly added string, we\nidentify all its suffixes shorter than a threshold â„and insert these\nsuffixes into ğ‘‡ğ‘–, during which the cardinality ğ‘¢.ğ‘ğ‘›ğ‘¡ forğ‘¢âˆˆğ‘‡ğ‘–is\nupdated in the same way as in SSCard discussed before. The results\nfrom SSCard and the suffix tree are then combined to estimate the\ncardinality of a given pattern.\nWe adopt two strategies when the size of ğ‘‡ğ‘–exceeds the fixed\nmemory budeget. The first is the single-SSCard update strategy ,\nwhich rebuilds a single SSCard by merging the original data strings\nand inserted data strings when the memory is full. The second,\ninspired by update strategies used in LSM-Tree families [ 13,39,42],\nis the multiple-SSCard update strategy . Rather than merging\nall data into one structure, we create an independent SSCard for\nthe newly inserted data. As a result, multiple SSCards coexist and\ncan later be consolidated during system idle periods. The multiple-\nSSCard update strategy is expected to greatly reduce update costs,\nat the expense of slightly increased cardinality estimation time and\nQ-error compared to the Single-SSCard update strategy.\nThe deletion of the old string from SSCard can be supported in\na similar way to handle the insertion, by building a new pruned\nsuffix treeğ‘‡ğ‘‘to cache the deleted strings.\n5.3 Analysis\nWe first discuss the time complexity and error bounds in the estima-\ntion, and then analyze the time/space cost in the dynamic update.\nTime Cost in Estimation. The cardinality estimation using SS-\nCard involves two major steps. The location of the starting node\nrequiresğ‘‚(log|ğ‘ƒ|)times trials, each of which requires ğ‘‚(â„)time\ncost. Thus, searching over the pruned suffix tree takes ğ‘‚(â„Â·log|ğ‘ƒ|).\nThe search over SSCard takes at most |ğ‘ƒ|steps in the worst case,\nand in each step, we locate the target segment via at most â„access\nto the suffix tree. The learning function for Rank takes a constant\ntime. Thus, the total time cost of searching SSCard is ğ‘‚(â„Â·|ğ‘ƒ|). By\ncombining two factors, the total time cost is ğ‘‚(â„Â·|ğ‘ƒ|). In practice,\nsinceâ„is usually a small constant, the overall time complexity can\nbe approximated as linear, i.e. ğ‘‚(|ğ‘ƒ|).\nEstimation Error Bound. The estimation error of SSCard includes\ntwo parts: 1) the multiple occurrences of ğ‘ƒin a single data string\nğ·âˆˆD, and 2) the cumulative error of approximate ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)over\ntheğ¿-array. In practice, the first issue is serious when the length\nof a pattern is limited but can be significantly alleviated with ğ‘ğ‘›ğ‘¡\nannotated to the suffix tree nodes. We mainly focus on the second\nissue using greedy spline interpolation with the error bound ğœ–. In\neach step, we estimate an index interval using the learned functions\nğ‘Ÿğ‘ğ‘›ğ‘˜ğ‘“(ğ‘,ğ‘–)two times. In the worst case, the error introduced in\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\nTable 2: Statistics about datasets for evaluation\nDatasetsString SetD Query SetP\n|Î£||D|ğ‘™ğ‘ğ‘£ğ‘”ğ‘™ğ‘šğ‘ğ‘¥ğ‘™ğ‘ ğ‘¢ğ‘š|P|ğ‘™ğ‘ğ‘£ğ‘”ğ‘™ğ‘šğ‘–ğ‘›ğ‘™ğ‘šğ‘ğ‘¥\nDBLP-AN 27 450,000 14.6 44 6,572,365 400,000 6.0 1 8\nIMDB-AN 27 550,000 14.1 39 7,774,344 500,000 6.2 1 8\nIMDB-MT 38 500,000 14.7 79 7,366,281 500,000 6.2 1 8\nTPCH-PN 26 200,000 32.8 50 6,550,221 1,128 3.9 1 8\nWIKI 3735 1,031,930 98.4 300 101,561,110 1,000,000 6.1 1 8\none backward step is 2ğœ–. With the total|ğ‘ƒ|steps, the absolute error\ndistance to the correct one is at most 2ğœ–Â·|ğ‘ƒ|in the worst case.\nTime and Space Cost in Update. For a newly inserted string ğ·,\nit takes at most ğ‘‚(|ğ·|2Â·â„)time to add all suffixes to the incremen-\ntal suffix tree ğ‘‡, whereâ„is the maximum height of ğ‘‡. The time\ncomplexity of rebuilding the SSCard is theoretically the same as\nbuilding the SSCard from scratch, which takes ğ‘‚(ğ‘›ğ‘š2)time. For the\nspace cost, the incremental suffix tree takes ğ‘‚(|Î£|â„)in the worst\ncase, where â„is the maximum height of the cached suffix tree.\n6 Experiments\nWe conduct experiments on five real-life datasets, comparing SS-\nCard with the state-of-the-art (SOTA) estimators, and evaluating\nthe effectiveness of different components in SSCard. Our source\ncode is available at https://github.com/marlcplhra/SSCard.\n6.1 Experimental Setup\nExperiment Environment: SSCard and other competitors are\nimplemented with Python on a machine with Intel(R) Xeon(R)\nSilver 4210R CPU @ 2.40GHz, and 256 GB of RAM, Ubuntu 20.04.6\nLTS. For learning-based methods, a single NVIDIA GeForce RTX\n3090 GPU is used for training.\nDatasets: We use the same datasets as the existing works [ 3,32,\n43], sampling author names (DBLP-AN) from DBLP1, actor names\n(IMDB-AN) from IMDB2, movie titles (IMDB-MT) from IMDB and\npart names (TPCH-PN) from TPCH3. These four datasets have a\nsmall alphabet, thus we include the WIKI dataset which is used in\nDREAM [ 31] to analyze methodâ€™s scalability for larger character\nsets. It is constructed by randomly sampling sentences from 101,873\nWikipedia articles in the DocRED dataset [50]. The query set Pis\nconstructed by sampling substrings of words from the string set\nD. Notice that TPCH-PN has only 92 unique words, thus there\nare only 1,128 unique substrings in total. The actual cardinalities\nof pattern strings in Pis generated by using the same summary\ndata structure in [ 43], and we take 50% of Pfor training and 50%\nas the test set. Within 50% of the training data, we take 10% for\nvalidation. For estimators that do not require training, we test their\nperformance directly on test sets.\nEvaluation Metrics: We evaluate the estimation accuracy, con-\nstruction time, estimation time, and estimator size of SSCard and\ncompetitors. For estimation accuracy, we utilize q-error as the eval-\nuation metric, which is widely used in previous work [ 19,24,25,\n1https://dblp.org\n2https://imdb.com\n3https://www.tpc.org/tpch/31,43]. Q-error is defined as follows, where ğ‘¦ğ‘–is an actual value\nand Ëœğ‘¦ğ‘–is an estimated value,\nğ‘âˆ’ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ(ğ‘¦ğ‘–,Ëœğ‘¦ğ‘–)=max(ğ‘¦ğ‘–\nËœğ‘¦ğ‘–,Ëœğ‘¦ğ‘–\nğ‘¦ğ‘–) (4)\nTo avoid dividing by zero, the lower bounds of ğ‘¦ğ‘–and Ëœğ‘¦ğ‘–are set to\n1as in other works [ 3,31,43]. The size of an estimator is measured\nby the absolute size of the file when the estimator is saved into the\nsecondary memory.\nCompetitors: We compare SSCard with the following methods:\nâ€¢MO: MO [ 21] is a substring cardinality estimator based on\npruned suffix tree. We set the prune threshold to 2%, reserv-\ning2%nodes of the full suffix tree.\nâ€¢LBS: LBS [ 33] is an estimator for approximate string queries\nbased onğ‘˜-gram.\nâ€¢Astrid: Astrid [ 43] learns selectivity-aware embeddings of\nsubstrings fromD. We train the embedding model using D\nand the selectivity model using the triplets generated from\nthe training set ofP.\nâ€¢DREAM: DREAM [ 31] is the SOTA estimator for approxi-\nmate string queries. We set the edit distance [ 18] threshold\nto0when comparing with other approaches. We use the\nbase training data of Pto train the model.\nâ€¢LPLM: LPLM [ 3] is the SOTA estimator for LIKE predicates.\nWe takePas the training set and utilize 500 SQLite databases\nin parallel to generate the ground truth probabilities of LPLM\nas mentioned in [3].\nHyperparameter: SSCard has four hyperparameters, includ-\ning the height of the pruned suffix tree â„, the minimum number\nof occurrences for each identical-character in a segment ğ‘ğ‘š, the\nsegment size ğ‘™, and the error bound ğœ–for spline interpolation. We\nsetâ„=3,ğ‘ğ‘š=10,ğ‘™=5000 andğœ–=32for all five datasets.\n6.2 General Comparison\nEstimator Accuracy: Table 3 presents the q-error results of SSCard\nand other approaches by the average value, the values at the 50-th,\n90-th,99-th percentiles, and the maximum value. Bold numbers\nindicate the best results, while underlined numbers indicate the\nsecond-best results. Results show that SSCard outperforms other\ncompetitors in terms of q-errors from all aspects.\nWe compare SSCard with the second-best methods in terms of\nq-error. On DBLP-AN, IMDB-AN and IMDB-MT datasets, SSCard\nachieves an approximate 15% reduction on average, as the mod-\nerate number of data strings and a relatively small alphabet size\nenable accurate learned representation within error bounds. While\nMO demonstrates low q-error at the 50-th and 90-th percentiles, it\n\nSIGMOD, Trovato et al.\nTable 3: Q-error of cardinality estimation\nEstimatorsDBLP-AN IMDB-AN IMDB-MT TPCH-PN WIKI\nAvg. 50th 90th 99th Max. Avg. 50th 90th 99th Max. Avg. 50th 90th 99th Max. Avg. 50th 90th 99th Max. Avg. 50th 90th 99th Max.\nMO 3.72 1.67 6.75 21.7 5968.9 2.48 1.00 3.79 16.55 19600.0 5.44 1.00 3.14 14.1 57451.9 1.00 1.00 1.00 1.00 1.00 86.9 1.98 16.5 730.0 460337.4\nLBS 3.12 1.98 8.00 17.0 537.8 2.20 1.00 5.00 15.0 2273.0 2.28 1.00 5.00 16.0 214.4 1.02 1.00 1.02 1.37 2.24 3.21 1.02 7.00 20.0 2372.4\nAstrid 3.84 2.27 5.97 30.2 1930.0 3.26 1.72 4.43 28.8 1330.6 3.23 1.75 4.74 28.9 2251.1 2.44 2.01 3.07 12.7 29.2 10.5 3.05 11.4 86.2 488367.7\nDREAM 3.21 1.89 5.47 22.9 1055.5 2.68 1.35 3.95 20.0 2359.3 2.59 1.33 4.07 21.0 805.8 1.83 1.20 1.65 21.1 71.8 6.23 1.82 7.35 61.6 37514.1\nLPLM 5.23 2.89 10.6 35.9 1342.4 3.44 2.16 6.09 22.1 1167.2 4.62 2.45 7.43 27.9 31473.8 1.85 1.64 2.75 4.09 4.32 93.6 12.7 102.4 823.9 1016548.9\nSSCard 2.92 1.80 6.00 20.0 64.0 2.05 1.00 4.00 14.0 70.0 2.14 1.00 4.00 16.0 71.0 1.00 1.00 1.00 1.00 1.02 2.61 1.02 5.00 20.0 73.0\nTable 4: Runtime of entire pipeline for cardinality estimators. P., T. Q. correspond to pre-processing, training and query time\nEstimatorsDBLP-AN IMDB-AN IMDB-MT TPCH-PN WIKI\nP. + T. Q. (ms) P. + T. Q. (ms) P. + T. Q. (ms) P. + T. Q. (ms) P. + T. Q. (ms)\nMO 2.97 (min) + 0 0.02 4.5 (min) + 0 0.02 7.5 (min) + 0 0.02 6.0 (min) + 0 0.01 3.5 (h) + 0 0.13\nLBS 16.6 (min) + 0 0.06 20.3 (min) + 0 0.06 19.5 (min) + 0 0.07 16.7 (min) + 0 0.1 7.2 (h) + 0 0.05\nAstrid 27.5 (s) + 2.9 (h) 1.42 53.2 (s) + 4.9 (h) 1.43 47.2 (s) + 5.3 (h) 1.46 0.1 (s) + 22.9 (s) 1.71 2.3 (min) + 10.8 (h) 2.34\nDREAM 4.8 (s) + 47.4 (min) 4.4 8.1 (s) + 1.5 (h) 7.9 7.2 (s) + 1.4 (h) 7.7 0.1 (s) + 18.4 (s) 6.3 25.6 (s) + 2.6 (h) 4.6\nLPLM 2.6 (h) + 14.7 (min) 0.16 4.0 (h) + 13.1 (min) 0.16 3.7 (h) + 13.2 (min) 0.15 13.7 (s) + 71.4 (s) 0.25 22.8 (h) + 0.48 (h) 6.5\nSSCard 2.0 (min) + 32.4 (s) 0.06 1.3 (min) + 39.5 (s) 0.06 1.4 (min) + 37.0 (s) 0.06 1.1 (min) + 29.3 (s) 0.02 2.2 (h) + 8.9 (min) 0.04\nFigure 6: Q-error of estimators varying pattern lengths\nFigure 7: Q-error of estimators varying actual result cardinality\nperforms poorly in terms of the maximum q-error. This is primarily\ndue to the character-wise independent estimation of short strings\nin MO, which often leads to substantial overestimation, as also\nshown in Figure 6. LBS achieves similar performance to SSCard\nin TPCH-PN due to the short pattern strings, with the ğ‘-gram\ntable (maximum length 5) covering most queries. DREAM ranks\nsecond among learned estimators (Astrid, DREAM, LPLM) by di-\nrectly establishing relationships between the query patterns and\ncardinalities, while LPLM performs the worst, particularly in WIKI,\nas its wildcard-based decomposition increases prediction difficulty.Notably, the maximum q-error of SSCard outperforms other esti-\nmators, being 50% of the second lowest on TPCH-PN and 3âˆ¼33%\nof the second lowest on other datasets. This improvement is attrib-\nuted to SSCardâ€™s error-bounded estimation. For a a pattern with an\nactual value ğ‘¦, the q-error is bounded by 1+2ğœ€Â·|ğ‘ƒ|\nğ‘¦âˆ’2ğœ€Â·|ğ‘ƒ|â‰¤1+2ğœ€Â·|ğ‘ƒ|.\nFor instance, the bound of q-error for SSCard does not exceed\n1+2Â·32Â·8=513in DBLP-AN.\nQ-error Varying Length of Pattern Strings: Figure 6 illustrates\nthe average q-error of each estimator across different pattern lengths.\nSSCard consistently achieves the lowest q-error, particularly for\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\nTable 5: Size of estimators (MB)\nEstimator DBLP-AN IMDB-AN IMDB-MT TPCH-PN WIKI\nMO 7.70 13.80 24.70 15.31 365.51\nLBS 20.85 20.69 23.04 3.56 89.95\nAstrid 0.36 0.36 0.84 0.40 14.69\nDREAM 7.82 7.82 7.82 7.82 7.88\nLPLM 1.02 1.02 1.05 1.01 9.82\nSSCard 4.40 4.29 4.75 0.37 23.00\nshort patterns. This is because SSCard combines both the advan-\ntages of the suffix tree and the FM-Index, in which the former\nprovides exact cardinality for query patterns shorter than â„, and\nthe latter supports arbitrary length pattern strings flexibly. Notice\nthat the q-error for learned estimators is significantly high for short\npattern lengths because of the infrequency of these short patterns,\nresulting in inadequate training for this portion of the data.\nQ-error Varying Actual Result Cardinality: As shown in Fig-\nure 7, SSCard has the lowest q-error especially in low and high\ncardinalities. The results are similar to those of Figure 6, which\nfurther verify our previous claim. It is not easy for a learned estima-\ntor to produce accuracy results for large cardinalities. Performance\ndegradation may be due to the limited training instances from\nvery large valid strings or the skew data distribution between the\ntraining and test set.\nRuntime Analysis: The runtime of all methods are shown in Ta-\nble 4. The pre-processing time for LBS and SSCard refers to the time\nin building summary data structures, and for other learning-based\nmethods, it refers to the time in generating training data. SSCard\nexhibits a significant advantage in pre-processing and training time\nexcept on TPCH-PN datasets. In particular, on DBLP-AN, IMDB-\nAN and IMDB-MT, SSCard only takes two minutes to construct,\nachieving an improvement 19Ã—âˆ¼40Ã—over the fastest competitior.\nThe training time of SSCard is short because one only needs one\npass of the suffix tree to construct spline functions. LBS performs\nwell except for WIKI, while large datasets require considerable\ntime to generate ğ‘˜-grams. Astrid consumes its major part of the\ntime learing embedding of data strings. For example, Astrid takes 8\nhours in learning embedding in WlKl with the top 10% frequently\nsubstrings for training. Both DREAM and LPLM train the model\ndirectly on pattern strings, taking the short time in training due to\nthe small size of pattern string set. However, they need to prepro-\ncess the original data to produce ground-truth labels for learning.\nFor query time, SSCard and LBS are much faster than the other\nthree learning-based methods. This is because they do not have\nhigh computational demands during inference, or vector operations\nlike padding and generating one-hot vectors for pattern strings.\nEstimator Size: The space requirements are depicted in Table\n5. As analyzed before, the space complexity of SSCard is directly\nproportional to the size of the data set, the key parts being the\nfitting functions. It is obvious that the number of fitting functions\ngrows with the increase of the dataset. For LBS, longer ğ‘˜-grams will\noccupy more space, as all extended grams and their corresponding\nhash values need preprocessing to ensure performance. For the\nDREAM model, its size remains approximately 7.8MB across all\nfour datasets. This is attributed to DREAMâ€™s LSTM architecture for\npattern string embeddings. As indicated in Table 2, the lengths ofthe pattern strings in the four data sets exhibit similar distributions.\nHence, the size of the DREAM model remains relatively constant\nand is independent of the underlying data string set D.\nTable 6: Comparison between FM-Index and SSCard (C++)\nEstimator DBLP-AN IMDB-AN IMDB-MT TPCH-PN WIKI\nSpace (MB)\nFM-Index 6.39 7.56 7.58 6.12 101.14\nSSCard (C++) 3.47 3.42 3.74 0.31 18.95\nPre-processing Time (s)\nFM-Index 1.57 1.95 1.80 1.36 30.56\nSSCard (C++) 7.10 6.32 4.57 5.35 684.77\nQuery Time ( ğœ‡ğ‘ )\nFM-Index 1.11 1.13 1.25 0.78 -\nSSCard (C++) 2.72 2.83 2.81 1.10 4.13\nComparing SSCard to FM-Index : We also compare SSCard with\nthe FM-Index. csa_wt class of sdsl-lite [ 44] in C++ is the state-of-\nthe-art implementation, which is also adopted in the experimental\nevaluation of [ 38]. We test FM-index on string columns in DB by\nconcatenating these strings with special delimiter characters into a\nlong string, as FM-Index does not natively support multiple strings.\nTo ensure a fair comparison, we also implement SSCard in C++. As\nshown in Table 6, while the FM-Index offers faster construction\nand slightly quicker query times, these differences are generally\noutweighed by SSCardâ€™s significant advantage in space efficiency,\nparticularly for datasets with large or complex alphabets. This is\nespecially evident in WIKI, where the FM-Index fails to handle\nvariable-length encodings like UTF-8. For comparison purposes, we\nencode the WIKI dataset as single-bit characters to enable FM-Index\nconstruction, allowing us to evaluate relative space usage.\n6.3 Effectiveness of Different Components of\nSSCard\nTable 7: Size comparison between gzip and SSCard (MB)\nMethod DBLP-AN IMDB-AN IMDB-MT TPCH-PN WIKI\ngzip 7.13 9.61 9.80 5.24 1373.50\nSSCard 4.40 4.29 4.75 0.37 23.00\nEffectiveness of Spline Interpolation: As shown in Figure 8, we\nvalidate the improvement of the spline interpolation-based strategy\nover linear fittings. For each dataset, we construct SSCards based\non spline interpolation with ğœ–=4,8,16,32,64. We also construct a\nvariant of SSCard based on linear fitting, using a comparable space\nbudget by adjusting the number of segments. Spline interpolation\nyields significantly better performance, primarily because it ensures\nthat fitting errors remain below the given maximum threshold. This\nprevents sudden error increases and enables SSCard to achieve\nconsistent and controllable results. We also compare the space\nconsumption between SSCard and standard compression technique\nin python in Table 7. We take gzip to compress the checkpoints of\nğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–)for everyğ‘˜entries as well as the ğ¿-array. For every query,\nwe decompress the ğ‘—=âŒŠğ‘–/ğ‘˜âŒ‹-th checkpoint and the corresponding\nfragment of the ğ¿-array to accurate calculate ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘,ğ‘–). A smallerğ‘˜\nresults in faster query time, but with higher space consumption. We\n\nSIGMOD, Trovato et al.\nFigure 8: Improvement of spline interpolation\nFigure 9: Study of the effect of the Suffix tree height â„.\nsetğ‘˜=500to achieve comparable query time between SSCard and\ngzip . Under this configuration, the gzip-based approach consumes\nsignificantly more space than SSCard.\nSuffix Tree height â„:As shown in Figure 9, we evaluate SSCard\nunder different values of the suffix tree height â„. Asâ„increases,\nthe q-error decreases, but the space usage grows accordingly. This\nis because more queries can be estimated precisely on the pruned\nsuffix tree with larger height. When â„=3, SSCard can estimate\nmost of the short strings accurately, avoiding the impact of multiple\noccurrences of ğ‘ƒin a single data string. However, the benefit of\nincreasingâ„diminishes beyond this point, while the space overhead\ncontinues to grow. Therefore, we set â„=3for our evaluation.\nTable 8: Comparison between SSCard w/o pushup operation\nMethod DBLP-AN IMDB-AN IMDB-MT TPCH-PN WIKI\nSpace (MB)\nw/o-pushup 8.46 8.95 13.75 0.99 346.46\npushup 4.40 4.29 4.75 0.37 23.00\nQ-error (Avg.)\nw/o-pushup 2.72 1.92 2.01 1.00 2.44\npushup 2.92 2.05 2.14 1.00 2.61\nEffect of Pushup: As mentioned in Section 4.1, SSCard takes a\npushup strategy to put rare characters into the segments linking\nfrom the high-level tree nodes adaptively. Table 8 illustrates an\nobvious reduction in space by the pushup operation, with minor\nincrease in q-error. For example, the optimized space cost is re-\nduced by 91% on WIKI compared to the space cost without pushup,\nwhich requires storing ğ‘‚(|Î£|)extra space cost per segment, which\nbecomes substantial when the alphabet is large.\nEvaluation on Incremental Update: We mainly compare two\nupdate strategies, including the single-SScard update strategy and\nmultiple-SSCard update strategy, in terms of the incremental update\ncost, space usage, q-error and query time. The experiments are\nconducted on the DBLP-AN dataset. We divide data strings into\n15 chunks, each of which fits into main memory. These chunks\nare then fed into the estimator sequentially. When the number\n(a) Incremental update time\n (b) Space\n(c) Q-error\n (d) Query time\nFigure 10: Incremental update (DBLP-AN)\nof nodes in the pruned suffix tree ğ‘‡ğ‘–exceeds 2.5Ã—105, we either\nrebuild the existing SSCard or create a new one, depending on\nthe update strategy. As shown in Figure 10, although the multiple-\nSSCard update strategy incurs slightly higher q-error (Figure 10c)\nand slower query time (Figure 10d) compared to the single-SSCard\nupdate strategy, it achieves much better update efficiency. Notably,\nthe update time remains nearly constant as the data grow, while the\nsingle-SSCard update time increases linearly (Figure 10a). Overall,\ndespite minor trade-offs, the multiple-SSCard update strategy is\nseveral times faster in updates and thus more practical for dynamic\nscenarios, especially given that update costs dominate over query\ntime.\n6.4 End-to-End Query execution Time\nWe evaluate the end-to-end query execution time by injecting esti-\nmated cardinalities into PostgreSQL 14.5. We take IMDB as dataset\nand select 79 out of 116 queries of the JOB workload [ 34] that\ncontains LIKE statement with the form %ğ‘¤ğ‘œğ‘Ÿğ‘‘ %. Cardinalities for\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\nthese LIKE predicates are estimated by SSCard as well as other\nbaselines, and then injected into query plans for execution. As\nshown in Table 9, the first row presents the original cardinalities\nestimated by PostgreSQL. In the following rows, the cardinalities\nof the LIKE predicates are estimated using different methods, while\nthe cardinalities of the other filters are still taken from PostgreSQLâ€™s\nestimates. Note that the last row represents the true cardinalities of\nLIKE predicates. To ensure that the cardinalities injected to single\ntables are not affected by other predicates, we modify the queries\nso that tables containing the LIKE predicate do not include any\nother predicates. We run each method three times and analyze the\naverage execution time. The injection approach is the same as [3].\nCompared to [ 3], we construct SSCard on all columns that filtered\nwith LIKE .\nAs illustrated in Table 9a, SSCard+PG improved most of the\nqueries, but the execution time is not strictly correlated with the\nestimation accuracy of LIKE prediates (Table 9b). This may be be-\ncause PostgreSQL produces inaccurate join cardinality estimates,\neven when provided with more accurate or true single-table car-\ndinalities. A typical example is 4a.sql, PG underestimates the join\nresults of table info_type andmovie_info_idx , and after inject-\ning true cardinalties larger than PGâ€™s of keyword.keyword LIKE\nâ€™%sequel%â€™ , PG put this filter in a later section of the query plan\nand thus produces numerous intermediate results. This also shows\nthat a more effective benchmark for single-table cardinality estima-\ntion is needed.\nTable 9: Experiments on the Join Order Benchmark\nImproved Regressed\n#Queries Avg. Imp. #Queries Avg. Reg.\nPostgreSQL - - - -\nMO+PG 44 9.29% 35 117.03%\nLBS+PG 43 9.10% 36 68.2%\nAstrid+PG 35 20.36% 44 90.05%\nDREAM+PG 43 12.77% 36 26.61%\nSSCard+PG 50 4.91% 29 85.29%\nTrueCard+PG 50 8.50% 29 74.40%\n(a) Improved and regressed queries\nAvg. 50th 90th 99th Max. Total\nPostgreSQL 1.34 0.34 4.43 8.82 11.00 105.83\nMO+PG 1.45 0.32 4.68 9.80 10.58 114.64\nLBS+PG 1.37 0.35 4.32 8.75 11.33 108.52\nAstrid+PG 1.48 0.33 5.06 10.15 10.88 116.58\nDREAM+PG 1.28 0.33 4.32 8.87 11.00 101.20\nSSCard+PG 1.35 0.36 4.39 8.67 10.80 106.66\nTrueCard+PG 1.37 0.38 4.40 8.78 10.98 108.29\n(b) Query execution time\n7 Related Work\nHere, we review the progress in the string index, the traditional\nand learned string cardinality estimation, and the learned index.\nString Index. Various forms of string indexes and their optimiza-\ntion strategies, such as suffix tree, ğ‘˜-gram, and BWT [ 6] have beenextensively studied. Ukkonen algorithm builds the suffix tree by ex-\ntending character iteratively with ğ‘‚(ğ‘š)time and space cost, where\nğ‘šis the string length. Suffix arrays offer a space-efficient structure\nwithğ‘‚(ğ‘š)space. BD-anchors [ 37] reduces the space consump-\ntion inğ‘˜gram algorithms, and were further optimized to reduce\nconstruction cost [ 38] recently. However, BD-anchors require that\nthe pattern string should be longer than a given threshold. FM-\nIndex [ 11] with the extra cached cumulative ranked on the ğ¿array\nto achieve the ğ‘‚(1)rank operation, whose space is not neglected\nwhen Î£is large. Wavelet tree [ 17] achievesğ‘‚(|D|) extra space with\nğ‘‚(log(|Î£|)rank operation.\nTraditional Cardinality Estimation for String. String cardinal-\nity estimation applies string indexing techniques in DBMS. KVI [ 30],\nMO [ 21], and CRT [ 16] mainly use the suffix tree to estimate pattern\ncardinality, differing in how they compute dependency probabil-\nities when pattern length exceeds the tree height. SPH [ 1] and\nP-SPH [ 2] useğ‘˜-grams to discover frequent patterns in the data\nstrings and cache the cardinality of these patterns in histograms,\nbut face challenges with both high mining costs and long query\npatterns. LBS [24] combines ğ‘˜-grams and set hashing for longer\nqueries. We can see that considerable effort has been devoted to\nlong patterns in classic methods. Luckily, SSCard extends FM-Index,\nwhich naturally supports various-length patterns.\nLearned Cardinality Estimation for String. Astrid [ 43] is one\nof the first deep-learning works for string cardinality estimation.\nIt learns the selectivity-aware embeddings for the substrings, fol-\nlowing a regression network to predict substring cardinality. Card-\nNet [ 48] takes an encoder-decoder structure to build the relation-\nships between pattern strings and their cardinalities. DREAM [ 31]\nshares a similar idea as CardNet, but uses the sequence model\n(LSTM) in the encoder-decoder framework. The most recent work\nfor LIKE predicates, LPLM [ 3] defines a probability distribution\nfunction to capture the semantics of LIKE-patterns.\nLearned Index. The learned indexes attempt to predict the position\nof the tuple using a learned model with a tuple search key as input.\nThe early work is based on the neural network [ 28], which verifies\nthe feasibility of the learned index. To achieve efficient construction\nand provide error bounds, methods like FITing-Tree [ 14] and PGM-\nIndex [ 13] approximate CDF (cumulative distribution function) with\nlinear functions, while spline interpolation has also proven effective.\nLeveraging the similarity between the rank order of the characters\nin theğ¿-array and the CDF, we adopt greedy spline interpolation\n[27] to balance space consumption and estimation quality. It is\nworth noting that LISA [ 20] is a learned index also based on the\nFM-Index. It achieves ğ‘‚(|ğ‘„|/ğ¾)time complexity for a string ğ‘„by\nsearching a ğ¾-length substring each time and applying RMI [ 29]\nto locate the index of the substring in the ğ¿-array. However, LISA\ntakes larger space than the FM-index and faces the similar challenge\nin handling large alphabets.\n8 Conclusion and Future Work\nWe proposed SSCard, a cardinality estimator that optimizes FM-\nIndex by incorporating a pruned suffix tree and a learned represen-\ntation. We also introduced a bidirectional estimation algorithm and\nincremental update strategies. SSCard can be further investigated\n\nSIGMOD, Trovato et al.\nin the following directions. First, SScard is expected to support\nmultiple patterns with wildcards by extending the ğ¿-triples with\nstring IDs and pattern indexes. Second, we plan to utilize SSCard\nto estimate the join cardinality of two tables with string columns,\nas well as the single table cardinality filtered with multi predicates\non different string columns.\n9 Acknowledgement\nThis work was supported in part by NSFC under Grant No.62272008\nand CCF-Huawei Populus Grove Fund.\nReferences\n[1]Mehmet Aytimur and Ali Cakmak. 2018. Estimating the selectivity of LIKE\nqueries using pattern-based histograms. Turkish Journal of Electrical Engineering\nand Computer Sciences 26, 6 (2018), 3319â€“3334.\n[2]Mehmet Aytimur and Ali Cakmak. 2021. Using positional sequence patterns to\nestimate the selectivity of SQL LIKE queries. Expert Systems with Applications\n165 (2021), 113762.\n[3]Mehmet Aytimur, Silvan Reiner, Leonard WÃ¶rteler, Theodoros Chondrogiannis,\nand Michael Grossniklaus. 2024. LPLM: A Neural Language Model for Cardinality\nEstimation of LIKE-Queries. Proceedings of the ACM on Management of Data 2, 1\n(2024), 1â€“25.\n[4]Nicolas Bruno and Surajit Chaudhuri. 2004. Conditional selectivity for statistics\non query expressions. In Proceedings of the 2004 ACM SIGMOD international\nconference on Management of data . 311â€“322.\n[5]Nicolas Bruno, Surajit Chaudhuri, and Luis Gravano. 2001. STHoles: A multidi-\nmensional workload-aware histogram. In Proceedings of the 2001 ACM SIGMOD\ninternational conference on Management of data . 211â€“222.\n[6]Michael Burrows. 1994. A block-sorting lossless data compression algorithm.\nSRS Research Report 124 (1994).\n[7]Tianyi Chen, Jun Gao, Hedui Chen, and Yaofeng Tu. 2023. Loger: A learned opti-\nmizer towards generating efficient and robust query execution plans. Proceedings\nof the VLDB Endowment 16, 7 (2023), 1777â€“1789.\n[8]Arghya Kusum Das, M Oguzhan Kulekci, and Sharma V Thankachan. 2022.\nMemoryâ€“Efficient FM-Index Construction for Reference Genomes. In 2022 IEEE\nInternational Conference on Bioinformatics and Biomedicine (BIBM) . IEEE, 736â€“\n739.\n[9]Arthur L Delcher, Simon Kasif, Robert D Fleischmann, Jeremy Peterson, Owen\nWhite, and Steven L Salzberg. 1999. Alignment of whole genomes. Nucleic acids\nresearch 27, 11 (1999), 2369â€“2376.\n[10] Arthur L Delcher, Adam Phillippy, Jane Carlton, and Steven L Salzberg. 2002.\nFast algorithms for large-scale genome alignment and comparison. Nucleic acids\nresearch 30, 11 (2002), 2478â€“2483.\n[11] Paolo Ferragina and Giovanni Manzini. 2000. Opportunistic data structures with\napplications. In Proceedings 41st annual symposium on foundations of computer\nscience . IEEE, 390â€“398.\n[12] Paolo Ferragina, Giovanni Manzini, Veli MÃ¤kinen, and Gonzalo Navarro. 2004.\nAn alphabet-friendly FM-index. In International Symposium on String Processing\nand Information Retrieval . Springer, 150â€“160.\n[13] Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-index: a fully-dynamic\ncompressed learned index with provable worst-case bounds. Proceedings of the\nVLDB Endowment 13, 8 (2020), 1162â€“1175.\n[14] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim\nKraska. 2019. Fiting-tree: A data-aware index structure. In Proceedings of the 2019\nInternational Conference on Management of Data . 1189â€“1206.\n[15] Simon Gog, Alistair Moffat, and Matthias Petri. 2017. CSA++: fast pattern search\nfor large alphabets. In 2017 Proceedings of the Ninteenth Workshop on Algorithm\nEngineering and Experiments (ALENEX) . SIAM, 73â€“82.\n[16] Surajit Chaudhuri Venkatesh Ganti Luis Gravano. [n. d.]. Selectivity Estimation\nfor String Predicates: Overcoming the Underestimation Problem. ([n. d.]).\n[17] Roberto Grossi, Ankur Gupta, and Jeffrey Scott Vitter. 2003. High-order entropy-\ncompressed text indexes. (2003).\n[18] D Gusfield. 1997. Algorithms on strings, trees, and sequences Cambridge Univer-\nsity Press. Cambridge, England (1997).\n[19] Benjamin Hilprecht, Andreas Schmidt, Moritz Kulessa, Alejandro Molina, Kristian\nKersting, and Carsten Binnig. 2019. Deepdb: Learn from data, not from queries!\narXiv preprint arXiv:1909.00607 (2019).\n[20] Darryl Ho, Jialin Ding, Sanchit Misra, Nesime Tatbul, Vikram Nathan, Vasimuddin\nMd, and Tim Kraska. 2019. LISA: towards learned DNA sequence search. arXiv\npreprint arXiv:1910.04728 (2019).\n[21] HV Jagadish, Raymond T Ng, and Divesh Srivastava. 1999. Substring selectiv-\nity estimation. In Proceedings of the eighteenth ACM SIGMOD-SIGACT-SIGART\nsymposium on Principles of database systems . 249â€“260.[22] Juha KÃ¤rkkÃ¤inen and Esko Ukkonen. 1996. Lempel-Ziv parsing and sublinear-size\nindex structures for string matching. In Proc. 3rd South American Workshop on\nString Processing (WSP) . 141â€“155.\n[23] Martin Kiefer, Max Heimel, Sebastian BreÃŸ, and Volker Markl. 2017. Estimating\njoin selectivities using bandwidth-optimized kernel density models. Proceedings\nof the VLDB Endowment 10, 13 (2017), 2085â€“2096.\n[24] Andreas Kipf, Michael Freitag, Dimitri Vorona, Peter Boncz, Thomas Neumann,\nand Alfons Kemper. 2019. Estimating filtered group-by queries is hard: Deep\nlearning to the rescue. In 1st International Workshop on Applied AI for Database\nSystems and Applications .\n[25] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and\nAlfons Kemper. 2018. Learned cardinalities: Estimating correlated joins with\ndeep learning. arXiv preprint arXiv:1809.00677 (2018).\n[26] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. In Proceedings of the third international workshop on exploiting artificial\nintelligence techniques for data management . 1â€“5.\n[27] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. In Proceedings of aiDM@SIGMOD 2020 . 5:1â€“5:5.\n[28] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The\nCase for Learned Index Structures. In Proceedings of the 2018 SIGMOD . 489â€“504.\n[29] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In Proceedings of the 2018 international\nconference on management of data . 489â€“504.\n[30] P Krishnan, Jeffrey Scott Vitter, and Bala Iyer. 1996. Estimating alphanumeric\nselectivity in the presence of wildcards. In Proceedings of the 1996 ACM SIGMOD\ninternational conference on Management of data . 282â€“293.\n[31] Suyong Kwon, Woohwan Jung, and Kyuseok Shim. 2022. Cardinality estimation\nof approximate substring queries using deep learning. Proceedings of the VLDB\nEndowment 15, 11 (2022), 3145â€“3157.\n[32] Hongrae Lee, Raymond T Ng, and Kyuseok Shim. 2007. Extending q-grams to\nestimate selectivity of string matching with low edit distance. In Proceedings of\nthe 33rd international conference on Very large data bases . Citeseer, 195â€“206.\n[33] Hongrae Lee, Raymond T Ng, and Kyuseok Shim. 2009. Approximate substring\nselectivity estimation. In Proceedings of the 12th International Conference on\nExtending Database Technology: Advances in Database Technology . 827â€“838.\n[34] Viktor Leis, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, and\nThomas Neumann. 2015. How good are query optimizers, really? (11 2015),\n204â€“215.\n[35] Heng Li. 2014. Fast construction of FM-index for long sequence reads. Bioinfor-\nmatics 30, 22 (2014), 3274â€“3275.\n[36] Richard J Lipton, Jeffrey F Naughton, and Donovan A Schneider. 1990. Practical\nselectivity estimation through adaptive sampling. In Proceedings of the 1990 ACM\nSIGMOD international conference on Management of data . 1â€“11.\n[37] Grigorios Loukides and Solon P. Pissis. 2021. Bidirectional String Anchors: A\nNew String Sampling Mechanism (LIPIcs, Vol. 204) . 64:1â€“64:21.\n[38] Grigorios Loukides, Solon P Pissis, et al .2023. Text indexing for long patterns:\nAnchors are all you need. In VLDB 2023-49th International Conference on Very\nLarge Data Bases , Vol. 16. 2117â€“2131.\n[39] Chen Luo and Michael J Carey. 2020. LSM-based storage techniques: a survey.\nThe VLDB Journal 29, 1 (2020), 393â€“418.\n[40] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Al-\nizadeh, and Tim Kraska. 2021. Bao: Making learned query optimization practical.\nInProceedings of the 2021 International Conference on Management of Data . 1275â€“\n1288.\n[41] Thomas Neumann and Sebastian Michel. 2008. Smooth interpolating histograms\nwith error guarantees. In British National Conference on Databases . Springer,\n126â€“138.\n[42] Patrick Oâ€™Neil, Edward Cheng, Dieter Gawlick, and Elizabeth Oâ€™Neil. 1996. The\nlog-structured merge-tree (LSM-tree). Acta Informatica 33 (1996), 351â€“385.\n[43] Suraj Shetiya, Saravanan Thirumuruganathan, Nick Koudas, and Gautam Das.\n2020. Astrid: accurate selectivity estimation for string predicates using deep\nlearning. Proceedings of the VLDB Endowment 14, 4 (2020).\n[44] Jared T Simpson and Richard Durbin. 2010. Efficient construction of an assembly\nstring graph using the FM-index. Bioinformatics 26, 12 (2010), i367â€“i373.\n[45] Kostas Tzoumas, Amol Deshpande, and Christian S Jensen. 2011. Lightweight\ngraphical models for selectivity estimation without independence assumptions.\nProceedings of the VLDB Endowment 4, 11 (2011), 852â€“863.\n[46] Esko Ukkonen. 1995. On-line construction of suffix trees. Algorithmica 14, 3\n(1995), 249â€“260.\n[47] Jiayi Wang, Chengliang Chai, Jiabin Liu, and Guoliang Li. 2021. FACE: A normal-\nizing flow based cardinality estimator. Proceedings of the VLDB Endowment 15, 1\n(2021), 72â€“84.\n[48] Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang, and\nMakoto Onizuka. 2020. Monotonic cardinality estimation of similarity selection:\nA deep learning approach. In Proceedings of the 2020 ACM SIGMOD International\nConference on Management of Data . 1197â€“1212.\n\nSSCard: Substring Cardinality Estimation using Suffix Tree-Guided Learned FM-Index SIGMOD,\n[49] Chenhao Xu, Chunyu Chen, Jinglin Peng, Jiannan Wang, and Jun Gao. 2025.\nBQSched: A Non-intrusive Scheduler for Batch Concurrent Queries via Rein-\nforcement Learning. arXiv:2504.19142 [cs.DB] https://arxiv.org/abs/2504.19142[50] Yuan Yao, Deming Ye, Peng Li, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu,\nLixin Huang, Jie Zhou, and Maosong Sun. 2019. DocRED: A large-scale document-\nlevel relation extraction dataset. arXiv preprint arXiv:1906.06127 (2019).\nReceived 20 February 2007; revised 12 March 2009; accepted 5 June 2009",
  "textLength": 80595
}