{
  "paperId": "703f5745c39e682949d91371e4e9667b6d79a6fb",
  "title": "QuickSel: Quick Selectivity Learning with Mixture Models",
  "pdfPath": "703f5745c39e682949d91371e4e9667b6d79a6fb.pdf",
  "text": "QuickSel: Quick Selectivity Learning\nwith Mixture Models\nYongjoo Park1*, Shucheng Zhong2*, Barzan Mozafari2\nUniversity of Illinois at Urbana-Champaign1University of Michigan2\nyongjoo@illinois.edu {joezhong,mozafari}@umich.edu\nABSTRACT\nEstimating the selectivity of a query is a key step in almost\nany cost-based query optimizer. Most of today’s databases\nrely on histograms or samples that are periodically refreshed\nby re-scanning the data as the underlying data changes. Since\nfrequent scans are costly, these statistics are often stale and\nlead to poor selectivity estimates. As an alternative to scans,\nquery-driven histograms have been proposed, which refine\nthe histograms based on the actual selectivities of the ob-\nserved queries. Unfortunately, these approaches are either\ntoo costly to use in practice—i.e., require an exponential\nnumber of buckets—or quickly lose their advantage as they\nobserve more queries.\nIn this paper, we propose a selectivity learning framework,\ncalled QuickSel, which falls into the query-driven paradigm\nbut does not use histograms. Instead, it builds an internal\nmodel of the underlying data, which can be refined signif-\nicantly faster (e.g., only 1.9 milliseconds for 300 queries).\nThis fast refinement allows QuickSel to continuously learn\nfrom each query and yield increasingly more accurate selec-\ntivity estimates over time. Unlike query-driven histograms,\nQuickSel relies on a mixture model and a new optimization\nalgorithm for training its model. Our extensive experiments\non two real-world datasets confirm that, given the same\ntarget accuracy, QuickSel is 34.0 ×–179.4×faster than state-\nof-the-art query-driven histograms, including ISOMER and\nSTHoles. Further, given the same space budget, QuickSel is\n26.8%–91.8% more accurate than periodically-updated his-\ntograms and samples, respectively.\n∗These authors contributed equally to this work.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies\nare not made or distributed for profit or commercial advantage and that\ncopies bear this notice and the full citation on the first page. Copyrights\nfor components of this work owned by others than the author(s) must\nbe honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific\npermission and/or a fee. Request permissions from permissions@acm.org.\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA\n©2020 Copyright held by the owner/author(s). Publication rights licensed\nto ACM.\nACM ISBN 978-1-4503-6735-6/20/06. . . $15.00\nhttps://doi.org/10.1145/3318464.3389727ACM Reference Format:\nYongjoo Park, Shucheng Zhong, Barzan Mozafari. 2020. QuickSel:\nQuick Selectivity Learning with Mixture Models. In Proceedings of\nthe 2020 ACM SIGMOD International Conference on Management of\nData (SIGMOD’20), June 14–19, 2020, Portland, OR, USA. ACM, New\nYork, NY, USA, Article 4, 19 pages. https://doi.org/10.1145/3318464.\n3389727\n1 INTRODUCTION\nEstimating the selectivity of a query—the fraction of input\ntuples that satisfy the query’s predicate—is a fundamen-\ntal component in cost-based query optimization, including\nboth traditional RDBMSs [ 2,3,7,9,83] and modern SQL-on-\nHadoop engines [ 42,88]. The estimated selectivities allow\nthe query optimizer to choose the cheapest access path or\nquery plan [54, 90].\nToday’s databases typically rely on histograms [ 2,7,9] or\nsamples [ 83] for their selectivity estimation. These structures\nneed to be populated in advance by performing costly table\nscans. However, as the underlying data changes, they quickly\nbecome stale and highly inaccurate. This is why they need to\nbe updated periodically, creating additional costly operations\nin the database engine (e.g., ANALYZE table ).1\nTo address the shortcoming of scan-based approaches, nu-\nmerous proposals for query-driven histograms have been\nintroduced, which continuously correct and refine the his-\ntograms based on the actual selectivities observed after run-\nning each query [ 11,12,20,53,67,76,86,93,96]. There\nare two approaches to query-driven histograms. The first\napproach [ 11,12,20,67], which we call error-feedback his-\ntograms , recursively splits existing buckets (both boundaries\nand frequencies) for every distinct query observed, such that\ntheir error is minimized for the latest query. Since the error-\nfeedback histograms do not minimize the (average) error\nacross multiple queries, their estimates tend to be much less\naccurate.\nTo achieve a higher accuracy, the second approach is to\ncompute the bucket frequencies based on the maximum\nentropy principle [ 53,76,86,93]. However, this approach\n1Some database systems [ 9] automatically update their statistics when the\nnumber of modified tuples exceeds a threshold.arXiv:1812.10568v2  [cs.DB]  10 Apr 2020\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nTable 1: The differences between query-driven histograms [53, 75, 76, 86, 93] and our method (QuickSel)\n. Query-driven Histograms QuickSel (ours) Our Contribution\nModel histograms\n(non-overlapping buckets)mixture models\n(overlapping subpopulations)Employs a new expressive model\n→no exponential growth of complexity\nTraining maximum entropy\nsolved by\niterative scalingmin difference from a uniform\ndistribution\nsolved analyticallyA new optimization objective and its reduction\nto quadratic programming (solved analytically)\n→fast training and model refinements\n(which is also the state-of-the-art) requires solving an opti-\nmization problem, which quickly becomes prohibitive as the\nnumber of observed queries (and hence, number of buckets)\ngrows. Unfortunately, one cannot simply prune the buckets\nin this approach, as it will break the underlying assumptions\nof their optimization algorithm (called iterative scaling , see\nSection 2.3 for details). Therefore, they prune the observed\nqueries instead in order to keep the optimization overhead\nfeasible in practice. However, this also means discarding data\nthat could be used for learning a more accurate distribution.\nOur Goal We aim to develop a new framework for se-\nlectivity estimation that can quickly refine its model after\nobserving each query, thereby producing increasingly more\naccurate estimates over time. We call this new framework\nselectivity learning . We particularly focus on designing a\nlow-overhead method that can scale to a large number of\nobserved queries without requiring an exponential number\nof buckets.\nOur Model To overcome the limitations of query-driven\nhistograms, we use a mixture model [18] to capture the un-\nknown distribution of the data. A mixture model is a proba-\nbilistic model to approximate an arbitrary probability density\nfunction (pdf), say f(x), using a combination of simpler pdfs:\nf(x)=mÕ\nz=1h(z)дz(x) (1)\nwhereдz(x)is the z-th simpler pdf and h(z)is its correspond-\ning weight. The subset of the data that follows each of the\nsimpler pdfs is called a subpopulation . Since the subpopu-\nlations are allowed to overlap with one another, a mixture\nmodel is strictly more expressive than histograms. In fact, it\nis shown that mixture models can achieve a higher accuracy\nthan histograms [ 25], which is confirmed by our empirical\nstudy (Section 5.5). To the best of our knowledge, we are the\nfirst to propose a mixture model for selectivity estimation.2\nChallenges Using a mixture model for selectivity learn-\ning requires finding optimal parameter values for h(z)and\n2Our mixture model also differs from kernel density estimation [19, 36, 41],\nwhich scans the actual data, rather than analyzing observed queries.дz(x); however, this optimization (a.k.a. training) is challeng-\ning for two reasons.\nFirst, the training process aims to find parameters that\nmaximize the model quality , defined as∫\nQ(f(x))dxfor\nsome metric of quality Q(e.g., entropy). However, computing\nthis integral is non-trivial for a mixture model since its sub-\npopulations may overlap in arbitrary ways. That is, the com-\nbinations of msubpopulations can create 2mdistinct ranges,\neach with a potentially different value of f(x). As a result,\nnaïvely computing the quality of a mixture model quickly be-\ncomes intractable as the number of observed queries grows.\nSecond, the outer optimization algorithms are often itera-\ntive (e.g., iterative scaling, gradient descent), which means\nthey have to repeatedly evaluate the model quality as they\nsearch for optimal parameter values. Thus, even when the\nmodel quality can be evaluated relatively efficiently, the over-\nall training/optimization process can be quite costly.\nOur Approach First, to ensure the efficiency of the model\nquality evaluation, we propose a new optimization objective.\nSpecifically, we find the parameter values that minimize the\nL2distance (or equivalently, mean squared error ) between\nthe mixture model and a uniform distribution, rather than\nmaximizing the entropy of the model (as pursued by previ-\nous work [ 53,75,76,86,93]). As described above, directly\ncomputing the quality of a mixture model involves costly\nintegrations over 2mdistinct ranges. However, when mini-\nmizing the L2distance, the 2mintegrals can be reduced to\nonly m2multiplications, hence greatly reducing the complex-\nity of the model quality evaluation. Although minimizing\ntheL2distance is much more efficient than maximizing the\nentropy, these two objectives are closely related (see our\nreport [16] for a discussion).\nIn addition, we adopt a non-conventional variant of mix-\nture models, called a uniform mixture model . While uniform\nmixture models have been previously explored in limited set-\ntings (with only a few subpopulations) [ 27,37], we find that\nthey are quite appropriate in our context as they allow for\nefficient computations of the L2distance. That is, with this\nchoice, we can evaluate the quality of a model by only using\nmin, max, and multiplication operations (Section 3.2). Finally,\nour optimization can be expressed as a standard quadratic\nprogram , which still requires an iterative procedure.\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\nTherefore, to avoid the costly iterative optimization, we\nalso devise an analytic solution that can be computed more\nefficiently. Specifically, in addition to the standard reduction\n(i.e., moving some of the original constraints to the objective\nclause as penalty terms), we completely relax the positivity\nconstraints for f(x), exploiting the fact that they will be\nnaturally satisfied in the process of approximating the true\ndistribution of the data. With these modifications, we can\nsolve for the solution analytically by setting the gradient of\nthe objective function to zero. This simple transformation\nspeeds up the training by 1.5 ×–17.2×. In addition, since our\nanalytic solution requires a constant number of operations,\nthe training time is also consistent across different datasets\nand workloads.\nUsing these ideas, we have developed a first prototype\nof our selectivity learning proposal, called QuickSel, which\nallows for extremely fast model refinements. As summarized\nin Table 1, QuickSel differs from—and considerably improves\nupon—query-driven histograms [ 11,53,67,76,86,93] in\nterms of both modeling and training (see Section 7 for a\ndetailed comparison).\nContributions We make the following contributions:\n1.We propose the first mixture model-based approach to\nselectivity estimation (Section 3).\n2.For training the mixture model, we design a constrained\noptimization problem (Section 4.1).\n3.We show that the proposed optimization problem can be\nreduced (from an exponentially complex one) to a qua-\ndratic program and present further optimization strategies\nfor solving it (Section 4.2).\n4.We conduct extensive experiments on two real-world\ndatasets to compare QuickSel’s performance and state-\nof-the-art selectivity estimation techniques (Section 5).\n2 PRELIMINARIES\nIn this section, we first define relevant notations in Sec-\ntion 2.1 and then formally define the problem of query-driven\nselectivity estimation in Section 2.2. Next, in Section 2.3, we\ndiscuss the drawbacks of previous approaches.\n2.1 Notations\nTable 2 summarizes the notations used throughout this paper.\nSet Notations Tis a relation that consists of dreal-valued\ncolumns C1, . . . , Cd.3The range of values in Ciis[li,ui]and\nthe cardinality (i.e., row count) of TisN=|T|. The tuples in\nTare denoted by x1, . . . , xN, where each xiis a size- dvector\nthat belongs to B0=[l1,u1]×···×[ ld,ud]. Geometrically, B0\nis the area bounded by a hyperrectangle whose bottom-left\n3Handling integer and categorical columns is discussed in Section 2.2.Table 2: Notations.\nSymbol Meaning\nT a table (or a relation)\nCi i-th column (or an attribute) of T;i=1, . . . , d\n|T| the number of tuples in T\n[li,ui] the range of the values in Ci\nx a tuple of T\nB0 the domain of x;[l1,u1]×···×[ ld,ud]\nPi i-th predicate\nBi hyperrectangle range for the i-th predicate\n|Bi| the size (of the area) of Bi\nx∈Bixbelongs to Bi; thus, satisfies Pi\nI(·) indicator function that returns 1 if its argument is\ntrue and 0 otherwise\nsi the selectivity of PiforT\n(Pi,si)i-th observed query\nn the total number of observed queries\nf(x) probability density function of tuple x(ofT)\ncorner is(l1, . . . , ld)and top-right corner is (u1, . . . , ud). The\nsize of B0can thus be computed as |B0|=(u1−l1)×···×( ud−ld).\nPredicates We use Pito denote the (selection) predicate\nof the i-th query on T. In this paper, a predicate is a con-\njunction4of one or more constraints . Each constraint is a\nrange constraint , which can be one-sided (e.g., 3≤C1) or\ntwo-sided (e.g.,−3≤C1≤10). This range can be extended\nto also handle equality constraints on categorical data (see\nSection 2.2). Each predicate Piis represented by a hyper-\nrectangle Bi. For example, a constraint “ 1≤C1≤3AND\n2≤C2” is represented by a hyperrectangle (1,3)×(2,u2),\nwhere u2is the upper-bound of C2. We use Poto denote an\nempty predicate, i.e., one that selects all tuples.\nSelectivity Theselectivity siofPiis defined as the fraction\nof the rows of Tthat satisfy the predicate. That is, si=\n(1/N)ÍN\nk=1I(xk∈Bi), where I(·)is the indicator function. A\npair(Pi,si)is referred to as an observed query .5Without loss\nof generality, we assume that nqueries have been observed\nforTand seek to estimate sn+1. Finally, we use f(x)to denote\nthe joint probability density function of tuple x(that has\ngenerated tuples of T).\n2.2 Problem Statement\nNext, we formally state the problem:\nProblem 1 (Query-driven Selectivity Estimation) Con-\nsider a set of nobserved queries(P1,s1), . . . ,(Pn,sn)forT. By\ndefinition, we have the following for each i=1, . . . , n:\n∫\nx∈Bif(x)dx=si\n4See Section 2.2 for a discussion of disjunctions and negations.\n5This pair is also referred to as an assertion by prior work [85].\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nThen, our goal is to build a model of f(x)that can estimate\nthe selectivity sn+1of a new predicate Pn+1.\nInitially, before any query is observed, we can conceptually\nconsider a default query (P0,1), where all tuples are selected\nand hence, the selectivity is 1 (i.e., no predicates).\nDiscrete and Categorical Values Problem 1 can be ex-\ntended to support discrete attributes (e.g., integers, charac-\nters, categorical values) and equality constraints on them, as\nfollows. Without loss of generality, suppose that Cicontains\nthe integers in{1,2, . . . , bi}. To apply the solution to Prob-\nlem 1, it suffices to (conceptually) treat these integers as real\nvalues in[1,bi+1]and then convert the original constraints\non the integer values into range constraints, as follows. A\nconstraint of the form “ Ci=k” will be converted to a range\nconstraint of the form k≤Ci<k+1. Mathematically, this\nis equivalent to replacing a probability mass function with a\nprobability density function defined using dirac delta func-\ntions .6Then, the summation of the original probability mass\nfunction can be converted to the integration of the proba-\nbility density function. String data types (e.g., char, varchar)\nand their equality constraints can be similarly supported, by\nconceptually mapping each string into an integer (preserving\ntheir order) and applying the conversion described above for\nthe integer data type.\nSupported Queries Similar to prior work [ 11,20,53,67,\n75,76,86,93], we support selectivity estimation for predi-\ncates with conjunctions, negations, and disjunctions of range\nand equality constraints on numeric and categorical columns.\nWe currently do not support wildcard constraints (e.g., LIKE\n’*word*’ ),EXISTS constraints, or ANYconstraints. In prac-\ntice, often a fixed selectivity is used for unsupported predi-\ncates, e.g., 3.125% in Oracle [83].\nTo simplify our presentation, we focus on conjunctive\npredicates. However, negations and disjunctions can also\nbe easily supported. This is because our algorithm only re-\nquires the ability to compute the intersection size of pairs\nof predicates PiandPj, which can be done by converting\nPi∧Pjinto a disjunctive normal form and then using the\ninclusion-exclusion principle to compute its size.\nAs in the previous work, we focus our presentation on\npredicates on a single relation. However, any selectivity es-\ntimation technique for a single relation can be applied to\nestimating selectivity of a join query whenever the predi-\ncates on the individual relations are independent of the join\nconditions [7, 42, 90, 98].\n6A dirac delta function δ(x)outputs∞ifx=0and outputs 0 otherwise\nwhile satisfying∫\nδ(x)dx=1.P1P2P3Split\nFigure 1: Bucket creation for query-driven histograms.\nP3is the range of a new predicate. The existing buckets\n(forP1andP2) are split into multiple buckets. The total\nnumber of buckets may grow exponentially as more\nqueries are observed.\n2.3 Why not Query-driven Histograms\nIn this section, we briefly describe how query-driven his-\ntograms work [ 11,20,53,67,76,86,93], and then discuss\ntheir limitations, which motivate our work.\nHow Query-driven Histograms Work To approximate\nf(x)(defined in Problem 1), query-driven histograms adjust\ntheir bucket boundaries and bucket frequencies according\nto the queries they observe. Specifically, they first determine\nbucket boundaries ( bucket creation step), and then compute\ntheir frequencies ( training step), as described next.\n1.Bucket Creation : Query-driven histograms determine their\nbucket boundaries based on the given predicate’s ranges [ 11,\n53,76,86,93]. If the range of a later predicate overlaps\nwith that of an earlier predicate, they split the bucket(s)\ncreated for the earlier one into two or more buckets in\norder to ensure that the buckets do not overlap with one\nanother. Figure 1 shows an example of this bucket splitting\noperation.\n2.Training : After creating the buckets, query-driven his-\ntograms assign frequencies to those buckets. Early work [ 11,\n67] determines bucket frequencies in the process of bucket\ncreations. That is, when a bucket is split into two or more,\nthe frequency of the original bucket is also split (or ad-\njusted), such that it minimizes the estimation error for the\nlatest observed query.\nHowever, since this process does not minimize the (av-\nerage) error across multiple queries, their estimates are\nmuch less accurate. More recent work [ 53,76,86,93] has\naddressed this limitation by explicitly solving an optimiza-\ntion problem based on the maximum entropy principle.\nThat is, they search for bucket frequencies that maximize\ntheentropy of the distribution while remaining consistent\nwith the actual selectivities observed.\nAlthough using the maximum entropy principle will lead\nto highly accurate estimates, it still suffers from two key\nlimitations.\nLimitation 1: Exponential Number of Buckets Since\nexisting buckets may split into multiple ones for each new\nobserved query, the number of buckets can potentially grow\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\nexponentially as the number of observed queries grows. For\nexample, in our experiment in Section 5.5, the number of\nbuckets was 22,370 for 100 observed queries, and 318,936 for\n300 observed queries. Unfortunately, the number of buckets\ndirectly affects the training time. Specifically, using iterative\nscaling —the optimization algorithm used by all previous\nwork [ 53,75,76,86,93]— the cost of each iteration grows\nlinearly with the number of variables (i.e., the number of\nbuckets). This means that the cost of each iteration can grow\nexponentially with the number of observed queries.\nAs stated in Section 1, we address this problem by employ-\ning a mixture model , which can express a probability distribu-\ntion more effectively than query-driven histograms. Specifi-\ncally, our empirical study in Section 5.5 shows that—using\nthe same number of parameters—a mixture model achieves\nconsiderably more accurate estimates than histograms.\nLimitation 2: Non-trivial Bucket Merge/Pruning Gi-\nven that query-driven histograms [ 76,93] quickly become\ninfeasible due to their large number of buckets, one might\nconsider merging or pruning the buckets in an effort to re-\nduce their training times. However, merging or pruning the\nhistogram buckets violates the assumption used by their opti-\nmization algorithms, i.e., iterative scaling. Specifically, itera-\ntive scaling relies on the fact that a bucket is either completely\nincluded in a query’s predicate range or completely outside of\nit.7That is, no partial overlap is allowed. This property must\nhold for each of the npredicates. However, merging some of\nthe buckets will inevitably cause partial overlaps (between\npredicate and histogram buckets). For interested readers, we\nhave included a more detailed explanation of why iterative\nscaling requires this assumption in Appendix A.\n3 QUICKSEL: MODEL\nThis section presents how QuickSel models the population\ndistribution and estimates the selectivity of a new query.\nQuickSel’s model relies on a probabilistic model called a mix-\nture model . In Section 3.1, we describe the mixture model\nemployed by QuickSel. Section 3.2 describes how to esti-\nmate the selectivity of a query using the mixture model.\nSection 3.3 describes the details of QuickSel’s mixture model\nconstruction.\n3.1 Uniform Mixture Model\nA mixture model is a probabilistic model that expresses a\n(complex) probability density function (of the population) as\na combination of (simpler) probability density functions (of\nsubpopulations ). The population distribution is the one that\n7For example, this property is required for the transition from Equation (6)\nto Equation (7) in [76].generates the tuple xofT. The subpopulations are internally\nmanaged by QuickSel to best approximate f(x).\nUniform Mixture Model QuickSel uses a type of mix-\nture model, called the uniform mixture model . The uniform\nmixture model represents a population distribution f(x)as a\nweighted summation of multiple uniform distributions, дz(x)\nforz=1, . . . , m. Specifically,\nf(x)=mÕ\nz=1h(z)дz(x)=mÕ\nz=1wzдz(x) (2)\nwhere h(z)is a categorical distribution that determines the\nweight of the z-th subpopulation, and дz(x)is the probability\ndensity function (which is a uniform distribution) for the z-\nth subpopulation. The support of h(z)is the integers ranging\nfrom 1 to m;h(z)=wz. The support for дz(x)is represented\nby a hyperrectangle Gz. Sinceдz(x)is a uniform distribution,\nдz(x)=1/|Gz|ifx∈Gzand 0 otherwise. The locations of\nGzand the values of wzare determined in the training stage\n(Section 4). In the remainder of this section (Section 3), we\nassume that Gzandwzare given.\nBenefit of Uniform Mixture Model The uniform mix-\nture model was studied early in the statistics community [ 27,\n37]; however, recently, a more complex model called the\nGaussian mixture model has received more attention [ 18,84,\n110].8The Gaussian mixture model uses a Gaussian distribu-\ntion for each subpopulation; the smoothness of its probability\ndensity function (thus, differentiable) makes the model more\nappealing when gradients need to be computed. Neverthe-\nless, we intentionally use the uniform mixture model for\nQuickSel due to its computational benefit in the training\nprocess, as we describe below.\nAs will be presented in Section 4.2, QuickSel’s training\ninvolves the computations of the intersection size between\ntwo subpopulations, for which the essential operation is\nevaluating the following integral:\n∫\nдz1(x)дz2(x)dx\nEvaluating the above expression for multivariate Gaussian\ndistributions, e.g., дz1(x)=exp\u0000\n−x⊤Σ−1x\u0001/p\n(2π)d|Σ|, re-\nquires numerical approximations [ 32,51], which are either\nslow or inaccurate. In contrast, the intersection size between\ntwo hyperrectangles can be exactly computed by simple min,\nmax, and multiplication operations.\n3.2 Selectivity Estimation with UMM\nFor the uniform mixture model, computing the selectivity of\na predicate Piis straightforward:\n8There are other variants of mixture models [15, 79].\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nPredicate rangesGenerates points\nusing\npredicate ranges\nWorkload-aware pointsCreates ranges\nthat cover\nthe points\nSubpopulation ranges\n(a) Case 1: Highly-overlapping query workloads\nPredicate rangesGenerates points\nusing\npredicate ranges\nWorkload-aware pointsCreates ranges\nthat cover\nthe points\nSubpopulation ranges\n(b) Case 2: Scattered query workloads\nFigure 2: QuickSel’s subpopulation creation. Due to the property of mixture model (i.e., subpopulations may over-\nlap with one another), creating subpopulations is straightforward for diverse query workloads.\n∫\nBif(x)dx=∫\nBimÕ\nz=1wzдz(x)dx=mÕ\nz=1wz∫\nBiдz(x)dx\n=mÕ\nz=1wz∫1\n|Gz|I(x∈Gz∩Bi)dx=mÕ\nz=1wz|Gz∩Bi|\n|Gz|\nRecall that both GzandBiare represented by hyperrect-\nangles. Thus, their intersection is also a hyperrectangle, and\ncomputing its size is straightforward.\n3.3 Subpopulations from Observed Queries\nWe describe QuickSel’s approach to determining the bound-\naries of Gzforz=1, . . . , m. Note that determining Gzis\northogonal to the model training process, which we describe\nin Section 4; thus, even if one devises an alternative approach\nto creating Gz, our fast training method is still applicable.\nQuickSel creates mhyperrectangular ranges9(for the sup-\nports of its subpopulations) in a way that satisfies the fol-\nlowing simple criterion: if more predicates involve a point x,\nuse a larger number of subpopulations for x. Unlike query-\ndriven histograms, QuickSel can easily pursue this goal by\nexploiting the property of a mixture model: the supports of\nsubpopulations may overlap with one another.\nIn short, QuickSel generates multiple points (using predi-\ncates) that represent the query workloads and create hyper-\nrectangles that can sufficiently cover those points. Specifi-\ncally, we propose two approaches for this: a sampling-based\n9The number mof subpopulations is set to min(4·n,4,000), by default.one and a clustering-based one. The sampling-based ap-\nproach is faster; the clustering-based approach is more accu-\nrate. Each of these is described in more detail below.\nSampling-based This approach performs the following\noperations for creating Gzforz=1, . . . , m.\n1.Within each predicate range, generate multiple random\npoints r. Generating a large number of random points\nincreases the consistency; however, QuickSel limits the\nnumber to 10 since having more than 10 points did not\nimprove accuracy in our preliminary study.\n2.Use simple random sampling to reduce the number of\npoints to m, which serves as the centers of Gzforz=\n1, . . . , m.\n3. The length of the i-th dimension of Gzis set to twice the\naverage of the distances (in the same i-th dimension) to\nthe 10 nearest-neighbor centers.\nFigure 2 illustrates how the subpopulations are created using\nboth (1) highly-overlapping query workloads and (2) scat-\ntered query workloads. In both cases, QuickSel generates\nrandom points to represent the distribution of query work-\nloads, which is then used to create Gz(z=1, . . . , m), i.e., the\nsupports of subpopulations. This sampling-based approach\nis faster, but it does not ensure the coverage of all random\npoints r. In contrast, the following clustering-based approach\nensures that.\nClustering-based The second approach relies on a clus-\ntering algorithm for generating hyperrectangles:\n1. Do the same as the sampling-based approach.\n2. Cluster rintomgroups. (We used K-means++.)\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\n3.For each of mgroups, we create the smallest hyperrectan-\ngleGzthat covers all the points belonging to the group.\nNote that since each rbelongs to a cluster and we have cre-\nated a hyperrectangle that fully covers each cluster, the union\nof the hyperrectangles covers all r. Our experiments primar-\nily use the sampling-based approach due to its efficiency, but\nwe also compare them empirically in Section 5.7.\nThe following section describes how to assign the weights\n(i.e.,h(z)=wz) of these subpopulations.\n4 QUICKSEL: MODEL TRAINING\nThis section describes how to compute the weights wzof\nQuickSel’s subpopulations. For training its model, Quick-\nSel finds the model that maximizes uniformity while being\nconsistent with the observed queries. In Section 4.1, we for-\nmulate an optimization problem based on this criteria. Next,\nSection 4.2 presents how to solve the problem efficiently.\n4.1 Training as Optimization\nThis section formulates an optimization problem for Quick-\nSel’s training. Let д0(x)be the uniform distribution with\nsupport B0; that is,д0(x)=1/|B0|ifx∈B0and 0 otherwise.\nQuickSel aims to find the model f(x), such that the difference\nbetween f(x)andд0(x)is minimized while being consistent\nwith the observed queries.\nThere are many metrics that can measure the distance\nbetween two probability density functions f(x)andд0(x),\nsuch as the earth mover’s distance [ 89], Kullback-Leibler di-\nvergence [ 63], the mean squared error (MSE), the Hellinger\ndistance, and more. Among them, QuickSel uses MSE (which\nis equivalent to L2distance between two distributions) since\nit enables the reduction of our originally formulated opti-\nmization problem (presented shortly; Problem 2) to a qua-\ndratic programming problem, which can be solved efficiently\nby many off-the-shelf optimization libraries [ 1,4,5,14]. Also,\nminimizing MSE between f(x)andд0(x)is closely related to\nmaximizing the entropy of f(x)[53,76,86,93]. See Section 6\nfor the explanation of this relationship.\nMSE between f(x)andд0(x)is defined as follows:\nMSE(f(x),д0(x))=∫\n(f(x)−д0(x))2dx\nRecall that the support for д0(x)isB0. Thus, QuickSel obtains\nthe optimal weights by solving the following problem.Problem 2 (QuickSel’s Training) QuickSel obtains the op-\ntimal parameter wfor its model by solving:\narg min\nw∫\nx∈B0\u0012\nf(x)−1\n|B0|\u00132\ndx (3)\nsuch that∫\nBif(x)dx=sifori=1, . . . , n (4)\nf(x)≥0 (5)\nHere, (5) ensures f(x)is a proper probability density function.\n4.2 Efficient Optimization\nWe first describe the challenges in solving Problem 2. Then,\nwe describe how to overcome the challenges.\nChallenge Solving Problem 2 in a naïve way is computa-\ntionally intractable. For example, consider a mixture model\nconsisting of (only) two subpopulations represented by G1\nandG2, respectively. Then,∫\nx∈B0(f(x)−д0(x))2dxis:\n∫\nx∈G1∩G2\u0012w1+w2\n|G1∩G2|−д0(x)\u00132\ndx\n+∫\nx∈G1∩¬G2\u0012w1\n|G1∩¬G2|−д0(x)\u00132\ndx\n+∫\nx∈¬G1∩G2\u0012w2\n|¬G1∩G2|−д0(x)\u00132\ndx\n+∫\nx∈¬G1∩¬G2\u00120\n|¬G1∩¬G2|−д0(x)\u00132\ndx\nObserve that with this approach, we need four separate inte-\ngrations only for two subpopulations. In general, the number\nof integrations is O(2m), which is O(2n). Thus, this direct\napproach is computationally intractable.\nConversion One: Quadratic Programming Problem 2\ncan be solved efficiently by exploiting the property of the\ndistance metric of our choice (i.e., MSE) and the fact that\nwe use uniform distributions for subpopulations (i.e., UMM).\nThe following theorem presents the efficient approach.\nTheorem 1 The optimization problem in Problem 2 can be\nsolved by the following quadratic optimization:\narg min\nww⊤Qw\nsuch that Aw=s,w≽0\nwhere\n(Q)ij=|Gi∩Gj|\n|Gi||Gj|(A)ij=|Bi∩Gj|\n|Gj|\nThe bendy inequality sign ( ≽) means that every element of\nthe vector on the left-hand side is equal to or larger than the\ncorresponding element of the vector on the right-hand side.\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nProof. This theorem can be shown by substituting the\ndefinition of QuickSel’s model (Equation (2)) into the proba-\nbility density function f(x)in Equation (3). Note that mini-\nmizing(f(x)−д0(x))2is equivalent to minimizing f(x)(f(x)−\n2д0(x)), which is also equivalent to minimizing (f(x))2since\nд0(x)is constant over B0and∫\nf(x)dx=1.\nThe integration of (f(x))2over B0can be converted to a\nmatrix multiplication, as shown below:\n∫\n(f(x))2dx=∫\"mÕ\nz=1wzI(x∈Gz)\n|Gz|#2\ndx\n=∫ mÕ\ni=1mÕ\nj=1wiwj\n|Gi||Gj|I(x∈Gi)I(x∈Gj)dx\nwhich can be simplified to\nmÕ\ni=1mÕ\nj=1wiwj\n|Gi||Gj||Gi∩Gj|\n=w1\nw2\n...\nwm⊤|G1∩G1|\n|G1||G1|···|G1∩Gm|\n|G1||Gm|\n......\n|Gm∩G1|\n|Gm||G1|···|Gm∩Gm|\n|Gm||Gm|w1\nw2\n...\nwm\n=w⊤Qw\nSecond, we express the equality constraints in an alter-\nnative form. Note that the left-hand side of each equality\nconstraint, i.e.,∫\nBif(x)dx, can be expressed as:\n∫\nBif(x)dx=∫\nBimÕ\nj=1wj\n|Gj|I(x∈Gj)dx\n=mÕ\nj=1wj\n|Gj|∫\nBiI(x∈Gj)dx=mÕ\nj=1wj\n|Gj||Bi∩Gj|\n=h\n|Bi∩G1|\n|G1|···|Bi∩Gm|\n|Gm|iw1\n...\nwm\nThen, the equality constraints, i.e.,∫\nBif(x)dx=sifori=\n1, . . . , n, can be expressed as follows:\n|B1∩G1|\n|G1|···|B1∩Gm|\n|Gm|\n.........\n|Bn∩G1|\n|G1|···|Bn∩Gm|\n|Gm|w1\n...\nwm=s1\n...\nsm\n⇒ Aw=s\nFinally, w⊤1=1if and only if∫\nf(x)=1, and w≽0for\narbitrary Gzif and only if∫\nf(x)≥0. □\nThe implication of the above theorem is significant: we\ncould reduce the problem of O(2n)complexity to the problem\nof only O(n2)complexity.Conversion Two: Moving Constraints The quadratic\nprogramming problem in Theorem 1 can be solved efficiently\nby most off-the-shelf optimization libraries; however, we can\nsolve the problem even faster by converting the problem to\nan alternative form. We first present the alternative problem,\nthen discuss it.\nProblem 3 (QuickSel’s QP) QuickSel solves this problem al-\nternative to the quadratic programming problem in Theorem 1:\narg min\nwℓ(w)=w⊤Qw+λ∥Aw−s∥2\nwhereλis a large real value (QuickSel uses λ=106).\nIn formulating Problem 3, two types of conversions are\nperformed: (1) the consistency with the observed queries\n(i.e., Aw=s) is moved into the optimization objective as a\npenalty term, and (2) the positivity of f(x)is not explicitly\nspecified (by w≽0). These two types of conversions have\nlittle impact on the solution for two reasons. First, to guar-\nantee the consistency, a large penalty (i.e., λ=106) is used.\nSecond, the mixture model f(x)is bound to approximate the\ntrue distribution, which is always non-negative. We empiri-\ncally examine the advantage of solving Problem 3 (instead\nof solving the problem in Theorem 1 directly) in Section 5.7.\nThe solution w∗to Problem 3 can be obtained in a straight-\nforward way by setting its gradients of the objective (with\nrespect to w) equal to 0:\n∂ℓ(w∗)\n∂w=2Qw∗+2λA⊤(Aw∗−s)=0\n⇒w∗=\u0000Q+λA⊤A\u0001−1λAs\nObserve that w∗is expressed in a closed form; thus, we can\nobtain w∗analytically instead of using iterative procedures\ntypically required for general quadratic programming.\n5 EXPERIMENT\nIn this section, we empirically study QuickSel. In summary,\nour results show the following:\n1.End-to-end comparison against other query-driven\nmethods: QuickSel was significantly faster (34.0 ×–179.4×)\nfor the same accuracy—and produced much more accu-\nrate estimates (26.8%–91.8% lower error) for the same time\nlimit—than previous query-driven methods. (Section 5.2)\n2.Comparison against periodic database scans: For the\nsame storage size, QuickSel’s selectivity estimates were\n77.7% and 91.3% more accurate than scan-based histograms\nand sampling, respectively. (Section 5.3)\n3.Impact on PostgreSQL performance: Using QuickSel\nfor PostgreSQL makes the system 2.25 ×faster (median)\nthan the default. (Section 5.4)\n4.Effectiveness of QuickSel’s mixture model: QuickSel’s\nmodel produced considerably more accurate estimates\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\nthan histograms given the same number of parameters.\n(Section 5.5)\n5.Robustness to workload shifts: QuickSel’s accuracy\nquickly recovers after sudden workload shifts. (Section 5.6)\n6.Optimization efficiency: QuickSel’s optimization method\n(Problem 3) was 1.5 ×–17.2×faster than solving the stan-\ndard quadratic programming. (Section 5.7)\n5.1 Experimental Setup\nMethods Our experiments compare QuickSel to six other\nselectivity estimation methods.\nQuery-driven Methods:\n1.STHoles [ 20]: This method creates histogram buckets by\npartitioning existing buckets (as in Figure 1). The fre-\nquency of an existing bucket is distributed uniformly\namong the newly created buckets.\n2.ISOMER [ 93]: This method applies STHoles for histogram\nbucket creations, but it computes the optimal frequencies\nof the buckets by finding the maximum entropy distri-\nbution. Among existing query-driven methods, ISOMER\nproduced the highest accuracy in our experiments.\n3.ISOMER+QP: This method combines ISOMER’s approach\nfor creating histogram buckets and QuickSel’s quadratic\nprogramming (Problem 3) for computing the optimal bucket\nfrequencies.\n4.QueryModel [ 13]: This method computes the selectivity\nestimate by a weighted average of the selectivities of ob-\nserved queries. The weights are determined based on the\nsimilarity of the new query and each of the queries ob-\nserved in the past.\nScan-based Methods:\n5.AutoHist: This method creates an equiwidth multidimen-\nsional histogram by scanning the data. It also updates its\nhistogram whenever more than 20% of the data changes\n(this is the default setting with SQL Server’s AUTO_UPDATE_\nSTATISTICS option [8]).\n6.AutoSample: This method relies on a uniform random\nsample of data to estimate selectivities. Similar to AutoHist,\nAutoSample updates its sample whenever more than 10%\nof the data changes.\nWe have implemented all methods in Java.\nDatasets and Query Sets We use two real datasets and\none synthetic dataset in our experiments, as follows:\n1.DMV: This dataset contains the vehicle registration records\nof New York State [ 95]. It contains 11,944,194 rows. Here,\nthe queries ask for the number of valid registrations for\nvehicles produced within a certain date range. Answer-\ning these queries involves predicates on three attributes:\nmodel_year ,registration_date , and expiration_date .2.Instacart : This dataset contains the sales records of an\nonline grocery store [ 94]. We use their orders table, which\ncontains 3.4 million sales records. Here, the queries ask\nfor the reorder frequency for orders made during differ-\nent hours of the day. Answering these queries involves\npredicates on two attributes: order_hour_of_day and\ndays_since_prior . (In Section 5.3, we use more attributes\n(up to ten).)\n3.Gaussian : We also generated a synthetic dataset using\na bivariate dimensional normal distribution. We varied\nthis dataset to study our method under workload shifts,\ndifferent degrees of correlation between the attributes, and\nmore. Here, the queries count the number of points that\nlie within a randomly generated rectangle.\nFor each dataset, we measured the estimation quality using\n100 test queries not used for training. The ranges for selection\npredicates (in queries) were generated randomly within a\nfeasible region; the ranges of different queries may or may\nnot overlap.\nEnvironment All our experiments were performed on\nm5.4xlarge EC2 instances, with 16-core Intel Xeon 2.5GHz\nand 64 GB of memory running Ubuntu 16.04.\nMetrics We use the root mean square (RMS) error:\nRMS error = \n1\nttÕ\ni=1(true_sel−est_sel)2!1/2\nwhere tis the number of test queries. We report the RMS\nerrors in percentage (by treating both true_sel and est_sel\nas percentages).\nWhen reporting training time, we include the time re-\nquired for refining a model using an additional observed\nquery, which itself includes the time to store the query and\nrun the necessary optimization routines.\n5.2 Selectivity Estimation Quality\nIn this section, we compare the end-to-end selectivity esti-\nmation quality of QuickSel versus query-driven histograms.\nSpecifically, we gradually increased the number of observed\nqueries provided to each method from 10 to 1,000. For each\nnumber of observed queries, we measured the estimation\nerror and training time of each method using 100 test queries.\nThese results are reported in Figure 3. Given the same\nnumber of observed queries, QuickSel’s training was sig-\nnificantly faster (Figures 3a and 3d), while still achieving\ncomparable estimation errors (Figures 3b and 3e). We also\nstudied the relationship between errors and training times\nin Figures 3c and 3f, confirming QuickSel’s superior effi-\nciency (STHoles, ISOMER+QP, and QueryModel are omitted\nin these figures due to their poor performance). In summary,\nQuickSel was able to quickly learn from a large number of\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\n102030405060708090100020406080100\nNumber of Observed QueriesTime (ms)STHoles ISOMER ISOMER+QP QueryModel QuickSel (ours)\n(a) # queries vs. Time (data: DMV)0 10 20 30 40 500%10%20%30%\nTime per Query (ms)RMS Error\n(b) Time vs. Err (data: DMV)10% 5% 4% 3% 2%0.11101001000\nRMS ErrorTime (ms)ISOMER QuickSel\n(c) Error vs. Time (data: DMV)\n102030405060708090100020406080100\nNumber of Observed QueriesTime (ms)\n(d) # queries vs. Time ( Instacart )0 10 20 30 40 500%2%4%6%8%10%\nTime per Query (ms)RMS Error\n(e) Time vs. Err (data: Instacart )1.5% 1.0% 0.5% 0.4% 0.3%0.1110100100010K\nRMS ErrorTime (ms)\n(f) Error vs. Time (data: Instacart )\nFigure 3: Comparison between QuickSel and query-driven histograms. The lower, the better. Left: The per-query\noverhead of QuickSel was extremely low. Middle: QuickSel was the most accurate for the same time budget. Right:\nQuickSel required significantly less time for the same accuracy.\n0200 400 600 800 10000%2%4%6%8%\nQuery Sequence NumberRMS ErrorAutoHist AutoSample QuickSel\n(a) Accuracy under Data\nChangeHist Sample QuickSel1101001000Time (ms)\n(b) Model Update Time2 4 6 8 100%10%20%30%40%50%60%Dataset: Instacart\nData DimensionRMS Error\n12 4 6 8 100%20%40%60%80%100%Dataset: Gaussian\nData DimensionRMS Error\n(c) Sensitivity to Data Dimension\nFigure 4: QuickSel versus periodically updating scan-based methods (given the same storage size).\nobserved queries (i.e., shorter training time) and produce\nhighly accurate models.\n5.3 Comparison to Scan-based Methods\nWe also compared QuickSel to two automatically-updating\nscan-based methods, AutoHist and AutoSample, which in-\ncorporate SQL Server’s automatic updating rule into equi-\nwidth multidimensional histograms and samples, respec-\ntively. Since both methods incur an up-front cost for ob-\ntaining their statistics, they should produce relatively more\naccurate estimates initially (before seeing new queries). In\ncontrast, the accuracy of QuickSel’s estimates should quickly\nimprove as new queries are observed.\nTo verify this empirically, we first generated a Gaussian\ndataset (1 million tuples) with correlation 0. We then in-\nserted 200K new tuples generated from a distribution with\nadifferent correlation after processing 200 queries, and re-\npeated this process. In other words, after processing the first100 queries, we inserted new data with correlation 0.1; af-\nter processing the next 100 queries, we inserted new data\nwith correlation 0.2; and continued this process until a total\nof 1000 queries were processed. We performed this process\nfor each method under comparison. QuickSel adjusted its\nmodel each time after observing 100 queries. AutoHist and\nAutoSample updated their statistics after each batch of data\ninsertion. QuickSel and AutoHist both used 100 parameters\n(# of subpopulations for the mixture model and # of buckets\nfor histograms); AutoSample used a sample of 100 tuples.\nFigure 4a shows the error of each method. As expected,\nAutoHist produced more accurate estimates initially. How-\never, as more queries were processed, the error of QuickSel\ndrastically decreased. In contrast, the errors of AutoSample\nand AutoHist did not improve with more queries, as they\nonly depend on the frequency at which a new scan (or sam-\npling) is performed. After processing only 100 queries (i.e.,\ninitial update), QuickSel produced more accurate estimates\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\n0 100 200 300 400 500 600 700 800 900 1,0000×1×2×3×4×\nQuery NumberSpeedup\n(a) Individual Query Speedup over Postgres DefaultSpeedup Stat Value\nMax 3.47 ×\nMedian 2.25 ×\nAverage 2.09 ×\nMin 0.98 ×\n(b) Summary of Speedup\nFigure 5: QuickSel’s impact on PostgreSQL query performance. We compared (1) PostgreSQL default and (2) Post-\ngreSQL with QuickSel. The left figure shows individual query speedups (note: the original latencies were between\n5.2–9.1 secs). The speedup values around 1 ×were due to no query plan change despite different estimates. The\nright figure summarizes those speedup numbers.\n10 20 30 40 50 60 70 80 90100010002000300040005000\nNumber of Observed QueriesNumber of\nModel Params\n(a) # of queries vs. # of parameters (data: Instacart )0 1000 2000 3000 40000%2%4%6%8%10%\nNumber of Model ParametersRel. ErrorSTHoles\nISOMER\nISOMER+QP\nQueryModel\nQuickSel (ours)\n(b) # of parameters vs. Error (data: Instacart )\nFigure 6: Comparison between QuickSel’s model and the models of query-driven histograms. The lower, the bet-\nter, Left: For the same number of observed queries, QuickSel used the least number of model parameters. Right:\nQuickSel’s model was more effective in expressing the data distribution, yielding the lowest error.\nthan both AutoHist and AutoSample. On average (including\nthe first 100 queries), QuickSel was 71.4% and 89.8% more\naccurate than AutoHist and AutoSample, respectively. This\nis consistent with the previously reported observations that\nquery-driven methods yield better accuracy than scan-based\nones [ 20]. (The reason why query-driven proposals have not\nbeen widely adopted to date is due to their prohibitive cost;\nsee Section 7.2).\nIn addition, Figure 4b compares the update times of the\nthree methods. By avoiding scans, QuickSel’s query-driven\nupdates were 525×and 243×faster than AutoHist and Au-\ntoSample, respectively.\nFinally, we studied how the performance of those methods\nchanged as we increased the data dimension (i.e., the number\nof attributes appearing in selection predicates). First, using\ntheInstacart dataset, we designed each query to target a\nrandom subset of dimensions (N/2) as increasing the dimen-\nsion N from 2 to 10. In all test cases (Figure 4c left), QuickSel\n’s accuracy was consistent, showing its ability to scale to\nhigh-dimensional data. Also in this experiment, QuickSel\nperformed significantly better than, or comparably to, his-\ntograms and sampling. We could also obtain a similar result\nusing the Gaussian dataset (Figure 4c right). This consistent\nperformance across different data dimensions is primarilydue to how QuickSel is designed; that is, its estimation only\ndepends on how much queries overlap with one another.\n5.4 Impact on Query Performance\nThis section examines QuickSel’s impact on query perfor-\nmance. That is, we test if QuickSel’s more accurate selectivity\nestimates can lead to improved query performance for actual\ndatabase systems (i.e., shorter latency).\nTo measure the actual query latencies, we used PostgreSQL\nver. 10 with a third-party extension, called pg_hint_plan [6].\nUsing this extension, we enforced our own estimates (for\nPostgreSQL’s query optimization) in place of the default\nones. We compared PostgreSQL Default (i.e., no hint) and\nQuickSel—to measure the latencies of the following join\nquery in processing the Instacart dataset:\nselect count (*)\nfrom S inner join T on S. tid = T. tid\ninner join U on T. uid = U. uid\nwhere ( range_filter_on_T )\nand ( range_filter_on_S );\nwhere the joins keys for the tables S,T, and Uwere in the PK-\nFK relationship, as described by the schema (of Instacart ).\nFigure 5 shows the speedups QuickSel could achieve in\ncomparison to PostgreSQL Default. Note that QuickSel does\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\n0 50 100 150 200 250 3000%1%2%3%4%\nQuery Sequence NumberRMS ErrorHistograms\nSampling\nQuickSel\nFigure 7: Robustness to sudden workload shifts, which\noccurred at the sequence #100 and at #200. QuickSel’s\nerror increased temporarily right after each workload\njump, but it reduced soon.\n0 200 400 600 800 1,000020406080100\nNumber of Observed QueriesRuntime (ms)Standard QP\nQuickSel’s QP\nFigure 8: QuickSel’s optimization effect.\nnot improve any underlying I/O or computation speed; its\nspeedups are purely from helping PostgreSQL’s query opti-\nmizer choose a more optimal plan based on improved selec-\ntivity estimates. Even so, QuickSel could bring 2.25 ×median\nspeedup, with 3.47 ×max speedup. In the worst case, Post-\ngreSQL with QuickSel was almost identical to PostgreSQL\nDefault (i.e., 0.98×speedup).\n5.5 QuickSel’s Model Effectiveness\nIn this section, we compare the effectiveness of QuickSel’s\nmodel to that of models used in the previous work. Specif-\nically, the effectiveness is assessed by (1) how the model\nsize—its number of parameters—grows as the number of ob-\nserved queries grows, and (2) how quickly its error decreases\nas its number of parameters grows.\nFigure 6a reports the relationship between the number\nof observed queries and the number of model parameters.\nAs discussed in Section 2.3, the number of buckets (hence,\nparameters) of ISOMER increased quickly as the number of\nobserved queries grew. STHoles was able to keep the number\nof its parameters small due to its bucket merging technique;\nhowever, this had a negative impact on its accuracy. Here,\nQuickSel used the least number of model parameters. For\ninstance, when 100 queries were observed for DMV, Quick-\nSel had 10×fewer parameters than STHoles and 56 ×fewer\nparameters than ISOMER.\nWe also studied the relationship between the number of\nmodel parameters and the error. The lower the error (for the\nsame number of model parameters), the more effective the\nmodel. Figure 6b shows the result. Given the same number of2 4 6 8100.0%0.5%1.0%1.5%2.0%2.5%3.0%\nData DimensionRMS ErrorSampling-based Clustering-based\n(a) Accuracy2 4 6 81005101520\nData DimensionOverhead (ms)\n(b) Per-query Overhead\nFigure 9: Subpopulation generation approaches.\nClustering-based was more accurate, but slower.\nmodel parameters, QuickSel produced significantly more ac-\ncurate estimates. Equivalently, QuickSel produced the same\nquality estimates with much fewer model parameters.\n5.6 Robustness to Workload Shifts\nIn this section, we test QuickSel’s performance under sig-\nnificant workload shifts. That is, after observing a certain\nnumber of queries (i.e., 100 queries) around a certain region\nof data, the query workload suddenly jumps to a novel region.\nThis pattern repeats several times.\nFigure 7 shows the result. Here, we could observe the\nfollowing pattern. QuickSel’s error increased significantly\nright after each jump (i.e., at query sequence #100 and at\n#200), producing 1.5 ×-3.6×higher RMS errors compared\nto histograms. However, QuickSel’s error dropped quickly,\nachieving 12×-378×lower RMS errors than histograms. This\nwas possible due to QuickSel’s faster adaptation.\n5.7 QuickSel Internal Mechanisms\nIn this section, we empirically study (1) the effect of Quick-\nSel’s optimization (presented in Section 4.2), and (2) two\nalternative mechanisms for generating subpopulations (pre-\nsented in Section 3.3).\nOptimization Efficiency To study QuickSel’s optimiza-\ntion efficiency, we compared two approaches for solving the\nquadratic problem defined in Theorem 1: solving the original\nQP without any modifications versus solving our modified\nversion (Problem 3). We used the cvxopt library for the for-\nmer and used jblas (a linear algebra library) for the latter.\nBoth libraries use multiple cores for parallel processing.\nFigure 8 shows the time taken by each optimization ap-\nproach. The second approach (Problem 3) was increasingly\nmore efficient as the number of observed queries grew. For\nexample, it was 8.36 ×faster when the number of observed\nqueries reached 1,000. This is thanks to the modified prob-\nlem having an analytical solution, while the original problem\nrequired an iterative gradient descent solution.\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\nSubpopulation Generation We empirically studied the\ntwo subpopulation generation approaches (i.e., the sampling-\nbased approach and the clustering-based approach, Section 3.3)\nin terms of their scalability to high-dimensional data. Specif-\nically, we compared their estimation accuracies and com-\nputational overhead using the Gaussian dataset (with its\ndimension set to 2–10).\nFigure 9 reports the results. As shown in Figure 9(a), the\nclustering-based approach obtained impressive accuracy in\ncomparison to the sampling-based one. However, as shown in\nFigure 9(b), the clustering-based approach produced higher\noverhead (i.e., longer training times), which is an example\nof the natural tradeoff between cost and accuracy.\n6 CONNECTION: MSE AND ENTROPY\nThe max-entropy query-driven histograms optimize their\nparameters (i.e., bucket frequencies) by searching for the\nparameter values that maximize the entropy of the distri-\nbution f(x). We show that this approach is approximately\nequivalent to QuickSel’s optimization objective, i.e., minimiz-\ning the mean squared error (MSE) of f(x)from a uniform\ndistribution. The entropy of the probability density func-\ntion is defined as −∫\nf(x)log(f(x))dx. Thus, maximizing\nthe entropy is equivalent to minimizing∫\nf(x)log(f(x))dx,\nwhich is related to minimizing MSE as follows:\narg min∫\nf(x)log(f(x))dx≈arg min∫\nf(x)(f(x)−1)dx\n=arg min∫\n(f(x))2dx\nsince∫\nf(x)dx=1by definition. We used the first-order\nTaylor expansion to approximate log(x)with x−1. Note that,\nwhen the constraint∫\nf(x)dx=1is considered, f(x)=\n1/|R0|is the common solution to both the entropy maximiza-\ntion and minimizing MSE.\n7 RELATED WORK\nThere is extensive work on selectivity estimation due to its\nimportance for query optimization. In this section, we review\nboth scan-based (Section 7.1) and query-driven methods (Sec-\ntion 7.2). QuickSel belongs to the latter category. We have\nsummarized the related work in Table 3.\n7.1 Database Scan-based Estimation\nAs explained in Section 1, we use the term scan-based methods\nto refer to techniques that directly inspect the data (or part\nof it) for collecting their statistics. These approaches differ\nfrom query-based methods which rely only on the actual\nselectivities of the observed queries.\nScan-based Histograms These approaches approximate\nthe joint distribution by periodically scanning the data. Therehas been much work on how to efficiently express the joint\ndistribution of multidimensional data [ 24,26,28,34–36,38,\n40,41,43–45,50,52,65,69,71,78,80,87,101,102,106]. There\nis also some work on histograms for special types of data,\nsuch as XML [ 10,17,107,109], spatial data [ 49,58–60,68,73,\n81,97,99,100,108,112,113], graph [ 30], string [ 46–48,77];\nor for privacy [39, 64, 66].\nSampling Sampling-based methods rely on a sample of\ndata for estimating its joint distribution [ 38,69,87]. However,\ndrawing a new random sample requires a table-scan or ran-\ndom retrieval of tuples, both of which are costly operations\nand hence, are only performed periodically.\nMachine Learning Models KDE is a technique that\ntranslates randomly sampled data points into a distribu-\ntion [ 91]. In the context of selectivity estimation, KDE has\nbeen used as an alternative to histograms [ 35,36,41]. The\nsimilarity between KDE and mixture models (which we em-\nploy for QuickSel) is that they both express a probability den-\nsity function as a summation of some basis functions. How-\never, KDE and MM (mixture models) are fundamentally dif-\nferent. KDE relies on independent and identically distributed\nsamples, and hence lends itself to scan-based selectivity es-\ntimation. In contrast, MM does not require any sampling\nand can thus be used in query-driven selectivity estimation\n(where sampling is not practical). Similarly, probabilistic\ngraphical models [ 33,92,104], neural networks [ 57,70], and\ntree-based ensembles [ 29] have been used for selectivity es-\ntimation. Unlike histograms, these approaches can capture\ncolumn correlations more succinctly. However, applicability\nof these models for query-driven selectivity estimation has\nnot been explored and remains unclear.\nMore recently, sketching [ 21] and probe executions [ 103]\nhave been proposed, which differ from ours in that they\nbuild their models directly using the data (not query results).\nSimilar to histograms, using the data requires either peri-\nodic updates or higher query processing overhead. QuickSel\navoids both of these shortcomings with its query-driven MM.\n7.2 Query-driven Estimation\nQuery-driven techniques create their histogram buckets adap-\ntively according to the queries they observe in the work-\nload. These can be further categorized into two techniques\nbased on how they compute their bucket frequencies: error-\nfeedback histograms and max-entropy histograms.\nError-feedback Histograms Error-feedback histograms [ 11,\n13,20,55,56,67] adjust bucket frequencies in consideration\nof the errors made by old bucket frequencies. They differ\nin how they create histogram buckets according to the ob-\nserved queries. For example, STHoles [ 20] splits existing\nbuckets with the predicate range of the new query. SASH [ 67]\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nTable 3: Comparison of selectivity estimation methods\nApproach Model Method Key Contributions\nBased on\nDatabase\nScans\n(Scan-based\nSelectivity\nEstimation)Histograms Multi-dim Hist [ 28,43,71]Introduces multidimensional histograms\nMuralikrishna [80] Introduces equidepth histograms\nVan Gelder [106] Estimates Join selectivity with histograms for important domains\nGOH [45] Optimizes single-attribute histograms for joint distribution\nThaper [101] Builds histograms over streaming data\nTo [102] Builds histograms with entropy as a metric\nSampling Lipton [69] Introduces adaptive sampling for high accuracy\nHaas [38] Uses sampling for join selectivity estimation\nRiondato [87] Guarantees accuracy relying on the VC-dimension of queries\nML KDE [35, 36, 41] Applies kernel density estimation to selectivity estimation\nPGM [33, 92, 104] Uses probabilistic graphical models for selectivity estimation\nNeural Net [57, 70] Trains a neural network for selectivity estimation\nBased on\nObserved\nQueries\n(Query-\ndriven\nSelectivity\nEstimation)Error-feedback\nHistograms\n(fast but\nless accurate)ST-histogram [11] Refines the bucket frequencies based on the errors\nLEO [96] Identifies incorrect statistics using observed queries\nSTHoles [20] Proposes a new buckets split mechanism; adopted by ISOMER\nSASH [67] Proposes a junction tree model for finding the best set of histograms\nQueryModel [13] Avoids modeling the data distribution by using queries directly\nMax-Entropy\nHistograms\n(accurate but\nslow)ISOMER [75, 76, 93] Finds a maximum entropy distribution consistent with observed queries\nKaushik et al. [53] Extends ISOMER for distinct values\nRé et al. [85, 86] Seeks the max entropy distribution based on possible worlds\nMixture Model\n(fast & accurate)QuickSel (Ours) Employs a mixture model for selectivity estimation; develops an efficient training\nalgorithm for the new model\nuses a space-efficient multidimensional histogram, called\nMHIST [ 28], but determines its bucket frequencies with an\nerror-feedback mechanism. QueryModel [ 13] treats the ob-\nserved queries themselves as conceptual histogram buckets\nand determines the distances among those buckets based on\nthe similarities among the queries’ predicates.\nMax-Entropy Histograms Max-entropy histograms [ 53,\n75,76,86,93] find a maximum entropy distribution consis-\ntent with the observed queries. Unfortunately, these methods\ngenerally suffer from the exponential growth in their number\nof buckets as the number of observed queries grows (as dis-\ncussed in Section 2). QuickSel avoids this problem by relying\non mixture models.\nFitting Parametric Functions Adaptive selectivity esti-\nmation [ 23] fits a parametric function (e.g., linear, polyno-\nmial) to the observed queries. This approach is more appli-\ncable when we know the data distribution a priori , which is\nnot assumed by QuickSel.\nSelf-tuning Databases Query-driven histograms have\nalso been studied in the context of self-tuning databases [ 61,\n72,74]. IBM’s LEO [ 96] corrects errors in any stage of queryexecution based on the observed queries. Microsoft’s Au-\ntoAdmin [ 12,22] focuses on automatic physical design, self-\ntuning histograms, and monitoring infrastructure. Part of\nthis effort is ST-histogram [ 11] and STHoles [ 20] (see Ta-\nble 3). DBL [ 82] and IDEA [ 31] exploit the answers to past\nqueries for more accurate approximate query processing.\nQueryBot 5000 [ 72] forecasts the future queries, whereas\nOtterTune [ 105] and index [ 62] use machine learning for\nautomatic physical design and building secondary indices,\nrespectively.\n8 CONCLUSION AND FUTURE WORK\nThe prohibitive cost of query-driven selectivity estimation\ntechniques has greatly limited their adoption by DBMS ven-\ndors, which for the most part still rely on scan-based his-\ntograms and samples that are periodically updated and are\notherwise stale. In this paper, we proposed a new framework,\ncalled selectivity learning or QuickSel, which learns from ev-\nery query to continuously refine its internal model of the\nunderlying data, and therefore produce increasingly more ac-\ncurate selectivity estimates over time. QuickSel differs from\nprevious query-driven selectivity estimation techniques by\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\n(i) not using histograms and (ii) enabling extremely fast re-\nfinements using its mixture model. We formally showed that\nthe training cost of our mixture model can be reduced from\nexponential to only quadratic complexity (Theorem 1).\nSupporting Complex Joins When modeling the selec-\ntivity of join queries, even state-of-the-art modes [ 29,57,111]\ntake a relatively simple approach: conceptually prejoining\ncorresponding tables, and constructing a joint probability dis-\ntribution over each join pattern. We plan to similarly extend\nour current formulation of QuickSel to model the selectivity\nof general joins.\n9 ACKNOWLEDGEMENT\nThis material is based upon work supported by the National\nScience Foundation under Grant No. 1629397 and the Michi-\ngan Institute for Data Science (MIDAS) PODS. Any opinions,\nfindings, and conclusions or recommendations expressed in\nthis material are those of the author(s) and do not necessarily\nreflect the views of the National Science Foundation.\nREFERENCES\n[1][n. d.]. Apache Commons: Optimization. http://commons.apache.\norg/proper/commons-math/userguide/optimization.html. [Online;\naccessed September-16-2018].\n[2][n. d.]. Collecting Histogram Statistics. https://www.ibm.com/\nsupport/knowledgecenter/SSEPEK_11.0.0/perf/src/tpc/db2z_\ncollecthistogramstatistics.html. [Online; accessed September-16-\n2018].\n[3][n. d.]. Histogram-based Statistics. https://mariadb.com/kb/en/\nlibrary/histogram-based-statistics/. [Online; accessed September-16-\n2018].\n[4][n. d.]. JOptimizer. http://www.joptimizer.com/. [Online; accessed\nSeptember-16-2018].\n[5][n. d.]. MATLAB: quadprog. https://www.mathworks.com/help/\noptim/ug/quadprog.html/. [Online; accessed September-16-2018].\n[6][n. d.]. pg_hint_plan 1.1. https://pghintplan.osdn.jp/pg_hint_plan.\nhtml. [Online; accessed February-13-2020].\n[7][n. d.]. PostgreSQL 9.2.24 Documentation. https://www.postgresql.\norg/docs/9.2/static/row-estimation-examples.html. [Online; accessed\nSeptember-16-2018].\n[8][n. d.]. Statistical maintenance functionality (AutoStats) in\nSQL Server. https://support.microsoft.com/en-us/help/195565/\nstatistical-maintenance-functionality-autostats-in-sql-server. [On-\nline; accessed September-16-2018].\n[9][n. d.]. Statistics. https://docs.microsoft.com/en-us/sql/\nrelational-databases/statistics/statistics?view=sql-server-2017.\n[Online; accessed September-16-2018].\n[10] Ashraf Aboulnaga, Alaa R Alameldeen, and Jeffrey F Naughton. 2001.\nEstimating the selectivity of XML path expressions for internet scale\napplications. In VLDB .\n[11] Ashraf Aboulnaga and Surajit Chaudhuri. 1999. Self-tuning his-\ntograms: Building histograms without looking at data. SIGMOD\n(1999).\n[12] Sanjay Agrawal, Nicolas Bruno, Surajit Chaudhuri, and Vivek R\nNarasayya. 2006. AutoAdmin: Self-Tuning Database SystemsTech-\nnology. IEEE Data Eng. Bull. (2006).[13] Christos Anagnostopoulos and Peter Triantafillou. 2015. Learning\nto accurately COUNT with query-driven predictive analytics. In Big\nData .\n[14] M Andersen, Joachim Dahl, and Lieven Vandenberghe. 2013. CVX-\nOPT: A Python package for convex optimization. (2013).\n[15] Tihomir Asparouhov and Bengt Muthén. 2016. Structural equation\nmodels and mixture models with continuous nonnormal skewed dis-\ntributions. Structural Equation Modeling: A Multidisciplinary Journal\n(2016).\n[16] Anonymous Authors. 2020. Title is blinded for anonymous submis-\nsion. Anonymous Venue (2020).\n[17] Sourav S Bhowmick, Erwin Leonardi, and Hongmei Sun. 2007. Effi-\ncient evaluation of high-selective xml twig patterns with parent child\nedges in tree-unaware rdbms. In SIGMOD .\n[18] Christopher M Bishop. 2006. Pattern recognition and machine learning .\n[19] Björn Blohsfeld, Dieter Korus, and Bernhard Seeger. 1999. A compar-\nison of selectivity estimators for range queries on metric attributes.\nInSIGMOD Record .\n[20] Nicolas Bruno, Surajit Chaudhuri, and Luis Gravano. 2001. STHoles:\na multidimensional workload-aware histogram. In SIGMOD .\n[21] Walter Cai, Magdalena Balazinska, and Dan Suciu. 2019. Pessimistic\nCardinality Estimation: Tighter Upper Bounds for Intermediate Join\nCardinalities. In SIGMOD .\n[22] Surajit Chaudhuri and Vivek Narasayya. 2007. Self-tuning database\nsystems: a decade of progress. In PVLDB .\n[23] Chungmin Melvin Chen and Nick Roussopoulos. 1994. Adaptive\nselectivity estimation using query feedback. In SIGMOD .\n[24] Lei Chen and M Tamer Ozsu. 2004. Multi-scale histograms for an-\nswering queries over time series data. In ICDE .\n[25] Yen-Chi Chen. [n. d.]. Lecture 6: Density Estimation: Histogram and\nKernel Density Estimator. http://faculty.washington.edu/yenchic/\n18W_425/Lec6_hist_KDE.pdf. [Online; accessed September-16-2018].\n[26] Graham Cormode, Minos Garofalakis, Peter J Haas, Chris Jermaine,\net al.2011. Synopses for massive data: Samples, histograms, wavelets,\nsketches. (2011).\n[27] Peter F Craigmile and DM Tirrerington. 1997. Parameter estima-\ntion for finite mixtures of uniform distributions. Communications in\nStatistics-Theory and Methods (1997).\n[28] Amol Deshpande, Minos Garofalakis, and Rajeev Rastogi. 2001. Inde-\npendence is good: Dependency-based histogram synopses for high-\ndimensional data. SIGMOD Record (2001).\n[29] Anshuman Dutt, Chi Wang, Azade Nazi, Srikanth Kandula, Vivek\nNarasayya, and Surajit Chaudhuri. 2019. Selectivity estimation for\nrange predicates using lightweight models. PVLDB (2019).\n[30] Jianhua Feng, Qian Qian, Yuguo Liao, Guoliang Li, and Na Ta. 2005.\nDMT: a flexible and versatile selectivity estimation approach for\ngraph query. In WAIM .\n[31] Alex Galakatos, Andrew Crotty, Emanuel Zgraggen, Carsten Bin-\nnig, and Tim Kraska. 2017. Revisiting reuse for approximate query\nprocessing. PVLDB (2017).\n[32] Alan Genz. 1992. Numerical computation of multivariate normal\nprobabilities. Journal of computational and graphical statistics (1992).\n[33] Lise Getoor, Benjamin Taskar, and Daphne Koller. 2001. Selectivity\nestimation using probabilistic models. In ACM SIGMOD Record , Vol. 30.\nACM, 461–472.\n[34] Sudipto Guha, Nick Koudas, and Divesh Srivastava. 2002. Fast algo-\nrithms for hierarchical range histogram construction. In PODS .\n[35] Dimitrios Gunopulos, George Kollios, Vassilis J Tsotras, and Car-\nlotta Domeniconi. 2000. Approximating multi-dimensional aggregate\nrange queries over real attributes. In SIGMOD Record .\n[36] Dimitrios Gunopulos, George Kollios, Vassilis J Tsotras, and Carlotta\nDomeniconi. 2005. Selectivity estimators for multidimensional range\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nqueries over real attributes. VLDBJ (2005).\n[37] AK Gupta and T Miyawaki. 1978. On a uniform mixture model.\nBiometrical Journal (1978).\n[38] Peter J Haas, Jeffrey F Naughton, and Arun N Swami. 1994. On the\nrelative cost of sampling for join selectivity estimation. In PODS .\n[39] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. 2010.\nBoosting the accuracy of differentially private histograms through\nconsistency. PVLDB (2010).\n[40] Zengyou He, Xiaofei Xu, Shengchun Deng, and Bin Dong. 2005. K-\nhistograms: An efficient clustering algorithm for categorical dataset.\narXiv preprint cs/0509033 (2005).\n[41] Max Heimel, Martin Kiefer, and Volker Markl. 2015. Self-tuning, GPU-\naccelerated kernel density models for multidimensional selectivity\nestimation. In SIGMOD .\n[42] Ron Hu, Zhenhua Wang, Wenchen Fan, and Sameer Agarwal. 2018.\nCost Based Optimizer in Apache Spark 2.2. https://databricks.com/\nblog/2017/08/31/cost-based-optimizer-in-apache-spark-2-2.html.\n[Online; accessed September-16-2018].\n[43] Ihab F Ilyas, Volker Markl, Peter Haas, Paul Brown, and Ashraf Aboul-\nnaga. 2004. CORDS: automatic discovery of correlations and soft\nfunctional dependencies. In SIGMOD .\n[44] Zsolt Istvan, Louis Woods, and Gustavo Alonso. 2014. Histograms as\na side effect of data movement for big data. In SIGMOD .\n[45] HV Jagadish, Hui Jin, Beng Chin Ooi, and Kian-Lee Tan. 2001. Global\noptimization of histograms. SIGMOD Record (2001).\n[46] HV Jagadish, Olga Kapitskaia, Raymond T Ng, and Divesh Srivastava.\n1999. Multi-dimensional substring selectivity estimation. In VLDB .\n[47] HV Jagadish, Olga Kapitskaia, Raymond T Ng, and Divesh Srivastava.\n2000. One-dimensional and multi-dimensional substring selectivity\nestimation. VLDB (2000).\n[48] HV Jagadish, Raymond T Ng, and Divesh Srivastava. 1999. Substring\nselectivity estimation. In PODS .\n[49] Hosagrahar Visvesvaraya Jagadish, Nick Koudas, S Muthukrishnan,\nViswanath Poosala, Kenneth C Sevcik, and Torsten Suel. 1998. Opti-\nmal histograms with quality guarantees. In VLDB .\n[50] Jeffrey Jestes, Ke Yi, and Feifei Li. 2011. Building wavelet histograms\non large data in MapReduce. PVLDB (2011).\n[51] Harry Joe. 1995. Approximations to multivariate normal rectangle\nprobabilities based on conditional expectations. J. Amer. Statist. Assoc.\n(1995).\n[52] P Karras and N Mamoulis. 2008. Lattice Histograms: a Resilient\nSynopsis Structure. In ICDE .\n[53] Raghav Kaushik and Dan Suciu. 2009. Consistent histograms in the\npresence of distinct value counts. PVLDB (2009).\n[54] Michael S Kester, Manos Athanassoulis, and Stratos Idreos. 2017.\nAccess Path Selection in Main-Memory Optimized Data Systems:\nShould I Scan or Should I Probe?. In SIGMOD .\n[55] Andranik Khachatryan, Emmanuel Müller, Christian Stier, and Kle-\nmens Böhm. 2012. Sensitivity of self-tuning histograms: query order\naffecting accuracy and robustness. In SSDBM .\n[56] Andranik Khachatryan, Emmanuel Müller, Christian Stier, and Kle-\nmens Böhm. 2015. Improving accuracy and robustness of self-tuning\nhistograms by subspace clustering. TKDE (2015).\n[57] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz,\nand Alfons Kemper. 2018. Learned cardinalities: Estimating correlated\njoins with deep learning. arXiv preprint arXiv:1809.00677 (2018).\n[58] Georgia Koloniari, Yannis Petrakis, Evaggelia Pitoura, and Thodoris\nTsotsos. 2005. Query workload-aware overlay construction using\nhistograms. In CIKM .\n[59] Flip Korn, Theodore Johnson, and HV Jagadish. 1999. Range selectiv-\nity estimation for continuous attributes. In ssdbm .[60] Nick Koudas, S Muthukrishnan, and Divesh Srivastava. 2000. Optimal\nhistograms for hierarchical range queries. In PODS .\n[61] Tim Kraska, Mohammad Alizadeh, Alex Beutel, Ed H. Chi, Ani Kristo,\nGuillaume Leclerc, Samuel Madden, Hongzi Mao, and Vikram Nathan.\n2019. SageDB: A Learned Database System. In CIDR .\n[62] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzo-\ntis. 2018. The case for learned index structures. In SIGMOD .\n[63] Solomon Kullback and Richard A Leibler. 1951. On information and\nsufficiency. The annals of mathematical statistics (1951).\n[64] Yu-Hsuan Kuo, Cho-Chun Chiu, Daniel Kifer, Michael Hay, and Ash-\nwin Machanavajjhala. 2018. Differentially private hierarchical count-\nof-counts histograms. PVLDB (2018).\n[65] Elizabeth Lam and Kenneth Salem. 2005. Dynamic histograms for\nnon-stationary updates. In IDEAS .\n[66] Chao Li, Michael Hay, Vibhor Rastogi, Gerome Miklau, and Andrew\nMcGregor. 2010. Optimizing linear counting queries under differential\nprivacy. In PODS .\n[67] Lipyeow Lim, Min Wang, and Jeffrey Scott Vitter. 2003. SASH: A\nself-adaptive histogram set for dynamically changing workloads. In\nVLDB .\n[68] Xuemin Lin, Qing Liu, Yidong Yuan, and Xiaofang Zhou. 2003. Mul-\ntiscale histograms: Summarizing topological relations in large spatial\ndatasets. In VLDB .\n[69] Richard J Lipton, Jeffrey F Naughton, and Donovan A Schneider. 1990.\nPractical selectivity estimation through adaptive sampling .\n[70] Henry Liu, Mingbin Xu, Ziting Yu, Vincent Corvinelli, and Calisto\nZuzarte. 2015. Cardinality Estimation Using Neural Networks. In\nProceedings of the 25th Annual International Conference on Computer\nScience and Software Engineering (CASCON ’15) . IBM Corp., Riverton,\nNJ, USA, 53–59. http://dl.acm.org/citation.cfm?id=2886444.2886453\n[71] Clifford A Lynch. 1988. Selectivity Estimation and Query Optimiza-\ntion in Large Databases with Highly Skewed Distribution of Column\nValues.. In VLDB .\n[72] Lin Ma, Dana Van Aken, Ahmed Hefny, Gustavo Mezerhane, Andrew\nPavlo, and Geoffrey J Gordon. 2018. Query-based Workload Forecast-\ning for Self-Driving Database Management Systems. In SIGMOD .\n[73] Nikos Mamoulis and Dimitris Papadias. 2001. Selectivity estimation\nof complex spatial queries. In International Symposium on Spatial and\nTemporal Databases . 155–174.\n[74] Ryan C. Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Moham-\nmad Alizadeh, Tim Kraska, Olga Papaemmanouil, and Nesime Tatbul.\n2019. Neo: A Learned Query Optimizer. PVLDB (2019).\n[75] Volker Markl, Peter J Haas, Marcel Kutsch, Nimrod Megiddo, Utkarsh\nSrivastava, and Tam Minh Tran. 2007. Consistent selectivity estima-\ntion via maximum entropy. VLDBJ (2007).\n[76] Volker Markl, Nimrod Megiddo, Marcel Kutsch, Tam Minh Tran, P\nHaas, and Utkarsh Srivastava. 2005. Consistently estimating the\nselectivity of conjuncts of predicates. In PVLDB .\n[77] Arturas Mazeika, Michael H Böhlen, Nick Koudas, and Divesh Srivas-\ntava. 2007. Estimating the selectivity of approximate string queries.\nTODS (2007).\n[78] Guido Moerkotte, David DeHaan, Norman May, Anisoara Nica, and\nAlexander Boehm. 2014. Exploiting ordered dictionaries to efficiently\nconstruct histograms with q-error guarantees in SAP HANA. In SIG-\nMOD .\n[79] Gerhard Moser, Sang Hong Lee, Ben J Hayes, Michael E Goddard,\nNaomi R Wray, and Peter M Visscher. 2015. Simultaneous discovery,\nestimation and prediction analysis of complex traits using a Bayesian\nmixture model. PLoS genetics (2015).\n[80] M Muralikrishna and David J DeWitt. 1988. Equi-depth multidimen-\nsional histograms. In SIGMOD Record .\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\n[81] Thomas Neumann and Sebastian Michel. 2008. Smooth interpolating\nhistograms with error guarantees. In British National Conference on\nDatabases .\n[82] Yongjoo Park, Ahmad Shahab Tajik, Michael Cafarella, and Barzan\nMozafari. 2017. Database learning: Toward a database that becomes\nsmarter every time. In SIGMOD .\n[83] Claude Proteau. [n. d.]. Guide to Performance and Tuning: Query\nPerformance and Sampled Selectivity. http://www.oracle.com/\ntechnetwork/products/rdb/0403-sampled-selectivity-128646.pdf.\n[Online; accessed September-16-2018].\n[84] Srikanth Ragothaman, Sridharakumar Narasimhan, Madivala G\nBasavaraj, and Rajan Dewar. 2016. Unsupervised segmentation of\ncervical cell images using gaussian mixture model. In CVPR Work-\nshops .\n[85] Christopher Ré and Dan Suciu. 2010. Understanding cardinality\nestimation using entropy maximization. In PODS .\n[86] Christopher Ré and Dan Suciu. 2012. Understanding cardinality\nestimation using entropy maximization. TODS (2012).\n[87] Matteo Riondato, Mert Akdere, Ugur Cetintemel, Stanley B Zdonik,\nand Eli Upfal. 2011. The VC-dimension of SQL queries and selectivity\nestimation through sampling. In ECML PKDD .\n[88] Jesús Camacho Rodríguez. [n. d.]. An Overview\non Optimization in Apache Hive: Past, Present Fu-\nture. https://www.slideshare.net/HadoopSummit/\nan-overview-on-optimization-in-apache-hive-past-present-future.\n[Online; accessed September-16-2018].\n[89] Yossi Rubner, Carlo Tomasi, and Leonidas J Guibas. 2000. The earth\nmover’s distance as a metric for image retrieval. International journal\nof computer vision (2000).\n[90] P Griffiths Selinger, Morton M Astrahan, Donald D Chamberlin, Ray-\nmond A Lorie, and Thomas G Price. 1979. Access path selection in a\nrelational database management system. In SIGMOD .\n[91] Bernard W Silverman. 2018. Density estimation for statistics and data\nanalysis .\n[92] Joshua Spiegel and Neoklis Polyzotis. 2006. Graph-based Synopses\nfor Relational Selectivity Estimation. In Proceedings of the 2006 ACM\nSIGMOD International Conference on Management of Data (SIGMOD\n’06). ACM, New York, NY, USA, 205–216. https://doi.org/10.1145/\n1142473.1142497\n[93] Utkarsh Srivastava, Peter J Haas, Volker Markl, Marcel Kutsch, and\nTam Minh Tran. 2006. ISOMER: Consistent histogram construction\nusing query feedback. In ICDE .\n[94] Jeremy Stanley. 2017. 3 Million Instacart Orders, Open Sourced.\nhttps://www.instacart.com/datasets/grocery-shopping-2017. [On-\nline; accessed September-16-2018].\n[95] State of New York. 2018. Vehicle, Snowmobile, and\nBoat Registrations. https://catalog.data.gov/dataset/\nvehicle-snowmobile-and-boat-registrations. [Online; accessed\nSeptember-16-2018].\n[96] Michael Stillger, Guy M Lohman, Volker Markl, and Mokhtar Kandil.\n2001. LEO-DB2’s learning optimizer. In VLDB .\n[97] Jimeng Sun, Yufei Tao, Dimitris Papadias, and George Kollios. 2006.\nSpatio-temporal join selectivity. Information Systems (2006).\n[98] Arun Swami and K Bernhard Schiefer. 1994. On the estimation of\njoin result sizes. In EDBT .\n[99] Mingwang Tang and Feifei Li. 2014. Scalable histograms on large\nprobabilistic data. In KDD .\n[100] Y Tao, Jimeng Sun, and Dimitris Papadias. 2003. Selectivity estimation\nfor predictive spatio-temporal queries. In ICDE .\n[101] Nitin Thaper, Sudipto Guha, Piotr Indyk, and Nick Koudas. 2002.\nDynamic multidimensional histograms. In SIGMOD .[102] Hien To, Kuorong Chiang, and Cyrus Shahabi. 2013. Entropy-based\nhistograms for selectivity estimation. In CIKM .\n[103] Immanuel Trummer. 2019. Exact Cardinality Query Optimization\nwith Bounded Execution Cost. In SIGMOD .\n[104] Kostas Tzoumas, Amol Deshpande, and Christian S. Jensen. 2013.\nEfficiently Adapting Graphical Models for Selectivity Estimation.\nThe VLDB Journal 22, 1 (Feb. 2013), 3–27. https://doi.org/10.1007/\ns00778-012-0293-7\n[105] Dana Van Aken, Andrew Pavlo, Geoffrey J Gordon, and Bohan Zhang.\n2017. Automatic database management system tuning through large-\nscale machine learning. In SIGMOD .\n[106] Allen Van Gelder. 1993. Multiple join size estimation by virtual\ndomains. In PODS .\n[107] Chao Wang, Srinivasan Parthasarathy, and Ruoming Jin. 2006. A\ndecomposition-based probabilistic framework for estimating the se-\nlectivity of XML twig queries. In EDBT .\n[108] Xiaoyang Wang, Ying Zhang, Wenjie Zhang, Xuemin Lin, and Wei\nWang. 2014. Selectivity estimation on streaming spatio-textual data\nusing local correlations. PVLDB (2014).\n[109] Yuqing Wu, Jignesh M Patel, and HV Jagadish. 2003. Using histograms\nto estimate answer sizes for XML queries. Information Systems (2003).\n[110] Jianbo Yang, Xuejun Liao, Xin Yuan, Patrick Llull, David J Brady,\nGuillermo Sapiro, and Lawrence Carin. 2015. Compressive sensing\nby learning a Gaussian mixture model from measurements. IEEE\nTransactions on Image Processing (2015).\n[111] Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan\nDuan, Xi Chen, Pieter Abbeel, Joseph M. Hellerstein, Sanjay Krishnan,\nand Ion Stoica. 2019. Selectivity Estimation with Deep Likelihood\nModels. CoRR abs/1905.04278 (2019). arXiv:1905.04278 http://arxiv.\norg/abs/1905.04278\n[112] Qing Zhang and Xuemin Lin. 2002. On linear-spline based histograms.\nInWAIM .\n[113] Qing Zhang and Xuemin Lin. 2004. Clustering moving objects for\nspatio-temporal selectivity estimation. In Australasian database con-\nference .\n\nSIGMOD’20, June 14–19, 2020, Portland, OR, USA Yongjoo Park, Shucheng Zhong, Barzan Mozafari\nA ANALYSIS OF ITERATIVE SCALING\nThe previous work uses an algorithm called iterative scal-\ningto optimize the bucket frequencies. In this section, we\nanalyze why using the approach is non-trivial when some\nbuckets are merged or pruned. Specifically, we show that\nthe approach becomes non-trivial if a histogram bucket may\npartially overlap with a predicate range, rather than being\ncompletely within or outside of the predicate range.\nSelectivity Estimation with Histograms First, we de-\nscribe how histograms can be used for selectivity estimation.\nThis description is needed to present iterative scaling itself.\nLetGzforz=1, . . . , mdenote the boundary of z-th bucket.\nwzis the frequency of the z-th bucket. Then, the histogram\napproximates the distribution of data as follows:\nf(x)=wj\n|Gj|forGjsuch that x∈Gj\nFor a query’s predicate Pi, its selectivity can be computed as\nfollows:\nsi=mÕ\nj=1|Bi∩Gj|\n|Gj|w=s\nOne can observe that the above expression is akin to selec-\ntivity estimation formula with a mixture model (Section 3.2),\nwhich is natural since mixture models can be regarded as a\ngeneralization of histograms.\nOptimization with Maximum Entropy Principle To\noptimize the bucket frequencies, the previous work employs\nthe maximum entropy principle. When the maximum en-\ntropy principle is used, one can optimize the bucket frequen-\ncies by solving the following problem.\nProblem 4 (Training with Max Entropy Principle)\narg min\nw∫\nf(x)log(f(x))dx\nsuch that Aw=s\nwhere Ais an-by-mmatrix; its(i,j)-th entry is defined as\n(A)i,j=|Bi∩Gj|\n|Gj|.\nsis a size- ncolumn vector; its i-th entry is the observed selec-\ntivity of the i-th query.\nIf a histogram bucket is completely included within a pred-\nicate range, Ai,jtakes 1; if a histogram bucket is completely\noutside a predicate range, Ai,jtakes 0. If a histogram bucket\npartially overlaps with a predicate range, Ai,jtakes a value\nbetween 0 and 1.For histograms, the integral in the above problem can be\ndirectly simplified as follows:\n∫\nf(x)log(f(x))dx=mÕ\ni=1∫\nx∈Giwi\n|Gi|log\u0012wi\n|Gi|\u0013\ndx\n=mÕ\ni=1wilog\u0012wi\n|Gi|\u0013\nIterative Scaling Iterative Scaling solves the above prob-\nlem by updating model parameters in a sequential order; that\nis, it updates w1as using fixed values for other parameters,\nit updates w2as using fixed values for other parameters, and\nso on. This iteration (i.e., updating all w1through wm) con-\ntinues until those parameter values converge. In this process,\nthe important part is the formula for the updates.\nTo derive this update rule, the previous work uses the\nLagrangian method, as follows. In the following derivation,\nwe suppose a slightly more general setting; that is, we allow\npossible partial overlaps. We first define L:\nL(w,λ)=mÕ\nj=1wjlog\u0012wj\n|Gj|\u0013\n−λ⊤(Aw−s)\nwhere λis a size- mcolumn vector containing mLagrangian\nmultipliers, i.e., λ=(λ1, . . . ,λm)⊤.\nAt optimal solutions, the derivative of Lwith respect to w\nandλmust be zero. Let the column vectors of Abe denoted\nbya1, . . . , am; that is, A=[a1, . . . , am]. Then,\n∂L\n∂wj=log(wj)+1−log(|Gj|)−a⊤\njλ=0\nLetzi=exp(λi). Then,\nlog\u0012wj\n|Gj|\u0013\n=a⊤\njλ−1 forj=1, . . . , m\n⇒wj\n|Gj|=1\neexp\u0010\na⊤\njλ\u0011\nforj=1, . . . , m\n⇒ wj=|Gj|\nenÖ\ni=1exp\u0000Ai,jλi\u0001forj=1, . . . , m\n⇒ wj=|Gj|\nenÖ\ni=1zAi,j\niforj=1, . . . , m (6)\nFrom the constraint thatÍm\nj=1Ai,jwj=sifori=1, . . . , n,\nmÕ\nj=1Ai,j|Gj|\nenÖ\ni=1zAi,j\ni=si (7)\nLet’s assume thatAi,jalways takes either 0 or 1 (the condi-\ntion used in the previous work); then, the above expression\ncan be simplified to produce an analytic update rule. Let Ci\nbe an index set such that Ci={k|Ai,k=1,k=1, . . . , m}.\n\nQuickSel: Quick Selectivity Learning with Mixture Models SIGMOD’20, June 14–19, 2020, Portland, OR, USA\nAlso, let Dj\\i={k|Ak,j=1,k=1, . . . , n,k,i}. Then,\nmÕ\nj=1Ai,j|Gj|\nenÖ\ni=1zAi,j\ni=si\n⇒Õ\nj∈Ci|Gj|\neziÖ\nk∈Di\\jzk=si\n⇒ zi=siÍ\nj∈Ci|Gj|/eÎ\nk∈Di\\jzk(8)\nUsing the above equation, the previous work continues to\nupdate zifori=1, . . . , nuntil convergence. Once those\nvalues are obtained, the bucket frequencies can be obtained\nby Equation (6).\nHowever , without the assumption that Ai,jalways takes\neither 0 or 1, obtaining the update equation (Equation (8))\nfrom Equation (7) is non-trivial.",
  "textLength": 85986
}