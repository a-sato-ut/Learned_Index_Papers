{
  "paperId": "ee2812c7569e287ec8aa4eb6801a18e740960f35",
  "title": "Bipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space",
  "pdfPath": "ee2812c7569e287ec8aa4eb6801a18e740960f35.pdf",
  "text": "Bipartite Graph Convolutional Hashing for Effective and\nEfficient Top-N Search in Hamming Space\nYankai Chen1, Yixiang Fang2, Yifei Zhang1, Irwin King1\n{ykchen, yfzhang, king}@cse.cuhk.edu.hk fangyixiang@cuhk.edu.cn\n1The Chinese University of Hong Kong2The Chinese University of Hong Kong, Shenzhen\nAbstract\nSearching on bipartite graphs is basal and versatile to many real-\nworld Web applications, e.g., online recommendation, database\nretrieval, and query-document searching. Given a query node, the\nconventional approaches rely on the similarity matching with the\nvectorized node embeddings in the continuous Euclidean space.\nTo efficiently manage intensive similarity computation, develop-\ning hashing techniques for graph-structured data has recently be-\ncome an emerging research direction. Despite the retrieval effi-\nciency in Hamming space, prior work is however confronted with\ncatastrophic performance decay . In this work, we investigate the\nproblem of hashing with Graph Convolutional Network on bipar-\ntite graphs for effective Top-N search. We propose an end-to-end\nBipartite Graph Convolutional Hashing approach, namely BGCH,\nwhich consists of three novel and effective modules: (1) adaptive\ngraph convolutional hashing , (2) latent feature dispersion , and (3)\nFourier serialized gradient estimation . Specifically, the former two\nmodules achieve the substantial retention of the structural informa-\ntion against the inevitable information loss in hash encoding; the\nlast module develops Fourier Series decomposition to the hashing\nfunction in the frequency domain mainly for more accurate gradient\nestimation. The extensive experiments on six real-world datasets\nnot only show the performance superiority over the competing\nhashing-based counterparts, but also demonstrate the effectiveness\nof all proposed model components contained therein.\nCCS Concepts\n‚Ä¢Computing methodologies ‚ÜíLearning latent representa-\ntions ;‚Ä¢Information systems ‚ÜíInformation retrieval .\nKeywords\nRepresentation Learning; Learning to Hash; Graph Convolutional\nNetwork; Bipartite Graph; Hamming Space Search\nACM Reference Format:\nYankai Chen1, Yixiang Fang2, Yifei Zhang1, Irwin King1. 2023. Bipartite\nGraph Convolutional Hashing for Effective and Efficient Top-N Search in\nHamming Space . In Proceedings of the ACM Web Conference 2023 (WWW\n‚Äô23), May 1‚Äì5, 2023, Austin, TX, USA. ACM, New York, NY, USA, 11 pages.\nhttps://doi.org/10.1145/3543507.3583219\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA\n¬©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-9416-1/23/04. . . $15.00\nhttps://doi.org/10.1145/3543507.3583219\n(a) Bipartite graph modeling\n(b) Effectiveness (NDCG@1000) versus matching computation latency (log-scale) Figure 1: Illustration of bipartite graph modeling and over-\nall model performance visualization on Dianping dataset.\n1 Introduction\nBipartite graphs are ubiquitous in the real world for the ease of\nmodeling various Web applications, e.g., as shown in Figure 1(a),\nuser-product recommendation [ 41,63] and online query-document\nmatching [ 66]. A fundamental task, Top-N search , is to filter out\nN best-matched graph nodes for a query node, e.g., recommend-\ning Top-N attractive products to a target user in the user-product\ngraph. With the development of the recent machine learning re-\nsearch, learning vectorized representations ( a.k.a. embeddings)\nnowadays has become one of the standard procedures for simi-\nlarity matching [ 10,16]. Among existing techniques, graph-based\nneural methods, i.e., Graph Convolutional Networks (GCNs), have\nrecently present remarkable model performance [ 17,19]. Due to the\nability to capture high-order connection information, GCN models\ncan thus produce semantic enrichment to the node embeddings.\nBased on the learned embeddings, similarity estimation is then\nexhaustively proceeded in the continuous Euclidean space.\nApart from embedding informativeness, computation latency and\nembedding memory overhead are two important criteria for realistic\napplication deployment. With the explosive data growth, learning to\nhash [25,51] recently provides an alternative option to graph-based\nmodels for optimizing the model scalability. Generally, it learns\nto convert the vectorized list of continuous values into the finite\nbinarized hash codes. In lieu of using full-precision1embeddings,\nthe learned hash codes have the promising potential to achieve, not\nonly the space reduction, but also the computation acceleration for\nTop-N object matching and retrieval in the Hamming space.\nDespite the promising advantages of bridging GCNs and learning\nto hash, simply stacking these two techniques is trivial and thus\nfalls short of performance satisfaction with several inadequacies:\n1The term ‚Äúfull-precision‚Äù generally refers to single-precision and double-precision. And we use\nfloat32 by default throughout this work for illustration.arXiv:2304.00241v1  [cs.IR]  1 Apr 2023\n\nWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Yankai Chen et al.\n‚Ä¢Coarse-grained similarity measurement. Compared to con-\ntinuous embeddings, hash codes with the same vector dimension\nare naturally less expressive with finite encoding permutation in\nHamming space (e.g., 2ùëëif the dimension is ùëë). Consequently,\nthis leads to a coarse-grained estimation of the pairwise node\nsimilarity, thus drawing a conspicuous performance decay with\ninaccurate Top-N matching.\n‚Ä¢Feature erosion issue. Recent work [ 38,44,45,49] usually\nadopts sign(¬∑)function for ùëÇ(1)complexity encoding. However,\nhashing via sign(¬∑)will inevitably smooth the embedding fea-\nture informativeness, via converting each digit of continuous\nembeddings into the hamming space, no matter what specific\nvalue it used to be. Thus the latent features in these learned hash\nembeddings become less informative, and existing models lack\ncertain mechanisms to hedge the feature erosion in hashing.\n‚Ä¢Intractable model optimization. Since sign(¬∑)is not differen-\ntiable at 0 and its derivatives are 0 anywhere else, previous models\nusually use visually similar but not necessarily theoretically rele-\nvant functions, e.g., tanh(¬∑), for gradient estimation. This may\nlead to inconsistent optimization directions in model training.\nMoreover, because of the embedding discreteness, the associated\nloss landscape2(Figure 2(a)) are steep and bumping [ 1], which\nfurther increases the difficulty in optimization.\nIn this paper, we study the problem of learning to hash with\nGraph Convolutional Network (GCN) on bipartite graphs for effec-\ntive Top-N Hamming space search. We propose a model namely\nBipartite Graph Convolutional Hashing (BGCH), with three effective\nmodules: (1) adaptive graph convolutional hashing , (2)latent feature\ndispersion , and (3) Fourier serialized gradient estimation . While the\nformer two modules significantly enrich the informativeness and\nexpressivity to the learned hash codes, the last one provides an\naccordant and tractable optimization flow in forward and backward\npropagation of model optimization. Concretely:\n‚Ä¢Adaptive graph convolutional hashing. Our first module de-\nsigns a topology-aware convolutional hashing that employs the\nlayer-wise hash encoding (from low- to high-order sub-structures\nof bipartite graphs) to consecutively binarize the node features\nwith different semantics. To boost the expressivity, the convolu-\ntional hashing is equipped an effective approximation technique\nforembedding rescaling , which does not undermine the efficiency\nof Hamming distance computation. Intuitively, these two designs\nmake the learned hash codes more informative and expressive\nfor preserving fine-grained similarity in the Hamming space.\n‚Ä¢Latent feature dispersion . Our second module, i.e., feature dis-\npersion, aims to hedge the inevitable information loss from the\nnumerical binarization. In conventional continuous embeddings,\nmajor features however condense in a small region of embed-\nding structures. Since these vectorized latent features tend to be\ninevitably smoothed by the hashing discreteness, it is natural\nto preserve information as much as possible by spreading out\nthose decisive features to the majority of embedding dimensions,\ninstead of the very few of them. To achieve this, our proposed\nmodule aims to explicitly disperse informative latent node fea-\ntures, which can be further diffused to each convolutional layer\nwhen exploring the bipartite graph.\n2Details about the visualization construction are attached in Appendix A.‚Ä¢Fourier serialized gradient estimation. Furthermore, to pro-\nvide accurate gradient estimation, BGCH proposes to decompose\nsign(¬∑)function with Fourier Series in the frequency domain.\nCompared to existing gradient estimators [ 11,15,39,44,59], this\nestimator better follows the main direction of factual gradients to\nenable an accordant and tractable model optimization in forward\nand backward propagation. With the limited number of decom-\nposition terms, BGCH can well provide more accurate gradient\nestimation to sign(¬∑)within the acceptable training cost.\nBased on the learned hash codes, BGCH maintains moderate\nresource consumption whilst providing substantial performance\nimprovement in Top-N Hamming space retrieval. The quality-cost\ntrade-off is summarized in Figure 1(b), which compares BGCH against\na list of representative counterparts ( including float32-based and\nhashing-based ) on a real-world bipartite graph with over 10 million\nobserved edges (experimental details are reported in ¬ß 5.1). As the\nlower-right corner of Figure 1(b) indicates the ideal optimal perfor-\nmance, BGCH can deliver over 8 √ócomputation acceleration and\nspace reduction relative to existing full-precision models, while\nbeing more effective than each hash-based method (¬ß 5.2 and ¬ß 5.3).\nTo summarize, our main contributions are organized as follows:\n‚Ä¢We study the problem of learning to hash with Graph Convolu-\ntional Network on bipartite graphs. We propose a novel approach\nBGCH with three effective modules for effective and efficient\nTop-N search in Hamming space (¬ß 4).\n‚Ä¢We conduct extensive experiments on six real-world datasets to\nevaluate the retrieval quality. In-depth analyses are also provided\ntowards the necessity of all proposed model components from\nboth technical and empirical perspectives (¬ß 5).\n‚Ä¢We theoretically prove the model effectiveness and provide com-\nplexity analyses in terms of time and space costs (Appendix C).\n2 Related Work\nGraph convolution network (GCN) . Early work studies the graph\nconvolutions mainly on the spectral domain , such as Laplacian eigen-\ndecomposition [ 3] and Chebyshev polynomials [ 12]. One major\nissue is that these models are usually computationally expensive.\nTo tackle this problem, spatial-based GCN models are proposed\nto re-define the graph convolution operations by aggregating the\nembeddings of neighbors to refine and update the target node‚Äôs\nembedding. Due to its scalability to large graphs, spatial-based GCN\nmodels are widely used in various applications [ 17,19,52]. For ex-\nample, to capture high-order structural information, NGCF [ 52] and\nLightGCN [ 19] learn the collaborative filtering signals on bipartite\ninteraction graphs for recommendation. Despite the effectiveness\nin embedding latent features for graph nodes, they usually suf-\nfer from inference inefficiency due to the high computational cost\nof similarity calculation between continuous embeddings [ 49]. To\naddress this issue, learning to hash provides the feasibility.\nLearning to hash . Learning to hash models are promising to\nachieve computation acceleration and storage reduction for general\ninformation retrieval and processing tasks [ 5,13,19,22,23,36,40].\nMore than reducing conflicts [ 33], similarity-preserving hashing\nmaps high-dimensional dense vectors to a low-dimensional Ham-\nming space for efficiently processing downstream tasks. A repre-\nsentative model is Locality Sensitive Hashing (LSH) [ 14] that uses\n\nBipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA\nrandom projections as the hash functions. Recent work focuses on\nintegrating the deep neural network architectures for model im-\nprovement [ 51]. They inspire a series of follow-up work for various\ntasks, such as fast retrieval of images [ 4,38,44], documents [ 9,35],\ncategorical information [27], e-commerce products [6, 65].\nTo leverage hashing techniques with GCNs, the state-of-the-art\nwork HashGNN [ 49] investigates learning to hash for online match-\ning and recommendation. Specifically, HashGNN consectively com-\nbines the GraphSage [ 17] as the embedding encoder and learning to\nhash method to get the corresponding binary encodings afterwards.\nIts hash encoding process only proceeds at the end of multi-layer\ngraph convolutions, i.e., using the aggregated output of Graph-\nSage for representation binarization. However, this fails to capture\nintermediate semantics from nodes‚Äô different layers of receptive\nfields [ 30]. The other issue of HashGNN is using Straight-Through\nEstimator (STE) [2] to assume all gradients of sign(¬∑)as 1 in back-\npropagation. However, the integral of 1 is a certain linear function\nother than the sign(¬∑), whereas this may lead to inconsistent opti-\nmization directions in the model training. To address these issues,\nour model BGCH is proposed with effectiveness justification in ¬ß 5.\n3 Preliminaries and Problem Formulation\nGraph Convolution Network (GCN). The general idea of GCN is\nto learn node embeddings by iteratively propagating and aggregating\nlatent features of node neighbors via the graph topology [ 19,30,56]:\nùëΩ(ùëô)\nùë•=ùê¥ùê∫ùê∫\u0010\nùëΩ(ùëô‚àí1)\nùë•,{ùëΩ(ùëô‚àí1)\nùëß :ùëß‚ààN(ùë•)}\u0011\n, (1)\nwhere ùëΩ(ùëô)\nùë•‚ààRùëëdenotes node ùë•‚Äôs embedding after ùëô-th iteration\nof graph convolutions, indexed in the embedding matrix ùëΩ.N(ùë•)\nis the set of ùë•‚Äôs neighbors. Function ùê¥ùê∫ùê∫(¬∑,¬∑)is the information\naggregation function, with several implementations in previous\nwork [ 17,30,50,57], mainly aiming to transform the center node fea-\nture and the neighbor features. In this work, we adopt the graph con-\nvolution paradigm from the state-of-the-art model LightGCN [ 19].\nBipartite Graph and Adjacency Matrix. The bipartite graph is\ndenoted asG={V1,V2,E}, whereV1andV2are two disjoint\nnode sets andEis the set of edges between nodes in V1andV2.\nWe can use ùíÄ‚ààR|V1|√ó|V 2|to indicate the edge transactions, where\n1-valued entries, i.e., ùíÄùë•,ùë¶=1, indicate there is an observed edge\nbetween nodes ùë•‚ààV 1andùë¶‚ààV 2, otherwise ùíÄùë•,ùë¶=0. Then the\nadjacency matrix ùë®of the whole graph can be defined as:\nùë®=\u00140ùíÄ\nùíÄùëá0\u0015\n. (2)\nProblem Formulation. Give a bipartite graph G={V1,V2,E}\nand its adjacency matrix ùë®, we devote to learn a hashing function:\nùêπ(ùë®|Œò)‚ÜíQ, (3)\nwhere Œòis the set of all learnable parameters. Given two nodes in\nthe bipartite graph, e.g., ùë•‚ààV 1andùë¶‚ààV 2, their hash codes are Qùë•\nandQùë¶. Then the probability of edge existence bùíÄùë•,ùë¶between nodes\nùë•‚ààV 1andùë¶‚ààV 2can be effectively and efficiently measured by\nthe hash codesQùë•andQùë¶, i.e.,bùíÄùë•,ùë¶=ùëì(Qùë•,Qùë¶)whereùëìis a score\nfunction. Intuitively, the larger value bùíÄùë•,ùë¶is, the more likely ùë•and\nùë¶are matched, i.e., an edge between ùë•andùë¶exists. Explanations of\nkey notations used in this paper are attached in Appendix B.4 BGCH: Methodology\n4.1 Overview\nWe formally introduce our BGCH model. Notice that since the effect\nof feature dispersion module propagates along with convolutional\nhashing, we then introduce these modules in the following order:\n(1)latent feature dispersion (¬ß 4.2) aims to disperse the embedded\nfeatures into wider embedding structures to hedge the inevitable in-\nformation loss in hashing; (2) adaptive graph convolutional hashing\n(¬ß 4.3) provides an effective encoding approach to significantly im-\nprove the hashed feature expressivity whilst maintaining the match-\ning efficiency in the hamming space; (3) Fourier serialized gradient\nestimation (¬ß 4.4) introduces the Fourier Series decomposition for\nsign(¬∑)in the frequency domain to provide more accurate gradient\napproximation. Based on the learned hash codes, BGCH develops\nefficient online matching with the Hamming distance measurement\n(¬ß 4.5). Our model illustration is attached in Figure 2(b).\n4.2 Latent Feature Dispersion\nTo tackle the feature erosion issue, we seek to disperse the em-\nbedded features as one effective strategy to hedge the inevitable\ninformation loss caused by numerical binarization. From the per-\nspective of singular value decomposition (SVD), singular values\nand corresponding singular vectors reconstruct the original ma-\ntrix; normally, large singular values can be interpreted to associate\nwith major feature structures of the matrix [ 54]. Since we want to\navoid condensing and gathering informative features in (relatively\nsmall) embedding sub-structures, it is natural to bridge the target\nby working on these singular values. Hence, based on this intuition,\nwe aim to normalize singular values for equalizing their respective\ncontributions in constituting latent features . To achieve this, Power\nNormalization [ 31,68] is one of the solutions that tackle related\nproblems such as feature imbalance [ 32]. Inspired by the recent ap-\nproximation attempt [ 61], we now introduce a lightweight feature\ndispersion technique in graph convolution as follows.\nConcretely, let ùë∞denote the identity matrix, we start from gener-\nating a standard normal random vector ùíë(0)‚àºN( 0,ùë∞)where ùíë(0)‚àà\nRùëê. Based on the embedding matrix to conduct feature dispersion,\ne.g., let ùëΩ=ùëΩ(0), we compute the desired dispersing vector ùíë(ùëò)\nby iteratively performing ùíë(ùëò)=ùëΩTùëΩùíë(ùëò‚àí1). The iteration for gen-\nerating dispersing vectors is independent of the graph convolution\niterations3. We have the projection matrix ùë∑ofùíë(ùêæ)via:\nùë∑=ùíë(ùêæ)ùíë(ùêæ)T\n||ùíë(ùêæ)||2\n2. (4)\nThen we have the feature-dispersed representation matrix with the\nhyper-parameter ùúñ‚àà(0,1)as follows:\neùëΩ=ùëΩ(ùë∞‚àíùúñùë∑). (5)\nConsequently, integrating the dispersed matrix eùëΩ, we have the\nfeature-dispersed graph convolution as:\neùëΩ(ùëô+1)=(ùë´‚àí1\n2ùë®ùë´‚àí1\n2)eùëΩ(ùëô),whereeùëΩ(0)=ùëΩ(0)(ùë∞‚àíùúñùë∑).(6)\nNote that we explicitly conduct this feature dispersion operation\none time only at the initial step, i.e., eùëΩ(0), and, more importantly,\nsuch feature dispersion can be diffused via the multi-layer graph\n3In our work, we set ùêæ‚â§ùêømainly to enable the associated complexity of dispersing vector gener-\nation is upper bounded by the graph convolution complexity.\n\nWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Yankai Chen et al.\nl=1\n<latexit sha1_base64=\"rKeL/G6b4GfPYs6wJbsCYZc6xg4=\">AAAB7nicdVDLSgMxFM3UV62vqks3wVZwNWSGaW0XQtGNywr2Ae1QMmmmDc1khiQjlKEf4caFIm79Hnf+jelDUNEDFw7n3Mu99wQJZ0oj9GHl1tY3Nrfy24Wd3b39g+LhUVvFqSS0RWIey26AFeVM0JZmmtNuIimOAk47weR67nfuqVQsFnd6mlA/wiPBQkawNlKnzOEldMqDYgnZtXq9glyIbA9VHa9iiFP1XFSHjo0WKIEVmoPie38YkzSiQhOOleo5KNF+hqVmhNNZoZ8qmmAywSPaM1TgiCo/W5w7g2dGGcIwlqaEhgv1+0SGI6WmUWA6I6zH6rc3F//yeqkOa37GRJJqKshyUZhyqGM4/x0OmaRE86khmEhmboVkjCUm2iRUMCF8fQr/J23Xdjy7cuuWGlerOPLgBJyCc+CAC9AAN6AJWoCACXgAT+DZSqxH68V6XbbmrNXMMfgB6+0TmhWOcw==</latexit>\nl=2\n<latexit sha1_base64=\"+5irm2GcwA2N0gsqNFYauwx0urI=\">AAAB7HicdVDLSgMxFM3UV62vqks3wVZwNWRqH9OFUHTjsoLTFtqhZNK0Dc1khiQjlKHf4MaFIm79IHf+jelDUNEDFw7n3Mu99wQxZ0oj9GFl1tY3Nrey27md3b39g/zhUUtFiSTUIxGPZCfAinImqKeZ5rQTS4rDgNN2MLme++17KhWLxJ2extQP8UiwISNYG8kr8stSsZ8vINut1yuoCpFdRlV0UTPEqbo1tw4dGy1QACs0+/n33iAiSUiFJhwr1XVQrP0US80Ip7NcL1E0xmSCR7RrqMAhVX66OHYGz4wygMNImhIaLtTvEykOlZqGgekMsR6r395c/MvrJnro+ikTcaKpIMtFw4RDHcH553DAJCWaTw3BRDJzKyRjLDHRJp+cCeHrU/g/aZVsp2xXbkuFxtUqjiw4AafgHDigBhrgBjSBBwhg4AE8gWdLWI/Wi/W6bM1Yq5lj8APW2ycMeY41</latexit>\nx1‚Äôs neighbors\n<latexit sha1_base64=\"fFADXxMlU8K5FcjMOC6hPalkPSk=\">AAAB+nicbVBNT8JAEJ3iF+JX0aOXjWD0RFqi0SPRi0dM5COBptkuC2zYbpvdrUoqP8WLB43x6i/x5r9xgR4UfMkkL+/NZGZeEHOmtON8W7mV1bX1jfxmYWt7Z3fPLu43VZRIQhsk4pFsB1hRzgRtaKY5bceS4jDgtBWMrqd+655KxSJxp8cx9UI8EKzPCNZG8u1i+dF3yycKCcoGwyCSyrdLTsWZAS0TNyMlyFD37a9uLyJJSIUmHCvVcZ1YeymWmhFOJ4VuomiMyQgPaMdQgUOqvHR2+gQdG6WH+pE0JTSaqb8nUhwqNQ4D0xliPVSL3lT8z+skun/ppUzEiaaCzBf1E450hKY5oB6TlGg+NgQTycytiAyxxESbtAomBHfx5WXSrFbcs8r5bbVUu8riyMMhHMEpuHABNbiBOjSAwAM8wyu8WU/Wi/Vufcxbc1Y2cwB/YH3+AOp5kyY=</latexit>\nNormalized Sumy3\n<latexit sha1_base64=\"m2ql1yRVdNWgmD/iKvyLKwiCcaY=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5JURY9FLx4rmLbQhrLZbtqlm03Y3Qgh9Dd48aCIV3+QN/+NmzYHbX0w8Hhvhpl5fsyZ0rb9bZXW1jc2t8rblZ3dvf2D6uFRR0WJJNQlEY9kz8eKciaoq5nmtBdLikOf064/vcv97hOVikXiUacx9UI8FixgBGsjufV0eFEfVmt2w54DrRKnIDUo0B5WvwajiCQhFZpwrFTfsWPtZVhqRjidVQaJojEmUzymfUMFDqnysvmxM3RmlBEKImlKaDRXf09kOFQqDX3TGWI9UcteLv7n9RMd3HgZE3GiqSCLRUHCkY5Q/jkaMUmJ5qkhmEhmbkVkgiUm2uRTMSE4yy+vkk6z4Vw2rh6atdZtEUcZTuAUzsGBa2jBPbTBBQIMnuEV3ixhvVjv1seitWQVM8fwB9bnD8rDjgU=</latexit>\ny1\n<latexit sha1_base64=\"Ptd3INDsNHeCUv1wwBmcl9W9ngw=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IURY9FLx4rmFpoQ9lsN+3SzW7Y3Qgh9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YcKZNq777ZTW1jc2t8rblZ3dvf2D6uFRR8tUEeoTyaXqhlhTzgT1DTOcdhNFcRxy+hhObmf+4xNVmknxYLKEBjEeCRYxgo2V/Ho28OqDas1tuHOgVeIVpAYF2oPqV38oSRpTYQjHWvc8NzFBjpVhhNNppZ9qmmAywSPas1TgmOognx87RWdWGaJIKlvCoLn6eyLHsdZZHNrOGJuxXvZm4n9eLzXRdZAzkaSGCrJYFKUcGYlmn6MhU5QYnlmCiWL2VkTGWGFibD4VG4K3/PIq6TQb3kXj8r5Za90UcZThBE7hHDy4ghbcQRt8IMDgGV7hzRHOi/PufCxaS04xcwx/4Hz+AMe5jgM=</latexit>\nV(0)y1\n<latexit sha1_base64=\"tBRP5HRS/S+eRVaM7uleempzArU=\">AAACBXicbVC7TsMwFHV4lvIKMMJg0SKVpUoqEIwVLIxFog+pDZHjuK1VJ45sBymKsrDwKywMIMTKP7DxNzhtBmg5kuWjc+7Vvfd4EaNSWda3sbS8srq2Xtoob25t7+yae/sdyWOBSRtzxkXPQ5IwGpK2ooqRXiQICjxGut7kOve7D0RIysM7lUTECdAopEOKkdKSax5VBx5nvkwC/aWdzE0T187u05p1mlVds2LVrSngIrELUgEFWq75NfA5jgMSKsyQlH3bipSTIqEoZiQrD2JJIoQnaET6moYoINJJp1dk8EQrPhxyoV+o4FT93ZGiQOZ76soAqbGc93LxP68fq+Glk9IwihUJ8WzQMGZQcZhHAn0qCFYs0QRhQfWuEI+RQFjp4Mo6BHv+5EXSadTts/r5baPSvCriKIFDcAxqwAYXoAluQAu0AQaP4Bm8gjfjyXgx3o2PWemSUfQcgD8wPn8A4BOYKQ==</latexit>\nV(0)y3\n<latexit sha1_base64=\"FO0Ewju9QDa8Q6XwYvHAX6YHsGk=\">AAACBXicbVC7TsMwFHXKq5RXgBGGiBapLFVSQDBWsDAWiT6kNkSO47RWnTiyHaQoysLCr7AwgBAr/8DG3+C0GaDlSJaPzrlX997jRpQIaZrfWmlpeWV1rbxe2djc2t7Rd/e6gsUc4Q5ilPG+CwWmJMQdSSTF/YhjGLgU99zJde73HjAXhIV3MomwHcBRSHyCoFSSox/Whi6jnkgC9aXdzEkT5zS7T+vmSVZz9KrZMKcwFolVkCoo0Hb0r6HHUBzgUCIKhRhYZiTtFHJJEMVZZRgLHEE0gSM8UDSEARZ2Or0iM46V4hk+4+qF0piqvztSGIh8T1UZQDkW814u/ucNYulf2ikJo1jiEM0G+TE1JDPySAyPcIwkTRSBiBO1q4HGkEMkVXAVFYI1f/Ii6TYb1lnj/LZZbV0VcZTBATgCdWCBC9ACN6ANOgCBR/AMXsGb9qS9aO/ax6y0pBU9++APtM8f4yuYKw==</latexit>\nl=1\n<latexit sha1_base64=\"rKeL/G6b4GfPYs6wJbsCYZc6xg4=\">AAAB7nicdVDLSgMxFM3UV62vqks3wVZwNWSGaW0XQtGNywr2Ae1QMmmmDc1khiQjlKEf4caFIm79Hnf+jelDUNEDFw7n3Mu99wQJZ0oj9GHl1tY3Nrfy24Wd3b39g+LhUVvFqSS0RWIey26AFeVM0JZmmtNuIimOAk47weR67nfuqVQsFnd6mlA/wiPBQkawNlKnzOEldMqDYgnZtXq9glyIbA9VHa9iiFP1XFSHjo0WKIEVmoPie38YkzSiQhOOleo5KNF+hqVmhNNZoZ8qmmAywSPaM1TgiCo/W5w7g2dGGcIwlqaEhgv1+0SGI6WmUWA6I6zH6rc3F//yeqkOa37GRJJqKshyUZhyqGM4/x0OmaRE86khmEhmboVkjCUm2iRUMCF8fQr/J23Xdjy7cuuWGlerOPLgBJyCc+CAC9AAN6AJWoCACXgAT+DZSqxH68V6XbbmrNXMMfgB6+0TmhWOcw==</latexit>\nl=2\n<latexit sha1_base64=\"+5irm2GcwA2N0gsqNFYauwx0urI=\">AAAB7HicdVDLSgMxFM3UV62vqks3wVZwNWRqH9OFUHTjsoLTFtqhZNK0Dc1khiQjlKHf4MaFIm79IHf+jelDUNEDFw7n3Mu99wQxZ0oj9GFl1tY3Nrey27md3b39g/zhUUtFiSTUIxGPZCfAinImqKeZ5rQTS4rDgNN2MLme++17KhWLxJ2extQP8UiwISNYG8kr8stSsZ8vINut1yuoCpFdRlV0UTPEqbo1tw4dGy1QACs0+/n33iAiSUiFJhwr1XVQrP0US80Ip7NcL1E0xmSCR7RrqMAhVX66OHYGz4wygMNImhIaLtTvEykOlZqGgekMsR6r395c/MvrJnro+ikTcaKpIMtFw4RDHcH553DAJCWaTw3BRDJzKyRjLDHRJp+cCeHrU/g/aZVsp2xXbkuFxtUqjiw4AafgHDigBhrgBjSBBwhg4AE8gWdLWI/Wi/W6bM1Yq5lj8APW2ycMeY41</latexit>\nNormalized Sumy2‚Äôs neighbors\n<latexit sha1_base64=\"mLQYqg5W9DQ1A8B//rIraAdErC4=\">AAAB/nicbVDLSsNAFJ3UV62vqLhyM9iKrkpSFF0W3bisYB/QhjCZTtqhk5kwMxFCCPgrblwo4tbvcOffOG2z0NYDFw7n3Mu99wQxo0o7zrdVWlldW98ob1a2tnd29+z9g44SicSkjQUTshcgRRjlpK2pZqQXS4KigJFuMLmd+t1HIhUV/EGnMfEiNOI0pBhpI/n2US1Lcz9r5LUzBTmho3EgpPLtqlN3ZoDLxC1IFRRo+fbXYChwEhGuMUNK9V0n1l6GpKaYkbwySBSJEZ6gEekbylFElJfNzs/hqVGGMBTSFNdwpv6eyFCkVBoFpjNCeqwWvan4n9dPdHjtZZTHiSYczxeFCYNawGkWcEglwZqlhiAsqbkV4jGSCGuTWMWE4C6+vEw6jbp7Ub+8b1SbN0UcZXAMTsA5cMEVaII70AJtgEEGnsEreLOerBfr3fqYt5asYuYQ/IH1+QOUGJVA</latexit>\nx1\n<latexit sha1_base64=\"/BCjIpSlQYsmAQdAn7NI7sBaNhY=\">AAAB7HicbVBNTwIxEJ3FL8Qv1KOXRjDxRHaJRo9ELx4xcYEENqRbutDQdjdt10g2/AYvHjTGqz/Im//GAntQ8CWTvLw3k5l5YcKZNq777RTW1jc2t4rbpZ3dvf2D8uFRS8epItQnMY9VJ8Saciapb5jhtJMoikXIaTsc38789iNVmsXywUwSGgg8lCxiBBsr+dWnvlftlytuzZ0DrRIvJxXI0eyXv3qDmKSCSkM41rrruYkJMqwMI5xOS71U0wSTMR7SrqUSC6qDbH7sFJ1ZZYCiWNmSBs3V3xMZFlpPRGg7BTYjvezNxP+8bmqi6yBjMkkNlWSxKEo5MjGafY4GTFFi+MQSTBSztyIywgoTY/Mp2RC85ZdXSate8y5ql/f1SuMmj6MIJ3AK5+DBFTTgDprgAwEGz/AKb450Xpx352PRWnDymWP4A+fzB8YyjgI=</latexit>\nx2\n<latexit sha1_base64=\"JcOhZeFQiUW/Fre3KnkZu6uNS40=\">AAAB7HicbVBNTwIxEJ3iF+IX6tFLI5h4IrtEo0eiF4+YuEACG9ItXWjodjdt10g2/AYvHjTGqz/Im//GAntQ8CWTvLw3k5l5QSK4No7zjQpr6xubW8Xt0s7u3v5B+fCopeNUUebRWMSqExDNBJfMM9wI1kkUI1EgWDsY38789iNTmsfywUwS5kdkKHnIKTFW8qpP/Xq1X644NWcOvErcnFQgR7Nf/uoNYppGTBoqiNZd10mMnxFlOBVsWuqlmiWEjsmQdS2VJGLaz+bHTvGZVQY4jJUtafBc/T2RkUjrSRTYzoiYkV72ZuJ/Xjc14bWfcZmkhkm6WBSmApsYzz7HA64YNWJiCaGK21sxHRFFqLH5lGwI7vLLq6RVr7kXtcv7eqVxk8dRhBM4hXNw4QoacAdN8IACh2d4hTck0Qt6Rx+L1gLKZ47hD9DnD8e3jgM=</latexit>\nV(0)x1\n<latexit sha1_base64=\"mloPF3GjGWB4QHD2hGGsUoi8ww8=\">AAACBXicbVC7TsMwFHXKq5RXgBEGixapLFVSgWCsYGEsEn1IbYgcx2mtOnFkO4gqysLCr7AwgBAr/8DG3+C0HaDlSJaPzrlX997jxYxKZVnfRmFpeWV1rbhe2tjc2t4xd/fakicCkxbmjIuuhyRhNCItRRUj3VgQFHqMdLzRVe537omQlEe3ahwTJ0SDiAYUI6Ul1zys9D3OfDkO9Ze2Mzd9cO3sLq1aJ1nFNctWzZoALhJ7RspghqZrfvV9jpOQRAozJGXPtmLlpEgoihnJSv1EkhjhERqQnqYRCol00skVGTzWig8DLvSLFJyovztSFMp8T10ZIjWU814u/uf1EhVcOCmN4kSRCE8HBQmDisM8EuhTQbBiY00QFlTvCvEQCYSVDq6kQ7DnT14k7XrNPq2d3dTLjctZHEVwAI5AFdjgHDTANWiCFsDgETyDV/BmPBkvxrvxMS0tGLOeffAHxucP3oWYKA==</latexit>\nV(0)x2\n<latexit sha1_base64=\"ao7jW9APLeOOwXjo2dORp2yo1gY=\">AAACBXicbVC7TsMwFHXKq5RXgBGGiBapLFVSgWCsYGEsEn1IbYgcx2mtOnZkO4gqysLCr7AwgBAr/8DG3+C0HaDlSJaPzrlX997jx5RIZdvfRmFpeWV1rbhe2tjc2t4xd/fakicC4RbilIuuDyWmhOGWIoribiwwjHyKO/7oKvc791hIwtmtGsfYjeCAkZAgqLTkmYeVvs9pIMeR/tJ25qUPXj27S6v2SVbxzLJdsyewFokzI2UwQ9Mzv/oBR0mEmUIUStlz7Fi5KRSKIIqzUj+ROIZoBAe4pymDEZZuOrkis461ElghF/oxZU3U3x0pjGS+p66MoBrKeS8X//N6iQov3JSwOFGYoemgMKGW4lYeiRUQgZGiY00gEkTvaqEhFBApHVxJh+DMn7xI2vWac1o7u6mXG5ezOIrgAByBKnDAOWiAa9AELYDAI3gGr+DNeDJejHfjY1paMGY9++APjM8f4BGYKQ==</latexit>\nDH(Qx1,Qy2).\n<latexit sha1_base64=\"GTKLSpvJeiw20Y7PWmDj9yU42D8=\">AAACHHicbVDLSsNAFJ3UV62vqEs3g61QQUJSFV0WddFlC/YBbQmT6aQdOnkwMxFDyIe48VfcuFDEjQvBv3HSZqHVA8MczrmXe+9xQkaFNM0vrbC0vLK6VlwvbWxube/ou3sdEUQckzYOWMB7DhKEUZ+0JZWM9EJOkOcw0nWm15nfvSNc0MC/lXFIhh4a+9SlGEkl2fpp5cZuVAdOwEYi9tSXtFI7ubet9AQuqrFdS48rBrT1smmYM8C/xMpJGeRo2vrHYBTgyCO+xAwJ0bfMUA4TxCXFjKSlQSRIiPAUjUlfUR95RAyT2XEpPFLKCLoBV8+XcKb+7EiQJ7IlVaWH5EQsepn4n9ePpHs5TKgfRpL4eD7IjRiUAcySgiPKCZYsVgRhTtWuEE8QR1iqPEsqBGvx5L+kUzOsM+O8VSvXr/I4iuAAHIIqsMAFqIMGaII2wOABPIEX8Ko9as/am/Y+Ly1oec8++AXt8xvw2KFF</latexit>\nHamming distance\nl=L\n<latexit sha1_base64=\"d/iV+msqBqxNCx+jwctMnOQepjw=\">AAAB7HicdVDLSsNAFJ3UV62vqks3g63gKiQx1nQhFN24cFHB2EIbymQ6aYdOJmFmIpTQb3DjQhG3fpA7/8bpQ1DRAxcO59zLvfeEKaNSWdaHUVhaXlldK66XNja3tnfKu3t3MskEJj5OWCLaIZKEUU58RRUj7VQQFIeMtMLR5dRv3RMhacJv1TglQYwGnEYUI6Ulv8rOr6u9csUyvVq97tagZZ44tue5mtiO69ZtaJvWDBWwQLNXfu/2E5zFhCvMkJQd20pVkCOhKGZkUupmkqQIj9CAdDTlKCYyyGfHTuCRVvowSoQuruBM/T6Ro1jKcRzqzhipofztTcW/vE6mIi/IKU8zRTieL4oyBlUCp5/DPhUEKzbWBGFB9a0QD5FAWOl8SjqEr0/h/+TOMW3XPL1xKo2LRRxFcAAOwTGwwRlogCvQBD7AgIIH8ASeDW48Gi/G67y1YCxm9sEPGG+fKqKOSA==</latexit>\nl=L\n<latexit sha1_base64=\"d/iV+msqBqxNCx+jwctMnOQepjw=\">AAAB7HicdVDLSsNAFJ3UV62vqks3g63gKiQx1nQhFN24cFHB2EIbymQ6aYdOJmFmIpTQb3DjQhG3fpA7/8bpQ1DRAxcO59zLvfeEKaNSWdaHUVhaXlldK66XNja3tnfKu3t3MskEJj5OWCLaIZKEUU58RRUj7VQQFIeMtMLR5dRv3RMhacJv1TglQYwGnEYUI6Ulv8rOr6u9csUyvVq97tagZZ44tue5mtiO69ZtaJvWDBWwQLNXfu/2E5zFhCvMkJQd20pVkCOhKGZkUupmkqQIj9CAdDTlKCYyyGfHTuCRVvowSoQuruBM/T6Ro1jKcRzqzhipofztTcW/vE6mIi/IKU8zRTieL4oyBlUCp5/DPhUEKzbWBGFB9a0QD5FAWOl8SjqEr0/h/+TOMW3XPL1xKo2LRRxFcAAOwTGwwRlogCvQBD7AgIIH8ASeDW48Gi/G67y1YCxm9sEPGG+fKqKOSA==</latexit>\nHash code segments\nQ(L)y2\n<latexit sha1_base64=\"RuWwvNwM6gqltcc53D/QgZL2LmY=\">AAACBXicbVC7TsMwFHV4lvIKMMIQ0SKVpUoqEIwVLAwMrUQfUhsix3Faq04c2Q5SFGVh4VdYGECIlX9g429w2gzQciTLR+fcq3vvcSNKhDTNb21peWV1bb20Ud7c2t7Z1ff2u4LFHOEOYpTxvgsFpiTEHUkkxf2IYxi4FPfcyXXu9x4wF4SFdzKJsB3AUUh8gqBUkqMfVYcuo55IAvWl7cxJE6eR3ae129Os6ugVs25OYSwSqyAVUKDl6F9Dj6E4wKFEFAoxsMxI2inkkiCKs/IwFjiCaAJHeKBoCAMs7HR6RWacKMUzfMbVC6UxVX93pDAQ+Z6qMoByLOa9XPzPG8TSv7RTEkaxxCGaDfJjakhm5JEYHuEYSZooAhEnalcDjSGHSKrgyioEa/7kRdJt1K2z+nm7UWleFXGUwCE4BjVggQvQBDegBToAgUfwDF7Bm/akvWjv2sesdEkreg7AH2ifPwSYmEE=</latexit>\n‚Üµ(L)y2\n<latexit sha1_base64=\"nbDKNDFL8RLXkRHVxuaxtPZNqXw=\">AAAB/XicbVDLSsNAFJ34rPUVHzs3g61QNyUpii4Lbly4qGAf0MZwM522QycPZiZCDMFfceNCEbf+hzv/xmmbhbYeuHA4517uvceLOJPKsr6NpeWV1bX1wkZxc2t7Z9fc22/JMBaENknIQ9HxQFLOAtpUTHHaiQQF3+O07Y2vJn77gQrJwuBOJRF1fBgGbMAIKC255mG5BzwagZsmbi27Tys3p1nZNUtW1ZoCLxI7JyWUo+GaX71+SGKfBopwkLJrW5FyUhCKEU6zYi+WNAIyhiHtahqAT6WTTq/P8IlW+ngQCl2BwlP190QKvpSJ7+lOH9RIznsT8T+vG6vBpZOyIIoVDchs0SDmWIV4EgXuM0GJ4okmQATTt2IyAgFE6cCKOgR7/uVF0qpV7bPq+W2tVK/ncRTQETpGFWSjC1RH16iBmoigR/SMXtGb8WS8GO/Gx6x1ychnDtAfGJ8/R0yUdQ==</latexit>\nAdaptive convolutional hashingHamming space query & matching(b) BGCH framework illustration\nV(L)x1\n<latexit sha1_base64=\"kqOjNtnoAfJbMEiGoPPD/HdcPdc=\">AAACBXicbVC7TsMwFHV4lvIKMMJg0SKVpUoqEIwVLAwMRaIPqQ2R47itVceJbAdRRVlY+BUWBhBi5R/Y+BucNgO0HMny0Tn36t57vIhRqSzr21hYXFpeWS2sFdc3Nre2zZ3dlgxjgUkThywUHQ9JwignTUUVI51IEBR4jLS90WXmt++JkDTkt2ocESdAA077FCOlJdc8KPe8kPlyHOgvaaVu8uDa6V1SuT5Oy65ZsqrWBHCe2DkpgRwN1/zq+SGOA8IVZkjKrm1FykmQUBQzkhZ7sSQRwiM0IF1NOQqIdJLJFSk80ooP+6HQjys4UX93JCiQ2Z66MkBqKGe9TPzP68aqf+4klEexIhxPB/VjBlUIs0igTwXBio01QVhQvSvEQyQQVjq4og7Bnj15nrRqVfukenpTK9Uv8jgKYB8cggqwwRmogyvQAE2AwSN4Bq/gzXgyXox342NaumDkPXvgD4zPHwlYmEQ=</latexit>\nV(2)x1\n<latexit sha1_base64=\"eMvM7FWOfbExH2IsL5FJchKa9nM=\">AAACBXicbVC7TsMwFHXKq5RXgBGGiBapLFVSgWCsYGEsEn1IbYgcx2mtOnZkO4gqysLCr7AwgBAr/8DG3+C0HaDlSJaPzrlX997jx5RIZdvfRmFpeWV1rbhe2tjc2t4xd/fakicC4RbilIuuDyWmhOGWIoribiwwjHyKO/7oKvc791hIwtmtGsfYjeCAkZAgqLTkmYeVvs9pIMeR/tJ25qUPnpPdpdX6SVbxzLJdsyewFokzI2UwQ9Mzv/oBR0mEmUIUStlz7Fi5KRSKIIqzUj+ROIZoBAe4pymDEZZuOrkis461ElghF/oxZU3U3x0pjGS+p66MoBrKeS8X//N6iQov3JSwOFGYoemgMKGW4lYeiRUQgZGiY00gEkTvaqEhFBApHVxJh+DMn7xI2vWac1o7u6mXG5ezOIrgAByBKnDAOWiAa9AELYDAI3gGr+DNeDJejHfjY1paMGY9++APjM8f4ZOYKg==</latexit>\nV(1)x1\n<latexit sha1_base64=\"q4CVr0jz6CBlB0OEhGhl+t5dYII=\">AAACBXicbVC7TsMwFHXKq5RXgBEGixapLFVSgWCsYGEsEn1IbYgcx2mtOnFkO4gqysLCr7AwgBAr/8DG3+C0HaDlSJaPzrlX997jxYxKZVnfRmFpeWV1rbhe2tjc2t4xd/fakicCkxbmjIuuhyRhNCItRRUj3VgQFHqMdLzRVe537omQlEe3ahwTJ0SDiAYUI6Ul1zys9D3OfDkO9Ze2Mzd9cO3sLq3aJ1nFNctWzZoALhJ7RspghqZrfvV9jpOQRAozJGXPtmLlpEgoihnJSv1EkhjhERqQnqYRCol00skVGTzWig8DLvSLFJyovztSFMp8T10ZIjWU814u/uf1EhVcOCmN4kSRCE8HBQmDisM8EuhTQbBiY00QFlTvCvEQCYSVDq6kQ7DnT14k7XrNPq2d3dTLjctZHEVwAI5AFdjgHDTANWiCFsDgETyDV/BmPBkvxrvxMS0tGLOeffAHxucP4AyYKQ==</latexit>\neV(1)x1\n<latexit sha1_base64=\"20M5PjqVaFq11wjRTtap/QWKro8=\">AAACEXicbVC7TgJBFJ3FF+Jr1dJmI5hgQ3aJRkoSG0tM5JEAbmZnLzBh9pGZWZVM9hds/BUbC42xtbPzbxxgCwVPMpmTc+7Nvfd4MaNC2va3kVtZXVvfyG8WtrZ3dvfM/YOWiBJOoEkiFvGOhwUwGkJTUsmgE3PAgceg7Y0vp377DrigUXgjJzH0AzwM6YASLLXkmuVS7576ICnzQfW8iPliEuhPtdLUVQ+uk96qsnOallyzaFfsGaxl4mSkiDI0XPOr50ckCSCUhGEhuo4dy77CXFLCIC30EgExJmM8hK6mIQ5A9NXsotQ60YpvDSKuXyitmfq7Q+FATBfVlQGWI7HoTcX/vG4iB7W+omGcSAjJfNAgYZaMrGk8lk85EMkmmmDCqd7VIiPMMZE6xIIOwVk8eZm0qhXnrHJ+XS3Wa1kceXSEjlEZOegC1dEVaqAmIugRPaNX9GY8GS/Gu/ExL80ZWc8h+gPj8wfr8J2m</latexit>\neV(2)x1\n<latexit sha1_base64=\"1V2xhBC1Oq1ek4zWfyXjJd9zePE=\">AAACEXicbVC7TsMwFHXKq5RXgZElokUqS5VUIDpWYmEsEn1IbYgc56a16sSR7QBVlF9g4VdYGECIlY2Nv8F9DNByJMtH59yre+/xYkalsqxvI7eyura+kd8sbG3v7O4V9w/akieCQItwxkXXwxIYjaClqGLQjQXg0GPQ8UaXE79zB0JSHt2ocQxOiAcRDSjBSktusVLu31MfFGU+pH2PM1+OQ/2l7Sxz0wfXzm7TSu00K7vFklW1pjCXiT0nJTRH0y1+9X1OkhAiRRiWsmdbsXJSLBQlDLJCP5EQYzLCA+hpGuEQpJNOL8rME634ZsCFfpEyp+rvjhSHcrKorgyxGspFbyL+5/USFdSdlEZxoiAis0FBwkzFzUk8pk8FEMXGmmAiqN7VJEMsMFE6xIIOwV48eZm0a1X7rHp+XSs16vM48ugIHaMKstEFaqAr1EQtRNAjekav6M14Ml6Md+NjVpoz5j2H6A+Mzx/td52n</latexit>\neV(L)x1\n<latexit sha1_base64=\"d09FlBRsHpAoirTnkSE3mS9KKuY=\">AAACEXicbVC7TsNAEDzzDOEVoKSxSJBCE9kRCMoIGgqKIJGHFBvrfF4np5wfujsDkeVfoOFXaChAiJaOjr/hkriAhJFON5rZ1e6OGzMqpGF8awuLS8srq4W14vrG5tZ2aWe3LaKEE2iRiEW862IBjIbQklQy6MYccOAy6LjDi7HfuQMuaBTeyFEMdoD7IfUpwVJJTqlase6pB5IyD1LLjZgnRoH60naWOemDY2a3afXqKKs4pbJRMybQ54mZkzLK0XRKX5YXkSSAUBKGheiZRiztFHNJCYOsaCUCYkyGuA89RUMcgLDTyUWZfqgUT/cjrl4o9Yn6uyPFgRgvqioDLAdi1huL/3m9RPpndkrDOJEQkukgP2G6jPRxPLpHORDJRopgwqnaVScDzDGRKsSiCsGcPXmetOs187h2cl0vN87zOApoHx2gKjLRKWqgS9RELUTQI3pGr+hNe9JetHftY1q6oOU9e+gPtM8fGD6dyw==</latexit>\neV=V(I\u0000‚úèP)\n<latexit sha1_base64=\"xwBpho72VDEPOiQABMDyg7/nMvg=\">AAACQHicbVDLSgMxFM34rPVVdekmWIW6sMyIohtBdKO7CvYBnVIymds2NJMMSUYpw3yaGz/BnWs3LhRx68r0sbDqgZCTc8/l3pwg5kwb1312Zmbn5hcWc0v55ZXVtfXCxmZNy0RRqFLJpWoERANnAqqGGQ6NWAGJAg71oH85rNfvQGkmxa0ZxNCKSFewDqPEWKldqO/69ywEw3gIqR9IHupBZK+0lmX4DE8rpZ/P6wwfYB9izbgUU8ZKtr/bLhTdsjsC/ku8CSmiCSrtwpMfSppEIAzlROum58amlRJlGOWQ5f1EQ0xon3ShaakgEehWOgogw3tWCXFHKnuEwSP1Z0dKIj1czjojYnr6d20o/ldrJqZz2kqZiBMDgo4HdRKOjcTDNHHIFFDDB5YQqpjdFdMeUYQam3nehuD9/vJfUjsse0fl45vD4vnFJI4c2kY7qIQ8dILO0RWqoCqi6AG9oDf07jw6r86H8zm2zjiTni00BefrG6YtsZA=</latexit>\n‚Ä¶‚Ä¶\nQ(1)x1\n<latexit sha1_base64=\"6LE2Wxy0MSJVaLBwN/rbkz7UCzA=\">AAACBXicbVC7TsMwFHV4lvIKMMJg0SKVpUoqEIwVLIytRB9SGyLHcVqrThzZDqKKsrDwKywMIMTKP7DxNzhtB2g5kuWjc+7Vvfd4MaNSWda3sbS8srq2Xtgobm5t7+yae/ttyROBSQtzxkXXQ5IwGpGWooqRbiwICj1GOt7oOvc790RIyqNbNY6JE6JBRAOKkdKSax6V+x5nvhyH+kubmZs+uHZ2l1bs06zsmiWrak0AF4k9IyUwQ8M1v/o+x0lIIoUZkrJnW7FyUiQUxYxkxX4iSYzwCA1IT9MIhUQ66eSKDJ5oxYcBF/pFCk7U3x0pCmW+p64MkRrKeS8X//N6iQounZRGcaJIhKeDgoRBxWEeCfSpIFixsSYIC6p3hXiIBMJKB1fUIdjzJy+Sdq1qn1XPm7VS/WoWRwEcgmNQATa4AHVwAxqgBTB4BM/gFbwZT8aL8W58TEuXjFnPAfgD4/MH2DKYJA==</latexit>\n‚Üµ(1)x1\n<latexit sha1_base64=\"KdvWJ5Jw/SMYW3IXKJJAaomovf4=\">AAAB/XicbVDLSsNAFL3xWesrPnZugq1QNyUpii4LblxWsA9oY5hMJ+3QySTMTMQagr/ixoUibv0Pd/6N0zYLbT1w4XDOvdx7jx8zKpVtfxtLyyura+uFjeLm1vbOrrm335JRIjBp4ohFouMjSRjlpKmoYqQTC4JCn5G2P7qa+O17IiSN+K0ax8QN0YDTgGKktOSZh+UeYvEQeemD52R3acU5zcqeWbKr9hTWInFyUoIcDc/86vUjnISEK8yQlF3HjpWbIqEoZiQr9hJJYoRHaEC6mnIUEumm0+sz60QrfSuIhC6urKn6eyJFoZTj0NedIVJDOe9NxP+8bqKCSzelPE4U4Xi2KEiYpSJrEoXVp4JgxcaaICyovtXCQyQQVjqwog7BmX95kbRqVeesen5TK9XreRwFOIJjqIADF1CHa2hAEzA8wjO8wpvxZLwY78bHrHXJyGcO4A+Mzx8a9ZRY</latexit>\n‚Üµ(2)x1\n<latexit sha1_base64=\"8Hd+F2VecXluJheUQ9T58/9vchA=\">AAAB/XicbVDLSsNAFL3xWesrPnZugq1QNyUpii4LblxWsA9oY5hMJ+3QySTMTMQagr/ixoUibv0Pd/6N0zYLbT1w4XDOvdx7jx8zKpVtfxtLyyura+uFjeLm1vbOrrm335JRIjBp4ohFouMjSRjlpKmoYqQTC4JCn5G2P7qa+O17IiSN+K0ax8QN0YDTgGKktOSZh+UeYvEQeemD52R3aaV2mpU9s2RX7SmsReLkpAQ5Gp751etHOAkJV5ghKbuOHSs3RUJRzEhW7CWSxAiP0IB0NeUoJNJNp9dn1olW+lYQCV1cWVP190SKQinHoa87Q6SGct6biP953UQFl25KeZwowvFsUZAwS0XWJAqrTwXBio01QVhQfauFh0ggrHRgRR2CM//yImnVqs5Z9fymVqrX8zgKcATHUAEHLqAO19CAJmB4hGd4hTfjyXgx3o2PWeuSkc8cwB8Ynz8cfJRZ</latexit>\nQ(2)x1\n<latexit sha1_base64=\"hFaYOk+oRHSOZyR4cU/IHcJ9gW0=\">AAACBXicbVC7TsMwFHV4lvIKMMJg0SKVpUoqEIwVLIytRB9SGyLHcVqrjhPZDqKKsrDwKywMIMTKP7DxNzhtB2g5kuWjc+7Vvfd4MaNSWda3sbS8srq2Xtgobm5t7+yae/ttGSUCkxaOWCS6HpKEUU5aiipGurEgKPQY6Xij69zv3BMhacRv1TgmTogGnAYUI6Ul1zwq972I+XIc6i9tZm764NrZXVqpnWZl1yxZVWsCuEjsGSmBGRqu+dX3I5yEhCvMkJQ924qVkyKhKGYkK/YTSWKER2hAeppyFBLppJMrMniiFR8GkdCPKzhRf3ekKJT5nroyRGoo571c/M/rJSq4dFLK40QRjqeDgoRBFcE8EuhTQbBiY00QFlTvCvEQCYSVDq6oQ7DnT14k7VrVPqueN2ul+tUsjgI4BMegAmxwAergBjRAC2DwCJ7BK3gznowX4934mJYuGbOeA/AHxucP2bmYJQ==</latexit>\nQ(L)x1\n<latexit sha1_base64=\"PuefMz16aMoADcITO1ADExXXFis=\">AAACBXicbVC7TsMwFHXKq5RXgBGGiBapLFVSgWCsYGFgaCX6kNoQOY7TWnWcyHYQVZSFhV9hYQAhVv6Bjb/BaTNAy5EsH51zr+69x40oEdI0v7XC0vLK6lpxvbSxubW9o+/udUQYc4TbKKQh77lQYEoYbksiKe5FHMPApbjrjq8yv3uPuSAhu5WTCNsBHDLiEwSlkhz9sDJwQ+qJSaC+pJU6yYNjpXdJ9eYkrTh62ayZUxiLxMpJGeRoOvrXwAtRHGAmEYVC9C0zknYCuSSI4rQ0iAWOIBrDIe4rymCAhZ1Mr0iNY6V4hh9y9Zg0purvjgQGIttTVQZQjsS8l4n/ef1Y+hd2QlgUS8zQbJAfU0OGRhaJ4RGOkaQTRSDiRO1qoBHkEEkVXEmFYM2fvEg69Zp1Wjtr1cuNyzyOIjgAR6AKLHAOGuAaNEEbIPAInsEreNOetBftXfuYlRa0vGcf/IH2+QMBfpg/</latexit>\n‚Üµ(L)x1\n<latexit sha1_base64=\"lahSvjrEbRhTu/o2DWjjU37axds=\">AAAB/XicbVDLSsNAFL2pr1pf8bFzE2yFuilJUXRZcOPCRQX7gDaGyXTSDp1MwsxErCH4K25cKOLW/3Dn3zh9LLT1wIXDOfdy7z1+zKhUtv1t5JaWV1bX8uuFjc2t7R1zd68po0Rg0sARi0TbR5IwyklDUcVIOxYEhT4jLX94OfZb90RIGvFbNYqJG6I+pwHFSGnJMw9KXcTiAfLSB8/J7tLy9UlW8syiXbEnsBaJMyNFmKHumV/dXoSTkHCFGZKy49ixclMkFMWMZIVuIkmM8BD1SUdTjkIi3XRyfWYda6VnBZHQxZU1UX9PpCiUchT6ujNEaiDnvbH4n9dJVHDhppTHiSIcTxcFCbNUZI2jsHpUEKzYSBOEBdW3WniABMJKB1bQITjzLy+SZrXinFbObqrFWm0WRx4O4QjK4MA51OAK6tAADI/wDK/wZjwZL8a78TFtzRmzmX34A+PzB0QylHM=</latexit>\nQ(0)x1\n<latexit sha1_base64=\"9TX9EYvBGBJh2ZquGM+Q3dIT4qs=\">AAACBXicbVC7TsMwFHV4lvIKMMJg0SKVpUoqEIwVLIytRB9SGyLHcVqrThzZDqKKsrDwKywMIMTKP7DxNzhtB2g5kuWjc+7Vvfd4MaNSWda3sbS8srq2Xtgobm5t7+yae/ttyROBSQtzxkXXQ5IwGpGWooqRbiwICj1GOt7oOvc790RIyqNbNY6JE6JBRAOKkdKSax6V+x5nvhyH+kubmZs+uHZ2l1as06zsmiWrak0AF4k9IyUwQ8M1v/o+x0lIIoUZkrJnW7FyUiQUxYxkxX4iSYzwCA1IT9MIhUQ66eSKDJ5oxYcBF/pFCk7U3x0pCmW+p64MkRrKeS8X//N6iQounZRGcaJIhKeDgoRBxWEeCfSpIFixsSYIC6p3hXiIBMJKB1fUIdjzJy+Sdq1qn1XPm7VS/WoWRwEcgmNQATa4AHVwAxqgBTB4BM/gFbwZT8aL8W58TEuXjFnPAfgD4/MH1quYIw==</latexit>\n‚Üµ(0)x1\n<latexit sha1_base64=\"4mwEBX9Qp7HsFt40F7bZnljd+BU=\">AAAB/XicbVDLSsNAFJ34rPUVHzs3wVaom5IURZcFNy4r2Ae0MdxMJ+3QySTMTMQagr/ixoUibv0Pd/6N0zYLbT1w4XDOvdx7jx8zKpVtfxtLyyura+uFjeLm1vbOrrm335JRIjBp4ohFouODJIxy0lRUMdKJBYHQZ6Ttj64mfvueCEkjfqvGMXFDGHAaUAxKS555WO4Bi4fgpQ+ek92lFfs0K3tmya7aU1iLxMlJCeVoeOZXrx/hJCRcYQZSdh07Vm4KQlHMSFbsJZLEgEcwIF1NOYREuun0+sw60UrfCiKhiytrqv6eSCGUchz6ujMENZTz3kT8z+smKrh0U8rjRBGOZ4uChFkqsiZRWH0qCFZsrAlgQfWtFh6CAKx0YEUdgjP/8iJp1arOWfX8plaq1/M4CugIHaMKctAFqqNr1EBNhNEjekav6M14Ml6Md+Nj1rpk5DMH6A+Mzx8ZbpRX</latexit>\neV=V(I\u0000‚úèP)\n<latexit sha1_base64=\"xwBpho72VDEPOiQABMDyg7/nMvg=\">AAACQHicbVDLSgMxFM34rPVVdekmWIW6sMyIohtBdKO7CvYBnVIymds2NJMMSUYpw3yaGz/BnWs3LhRx68r0sbDqgZCTc8/l3pwg5kwb1312Zmbn5hcWc0v55ZXVtfXCxmZNy0RRqFLJpWoERANnAqqGGQ6NWAGJAg71oH85rNfvQGkmxa0ZxNCKSFewDqPEWKldqO/69ywEw3gIqR9IHupBZK+0lmX4DE8rpZ/P6wwfYB9izbgUU8ZKtr/bLhTdsjsC/ku8CSmiCSrtwpMfSppEIAzlROum58amlRJlGOWQ5f1EQ0xon3ShaakgEehWOgogw3tWCXFHKnuEwSP1Z0dKIj1czjojYnr6d20o/ldrJqZz2kqZiBMDgo4HdRKOjcTDNHHIFFDDB5YQqpjdFdMeUYQam3nehuD9/vJfUjsse0fl45vD4vnFJI4c2kY7qIQ8dILO0RWqoCqi6AG9oDf07jw6r86H8zm2zjiTni00BefrG6YtsZA=</latexit>\n‚Ä¶‚Ä¶V(1)y2\n<latexit sha1_base64=\"p0ifIflL662+Dr56vzoA8T0ST94=\">AAACB3icbVDLSgMxFM34rPU16lKQYCvUTZkpvpYFNy4r2Ae045DJpG1o5kGSEYYwOzf+ihsXirj1F9z5N2baWWjrgZDDOfdy7z1ezKiQlvVtLC2vrK6tlzbKm1vbO7vm3n5HRAnHpI0jFvGehwRhNCRtSSUjvZgTFHiMdL3Jde53HwgXNArvZBoTJ0CjkA4pRlJLrnlUVQMvYr5IA/2pTpa5KnUb2b2q2adZ1TUrVt2aAi4SuyAVUKDlml8DP8JJQEKJGRKib1uxdBTikmJGsvIgESRGeIJGpK9piAIiHDW9I4MnWvHhMOL6hRJO1d8dCgUiX1RXBkiOxbyXi/95/UQOrxxFwziRJMSzQcOEQRnBPBToU06wZKkmCHOqd4V4jDjCUkdX1iHY8ycvkk6jbp/Vz28bleZFEUcJHIJjUAM2uARNcANaoA0weATP4BW8GU/Gi/FufMxKl4yi5wD8gfH5A7vymSs=</latexit>\nV(2)y2\n<latexit sha1_base64=\"r55JPpqBphT33okb4V+t/zaet+I=\">AAACB3icbVDLSsNAFJ34rPUVdSlIsBXqpiTB17LgxmUF+4A2hslk0g6dZMLMRAghOzf+ihsXirj1F9z5N07aLLT1wDCHc+7l3nu8mBIhTfNbW1peWV1br2xUN7e2d3b1vf2uYAlHuIMYZbzvQYEpiXBHEklxP+YYhh7FPW9yXfi9B8wFYdGdTGPshHAUkYAgKJXk6kf1bOgx6os0VF/WzXM3S107v88a9mled/Wa2TSnMBaJVZIaKNF29a+hz1AS4kgiCoUYWGYsnQxySRDFeXWYCBxDNIEjPFA0giEWTja9IzdOlOIbAePqRdKYqr87MhiKYlFVGUI5FvNeIf7nDRIZXDkZieJE4gjNBgUJNSQzilAMn3CMJE0VgYgTtauBxpBDJFV0VRWCNX/yIunaTeuseX5r11oXZRwVcAiOQQNY4BK0wA1ogw5A4BE8g1fwpj1pL9q79jErXdLKngPwB9rnD715mSw=</latexit>\nV(L)y2\n<latexit sha1_base64=\"CpVjgsHGZzwJKWFePcFeA8A62Ac=\">AAACB3icbVDLSsNAFJ3UV62vqEtBgq1QNyUpvpYFNy5cVLAPaGOYTCbt0MkkzEyEELJz46+4caGIW3/BnX/jpM1CWw8MczjnXu69x40oEdI0v7XS0vLK6lp5vbKxubW9o+/udUUYc4Q7KKQh77tQYEoY7kgiKe5HHMPApbjnTq5yv/eAuSAhu5NJhO0AjhjxCYJSSY5+WEuHbkg9kQTqS7tZ5qSJ08zu0/rNSVZz9KrZMKcwFolVkCoo0Hb0r6EXojjATCIKhRhYZiTtFHJJEMVZZRgLHEE0gSM8UJTBAAs7nd6RGcdK8Qw/5OoxaUzV3x0pDES+qKoMoByLeS8X//MGsfQv7ZSwKJaYodkgP6aGDI08FMMjHCNJE0Ug4kTtaqAx5BBJFV1FhWDNn7xIus2Gddo4u21WW+dFHGVwAI5AHVjgArTANWiDDkDgETyDV/CmPWkv2rv2MSstaUXPPvgD7fMH5S+ZRg==</latexit>\neV(L)y2\n<latexit sha1_base64=\"ZoT54L8qwhKrkxXmVx83CljfdyY=\">AAACEXicbVC7TsMwFHXKq5RXgZElokUqS5VUvMZKLAwMRaIPqQ2R49y0Vp04sh1QFeUXWPgVFgYQYmVj429wHwO0HMny0Tn36t57vJhRqSzr28gtLa+sruXXCxubW9s7xd29luSJINAknHHR8bAERiNoKqoYdGIBOPQYtL3h5dhv34OQlEe3ahSDE+J+RANKsNKSW6yUew/UB0WZD2nP48yXo1B/aSvL3HTk1rK7tHJ9nJXdYsmqWhOYi8SekRKaoeEWv3o+J0kIkSIMS9m1rVg5KRaKEgZZoZdIiDEZ4j50NY1wCNJJJxdl5pFWfDPgQr9ImRP1d0eKQzleVFeGWA3kvDcW//O6iQounJRGcaIgItNBQcJMxc1xPKZPBRDFRppgIqje1SQDLDBROsSCDsGeP3mRtGpV+6R6elMr1c9mceTRATpEFWSjc1RHV6iBmoigR/SMXtGb8WS8GO/Gx7Q0Z8x69tEfGJ8/F7ydwQ==</latexit>\neV(2)y2\n<latexit sha1_base64=\"Vic+MSNzHtXXpOMVUlFQ8/F89Wo=\">AAACEXicbVC7TsMwFHV4lvIKMLJEtEhlqZKI11iJhbFI9CG1JXKc29aq85DtgCorv8DCr7AwgBArGxt/g9N2gJYjWT46517de4+fMCqkbX8bS8srq2vrhY3i5tb2zq65t98UccoJNEjMYt72sQBGI2hIKhm0Ew449Bm0/NFV7rfugQsaR7dynEAvxIOI9inBUkueWSl3H2gAkrIAVNePWSDGof5UM8s8Nfbc7E5V3JOs7Jklu2pPYC0SZ0ZKaIa6Z351g5ikIUSSMCxEx7ET2VOYS0oYZMVuKiDBZIQH0NE0wiGInppclFnHWgmsfsz1i6Q1UX93KByKfFFdGWI5FPNeLv7ndVLZv+wpGiWphIhMB/VTZsnYyuOxAsqBSDbWBBNO9a4WGWKOidQhFnUIzvzJi6TpVp3T6tmNW6qdz+IooEN0hCrIQReohq5RHTUQQY/oGb2iN+PJeDHejY9p6ZIx6zlAf2B8/gDv952n</latexit>\neV(1)y2\n<latexit sha1_base64=\"LSfCMWAoheDgYvzoA/je09mL90E=\">AAACEXicbVC7TsMwFHV4lvIqMLJEtEhlqZKK11iJhbFI9CE1JXKcm9aqE0e2A6qi/AILv8LCAEKsbGz8DU7bAVqOZPnonHt17z1ezKhUlvVtLC2vrK6tFzaKm1vbO7ulvf225Ikg0CKccdH1sARGI2gpqhh0YwE49Bh0vNFV7nfuQUjKo1s1jqEf4kFEA0qw0pJbqlacB+qDosyH1PE48+U41F/azjI3Hbv17C6t2idZxS2VrZo1gblI7BkpoxmabunL8TlJQogUYVjKnm3Fqp9ioShhkBWdREKMyQgPoKdphEOQ/XRyUWYea8U3Ay70i5Q5UX93pDiU+aK6MsRqKOe9XPzP6yUquOynNIoTBRGZDgoSZipu5vGYPhVAFBtrgomgeleTDLHAROkQizoEe/7kRdKu1+zT2tlNvdw4n8VRQIfoCFWRjS5QA12jJmohgh7RM3pFb8aT8WK8Gx/T0iVj1nOA/sD4/AHucJ2m</latexit>\nLatent Feature Dispersion\nHash code segmentsQ(0)y2\n<latexit sha1_base64=\"aFNegwyR2IMqmkhj+SKcO+74MXU=\">AAACBXicbVC7TsMwFHXKq5RXgBEGixapLFVSgWCsYGFsJfqQ2hA5jtNadR6yHaQoysLCr7AwgBAr/8DG3+C0GaDlSJaPzrlX997jRIwKaRjfWmlldW19o7xZ2dre2d3T9w96Iow5Jl0cspAPHCQIowHpSioZGUScIN9hpO9Mb3K//0C4oGFwJ5OIWD4aB9SjGEkl2fpxbeSEzBWJr760k9lpYjez+7RunGU1W68aDWMGuEzMglRBgbatf43cEMc+CSRmSIihaUTSShGXFDOSVUaxIBHCUzQmQ0UD5BNhpbMrMniqFBd6IVcvkHCm/u5IkS/yPVWlj+RELHq5+J83jKV3ZaU0iGJJAjwf5MUMyhDmkUCXcoIlSxRBmFO1K8QTxBGWKriKCsFcPHmZ9JoN87xx0WlWW9dFHGVwBE5AHZjgErTALWiDLsDgETyDV/CmPWkv2rv2MS8taUXPIfgD7fMH2cWYJQ==</latexit>\n‚Üµ(0)y2\n<latexit sha1_base64=\"yAQ++lpvgX6m7VHJbaE6WX3FQj4=\">AAAB/XicbVDLSsNAFJ3UV62v+Ni5CbZC3ZSkKLosuHFZwT6gjeFmOmmHTiZhZiLUEPwVNy4Ucet/uPNvnLZZaOuBC4dz7uXee/yYUals+9sorKyurW8UN0tb2zu7e+b+QVtGicCkhSMWia4PkjDKSUtRxUg3FgRCn5GOP76e+p0HIiSN+J2axMQNYchpQDEoLXnmUaUPLB6Bl068enafVu2zrOKZZbtmz2AtEycnZZSj6Zlf/UGEk5BwhRlI2XPsWLkpCEUxI1mpn0gSAx7DkPQ05RAS6aaz6zPrVCsDK4iELq6smfp7IoVQykno684Q1EguelPxP6+XqODKTSmPE0U4ni8KEmapyJpGYQ2oIFixiSaABdW3WngEArDSgZV0CM7iy8ukXa8557WL23q50cjjKKJjdIKqyEGXqIFuUBO1EEaP6Bm9ojfjyXgx3o2PeWvByGcO0R8Ynz8ciJRZ</latexit>\nQ(1)y2\n<latexit sha1_base64=\"Ob6ddsHHTJAdrWFU77e9N6c901A=\">AAACBXicbVC7TsMwFHXKq5RXgBEGixapLFVSgWCsYGFsJfqQ2hA5jtNadR6yHaQoysLCr7AwgBAr/8DG3+C0GaDlSJaPzrlX997jRIwKaRjfWmlldW19o7xZ2dre2d3T9w96Iow5Jl0cspAPHCQIowHpSioZGUScIN9hpO9Mb3K//0C4oGFwJ5OIWD4aB9SjGEkl2fpxbeSEzBWJr760k9lpYjez+7RunmU1W68aDWMGuEzMglRBgbatf43cEMc+CSRmSIihaUTSShGXFDOSVUaxIBHCUzQmQ0UD5BNhpbMrMniqFBd6IVcvkHCm/u5IkS/yPVWlj+RELHq5+J83jKV3ZaU0iGJJAjwf5MUMyhDmkUCXcoIlSxRBmFO1K8QTxBGWKriKCsFcPHmZ9JoN87xx0WlWW9dFHGVwBE5AHZjgErTALWiDLsDgETyDV/CmPWkv2rv2MS8taUXPIfgD7fMH20yYJg==</latexit>\n‚Üµ(1)y2\n<latexit sha1_base64=\"xEO3xkOJ+Awe1o/PaixWqru30YE=\">AAAB/XicbVDLSsNAFJ3UV62v+Ni5CbZC3ZSkKLosuHFZwT6gjeFmOmmHTiZhZiLUEPwVNy4Ucet/uPNvnLZZaOuBC4dz7uXee/yYUals+9sorKyurW8UN0tb2zu7e+b+QVtGicCkhSMWia4PkjDKSUtRxUg3FgRCn5GOP76e+p0HIiSN+J2axMQNYchpQDEoLXnmUaUPLB6Bl068enafVp2zrOKZZbtmz2AtEycnZZSj6Zlf/UGEk5BwhRlI2XPsWLkpCEUxI1mpn0gSAx7DkPQ05RAS6aaz6zPrVCsDK4iELq6smfp7IoVQykno684Q1EguelPxP6+XqODKTSmPE0U4ni8KEmapyJpGYQ2oIFixiSaABdW3WngEArDSgZV0CM7iy8ukXa8557WL23q50cjjKKJjdIKqyEGXqIFuUBO1EEaP6Bm9ojfjyXgx3o2PeWvByGcO0R8Ynz8eD5Ra</latexit>\nQ(2)y2\n<latexit sha1_base64=\"ISqx/lEhkvd4u83fAEm8FC69qt0=\">AAACBXicbVC7TsMwFHXKq5RXgBEGixapLFUSgWCsYGFsJfqQ2hA5jttadR6yHaQoysLCr7AwgBAr/8DG3+C0GaDlSJaPzrlX997jRowKaRjfWmlldW19o7xZ2dre2d3T9w+6Iow5Jh0cspD3XSQIowHpSCoZ6UecIN9lpOdOb3K/90C4oGFwJ5OI2D4aB3REMZJKcvTj2tANmScSX31pO3PSxLGy+7RunWU1R68aDWMGuEzMglRBgZajfw29EMc+CSRmSIiBaUTSThGXFDOSVYaxIBHCUzQmA0UD5BNhp7MrMniqFA+OQq5eIOFM/d2RIl/ke6pKH8mJWPRy8T9vEMvRlZ3SIIolCfB80ChmUIYwjwR6lBMsWaIIwpyqXSGeII6wVMFVVAjm4snLpGs1zPPGRduqNq+LOMrgCJyAOjDBJWiCW9ACHYDBI3gGr+BNe9JetHftY15a0oqeQ/AH2ucP3NOYJw==</latexit>\n‚Üµ(2)y2\n<latexit sha1_base64=\"czsA/AHZfm/WvPBMaPM4UszxZTQ=\">AAAB/XicbVDLSsNAFJ3UV62v+Ni5GWyFuilJUHRZcOOygn1AG8NkOmmHTiZhZiLEEPwVNy4Ucet/uPNvnLZZaOuBC4dz7uXee/yYUaks69sorayurW+UNytb2zu7e+b+QUdGicCkjSMWiZ6PJGGUk7aiipFeLAgKfUa6/uR66ncfiJA04ncqjYkbohGnAcVIackzj2oDxOIx8rLUc/L7rO6c5TXPrFoNawa4TOyCVEGBlmd+DYYRTkLCFWZIyr5txcrNkFAUM5JXBokkMcITNCJ9TTkKiXSz2fU5PNXKEAaR0MUVnKm/JzIUSpmGvu4MkRrLRW8q/uf1ExVcuRnlcaIIx/NFQcKgiuA0CjikgmDFUk0QFlTfCvEYCYSVDqyiQ7AXX14mHadhnzcubp1qs1nEUQbH4ATUgQ0uQRPcgBZoAwwewTN4BW/Gk/FivBsf89aSUcwcgj8wPn8AH5aUWw==</latexit>\nx1<latexit sha1_base64=\"/BCjIpSlQYsmAQdAn7NI7sBaNhY=\">AAAB7HicbVBNTwIxEJ3FL8Qv1KOXRjDxRHaJRo9ELx4xcYEENqRbutDQdjdt10g2/AYvHjTGqz/Im//GAntQ8CWTvLw3k5l5YcKZNq777RTW1jc2t4rbpZ3dvf2D8uFRS8epItQnMY9VJ8Saciapb5jhtJMoikXIaTsc38789iNVmsXywUwSGgg8lCxiBBsr+dWnvlftlytuzZ0DrRIvJxXI0eyXv3qDmKSCSkM41rrruYkJMqwMI5xOS71U0wSTMR7SrqUSC6qDbH7sFJ1ZZYCiWNmSBs3V3xMZFlpPRGg7BTYjvezNxP+8bmqi6yBjMkkNlWSxKEo5MjGafY4GTFFi+MQSTBSztyIywgoTY/Mp2RC85ZdXSate8y5ql/f1SuMmj6MIJ3AK5+DBFTTgDprgAwEGz/AKb450Xpx352PRWnDymWP4A+fzB8YyjgI=</latexit>\nx2<latexit sha1_base64=\"JcOhZeFQiUW/Fre3KnkZu6uNS40=\">AAAB7HicbVBNTwIxEJ3iF+IX6tFLI5h4IrtEo0eiF4+YuEACG9ItXWjodjdt10g2/AYvHjTGqz/Im//GAntQ8CWTvLw3k5l5QSK4No7zjQpr6xubW8Xt0s7u3v5B+fCopeNUUebRWMSqExDNBJfMM9wI1kkUI1EgWDsY38789iNTmsfywUwS5kdkKHnIKTFW8qpP/Xq1X644NWcOvErcnFQgR7Nf/uoNYppGTBoqiNZd10mMnxFlOBVsWuqlmiWEjsmQdS2VJGLaz+bHTvGZVQY4jJUtafBc/T2RkUjrSRTYzoiYkV72ZuJ/Xjc14bWfcZmkhkm6WBSmApsYzz7HA64YNWJiCaGK21sxHRFFqLH5lGwI7vLLq6RVr7kXtcv7eqVxk8dRhBM4hXNw4QoacAdN8IACh2d4hTck0Qt6Rx+L1gLKZ47hD9DnD8e3jgM=</latexit>\ny2<latexit sha1_base64=\"gplGgMFCYykae036wvOlmcSt1WY=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IURY9FLx4rmFpoQ9lsN+3S3U3Y3Qgh9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YcKZNq777ZTW1jc2t8rblZ3dvf2D6uFRR8epItQnMY9VN8Saciapb5jhtJsoikXI6WM4uZ35j09UaRbLB5MlNBB4JFnECDZW8uvZoFkfVGtuw50DrRKvIDUo0B5Uv/rDmKSCSkM41rrnuYkJcqwMI5xOK/1U0wSTCR7RnqUSC6qDfH7sFJ1ZZYiiWNmSBs3V3xM5FlpnIrSdApuxXvZm4n9eLzXRdZAzmaSGSrJYFKUcmRjNPkdDpigxPLMEE8XsrYiMscLE2HwqNgRv+eVV0mk2vIvG5X2z1rop4ijDCZzCOXhwBS24gzb4QIDBM7zCmyOdF+fd+Vi0lpxi5hj+wPn8Ack+jgQ=</latexit>\ny1<latexit sha1_base64=\"Ptd3INDsNHeCUv1wwBmcl9W9ngw=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5IURY9FLx4rmFpoQ9lsN+3SzW7Y3Qgh9Dd48aCIV3+QN/+N2zYHbX0w8Hhvhpl5YcKZNq777ZTW1jc2t8rblZ3dvf2D6uFRR8tUEeoTyaXqhlhTzgT1DTOcdhNFcRxy+hhObmf+4xNVmknxYLKEBjEeCRYxgo2V/Ho28OqDas1tuHOgVeIVpAYF2oPqV38oSRpTYQjHWvc8NzFBjpVhhNNppZ9qmmAywSPas1TgmOognx87RWdWGaJIKlvCoLn6eyLHsdZZHNrOGJuxXvZm4n9eLzXRdZAzkaSGCrJYFKUcGYlmn6MhU5QYnlmCiWL2VkTGWGFibD4VG4K3/PIq6TQb3kXj8r5Za90UcZThBE7hHDy4ghbcQRt8IMDgGV7hzRHOi/PufCxaS04xcwx/4Hz+AMe5jgM=</latexit>\ny3<latexit sha1_base64=\"m2ql1yRVdNWgmD/iKvyLKwiCcaY=\">AAAB7HicbVBNS8NAEJ3Ur1q/qh69LLaCp5JURY9FLx4rmLbQhrLZbtqlm03Y3Qgh9Dd48aCIV3+QN/+NmzYHbX0w8Hhvhpl5fsyZ0rb9bZXW1jc2t8rblZ3dvf2D6uFRR0WJJNQlEY9kz8eKciaoq5nmtBdLikOf064/vcv97hOVikXiUacx9UI8FixgBGsjufV0eFEfVmt2w54DrRKnIDUo0B5WvwajiCQhFZpwrFTfsWPtZVhqRjidVQaJojEmUzymfUMFDqnysvmxM3RmlBEKImlKaDRXf09kOFQqDX3TGWI9UcteLv7n9RMd3HgZE3GiqSCLRUHCkY5Q/jkaMUmJ5qkhmEhmbkVkgiUm2uRTMSE4yy+vkk6z4Vw2rh6atdZtEUcZTuAUzsGBa2jBPbTBBQIMnuEV3ixhvVjv1seitWQVM8fwB9bnD8rDjgU=</latexit>\n‚Ä¶Low- to high-order graph topologyl=1\n<latexit sha1_base64=\"rKeL/G6b4GfPYs6wJbsCYZc6xg4=\">AAAB7nicdVDLSgMxFM3UV62vqks3wVZwNWSGaW0XQtGNywr2Ae1QMmmmDc1khiQjlKEf4caFIm79Hnf+jelDUNEDFw7n3Mu99wQJZ0oj9GHl1tY3Nrfy24Wd3b39g+LhUVvFqSS0RWIey26AFeVM0JZmmtNuIimOAk47weR67nfuqVQsFnd6mlA/wiPBQkawNlKnzOEldMqDYgnZtXq9glyIbA9VHa9iiFP1XFSHjo0WKIEVmoPie38YkzSiQhOOleo5KNF+hqVmhNNZoZ8qmmAywSPaM1TgiCo/W5w7g2dGGcIwlqaEhgv1+0SGI6WmUWA6I6zH6rc3F//yeqkOa37GRJJqKshyUZhyqGM4/x0OmaRE86khmEhmboVkjCUm2iRUMCF8fQr/J23Xdjy7cuuWGlerOPLgBJyCc+CAC9AAN6AJWoCACXgAT+DZSqxH68V6XbbmrNXMMfgB6+0TmhWOcw==</latexit>\nl=2\n<latexit sha1_base64=\"+5irm2GcwA2N0gsqNFYauwx0urI=\">AAAB7HicdVDLSgMxFM3UV62vqks3wVZwNWRqH9OFUHTjsoLTFtqhZNK0Dc1khiQjlKHf4MaFIm79IHf+jelDUNEDFw7n3Mu99wQxZ0oj9GFl1tY3Nrey27md3b39g/zhUUtFiSTUIxGPZCfAinImqKeZ5rQTS4rDgNN2MLme++17KhWLxJ2extQP8UiwISNYG8kr8stSsZ8vINut1yuoCpFdRlV0UTPEqbo1tw4dGy1QACs0+/n33iAiSUiFJhwr1XVQrP0US80Ip7NcL1E0xmSCR7RrqMAhVX66OHYGz4wygMNImhIaLtTvEykOlZqGgekMsR6r395c/MvrJnro+ikTcaKpIMtFw4RDHcH553DAJCWaTw3BRDJzKyRjLDHRJp+cCeHrU/g/aZVsp2xXbkuFxtUqjiw4AafgHDigBhrgBjSBBwhg4AE8gWdLWI/Wi/W6bM1Yq5lj8APW2ycMeY41</latexit>\nl=L\n<latexit sha1_base64=\"d/iV+msqBqxNCx+jwctMnOQepjw=\">AAAB7HicdVDLSsNAFJ3UV62vqks3g63gKiQx1nQhFN24cFHB2EIbymQ6aYdOJmFmIpTQb3DjQhG3fpA7/8bpQ1DRAxcO59zLvfeEKaNSWdaHUVhaXlldK66XNja3tnfKu3t3MskEJj5OWCLaIZKEUU58RRUj7VQQFIeMtMLR5dRv3RMhacJv1TglQYwGnEYUI6Ulv8rOr6u9csUyvVq97tagZZ44tue5mtiO69ZtaJvWDBWwQLNXfu/2E5zFhCvMkJQd20pVkCOhKGZkUupmkqQIj9CAdDTlKCYyyGfHTuCRVvowSoQuruBM/T6Ro1jKcRzqzhipofztTcW/vE6mIi/IKU8zRTieL4oyBlUCp5/DPhUEKzbWBGFB9a0QD5FAWOl8SjqEr0/h/+TOMW3XPL1xKo2LRRxFcAAOwTGwwRlogCvQBD7AgIIH8ASeDW48Gi/G67y1YCxm9sEPGG+fKqKOSA==</latexit>\nFourier serialized gradient estimation\nNon-hashing\nWith hashingPerturbationPerturbation\nPerturbation\nPerturbationPerturbation(a) Loss landscape visualizationHash-basedBackward propagationForward propagation\n(c) Gradient estimation\nFigure 2: (a) Visualized loss landscape comparison; (b) BGCH model framework (best view in color); (c) Fourier Serialized\ngradient estimation in forward and bachward propagation.\nconvolutions from 0toùêø. Compare to the unprocessed embedding\ncounterpart, e.g., ùëΩ(ùëô), embedding matrix eùëΩ(ùëô)at each layer presents\na dispersed feature structure with a more balanced distribution of\nsingular values in expection . We formally explain this as follows:\nTheorem 1 (Feature Dispersion ).LetùëΩ(ùëô)=ùëº1ùö∫ùëºT\n2, where ùëº1\nandùëº2are unitary matrices and descending singular value matrix\nùö∫=diag(ùúé1,ùúé2,¬∑¬∑¬∑,ùúéùëê). Then E(eùëΩ(ùëô))=ùëº1ùö∫ùö∫ùúáùëºT\n2where ùö∫ùúá=\ndiag(ùúá1,ùúá2,¬∑¬∑¬∑,ùúáùëê)0<ùúá1¬∑¬∑¬∑ùëê<1is in ascending order.\nIntuitively, given the same orthonormal bases, compared to ùëΩ(ùëô),\nit is harder in expectation to reconstruct eùëΩ(ùëô)with informative\nfeatures being dispersed out in larger matrix sub-structures. This\neventually provides the functionality to hedge the information loss\nin numerical binarization. We attach the theorem proof in Appendix\nC and evaluate the module effectiveness later in ¬ß 5.4.\n4.3 Adaptive Graph Convolutional Hashing\nOne feasible solution for increasing expressivity and smoothing\nloss landscapes is to include the relaxation strategy . Hence, apart\nfrom the topology-aware embedding binarization with sign(¬∑):\nùë∏(ùëô)\nùë•=sign(eùëΩ(ùëô)\nùë•), (7)\nour model BGCH additionally computes a layer-wise positive rescal-\ning factor for each node, e.g., ùõº(ùëô)\nùë•‚ààR+, such that eùëΩ(ùëô)\nùë•‚âàùõº(ùëô)\nùë•ùë∏(ùëô)\nùë•.\nIn this work, we introduce a simple but effective approach to di-\nrectly calculate the rescaling factors as follows:\nùõº(ùëô)\nùë•=1\nùëë||eùëΩ(ùëô)\nùë•||1. (8)\nInstead of setting these factors as learnable, such deterministic\ncomputation substantially prunes the parameter search space while\nattaining the adaptive approximation functionality for different\ngraph nodes. We demonstrate this in ¬ß 5.4 of experiments.\nAfterùêøiterations of feature propagation and hashing, we ob-\ntain the table of adaptive hash codes Q={ùú∂,ùë∏}, where ùú∂‚àà\nR(|V 1|+|V 2|)√ó(ùêø+1)andùë∏‚ààR(|V 1|+|V 2|)√óùëë}. For each node ùë•, its\ncorresponding hash codes are indexed and assembled:\nùú∂ùë•=ùõº(0)\nùë•||ùõº(1)\nùë•||¬∑¬∑¬∑||ùõº(ùêø)\nùë•,andùë∏ùë•=ùë∏(0)\nùë•||ùë∏(1)\nùë•||¬∑¬∑¬∑|| ùë∏(ùêø)\nùë•.(9)Intuitively, the hash code table Qrepresents the bipartite structural\ninformation that is propagated back and forth at different itera-\ntion stepsùëô, i.e., from 0to the maximum step ùêø. It not only tracks\nthe intermediate knowledge hashed for all graph nodes, but also\nmaintains the value approximation to their original continuous\nembeddings, e.g., eùëΩ(ùëô)\nùë•. In addition, with the slightly more space\ncost (complexity analysis in Appendix C, such detached hash en-\ncoding approach still supports the bitwise operations ( ¬ß 4.5) for\naccelerating inference and matching.\n4.4 Fourier Serialized Gradient Estimation\nTo provide the accordant gradient estimation for hash function\nsign(¬∑), we approximate it by introducing its Fourier Series de-\ncomposition in the frequency domain. Specifically, sign(¬∑)can be\nviewed as a special case of the periodical Square Wave Function\nùë°(ùë•)within the length 2ùêª, i.e., sign(ùúô)=ùë°(ùúô),|ùúô|<ùêª. Sinceùë°(ùë•)\ncan be decomposed in Fourier Series, we shall have:\nsign(ùúô)=4\nùúã+‚àû‚àëÔ∏Å\nùëñ=1,3,5,¬∑¬∑¬∑1\nùëñsin(ùúãùëñùúô\nùêª),where|ùúô|<ùêª. (10)\nFourier Series decomposition of sign(¬∑)with infinite terms is a\nlossless transformation [ 46]. Thus, as shown in Figure 2(c), we can\nset the finite expanding term ùëõto obtain its approximation version\nas follows:\nsign(ùúô)\u00114\nùúãùëõ‚àëÔ∏Å\nùëñ=1,3,5,¬∑¬∑¬∑1\nùëñsin(ùúãùëñùúô\nùêª). (11)\nThe corresponding derivatives can be derived accordingly as:\nùúïsign(ùúô)\nùúïùúô\u00114\nùêªùëõ‚àëÔ∏Å\nùëñ=1,3,5,¬∑¬∑¬∑cos(ùúãùëñùúô\nùêª). (12)\nDifferent from other gradient estimators such as tanh-alike [ 15,\n44] and SignSwish [ 11], approximating sign(¬∑)function with its\nFourier Series will not corrupt the main direction of factual gra-\ndients in model optimization [ 58]. This is beneficial to bridge a\ncoordinated transformation from the continuous values to its cor-\nresponding binarization for node representations, which signifi-\ncantly retains the discriminability of binarized representations and\n\nBipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA\nproduces better retrieval accuracy accordingly. We present this\nperformance comparison in ¬ß 5.6 of experiments. To summarize,\nas shown in Equation (13), to learn and optimize the binarized\nembeddings for graph nodes, we apply the strict sign(¬∑)function\nfor forward propagation and estimate the gradientsùúïsign(ùúô)\nùúïùúôfor\nbackward propagation.\nÔ£±Ô£¥Ô£¥Ô£¥Ô£¥ Ô£≤\nÔ£¥Ô£¥Ô£¥Ô£¥Ô£≥ùë∏(ùëô)=sign(ùúô), Forward propagation.\nùúïùë∏(ùëô)\nùúïùúô\u00114\nùêªùëõ‚àëÔ∏Å\nùëñ=1,3,5,¬∑¬∑¬∑cos(ùúãùëñùúô\nùêª).Backward propagation.(13)\n4.5 Score Prediction and Model Optimization\n4.5.1 Matching score prediction. Given two nodes ùë•‚ààV 1and\nùë¶‚ààV 2, one natural manner to implement the score function is\ninner-product , mainly for its simplicity as:\nbùíÄùë•,ùë¶=(ùõºùë•ùë∏ùë•)T¬∑(ùõºùë¶ùë∏ùë¶). (14)\nHowever, the inner product in Equation (14) is still conducted in\nthe (continuous) Euclidean space with full-precision arithmetics . To\nbridge the connection between the inner product and Hamming\ndistance measurement, we introduce Theorem 2 as follows:\nTheorem 2 (Hamming Distance Matching ).Given two hash\ncodes, we have(ùõºùë•ùë∏ùë•)T¬∑(ùõºùë¶ùë∏ùë¶)=ùõºùë•ùõºùë¶(ùëë‚àí2ùê∑ùêª(ùë∏ùë•,ùë∏ùë¶)).\nùê∑ùêª(¬∑,¬∑)denotes the Hamming distance between two inputs.\nBased on Theorem 2, we transform the score computation to the\nHamming distance matching. By doing so, we can reduce most\nnumber of the floating-point operations (#FLOPs) in the original\nscore computation formulation (Equation (14)) to efficient ham-\nming distance matching. This can develop substantial computation\nacceleration that is analyzed in Appendix C.\n4.5.2 Multi-loss Objective Function. Our objective function\nconsists of two components, i.e., graph reconstruction loss Lùëüùëíùëê\nand BPR lossLùëèùëùùëü. Generally, these two loss functions harness the\nregularization effect to each other. The intuition of such design is:\n‚Ä¢Lùëüùëíùëêreconstructs the observed bipartite graph topology;\n‚Ä¢Lùëèùëùùëüranks the matching scores computed from the hash codes.\nConcretely, we implement Lùëüùëíùëêwith Cross-entropy loss:\nLùëüùëíùëê=‚àëÔ∏Å\nùë•‚ààV1\u0010‚àëÔ∏Å\nùë¶‚ààN(ùë•)lnùúé\u0010\n(ùëΩ(0)\nùë•)T¬∑ùëΩ(0)\nùë¶\u0011\n+‚àëÔ∏Å\nùë¶‚Ä≤‚àâN(ùë•)ln\u0010\n1‚àíùúé\u0000(ùëΩ(0)\nùë•)T¬∑ùëΩ(0)\nùë¶‚Ä≤\u0001\u0011\u0011\n,\n(15)\nwhereùúéis the activation function, e.g., Sigmoid. Lùëüùëíùëêbases on\nthe initial continuous embeddings before the graph convolution,\ne.g.,ùëΩ(0)\nùë•, providing the most fundamental information for topol-\nogy reconstruction. As for Lùëèùëùùëü, we employ Bayesian Personalized\nRanking (BPR) loss as:\nLùëèùëùùëü=‚àí‚àëÔ∏Å\nùë•‚ààV1‚àëÔ∏Å\nùë¶‚ààN(ùë•)\nùë¶‚Ä≤‚àâN(ùë•)lnùúé(bùíÄùë•,ùë¶‚àíbùíÄùë•,ùë¶‚Ä≤). (16)\nLùëèùëùùëüencourages the predicted score of an observed edge to be\nhigher than its unobserved counterparts [ 19]. LetŒòdenote the set\nof trainable embeddings regularized by the parameter ùúÜ2to avoid\nover-fitting. our final objective function is finally defined as:\nL=Lùëüùëíùëê+ùúÜ1Lùëèùëùùëü+ùúÜ2||Œò||2\n2. (17)Table 1: The statistics of datasets.\nMovieLens Gowalla Pinterest Yelp2018 AMZ-Book Dianping\n|V1| 6,040 29,858 55,186 31,668 52,643 332,295\n|V2| 3,952 40,981 9,916 38,048 91,599 1,362\n|E| 1,000,209 1,027,370 1,463,556 1,561,406 2,984,108 10,000,014\nDensity 0.04190 0.00084 0.00267 0.00130 0.00062 0.02210\nSo far, we have introduced all technical parts of BGCH and\nattached the pseudocodes in Appendix B. We present all the theorem\nproofs and complexity analyses in Appendix C.\n5 Experimental Evaluation\nWe evaluate BGCH to answer the following research questions:\n‚Ä¢RQ1. How does BGCH perform compared to state-of-the-art\nhashing-based models in the Top-N Hamming space retrieval?\n‚Ä¢RQ2. what is the performance gap between BGCH and the full-\nprecision models in terms of long-list retrieval quality?\n‚Ä¢RQ3. What are the benefits of proposed components in BGCH?\n‚Ä¢RQ4. what is the practical BGCH resource consumption?\n‚Ä¢RQ5. How does the Fourier Series decomposition perform w.r.t.\nretrieval accuracy and training efficiency?\n5.1 Experiment Setup\nDatasets and evaluation metrics. We include six real-world bi-\npartite graphs in Table 1 that are widely evaluated [ 7,8,19,52,60,\n64]. We adopt evaluation protocols Recall@N and NDCG@N to\nmeasure the Top-N Hamming space ranking capability. Dataset\ndetails and evaluation procedure are explained in Appendix D.\nBaselines. We include the following representative hashing-\nbased models for (1) general object retrieval (LSH [ 14]), (2) image\nsearch (HashNet [ 4]), and (3) Top-N candidate generation for recom-\nmendation (Hash_Gumbel [ 24,42], CIGAR [ 28] and HashGNN [ 49]).\nWe also include several state-of-the-art full-precision4recommender\nmodels, i.e., NeurCF [ 20], NGCF [ 52], DGCF [ 53], LightGCN [ 19],\nfor the long-list ranking quality comparison. Model introductions\nare referred in Appendix D. Early hashing methods, e.g., SH [ 55],\nRMMH [ 26], LCH [ 62], are excluded mainly because the above\ncompeting models [ 4,28] have already validated the performance\nsuperiority over them.\n5.2 Top-N Hamming Space Query (RQ1)\nTo evaluate fine-to-coarse Top-N ranking capability, we set N=1000.\nWe first report the results of Recall@20 1000and NDCG@20 10005\nin Top-1000 search in Table 2 and then plot the holistic Recall and\nNDCG metric curves of {20, 50, 100, 200, 500, 1000} of Top-1000 in\nFigure 3. We set convolution iteration number as 2 and embedding\ndimension as 256 for BGCH and baselines for fair comparison.\n‚Ä¢The results demonstrate the superiority of BGCH model\nover prior hashing-based models. (1) As shown in Table 2, the\nstate-of-the-art model, i.e., HashGNN, works better than tradi-\ntional hashing-based baselines, e.g., LSH, HashNet, CIGAR. This\nindicates that, compared to graph-based models, a direct adapta-\ntion of conventional (i.e., non-graph-based) hashing methods may\n4They are denoted by FT32 as we implement them with float32 in the experiments.\n5We then use simple notation Recall@20, NDCG@20 if there is no ambiguity caused.\n\nWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Yankai Chen et al.\nTable 2: Results of Recall@20 and NDCG@20 in Top-1000 retrieval: (1) ‚ÄúR‚Äù and ‚ÄúN‚Äù denote the Recall and NGCG; (2) the\nbold indicate BGCH and the underline represents the best-performing models; (3) Mark‚àódenotes scenarios where Wilcoxon\nsigned-rank tests indicate statistically significant improvements over the second-best models over 95% confidence level.\nDataset MovieLens (%) Gowalla (%) Pinterest (%) Yelp2018 (%) AMZ-Book (%) Dianping (%)\nMetric R@20 1000 N@20 1000 R@20 1000 N@20 1000 R@20 1000 N@20 1000 R@20 1000 N@20 1000 R@20 1000 N@20 1000 R@20 1000 N@20 1000\nLSH 11.38 25.87 8.14 12.23 7.88 6.71 2.91 4.35 2.41 2.34 5.85 5.84\nHashNet 15.43 32.23 11.38 13.74 10.27 7.33 3.37 4.41 2.86 2.71 6.24 5.59\nCIGAR 14.84 31.73 11.57 14.21 10.34 8.53 3.65 4.57 3.05 3.03 6.91 6.03\nHash_Gumbel 16.62 32.48 12.26 14.68 10.53 8.74 3.85 5.12 2.69 3.24 8.29 6.43\nHashGNN h 14.21 31.83 11.63 14.21 10.15 8.67 3.77 5.04 3.09 3.15 8.34 6.68\nHashGNN s 19.87 33.21 13.45 14.87 12.38 9.11 4.86 5.34 3.34 3.45 9.57 7.13\nBGCH 22.86‚àó36.26‚àó16.73‚àó16.48‚àó12.78‚àó9.42‚àó5.51‚àó5.84‚àó3.48‚àó3.92‚àó10.66‚àó7.63‚àó\n% Gain 15.05% 9.18% 24.39% 10.83% 3.23% 3.40% 13.37% 9.36% 4.19% 13.62% 11.39% 7.01%\n(a) MovieLens (b) Gowalla (c)Pinterest (d) Yelp2018 (e) Amazon-Book (f) Dianping \nFigure 3: Top-N retrieval quality with N in {20, 50, 100, 200, 500, 1000} (best view in color).\nbe hard to achieve comparable performance, mainly because of\nthe effectiveness of graph convolutional architecture in capturing\nlatent information within the bipartite graph topology for hash\nencoding preparation. (2) Owing to our proposed model compo-\nnents, e.g., adaptive graph convolutional hashing , BGCH consis-\ntently outperforms HashGNN over all datasets, by 3.23% ‚àº24.39%,\nand 3.40%‚àº13.62% w.r.t. Recall@20 and NDCG@20, respectively.\n(3) Furthermore, we conduct the Wilcoxon signed-rank tests at\nBGCH. The results verify that all BGCH improvements over the\nsecond-best model are statistically significant over 95% confi-\ndence level. (4) To explain these, our proposed topology-aware\ngraph convolutional hashing approach effectively enriches the\ngraph node embeddings. Our proposed feature dispersion further\nalleviates the feature erosion issue caused by numerical binariza-\ntion. Last but not least, our proposed Fourier serialized gradient\nestimation is also vital to provide accurate gradients for model\noptimization. We conduct the ablation study later in ¬ß 5.4.\n‚Ä¢By varying N from 20 to 1000, BGCH consistently shows\ncompetitive performance compared to the baselines. While\nRecall@N indicates the fraction of relevant objects in Top-N re-\ntrieval, NDCG@N measures the ranking capability for relative\norders. As shown in Figure 3: (1) Compared to the approximated\nversion of HashGNN, i.e., HashGNN ùë†, BGCH generally obtains\nstable and significant improvements of both Recall and NDCG\nmetrics over all six benchmarks with N from 20 to 1000. (2)Table 3: NDCG@1000 results of Float32-based models.\nMovie Gowalla Pinterest Yelp2018 AMZ-Book Dianping\nNeurCF 58.76 32.07 28.79 24.69 19.83 25.54\nNGCF 60.28 32.13 29.78 25.23 20.37 25.76\nDGCF 62.41 34.97 31.47 26.28 21.74 26.87\nLightGCN 62.88 35.26 31.32 26.55 21.92 27.28\nBGCH 59.16 32.87 29.09 25.01 19.79 25.57\n% capacity 94.08% 93.22% 92.44% 94.20% 90.28% 93.73%\nApart from the higher retrieval quality, another advantage of\nBGCH over HashGNN ùë†is that it still supports bitwise operations,\ni.e., hamming distance matching, for inference acceleration. This\nis because, to improve the prediction accuracy, HashGNN ùë†adopts\na Bernoulli random variable to provide the probability of replac-\ning the certain digits in the hash codes with the original continu-\nous values, which thus disables the bitwise computation. As we\npresent in ¬ß 5.5, BGCH achieves over 8 √óinference acceleration\nover HashGNN ùë†, which is particularly promising for query-based\nonline matching and retrieval applications.\n5.3 Comparing to FT32-based Models (RQ2)\nIn this section, we also compare BGCH with several full-precision\n(FT32-based) models to evaluate the long-list search quality. As\nwe can observe from Table 3, we have the following analyses. (1)\nWe notice that our model BGCH generally performs competitively\nwith early full-precision models, e.g., NeurCF and NGCF, over all\ndatasets. As for the state-of-the-art model LightGCN, our model\n\nBipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA\nTable 4: Ablation study.\nVariantMovieLens Gowalla Pinterest Yelp2018 AMZ-Book Dianping\nR@20 N@20 R@20 N@20 R@20 N@20 R@20 N@20 R@20 N@20 R@20 N@20\nw/o FD 22.82 (-0.17%) 35.87 (-1.08%) 15.92 (-4.84%) 15.79 (-4.19%) 12.25 (-4.15%) 9.07 (-3.72%) 5.16 (-6.35%) 5.49 (-2.49%) 3.26 (-6.32%) 3.57 (-8.93%) 10.46 (-1.88%) 7.50 (-1.70%)\nw/o AH-TA 19.54 (-14.52%) 29.17 (-19.55%) 13.49 (-19.37%) 12.38 (-24.88%) 12.24 (-4.23%) 8.86 (-5.94%) 4.77 (-13.43%) 5.18 (-11.30%) 2.49 (-28.45%) 2.86 (-27.04%) 9.83 (-7.79%) 6.87 (-9.96%)\nw/o AH-RF 16.73 (-26.82%) 26.97 (-25.62%) 11.24 (-32.82%) 11.29 (-31.49%) 10.18 (-20.34%) 7.33 (-22.19%) 3.76 (-31.76%) 4.30 (-26.37%) 3.27 (-6.03%) 3.64 (-7.14%) 8.33 (-21.86%) 6.93 (-9.17%)\nw/in LF 21.06 (-7.87%) 34.59 (-4.61%) 15.48 (-7.47%) 15.38 (-6.67%) 11.94 (-6.57%) 8.89 (-5.63%) 4.86 (-11.80%) 5.17 (-11.47%) 3.14 (-9.77%) 3.62 (-7.65%) 9.40 (-11.82%) 7.27 (-4.72%)\nw/oLùëèùëùùëü 21.42 (-6.30%) 34.83 (-3.94%) 15.87 (-5.14%) 15.66 (-4.98%) 12.33 (-3.52%) 9.17 (-2.65%) 5.31 (-3.63%) 5.61 (-3.94%) 3.35 (-3.74%) 3.77 (-3.83%) 10.21 (-4.22%) 7.38 (-3.28%)\nw/oLùëüùëíùëê 17.01 (-25.59%) 27.16 (-25.10%) 12.27 (-26.66%) 12.63 (-23.36%) 10.81 (-15.41%) 7.86 (-16.56%) 3.93 (-28.68%) 4.37 (-25.17%) 3.19 (-8.33%) 3.73 (-4.85%) 8.82 (-17.26%) 7.26 (-4.85%)\nBGCH 22.86 36.26 16.73 16.48 12.78 9.42 5.51 5.84 3.48 3.92 10.66 7.63\ncan generally achieve over 90% of the Top-1000 ranking capability.\n(2) The performance of BGCH demonstrates its effectiveness in\nguaranteeing the long-list Top-N retrieval quality. This is useful\nfor some industrial applications, e.g., recommender systems, which\nusually consist of two major stages: candidate generation andre-\nranking . Thus, obviously, the good quality of candidate generation\ndirectly reduces the complexity of next-stage re-ranking, as the\nsearch space is substantially pruned. (3) Considering the efficiency\nin Hamming space retrieval and the reduced space cost of those\nlearned hash codes, we believe that BGCH can provide the optional\nalternative to these full-precision models, especially in scenarios\nwith limited computation resources.\n5.4 Ablation Study (RQ3)\nWe evaluate the necessity of model components with Top-20 search\nmetrics and report the results in Table 4.\nEffect of Feature Dispersion. We first analyze the effect of our\nproposed feature dispersion approach for hedging the feature ero-\nsion in hash encoding. We introduce the model variant, denoted by\nw/o FD , to directly disable it by setting ùúÇas 0. As shown in Table 4,\nthe performance gap between w/o FD and BGCH well demonstrates\nthe effectiveness of dispersing the latent features before embed-\nding binarization for hashing over these six datasets. Moreover, let\nthe density summarized in Table 1 be computed by|V1|√ó|V 2|\n|E|. In\nsparse datasets, i.e., Gowalla (0.00084), Pinterest (0.00267), Yelp2018\n(0.00130), and AMZ-Book (0.00062), the performance decay between\nBGCH and w/o FD is much larger than on the other two datasets,\ni.e., MovieLens (0.04190) and Dianping (0.02210). This is because\nsparse datasets are more sensitive to hashing as they may not have\ninsufficient training edges to abridge the gap against their unhashed\nversion. Another promising approach to tackle data sparsity issue\nisdata augmentation [67] and we leave it for future work.\nEffect of Adaptive Graph Convolutional Hashing. Then we\nstudy this model component by setting two variants, where: (1) w/o\nAH-TA only disables the topology-awareness of hashing and sets\nit as the final encoder after all graph convolutions (just like the\nconventional manner [ 4,49]); (2) w/o AH-RF removes the rescaling\nfactors . From Table 4 results, we have the following observations:\n(1)The variant w/o AH-TA consistently underperforms BGCH. This\ndemonstrates that simply using the rear output embeddings\nfrom the GCN framework may not sufficiently model the unique\nlatent node features for hashing, especially for the rich struc-\ntural information within different graph depths. While in BGCH,\nby capturing the intermediate information for representationenrichment, the topology-aware hashing can effectively allevi-\nate the limited expressivity of discrete hash codes.\n(2)Apart from the topology-aware hashing, another key point for\ncontributing to the performance improvement is the rescaling\nfactor that we introduced in Equation (8). After removing it\nfrom BGCH, variant w/o AH-RF presents huge performance de-\ncay. Although these factors are directly calculated and may not\nbe theoretically optimal, they reflect the numerical uniqueness\nof embeddings for later hash encoding, which substantially im-\nproves BGCH‚Äôs prediction capability. We study the determinacy\ndesign of factor computation in the following section.\nDesign of Learnable Rescaling. We include another variant\nnamely w/in LF to indicate the model version using learnable rescal-\ning factors . As shown in Table 4, the design of learnable rescaling\nfactors in w/in LF does not achieve good performance as expected.\nOne explanation is that, our proposed model currently does not\npost a strong mathematical constraint to the learnable factors ( ùõºùë•),\ne.g.,ùõº(ùëô)\nùë•=argmin(eùëΩ(ùëô)\nùë•,ùõº(ùëô)\nùë•ùë∏(ùëô)\nùë•), mainly because of its additional\ntraining complexity; and purely relying on the stochastic optimiza-\ntion, e.g., stochastic gradient descent (SGD), may hardly reach the\noptimum. Considering the additional search space introduced from\nthis regularization design, we argue that our deterministic rescaling\nmethod is simple yet effective in practice.\nEffect of Multi-loss in Optimization. Lastly, to study the ef-\nfect of BPR lossLùëèùëùùëüand graph reconstruction loss Lùëüùëíùëê, we set two\nvariants, termed by w/oLùëèùëùùëüandw/oLùëüùëíùëê, to optimize BGCH sep-\narately. As shown in Table 4, with all other model components,\npartially using each one of LùëèùëùùëüandLùëüùëíùëêcan not achieve the ex-\npected performance. This confirms the effectiveness of our proposed\nmulti-loss design: while Lùëèùëùùëülearns to assign higher prediction\nvalues to observed edges, i.e., ùíÄùë•,ùë¶=1, than the unobserved node\npair counterparts, Lùëüùëíùëêtransfers the graph reconstruction prob-\nlem to a classification task by using the original embeddings in\ntraining. By collectively optimizing these two loss functions, our\nmodel BGCH can learn precise intermediate embeddings from Lùëüùëíùëê,\nand generate targeted hash codes with high-quality relative order\ninformation regularized by Lùëèùëùùëüaccordingly.\n5.5 Resource Consumption Analysis (RQ4)\nDue to the various value ranges over all six datasets, we compactly\nreport the value ratios of BGCH over the state-of-the-art hashing-\nbased model HashGNN ùë†in Figure 4.\nModel Training Time Cost. As indicated by the metric ‚Äú T-\nTime ‚Äù in Figure 4, we notice that training HashGNN ùë†is more\ntime-consuming than our proposed model. The main reason is\n\nWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Yankai Chen et al.\nMovieLens Gowalla Pinterest Yelp2018 AMZ-Book Dianping02004006008001000Ratio (%)\n258 271 266 283548613806912\n8431020\n866 887 906 908 905 907 904880TTime:HashGNNs\nBGCH\nITime:HashGNNs\nBGCH\nSpace:HashGNNs\nBGCH\nFigure 4: Resource consumption ratios.\nthat HashGNN adopts the early GCN framework [ 17] as the model\nbackbone, while our model follows the latest framework [ 19] to\nremove operations, e.g., self-connection, feature transformation,\nand nonlinear activation. In addition, on the two largest datasets\nAMZ-Book and Dianping, the training cost ratio further increases\nto around 5‚àº6 times. This is because we have to decrease the batch\nsize of HashGNN ùë†for tractable training process.\nOnline Inference Time Cost. We randomly generate 1,000\nqueries and evaluate the computation time cost. To present a fair\ncomparison, we disable all parallel arithmetic techniques (e.g., MKL,\nBLAS) by using the open-source toolkit6. Indicated by ‚Äú I-Time ‚Äù in\nFigure 4, our model with Hamming distance matching generally\nachieves over 8√ócomputation acceleration over HashGNN ùë†on all\ndatasets. This is because, as we have explained in ¬ß 5.2, HashGNN ùë†\nrandomly replaces the hash codes with their original continuous\nembeddings for relaxation and adopts floating-point arithmetics to\npursue performance improvement while sacrificing the computa-\ntion acceleration from the bitwise operations.\nHash Codes Memory Footprint. Binarized embeddings can\nlargely reduce memory space consumption. Compared to the state-\nof-the-art hashing-based model HashGNN ùë†, our BGCH further\nachieves about 9√óof memory space reduction for the hash codes.\nAs we have just explained, since HashGNN ùë†interprets hash codes\nwith random real-value digits, it thus requires additional cost to\ndistinguish binary digits from full-precision ones. On the contrary,\nBGCH separates the storage of binarized encoding parts and corre-\nsponding rescaling factors, thus providing the advantage for space\noverhead optimization.\n5.6 Study of Fourier Gradient Estimation (RQ5)\nWe take our largest dataset Dianping for illustration and the analysis\ncan be generally popularized to the other datasets.\nEffect of Decomposition Term ùëõ.We vary the decomposition\ntermùëõfrom 1 to 16. As shown in Figure 5, we have two observa-\ntions: (1) Different decomposition terms will surely affect the final\nretrieval quality, as theoretically, the larger ùëõincreases, the more\naccurate gradients can be estimated. However, in practice, too large\nvalues ofùëõmay introduce the overfitting risk, which implies that\nkeeping a moderate ùëõ, e.g.,ùëõ=4 in Figure 5(a), can already maximize\nthe model performance. (2) By varying ùëõfrom 1 to 16, the training\ntime per iteration of BGCH slowly increases. This generally coin-\ncides with our complexity analysis in Appendix C, in which the\nmajority of training cost lies in our feature dispersion and graph\nconvolutional hashing, as ùëÇ(2ùëêùë†(ùêæ+ùêø)|E|2\nùêµ)‚â´ùëÇ(ùë†ùëõùëë|E|).\n6https://www.lfd.uci.edu/~gohlke/pythonlibs/\n(a) Top-20 retrieval metrics (b) Training time costs Figure 5: Fourier Series decomposition term ùëõin BGCH.\nTable 5: Gradient estimator comparison on Recall@20.\nMovie Gowalla Pinterest Yelp2018 AMZ-Book Dianping\nSTE 20.93 ( -8.44% )14.85( -11.24% )12.35 ( -3.36% )5.24 ( -4.90% )3.12( -10.34% )10.34 ( -3.00% )\nTanh 21.75 ( -4.86% )15.06 ( -9.98% )12.36 ( -3.29% )5.43 ( -1.45% )3.21 ( -7.76% )10.41 ( -2.34% )\nSignSwish 22.13 ( -3.19% )15.62 ( -6.63% )12.44 ( -2.66% )5.50 ( -0.18% )3.34 ( -4.02% )10.43 ( -2.16% )\nSigmoid 22.08 ( -3.41% )15.21 ( -9.09% )12.52 ( -2.03% )5.53 ( +0.03% )3.18 ( -8.62% )10.38 ( -2.63% )\nPBE 21.68 ( -5.16% )15.05( -10.04% )12.32 ( -3.60% )5.35 ( -2.90% )3.13( -10.06% )10.47 ( -1.78% )\nBGCH 22.86 16.73 12.78 5.51 3.48 10.66\nComparison with Other Gradient Estimators. We include\nseveral recent gradient estimators, i.e., Tanh-like [15,44],Sign-\nSwish [11],Sigmoid [59], and projected-based estimator [39] (denoted\nas PBE). (1) The results summarized in Table 5 well demonstrate the\nsuperiority of our proposed Fourier Series decomposition to sign(¬∑)\nfunction in gradient estimation. As we have briefly explained, most\nexisting estimators employ the visually similar function approxi-\nmation to sign(¬∑); compared to STE, they generally provide better\ngradient estimation. (2) However, for those bipartite graphs with\nheavy sparsity, e.g., Gowalla (0.00084) and AMZ-Book (0.00062),\ngraph-based models may hardly collect enough structural informa-\ntion for effective hash codes training. Based on the limited training\nsamples, these theoretically irrelevant estimators may not effectively\nrectify the optimization deviation, and thus present a recognizable\nperformance gap against our proposed Fourier serialized estimator.\n6 Conclusion\nWe study the graph convolutional hashing over bipartite graphs for\nefficient Hamming space search, by proposing BGCH with three\neffectual modules. Extensive experiments demonstrate the model\nsuperiority over conventional counterparts and validate the effec-\ntiveness of all proposed modules. As for future work, we plan to\ninvestigate modeling with the semi-supervised graph setting [ 47,48]\nmainly for its commonality in practice. Moreover, another promis-\ning direction is to upgrade BGCH for inductive learning [17], such\nthat it can make adaptive matching and prediction for evolving\ngraphs with structural updates.\nAcknowledgments\nWe thank anonymous reviewers for their insightful comments and\nsuggestions. Yankai Chen, Yifei Zhang and Irwin King were sup-\nported by the National Key Research and Development Program of\nChina (No. 2018AAA0100204) and by the Research Grants Council\nof the Hong Kong Special Administrative Region, China (CUHK\n2410021, Research Impact Fund, No. R5034-18). Yixiang Fang was\nsupported by NSFC Grant (62102341).\n\nBipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA\nReferences\n[1]Haoli Bai, Wei Zhang, Lu Hou, Lifeng Shang, Jing Jin, Xin Jiang, Qun Liu, Michael\nLyu, and Irwin King. 2020. Pushing the limit of bert quantization. arXiv (2020).\n[2]Yoshua Bengio, Nicholas L√©onard, and Aaron Courville. 2013. Estimating or\npropagating gradients through stochastic neurons for conditional computation.\narXiv (2013).\n[3]Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2013. Spectral\nnetworks and locally connected networks on graphs. arXiv (2013).\n[4]Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Philip S Yu. 2017. Hashnet:\nDeep learning to hash by continuation. In ICCV. 5608‚Äì5617.\n[5]Minyu Chen, Guoqiang Li, Chen Ma, Jingyang Li, and Hongfei Fu. 2022. Answer-\ning Coding Questions via Dense Retrieval on GitHub Repositories. In COLING .\n[6]Yankai Chen, Huifeng Guo, Yingxue Zhang, Chen Ma, Ruiming Tang, Jingjie\nLi, and Irwin King. 2022. Learning binarized graph representations with multi-\nfaceted quantization reinforcement for top-k recommendation. In SIGKDD.\n[7]Yankai Chen, Menglin Yang, Yingxue Zhang, Mengchen Zhao, Ziqiao Meng,\nJianye Hao, and Irwin King. 2022. Modeling Scale-free Graphs with Hyperbolic\nGeometry for Knowledge-aware Recommendation. In WSDM. 94‚Äì102.\n[8]Yankai Chen, Yaming Yang, Yujing Wang, Jing Bai, Xiangchen Song, and Irwin\nKing. 2022. Attentive Knowledge-aware Graph Convolutional Networks with\nCollaborative Guidance for Personalized Recommendation. In ICDE.\n[9]Yankai Chen, Yifei Zhang, Huifeng Guo, Ruiming Tang, and Irwin King. 2022.\nAn Effective Post-training Embedding Binarization Approach for Fast Online\nTop-K Passage Matching. In AACL-IJCNLP. 102‚Äì108.\n[10] Zhiyong Cheng, Ying Ding, Lei Zhu, and Mohan Kankanhalli. 2018. Aspect-aware\nlatent factor model: Rating prediction with ratings and reviews. In WWW.\n[11] Sajad Darabi, Mouloud Belbahri, Matthieu Courbariaux, and Vahid Partovi Nia.\n2018. Bnn+: Improved binary network training. (2018).\n[12] Micha√´l Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. CNNs on\ngraphs with fast localized spectral filtering. NeurIPS 29 (2016).\n[13] Yifan Gao, Chien-Sheng Wu, Jingjing Li, Shafiq Joty, Steven CH Hoi, Caiming\nXiong, Irwin King, and Michael Lyu. 2020. Discern: Discourse-Aware Entailment\nReasoning Network for Conversational Machine Reading. In EMNLP . 2439‚Äì2449.\n[14] Aristides Gionis, Piotr Indyk, Rajeev Motwani, et al .1999. Similarity search in\nhigh dimensions via hashing. In PVLDB, Vol. 99. 518‚Äì529.\n[15] Ruihao Gong, Xianglong Liu, Shenghu Jiang, Tianxiang Li, Peng Hu, Jiazhen\nLin, Fengwei Yu, and Junjie Yan. 2019. Differentiable soft quantization: Bridging\nfull-precision and low-bit neural networks. In ICCV. 4852‚Äì4861.\n[16] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for\nnetworks. In SIGKDD. 855‚Äì864.\n[17] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation\nlearning on large graphs. In NeurIPS. 1025‚Äì1035.\n[18] Ruining He and Julian McAuley. 2016. Modeling the visual evolution of fashion\ntrends with one-class collaborative filtering. In WWW. 507‚Äì517.\n[19] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng\nWang. 2020. Lightgcn: Simplifying and powering graph convolution network for\nrecommendation. In SIGIR. 639‚Äì648.\n[20] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng\nChua. 2017. Neural collaborative filtering. In WWW. 173‚Äì182.\n[21] Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast\nmatrix factorization for online recommendation with implicit feedback. In ICCV .\n[22] Xuming Hu, Fukun Ma, Chenyao Liu, Chenwei Zhang, Lijie Wen, and Philip S Yu.\n2021. Semi-supervised Relation Extraction via Incremental Meta Self-Training.\nInEMNLP.\n[23] Xuming Hu, Lijie Wen, Yusong Xu, Chenwei Zhang, and Philip S. Yu. 2020. Self-\nORE: Self-supervised Relational Feature Learning for Open Relation Extraction.\nInEMNLP. 3673‚Äì3682.\n[24] Eric Jang, Shixiang Gu, and Ben Poole. 2017. Categorical reparameterization\nwith gumbel-softmax. (2017).\n[25] Herve Jegou, Matthijs Douze, and Cordelia Schmid. 2010. Product quantization\nfor nearest neighbor search. TPAMI 33, 1 (2010), 117‚Äì128.\n[26] Alexis Joly and Olivier Buisson. 2011. Random maximum margin hashing. In\nCVPR. IEEE, 873‚Äì880.\n[27] Wang-Cheng Kang, Derek Zhiyuan Cheng, Tiansheng Yao, Xinyang Yi, Ting\nChen, Lichan Hong, and Ed H Chi. 2021. Learning to Embed Categorical Features\nwithout Embedding Tables for Recommendation. In SIGKDD. 840‚Äì850.\n[28] Wang-Cheng Kang and Julian McAuley. 2019. Candidate generation with binary\ncodes for large-scale top-n recommendation. In CIKM. 1523‚Äì1532.\n[29] Diederik Kingma and Jimmy Ba. 2015. Method for stochastic optimization. ICLR .\n[30] Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graph\nconvolutional networks. (2017).\n[31] Piotr Koniusz, Fei Yan, Philippe-Henri Gosselin, and Krystian Mikolajczyk. 2016.\nHigher-order occurrence pooling for bags-of-words: Visual concept detection.\nTPAMI 39, 2 (2016), 313‚Äì326.\n[32] Piotr Koniusz, Hongguang Zhang, and Fatih Porikli. 2018. A deeper look at power\nnormalizations. In CVPR. 5774‚Äì5783.[33] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In SIGMOD. 489‚Äì504.\n[34] Guohao Li, Matthias Muller, Ali Thabet, and Bernard Ghanem. 2019. Deepgcns:\nCan gcns go as deep as cnns?. In ICCV. 9267‚Äì9276.\n[35] Hao Li, Wei Liu, and Heng Ji. 2014. Two-Stage Hashing for Fast Document\nRetrieval.. In ACL. 495‚Äì500.\n[36] Jingjing Li, Zichao Li, Lili Mou, Xin Jiang, Michael Lyu, and Irwin King. 2020.\nUnsupervised text generation by learning from search. NeurIPS.\n[37] Dawen Liang, Laurent Charlin, James McInerney, and David M Blei. 2016. Mod-\neling user exposure in recommendation. In WWW. 951‚Äì961.\n[38] Xiaofan Lin, Cong Zhao, and Wei Pan. 2017. Towards accurate binary convolu-\ntional neural network. (2017).\n[39] Chunlei Liu, Wenrui Ding, Xin Xia, Yuan Hu, Baochang Zhang, Jianzhuang\nLiu, Bohan Zhuang, and Guodong Guo. 2019. Rectified Binary Convolutional\nNetworks for Enhancing the Performance of 1-bit DCNNs. arXiv (2019).\n[40] Chen Ma, Peng Kang, and Xue Liu. 2019. Hierarchical gating networks for\nsequential recommendation. In SIGKDD.\n[41] Chen Ma, Liheng Ma, Yingxue Zhang, Ruiming Tang, Xue Liu, and Mark Coates.\n2020. Probabilistic metric learning with adaptive margin for top-k recommenda-\ntion. In SIGKDD.\n[42] Chris J Maddison, Andriy Mnih, and Yee Whye Teh. 2017. The concrete distribu-\ntion: A continuous relaxation of discrete random variables. (2017).\n[43] Yury Nahshan, Brian Chmiel, Chaim Baskin, Evgenii Zheltonozhskii, Ron Ban-\nner, Alex M Bronstein, and Avi Mendelson. 2021. Loss aware post-training\nquantization. Machine Learning (2021), 1‚Äì18.\n[44] Haotong Qin, Ruihao Gong, Xianglong Liu, Mingzhu Shen, Ziran Wei, Fengwei\nYu, and Jingkuan Song. 2020. Forward and backward information retention for\naccurate BNNs. In CVPR. 2250‚Äì2259.\n[45] Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. 2016.\nImagenet classification using binary CNNs. In ECCV. Springer, 525‚Äì542.\n[46] BRYAN RUST. 2013. CONVERGENCE OF FOURIER SERIES. (2013).\n[47] Zixing Song, Ziqiao Meng, Yifei Zhang, and Irwin King. 2021. Semi-supervised\nMulti-label Learning for Graph-structured Data. In CIKM.\n[48] Zixing Song, Yifei Zhang, and Irwin King. 2022. Towards an Optimal Asymmetric\nGraph Structure for Robust Semi-supervised Node Classification. In SIGKDD.\n[49] Qiaoyu Tan, Ninghao Liu, Xing Zhao, Hongxia Yang, Jingren Zhou, and Xia Hu.\n2020. Learning to hash with GNNs for RecSys. In WWW. 1988‚Äì1998.\n[50] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro\nLi√≤, and Yoshua Bengio. 2018. Graph Attention Networks. In ICLR.\n[51] Jingdong Wang, Ting Zhang, Nicu Sebe, Heng Tao Shen, et al .2017. A survey on\nlearning to hash. TPAMI 40, 4 (2017), 769‚Äì790.\n[52] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.\nNeural graph collaborative filtering. In SIGIR. 165‚Äì174.\n[53] Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua.\n2020. Disentangled graph collaborative filtering. In ICLR. 1001‚Äì1010.\n[54] Xing Wei, Yue Zhang, Yihong Gong, Jiawei Zhang, and Nanning Zheng. 2018.\nGrassmann pooling as compact homogeneous bilinear pooling for fine-grained\nvisual classification. In ECCV. 355‚Äì370.\n[55] Yair Weiss and Antonio Torralba. 2008. Spectral hashing. NeurIPS (2008).\n[56] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian\nWeinberger. 2019. Simplifying graph convolutional networks. In ICML.\n[57] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How powerful\nare graph neural networks? (2019).\n[58] Yixing Xu, Kai Han, Chang Xu, Yehui Tang, Chunjing Xu, and Yunhe Wang. 2021.\nLearning frequency domain approximation for BNNs. arXiv (2021).\n[59] Jiwei Yang, Xu Shen, Jun Xing, Xinmei Tian, Houqiang Li, Bing Deng, Jianqiang\nHuang, and Xian-Sheng Hua. 2019. Quantization Networks. In CVPR . 7308‚Äì7316.\n[60] Menglin Yang, Min Zhou, Jiahong Liu, Defu Lian, and Irwin King. 2022. HRCF:\nEnhancing collaborative filtering via hyperbolic geometric regularization. In\nWWW. 2462‚Äì2471.\n[61] Tan Yu, Yunfeng Cai, and Ping Li. 2020. Toward faster and simpler matrix\nnormalization via rank-1 update. In ECCV. Springer, 203‚Äì219.\n[62] Dell Zhang, Jun Wang, Deng Cai, and Jinsong Lu. 2010. Laplacian co-hashing of\nterms and documents. In ECIR. Springer, 577‚Äì580.\n[63] Jiani Zhang, Xingjian Shi, Shenglin Zhao, and Irwin King. 2019. Stacked and\nreconstructed graph convolutional networks for recommender systems. IJCAI .\n[64] Xinni Zhang, Yankai Chen, Cuiyun Gao, Qing Liao, Shenglin Zhao, and Irwin King.\n2022. Knowledge-aware Neural Networks with Personalized Feature Referencing\nfor Cold-start Recommendation. arXiv (2022).\n[65] Yan Zhang, Defu Lian, and Guowu Yang. 2017. Discrete personalized ranking for\nfast collaborative filtering from implicit feedback. In AAAI, Vol. 31.\n[66] Yifei Zhang and Hao Zhu. 2019. Doc2hash: Learning discrete latent variables for\ndocuments retrieval. In NAACL. 2235‚Äì2240.\n[67] Yifei Zhang, Hao Zhu, Zixing Song, Piotr Koniusz, and Irwin King. 2022. COSTA:\nCovariance-Preserving Feature Augmentation for Graph Contrastive Learning.\nInSIGKDD.\n[68] Yifei Zhang, Hao Zhu, Zixing Song, Piotr Koniusz, and Irwin King. 2022. Spectral\nFeature Augmentation for Graph Contrastive Learning and Beyond. In arXiv.\n\nWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Yankai Chen et al.\nTable 6: Notations and meanings.\nNotation Meaning\nG,V1,V2,E Bipartite graph with sets of nodes and edges.\nùëê,ùëë Convolution dimension and hash code dimension.\nùëΩ(ùëô)\nùë• Nodeùë•‚Äôs embedding at iteration ùëô.\nùíÄEdge transactions where ùíÄùë•,ùë¶=1indicates the interaction\nexistence between nodes ùë•andùë¶, and otherwise ùíÄùë•,ùë¶=0.\nùë®,ùë´ Adjacency matrix and associated diagonal degree matrix.\nùíë(ùëò),ùë∑ Dispersing vector at iteration ùëòand the projection matrix.\neùëâ Feature-dispersed embedding matrix.\nbùíÄ Estimated matching scores.\nùë∏(ùëô)\nùë• Hash code segment of node ùë•at iterationùëô.\nùõº(ùëô)ùë•‚Äôs rescaling factor computed at the ùëô-th convolution.\nùë∏ùë• Target hash codes of node ùë•.\nùêø,ùêæ Numbers of convolutional hashing and dispersion generation.\nLùëüùëíùëê,Lùëèùëùùëü,L Two loss terms of final objective function L.\nùúÇ,ùêª,ùëõ,ùúÜ1,ùúÜ2 hyper-parameters.\nAlgorithm 1: BGCH algorithm.\n1while model not converge do\n2 forùëò=0,¬∑¬∑¬∑,ùêæ‚àí1do\n3 ùíë(ùëò+1)‚Üê(ùëΩ(0))TùëΩ(0)ùíë(ùëò);\n4 ùë∑‚Üêobtain the projection matrix ; ‚ä≤Eq.(4)\n5eùëΩ(0)‚Üêobtain the feature-dispersed embeddings ; ‚ä≤Eq.(5)\n6 forùëô=0,¬∑¬∑¬∑,ùêø‚àí1do\n7 eùëΩ(ùëô+1)‚Üê(ùë´‚àí1\n2ùë®ùë´‚àí1\n2)eùëΩ(ùëô); ‚ä≤Eq.(6)\n8 ùë∏(ùëô+1)‚Üêsign\u0000eùëΩ(ùëô+1)); ‚ä≤Eq.(7)\n9 ùú∂‚Üêcalculate the rescaling factors ; ‚ä≤Eq.(8)\n10 forùë•‚ààV 1,ùë¶‚ààN(ùë•)do\n11 bùíÄùë•,ùë¶‚Üêùõºùë•ùõºùë¶(ùëë‚àí2ùê∑ùêª(ùë∏ùë•,ùë∏ùë¶));‚ä≤Eq.(14)&Thm.2\n12L‚Üê compute loss and optimize the model ; ‚ä≤Eq‚Äôs.(15-17)\n13Function Gradient_estimator( L):\n14ùúïL\nùúïùëΩ‚ÜêùúïL\nùúïùë∏¬∑4\nùêª√çùëõ\nùëñ=1,3,5,¬∑¬∑¬∑cos(ùúãùëñùëΩ\nùêª); ‚ä≤Eq.(12)\nA Loss Landscape Visualization\nWe simulate the optimization trajectories of learnable embeddings\nand visually compare the loss landscapes of non-hashing and hash-\ning versions in Figure 2(a). Specifically, we manually assign pertur-\nbations [ 1,43] to the embeddings on MovieLens dataset as: ùëΩ(ùëô)\nùë•=\nùëΩ(ùëô)\nùë•¬±ùëù¬∑|ùëΩ(ùëô)\nùë•|¬∑1(ùëô). where|ùëΩ(ùëô)\nùë•|represents the absolute mean of en-\ntries in ùëΩ(ùëô)\nùë•and perturbation magnitudes ùëùare from{0.01,¬∑¬∑¬∑,0.50}.\n1is an all-one vector. For pairs of perturbed node embeddings, we\nplot their loss distribution accordingly. As we can observe, the\nnon-hashing version produces a flat loss surface, showing the local\nconvexity. On the contrary, the hashing counterpart has a bumping\nand complex loss landscape.\nB Notation Table and BGCH Pseudo-codes\nWe use bold uppercase and calligraphy characters for matrices and\nsets. The non-bolded denote graph nodes or scalars. Key notations\nand Pseudocodes are explained in Table 6 and Algorithm 1.\nC Theoretical Proofs and Analyses\nTheorem 1 (Feature Dispersion ).LetùëΩ(ùëô)=ùëº1ùö∫ùëºT\n2, where ùëº1\nandùëº2are unitary matrices and descending singular value matrix\nùö∫=diag(ùúé1,ùúé2,¬∑¬∑¬∑,ùúéùëê). Then E(eùëΩ(ùëô))=ùëº1ùö∫ùö∫ùúáùëºT\n2where ùö∫ùúá=\ndiag(ùúá1,ùúá2,¬∑¬∑¬∑,ùúáùëê)0<ùúá1¬∑¬∑¬∑ùëê<1is in ascending order.Proof. We focus on comparing ( eùëΩ(0),ùëΩ(0)), which can be easily\npopularized to any convolution layer, i.e., ( eùëΩ(ùëô),ùëΩ(ùëô)). Conducting\nSVD decomposition on ùëΩ(0), we have ùëΩ(0)=ùëº1ùö∫ùëºT\n2, where ùëº1and\nùëº2are unitary matrices of singular vectors. Then following ùíë(ùëò)=\nùëΩ(0)TùëΩ(0)ùíë(ùëò‚àí1), we shall have ùíë(ùëò)=(ùëΩ(0)TùëΩ(0))ùëòùíë(0). Replacing\nùëΩ(0)with its SVD decomposition, we get the following equation:\nùíë(ùëò)=(ùëº2ùö∫2ùëòùëºT\n2)ùíë(0). (18)\nThen we transform the projection matrix in Equation (4) as follows:\nùë∑=ùíë(ùëò)ùíë(ùëò)T\nùíë(ùëò)Tùíë(ùëò)=(ùëº2ùö∫2ùëòùëºT\n2)ùíë(0)ùíë(0)T(ùëº2ùö∫2ùëòùëºT\n2)\nùíë(0)T(ùëº2ùö∫2ùëòùëºT\n2)(ùëº2ùö∫2ùëòùëºT\n2)ùíë(0)\n=ùëº2ùö∫2ùëòùëºT\n2ùíë(0)ùíë(0)Tùëº2\nùíë(0)Tùëº2ùö∫4ùëòùëºT\n2ùíë(0)ùö∫2ùëòùëºT\n2.(19)\nLetùíï=ùëºT\n2ùíë(0), we can further simplify the above equation to:\nùë∑=ùëº2ùö∫2ùëòùíïùíïT\nùíïTùö∫4ùëòùíïùö∫2ùëòùëºT\n2,where scalar ùíïTùö∫4ùëòùíï=ùëê‚àëÔ∏Å\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó.(20)\nRecalling that eùëΩ(0)=ùëΩ(0)(ùë∞‚àíùúñùë∑),E(eùëΩ(0))=ùëΩ(0)‚àíùúñ¬∑E(ùëΩ(0)ùë∑).\nThen we focus on the term E(ùëΩ(0)ùë∑)as follows:\nE(ùëΩ(0)ùë∑)=1\nùíïTùö∫4ùëòùíïùëº1ùö∫2ùëò+1¬∑E(ùíïùíïT)¬∑ùö∫2ùëòùëºT\n2(21)\nSince ùíë(0)‚àºN( 0,ùë∞)andùëº2is a unitary matrix, thus ùíï‚àºN( 0,ùë∞). This\nindices that each element of ùíï, e.g.,ùë°ùëó‚ààùíï, isi.i.d. random variable.\nThus, E(ùë°ùëó¬∑ùë°ùëò)=0forùëó‚â†ùëòandE(ùíïùíïT)is a diagonal matrix, i.e.,\nE(ùíïùíïT)=diag(ùë°2\n1,ùë°2\n2,¬∑¬∑¬∑,ùë°2ùëê). We then have:\nE(ùëΩ(0)ùë∑)=ùëº1¬∑diag\u0000ùúé1ùë°2\n1ùúé4ùëò\n1√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó,¬∑¬∑¬∑,ùúéùëêùë°2ùëêùúé4ùëòùëê√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó\u0001¬∑ùëºT\n2.(22)\nTherefore,\nE(eùëΩ(0))=ùëº1¬∑diag\u0000ùúé1‚àíùúñùúé1ùë°2\n1ùúé4ùëò\n1√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó,¬∑¬∑¬∑,ùúéùëê‚àíùúñùúéùëêùë°2ùëêùúé4ùëòùëê√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó\u0001¬∑ùëºT\n2.\n(23)\nLetùúáùëò=1‚àíùúñùë°2\nùëòùúé4ùëò\nùëò√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó, withùúñ‚àà(0,1), obviously, 0<ùúáùëò<1.\nFurthermore,‚àÄùëò1‚â•ùëò2, we have:\nùúáùëò1‚àíùúáùëò2=ùúñE(ùë°2\nùëò1ùúé4ùëò\nùëò1√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó‚àíùë°2\nùëò2ùúé4ùëò\nùëò2√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó)‚â•ùúñùúé4ùëò\nùëò1¬∑E(ùë°2\nùëò1‚àíùë°2\nùëò2√çùëê\nùëó=1ùë°2\nùëóùúé4ùëò\nùëó)=0,\n(24)\nasùúé4ùëò\nùëò2‚â•ùúé4ùëò\nùëò1, andùë°ùëò1andùë°ùëò2arei.i.d. random variables with same\nnormal distribution. Equation (24) proves that ùúáùëòismonotone non-\ndecreasing in expectation, which completes the proof. ‚ñ°\nTheorem 2 (Hamming Distance Matching ).Given two hash\ncodes, we have(ùõºùë•ùë∏ùë¢)T¬∑(ùõºùë¶ùë∏ùë¶)=ùõºùë•ùõºùë¶(ùëë‚àí2ùê∑ùêª(ùë∏ùë•,ùë∏ùë¶)).\nProof.\nùë∏T\nùë•¬∑ùë∏ùë¶=\f\f{ùëñ|(ùë∏ùë•)ùëñ=(ùë∏ùë¶)ùëñ=1}\f\f+\f\f{ùëñ|(ùë∏ùë•)ùëñ=(ùë∏ùë¶)ùëñ=‚àí1}\f\f\n‚àí\f\f{ùëñ|(ùë∏ùë•)ùëñ‚â†(ùë∏ùë¶)ùëñ}\f\f\n=ùëë‚àí2¬∑\f\f{ùëñ|(ùë∏ùë•)ùëñ‚â†(ùë∏ùë¶)ùëñ}\f\f=ùëë‚àí2ùê∑ùêª(ùë∏ùë•,ùë∏ùë¶)),\n(25)\nwhich completes the proof. ‚ñ°\nTraining time complexity. As shown in Table 7, |E|,ùêµ,ùë†, and\nùëõare the edge number, batch size, numbers of train iterations and\n\nBipartite Graph Convolutional Hashing for Effective and Efficient Top-N Search in Hamming Space WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA\nTable 7: Traing time complexity.\nGraph Norm. Feat. Disp. Conv. & Hash. Loss Comp. Grad. Est.\nùëÇ(2|E|)ùëÇ(2ùëêùë†ùêæ|E|2\nùêµ)ùëÇ(2ùëêùë†ùêø|E|2\nùêµ)ùëÇ\u00002ùë†(ùëê+ùëë)|E|\u0001ùëÇ(ùë†ùëõùëë|E|)\nTable 8: Complexity of space and computation.\nSpace cost #FLOP #BOP\nfloat32-based 32|V1‚à™V 2|ùëëùëÇ\u0000|V1|¬∑|V 2|ùëë\u0001-\nBGCH|V1‚à™V 2|(ùëë+32(ùêø+1))ùëÇ\u00004|V1|¬∑|V 2|\u0001ùëÇ\u0000|V1|¬∑|V 2|ùëë\u0001\nFourier Series decomposition terms. (1) The time complexity of\nthe graph normalization, i.e., ùë´‚àí1\n2ùë®ùë´‚àí1\n2, isùëÇ(2|E|). (2) Before the\ngraph convolution, we first conduct the feature dispersion only for\nthe initial node embeddings, e.g., ùëΩ(0)\nùë•, which takes ùëÇ(2ùëêùë†ùêæ|E|2\nùêµ)\ncomplexity. In our experiment, hyper-parameter ùêæ‚â§3. (3) In graph\nconvolution, the time complexity is ùëÇ(2ùëêùë†ùêø|E|2\nùêµ), whereùêø‚â§4is a\ncommon setting [ 17,19,30,52] to avoid over-smoothing [34]. (4)\nAs for the loss computation, BGCH takes ùëÇ\u00002ùë†ùëê|E|\u0001to compute\nLùëüùëíùëêandùëÇ\u00002ùë†ùëë|E|\u0001forLùëèùëùùëü. (5) Lastly, BGCH takes ùëÇ(ùë†ùëõùëë|E|)to\nestimate the gradients for the ùëë-dimension hash codes. Thus, thee\ntotal complexity in total is quadratic to the graph edge numbers,\ni.e.,|E|, which is common in GCN frameworks.\nHash codes space cost. As shown in Table 8, the total space\ncost of hash codes is ùëÇ(|V 1‚à™V 2|(ùëë+32(ùêø+1)))bits, supposing\nthat we use float32 for those rescaling factors in ùêø+1iterations.\nCompared to the continuous embedding size, i.e., 32|V1‚à™V 2|ùëëbits,\nthe theoretical size reduction ratio thus is:\nùëüùëéùë°ùëñùëú=32|V1‚à™V 2|ùëë\n|V1‚à™V 2|(ùëë+32(ùêø+1))=32ùëë\nùëë+32(ùêø+1).(26)\nAs we just explained, stacking too many iteration layers will in-\ncurring performance detriment [ 34]. Hence, ifùêø‚â§4andùëë=1024,\nBGCH can achieve considerable size compression.\nOnline matching. The original score formulation in Equation (14)\ncontainsùëëfloating-point operations (#FLOPs). As shown in Table 8,\nusing Hamming distance matching can convert the most of floating-\npoint arithmetics to binary operations (#BOPs), with slightly more\n#FLOPs for scalar computations, i.e., 4‚â™ùëë.\nD Experiment Setup Details\nDatasets. We evaluate our model on the following six six datasets:\n(1)MovieLens7is a widely adopted benchmark between users and\nmovies . Similar to the setting in [ 21,49], if the user ùë•has rated\nitemùë¶, we set the edge ùíÄùë•,ùë¶=1, otherwise ùíÄùë•,ùë¶=0.\n(2)Gowalla8[19,49,52,53] is the dataset [ 37] between customers\nandtheir check-in locations collected from Gowalla.\n(3)Pinterest9is an open dataset for image recommendation be-\ntween users andimages . Edges represent the pins over images\ninitiated by users.\n(4)Yelp201810is from Yelp Challenge 2018 Edition, bipartitely\nmodeling between users andlocal businesses .\n7https://grouplens.org/datasets/movielens/1m/\n8https://github.com/gusye1234/LightGCN-PyTorch/tree/master/data/gowalla\n9https://sites.google.com/site/xueatalphabeta/dataset-1/pinterest_iccv\n10https://github.com/gusye1234/LightGCN-PyTorch/tree/master/data/yelp2018(5)AMZ-Book11is the bipartite graph between readers andbooks ,\norganized from the book collection of Amazon-review [18].\n(6)Dianping12is a commercial dataset between users and local\nbusinesses recording their diverse interactions, e.g., clicking,\nsaving, and purchasing.\nEvaluation metrics. To evaluate the model performance of\nHamming space retrieval over bipartite graphs, we directly deploy\nour model BGCH in the basic user-item recommendation scenarios.\nSpecifically, given a query node, we apply the hash codes to match\nTop-N answers for the query with the closest Hamming distances,\nand thus adopt two widely-used evaluation protocols Recall@N\nand NDCG@N to measure the ranking capability.\nImplementations. We implement our models under Python 3.6\nand PyTorch 1.14.0 on a Linux machine with 1 Nvidia GeForce RTX\n3090 GPU, 4 Intel Core i7-8700 CPUs, 32 GB of RAM with 3.20GHz.\nFor all the baselines, we follow the official hyper-parameter settings.\nWe apply a grid search if lacking recommended model settings. The\ndimension is searched in { 32,64,128,256,512}. The learning rate ùúÇ\nis tuned within { 10‚àí3,5√ó10‚àí3,10‚àí2,5√ó10‚àí2} and the coefficient\nùúÜis tuned among { 10‚àí5,10‚àí4,10‚àí3}. We initialize and optimize all\nmodels with default normal initializer and Adam optimizer [29].\nBaselines. All baselines studied in this paper are introduced as:\n(1)LSH [14] is a classical hashing method. LSH is proposed to\napproximate the similarity search for massive high-dimensional\ndata and we introduce it for Top-N object search by following\nthe adaptation in [49].\n(2)HashNet [4] is a representative deep hashing method that\nis originally proposed for multimedia retrieval tasks. Similar\nto [49], we adapt it for graph data by modifying it with the\ngeneral graph convolutional network.\n(3)CIGAR [28] is a state-of-the-art neural-network-based frame-\nwork for fast Top-N candidate generation in recommendation.\nCIGAR can be further followed by a full-precision re-ranking\nalgorithm. And we only use its hashing part for fair comparison.\n(4)Hash_Gumbel is a variance of BGCH with Gumbel-softmax\nfor hash encoding and gradient estimation [ 24,42]. Specifically,\nwe first expand each embedding bit to a size-two one-hot en-\ncoding. Then it utilizes the Gumbel-softmax trick to replace\nsign(¬∑)as relaxation for binary hash code generation.\n(5)HashGNN [49] is the state-of-the-art learning to hash based\nmethod with GCN framework. We use HashGNN ‚Ñéto denote\nthe vanilla version with hard encoding proposed in [ 49], where\neach element of user-item embeddings is strictly binarized. We\nuse HashGNN ùë†to denote its proposed approximated version.\n(6)NeurCF [20] is one representative deep neural network model\nfor collaborative filtering in recommendation.\n(7)NGCF [52] is one of the representative graph-based recom-\nmender models with collaborative filtering methodology.\n(8)DGCF [53] is a state-of-the-art graph-based model that learns\ndisentangled user intents for better recommendation.\n(9)LightGCN [19] is another latest state-of-the-art GCN-based\nrecommender model that has been widely evaluated.\n11https://github.com/gusye1234/LightGCN-PyTorch/tree/master/data/amazon-book\n12https://www.dianping.com/",
  "textLength": 97742
}