{
  "paperId": "8731e01cba81f6b9bfa79430f3c2d23ff36e5bf6",
  "title": "Deep Learning-Based Bloom Filter for Efficient Multi-key Membership Testing",
  "pdfPath": "8731e01cba81f6b9bfa79430f3c2d23ff36e5bf6.pdf",
  "text": "Vol:.(1234567890)Data Science and Engineering (2023) 8:234â€“246\nhttps://doi.org/10.1007/s41019-023-00224-9\n1 3\nRESEARCH PAPER\nDeep Learningâ€‘Based Bloom Filter forÂ Efficient Multiâ€‘key Membership \nTesting\nHaitianÂ Chen3Â Â· ZiweiÂ Wang2Â Â· YunchuanÂ Li2Â Â· RuixinÂ Yang2Â Â· YanÂ Zhao4Â Â· RuiÂ Zhou5Â Â· KaiÂ Zheng1,2,3 \nReceived: 18 May 2023 / Revised: 20 July 2023 / Accepted: 8 August 2023 / Published online: 2 September 2023 \nÂ© The Author(s) 2023\nAbstract\nMulti-key membership testing plays a crucial role in computing systems and networking applications, encompassing web \nsearch, mail systems, distributed databases, firewalls, and network routing. Traditional approaches, such as the Bloom filter, \nencounter limitations within this specific context. Addressing these challenges, we propose the Multi-key Learned Bloom \nFilter (MLBF), a hybrid method that combines machine learning techniques with the Bloom filter. The MLBF introduces \na value-interaction-based multi-key classifier and a multi-key Bloom filter. Furthermore, we introduce an Interval-based \nMLBF approach, which categorizes keys into specific intervals based on data distribution to minimize the False Positive \nRate (FPR). Additionally, MLBF incorporates an out-of-distribution (OOD) detection component to identify data shifts. \nThrough extensive experimental evaluations on three authentic datasets, we demonstrate the superiority of the proposed \nMLBF in terms of FPR and query efficiency.\nKeywords Bloom filterÂ Â· Learned structuresÂ Â· Learned bloom filterÂ Â· Membership testing\n1 Introduction\nMembership testing is a problem of judging whether a que-\nried element eq exists in a certain element set S , which is \ncommon in computer-related fields, e.g., database systems, \nweb search, firewalls, network routing, etc. The proliferation \nof massive raw data brings with it a series of storage and \nprocessing challenges.\nTo enable fast membership testing among massive raw \ndata, effective data structures are needed that can store raw data using small space and answer queries efficiently. As a \ncommon data structure, hash table works well in member -\nship testing, where data are mapped on a hash table using \nrandom hash functions. Although it helps to ensure fast \nquery to some extent, it has long been blamed for its low \nspace efficiency. To achieve high space efficiency and high-\nspeed query processing, Bloom filter (BF)Â [1 ], a probabilistic \ndata structure, is proposed to perform approximate mem-\nbership testing. However, it is always necessary to make \na trade-off between FPR and memory usage when using \n * Kai Zheng \n zhengkai@uestc.edu.cn\n Haitian Chen \n haitianchen@std.uestc.edu.cn\n Ziwei Wang \n ziwei@std.uestc.edu.cn\n Yunchuan Li \n liyunchuan@std.uestc.edu.cn\n Ruixin Yang \n youngrx@std.uestc.edu.cn\n Yan Zhao \n yanz@cs.aau.dk\n Rui Zhou \n zhourui24@huawei.com1 Yangtze Delta Region Institute (Quzhou), University \nofÂ Electronic Science andÂ Technology ofÂ China, Quzhou, \nChina\n2 School ofÂ Computer Science andÂ Engineering, University \nofÂ Electronic Science andÂ Technology ofÂ China, Chengdu, \nChina\n3 Shenzhen Institute forÂ Advanced Study, University \nofÂ Electronic Science andÂ Technology ofÂ China, Shenzhen, \nChina\n4 Aalborg University, Aalborg, Denmark\n5 Cloud Database Innovation Lab ofÂ Cloud BU, Huawei \nTechnologies Co.,Ltd, Chengdu, China\n\n235 Deep Learning-Based Bloom Filter forÂ Efficient Multi-key Membership Testing  \n1 3\nBloom filter. So, in recent years, extensive effort has been \ndevoted to exploring low FPR and low memory occupancy \nof Bloom filter, but most of existing studiesÂ [2 â€“6] have not \nachieved significant improvement.\nIn order to further improve the space efficiency, Bloom \nfilter empowered by machine learning techniques are pro-\nposedÂ [7 â€“9]. Kraska etÂ al.Â [7 ] regard membership testing as \na binary classification problem and use a learned classifica-\ntion model combined with traditional Bloom filter. Such a \ndata structure is called Learned Bloom filter (LBF). Based \non LBF, Dai etÂ al.Â [8 ] propose an Ada-Bloom filter, which \ndivides the scores learned in the machine learning stage into \ndifferent intervals and uses different discrimination strate-\ngies for elements in different score intervals. Considering \nthat when the amount of data in the data stream is close to \ninfinity, the FPR of BF/LBF may be close to 1. Adapting \nLBF to the extremely large amount of data, Liu etÂ al.Â [9 ] \npropose a Stable LBF, which combines the classifier with \nan updatable stable Bloom filter to make the filterâ€™s perfor -\nmance decay effect more controllable to achieve a satisfying \nFPR.\nPrevious studies primarily focus on single-key member -\nship testing with the learned Bloom filter. This means their \nmethods are designed for scenarios where each element \nhas only one key-value pair. In a multi-key scenario, e.g., \nstoring data in a distributed database across multiple physi-\ncal nodes, accessing the disks of all physical nodes when a \nquery with filtering conditions arrives results in increased \nlatency. By implementing an efficient and reliable multi-key \nBloom filter for each physical node, we can significantly \nreduce the fan-out of nodes. Additionally, the traditional \nBloom filter can only handle queries where all keys are \nspecified. Existing methods often concatenate all keys into \none key or input each key sequentially to handle multi-key \nscenarios as single-key scenarios. However, in most cases, \nwhen processing a query where not all keys are specified, the \ntraditional Bloom filter will have a high false positive rate \n(FPR) because each individual key-value pair may exist, but \ntheir combinations may not. Moreover, the traditional Bloom \nfilter applies the same family of hash functions for each key \nin the query, resulting in a higher FPR.\nIn order to achieve lower FPR and lower space consump -\ntion in multi-key membership testing, in this paper, we \npropose a method, called Multi-key Learned Bloom Filter \n(MLBF), to tackle the problem. Similar to other LBF meth-\nods, MLBF first classifies the queried elements through a \nvalue-interaction-based multi-key classifier, and the ele -\nments determined to be absent by the classifier will enter \na multi-key Bloom filter for further determination. We pro-\npose an optimization strategies for multi-key Bloom filters, \nto improve the performance of MLBF.\nOur contributions can be summarized as follows: (1) To the best of our knowledge, this is the first work that \nadopts LBF to systematically solve the multi-key mem-\nbership testing problem.\n(2) For multi-key membership testing, we propose a Value-\nInteraction-based Multi-key Classifier (VIMC) model, \nwhich does not rely on feature engineering, to learn \nvalue interactions between keys to classify multi-key \nelements. In addition, we propose an adaptive negative \nweighted cross-entropy loss function to limit the FPR \nof the LBFâ€™s learning model, thereby reducing the FPR \nof the entire LBF.\n(3) We also propose an optimization strategies for multi-\nkey Bloom Filter, i.e., interval-based optimization, and \nutilize an out-of-distribution (OOD) detection mecha-\nnism, making our proposed method more applicable.\n(4) We report on experiments using real data, offering evi -\ndence of the good performance and applicability of the \npaperâ€™s proposals.\nThe rest of the paper is structured as follows: We give the \nproblem definition and background of LBF in Sect.Â  2. Sec-\ntionÂ 3 details the proposed data structures, where their fea-\nsibility and performance are analyzed. We report the results \nfrom an empirical study in Sect.Â  4, and Sect.Â  6 concludes \nthis paper.\n2  Preliminaries\nIn this section, we first formalize the problem of multi-key \nmembership testing and then introduce multi-key Bloom fil-\nter that we exploit in the proposed data structures.\n2.1  Problem Statement\n2.1.1  Multiâ€‘key Element Set\nA multi-key element set (a.k.a. a multi-key member set), S , is \na set of elements S={e1,e2, ...,en}, where n  is the number of \nelements, and eiâˆˆS denotes a multi-key element containing \nc key-value pairs, i.e., ei={key1âˆ¶v1,key2âˆ¶v2, ..., keycâˆ¶vc}\n.\n2.1.2  Multiâ€‘key Membership Testing\nGiven a multi-key element set S={e1,e2, ...,en} , and a que-\nried element eq={keyq1âˆ¶vq1,keyq2âˆ¶vq2, ...,keyqcâˆ¶vqc} , \nwhere 1â‰¤q1<q2<...<qcâ‰¤c . As shown in Fig.Â  1, If \nthere is a multi-key element ei in the multi-key set S , and \nvqi=vi for all keyqi=keyi , element eq exists. That is, query \neq exists in S  if its values of keys are the same with those of \nan element in S.\n\n236 H.Â Chen et al.\n1 3\n2.2  Multiâ€‘key Bloom Filter\nA Multi-key Bloom filter consists of c  hash function families \nand a bitmap of size m . When inserting a multi-key element \ne, e is input into these hash function families to calculate a \nbit vector, and the mapped positions in the bitmap are set to \n1. When querying whether an multi-key element exists, the \nelement is also input into the hash function family to obtain a \nbit vector, and each bit of the vector is mapped to the bitmap. \nIf all the mapped bits in the bitmap are 1, it means that the \nqueried element exists, otherwise it does not exist.\nGiven a multi-key element set containing four \nelements, e1,e2,e3,e4 . Initially, all bits of the bit -\nmap are set to 0. Taking the inserting multi-key \ne1={key1âˆ¶ }}aaï¿½ï¿½,key2âˆ¶ }}abï¿½ï¿½,key3âˆ¶ }}acï¿½ï¿½} as an  \nexample, e1 will be hashed to multiple bit positions first. \nWhen a query eq is proposed and the same hashing strategy \nis used for inserting, if all the positions after the hash are \n1, the query eq is determined to exist; otherwise it does not \nexist. It can be seen that the basic operations of the multi-key \nbloom filter and the single-key bloom filter are very similar. \nHowever, we need to consider some additional issues, such \nas how to hash multi-keys into the bitmap and how to reduce \nFPR, which we will introduce in detail in Sect. Â  3.\n3  Methodology\n3.1  MLBF Framework Overview\nThe framework has two components: a value-interaction-\nbased multi-key classifier and a multi-key Bloom filter. In \nthe first component, a queried multi-key element is input \ninto a value-interaction-based multi-key classifier, which \nis trained by a given multi-key element set. The classifier \ncan learn the score of the element, where the queried ele-\nment exists in the given multi-key element set if the score is \ngreater that a given threshold. When the score is less than \nthe threshold, we will put the queried element into a multi-\nkey Bloom filter for further judgment.3.2  Valueâ€‘Interactionâ€‘Based Multiâ€‘key Classifier\nTo solve the multi-key membership testing problem effec-\ntively, it is critical to learn sophisticated key interactions, \nwhich can capture the latent correlation between keys. \nTherefore, we propose a Value-Interaction-based Multi-\nkey Classifier (VIMC) model to learn the value interactions \ndirectly from values of keys. The framework of Value-\nInteraction-based Multi-key Classifier (VIMC) is shown in \nFig.Â 2. Specifically, VIMC encodes the values of the inputs \nwith a DeepFM encoder and then learns the value interac-\ntions from the encoded data through a Multi-layer Multi-\nhead Self-Attention (MMSA) module, the outputs of which \nare fed into a linear layer.\n3.2.1  DeepFM Encoder\nDeepFMÂ [10] is an efficient end-to-end learning model that \ncan learn both low-order and high-order feature interactions.\nGiven a multi-key element set, each element has one or \nmore values in each key. Firstly, the continuous values in the \nset will be discretized, i.e., for keyi , its values are divided \ninto ui different intervals according to a given segmentation \nstandard sti . Secondly, we create dictionaries for each key \nkeyj with discrete value types, where the length of its diction-\nary is dlj . Then, an element will be embedded into a one-hot \nvector X={x1,x2, ...,xL} , where L=âˆ‘\niui+âˆ‘\njdlj . When \nan element contains valuei , the corresponding xi will be set \nto 1, otherwise it will be set to 0.\nIn order to emphasize the low-order and high-order value \ninteractions, DeepFM adopts two components, an FM com-\nponent and a deep component The FM component is a \nfactorization machine, which is used to learn order-1 and \norder-2 value interactions. Specifically, a linear regression \nmodel is introduced to learn the order-1 value interaction, \nas shown in Eq.Â  1.\n(1) yorder1=âŸ¨w,xâŸ©+bFig. 1  Illustration of the multi-\nkey membership testing\n\n237 Deep Learning-Based Bloom Filter forÂ Efficient Multi-key Membership Testing  \n1 3\nwhere w is the parameter vector of the linear regression \nmodel and b is the bias.\nTo learn the order-2 value interaction, for valuei , a latent \nvector Vi is introduced to measure its impact of interactions \nwith other values. Specifically, for each value pair ( valuei , \nvaluej ) in an element, the value interaction between valuei \nand valuej is calculated by the inner product of the latent \nvectors Vi and Vj . The total order-2 value interaction is cal-\nculated as follows:\nThe output of FM is the summation of the order-1 and \norder-2 value interaction, which is shown in the following \nequation:\nThe deep component is a feed-forward neural network, \nwhich is used to learn high-order feature interactions. The \nlatent vector matrix containing interactive information is \nused to encode the value in the deep component. Put differ -\nently, each value in an element is mapped to the correspond-\ning latent vector, and the concatenation of latent vectors will \nbe used as the input of the feed-forward network. We take \nFN as the feed-forward network, and the output of the deep \ncomponent for a given query is shown as follows:\nwhere v=[V1,V2, ...,Vm] , and m is the number of values in \nthe query.\nFor the purpose of DeepFM training, in contrast to \nconventional classification tasks, we employ a supervised (2) yorder2=Lï¿½\ni=1Lï¿½\nj=i+1âŸ¨Vi,VjâŸ©xiâ‹…xj\n(3) yFM=yorder1+yorder2\n(4) yDeep =FN(v)contrastive learning loss for pretraining. Consequently, we \nfeed the output of the two components into a projection net-\nwork Proj (â‹…) , responsible for mapping high-dimensional \nfeatures onto a projection space, and subsequently normal-\nize the network output to lie on the unit hypersphere. We \nleverage these input values to facilitate supervised contras-\ntive learning.\nAfter training, the latent vectors in the FM component \nof DeepFM contain order-1, order-2 and high-order value \ninteraction information. Hence, we discard the projection \nnetwork and use the latent vectors as the embeddings of the \ncorresponding values.\n3.2.2  Supervised Contrastive Learning\nTo fully leverage the information provided by the samples, \nenhance sample efficiency, and improve the generalization \nperformance of the framework, we employed supervised \ncontrastive learning to train the DeepFM module.\nThe core principle of contrastive learning is to minimize \nthe distance between an anchor point and its positive sam-\nples while maximizing the distance between the anchor point \nand its negative samples. Self-supervised contrastive learn-\ningâ€™s efficacy is largely impacted by the distinction between \npositive and negative samples, while supervised contrastive \nlearning incorporates label information to better character -\nize the similarity of intra-class samples. For Bloom filters, \nthe significance of each sampleâ€™s key poses a challenge in \nexpanding data samples with noise, as it can lead to unpre-\ndictable outcomes. Therefore, we adapted the Loss function \nof supervised learning called SupCon lossÂ [11]. Specifically, \nas depicted in Fig.Â  2, we compute the loss of the feature \nvectors of each batch of samples output by the projection \nnetwork as follows:Fig. 2  VIMC model overview\n\n238 H.Â Chen et al.\n1 3\nwhere zl=Proj(yDeep+yFM) , l is an indicator function that \ntakes the value 0 only when k=i for all samples in the cur -\nrent batch, and 1 otherwise. /u1D70F is the temperature parameter \nbeing optimized.\nAfter pretraining the DeepFM module using supervised \ncontrastive learning, we discard the projection network and \nfreeze the parameters that have already been trained in the \nDeepFM module during the subsequent classifier training.\n3.2.3  Multiâ€‘layer Multiâ€‘head Selfâ€‘Attention\nSelf-AttentionÂ [12] uses attention mechanism to calculate \nthe value interaction between each value in the query and \nother values, and uses attention scores to show the degree \nof interaction between values.\nAs shown in Fig.Â  2, each value in a query is encoded by \nthe DeepFM encoder as a vector containing value interac-\ntion information. For simple self-attention, the representa-\ntion matrix of a query will be mapped into Q(Query ) , K(Key ) \nand V(Value)  matrices by three different mapping matrices \nWQ , WK and WV . Similar to DeepFM, self-attention measures \nthe correlation between values by calculating the inner prod-\nuct of Q  and K , which can well retain the value interaction \nlearned by the DeepFM encoder. We compute the matrix of \noutputs as:\nwhere dK is the dimension of each row vector in K , in order \nto prevent the result from being too large.\nMulti-head attention is a combination of multiple self-\nattention structures, each head learning features in different \nrepresentation spaces. A multi-head self-attention layer con-\nsists of a multi-head self-attention model and a feed-forward \nnetwork, and the output of multi-head self-attention will \npass through the feed-forward network to extract features.\n3.2.4  Progressive Selfâ€‘Knowledge Distillation\nTo increase the generalization performance of VIMC, we \nuse a simple yet effective regularization method, namely (5)LSCL=Nï¿½\ni=1LSCL\ni\nLSCL\ni=âˆ’1\nNâˆ’1Nï¿½\nj=1l[iâ‰ j]â‹…l[yi=yj]\nlogexp(ziâ‹…zj(i)âˆ•/u1D70F)\nâˆ‘N\nk=1l[kâ‰ i] â‹…exp(ziâ‹…zj(i)âˆ•/u1D70F)\n(6) Attention (Q,K,V)=softmax(QâŠ™KT\nâˆš\ndK)VProgressive Self-Knowledge Distillation (PSKD)Â [13]. \nPSKD enables the student model to distill its own knowl-\nedge, which means that the student becomes teacher itself. \nSpecifically, PSKD utilizes the past predictions of the stu-\ndent model as a teacher to obtain more information during \ntraining. The details of this process can be seen in the right \npart of Fig.Â  2. Suppose that Pstu\nt(x) is the prediction of the \nstudent model about the input x  at the t -th epoch. Then, \nthe objective at t-th epoch can be written as:\nwhere H is the binary cross-entropy loss function, /u1D6FCt is a \nhyperparameter that determines how much knowledge from \nthe teacher (i.e., Pstu\ntâˆ’1(x) ) to be accepted, y  is the hard target, \nand (1âˆ’/u1D6FCt)y+/u1D6FCtPstu\ntâˆ’1(x) is the softening target for the input \nx in the t-th epoch of training.\nHowever, there is a problem with /u1D6FCt that the model does \nnot have enough knowledge in the early stages of training. \nIn such a situation, /u1D6FCt should be tuned down. For this rea-\nson, PSKD increases the value of /u1D6FCt as t grows. Therefore, \n/u1D6FCt is computed as follows:\nwhere T is the total number of epochs for model training, \nand /u1D6FCT is the value of /u1D6FCt at the last epoch that is determined \nvia validation process.\n3.2.5  Adaptive Negative Weighted Crossâ€‘Entropy Loss \nFunction\nAs with traditional binary classification tasks, we initially \nconsidered the balanced cross-entropy loss function. Sup-\npose there are N  input samples to be predicted. Balanced \nloss is shown as follows:\nwhere yi is the label of the input, pi is the probability of \nbeing predicted to be positive, /u1D6FC is a weight parameter. Sup-\npose Cp and Cn are the number of positive and negative \nexamples, respectively. So, the value of /u1D6FC can be calculated \nfrom /u1D6FC\n1âˆ’/u1D6FC=Cn\nCp.\nFocal lossÂ [14] allows the binary classification model \nto focus on learning samples that are difficult to learn and \nsolves the problem of class imbalance to a certain extent. \nFocal loss is shown as follows:(7)LKD,t(x,y)= H/parenleft.s1/parenleft.s11âˆ’/u1D6FCt/parenright.s1y+/u1D6FCtPstu\ntâˆ’1(x),Pstu\nt(x)/parenright.s1\nH(y,p)=1\nN/uni2211.s1\niâˆ’/bracketleft.s1yiâ‹…log/parenleft.s1pi/parenright.s1+/parenleft.s11âˆ’yi/parenright.s1â‹…log/parenleft.s11âˆ’pi/parenright.s1/bracketright.s1\n(8) /u1D6FCt=/u1D6FCTÃ—t\nT,\n(9)Lossbalanced =1\nN/uni2211.s1\niâˆ’/bracketleft.s1/u1D6FCâ‹…yiâ‹…log(pi)+( 1âˆ’/u1D6FC)â‹…(1âˆ’yi)â‹…log(1 âˆ’pi)/bracketright.s1\n\n239 Deep Learning-Based Bloom Filter forÂ Efficient Multi-key Membership Testing  \n1 3\nwhere /u1D6FE is a hyperparameter, pi reflects how close the pre-\ndiction is to the ground truth, i.e., yi . Focal loss increases \nthe weight of the hard samples in the loss function through \nthe modulation of /u1D6FE and pi , so that the loss function tends to \nsolve the hard samples, which helps to improve the accuracy \nof the hard samples.\nHowever, neither the balanced loss nor the focal loss is \nsuitable for the MLBF data structure. As discussed above, \nfor a standard LBF, a query judged by the learned model as \na positive example will not be checked again, which leads to \nfalse positive examples. Therefore, for the learned model in \nLBF, false positives are often more unacceptable than false \nnegatives. At the same time, in many scenarios, negative \nexamples that can be used for training are more difficult to \nobtain than positive examples, which leads to more inac-\ncurate predictions for negative examples.\nIn order to solve the above problem, we propose an adap-\ntive negative weighted cross-entropy loss function. Specifi-\ncally, we give each negative example an adaptive weight, \nwhich is shown as follows:\nwhere yi is the label of the input element ei , pi is the prob-\nability that ei is predicted to be positive, /u1D6FE is a hyperpa-\nrameter, and /u1D6FE and pi determine the weight of the negative \nelement ei . Suppose that the label yi of the input element \nei is 0. When the predicted value pi is larger, the greater \nweight (i.e., exp (/u1D6FEâ‹…pi) ) is added to the loss of this negative \nexample, which can make the prediction more accurate and \ncan greatly reduce the FPR.\n3.2.6  Out ofÂ Distribution Detection\nLearned Bloom filter can iteratively improve its perfor -\nmance through the learning process. Nevertheless, in prac-\ntical scenarios with a high volume of queries, the system \nmay encounter out-of-distribution (OOD) queries that do \nnot conform to the original data distribution. These que-\nries may lead to false positives, potentially compromising \nthe Bloom filterâ€™s reliability and performance. Therefore, \nestablishing mechanisms for detecting and handling OOD \nqueries is essential to ensure the accuracy and robustness \nof the Bloom filter.\nWe have adopted a loss-based OOD detection mechanism \nto identify whether OOD situations exist, by establishing \na sampling distribution for new and old data using their \naverage loss values, and conducting statistical tests on the (10)Lossfocal=1\nN/uni2211.s1\niâˆ’[(1 âˆ’pi)/u1D6FEâ‹…yi\nlog(pi)+( pi)/u1D6FEâ‹…(1âˆ’yi)â‹…log(1 âˆ’pi)]\n(11)Lossada=1\nN/uni2211.s1\niâˆ’/bracketleft.s1yiâ‹…log(pi)+exp(/u1D6FEâ‹…pi)â‹…(1âˆ’yi)â‹…log(1 âˆ’pi)/bracketright.s1,distribution[15]. Specifically, we maintain two sets, Sold and \nSnew , each containing N bootstrapped samples of new and \nold data, respectively. Note that the bootstrapped samples \nhere refer to a batch of resampled samples. When detection \nis necessary, we calculate the standard deviation std based \non the sampling distribution of Snew . Periodically, we use the \nlatest converged model to calculate the average loss value for \neach sample in both sets and create a sampling distribution. \nWe then use the linear difference between the average loss \nvalues of bootstrapped samples from new and old data as the \ntest statistic as follows:\nwhere L is the loss function used for training the model with \nparameter /u1D703 . Finally, we compare the test statistic and the \nthreshold, and if d(Sold,Snew)>2Ã—std , which is equivalent \nto p-value <ð›¿ where /u1D6FF=0.5 in a two-sample test proce-\ndure, we consider that the data have undergone a signifi-\ncant change and issue an OOD signal, update the model \naccordingly.\n3.3  Multiâ€‘key Bloom Filter\nIn this section, we present the details of the multi-key bloom \nfilter part of the model. The Multi-key Bloom Filter (MBF) \ncontains a bitmap of m -bit size. When the processed multi-\nkey contains c  keys, MBF will create c  hash function fami-\nlies, and all hash functions are independent of each other. \nThe most basic operations of MBF are Insert (S, e) and \nQuery( S,eq ), where S is the element member set.\nInsert( S, e): For each element e={k1,k2, ...,kc} that \nneeds to be inserted into S , each key is associated with a \nfamily of hash functions. For the i -th key value in e , we use \nthe i-th hash function family to hash it to the specific posi-\ntions MBF [hi1(e[i])] ,MBF [hi2(e[i])] ,..., MBF [hik(e[i])]  in the \nbitmap, and set corresponding positions to 1.\nQuery(S, eq ): The Query operation is similar \nto the Insert operation. It also calculates the posi-\ntions hi1(ei),hi2(ei), ..., hik(ei) of eq after being \nhashed by multiple hash function families. Then, \nMBF will check whether the corresponding bits \nMBF [hi1(ei)],MBF [hi2(ei)], ..., MBF [hik(ei)] are all 1 in the \nbitmap. If they are, eq exists, otherwise it will return it does \nnot exist.\n3.3.1  Intervalâ€‘Based Optimization\nMBF uses the same number of hash functions for all keys, \nwithout considering the data distribution of each key. In fact, \nthe data distribution of each key is not consistent, e.g., some (12)d(Sold,Snew)=/uni007C.x/uni007C.x/uni007C.x/uni007C.x/uni007C.x/uni007C.x1\n/uni007C.varSold/uni007C.var/uni2211.s1\nsâˆˆSoldL(s;/u1D703)âˆ’1\n/uni007C.varSnew/uni007C.var/uni2211.s1\nsâˆˆSnewL(s;/u1D703)/uni007C.x/uni007C.x/uni007C.x/uni007C.x/uni007C.x/uni007C.x\n\n240 H.Â Chen et al.\n1 3\nkeys are uneven, and others are uniform. Considering this \nsituation, we propose an Interval-based Multi-key Bloom \nFilter (IMBF). IMBF divides the key into specific intervals \naccording to the data distribution, where different intervals \nuse different numbers of hash functions.\nMore specifically, suppose that each element has c  keys. \nFor the i-th key, the probability that the bit is still not set to \n1 after being hashed k times is as follows:\nAfter inserting n  elements, the probability that a bit is still \n1 is as follows:\nwhere nj is the number of distinct elements in the i -th key. \nAfter inserting n  multi-key elements, the total number of \nhashes is âˆ‘c\nj=1njkj . Therefore, for the i -th key, the expected \nvalue of its FPR is expressed as follows:\nWe assume that the data distributions of all keys are inde-\npendent with each other, which is reasonable in practice. \nWe can get the FPR of all keys as follows, where Pi=nj\nn , \nand n is the total number of multi-keys. For simplicity, we \nassume that the total number of hash functions for all keys \nis a constant Ksum , i.e., Ksum=âˆ‘c\ni=1ki.\nAt this point, we can transform the problem that aims to \nminimize {E(FPR)}  into the problem that is to minimize \n{âˆ‘c\nj=1njkj} . According to the AM-GM inequality, when \nnjkjâ‰¥0 , there is an inequality âˆ‘c\nj=1njkjâ‰¥cï¿½âˆc\ni=1njkj , and \nthe two items are equal if and only if each item on the left \nside is equal. Therefore, in order to achieve the optimization \ngoal min{âˆ‘c\nj=1njkj} , we need to set a smaller kj for a larger \nnj , and a larger kj for a smaller nj.\nEmpirically, for a small amount of data, we can directly \ncalculate the size of nj . If the amount of data is huge, we \ncan use sampling or some cardinality estimation methods \nsuch as HyperLogLog CountingÂ [16] and Adaptive Count-\ningÂ [17]. In the experiments of this paper, we use the method \nof sampling estimation.\nBased on this idea, we can further simplify our model. \nThe ratio of the number of unique elements to the total /parenleft.s2\n1âˆ’1\nm/parenright.s2k\n1âˆ’ï¿½\n1âˆ’1\nmï¿½âˆ‘c\nj=1njkj\n(13) E(FRPi)=ï¿½\n1âˆ’ï¿½\n1âˆ’1\nmï¿½âˆ‘c\nj=1njkjï¿½ki\n(14)E(FRP )=pï¿½\ni=1E(FPRi)=ï¿½\n1âˆ’ï¿½\n1âˆ’1\nmï¿½âˆ‘c\nj=1njkjï¿½âˆ‘c\ni=1ki\nâ‰ˆï¿½\n1âˆ’eâˆ’1\nmâˆ‘c\nj=1njkjï¿½Ksumâ‰ˆï¿½\n1âˆ’eâˆ’n\nmâˆ‘c\nj=1Pjkjï¿½Ksumnumber of elements is P . We can divide P  into intervals and \nuse different numbers of hash functions for different inter -\nvals. For simplicity, we give an interval division parameter \nI. When I =4, we divide the interval of P  into four parts, \nnamely I1=[0, 25%), I2=[25%, 50%), I3 = [50%, 75%) and \nI4=[75%, 100%]. Based on the previous derivation, I4 uses \nfewer hash functions, and I1 uses more hash functions. We \nset the number of hash functions between the two intervals \nto differ by 1. Combining with the learned classifier (i.e., \nVIMC in Sect.Â  3.2), we have an improved MLBF called \nInterval-based Multi-key Learned Bloom Filter (IMLBF).\n4  Experimental Evaluation\nWe evaluate the performance of the multi-key classifier, \nand the multi-key Bloom filter on real data, respectively. \nAll experiments are implemented on Intel(R) Core(TM) \ni7-10700 CPU @ 2.90GHz with 32 GB RAM.\n4.1  Datasets\nWe use three datasets, IMDBmovies, CriteoCTR , and Mali-\nciousURLs, to simulate multi-key inserts and queries. The \nfirst two datasets are employed to simulate key forecasting \nscenarios, given the significant amount of missing data in \nboth sets. The URL dataset, encompassing all available data, \nis employed to evaluate the performance of MLBF under \nhigh query load and exemplify its application in malicious \nwebsite identification.\n4.1.1  IMDBmovies\nIMDBmovies  comes from IMDB,1 an online database of \nmovies, television programs, etc. IMDBmovies has 80,Â 000 \nmovie reviews, each with information such as movie length, \naverage rating, and number of directors/actors. Each data \nelement contains string, number, and other types of fields, \nwhich meets the multi-key membership testing scenarios. \nWe remove redundant elements and the columns with mas-\nsive missing values. We treat the original data as positive \nsamples. Since the dataset does not contain explicit negative \ndata, we randomly select an element from each column to \nform a new element as a negative sample.\n4.1.2  Criteo CTR \nCriteo CTR  is an online advertising dataset released by \nCriteo Labs.2 It contains feature values and click feedback \n1 https:// www. imdb. com/.\n2 https:// labs. criteo. com/.\n\n241 Deep Learning-Based Bloom Filter forÂ Efficient Multi-key Membership Testing  \n1 3\nof display ads, and this dataset can be used as a benchmark \nfor click-through rate (CTR) prediction. Each advertisement \nhas the function of describing data. To simulate multi-key \nmembership testing, the advertisements with a label of 0 \nare regarded as negative samples, and others are regarded \nas positive samples.\n4.1.3  MaliciousURLs\nMaliciousURLs consists of a total of 651,191 URLs, includ-\ning 428,103 benign URLs, 96,457 defacement URLs, 94,111 \nphishing URLs, and 32,520 malware URLs, which has been \npublished on Kaggle.3 We classify all the malicious URLs as \npositive samples, while categorizing the rest benign URLs \nas negative samples. Moreover, to assess the performance of \nour method in multi-key scenarios, we will divide each URL \ninto various keys, such as hostname and port.\n4.2  Experiment Results\n4.2.1  Performance ofÂ VIMC\nIn this set of experiments, we evaluate the performance of \nthe multi-key classifier. Firstly, we compare our method with \nthe baseline methods on the real-world datasets. Secondly, \nwe verify the effectiveness of each component of the pro-\nposed model through ablation experiments. Then, we show \nthe FPR of VIMC at different thresholds to demonstrate the \nsignificant effect of the proposed model on reducing FPR. \nFinally, we analyze the hyperparameter settings of /u1D6FE for dif-\nferent loss functions to prove that our loss function can fur -\nther reduce FPR.\nAccuracy of VIMC In order to verify the effectiveness \nof our proposed Value-Interaction-based Multi-key Classi-\nfier (VIMC) model, we introduce five mainstream models as \nbaselines, including DeepFMÂ [10], DNNÂ [18], LSTMÂ [19], \nLinearÂ [20] and Random Forest (RF)Â [21].\nWe use accuracy to evaluate the performance of the six \nmethods, which is a commonly-used metric to measure the \nperformance of deep learning models and can be calculated \nas follows:\nwhere TP is the number of true positives, TN is the number \nof true negatives, P  is the number of positives, and N  is the \nnumber of negatives.\nWe report the accuracy of the methods in Fig.Â  3. It is \nobvious that, on both datasets, our proposed VIMC has \nthe best performance. VIMC outperforms the best (i.e., (15) Accuracy =(TP+TN)âˆ•(P +N)DeepFM) among the baseline methods by 2.95%  , 0.97%  and \n2.24%  on IMDBmovies, Criteo CTR  and MaliciousURLs, \nrespectively. Since both datasets contain a large portion of \nmissing attributes, it is a good evidence for the effectiveness \nof VIMC in reducing FPR of MLBF and IMLBF for partial \nkey queries.\nAblation Study In this experiment, we conduct detailed \nablation study by comparing the accuracy(ACC) and binary \ncross-entropy loss (BCE) of different the proposed model \nvariants on both datasets.\nWe first introduce the three variants each with an opti-\nmization component removed. VIMC-DeepFM is a variant \nbased on VIMC, removing DeepFM Encoder. The variant \nnamed VIMC-pskd removes the progressive self-knowledge \ndistillation from VIMC. And VIMC-DeepFM-pskd means \nboth components are removed.\nAs expected, all three variants perform worse than VIMC. \nAs shown in TableÂ  1, no matter which part is removed, the \naccuracy decreases and the loss increases. Specifically, after \ndeleting the DeepFM and the progressive self-knowledge \ndistillation from VIMC, the accuracy drops by about 1.6%, \n1.0% and 1.5%, while the binary cross-entropy loss increases \nby about 0.04, 0.02 and 0.02 on the IMDBmovies, Criteo  \nCTR  and MaliciousURLs datasets, respectively. Therefore, \nwe verify that both components of our proposed model are \nable to learn value interactions from the data and enhance \nthe performance of multi-key classifier.\nFPR of VIMC  We now evaluate accuracy (ACC) and false \npositive rate (FPR) of VIMC at different thresholds. Results \nare reported in TableÂ  2. Through this experiment, we can \neffectively evaluate the ability of VIMC to reduce false posi -\ntives. The threshold varies in the range of [0.5, 0.9]. It can \nbe seen from the table that as the threshold increases, the \naccuracy of VIMC decreases, but the FPR of VIMC also \ndecreases. A higher threshold can effectively reduce the \nfalse positives produced by VIMC, which is very important \nfor LBF. At the same time, we can also see that even if the \nthreshold is set to 0.9, the attenuation of model capability \nis still acceptable.Fig. 3  Model accuracy comparison\n3 https:// www. kaggle. com/ datas ets/ sid32 1axn/ malic ious- urls- datas  \net/.\n\n242 H.Â Chen et al.\n1 3\nEffect of /u1D6FE . /u1D6FE is the hyperparameter of loss function in \nthe weighted methods. We compare the level of FPR reduc-\ntion in focal loss and adaptive loss at different /u1D6FE . In this \nexperiment, we train the model at different /u1D6FE (0, 0.2, 0.5, 1.0, \n1.5, 2.0, 5.0) while keeping other parameters unchanged. \nIn addition, VIMC means that no weighted loss function is \nused. So there is no change in VIMC when /u1D6FE increases. As \nillustrated in Fig.Â  4, both focal loss and adaptive loss meth-\nods show decreasing FPR with increasing /u1D6FE . But the FPR \nof our proposed method on all datasets drops significantly \nfaster than focal loss. In particular, when /u1D6FE=5 , the FPR \nvalues of our method are 4.95%  , 11, 71%  , 1.23%  lower than \nfocal loss on IMDBmovies, Criteo CTR , and MaliciousURLs, \nrespectively. Because our method can adaptively weight \nnegative examples for different prediction probability inter -\nvals, it can effectively reduce FPR. In another word, VIMC \nbased on adaptive negative weighted method can be used as a multi-key classifier with extremely low FPR level, which \nis well adapted to bloom filter.\nOOD Detection Sensitivity To evaluate the sensitivity of \nthe OOD detection module, we conducted experiments by \nrandomly selecting 20% of the dataset as test data, which \nmimics new batches of data that may be encountered in the \nfuture. Within this test data, we randomly selected a subset \nof samples with a proportion equivalent to the ratio /u1D6FD of \nthe entire dataset, and modified them to deviate from the \noriginal distribution. The performance of the OOD detec-\ntion component was evaluated on the same trained model, \nand the experimental results were reported in TableÂ  3. If \ndâˆ’2Ã—std>0 , it is deemed that out-of-distribution (OOD) \nhas occurred.\nThe relative accuracy here reflects the change in model \naccuracy before and after inserting out-of-distribution \n(OOD) data. Experimental results on three datasets show Table 1  Ablation study results \nbased VIMC\nBold represents the best performance amongst all competitorsDataset IMDBmovies Criteo CTR Malicious URLs\nModels ACC (%) BCE ACC (%) BCE ACC (%) BCE\nVIMC-DeepFM 91.87 0.2357 76.39 0.4706 92.03 0.1897\nVIMC-pskd 92.13 0.2115 76.54 0.4654 92.53 0.1828\nVIMC-DeepFM-pskd 91.23 0.2437 75.89 0.4852 91.82 0.1927\nVIMC 92.81 0.2079 76.86 0.4643 93.30 0.1736\nTable 2  FPR of VIMC at \ndifferent thresholdsDataset IMDBmovies Criteo CTR Malicious URLs\nThreshold /u1D70F ACC (%) FPR (%) ACC (%) FPR (%) ACC (%) FPR (%)\n0.50 92.81 9.44 76.86 21.38 93.30 3.52\n0.55 92.49 8.28 76.46 15.12 92.25 2.81\n0.60 91.91 7.04 74.59 10.35 91.78 2.29\n0.65 91.15 5.92 72.23 6.76 91.22 1.84\n0.70 89.82 5.14 69.16 4.17 89.22 1.13\n0.75 87.78 4.19 65.61 2.19 88.32 0.97\n0.80 85.13 3.04 61.70 1.00 87.22 0.77\n0.85 81.15 1.97 57.54 0.47 85.31 0.56\n0.90 73.98 1.07 54.14 0.13 84.22 0.39\nFig. 4  Effect of /u1D6FE\n\n243 Deep Learning-Based Bloom Filter forÂ Efficient Multi-key Membership Testing  \n1 3\nthat the modelâ€™s accuracy significantly degrades when \nencountering OOD data. Nevertheless, the OOD detection \nmethod we adopted is effective in identifying this situa-\ntion and does not generate false positives for minor data \nperturbations.\n4.2.2  Performance ofÂ Multiâ€‘key Learned Bloom Filter.\nIn this set of experiments, we evaluate the performance of \nmulti-key Bloom filter. Two main metrics are compared for \nthe above methods, i.e., False Positive Rate (FPR), and CPU \ntime for a query. We perform all negative queries and report \nthe average CPU time for a query. We study the following \ndata structures. \n(1) SMBF The Standard Multi-key Bloom Filter data struc-\nture that uses only a single Bloom filter, which has the \nsame structure and settings with the Bloom filter in our \nMLBF.\n(2) IMBF Our Interval-based Multi-key Bloom Filter. This \ndata structure uses the interval-based optimization \nmethod on the basis of SMBF\n(3) Ada-BF Ada-BF adjusts FPR adaptively by tuning the \nnumber of hash functions in different regionsÂ [8 ]. The \nclassifier used in this study is random forest. To facili-\ntate multi-key membership testing for Ada-BF, the keys \nof each query in the dataset used for the study are con-\ncatenated.(4) MLBF Our Multi-key Learned Bloom Filter. This vari-\nant of SMBF includes the predictor part, i.e., VIMC.\n(5) IMLBF Our Interval-based Multi-key Learned Bloom \nFilter, which uses the interval-based optimization \nmethod on the basis of MLBF.\nIn the following, we first study the effect of I , a parameter in \nthe interval-based optimization method denoting the num-\nber of intervals, to validate the sensitivity of both metrics \nto I. Then, we evaluate the performance of our proposed \ndata structures after using two optimization methods. All the \nabove experiments are performed on three datasets.\nEffect of I . In IMBF, we obtain lower FPR by using dif-\nferent number of hash functions for different keys, and we \nuse the hyperparameter I  to adjust the number of hash func-\ntions. To facilitate the experiment, we compare only MBF \nand IMBF in this section, which are the Bloom filter parts \nof MLBF and IMLBF, respectively. As shown in Figs.Â  5 and \n6, we compare the FPR and CPU time of MBF and IMBF \nwith different I  by changing the bitmap size from 150Kb to \n240Kb. As we increase the bitmap size, all methods show a \ndecreasing trend in FPR, because a larger bitmap implies a \nsmaller hash function collision probability. At the same time, \nthe CPU time of all methods shows a decreasing trend when \nthe bitmap size is larger since it means that the probability \nof a bit being 0 is also greater. When querying whether the \nelement exists, if the bit of a mapping is 0, the methods \ndirectly return the result that the data do not exist, i.e., a Table 3  Sensitivity of OOD \ndetectionDataset IMDBmovies Criteo CTR Malicious URLs\n/u1D6FD Rel ACC (%) dâˆ’2Ã—std Rel ACC (%) dâˆ’2Ã—std Rel ACC (%) dâˆ’2Ã—std\n0.20 âˆ’39.32 0.6199 âˆ’25.33 0.1666 âˆ’23.27 0.6234\n0.15 âˆ’29.78 0.3891 âˆ’19.19 0.1018 âˆ’18.23 0.3452\n0.10 âˆ’19.44 0.1921 âˆ’13.29 0.0446 âˆ’13.24 0.1778\n0.05 âˆ’10.38 0.0455 âˆ’6.19 âˆ’0.00372 âˆ’7.32 0.0821\n0.025 âˆ’5.16 âˆ’0.0285 âˆ’3.06 âˆ’0.0343 âˆ’3.44 âˆ’0.0439\n0.015 âˆ’3.11 âˆ’0.0432 âˆ’2.02 âˆ’0.0559 âˆ’2.11 âˆ’0.0626\n0.010 âˆ’1.94 âˆ’0.0539 âˆ’1.25 âˆ’0.0574 âˆ’0.95 âˆ’0.0788\nFig. 5  Effect of I on FPR\n\n244 H.Â Chen et al.\n1 3\nlarger bitmap leads to a higher probability of taking less time \nto return the result. Also, when fixing the size of the bitmap, \nit can be seen that a larger hyperparameter I  corresponds to \na smaller FPR, which is consistent with the results derived \nfrom Eq.Â  14.\nComparison of Different Methods.We proceed to com -\npare the FPR and CPU time for four methods at different \nbitmap sizes, namely SMBF, Ada-BF, MLBF and IMLBF. \nThe CPU time for all LBF-related data structures includes \nthe time spent on model predictions. This experiment also \nstrictly adhered to the parameter settings stated at the begin-\nning of Sect.Â  4.2.2. As shown in Figs.Â  7 and 8 , with our \nproposed multi-key classifier (i.e., VIMC), the FPR of all \nlearned BF reduced remarkably, at the price of minor extra \nCPU cost. We also observe that IMLBF always performs \nbetter than others in terms of FPR, regardless of the bitmap \nsize, which shows the superiority of our optimization strate-\ngies. Moreover, with the growing bitmap size, the CPU time \ndecreases for all methods, which is due to the fact that larger \nbitmaps are more likely to return results earlier in a query. And the FPR of all methods shows a decreasing trend as the \nbitmap size increases. For the same reason as in the previ-\nous experiment, because a larger bitmap means that the hash \nfunction is more likely to be collision-free, there is a smaller \nprobability of a false positive occurring. Experiments on the \nMaliciousURLs  dataset demonstrate the proposed methodâ€™s \nability to maintain a low FPR and achieve a running time of \napproximately 0.1 ms when dealing with large-scale data-\nsets and high query loads. This suggests that the method is \nfeasible for online membership testing scenarios, e.g., the \nidentification of malicious websites.\n5  Related Work\n5.1  Bloom Filter\nBloom Filter (BF)Â [1 ] was designed by Bloom in 1970 and \nis widely used for membership testing that is deployed in \nvarious domains. For example, some website servers use BF \nFig. 6  Effect of I on CPU time\nFig. 7  Comparison of different methods on FPR\nFig. 8  Comparison of different methods on CPU time\n\n245 Deep Learning-Based Bloom Filter forÂ Efficient Multi-key Membership Testing  \n1 3\nto lock malicious IP addressesÂ [22]. The distributed data-\nbases, such as Google BigtableÂ [23] and Apache Cassandra, \nuse BF to avoid unnecessary disk access to optimize their \nspace efficiency. Even BitcoinÂ [24] uses BF to determine \nwhether the wallet is synchronized successfully. To meet \ndifferent requirements (e.g., high lookup performance and \nlow memory consumption), various BF variants have been \nproposed. Compressed BFÂ [6 ] uses arithmetic encoding to \nfurther compress the space of BF.\n5.2  Learned Bloom Filter\nKraska etÂ al.Â [7 ] improve the traditional BF by adding a \nlearning classifier before the BF, where the classifier first \nlearns the data distribution when a new queried element \narrives and then determines whether the element exists in \na given element set. For non-existent elements, an addi -\ntional BF is used to determine whether they exist or not. \nThis improved BF is called Learned Bloom Filter (LBF). \nA large number of studiesÂ [8 , 25, 26] have proved that LBF \ncan optimize the traditional BF, especially in reducing FPR \nand memory consumption.\n6  Conclusion\nWe propose and offer solutions to a novel multi-key mem-\nbership testing problem. In order to achieve low False Posi-\ntive Rate (FPR) and low memory consumption, we give a \nMulti-key Learned Bloom Filter (MLBF) data structure that \ncombines a value-interaction-based multi-key classifier and \na tailor-made multi-key Bloom filter. Further, a improved \nMLBF data structure, i.e., Interval MLBF, is proposed to \nimprove the multi-key membership testing performance. To \nthe best of our knowledge, this is the first study that consid-\ners multi-key membership testing and multi-key learning \nBloom filter. An extensive empirical study with real data \noffers evidence that the paperâ€™s proposals can significantly \nreduce the FPR during membership query while offering \nacceptable query efficiency.\nAcknowledgements This work is partially supported by NSFC (Nos. \n61972069, 61836007, 61832017, 62272086), Shenzhen Municipal \nScience and Technology R &D Funding Basic Research Program \n(JCYJ20210324133607021), Municipal Government of Quzhou under \nGrant No. 2022D037, and Key Laboratory of Data Intelligence and \nCognitive Computing, Longhua District, Shenzhen.\nAuthor Contributions All authors contributed to the study conception \nand design. Data preparation, code implementation and data analysis \nwere performed by the first author, the second author, the third author \nand the fourth author. The first draft of the manuscript was written by \nthe first author and the third author, and all authors commented on \nprevious versions of the manuscript. All authors read and approved \nthe final manuscript.Data availability The authors confirm that the data supporting the find-\nings of this study are available within the article.\nDeclarations  \n Conflict of interest The authors have no financial, competing or pro-\nprietary interests in any material discussed in this article.\nOpen Access  This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. Bloom BH (1970) Space/time trade-offs in hash coding with \nallowable errors. Commun ACM 13(7):422â€“426\n 2. Fan L, Cao P, Almeida J, Broder AZ (1998) Summary cache: \na scalable wide-area web cache sharing protocol. SIGCOMM \n28(4):254â€“265\n 3. Putze F, Sanders P, Singler J (2010) Cache-, hash-, and space-\nefficient bloom filters. JEA 14:4â€“4\n 4. Bonomi F, Mitzenmacher M, Panigrahy R, Singh S, Varghese, G \n(2006) An improved construction for counting bloom filters. In: \nEuropean symposium on algorithms, pp 684â€“695\n 5. Fan B, Andersen DG, Kaminsky M, Mitzenmacher MD (2014) \nCuckoo filter: practically better than bloom. In: CoNEXT, pp \n75â€“88\n 6. Mitzenmacher M (2002) Compressed bloom filters. Trans Netw \n10(5):604â€“612\n 7. Kraska T, Beutel A, Chi EH, Dean J, Polyzotis N (2018) The case \nfor learned index structures. In: SIGMOD, pp 489â€“504\n 8. Dai Z, Shrivastava A (2020) Adaptive learned bloom filter (ada-\nbf): efficient utilization of the classifier with application to real-\ntime information filtering on the web. NIPS 33:11700â€“11710\n 9. Liu Q, Zheng L, Shen Y, Chen L (2020) Stable learned bloom \nfilters for data streams. PVLDB 13(12):2355â€“2367\n 10. Guo H, Tang R, Ye Y, Li Z, He X (2017) Deepfm: a factorization-\nmachine based neural network for ctr prediction. In: IJCAI, pp \n1725â€“1731\n 11. Khosla P, Teterwak P, Wang C, Sarna A, Tian Y, Isola P, Maschi-\nnot A, Liu C, Krishnan D (2020) Supervised contrastive learning. \nAdv Neural Inf Process Syst 33:18661â€“18673\n 12. Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez \nAN, Kaiser Å, Polosukhin I (2017) Attention is all you need. In: \nNIPS, pp 5998â€“6008\n 13. Kim K, Ji B, Yoon D, Hwang S (2021) Self-knowledge distillation \nwith progressive refinement of targets. In: ICCV, pp 6567â€“6576\n 14. Lin T-Y, Goyal P, Girshick R, He K, DollÃ¡r P (2017) Focal loss \nfor dense object detection. In: ICCV, pp 2980â€“2988\n 15. Kurmanji M, Triantafillou P (2022) Detect, distill and update: \nlearned db systems facing out of distribution data. arXiv preprint \narXiv: 2210. 05508\n 16. Flajolet P, Fusy Ã‰, Gandouet O, Meunier F (2007) Hyperloglog: \nthe analysis of a near-optimal cardinality estimation algorithm. \n\n246 H.Â Chen et al.\n1 3\nIn: Discrete Mathematics and Theoretical Computer Science, pp. \n137â€“156\n 17. Cai M, Pan J, Kwok Y-K, Hwang K (2005) Fast and accurate traf-\nfic matrix measurement using adaptive cardinality counting. In: \nSIGCOMM workshop, pp 205â€“206\n 18. LeCun Y, Jackel LD, Boser BE, Denker JS, Graf HP, Guyon I, \nHenderson D, Howard RE, Hubbard WE (1989) Handwritten digit \nrecognition: applications of neural network chips and automatic \nlearning. IEEE Commun Magaz 27:41â€“46\n 19. Hochreiter S, Schmidhuber J (1997) Long short-term memory. \nNeural Comput 9(8):1735â€“1780\n 20. Montgomery DC, Peck EA (2001) Introduction to linear regres-\nsion analysis 21. Rigatti SJ (2017) Random forest. J Insur Med 47(1):31â€“39\n 22. Geravand S, Ahmadi M (2013) Bloom filter applications in \nnetwork security: a state-of-the-art survey. Comput Netw \n57(18):4047â€“4064\n 23. Chang F, Dean J, Ghemawat S, Hsieh WC, Wallach DA, Burrows \nM, Chandra T, Fikes A, Gruber RE (2008) Bigtable: a distributed \nstorage system for structured data. TOCS 26(2):1â€“26\n 24. Nakamoto S (2008) Bitcoin: a peer-to-peer electronic cash system. \nDecentralized Business Review, 21260\n 25. Mitzenmacher M (2018) A model for learned bloom filters, and \noptimizing by sandwiching. In: NIPS, pp 462â€“471\n 26. Rae J, Bartunov S, Lillicrap T (2019) Meta-learning neural bloom \nfilters. In: ICML, pp 5271â€“5280",
  "textLength": 50512
}