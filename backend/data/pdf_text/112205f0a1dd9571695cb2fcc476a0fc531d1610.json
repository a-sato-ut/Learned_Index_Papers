{
  "paperId": "112205f0a1dd9571695cb2fcc476a0fc531d1610",
  "title": "Joint Optimization of Tree-based Index and Deep Model for Recommender Systems",
  "pdfPath": "112205f0a1dd9571695cb2fcc476a0fc531d1610.pdf",
  "text": "arXiv:1902.07565v2  [cs.IR]  20 Nov 2019Joint Optimization of Tree-based Index and Deep\nModel for Recommender Systems\nHan Zhu1, Daqing Chang1, Ziru Xu1,2∗, Pengye Zhang1\n1Alibaba Group\n2School of Software, Tsinghua University\nBeijing, China\n{zhuhan.zh, daqing.cdq, ziru.xzr, pengye.zpy }@alibaba-inc.com\nXiang Li, Jie He, Han Li, Jian Xu, Kun Gai\nAlibaba Group\nBeijing, China\n{yushi.lx, jay.hj, lihan.lh, xiyu.xj, jingshi.gk }@alibaba-inc.com\nAbstract\nLarge-scale industrial recommender systems are usually co nfronted with compu-\ntational problems due to the enormous corpus size. To retrie ve and recommend\nthe most relevant items to users under response time limits, resorting to an ef-\nﬁcient index structure is an effective and practical soluti on. The previous work\nTree-based Deep Model (TDM) [34] greatly improves recommen dation accuracy\nusing tree index. By indexing items in a tree hierarchy and tr aining a user-node\npreference prediction model satisfying a max-heap like pro perty in the tree, TDM\nprovides logarithmic computational complexity w.r.t. the corpus size, enabling the\nuse of arbitrary advanced models in candidate retrieval and recommendation.\nIn tree-based recommendation methods, the quality of both t he tree index and the\nuser-node preference prediction model determines the reco mmendation accuracy\nfor the most part. We argue that the learning of tree index and preference model\nhas interdependence. Our purpose, in this paper, is to devel op a method to jointly\nlearn the index structure and user preference prediction mo del. In our proposed\njoint optimization framework, the learning of index and use r preference prediction\nmodel are carried out under a uniﬁed performance measure. Be sides, we come\nup with a novel hierarchical user preference representatio n utilizing the tree in-\ndex hierarchy. Experimental evaluations with two large-sc ale real-world datasets\nshow that the proposed method improves recommendation accu racy signiﬁcantly.\nOnline A/B test results at a display advertising platform al so demonstrate the ef-\nfectiveness of the proposed method in production environme nts.\n1 Introduction\nRecommendation problem is basically to retrieve a set of mos t relevant or preferred items for each\nuser request from the entire corpus. In the practice of large -scale recommendation, the algorithm\ndesign should strike a balance between accuracy and efﬁcien cy. In corpus with tens or hundreds of\nmillions of items, methods that need to linearly scan each it em’s preference score for each single\nuser request are not computationally tractable. To solve th e problem, index structure is commonly\nused to accelerate the retrieval process. In early recommen der systems, item-based collaborative\n∗The work is done when she was a student intern in Alibaba Group\n33rd Conference on Neural Information Processing Systems ( NeurIPS 2019), Vancouver, Canada.\n\nﬁltering (Item-CF) along with the inverted index is a popula r solution to overcome the calculation\nbarrier [18]. However, the scope of candidate set is limited , because only those items similar to\nuser’s historical behaviors can be ultimately recommended .\nIn recent days, vector representation learning methods [27 , 16, 26, 5, 22, 2] have been actively re-\nsearched. This kind of methods can learn user and item’s vect or representations, the inner-product\nof which represents user-item preference. For systems that use vector representation based methods,\nthe recommendation set generation is equivalent to the k-ne arest neighbor (kNN) search problem.\nQuantization-based index [19, 14] for approximate kNN sear ch is widely adopted to accelerate the\nretrieval process. However, in the above solution, the vect or representation learning and the kNN\nsearch index construction are optimized towards different objectives individually. The objective\ndivergence leads to suboptimal vector representations and index structure [4]. An even more impor-\ntant problem is that the dependence on vector kNN search inde x requires an inner-product form of\nuser preference modeling, which limits the model capabilit y [10]. Models like Deep Interest Net-\nwork [32], Deep Interest Evolution Network [31] and xDeepFM [17], which have been proven to be\neffective in user preference prediction, could not be used t o generate candidates in recommendation.\nIn order to break the inner-product form limitation and make arbitrary advanced user preference\nmodels computationally tractable to retrieve candidates f rom the entire corpus, the previous work\nTree-based Deep Model (TDM) [34] creatively uses tree struc ture as index and greatly improves\nthe recommendation accuracy. TDM uses a tree index to organi ze items, and each leaf node in the\ntree corresponds to an item. Like a max-heap, TDM assumes tha t each user-node preference equals\nto the largest one among the user’s preference over all child ren of this node. In the training stage,\na user-node preference prediction model is trained to ﬁt the max-heap like preference distribution.\nUnlike vector kNN search based methods where the index struc ture requires an inner-product form\nof user preference modeling, there is no restriction on the f orm of preference model in TDM. And\nin prediction, preference scores given by the trained model are used to perform layer-wise beam\nsearch in the tree index to retrieve the candidate items. The time complexity of beam search in\ntree index is logarithmic w.r.t. the corpus size and no restr iction is imposed on the model structure,\nwhich is a prerequisite to make advanced user preference mod els feasible to retrieve candidates in\nrecommendation.\nThe index structure plays different roles in kNN search base d methods and tree-based methods. In\nkNN search based methods, the user and item’s vector represe ntations are learnt ﬁrst, and the vector\nsearch index is built then. While in tree-based methods, the tree index’s hierarchy also affects the\nretrieval model training. Therefore, how to learn the tree i ndex and user preference model jointly\nis an important problem. Tree-based method is also an active research topic in literature of extreme\nclassiﬁcation [29, 1, 24, 11, 8, 25], which is sometimes cons idered the same as recommendation\n[12, 25]. In the existing tree-based methods, the tree struc ture is learnt for a better hierarchy in\nthe sample or label space. However, the objective of sample o r label partitioning task in the tree\nlearning stage is not fully consistent with the ultimate tar get, i.e., accurate recommendation. The\ninconsistency between objectives of index learning and pre diction model training leads the overall\nsystem to a suboptimal status. To address this challenge and facilitate better cooperation of tree\nindex and user preference prediction model, we focus on deve loping a way to simultaneously learn\nthe tree index and user preference prediction model by optim izing a uniﬁed performance measure.\nThe main contributions of this paper are: 1) We propose a join t optimization framework to learn\nthe tree index and user preference prediction model in tree- based recommendation, where a uniﬁed\nperformance measure, i.e., the accuracy of user preference prediction is optimized; 2) We demon-\nstrate that the proposed tree learning algorithm is equival ent to the weighted maximum matching\nproblem of bipartite graph, and give an approximate algorit hm to learn the tree; 3) We propose a\nnovel method that makes better use of tree index to generate h ierarchical user representation, which\ncan help learn more accurate user preference prediction mod el; 4) We show that both the tree index\nlearning and hierarchical user representation can improve recommendation accuracy, and these two\nmodules can even mutually improve each other to achieve more signiﬁcant performance promotion.\n2\n\n1 2 3 5 6 7 4 8Item \nItems /gid3351\n2 3\n4 5 6 7\n8 9 10 11 12 13 14 15 Level 0 \nLevel 1 \nLevel 2 \nLevel 3(leaf) Scored and selected node \nUser preference prediction model \nNode Scored node Probability \nUser profile /gid335\n(a) (b) Level 0 \nLevel 1 \nLevel 2 \nLevel 3 \n/gid335\nUser behaviors /gid335/gid335\nHierarchical representation \nFigure 1: Tree-based deep recommendation model. (a) User pr eference prediction model. We ﬁrstly\nhierarchically abstract the user behaviors with nodes in co rresponding levels. Then the abstract user\nbehaviors and the target node together with the other featur e such as the user proﬁle are used as the\ninput of the model. (b) Tree hierarchy. Each item is ﬁrstly as signed to a different leaf node with a\nprojection function π(·). In retrieval stage, items that assigned to the red nodes in t he leaf level are\nselected as the candidate set.\n2 Joint Optimization of Tree-based Index and Deep Model\nIn this section, we ﬁrstly give a brief review of TDM [34] to ma ke this paper self-contained. Then we\npropose the joint learning framework of the tree-based inde x and deep model. In the last subsection,\nwe specify the hierarchical user preference representatio n used in model training.\n2.1 Tree-based Deep Recommendation Model\nIn recommender systems with large-scale corpus, how to retr ieve candidates effectively and efﬁ-\nciently is a challenging problem. TDM uses a tree as index and proposes a max-heap like probability\nformulation in the tree, where the user preference for each n on-leaf node nin levellis derived as:\np(l)(n|u) =maxnc∈{n′schildren in level l+1}p(l+1)(nc|u)\nα(l)(1)\nwherep(l)(n|u)is the ground truth probability that the user uprefers the node n.α(l)is a level\nnormalization term. The above formulation means that the gr ound truth user-node probability on a\nnode equals to the maximum user-node probability of its chil dren divided by a normalization term.\nTherefore, the top-k nodes in level lmust be contained in the children of top-k nodes in level l−1,\nand the retrieval for top-k leaf items can be restricted to re cursive top-k nodes retrieval top-down in\neach level without losing the accuracy. Based on this, TDM tu rns the recommendation task into a\nhierarchical retrieval problem, where the candidate items are selected gradually from coarse to ﬁne.\nThe candidate generating process of TDM is shown in Fig 1.\nEach item is ﬁrstly assigned to a leaf node in the tree hierarc hyT. A layer-wise beam search strategy\nis carried out as shown in Fig1(b). For level l, only the children of nodes with top-k probabilities in\nlevell−1are scored and sorted to pick kcandidate nodes in level l. This process continues until k\nleaf items are reached. User features combined with the cand idate node are used as the input of the\nprediction modelM(e.g. fully-connected networks) to get the preference prob ability, as shown in\nFig 1(a). With tree index, the overall retrieval complexity for a user request is reduced from linear\nto logarithmic w.r.t. the corpus size, and there is no restri ction on the preference model structure.\nThis makes TDM break the inner-product form of user preferen ce modeling restriction brought by\nvector kNN search index and enable arbitrary advanced deep m odels to retrieve candidates from the\nentire corpus, which greatly raises the recommendation acc uracy.\n2.2 Joint Optimization Framework\nDerive the training set that has nsamples as{(u(i),c(i))}n\ni=1, in which the i-th pair(u(i),c(i))means\nthe useru(i)is interested in the target item c(i). For(u(i),c(i)), tree hierarchyTdetermines the path\nthat prediction model Mshould select to achieve c(i)foru(i). We propose to jointly learn Mand\n3\n\nAlgorithm 1: Joint learning framework of the tree index and deep model\nInput: Loss functionL(θ,π), initial deep model Mand initial treeT\n1:fort= 0,1,2...do\n2: SolveminθL(θ,π)by optimizing the model M.\n3: Solvemaxπ−L(θ,π)by optimizing the tree hierarchy with Algorithm 2\n4:end for\nOutput: Learned modelMand treeT\nTunder a global loss function. As we will see in experiments, j ointly optimizingMandTcould\nimprove the ultimate recommendation accuracy.\nGiven a user-item pair (u,c), denotep(π(c)|u;π)as useru’s preference probability over leaf node\nπ(c)whereπ(·)is a projection function that projects an item to a leaf node i nT. Note that π(·)\ncompletely determines the tree hierarchy T, as shown in Fig 1(b). And optimizing Tis actu-\nally optimizing π(·). The modelMestimates the user-node preference ˆp(π(c)|u;θ,π), givenθ\nas model parameters. If the pair (u,c)is a positive sample, we have the ground truth preference\np(π(c)|u;π) = 1 following the multi-class setting [5, 2]. According to the m ax-heap property, the\nuser preference probability of all π(c)’s ancestor nodes, i.e., {p(bj(π(c))|u;π)}lmax\nj=0should also be\n1, in which bj(·)is the projection from a node to its ancestor node in level jandlmax is the max\nlevel inT. To ﬁt such a user-node preference distribution, the global loss function is formulated as\nL(θ,π) =−n/summationdisplay\ni=1lmax/summationdisplay\nj=0log ˆp/parenleftBig\nbj(π(c(i)))|u(i);θ,π/parenrightBig\n, (2)\nwhere we sum up the negative logarithm of predicted user-nod e preference probability on all the\npositive training samples and their ancestor user-node pai rs as the global empirical loss.\nOptimizing π(·)is a combinational optimization problem, which can hardly b e simultaneously op-\ntimized with θusing gradient-based algorithms. To conquer this, we propo se a joint learning frame-\nwork as shown in Algorithm 1. It alternatively optimizes the loss function (2)with respect to the\nuser preference model and the tree hierarchy. The consisten cy of the training loss in model training\nand tree learning promotes the convergence of the framework . Actually, Algorithm 1 surely con-\nverges if both the model training and tree learning decrease the value of (2) since {L(θt,πt)}is a\ndecreasing sequence and lower bounded by 0. In model training, minθL(θ,π)is to learn a user-node\npreference model for all levels, which can be solved by popul ar optimization algorithms for neural\nnetworks such as SGD[3], Adam[15]. In the normalized user pr eference setting [5, 2], since the\nnumber of nodes increases exponentially with the node level , Noise-contrastive estimation[7] is an\nalternative to estimate ˆp(bj(π(c))|u;θ,π)to avoid calculating the normalization term by sampling\nstrategy. The task of tree learning is to solve maxπ−L(θ,π)givenθ.maxπ−L(θ,π)equals to the\nmaximum weighted matching problem of bipartite graph that c onsists of items in the corpus Cand\nthe leaf nodes ofT2. The detailed proof is shown in the supplementary material.\nTraditional algorithms for assignment problem such as the c lassic Hungarian algorithm are hard\nto apply for large corpus because of their high complexities . Even for the naive greedy algorithm\nthat greedily chooses the unassigned edge with the largest w eight, a big weight matrix needs to\nbe computed and stored in advance, which is not acceptable. T o conquer this issue, we propose a\nsegmented tree learning algorithm.\nInstead of assigning items directly to leaf nodes, we achiev e this step-by-step from the root node to\nthe leaf level. Given a projection πand thek-th itemckin the corpus, denote\nLs,e\nck(π) =/summationdisplay\n(u,c)∈Ake/summationdisplay\nj=slog ˆp(bj(π(c))|u;θ,π),\nwhereAk={(u(i),c(i))|c(i)=ck}n\ni=1is the set of training samples whose target item is ck,s\nandeare the start and end level respectively. We ﬁrstly maximize/summationtext|C|\nk=1L1,d\nck(π)w.r.t.π, which is\n2For convenience, we assume Tis a given complete binary tree. It is worth mentioning that t he proposed\nalgorithm can be naturally extended to multi-way trees.\n4\n\nAlgorithm 2: Tree learning algorithm\nInput: Gapd, max tree level lmax, original projection πold\nOutput: Optimized projection πnew\n1:Set current level l←d, initialize πnew←πold\n2:whiled >0do\n3: foreach node niin levell−ddo\n4: DenoteCnias the item set that ∀c∈Cni,bl−d(πnew(c)) =ni\n5: Findπ∗that maximize/summationtext\nc∈CniLl−d+1,l\nc(π), s.t.∀c∈Cni,bl−d(π∗(c)) =ni\n6: Updateπnew.∀c∈Cni,πnew(c)←π∗(c)\n7: end for\n8:d←min(d,lmax−l)\n9:l←l+d\n10:end while\nequivalent to assign all the items to nodes in level d. For a complete binary tree Twith max level\nlmax, each node in level dis assigned with no more than 2lmax−ditems. This is also a maximum\nmatching problem which can be efﬁciently solved by a greedy a lgorithm, since the number of pos-\nsible locations for each item is largely decreased if dis well chosen (e.g. for d= 7, the number is\n2d= 128 ). Denote the found optimal projection in this step as π∗. Then, we successively maximize/summationtext|C|\nk=1Ld+1,2d\nck(π)under the constraint that ∀c∈C,bd(π(c)) =bd(π∗(c)), which means keeping\neach item’s corresponding ancestor node in level dunchanged. The recursion stops until each item\nis assigned to a leaf node. The proposed algorithm is detaile d in Algorithm 2.\nIn line 5 of Algorithm 2, we use a greedy algorithm with rebala nce strategy to solve the sub-problem.\nEach item c∈Cniis ﬁrstly assigned to the child of niin levellwith largest weight Ll−d+1,l\nc(·).\nThen, a rebalance process is applied to ensure that each chil d is assigned with no more than 2lmax−l\nitems. The detailed implementation of Algorithm 2 is given i n the supplementary material.\n2.3 Hierarchical User Preference Representation\nAs shown in Section 2.1, TDM is a hierarchical retrieval mode l to generate the candidate items hier-\narchically from coarse to ﬁne. In retrieval, a layer-wise to p-down beam search is carried out through\nthe tree index by the user preference prediction model M. Therefore,M′stask in each level are\nheterogeneous. Based on this, a level-speciﬁc input of Mis necessary to raise the recommendation\naccuracy.\nA series of related work [30, 6, 18, 16, 32, 33, 34] has shown th at the user’s historical be-\nhaviors play a key role in predicting the user’s interests. H owever, in our tree-based approach\nwe could even enlarge this key role in a novel and effective wa y. Given a user behavior se-\nquencec={c1,c2,···,cm}whereciis thei-th item the user interacts, we propose to use\ncl={bl(π(c1)),bl(π(c2)),···,bl(π(cm))}as user’s behavior feature in level l.cltogether with\nthe target node and other possible features such as user proﬁ le are used as the input of Min level\nlto predict the user-node preference, as shown in Fig 1(a). In addition, since each node or item is\na one-hot ID feature, we follow the common way to embed them in to continuous feature space. In\nthis way, the ancestor nodes of items the user interacts are u sed as the hierarchical user preference\nrepresentation. Generally, the hierarchical representat ion brings two main beneﬁts:\n1.Level independence . As in the common way, sharing item embeddings between diffe rent levels\nwill bring noises in training the user preference predictio n modelM, because the targets differ\nfor different levels. An explicit solution is to attach an it em with an independent embedding for\neach level. However, this will greatly increase the number o f parameters and make the system\nhard to optimize and apply. The proposed hierarchical repre sentation uses node embeddings in\nthe corresponding level as the input of M, which achieves level independence in training without\nincreasing the number of parameters.\n2.Precise description .Mgenerates the candidate items hierarchically through the t ree. With the\nincrease of retrieval level, the candidate nodes in each lev el describe the ultimate recommended\nitems from coarse to ﬁne until the leaf level is reached. The p roposed hierarchical user preference\nrepresentation grasps the nature of the retrieval process a nd gives a precise description of user\n5\n\nbehaviors with nodes in corresponding level, which promote s the predictability of user preference\nby reducing the confusion brought by too detailed or coarse d escription. For example, M’s task in\nupper levels is to coarsely select a candidate set and the use r behaviors are also coarsely described\nwith homogeneous node embeddings in the same upper levels in training and prediction.\nExperimental study in both Section 3 and the supplementary m aterial will show the signiﬁcant ef-\nfectiveness of the proposed hierarchical representation.\n3 Experimental Study\nWe study the performance of the proposed method both ofﬂine a nd online in this section. We ﬁrstly\ncompare the overall performance of the proposed method with other baselines. Then we conduct\nexperiments to verify the contribution of each part and conv ergence of the framework. At last, we\nshow the performance of the proposed method in an online disp lay advertising platform with real\ntrafﬁc.\n3.1 Experiment Setup\nThe ofﬂine experiments are conducted with two large-scale r eal-world datasets: 1) Amazon\nBooks3[20, 9], a user-book review dataset made up of product review s from Amazon. Here we\nuse its largest subset Books; 2) UserBehavior4[34], a subset of Taobao user behavior data. These\ntwo datasets both contain millions of items and the data is or ganized in user-item interaction form:\neach user-item interaction consists of user ID, item ID, cat egory ID and timestamp. For the above\ntwo datasets, only users with no less than 10interactions are kept.\nTo evaluate the performance of the proposed framework, we co mpare the following methods:\n•Item-CF [28] is a basic collaborative ﬁltering method and is widely u sed for personalized recom-\nmendation especially for large-scale corpus [18].\n•YouTube product-DNN [5] is a practical method used in YouTube video recommendati on. It’s\nthe representative work of vector kNN search based methods. The inner-product of the learnt\nuser and item’s vector representation reﬂects the preferen ce. And we use the exact kNN search to\nretrieve candidates in prediction.\n•HSM [21] is the hierarchical softmax model. It adopts the multip lication of layer-wise conditional\nprobabilities to get the normalized item preference probab ility.\n•TDM [34] is the tree-based deep model for recommendation. It ena bles arbitrary advanced mod-\nels to retrieve user interests using the tree index. We use th e proposed basic DNN version of TDM\nwithout tree learning and attention.\n•DNN is a variant of TDM without tree index. The only difference is that it directly learns a user-\nitem preference model and linearly scan all items to retriev e the top-k candidates in prediction.\nIt’s computationally intractable in online system but a str ong baseline in ofﬂine comparison.\n•JTM is the proposed joint learning framework of the tree index an d user preference prediction\nmodel. JTM-J andJTM-H are two variants. JTM-J jointly optimizes the tree index and user\npreference prediction model without the proposed hierarch ical representation in Section 2.3. And\nJTM-H adopts the hierarchical representation but use the ﬁxed ini tial tree index without tree\nlearning.\nFollowing TDM [34], we split users into training, validatio n and testing sets disjointly. Each user-\nitem interaction in training set is a training sample, and th e user’s behaviors before the interaction\nare the corresponding features. For each user in validation and testing set, we take the ﬁrst half of\nbehaviors along the time line as known features and the latte r half as ground truth.\nTaking advantage of TDM’s open source work5, we implement all methods in Alibaba’s deep learn-\ning platform X-DeepLearning (XDL). HSM, DNN and JTM adopt th e same user preference predic-\ntion model with TDM. We deploy negative sampling for all meth ods except Item-CF and use the\nsame negative sampling ratio. 100negative items in Amazon Books and 200in UserBehavior are\n3http://jmcauley.ucsd.edu/data/amazon\n4http://tianchi.aliyun.com/dataset/dataDetail?dataId =649&userId=1\n5http://github.com/alibaba/x-deeplearning/tree/maste r/xdl-algorithm-solution/TDM\n6\n\nsampled for each training sample. HSM, TDM and JTM require an initial tree in advance of training\nprocess. Following TDM, we use category information to init ialize the tree structure where items\nfrom the same category aggregate in the leaf level. More deta ils and codes about data pre-processing\nand training are listed in the supplementary material.\nPrecision, Recall and F-Measure are three general metrics a nd we use them to evaluate the perfor-\nmance of different methods. For a user u, supposePu(|Pu|=M) is the recalled set and Guis the\nground truth set. The equations of three metrics are\nPrecision@M(u) =|Pu∩Gu|\n|Pu|,Recall@M(u) =|Pu∩Gu|\n|Gu|\nF-Measure @M(u) =2∗Precision@M(u)∗Recall@M(u)\nPrecision@M(u)+Recall@M(u)\nThe results of each metric are averaged across all users in th e testing set, and the listed values are\nthe average of ﬁve different runs.\n3.2 Comparison Results\nTable 1 exhibits the results of all methods in two datasets. I t clearly shows that our proposed JTM\noutperforms other baselines in all metrics. Compared with t he previous best model DNN in two\ndatasets, JTM achieves 45.3%and9.4%recall lift in Amazon Books and UserBehavior respectively.\nTable 1: Comparison results of different methods in Amazon B ooks and UserBehavior ( M= 200 ).\nMethodAmazon Books UserBehavior\nPrecision Recall F-Measure Precision Recall F-Measure\nItem-CF 0.52% 8.18% 0.92% 1.56% 6.75% 2.30%\nYouTube product-DNN 0.53% 8.26% 0.93% 2.25% 10.15% 3.36%\nHSM 0.42% 6.22% 0.72% 1.80% 8.62% 2.71%\nTDM 0.50% 7.49% 0.88% 2.23% 10.84% 3.40%\nDNN 0.56% 8.57% 0.98% 2.81% 13.45% 4.23%\nJTM-J 0.51% 7.60% 0.89% 2.48% 11.72% 3.73%\nJTM-H 0.68% 10.45% 1.19% 2.66% 12.93% 4.02%\nJTM 0.79% 12.45% 1.38% 3.11% 14.71% 4.68%\nAs mentioned before, though computationally intractable i n online system, DNN is a signiﬁcantly\nstrong baseline for ofﬂine comparison. Comparison results of DNN and other methods give insights\nin many aspects.\nFirstly, gap between YouTube product-DNN and DNN shows the l imitation of inner-product form.\nThe only difference between these two methods is that YouTub e product-DNN uses the inner-\nproduct of user and item’s vectors to calculate the preferen ce score, while DNN uses a fully-\nconnected network. Such a change brings apparent improveme nt, which veriﬁes the effectiveness of\nadvanced neural network over inner-product form.\nNext, TDM performs worse than DNN with an ordinary but not opt imized tree hierarchy. Tree hi-\nerarchy takes effect in both training and prediction proces s. User-node samples are generated along\nthe tree to ﬁt max-heap like preference distribution, and la yer-wise beam search is deployed in the\ntree index when prediction. Without a well-deﬁned tree hier archy, user preference prediction model\nmay converge to a suboptimal version with confused generate d samples, and it’s possible to lose\ntargets in the non-leaf levels so that inaccurate candidate sets may be returned. Especially in sparse\ndataset like Amazon Books, learnt embedding of each node in t ree hierarchy is not distinguishable\nenough so that TDM doesn’t perform well than other baselines . This phenomenon illustrates the\ninﬂuence of tree and necessity of tree learning. Additional ly, HSM gets much worse results than\nTDM. This result is consistent with that reported in TDM[34] . When dealing with large corpus, as\na result of layer-wise probability multiplication and beam search, HSM cannot guarantee the ﬁnal\nrecalled set to be optimal.\nBy joint learning of tree index and user preference model, JT M outperforms DNN on all met-\nrics in two datasets with much lower retrieval complexity . More precise user preference predic-\n7\n\ntion model and better tree hierarchy are obtained in JTM, whi ch leads a better item set selection.\nHierarchical user preference representation alleviates t he data sparsity problem in upper levels, be-\ncause the feature space of user behavior feature is much smal ler while having the same number\nof samples. And it helps model training in a layer-wise way to reduce the propagation of noises\nbetween levels. Besides, tree hierarchy learning makes sim ilar items aggregate in the leaf level,\nso that the internal level models can get training samples wi th more consistent and unambiguous\ndistribution. Beneﬁted from the above two reasons, JTM prov ides better results than DNN.\nResults in Table 1 under the dash line indicate the contribut ion of each part and their joint perfor-\nmance in JTM. Take the recall metric as an example. Compared t o TDM in UserBehavior, tree\nlearning and hierarchical representation of user preferen ce brings 0.88% and2.09% absolute gain\nseparately. Furthermore, 3.87% absolute recall promotion is achieved by the corporation of both\noptimizations under a uniﬁed objective. Similar gain is obs erved in Amazon Books. The above\nresults clearly show the effectiveness of hierarchical rep resentation and tree learning, as well as the\njoint learning framework.\nConvergence of Iterative Joint Learning Tree hierarchy determines sample generation and\nsearch path. A suitable tree would beneﬁt model training and inference a great deal. Fig 2 gives\nthe comparison of clustering-based tree learning algorith m proposed in TDM [34] and our proposed\njoint learning approach. For fairness, two methods both ado pt hierarchical user representation.\nSince the proposed tree learning algorithm has the same obje ctive with the user preference prediction\nmodel, it has two merits from the results: 1) It can converge t o an optimal tree stably; 2) The ﬁnal\nrecommendation accuracy is higher than the clustering-bas ed method. From Fig 2, we can see that\nresults increase iteratively on all three metrics. Besides , the model stably converges in both datasets,\nwhile clustering-based approach ultimately overﬁts. The a bove results demonstrate the effectiveness\nand convergence of iterative joint learning empirically. S ome careful readers might have noticed\nthat the clustering algorithm outperforms JTM in the ﬁrst fe w iterations. The reason is that the tree\nlearning algorithm in JTM involves a lazy strategy , i.e., try to reduce the degree of tree structure\nchange in each iteration (details are given in the supplemen tary material).\n0123456789100.65%0.70%0.75%0.80%\nJoint Learning\nClustering\n(a) Precision01234567891010.2%11.1%11.9%12.7%\nJoint Learning\nClustering\n(b) Recall0123456789101.16%1.24%1.32%1.40%\nJoint Learning\nClustering\n(c) F-Measure\n0123456789102.62%2.80%2.98%3.16%\nJoint Learning\nClustering\n(d) Precision01234567891012.8%13.5%14.2%14.9%\nJoint Learning\nClustering\n(e) Recall0123456789103.94%4.20%4.46%4.72%\nJoint Learning\nClustering\n(f) F-Measure\nFigure 2: Results of iterative joint learning in two dataset s (M= 200 ). 2(a), 2(b), 2(c) are results in\nAmazon Books and 2(d), 2(e), 2(f) shows the performance in Us erBehavior. The horizontal axis of\neach ﬁgure represents the number of iterations.\n3.3 Online Results\nWe also evaluate the proposed JTM in production environment s: the display advertising scenario\nofGuess What You Like column of Taobao App Homepage. We use click-through rate (CT R) and\nrevenue per mille (RPM) to measure the performance, which ar e the key performance indicators.\n8\n\nThe deﬁnitions are:\nCTR=# of clicks\n# of impressions,RPM=Ad revenue\n# of impressions∗1000\nIn the platform, advertisers bid on plenty of granularities like ad clusters, items, shops, etc. Several\nsimultaneously running recommendation approaches in all g ranularities produce candidate sets and\nthe combination of them are passed to subsequent stages, lik e CTR prediction [32, 31, 23], ranking\n[33, 13], etc. The comparison baseline is such a combination of all running recommendation meth-\nods. To assess the effectiveness of JTM, we deploy JTM to repl ace Item-CF, which is one of the\nmajor candidate-generation approaches in granularity of i tems in the platform. TDM is evaluated\nin the same way as JTM. The corpus to deal with contains tens of millions of items. Each com-\nparison bucket has 2%of the online trafﬁc, which is big enough considering the ove rall page view\nrequest amount. Table 2 lists the promotion of the two main on line metrics. 11.3%growth on CTR\nexhibits that more precise items have been recommended with JTM. As for RPM, it has a 12.9%\nimprovement, indicating JTM can bring more income for the pl atform.\nTable 2: Online results from Jan 21 to Jan 27, 2019.\nMetric Baseline TDM JTM\nCTR 0.0% +5.4% +11.3%\nRPM 0.0% +7.6% +12.9%\n4 Conclusion\nRecommender system plays a key role in various kinds of appli cations such as video streaming\nand e-commerce. In this paper, we address an important probl em in large-scale recommendation,\ni.e., how to optimize user representation, user preference prediction and the index structure under\na global objective. To the best of our knowledge, JTM is the ﬁr st work that proposes a uniﬁed\nframework to integrate the optimization of these three key f actors. A joint learning approach of the\ntree index and user preference prediction model is introduc ed in this framework. The tree index\nand deep model are alternatively optimized under a global lo ss function with a novel hierarchical\nuser representation based on the tree index. Both online and ofﬂine experimental results show the\nadvantages of the proposed framework over other large-scal e recommendation models.\nAcknowledgements\nWe deeply appreciate Jingwei Zhuo, Mingsheng Long, Jin Li fo r their helpful suggestions and dis-\ncussions. Thank Huimin Yi, Yang Zheng and Xianteng Wu for imp lementing the key components\nof the training and inference platform. Thank Yin Yang, Limi ng Duan, Yao Xu, Guan Wang and\nYue Gao for necessary supports about online serving.\nReferences\n[1] R. Agrawal, A. Gupta, Y . Prabhu, and M. Varma. Multi-labe l learning with millions of labels: recom-\nmending advertiser bid phrases for web pages. In WWW , pages 13–24, 2013.\n[2] A. Beutel, P. Covington, S. Jain, C. Xu, J. Li, V . Gatto, an d E. H. Chi. Latent cross: Making use of context\nin recurrent recommender systems. In WSDM , pages 46–54, 2018.\n[3] L. Bottou. Large-scale machine learning with stochasti c gradient descent. In COMPSTAT , pages 177–186.\n2010.\n[4] Y . Cao, M. Long, J. Wang, H. Zhu, and Q. Wen. Deep quantizat ion network for efﬁcient image retrieval.\nInAAAI , pages 3457–3463, 2016.\n[5] P. Covington, J. Adams, and E. Sargin. Deep neural networ ks for youtube recommendations. In RecSys ,\npages 191–198, 2016.\n[6] J. Davidson, B. Liebald, J. Liu, P. Nandy, T. V . Vleet, U. G argi, S. Gupta, Y . He, M. Lambert, B. Liv-\ningston, and D. Sampath. The youtube video recommendation s ystem. In RecSys , pages 293–296, 2010.\n[7] M. Gutmann and A. Hyv¨ arinen. Noise-contrastive estima tion: A new estimation principle for unnormal-\nized statistical models. In AISTATS , pages 297–304, 2010.\n9\n\n[8] L. Han, Y . Huang, and T. Zhang. Candidates vs. noises esti mation for large multi-class classiﬁcation\nproblem. In ICML , pages 1885–1894, 2018.\n[9] R. He and J. McAuley. Ups and downs: Modeling the visual ev olution of fashion trends with one-class\ncollaborative ﬁltering. In WWW , pages 507–517, 2016.\n[10] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T. Chua. Neural collaborative ﬁltering. In WWW , pages\n173–182, 2017.\n[11] H. D. III, N. Karampatziakis, J. Langford, and P. Mineir o. Logarithmic time one-against-some. In ICML ,\npages 923–932, 2017.\n[12] H. Jain, Y . Prabhu, and M. Varma. Extreme multi-label lo ss functions for recommendation, tagging,\nranking & other missing label applications. In KDD , pages 935–944, 2016.\n[13] J. Jin, C. Song, H. Li, K. Gai, J. Wang, and W. Zhang. Real- time bidding with multi-agent reinforcement\nlearning in display advertising. In CIKM , pages 2193–2201, 2018.\n[14] J. Johnson, M. Douze, and H. J´ egou. Billion-scale simi larity search with gpus. arXiv preprint\narXiv:1702.08734 , 2017.\n[15] D. P. Kingma and J. Ba. Adam: A method for stochastic opti mization. In ICLR , 2015.\n[16] Y . Koren, R. M. Bell, and C. V olinsky. Matrix factorizat ion techniques for recommender systems. IEEE\nComputer , 42(8):30–37, 2009.\n[17] J. Lian, X. Zhou, F. Zhang, Z. Chen, X. Xie, and G. Sun. xde epfm: Combining explicit and implicit\nfeature interactions for recommender systems. In KDD , pages 1754–1763, 2018.\n[18] G. Linden, B. Smith, and J. York. Amazon.com recommenda tions: Item-to-item collaborative ﬁltering.\nIEEE Internet Computing , 7(1):76–80, 2003.\n[19] T. Liu, A. W. Moore, A. G. Gray, and K. Yang. An investigat ion of practical approximate nearest neighbor\nalgorithms. In NeurIPS , pages 825–832, 2004.\n[20] J. J. McAuley, C. Targett, Q. Shi, and A. van den Hengel. I mage-based recommendations on styles and\nsubstitutes. In SIGIR , pages 43–52, 2015.\n[21] F. Morin and Y . Bengio. Hierarchical probabilistic neu ral network language model. In AISTATS , 2005.\n[22] S. Okura, Y . Tagami, S. Ono, and A. Tajima. Embedding-ba sed news recommendation for millions of\nusers. In KDD , pages 1933–1942, 2017.\n[23] Q. Pi, W. Bian, G. Zhou, X. Zhu, and K. Gai. Practice on lon g sequential user behavior modeling for\nclick-through rate prediction. In KDD , pages 2671–2679, 2019.\n[24] Y . Prabhu and M. Varma. Fastxml: a fast, accurate and sta ble tree-classiﬁer for extreme multi-label\nlearning. In KDD , pages 263–272, 2014.\n[25] Y . Prabhu, A. Kag, S. Harsola, R. Agrawal, and M. Varma. P arabel: Partitioned label trees for extreme\nclassiﬁcation with application to dynamic search advertis ing. In WWW , pages 993–1002, 2018.\n[26] S. Rendle. Factorization machines. In ICDM , pages 995–1000, 2010.\n[27] R. Salakhutdinov and A. Mnih. Probabilistic matrix fac torization. In NeurIPS , pages 1257–1264, 2007.\n[28] B. M. Sarwar, G. Karypis, J. A. Konstan, and J. Riedl. Ite m-based collaborative ﬁltering recommendation\nalgorithms. In WWW , pages 285–295, 2001.\n[29] J. Weston, A. Makadia, and H. Yee. Label partitioning fo r sublinear ranking. In ICML , pages 181–189,\n2013.\n[30] S. Zhang, L. Yao, and A. Sun. Deep learning based recomme nder system: A survey and new perspectives.\narXiv preprint arXiv:1707.07435 , 2017.\n[31] G. Zhou, N. Mou, Y . Fan, Q. Pi, W. Bian, C. Zhou, X. Zhu, and K. Gai. Deep interest evolution network\nfor click-through rate prediction. arXiv preprint arXiv:1809.03672 , 2018.\n[32] G. Zhou, X. Zhu, C. Song, Y . Fan, H. Zhu, X. Ma, Y . Yan, J. Ji n, H. Li, and K. Gai. Deep interest network\nfor click-through rate prediction. In KDD , pages 1059–1068, 2018.\n[33] H. Zhu, J. Jin, C. Tan, F. Pan, Y . Zeng, H. Li, and K. Gai. Op timized cost per click in taobao display\nadvertising. In KDD , pages 2191–2200, 2017.\n[34] H. Zhu, X. Li, P. Zhang, G. Li, J. He, H. Li, and K. Gai. Lear ning tree-based deep model for recommender\nsystems. In KDD , pages 1079–1088, 2018.\n10",
  "textLength": 38403
}