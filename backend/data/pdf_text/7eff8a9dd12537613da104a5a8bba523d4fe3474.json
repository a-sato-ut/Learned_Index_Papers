{
  "paperId": "7eff8a9dd12537613da104a5a8bba523d4fe3474",
  "title": "Online Metric Algorithms with Untrusted Predictions",
  "pdfPath": "7eff8a9dd12537613da104a5a8bba523d4fe3474.pdf",
  "text": "Online Metric Algorithms withUntrusted Predictions\nANTONIOSANTONIADIS, Universityof Twente,Netherlands\nCHRISTIANCOESTER, Universityof Oxford,UnitedKingdom\nMAREK ELIÁŠ, Bocconi University,Italy\nADAMPOLAK, Max Planck Institute forInformatics,Germanyand JagiellonianUniversity,Poland\nBERTRANDSIMON, IN2P3ComputingCenter, CNRS, France\nMachine-learnedpredictors,althoughachievingverygoodresultsforinputsresemblingtrainingdata,cannotpossiblyprovide\nperfectpredictionsinallsituations.Still,decision-makingsystemsthatarebasedonsuchpredictorsneednotonlybeneit\nfrom good predictions, but should also achieve a decent performance when the predictions are inadequate. In this paper, we\npropose a prediction setup for arbitrary metrical task systems (MTS) (e.g.,caching,-serverandconvex body chasing ) and\nonlinematchingontheline .Weutilizeresultsfromthetheoryofonlinealgorithmstoshowhowtomakethesetuprobust.\nSpeciically for caching, we present analgorithm whose performance, as a function of theprediction error,is exponentially\nbetterthanwhatisachievableforgeneralMTS.Finally,wepresentanempiricalevaluationofourmethodsonrealworld\ndatasets,whichsuggestspracticality.\nCCS Concepts:· Theory ofcomputation →Online algorithms ; ·Computingmethodologies →Machinelearning .\nAdditionalKey WordsandPhrases:metrical tasksystems,caching, competitive analysis\n1 INTRODUCTION\nMetricaltasksystems(MTS),introducedbyBorodinetal . [12],arearichclasscontainingseveralfundamental\nproblemsinonlineoptimizationasspecialcases,including caching,-server,convexbodychasing ,andconvex\nfunction chasing . MTS are capable of modeling many problems arising in computing and production systems\n[48,55],movementsofservicevehicles[ 22,25],powermanagementofembeddedsystemsaswellasdatacenters\n[33,43],and arealsorelatedto the expertsproblem in online learning, see[10,24].\nInitially, we are given a metric space ofstates, which can be interpreted for example as actions, investment\nstrategies,orconigurationsofsomeproductionmachine.Westartatapredeinedinitialstate 0.Ateachtime\n=1,2,...,wearepresentedwitha costfunction ℓ:→R+∪{0,+∞}andourtaskistodecideeithertostayat\n−1andpaythecost ℓ(−1),ortomovetosomeother(possiblycheaper)state andpaydist(−1,)+ℓ(),\nwheredist(−1,)is the cost of the transition between states −1and. The objective is to minimize the\noverall costincurredovertime.\nGiventhatMTSisanonlineproblem,oneneedstomakeeachdecisionwithoutanyinformationaboutthe\nfuturecostfunctions.Thismakestheproblemsubstantiallydiicult,assupportedbystronglowerboundsfor\nAuthors’ addresses: Antonios Antoniadis, University of Twente, Drienerlolaan 5, Enschede, Netherlands, 7522 NB, a.antoniadis@utwente.nl;\nChristian Coester, University of Oxford, Parks Road, OX1 3QD, Oxford, United Kingdom, christian.coester@cs.ox.ac.uk; Marek Eliáš, Bocconi\nUniversity, Milan, Via Roentgen, 1, 20136, Italy, marek.elias@unibocconi.it; Adam Polak, Max Planck Institute for Informatics, Campus E1 4,\n66123,Saarbrücken,GermanyandJagiellonianUniversity,Łojasiewicza6,30-348,Kraków,Poland,apolak@mpi-inf.mpg.de,polak@tcs.uj.edu.\npl;BertrandSimon,IN2P3Computing Center,CNRS, 21 avenue PierredeCoubertin, Villeurbanne, 69627,France, bertrand.simon@cnrs.fr.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that\ncopies are not made or distributed for proit or commercial advantage and that copies bear this notice and the full citation on the irst page.\nCopyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy\notherwise, orrepublish, topostonserversor toredistributetolists,requires priorspeciicpermissionand/ora fee.Requestpermissions from\npermissions@acm.org.\n© 2023Copyrightheld by the owner/author(s).Publication rights licensed to ACM.\n1549-6325/2023/2-ART $15.00\nhttps://doi.org/10.1145/3582689\nACM Trans. Algor.\n\n\n2 • Antoniadis et al.\ngeneralMTS[ 12]aswellasformanyspecialMTSproblems[seee.g. 27,37].FortherecentworkonMTS,see\nBubecket al. [14], Bubeckand Rabani [15], Coesterand Lee[23].\nIn this paper, we study how to utilize predictors (possibly based on machine learning) in order to decrease\nthe uncertainty about the future and achieve a better performance for MTS. We propose a natural prediction\nsetup for MTS and show how to develop algorithms in this setup with the following properties of consistency (i),\nsmoothness (ii), androbustness (iii).\n(i) Theirperformancewithperfectpredictions iscloseto optimal.\n(ii)With decreasing accuracy of the predictions, their performance deteriorates smoothly as a function of the\npredictionerror.\n(iii)When given poor predictions, their performance is comparable to that of the best online algorithm which\ndoesnot use predictions.\nCaching and weighted caching problems, which are special cases of MTS, have already been studied in\nthis context of utilizing predictors [ 6,35,46,53,56]. However, the corresponding prediction setups do not\nseem applicable to general MTS. For example, algorithms by Lykouris and Vassilvitskii [46]and Rohatgi [53]\nprovidesimilarguaranteesbyusingpredictionsofthenextreoccurrencetimeofthecurrentpageintheinput\nsequence.However,asweshowinthispaper,suchpredictionsarenotusefulformoregeneralMTS:evenfor\nweighted caching, they do not help to improve upon the bounds achievable without predictions unless additional\nassumptions aremade(see[6] foran exampleof such an assumption).\nWeproposeapredictionsetupbasedon actionpredictions where,ateachtimestep,thepredictortriestopredict\ntheactionthatanolinealgorithmwouldhavetaken.Wecanviewthesepredictionsasrecommendationsof\nwhatouralgorithmshoulddo.Weshowthatusingthispredictionsetup,wecanachieveconsistency,smoothness,\nandrobustnessforanyMTS.Forthe(unweighted)cachingproblem,wedevelopanalgorithmthatobtainsabetter\ndependencyonthepredictionerrorthanourgeneralresult,andwhoseperformanceinempiricaltestsiseither\nbetterorcomparabletothealgorithmsbyLykourisandVassilvitskii [46]andRohatgi [53].Thisdemonstratesthe\nlexibilityofour setup. We would liketo stressthat speciically for thecaching problem,theactionpredictions\ncanbeobtainedbysimplyconvertingthereoccurrencetimepredictionsusedin[ 46,53,56],afeaturethatweuse\nin orderto compareour results to those previous algorithms. Nevertheless our prediction setup isapplicable to\nthemuchbroadercontextofMTS.WedemonstratethisandsuggestpracticabilityofouralgorithmsalsoforMTS\notherthancachingbyprovidingexperimentalresultsforthe icecream problem[ 19],asimpleexampleofanMTS.\nFinally, weextendour theoretical resultbeyond MTS to onlinematching on the line .\nActionPredictions for MTS. Ateach time ,thepredictor proposesan action,i.e.,a state in themetric space\n. Wedeine the prediction error with respectto some oline algorithm Offas\n=︁\n=1;=dist(,), (1)\nwheredenotesthestateof Offat timeanddenotesthelength of theinput sequence.\nThe predictions could be, for instance, the output of a machine-learned model or actions of a heuristic which\ntendstoproducegoodsolutionsinpractice,butpossiblywithoutatheoreticalguarantee.Theolinealgorithm Off\ncan be an optimal one, but also other options are plausible. For example, if the typical instances are composed of\nsubpatternsknownfromthepastandforwhichgoodsolutionsareknown,then Offcouldalsobeanear-optimal\nalgorithm which composes its output from the partial solutions to the subpatterns. The task of the predictor\ninthiscaseistoanticipatewhichsubpatternisgoingtofollowandprovidetheprecomputedsolutiontothat\nsubpattern. In the case of the caching problem, as mentioned above and explained in Section 1.3, we can actually\nconvertthereoccurrence predictions [46,53, 56] into action predictions.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions • 3\nNotethat,even ifthepredictionerrorwithrespectto Offislow,thecostofthesolutioncomposedfromthe\npredictions 1,...,canbemuchhigherthanthecostincurredby Off,sinceℓ()canbemuchlargerthan\nℓ()even ifdist(,)is small. However, wecandesign algorithms which usesuchpredictions and achievea\ngood performance whenever the predictions have small error with respect to any low-cost oline algorithm. We\naimatexpressingtheperformanceoftheprediction-basedalgorithmsasafunctionof /Off,where(abusing\nnotation) Offdenotes the costoftheoline algorithm.Thisis toavoid scaling issues: if the oline algorithm\nincurs movement cost 1000, predictions with total error =1give us a rather precise estimate of its state, unlike\nwhenOff=0.1.\nCachingProblem. Inthecachingproblemwehaveatwo-levelcomputermemory,outofwhichthefastone\n(cache)canonlystore pages.Weneedtoanswerasequenceofrequeststopages.Sucharequestrequiresno\naction and incurs no cost if the page is already in the cache, but otherwise a page fault occurs and we have\nto add the page and evict some other page at a cost of 1. Caching can be seen as an MTS whose states are\ncache conigurations1. Therefore, also the predictions are cache conigurations in our setup, but as we discuss in\nSection1.3theycan be encodedmuchmore succinctly than specifying the fullcache content ineachtime step.\nThe error describes in this case the number of pages on which the predicted cache and the cache of Offdifer\nat time.\n1.1 OurResults\nWeprovetwogeneraltheoremsproviding robustness and consistency guaranteesforany MTS.\nTheorem1. Letbeadeterministic -competitiveonlinealgorithmforaproblem belongingtoMTS.Given\naction predictions for ,thereisadeterministicalgorithm achieving competitiveratio\n9·min{,1+4/Off}\nagainst any oline algorithm Off,whereisthe prediction errorwith respect to Off.\nRoughlyspeaking,thecompetitiveratio(formallydeinedinSection2)istheworstcaseratiobetweenthecost\noftwo algorithms.If Offis anoptimal algorithm,then the expressionin the theoremis the overall competitive\nratioof theprediction-basedalgorithm.\nTheorem2. Letbea randomized -competitiveonline algorithm foranMTS with metric space diameter .\nFor any≤1/4,givenaction predictions for thereisarandomized algorithm achieving cost\n(1+)·min{,1+4/Off}·Off+(/),\nwhereis the prediction error with respect to an oline algorithm Off. Thus, ifOffis(near-)optimal and ≪Off,\nthe competitiveratio isclose to 1+.\nWenote thatthe proofsofthese theoremsarebasedon thepowerfulresultsbyFiat etal . [29]and Blumand\nBurch[10]. In Theorem 20, we show that the dependence on /Offin the preceding theorems is tight up to\nconstantfactorsforsome MTS instance.\nFor some speciic MTS, however, the dependence on /Offcan be improved, as shown in Section 3, where we\npresentanewalgorithmforcachingwhosecompetitiveratiohasalogarithmicdependenceon /Off.Oneofthe\nmain characteristics of our algorithm, which we call Trust&Doubt, compared to previous approaches, is that it\nisableto gradually adaptitsleveloftrustinthepredictorthroughouttheinstance.Showingthatourgeneral\npredictionsetupcanbeusedtodesignsucheicientalgorithmsforcachingisthemostinvolvedresultofour\npaper, so thefollowing resultisprovedbeforeTheorems1 and 2.\n1Acache coniguration is the setofpagesin cache.\nACM Trans. Algor.\n\n\n4 • Antoniadis et al.\nTheorem3. Forcachingwithactionpredictions,thereisarandomizedalgorithmwithcompetitiveratio min/braceleftbig\n(\nOff),()/bracerightbig\nagainst any algorithm Off, where(\nOff) ≤(log\nOff)is the smoothness with prediction error and() ≤\n(log())isthe robustnesswith cachesize .\nWedonotattempttooptimizeconstant factorsintheproofofTheorem3,butweremarkthat canbechosen\nsuch that (0)=1+, for arbitrary >0. The reason is that our algorithm in the proof of Theorem 3 can be\nusedasalgorithm inTheorem 2.\nAlthough we designed our prediction setup with MTS in mind, it can also be applied to problems beyond MTS.\nWedemonstratethisinSection5byemployingourtechniquestoprovideanalgorithmofsimilarlavorfor online\nmatching on the line , a problem not knownto bean MTS.\nTheorem 4. For online matching on the line with action predictions, there is a deterministic algorithm with\ncompetitiveratio (min{log,1+/Off}),whereisthepredictionerrorwithrespecttosomeolinealgorithm\nOff.\nWe also showthatTheorem 4can be generalized togive a (min{2−1,/Off})-competitive algorithmfor\nonlinemetricbipartite matching .\nIn Section C, we show that the reoccurrence time predictions introduced by Lykouris and Vassilvitskii [46]for\ncaching donot help formoregeneralMTS.\nTheorem5. Thecompetitiveratioofanyalgorithmforweightedcachingevenifprovidedwithprecisereoccurrence\ntimepredictions is Ω(log).\nNote that there are (log)-competitive online algorithms for weighted caching which do not use any\npredictions[see 5].Thismotivatestheneedforadiferentpredictionsetupasintroducedinthispaper.Thislower\nboundresulthasbeenobtainedindependentlybyJiangetal . [35]whoalsoprovedalowerboundof Ω()for\ndeterministicalgorithms withprecise reoccurrencetimepredictions.However,forinstanceswithonly ℓweight\nclasses, Bansal et al . [6]showed that perfect reoccurrence time predictions allow achieving a competitive ratio of\nΘ(logℓ).\nWe round up by presentingan extensive experimental evaluationof our results thatsuggests practicality.We\ntest the performance of our algorithms on public data with previously used models. With respect to caching,\nour algorithms outperform all previous approaches in most settings (and are always at least comparable). A\nvery interesting use of our setup is that it allows us to employ any other online algorithm as a predictor for\nour algorithm. For instance, when using the Least Recently Used (LRU) algorithm ś which is considered the\ngoldstandardinpractice ś asapredictor for ouralgorithm,our experiments suggestthat we achieve thesame\npractical performance as LRU, but with an exponential improvement in the theoretical worst-case guarantee\n((log)instead of ). Finallyweappliedour general algorithmsto asimple MTScalledthe ice cream problem\nand wereable to obtain results thatalsosuggestpracticality of our setup beyond caching.\n1.2 RelatedWork\nOur work is part of a larger and recent movement to prove rigorous performance guarantees for algorithms\nbased on machine learning. The irst main results have been established on both classical [see 38,40] and online\nproblems:LykourisandVassilvitskii [46]andRohatgi [53]oncaching,Lattanzietal .[41]onrestrictedassignment\nscheduling, Purohit et al . [51]on ski rental and non-clairvoyant scheduling, Gollapudi and Panigrahi [32]on ski\nrental with multiple predictors, Mitzenmacher [50]on scheduling/queuing, and Medina and Vassilvitskii [49]on\nrevenue optimization.\nMost of the online results are analyzed by means of consistency (competitive ratio in the case of perfect\npredictions)and robustness (worst-casecompetitive-ratioregardlessofpredictionquality),whichwasirstdeined\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions • 5\ninthiscontextbyPurohitetal .[51],whileMitzenmacher [50]usesadiferentmeasurecalled priceofmisprediction .\nIt should be noted that the exact deinitions of consistency and robustness are slightly inconsistent between\ndiferentworks intheliterature, makingitoften diicult to directlycompareresults.\nResults on Caching. Among the closest results to our work are the ones by Lykouris and Vassilvitskii [46]and\nRohatgi[53], who study the caching problem (a special case of MTS) with machine learned predictions. Lykouris\nandVassilvitskii [46]introducedthefollowingpredictionsetupforcaching:wheneverapageisrequested,the\nalgorithm receives a prediction of the time when the same page will be requested again. The prediction error is\ndeinedasthe ℓ1-distancebetweenthe predictionsandthetruth,i.e.,thesumśoverall requestsśoftheabsolute\ndiferencebetweenthepredictedandtherealreoccurrencetimeofthesamerequest.Forthispredictionsetup,\ntheyadaptedtheclassicMarkeralgorithminordertoachieve,uptoconstantfactors,thebestrobustnessand\nconsistency possible. In particular, they achieved a competitive ratio of /︁arenleftbig1+min{︁\n/Opt,log}/︁arenrightbigand their\nalgorithmwasshowntoperformwellinexperiments.Later,Rohatgi [53]achievedabetterdependencyonthe\npredictionerror: /︁arenleftbig1+min/braceleftbiglog\n\nOpt,log/bracerightbig/︁arenrightbig. He alsoprovides a closelowerbound.\nFollowingtheoriginalannouncementofourwork,welearnedaboutfurtherdevelopmentsbyWei [56]and\nJiangetal .[35].Wei[56]furtherreinedtheaforementionedresultsforcachingwithreoccurrencetimepredictions.\nThepaperbyJiangetal .[35]proposesanalgorithmforweightedcachinginaverystrongpredictionsetup,where\nthe predictor reports at each time step the reoccurrence time of the currently requested page as well as allpage\nrequestsuptothattime.Jiangetal .[35]provideacollectionoflowerboundsforweakerpredictors(includingan\nindependent proof of Theorem 5), justifying the need for such a strong predictor. In a followup work, Bansal\net al. [6]showed, though, that the reoccurrence time predictions2are still useful for weighted caching when the\nnumberℓof weight classes issmall, allowing to achievea competitiveratioof Θ(logℓ)forgoodpredictions.\nWestressthattheaforementionedresultsusediferentpredictionsetupsandtheydonotimplyanyboundsfor\nour setup. This is due to a diferent way of measuring prediction errors, see Section 1.3 for details. Therefore,\nwe cannot compare the theoretical guarantees achieved by previously published caching algorithms in their\npredictionsetuptoournewcachingalgorithmwithinourbroadersetup.Instead,weprovideacomparisonvia\nexperiments.3\nCombiningWorst-CaseandOptimisticAlgorithms. Anapproachinsomewayssimilartoourswasdevelopedby\nMahdianetal . [47],whoassumetheexistenceofanoptimisticalgorithmanddevelopedameta-algorithmthat\ncombines this algorithm with a classical one and obtains a competitive ratio that is an interpolation between the\nratios of the two algorithms. They designed such algorithms for several problems including facility location and\nload balancing. The competitive ratios obtained depend on the performance of the optimistic algorithm and the\nchoiceoftheinterpolationparameter.Furthermorethemeta-algorithmisdesignedonaproblem-by-problem\nbasis. In contrast, (i) our performance guarantees are a function of the prediction error, (ii) generally we are able\ntoapproachtheperformanceofthebestalgorithm,and(iii)ourwayofsimulatingmultiplealgorithmscanbe\nseen asa blackboxand isproblem independent.\nOnlineAlgorithmswithAdvice. Anothermodelforaugmentingonlinealgorithms,butnotdirectlyrelatedto\nthepredictionsettingstudiedinthispaper,isthatof advicecomplexity ,whereinformationaboutthefutureis\nobtained in the form of some always correct bits of advice (see [ 13] for a survey). Emek et al . [26]considered\n2Their actual algorithm onlyneedsthe relativeorderingofreoccurrence times, whichis alsotrue for[46,53, 56].\n3One might be tempted to adapt the algorithm of Rohatgi [53]to action predictions by replacing the page with the furthest predicted\nreoccurrence in the algorithm of Rohatgi [53]by a page evicted by the predictor in our setting. However, it is not hard, following ideas\nsimilar to the irst example about prediction errors in the Section 1.3, to construct an instance where this algorithm is Ω(log)-competitive\nalthough\nOpt=(1)in our setup.\nACM Trans. Algor.\n\n\n6 • Antoniadis et al.\nMTS under advicecomplexity,andAngelopoulos et al .[3]consideradvice complexity withpossibly adversarial\nadvice and focus on Pareto-optimal algorithms for consistency and robustness in several similar online problems.\n1.3 Comparison to theSetupof LykourisandVassilvitskii\nAlthoughtheworkofLykourisandVassilvitskii [46]forcachingservedasaninspiration,ourpredictionsetup\ncannotbeunderstoodasanextensionorgeneralizationoftheirsetup.Herewelistthemostimportantconnections\nand diferences.\nConversion of Predictions for Caching. One can convert the reoccurrence time predictions of Lykouris and\nVassilvitskii [46]forcachingintopredictionsforoursetupusinganaturalalgorithm:Ateachpagefault,evictthe\npage whose next request is predicted furthest in the future. Note that, if given perfect predictions, this algorithm\nproducesanoptimalsolution[ 7].Thestatesofthisalgorithmateachtimearetheninterpretedaspredictions\nin our setup. We use this conversion to compare the performance of our algorithms to those of Lykouris and\nVassilvitskii[46]and Rohatgi[53]in empirical experiments in Section6.\nPrediction Error. The prediction error as deinedbyLykouris and Vassilvitskii [46]isnot directlycomparable\nto ours.Herearetwoexamples.\n(1) Consider a paging instance where some page is requested at times 1and3, and suppose we are given\nreoccurrencetimepredictionsthatarealmostperfectexceptattime 1whereitispredictedthat reoccursat\ntimerather than 3, for some large . Then the prediction error in the setting of Lykouris and Vassilvitskii [46]\nisΩ(). However, the corresponding action predictions obtained by the conversion above are wrong only at\ntime step 2, meaning thepredictionerror in our setting isonly 1with respectto theoline optimum.\n(2)Onecancreatearequestsequenceconsistingof +1distinctpageswhereswappingtwopredictedtimesof\nnext arrivals causes a diferent prediction to be generated by the conversion algorithm. The modiied prediction\nin the setup of Lykouris and Vassilvitskii [46]may only have error 2while the error in our setup with respect to\nthe oline optimum can be arbitrarily high (depending on how far in the future these arrivals happen). However,\nour results provide meaningful bounds also in this situation. Such predictions still have error 0in our setup with\nrespecttoanear-optimalalgorithmwhichincursonlyoneadditionalpagefaultcomparedtotheolineoptimum.\nTheorems1ś3thenprovide constant-competitivealgorithms with respectto this near-optimalalgorithm.\nThe irst example shows that the results of Lykouris and Vassilvitskii [46], Rohatgi [53], Wei[56]do not imply\nanyboundsinoursetup.Ontheotherhand,therecentresultofWei [56]showsthatouralgorithmsfromTheorems\n1ś3, combined with the prediction-converting algorithm above, are (1+min{1\n\nOpt,log})-competitive for\ncaching in the setup of Lykouris and Vassilvitskii [46], thus also matching the best known competitive ratio\ninthatsetup:Theoutputoftheconversionalgorithmhaserror0withrespecttoitselfandouralgorithmsare\nconstant-competitive with respect toit. Sincethecompetitive ratio of theconversion algorithm is (1+1\n\nOpt)\nbyWei[56],ouralgorithmsare (min{1+1\n\nOpt,log})-competitive,where denotesthepredictionerrorin\nthesetup of Lykouris and Vassilvitskii[46].\nSuccinctness. Inthecaseofcaching,wecanrestrictourselvesto lazypredictors,whereeachpredictedcache\ncontent difers from the previous predicted cache content by at most one page, and only if the previous predicted\ncache content did not contain the requested page. This is motivated by the fact that any algorithm can be\ntransformed into a lazy version of itself without increasing its cost. Therefore, (log)bits are enough to\ndescribeeachactionprediction,sayingwhichpageshouldbeevicted,comparedto Θ(log)bitsneededtoencode\nareoccurrencetimeinthesetupofLykourisandVassilvitskii [46].Infact,weneedtoreceiveapredictionnotfor\nalltimestepsbutonlythosewhenthecurrentrequestisnotpartofthepreviouscachecontentofthepredictor.In\ncases when running an ML predictor at each of these time steps is too costly, our setup allows predictions being\ngenerated by some fast heuristic whose parameters can be recalculated by the ML algorithm only when needed.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions • 7\nLearnability. In order to generate the reoccurrence time predictions, Lykouris and Vassilvitskii [46]used a\nsimple PLECO [ 2] predictor. In this paper, we introduce another simple predictor called POPU and show that the\noutputof thesepredictorscan beconvertedto action predictions.\nPredictors Hawkey[34] andGlider[54] use binary classiiers to identify pages in the cache which are going to\nbe reused soon, evicting irst the other ones. As shown by their empirical results, such binary information is\nenoughtoproduceaveryeicientcachereplacementpolicy,i.e.,actionpredictions.Intheirrecentpaper,Liuetal .\n[45]have proposed a new predictor, called Parrot, that is trained using the imitation learning approach and tries\ntomimicthebehaviouroftheoptimalolinealgorithm[ 7].Themainoutputoftheirmodel,implementedusinga\nneuralnetwork,areinfactactionpredictions.Howeveritalsoproducesthereoccurrencetimepredictionsinorder\ntoaddfurthersupervisionduringthetrainingprocess.Whileatirstitmayseemthatpredictingreoccurrence\ntimesisaneasiertask(inparticular,ithastheformofastandardsupervisedlearningtask),theresultsofLiu\net al. [45]show that it might well be the opposite ś e.g., when the input instance variance makes it impossible to\npredictthereoccurrence timesaccuratelyyetit is stillpossible tosolve it(nearly)optimallyonline.Wereferto\nthepaperofChłędowskietal . [17]foranextensiveevaluationoftheexistinglearningaugmentedalgorithms\nusingbothreoccurrencetimeandactionpredictions.Followingtheemergenceoflearning-augmentedalgorithms,\nAnand et al. [ 1] even designed predictors speciically tuned to optimize the error used in the algorithms analysis.\nThis work hasbeen restrictedso farto a muchsimpler online problem, ski rental.\n2 PRELIMINARIES\nIn MTS, we are given a metric space of states and an initial state 0∈. At each time =1,2,..., we receive\na taskℓ:→R+∪{0,+∞}and we have to choose a new state without knowledge of the future tasks,\nincurring cost dist(−1,)+ℓ(). Notethat dist(−1,)=0if−1=bytheidentity propertyof metrics.\nAlthough MTS share several similarities with the expertsproblem from the theory of online learning [ 20,30],\nthere arethree importantdiferences.First, thereisa switchingcost : weneed topay costforswitchingbetween\nstatesequaltotheirdistanceintheunderlyingmetricspace.Second,analgorithmforMTShas one-steplookahead ,\ni.e., itcan see thetask (orloss function) before choosing the new state and incurring the cost of this task. Third,\ntherecanbe unboundedcosts inMTS,whichcanbehandledthankstothelookahead.SeeBlumandBurch [10]\nformoredetails on therelationbetween expertsand MTS.\nToassesstheperformanceofalgorithms,weusethe competitiveratio śtheclassicalmeasureusedinonline\nalgorithms.\nDefinition1(Competitiveratio). LetAbeanonlinealgorithmforsomecost-minimizationproblem .We\nsay thatAis-competitive and callthecompetitiveratio ofA,if for any input sequence ∈,wehave\nE[cost(A())]≤·Opt+,\nwhereis a constant independent of the input sequence, A()is the solution produced by the online algorithm and\nOptisthecostofanoptimalsolutioncomputedolinewiththepriorknowledgeofthewholeinputsequence.The\nexpectation is over the randomness in the online algorithm. If Optis replaced by the cost of some speciic algorithm\nOff,wesay thatAis-competitiveagainst Off.\nBeforeweproveourresultsforgeneralMTS,weconsiderinthenextsectionthecachingproblem.Itcorresponds\nto the special case of MTS where the metric space is the set of cardinality- subsets of a cardinality- set (of\npages), the distance between two sets is the number of pages in which they difer, and each cost function assigns\nvalue0to all setscontainingsome page and∞to other sets.\nACM Trans. Algor.\n\n\n8 • Antoniadis et al.\n3 LOGARITHMIC ERROR DEPENDENCE FOR CACHING\nWedescribeinthissectionanewalgorithm,whichwecall Trust&Doubt,forthe(unweighted)cachingproblem,\nand prove Theorem 3. The algorithm achieves a competitive ratio logarithmic in the error (thus overcoming\nthe lower bound ofTheorem 20thatholdsfor generalMTSevenon a uniformmetric), while alsoattainingthe\noptimal worst-case guaranteeof (log).\nWeassumethatthepredictoris lazyin thefollowing sense. Let bethepage thatisrequestedat time and\nletbetheconiguration(i.e.,setofpagesinthecache)ofthepredictorattime .Thendifersfrom −1only\nif∉−1and,inthiscase, =−1∪{}\\{}for somepage ∈−1. Note thatanyalgorithmfor caching\ncan beconvertedinto a lazyone withoutincreasing its cost.\nWe partition the request sequence into phases, which are maximal time periods where distinct pages are\nrequested4: Theirst phasebegins with the irst request.Aphaseends(andanewphasebegins) after distinct\npages havebeen requestedin the current phaseand right before the next arrival of apage thatis diferentfrom\nall thesepages. For a given point in time, we say that a page is markedif it has been requested at least once in\nthecurrentphase.Foreachpage requestedinaphase,wecalltheirstrequestto inthatphasethe arrival\nof.Thisisthetimewhen getsmarked.Manyalgorithms,includingthatofLykourisandVassilvitskii [46],\nbelong to the class of so-called marking algorithms , which evict a page only if it is unmarked. The classical\n(log)-competitive online algorithm of [ 28] is a particularly simple marking algorithm: On a cache miss, evict\nauniformlyrandomunmarkedpage.Ingeneral,nomarkingalgorithmcanbebetterthan 2-competitiveeven\nwhen provided with perfect predictions. As will become clear from the deinition of Trust&Doubtlater, it may\nfollow the predictor’s advice to evict even marked pages, meaning that it is not a marking algorithm. As can\nbe seen in our experiments in Section 6, this allows Trust&Doubtto outperform previous algorithms when\npredictions are good.5We believe that one could modify the algorithm so that it is truly 1-competitive in the\ncaseofperfectpredictions.However,formallyprovingsoseemstorequireasigniicantamountofadditional\ntechnical complications regarding notation and algorithm description. To keep the presentation relatively simple,\nweabstain from optimizing constantshere.\n3.1 First warm-up: Auniverseof +1pages\nBeforewegivethefull-ledged Trust&Doubtalgorithmforthegeneralsetting,weirstdescribeanalgorithmfor\nthesimplersettingwhenthereexistonly +1diferentpagesthatcanberequested.Thisassumptionsubstantially\nsimpliiesboththedescriptionandtheanalysisofthealgorithmwhilealreadyshowcasingsomekeyideas.In\nSections 3.2 and 3.3, wewill explaintheadditionalideasrequiredto extendthealgorithmto thegeneralcase.\nOur assumption means that at each time, there is only one page missing from the algorithm’s cache and only\none page missing from the predicted cache. Moreover, the irst request in each phase is an arrival of the (unique)\npagethatwasnotrequestedinthepreviousphase,andallotherarrivalsinaphasearerequeststopagesthat\nwerealsorequestedintheprevious phase.\n3.1.1 Algorithm (simplified seting). We denote by the set of marked pages and by the set of unmarked\npages.\nIn each phase, we partition time into alternating Trust intervals andDoubt intervals , as follows: When a phase\nstarts,theirstTrustintervalbegins.ThroughouteachTrustinterval,weensurethatthealgorithm’scacheis\nequal to the predicted cache . As soon as the page missing from is requested during a Trust interval, we\nterminate thecurrentTrustinterval and start anewDoubt interval. In aDoubt interval,wetreat pagefaultsby\n4Subdividingtheinputsequenceintosuchphasesisaverycommontechniqueintheanalysisofcachingalgorithms,seeforexampleBorodin\nandEl-Yaniv [11]andreferencestherein.\n5Thereexistinstanceswhere Trust&Doubtwithperfectpredictionsstrictlyoutperformsthebestmarkingalgorithm,butalsoviceversa,see\nAppendixB.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions • 9\nevictinga uniformlyrandompagefrom .Assoonastherehavebeen 2−1arrivalssincethebeginningofthe th\nDoubt interval of a phase, the Doubt interval ends and a new Trust interval begins (and we again ensure that the\nalgorithm’s cache isequalto ).\n3.1.2 Analysis(simplifiedseting). Letℓbethenumberof Doubtintervals in phase ℓ.\nClaim 6. Theexpected numberof cachemissesinphase ℓis1+(ℓ).\nProof.AnycachemissduringaTrustintervalstartsanewDoubtinterval,sothereare ℓcachemissesduring\nTrustintervals.Theremaybeonemorecachemissatthestartofthephase.Itremainstoshowthatthereare\n(ℓ)cache missesinexpectationduring Doubtintervals.\nIna Doubtinterval,wecan haveacache missonlywhen a page from arrives.The arrivingpage from is\ntheonemissingfromthecachewithprobability 1/||.Moreover,whenapagefrom arrives,itisremovedfrom\n.TheexpectednumberofcachemissesduringDoubtintervalsisthereforeasumoftermsoftheform 1/||\nfordistinctvaluesof ||.SincethetotalnumberofarrivalsduringDoubtintervalsisatmost 2ℓ,theexpected\nnumberof cache missesduring Doubtintervals isat most/summationtext.12ℓ\n=11/=(ℓ). □\nDue to theclaim,our main remainingtask isto upperboundthenumberof Doubtintervals.\nWe call a Doubt interval error interval if at each time during the interval, the page missing from is present\nin the cache of the oline algorithm. Note that each time step during an error interval contributes to the error .\nLetℓ≤ℓbe the number of error intervals of phase ℓ. Since for all <ℓ, theth error interval contains at least\n2−1time steps, wecan boundtheerror as\n≥︁\nℓ/︁arenleftbig2ℓ−1−1/︁arenrightbig. (2)\nDenoteby Offℓthecostof theoline algorithmduring phase ℓ.\nClaim 7. ℓ≤Offℓ+ℓ+1.\nProof.Consider the quantity ℓ−ℓ. This is the number of Doubt intervals of phase ℓduring which is\nequal to the oline cache at some point. Since changes at the start of each Doubt interval, but changes only\nifthepagemissingfrom isrequested(sinceweassumethepredictortobelazy),thismeansthattheoline\ncache mustchangebetween any twosuch intervals. Thus, ℓ−ℓ−1≤Offℓ. □\nCombiningtheseclaims,thetotalnumberofcachemissesofthealgorithmisatmost(notingby #phasesthe\nnumberof phases)\n︁\nℓ(1+(ℓ))≤/︁arenleftBigg\nOff+#phases+︁\nℓ(ℓ−1)/︁arenrightBigg\n.\nEachterm(ℓ−1)canberewrittenas log2/︁arenleftbig1+(2ℓ−1−1)/︁arenrightbig.Byconcavityof ↦→log(1+),subjecttothebound\n(2)the sum of these terms is maximized when each term 2ℓ−1−1equals\n#phases. Thus, the total number of cache\nmissesof thealgorithmisat most\n/︁arenleftbigg\nOff+#phases+#phases·log/︁arenleftbigg\n1+\n#phases/︁arenrightbigg/︁arenrightbigg\n≤Off·/︁arenleftBig\n1+log/︁arenleftBig\n1+\nOff/︁arenrightBig/︁arenrightBig\n,\nwhere the last inequality uses that Off=Ω(#phases)since all+1pages are requested in any two adjacent\nphases,so theoline algorithmmusthavea cache missin any twoadjacentphases.\nACM Trans. Algor.\n\n\n10 • Antoniadis et al.\n3.2 Second warm-up: The predictorisa markingalgorithm\nWe now drop the assumption from the previous section and allow the number of pages in the universe to be\narbitrary.However,wewillassumeinthissectionthatthepredictorisamarkingalgorithm(i.e.,thepredicted\ncachealwayscontains all markedpages). Inthis case, our algorithmwill alsobea marking algorithm.\nOur algorithm isagainbased on phases, whichare deined asbefore.Denote by theset of unmarked pages\nthat were in the cache at the beginning of the phase, and by the set of marked pages. By our assumption\nthatboththepredictorandouralgorithmaremarkingalgorithms,atthestartofaphase isequaltoboththe\npredicted cache as well as the algorithm’s cache as it contains precisely the pages that were requested in the\nprevious phase. An important notion in phase-based paging algorithms is that of clean pages . For the setting\nconsidered in this section, where the predictor is a marking algorithm, we deine a page as cleanif it is requested\ninthecurrentphasebutwasnotrequestedinthepreviousphase.Wedenoteby thesetofcleanpagesthathave\narrived so far in the current phase. (In the general setting, we will need to deine clean pages slightly diferently.)\nSeveral simultaneous interval partitions. While in the irst warm-up setting with a (+1)-page universe\nthere could be only a single clean page per phase, a main diference now is that there can be severalclean pages\ninaphase.Forthisreason,itisnolongersuicienttopartitionthephaseintoTrustintervalsandDoubtintervals\nthataredeined“globallyž.Instead,wewillassociatewith eachcleanpagea diferentsubdivisionoftimeinto\nTrust intervals and Doubtintervals: The time from the arrival of until the end ofthe phase is partitioned into\nalternating -Trustintervals and-Doubtintervals .Thus,atime canbelongtovariousintervalsśoneassociated\ntoeachclean thathasarrivedsofarinthecurrentphase.Atanytime,someofthecurrentintervalsmaybe\nTrustintervalswhiletherestareDoubtintervals.Duringa -Trustinterval,wewill notensurethattheentire\nalgorithm’scache is equal to the predictor’s cache, butonlythat oneparticular page ()thatis evictedby the\npredictor isalsopredictedbythealgorithm.\nMore precisely, we will also maintain a map :→\\that maps each clean page ∈ℓ(that has arrived\nsofar)toanassociatedpage ()thatwasevictedbythepredictorduringthecurrentphase(andiscurrentlystill\nmissing from the predictor’s cache). Intuitively, we can think of ()as the page that the predictor advises us to\nevict to makespacefor .If ithappensthat the page ()associated to someclean is requested, the predictor\nhastoload ()backtoitscache ,andweredeine ()tobethepagethatthepredictorevictsatthistime.\nObservethatthisensuresthatthepages ()aredistinctfordiferent (infact,sinceweassumethepredictorto\nbea lazymarking algorithm, isa bijectionin this case).\nWhenacleanpage arrives,theirst -Trustintervalbegins.Throughouteach -Trustinterval,wewillensure\nthat the page ()is evicted fromour algorithm’scache. If during a -Trustinterval thepage ()is requested,\nwe terminate the current -Trust interval and start a new -Doubt interval. In a -Doubt interval, we ignore the\nadvicetoevict ()andinsteadevictauniformlyrandomunmarkedpagewhennecessary.Assoonastherehave\nbeen2−1arrivalssincethebeginningofthe th-Doubtinterval,the -Doubtintervalendsandanew -Trust\nintervalbegins(and weagainensurethatthepage currently deinedas ()isevicted).\nWewillskipamoreformaldescriptionandanalysisofthealgorithmforthissettingasitwillbecontainedasa\nspecialcaseof our algorithmin thenextsection.\nRemark 8. At a highlevel, the idea of linking evictionsto individual clean pages (whichis explicit for the pages\n()evicted in Trust intervals) bears some similarities to the notion of eviction chains used in [ 46,53]. However, our\nalgorithm and charging scheme are quite diferent. In particular, the natural adaptations of algorithms in [ 46,53] to\nour setting would only be Ω(log)-competitive even when\nOpt=(1), whereis the prediction error in our setting.\nThis can happen on instances where predictions are mostly good, but occasionally very bad. To overcome this, we use\nDoubtintervalsthatstartsmalland growovertime,which allowsour algorithm torecoverquicklyfromoccasional\nvery bad predictions.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions • 11\n3.3 Algorithmfor thegeneralcase\nWe now describe our algorithm Trust&Doubtfor the general case. In contrast to the previous section, we drop\nheretheassumptionthatthepredictormustbeamarkingalgorithm.Thus,thepredictormayevictmarkedpages,\nand since Trust&Doubtmay trust suchevictions, also Trust&Doubtmay evict markedpages. Consequently,\nitisnolongertruethatsetofpagesinthealgorithm’scacheatthestartofaphaseisequaltothesetofpages\nrequestedintheprevious phase. This meansthatsome pagesmay be“ancientž asperthefollowing deinition.\nDefinition 2. A page is called ancientif it is inTrust&Doubt’s cache even though it has been requested in\nneitherthe previousnor the currentphase (sofar).\nWepartitioneachphaseintotwostagesthataredeterminedbywhetherancientpagesexistornot:During\nstage one there exists at least one ancient page, and during stage two there exist no ancient pages. We note that\none of thetwostages may beempty.\nThe algorithmfor stage one isvery simple:Wheneverthere isa page fault, evict an arbitrary ancient page.\nThis makes sense since ancient pages have not been requested for a long time, so we treat them like a reserve of\npagesthataresafe to evict.Once this reservehasbeen usedup, stagetwobegins.\nThe algorithmfor stagetwo is essentially the one alreadydescribedin theprevious section. Beforewe givea\nmore formal description, we irst ix some notation. Let be the set of pages that were in cache at the beginning\nof stage two and that are currently unmarked. Let be the set of marked pages. We call a page cleanfor a phase\nif it arrives in stage two and it was not in ∪immediately before its arrival. (Pages arriving in stage one are\nnotconsideredcleanasthese areeasy tochargefor anddonotneedtheanalysis linkedtoclean pages instage\ntwo.)Bywedenote thesetof cleanpagesthathavearrivedso farin thecurrentphase.\na... =3\n ba\nca\ne\nb\nae\nc...t\nTrust&Doubtpossiblecache at time :{a,c,d}arrivals endof phases\nancient\nFig.1. IllustrationofdefinitionsusedtodescribeT rust&Doubt.Attime ,anewphasestartsandthecachecontains ,\nand, whereis ancient. In the following phase, is not clean because it arrives during stage one. When is requested,\nTrust&Doubtevictstheancientpage andloads ,andthenstagetwobeginswith ={,}and={}initially.The\npagerequested next is considered clean because, although it was also requested in the previous phase, it was not in ∪\nimmediately before its request. The next requestedpage isnotcleanasit was already in ∪.\nItisimmediatefrom thedeinitionsthatthefollowing equationismaintainedduring stagetwo:\n|∪|=+|| (3)\nSimilarly to before, Trust&Doubtmaintains an injective map :→(∪)\\that maps each clean\npage∈(thathasarrivedsofar)toadistinctpage ()thatiscurrentlymissingfromthepredictor’scache.\nNotethatsincethepredictormayevictmarkedpages,itisnecessarytoincludemarkedpagesinthecodomainof\n.Asbefore,thetimefromthearrivalofacleanpage totheendofthephaseispartitionedintoalternating\n-Trust intervals and -Doubt intervals. Depending on the type of the current interval, we will also say that is\ntrustedor isdoubted.Let\n:={()|∈trusted}\n:={()|∈doubted}.\nACM Trans. Algor.\n\n\n12 •Antoniadis et al.\nTo organize the random evictions that the algorithm makes, we sort the pages ofin a uniformly random order\nat the beginning of stage two. We refer to the position of a page in this order as its rank, and we will ensure that\ntherandomly evictedpagesarethose with thelowestranks.6\nA pseudocode of Trust&Doubtwhen a page isrequestedin stagetwoisgiven inAlgorithm1.\nIfis cleanand the request is an arrival (thecondition in line 1 is true), we irst deine its associated page ()\nas an arbitrary7page from(∪)\\(∪∪). We will justify later in Lemma 10 that this set is non-empty.\nWethenstartan -Trustinterval.(Notethatthisadds ()totheset .)Sinceisthentrusted,weensurethat\n()is evicted from the cache. If it was already evicted, then we instead evict the page in cache with the lowest\nrank. Either way, there is now a free cache slot that will be loaded to in line 6. We also initialize a variable as\n1. Foreachcleanpage , wewill use this variable to determine thedurationof thenext -Doubt interval.\nOtherwise, we also ensure that is in cache, evicting the page in cache with the lowest rank if necessary\n(lines8ś10).\nIfisapageoftheform (),weredeine (),andsincethepreviouspredictiontoevicttheold ()was\nbad,weensurethat isnow doubted(lines11ś14), i.e., westarta new -Doubt intervalif was trusted.\nFinally,inlines15ś20wecheckforeachcleanpage whetheritshouldreachtheendofitsDoubtinterval.If \nisinitsthDoubtinterval,thenthishappensifthecurrentarrivalisthe 2−1tharrivalafterthestartofthecurrent\n-Doubt interval.Foreach forwhicha -Doubt interval ends,we start anew -Trust interval andensurethat\n()is evicted from the cache.If ()wasnot evicted yet, we reload the evicted pagewith the highestrank back\nto thecache so thatthecache contains pagesat all times.\nRemark9. Tosimplifytheanalysis,thealgorithmis deinednon-lazilyhereinthesense thatitmayload pages\nevenwhentheyarenotrequested(inline20).Animplementationshouldonlysimulatethisnon-lazyalgorithmin\nthebackgroundand,whenevertheactualalgorithmhasapagefault,itevictsanarbitrary(e.g.,theleastrecently\nused)pagethatispresentinitsowncachebut missing fromthe simulated cache.\nCorrectness. Itisstraightforwardtocheckthatthealgorithm’scacheisalwaysasubsetof (∪)\\,since\nany page added to is evicted. Moreover, it is always a superset of \\because pages from are only evicted\nifthey arein .\nThe following two lemmas capture invariants that are maintained throughout the execution of the algorithm.\nInparticular, they justify thethealgorithmiswell-deined.\nLemma 10. The set(∪)\\(∪∪)isnon-empty before ()or()ischosen from it inlines 2 and 12.\nProof.Itsuicesto show that |∪|>|∪∪|rightbeforetherespectiveline isexecuted.\nBeforeline2isexecuted, itwillbe thecasethat ||=|∪|+1(because∈,but()isnotdeinedyet).\nThus, equation(3)yields |∪|=+|∪|+1>|∪∪|.\nBefore line 12 is executed, it holds that ||=|∪|and∈(∪)∩. Again, the inequality follows from\nequation(3). □\nThenextlemmajustiiesthatreloadingapageinline20willbepossible,andthelemmawillalsobecrucialfor\nthecompetitiveanalysislater.\nLemma 11. Beforeeachrequestof stage two,thereare ||pagesfrom \\missing fromthe cache.\nProof.The pages in cache are a subset of ∪of size. By equation (3), there are||=|∪|of these\npages missing from the cache. The pages in account for||of those missing pages. The remaining ||missing\npagesareall in \\(becausepagesfrom areonlyevictedifthey arein ). □\n6Since randomly evicted pages may be reloaded even when they are not requested, maintaining such ranks leads to consistent random\nchoices throughoutaphase.\n7e.g., the least recentlyused\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •13\nAlgorithm 1: When page isrequestedin phase ℓand no ancientpagesexist\n1if∈and this isthe arrival of then // Arrival of a clean page\n2Let()bean arbitrary page from(∪)\\(∪∪)\n3Startan-Trustinterval\n4if()isincache thenevict()\n5elseevictthelowestrankedcachedpage from \\\n6Loadto thecache\n7:=1 // Duration of next -Doubt interval (if it exists)\n8elseifisnotincache then // Page fault, but not arrival of clean page\n9Evictthelowestrankedcachedpage from \\\n10Loadto thecache\n11if=()for some∈then // Advice to evict ()was bad\n12Redeine ()asan arbitrary page from (∪)\\(∪∪)\n13ifistrusted then\n14 Endthe-Trustintervaland starta -Doubt interval\n15foreach∈thatisdoubted do // Check for end of Doubt intervals\n16ifthe currentrequestisthe th arrival since the start of this -Doubtinterval then\n17 Endthe-Doubt intervaland starta -Trustinterval\n18 :=2·\n19 if()isincache then\n20 Evict()and load thehighest rankedevictedpage from \\backto thecache\n3.4 Competitive analysis.\nLetℓdenote the set at the end of phase ℓ. The next lemma and its proof are similar to a statement in Fiat et al .\n[28]. However, since our deinitionof cleanpagesisdiferent,weneedto reproveitinour setting.\nLemma 12. Any oline algorithm suferscostat least\nOff≥Ω/︁arenleftBigg︁\nℓ|ℓ|/︁arenrightBigg\n.\nProof.We irst claim that at least +|ℓ|distinct pages are requested in phases ℓ−1andℓtogether. If there\nis no stagetwo inphase ℓ, thenℓis emptyandthestatement trivial.Otherwise, all pagesthatarein ∪at\ntheend of phase ℓwererequestedin phase ℓ−1orℓ, and byequation(3)this setcontains +|ℓ|pages.\nThus,anyalgorithmmustsuferatleastcost |ℓ|duringthesetwophases.Hence, Offislowerboundedby\nthe sum of|ℓ|over all even phases and, up to a constant, by the according sum over all odd phases. The lemma\nfollows. □\nBythefollowing lemma, itsuicesto boundthecostof Trust&Doubtincurredduring stagetwo.\nLemma 13. Thecostduringstage one of phase ℓisat mostthe costduringstage twoof phase ℓ−1.\nACM Trans. Algor.\n\n\n14 •Antoniadis et al.\nProof.The cost during stage one of phaseℓis at most the number of ancient pages at the beginning of phase\nℓ. This is at most the number of marked pages that were evicted in phase ℓ−1. Since a marked page can be\nevictedonlyduring stagetwo, thelemma follows. □\nLet,ℓbethenumberof -Doubtintervalsinphase ℓ.ThenextlemmaisreminiscentofClaim6fromourirst\nwarm-upsection.\nLemma 14. Theexpected costduringstage twoof phase ℓis/︁arenleftBig\n|ℓ|+/summationtext.1\n∈ℓ,ℓ/︁arenrightBig\n.\nProof.The cost incurred in lines 1ś7 is at most (|ℓ|). In lines 8ś10, the algorithm can incur cost only if the\nrequested page was in ∪before the request (because the request is not an arrival of a clean page, so it was in\n∪, and if it was in \\then it was in cache already). If the page was in , then a new Doubt interval will\nstartinline14,sothecostduetothosepagesisat most/summationtext.1\n∈ℓ,ℓ.Ifthepagewas in \\,thenbyLemma11\nandtherandomchoiceofranksitwasmissingfromthecachewithprobability||\n|\\|.Toaccountforthiscost,we\ncharge1\n|\\|to each clean that is doubted at the time. Over the whole phase, the number of times we charge to\neach∈ℓinthiswayisatmostthetotalnumberofarrivalsduring -Doubtintervals,whichisatmost 2,ℓ.By\nequation(3)andsince||=||+||,wehave||=+||+||−||,so|\\|≥+||−||≥+1−||.\nThe quantity||increases by 1after each such request to a page in |\\|, so the value of|\\|can be lower\nbounded by 1,2,3,...,2,ℓduring the at most 2,ℓarrivals when1\n|\\|is charged to . Hence, the total cost\nchargedto isat most (,ℓ). Itfollowsthattheoverall costincurredin linesisat most /︁arenleftBig/summationtext.1\n∈ℓ,ℓ/︁arenrightBig\nFinally, the only other time cost is incurred is in line 20. This also amounts to at most/summationtext.1\n∈ℓ,ℓbecause it\nhappensonlyat theend of a Doubt-interval. □\nDenoteby ,ℓthenumberof -Doubtintervalswiththepropertythatateachtimeduringtheinterval,thepage\ncurrentlydeinedas ()ispresentintheolinecache.Sincethecurrentpage ()isneverinthepredictor’s\ncache,andthe thdoubted -intervalcontains 2−1arrivalsfor <,alowerboundonthepredictionerroris\ngiven by\n≥︁\nℓ︁\n∈ℓ(2,ℓ−1−1). (4)\nDenoteby Off,ℓthenumberoftimesinphase ℓwhentheolinealgorithmincurscostforloadingthepage\ncurrently deinedas ()to its cache.\nThe nextlemma isthegeneralization of Claim7.\nLemma 15. For each∈ℓ,wehave ,ℓ≤Off,ℓ+,ℓ+1.\nProof.Considerthequantity ,ℓ−,ℓ.Thisisthenumberof -Doubtintervalsofphase ℓduringwhich ()\nis missing from the oline cache at some point. Except for the last such interval, the page ()will subsequently\nbe requested during the phase, so the oline algorithm will incur cost for loading it to its cache. The lemma\nfollows,withthe“+1žterm accounting forthelast interval. □\nWearenow ready to provethemain resultof this section.\nTheorem (RestatedTheorem 3). Trust&Doubthas competitiveratio (min{1+log(1+\nOff),log})against\nany oline algorithm Off,whereisthe prediction errorwith respect to Off.\nProof.The(log)bound follows from Lemma 14, Lemma 12 and the fact that ,ℓ≤(log)for each\n∈ℓ.Thelatterfactholdsbecauseif ,ℓ≥2,thenthe(,ℓ−1)st-Doubtintervalcontains 2,ℓ−2arrivals,but\nthereareonly arrivalsperphase.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •15\nForthemain bound,combiningLemmas 13, 14 and 15 weseethatthetotalcost of thealgorithmisat most\n/︁arenleftt︁A/︁arenleftexA\n/︁arenleftbtAOff+︁\nℓ|ℓ|+︁\nℓ︁\n∈ℓ,ℓ/︁arenrightt︁A/︁arenrightexA\n/︁arenrightbtA.\nThesummands ,ℓcanberewrittenas 1+log2/︁arenleftbig1+[2,ℓ−1−1]/︁arenrightbig.Byconcavityof ↦→log(1+),whilerespecting\nthe bound (4)the sum of these terms is maximized when each term in brackets equals/summationtext.1\nℓ|ℓ|, giving a bound on\nthecostof\n/︁arenleftBigg\nOff+︁\nℓ|ℓ|/︁arenleftbigg\n1+log/︁arenleftbigg\n1+/summationtext.1\nℓ|ℓ|/︁arenrightbigg/︁arenrightbigg/︁arenrightBigg\n.\nSince this quantityisincreasing in/summationtext.1\nℓ|ℓ|, applying Lemma 12 completes theproof of thetheorem. □\n3.5 Lowerbound\nThe(log)upper bound matches the known lower bound Ω(log)on the competitive ratio of randomized\nonlinealgorithmswithoutprediction[ 28].Thecompetitiveratioof Trust&Doubtwhenexpressedonlyasa\nfunction of the error, (1+log(1+\nOff)), is also tight due to the following theorem. It should be noted, though,\nthatforthecompetitiveratioasafunctionofboth and\nOffitisstillplausiblethatabetterboundcanbeachieved\nwhen\nOffisrelativelysmall comparedto .\nTheorem 16. If an online caching algorithm achieves competitive ratio at most (\nOpt)for arbitrary when\nprovided with action predictions with error at most with respect to an optimal oline algorithm Opt, then()=\nΩ(log)as→∞.\nProof.Fixsome+1pagesandconsidertherequestsequencewhereeachrequestistoauniformlyrandomly\nchosen page from this set. We deine phases in the same way as in the description of Trust&Doubt. By a\nstandard coupon collector argument, each phase lasts Θ(log)requests in expectation. An optimal oline\nalgorithm can sufer only one page fault per page by evicting only the one page that is not requested in each\nphase.Ontheotherhand,sincerequestsarechosenuniformlyatrandom,anyonlinealgorithmsufersapage\nfaultwithprobability 1/(+1)perrequest,givingacostof Θ(log)perphase.Since\nOpt=(log)dueto\nthedurationof phases,thecompetitiveratioof thealgorithmis Ω(log)=Ω(log\nOpt). □\n4 ROBUSTALGORITHMS FOR MTS\nThe goal of this section is to prove Theorem 1 and Theorem 2, which deal with algorithms substantially simpler\nthanTrust&Doubt,but demonstratethe usefulness of ourprediction setup for thebroadclassofMTSproblems.\nInSection4.1wewillirstdescribeasimplealgorithmwhosecompetitiveratiodependslinearlyontheprediction\nerror,butthealgorithmisnotrobustagainstlargeerrors.InSection4.2wethenrobustifythisalgorithmbasedon\npowerful methods from the literature. Finally, in Section 4.3 we show that the linear dependency of the achieved\ncompetitiveratioon /Optisinevitableforsome MTS.\n4.1 Anon-robustalgorithm.\nWeconsider a simple memoryless algorithm,which wecall FtP.\nAlgorithmFollowthePrediction( FtP).Intuitively,ouralgorithmfollowsthepredictions,butstillsomewhat\ncautiously: if there exists a state “closež to the predicted one that has a much cheaper service cost, then it is to be\npreferred. Let us consider a metrical task system with a set of states . We deine the algorithm FtP(Follow the\nACM Trans. Algor.\n\n\n16 •Antoniadis et al.\nPrediction)as follows:at time , afterreceiving task ℓand prediction , itmovesto thestate\n←argmin\n∈{ℓ()+2dist(,)}. (5)\nIn other words, FtPfollows the predictions except when it is beneicial to move from the predicted state to some\nother state, pay theservice and movebackto thepredictedstate.\nLemma 17. For any MTS with action predictions, algorithm FtPwhich achieves competitive ratio 1+4\nOffagainst\nany oline algorithm Off,whereisthe prediction errorwith respect to Off.\nProof.Ateachtime ,theFtPalgorithmislocatedatconiguration −1andneedstochoose afterreceiving\ntaskℓand prediction . Letusconsider someoline algorithm Off. Wedenote 0,1,...,thestatesof Off,\nwheretheinitialstate 0iscommonfor Offand forFtP, anddenotesthelength of thesequence.\nWe deine to be the algorithm which agrees with FtPin its irst conigurations 0,1,...,and then\nagrees with the states of Off, i.e.,+1,...,. Note that cost(0)=Offandcost()=cost(FtP). We claim\nthatcost()≤cost(−1)+4foreach,where=dist(,).Thealgorithms and−1areinthesame\nconigurationat eachtime except , whenisinwhile−1isin. Bythetriangleinequality, wehave\ncost()≤cost(−1)+2dist(,)+ℓ()−ℓ()\n≤cost(−1)+2dist(,)−ℓ()+2dist(,)+ℓ()\n≤cost(−1)+4dist(,),\nThelastinequalityfollowsfrom (5):wehave 2dist(,)+ℓ()≤2dist(,)+ℓ().Bysummingoverall\ntimes=1,...,, weget\ncost(FtP)=cost()≤cost(0)+4/summationtext.1\n=1,\nwhich equals Off+4. □\n4.2 CombiningOnlineAlgorithms\nWe describe now how to make algorithm FtProbust by combining it with a classical online algorithm. Although\nweonlyneedtocombinetwoalgorithms,wewillformulatethecombinationtheoremsmoregenerallyforany\nnumberof algorithms.\nConsider algorithms 0,...,−1for some problem belonging to MTS. We describe two methods to\ncombinetheminto onealgorithm whichachieves a performanceguaranteecloseto thebestofthem. Notethat\nthesemethodsarealsoapplicabletoproblemswhichdonotbelongtoMTSaslongasonecansimulateallthe\nalgorithms at once and boundthecostforswitching between them.\nDeterministicCombination. ThefollowingmethodwasproposedbyFiatetal . [29]forthe-serverproblem,\nbutcanbegeneralizedtoMTS.WenotethatasimilarcombinationisalsomentionedinLykourisandVassilvitskii\n[46].Wesimulatetheexecutionof 0,...,−1simultaneously.Ateachtime,westayintheconigurationof\none of them, and we switch between the algorithms in the manner of a solution for the -lanecow path problem,\nseeAlgorithm2 fordetails.\nTheorem18(generalizationofTheorem1inFiatetal .[29]).Givenonlinealgorithms 0,...−1fora\nprobleminMTS,thealgorithm achievescostatmost (2\n−1+1)·min{()},foranyinputsequence .\nAproofofthistheoremcanbefoundinSectionA.Theoptimalchoiceof is\n−1.Then2\n−1+1becomes9for\n=2, and can beboundedby 2forlarger . Combinedwith Lemma 17, weobtain Theorem 1.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •17\nAlgorithm 2: [29]\n1choose1 <≤2; setℓ:=0\n2repeat\n3:=ℓmod\n4whilecost()≤ℓ,follow\n5ℓ:=ℓ+1\n6untilthe endof the input\nRandomizedCombination. BlumandBurch [10]proposedthefollowingwaytocombineonlinealgorithmsbased\nontheWMR[ 44](WeightedMajorityRandomized)algorithmfortheexpertsproblem.Ateachtime ,itmaintains\naprobabilitydistribution overthealgorithmsupdatedusingWMR.Let dist(,+1)=/summationtext.1\nmax{0,\n−+1\n}\nbe the earth-mover distance between and+1and let≥0be the transfer of the probability mass from\n\nto+1\ncertifying this distance, so that \n=/summationtext.1−1\n=0anddist(,+1)=/summationtext.1\n≠. If we are now following\nalgorithm ,we switchto withprobability /\n.See Algorithm3fordetails.Theparameter isan upper\nboundon theswitching costbetween thestates of twoalgorithms.\nAlgorithm 3: [10]\n1:=1−\n2; // for parameter <1/2\n20\n:=1foreach=0,...,−1;\n3foreachtimedo\n4\n:=costincurredby at time;\n5+1\n:=\n·\n/and+1\n:=+1\n/summationtext.1+1\n;\n6,:=masstransferredfrom \nto+1\n;\n7switch from tow.p./\n;\nTheorem 19 (Blum and Burch [10]).Givenon-line algorithms 0,...−1for an MTS with diameter and\n<1/2,thereisarandomized algorithm such that, for any instance ,itsexpected costisat most\n(1+)·min\n{cost(())}+(/)ln.\nCombinedwithLemma 17, weobtain Theorem 2.\n4.3 Lowerbound\nWeshowthatourupperboundsforgeneralmetricaltasksystems(Theorems1and2)aretightuptoconstant\nfactors. We show this for MTS on a uniform metric, i.e., the metric where the distance between any two points is\n1.\nTheorem 20. For¯≥0and∈N, every deterministic (or randomized) online algorithm for MTS on the -point\nuniform metric with access to an action prediction oracle with error at most ¯·Optwith respect to some optimal\noline algorithm has competitive ratio Ω(min{,1+¯}), where=Θ()(or=Θ(log)) is the optimal\ncompetitiveratio of deterministic(orrandomized)algorithms without prediction.\nACM Trans. Algor.\n\n\n18 •Antoniadis et al.\nProof.For deterministic algorithms, we construct an input sequence consisting of phases deined as follows.\nWewillensurethattheonlineandolinealgorithmsarelocatedatthesamepointatthebeginningofaphase.\nTheirstmin{−2,⌊¯⌋}costfunctionsofaphasealwaystakevalue ∞attheoldpositionoftheonlinealgorithm\nandvalue 0elsewhere,thusforcingthealgorithmtomove.Let beapointthattheonlinealgorithmhasnot\nvisitedsincethebeginningofthephase.Onlyonemorecostfunctionwillbeissuedtoconcludethephase,which\ntakesvalue 0atand∞elsewhere,henceforcingboththeonlineandolinealgorithmsto .Theoptimaloline\nalgorithmsufersacostofexactly 1perphasebecauseitcanmoveto alreadyatthebeginningofthephase.\nTheerrorisatmost ¯perphaseprovidedthatpoint ispredictedatthelaststepofthephase,simplybecause\nthereareonlyatmost ¯otherstepsinthephase,eachofwhichcancontribute atmost 1totheerror. Thus,the\ntotal error is at most ¯Opt. The online algorithm sufers a cost min{−1,1+⌈¯⌉}during each phase, which\nprovesthedeterministiclowerbound.\nFor randomized algorithms, let :=⌊log2⌋and ix a subset 0of the metric space of 2points. We construct\nagainaninputsequenceconsistingofphases:For =1,...,min{,⌊¯⌋},thethcostfunctionofaphasetakes\nvalue0on some set of feasible states and ∞outside of . Here, we deine ⊂−1to be the set consisting of\nthehalfofthepointsof −1wherethealgorithm’sprobabilityofresidingissmallestrightbeforethe thcost\nfunction of the phase is issued (breaking ties arbitrarily). Thus, the probability of the algorithm already residing\natapointfrom whenthe thcostfunctionarrivesisatmost 1/2,andhencetheexpectedcostperstepisat\nleast1/2. We assume that ¯≥1(otherwise the theorem is trivial). Similarly to the deterministic case, the phase\nconcludeswithonemorecostfunctionthatforcestheonlineandolinealgorithmstosomepoint intheinalset\n.Again,theoptimalcostisexactly 1perphase,theerrorisatmost ¯ineachphaseprovidedthelastpredictionof\nthe phase is correct, and the algorithm’s expected cost per phase is at least1\n2min{,⌊¯⌋}=Ω(min(log,1+¯)),\nconcludingtheproof. □\nInlightoftheprevioustheoremitmayseemsurprisingthatouralgorithm Trust&Doubtforcaching(see\nSection3)achievesacompetitiveratiologarithmicratherthanlinearinthepredictionerror,especiallyconsidering\nthat the special case of caching when there are only +1distinct pages corresponds to an MTS on the uniform\nmetric.However,theconstructionoftherandomizedlowerboundinTheorem20requirescostfunctionsthat\ntakevalue∞at several pointsat once, whereas in caching onlyone page isrequestedpertime step.\n5 BEYONDMETRICAL TASK SYSTEMS\nTheobjectiveofthissectionistoshowthatthepredictionsetupintroducedinthispaperisnotlimitedtoMetrical\nTask Systems, but can also be useful for relevant problems not known to be inside this class. This emphasizes the\ngenerality of our approach, compared to prediction setups designed for a single problem. We focus on the online\nmatching on the line problem, which hasbeen studiedforthreedecades and hasseen recent developments.\nIn theonline matching on the line problem, we are given a set ={1,2,...}of server locations on the real\nline. A set of requests ={1,2,...}which are also locations on the real line, arrive over time. Once request\narrives, it has to be irrevocably matchedto some previously unmatched server . The costof this edge in the\nmatching is the distance between and, i.e.,|−|and the total cost is given by the sum of all such edges in\nthe inal matching, i.e., the matchingthatmatches every request in to someuniqueserver in .Theobjective is\nto minimizethis totalcost.\nThebestknownlowerboundonthecompetitiveratioofanydeterministicalgorithmis 9.001[31]andthebest\nknownupperboundforany algorithmis (log), dueto Raghvendra [52].\nWestartbydeiningthenotion of distancebetween twosetsof servers.\nDefinition 3. Let1\nand2\nbe two sets of points in a metric space, of size each. We then say that their distance\ndist(1\n,2\n)is equal to the cost of a minimum-cost perfect matching in the bipartite graph having 1\nand2\nas the\ntwosidesof the bipartition.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •19\nInonline matching on the line with action predictions we assume that, in each round along with request , we\nobtain a prediction ⊆with||=on the server set that the oline optimal algorithm is using for the irst \nmany requests. We allow here even that ⊈+1. The error in round is given by :=(,Off), where\nOffistheserversetof a (ixed)oline algorithmon theinstance. The totalpredictionerror is =/summationtext.1\n=1.\nSincearequesthastobeirrevocablymatchedtoaserver,itisnotstraightforwardthatonecanswitchbetween\nconigurations of diferent algorithms. Nevertheless, we are able to simulate such a switching procedure. By\napplyingthisswitchingproceduretothebestknownclassiconlinealgorithmfortheproblem,duetoRaghvendra\n[52],anddesigningaFollow-The-Predictionalgorithmthatachievesacompetitiveratioof 1+2/Off,wecan\napply thecombiningmethodof Theorem 18 to get thefollowing result.\nTheorem (Restated Theorem 4). There exists a deterministic algorithm for the online matching on the line\nproblem with action predictions thatattainsacompetitiveratio of\nmin{(log),9+8\nOff},\nfor any oline algorithm Off.\nWenotethatforsomeinstancestheswitchingcostbetweenthesetwoalgorithms(andtherefore,inasense,also\nthemetricspacediameter)canbeashighas Θ(Opt)which renderstherandomizedcombinationuninteresting\nforthis particular problem.\n5.1 Apotential function\nWe deine the coniguration of an algorithm at some point in time as the set of servers which are currently\nmatchedto a request.\nForeachroundofthealgorithm,wedeine asthecurrentconigurationand asthepredictedconiguration,\nwhich verify||=||=. We deine a potential function after each round to beΦ=dist(,), and letbe\nthe associated matching between andthat realizes this distance, such that all servers in ∩are matched\ntothemselvesforzerocost.Weextend tothecompletesetofsevers bysetting ()=forall∉∪.\nTheintuitionbehindthepotentialfunctionisthatafterround onecansimulatebeinginconiguration instead\nof theactual coniguration , at an additionalexpense of Φ.\n5.2 Distance amongdiferent configurations\nThepurposeofthissectionistoshowthatthedistanceamongtheconigurationsoftwoalgorithmsisatmost\nthe sum of their current costs. As we will see, this will imply that we can aford switching between any two\nalgorithms.\nWecontinue bybounding thedistance between any twoalgorithms asa function of theircosts.\nLemma21. Considertwoalgorithms and,andixthesetofservers aswellastherequestsequence .Let\nandbe the respective conigurations of the algorithms(i.e.,currently matchedservers) after serving theirst \nrequests of with servers from . Furthermore, let Opt\n(resp.Opt\n) be the optimal matching between {1,2,...}\nand(resp.),and let\n(resp.\n) bethe correspondingmatching produced by (resp.).Then:\ndist(,)≤cost(Opt\n)+cost(Opt\n)\n≤cost(\n)+cost(\n).\nProof.Thesecondinequalityfollows bythe optimalityof Opt\nandOpt\n.Forthe irstinequalitylet \n(resp.\n\n) be the server matched to byOpt\n(resp.Opt\n), for all∈{1,...,}. Therefore, there exists a matching\nACM Trans. Algor.\n\n\n20 •Antoniadis et al.\nbetweenandthatmatches forall∈{1,...,},\nto\nwhich hasa totalcostof\n︁\n=1dist(\n−\n)≤︁\n=1dist(\n−)+︁\n=1dist(\n−)\n=cost(Opt\n)+cost(Opt\n),\nwhere the inequality follows by the triangle inequality. By the deinition of distance we have that dist(,)≤/summationtext.1\n=1dist(\n−\n), which concludestheproof. □\n5.3 Follow-The-Prediction\nSinceonlinematchingontheline isnotknowntobeinMTS,westartbyredeiningthealgorithmFollow-The-\nPrediction for this particular problem. In essence, the algorithm virtually switches from predicted coniguration\nto predictedconiguration +1.\nLetbetheactualsetofserversusedbyFollow-The-Predictionafterround .Follow-The-Predictioncomputes\ntheoptimalmatchingamong +1andthemultiset ∪{+1}whichmapstheelementsof +1∩tothemselves.\nNotethatif +1∈,then∪{+1}isamultisetwhere +1occurstwice.Suchmatchingwillmatch +1tosome\nserver∈+1\\.Recallthat istheminimumcostbipartitematchingbetween andextendedbyzero-cost\nedges to the whole set of servers. Follow-The-Prediction matches +1to the server (), i.e., to the server to\nwhichis matched to under . We can show easily that ()∉. Since∉, there are two possibilities: If\n∉,then()=∉byextensionof toelementswhichdonotbelongto nor.Otherwise, ∈\\\nand, since matchesall theelementsof ∩to themselves,wehave ()∈\\.\nTheorem 22. Follow-The-Prediction has total matching cost at most Off+2and therefore the algorithm has a\ncompetitiveratio of\n1+2/Off\nagainst any oline algorithm Off.\nProof.Theideabehind theproofisthat,bypayingtheswitchingcost of ΔΦateachround,wecanalways\nvirtually assume that we reside in coniguration . So whenever a new request +1and a new predicted\nconiguration +1arrive, we pay the costs for switching from to+1and for matching +1to a server in +1.\nWeirstshow that,forevery round , wehave:\n+ΔΦ≤dist(+1,∪{+1})\n⇔dist(+1,())+Φ+1≤dist(+1,∪{+1})+Φ.\nNote that for all ,Φ=dist(,)=dist(¯,¯), where¯and¯denote the complements of and\nrespectively.\nWehaveinaddition dist(¯,¯)=dist(¯\\{()},¯\\{})+dist(,())as∉and()∉,and(,())\nis an edge in the min-cost matching between ¯and¯. Note that +1=∪{()}so¯\\{()}=¯+1.\nTherefore, weget:\nΦ=dist(¯,¯)=dist(¯+1,¯\\{})+dist(,())=dist(+1,∪{})+dist(,()).\nIn addition, we have dist(+1,∪{+1})=dist(,+1)+dist(+1\\{},)because by deinition of ,is\nmatchedto +1inaminimumcostmatchingbetween +1and∪{+1}.Now,∉,sodist(+1\\{},)=\ndist(+1,∪{})asthisisequivalenttoaddingazero-lengthedgefrom toitselftotheassociatedmatching.\nTherefore, weget:\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •21\ndist(+1,∪{+1})=dist(,+1)+dist(+1,∪{}).\nCombining theresults above, weobtain:\n+ΔΦ≤dist(+1,∪{+1})\n⇔(+1,())+Φ+1≤dist(+1,∪{+1})+Φ\n⇔dist(+1,())+dist(+1,+1)\n≤dist(+1,∪{})+dist(,())+dist(,+1)+dist(+1,∪{})\nThe last equationholdsbythetriangleinequality.\nFinally, we bound dist(+1,∪{+1})using the triangle inequality. In the following Offrefers to the\nconigurationof oline algorithm Offaftertheirst requests havebeen served.\ndist(+1,∪{+1})\n≤dist(∪{+1},Off∪{+1})+dist(Off∪{+1},Off+1)+dist(Off+1,+1)\n≤+|Off|++1.\nSummingup overall rounds, and using that Φ1=Φ=0completes theproof of thetheorem. □\n5.4 The maintheorem\nThe goal of this subsectionisto proveTheorem 4.\nProofof Theorem4. The main idea behind the proof is to show that we can apply Theorem 18 and virtually\nsimulate thetwoalgorithms (Follow-The-Predictionand theonline algorithmof Raghvendra [52]).\nWeneedtoshowthatwecanassumethatweareinsomeconigurationandexecutingtherespectivealgorithm,\nandthattheswitchingcostbetweentheseconigurationsisupperboundedbythecostofthetwoalgorithms.\nSimilarlytotheanalysisofFollow-The-Prediction,wecanvirtuallybeinanyconigurationaslongaswepay\nforthedistance between anytwoconsecutive conigurations.Whenwe currently simulateanalgorithm , the\ndistance between the two consecutive conigurations is exactly the cost of the edge that introduces in this\nround.Whenweswitchfromtheconigurationofsomealgorithm totheconigurationofsomealgorithm ,\nthenbyLemma 21, thedistance between thetwoconigurations isat most thetotalcurrentcostof and.\nThis along with Theorem 24 (which is generalizing Theorem 18 beyond MTS and can be found in Appendix A)\nconcludestheproof. □\n5.5 Bipartitemetric matching\nBipartite metric matching is the generalization of online matching on the line where the servers and requests\ncan be points of any metric space. The problem is known to have a tight (2−1)-competitive algorithm, due to\nKalyanasundaramand Pruhs[36]aswell asKhuller et al. [39].\nWe notethat ourarguments in this sectionare not line-speciic andapplyto that problem aswell. Thisgives\nthefollowing result:\nTheorem 23. There exists a deterministic algorithm for the online metric bipartite matching problem with action\npredictions thatattainsacompetitiveratio of\nmin{2−1,9+8\nOff},\nACM Trans. Algor.\n\n\n22 •Antoniadis et al.\nagainst any oline algorithm Off.\n6 EXPERIMENTS\nWe evaluate the practicality of our approach on real-world datasets for two MTS: cachingandice cream problem.\nThe source code and datasets are available at GitHub8. Each experiment was run 10times and we report the\nmean competitiveratios. The maximumstandarddeviationweobservedwas of theorderof 0.001.\n6.1 The CachingProblem\nDatasets. Forthesake of comparability, weusedthesame twodatasets asLykouris and Vassilvitskii[46].\n•BKdataset comes from a former social network BrightKite [ 18]. It contains checkins with user IDs and\nlocations.Wetreatthesequenceofcheckinlocationsofeachusersasaseparateinstanceofcachingproblem.\nWe ilter users with the maximum sequence length ( 2100) who require at least 50evictions in an optimum\ncache policy. Outof those wetaketheirst 100instances. Wesetthecache size to =10.\n•CitidatasetcomesfromabikesharingplatformCitiBike [21].Foreachmonthof2017,weconsiderthe\nirst25000biketripsandbuildaninstancewherearequestcorrespondstothestartingstationofatrip.We\nsetthecache size to =100.\nPredictions. We irst generate the reoccurrence time predictions, these predictions being used by previous\nprediction-augmented algorithms. To this purpose, we use the same two predictors as Lykouris and Vassilvitskii\n[46]. Additionally we also consider a simple predictor, which we call POPU (from popularity ), and the LRU\nheuristicadaptedto serveasa predictor.\n•Synthetic predictions:we irst compute the exact reoccurrence timefor each request, setting itto the end\nof the instance if it does not reappear. We then add some noise drawn from a lognormal distribution, with\nthemean parameter 0and thestandarddeviation , in orderto model rarebut large failures.\n•PLECO predictions: we usethe PLECO modeldescribed inAndersonet al . [2], withthe sameparameters\nasLykourisandVassilvitskii [46],whichwereittedforthe BKdataset(butnotreittedfor Citi).Thismodel\nestimatesthat apagerequested stepsearlierwillbe thenextrequestwitha probabilityproportionalto\n(+10)−1.8−/670.Wesumtheweightscorrespondingtoalltheearlierappearancesofthecurrentrequest\nto obtain the probability that this request is also the next one. We then estimate that such a request will\nreappear 1/steps later.\n•POPUpredictions:ifthecurrentrequesthasbeenseeninafraction ofthepastrequests,wepredictit\nwill berepeated 1/steps later.\n•LRU predictions: Lykouris and Vassilvitskii [46]already remarked on (but did not evaluate experimentally)\na predictor that emulates the behavior of the LRU heuristic. A page requested at time is predicted to\nappearattime−.Notethatthealgorithmsonlyconsidertheorderofpredictedtimesamongpages,and\nnot theirvalues, so thenegativepredictions pointing to thepastarenot an issue.\nWethentransformthereoccurrencetimepredictionstoactionpredictionsbysimulatingthealgorithmthat\nevicts the element predicted to appear the furthest in the future. In each step the prediction to our algorithm\nistheconigurationofthisalgorithm.NotethatinthecaseofLRUpredictions,thepredictedconigurationis\npreciselytheconigurationof theLRU algorithm.\nAlgorithms. Weconsideredthefollowingalgorithms,whosecompetitiveratiosarereportedinTable1.Two\nonline algorithms: the heuristic LRU, which is considered the gold standard for caching, and the (log)-\ncompetitiveMarker[ 29].Threerobustalgorithmsfromtheliteratureusingthe“next-arrivaltimežpredictions:\n8https://github.com/adampolak/mts-with-predictions\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •23\nAlgorithm Competitive ratio Property Reference\nLRU  [55]\nMarker (log) Robust [28]\nFtP 1+4\nOptC+S Lemma 17\nL&V 2+(min{︃\n′\nOpt,log}) C+S+R [46]\nRobustFtP(1+)min{1+4\nOpt,(log)}C+S+R Theorem 2\nLMarker (1+min{log′\nOpt,log)} C+S+R [53]\nLNonMarker (1+min{1,′\n·Opt}log)C+S+R [53]\nTrust&Doubt (min{1+log(1+\nOpt),log})C+S+R Theorem 3\nTable 1. Summary of caching algorithms evaluated in experiments. Note that and′are diferent measures of prediction\nerror, so their functions should not be compared directly. Properties C+S+R mean Consistency, Smoothness, and Robustness\nrespectively.\nL&V[46],LMarker[ 53],andLNonMarker[ 53].Threealgorithmsusingthepredictionsetupwhichisthefocusof\nthispaper: FtP,whichnaivelyfollowsthepredictedstate,RobustFtP,whichisdeinedas (FtP,Marker),\nandisaninstanceofthegeneralMTSalgorithmdescribedinSection4,and Trust&Doubt,thecachingalgorithm\ndescribedinSection3.\nWe implemented the deterministic and randomized combination schemes described in Section 4.2 with a\nsubtlety for the caching problem: we do not lush the whole cache when switching algorithms, but perform only\na single eviction per page fault in the same way as described in Remark 9. We set the parameters to =1+0.01\nand=0.5. These values, chosen from {0.001,0.01,0.1,0.5}, happen to be consistently the best choice in all our\nexperimental settings.\n0\n 50\n 100\n 150\n 200\nNoise parameter ofthe synthetic predictor\n1.0\n1.1\n1.2\n1.3\n1.4Competitiveratio\nLRU\nMarker\nFtP\nL&V\nRobustFtP\nTrust&Doubt\nFig.2. Comparison ofcaching algorithmsaugmentedwithsyntheticpredictions on the BKdataset.\nACM Trans. Algor.\n\n\n24 •Antoniadis et al.\nDataset BK Citi\nLRU 1.291 1.848\nMarker 1.333 1.861\nPredictions PLECO POPU LRU PLECO POPU LRU\nFtP 2.081 1.707 1.291 2.277 1.734 1.848\nL&V 1.340 1.262 1.291 1.877 1.776 1.848\nLMarker 1.337 1.264 1.291 1.876 1.780 1.848\nLNonMarker 1.333 1.292 1.299 1.862 1.771 1.855\nRobustFtP 1.338 1.316 1.297 1.862 1.831 1.849\nTrust&Doubt 1.292 1.276 1.291 1.847 1.775 1.849\nTable 2. Competitive ratiosofcaching algorithmsusing PLECO,POPU,andLRUpredictions on both datasets.\nResults.For both datasets, foreach algorithmand each prediction considered,we computed thetotal number\nofpagefaultsoveralltheinstancesanddivideditbytheoptimalnumberinordertoobtaina competitiveratio .\nFigure2presentstheperformanceofaselectionofthealgorithmsdependingonthenoiseofsyntheticpredictions\nfor theBKdataset. We omit LMarker and LNonMarker for readability since they perform no better than L&V.\nThis experiment shows that our algorithm Trust&Doubtoutperforms previous prediction-based algorithms as\nwellasLRU onthe BKdatasetwith suchpredictions.Figures3and 4presenttheperformanceofall algorithms\nontheBKandCitidatasets,respectively.Onthe Citidataset(Figure4), FtPachievesverygoodresultseven\nwithanoisysynthetic predictor,andthereforeRobustFtP surpassesotherguaranteedalgorithms.LNonMarker\npresents betterperformancefornoisy predictions thantheother algorithms.\nIn Table 2 we provide the results obtained on both datasets using PLECO, POPU, and LRU predictions. We\nobserve that PLECO predictions are not accurate enough to allow previously known algorithms to improve over\ntheMarkeralgorithm.Thismaybeduetothesensitivityofthispredictortoconsecutiveidenticalrequests,which\nare irrelevant for the caching problem. However, using the simple POPU predictions enables the prediction-\naugmentedalgorithmstosigniicantlyimprovetheirperformancecomparedtotheclassicalonlinealgorithms.\nUsingTrust&Doubtwith either of the predictions is however suicient to get a performance similar or better\nthanLRU(andthanallotheralternatives,exceptedforPOPUpredictionsontheBKdataset).RobustFtP,although\nbeing averygenericalgorithmwithworse theoretical guarantees than Trust&Doubt,achieves aperformance\nwhich is not that far from previously known algorithms. Note that we did not use a prediction model tailored to\nour setup, which suggeststhat even better results can be achieved. Whenwe use the LRU heuristic as a predictor,\nall the prediction-augmented algorithms perform comparably to the bare LRU algorithm. For Trust&Doubt\nand RobustFTP, there is a theoretical guarantee that this must be the case: Since the prediction error with\nrespect to LRU is 0, these algorithms are (1)-competitive against LRU. Thus, Trust&Doubtachieves both the\npractical performanceof LRUwithan exponentiallybetter worst-caseguarantee than LRU.NotethatLykouris\nand Vassilvitskii [46]also discuss how their algorithm framework performs when using LRU predictions, but did\nnot provide both of thesetheoretical guaranteessimultaneously.\n6.2 ASimpleMTS:the Ice Cream Problem\nWe consider a simple MTS example from Chrobak and Larmore [19], namedice cream problem. It it an MTS with\ntwostates,named and,atdistance 1fromeachother,andtwotypesofrequests, and.Servingarequest\nwhilebeinginthematchingstatecosts 1forand2for,andthecostsaredoubledforthemismatchedstate.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •25\n0\n 25\n 50\n 75\n 100\n 125\n 150\n 175\n 200\nNoiseparameter ofthe syntheticpredictor\n1.0\n1.1\n1.2\n1.3\n1.4Competitive ratio\nLRU\nMarkerFtP\nL&V\nRobustFtP\nLMarker\nLNonMarker\nTrust&Doubt\nFig.3. Comparison ofcaching algorithmsaugmentedwithsyntheticpredictions on the BKdataset.\n0\n 25\n 50\n 75\n 100\n 125\n 150\n 175\n 200\nNoiseparameter ofthe syntheticpredictor\n1.0\n1.2\n1.4\n1.6\n1.8Competitive ratio\nLRU\nMarkerFtP\nL&V\nRobustFtP\nLMarker\nLNonMarker\nTrust&Doubt\nFig.4. Comparison ofcaching algorithmsaugmentedwithsyntheticpredictions on the Citidataset.\nThe problem is motivated by an ice cream machine which operates in two modes (states) ś vanilla or chocolate ś\neachfacilitatinga cheaperproductionof a typeof ice cream(requests).\nWe use the BrightKitedataset to prepare test instances forthe problem. We extract the same 100users asfor\ncaching. For each user we look at the geographic coordinates of the checkins, and we issue a request for each\ncheckininthenorthmosthalf,and a request foreach checkin in thesouthmost half.\nInordertoobtainsyntheticpredictions,weirstcomputetheoptimalolinepolicy,usingdynamicprogramming.\nThen, for an error parameter , for each request we follow the policy with probability 1−, and do the opposite\nwithprobability .\nWe consider the following algorithms: the Work Function algorithm [11, 12],of competitive ratio of 3in this\nsetting (2−1in general); FtP, deined in Section 4 (in case of ties in Equation 5, we follow the prediction); and\nACM Trans. Algor.\n\n\n26 •Antoniadis et al.\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\nErrorprobability ofthe syntheticpredictor\n1.00\n1.02\n1.04\n1.06\n1.08\n1.10Competitive ratio\nWork Function\nFtP\nRobustFtP deterministic\nRobustFtP randomized\nFig.5. Performanceon the ice creamproblem withsyntheticpredictions.\nthedeterministicandrandomizedcombination ofthetwoabovealgorithms(withthesame andaspreviously)\nasproposedinSection4.\nFigure 5 presents the competitive ratios we obtained. We can see that the general MTS algorithms we propose\nin Section 4 allow to beneit from good predictions while providing the worst-case guarantee of the classical\nonline algorithm. The deterministic and randomized combinations are comparable to the best of the algorithms\ncombined,and improveupon themwhen both algorithms havea similar performance.\n7 CONCLUSION\nInthispaper,weproposedapredictionsetupthatallowedustodesignageneralprediction-augmentedalgorithm\nforalargeclassofproblemsencompassingMTS.FortheMTSproblemofcachinginparticular,thesetuprequires\nlessinformationfromthepredictorthanpreviouslystudiedones(sincepreviouspredictionscanbeconverted\nto ours). Despite the more general setup, we can design a speciic algorithm for the caching problem in our\nsetup which ofers guarantees of a similar lavor to previous algorithms and even performs better in most of our\nexperiments.\nIt may be considered somewhat surprising that a better bound is attainable for caching than for general\nMTS, given that our lower bound instance for MTS uses a uniform metric (and caching with a (+1)-point\nuniverse also corresponds to a uniform metric). We conjecture logarithmic smoothness guarantees are also\nattainableforotherMTSproblemswitharequeststructuresimilartocaching,likeweightedcachingandthe\n-serverproblem.FurtherspecialcasesofMTScanbeobtainedbyrestrictingthenumberofpossibledistinct\nrequests (forexample an MTS withtwo diferent possible requests can model an important power management\nproblem[ 33]),orrequiringaspeciicstructurefromthemetricspace.SeveralsuchparametrizationsofMTSwere\nconsidered by Bubeck and Rabani [16]and it would be interesting to study whether an improved dependence on\nthepredictionerror can beobtainedin such settings.\nWith respect to matching problems, there have been recent investigations through the lens of learning\naugmentation under speciic matroid constraints in [ 4], but this territory is still largely unexplored. It would also\nbeinterestingtoevaluateourresourceaugmentedalgorithmforonlinemetricmatchingsinreal-lifesituations.\nAs an example online matching algorithms are employed in several cities in order to match cars to parking spots\n(for example SFpark in San Francisco or ParkPlus in Calgary). Not only have such matching problems been\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •27\nstudiedfrom an algorithmic point of view (see e.g. Bender et al . [8], [9]), but arguably it should be doable to\ngeneratehigh-quality predictions from historical datamakingour approach very promising.\nAnotherresearchdirectionistoidentifymoresophisticatedpredictorsforcachingandotherproblemsthat\nwill furtherenhancetheperformanceof prediction-augmentedalgorithms.\nACKNOWLEDGMENTS\nTheauthorswouldliketothankIGAFITfortheorganizationoftheAlgPiEworkshopwhichmadethisproject\npossible. Antonios Antoniadis was supported by DFG Grant AN 1262/1-1, Christian Coester by NWO VICI grant\n639.023.812 of Nikhil Bansal, Marek Eliáš by ERC Starting Grant 759471 of Michael Kapralov, Adam Polak by\nNational Science Center of Poland grant 2017/27/N/ST6/01334 and by Swiss National Science Foundation within\ntheproject LatticeAlgorithmsandIntegerProgramming (185030),andBertrandSimonbytheDFGProjectNumber\n146371743śTRR89InvasiveComputing.\nA DETERMINISTICCOMBINATIONOFACOLLECTION OFALGORITHMS\nWe consider a problem andalgorithms 0,1,...,−1for this problem which fulill the following require-\nments.\n•0,...,−1startat thesame stateand weareable to simulate therun of all of themsimultaneously\n•for two algorithms and, the cost of switching between their states is bounded by cost()+cost().\nTheorem24(RestatedTheorem18;generalizationofTheorem1inFiatetal . [29]).Givenon-line\nalgorithms 0,...−1foraproblem whichsatisfytherequirementsabove,thealgorithm withparameter\n1<≤2incurscostat most\n/︁arenleftbigg2\n−1+1/︁arenrightbigg\n·min\n{cost(())},\non any input instance such that Opt≥1. If we choose =\n−1, the coeicient2\n−1+1equals9if=2and can\nbebounded by 2.\nNote that assumption on Opt≥1is just to take care of the corner-case instances with very small costs. If we\ncan only assume Opt≥for some 0<<1, then we scale all the costs fed to by1/and instances\nwithOpt=0are usually not very interesting. The value of is usually clear from the particular problem in\nhand,e.g., forcaching weonlycareaboutinstances which needat leastone page fault, i.e., Opt≥1.\nProof.Let us consider the ℓ-th cycle of the algorithm and denote =ℓmodand′=(ℓ−1)mod. We\nareswitchingfromalgorithm ′,whosecurrentcostwedenote cost′(′)=ℓ−1to,whosecurrentcostwe\ndenotecost′(),anditscostattheendofthiscyclewillbecome cost()=ℓ.Ourcostduringthiscycle,i.e.,\nforswitching and forexecutionof , isat most\ncost′(′)+cost′()+(cost()−cost′())=cost′(′)+cost()=ℓ−1+ℓ.\nNow, let us consider the last cycle , when we run the algorithm number =mod. By the preceding\nequation,thetotalcostof can beboundedas\ncost()≤2·−1︁\nℓℓ+cost()=2−1\n−1+cost()≤2\n−1+cost().\nACM Trans. Algor.\n\n\n28 •Antoniadis et al.\nIf<, we use the fact that Opt≥1and therefore the cost of each algorithm processing the whole instance\nwouldbeat leastone. Therefore, wehave\ncost()≤2\n−1+≤2\n−1·min\n{cost()},\nbecause\n−1+=+1\n−1and+1≤.\nNow, wehave ≥, denoting =mod, and wedistinguishtwocases.\n(1)Ifmin{cost()}=cost(), thencost()≥−foreach, and therefore\ncost()\nmin{cost()}≤2\n−1+cost()\nmin{cost()}\nNotethat cost()≥−, its costfrom theprevious usage. Since min{cost()}=cost(), weget\ncost()\nmin{cost()}≤2\n−1+1.\n(2)Otherwise, wehave min{cost()}≥−+1andcost()≤and therefore\ncost()\nmin{cost()}≤2−1\n−1+−1≤2\n−1.\nFor=\n−1wehave\n2\n−1+1=2(−1)/︁arenleftBig\n−1/︁arenrightBig\n+1,\nwhich equals 9for=2and can beboundedby 2.\n□\nB COMPARISONBETWEEN TRUST&DOUBTANDTHE BEST MARKING ALGORITHM\nThealgorithm Trust&Doubtdoesnotbelongtothebroadclassof markingalgorithms.Wenoticeinthissection\nthat,givenperfectpredictions,thispropertyallowsittooutperformallmarkingalgorithmsonsomeinstances,\nbut, at the same time, it does not always perform as well as the best marking algorithm even when given perfect\npredictions.\nRemark 25. With perfectly accurate predictions, there exist both a caching instance on which Trust&Doubtper-\nformsbetterthanthebestmarkingalgorithm,andanothercachinginstanceonwhich Trust&Doubtisoutperformed\nby amarking algorithm.\nProof.We irst build an instance where Trust&Doubt, given predictions corresponding to the optimal\nalgorithmevictingthepagearrivingthefurthestinthefuture,outperformsthebestmarkingalgorithm.Consider\nacacheofsize3andtherequestsequence1,2,3;4,5,6;1,2,3,composedofthreephasesoflengththree(separated\nby semicolons). Trust&Doubtkeeps the pages 1 and 2 in cache during the second phase so sufers seven cache\nmisses.The bestmarking algorithmisnot able to keepsuch oldpagesin cache so sufers nine cache misses.\nNow, we build an instance where Trust&Doubt, given again predictions corresponding to the optimal\nalgorithm evicting the page arriving the furthest in the future, sufers more cache misses than the best marking\nalgorithm. Consider a cache of size 3, and the request sequence 1, 2, 3; 4, 5, 6, 5, 6; 7, 1, 4, composed of three\nphasesoflengththree,iveandthree.Thebestmarkingalgorithmsuferseightcachemisses,thepage4being\npresent in the cache for the last request. The cache of Trust&Doubtafter the second phase contains 1, 5, 6, as\nthepage1 is given priorityoverthepage4, and, at thestartofthelastphase,thenowancientpage1 is evicted,\nso thealgorithmsufers nine cache misses. □\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •29\nC LIMITATIONSOFTHE REOCCURRENCE TIME PREDICTIONS\nInthissection,weproveTheorem5.Inpreviousworksoncaching[ 46,53,56],thepredictionsarethetime ofthe\nnext reoccurrence toeach page.It isnatural totry extendingthis typeof predictions to otherproblems, such as\nweightedcaching.Inweightedcachingeachpagehasaweight/costthatispaideachtimethepageentersthe\ncache. However, it turns out that even with perfect predictions of this type for weighted caching, one cannot\nimproveuponthe competitive ratio Θ(log),whichcanalreadybe attained withoutpredictions [ 5].Ourproof is\nbasedonaknownlowerboundforMTSonaso-called“superincreasingžmetric[ 37].Followingapresentation\nofthislowerboundby[ 42],wemodifythelowerboundsothattheperfectpredictionsprovidenoadditional\ninformation.\nWecallanalgorithmforweightedcaching semi-online ifitisonlineexceptthatitreceivesineachtimestep,as\nan additional input, the reoccurrence time of the currently requested page (guaranteed to be without error). We\nprovethefollowing result:\nTheorem(RestatedTheorem5). Everyrandomizedsemi-onlinealgorithmforweightedcachingis Ω(log)-\ncompetitive.\nProof.Let>0besomelargeconstant.Consideraninstanceofweightedcachingwithcachesize and+1\npages,denoted bythe numbers 0,...,, and such that theweight of page is2. It issomewhat easier to think\nof the following equivalent evaderproblem: Let be the weighted star with leaves 0,1,...,and such that leaf\nisatdistance fromtheroot.Asingleevaderislocatedinthemetricspace.Wheneverthereisarequestto\npage, the evader must be located at some leaf of other than . The cost is the distance traveled by the evader.\nAnyweightedcachingalgorithmgivesrisetotheevaderalgorithmthatkeepsitsevaderattheoneleafthatis\nnotcurrently in the algorithm’s cache. The cost between the two models difers only by an additive constant\n(depending on and).\nForℎ=1,...,andanon-emptytimeinterval (,),wewilldeineinductivelyarandomsequence ℎ=ℎ(,)\nof requests to theleaves 0,...,ℎ, such thateach request arrivesin thetime interval (,)and\nℎ≥4ℎ−1ℎ≥ℎ·Optℎ, (6)\nwhereℎdenotes the expected cost of an arbitrary semi-online algorithm to serve the random sequence ℎ\nwhile staying among the leaves 0,...,ℎ,Optℎdenotes the expected optimal oline cost of doing so with an\noline evader that starts and ends at leaf 0,0=1+\n4, andℎ=1/2+logℎforℎ≥1, where>0is a constant\ndeterminedlater.Theinequalitybetweentheirstandlasttermin (6)impliesthetheorem.Wewillalsoensure\nthat(0,1,...,ℎ)isboth a preix and a suix of thesequenceof requests in ℎ.\nFor the base case ℎ=1, the inequality is satisied by the request sequence 1that requests irst 0and then 1at\narbitrary timeswithin theinterval (,).\nForℎ≥2,therequestsequence ℎconsistsofsubsequences(iterations)ofthefollowingtwotypes(wewill\nonly describe the sequence of request locations for now and later how to choose the exact arrival times of these\nrequests):A type1iteration isthesequence(0,1,...,ℎ).Atype2iteration istheconcatenationof ⌈ℎ\nℎ−1Optℎ−1⌉\nindependent samples of a random request sequence of the form ℎ−1. The request sequence ℎis formed by\nconcatenating⌈8ℎ−1⌉iterations, where each iterationis chosen uniformly at random to be of type 1 or type 2. If\nthe last iteration is of type 2, an additional inal request at ℎis issued. Thus, by induction, (0,...,ℎ)is both a\npreix and a suix of ℎ.\nWenextshow (6)undertheassumptionthatatthestartofeachiteration,theiterationisoftype1or2each\nwith probability 1/2even when conditioned on the knowledge of the semi-online algorithm at that time. We will\nlater show how to design the arrival times of individual requests so that this assumption is satisied. We begin by\nproving the irst inequality of (6). We claim that in each iteration of ℎ, the expected cost of any semi-online\nalgorithm (restrictedto staying at the leaves 0,...,ℎ)isat least ℎ/2. Indeed,if the evaderstartstheiteration at\nACM Trans. Algor.\n\n\n30 •Antoniadis et al.\nleafℎ, then with probability 1/2we have a type 1iteration forcing the evader to vacate leaf ℎfor costℎ, giving\nanexpectedcostof ℎ/2.Iftheevaderisatoneoftheleaves 0,...,ℎ−1,thenwithprobability 1/2wehaveatype\n2 iteration. In this case, it must either move to ℎfor cost at least ℎ, or⌈ℎ\nℎ−1Optℎ−1⌉times it sufers expected cost\nat leastℎ−1Optℎ−1by the induction hypothesis. So again, the expected cost is at least ℎ/2. Sinceℎconsists of\n⌈8ℎ−1⌉iterations, wehave\nℎ≥4ℎ−1ℎ,\ngiving theirstinequality of (6).\nToshow thesecond inequality of (6),we describe an oline strategy.With probability 2−⌈8ℎ−1⌉,all iterations\nofℎare of type 2. In this case, the oline evader moves to leaf ℎat the beginning of ℎand back to leaf 0upon\nthe one request to ℎat the end of ℎ, for total cost 2(1+ℎ). With the remaining probability, there is at least one\ntype1iteration.Conditionedonthisbeingthecase,theexpectednumberoftype1iterationsis ⌈8ℎ−1+1⌉/2,\nand the expected number of type 2 iterations is ⌈8ℎ−1−1⌉/2. The oline evader can serve each type 1 iteration\nforcost2(1+)andeachtype2iterationforexpectedcost ⌈ℎ\nℎ−1Optℎ−1⌉Optℎ−1,anditinisheseachiteration\nat leaf0. (Thus, if the last iteration is of type 2, then the inal request to ℎincurs no additional cost.) By the\ninductionhypothesis, Optℎ−1≤(ℎ−1). Hence, wecan rewrite theexpectedcostof a type2 iteration as\n/ceilingleftbiggℎ\nℎ−1Optℎ−1/ceilingrightbigg\nOptℎ−1=(1+(1))ℎ\nℎ−1,\nas→∞.Sinceℎ≥2,theexpectedcostofalltype1iterationsisonlyan (1)fractionoftheexpectedcostof\nthetype2 iterations. Overall, weget\nOptℎ≤2−⌈8ℎ−1⌉2(1+ℎ)+\n(1+(1))/︁arenleftBig\n1−2−⌈8ℎ−1⌉/︁arenrightBig⌈8ℎ−1−1⌉\n2ℎ\nℎ−1\n≤(1+(1))/bracketleftBig\n2−⌈8ℎ−1⌉2ℎ+/︁arenleftBig\n1−2−⌈8ℎ−1⌉/︁arenrightBig\n4ℎ/bracketrightBig\n=(1+(1))/︁arenleftBig\n1−2−⌈8ℎ−1⌉−1/︁arenrightBig\n4ℎ\n≤4ℎ\n1+2−⌈8ℎ−1⌉−1.\nWeobtain thesecondinequality in (6)by\n4ℎ−1ℎ\nOptℎ≥ℎ−1/︁arenleftBig\n1+2−⌈8ℎ−1⌉−1/︁arenrightBig\n≥1\n2+log(ℎ−1)+2−8log(ℎ−1)−7\n≥1\n2+log(ℎ−1)+\nℎ−1\n≥1\n2+logℎ\n=ℎ,\nwherethethirdinequality holdsfor =2−7.\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •31\nIt remains to deine to deine the arrival times for the requests of sequence ℎwithin the interval (,). We do\nthisasfollows:Let ≥1bethenumberofrequeststoleaf ℎinℎ.Theserequeststo ℎwillbeissuedattimes\n+(−)/summationtext.1\n=12−for=1,...,.\nTo deine the arrival times of the other requests, we will maintain a time variable ∈[,)indicating the\ncurrenttime, and a variable >indicating the time of the nextrequest to leaf ℎafter time . Initially, :=and\n:=(+)/2.Considertheirstiterationforwhichthearrivaltimeshavenotbeendeinedyet.Iftheiterationis\nof type 2, we choose the arrival times according to the induction hypothesis so that all subsequences ℎ−1within\nthe iteration it into the time window (,(+)/2), and we update :=(+)/2. If the iteration is of type 1,\nsampleatype2iteration andlet1,...,ℎ−1besuchthat wouldbethetimeofthenextrequesttopage if\nthenextiterationwerethisiteration oftype2insteadofatype1iteration.Wedeinethearrivaltimesofthe\n(single)request to leaf <ℎin this type1 iterationto be .If thiswasnot the lastiteration, we update :=and\nincreaseto thetime of thenextrequest to ℎ(asdeinedabove).\nNoticethatatthebeginningofeachiterationwithin ℎ,orderingthepagesbythetimeoftheirnextrequest\nalwaysyieldsthesequence 0,1,...,,andthetimeofthenextrequesttoeachpageisindependentofwhether\nthenextiterationisoftype1ortype2.Thus,aspromised,whetherthenextiterationisoftype1ortype2is\nindependent of theknowledge of thesemi-online algorithm. □\nREFERENCES\n[1]Keerti Anand, Rong Ge, and Debmalya Panigrahi. 2020. Customizing ML predictions for online algorithms. In International Conference\nonMachine Learning . PMLR,303ś313.\n[2]Ashton Anderson, Ravi Kumar, Andrew Tomkins, and Sergei Vassilvitskii. 2014. The dynamics of repeat consumption. In Proceedings of\nconferenceWorld Wide Web ’14 . 419ś430. https://doi.org/10.1145/2566486.2568018\n[3]SpyrosAngelopoulos,ChristophDürr,ShendanJin,ShahinKamali,andMarcRenault.2020. OnlineComputationwithUntrustedAdvice.\nInProceedingsof ITCS’20 , Vol.151.52:1ś52:15. https://doi.org/10.4230/LIPIcs.ITCS.2020.52\n[4]AntoniosAntoniadis,ThemisGouleakis,PieterKleer,andPavelKolev.2020. SecretaryandOnlineMatchingProblemswithMachine\nLearned Advice. In Proceedingsof NeurIPS’20 .\n[5]Nikhil Bansal, Niv Buchbinder, and Joseph Naor. 2012. A Primal-Dual Randomized Algorithm for Weighted Paging. J. ACM59, 4 (2012),\n19:1ś19:24. https://doi.org/10.1145/2339123.2339126\n[6]NikhilBansal,ChristianCoester,RaviKumar,ManishPurohit,andErikVee.2022. Learning-AugmentedWeightedPaging.In Proceedings\nof the Thirty-ThirdAnnualACM-SIAM SymposiumonDiscreteAlgorithms (SODA’22) .\n[7]L. A. Belady. 1966. A Study of Replacement Algorithms for a Virtual-Storage Computer. IBM Syst. J. 5, 2 (1966), 78ś101. https:\n//doi.org/10.1147/sj.52.0078\n[8]Max Bender, Jacob Gilbert, Aditya Krishnan, and Kirk Pruhs. 2020. Competitively Pricing Parking in a Tree. In WINE (Lecture Notes in\nComputer Science,Vol. 12495) . Springer, 220ś233.\n[9]MaxBender,JacobGilbert,andKirkPruhs.2021. APoly-logCompetitivePosted-PriceAlgorithmforOnlineMetricalMatchingona\nSpider. In FCT (Lecture Notes inComputer Science,Vol. 12867) . Springer, 67ś84.\n[10]Avrim Blum and Carl Burch. 2000. On-line Learning and the Metrical Task System Problem. Machine Learning 39, 1 (2000), 35ś58.\nhttps://doi.org/10.1023/A:1007621832648\n[11] AllanBorodin andRan El-Yaniv. 1998. Online computationandcompetitive analysis . CambridgeUniversityPress.\n[12]Allan Borodin, Nathan Linial, and Michael E. Saks. 1992. An Optimal On-Line Algorithm for Metrical Task System. J. ACM39, 4 (1992),\n745ś763. https://doi.org/10.1145/146585.146588\n[13]JoanBoyar,LeneM.Favrholdt,ChristianKudahl,KimS.Larsen,andJesperW.Mikkelsen.2017. OnlineAlgorithmswithAdvice:A\nSurvey.ACM Comput.Surv. 50, 2(2017), 19:1ś19:34. https://doi.org/10.1145/3056461\n[14]Sébastien Bubeck, Michael B. Cohen, James R. Lee, and Yin Tat Lee. 2019. Metrical task systems on trees via mirror descent and unfair\ngluing.In ProceedingsoftheThirtiethAnnualACM-SIAMSymposiumonDiscreteAlgorithms,SODA2019,SanDiego,California,USA,\nJanuary 6-9, 2019 . 89ś97. https://doi.org/10.1137/1.9781611975482.6\n[15]SébastienBubeck andYuvalRabani.2020. ParametrizedMetrical TaskSystems.In Approximation, Randomization, and Combinatorial\nOptimization. AlgorithmsandTechniques(APPROX/RANDOM 2020) .\n[16]SébastienBubeckandYuvalRabani.2020. ParametrizedMetricalTaskSystems.In APPROX-RANDOM (LIPIcs,Vol.176) .SchlossDagstuhl\n-Leibniz-ZentrumfürInformatik,54:1ś54:14.\nACM Trans. Algor.\n\n\n32 •Antoniadis et al.\n[17]Jakub Chłędowski, Adam Polak, Bartosz Szabucki, and Konrad Tomasz Żołna. 2021. Robust Learning-Augmented Caching: An\nExperimental Study. In Proceedings of the 38th International Conference on Machine Learning (Proceedings of Machine Learning Research,\nVol. 139). PMLR,1920ś1930. https://proceedings.mlr.press/v139/chledowski21a.html\n[18]EunjoonCho,SethAMyers,andJureLeskovec.2011. Friendshipandmobility:usermovementinlocation-basedsocialnetworks.In\nProceedingsof SIGKDD’11 . 1082ś1090. https://doi.org/10.1145/2020408.2020579\n[19]Marek Chrobak and Lawrence L Larmore. 1998. Metrical task systems, the server problem and the work function algorithm. In Online\nAlgorithms . Springer, 74ś96. https://doi.org/10.1007/BFb0029565\n[20]Thomas H. Chung. 1994. Approximate Methods for Sequential Decision Making Using Expert Advice. In Proceedings of COLT’94 .\nAssociationforComputingMachinery, 183ś189. https://doi.org/10.1145/180139.181097\n[21] CitiBike. 2017. Citi BikeTrip Histories. https://www.citibikenyc.com/system-data. Accessed:02/02/2020.\n[22]Christian Coester and Elias Koutsoupias. 2019. Theonline -taxi problem..In Proceedings of the 51stAnnualACM SIGACTSymposium\nonTheory of Computing,STOC 2019 . 1136ś1147. https://doi.org/10.1145/3313276.3316370\n[23]Christian Coester and James R. Lee. 2019. Pure entropic regularization for metrical task systems. In Conference on Learning Theory,\nCOLT 2019 . 835ś848.\n[24]Amit Daniely and Yishay Mansour. 2019. Competitive ratio vs regret minimization: achieving the best of both worlds. In Proceedings of\nALT 2019 . 333ś368. http://proceedings.mlr.press/v98/daniely19a.html\n[25]Sina Dehghani, Soheil Ehsani, MohammadTaghi Hajiaghayi, Vahid Liaghat, and Saeed Seddighin. 2017. Stochastic k-Server: How\nShouldUberWork?.In 44thInternationalColloquiumonAutomata,Languages,andProgramming(ICALP2017) ,Vol.80.126:1ś126:14.\nhttps://doi.org/10.4230/LIPIcs.ICALP.2017.126\n[26]Yuval Emek, Pierre Fraigniaud, Amos Korman, and Adi Rosén. 2011. Online computation with advice. Theor. Comput. Sci. 412, 24 (2011),\n2642ś2656. https://doi.org/10.1016/j.tcs.2010.08.007\n[27]Amos Fiat, Dean P. Foster, Howard J. Karlof, Yuval Rabani, Yiftach Ravid, and Sundar Vishwanathan. 1998. Competitive Algorithms for\nLayered GraphTraversal. SIAMJ.Comput. 28, 2(1998), 447ś462. https://doi.org/10.1137/S0097539795279943\n[28]AmosFiat,RichardM.Karp,MichaelLuby,LyleA.McGeoch,DanielDominicSleator,andNealE.Young.1991. CompetitivePaging\nAlgorithms. J.Algorithms 12, 4(1991), 685ś699. https://doi.org/10.1016/0196-6774(91)90041-V\n[29]Amos Fiat, Yuval Rabani, and Yiftach Ravid. 1994. Competitive k-Server Algorithms. J. Comput. Syst. Sci. 48, 3 (1994), 410ś428.\nhttps://doi.org/10.1016/S0022-0000(05)80060-1\n[30]Yoav Freund and Robert E Schapire. 1997. A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting. J.\nComput.System Sci. 55, 1(1997), 119ś139. https://doi.org/10.1006/jcss.1997.1504\n[31]Bernhard Fuchs, Winfried Hochstättler, and Walter Kern. 2005. Online matching on a line. Theor. Comput. Sci. 332, 1-3 (2005), 251ś264.\nhttps://doi.org/10.1016/j.tcs.2004.10.028\n[32]Sreenivas Gollapudi and Debmalya Panigrahi. 2019. Online Algorithms for Rent-Or-Buy with Expert Advice. In Proceedings of ICML’19 .\n2319ś2327. http://proceedings.mlr.press/v97/gollapudi19a.html\n[33]SandyIrani,SandeepShukla,andRajeshGupta.2003. OnlineStrategiesforDynamicPowerManagementinSystemswithMultiple\nPower-Saving States. ACM Trans. Embed. Comput.Syst. 2,3(2003), 325ś346. https://doi.org/10.1145/860176.860180\n[34]Akanksha Jain andCalvin Lin. 2016. Back tothe Future: Leveraging Belady’s Algorithm forImprovedCacheReplacement. SIGARCH\nComput.Archit. News 44, 3(June2016),78ś89. https://doi.org/10.1145/3007787.3001146\n[35]ZhihaoJiang, Debmalya Panigrahi, andKevin Su. 2020. Online Algorithms forWeightedPaging withPredictions. In 47th International\nColloquium onAutomata, Languages,andProgramming(ICALP 2020) .\n[36]Bala Kalyanasundaram and Kirk Pruhs. 1993. Online Weighted Matching. J. Algorithms 14, 3 (1993), 478ś488. https://doi.org/10.1006/\njagm.1993.1026\n[37]HowardJ.Karlof,YuvalRabani,andYiftachRavid.1994. LowerBoundsforRandomizedk-ServerandMotion-PlanningAlgorithms.\nSIAMJ.Comput. 23, 2(1994), 293ś312. https://doi.org/10.1137/S0097539792224838\n[38]Elias B. Khalil, Bistra Dilkina, George L. Nemhauser, Shabbir Ahmed, and Yufen Shao. 2017. Learning to Run Heuristics in Tree Search.\nInProceedingsof IJCAI’17 . 659ś666. https://doi.org/10.24963/ijcai.2017/92\n[39]Samir Khuller, Stephen G. Mitchell, and Vijay V. Vazirani. 1994. On-Line Algorithms for Weighted Bipartite Matching and Stable\nMarriages. Theor.Comput.Sci. 127,2(1994), 255ś267. https://doi.org/10.1016/0304-3975(94)90042-6\n[40]Tim Kraska, Alex Beutel, Ed H. Chi, Jefrey Dean, and Neoklis Polyzotis. 2018. The Case for Learned Index Structures. In Proceedings of\nSIGMOD’18 . 489ś504. https://doi.org/10.1145/3183713.3196909\n[41]Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. 2020. Online Scheduling via Learned Weights. In\nProceedingsof the Thirty-FirstAnnualACM-SIAM SymposiumonDiscreteAlgorithms (SODA’20) . 1859ś1877.\n[42]JamesR. Lee.2018. LowerboundsforMTS. Lecture notes. https://tcsmath.github.io/online/2018/04/20/mts-lower-bounds/ Accessed:\n02/02/2020.\n[43]MinghongLin,AdamWierman,LachlanL.H.Andrew,andEnoThereska.2013. DynamicRight-SizingforPower-ProportionalData\nCenters.IEEE/ACM Trans. Netw. 21, 5(2013), 1378ś1391. https://doi.org/10.1109/TNET.2012.2226216\nACM Trans. Algor.\n\n\nOnlineMetricAlgorithms with Untrusted Predictions •33\n[44]N.LittlestoneandM.K.Warmuth.1994. TheWeightedMajorityAlgorithm. InformationandComputation 108,2(Feb.1994),212ś261.\nhttps://doi.org/10.1006/inco.1994.1009\n[45]EvanLiu, Milad Hashemi, KevinSwersky, Parthasarathy Ranganathan, and JunwhanAhn. 2020. AnImitation Learning Approach for\nCache Replacement. In Proceedings of the 37th International Conference on Machine Learning (Proceedings of Machine Learning Research,\nVol. 119). PMLR,6237ś6247. https://proceedings.mlr.press/v119/liu20f.html\n[46]Thodoris Lykouris and Sergei Vassilvitskii. 2018. Competitive Caching with Machine Learned Advice. In Proceedings of ICML’18 .\n3302ś3311. http://proceedings.mlr.press/v80/lykouris18a.html\n[47]Mohammad Mahdian, Hamid Nazerzadeh, and Amin Saberi. 2012. Online Optimization with Uncertain Information. ACM Trans.\nAlgorithms 8,1(2012), 2:1ś2:29. https://doi.org/10.1145/2071379.2071381\n[48]Mark S. Manasse, Lyle A. McGeoch, and Daniel D. Sleator. 1990. Competitive algorithms for server problems. J. ACM11, 2 (1990),\n208ś230. https://doi.org/10.1016/0196-6774(90)90003-W\n[49]Andres Muñoz Medina and Sergei Vassilvitskii. 2017. Revenue Optimization with Approximate Bid Predictions. In Proceedings of\nNeurIPS’17 . 1858ś1866.\n[50]Michael Mitzenmacher. 2020. Scheduling with Predictions and the Price of Misprediction. In Proceedings of ITCS’20 . 14:1ś14:18.\nhttps://doi.org/10.4230/LIPIcs.ITCS.2020.14\n[51] Manish Purohit, Zoya Svitkina, and Ravi Kumar. 2018. Improving Online Algorithms via ML Predictions. In Proceedings of NeurIPS’18 .\n9684ś9693.\n[52]SharathRaghvendra.2018. OptimalAnalysisofanOnlineAlgorithmfortheBipartiteMatchingProblemonaLine.In Proceedingsof\nSoCG’18. 67:1ś67:14. https://doi.org/10.4230/LIPIcs.SoCG.2018.67\n[53]Dhruv Rohatgi. 2020. Near-Optimal Bounds for Online Caching with Machine Learned Advice. In Proceedings of the Thirty-First Annual\nACM-SIAM SymposiumonDiscreteAlgorithms (SODA’20) . 1834ś1845.\n[54]Zhan Shi, Xiangru Huang, Akanksha Jain, and Calvin Lin. 2019. Applying Deep Learning to the Cache Replacement Problem. In\nProceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture (Columbus, OH, USA) (MICRO ’52) . Association\nforComputingMachinery, NewYork, NY, USA,413ś425. https://doi.org/10.1145/3352460.3358319\n[55]DanielDominicSleatorandRobertEndreTarjan.1985. AmortizedEiciencyofListUpdateandPagingRules. Commun.ACM 28,2\n(1985), 202ś208. https://doi.org/10.1145/2786.2793\n[56]Alexander Wei.2020. Betterand SimplerLearning-Augmented Online Caching. In Approximation, Randomization, and Combinatorial\nOptimization. AlgorithmsandTechniques(APPROX/RANDOM 2020) .\nACM Trans. Algor.\n",
  "textLength": 105736
}