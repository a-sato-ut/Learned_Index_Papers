{
  "paperId": "9a3329514b1de66ef2839324a33bfaf3d91f2e2b",
  "title": "AI Meets Database: AI4DB and DB4AI",
  "pdfPath": "9a3329514b1de66ef2839324a33bfaf3d91f2e2b.pdf",
  "text": "MIT Open Access Articles\nAI Meets Database: AI4DB and DB4AI\nThe MIT Faculty has made this article openly available. Please share\nhow this access benefits you. Your story matters.\nCitation: Li, Guoliang, Zhou, Xuanhe and Cao, Lei. 2021. \"AI Meets Database: AI4DB and DB4AI.\"\nAs Published: https://doi.org/10.1145/3448016.3457542\nPublisher: ACM|Proceedings of the 2021 International Conference on Management of Data\nPersistent URL: https://hdl.handle.net/1721.1/145960\nVersion: Final published version: final published article, as it appeared in a journal, conference \nproceedings, or other formally published context\nTerms of Use: Article is made available in accordance with the publisher's policy and may be \nsubject to US copyright law. Please refer to the publisher's site for terms of use.\n\n\nAI Meets Database: AI4DB and DB4AI\nGuoliang Li, Xuanhe Zhou\nTsinghua University\nChina\n{liguoliang,zhouxuan19@mails}@tsinghua.edu.cnLei Cao\nCSAIL, MIT\nUSA\nlcao@csail.mit.edu\nABSTRACT\nDatabase and Artificial Intelligence (AI) can benefit from each other.\nOn one hand, AI can make database more intelligent (AI4DB). For\nexample, traditional empirical database optimization techniques\n(e.g., cost estimation, join order selection, knob tuning, index and\nview advisor) cannot meet the high-performance requirement for\nlarge-scale database instances, various applications and diversified\nusers, especially on the cloud. Fortunately, learning-based tech-\nniques can alleviate this problem. On the other hand, database tech-\nniques can optimize AI models (DB4AI). For example, AI is hard\nto deploy, because it requires developers to write complex codes\nand train complicated models. Database techniques can be used to\nreduce the complexity of using AI models, accelerate AI algorithms\nand provide AI capability inside databases. DB4AI and AI4DB have\nbeen extensively studied recently. In this tutorial, we review ex-\nisting studies on AI4DB and DB4AI. For AI4DB, we review the\ntechniques on learning-based database configuration, optimization,\ndesign, monitoring, and security. For DB4AI, we review AI-oriented\ndeclarative language, data governance, training acceleration, and\ninference acceleration. Finally, we provide research challenges and\nfuture directions in AI4DB and DB4AI.\nACM Reference Format:\nGuoliang Li, Xuanhe Zhou and Lei Cao. 2021. AI Meets Database: AI4DB and\nDB4AI. In Proceedings of the 2021 International Conference on Management\nof Data (SIGMOD ’21), June 20–25, 2021, Virtual Event, China. ACM, New\nYork, NY, USA, 8 pages. https://doi.org/10.1145/3448016.3457542\n1 INTRODUCTION\nArtificial intelligence (AI) and database (DB) have been extensively\nstudied over the last five decades. First, database systems have been\nwidely used in many applications, because databases are easy to\nuse by providing user-friendly declarative query paradigms and\nencapsulating complicated query optimization functions. Second,\nAI has recently made breakthroughs due to three driving forces:\nlarge-scale data, new algorithms and high computing power.\nMoreover, AI and database can benefit from each other. On one\nhand, AI can make database more intelligent (AI4DB). For exam-\nple, traditional empirical database optimization techniques (e.g.,\ncost estimation, join order selection, knob tuning, index and view\nadvisor) are based on empirical methodologies and specifications,\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n©2021 Association for Computing Machinery.\nACM ISBN 978-1-4503-8343-1/21/06. . . $15.00\nhttps://doi.org/10.1145/3448016.3457542and requires human involvement (e.g., DBAs) to tune and maintain\nthe databases. Thus existing empirical techniques cannot meet the\nhigh-performance requirement for large-scale database instances,\nvarious applications and diversified users, especially on the cloud.\nFortunately, learning-based techniques can alleviate this problem.\nFor instance, deep learning can improve the quality of cost esti-\nmation, reinforcement learning can be used to optimize join order\nselection, and deep reinforcement learning can be used to tune\ndatabase knobs [3, 42, 87].\nOn the other hand, database techniques can optimize AI models\n(DB4AI). In many real applications, AI is hard to deploy, because it\nrequires developers to write complex codes and train complicated\nmodels. Fortunately, database techniques can be used to reduce\nthe complexity of using AI models, accelerate AI algorithms and\nprovide AI capability inside databases. For example, database tech-\nniques can be used to improve data quality (e.g., data discovery, data\ncleaning, data integration, data labeling, and data lineage), auto-\nmatically select appropriate models, recommend model parameters,\nand accelerate the model inference.\nDB4AI and AI4DB have been extensively studied recently [ 17,\n26,41,44,67,73,76,77,89]. In this tutorial, we summarize existing\ntechniques on DB4AI and AI4DB, and provide research challenges\nand open problems.\nTutorial Overview. We will provide a 3 hours tutorial. In the first\nsection (1.5 hours), we introduce AI4DB techniques.\n(1)Learning-based database configuration (20min). It aims to utilize\nmachine learning techniques to automate database configurations,\ne.g., deep reinforcement learning for knob tuning [ 42,87], classifier\nfor index advisor [ 30,50], reinforcement learning for view advi-\nsor [ 21,30,45,84], SQL rewriter, and reinforcement learning for\ndatabase partition [23].\n(2)Learning-based database optimization (20min). It aims to uti-\nlize machine learning techniques to address the hard problems in\ndatabase optimization, e.g., SQL rewrite, cost/cardinality estima-\ntion [ 70,80,82], join order selection [ 54,55,83], and end-to-end\noptimizer [53, 80].\n(3)Learning-based database design (20min). It aims to utilize ma-\nchine learning techniques to design database components, e.g.,\nlearned indexes [ 12,24,59], learned KV store design [ 24,25], and\ntransaction management [86].\n(4)Learning-based database monitoring (20min). Traditional meth-\nods rely on DBAs to monitor database activities and report the\nanomalies, and these methods are incomplete and inefficient for\nautonomous monitoring. Thus, machine learning based techniques\nare proposed to predict query arrival rates [ 49], estimate query per-\nformance [ 56,90], diagnose root causes of slow queries [ 51], and\ndetermine when and how to monitor what database metrics [28].\n(5)Learning-based database security (10min). Traditional database\nsecurity techniques (e.g., data masking and auditing, sensitive data\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2859\n\n      Database ConfigurationDeclarative Language Model\nIndex AdvisorView AdvisorSQL Rewriter\n       Database OptimizationCost EstimationJoin Order SelectionEnd-to-end Optimizer\n            Database DesignDB/AI RequestsQuery/Train/Inference Results\n         Database Monitoring\n               Database SecurityData DiscoveryAccessControlSQLInjection\n    Data Governance for AI\n       Model Training for AI\n      Model Inference for AI\nData DiscoveryData CleaningData LabelingData LineageFeature SelectionModel SelectionModel ManagementHardware AccelerationOperator SupportOperator SelectionExecution Acceleration\nKnob Tuning\nCardinality EstimationAI for DBDB for AI\nLearned IndexesLearned Data Structures Transaction ManagementHealthMonitorActivityMonitorPerformancePredictionFigure 1: Overview of DB4AI and AI4DB.\ndiscovery) rely on user-defined rules, which cannot automatically\ndetect unknown security vulnerabilities. Learning based algorithms\nare proposed to discover sensitive data, detect anomaly [ 46], con-\nduct access control [18], and avoid SQL injection [72].\nIn the second section, we focus on DB4AI techniques (70min). To\nlower the barrier for using AI, the database community extends the\ndatabase techniques to encapsulate the complexity of AI algorithms\nand enable users to use declarative languages, e.g., SQL, to utilize\nthe AI algorithms.\n(1)Declarative language model (15min). SQL is relatively easy to be\nused and widely accepted in database systems. We can extend SQL\nto support AI models [ 66], and we can also design user-friendly\ntools to support AI models [15].\n(2)Data governance (15min). Data quality is important for machine\nlearning, and we can use data governance techniques to improve\ndata quality and enhance the efficiency, e.g., data discovery [ 16],\ndata cleaning [79], data labeling [40, 57], and data lineage.\n(3)Model training (20min). Model training is a time-consuming and\ncomplicated process, and thus it requires optimization techniques,\ne.g., feature selection [ 85], model selection, model management [ 75],\nhardware acceleration [29].\n(4)Model inference (20min). Model inference aims to effectively infer\nthe results using a trained model with in-database optimization\ntechniques, e.g., operator support, operator selection, execution\nacceleration.\nIn the third section, we provide research challenges and open\nproblems (20min). For AI4DB, we discuss AI for transactions anddatabase reliability when AI models cannot converge. For DB4AI,\nwe discuss how to enhance AI training inside database, how to\nreduce errors with error-tolerant techniques, and build a database-\nlike AI optimizer. For hybrid AI and DB, we present hybrid data\nmodels, hybrid computation models, and hybrid AI&DB systems.\nTarget Audience. The intended audience include SIGMOD atten-\ndees from both research and industry communities that are inter-\nested in database optimization and machine learning. We will not\nrequire any prior background knowledge in database or machine\nlearning domain. The tutorial will be self-contained, and we will\ninclude a broad introduction and motivating examples for non-\nspecialists to follow.\nDifference with Existing Tutorials. There are some existing tu-\ntorials on machine learning and databases [ 62,64,76]. Different\nfrom them, we focus on the fundamental techniques for using AI\ntechniques to optimize databases and using DB techniques to accel-\nerate AI models.\n2 TUTORIAL OUTLINE\nWe start with a brief overview of this tutorial, to give the audience\na clear outline and talk goals. We then summarize existing tech-\nniques of AI4DB, DB4AI, and hybrid AI and DB. Finally, we provide\nresearch challenges and open problems.\n2.1 AI for DB\nTraditional database design is based on empirical methodologies\nand specifications, and requires human involvement (e.g., DBAs)\nto tune and maintain the databases. AI techniques can be used\nto alleviate these limitations – exploring larger design space than\nhumans and replacing heuristics to address hard problems. We\ncategorize existing AI4DB techniques as below.\nLearning-based Database Configuration. It aims to utilize AI\ntechniques to automate database configurations, including knob\ntuning, index advisor, materialized view advisor, SQL rewriter, and\ndatabase partition.\n(1)Knob tuning. Databases have hundreds of tunable system knobs\n(e.g., Work_Mem ,Max_Connections ) [48], which control many im-\nportant aspects of databases (e.g., memory allocation, I/O control,\nlogging) and affect database performance. Traditional manual meth-\nods leverage DBAs to manually tune these knobs based on their\nexperiences but they always spend too much time to tune the knobs\n(several days to weeks) and cannot handle millions of database\ninstances on cloud databases. To address this problem, the data-\nbase community utilizes learning-based techniques [ 38,42,87] to\nautomate knob tuning, which not only achieve higher tuning per-\nformance but less tuning time. For example, CDBTune [ 87] models\ndatabase tuning as a sequential decision problem and relies on rein-\nforcement learning to improve tuning performance. Moreover, since\nCDBTune only takes previous database state as input, QTune [ 42]\nfurther characterizes query features using deep learning and can\nachieve finer granularity tuning, e.g., query-level tuning, session-\nlevel tuning, and system-level tuning.\n(2)Index advisor. Indexes are vital to speed up query execution,\nand indexes on appropriate columns can achieve high performance.\nHowever, it is expensive to recommend and build indexes with large\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2860\n\nnumber of column combinations. Hence, there are some learning-\nbased works that automatically recommend indexes [ 30,50]. For\nexample, Sadri et al [ 65] propose a reinforcement-learning-based\nindex selection method. First, without expert rules, they denote\nworkload features as the arrival rate of queries, column features\nas the access frequency and selectivity of each column. Second,\nthey use the Markov Decision Process model (MDP) to learn from\nfeatures of queries, columns, and outputs a set of actions, which\ndenote creating/dropping an index.\n(3)View advisor . It is important in DBMS that utilizes views to im-\nprove the query performance based on the space-for-time trade-off\nprinciple. Judiciously selecting materialized views can significantly\nimprove the query performance within an acceptable overhead.\nHowever, existing methods rely on DBAs to generate and main-\ntain materialized views. Unfortunately, even DBAs cannot handle\nlarge-scale databases, especially cloud databases that have millions\nof database instances and support millions of users. Thus, it calls\nfor the view advisor, which automatically identifies the appropriate\nviews for a given query workload [ 30,45,84]. For example, Han et\nal [21] propose a deep reinforcement learning method to estimate\nthe benefit of different MV candidates and queries, and select MVs\nfor dynamic workloads.\n(4)SQL rewriter. SQL rewriter can remove the redundant or inef-\nficient operators in logic query and enhance query performance\nsignificantly. However, there are numerous rewrite orders for a slow\nquery (e.g., different operators and applicable rules), and traditional\nempirical query rewriting methods only rewrite in a fixed order\n(e.g., top down) and may derive suboptimal queries. Instead, deep re-\ninforcing learning can be used to judiciously select the appropriate\nrules and apply the rules in a good order.\n(5)Database Partition. Traditional methods heuristically select\ncolumns as partition keys (single column mostly) and cannot bal-\nance between load balance and access efficiency. Some work [ 23]\nalso utilizes reinforcement learning model to explore different par-\ntition keys and implements a fully-connected neural network to\nestimate partition benefits.\nLearning-based Database Optimization . It aims to utilize ma-\nchine learning techniques to address the hard problems in database\noptimization, including cost estimation, join order selection, and\nend-to-end optimizers.\n(1)Cardinality/Cost estimation . Database optimizer relies on cardi-\nnality and cost estimation to select an optimized plan, but traditional\ntechniques cannot effectively capture the correlations between dif-\nferent columns/tables and thus cannot provide high-quality esti-\nmation. Recently, deep learning based techniques (e.g., CNN [ 13],\nRNN [ 70], Mixture Model [ 60]) are proposed to estimate the cost\nand cardinality by using deep neural networks to capture data\ncorrelations. For example, a LSTM based work [ 70] learns a repre-\nsentation for each sub-plan with physical operator and predicates,\nand outputs the estimated cardinality and cost simultaneously by\nusing an estimation layer.\n(2)Join order selection. A SQL query may have millions, even billions\nof possible plans and it is very important to efficiently find a good\nplan. Traditional heuristics methods cannot find optimal plans for\ndozens of tables and dynamic programming is costly to explore thehuge plan space. Thus there are some deep reinforcement learning\nbased methods [ 54,55,83] that automatically select good plans.\nFor example, SkinnerDB [ 74] uses a Monte-Carlo tree search based\nmethods to try out different join orders in each time slice and can\noptimize the join order on the fly.\n(3)End-to-end optimizer. A full-fledged optimizer not only replies on\ncost estimation and join order, but also requires to consider indexes\nand views, and it is important to design an end-to-end optimizer.\nLearning-based optimizers [ 53,55,80] use deep neural networks\nto optimize SQL queries. For example, Marcus et al [ 55] propose\nan end-to-end optimizer NEO to generate the final physical plan.\nWithout information from the cost model, NEO uses PostgreSQL’s\nplan to pre-train the neural network and uses latency as feedback to\ntrain the neural network. This end-to-end method learns from the\nlatency to generate the whole physical plan, which can be applied\nto many scenarios and robust to estimation errors.\nLearning-based Database Design. Traditional databases are de-\nsigned by database architects based on their experiences, but data-\nbase architects can only explore a limited number of possible design\nspaces. Recently some learning-based self-design techniques have\nbeen proposed.\n(1)Learned indexes [12,24,59] are proposed for not only reducing\nthe index size but also improving the query performance using the\nindexes. For example, Kraska et al. [ 32] propose that indexes are\nmodels, where the B+tree index can be seen as a model that maps\neach query key to its page. Learned indexes are also studied for\ndata updates and high-dimensional data.\n(2)Learned data structure design. Different data structures may be\nsuit for different environments (e.g., different hardware, different\nread/write transactions) and it is hard to design appropriate struc-\ntures for every scenario. Techniques like data structure alchemy [ 24]\nare proposed to automatically recommend and design data struc-\ntures. They define the design space by the fundamental design com-\nponents (e.g., fence pointers, links, and temporal partitioning). To\ndesign a data structure, they first identify the bottleneck of the total\ncost and then tweak different knobs in one direction until reaching\nthe cost boundary or the total cost is minimal, which is similar to\nthe gradient descent procedure.\n(3)Learning-based transaction management. Effective workload\nscheduling can greatly improve the performance by avoiding\nthe data conflicts. We introduce learned transaction management\ntechniques from two aspects: transaction prediction and transac-\ntion scheduling. First, for transaction prediction, traditional work-\nload prediction methods are rule-based. For example, a rule-based\nmethod [ 11] uses domain knowledge of database engines (e.g., in-\nternal latency, resource utilization) to identify signals relevant to\nworkload characteristics, which takes much time to rebuild a statis-\ntics model when workload changes, so Ma et al. [ 49] propose an\nML-based system that predicts the future trend of different work-\nloads. Second, for transaction scheduling, traditional database sys-\ntems either schedule workload sequentially, which cannot consider\npotential conflicts, or schedule workloads based on the execution\ncosts predicted by the database optimizer. Sheng et al. [ 68] propose\na learning based transaction scheduling method, which can balance\nconcurrency and conflict rates using supervised algorithms.\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2861\n\nLearning-based Database Monitoring. Traditional methods rely\non database administrators to monitor most database activities\nand report the anomalies and these methods are incomplete and\ninefficient. Thus, machine learning based techniques [ 28,56,90] are\nproposed for three main cases – health monitor, activity monitor\nand performance prediction.\n(1)Database Health Monitor (DHM). It records database health re-\nlated metrics, e.g., the number of queries per second, the query\nlatency, to optimize database or diagnose failures. In [51], they as-\nsume that intermittent slow queries with similar key performance\nindicators (e.g., CPU usage, transactions per second) have the same\nroot causes. Thus, they first extract slow SQLs from the failure\nrecords, cluster them with KPI states, and ask DBAs to assign root\ncauses for each cluster. Next, for an incoming slow SQL, they match\nit to a cluster Cbased on similarity score of KPI states. If matched,\nthey use the root cause of Cto notify DBAs; otherwise, they gener-\nate a new cluster and ask DBAs to assign the root causes. However,\nthese methods [ 51] cannot prevent potential database failure and\nit highly relies on DBA’s experience. So Taft et al. [ 71] propose to\nproactively monitor database to adapt to workload changes.\n(2)Database Activity Monitor (DAM). It externally monitors and\ncontrols database activities (e.g., creating new accounts, viewing\nsensitive information), which are vital to protecting sensitive data.\nWe broadly classify DAM into two classes, activity selection and\nactivity trace. For activity selection, traditional DAM methods are\nrequired to record all the activities on extra systems according to\ntrigger rules [ 10]. However, it is still a heavy burden to record all the\nactivities, which brings frequent data exchanges between databases\nand monitoring systems. Hence, it requires to automatically select\nand record risky activities, and Hagit et al. [ 19] take database moni-\ntoring as a multi-armed bandits problem (MAB), which selects risky\ndatabase activities by exploiting current policy and exploring new\npolicies. The goal is to train an optimal policy with the maximal\nrisk score.\n(3)Performance Prediction. Query performance prediction is vital to\nmeet the service level agreements (SLAs), especially for concurrent\nqueries. Marcus et al [ 56] use deep learning to predict query la-\ntency under concurrency scenarios, including interactions between\nchild/parent operators, and parallel plans. However, it adopts a\npipeline structure (causing information loss) and fails to capture\noperator-to-operator relations like data sharing/conflict features.\nHence, Zhou et al [ 90] propose a performance prediction method\nwith graph embedding. They use a graph model to characterize con-\ncurrent queries and utilize a graph convolution network to embed\nthe workload graph into performance metrics.\nLearning-based Database Security. Traditional database secu-\nrity techniques (e.g., data masking and auditing) rely on user-\ndefined rules, which cannot automatically detect the unknown\nsecurity vulnerabilities. Thus, learning based algorithms [ 18,46,72]\nare proposed to discover sensitive data, conduct access control, and\navoid SQL injection.\n(1)Learning-based Sensitive Data Discovery. Since sensitive data\nleakage will cause great financial and personal information loss, it\nis important to protect the sensitive data in a database. Sensitive\ndata discovery aims to automatically detect and protect confidentialdata. For example, Fernandez et al. propose Aurum [16], which is\na data discovery system that provides flexible queries to search\ndataset based on users’ demand.\n(2)Access Control. It aims to prevent unauthorized users to access\nthe data, including table-level and record-level access control. Tra-\nditional methods cannot effectively prevent these attacks. Recently,\nmachine learning based algorithms are proposed to estimate the\nlegality of access requests. Colombo et al [ 9] propose a purpose-\nbased access control model, which customizes control polices to\nregulate data requests. As different actions and data content may\nlead to different private problems, this method aims to learn legal\naccess purposes.\n(3)SQL Injection. SQL injection is a common and harmful vulnera-\nbility to database. Attackers may modify or view data that exceeds\ntheir priorities by bypassing additional information or interfering\nwith the SQL statement, such as retrieving hidden data, subverting\napplication logic, union attacks and etc. There are mainly two types\nof SQL injection detection methods that utilize machine learning\ntechniques, including classification tree [ 47,69] and fuzzy neural\nnetwork [5].\nLearning-based Database Systems. There are some learning-\nbased database systems which are studied by both the academia and\nindustry [ 31,41,61]. For example, SageDB [31] provided a vision\nto specialize the database implementation by learning the data dis-\ntribution (CDF models) and designing database components based\non the knowledge, e.g., learned index, learned query scheduling.\n2.2 DB for AI\nDeclarative Language Model. Traditional machine learning algo-\nrithms are mostly implemented with programming languages (e.g.,\nPython, R) and have several limitations. First, they require engineer-\ning skills to define the complete execution logic, e.g., the iterative\npatterns of model training, and tensor operations like matrix multi-\nplication and flattening. Second, machine learning algorithms have\nto load data from database systems, and the data import/export\ncosts may be very high. Instead, SQL is relatively easy to be used\nand widely accepted in database systems. However, SQL lacks some\ncomplex processing patterns (e.g., iterative training) compared with\nother high-level machine learning languages. Fortunately, SQL can\nbe extended to support AI models [ 66], and we can also design\nuser-friendly tools to support AI models in SQL statements [15].\nData Governance. AI models rely on high-quality data, and data\ngovernance aims to discover, clean, integrate, and label the data to\nimprove the data quality.\n(1)Data discovery. Data discovery aims to automatically find rel-\nevant datasets from data warehouse considering the applications\nand user needs. Learning based data discovery [ 8,16,20,81,88]\nenhances the ability of finding relevant data, which effectively finds\nout relevant data among a large number of data sources. For exam-\nple, Fernandez et al. propose Aurum [16], which is a data discovery\nsystem that provides flexible queries to search dataset based on\nusers’ demand. It leverages enterprise knowledge graph (EKG) to\ncapture a variety of relationships to support a wide range of queries.\nThe EKG is a hyper-graph where each node denotes a table col-\numn, each edge represents the relationship between two nodes and\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2862\n\nhyper-edges connect nodes that are hierarchically related such as\ncolumns in the same table.\n(2)Data cleaning. Dirty or inconsistent data can affect the training\nperformance terribly. Data cleaning and integration techniques [ 14,\n27,34,36,39] can detect and repair the dirty data, and integrate\nthe data from multiple sources. Wang et al. propose a cleaning\nframework ActiveClean for machine learning tasks [ 34]. Given a\ndataset and machine learning model with a convex loss, it selects\nrecords that can improve the performance of the model most and\ncleans those records iteratively.\n(3)Data labeling. We can properly utilize domain experts, crowd-\nsourcing and existing knowledge to label a large number of train-\ning data for ML algorithms [ 1,57]. For example, with commer-\ncial public crowdsourcing platforms like Amazon Mechanical Turk\n(https://www.mturk.com), crowdsourcing is an effective way to\naddress such tasks by utilizing hundreds or thousands of workers\nto label the data.\nModel Training. Model training aims to train a high-quality model\nfor online inference. Model training is a time-consuming and com-\nplicated process, and thus it requires optimization techniques, in-\ncluding feature selection, model selection, model management and\nhardware acceleration.\n(1)Feature selection aims to search appropriate features from a large\nnumber of possible features, which is laborious and time-consuming.\nDatabase techniques like batching [ 85], materialization [ 35,85],\nactive learning [ 4] are proposed to address this issue. For example,\nbatching and materialization techniques [ 85] are utilized to reduce\nthe feature enumeration cost. Active learning based techniques [ 4]\nare utilized to accelerate the evaluation process.\n(2)Model selection aims to select an appropriate model (and param-\neter values) from a large number of possible models. Parallelism\ntechniques are proposed to accelerate this step, including task par-\nallel [ 58], bulk synchronous parallel [ 33], parameter server [ 43]\nand model parallelism. A key bottleneck of this problem is model\nselection throughput, i.e., the number of training configurations\nis tested per unit time. High throughput allows the user to test\nmore configurations during a fixed period, which makes the entire\ntraining process efficient. A solution is to enhance the through-\nput is parallelism, and the popular parallelism strategies include\ntask parallel [ 58] , bulk synchronous parallel [ 33] , and parameter\nserver [43].\n(3)Model management . Since model training is a trial-and-error\nprocess that needs to maintain many models and parameters that\nhave been tried, it is necessary to design a model management\nsystem to track, store and search the ML models. We review GUI-\nbased [6] and command-based model [75] management system.\n(4)Hardware acceleration. Morden hardwares, like GPU and FPGA,\nare also utilized to accelerate the model training. We introduce hard-\nware acceleration techniques in row-store and column-store [ 29]\ndatabases respectively. For example, DAnA [52] parses the query\nand utilizes a hardware mechanism that connects the FPGA and\ndatabase. It retrieves the training data from the buffer pool to the\naccelerator directly without accessing the CPU. Besides, they de-\nsign an execution model to combine thread-level and data-level\nparallelism for accelerating the ML algorithms.Model Inference. It aims to infer the results using a trained model\nwith in-database optimization techniques.\n(1)Operator support. An ML model may contain different types of\noperators (e.g., scalar, tensor), which have different optimization\nrequirements. Thus in-database techniques are proposed to support\nAI operators [ 22,78]. For example, Boehm et al. [ 7] propose an in-\ndatabase machine learning system SystemML. SystemML supports\nmatrix operations with user-defined aggregation functions, which\nprovide parallel data processing in the column level. For example,\nBoehm et al. [ 7] propose an in-database machine learning system\nSystemML. SystemML supports matrix operations with user-defined\naggregation functions, which provide parallel data processing in\nthe column level.\n(2)Operator selection. The same ML model can be converted to dif-\nferent physical operators, which may bring significant performance\ndifference. In-database operator selection can estimate resource\nconsumption and judiciously schedule the operators [7, 36].\n(3)Execution acceleration. Different from model training, model\ninference needs to choose ML models and execute forward propa-\ngation to predict for different problems. Existing execution acceler-\nation techniques include in-memory methods [ 37] and distributed\nmethods[ 2,63]. In-memory methods aim to compress data into\nmemory and conduct in-memory computation as much as possible.\nAnd the distributed methods route tasks to different nodes and\nreduce the burden of data processing and model computation using\nparallel computing.\n2.3 Challenges and Open Problems\nAlthough AI4DB and DB4AI have been extensively studied, there\nare still many opportunities and challenges to apply AI4DB and\nDB4AI techniques in practice, and it also calls for hybrid AI and\nDB techniques.\nAI4DB . There are several challenges that utilize AI techniques to\noptimize databases.\n(1)Model Selection. There are two challenges. First, there are differ-\nent kinds of ML models (e.g., forward-feeding, sequential, graph\nembedding) and it is inefficient to manually select appropriate mod-\nels and adjust the parameters. Second, it is hard to evaluate whether\na learned model is effective in most scenarios, for which a validation\nmodel is required.\n(2)Model Validation. It is hard to evaluate whether a learned model\nis effective and outperforms non-learning methods. For example,\nwhether a knob tuning strategy really works for a workload? It\nrequires to design a validation model to evaluate a learned model.\n(3)Model Management. Different database components may use\ndifferent ML models and it is important to provide a unified ML\nplatform to achieve a unified resource scheduling and a unified\nmodel management.\n(4)Training data. Most AI models require large-scale, high-quality,\ndiversified training data to achieve high performance. However,\nit is rather hard to get training data in AI4DB, because the data\neither is security critical or relies on DBAs. For example, in database\nknob tuning, the training samples are collected based on DBAs’\nexperiences. And it is laborious to get a large number of training\nsamples. Moreover, to build an effective model, the training data\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2863\n\nshould cover different scenarios, different hardware environments,\nand different workloads. It calls for new methods that use a small\ntraining dataset to get a high-quality model.\n(5)Adaptability. The adaptability is a big challenge, e.g., adapting to\ndynamic data updates, other datasets, new hardware environments,\nand other database systems. We need to address the following\nchallenges. First, how to adapt a trained model (e.g., optimizer, cost\nestimation) on a dataset to other datasets? Second, how to adapt\na trained model on a hardware environment to other hardware\nenvironments? Third, how to adapt a trained model on a database\nto other databases? Fourth, how to make a trained model support\ndynamic data updates?\n(6)Model convergence. It is very important that whether a learned\nmodel can be converged. If the model cannot be converged, we\nneed to provide alternative ways to avoid making delayed and\ninaccurate decisions. For example, in knob tuning, if the model\nis not converged, we cannot utilize the model for online knob\nsuggestion.\n(7)Learning for OLAP. Traditional OLAP focuses on relational data\nanalytics. However, in the big data era, many new data types have\nemerged, e.g., graph data, time-series data, spatial data, it calls\nfor new data analytics techniques to analyze these multi-model\ndata. Moreover, besides traditional aggregation queries, many ap-\nplications require to use machine learning algorithms to enhance\ndata analytics, e.g., image analysis. Thus it is rather challenging\nto integrate AI and DB techniques to provide new data analytics\nfunctionality.\n(8)Learning for OLTP. Transaction modeling and scheduling are\nrather important to OLTP systems, because different transactions\nmay have conflicts. However, it is not free to model and schedule\nthe transactions, and it calls for more efficient models that can\ninstantly model and schedule the transactions in multiple cores and\nmultiple machines.\nDB4AI . There are still several challenges to utilize in-database\ntechniques to optimize AI algorithms.\n(1)In-database training. It is challenging to support AI training in-\nside databases, including model storage, model update and parallel\ntraining. First, it is challenging to store a model in databases, such\nthat the model can be trained and used by multi-tenants, and we\nneed to consider the security and privacy issues. Second, it is chal-\nlenging to update a model, especially when the data is dynamically\nupdated.\n(2)Training acceleration using database techniques. Most of studies\nfocus on the effectiveness of AI algorithms but do not pay much\nattention to efficiency. It calls for utilizing database techniques\nto improve the performance of AI algorithms, e.g., indexes and\nviews. For example, self-driving vehicles require a large number of\nexamples for training, which is rather time consuming. Actually, it\nonly requires some important examples, e.g., the training cases in\nthe night or rainy day, but not many redundant examples. Thus we\ncan index the samples and features for effective training.\n(3)AI optimizer. Existing studies use user-defined functions (UDF)\nto support AI models, which are not effectively optimized. It re-\nquires to implement the AI models as operators insider databases,\nand design physical operators for each operator. Most importantly,it requires to push down the AI operators and estimate the cost/-\ncardinality of AI operators. It calls for an AI optimizer to optimize\nthe AI training and inference. Furthermore, it is more important to\nefficiently support AI operators in a distributed environment.\n(4)Fault-tolerant learning. Existing learning model training does\nnot consider error tolerance. If a process crashes and the whole\ntask will fail. We can use the error tolerance techniques to improve\nthe robustness of in-database learning. However, to ensure busi-\nness continuity under predictable/unpredictable disasters, database\nsystems must provide capabilities like fault tolerance and disaster\nrecovery.\nAI&DB co-optimization . There are several challenges in model\nsupport, inference, and system integration.\n(1)Hybrid relational and tensor model. Traditional CPU cannot ef-\nficiently process tensor models and AI chips cannot efficiently\nprocess relational models. It calls for effective methods that accel-\nerate relational operations on AI chips, schedule operators across\ntraditional CPU and AI chips, and supporting both relational and\ntensor model.\n(2)Hybrid DB&AI inference. Many applications require both DB\nand AI operations, e.g., finding all the patients of a hospital whose\nstay time will be longer than 3 days. A native way is to predict the\nhospital stay of each patient and then prune the patients whose\nstay time is less than 3. Obviously this method is rather expensive,\nand it calls for a new optimization model to optimize both DB and\nAI, e.g, new optimization model, AI operator push-down, AI cost\nestimation, and AI index/views.\n(3)Hybrid DB&AI system. It calls for an end-to-end hybrid AI&DB\nsystem that supports a declarative language, e.g., AISQL, which\nextends SQL to support AI operators, an AI&DB optimizer that co-\noptimizes the two operations, an effective (distributed) execution\nengine that schedules the two types of tasks, and an appropriate\nstorage engine.\n3 BIOGRAPHY\nGuoliang Li is a full professor in the Department of Computer\nScience, Tsinghua University. His research interests mainly include\ndata cleaning and integration, crowdsourcing, and AI4DB, DB4AI,\nhybrid DB&AI. He got VLDB 2017 early research contribution\naward, TCDE 2014 early career award, CIKM 2017 best paper award,\nand best of VLDB/ICDE. He will present AI4DB and open problems.\nXuanhe Zhou is currently a PhD student in the Department of\nComputer Science, Tsinghua University. His research interests lie in\nthe interdisciplinary technologies of database and machine learning.\nHe will present AI4DB.\nLei Cao is a Postdoc Associate at MIT CSAIL, working with Prof.\nSamuel Madden and Prof. Michael Stonebraker. Before that he\nworked for IBM T.J. Watson Research Center as a Research Staff\nMember. He received his Ph.D. in Computer Science from Worcester\nPolytechnic Institute. He focused on developing end-to-end tools\nfor data scientists to make sense of data. He will present DB4AI.\nAcknowledgement. This paper was supported by NSF of China\n(61925205, 61632016), Huawei, Beijing National Research Center for\nInformation Science and Technology(BNRist), and TAL education.\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2864\n\nREFERENCES\n[1]C. C. Aggarwal, X. Kong, Q. Gu, J. Han, and P. S. Yu. Active learning: A survey.\nInData Classification: Algorithms and Applications, pages 571–606. 2014.\n[2]D. Agrawal and et al. Rheem: Enabling multi-platform task execution. In SIGMOD\n2016, pages 2069–2072, 2016.\n[3]D. V. Aken, A. Pavlo, G. J. Gordon, and B. Zhang. Automatic database management\nsystem tuning through large-scale machine learning. In SIGMOD 2017, pages\n1009–1024, 2017.\n[4]M. R. Anderson and M. J. Cafarella. Input selection for fast feature engineering.\nInICDE 2016,, pages 577–588, 2016.\n[5]L. O. Batista, G. A. de Silva, V. S. Araújo, V. J. S. Araújo, T. S. Rezende, A. J.\nGuimarães, and P. V. de Campos Souza. Fuzzy neural networks to create an\nexpert system for detecting attacks by SQL injection. CoRR, abs/1901.02868, 2019.\n[6]L. Bavoil, S. P. Callahan, C. E. Scheidegger, H. T. Vo, P. Crossno, C. T. Silva, and\nJ. Freire. Vistrails: Enabling interactive multiple-view visualizations. In VIS 2005,\npages 135–142, 2005.\n[7]M. Boehm, M. Dusenberry, D. Eriksson, A. V. Evfimievski, F. M. Manshadi,\nN. Pansare, B. Reinwald, F. Reiss, P. Sen, A. Surve, and S. Tatikonda. Systemml:\nDeclarative machine learning on spark. PVLDB, 9(13):1425–1436, 2016.\n[8]N. Chepurko, R. Marcus, E. Zgraggen, and et al. ARDA: automatic relational data\naugmentation for machine learning. VLDB, 13(9):1373–1387, 2020.\n[9]P. Colombo and E. Ferrari. Efficient enforcement of action-aware purpose-based\naccess control within relational database management systems. In ICDE 2016,\npages 1516–1517, 2016.\n[10] C. Curino, E. P. C. Jones, S. Madden, and H. Balakrishnan. Workload-aware\ndatabase monitoring and consolidation. In SIGMOD 2011, pages 313–324, 2011.\n[11] S. Das, F. Li, V. R. Narasayya, and A. C. König. Automated demand-driven resource\nscaling in relational database-as-a-service. In SIGMOD 2016, pages 1923–1934,\n2016.\n[12] J. Ding, U. F. Minhas, J. Yu, and et al. ALEX: an updatable adaptive learned index.\nInSIGMOD, pages 969–984. ACM, 2020.\n[13] A. Dutt, C. Wang, A. Nazi, and et al. Selectivity estimation for range predicates\nusing lightweight models. VLDB, 12(9):1044–1057, 2019.\n[14] J. Fan and G. Li. Human-in-the-loop rule learning for data integration. IEEE Data\nEng. Bull., 41(2):104–115, 2018.\n[15] S. Fernandes and J. Bernardino. What is bigquery? In Proceedings of the 19th\nInternational Database Engineering & Applications Symposium, Yokohama, Japan,\nJuly 13-15, 2015, pages 202–203, 2015.\n[16] R. C. Fernandez, Z. Abedjan, F. Koko, G. Yuan, S. Madden, and M. Stonebraker.\nAurum: A data discovery system. In ICDE 2018, pages 1001–1012, 2018.\n[17] Z. Gharibshah, X. Zhu, A. Hainline, and M. Conway. Deep learning for user\ninterest and response prediction in online display advertising. Data Science and\nEngineering, 5(1):12–26, 2020.\n[18] M. L. Goyal and G. V. Singh. Access control in distributed heterogeneous database\nmanagement systems. Computers & Security, 10(7):661–669, 1991.\n[19] H. Grushka-Cohen, O. Biller, O. Sofer, L. Rokach, and B. Shapira. Diversifying\ndatabase activity monitoring with bandits. CoRR, abs/1910.10777, 2019.\n[20] A. Y. Halevy, F. Korn, N. F. Noy, C. Olston, N. Polyzotis, S. Roy, and S. E. Whang.\nGoods: Organizing google’s datasets. In SIGMOD 2016, pages 795–806, 2016.\n[21] Y. Han, G. Li, H. Yuan, and J. Sun. An autonomous materialized view management\nsystem with deep reinforcement learning. In ICDE, 2021.\n[22] J. M. Hellerstein, C. Ré, F. Schoppmann, D. Z. Wang, E. Fratkin, A. Gorajek, K. S.\nNg, C. Welton, X. Feng, K. Li, and A. Kumar. The madlib analytics library or\nMAD skills, the SQL. PVLDB, 5(12):1700–1711, 2012.\n[23] B. Hilprecht, C. Binnig, and U. Röhm. Learning a partitioning advisor for cloud\ndatabases. In SIGMOD, pages 143–157. ACM, 2020.\n[24] S. Idreos, N. Dayan, W. Qin, M. Akmanalp, S. Hilgard, A. Ross, J. Lennon, V. Jain,\nH. Gupta, D. Li, and Z. Zhu. Design continuums and the path toward self-\ndesigning key-value stores that know and learn. In CIDR, 2019.\n[25] S. Idreos, N. Dayan, W. Qin, and et al. Learning key-value store design. CoRR,\nabs/1907.05443, 2019.\n[26] S. Idreos and T. Kraska. From auto-tuning one size fits all to self-designed and\nlearned data-intensive systems. In SIGMOD, pages 2054–2059. ACM, 2019.\n[27] I. F. Ilyas and X. Chu. Data Cleaning. ACM, 2019.\n[28] H. Kaneko and K. Funatsu. Automatic database monitoring for process control\nsystems. In IEA/AIE 2014, pages 410–419, 2014.\n[29] K. Kara, K. Eguro, C. Zhang, and G. Alonso. Columnml: Column-store machine\nlearning with on-the-fly data transformation. PVLDB, 12(4):348–361, 2018.\n[30] J. Kossmann, S. Halfpap, M. Jankrift, and R. Schlosser. Magic mirror in my hand,\nwhich is the best in the land? an experimental evaluation of index selection\nalgorithms. Proc. VLDB Endow., 13(11):2382–2395, 2020.\n[31] T. Kraska, M. Alizadeh, A. Beutel, E. H. Chi, and et al. Sagedb: A learned database\nsystem. In CIDR, 2019.\n[32] T. Kraska, A. Beutel, and E. H. C. et al. The case for learned index structures. In\nSIGMOD, pages 489–504, 2018.\n[33] T. Kraska, A. Talwalkar, J. C. Duchi, R. Griffith, M. J. Franklin, and M. I. Jordan.\nMlbase: A distributed machine-learning system. In CIDR 2013, 2013.[34] S. Krishnan, J. Wang, E. Wu, M. J. Franklin, and K. Goldberg. Activeclean:\nInteractive data cleaning for statistical modeling. PVLDB, 9(12):948–959, 2016.\n[35] A. Kumar, M. Boehm, and J. Yang. Data management in machine learning:\nChallenges, techniques, and systems. In SIGMOD 2017, pages 1717–1722, 2017.\n[36] A. Kumar, J. F. Naughton, J. M. Patel, and X. Zhu. To join or not to join?: Thinking\ntwice about joins before feature selection. In SIGMOD 2016, pages 19–34, 2016.\n[37] M. Kunjir and S. Babu. Thoth in action: Memory management in modern data\nanalytics. PVLDB, 10(12):1917–1920, 2017.\n[38] M. Kunjir and S. Babu. Black or white? how to develop an autotuner for memory-\nbased analytics [extended version]. CoRR, abs/2002.11780, 2020.\n[39] G. Li. Human-in-the-loop data integration. Proc. VLDB Endow. , 10(12):2006–2017,\n2017.\n[40] G. Li, J. Wang, Y. Zheng, and M. J. Franklin. Crowdsourced data management: A\nsurvey. IEEE Trans. Knowl. Data Eng., 28(9):2296–2319, 2016.\n[41] G. Li, X. Zhou, and S. Li. Xuanyuan: An ai-native database. IEEE Data Eng. Bull.,\n42(2):70–81, 2019.\n[42] G. Li, X. Zhou, S. Li, and B. Gao. Qtune: A query-aware database tuning system\nwith deep reinforcement learning. VLDB, 12(12):2118–2130, 2019.\n[43] M. Li, D. G. Andersen, J. W. Park, A. J. Smola, A. Ahmed, V. Josifovski, J. Long,\nE. J. Shekita, and B. Su. Scaling distributed machine learning with the parameter\nserver. In OSDI 2014, pages 583–598, 2014.\n[44] M. Li, H. Wang, and J. Li. Mining conditional functional dependency rules on big\ndata. Big Data Mining and Analytics, 03(01):68, 2020.\n[45] X. Liang, A. J. Elmore, and S. Krishnan. Opportunistic view materialization with\ndeep reinforcement learning. CoRR, abs/1903.01363, 2019.\n[46] Z. Lin, X. Li, and X. Kuang. Machine learning in vulnerability databases. In ISCID\n2017, pages 108–113, 2017.\n[47] M. Lodeiro-Santiago, C. Caballero-Gil, and P. Caballero-Gil. Collaborative sql-\ninjections detection system with machine learning. In IML 2017, pages 45:1–45:5,\n2017.\n[48] J. Lu, Y. Chen, H. Herodotou, and S. Babu. Speedup your analytics: Automatic\nparameter tuning for databases and big data systems. PVLDB, 12(12):1970–1973,\n2019.\n[49] L. Ma, D. V. Aken, A. Hefny, G. Mezerhane, A. Pavlo, and G. J. Gordon. Query-\nbased workload forecasting for self-driving database management systems. In\nSIGMOD 2018, pages 631–645, 2018.\n[50] L. Ma, B. Ding, S. Das, and et al. Active learning for ML enhanced database\nsystems. In SIGMOD, pages 175–191. ACM, 2020.\n[51] M. Ma, Z. Yin, S. Zhang, S. Wang, and et al. Diagnosing root causes of intermittent\nslow queries in large-scale cloud databases. VLDB, 13(8):1176–1189, 2020.\n[52] D. Mahajan, J. K. Kim, J. Sacks, A. Ardalan, A. Kumar, and H. Esmaeilzadeh.\nIn-rdbms hardware acceleration of advanced analytics. PVLDB, 11(11):1317–1331,\n2018.\n[53] R. Marcus, P. Negi, H. Mao, and et al. Bao: Learning to steer query optimizers.\nCoRR, abs/2004.03814, 2020.\n[54] R. Marcus and O. Papaemmanouil. Deep reinforcement learning for join order\nenumeration. In SIGMOD 2018, pages 3:1–3:4, 2018.\n[55] R. C. Marcus, P. Negi, H. Mao, C. Zhang, M. Alizadeh, T. Kraska, O. Papaem-\nmanouil, and N. Tatbul. Neo: A learned query optimizer. PVLDB, 12(11):1705–1718,\n2019.\n[56] R. C. Marcus and O. Papaemmanouil. Plan-structured deep neural network\nmodels for query performance prediction. VLDB, 12(11):1733–1746, 2019.\n[57] M. Mintz, S. Bills, R. Snow, and D. Jurafsky. Distant supervision for relation\nextraction without labeled data. In ACL 2009, pages 1003–1011, 2009.\n[58] P. Moritz, R. Nishihara, S. Wang, A. Tumanov, R. Liaw, E. Liang, M. Elibol, Z. Yang,\nW. Paul, M. I. Jordan, and I. Stoica. Ray: A distributed framework for emerging\nAI applications. In OSDI 2018, pages 561–577, 2018.\n[59] V. Nathan, J. Ding, M. Alizadeh, and T. Kraska. Learning multi-dimensional\nindexes. In SIGMOD, pages 985–1000, 2020.\n[60] Y. Park, S. Zhong, and B. Mozafari. Quicksel: Quick selectivity learning with\nmixture models. In SIGMOD, pages 1017–1033. ACM, 2020.\n[61] A. Pavlo, G. Angulo, J. Arulraj, H. Lin, J. Lin, L. Ma, P. Menon, T. C. Mowry,\nM. Perron, I. Quah, S. Santurkar, A. Tomasic, S. Toor, D. V. Aken, Z. Wang, Y. Wu,\nR. Xian, and T. Zhang. Self-driving database management systems. In CIDR 2017,\n2017.\n[62] C. Ré, D. Agrawal, M. Balazinska, M. J. Cafarella, M. I. Jordan, T. Kraska, and\nR. Ramakrishnan. Machine learning and databases: The sound of things to come\nor a cacophony of hype? In SIGMOD, pages 283–284, 2015.\n[63] J. M. Rzeszotarski and A. Kittur. Kinetica: naturalistic multi-touch data visualiza-\ntion. In CHI 2014, pages 897–906, 2014.\n[64] I. Sabek and M. F. Mokbel. Machine learning meets big spatial data. PVLDB,\n12(12):1982–1985, 2019.\n[65] Z. Sadri, L. Gruenwald, and E. Leal. Online index selection using deep reinforce-\nment learning for a cluster database. In ICDE, pages 158–161, 2020.\n[66] T. Schindler and C. Skornia. Secure parallel processing of big data using order-\npreserving encryption on google bigquery. CoRR, abs/1608.07981, 2016.\n[67] C. Shan, N. Mamoulis, R. Cheng, G. Li, X. Li, and Y. Qian. An end-to-end deep\nRL framework for task arrangement in crowdsourcing platforms. In ICDE, pages\n49–60, 2020.\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2865\n\n[68] Y. Sheng, A. Tomasic, T. Sheng, and A. Pavlo. Scheduling OLTP transactions via\nmachine learning. CoRR, abs/1903.02990, 2019.\n[69] N. M. Sheykhkanloo. A learning-based neural network model for the detection\nand classification of SQL injection attacks. IJCWT, 7(2):16–41, 2017.\n[70] J. Sun and G. Li. An end-to-end learning-based cost estimator. PVLDB , 13(3):307–\n319, 2019.\n[71] R. Taft, N. El-Sayed, M. Serafini, Y. Lu, A. Aboulnaga, M. Stonebraker, R. May-\nerhofer, and F. J. Andrade. P-store: An elastic database system with predictive\nprovisioning. In SIGMOD 2018, pages 205–219, 2018.\n[72] P. Tang, W. Qiu, Z. Huang, H. Lian, and G. Liu. SQL injection behavior mining\nbased deep learning. In ADMA 2018, pages 445–454, 2018.\n[73] S. Tian, S. Mo, L. Wang, and Z. Peng. Deep reinforcement learning-based approach\nto tackle topic-aware influence maximization. Data Science and Engineering,\n5(1):1–11, 2020.\n[74] I. Trummer, J. Wang, D. Maram, S. Moseley, S. Jo, and J. Antonakakis. Skinnerdb:\nRegret-bounded query evaluation via reinforcement learning. In SIGMOD, pages\n1153–1170, 2019.\n[75] M. Vartak, H. Subramanyam, W. Lee, S. Viswanathan, S. Husnoo, S. Madden, and\nM. Zaharia. Modeldb: a system for machine learning model management. In\nSIGMOD 2016, page 14, 2016.\n[76] W. Wang, M. Zhang, G. Chen, H. V. Jagadish, B. C. Ooi, and K. Tan. Database\nmeets deep learning: Challenges and opportunities. SIGMOD Rec., 45(2):17–22,\n2016.\n[77] Y. Wang, Y. Yao, H. Tong, F. Xu, and J. Lu. A brief review of network embedding.\nBig Data Mining and Analytics, 2(1):35, 2019.\n[78] Y. R. Wang, S. Hutchison, D. Suciu, and et al. SPORES: sum-product optimization\nvia relational equality saturation for large scale linear algebra. VLDB, 13(11):1919–\n1932, 2020.[79] G. M. Weiss and H. Hirsh. Learning to predict rare events in event sequences. In\nKDD, pages 359–363, 1998.\n[80] C. Wu, A. Jindal, S. Amizadeh, H. Patel, W. Le, S. Qiao, and S. Rao. Towards a\nlearning optimizer for shared clouds. PVLDB, 12(3):210–222, 2018.\n[81] M. Yakout, K. Ganjam, K. Chakrabarti, and S. Chaudhuri. Infogather: entity\naugmentation and attribute discovery by holistic matching with web tables. In\nSIGMOD 2012, pages 97–108, 2012.\n[82] Z. Yang, E. Liang, A. Kamsetty, C. Wu, and et al. Deep unsupervised cardinality\nestimation. VLDB, 13(3):279–292, 2019.\n[83] X. Yu, G. Li, C. chai, and N. Tang. Reinforcement learning with tree-lstm for join\norder selection. In ICDE 2020, pages 196–207, 2019.\n[84] H. Yuan, G. Li, L. Feng, and et al. Automatic view generation with deep learning\nand reinforcement learning. In ICDE, pages 1501–1512, 2020.\n[85] C. Zhang, A. Kumar, and C. Ré. Materialization optimizations for feature selection\nworkloads. In SIGMOD 2014, pages 265–276, 2014.\n[86] C. Zhang, R. Marcus, A. Kleiman, and O. Papaemmanouil. Buffer pool aware\nquery scheduling via deep reinforcement learning. CoRR, abs/2007.10568, 2020.\n[87] J. Zhang, Y. Liu, K. Zhou, G. Li, Z. Xiao, B. Cheng, J. Xing, Y. Wang, T. Cheng,\nL. Liu, M. Ran, and Z. Li. An end-to-end automatic cloud database tuning system\nusing deep reinforcement learning. In SIGMOD 2019, pages 415–432, 2019.\n[88] Y. Zheng, G. Li, Y. Li, C. Shan, and R. Cheng. Truth inference in crowdsourcing:\nIs the problem solved? Proc. VLDB Endow., 10(5):541–552, 2017.\n[89] X. Zhou, C. Chai, G. Li, and J. Sun. Database meets artificial intelligence: A survey.\nTKDE, 2020.\n[90] X. Zhou, J. Sun, G. Li, and J. Feng. Query performance prediction for concurrent\nqueries using graph embedding. VLDB, 13(9):1416–1428, 2020.\nTutorial Track Paper\n \nSIGMOD ’21, June 20–25, 2021, Virtual Event, China\n2866",
  "textLength": 54034
}