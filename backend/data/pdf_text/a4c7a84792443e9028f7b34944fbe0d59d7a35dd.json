{
  "paperId": "a4c7a84792443e9028f7b34944fbe0d59d7a35dd",
  "title": "Faster Fundamental Graph Algorithms via Learned Predictions",
  "pdfPath": "a4c7a84792443e9028f7b34944fbe0d59d7a35dd.pdf",
  "text": "Faster Fundamental Graph Algorithms via Learned Predictions\nJustin Y. Chen\nMIT\njustc@mit.eduSandeep Silwal\nMIT\nsilwal@mit.eduAli Vakilian\nTTIC\nvakilian@ttic.eduFred Zhang\nUC Berkeley\nz0@berkeley.edu\nAbstract\nWe consider the question of speeding up classic graph algorithms with machine-learned predictions.\nIn this model, algorithms are furnished with extra advice learned from past or similar instances. Given\nthe additional information, we aim to improve upon the traditional worst-case run-time guarantees. Our\ncontributions are the following:\n(i) We give a faster algorithm for minimum-weight bipartite matching via learned duals, improving\nthe recent result by Dinitz, Im, Lavastida, Moseley and Vassilvitskii (NeurIPS, 2021);\n(ii) We extend the learned dual approach to the single-source shortest path problem (with negative edge\nlengths), achieving an almost linear runtime given su\u000eciently accurate predictions which improves\nupon the classic fastest algorithm due to Goldberg (SIAM J. Comput., 1995);\n(iii) We provide a general reduction-based framework for learning-based graph algorithms, leading to\nnew algorithms for degree-constrained subgraph and minimum-cost 0-1 \row, based on reductions\nto bipartite matching and the shortest path problem.\nFinally, we give a set of general learnability theorems, showing that the predictions required by our\nalgorithms can be e\u000eciently learned in a PAC fashion.\n1arXiv:2204.12055v1  [cs.DS]  26 Apr 2022\n\n1 Introduction\nThere has been recent interest in moving beyond the traditional and often pessimistic worst-case analysis\nof algorithms by using machine-learned predictions. This paradigm of learning-augmented algorithms is\ninspired by the great success of machine learning (ML) and aims to utilize ML predictions to improve the\nperformance of classic algorithms.\nThe extra information assumed in learning-augmented algorithms can be supplied in a variety of settings.\nFor example, in data streams, the observation that underlying patterns in real-world datasets do not change\nquickly over time has led to the development of an oracle capable of predicting frequently occurring stream\nelements. In distribution learning, it is natural to have access to di\u000berent but related distributions that can\naid our learning tasks. In many other applications, the current input can be similar to past instances that\nmight help us to avoid computing the solution from scratch. All these scenarios fall under the general umbrella\nof a \\warm start\", which enables better initialization of the algorithms to improve their performance.\nThis learning-based paradigm has been successfully applied in many algorithmic domains. They all share\nan underlying goal to minimize some resource constraints: in online algorithms, predictions are used to\nmake better future decisions and reduce regret and competitive ratios [LV18]. In streaming algorithms and\ndata structures, predictors have been developed to optimize space usage [KBC+18, HIKV19]. In sublinear\nalgorithms, predictors can reduce the sample complexity of a task [EIN+21].\nDespite this activity, only recently have there been works on provably improving the time complexity\nof algorithms under this framework. Two recent works which consider this resource include the work of\n[EFS+21] on thek-means clustering problem and the work of [DIL+21] on graph matching; our paper relates\nto the latter. In [DIL+21], the authors give a learning-based algorithm for (min-cost) bipartite matching\nand show that predictions provably result in faster algorithms. Our paper is motivated by three natural\nfollow-up questions:\n(i) Can we derive learning-augmented algorithms which exploit warm starts and other auxilliary informa-\ntion for other important graph optimization problems besides bipartite matching?\n(ii) Do we need a tailor made learning-augmented algorithm for every di\u000berent graph optimization problem?\n(iii) Can we understand when warm starts are learnable for general problems?\n1.1 Our Results\nOur main contributions provide answers to the three motivating questions. We individually address these\nquestions and our relevant contributions.\nCan we derive learning-augmented algorithms for other classic graph optimization problems be-\nsides bipartite matching?\nTowards answering this question, we \frst provide a more e\u000ecient learning-augmented algorithm for bipartite\nmatching than the one in [DIL+21], in Section 3. The algorithm of [DIL+21] uses dual variables from the\nlinear programming formulation of bipartite matching as predictions. We achieve better runtime by utilizing\nthe interplay of this dual and another set of related dual variables, called reduced edge duals, arising from\nviewing bipartite matching as a max-\row problem. This result extends to b-matching as well.\nTheorem 1.1 (Informal; see Theorem 3.2) .Given a weighted bipartite graph and predicted dual ^y, there\nexists an algorithm that \fnds a minimum weight perfect matching in time O(mpn+(m+nlogn)jjy\u0003\u0000^yjj0),\nwherey\u0003is an optimal dual solution.\nThis signi\fcantly improves upon the prior bound of eO(minfmpnjjy\u0003\u0000^y0jj1;mng) due to [DIL+21].\nBeyond the problem of minimum-weight matching, we also use reduced edge duals, which allow us to\nobtain the \frst learning-augmented algorithm for the single-source shortest-paths problem with negative\nedge lengths.\n2\n\nTheorem 1.2 (Informal; see Theorem D.4) .Given a directed graph with negative edge weights and predicted\ndual ^y, there exists an algorithm that \fnds single-source shortest paths in time O(mminfk^y\u0000y\u0003k1\u0001k^y\u0000\ny\u0003k1;pnlog(k^y\u0000y\u0003k1)g), wherey\u0003is an optimal dual solution.\nTo properly utilize these duals, we give an e\u000ecient rounding scheme which takes in as input a set of\npredicted reduced edge duals and rounds them to a feasible instance. See Section 4 for the formal notion of\nfeasibility and our rounding algorithm.\nDo we need a `tailor made' learning-augmented algorithm for every di\u000berent graph optimization\nproblem?\nThe prior work [DIL+21] outlined the three challenges of \\feasibility, optimization, and learnabilty\"\nneeded to put warm start heuristics on theoretical footing. We leverage reductions to avoid addressing\nthese challenges from scratch for each new graph problem. Speci\fcally, we introduce a general framework of\nreductions that takes existing learning-augmented algorithms and applies them to new problems. Note that\nin the context of learning-augmented algorithms, we need reductions that e\u000eciently convert instances of a\ngiven problem to instances of another problem which we know how to solve using predictions. Therefore, we\nmust judiciously choose the problems and reductions to apply in this framework. Nonetheless, the bene\fts of\nour reduction framework include faster learning-augmented algorithms for shortest-paths and new algorithms\nfor other problems, such as degree-constrained subgraph and unit-capacity maximum \row.\nCan we understand when warm starts are learnable for general graph problems?\nGiven the wide range of problems we consider, we need to understand when good hints and predictions\nwhich generalize are learnable. (Note that [DIL+21] is only concerned about learnability of duals for the\nspeci\fc problem of bipartite matching.) We answer this question in Section 6 by generalizing the arguments\nof [DIL+21] beyond bipartite matching.\n1.2 Related Work\nLearning-augmented graph algorithms. The most relevant work to ours is [DIL+21]. We improve\nand extend their results in several ways, as discussed earlier. For the shortest-path problem, a recent work\n[EIX22] investigates the theory of learning-based labeling scheme for the A\u0003search heuristic, whereas a few\nothers approach it empirically [BCS17, YTB+21, CLDS20]. Several previous papers focus on online graph\nproblems [AGKK20, LMRX21, XM21, APT22]. The scope of our paper di\u000bers from theirs, as we study only\no\u000fine problems.\nClassic graph algorithms. There is a vast body of literature addressing graph optimization problems\nconsidered in this paper. We only mention a few that are most relevant to this paper. Similar to [DIL+21],\nour matching algorithm builds upon the classic Hungarian method. There are other theoretically faster\n(exact) algorithms for (bipartite) minimum-cost perfect matching, including [OA92, GK97, DS12]. However,\nthese procedures are fairly involved and hard to incorporate predictions. Our learning-based algorithm for\nsingle-source negative-length shortest paths is inspired by [Gol95]. In the classic setting, a web of reductions\namong graph problems were introduced by [Gab83, Gab85, GT89].\nThe learning-based algorithm paradigm has been applied to a number of other problems. See Appendix A\nfor more related works.\n1.3 Organization\nThe remainder of the paper proceeds as follows. We set up some preliminary background and notations\nin Section 2. In Section 3, we give an improved algorithm for learning-augmented minimum-cost bipartite\nmatching. We then extend the approach to shortest path in Section 4. We address the question of learnability\nin Section 6. Finally, we provide numerical evaluations of our shortest-path algorithm via reductions in\nSection 7.\n3\n\n2 Preliminaries\nNotation. LetG= (V;E) be a graph of medges andnvertices. We will specify its directedness in\ndi\u000berent settings. For a vector x2Rm, we letkxkpto denote its pth norm, for any p\u00150.\nMinimum-Weight Bipartite Perfect Matching. LetG= (V;E) be a bipartite graph with non-negative\nedge costs, and Cbe the maximum cost. The objective of this problem is to \fnd a perfect matching Mwith\nminimum total cost in G. In the minimum-weight b-matching problem, we are also given a demand vector\nb2ZV\n+. The goal is to match each vertex u butimes, with minimum cost.\nMaximum Flow. Given a directed graph G= (V;E) with capacity vector c2RE\n+, letsandtbe distinct\nvertices of H. A feasible s-t\row is a vector f2RE\n+, with each entry representing \row along an edge,\nsuch that sum of incoming \row along edges ( v;u) equals sum of outgoing \row along edges ( u;v) for all\nu2Vnfs;tgandfuv\u0014cuvfor all edge uv. Ans-t-\rowfis maximum if it maximizes the outgoing \row\nfroms. For a feasible \row f,Gfdenotes its residual graph. A classic procedure for \fnding maximum \row\nis Ford-Fulkerson; see [CLRS09].\n3 Improved Learning-Based Minimum-Weight Matching\nThe results from [DIL+21] on matching contain two main results: (1) that given predicted duals for a\nminimum-weight matching problem, there is an e\u000ecient near-optimal algorithm to round the duals to fea-\nsibility and (2) that after rounding, these feasible predicted duals can be used to quickly \fnd a solution to\nthe primal. We provide a new approach to the second problem of using a feasible prediction to quickly solve\nminimum-weight matching that signi\fcantly improves upon prior work.\nFirst, we will restate the theorem from [DIL+21] which established an algorithm from using a feasible\npredicted dual to quickly solve minimum-weight matching.\nTheorem 3.1 (Theorem 13 in [DIL+21]).There exists an algorithm which takes as input a feasible integer\ndual solution ^y0and \fnds a minimum-weight bipartite perfect matching in eO(minfmpnky\u0003\u0000^y0k1;mng)time,\nwherey\u0003is an optimal dual solution.\nWith small modi\fcations to the algorithm and an improved analysis, we present the following improved\ntime complexity.\nTheorem 3.2 (Faster Matching from Predicted Duals) .There exists an algorithm which takes as input a\nfeasible integer dual solution ^y0and \fnds a minimum-weight bipartite perfect matching in O(mpn+ (m+\nnlogn)ky\u0003\u0000^y0k0)time, where y\u0003is an optimal dual solution.\nIf the feasible dual is within O(pn) of an optimal dual in `1distance (which is the case in which the\nalgorithm from [DIL+21] attains an improved runtime over the classical algorithm), our algorithm improves\nupon the time complexity by a factor of\npn\u0012ky\u0003\u0000^y0k1\nky\u0003\u0000^y0k0\u0013\n:\nNote thatky\u0003(c)\u0000^y0(c)k0<ky\u0003(c)\u0000^y0(c)k1as we are considering only integral duals.\nWhile the algorithm from [DIL+21] improves upon the classic Hungarian algorithm only when ky\u0003(c)\u0000\n^y0(c)k1=o(pn), our algorithm improves upon the Hungarian algorithm as long as ky\u0003(c)\u0000^y0(c)k0=o(n),\na much milder condition on the predictions.\nAs a corollary, when combined with the linear-time rounding procedure from [DIL+21], this algorithm\ngives a fast framework for taking a predicted (possibly infeasible) dual and using it to speed up minimum-\nweight matching.\n4\n\nCorollary 3.3. There exists an algorithm which takes as input a (possibly infeasible) integral dual solution\n^y, produces a feasible dual ^y0s.t.k^y0\u0000y\u0003k1\u00143k^y\u0000y\u0003k1, and \fnds a minimum-weight bipartite perfect\nmatching in O(mpn+ (m+nlogn)ky\u0003\u0000^y0k0)time, where y\u0003is an optimal dual solution.\nOur algorithm is given in Algorithm 1. The main di\u000berence in the algorithm/analysis to prior work is\nthat they essentially consider running a O(mpn) matching algorithm at each step and then reason that the\ndual variables increase by at least one on each call to the algorithm, getting the `1dependence on the error.\nOur improvements are based on the following observation. If the predicted duals are accurate enough\nto get improvements over the normal Hungarian algorithm, then the \frst call to a maximum cardinality\nmatching algorithm will match many edges. Then, we can account for the amount of work we have to do in\nsubsequent iterations by the small number of edges remaining to be matched by via a \row interpretation of\nthe matching problem.\nAlgorithm 1 Faster Primal-Dual Scheme for MWPM\n1:procedure MWPM-PD ++(G= (L[R;E);c;y)\n2:E0 fe2Ejyi+yj=cijg\n3:G0 (V;E0)\n4:M Maximum cardinality matching in G0\n5: Give all edges in Eunit capacity and direct them from left to right .Flow representation\n6: Add nodes s;ttoGalong with unit capacity, zero cost edges ( s;i) for alli2Land (j;t) for allj2R\n7: Associate a \row fwithMs.t.8(i;j)2M,fsi=fij=fjt= 1 and otherwise fe= 0\n8:zi \u0000yi8i2L\n9:zj yj8j2R\n10:c0\ne ce+zi\u0000zj8e= (i;j)2Es.t.i;j =2fs;tgandc0\ne 0 for all other edges\n11: whilefhas \row value less than ndo\n12:zu zu+d(s;u)8u2L[Rwhered(\u0001;\u0001) is shortest path distance in Gfw.r.t.c0.Dijkstra\n13:c0\ne ce+zi\u0000zj8e= (i;j)2Es.t.i;j =2fs;tg\n14:E0\nf fe2Efjc0\ne= 0g.\n15:G0\nf (V;E0\nf)\n16:g Maximum \row in G0\nf .Ford-Fulkerson\n17: Augment along ginGf\n18: end while\n19: Returnfe= (i;j)2f:i2L;j2R;fe= 1g\n20:end procedure\nThe formal analysis of the algorithm is somewhat technical and appears in Appendix B, where we prove\nTheorem 3.2.\nExtension to b-matching We extend the improvements for learning-based minimum-weight perfect bi-\npartite matching to the more general problem of minimum-weight perfect b-matching. For two sets of dual\nvariables over the vertices yandz, we will use as a distance measure the weighted `perror:\nky\u0000zkb;p=X\ni2Vbijyi\u0000zijp:\nWe will restate a theorem from [DIL+21].\nTheorem 3.4 (Theorem 31 in [DIL+21]).There exists an algorithm which takes as input a feasible integer\ndual solution ^y0and \fnds a minimum-weight perfect b-matching in O(mnky\u0003\u0000^y0kb;1)time, where y\u0003is an\noptimal dual solution.\nUsing the same algorithm (Algorithm 4 shown in Appendix C), but with an improved analysis, we show\nthe following improved runtime.\n5\n\nTheorem 3.5. There exists an algorithm which takes as input a feasible integer dual solution ^y0and \fnds\na minimum-weight perfect b-matching in O(mn+mky\u0003\u0000^y0kb;0)time, where y\u0003is an optimal dual solution.\nAs before, since the duals are integral, ky\u0003\u0000^y0kb;0\u0014ky\u0003\u0000^y0kb;1. Note that this runtime improves upon\nprior work by a factor of\nmin\u001a\nnky\u0003\u0000^y0kb;1\nky\u0003\u0000^y0kb;0;ky\u0003\u0000^y0kb;1\u001b\n:\nThe full details and proof are in Appendix C.\n4 Fast Learning-Based Shortest Paths\nIn this section, we introduce the reduced edge length duals and how to round them e\u000eciently given predic-\ntions. Reduced edge length duals are de\fned as follows.\nDe\fnition 4.1 (Reduced Edge Length Duals (RE Duals)) .LetG= (V;E)withjVj=n;jEj=m, denote\na directed graph and `:E!Zdenote the length of the edges, which may be negative. y2ZVis a valid or\nfeasible reduced edge length dual (RE Dual) if\n`y(u;v) :=`(u;v) +yu\u0000yv\u00150\nfor all edges e= (u;v)2E.\nIt is natural to study these duals as they appear in many fundamental combinatorial optimization prob-\nlems. For example, consider the dual linear program for the shortest paths problem on the graph G(where\nwe wish to compute the shortest path from vertex stot). It is given by:\nmaxyt\ns.t.yv\u0000yu\u0014`(u;v)\nys= 0:\nNote that the constraints yv\u0000yu\u0014`(u;v) exactly encode `y(u;v)\u00150 in De\fnition 4.1. Furthermore,\ngiven a valid dual solution yto the dual linear program, one can quickly compute the shortest paths in near\nlinear time via an application of Dijkstra's algorithm since all reduced edge lengths are non negative by\nDe\fnition 4.1. This is because the sum of the lengths of edges along any path ( v1;v2;\u0001\u0001\u0001;vk) is the same up\nto an additive term yv1\u0000yvkdue to telescoping. Thus, this transformation preserves the identity of shortest\npaths from a starting vertex. Furthermore, many shortest paths algorithms on general graphs, such as the\nBellman-Ford algorithm, also implicitly calculate the dual y: in the Bellman-Ford algorithm, the dual can\nbe constructed in linear time after the algorithm terminates.\nNow suppose predictions ^ y:V!Zfor the duals yare given. The main result of this section is that\nthere exists an e\u000ecient algorithm, Algorithm 2, which outputs a feasible ^ y0according to De\fnition 4.1.\nTheorem 4.1 (Fast Shortest-Path from Predicted Duals) .Let^y:V!Zbe predicted duals and let y\u0003:V!\nZbe a feasible set of reduced edge length duals according to De\fnition 4.1 such that k^y\u0000y\u0003k1is minimized.\nAlgorithm 2 returns a feasible ^y0:V!Zin time\nO(mminfk^y\u0000y\u0003k1\u0001k^y\u0000y\u0003k1;pnlog(k^y\u0000y\u0003k1)g):\nIf we de\fne reduced edge lengths according to the predicted dual ^ y, it is likely that the non-negativity\nconstraint of some edges become violated, i.e., `^y(e)<0. The goal of Algorithm 2 is to modify some\ncoordinates of ^ yto \fx these negative edge weights. The algorithm uses a key subroutine of Goldberg's\nalgorithm on shortest paths [Gol95]. It proceeds by mending negative edges by reducing the dual value\nof one of their endpoints. At every iteration, we greedily maximize the number of dual variable which\n6\n\nare updated. The vertices which are updated are picked through a layering structure utilized in [Gol95].\nAlgorithm 2 presents the formal details.\nNote that we implicitly assume the given graph Gwith edge lengths given by `does not have a negative\nweight cycle. This is a necessary assumption since otherwise, there exists no valid RE Duals for G: the\nlength of a cycle under any valid dual ymust be non-negative by de\fnition but the cost of any cycle is the\nsame under `and`ydue to telescoping which leads to a contradiction if `induces a negative weight cycle.\nAlgorithm 2 Rounding Predictions for Reduced Edge Length Duals\n1:Input: GraphG= (V;E), predicted duals ^ y:V!Z\n2:procedure Round-RE-Duals (G;^y)\n3: while there exists an edge esuch that`^y(e)<0do\n4:G\u0000= (V;E\u0000) subgraph of Gthat have weight at most 0 under `^y\n5: Contract all strongly connected components in G\u0000.All edges connecting vertices in the same\nstrongly connected component are 0 [Gol95]\n6: Add a vertex xtoG\u0000and connect it with zero length edges to all of V\n7:Li fv2Vjd(x;v) =\u0000ig. dis graph distance in G\u0000using reduced edge lengths given by `^y\n8:i\u0003 arg maxijLij\n9: Lower the value of ^ yvfor all vertices in [t\u0015i\u0003Ltby 1\n10: end while\n11: Return ^y\n12:end procedure\nThe analysis of the algorithm and the proof of Theorem 4.1 appear in Appendix D. The theorem also\nimplies an algorithm for all-pair shortest paths; see Appendix D.2 for details.\n5 A General Framework for Learning-Based Reductions\nIn this section, we introduce a general framework for obtaining learning-augmented algorithms via reductions.\nSuppose we have an oracle which provides hints or a warm start to instances of problem P1. If we are instead\ninterested in solving instances of another problem P2, we can hope to transform our instance at hand to an\ninstance of P1in order to utilize the available predictions. If there exists an e\u000ecient reduction from P2to\nP1, we can indeed use this reduction to transform our instance of P2to that ofP1, use the hints available\nforP1to e\u000eciently solve our new problem, and use the solution found to solve our original instance of P2.\nThis will be the basis of our framework for learning-based reductions.\nWhy is such a framework useful? First, hints might be easier to learn for problem P1or there may\nnot be a natural notion of hints for instances of P2. In addition, there might already exist a learning-based\nalgorithm for P1which e\u000eciently utilizes hints. Therefore, using reductions from other problems to P1would\neliminate the need to create new algorithms and thereby increasing the power and usability of the existing\nlearning-based algorithms.\nWe formally de\fne reductions as follows.\nDe\fnition 5.1 (Reductions) .LetP1andP2be two problem instances. We say that R:P2!P1is a\nreduction from P2toP1if for any instance I2P2,R(I)maps to an instance I0ofP2. Furthermore,\nFurthermore, there exists mapping which takes a solution of I0and converts it to a solution for I.\nNote that the de\fnition of reduction by itself is not quite useful: by the Cook-Levin theorem, any problem\nin the complexity class P can be reduced to 3SAT. However in this paper, we are interested in e\u000ecient\nreductions which take linear or almost linear time in the size of the input. Therefore, such reductions would\nbe extremely fast to execute in practice and the \fnal algorithm of solving instances of IofP2via solving\ninstances of P1using a learned oracle would overall be faster than solving Iwith no hints.\n7\n\n5.1 General Framework\nOur framework is given in Algorithm 3. Note that there, Ais an existing algorithm which solves instances\nof problem P1using hints given by a predictor y:P1!Rd, i.e., the hints are ddimensional vectors.\nAlgorithm 3 General Reduction Framework for Learning-Based Algorithms\n1:Input: Problem instance I2P2. Predictor y:P1!Rd, reduction R:P2!P1, AlgorithmA(P1;y(P1))\n2:procedure Reduction-Solve (P1;P2;y;R;A)\n3:I0 R(I) .Use reduction Rto get an instance of P1\n4: ^y y(I0) .Get hints for instance I0using predictor y\n5: ExecuteA(I0;^y) .Solve instance I0using hints and learning-based algorithm A.\n6: Return solution to Iusing solution for I0given byA(I0;^y).\n7:end procedure\nNote that Step 6 in Algorithm 3 would depend on the instances P1;P2and the reduction R. In some\ncases, some post-processing the solution A(I0;^y) could be required. In the examples we study in this paper,\nboth this step and the reduction Rare e\u000ecient. We give concrete instantiations of Algorithm 3 in Section 5.2.\nNote that we still need to understand the learnability of the hints ^ yin Step 4 of Algorithm 3: even if\nthere exists an e\u000ecient algorithm Afor problem P1, we might not have a predictor yat hand. Note that in\n[DIL+21], the question of learnability of predictors was tackled by assuming access to multiple instances of\na particular problem class drawn from some distribution. In our case, we might have lots of training data\non instances of problem P2but our goal is to train a predictor yforP1in hopes of utilizing A. To do so,\nwe can just go through the reduction Rto get samples of problem instances drawn from P1. Note that the\ndistribution on these problems will be di\u000berent than that on P2. We introduce general learnability results\nwhich imply one can learn a good predictor y. For details, see Section 6.\n5.2 Reductions and Their Implications\nWe now present one application of the reduction framework outlined in the previous section. We demonstrate\nthree more reductions, for degree constrained subgraph, minimum-cost 0-1 \row, and graph diameter, in\nAppendix E.\nShortest Path from Matching. We leverage the following reduction from shortest path (with negative\nedge lengths) to maximum-weight perfect matching on bipartite graphs, due to [Gab85]. Given a directed\ngraphGwith edge lengths given by `, construct a weighted bipartite graph H= (L;R;E ).\n•For each vertex u2G, make two copies u12Landu22R.\n•For each arc ( u;v)2G, create an edge e= (u1;v2) of weight\u0000`(e) inH.\n•Finally, create an edge ( u1;u2) of weight 0 for each vertex u2G.\nNow suppose we \fnd the maximum weight perfect matching of Hand its corresponding dual variables yui\nfor allu2Gandi2f1;2g. By the construction, we immediately have:\nLemma 5.1. The maximum weight perfect matching of Hhas positive weight if and only if the graph Ghas\nnegative cycles.\nOtherwise, we can let \u0019u=yu1for eachu2G. Then by feasibility of y, we have\n\u0000`(e)\u0014yu1+yv2\u0014\u0019u\u0000\u0019v;\nfor anye= (u;v)2G. It follows that \u0019is a feasible dual for the shortest path problem on G, i.e., it satis\fes\nDe\fnition 4.1.\nObserve that the graph Hcontainsm+nedges. By using the run-times for faster matching from [DIL+21]\nas well as our runtime of Section Section 3, we have the following corollary due to Algorithm 3.\n8\n\nTheorem 5.2. Given a shortest path problem on input graph G= (V;E)withnvertices and medges, there\nexists an algorithm which takes takes as input a predicted dual solution ^yto an instance of maximum weight\nperfect matching derived from G, near-optimally rounds the dual to a feasible solution ^y0, and \fnds feasible\nreduced edge length duals for Gin timeO(mpn+ (m+nlogn)jjy\u0003\u0000^y0jj0).\nRemark 5.1. Recall that in Section 4 we derived an alternative runtime of\nO(mminfk^y\u0000y\u0003k1\u0001k^y\u0000y\u0003k1;pnlog(k^y\u0000y\u0003k1))g\nfor the problem of rounding a predicted dual ^yto a feasible dual ^y0to satisfy the reduced edge property of\nDe\fnition 4.1. These results are incomparable since Theorem 5.2 uses dual predictions for matchings on a\ntransformed graph whereas Theorem 4.1 uses predictions for shortest path duals (RE duals) on the original\ngraph.\n6 General Learnability of Hints\nWe now present two general learnability theorems on vector-valued hints for graph optimization problems.\nWe consider the model where the edge weights (or capacities) are drawn from a distribution, while the\nvertex set is the same. The goal is to learn a hint vector in Rdthat is close to the optimal hint on average\n(in`1or`1norm), given i.i.d. samples of the edge weights. We require no assumption either on the edge\nweights distribution or on the notion of optimality of a hint. Indeed, the latter needs to depend on particular\nproblems. For a variety of graph problems, though, the optimal hint could be taken as the optimal dual\nsolution of certain LP relaxation.\nThroughout the section, we assume that the edge weights care drawn from an unknown distribution of\nD. We search for a hint within a range H\u0012Rd.\n6.1 Learnability from Bounded Pseudo-Dimension\nFor a \fxed problem, given edge weight c2Rm, and graph G, leth\u0003(c) denote an optimal hint with respect\nto the instance ( G;c). We consider `1and`1loss:\n`1(h;c) =kh\u0003(c)\u0000hk1=dX\ni=1jh\u0003\ni(c)\u0000hij; (1)\n`1(h;c) =kh\u0003(c)\u0000hk1= max\nijh\u0003\ni(c)\u0000hij: (2)\nThe goal of the algorithm is to \fnd a hint bh2H such that the expected loss Ec\u0018D`(h;c) is minimized, for\n`=`1or`1. Leth\u00032arg minh2HEc\u0018D`(h;c).\nL1Loss. Our \frst result is a straightforward abstraction of the main learnability theorem of [DIL+21], for\nthe`1loss. In particular, we show that one can \fnd a hint vector bh2Rdthat approximately minimizes the\npopulation loss Ec\u0018D`1(h;c), under the following conditions:\nTheorem 6.1 (`1-learnability; see also Theorem 14 of [DIL+21]).For any graph problem with optimal hint\nh\u0003(c)2H forc\u0018D, assume that\n•(bounded range) for any h2H we havehi2[\u0000M;M ]for alli, for someM; and\n•(e\u000ecient optimization) there exists a polynomial time algorithm that \fnds a hint vector h2H that\nminimizesPs\ni=1kh\u0003(ci)\u0000hk1, given i.i.d. samples c1;c2;:::;cs\u0018D.\nThen there is a polynomial-time algorithm that given s=O\u0010\u0000dM\n\u000f\u00012(dlogd+ log(1=\u000e))\u0011\nsamples returns a\nhinth2H such that Ec\u0018D`1(h;c)\u0014Ec\u0018D`1(h\u0003(c);c) +\u000fwith probability at least 1\u0000\u000e.\n9\n\nL1Loss. We now give a learnability result for the `1loss.\nTheorem 6.2 (`1-learnability) .For any graph problem with optimal hint h\u0003(c)2H forc\u0018D, assume that\n•(bounded range) for any h2H we havehi2[\u0000M;M ]for alli, for someM; and\n•(e\u000ecient optimization) there exists a polynomial time algorithm that \fnds a hint vector h2H that\nminimizesPs\ni=1kh\u0003(ci)\u0000hk1, given i.i.d. samples c1;c2;:::;cs\u0018D.\nThen there is a polynomial-time algorithm that given s=O\u0010\u0000dM\n\u000f\u00012(d+ log(1=\u000e))\u0011\nsamples returns a hint\nh2H such that Ec\u0018D`1(h;c)\u0014Ec\u0018D`1(h\u0003(c);c) +\u000fwith probability at least 1\u0000\u000e.\nThe proofs of the two theorems appear in Appendix F.\n6.2 Learnability from Arithmetic Complexity\nWe give an alternative argument for learning predictions. Informally, we show that good predictions can be\nlearned e\u000eciently if the loss function can be `computed e\u000eciently'. This provides a more general framework\nthat goes beyond `1or`1norm error. See Appendix F.3 for formal details.\n7 Empirical Simulations\nWe demonstrate the applicability of our learning-based reductions framework with a real world case study\non foreign exchange markets. The reduction we focus on is the general shortest paths to bipartite matching\nreduction outlined in Section 7. We focus our evaluation on this task since prior work in [DIL+21] has\nalready demonstrated the empirical advantage of learning-based methods for bipartite matching.\nOur graph dataset is constructed as follows. We have a weighted directed graph where nodes represent\ncountries and all possible directed edges between all pairs are present. The weight of the directed edge from\ncountryiandjrepresents the average monthly exchange rate between the currencies of the two countries, i.e.,\nthe amount of currency jwe can obtain starting from one unit of currency i, as set by the foreign exchange\nrate market1. We transform these weights by taking the natural logarithm and negating the weight. This\nimplies that the shortest path from country ito countryjon the transformed graph represents the optimal\nway to convert one unit of currency ito the currency of j, i.e., the set of conversions which maximize the\namount of currency j.\nExperimental Setup. We \frst describe our training dataset. We construct the graph described above\nfor each month of the year 2019 where we use the average monthly exchange rates as edge weights before\nperforming the transformation. Our testing dataset are similarly constructed graphs for each month of 2020\nand 2021. For each graph, we construct the reduction from shortest paths to matching outlined in Section 5.2.\nBy Lemma 5.1, the output of the maximum weight perfect matching on the bipartite graph obtained via\nthe reduction gives us feasible reduced edge length duals which we can be subsequently use to solve shortest\npaths in nearly linear time. The resulting bipartite graphs have \u0018500 vertices each and \u00185\u0001104edges.\nWe use the code from [DIL+21]2for the maximum weight bipartite matching algorithm. As in [DIL+21],\nwe measure the runtime in terms of the number of steps used by the Hungarian algorithm to solve the\nmatching instances derived from our training and test graph datasets when we initialize the algorithm with\npredicted duals versus when we start the algorithm \\from scratch.\"\nWe instantiate predictions in two distinct ways, similar to the methodology of [DIL+21]: (a) \frst, we\nconsider the batch version where we compute the optimal dual variables in the training set, take their median,\nand use these as the predicted dual variables for each of the graphs in the test set. (b) The second method\nis the online version where we use the optimal dual variables from the graph for the prior month in the test\nset as initialization for the current month.\n1Dataset scraped from https://fxtop.com/en/historical-exchange-rates.php\n2Available at https://github.com/tlavastida/LearnedDuals\n10\n\n1/2020\n2/2020\n3/2020\n4/2020\n5/2020\n6/2020\n7/2020\n8/2020\n9/2020\n10/2020\n11/2020\n12/2020\n1/2021\n2/2021\n3/2021\n4/2021\n5/2021\n6/2021\n7/2021\n8/2021\n9/2021\n10/2021\n11/2021\n12/202150100150200250300350# IterationsClassic\nLearned (Batch)\nLearned (Online)Figure 1: Comparison of the classical Hungarian\nalgorithm (blue) versus learning-augmented\nalgorithms. Predictions lead to up to an order\nmagnitude reduction in number of iterations.\n6000 8000 10000 12000 14000 16000 18000 20000 22000\nExcess Dual Objective210220230240250Saved Hungarian IterationsLinear Fit\nExcess IterationsFigure 2: Excess dual objective versus the number\nof saved Hungarian iterations in the batch version.\nThere is a negative correlation between the\nexcess dual and the # of saved iterations\nResults. Our results are shown in Figures 1 and 2. Figure 1 shows up to an order of magnitude reduction\nin the number of iterations taken by the learning-augmented algorithm versus the classical and widely used\nHungarian algorithm. As expected, the online method performs slightly better than the batch version as it\nis able to o\u000ber more accurate predictions for the next graph instance. This is very intuitive: it is rare for the\nforeign exchange market to experience drastic shifts over the span of one month since such a shift implies a\nmajor global event.\nOur results also validate the dependence of prediction error derived in our theoretical bounds. In Figure\n2, we plot the excess dual objective, de\fned asP\ney\u0003\ne\u0000P\ne^yewhere recall that y\u0003represents the optimal\ndual variables and ^ ydenotes the predictions, versus the number of steps saved in the Hungarian algorithm\nin our batch setting; we obtained a qualitatively similar result for the online setting. We see there is a\ndirect linear relationship between the excess dual objective, which represents the prediction error, and the\ndecrease in runtime, measured by the number of Hungarian iterations saved. Note that we removed three\noutlier points from Figure 2 which represent data from October 2021 to December 2021. The outlier points\nshowed a large excess dual as well as large savings in runtime (which can be inferred from Figure 1). We\nhypothesize that this is because of a distribution shift which occurred during these months in the foreign\nexchange markets. Indeed, examining the conversion rate from the Euro to US Dollars for example, we see\na 3% decrease in the exchange rate which represents the biggest decrease in the time frame of our training\nand test dataset. This can be explained by global events such as the rise of the Omicron strain or concerns\nabout increased in\ration.\nIn addition to extending and complementing the experimental results of [DIL+21], we summarize our\nresults in the following points: (a) Our theory is predictive of experimental performance. Both \fgures demon-\nstrates that better predictions imply better empirical runtime. In addition, Figure 2 demonstrates a direct\nrelationship between prediction error and runtime, as implied by our theoretical bounds. (b) The reduction\nframework is e\u000ecient to carry out and execute in practice. (c) Learning augmented graph algorithms can be\napplied to real world datasets varying over time such as in the analysis of graphs derived from the foreign\nexchange rates market.\nAcknowledgment\nWe thank Piotr Indyk for helpful comments on an early draft of the paper and Robert Tarjan for providing\nus with the reference [Gab83].\n11\n\nJustin and Sandeep are supported by an NSF Graduate Research Fellowship under Grant No. 1745302,\nNSF TRIPODS program (award DMS-2022448), NSF award CCF-2006798, and Simons Investigator Award.\nJustin is also supported by a MathWorks Engineering Fellowship. Ali is supported by NSF award CCF-\n1934843.\nReferences\n[ABB99] Martin Anthony, Peter L Bartlett, and Peter L Bartlett. Neural Network Learning: Theoretical\nFoundations , volume 9. Cambridge University Press, 1999.\n[ACI22] Anders Aamand, Justin Y. Chen, and Piotr Indyk. (Optimal) Online Bipartite Matching with\nPredicted Degrees. CoRR , abs/2110.11439, 2022.\n[AEMP22] Sara Ahmadian, Hossein Esfandiari, Vahab Mirrokni, and Binghui Peng. Robust load balancing\nwith machine learned advice. In Proceedings of the 2022 Annual ACM-SIAM Symposium on\nDiscrete Algorithms (SODA) , 2022.\n[AGKK20] Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online\nmatching problems with machine learned advice. In Advanced in Neural Information Processing\nSystems (NeurIPS) , 2020.\n[AGKP21] Keerti Anand, Rong Ge, Amit Kumar, and Debmalya Panigrahi. A regression approach to\nlearning-augmented online algorithms. Advances in Neural Information Processing Systems\n(NeurIPS) , 34, 2021.\n[AGP20] Keerti Anand, Rong Ge, and Debmalya Panigrahi. Customizing ml predictions for online algo-\nrithms. In International Conference on Machine Learning (ICML) , 2020.\n[AKL+19] Daniel Alabi, Adam Tauman Kalai, Katrina Liggett, Cameron Musco, Christos Tzamos, and\nEllen Vitercik. Learning to prune: Speeding up repeated computations. In Conference on\nLearning Theory (COLT) , 2019.\n[AMK21] Mohammad Ali Alomrani, Reza Moravej, and Elias B Khalil. Deep policies for online bipartite\nmatching: A reinforcement learning approach. arXiv preprint arXiv:2109.10380 , 2021.\n[AMO93] Ravindra K. Ahuja, Thomas L. Magnanti, and James B. Orlin. Network Flows: Theory, Algo-\nrithms, and Applications . Prentice Hall, 1993.\n[AMW19] Saeed Amizadeh, Sergiy Matusevych, and Markus Weimer. Learning to solve circuit-SAT: An\nunsupervised di\u000berentiable approach. In International Conference on Learning Representations\n(ICLR) , 2019.\n[APT22] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. Online graph algorithms with predictions.\nInProceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) .\nSIAM, 2022.\n[BCK+22] Nikhil Bansal, Christian Coester, Ravi Kumar, Manish Purohit, and Erik Vee. Learning-\naugmented weighted paging. In Proceedings of the 2022 Annual ACM-SIAM Symposium on\nDiscrete Algorithms (SODA) . SIAM, 2022.\n[BCS17] Mohak Bhardwaj, Sanjiban Choudhury, and Sebastian Scherer. Learning heuristic search via\nimitation. In Conference on Robot Learning (CoRL , 2017.\n[BDD+21] Maria-Florina Balcan, Dan F. DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and\nEllen Vitercik. How much data is su\u000ecient to learn high-performing algorithms? generalization\nguarantees for data-driven algorithm design. Proceedings of the 53rd Annual ACM SIGACT\nSymposium on Theory of Computing (STOC) , 2021.\n12\n\n[BDSV18a] Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch.\nInInternational Conference on Machine Learning (ICML) , 2018.\n[BDSV18b] Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch.\nInInternational Conference on Machine Learning (ICML) , 2018.\n[BDV18] Maria-Florina Balcan, Travis Dick, and Ellen Vitercik. Dispersion for data-driven algorithm\ndesign, online learning, and private optimization. 2018 IEEE 59th Annual Symposium on Foun-\ndations of Computer Science (FOCS) , 2018.\n[BDW18] Maria-Florina Balcan, Travis Dick, and Colin White. Data-driven clustering via parameterized\nLloyd's families. In Advanced in Neural Information Processing Systems (NeurIPS) , 2018.\n[BLP21] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial\noptimization: a methodological tour d'horizon. European Journal of Operational Research ,\n290(2):405{421, 2021.\n[BMS20] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning\naugmented algorithms. In Advances in Neural Information Processing Systems (NeurIPS) ,\n2020.\n[BPL+16] Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. Neural combina-\ntorial optimization with reinforcement learning. CoRR , abs/1611.09940, 2016.\n[CGP20] Edith Cohen, O\fr Geri, and Rasmus Pagh. Composable sketches for functions of frequencies:\nBeyond the worst case. In International Conference on Machine Learning (ICML) , 2020.\n[CGT+20] Shuchi Chawla, Evangelia Gergatsouli, Yifeng Teng, Christos Tzamos, and Ruimin Zhang.\nPandora's box with correlations: Learning and approximation. In IEEE 61st Annual Symposium\non Foundations of Computer Science (FOCS) , 2020.\n[CLDS20] Binghong Chen, Chengtao Li, Hanjun Dai, and Le Song. Retro*: learning retrosynthetic plan-\nning with neural guided a* search. In International Conference on Machine Learning (ICML) ,\n2020.\n[CLRS09] Thomas H Cormen, Charles E Leiserson, Ronald L Rivest, and Cli\u000bord Stein. Introduction to\nalgorithms . MIT press, 2009.\n[DIL+21] Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii.\nFaster matchings via learned duals. Advances in Neural Information Processing Systems\n(NeurIPS) , 2021.\n[DIRW20] Yihe Dong, Piotr Indyk, Ilya P Razenshteyn, and Tal Wagner. Learning space partitions for\nnearest neighbor search. International Conference on Learning Representations (ICLR) , 2020.\n[DKT+21] Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, Ali Vakilian, and Nikos Zari\fs. Learning\nonline algorithms with distributional advice. In International Conference on Machine Learning\n(ICML) , 2021.\n[DS12] Ran Duan and Hsin-Hao Su. A scaling algorithm for maximum weight matching in bipartite\ngraphs. In Proceedings of the twenty-third annual ACM-SIAM symposium on Discrete Algo-\nrithms (SODA) , 2012.\n[DW21] Mina Dalirrooyfard and Nicole Wein. Tight conditional lower bounds for approximating diame-\nter in directed graphs. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory\nof Computing (STOC) , 2021.\n13\n\n[DWM21] Elbert Du, Franklyn Wang, and Michael Mitzenmacher. Putting the \\learning\" into learning-\naugmented algorithms for frequency estimation. In International Conference on Machine Learn-\ning (ICML) , 2021.\n[EFS+21] Jon Ergun, Zhili Feng, Sandeep Silwal, David P. Woodru\u000b, and Samson Zhou. Learning-\naugmented k-means clustering. CoRR , abs/2110.14094, 2021.\n[EIN+21] Talya Eden, Piotr Indyk, Shyam Narayanan, Ronitt Rubinfeld, Sandeep Silwal, and Tal Wagner.\nLearning-based support estimation in sublinear time. In International Conference on Learning\nRepresentations (ICLR) , 2021.\n[EIX22] Talya Eden, Piotr Indyk, and Haike Xu. Embeddings and labeling schemes for a. In 13th\nInnovations in Theoretical Computer Science Conference (ITCS 2022) , 2022.\n[EKM15] Hossein Esfandiari, Nitish Korula, and Vahab Mirrokni. Online allocation with tra\u000ec spikes:\nMixing adversarial and stochastic models. In Proceedings of the Sixteenth ACM Conference on\nEconomics and Computation (EC) , 2015.\n[FLV20] Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so e\u000bective?\nInInternational Conference on Machine Learning (ICML) , 2020.\n[Gab83] Harold N Gabow. An e\u000ecient reduction technique for degree-constrained subgraph and bidi-\nrected network \row problems. In Proceedings of the Fifteenth Annual ACM Symposium on\nTheory of Computing (STOC) , 1983.\n[Gab85] Harold N Gabow. Scaling algorithms for network problems. Journal of Computer and System\nSciences , 31(2):148{168, 1985.\n[GK97] Andrew V Goldberg and Robert Kennedy. Global price updates help. SIAM Journal on Discrete\nMathematics , 10(4):551{572, 1997.\n[Gol95] Andrew V Goldberg. Scaling algorithms for the shortest paths problem. SIAM Journal on\nComputing , 24(3):494{504, 1995.\n[GP19] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert\nadvice. In International Conference on Machine Learning (ICML) , 2019.\n[GR17] Rishi Gupta and Tim Roughgarden. A PAC approach to application-speci\fc algorithm selection.\nSIAM J. Comput. , 46:992{1017, 2017.\n[GT89] Harold N Gabow and Robert E Tarjan. Faster scaling algorithms for network problems. SIAM\nJournal on Computing , 18(5):1013{1036, 1989.\n[HIKV19] Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency estimation\nalgorithms. In International Conference on Learning Representations (ICLR) , 2019.\n[IKMQP21] Sungjin Im, Ravi Kumar, Mahshid Montazer Qaem, and Manish Purohit. Non-clairvoyant\nscheduling with predictions. In Proceedings of the 33rd ACM Symposium on Parallelism in\nAlgorithms and Architectures (SPAA) , 2021.\n[ISZ21] Zachary Izzo, Sandeep Silwal, and Samson Zhou. Dimensionality reduction for wasserstein\nbarycenter. In Advances in Neural Information Processing Systems (NeurIPS) , 2021.\n[IVY19] Piotr Indyk, Ali Vakilian, and Yang Yuan. Learning-based low-rank approximations. In Ad-\nvanced in Neural Information Processing Systems (NeurIPS) , 2019.\n[JLL+20] Tanqiu Jiang, Yi Li, Honghao Lin, Yisong Ruan, and David P. Woodru\u000b. Learning-augmented\ndata stream algorithms. In International Conference on Learning Representations (ICLR) , 2020.\n14\n\n[KBC+18] Tim Kraska, Alex Beutel, Ed H Chi, Je\u000brey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proceedings of the 2018 International Conference on Management of Data\n(SIGMOD) , pages 489{504, 2018.\n[KDN+17] Elias B Khalil, Bistra Dilkina, George L Nemhauser, Shabbir Ahmed, and Yufen Shao. Learning\nto run heuristics in tree search. In IJCAI , 2017.\n[KDZ+17] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial\noptimization algorithms over graphs. In Advances in Neural Information Processing Systems\n(NIPS) , 2017.\n[KLBS+16] Elias Khalil, Pierre Le Bodic, Le Song, George Nemhauser, and Bistra Dilkina. Learning to\nbranch in mixed integer programming. In Proceedings of the AAAI Conference on Arti\fcial\nIntelligence (AAAI) , 2016.\n[KvHW19] Wouter Kool, Herke van Hoof, and Max Welling. Attention, learn to solve routing problems!\nInInternational Conference on Learning Representations (ICLR) , 2019.\n[LCK18] Zhuwen Li, Qifeng Chen, and Vladlen Koltun. Combinatorial optimization with graph convolu-\ntional networks and guided tree search. In Advances in Neural Information Processing Systems\n(NeurIPS) , 2018.\n[LFKF18] Mario Lucic, Matthew Faulkner, Andreas Krause, and Dan Feldman. Training gaussian mixture\nmodels at scale via coresets. Journal of Machine Learning Research (JMLR) , 18(160):1{25, 2018.\n[LLMV20] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online schedul-\ning via learned weights. In Proceedings of the 31st Annual ACM-SIAM Symposium on Discrete\nAlgorithms (SODA) , 2020.\n[LMRX21] Thomas Lavastida, Benjamin Moseley, R. Ravi, and Chenyang Xu. Learnable and instance-\nrobust predictions for online matching, \rows and load balancing. In 29th Annual European\nSymposium on Algorithms (ESA) , 2021.\n[LV18] Thodoris Lykouris and Sergei Vassilvtiskii. Competitive caching with machine learned advice.\nInInternational Conference on Machine Learning (ICML) . PMLR, 2018.\n[Mit18] Michael Mitzenmacher. A model for learned bloom \flters and optimizing by sandwiching. In\nAdvances in Neural Information Processing Systems (NeurIPS) , 2018.\n[Mit20] Michael Mitzenmacher. Scheduling with predictions and the price of misprediction. In 11th\nInnovations in Theoretical Computer Science Conference (ITCS) , 2020.\n[MNS12] Mohammad Mahdian, Hamid Nazerzadeh, and Amin Saberi. Online optimization with uncertain\ninformation. ACM Transactions on Algorithms (TALG) , 8(1):1{29, 2012.\n[MRT18] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning .\nMIT Press, 2018.\n[MSIB21] Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Burnaev. Reinforcement learning\nfor combinatorial optimization: A survey. Computers & Operations Research , page 105400, 2021.\n[MSV+19] Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng, and Mohammad\nAlizadeh. Learning scheduling algorithms for data processing clusters. In Proceedings of the\nACM Special Interest Group on Data Communication . 2019.\n[MV20] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. arXiv preprint\narXiv:2006.09123 , 2020.\n15\n\n[NOST18] Mohammadreza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin Tak\u0013 ac. Reinforcement\nlearning for solving the vehicle routing problem. In Advances in Neural Information Processing\nSystems (NeurIPS) , 2018.\n[OA92] James B Orlin and Ravindra K Ahuja. New scaling algorithms for the assignment and minimum\nmean cycle problems. Mathematical programming , 54(1):41{56, 1992.\n[PSK18] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predic-\ntions. In Advances in Neural Information Processing Systems (NeurIPS) , 2018.\n[RBL19] Jack Rae, Sergey Bartunov, and Timothy Lillicrap. Meta-learning neural bloom \flters. In\nInternational Conference on Machine Learning (ICML) , 2019.\n[Roh20] Dhruv Rohatgi. Near-optimal bounds for online caching with machine learned advice. In\nProceedings of the 31st Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) , 2020.\n[SLB+19] Daniel Selsam, Matthew Lamm, Benedikt B unz, Percy Liang, Leonardo de Moura, and David L.\nDill. Learning a SAT solver from single-bit supervision. In International Conference on Learning\nRepresentations (ICLR) , 2019.\n[VKKM21] Kapil Vaidya, Eric Knorr, Tim Kraska, and Michael Mitzenmacher. Partitioned learned bloom\n\flter. In International Conference on Learning Representations (ICLR) , 2021.\n[Wei20] Alexander Wei. Better and simpler learning-augmented online caching. In Approxima-\ntion, Randomization, and Combinatorial Optimization. Algorithms and Techniques (AP-\nPROX/RANDOM 2020) , 2020.\n[WLKC16] Jun Wang, Wei Liu, Sanjiv Kumar, and Shih-Fu Chang. Learning to hash for indexing big data\n- a survey. Proceedings of the IEEE , 104(1):34{57, 2016.\n[WZ20] Alexander Wei and Fred Zhang. Optimal robustness-consistency trade-o\u000bs for learning-\naugmented online algorithms. Advances in Neural Information Processing Systems (NeurIPS) ,\n2020.\n[XM21] Chenyang Xu and Benjamin Moseley. Learning-augmented algorithms for online steiner tree.\narXiv preprint arXiv:2112.05353 , 2021.\n[YTB+21] Ryo Yonetani, Tatsunori Taniai, Mohammadamin Barekatain, Mai Nishimura, and Asako\nKanezaki. Path planning using neural a* search. In International Conference on Machine\nLearning (ICML) , 2021.\n[ZGA+21] Hang Zhu, Varun Gupta, Satyajeet Singh Ahuja, Yuandong Tian, Ying Zhang, and Xin Jin.\nNetwork planning with deep reinforcement learning. In Proceedings of the 2021 ACM SIGCOMM\n2021 Conference , pages 258{271, 2021.\n16\n\nA More Related work\nLearning-augmented approaches have found success in a wide array of algorithmic tasks. This includes\nimproving classic space complexity in streaming algorithms [HIKV19, IVY19, CGP20, JLL+20, EIN+21,\nDWM21], and achieving better competitive ratios in online algorithms [MNS12, EKM15, LV18, PSK18,\nGP19, Roh20, Wei20, LLMV20, BMS20, ACI22, AGP20, WZ20, DKT+21, AGKP21, BCK+22]. Other appli-\ncation domains include data structures [KBC+18, FLV20, Mit18, RBL19, VKKM21], similarity search [WLKC16,\nDIRW20], and machine scheduling [Mit20, AEMP22, LLMV20, IKMQP21].\nA number of works study deep and reinforcement learning for combinatorial optimization and integer\nprogramming [BPL+16, KLBS+16, KDN+17, KDZ+17, BDSV18a, NOST18, LCK18, KvHW19, SLB+19,\nMSV+19, AMW19, AKL+19, ZGA+21, AMK21]. Most of the work in this direction are empirical in nature.\nSee [MSIB21, BLP21] for two recent surveys.\nThere are also recent works on a related area of data driven algorithm design whose focus is to learn a\ngeneralizable algorithm from a family using a small number of samples rather than study how a predictor can\naid in an algorithmic task [GR17, BDD+21, BDV18, BDSV18b, BDW18, CGT+20]. See the article [MV20]\nfor a recent survey.\nB Omitted Details from Section 3\nB.1 Proof of Theorem 3.2\nCorrectness of Algorithm 1. We now prove the correctness of Algorithm 1. The following three claims\nare well known facts about the minimum-weight perfect matching problem (see, for instance [AMO93]).\nClaim B.1. There exists a \row of value nif and only if there exists a perfect matching.\nClaim B.2. If the \rowfat the end of the algorithm is a minimum-cost \row of value n, then the returned\nset of edges is a minimum-cost perfect matching.\nClaim B.3. A \rowfis a minimum-cost \row if and only if Gfcontains no negative cost cycles.\nLemma B.4. The residual graph Gfat the end of Algorithm 1 contains no cycles which include nodes sor\nt.\nProof. At the end of the algorithm, fwill have value nand will saturate all edges leaving sas well as all\nedges entering t. Therefore, all edges containing swill be incoming edges and all edges containing twill\nbe outgoing edges. For both nodes, as all of their edges are oriented in the same direction, they cannot be\nincluded in any cycles.\nLemma B.5. From their initialization in step 10 of Algorithm 1, all reduced edge costs c0in the residual\ngraphGfare non-negative.\nProof. Note that any edges containing sortalways have reduced cost 0. Starting from the costs set at step\n10 of the algorithm, we will prove inductively that for all edges ( i;j) in the residual graph s.t. i;j =2fs;tg,\nc0\nij\u00150. From the feasibility of the dual variables y, for all (i;j)2Es.t.i2L;j2R,\nyi+yj\u0014cij:\nTherefore, for all left to right edges in the residual graph,\nc0\nij=cij+zi\u0000zj=cij\u0000yi\u0000yj\u00150:\nIt remains to consider edges ( j;i)2Efs.t.j2R;i2L. These backwards edges exist if and only if fij= 1.\nBy step 7,fij= 1 only if the matching Mderived in step 4 contains ( i;j). This implies that yi+yj=cij.\nTherefore, for such edges ( j;i)2Ef,\nc0\nji=\u0000cij+zj\u0000zi=\u0000cij+yj+yi= 0:\n17\n\nThis completes the base case: all edges in the residual graph have non-negative reduced cost at step 10.\nFor the inductive step, assume going into the while loop that all c0\nefore= (i;j)2Gfsuch that\ni;j =2fs;tgare non-negative. Consider the new reduced costs for any such edge ( i;j) at step 13, noting that\nd(s;j)\u0014d(s;i) +c0\nij. Letc00denote the updated costs and c0denote the previous reduced costs:\nc00\nij=cij+zi\u0000zj=c0\nij+d(s;i)\u0000d(s;j)\n\u0015c0\nij+d(s;i)\u0000(d(s;i) +c0\nij) = 0:\nSo, the new costs are also non-negative.\nNow, consider the augmentation in step 17 which will change the edges in the residual graph Gf. In\nparticular, some edges ( i;j) will disappear and be replaced by edges ( j;i) with reduced costs c0\nji=\u0000c0\nij. As\nwe only augment along edges with reduced costs cij= 0, the reverse edges we create in the residual graph\nwill also have reduced cost 0. Therefore, the invariant holds that costs remain non-negative, completing the\nproof.\nLemma B.6. Assume that there exists a perfect matching. If fhas \row value less than n, then the \row g\ncomputed in step 16 of Algorithm 1 will have value at least 1.\nProof. First, note that the \row fmaintained by the algorithm will always have capacity in f0;1gas the\ngraphGhas unit capacities and we always augment by a maximum \row which will have value either 0 or\n1 along each edge. If fhas value less than n, as the max \row value is n(due to the existence of a perfect\nmatching), there must exist some path of \row value 1 from stotinGf. This implies that d(s;t)>0. Let\nPbe the a shortest path from stotinGfas measured by the reduced costs c0. Note that for any edge\n(i;j)2P,d(s;j) =d(s;i) +c0\nij(or else,Pis not a shortest path). So, after updating the reduced costs in\nstep 13, every edge in Pmust have reduced cost 0. Therefore, P\u0012E0\nfand the maximum \row computed in\nstep 16 must have \row value 1.\nLemma B.7. Algorithm 1 returns a minimum-cost perfect matching, if one exists.\nProof. Assume that a perfect matching exists. By Lemmas B.1 and B.6, the algorithm will terminate with\na \row of value n. By Lemmas B.2 and B.3, it su\u000eces to show that there are no negative cycles in the\n\fnal residual graph Gf. By Lemma B.4, any cycles in Gfmust only contain edges ( i;j) wherei;j =2fs;tg.\nBy Lemma B.5, all reduced costs c0\nijof edges (i;j)2Efare non-negative. Let C\u001aEfbe any cycle in Gf.\nThe value of Cis X\n(i;j)2Ccij=X\n(i;j)2Cc0\nij\u0000zi+zj\u0015X\n(i;j)2C\u0000zi+zj:\nAsCis a cycle, each vertex incident on Chas equally many incoming and outgoing edges, cancelling out\nthe contributions of each zuso thatX\n(i;j)2C\u0000zi+zj= 0:\nHence, there are no negative cycles in Gf, completing the proof of the correctness of Algorithm 1.\nRuntime of Algorithm 1 We now analyze the runtime of Algorithm 1.\nLemma B.8. After the \frst call to maximum cardinality matching in step 4, the partial matching Mwill\ncontain at least n\u0000ky\u0003\u0000^y0k0edges.\nProof. Consider the minimum-weight perfect matching M\u0003corresponding to the optimal duals y\u0003. Note\nthat the edges in M\u0003are vertex disjoint since they constitute a matching. Let M00be the set of edges in M\u0003\nthat are tight under ^ y0:\nM00=fe=ij2M\u0003: ^y0\ni+ ^y0\nj=ceg:\n18\n\nAsy\u0003is tight for all edges in M\u0003, if the predicted and optimal duals agree on both endpoints of an edge in\nM\u0003, that edge is also tight under ^ y0. Therefore, out of the nedges inM\u0003, at mostky\u0003\u0000^y0k0of them do\nnot have tight constraints under ^y0. Equivalently,jM00j\u0015n\u0000ky\u0003\u0000^y0k0.\nConsider the call to maximum cardinality matching in step 4. As M\u0003is a valid matching and M00\u0012M\u0003,\nM00is a valid matching as well. In addition, all of M00's edges are contained in E0(the set of tight edges\nunder ^y0). Therefore, M00is a valid matching for step 4. So, the maximum cardinality matching returned\nby step 4 must have size at least jM00j\u0015n\u0000ky\u0003\u0000^y0k0, completing the proof.\nLemma B.9. The total number of iterations of the while loop in step 11 will be at most ky\u0003\u0000^y0k0.\nProof. By Lemma B.6, we will increase the \row value of fby at least 1 each iteration of the while loop.\nBy Lemma B.8, fenters the while loop with value n\u0000ky\u0003\u0000^y0k0. Therefore, there can be at most ky\u0003\u0000^y0k0\niterations.\nLemma B.10. The total amount of work done by calls to Ford-Fulkerson in step 16 is O(mky\u0003\u0000^y0k0)\nProof. The runtime of Ford-Fulkerson is O(mf) wherefis the value of the max \row. By Lemma B.8, the\n\row value can increase by at most ky\u0003\u0000^y0k0over all calls to Ford-Fulkerson before we reach a \row of value\nn. So, Ford-Fulkerson does a total of O(mky\u0003\u0000^y0k0) work, as required.\nWe are now ready to prove the main theorem.\nProof of Theorem 3.2. By Lemma B.7, the algorithm returns a minimum-cost perfect matching, if one exists.\nIt remains to prove the runtime. The \frst call to matching takes O(mpn) time. Constructing the initial \row\nand residual graph as well as the corresponding costs takes O(m) time. By Lemma B.9, there are at most\nky\u0003\u0000^y0k0iterations of the while loop. In each iteration, calculating the shortest path distances can be done\nvia Dijkstra's algorithm in O(m+nlogn) time as the reduced costs are always non-negative by Lemma B.5.\nUpdating the costs and constructing the subgraph G0\nftakesO(m) time. Augmenting along the \row gtakes\nO(m) time. So, ignoring calls to Ford-Fulkerson, the total running time of work done in the while loop is\nO((m+nlogn)ky\u0003\u0000^y0k0). By Lemma B.10, all calls to Ford-Fulkerson takes a total of O(mky\u0003\u0000^y0k0).\nSo, the total runtime of the algorithm is O(mpn+ (m+nlogn)ky\u0003\u0000^y0k0), as required.\nC Improved Learning-Based Minimum-Weight b-Matching\nAs a corollary to Theorem 3.5, when combined with the near-linear time rounding procedure from [DIL+21],\nthis algorithm gives a fast framework for taking a predicted (possibly infeasible) dual and using it to speed\nup minimum-weight b-matching.\nCorollary C.1. There exists an algorithm which takes as input a (possibly infeasible) integral dual solution\n^y, produces a feasible dual ^y0s.t.k^y0\u0000y\u0003kb;1\u00145k^y\u0000y\u0003kb;1, and \fnds a minimum-weight perfect b-matching\ninO(mn+mky\u0003\u0000^y0kb;0)time, where y\u0003is an optimal dual solution.\nThe runtime of O(mnky\u0003\u0000^y0kb;1) from [DIL+21] is derived from the fact that each time a maximum\n\row is found in step 13, the \row value is increased by at least 1 (due to the integrality of the problem), and\neach maximum \row can be found in O(nm) time.\nTo get the improved runtime in Theorem 3.5, we can follow essentially the same analysis to that for\nminimum-weight perfect matching, showing that \frst call to maximum \row will push a signi\fcant amount\nof \row and then bounding the rest of the work in terms of the remaining \row to be pushed.\nProof of Theorem 3.5. The correctness of Algorithm 4 comes from prior work, so it su\u000eces to prove the time\ncomplexity. After the \frst call to max \row in step 6, the \row value will be at leastP\nibi\u0000ky\u0003\u0000^y0kb;0by the\nsame argument as Lemma B.8. In particular, consider an optimal \row (corresponding to a minimum-weight\nb-matching) f\u0003. Consider the \row gwherege= minff\u0003\ne;u0\negwhereu0\neis the capacity of edge einG0in step\n6 of the algorithm ( gis the subset of fthat satis\fes the capacities in G0). For each edge e= (u;v) where\n19\n\nAlgorithm 4 Primal-Dual Scheme for MWBM from [DIL+21]\n1:procedure MWBM-PD (G= (V;E);c;y)\n2:E0 fij2Ejyi+yj=cijg .Set of tight edges in the dual\n3:G0 (L[R[fs;tg;E0[fsiji2Lg[fjtjj2Rg) .Network of tight edges\n4:8e2E(G0) s.t.e=siore=it,ue bi\n5:ue 1 for all other edges of G0\n6:f Maximums\u0000t\row inG0with capacities u\n7: while Value offis<P\ni2Lbido\n8: Find a setS\u0012Lsuch thatP\ni2Sbi>P\nj2\u0000(S)bj .Can be found in O(m+n) time\n9:\u000f mini2S;j2Rn\u0000(S)fcij\u0000yi\u0000yjg\n10:8i2S,yi yi+\"\n11:8j2\u0000(S),yj yj\u0000\"\n12: UpdateE0;G0;u\n13:f Maximums\u0000t\row inG0with capacities u\n14: end while\n15:x frestricted to edges of G\n16: Returnx\n17:end procedure\ny\u0003\nu=y0\nuandy\u0003\nv=y0\nv,ge=fe. Conversely, if there is some vertex uwherey\u0003\nu6=y0\nu, at worst this vertex can\ninvalidatebuedges asucan be incident on at most buedges inf\u0003. So, the value of gis at mostky\u0003\u0000^y0kb;0\nless than that of f\u0003. Asf\u0003is optimal, it has valueP\nibi, and the \frst call to max \row must push at leastP\nibi\u0000ky\u0003\u0000^y0kb;0units of \row.\nSubsequently, over all calls to maximum \row in step 13, the total amount of \row pushed is at most\nky\u0003\u0000^y0kb;0and the total number of iterations of the while loop is at most ky\u0003\u0000^y0kb;0. By implementing\nmax \row in step 13 by the Ford-Fulkerson algorithm, the total amount of work done in the while loop will\nbeO(mky\u0003\u0000^y0kb;0) as Ford-Fulkerson takes linear time per unit of \row and all other work done in the while\nloop takes linear time per iteration. As the \frst call to max \row in step 6 can take time O(mn), we get a\ntotal runtime of O(mn+mky\u0003\u0000^y0kb;0), as required.\nD Omitted Details from Section 4\nD.1 Proof of Main Theorem: Theorem 4.1\nThe goal of the section is to prove the correctness and runtime of Algorithm 2. We \frst need the following\nauxiliary lemmas, starting from an observation from [Gol95].\nLemma D.1. The graphG\u0000(after contracting all strongly connected components) is acyclic.\nLemma D.2. Consider any edge esuch that`^y(e)\u00150at any stage of Algorithm 2. Then ewill always\ncontinue to satisfy `^y(e)\u00150.\nProof. Lete= (u;v). We prove the lemma by showing that `^y(e)\u00150 continues to hold after every iteration\nof the while loop in step 3. The only way for `^y(e) to change is if one of yuoryvis updated in step 9 of\nAlgorithm 2. If both u;v2[t\u0015i\u0003Lior bothu;v62[t\u0015i\u0003Lithen the edge is unchanged. Now if v2[t\u0015i\u0003Li\nbut notu, then`^y(e) increases by 1 so `^y(e)\u00150 continues to hold for this iteration. Now suppose that\nu2[t\u0015i\u0003Libut notv. In this case, if `^y(e) was strictly greater than zero, i.e., `^y(e)\u00151, then`u\u0000`vonly\ndecreases by 1 so `^y(e)\u00150 is maintained. Lastly we need to consider the possibility that `^y(e) = 0. In this\ncase, it must be that v2[t\u0015i\u0003Lisince we can go from xtovviax!u!vwhich means vis either in\nthe same layer as uor possibly a higher layer. Both of these scenarios were addressed previously so we are\ndone.\n20\n\nLemma D.3. At any iteration of the while loop,i\u0003\u00142k^y\u0000y\u0003k1where the quantity k^y\u0000y\u0003k1denotes the\ninitial predictor error.\nProof. We \frst provide a bound for the very \frst iteration of the while loop on Line 3 of Algorithm 2. Note\nthatG\u0000is acyclic due to Lemma D.1. All paths in G\u0000must use non-negative edges. Any negative edge\ne= (u;v) has reduced length at least \u0000(jy\u0003\nu\u0000^yuj+jy\u0003\nv\u0000^yvj). This is because we know that `(u;v)+y\u0003\nu\u0000y\u0003\nv\u00150.\nThus, the absolute value of the length of `^y(e) is at most\nj`y\u0003(e)\u0000`^y(e)j\u0014jy\u0003\nu\u0000^yuj+jy\u0003\nv\u0000^yvj:\nNow consider the max ifor whichLiexists. This means there is a path x=u1;\u0001\u0001\u0001;uk=vof total length\n\u0000i. We have\ni=k\u00001X\nj=1j`^y(uj;uj+1)j\u0014k\u00001X\nj=1jy\u0003\nuj\u0000^yujj+jy\u0003\nuj+1\u0000^yuj+1j\u00142ky\u0003\u0000^yk1\nsince every vertex ucan appear at most twice in the middle summation above.\nWe now claim that the maximum iisalways at most 2ky\u0003\u0000^yk1. Lemma D.2 implies that non-negative\nedges (under `^y) always stay non-negative. Furthermore, the proof of Lemma D.2 tells us that the length\nof any negative edge is monotonically increasing until the edge becomes non-negative. Therefore any path\nfromxtovinG\u0000in any iteration of the while loop must have also existed in the very \frst iteration. It\nfollows that most negative distances in G\u0000are monotonically decreasing every iteration, i.e., becoming less\nnegative. Therefore, the same bound on the number of layers Lialso continues to hold for all instances of\nG\u0000.\nProof of Theorem 4.1. The correctness of Theorem 4.1 follows from the fact that the while loop only stops\nwhen all reduced edge lengths are non-negative. Therefore, the main challenge is to bound the number of\niterations. From the standard analysis of Goldberg's algorithm [Gol95], we know that each iteration of the\nwhile loop takesO(m) time. This is because G\u0000is an acyclic graph and thus, \fnding the layers Liand all\nsubsequent computations can be done in O(m) time. Thus, it remains to bound the number of while loop\niterations.\nNow call a vertex vtouched ifv2Li\u0003fori\u0003de\fned in step 8 of Algorithm 2. Note that for a vertex\nto be touched, it must exist in some layer and therefore has a negative incoming edge. We now claim that\nevery time a vertex is touched, its most negative incoming edge increases in length by +1.\nIndeed, let ( u;v) be the most negative incoming edge to vand suppose that v2Li\u0003. Vertexucannot\nexist in layer Ltfor somet>i\u0003since we can consider the path x!u!vwhich implies vmust exist in a\nlarger layer than u. Thus when vis touched, the edge length ( u;v) must increase by 1. From Lemma D.3,\nwe know that layer Li\u0003has at least n=(2k^y\u0000y\u0003k1) many vertices since there are at most 2 k^y\u0000y\u0003k1layers\nwhich partition all nvertices. Therefore, at least n=(2k^y\u0000y\u0003k1) many vertices get touched in every iteration\nof the while loop. Each vertex can only get touched at most O(ky\u0003\u0000^yk1) times since the most negative\nedge length in the very beginning of Algorithm 2 has absolute value at most O(ky\u0003\u0000^yk1). This implies\nthat the number of while loop iterations is at most O(k^y\u0000y\u0003k1\u0001ky\u0003\u0000^yk1). Since every while loop\niteration takes O(m) time, the bound of O(mk^y\u0000y\u0003k1\u0001ky\u0003\u0000^yk1) follows. Note that we could have also\nused Goldberg's algorithm after getting the reduced edge lengths from `^ywith no further modi\fcations to\nget timeO(mpnlog(ky\u0003\u0000^yk1). Therefore, running these two algorithms in parallel implies the claimed\nrunning time.\nD.2 All-Pair Shortest Paths\nWe observe that Theorem 4.1 implies the following runtime for \fnding all pairs shortest paths on a graph.\nTheorem D.4. There exists an algorithm which takes as input predicted reduced edge duals ^y:V!Zand\noutputs all pair shortest paths in O(mminfk^y\u0000y\u0003k1\u0001k^y\u0000y\u0003k1;pnlog(k^y\u0000y\u0003k1))g+mn+n2logn)time\nwherey\u0003:V!Zdenotes a feasible set of reduced edge length duals.\n21\n\nProof. Consider Algorithm 2. It applies Algorithm 2 to round ^ yinto a feasible RE dual ^ y0. Then we can\nrun Dijkstra's algorithm starting from all vertices in time O(mn+n2logn). The running time follows from\nTheorem 4.1.\nAlgorithm 5 Learning-based Shortest Paths\n1:Input: GraphG= (V;E), predicted duals ^ y:V!Z\n2:procedure Faster-Shortest-Paths (G;^y)\n3: ^y0 Round-RE-Duals( G;^y) .^y0is a feasible RE Dual\n4: forallv2Vdo\n5: Run Dijkstra's algorithm starting from v\n6: end for\n7: Return all shortest paths found from all vertices\n8:end procedure\nE Additional Reductions for Learning-Based Graph Algorithms\nE.1 Degree-Constrained Subgraph from Matching\nThe degree constrained subgraph (DCS) problem is de\fned as follows. We are given an undirected multigraph\nG= (V;E) (we will only be considering bipartite graphs) as well as a set of desired upper and lower bound\non each vertex's degree: li\u0014di\u0014uifor alli2V. A DCS is an edge-induced subgraph of Gwhere the\ndegree conditions are satis\fed. A DCS is called complete if each degree achieves its upper bound: di=ui\nfor alli2V.\nThe maximum perfect DCS and maximum weights DCS problems correspond to maximum perfect match-\ning and maximum weight matching, respectively. Note that the DCS versions of these problems generalize\nthe matching versions by setting li= 0 andui= 1 for all vertices. Next, we will show that DCS can also be\nreduced to matching following the reduction given in [Gab85].\nFirst consider the maximum perfect DCS problem. Let G= (L;R;E ) be the corresponding multigraph\nwith degree bounds li;uifori2V. We will build a corresponding bipartite graph H= (L0;R0;E0) as follows.\n•For each vertex iinG, create a complete bipartite graph K\u000e;dwhered=diis the degree of iinGand\n\u000e=di\u0000uiis how many edges need to be removed from ito meet the upper bound. We will call the\n\u000eside ofK\u000e;dinternal nodes and the dside external nodes . Without loss of generality, assume i2L.\nThen, the external side of K\u000e;dis inL0and the internal side is in R0.\n•Associate each of i's edges in Gwith one of its external nodes in H. Speci\fcally, for each ( i;j)2E,\nthere will be an edge between one of i's and one of j's external nodes in Hand both of those nodes\nwill not be neighbors with any other external nodes. Note that as Gis bipartite, with these added\nedges,Hwill still be bipartite.\n•For each of these external-external edges, give them costs in Hcorresponding to their costs in G.\nFirst, note that a perfect matching in Hcorresponds to a perfect DCS in G. For each node iinG, all of\nits\u000einternal nodes in Hwill be matched, meaning that exactly uiof its external nodes are matched with\nother external nodes. As each of these external-external edges correspond to edges in the original edgeset E,\nthis means that iwill have degree uiin the subgraph induced by the external-external edges in the perfect\nmatching, as required.\nSimilarly, it is easy to see that every perfect DCS in Gcorresponds to a perfect matching in H, so\noptimizing over perfect matchings/DCS's are equivalent, completing the reduction.\nAssume that Ghadnvertices and medges (counting copies). In H, we will have O(m) total vertices\nandO(m\u0001dmax) total edges where dmaxis the maximum degree of any vertex in G. Algorithm 3 gives us\nthe following corollary.\n22\n\nTheorem E.1. Given a maximum weight perfect DCS problem on input graph G= (V;E)withnvertices,\nmedges, and maximum degree dmax, there exists an algorithm which takes takes as input a predicted dual\nsolution ^yto an instance of maximum weight perfect matching derived from G, near-optimally rounds the\ndual to a feasible solution ^y0, and solves the DCS in time O(m3=2dmax+ (mdmax+mlogm)jjy\u0003\u0000^y0jj0).\nE.2 Minimum-Cost 0-1 Flow from Degree-Constrained Subgraph\nThe reduction bares resemblance to the reduction from shortest path from matching and is also due\nto [Gab85]. We are given a directed graph Gwith unit capacities and integral edge costs aij. We want\nto \fnd a minimum cost \row of \row value v. We will construct a bipartite multigraph H= (L;R;E ) for the\nDCS problem as follows.\n•For each vertex i2G, make two copies i12Landi22R.\n•Addmindegree (i) copies of the edge ( i1;i2) toHeach with weight 0. Where mindegree (i) is the\nminimum of i's indegree and outdegree.\n•For each edge ( i;j) inG, add an edge ( j1;k2) toHwith weight\u0000ajk.\n•Set the degree constrains ui1=ui2=mindegree (i) for alli6=s;t. Setus2=mindegree (s),us1=\nus2+v,ut2=mindegree (t),ut1=ut2+v.\nNote that the number of vertices and edges in Hare at most twice those in G.\nTheorem E.2. Given a minimum-cost 0-1 \row problem on input graph G= (V;E)withnvertices,medges,\nand maximum degree dmax, there exists an algorithm which takes takes as input a predicted dual solution\n^yto an instance of maximum weight perfect matching derived from G, near-optimally rounds the dual to a\nfeasible solution ^y0, and solves the DCS in time O(m3=2dmax+ (mdmax+mlogm)jjy\u0003\u0000^y0jj0).\nE.3 Diameter to Shortest Paths\nThe diameter of a graph is de\fned as the largest distance between any pair of vertices. All exact algorithms for\ncalculating the diameter on general weighted graphs all rely on computing all pairs shortest paths (and there\nis evidence that this approach is unavoidable [DW21]). Our learning-augmented algorithm for computing\nshortest-paths of Section 4 gives us the following corollary for computing the diameter of an input graph\nwhich follows by \frst rounding to a valid reduced edge length dual of De\fnition 4.1 and running all pairs\nshortest paths using Dijkstra's algorithm on the resulting graph with non-negative weights.\nTheorem E.3. Given an input graph Gwithnvertices and medges with possibly negative integer edge\nlengths given by `, there exists an algorithm which takes takes as input a predicted dual solution ^yto the\nreduced edge length dual on Gand computes the diameter of Gin time\nO(mminfk^y\u0000y\u0003k1\u0001k^y\u0000y\u0003k1;pnlog(k^y\u0000y\u0003k1)g) +~O(mn):\nRemark E.1. Note that the an algorithm which doesn't use any learned predictions for computing shortest\npaths on a graph with negative weights, such as the Bellman-Ford algorithm, would have taken time O(mn2)\nto compute the diameter. Note that we could have also reduced the diameter problem to matching by using\nthe reduction from shortest paths to matching. However the reduction used in Theorem E.3 is simpler as we\ndon't need to compute any new graphs.\nF Omitted Details from Section 6\nOur results generally follow from bounding the pseudo-dimension of the loss function and applying standard\nuniform convergence for PAC learning.\n23\n\nDe\fnition F.1 (pseudo-dimension) .LetFbe a class of functions f:X!R:LetS=fx1;x2;:::;xsg\u001aX\nWe say that that Sis shattered byFif there exist real numbers r1;:::;rsso that for all S0\u0012S, there is a\nfunctionf2F such thatf(xi)\u0014riif and only if xi2S0for alli2[s]. The pseudo-dimension of Fis the\nlargestssuch that there exists an S\u0012XwithjSj=sthat is shattered by F.\nFor a class of loss functions with bounded range and pseudo-dimension, the following lemma provides a\nPAC learning guarantee.\nLemma F.1 (uniform convergence; e.g., [ABB99]) .LetDbe a distribution over a domain XandFbe a\nclass of functions f:X![0;H]with pseudo-dimension dF. Consider si.i.d. samples x1;x2;:::;xsfrom\nD:There is a universal constant c0, such that for any \u000f >0andp2(0;1), ifs\u0015c0\u0000H\n\u000f\u00012(dF+ ln(1=\u000e));\nthen we have \f\f\f\f\f1\nssX\ni=1f(xi)\u0000Ex\u0018Df(x)\f\f\f\f\f\u0014\u000f\nfor allf2F with probability at least 1\u0000\u000e:\nF.1 Proof of Theorem 6.1\nTo prove Theorem 6.1 Let f1;h(c) =`1(h;c) forh2H. The following lemma provides a bound on the\npseudo-dimension of the family F1=ff1;h(c) :h2Hg .\nLemma F.2 ([DIL+21]).The pseudo-dimension of F1is bounded above by O(dlogd).\nNow we are ready to prove our learnability result Theorem 6.1.\nProof of Theorem 6.1. Givenssamplesc1;c2\u0001\u0001\u0001;cs, the algorithm performs empirical risk minimization on\nthe loss ^`(h) =Ps\ni=1kh\u0003(ci)\u0000hk1. The algorithm runs in polynomial time by the e\u000ecient optimization\nassumption.\nMoreover, sinceH\u0012RdandHhas bounded range, we have that any function in F1is bounded by dM.\nTherefore, the sample complexity and error bound follows from Lemma F.1 and Lemma F.2.\nF.2 Proof of Theorem 6.2\nProof of Theorem 6.2. Similar to the `1learnability theorem, the algorithm simply \fnds the empirical min-\nimizer of ^`(h) =Ps\ni=1kh\u0003(ci)\u0000hk1. The algorithm runs in polynomial time by the e\u000ecient optimization\nassumption.\nLetf1;h(c) =`1(h;c) forh2H. It now su\u000eces to bound the pseudo-dimension of the family F1=\nff1;h(c) :h2Hg and then apply the uniform convergence lemma (Lemma F.1). Now observe that the\npseudo-dimension of F1can be in turn bounded by the VC dimension of axis-aligned hyperrectangles in\nRd, which is known to be 2 d[MRT18].\nF.3 Details on Learnability Via Arithmetic Complexity\nSuppose we have any loss function L(h;G)2Rwhich represents how well a hint vector performs on some\ninputG. For notational simplicity, we de\fne Aas the class of functions in hcomposed with L:\nA:=fL\u000eh:h2Hg:\nWe also assume that the range of Lis equal to [0 ;H] and that all graphs Gcan be represented as a feature\nvector in Rm.\nAgain, we aim to learn the best function h2H which minimizes the following objective:\nE\nc\u0018D[L(h;G)]: (3)\n24\n\nTowards this end, we let h\u0003be such the optimal h2H. We also assume that for each instance Gand each\nh2H,L\u000eh(G) can be computed in time T(m;d). For example, suppose graphs drawn from Dpossess edge\nfeatures in Rdfor somedand our familyHis parameterized by a single vector \u00122Rdand represents linear\nfunctions which report the dot product of each edge feature with \u0012. Then it is clear that T(m;d) is a (small)\npolynomial in the relevant parameters.\nThe result of this section is to bound the pseudo-dimension of A. After obtaining a bound, we can readily\napply Lemma F.1 as we did in the proof of Theorem 6.1 in Section 6.1.\nTheorem F.3 (Learnability via computational complexity) .Suppose that any a2A takesT(m;d)time to\ncompute given any graph Hdrawn fromD. Then the pseudo-dimension of AisO(poly(T(m;d)).\nTo prove Theorem F.3, we \frst relate the pseudo-dimension to the VC dimension of a related class of\nthreshold functions. This relationship has been fruitful in obtaining learning bounds in a variety of works\nsuch as [LFKF18, ISZ21].\nLemma F.4 (Pseudo-dimension to VC dimension, Lemma 10 in [LFKF18]) .For anya2A, letBabe the\nindicator function of the region on or below the graph of a, i.e.,Ba(x;y) = sgn(a(x)\u0000y). The pseudo-\ndimension ofAis equivalent to the VC-dimension of the subgraph class BA=fBaja2Ag .\nThe following theorem then relates the VC dimension of a given function class to its computational\ncomplexity, i.e., the complexity of computing a function in the class in terms of the number of operations\nneeded.\nLemma F.5 (Theorem 8 :14 in [ABB99]) .Letw:R\u000b\u0002R\f!f0;1g, determining the class\nW=fx!w(\u0012;x) :\u00122R\u000bg:\nSuppose that any wcan be computed by an algorithm that takes as input the pair (\u0012;x)2R\u000b\u0002R\fand\nreturnsw(\u0012;x)after no more than rof the following operations:\n•arithmetic operations +;\u0000;\u0002;and=on real numbers,\n•jumps conditioned on >;\u0015;<;\u0014;=;and=comparisons of real numbers, and\n•output 0;1,\nthen the VC dimension of WisO(\u000b2r2+r2\u000blog\u000b).\nCombining the previous results allows us prove Theorem F.3. At a high level, we are instantiating\nLemma F.5 with the complexity of computing any function in the function class A.\n25",
  "textLength": 77988
}