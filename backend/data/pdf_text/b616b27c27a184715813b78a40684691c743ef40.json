{
  "paperId": "b616b27c27a184715813b78a40684691c743ef40",
  "title": "Proteus: A Self-Designing Range Filter",
  "pdfPath": "b616b27c27a184715813b78a40684691c743ef40.pdf",
  "text": "Proteus: A Self-Designing Range Filter\nEric R. Knorr*1, Baptiste Lemaire*1, Andrew Lim*1\nSiqiang Luo2, Huanchen Zhang3, Stratos Idreos1, Michael Mitzenmacher1\n1Harvard University,2Nanyang Technological University,3Tsinghua University\nABSTRACT\nWe introduce Proteus, a novel self-designing approximate range\nfilter, which configures itself based on sampled data in order to\noptimize its false positive rate (FPR) for a given space requirement.\nProteus unifies the probabilistic and deterministic design spaces of\nstate-of-the-art range filters to achieve robust performance across\na larger variety of use cases. At the core of Proteus lies our Con-\ntextual Prefix FPR (CPFPR) model â€”a formal framework for the\nFPR of prefix-based filters across their design spaces. We empiri-\ncally demonstrate the accuracy of our model and Proteusâ€™ ability\nto optimize over both synthetic workloads and real-world datasets.\nWe further evaluate Proteus in RocksDB and show that it is able\nto improve end-to-end performance by as much as 5.3x over more\nbrittle state-of-the-art methods such as SuRF and Rosetta. Our ex-\nperiments also indicate that the cost of modeling is not significant\ncompared to the end-to-end performance gains and that Proteus is\nrobust to workload shifts.\nCCS CONCEPTS\nâ€¢Information systems â†’Database design and models ;Uni-\ndimensional range search ;â€¢Theory of computation â†’Bloom\nfilters and hashing .\nKEYWORDS\nRange Filter, Self-Designing, Sample-Based Modeling, Bloom Filter\nACM Reference Format:\nEric R. Knorr, Baptiste Lemaire, Andrew Lim, Siqiang Luo, Huanchen Zhang,\nStratos Idreos, Michael Mitzenmacher. 2022. Proteus: A Self-Designing\nRange Filter. In Proceedings of the 2022 International Conference on Manage-\nment of Data (SIGMOD â€™22), June 12â€“17, 2022, Philadelphia, PA, USA. ACM,\nNew York, NY, USA, 15 pages. https://doi.org/10.1145/3514221.3526167\n1 INTRODUCTION\nThe Importance of Range Filters: Range queries are a funda-\nmental operation in big data applications. Given a set ğ‘†, a range\nquery [a,b] returns the members of ğ‘†within the query interval, i.e.\nğ‘†âˆ©[a,b] . Example applications that need range queries and handle\nlarge amounts of data include social media platforms using spatio-\ntemporal queries to aggregate user events [ 3], pattern discovery\n*These authors contributed equally.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nÂ©2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9249-5/22/06. . . $15.00\nhttps://doi.org/10.1145/3514221.3526167\nFigure 1: A self-designing filter achieves superior performance in\na wide variety of workloads. (Darker is better, lower FPR.)\nand anomaly detection in time-series data streams [ 31], scientific\nspatial models [ 47], graph databases [ 16,33] and Blockchain an-\nalytics [ 46]. Range queries over such data sets are expensive due\nto the disk or network costs required to process the data. Using a\nfilter data structure to determine when no elements are in the query\nrange can vastly improve performance by preventing unnecessary\nIO operations.\nAs an important unifying application, large-scale data systems\nkeep large volumes of data on cheap but high latency storage de-\nvices. Answering range queries requires checking every data page\nthat intersects with the queried range to retrieve the relevant data.\nFor example, in widely used Log Structured Merge (LSM) tree-\nbased key-value stores, one or more pages must be checked per\nlevel [ 2,13,19,34,43]. However, explicitly reading in all intersect-\ning data pages would be far too expensive. In this setting, a compact\nrange query data structure can be set up on a per page basis. Range\nquery structures then act as filters, which can determine that no\ndata in a range exists on a page (that is, we have an empty query)\nbefore resorting to accessing disk. As such, much of our evaluation\nconsiders the effectiveness of range filters in LSM-trees.\nStrong Guarantees are Impractical: Most work on filtering has\nbeen focused on single key queries. Such filters are referred to as\nApproximate Membership Query structures (AMQs). AMQs such\nas Bloom filters [ 10] and their many variants are used to avoid the\nmajority of unnecessary lookups for individual items in diverse\napplications. AMQs tolerate a small probability of false positives\nin order to achieve a compact representation of the key set that\nsupports membership queries. The false positive rate (FPR) is the\nprimary metric of a filterâ€™s performance, as false positives incur\nunnecessary lookups to verify their emptiness. Similar techniques\ncan be applied to the approximate range emptiness problem to\navoid unnecessary range lookups, but guaranteeing a low FPR\nfor all potential queries can be expensive. Prior work has shown\nthat to guarantee an FPR ğœ–for range emptiness queries of range\nsizeğ‘…requires Î©(log2(ğ‘…)+log2(1/ğœ–))bits per key (BPK) [ 23].arXiv:2207.01503v1  [cs.DB]  30 Jun 2022\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\nAchieving a small FPR for all queries including for large ranges\ntherefore requires an undesirable memory budget.\nDesign Tradeoffs are Necessary For Performance: Current range\nfilters aim to use less memory than theoretical worst-case guar-\nantees require by notproviding false positive guarantees for all\nqueries. Instead, state-of-the-art solutions prioritize particular types\nof workloads, such as those with large ranges [ 48] or queries that\nare correlated to the key set [ 36], by making hard-coded design\ndecisions that cater to their target use case. These range filters use\nheuristic methods where the FPR depends on the relationship be-\ntween the key and query sets, and provable guarantees are weak or\nrestricted to specific situations. These decisions limit their useful-\nness as deviation from the intended use cases results in increasingly\nsub-optimal performance, as seen in Figure 1. This is an issue for\nuse cases not covered by current range filters, for example, particle\nphysics workloads that contain long ranges and correlated queries\nwhen cross referencing time series data from multiple sensors to\nidentify events of interest [ 4]. Additionally, deviations can also\narise from workloads that shift over time. For instance, applications\nwith different data based on language, such as Wikipedia, exhibit\ntemporal skew in query distribution due to the correlation between\ntime zone and language [ 22,42]. Therefore, a robust range filter\nrequires the ability to prioritize the desired use case by navigating\nthe range filter design space. However, to our knowledge, there\nhas been no prior work on formalizing the parameters of the range\nfilter design space and the tradeoffs therein.\nA Formal Framework Allows for Informed Designs: The stan-\ndard metric for FPR analysis is worst-case performance which fails\nto capture the nuances of range filter design choices because they\noptimize for specific use cases. We introduce the Contextual Prefix\nFPR (CPFPR) model which formalizes how FPR varies across the\ndesign space of prefix-based filters. We focus on the prefix filter\ndesign space as this encompasses all state-of-the-art range filter\ndesigns [ 1,27,36,48]. The nuances of each design are captured by\nexpressing their FPR in terms of use case features, such as query\nrange size and the proximity between keys and queries. These fea-\ntures can be concisely described by the characteristics of shared\nprefixes and the number of unique prefixes of a given length. We\nthen apply the CPFPR model to techniques used by state-of-the-art\nrange filters in order to understand their design tradeoffs.\nSelf-Designing Approximate Range Filters: We use insights\nfrom the CPFPR model to develop a novel class of readily optimized\nrange filters, that we have dubbed Protean Range Filters (PRFs).\nPRFs navigate some portion of the range filter design space and aim\nto choose the best design available for a given use case. We introduce\na novel PRF filter, Proteus, that spans a large portion of the prefix-\nfilter design space and makes use of the CPFPR model to navigate\nit. Not only does Proteus encompass the design spaces of state-of-\nthe-art range filters, but it is also able to combine their designs in a\ncomplementary fashion for even greater effect. The user need only\nsupply a sample of example queries to be fed into the CPFPR model.\nIncreased design flexibility paired with automated optimization\nallows Proteus to outperform more constrained designs in the vast\nmajority cases, even when said designs are optimally tuned. We can\nsee in Figure 1 that Proteus achieves a low FPR on a larger region of\nthe workload space as compared to the state-of-the-art range filters\nwhich are only optimal within confined, mostly disjoint regions.Contributions: Our contributions are as follows:\nâ€¢Novel Range Filter: We present a novel range filter that can instan-\ntiate configurations from across the current range filter design\nspace to meet the needs of various workloads within a limited\nmemory budget.\nâ€¢Formalization of the Range Filter Design Space: We introduce the\nCPFPR model which captures the tradeoffs in the design space of\nprefix-based range filters. We use this model to break down and\nincorporate the design elements of state-of-the-art range filters\ninto our novel range filter (Section 3) .\nâ€¢Efficiently Leveraging Context: We demonstrate how to practically\nnavigate the prefix filter design space (Section 4) .\nâ€¢Model Validation: We validate the accuracy of our model and\ndemonstrate its ability to optimize across the prefix filter design\nspace in a wide variety of settings using both synthetic workloads\nand real world datasets (Section 5) .\nâ€¢Robust End-to-End Gains: We show how PRFs can be integrated in\na real world system, RocksDB, and demonstrate PRFsâ€™ robustness\nto changing workloads as well as end to end latency improve-\nments of up to 3.9x on 64-bit integers (Section 6) and 5.3x on\nstrings (Section 7) .\n2 THE RANGE FILTER DESIGN SPACE\nCurrent solutions to the approximate range emptiness problem, or\nApproximate Range Emptiness structures (AREs), use one of two\nfundamental design elements: probabilistic Approximate Member-\nship Query data structures (AMQs) and deterministic search trees.\nBoth strategies use prefixes of the key set to encode the key space\nat different granularities.\nAMQs are natural building blocks as they are designed to reduce\nunnecessary lookups by using a compact representation of the\ndata set that is small enough to fit in memory and supports fast\nmembership queries. A low non-zero false positive probability is\ntolerated in order for the representation to be sufficiently compact,\nbut never a false negative. The search tree approach is more novel\nand explicitly encodes prefixes of the key set as a trie.\n2.1 Probabilistic Prefix Filters\nOne method used by current AREs is to include one or more AMQs\nthat encode regions of the key space with a single hashed value.\nThere are many examples of AMQs, such as Bloom Filters, Cuckoo\nFilters, Quotient Filters, Xor Filters and Ribbon Filters [ 8,10,18,20,\n24], which we will collectively refer to as Bloom filters. Though\ntheir specifics vary, Bloom filters generally make use of one or more\nhash functions to encode the key set as a compact array. Hashing\nallows for fast individual item lookups with a low probability of\nfalse positives; however, valuable ordering information is lost in the\nhashing process. In order to know whether a range [ğ‘™,ğ‘Ÿ]contains\nmembers of the key set, every key from ğ‘™toğ‘Ÿwould need to be\nqueried individually and the probability that at least one of them\nresults in a false positive is then proportional to ğ‘Ÿâˆ’ğ‘™. As such, the\nusefulness of Bloom filters for such queries rapidly declines with\nthe size of the range being queried.\nThis can be compensated for by hashing prefixes of the key set\nrather than each individual key. Hashing a given prefix encodes\nthat there is at least one member of the key set with the given prefix.\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nThis retains the benefits of hashing while allowing queries to the\nBloom filter to rule out entire regions of the key space at a time.\nPrefix Bloom Filters: Prefix Bloom filters have been in use for\nsome time now, particularly in the context of network routing\n[17]. By hashing a key prefix of length ğ‘™bits, the prefix Bloom\nfilter encodes a region of the key space of size 2ğ‘˜âˆ’ğ‘™, whereğ‘˜is the\nmaximum key length. Using this strategy, a range of the key space\ncan be queried by querying the Bloom filter for each region that\noverlaps with the desired range. This is well suited to situations\nwith clustered target ranges, like IP addresses in network routing,\nas the prefix length used can be tuned to the cluster sizes. Prefix\nBloom filters are also used in key-value stores, but the constraint of\nencoding the key space as fixed size, prefix defined regions limits\ntheir usefulness when the target ranges are not well known. In\nparticular, prefix Bloom filters are very sensitive to the choice of\nprefix length which we will discuss in more detail in Section 3.\nRosetta: Rosetta [ 36] is an ARE aimed specifically at range queries\nin database systems using LSM trees, such as RocksDB [ 27]. These\nsystems have used prefix Bloom filters with shorter prefixes to filter\nout large range queries; however, if they are not properly tuned,\nthese prefix filters perform very poorly on small to medium range\nqueries as well as individual key queries. This becomes even worse\nif the queries are correlated to the key set and empty queries tend\nto fall close to the key set.\nConceptually, Rosetta encodes the nodes of an implicit segment\ntree, or binary trie, representing the entire key space. All nodes of\na given depth present in the key set are encoded by hashing the\ncorresponding prefixes into a single Bloom filter. The prefix filter\nencoding the leaf nodes of the tree is then equivalent to a Bloom\nfilter populated with full key hashes. A range is queried by checking\nfor the presence of each node in the sub-tree corresponding to the\nthat range in depth first order. If any node is not present in its\nrespective prefix filter, the entire sub-tree rooted at that node is\nknown to be empty and is not queried further. If a given node may\nbe present, the sub-tree continues to be queried in depth-first order\nuntil either a leaf node is reported as present, resulting in a positive\nrange query, or the entire sub-tree is found to be empty.\nIn practice, Rosetta does not encode every level of this tree and\nis configured by apportioning the total memory budget between\nthe prefix Bloom filters encoding each prefix length. In particular,\nRosetta typically allocates all of its memory budget to the last few\nprefix lengths. This allocation strategy works well for small ranges\nand point queries, regardless of proximity to the key set, but larger\nrange queries will still require many Bloom filter queries to cover\nthe query range and performance trends towards that of an AMQ.\n2.2 Deterministic Prefix Filters\nOther solutions forgo the benefits of hashing to retain as much\nordering information as possible. These AREs typically make use\nof an explicitly encoded search tree which performs a similar role\nto the implicit tree encoded by Rosetta. In particular, tries are a\nwell studied method of encoding prefixes in a succinct search tree\n[6,9,21]. In order to fit these trees in memory, they must be pruned\ndown to prefixes of the key set. As before, each prefix found in the\ntree represents a range that has at least one member of the key set,\nwhile any prefix not found in the tree will not be present in thekey set. The pruning therefore introduces the possibility of false\npositives due to common prefixes between keys and non-keys.\nThese trees are more flexible than prefix Bloom filters in cer-\ntain aspects as they can easily encode prefixes of different lengths\nwithin the same structure and all sub-prefixes are also retained.\nThis comes with the downside of having to pay more memory for\nlonger prefixes, since the entire prefix must be explicitly stored,\nas opposed to prefix Bloom filters which can dedicate available\nmemory to any individual prefix length.\nSuRF: The Succinct Range Filter (SuRF) [ 48] is a state-of-the-art\nARE that encodes prefixes of the key set as a Fast Succinct Trie (FST).\nIt is a static filter and does not adapt to queries. The FST in SuRF\ncombines the LOUDS-Dense and LOUDS-Sparse representations\nfrom [ 29] to achieve an efficient trie encoding (LOUDS-DS) which\nallows SuRF to encode longer prefixes than other trie-based prefix\nfilters on the same memory budget. This encoding can also be\nsearched in constant time, so the query time is independent of the\nsize of the range. Despite this, encoding every full key in the FST is\nstill typically too expensive, so SuRFâ€™s base configuration prunes\nthe branch for each key to the minimum length prefix that uniquely\nidentifies it in the key set. If there is additional memory available\nit can be used to extend these prefixes. It can also be used to store\nhashes of the key suffixes to help rule out individual keys, though\nthese do not provide any additional benefit for range queries.\nBecause SuRF is configured purely based on the key distribution,\nsparsely populated regions of the key space are encoded more\ncoarsely. As with other prefix filters, these coarsely encoded regions\nare not well suited for filtering queries that are close to the key\nset. The requirement that each prefix be at least long enough to be\nuniquely identified in the key set also means that SuRFs minimum\nmemory usage is determined by the distribution of the keys. Despite\nthe encoding being very compact, this can still pose an issue in\nsituations where tight memory budgets must be strictly maintained.\n3 A CONTEXTUAL PREFIX FPR MODEL\nIn this section we will formalize how different aspects of a workload\naffect the performance of prefix-based range filters in order to\nunderstand the tradeoffs of different designs. We use this framework\nto break down the fundamental components of state-of-the-art\nAREs and realize a unified design space.\n3.1 The Importance of Prefix Lengths\nWe begin by modeling a standard prefix Bloom filter as this forms\nthe basis for our more complex structures. When considering a\nsingle prefix Bloom filter, the only parameter to configure is the\nchoice of prefix length. Figure 2 shows how a set of 4-bit keys can\nbe encoded using 1-4 bit prefixes. Each prefix hashed into the filter\nencodes that at least one member of the key set contains that prefix;\ntherefore, a short prefix encodes many values while a long prefix\nmay only encode a few.\nConsider a key space Kwith total orderâª¯1and a prefix Bloom\nfilter encoding a key set ğ¾âˆˆK with prefix length ğ‘™and an FPR of\nğ‘. We use the following terms and notation:\n1The total orderâª¯depends on the types of keys being used. For instance, integer\nkeys would use the standard less-than-or-equal relation, while string keys would use\nlexicographical ordering.\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\nFigure 2: Encodings of a 4-bit key space using 1-4 bit prefixes and\nthe respective prefixes required to cover the range [4,8] (outlined\nin red). Regions containing at least one key are shaded grey.\nğ‘„: An empty range query, i.e. an interval of Ks.t.ğ‘„âˆ©ğ¾=âˆ….\nğ‘‹ğ‘–:For an arbitrary set of values ğ‘‹and integerğ‘–,ğ‘‹ğ‘–is the set of\nunique prefixes ğ‘¦s.t.ğ‘™ğ‘’ğ‘›(ğ‘¦)=ğ‘–andğ‘¦is a prefix of some ğ‘¥âˆˆ\nğ‘‹. Figure 2 shows ğ‘„ğ‘™bordered in red for ğ‘„=[0100,1000]\nand eachğ‘™âˆˆ{1,2,3,4}.\nLCP: The longest common prefix. For two arbitrary sets, ğ‘‹,ğ‘Œ,\nwe defineğ‘™ğ‘ğ‘(ğ‘‹,ğ‘Œ)as the longest LCP between any pair\n{ğ‘¥,ğ‘¦|ğ‘¥âˆˆğ‘‹,ğ‘¦âˆˆğ‘Œ}.\nAs described in Section 2, a prefix Bloom filter returns negative\nonly if each prefix in ğ‘„ğ‘™returns negative. If ğ‘„ğ‘™âˆ©ğ¾ğ‘™is non-empty,\nthenğ‘„is guaranteed to result in a false positive because it contains a\nprefix used to encode ğ¾. Whether this happens is dependent on the\nproximity of ğ‘„andğ¾which we can express in terms of ğ‘™ğ‘ğ‘(ğ‘„,ğ¾).\nIfğ‘™ğ‘ğ‘(ğ‘„,ğ¾)is greater than the prefix length used to encode the key\nset, then the corresponding members of the key and query set will\nbe indistinguishable from each other. This can be seen in Figure\n2 where only the 4 bit encoding of the key space can distinguish\n1000 from 1001 as they only differ in the 4th bit. Putting all of\nthis together, we can express the probability of a range query false\npositive in terms of the prefix filterâ€™s point query FPR, the range\nsize and proximity of the query to any key, as shown in Equation 1.\nğ‘ƒğ‘“ğ‘(ğ‘„)=(\n1âˆ’(1âˆ’ğ‘)|ğ‘„ğ‘™|, ğ‘™ğ‘ğ‘(ğ‘„,ğ¾)<ğ‘™\n1, ğ‘™â‰¤ğ‘™ğ‘ğ‘(ğ‘„,ğ¾)(1)\nWith only a single prefix Bloom filter, there is a clear contention\nbetween how many regions must be queried (a short ğ‘™), and whether\nqueries close to the key set can be distinguished from it (a long ğ‘™).\nOne option to address this would be to split the memory budget\nbetween multiple Bloom filters. The downside of this approach is\nthat each Bloom filter may only be able to contribute to a portion of\nthe queries. This can be justified if there is a substantial divergence\nin types of queries such that a single prefix length will not be able to\nhandle all types of queries effectively. Take for instance a bimodal\ndistribution of small queries in close proximity to the key set and\nlarge non-key-correlated queries. A single filter tuned to either half\nof the query set would be effectively useless for the other half. How-\never, this requires orders of magnitude of difference between range\nsizes or key-query correlations for even two filters to be justified\nas a less performant filter that can contribute to all or most of the\nqueries will result in better overall performance. If the distribution\nis split between additional modes, the possible difference between\neach decreases and the benefit of further subdividing our memorybecomes increasingly marginal. As such, we will only consider up\nto one additional Bloom filter.\nConsider then the same setting as before but with two Bloom\nfilters for prefix lengths ğ‘™1<ğ‘™2with point query FPRs ğ‘1andğ‘2\nrespectively. We will have to consider several cases depending on\nhow the regions encoded by the first Bloom filter align with ğ‘„, for\nwhich we will use the following additional terms and notation:\nğ¼0,ğ¼1:Indicator variables for whether the ranges defined by the\nfirst and last members of ğ‘„ğ‘™1arenotfully contained in ğ‘„.\nğ¼2,ğ¼3:Indicator variables for whether the first and last members of\nğ‘„ğ‘™1arenotinğ¾ğ‘™2. If|ğ‘„ğ‘™1|=1andğ‘„ğ‘™1âŠ†ğ¾ğ‘™1, letğ¼2=1and\nğ¼3=0. Note that we cannot have ğ¼0=ğ¼2=0orğ¼1=ğ¼3=0\nsinceğ‘„is empty.\nğ¿,ğ‘…:The sets ofğ‘™2prefixes that intersect with ğ‘„and contain the\nfirst and last prefixes of ğ‘„ğ‘™1respectively.\nğ‘ƒğ‘™1(ğ‘–):The probability that ğ‘–of theğ‘™1prefixes completely within ğ‘„\nreturn false positives. This can be expressed as the probability\nmass function for the binomial coefficient with ğ‘›=|ğ‘„ğ‘™1|âˆ’\nğ¼0âˆ’ğ¼1andğ‘=ğ‘1as shown in Equation 3.\nÂ¯ğ‘ğ¿,Â¯ğ‘ğ‘…:The probability that ğ¿orğ‘…respectively are not resolved at\nthe first Bloom filter and return only negatives at the second,\ngiven by Equation 2.\nWe now determine the probability of a false positive using two\nBloom filters. As before, if ğ‘™1<ğ‘™2â‰¤ğ‘™ğ‘ğ‘(ğ‘„,ğ¾), thenğ‘„is guaranteed\nto result in a false positive. We therefore consider the case when\nğ‘™ğ‘ğ‘(ğ‘„,ğ¾)<ğ‘™2. Sinceğ‘„âˆ©ğ¾is empty, any prefix of ğ‘„ğ‘™1such that\nthe corresponding set of values is fully contained in ğ‘„either yields\na false positive or a true negative. When a false positive for such\na prefix occurs, this yields 2ğ‘™2âˆ’ğ‘™1queries that need to be done at\nthe second Bloom filter. However, ğ‘„ğ‘™1can also share at most two\ncommon prefixes with ğ¾, those at either end of the query; therefore,\nthese end prefixes may yield false positives or true positives. Also,\nthese end prefixes, being the only ones that may not be completely\nwithinğ‘„, result in a number of queries at the second Bloom filter\nthat depends on the overlap between ğ‘„and the prefix whenever a\npositive (false or true) is returned.\nThe end prefix cases are covered by the Â¯ğ‘ğ¿andÂ¯ğ‘ğ‘…terms defined\nin Equation 2. We then must also sum over the remaining possible\ncombinations of false positives resulting from ğ‘„ğ‘™1. Here Equation 3\ngives the probability ğ‘ƒğ‘™1(ğ‘–)of havingğ‘–false positives that each result\nin2ğ‘™2âˆ’ğ‘™1queries atğ‘™2. For each of these we use the complement of\nthe probability that all ğ‘™2queries return negative. Combining these\nwe obtain Equation 4.\nÂ¯ğ‘ğ¿=ğ‘ğ¼2\n1Â·ğ¼0(1âˆ’ğ‘2)|ğ¿|,Â¯ğ‘ğ‘…=ğ‘ğ¼3\n1Â·ğ¼1(1âˆ’ğ‘2)|ğ‘…|(2)\nğ‘ƒğ‘™1(ğ‘–)=\u0012|ğ‘„ğ‘™1|âˆ’ğ¼0âˆ’ğ¼1\nğ‘–\u0013\nğ‘ğ‘–\n1(1âˆ’ğ‘1)|ğ‘„ğ‘™1|âˆ’ğ¼0âˆ’ğ¼1âˆ’ğ‘–(3)\nğ‘ƒğ‘“ğ‘(ğ‘„)=1âˆ’Â¯ğ‘ğ¿âˆ’Â¯ğ‘ğ‘…âˆ’|ğ‘„ğ‘™1|âˆ’ğ¼0âˆ’ğ¼1âˆ‘ï¸\nğ‘–=0ğ‘ƒğ‘™1(ğ‘–)\u0010\n(1âˆ’ğ‘2)ğ‘–2ğ‘™2âˆ’ğ‘™1\u0011\n(4)\n3.2 Tractable Tries\nBy using two Bloom filters with different prefix lengths, one can\nreasonably address divergent query workloads, but their probabilis-\ntic nature can still pose issues. As discussed before, the longer prefix\nlength is not well suited for large ranges, and any ğ‘™1prefix fully\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nwithinğ‘„that results in a false positive will require 2ğ‘™2âˆ’ğ‘™1prefixes\nqueries atğ‘™2. If there is much difference between ğ‘™1andğ‘™2, which is\nlikely if two Bloom filters are justified, then the second Bloom filter\nwill have a very low probability of catching larger ranges missed by\nthe first. We could reduce the number of false positives at the first\nBloom filter by allocating it a larger proportion of the memory, but\nthis also reduces the filterâ€™s ability to deal with correlated queries\nsince this memory must be taken from the second Bloom filter.\nAlternatively, using a uniform depth trie at ğ‘™1puts a hard limit\non the number of prefix queries that may be required at ğ‘™2for any\nrange query. Consider then the same situation as before but ğ‘™1now\nrepresents the prefix length of the trie and ğ‘is the FPR of the Bloom\nfilter. Since the trie is deterministic, only prefixes that match the\nleaf nodes will ever make it to the Bloom filter. As discussed prior,\nonly the first and last members of ğ‘„ğ‘™1can ever match the key set,\nso no more than 2ğ‘™2âˆ’ğ‘™1+1âˆ’2prefixes will need to be queried at ğ‘™2\nfor a given range query. The probability of a false positive is then\ngiven by Equation 5.\nğ‘ƒğ‘“ğ‘(ğ‘„)=ï£±ï£´ï£´ï£´ ï£²\nï£´ï£´ï£´ï£³0, ğ‘™ğ‘ğ‘ (ğ‘„,ğ¾)<ğ‘™1<ğ‘™2\n1âˆ’(1âˆ’ğ‘)ğ¼2|ğ¿|+ğ¼3|ğ‘…|, ğ‘™1â‰¤ğ‘™ğ‘ğ‘(ğ‘„,ğ¾)<ğ‘™2\n1, ğ‘™ 1<ğ‘™2â‰¤ğ‘™ğ‘ğ‘(ğ‘„,ğ¾)(5)\nNot only is Equation 5 simpler to compute than Equation 4, but it\nwill achieve a better FPR for any combination of ğ‘™1andğ‘™2assuming\nthat theğ‘™2Bloom filter receives the same amount of memory in\neach. This does come with the limitations that ğ‘™1now has a fixed\nmemory cost for each possible length. There is then a hard limit on\nhow longğ‘™1can be and the longer it is, the less memory is available\nfor theğ‘™2Bloom filter. Despite this, a short ğ‘™1is often cheaper to\nstore explicitly as a trie when compared to the memory a Bloom\nfilter would require to perform comparably. Tries are particularly\nefficient when representing clustered data as there will be fewer\nunique prefixes, but even sparse data sets are relatively cheap to\nrepresent as an FST when using a sufficiently short prefix length.\n4 PROTEAN RANGE FILTERS\nProtean (proÂ·teÂ·an) adj. â€”having a varied nature or ability to assume\ndifferent forms [38]\nWe define a Protean Range Filter (PRF) as a filter that supports\napproximate range emptiness queries and configures its own design\nto optimize performance for any given use case. We have presented\nthe CPFPR models for three PRFs: 1PBF â€”a standard prefix Bloom\nfilter (Equation 1), 2PBF â€”a pair of prefix Bloom filters (Equation 4)\nand Proteus â€”a hybrid filter that uses both a trie and a prefix Bloom\nfilter (Equation 5). Other than the use of the respective CPFPR\nmodels, 1PBF operates as described in Section 2 while 2PBF is\nequivalent to an instance of Rosetta that uses only 2 filters. As such,\nthis section will focus primarily on the structure of Proteus and its\nrespective model. The models for 1PBF and 2PBF are implemented\nin a similar fashion. We also provide a breakdown of the costs\nassociated with using the model and how these compare for each.\nWe assume fixed length, integer keys in this section and discuss\nvariable length keys in Section 7.\nFigure 3: An example of Proteus using 24 bit keys with a trie depth\nof 16 bits and a Bloom filter prefix length of 20 bits. The blue and\nred show the logical paths of two empty range queries, the first\nof which is resolved in the trie while the second is resolved in the\nBloom filter and could result in a false positive.\n4.1 Hybrid Architecture\nUnlike the other filters we have discussed, Proteus uses both prob-\nabilistic and deterministic encodings of the key space: an FST and\na prefix Bloom filter. As opposed to SuRF, the FST in Proteus does\nnot encode a unique prefix for every key, but rather all unique key\nprefixes of a fixed length, resulting in a FST with uniform depth.\nRecall that SuRF prunes the branch for each key to the minimum\nlength prefix that uniquely identifies it in the key set and can ex-\ntend these prefixes with explicitly stored key bits. Similarly, in the\nProteus FST, any trie branch encoding a single key is extended to\nthe chosen trie depth by explicitly storing the additional key bits,\nrather than using the LOUDS-DS trie encoding. A toy example of a\nProteus encoding a 24 bit key space is shown in Figure 3 using a trie\ndepth and Bloom filter prefix length of 16 and 20 bits respectively.\nA uniform trie depth is used in part because it simplifies the\nmodeling process, but also because we believe it to be a better use\nof memory. The intuition here is that sparse regions of the key\nspace that use a coarse encoding are highly susceptible to false\npositives since they encode very large empty sub-regions. Similarly,\nencoding a densely populated portion of the key space at a coarse\ngranularity will only result in small empty sub-regions that are less\nlikely to cause false positives. SuRF requires a unique prefix for\neach key in order to support queries other than range emptiness\nsuch as range counts and sums, but this also imposes a minimal\nmemory requirement and limits its usefulness for situations with\nstrict memory constraints. Alternatively, a uniform depth can be\nadjusted to fit within any memory constraint while any leftover\nmemory can still be put to use in the Bloom filter. While Proteus\ndoes not support range queries other than emptiness queries, re-\nplacing the Bloom filter with a counting Bloom filter would provide\nthis functionality [ 11]. The Bloom filter is assigned a prefix length\nbetween the maximum key length and the depth of the trie.\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\nAlgorithm 1 The modeling process for prefix length selection.\nInputğ¾- the key set\nInputğ‘˜- the maximum key length in bits\nInputğ‘š- the memory budget in bits\nInputğ‘†- the set of empty sample queries\nOutput(ğ‘™1,ğ‘™2)- prefix lengths for the best FPR\nFunction trieMem(ğ‘™)- returns size of trie with depth ğ‘™.\nFunction BFfpr(ğ‘š,ğ‘› )- returns Bloom filter FPR for ğ‘šbits andğ‘›elements.\n1:procedure Model (ğ¾,ğ‘˜,ğ‘š,ğ‘† )\n2: unsigned int resolvedInTrie[ ğ‘˜]\n3: map nRegionsQueried[ ğ‘˜][ğ‘˜] âŠ²stores pairs ( nRegions ,count )\n4: forğ‘„inğ‘†do\n5: minLenâ†ğ‘™ğ‘ğ‘(ğ¾,ğ‘„) âŠ²LCP is the min granularity to filter ğ‘„\n6: fortLenâ†0such that trieMem(tLen)â‰¤ğ‘šdo\n7: iftLen > minLen then\n8: resolvedInTrie[tLen]++\n9: forbLenâ†tLen + 1 up toğ‘˜do\n10: iftLen < minLen && bLen > minLen then\n11: nRegionsQueried[tLen][bLen].increment( ğ¼2|ğ¿|+ğ¼3|ğ‘…|)\n12: minFPRâ†1\n13: fortLenâ†0such that trieMem(tLen)â‰¤ğ‘šdo\n14: tFPRâ†1 - (resolvedInTrie[tLen] / | ğ‘†|)\n15: iftFPRâ‰¤minFPR then âŠ²Can be changed to tFPR < minFPR\n16: minFPRâ†tFPR\n17:(ğ‘™1,ğ‘™2)â† (tLen, 0)\n18: forbLenâ†tLen + 1 up toğ‘˜do\n19: bFPRâ†BFfpr(m - trieMem(tLen),| ğ¾bLen|)âŠ²Any BF can be used\n20: FPRâ†0\n21: queriesâ†resolvedInTrie\n22: for(nRegions, count) innRegionsQueried[tLen, bLen] do\n23: FPRâ†FPR + nRegions * bFPR * count\n24: queriesâ†queries + count\n25: FPRâ†FPR + (|ğ‘†| - queries) / | ğ‘†|\n26: ifFPRâ‰¤minFPR then âŠ²Can be changed to FPR < minFPR\n27: minFPRâ†FPR\n28:(ğ‘™1,ğ‘™2)â† (tLen, bLen)\n29: return(ğ‘™1,ğ‘™2)\nProteus reaps the benefits of both encodings while also miti-\ngating their shortcomings. The trie is able to efficiently rule out\nlarge ranges in constant time, while the prefix Bloom filter can\nbe positioned to catch most of the queries that would fall within\nthe empty sub-regions encoded by the trie. Careful choice of the\nBloom filterâ€™s prefix length will also improve the prefix Bloom\nfilterâ€™s performance independent of the trie. When exploring the\nconfiguration space, Proteus is free to dedicate its entire memory\nbudget to either encoding and so can be either entirely probabilistic\nor deterministic depending on the context. Configuring Proteus\namounts to choosing the prefix lengths for the trie and Bloom filter.\nThe possible prefix lengths of the trie are limited by the memory\nbudget while any memory not used in the trie can be assigned to\nany single prefix length using the Bloom filter.\n4.2 Operations\nQueries in Proteus are carried out by searching the combined struc-\nture for any members of ğ‘„ğ‘™2in depth-first order. If any prefix\nğ‘¥âˆˆğ‘„ğ‘™1âˆ©ğ¾ğ‘™1is found in the trie, then the prefixes ğ‘¦âˆ©ğ‘„ğ‘™2s.t.ğ‘¥is\na prefix ofğ‘¦are queried in the Bloom filter. If any of these prefixes\nare present in the Bloom filter or return a false positive, the query\nends and returns positive. If all of these prefixes return negative\nat the Bloom filter, the query continues to the next matching leaf\nnode in the trie. If there are no more valid leaves in the trie and\nall queried Bloom filter regions have returned negative, the query\nreturns negative. Queries that land sufficiently far from the keyset are then ruled out in the trie as ğ‘™ğ‘ğ‘(ğ‘„,ğ¾)will be short, while\nqueries that land closer to the key set must rely on the Bloom fil-\nter. In Figure 3, the query ğ‘„=[0x00F200, 0x010000] (blue) is\nan example of the former. The trie is searched for any member of\nğ‘„ğ‘™1=[0x00F2, 0x0100] , but none are found so no prefixes are\nqueried at the Bloom filter and the query returns negative. How-\never, forğ‘„=[0x020073, 0x02009C] (red), a matching prefix is\nfound in the trie, 0x0200 , so the members of ğ‘„ğ‘™2with this prefix,\n{0x02007, 0x02008, 0x02009} , must all be queried at the Bloom\nfilter. In this case we have that ğ‘™ğ‘ğ‘(ğ‘„,ğ¾)<ğ‘™2=â‡’ğ‘„ğ‘™2âˆ©ğ¾ğ‘™2=âˆ…,\nso the query will return negative so long as none of the prefixes\nqueried at the Bloom filter result in false positives.\n4.3 Using the CPFPR Model\nProteus determines its configuration by calculating the expected\nFPR for each possible configuration and choosing the one resulting\nin the lowest FPR, as shown in Algorithm 1. This involves extracting\nand storing the necessary information from a set of empty sample\nqueries and the key set, then using it to compute Equation 5 for the\ndesired memory budget.\nBloom Filter FPR: The false positive probability ğ‘in Equation\n5 is dependent on the type of Bloom filter being used. We imple-\nmented Proteus using a standard Bloom filter [ 10] for simplicity\nand calculate ğ‘according to Equation 6, where ğ‘›is the number of\nkey prefixes in the filter, ğ‘šis the number of bits allocated to it, and\nâŒˆğ‘š/ğ‘›Â·ln(2)âŒ‰hash functions are used.2\nğ‘=\u0010\n1âˆ’ğ‘’âˆ’ln(2)\u0011âŒˆğ‘š/ğ‘›Â·ln(2)âŒ‰\n(6)\nNote that both Equation 5 and Algorithm 1 are AMQ-agnostic.\nThe Bloom filters in our PRFs can be replaced with any AMQ, and\nwe need only use the corresponding FPR formula.\nCount Key Prefixes: As the Bloom filter FPR is dependent on the\nnumber of elements, we must count the number of unique key\nprefixes,|ğ¾ğ‘™|, for all possible prefix lengths ğ‘™. This can be done\nby computing the successive LCPs of the sorted key set as each\nsuccessive LCP indicates the minimum prefix length at which a\nkey is uniquely represented. This is an ğ‘‚(|ğ¾|)operation, assuming\nthe keys are already sorted. In our example application, RocksDB\nâ€”described in Section 6 â€”the keys are sorted internally for the filter.\nCalculate Trie Memory: The number of unique key prefixes |ğ¾ğ‘™|\nis also used to estimate the size of the trie at each depth ğ‘™. This\nestimation is based on the implementations of LOUDS-Sparse and\nLOUDS-Dense as described in [ 48]. We also implemented a method\nto accurately calculate the trie size, but this dominated the combined\nmodeling and construction cost of the filter and provided little\nbenefit. As is, we overestimate the cost of the trie because we do\nnot consider the memory saved by using explicitly stored key bits\nafter a key has been uniquely represented in the FST. When the trie\nis short, this has little to no effect as very few keys will be uniquely\nrepresented. This error then grows with the depth of the trie, but\nany leftover memory is simply allocated to the Bloom filter. We also\nuse this to approximate the ideal number of FST levels that should\nbe encoded with LOUDS-Dense and LOUDS-Sparse respectively,\n2A max limit of 32 hash functions is imposed since ğ‘š/ğ‘›can be quite high for short\nprefix lengths resulting in very large hash function counts that are not practical when\nmaking multiple prefix queries. We use the MurmurHash3 and CLHASH hash functions\nfor integer and string workloads respectively [35].\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nğ‘ğ›¿21 2 3 4 5\nBound 0.00425 0.00132 0.00005 0.000002 0.0000001\nTable 1: Bounds forğ‘’âˆ’ğ‘ğ›¿2/(2ğ‘)+ğ‘’âˆ’ğ‘ğ›¿2/(3ğ‘)for different values\nofğ‘ğ›¿2,ğ‘â‰¤0.1.\nrather than relying on a fixed ratio as SuRF does. This allows our\nFST to be even more memory-efficient than SuRF.\nCount Query Prefixes: Here we obtain the relevant metrics from\nour sample queries. For each ğ‘„âˆˆğ‘†, we must determine which\ntrie depths will resolve the query as well as the number of regions\nrequired to cover ğ‘„for each possible prefix length ğ‘™,|ğ‘„ğ‘™|. The first of\nthese requires ğ‘™ğ‘ğ‘(ğ¾,ğ‘„)which entails searching ğ¾for the nearest\nmember to ğ‘„. In the worst case, computing this for all queries\nisğ‘‚(|ğ‘†|log2|ğ¾|), but we sort the left query bounds, which costs\nğ‘‚(|ğ‘†|log2|ğ‘†|), and start each search from the key found for the\nprevious query. For the second, we simply shift the left and right\nbounds ofğ‘„to each prefix length and take their difference. This is\na constant amount of work for each query.\nCalculate Configuration FPRs: Once we have gathered the above\ninformation from ğ¾andğ‘†, we have everything we need to compute\nEquation 5 for each ğ‘„and configuration. Averaging these across a\ngiven configuration gives us our corresponding expected FPR. The\nadvantage of gathering all the information first is that the false pos-\nitive probabilities for the individual queries can be batched together.\nSpecifically, all queries with the same |ğ‘„ğ‘™|for a given prefix length\nğ‘™have the same false positive probability and can thus be calculated\ntogether. The number of such calculations is then dependent on the\nnumber of queries with distinct prefix counts for each configuration.\nIf range query sizes vary significantly, then most queries will have\na distinct number of prefixes and the number of calculations per\nconfiguration approaches ğ‘‚(|ğ‘†|), which is not ideal.\nTo counteract this, we bin the query prefix counts into ğ‘˜bins of\nexponentially increasing size, where ğ‘˜is the maximum key length\nin bits. Bin ğ‘–contains the number of queries with prefix counts\nin[2ğ‘–âˆ’1,2ğ‘–)as well as the average number of prefix counts for\nthose queries and bin 0 contains the number of queries resolved\nin the trie. A single batch FPR calculation is then performed for\neach non-empty bin using the average prefix query count. Calcu-\nlating the total FPR for a given configuration therefore requires at\nmostğ‘˜batch calculations. This significantly reduces the amount of\nmodeling work and has little effect on the accuracy. This is because\nthe probability of returning negative for an empty query decays\nexponentially with the number of prefix queries required. Despite\ncontaining more disparate values, the bins with larger ranges will\nstill batch together queries with similar false positive probabilities.\nSample Size: We based our sample size on confidence intervals\nderived using a Chernoff bound. Using ğ‘queries, we obtain an\nestimate ^ğ‘of the FPR of a given configuration by dividing the\nnumber of false positives found by ğ‘. Assuming the ğ‘queries\nare independently false positives with probability ğ‘, a standard\nChernoff bound (see, e.g., Chapter 4 of [ 41]) yields the following\nbound for the probability that our estimate, ^ğ‘, is withinğ›¿ofğ‘:\nğ‘ƒğ‘Ÿ(ğ‘âˆˆ[^ğ‘âˆ’ğ›¿,^ğ‘+ğ›¿])â‰¥1âˆ’min(2ğ‘’âˆ’2ğ‘ğ›¿2,ğ‘’âˆ’ğ‘ğ›¿2/(2ğ‘)+ğ‘’âˆ’ğ‘ğ›¿2/(3ğ‘)).Count\nKey\nPrefixesCalc.\nTrie\nMem.Count\nQuery\nPrefixesCalc.\nConfig\nFPRsBuild\nFilterTotal\n1PBF 32 - 9 1 3139 3181\n2PBF 32 - 81 884 3239 4236\nProteus 32 1 71 1 3130 3235\nSuRF - 482 482\nRosetta 3 4775 4778\nTable 2: Breakdown and comparison of filter construction times,\nincluding modeling. Values are rounded up to nearest millisecond.\nIn our setting, typically ğ‘â‰¤0.1. Table 1 provides (upper bounds\nfor) the largest value of ğ‘’âˆ’ğ‘ğ›¿2/(2ğ‘)+ğ‘’âˆ’ğ‘ğ›¿2/(3ğ‘))forğ‘â‰¤0.1, for\ndifferent values of ğ‘ğ›¿2. For example, with sample sizes of 10,000\nand 50,000 queries, the probability that ^ğ‘differs from ğ‘by more\nthan0.01will be at most 0.00425 and0.0000001 respectively. Note\nthat this is an upper bound and so the actual probability will likely\nbe smaller in practice. Furthermore, accurately estimating the FPR\nof each configuration is less consequential than finding a good\nconfiguration. So long as our estimates are close, we will end up\nwith a configuration that is close to ideal. We show in Section 5.1\nthe accuracy of our FPR estimates over the space of possible PRF\nconfigurations for a sample size of 10K queries. In Section 5.2, we\ncompare Proteus configured using 20K sample queries against the\nstate-of-the-art on diverse workloads.\nModeling Cost Breakdown: Table 2 shows a breakdown of these\ncosts for 10M normally distributed keys, a sample of 20K correlated\nempty queries, and a memory budget of 10 BPK. This workload is\ndesigned to maximize the number of possible configurations for\nProteus and consequently the computation required for modeling.\nWe use normally distributed keys to increase the number of viable\nconfigurations to test as there will be more common key prefixes,\nthereby making the trie more compact. The queries are correlated\nto the keys just enough that most will not be resolved in the trie\nwhich increases the number of calculations required to compute\nthe expected FPR for each configuration. Lastly, we use range sizes\nuniformly distributed between 2and220to have a large number of\ndistinct prefix counts. 2PBF uses a maximum range size of 215due\nto values overflowing when computing the binomial coefficient in\nEquation 4 for queries with a large number of prefixes.\nLooking at the results in Table 2, we see that the modeling time\nfor 1PBF (~42ms) is about two orders of magnitude smaller than its\nconstruction time (~3s), which is just that of a standard Bloom filter.\nProteusâ€™s modeling is a modestly more expensive (~100ms) but is\nstill dominated by the construction time (~3s). It is worth noting\nthat, without the binning, calculating the expected FPRs for each\nconfiguration becomes the dominant factor for all of our PRFs, in\nthe worst case. With the binning, the combined modeling and build\ncost of both 1PBF and Proteus is comparable to the construction\ncost of a standard Bloom filter. However, the modeling cost alone\nfor 2PBF is comparable to the construction cost for a Bloom filter,\neven with reduced range size. This is for a number of reasons. While\nProteusâ€™s potential configurations are limited by the cost of its trie,\n2PBFâ€™s choice of ğ‘™1has no such limit. 2PBF therefore considers all\ncombinations of ğ‘™1<ğ‘™2âˆˆ[1,64]for multiple memory allocations.\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\n0.00.20.40.60.81.0\n1\n20 25 30 35 40 45 50 55 60\nPrefix length0.00.20.40.60.81.0\n2False positive rate (FPR)Max range / Correlation deg\n(exp FPR)\n23\n27\n211\n215\n219(obs FPR)\n23\n27\n211\n215\n219\n(a)1PBF\n (b)2PBF\n (c)Proteus\nFigure 4: The CPFPR model accurately predicts the FPR for all possible designs of different Protean Range Filters.\nAn exhaustive search of all possible memory allocations is infeasible,\nso we implement 2PBF to test 2 asymmetric allocations (60-40/40-60)\nand a symmetric allocation. Furthermore, the probabilistic nature\nof the first filter results in many possible outcomes for each query,\nall of which must be considered when calculating the queryâ€™s false\npositive probability. This puts 2PBFâ€™s modeling time (~1s) on the\nsame order of magnitude as itâ€™s construction time (~3s). Note that\nthis is a worst case workload for modeling time but not filter build\ntime. This is because 2PBF only ends up using a single Bloom filter\nwhile Proteus does not use a trie. However, the worst case build\ntime for Proteus will not be significantly larger since the FST can\nbe built very quickly, as shown by SuRFâ€™s build time. 2PBFâ€™s build\ntime can as much as double if it has to build a second Bloom filter.\n5 MODEL VALIDATION\nHere we demonstrate the accuracy of the described CPFPR models\nand evaluate our PRFs (1PBF, 2PBF, and Proteus) as in-memory\nstandalone filters. We show that Proteus selects optimal designs\nacross a variety of workloads and achieves better FPRs than state-\nof-the-art AREs due to its broader design space. In Section 6, we\nevaluate these AREs in RocksDB with end-to-end system metrics.\nWe use 64-bit unsigned integers for our experiments in Section 5\nand Section 6 and focus on strings in Section 7.\nDatasets: The real world datasets come from the Searched on\nSorted Data (SOSD) benchmark for index structures [30, 37].\nâ€¢Uniform: Keys are generated uniformly from [0,264- 1] .\nâ€¢Normal: Keys are generated with a mean of 263and a standard\ndeviation of 264Â·0.01.\nâ€¢Books: Amazon booksale popularity data for 800M books. This\ndata has a fairly heavy skew with many more low popularity\nscores than high.\nâ€¢Facebook: A set of 200M upsampled Facebook user IDs. This\ndata is fairly dense and covers a relatively small range of values\nwith uniformly distributed gaps.\nWorkloads: We test variations of YCSB Workload E, a range-scan\nintensive workload. Queries are of the form [left, left+offset] ,\nwhere offset is chosen uniformly at random from [2, RMAX]\nunless otherwise stated. For point queries, offset is set to 0.â€¢Uniform: left is taken uniformly at random from [0,264âˆ’\nRMAX] .\nâ€¢Correlated: Akeyis chosen uniformly at random from the\ndataset and then left is chosen uniformly at random from [key+1,\nkey+CORRDEGREE] . We use a default CORRDEGREE of210.\nâ€¢Split: An even split of Uniform andCorrelated queries, similar\nto the particle physics workload mentioned in Section 1.\nâ€¢Real: For a real world dataset, we uniformly sample 10M integers\nto use as keys and another 1M integers to use as the left bounds.\nExperimental Setup: All experiments were run on Linux kernel\n5.13.12-arch1-1 with an AMD Ryzen 7 1800X 8-core processor, 16GB\nRAM, and 1TB Samsung 850 EVO SSD. For each experiment, 1M\nqueries were executed serially on a single thread with a sample of\n20K queries and a data set of 10M keys.\n5.1 Model Accuracy\nWe validate the accuracy of the CPFPR models for 1PBF, 2PBF,\nand Proteus by comparing the expected FPR â€”as calculated by\nthe corresponding CPFPR model â€”with the observed FPR on all\npossible designs in the respective filter design spaces. We use a\nsample size of 10K queries for these experiments, demonstrating\nour accuracy at the lowest ğ‘ğ›¿2in Table 1.\n1PBF: We run two experiments to highlight the impact of each\nof our contextual parameters, range size and correlation between\nkeys and queries, as shown in Figure 4a. The top graph varies RMAX\nonUniform-Uniform , while the bottom graph varies CORRDEGREE\nonUniform-Correlated . The RMAX for the bottom graph is fixed\nat27and the prefix length on the x-axis represents the different\npossible designs for 1PBF.\nIn Figure 4a.1, we see that the observed FPR quickly increases\nonce the prefix length passes 64âˆ’log2RMAX . Before this threshold,\na given range query will not require more than 2 regions to be\nqueried in the prefix Bloom filter as the range queries are all smaller\nthan the regions encoded the prefix filter. Since we use Uniform\nkeys and queries, the significant majority of queries do not fall\nclose to keys. As such, empty sub-regions only become an issue\nfor prefix lengths shorter than 30. The same effect becomes more\nprevalent in Figure 4a.2 where we see that any prefix length shorter\nthan64âˆ’log2CORRDEGREE is affected by empty sub-regions. Since\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nFigure 5: Proteus optimally configures its design on diverse workloads with varying range sizes and memory budgets.\nFigure 4a.b uses a range size of 27, any prefix length longer than\n57 will also result in more false positives due to range size. When\nlog2CORRDEGREE >7, the prefix filter must contend with false\npositives resulting from both empty sub-regions and range size.\nIn both experiments, the 1PBF CPFPR model is able to accurately\ncapture the effects of both conditions as they pertain to the FPR.\n2PBF & Proteus: For both of our PRFs that use two prefix lengths,\nwe focus on a situation that calls for multiple prefix lengths, as\ndescribed in Section 3. We use Normal-Split with short range\nCorrelated and long range Uniform queries to necessitate the\nuse of two prefix lengths. The FPRs for each design are shown in\nFigure 4b and 4c for 2PBF and Proteus respectively. The expected\nFPRs are shown in the upper right triangle of the matrix while the\ncorresponding observed FPRs are reflected in the lower left.\nFor both filters, we correctly predict the optimal design, and\naccurately predict the range of FPRs over the entire design space.\nThe optimal design for 2PBF is uses prefix lengths of 26 and 57 bits\nwhile Proteusâ€™s optimal design uses a 24 bit trie and a prefix length\nof 58 bits. The corresponding expected and observed FPRs are 11.4%\nand 12.3% for 2PBF and 5.17% and 4.91% for Proteus respectively.\nThese values may seem high in terms of the FPRs typically achievedby AMQs, but this is also a highly adversarial case which current\nAREs are unable to handle. We re-visit this use case in Section 6.3\nin the context of end-to-end system performance. The gray region\ncorresponds to the part of the parameter space where the trie is\ntoo large for the memory budget (10 BPK). Despite its more limited\ndesign space, Proteus achieves lower FPRs than 2PBF.\nFigure 4b shows the results for the best memory division between\nthe two Bloom filters, a 50-50 split. This works best as our Split\nquery distribution is evenly split between small, key-correlated\nqueries and large, uniformly distributed queries. 2PBF also considers\nasymmetric memory allocations, as described in Section 4.\nBoth Proteus and 2PBF fully encompass 1PBFâ€™s design space\nand will always achieve an equivalent or lower FPR. Moreover,\neven though Proteus and 2PBF occupy slightly different design\nspaces, in the situations where a second Bloom filter is helpful, it is\noutperformed by Proteusâ€™s trie.\n5.2 Optimizing Across the Design Space\nWe now demonstrate Proteusâ€™s ability to select optimal designs\nacross a variety of workloads. We also contrast Proteus flexibility\nagainst state-of-the-art AREs Rosetta and SuRF for each, as shown\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\nin Figure 5. Each row in Figure 5 shows the results for a Dataset-\nWorkload pair for point queries, small range queries, large range\nqueries and a combination of point and range queries. The SuRF\nresults show the lowest FPR for all possible configurations of real\nand hash-suffix bits, but in practice users will need to implement a\npolicy to choose the appropriate SuRF configuration. In these ex-\nperiments, Proteus and Rosetta both use 20K empty sample queries\nwhich gives us a bound of 0.00425 forğ›¿=0.1, as per Table 1. This\nwill give us higher confidence in the optimality of Proteusâ€™s chosen\ndesign as we compare its performance across workloads.\nEffective Navigation of Design Space : For nearly all use cases,\nProteus is able to choose a design that achieves a low FPR. This\nis less true for large Correlated queries â€”an adversarial case for\nany prefix-based filter â€”as Proteus must rely entirely on a Bloom\nfilter design. Even so, Proteus is able to achieve a much lower\nFPR than any state-of-the-art ARE by picking a prefix length that\nbalances the number of prefixes per query and the number of range\nqueries distinguishable from the key set. In situations where SuRF\nand Rosetta are optimal, Proteus takes on a similar design to the\nrespective filter and achieves similar performance. For instance,\nRosetta and Proteus are virtually indistinguishable in terms of FPR\nin point query workloads. Similarly, Proteus and SuRF achieve very\nsimilar FPRs on Facebook-Real as the keys lie in a narrow range\nwhich causes both Proteus and SuRF to have extremely deep tries.\nImpact of Restricted Design Spaces : However, if the optimal\ndesign lies outside the restricted design spaces of SuRF or Rosetta,\nthen the corresponding filterâ€™s performance will be limited. For\nexample, consider the Uniform-Correlated small range query\nworkload. Despite only a small increase in range size from the\npoint query workload, a full length prefix filter is no longer optimal\nfor lower memory budgets as the benefit from distinguishing all\nqueries is outweighed by the benefit of querying fewer prefixes,\nas corroborated by Proteusâ€™s design. Even so, Rosetta will always\ndedicate the majority of its memory to the full length prefix filter.\nFor all point query workloads as well as the mixed query workloads\nforUniform-Correlated andNormal-Split , SuRF achieves its\nbest FPR with the use of hash-suffix bits and only achieves good\nFPR with high memory budgets. In such cases, a Bloom filter is\na more efficient use of memory and can be tuned to optimize for\narbitrary range sizes, in contrast to the hash-suffix bits which are\nonly used for point queries. We can also observe SuRFâ€™s minimum\nmemory requirement across the various workloads. In most cases,\nit requires 11-12 BPK, while Proteus can always achieve equivalent\nif not better performance at 8BPK.\nAdditional Benefits of the Hybrid Design Space : The combi-\nnation of complementary design elements in Proteus allows it to\nachieve better FPR than designs which rely only on a single tech-\nnique. Even for some point query workloads, such as Normal-\nUniform , a hybrid design can leverage a short, memory-efficient\ntrie to achieve a better FPR-memory tradeoff than a standard Bloom\nfilter. Furthermore, on Split workloads, Proteus is able to gracefully\nhandle both types of queries, but more brittle structures may have\nto sacrifice performance on a certain portion of the queries. For\ninstance, on the mixed Normal-Split workload at a low memory\nbudget, Rosetta and SuRF can only filter the Correlated point\nqueries and the Uniform range queries respectively.6 SYSTEM EVALUATION: ROCKSDB\nWe integrate Proteus into RocksDB â€”a popular key-value store\nâ€”and demonstrate that it improves end-to-end range query perfor-\nmance by up to 3.9x and 3.3x over Rosetta and SuRF respectively\nacross a variety of workloads, with consistently better performance\nat low BPKs (8-12). This speed-up is due to a reduction in I/O op-\nerations as a result of the lower FPR achieved. Furthermore, we\nshow that the additional cost of modeling in filter construction does\nnot significantly impact the end-to-end performance of RocksDB\nand that Proteus is able to adapt smoothly to changes in the query\nworkload distribution, unlike Rosetta and SuRF which suffer drastic\ndeclines in performance on certain adversarial distributions.\n6.1 Proteus System Integration\nRocksDB uses an LSM tree architecture which organizes data on\ndisk into levels of increasing size, where each level ğ¿ğ‘–(exceptğ¿0) is\nrange partitioned into multiple sorted runs or Static Sorted Table\n(SST) files that occupy disjoint key ranges. The SST files in ğ¿0are\ndirectly flushed to disk from MemTables â€”in-memory structures\nthat buffer writes â€”and thus typically have overlapping key ranges.\nStatic filters (e.g. Bloom filters) are built on every SST file to reduce\nunnecessary accesses for non-existent keys. When a level ğ¿ğ‘–reaches\nits maximum capacity, RocksDB selectively merges SST files from ğ¿ğ‘–\nintoğ¿ğ‘–+1, triggering the construction of new filters on the merged\ndata in the new ğ¿ğ‘–+1SST files. This process is called compaction.\nRange Query Implementation: Similar to [ 36], we modify the\nRocksDB closed Seek logic to first check all filters for the existence\nof keys in the queried range. If all filters return false, then Seek\nreturns an invalid iterator. For the filters that return true, RocksDB\nproceeds to retrieve the smallest keys from the associated SST files\nthat are greater than or equal to the lower query bound. This is done\nby binary searching over the index block which stores min/max\ninformation in each SST file and fetching the corresponding data\nblock. If the global smallest key is smaller than the upper query\nbound, an iterator pointing to that key is returned. Otherwise, an\ninvalid iterator is returned for the empty range query.\nSample Query Queue: Since Proteus (and Rosetta) need sample\nqueries, we create a fixed size query queue and seed it with an\ninitial query sample. Older queries are evicted with a FIFO policy.\nThis changing set of sample queries is used in conjunction with the\nkeys in each SST file to determine the optimal filter design for each\nSST file at construction time. In our experiments, we use a queue\nsize of 20K queries (~320KB) and update the queue with every 100th\nexecuted empty query.\nTuning RocksDB: Since all filters have to be queried during a\nclosed Seek , we curtail this CPU cost by tuning RocksDB to fit\nmore data in each SST file, thereby reducing the number of filters\nqueried. This also helps to control the overall cost of modeling from\nfilter construction when there are heavy compactions. We increase\nthe SST file size from the default of 64MB to 256MB and scale up the\nsize ofğ¿1and the MemTables to maintain the same number of SST\nfiles that fit in them with default settings.3Similarly, we selectively\nenable data compression for certain levels. We leave the few SST\nfiles inğ¿0andğ¿1uncompressed to maintain the speed of MemTable\nflushes and ğ¿0â†’ğ¿1compactions. For SST files in ğ¿2, we use LZ4\n3write_buffer_size = 256MB, max_bytes_for_level_base = 1024MB\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nFigure 6: Proteus improves end-to-end RocksDB performance on low memory budgets across diverse workloads.\n0 0.5 10123Cumulative Latency (â‹…103s)\n1Uniform âŸ¶ Correlated\n0 0.5 102468\n2Correlated âŸ¶ Uniform\n0.00.20.40.60.81.0False Positive Rate\nWorkload Transition RatioLatency\nProteus\nRosetta\nSuRF\nFPR\nProteus\nRosetta\nSuRF\nFigure 7: Proteus is robust against extreme workload shifts.\ncompression â€”a light-weight compression algorithm recommended\nby RocksDB [ 28] that balances CPU cost and compression size. We\nuse heavy-weight ZSTD compression for SST files in ğ¿3onwards\nas they are less frequently modified and contain bulk of the data in\nthe LSM tree. We ensure that the filters are cached in the RocksDB\nblock cache4and assign RocksDB 6 background threads for flushes\nand compactions.\n6.2 Experimental Setup\nWe use the same datasets, range query workloads, and machine\ndescribed in Section 5 for experiments carried out in RocksDB\nv6.20.3. For each 8 byte integer key, we generate an associated\n512 byte value. The first half of all values are zeroed out, while\nthe second half is randomly generated which yields a constant\ncompression ratio of 0.5. To ensure that all experiments start from\na consistent LSM tree state, we manually flush the MemTable after\npopulating the initial, empty database, and wait for all background\ncompactions to finish before executing the benchmark. In Section\n6.3, the initial database has 50M key-value pairs which yields a 4\nlevel (~14GB compressed) LSM tree with ~70 SST files. In Section 6.4,\nwe first insert 20M key-value pairs to get a 3 level (~6GB compressed)\nLSM tree with ~40 SST files, and subsequently Putan additional\n40M key-value pairs over the course of the experiments. In both\ncases,ğ¿0is empty in the initial database state as we set RocksDB\nto compact all ğ¿0SST files toğ¿1for sake of consistency. Lastly, we\nwarm the RocksDB block cache (1GB) and the OS page cache by\nrunning 1M uniformly distributed point queries of existing keys to\nensure that all indexes and filters are loaded into memory.\n6.3 End-to-End Performance\nWe measure the end-to-end range query performance in terms of\nworkload execution latency for Proteus, SuRF, and Rosetta on four\n4cache_index_and_filter_blocks = true,\npin_l0_filter_and_index_blocks_in_cache = true\nUniform |Correlated0123Cumulative Latency (â‹…103s)\n1Uniform âŸ¶ Correlated\nCorrelated |Uniform02468\n2Correlated âŸ¶ Uniform\n0.00.20.40.60.81.0False Positive Rate\nWorkload TypeLatency\nProteus\nFPR\nProteusFigure 8: Proteus is robust to immediate, extreme workload shifts.\nuse cases targeting different points in the design space. As shown\nin Figure 6, Proteus achieves the lowest latency across all work-\nloads on low memory budgets, improving upon SuRF and Rosetta\nby as much as 3.3x and 3.9x respectively. In RocksDB, one of the\nprimary sources of latency is I/O when accessing the SST files. As\nsuch, a lower FPR generally results in lower latency because we can\navoid unnecessary I/O. However, situations such as thrashing in\nRocksDBâ€™s internal cache or excessive prefix queries during Bloom\nfilter probes can result in higher latency despite a low FPR. For\nexample, Rosetta improves its FPR on Normal-Uniform as its mem-\nory budget increases by using more hash functions per Bloom filter,\nbut the resulting latency increases. This is because a large range\nquery requires Rosetta to query many prefixes and the CPU cost for\neach is proportional to the number of hash functions used. Proteus\nis able to frequently avoid this as the trie limits - and sometimes\neliminates all - prefix queries made at the Bloom filter. SuRF has an\neffectively constant computational cost for queries, but can suffer\ndue to pressure on RockDBâ€™s internal cache. This can be seen in\nboth the Normal-Split andUniform-Correlated workloads. We\nobserved that SuRF puts more pressure on RocksDBâ€™s internal cache\nwhich results in thrashing after passing a certain FPR threshold\n(~0.1 to 0.2 in our experiments).5This thrashing severely impacts\nthe overall system latency. We also observed that SuRFâ€™s memory\nfootprint varies by as much as 3 BPK across SST files, while Proteus\nand Rosetta maintain consistent BPKs and do not result in thrashing.\nNaturally, I/O savings would be magnified for larger datasets.\n6.4 Robustness to Shifting Query Distribution\nWe now evaluate the robustness of Proteus: its ability to main-\ntain good end-to-end performance when the workload shifts. We\nexamine incrementally shifting workloads which mimic real-life\napplications with temporal skew, such as Wikipedia. As shown in\n5rocksdb.block.cache.add shows that more data blocks are added to the cache\nwhen using SuRF compared to Proteus with similar FPR.\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\nSection 3, a range filterâ€™s performance is primarily affected by the\nrelative positioning between the data keys and the queried keys.\nThus, changing the queries or the data are essentially equivalent in\nterms of impact on filter performance and so we focus on changing\nthe query distribution to be able to control the relative key-query\nproximities. We test with workloads that gradually shift between\nlarge range Uniform queries and small range Correlated queries\nwhich favor shorter and longer prefix lengths respectively. To mag-\nnify the difference in Proteus designs, we maintain a Normal key\ndistribution when shifting from long Uniform queries to short\nCorrelated queries as the trie chosen for Uniform queries is inef-\nfective for Correlated queries and take memory away from the\nBloom filter. Similarly, we maintain a Uniform key distribution\nfor a short Correlated to long Uniform query transition which\nprecludes the use of a trie for long Uniform queries.\nFor each workload, we define the workload transition ratio as the\nprobability of executing a query from the end query distribution. We\ntest 60M closed Seeks with a workload transition ratio increasing\nlinearly from 0 to 1. We start with an initial database of 20M keys\nand uniformly interleave 40M Puts with the 60M Seeks to trigger\nperiodic compactions and construction of new filters.\nIn Figure 7, we show the cumulative latency as the respective\nworkloads transition from one type of query to another, and re-\nport the FPR for every batch of 5M Seeks . Proteus is resilient to\nthe extreme workload shifts and is able to instantiate new designs\nto maintain a consistently low Seek latency. As shown in Figure\n7.1 and 7.2, Proteus has a smooth increase in cumulative latency\nwhich stems from the low FPR maintained as the workload shifts.\nThis is because Proteus can configure itself accurately by relying\non the sample query queue to provide an up-to-date view of the\nquery workload. The end-to-end behavior observed also highlights\nthat the additional cost of modeling for Proteus during filter con-\nstruction does not impact the overall performance despite heavy\nongoing compactions (~15-20 for each 5M Seek batch). In contrast,\nthe latencies for SuRF and Rosetta increase sharply when the work-\nload transitions past 0.5 for Uniformâ†’Correlated (Figure 7.1)\nandCorrelatedâ†’Uniform (Figure 7.2) respectively. Due to their\nrestricted design spaces, Rosetta and SuRF can only effectively han-\ndle one of the two types of queries. We observe the impact of their\nbrittle designs in the FPR which decreases as the workload shifts.\nWe repeated the same experiments for Proteus with an immedi-\nate change in query distribution, simulated by not mixing the two\ndistributions, with results shown in Figure 8. We observe a larger\nincrease in FPR and latency after the drastic transition since the\nfilter designs are not optimal for the new query distribution, but\nthe decrease in performance is temporary as the filters are rebuilt\nusing the updated query cache, giving robust performance.\n7 VARIABLE LENGTH KEYS\nDatabase workloads commonly include variable length keys, which\noften arise from concatenations of various metadata [ 12,25]. In this\nsection, we show how Proteus can be used with variable length keys\nand demonstrate that the CPFPR model extends to any key length.\nWe also show that Proteus reduces end-to-end query latency in\nRocksDB by as much as 5.3x vs. SuRF on a real-world string dataset.7.1 Extending the Model and Filter\nModeling: Shifting from a fixed length integer key space to a\nvariable length key space in the CPFPR model is equivalent to\nchanging the total ordering from a less-than-or-equal relation to\na lexicographical relation. For longer keys, Proteus also has more\npotential designs due to the larger range of prefix lengths. In the\ncontext of static filters, the length of the longest key in the dataset\nis known and therefore Proteusâ€™s design space is well defined.\nFilter Operation: The trie portion of Proteus handles string keys\nwithout requiring any modifications. On the other hand, variable\nlength keys give rise to an exploding number of prefixes to query\nin the prefix Bloom filters. In addition, every Bloom filter query\ninherently increases the probability of a false positive. Proteus\nachieves low FPR and query time by padding short keys and queries\nwith trailing null bytes to a chosen prefix length, thus mapping\nthe key space onto a fixed-length key space. This means that the\nprefix Bloom filter does not distinguish between short keys and\ntheir padded equivalents, which will result in false positives if\nthe application does not make the same assumption. Finally, we\nchanged the Bloom filter hash function from MurmurHash3 to\nCLHASH which can handle strings [5, 35].\n7.2 Validation and Evaluation\nExperimental Setup: We run in-memory and RocksDB bench-\nmarks similar to Section 5.2 and Section 6.3 respectively. For in-\nmemory experiments, we generate three datasets of fixed-length\nstring keys of size 80, 200, and 1440 that conform to either a Uni-\nform orNormal distribution. Uniform keys are concatenations of\nuniformly generated key bytes up to the specified key length, while\nNormal keys are normally distributed around the middle of the key\nspace with standard deviation ğœ=0.01Â·264. Specifically, the mean\nkey is defined to be the string with a most significant byte value\nof 128 followed by null bytes up to the key length. We also gener-\nated Uniform ,Correlated , and Split synthetic string workloads\nwith RMAX 230andCORRDEGREE 229. The in-memory experiments\nwere run with 10M keys, 1M queries, and 20K sample queries. For\nRocksDB experiments, we use an internet domain dataset compris-\ning ~31M crawled .org domains [ 44]. The domains are 5 to 253\nbytes long with a median length of 21 bytes and follow a log-normal\ndistribution ( ğ‘…2=0.98). The initial database was populated with\n20M domain keys and 512 byte random values, resulting in a 3\nlevel (~6GB compressed) LSM tree with ~30 SST files. Another 10M\nrandom domains were used to generate queries with RMAX 230, as\nwith our other Real workloads. To control the distribution of RMAX ,\nwe pad the dataset with null bytes to the max key length. Note that\nthis does not affect the performance of SuRF as it only considers\nthe keys up to their unique prefixes which will be unchanged by\nthe padding. For Proteus, the padding would ideally be done on\na per-SST file basis to avoid unnecessary padding and modeling\nof designs with longer prefix lengths. These costs are incurred at\nconstruction time and not measured in the read-only experiment.\nFPR is Unaffected by Key Length: In Figure 9a-d, we present\nin-memory results for 1440-bit keys. As with integers, Proteus\noutperforms SuRF across distributions and filter sizes. Experiments\nwith other key lengths show the same performance patterns as only\nthe range size and key-query proximity matter.\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\n0.00.20.40.60.81.0False Positive Rate (FPR)\n(a) Uniform - Uniform\n (b) Uniform - Correlated\n (c) Normal - Split\n (d) Normal - Correlated\nProteus\nSuRF\n8 10 12 14 16 1839 42 40 38 39 38\n8 10 12 14 16 181413 1414 1415 1415 1416 1417\n8 10 12 14 16 181435 1436 1437 1438 1438 1439\n2416 16 1624 24\n8 10 12 14 16 181413 1414 1415 1415 1416 1417\nPrefix len.\nTrie depth\nBits per Key (BPK)\n10 15 20 25\nBits per Key (BPK)100200300400500Latency (s)\n(e) org domains\nLatency\nProteus\nSuRF\n0.00.10.2False Positive Rate (FPR)\nFPR\nProteus\nSuRF\nFigure 9: Proteus achieves lower FPR than SuRF on synthetic strings (a-d) and lower RocksDB latency on real-world strings (e).\nModeling Time Increases with Key Length: While the model-\ning accuracy is preserved across key length, the number of possible\ndesigns isO(ğ‘˜2)with respect to the maximum key length. Longer\nkeys can therefore result in a significant increase in the time re-\nquired to model the designs. In our in-memory benchmarks, the\ntime to model all possible designs with 1440-bit keys ranged from\n2.82 to 149 seconds. The worst case is too expensive for most real\nworld applications; however, we can achieve an order of magnitude\nspeedup by using a coarser search as the difference in performance\nfor similar designs is often quite small. The results for Proteus\nshown in Figure 9 were obtained by only modeling 128 uniformly\nspaced Bloom filter prefix lengths for all feasible trie depths. The\nmodeling times with this optimization ranged from 0.86 to 14.3\nseconds while still achieving similar performance.\nThe structure of the modeling also lends itself very well to par-\nallel computation. As shown in Section 4.3, the dominant cost of\nthe sampling is extracting the information needed to model each\nsample query relative to each design. This can be done indepen-\ndently on both a per-query and per-design basis. Since modern\ndatabase services are hosted on elastic cloud architectures, occa-\nsional increases in CPU usage can easily be amortized at a low cost\ncompared to the benefits of a more performant filter.\nProteus Maintains Strong Performance on Strings: Figure 9\nshows the results of our real-world string benchmark in RocksDB.\nProteus outperforms SuRF in both end-to-end latency and FPR by an\neven larger margin using the aforementioned coarse-grained model-\ning. We see the impact of design tradeoffs amplified for longer keys\nâ€”SuRFâ€™s rigid design requires a large minimum memory budget\nand limits the effectiveness of additional filter memory. Conversely,\nProteusâ€™s flexible design allows it to distribute memory between\nits design elements for more efficient memory use. As shown in\nFigure 9, SuRF requires at least 16 BPK while Proteus can achieve\nsignificant performance gains with as little as 8 BPK.\n8 RELATED WORK\nOur investigation is part of a broader initiative in the systems\ncommunity to design contextually-customized data structures.\nAdaptive Range Filter: The Adaptive Range Filter (ARF) [ 1] adapts\nits binary trie structure in response to queries, extending branches\nto compensate for false positives and retracting them to maintain\nits memory footprint. However, ARFâ€™s encoding strategy limits its\nmemory efficiency and requires significant time and memory topre-train [ 48]. Similar adaptive techniques have been applied to\nAMQs to deal with adversarial workloads [7, 40].\nStacked Filters: Stacked Filters [ 15] also use modeling to incorpo-\nrate workload specific information in their design. However, their\nmodel is designed for point rather than range queries.\nData Calculator: Similar to PRFs, the Data Calculator [ 26] breaks\ndown a complex design space into its fundamental design primitives\nand models the behavior of designs to determine the optimal design\nfor a given workload. However, the Data Calculator focuses on the\ndesign space of key-value structures rather than range filters and\nmerely synthesizes the optimal design rather than instantiating it.\nLearned Structures: Several iterations of learned Bloom filters\nuse learned models to leverage patterns in the data for better per-\nformance [ 14,39,45]. These filters are designed for single item\nqueries and perform poorly on range queries for the same reasons\nas other AMQs. This method of fitting to the use case also requires\nthe presence of patterns in the data that are amenable to the model\nbeing used. Similar techniques have been applied to indexing struc-\ntures in databases to speed up searches [ 32]. Indexes can also be\nused to answer range queries, but they are larger, general purpose\nstructures which typically require more I/O to answer a query.\n9 SUMMARY AND OPPORTUNITIES\nThis paper introduces Proteus, a self-designing range filter that\nachieves robust performance across a large variety of workloads.\nThe core idea is that (1) Proteus unifies the design spaces of state-\nof-the-art range filters to cover a wider range of workloads and (2)\nis able to instantiate workload-optimal designs. Analysing cutting-\nedge range filtering techniques through the lens of the CPFPR\nmodel reveals adversarial workloads which no current design can\nhandle practically, suggesting the need for further expansion of\nthe range filter design space. Other promising directions include\nextending the CPFPR model to support higher order optimization\nstrategies by incorporating metrics such as query latency as well as\nexploring non-uniform memory allocation strategies in RocksDB.\nACKNOWLEDGMENTS\nThis work is supported in part by NSF grants CCF-2101140, CNS-\n2107078, CCF-1563710, and DMS-2023528, and by a gift to the Cen-\nter for Research on Computation and Society at Harvard University.\nAdditional funding was provided by USA Department of Energy\nproject DE-SC0020200. We would also like to thank our reviewers\nfor their helpful and constructive feedback.\n\nSIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA Knorr, Lemaire and Lim, et al.\nREFERENCES\n[1]Karolina Alexiou, Donald Kossmann, and Paul Larson. 2013. Adaptive Range\nFilters for Cold Data: Avoiding Trips to Siberia. In Proceedings of the VLDB En-\ndowment, Vol. 6, No. 14 . https://www.microsoft.com/en-us/research/publication/\nadaptive-range-filters-for-cold-data-avoiding-trips-to-siberia/\n[2]Sattam Alsubaiee, Yasser Altowim, Hotham Altwaijry, Alexander Behm, Vinayak\nBorkar, Yingyi Bu, Michael Carey, Inci Cetindil, Madhusudan Cheelangi, Khurram\nFaraaz, et al .2014. AsterixDB: A scalable, open source BDMS. arXiv preprint\narXiv:1407.0454 (2014).\n[3]Sattam Alsubaiee, Michael J. Carey, and Chen Li. 2015. LSM-Based Storage\nand Indexing: An Old Idea with Timely Benefits. In Second International ACM\nWorkshop on Managing and Mining Enriched Geo-Spatial Data (Melbourne, VIC,\nAustralia) (GeoRichâ€™15) . Association for Computing Machinery, New York, NY,\nUSA, 1â€“6. https://doi.org/10.1145/2786006.2786007\n[4]Sabrina Amrouche, Laurent Basara, Paolo Calafiura, Dmitry Emeliyanov, Victor\nEstrade, Steven Farrell, CÃ©cile Germain, Vladimir Vava Gligorov, Tobias Golling,\nSergey Gorbunov, Heather Gray, Isabelle Guyon, Mikhail Hushchyn, Vincenzo\nInnocente, Moritz Kiehn, Marcel Kunze, Edward Moyse, David Rousseau, Andreas\nSalzburger, Andrey Ustyuzhanin, and Jean-Roch Vlimant. 2021. The Tracking\nMachine Learning challenge : Throughput phase. arXiv:2105.01160 [cs.LG]\n[5] Austin Appleby. 2008. . https://sites.google.com/site/murmurhash/\n[6]Diego Arroyuelo, Rodrigo CÃ¡novas, Gonzalo Navarro, and Kunihiko Sadakane.\n2010. Succinct Trees in Practice. In Proceedings of the Meeting on Algorithm\nEngineering & Expermiments (Austin, Texas) (ALENEX â€™10) . Society for Industrial\nand Applied Mathematics, USA, 84â€“97.\n[7]Michael A. Bender, Martin Farach-Colton, Mayank Goswami, Rob Johnson,\nSamuel McCauley, and Shikha Singh. 2018. Bloom Filters, Adaptivity, and the\nDictionary Problem. In 2018 IEEE 59th Annual Symposium on Foundations of\nComputer Science (FOCS) . 182â€“193. https://doi.org/10.1109/FOCS.2018.00026\n[8]Michael A. Bender, Martin Farach-Colton, Rob Johnson, Russell Kraner, Bradley C.\nKuszmaul, Dzejla Medjedovic, Pablo Montes, Pradeep Shetty, Richard P. Spillane,\nand Erez Zadok. 2012. Donâ€™t Thrash: How to Cache Your Hash on Flash. Proc.\nVLDB Endow. 5, 11 (July 2012), 1627â€“1637. https://doi.org/10.14778/2350229.\n2350275\n[9]David Benoit, Erik D. Demaine, J. Ian Munro, Rajeev Raman, Venkatesh Raman,\nand S. Srinivasa Rao. 2005. Representing Trees of Higher Degree. Algorithmica\n43, 4 (Dec. 2005), 275â€“292.\n[10] Burton H. Bloom. 1970. Space/Time Trade-Offs in Hash Coding with Allowable\nErrors. Commun. ACM 13, 7 (July 1970), 422â€“426. https://doi.org/10.1145/362686.\n362692\n[11] Flavio Bonomi, Michael Mitzenmacher, Rina Panigrahy, Sushil Singh, and George\nVarghese. 2006. An Improved Construction for Counting Bloom Filters (ESAâ€™06) .\nSpringer-Verlag, Berlin, Heidelberg, 684â€“695. https://doi.org/10.1007/11841036_\n61\n[12] Zhichao Cao, Siying Dong, Sagar Vemuri, and David H.C. Du. 2020. Characteriz-\ning, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook.\nIn18th USENIX Conference on File and Storage Technologies (FAST 20) . USENIX\nAssociation, Santa Clara, CA, 209â€“223. https://www.usenix.org/conference/\nfast20/presentation/cao-zhichao\n[13] Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C Hsieh, Deborah A Wal-\nlach, Mike Burrows, Tushar Chandra, Andrew Fikes, and Robert E Gruber. 2008.\nBigtable: A distributed storage system for structured data. ACM Transactions on\nComputer Systems (TOCS) 26, 2 (2008), 1â€“26.\n[14] Zhenwei Dai and Anshumali Shrivastava. 2019. Adaptive Learned Bloom Filter\n(Ada-BF): Efficient Utilization of the Classifier. CoRR abs/1910.09131 (2019).\narXiv:1910.09131 http://arxiv.org/abs/1910.09131\n[15] Kyle Deeds, Brian Hentschel, and Stratos Idreos. 2021. Stacked Filters: Learning\nto Filter by Structure. Proceedings of the VLDB Endowment 14, 4 (2021), 600 â€“ 612.\n[16] Dgraph. 2017. Fast Key-value DB in Go. https://github.com/dgraph-io/badger\n[17] S. Dharmapurikar, P. Krishnamurthy, and D.E. Taylor. 2006. Longest prefix\nmatching using bloom filters. IEEE/ACM Transactions on Networking 14, 2 (2006),\n397â€“409. https://doi.org/10.1109/TNET.2006.872576\n[18] Peter C. Dillinger and Stefan Walzer. 2021. Ribbon filter: practically smaller\nthan Bloom and Xor. CoRR abs/2103.02515 (2021). arXiv:2103.02515 https:\n//arxiv.org/abs/2103.02515\n[19] Siying Dong, Andrew Kryczka, Yanqin Jin, and Michael Stumm. 2021. Evolution\nof Development Priorities in Key-value Stores Serving Large-scale Applications:\nThe{RocksDB}Experience. In 19th USENIX Conference on File and Storage\nTechnologies (FAST 21) . 33â€“49.\n[20] Bin Fan, Dave G. Andersen, Michael Kaminsky, and Michael D. Mitzenmacher.\n2014. Cuckoo Filter: Practically Better Than Bloom. In Proceedings of the 10th ACM\nInternational on Conference on Emerging Networking Experiments and Technologies\n(Sydney, Australia) (CoNEXT â€™14) . Association for Computing Machinery, New\nYork, NY, USA, 75â€“88. https://doi.org/10.1145/2674005.2674994\n[21] Edward Fredkin. 1960. Trie Memory. Commun. ACM 3, 9 (Sept. 1960), 490â€“499.\nhttps://doi.org/10.1145/367390.367400[22] Wei Ge, Xianxian Li, Chunfeng Yuan, and Yihua Huang. 2019. Correlation-Aware\nPartitioning for Skewed Range Query Optimization. World Wide Web 22, 1 (Jan.\n2019), 125â€“151. https://doi.org/10.1007/s11280-018-0547-4\n[23] Mayank Goswami, Allan GrÃ¸nlund, Kasper Green Larsen, and Rasmus\nPagh. [n.d.]. Approximate Range Emptiness in Constant Time and\nOptimal Space . 769â€“775. https://doi.org/10.1137/1.9781611973730.52\narXiv:https://epubs.siam.org/doi/pdf/10.1137/1.9781611973730.52\n[24] Thomas Mueller Graf and Daniel Lemire. 2019. Xor Filters: Faster and Smaller\nThan Bloom and Cuckoo Filters. CoRR abs/1912.08258 (2019). arXiv:1912.08258\nhttp://arxiv.org/abs/1912.08258\n[25] Stratos Idreos and Mark Callaghan. 2020. Key-value storage engines. In Proceed-\nings of the 2020 ACM SIGMOD International Conference on Management of Data .\n2667â€“2672.\n[26] Stratos Idreos, Kostas Zoumpatianos, Brian Hentschel, Michael S. Kester, and\nDemi Guo. 2018. The Data Calculator: Data Structure Design and Cost Syn-\nthesis from First Principles and Learned Cost Models. In Proceedings of the\n2018 International Conference on Management of Data (Houston, TX, USA) (SIG-\nMOD â€™18) . Association for Computing Machinery, New York, NY, USA, 535â€“550.\nhttps://doi.org/10.1145/3183713.3199671\n[27] Facebook Inc. 2012. RocksDB . https://github.com/facebook/rocksdb\n[28] Facebook Inc. 2020. Compression . https://github.com/facebook/rocksdb/wiki/\nCompression\n[29] G. Jacobson. 1989. Space-efficient static trees and graphs. In 30th Annual Sympo-\nsium on Foundations of Computer Science . 549â€“554. https://doi.org/10.1109/SFCS.\n1989.63533\n[30] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2019. SOSD: A Benchmark for Learned\nIndexes. NeurIPS Workshop on Machine Learning for Systems (2019).\n[31] Haridimos Kondylakis, Niv Dayan, Kostas Zoumpatianos, and Themis Palpanas.\n2020. Coconut Palm: Static and Streaming Data Series Exploration Now in your\nPalm. arXiv:2006.13079 [cs.DB]\n[32] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe Case for Learned Index Structures. In Proceedings of the 2018 International\nConference on Management of Data (Houston, TX, USA) (SIGMOD â€™18) . Association\nfor Computing Machinery, New York, NY, USA, 489â€“504. https://doi.org/10.\n1145/3183713.3196909\n[33] Aapo Kyrola and Carlos Guestrin. 2014. GraphChi-DB: Simple Design for a\nScalable Graph Database System â€“ on Just a PC. arXiv:1403.0701 [cs.DB]\n[34] Avinash Lakshman and Prashant Malik. 2010. Cassandra: a decentralized struc-\ntured storage system. ACM SIGOPS Operating Systems Review 44, 2 (2010), 35â€“40.\n[35] Daniel Lemire and Owen Kaser. 2016. Faster 64-bit universal hashing using carry-\nless multiplications. Journal of Cryptographic Engineering 6, 3 (2016), 171â€“185.\n[36] Siqiang Luo, Subarna Chatterjee, Rafael Ketsetsidis, Niv Dayan, Wilson Qin,\nand Stratos Idreos. 2020. Rosetta: A Robust Space-Time Optimized Range Filter\nfor Key-Value Stores. In Proceedings of the 2020 ACM SIGMOD International\nConference on Management of Data (Portland, OR, USA) (SIGMOD â€™20) . Association\nfor Computing Machinery, New York, NY, USA, 2071â€“2086. https://doi.org/10.\n1145/3318464.3389731\n[37] Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra,\nAlfons Kemper, Thomas Neumann, and Tim Kraska. 2020. Benchmarking Learned\nIndexes. Proc. VLDB Endow. 14, 1 (2020), 1â€“13.\n[38] Merriam-Webster. [n.d.]. Protean. In Merriam-Webster.com dictionary . https:\n//www.merriam-webster.com/dictionary/Protean\n[39] Michael Mitzenmacher. 2018. A Model for Learned Bloom Filters and Optimizing\nby Sandwiching. In Advances in Neural Information Processing Systems , S. Bengio,\nH. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (Eds.),\nVol. 31. Curran Associates, Inc. https://proceedings.neurips.cc/paper/2018/file/\n0f49c89d1e7298bb9930789c8ed59d48-Paper.pdf\n[40] Michael Mitzenmacher, Salvatore Pontarelli, and Pedro Reviriego. 2017. Adaptive\nCuckoo Filters. arXiv:1704.06818 [cs.DS]\n[41] Michael Mitzenmacher and Eli Upfal. 2017. Probability and computing: Random-\nization and probabilistic techniques in algorithms and data analysis . Cambridge\nuniversity press.\n[42] Andrew Pavlo, Carlo Curino, and Stanley Zdonik. 2012. Skew-Aware Automatic\nDatabase Partitioning in Shared-Nothing, Parallel OLTP Systems. In Proceed-\nings of the 2012 ACM SIGMOD International Conference on Management of Data\n(Scottsdale, Arizona, USA) (SIGMOD â€™12) . Association for Computing Machinery,\nNew York, NY, USA, 61â€“72. https://doi.org/10.1145/2213836.2213844\n[43] Swaminathan Sivasubramanian. 2012. Amazon dynamoDB: a seamlessly scal-\nable non-relational database service. In Proceedings of the 2012 ACM SIGMOD\nInternational Conference on Management of Data . 729â€“730.\n[44] Bohdan Turkynewych. 2022. Domains Project . Retrieved March 20, 2022 from\nhttps://domainsproject.org/\n[45] Kapil Vaidya, Eric Knorr, Tim Kraska, and Michael Mitzenmacher. 2020. Par-\ntitioned Learned Bloom Filter. CoRR abs/2006.03176 (2020). arXiv:2006.03176\nhttps://arxiv.org/abs/2006.03176\n[46] Cheng Xu, Ce Zhang, and Jianliang Xu. 2019. VChain: Enabling Verifiable Boolean\nRange Queries over Blockchain Databases. In Proceedings of the 2019 International\n\nProteus: A Self-Designing Range Filter SIGMOD â€™22, June 12â€“17, 2022, Philadelphia, PA, USA\nConference on Management of Data (Amsterdam, Netherlands) (SIGMOD â€™19) .\nAssociation for Computing Machinery, New York, NY, USA, 141â€“158. https:\n//doi.org/10.1145/3299869.3300083\n[47] Eleni Tzirita Zacharatou, Darius Å idlauskas, Farhan Tauheed, Thomas Heinis,\nand Anastasia Ailamaki. 2019. Efficient Bundled Spatial Range Queries. In Pro-\nceedings of the 27th ACM SIGSPATIAL International Conference on Advances\nin Geographic Information Systems (Chicago, IL, USA) (SIGSPATIAL â€™19) . As-\nsociation for Computing Machinery, New York, NY, USA, 139â€“148. https://doi.org/10.1145/3347146.3359077\n[48] Huanchen Zhang, Hyeontaek Lim, Viktor Leis, David G. Andersen, Michael\nKaminsky, Kimberly Keeton, and Andrew Pavlo. 2018. SuRF: Practical Range\nQuery Filtering with Fast Succinct Tries (SIGMOD â€™18) . Association for Comput-\ning Machinery, New York, NY, USA, 323â€“336. https://doi.org/10.1145/3183713.\n3196931",
  "textLength": 88109
}