{
  "paperId": "e42a3b4f94bb42b91adca6c4429b85fb24f9aeed",
  "title": "Learned Data Compression: Challenges and Opportunities for the Future",
  "pdfPath": "e42a3b4f94bb42b91adca6c4429b85fb24f9aeed.pdf",
  "text": "Learned Data Compression: Challenges and\nOpportunities for the Future\nQiyu Liu∗, Siyuan Han†, Jianwei Liao∗, Jin Li‡, Jingshu Peng§, Jun Du¶, Lei Chen†∥\n∗Southwest University,†HKUST,‡Harvard University,§ByteDanace,¶Hong Kong University,∥HKUST (GZ)\n{qyliu.cs, liaotoad }@gmail.com, {shanaj, leichen }@cse.ust.hk, jinli@g.harvard.edu,\njingshu.peng@bytedance.com, jundu2024@connect.hku.hk\nAbstract —Compressing integer keys is a fundamental opera-\ntion among multiple communities, such as database management\n(DB), information retrieval (IR), and high-performance comput-\ning (HPC). Recent advances in learned indexes have inspired\nthe development of learned compressors , which leverage simple\nyet compact machine learning (ML) models to compress large-\nscale sorted keys. The core idea behind learned compressors is to\nlosslessly encode sorted keys by approximating them with error-\nbounded ML models (e.g., piecewise linear functions) and using\naresidual array to guarantee accurate key reconstruction.\nWhile the concept of learned compressors remains in its\nearly stages of exploration, our benchmark results demonstrate\nthat an SIMD-optimized learned compressor can significantly\noutperform state-of-the-art CPU-based compressors. Drawing\non our preliminary experiments, this vision paper explores the\npotential of learned data compression to enhance critical areas\nin DBMS and related domains. Furthermore, we outline the key\ntechnical challenges that existing systems must address when\nintegrating this emerging methodology.\nIndex Terms —Learned Index, Data Compression, Query Pro-\ncessing, Compressed DBMS\nI. I NTRODUCTION\nA defining feature of modern data-driven systems is the\nunprecedented scale of data they manage and store [1], [2].\nAs data volumes continue to grow exponentially, the demand\nfor storage in data analytics is increasing rapidly. As illustrated\nin Figure 1, unfortunately, compared to the explosive growth\nof data, advancements in storage (in terms of cost per GiB)\nhave been far less significant. Consequently, data compression\nhas become a critical component in big data management\nand analytics, especially within resource-constrained environ-\nments [3], [4]. An effective data compression algorithm can\nsignificantly reduce I/O and communication overhead, thereby\nimproving system performance.\nThe design philosophies of compression algorithms vary\nsignificantly across different data types, such as integers,\nfloats, and strings. In this paper, we focus on lossless sorted\ninteger key compression , which is widely used in database\nsystems and information retrieval applications, such as key-\nvalue (KV) stores [5], [6], distributed systems [7], [8], inverted\nindexes [9], and vector databases [10]. Formally, the problem\nof sorted integer compression is defined as follows.\nDefinition 1 (Lossless Integer Compression) .Given a sorted\nlist of Ninteger keys K={k1, k2,···, kN}, where ki∈Z\nCorrespondence to Dr. Qiyu Liu (Email: qyliu.cs@gmail.com).\n<$100\n Device RAMCost ($)\nEmbedded \nDevicesMobile \nPhones\nPC & \nLaptops\nData Centers \n& Cloud \nPlatforms\n$500$1,000>$1M\n<4GB 16GB 1TBEdge Devices\nEfficient Query \nProcessingSeamless \nIntegrationExtreme \nCompression\nObjectives\n1PBFig. 1: (left) Illustration of the disproportionate growth be-\ntween the device memory capacities and their associated costs.\n(right) Key design objectives for a compression algorithm:\n❶high compression ratio, ❷seamless integration with existing\nsystems, and ❸efficient query processing, ideally enabling\ndirect query processing on the compressed data.\nis from a universe of U={a, a+ 1,···, b}. The problem\nof lossless integer compression is to find a compact encoding\nscheme Kctogether with a decoding function Dec(·), such that\nDec(Kc)[i] =K[i]for∀i= 1,···, N. The compression ratio\nis defined as r=size(Kc)/size(K).\nAs a classic problem, integer compression has been ex-\ntensively studied by the database, information retrieval (IR),\nand high-performance computing (HPC) communities for\ndecades, with related algorithms widely deployed in practical\nsystems. Existing solutions can be majorly classified into\nthree families: ❶Generic Integer Compression , such as\nδ-code [11], Golomb [12], [13], Rice [14], and Variable-\nByte [15], [16]; ❷Ordered List Compression : such as\nP4Delta [17], OptP4Delta [18], Elias-Fano Index [19]–[21],\nand Binary Interpolative Code (BIC) [22], [23]; and ❸En-\ntropy Encoding : such as Huffman encoding [24], Asymmetric\nNumeral System (ANS) [25], and Arithmetic coding [26]. A\nrecent experimental survey [9] systematically summarizes and\nevaluates the mainstream approaches to sorted integer list com-\npression, from the perspective of inverted index compression\nin full-text search engines.\nInspired by the seminal work on learned index [27], recent\nstudies have begun exploring the use of simple machine\nlearning (ML) models for data compression, leading to a new\nparadigm named learned compression [28], [29]. Given an in-arXiv:2412.10770v1  [cs.DB]  14 Dec 2024\n\n20 0 1 2 3 4 5 6 7 8 9 10 1112 13 14 15 16 17 18 191 3 4 7 10 14 23 25 28 31 46 50 54 56 59 63 65 68 71 75 77\nIndexKeys\n0 3 6 9 12 15 20 24 28 32 44 47 50 53 56 59 62 65 68 71 74 Prediction\n1 0 -2 -2 -2 -1 3 1 0 -1 2 3 4 3 3 4 3 3 3 4 3 ResidualFig. 2: A toy example of learned integer compressor based on an error-bounded PLA model. ❶Encoding Stage : By setting\nϵ= 4, a PLA model with 3 line segments can be fitted such that each residual |δi|=|K[i]− ⌊f(i)⌋| ≤ϵ. Segments f1, f2, f3\nand all residuals, ∆ ={1,0,···,3}, are materialized as a compressed version to the original key set {1,3,···,77}. Encoding\neach residual requires ⌈log2(2ϵ+ 1)⌉= 4bits.❷Decoding Stage : For each index i∈[0,5], the original key can be losslessly\nrecovered by K[i] =⌊f1(i)⌋+ ∆[i]. Similarly, K[i] =⌊f2(i)⌋+ ∆[i]fori∈[6,9], andK[i] =⌊f3(i)⌋+ ∆[i]fori∈[10,20].\nteger list K, learned compressors aim to directly fit a projection\nfunction f:I 7→ K with a controllable error constraint ϵ,\nwhere I={1,2,···,|K|} is the index set. With an error-\nbounded f, the sorted list Kcan be encoded as Kc= (f,∆),\nwhere ∆is an array of low-bit residuals ( ⌈log2(2ϵ+ 1)⌉\nbits) between the model’s predictions and the actual keys, i.e.,\n∆[i] =K[i]− ⌊f(i)⌋. Given Kc, the decompression, which is\nlossless , is easy as K[i] =⌊f(i)⌋+ ∆[i].\nIntuitively, the compression efficacy hinges on the ability\nof a compact model fto approximate this mapping with low\nmaximum error, requiring a careful balance between model\nsize and residual size. Boffa et al. propose la-vector [28],\n[29] as the first learned compression algorithm, building on\ntheir earlier work PGM-Index [30], [31]. Similar to the PGM-\nIndex, la-vector employs the error-bounded piecewise linear\napproximation ( ϵ-PLA) model to fit the mapping f:I 7→ K ,\nand Figure 2 illustrates a toy example of PLA-based learned\ncompression.\nUnlike learned indexes1, which have attracted significant\nattention from both academia and industry since the seminal\nwork by Kraska et al. [27], the concept of learned compres-\nsion, introduced in 2021 [29], has yet to gain widespread\nadoption or undergo thorough exploration. The core reason\nis that, compared to conventional integer compressors like\nOptP4Delta [18] and BIC [22], current learned compressors\nlikela-vector are not fully optimized and cannot show dom-\ninant performance in practice, in terms of both compression\nratio and decompression throughput. Moreover, conventional\nmethods have been deeply integrated into DBMS and full-\ntext search engines for decades, such as PostgreSQL [32],\nOracle [33], Solr [34], and Elasticsearch [35]. As a result,\npractitioners have shown limited interest in transitioning to\nthe relatively immature learned data compression techniques.\nHowever, as we will demonstrate in Section II, an opti-\nmized implementation of learned compression that fully lever-\nages the SIMD parallelism available in modern architectures\ncan achieve a comparable compression ratio while deliver-\ning SOTA decompression throughput on CPUs. Specifically,\n1As of December 1, 2024, a search for the term “learned index” on DBLP\nreturned 205 matches. Ref: https://dblp.org/search?q=learned+indexlearned compressor with SIMD achieves a throughput of\n6.535 GiB/sec, which is 1.68× faster than OptP4Delta [18]\nand 18.25× faster than BIC [22], on a web-scale inverted\nindex compression benchmark [36]. These preliminary results\nsuggest that, though requiring substantial optimization, the\nlearned data compression methodology has the potential to\nchallenge and redefine the role of widely used data compres-\nsion algorithms in modern data-intensive systems.\nWe emphasize the potential advantages of learned data\ncompression in three key aspects. ❶High Performance : a\nwell-optimized SIMD-based implementation can outperform\nthe existing CPU-based compressors. ❷Flexibility : existing\nsystems can obtain a seamless improvement by replacing\noriginal compression algorithms with learned compressors.\n❸Potential Query Support : learned compressors can be\nextended to efficiently process a wide range of queries, such\nas list intersection, union, and approximate quantiles.\nBuilding on these advantages, we claim that learned data\ncompression can serve as a new foundation for systems requir-\ning high-performance integer compression. In this vision pa-\nper, we comprehensively explore the potential applications and\ntechnical challenges of learned data compression in addressing\nconventional DB and IR problems, such as full-text search\nengines [9], [34], KV store compression [8], approximate\nquery processing [37], [38], and vector databases [10].\nThe remainder of this paper is structured as follows. Sec-\ntion II provides an overview of the preliminaries and presents\nthe motivation experiments. Section III explores how and why\nexisting DBMS and IR systems can benefit from integrating\nlearned data compression. In Section IV, we discuss the tech-\nnical challenges to be addressed to facilitate the deployment\nof this promising approach in real-world systems.\nII. L EARNED COMPRESSION FOUNDATION\nIn this section, we introduce the foundations of learned com-\npression methodology and report some preliminary benchmark\nresults for motivation.\nA. Learned Compression Methodology\nIntuitively, learning the mapping from the index space to the\nkey space, i.e., f:I 7→ K , is equivalent to learning the inverse\n\nMethodTotal Size\nGiBAvg. Size\nbits/intDec. Time\nns/intThroughput\nGiB/s\nbic 7.472 7.384 10.41 0.358\nrice 7.740 7.382 4.00 0.931\nsimple16 8.556 8.455 2.01 1.853\noptpfor 8.400 8.301 1.32 2.822\nvbyte 13.807 13.743 1.33 2.801\nopt-vbyte 9.090 8.983 0.96 3.881\nslicing 9.545 9.432 0.89 4.186\nqmx 9.817 9.701 0.74 5.034\nlc 8.947 8.841 0.81 4.599\nlc-simd 8.947 8.841 0.57 6.535\n(a) Results on dataset CCNews [36].\n1 2 3 4 5 6\nThroughput (GiB/sec)4.04.55.05.56.06.57.0Compression RatioMethods\nbic\nrice\nsimp16\noptpfor\nvbyte\nopt-vbyte\nsclicing\nqmx\nlc\nlc-simd (b) Compression ratio v.s. decompression throughput.\nFig. 3: Preliminary benchmark results for the original learned compressor implementation [28] ( lc, a.k.a. la-vector ) and our\nSIMD-based optimization ( lc-simd ). Note we enable the compiler’s auto-vectorization for lc. All the other baselines are chosen\nfrom a recent benchmark for inverted index compression [18]. All the experiments are performed on a Ubuntu machine with\nan Intel© Xeon™ Gold 6430 CPU and 512 GiB DDR5 memory.\ncumulative distribution function (ICDF, a.k.a. quantile func-\ntion) of K. To balance the model’s expressivity and inference\nefficiency, existing learned compressors like la-vector [28],\n[29] opt to employ simple models like piecewise linear func-\ntions to approximate f. The error-bounded piecewise linear\napproximation ( ϵ-PLA) model is defined as follows.\nDefinition 2 (ϵ-PLA) .Given a set of points in Cartesian\nspace {(i,K[i])}i=1,···,N⊆ I × K , anϵ-PLA is defined as\na piecewise linear function of Lline segments,\nf(i) =\n\nα1·(i−s1) +β1 ifs1≤i < s 2\nα2·(i−s2) +β2 ifs2≤i < s 3\n··· ···\nαL·(i−sL) +βL ifsL≤i(1)\nsuch that |K[i]− ⌊f(i)⌋| ≤ϵholds for ∀i= 1,···, N. Each\nsegment in fis a tuple (sj, αj, βj), where sjis the starting\nindex, αjis the slope, and βjis the intercept.\nConsider a scenario where an ϵ-PLA f, comprising L\nline segments, is fitted for a sorted key set K. The la-\nvector method losslessly encodes KasKc= (f,∆)where\n∆ ={K[i]−⌊f(i)⌋ |i= 1,···N}. Since fis error-bounded,\neach residual satisfies ∆[i]∈[−ϵ,+ϵ]. Thus, encoding each\nresidual requires ⌈log2(2ϵ+ 1)⌉bits, and the total bits can be\nexpressed as size(Kc) =size(f) +N· ⌈log2(2ϵ+ 1)⌉, where\nsize(f)is the bits required to encode f. For uint32 keys and\nfloat32 slopes/intercepts, encoding each segment requires 12\nbytes, meaning that size(f) = 96 Lbits. To efficiently learn\nfsatisfying a given error constraint, [28], [29] employ an\noptimal online ϵ-PLA fitting algorithm [39] to minimize the\nnumber of required line segments Lin linear time O(N).\nSimilar to conventional compressors, learned compressors\nneed to tune hyper-parameters (i.e., ϵin PLA) to achieve\noptimal performance. Intuitively, the choice of ϵis a trade-off:\na large ϵreduces the required segment count but increases the\nbits needed per residual, while a small ϵsaves bits per residual\nat the cost of introducing more segments to satisfy the error\nconstraint. Building on the theoretical foundations of learned\nindexes [30], [31], [40], a recent study BitTuner [41] derivesthe minimized total space cost of a learned compressor based\nonϵ-PLA as Bopt≈N·(1.721 + ⌈log2ϵopt⌉), where the corre-\nsponding ϵoptis given by ϵopt=p\n2 ln 2·σ2·C·(K+ 2F).\nHere, σ2is the variance of key gaps (i.e., K[i]− K[i−1]),C\nis a data-dependent constant, and KandFdenote the number\nof bits to encode an integer (i.e., keys) and a float (i.e., slopes\nand intercepts), respectively.\nB. Connection with Learned Index\nAlthough learned indexing and learned compression appear\nsimilar, their design objectives exhibit fundamental differ-\nences. Intuitively, learned indexing and learned compression\nare“dual” problems. Given a sorted key set K, learned indexes\nlike [27], [30], [42] model the cumulative distribution function\n(CDF) of K(i.e., the mapping of g:K 7→ I ), whereas learned\ncompression [28], [29] tries to fit the inverse CDF (i.e., the\nmapping of f:I 7→ K ), a.k.a. the quantile function [43].\nThe key differences between learned indexing and learned\ncompression are threefold. ❶Theoretical Foundation : intu-\nitively, when the data universe is large, learning the ICDF is\nmore challenging than learning the CDF; conversely, when\nthe universe is small, learning the CDF becomes more dif-\nficult [28], [31], [41]. ❷Data Structure : learned indexes\nlike RMI [27] and PGM-Index [30] are typically hierarchical\nstructures optimized to reduce lookup latency. In contrast,\nlearned compressors employ a flat structure (i.e., one level) to\nsave space. ❸Query Support : learned indexes are designed as\nalternatives for conventional B+-tree indexes [44], necessitat-\ning efficient support for lookup and range queries. On the other\nhand, learned compressors primarily focus on decompression\noperations (i.e., reconstructing K[i]). Supporting additional\nqueries, such as intersection, union, or rank, requires further\nalgorithmic and engineering efforts.\nC. Preliminary Benchmark Results\nAs discussed in Section I, the first learned compressor la-\nvector [28], [29] cannot significantly outperform conventional\nmethods in terms of compression ratio and decompression\n\nefficiency. After carefully revisiting the workflow of PLA-\nbased learned compressors, we propose SIMD-aware opti-\nmizations to fully exploit the hardware parallelism available\non most modern architectures2. It is important to note that our\nimplementation is not an embarrassingly parallel algorithm, as\nit incorporates techniques such as task decomposition, operator\nfusion, and memory alignment. The technical details of SIMD\noptimization can be found in [45].\nWe evaluate our learned compressor implementation using\na benchmark designed for inverted index compression [9].\nEight integer compressors are adopted as baselines, covering\nmainstream methodologies employed in practical systems. All\nthe compared methods are implemented in C++ and compiled\nwith g++ using the -O3 optimization, with auto-vectorization\nenabled. The results on a large-scale document inverted index\ncompression task, CCNews [36] (approx. 53 GiB of integer\ndocument IDs), are presented in Figure 3. As seen in Figure 3a,\nthe learned compressor with SIMD optimization (i.e., lc-simd )\nachieves a decompression throughput of 6.535 GiB/s , which\nis18.254× ,2.316× ,2.333× , and 1.298× faster than BIC [13],\nOptP4Delta [18], Variable-Byte [15], and QMX [46], respec-\ntively. Notably, most of the compared methods are also highly\noptimized using SIMD. Specifically, lc-simd is1.421× faster\nthanlc, which is essentially the la-vector [28], [29] optimized\nwith compiler’s auto-vectorization. Figure 3b further visual-\nizes the trade-off between compression ratio and decompres-\nsion throughput for each method, highlighting that lc-simd\nachieves comparable compression power while delivering the\nhighest throughput among all CPU-based baselines. Results\non other datasets exhibit similar trends and are excluded from\nthis paper for brevity.\nIn summary, this preliminary benchmark study reveals that\nwith proper low-level optimizations, the learned compressor\ncan emerge as a strong competitor, challenging the conven-\ntional compression algorithms used for decades. Moreover, our\nlc-simd implementation can be further enhanced by consid-\nering better memory alignment and pre-fetching [47]. In the\nsubsequent sections, we will discuss optimization opportuni-\nties and technical challenges to deploy this emerging technique\nin practical DBMS and information retrieval systems.\nIII. A PPLICATION SCENARIOS\nIn this section, we explore potential application scenarios\nthat can benefit from the high performance of learned com-\npression methodologies.\nA. Inverted Index Compression\nThe inverted index (a.k.a. inverted lists or posting lists) in\nfull-text search engines like Solr [34] and Elasticsearch [35]\nrepresents a key application of integer compression. Given\na collection of documents, each distinct term tis associated\n2Customer-grade CPUs like Intel© Core™ and AMD© Ryzen™ typically\nprovide 256-bit SIMD registers (i.e., A VX2), while enterprise CPUs like In-\ntel© Xeon™ are equipped with wider 512-bit SIMD registers (i.e., A VX512).\nBesides SIMD parallelism on X86 platforms, we also plan to release an ARM-\nbased version and a GPU-accelerated version in the future.\n1 3 4 7 10 14 23 25 28 31 46 507 23 31(a) Illustration of skip pointers.\n1 3 4 7 10 14 23 25 28 31 46 50\nPossible Range: [-4, 19] Possible Rnage: [16, 36]\n(b) Illustration of segment-based pruning.\nFig. 4: (a) Skip pointers in conventional inverted index designs.\n(b) Natural pruning support in learned compressors. The\npossible key range covered by a line segment is known due\nto the error-bounded nature of an ϵ-PLA.\nwith an inverted index It, which is an ordered list of integers\nstoring the identifiers of the documents where tappears [48].\nFor web-scale document collections, the raw size of inverted\nindexes can easily scale to hundreds of gigabytes. As a result,\ncompressing inverted indexes is necessary to reduce memory\nfootprint and improve query throughput [9].\nList intersection (AND queries) and list union (OR queries)\nare fundamental operations for learned compressors to ensure\ncompatibility with existing full-text search engines. Fortu-\nnately, learned compressors inherently support these queries\nefficiently by utilizing segment-level pruning. As illustrated\nin Figure 4a, traditional compressors such as P4Delta [17]\nand Elias-Fano Index [21] often implement auxiliary shortcuts\ncalled “skip pointers” that bypass sections of inverted lists\nthat do not appear in the final query results. While skip\npointers improve query performance, they inevitably introduce\nadditional space overhead. On the other hand, PLA-based\nlearned compressors eliminate the need for such auxiliary\nstructures. As shown in Figure 4b, each segment in a learned\ncompressor naturally encodes the possible range of its covered\nkeys, thus effectively performing the same function as skip\npointers without incurring extra space costs.\nB. KV Store Compression\nKey-value (KV) storage is a popular DBMS paradigm\nwhere key-value pairs are treated as first-class citizens. The\nunderlying storage layer of modern KV systems is the log-\nstructured merge tree (LSM-tree), which buffers all writes into\nan in-memory structure (MemTable) before flushing them to\nfiles on disk (SSTable) and merging them through sequential\nI/Os [6], [49], [50]. This design offers several key advan-\ntages, including enhanced write performance, efficient space\nutilization, and simplified concurrency control and recovery\nmechanisms, making KV systems particularly suitable for\ncaching, session management, and real-time analytics.\nIn practical KV systems like Redis [51], LevelDB [52],\nand RocksDB [5], the key blocks and data blocks within an\nSSTable are often compressed to further reduce I/Os3. Current\n3https://github.com/facebook/rocksdb/wiki/Compression\n\nsystems commonly employ generic byte-stream compressors,\nsuch as LZ4 [53] and Snappy [54], which are known to be\nmore suitable for textual data rather than integer lists.\nAs highlighted in Section II-C, learned compressors offer\nsuperior compression efficacy and decompression throughput,\nmaking them a compelling alternative to conventional methods\nused for decades. For example, LevelDB [52] uses Snappy [54]\nas the default compressor, with a decompression through-\nput of 546 MB/s . In contrast, the SIMD-optimized learned\ncompressor delivers a much better compression ratio and a\n12.26× higher throughput of 6.535 GiB/s , according to our\npreliminary benchmark results in Section II-C.\nIntegrating learned compressors into practical KV stores\nrequires efficient support for merge operations, a.k.a. the\ncompaction operations in LSM-trees. A merge operation com-\nbines two compressed sorted key sets into a single one while\nmaintaining the order. A key technical challenge here lies in\ndynamically adjusting the error constraint ϵto accommodate\nthe new data distribution resulting from the merging operation.\nAdditionally, to boost read requests in KV systems, auxiliary\nindex structures (e.g., compact B+-tree variants [48] or learned\nindexes [27]) are necessary to enable fast localization of the\ncorresponding line segment for a given key.\nC. DBMS Query Processing\nLearned compressors also hold substantial potential for tra-\nditional DBMS workloads, such as analytical query processing\nand large-scale distributed join acceleration.\nAs introduced in Section II, a learned compressor encodes\nthe inverse CDF (ICDF) of a given key set in an error-bounded\nand space-efficient manner. Thus, learned compressors can be\ndirectly applied to process QUANTILE queries and MEDIAN\nqueries (a special case of QUANTILE ), which are common\nyet costly operators in analytical workloads [55]. For example,\ngiven a learned compressor Kc= (f,∆), the k-thq-quantile\ncan be computed by f(⌊N·k/q⌋) + ∆[ ⌊N·k/q⌋]. Based\non the previous theoretical results [28], [31], in Table I, we\nsummarize the space and time complexities for using learned\ncompressors to compute arbitrary quantiles, contrasted with\nthe commonly used quick select algorithm [56].\nMethod Space Complexity Time Complexity\nLC(exact) O(N/ϵ2+N·logϵ) O(log(N/ϵ2))\nLC(approx.) O(N/ϵ2) O(log(N/ϵ2))\nQuickSel [56] O(N) Avg.O(N)\nTABLE I: Complexities to compute quantile queries. The\nlogarithmic term in the time complexity comes from finding\nthe corresponding segment using binary search.\nNotably, when query accuracy requirements can be relaxed,\nthe residuals ∆for lossless reconstruction can be omitted,\nenabling approximate query processing (AQP) with a max-\nimum error bounded by ϵ. This adjustment yields a more\ncompact representation consisting solely of segments , offering\nflexibility to adapt learned compressors to the specific needs\nof analytical workloads. Additionally, it would be interesting\n...VQ\n(a) Dense vectors. (b) Discrete codebook.Fig. 5: Illustration of a vector quantizer (VQ). When product\nquantization (PQ) is applied, dense vectors are partitioned into\nsubspaces and clustered within each subspace. Each integer in\nthe learned codebook corresponds to a cluster ID.\nto integrate the learned structures with conventional data\nsummary techniques designed for AQP [55].\nAnother promising direction for future exploration is the\nintegration of learned compressors with join processing. In\ndistributed environments, space-efficient filters like Bloom\nfilters [57], [58] are widely used to reduce communication\ncosts, as exemplified by the BloomJoin technique [59], [60].\nTo compute R1⋊ ⋉R2where relations R1andR2reside on\ndifferent sites, the BloomJoin technique involves three steps:\n❶Site 1 creates a Bloom filter BF(R1)on the join attribute of\nR1and sends it to site 2. ❷Site 2 filters R2by using BF(R1)\nand sends back tuples R12with matched join attribute to R1.\n❸Finally, site 1 produces the final join result by joining R1\nwithR12using local join algorithms like merge join.\nAs a compact data representation, learned compressors can\nalso function as effective data filters, akin to BF(R1)in\nBloomJoin. It would be interesting to benchmark the filtering\nefficacy of learned compressors under varying space con-\nstraints when compared to Bloom filters and their variants [57],\n[61], [62]. A key technical challenge lies in the dependency\nof learned compressor performance on the key distribution\ncharacteristics, which can vary significantly for arbitrary SPJ\n(select-project-join) queries4. To mitigate the risk of inconsis-\ntent performance, a possible solution is to integrate learned\ncompressors with conventional Bloom filters or recent learned\nBloom filters [62], [63]. This hybrid approach leverages the\nstrengths of both techniques to ensure robust and efficient\nquery processing.\nD. Vector Database Compression\nThe rapid advancements of retrieval-augmented generation\n(RAG) have recently sparked renewed interest in approximate\nnearest neighbor (ANN) search and VectorDB [64]. Due to\nthe inefficiencies associated with storing and querying raw\ndense vectors in terms of both space and time, modern\nVectorDBs, such as Milvus [65] and Pinecone [66], often\nemploy coarse vector quantization (VQ) techniques, such as\nPQ [67], OPQ [68], and AQ [69]. As illustrated in Figure 5,\nthese methods represent dense vectors as discrete and compact\n4Notably, this limitation is not unique to learned compressors but applies\nto all compression algorithms, as higher information entropy in a dataset\ninherently makes it harder to compress.\n\nrepresentations (commonly referred to as codewords) while\npreserving the essential distance information.\nHowever, for web-scale vector sets, these compact code-\nbooks remain too large, making it hard to deploy on resource-\nconstrained devices, such as mobile phones or personal lap-\ntops. A recent study DeltaPQ [70] attempts to compress\nVQ codebooks by exploring redundancies residing in code-\nwords. Given the compression efficacy and high decompres-\nsion throughput of learned compressors on integers, a promis-\ning approach is to reorder the codebook and apply learned\ncompressors, potentially leading to a more compact vector\nrepresentation while maintaining query efficiency. A promising\nresearch direction involves extending existing codebook traver-\nsal algorithms, such as PQFS [71] and Quicker ADC [71],\nto accommodate compressed VQ codebooks. Furthermore, it\nwould also be interesting to explore the potential of applying\nthe “learned” methodology to compress other widely-used\nANN indexes, such as graph-based indexes like HNSW [72]\nand locality-sensitive hashing (LSH) techniques [73].\nE. Storage Mapping Table Compression\nLastly, learned compressors also exhibit potential in low-\nlevel system optimizations. In main memory and secondary\nstorage of computing systems [74]–[76], mapping table en-\ntries that map logical addresses to physical addresses can\nbe intercepted and compressed into compression units, and\neach unit can hold multiple mapping table entries [77]. The\nlearned compressor aims to further improve compression and\ndecompression efficiency, which can be naturally deployed in\nthose existing approaches, for not only saving the space to\nhold the mapping table entries, but also speeding up address\ntranslation, since it requires fewer operations on fetching the\nentries and less time overhead for decompression.\nIV. T ECHNICAL CHALLENGES AND FUTURE DIRECTIONS\nThough learned compressors exhibit significant potential\nacross various domains, they also present critical technical\nchallenges that simultaneously serve as research opportunities\nfor deeper exploration.\nA. Hyper-parameter Tuning\nAs outlined in Section II, the error constraint ϵis critical\nin determining the overall space cost of learned compres-\nsors. Assuming that all keys are i.i.d. samples from the\nsame distribution, a recent work, BitTuner [41], derives a\nclosed-form solution for minimizing the total space cost as\nϵopt=p\n2 ln 2·σ2·C·(K+ 2F). However, the statistical\nassumption might be too strong in real applications, making a\nglobal hyper-parameter configuration sub-optimal.\nA possible solution is to adaptively partition the data into\nconsecutive, disjoint partitions, with ϵconfigured individually\nfor each partition [20], [28], [29]. As illustrated in Figure 6,\nsuch a data partition problem can be modeled as a graph\nG= (V, E), where each node represents a key ki, and each\nedge ki→kj(j > i ) corresponds to a partition range [i, j).\nBy assigning edge weight based on the space cost of a learned\nAn integer key \nA partition from\n to Fig. 6: A graph model of the key partition problem. The path in\nredk1→k3→k6implies partitioning {k1, k2, k3, k4, k5, k6}\ninto two parts {k1, k2}and{k3, k4, k5, k6}.\ncompressor trained on the corresponding partition, the optimal\npartitioning can be obtained by finding the shortest path from\nk1tokN. As|V|= Θ( N)and|E|= Θ( N2), a standard\nDijkstra’s algorithm yields a time complexity of O(N2),\nwhich is intractable for large-scale applications. Though linear\ntime approximations are investigated in [20], [28], [29], their\nperformance is still costly, given that fitting an optimal PLA\nonly requires linear time [39]. Therefore, developing effective\nparameter tuning strategies that balance efficiency and effec-\ntiveness remains a challenging yet promising area of research.\nB. Handling Dynamic Updates\nA well-known technical challenge for learned indexes is\nhandling dynamic operations, such as insertions, deletions, or\nmodifications [42], [78]. The core difficulty lies in the need to\npromptly update outdated ML models to prevent performance\ndegradation. Similarly, as learned compressors also incorporate\nML models into their design, they inherit the same challenge\nof being difficult to update.\nExisting updatable learned index structures, such as\nALEX [42], usually adopt a “gapped array” design, which\nreserves empty cells within the underlying key storage to en-\nable efficient updates. However, this approach is incompatible\nwith learned compressors, as the objective of compression is to\nrepresent data as compactly as possible, which fundamentally\nconflicts with the gapped array design. Moreover, when han-\ndling dynamic updates, not only does the model itself require\nupdates, but the hyper-parameters of the learned compressor\n(e.g., the error constraint ϵ), also need to be accordingly\nadjusted to accommodate data distribution shifts after updates.\nIn the worst case, updating either the ML models (e.g.,\nPLA) or the hyper-parameters may necessitate a complete re-\nconstruction of the learned compressor, which can be compu-\ntationally expensive. Consequently, devising effective update\nstrategies is a critical technical challenge for deploying learned\ncompressors in real-world systems with intensive data updates.\nC. Generic ML Model Choice\nRecall that the basic idea behind learned compressors is\nData = Model Predictions + Residuals . The ML model\nfunctions as a coarser predictor to reduce the residual range,\nsuch that each residual can be encoded using only a few bits.\nAs introduced in Section II, existing learned compressors com-\nmonly adopt the error-bounded piecewise linear approximation\n(ϵ-PLA) model. The reasons are mainly twofold. ❶Linear\nfunctions are simple to implement and computationally effi-\ncient compared to more complex models, particularly those\n\nDevice MemoryGPU MemoryGPU Cache\nDDR5: 40 GiB/s (512 GiB)HBM: 1.6 TiB/s (40 GiB)SRAM: 19 TiB/s (20 MB)(a) GPU memory hierarchy that highlights memory\nbandwidth and size.\nFP16/BF16\nFP16/BF16FP32\nFP32\n(b) Tensor Cores on the NVIDIA A100 GPU. Each\nTensor Core performs 64mixed-precision floating-point\nfused multiply-add (FMA) operations per cycle .\nFig. 7: Illustration of the GPU architecture characteristics.\nrelying on heavy deep learning frameworks like PyTorch.\n❷Theoretical results from learned indexes using linear mod-\nels, such as those in [31], [40], can be extended to prove the\neffectiveness of learned compressors.\nClearly, a design trade-off exists here. Simpler models, such\nas linear models, are easier to implement, well-supported by\ntheoretical results, and benefit from a wide range of optimiza-\ntions like [39]. However, more expressive models have the\npotential to achieve a better trade-off between fitting error and\nmodel complexity. It would be interesting to establish new\ntheoretical results for non-linear base models (e.g., piecewise\npolynomial functions) and to develop efficient training and\ninference algorithms for such models5. Moreover, given the\ndual relationship between learned compression and learned\nindexing, new theoretical findings could also inspire the design\nof next-generation learned index structures.\nD. Extension to Floating-Point Data Compression\nLearned compressors are specifically designed for integer\ndata. However, in other domains, such as scientific computing\nand sensor data analytics, users often work with floating-point\ndata of bounded precision [79]. For example, a typical GPS de-\nvice generates data ranging from −180.0000 to180.0000 , and\na resistance thermometer records temperature data within the\nrange of −50.000◦C to 100.000◦C. Existing solutions [79]–\n[81] often employ quantization and dictionary encoding to\ncompress large-scale floating-point values.\nAccording to the IEEE standard [82], a floating value is\ndefined as (−1)sign×1.mantissa ×2exponent, where the number\nof bits allocated to the mantissa and exponent determines\nthe precision. To adapt learned compressors for bounded\nfloats, a straightforward approach is to separately compress\nthe mantissa and exponent, each of which can be treated\nas an integer, using learned compressors. However, three\n5Intrinsically, the problem is to explore the learning theory on the hardness\nof fitting an ICDF within an arbitrary error constraint.technical questions here require further investigation. ❶Can\nthis approach achieve comparable performance to compressing\ninteger data? ❷Scientific computing workloads often require\nin situ query processing [83]. How can direct query processing\non compressed data be enabled to maintain compatibility with\nexisting applications? ❸If some level of floating-point preci-\nsion can be sacrificed, could this trade-off result in significant\ngains in compression ratios and decompression performance?\nE. Acceleration using Modern Hardware\nAlthough initially designed as accelerators for rendering,\nGPUs are playing an increasingly important role in AI model\ntraining and high-performance computing. Due to the highly\nmulti-threaded architecture, GPUs can accelerate a wide range\nof classic data-centric tasks, such as sorting [84], [85], query\nprocessing [86], and indexing [87], [88]. Given that our SIMD-\noptimized learned compressor already outperforms CPU base-\nlines, extending it to the GPU’s single-instruction multiple-\nthread (SIMT) operating model presents a promising avenue\nfor further performance enhancement.\nTo align with the characteristics of GPU architectures (as\nillustrated in Figure 7), we outline key optimizations to be\nexplored as follows. ❶To fully leverage the GPU’s highly\nmulti-threaded design, it is necessary to further reduce the data\ndependencies inherent in learned compressors to maximize\nparallelism. ❷Similar to the SIMD case, memory access\nlatency constitutes a significant portion of the total compu-\ntational overhead. Refining the learned compressor’s structure\nto better align with the GPU memory hierarchy is essential for\nachieving better performance. ❸Modern GPUs like NVIDIA\nA100 are equipped with Tensor Cores capable of operating 64\nfused multiply-add (FMA, i.e., D←A×B+C) operations per\nclock. This hardware capability is well-suited to PLA-based\nlearned compressors, given that key recovery is to compute\n⌊α·(i−s) +β⌋+ ∆[i]. However, as depicted in Figure 7b,\nthe Tensor Cores are designed for mixed-precision AI model\ntraining, where A,Bare matrices of FP16/BP16 floats while\nC,Dare matrices of FP32 floats. Therefore, addressing the\nnumerical issues introduced by mixed-precision computation\nwill emerge as a technical challenge for future research.\nV. C ONCLUSION\nCompressing integer keys is fundamental across diverse\nscenarios, spanning from low-level system optimizations to\nhigh-level data-driven applications. While research on learned\ncompressors is still in its infancy, our preliminary bench-\nmarks highlight that an SIMD-optimized learned compressor\ncan significantly outperform conventional data compression\nalgorithms. Building on these findings, this paper envisions\na future where learned compression techniques become vital\ncomponents of modern database and information retrieval\nsystems. However, despite their significant potential, learned\ncompressors face critical technical challenges that also present\ncompelling research opportunities, paving the way for deeper\nexploration and innovation in this emerging field.\n\nREFERENCES\n[1] V . Marx, “The big challenges of big data,” Nature , vol. 498, no. 7453,\npp. 255–260, 2013.\n[2] O. Trelles, P. Prins, M. Snir, and R. C. Jansen, “Big data, but are we\nready?” Nature Reviews Genetics , vol. 12, no. 3, pp. 224–224, 2011.\n[3] M. Satyanarayanan, “Mobile computing: the next decade,” ACM SIG-\nMOBILE Mobile Computing and Communications Review , vol. 15, no. 2,\npp. 2–10, 2011.\n[4] L. Lin, X. Liao, H. Jin, and P. Li, “Computation offloading toward edge\ncomputing,” Proceedings of the IEEE , vol. 107, no. 8, pp. 1584–1607,\n2019.\n[5] “RocksDB,” https://rocksdb.org/, accessed: 2024-10-20.\n[6] C. Luo and M. J. Carey, “Lsm-based storage techniques: a survey,” The\nVLDB Journal , vol. 29, no. 1, pp. 393–418, 2020.\n[7] M. T. ¨Ozsu, P. Valduriez et al. ,Principles of distributed database\nsystems . Springer, 1999, vol. 2.\n[8] R. Geambasu, A. A. Levy, T. Kohno, A. Krishnamurthy, and H. M.\nLevy, “Comet: An active distributed {Key-Value }store,” in 9th USENIX\nSymposium on Operating Systems Design and Implementation (OSDI\n10), 2010.\n[9] G. E. Pibiri and R. Venturini, “Techniques for inverted index compres-\nsion,” ACM Computing Surveys (CSUR) , vol. 53, no. 6, pp. 1–36, 2020.\n[10] J. J. Pan, J. Wang, and G. Li, “Survey of vector database management\nsystems,” The VLDB Journal , vol. 33, no. 5, pp. 1591–1615, 2024.\n[11] P. Elias, “Universal codeword sets and representations of the integers,”\nIEEE transactions on information theory , vol. 21, no. 2, pp. 194–203,\n1975.\n[12] S. Golomb, “Run-length encodings (corresp.),” IEEE transactions on\ninformation theory , vol. 12, no. 3, pp. 399–401, 1966.\n[13] J. Teuhola, “A compression method for clustered bit-vectors,” Informa-\ntion processing letters , vol. 7, no. 6, pp. 308–311, 1978.\n[14] R. Rice and J. Plaunt, “Adaptive variable-length coding for efficient\ncompression of spacecraft television data,” IEEE Transactions on Com-\nmunication Technology , vol. 19, no. 6, pp. 889–897, 1971.\n[15] A. A. Stepanov, A. R. Gangolli, D. E. Rose, R. J. Ernst, and P. S. Oberoi,\n“Simd-based decoding of posting lists,” in Proceedings of the 20th ACM\ninternational conference on Information and knowledge management ,\n2011, pp. 317–326.\n[16] J. Dean et al. , “Challenges in building large-scale information retrieval\nsystems,” in Keynote of the 2nd ACM international conference on web\nsearch and data mining (WSDM) , vol. 10, no. 1498759.1498761, 2009.\n[17] M. Zukowski, S. Heman, N. Nes, and P. Boncz, “Super-scalar ram-\ncpu cache compression,” in 22nd International Conference on Data\nEngineering (ICDE’06) . IEEE, 2006, pp. 59–59.\n[18] H. Yan, S. Ding, and T. Suel, “Inverted index compression and query\nprocessing with optimized document ordering,” in Proceedings of the\n18th international conference on World wide web , 2009, pp. 401–410.\n[19] P. Elias, “Efficient storage and retrieval by content and address of static\nfiles,” Journal of the ACM (JACM) , vol. 21, no. 2, pp. 246–260, 1974.\n[20] G. Ottaviano and R. Venturini, “Partitioned elias-fano indexes,” in Pro-\nceedings of the 37th international ACM SIGIR conference on Research\n& development in information retrieval , 2014, pp. 273–282.\n[21] S. Vigna, “Quasi-succinct indices,” in Proceedings of the sixth ACM\ninternational conference on Web search and data mining , 2013, pp. 83–\n92.\n[22] A. Moffat and L. Stuiver, “Exploiting clustering in inverted file compres-\nsion,” in Proceedings of Data Compression Conference-DCC’96 . IEEE,\n1996, pp. 82–91.\n[23] ——, “Binary interpolative coding for effective index compression,”\nInformation Retrieval , vol. 3, pp. 25–47, 2000.\n[24] D. A. Huffman, “A method for the construction of minimum-redundancy\ncodes,” Proceedings of the IRE , vol. 40, no. 9, pp. 1098–1101, 1952.\n[25] J. Duda, “Asymmetric numeral systems: entropy coding combining\nspeed of huffman coding with compression rate of arithmetic coding,”\narXiv preprint arXiv:1311.2540 , 2013.\n[26] A. Moffat, R. M. Neal, and I. H. Witten, “Arithmetic coding revisited,”\nACM Transactions on Information Systems (TOIS) , vol. 16, no. 3, pp.\n256–294, 1998.\n[27] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis, “The case\nfor learned index structures,” in Proceedings of the 2018 international\nconference on management of data , 2018, pp. 489–504.[28] A. Boffa, P. Ferragina, and G. Vinciguerra, “A learned approach to\ndesign compressed rank/select data structures,” ACM Transactions on\nAlgorithms (TALG) , vol. 18, no. 3, pp. 1–28, 2022.\n[29] ——, “A “learned” approach to quicken and compress rank/select dictio-\nnaries,” in 2021 Proceedings of the Workshop on Algorithm Engineering\nand Experiments (ALENEX) . SIAM, 2021, pp. 46–59.\n[30] P. Ferragina and G. Vinciguerra, “The pgm-index: a fully-dynamic com-\npressed learned index with provable worst-case bounds,” Proceedings of\nthe VLDB Endowment , vol. 13, no. 8, pp. 1162–1175, 2020.\n[31] P. Ferragina, F. Lillo, and G. Vinciguerra, “Why are learned indexes so\neffective?” in International Conference on Machine Learning . PMLR,\n2020, pp. 3123–3132.\n[32] “PostgreSQL,” https://www.postgresql.org/, accessed: 2024-10-20.\n[33] “Oracle,” https://www.oracle.com/, accessed: 2024-10-20.\n[34] “Apache Solr,” https://solr.apache.org/, accessed: 2024-10-20.\n[35] “Elasticsearch: The Official Distributed Search & Analytics Engine,”\nhttps://www.elastic.co/elasticsearch, accessed: 2024-10-20.\n[36] J. Mackenzie, R. Benham, M. Petri, J. R. Trippas, J. S. Culpepper, and\nA. Moffat, “Cc-news-en: A large english news corpus,” in Proc. CIKM ,\n2020, pp. 3077–3084.\n[37] S. Chaudhuri, B. Ding, and S. Kandula, “Approximate query process-\ning: No silver bullet,” in Proceedings of the 2017 ACM International\nConference on Management of Data , 2017, pp. 511–519.\n[38] G. Cormode, “Sketch techniques for approximate query processing,”\nFoundations and Trends in Databases. NOW publishers , vol. 15, 2011.\n[39] J. O’Rourke, “An on-line algorithm for fitting straight lines between data\nranges,” Commun. ACM , vol. 24, no. 9, pp. 574–578, 1981.\n[40] Q. Liu, S. Han, Y . Qi, J. Peng, J. Li, L. Lin, and L. Chen, “Why are\nlearned indexes so effective but sometimes ineffective?” arXiv preprint\narXiv:2410.00846 , 2024.\n[41] “BitTuner,” https://github.com/qyliu-hkust/BitTuner, accessed: 2024-10-\n20.\n[42] J. Ding, U. F. Minhas, J. Yu, C. Wang, J. Do, Y . Li, H. Zhang,\nB. Chandramouli, J. Gehrke, D. Kossmann et al. , “Alex: an updatable\nadaptive learned index,” in Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data , 2020, pp. 969–984.\n[43] R. J. Serfling, Approximation theorems of mathematical statistics . John\nWiley & Sons, 2009.\n[44] G. Graefe et al. , “Modern b-tree techniques,” Foundations and Trends®\nin Databases , vol. 3, no. 4, pp. 203–402, 2011.\n[45] “SALAD: SIMD-Aware Learned Data Compression,” https:\n//github.com/qyliu-hkust/salad/tree/PGM-INDEX-SIMD-TEMP,\naccessed: 2024-10-20.\n[46] A. Trotman and J. Lin, “In vacuo and in situ evaluation of simd\ncodecs,” in Proceedings of the 21st Australasian Document Computing\nSymposium , 2016, pp. 1–8.\n[47] J. Lee, H. Kim, and R. Vuduc, “When prefetching works, when\nit doesn’t, and why,” ACM Transactions on Architecture and Code\nOptimization (TACO) , vol. 9, no. 1, pp. 1–29, 2012.\n[48] A. Singhal et al. , “Modern information retrieval: A brief overview,”\nIEEE Data Eng. Bull. , vol. 24, no. 4, pp. 35–43, 2001.\n[49] P. O’Neil, E. Cheng, D. Gawlick, and E. O’Neil, “The log-structured\nmerge-tree (lsm-tree),” Acta Informatica , vol. 33, pp. 351–385, 1996.\n[50] A. Huynh, H. A. Chaudhari, E. Terzi, and M. Athanassoulis, “Towards\nflexibility and robustness of lsm trees,” The VLDB Journal , pp. 1–24,\n2024.\n[51] “Redis,” https://redis.io/, accessed: 2024-10-20.\n[52] “LevelDB,” https://github.com/google/leveldb, accessed: 2024-10-20.\n[53] “Etremely fast compression,” https://lz4.org/, accessed: 2024-06-12.\n[54] “Snappy: A fast compressor/decompressor,” https://google.github.io/\nsnappy/, accessed: 2024-06-12.\n[55] Z. Chen and A. Zhang, “A survey of approximate quantile computation\non large-scale data,” IEEE Access , vol. 8, pp. 34 585–34 597, 2020.\n[56] C. A. Hoare, “Algorithm 65: find,” Communications of the ACM , vol. 4,\nno. 7, pp. 321–322, 1961.\n[57] D. Guo, J. Wu, H. Chen, and X. Luo, “Theory and network applications\nof dynamic bloom filters,” in Proceedings IEEE INFOCOM 2006.\n25TH IEEE International Conference on Computer Communications .\nCiteseer, 2006, pp. 1–12.\n[58] H. Lang, T. Neumann, A. Kemper, and P. Boncz, “Performance-optimal\nfiltering: Bloom overtakes cuckoo at high throughput,” Proceedings of\nthe VLDB Endowment , vol. 12, no. 5, pp. 502–515, 2019.\n\n[59] L. F. Mackert and G. M. Lohman, “R* optimizer validation and\nperformance evaluation for local queries,” in Proceedings of the 1986\nACM SIGMOD international conference on Management of data , 1986,\npp. 84–95.\n[60] Z. Li and K. A. Ross, “Perf join: An alternative to two-way semijoin\nand bloomjoin,” in Proceedings of the fourth international conference\non Information and knowledge management , 1995, pp. 137–144.\n[61] L. Luo, D. Guo, R. T. Ma, O. Rottenstreich, and X. Luo, “Optimizing\nbloom filter: Challenges, solutions, and comparisons,” IEEE Communi-\ncations Surveys & Tutorials , vol. 21, no. 2, pp. 1912–1949, 2018.\n[62] Q. Liu, L. Zheng, Y . Shen, and L. Chen, “Stable learned bloom filters\nfor data streams,” Proceedings of the VLDB Endowment , vol. 13, no. 12,\npp. 2355–2367, 2020.\n[63] M. Mitzenmacher, “A model for learned bloom filters and optimizing\nby sandwiching,” Advances in Neural Information Processing Systems ,\nvol. 31, 2018.\n[64] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\nH. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel et al. , “Retrieval-\naugmented generation for knowledge-intensive nlp tasks,” Advances in\nNeural Information Processing Systems , vol. 33, pp. 9459–9474, 2020.\n[65] “The high-performance vector database built for scale,” https://milvus.\nio/, accessed: 2024-06-12.\n[66] “Pinecone: The vector database to build knowledgeable AI,” https:\n//www.pinecone.io/, accessed: 2024-06-12.\n[67] H. Jegou, M. Douze, and C. Schmid, “Product quantization for nearest\nneighbor search,” IEEE transactions on pattern analysis and machine\nintelligence , vol. 33, no. 1, pp. 117–128, 2010.\n[68] T. Ge, K. He, Q. Ke, and J. Sun, “Optimized product quantization,” IEEE\ntransactions on pattern analysis and machine intelligence , vol. 36, no. 4,\npp. 744–755, 2013.\n[69] A. Babenko and V . Lempitsky, “Additive quantization for extreme vector\ncompression,” in Proceedings of the IEEE Conference on Computer\nVision and Pattern Recognition , 2014, pp. 931–938.\n[70] R. Wang and D. Deng, “Deltapq: lossless product quantization code\ncompression for high dimensional similarity search,” Proceedings of the\nVLDB Endowment , vol. 13, no. 13, pp. 3603–3616, 2020.\n[71] F. Andr ´e, A.-M. Kermarrec, and N. Le Scouarnec, “Cache locality is\nnot enough: High-performance nearest neighbor search with product\nquantization fast scan,” in 42nd International Conference on Very Large\nData Bases , vol. 9, no. 4, 2016, p. 12.\n[72] M. Wang, X. Xu, Q. Yue, and Y . Wang, “A comprehensive survey and\nexperimental comparison of graph-based approximate nearest neighbor\nsearch,” Proceedings of the VLDB Endowment , vol. 14, no. 11, pp. 1964–\n1978, 2021.\n[73] L. Chi and X. Zhu, “Hashing techniques: A survey and taxonomy,” ACM\nComputing Surveys (Csur) , vol. 50, no. 1, pp. 1–36, 2017.\n[74] X. Tang, Z. Zhang, W. Xu, M. T. Kandemir, R. Melhem, and J. Yang,\n“Enhancing address translations in throughput processors via compres-\nsion,” in Proceedings of the ACM International Conference on Parallel\nArchitectures and Compilation Techniques , 2020, pp. 191–204.\n[75] Y . Zhou, F. Wu, P. Huang, X. He, C. Xie, and J. Zhou, “Understanding\nand alleviating the impact of the flash address translation on solid state\ndevices,” ACM Transactions on Storage (TOS) , vol. 13, no. 2, pp. 1–29,\n2017.\n[76] Z. Yan, D. Lustig, D. Nellans, and A. Bhattacharjee, “Translation ranger:\nOperating system support for contiguity-aware tlbs,” in Proceedings of\nthe 46th International Symposium on Computer Architecture , 2019, pp.\n698–710.\n[77] Y . Pan, H. Chen, J. Zhao, and Y . Xu, “Hcftl: A locality-aware flash\ntranslation layer for efficient address translation,” IEEE Transactions\non Computer-Aided Design of Integrated Circuits and Systems , vol. 41,\nno. 8, pp. 2477–2489, 2021.\n[78] C. Wongkham, B. Lu, C. Liu, Z. Zhong, E. Lo, and T. Wang, “Are up-\ndatable learned indexes ready?” Proceedings of the VLDB Endowment ,\nvol. 15, no. 11, pp. 3004–3017, 2022.\n[79] C. Liu, H. Jiang, J. Paparrizos, and A. J. Elmore, “Decomposed bounded\nfloats for fast compression and queries,” Proceedings of the VLDB\nEndowment , vol. 14, no. 11, pp. 2586–2598, 2021.\n[80] T. Pelkonen, S. Franklin, J. Teller, P. Cavallaro, Q. Huang, J. Meza,\nand K. Veeraraghavan, “Gorilla: A fast, scalable, in-memory time series\ndatabase,” Proceedings of the VLDB Endowment , vol. 8, no. 12, pp.\n1816–1827, 2015.\n[81] D. Blalock, S. Madden, and J. Guttag, “Sprintz: Time series compression\nfor the internet of things,” Proceedings of the ACM on Interactive,Mobile, Wearable and Ubiquitous Technologies , vol. 2, no. 3, pp. 1–\n23, 2018.\n[82] “Ieee standard for floating-point arithmetic,” IEEE Std 754-2019 (Revi-\nsion of IEEE 754-2008) , pp. 1–84, 2019.\n[83] X. Chen, J. Tian, I. Beaver, C. Freeman, Y . Yan, J. Wang, and D. Tao,\n“Fcbench: Cross-domain benchmarking of lossless compression for\nfloating-point data,” Proceedings of the VLDB Endowment , vol. 17,\nno. 6, pp. 1418–1431, 2024.\n[84] N. Govindaraju, J. Gray, R. Kumar, and D. Manocha, “Gputerasort:\nhigh performance graphics co-processor sorting for large database\nmanagement,” in Proceedings of the 2006 ACM SIGMOD international\nconference on Management of data , 2006, pp. 325–336.\n[85] R. Rui, H. Li, and Y .-C. Tu, “Efficient join algorithms for large\ndatabase tables in a multi-gpu environment,” in Proceedings of the\nVLDB Endowment. International Conference on Very Large Data Bases ,\nvol. 14, no. 4. NIH Public Access, 2020, p. 708.\n[86] J. Paul, B. He, S. Lu, and C. T. Lau, “Improving execution efficiency of\njust-in-time compilation based query processing on gpus,” Proceedings\nof the VLDB Endowment , vol. 14, no. 2, pp. 202–214, 2020.\n[87] M. A. Awad, S. Ashkiani, S. D. Porumbescu, M. Farach-Colton, and\nJ. D. Owens, “Analyzing and implementing gpu hash tables,” in 2023\nSymposium on Algorithmic Principles of Computer Systems (APOCS) .\nSIAM, 2023, pp. 33–50.\n[88] J. Heo, J. Won, Y . Lee, S. Bharuka, J. Jang, T. J. Ham, and J. W. Lee,\n“Iiu: Specialized architecture for inverted index search,” in Proceedings\nof the Twenty-Fifth International Conference on Architectural Support\nfor Programming Languages and Operating Systems , 2020, pp. 1233–\n1245.",
  "textLength": 53102
}