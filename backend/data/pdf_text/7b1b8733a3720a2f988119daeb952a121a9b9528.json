{
  "paperId": "7b1b8733a3720a2f988119daeb952a121a9b9528",
  "title": "Online bipartite matching with imperfect advice",
  "pdfPath": "7b1b8733a3720a2f988119daeb952a121a9b9528.pdf",
  "text": "Online bipartite matching with imperfect advice\nDavin Choo∗1, Themis Gouleakis∗2, Chun Kai Ling∗3, and Arnab Bhattacharyya4\n1,2,4School of Computing, National University of Singapore\n3Industrial Engineering and Operations Research, Columbia University\nAbstract\nWe study the problem of online unweighted bipartite matching with noffline vertices and nonline\nvertices where one wishes to be competitive against the optimal offline algorithm. While the classic Ranking\nalgorithm of Karp et al. [1990] provably attains competitive ratio of 1 −1/e > 1/2, we show that no learning-\naugmented method can be both 1-consistent and strictly better than 1 /2-robust under the adversarial arrival\nmodel. Meanwhile, under the random arrival model, we show how one can utilize methods from distribution\ntesting to design an algorithm that takes in external advice about the online vertices and provably achieves\ncompetitive ratio interpolating between any ratio attainable by advice-free methods and the optimal ratio of\n1, depending on the advice quality.\n1 Introduction\nFinding matchings in bipartite graphs is a mainstay of algorithms research. The area’s mathematical richness\nis complemented by a vast array of applications — any two-sided market (e.g., kidney exchange, ridesharing)\nyields a matching problem. In particular, the online variant enjoys much attention due to its application in\ninternet advertising. Consider a website with a number of pages and ad slots (videos, images, etc.). Advertisers\nspecify ahead of time the pages and slots they like their ads to appear in, as well as the target user. The\nwebsite is paid based on the number of ads appropriately fulfilled. Crucially, ads slots are available only when\ntraffic occurs on the website and are not known in advance. Thus, the website is faced with the online decision\nproblem of matching advertisements to open ad slots.\nThe classic online unweighted bipartite matching problem by Karp et al. [1990] features noffline vertices U\nandnonline vertices V. Each v∈Vreveals its incident edges sequentially upon arrival. With each arrival,\none makes an irrevocable decision whether (and how) to match vwith a neighboring vertex in U. The final\noffline graph G= (U∪V, E) is assumed to have a largest possible matching of size n∗≤n, and we seek online\nalgorithms producing matchings of size as close to n∗as possible. The performance of a (randomized) algorithm\nAis measured by its competitive ratio :\nmin\nG=(U∪V,E)min\nV’s arrival seq.E[# matches by A]\nn∗, (1)\nwhere the randomness is over any random decisions made by A. Traditionally, one assumes the adversarial\narrival model , i.e., an adversary controls both the final graph Gand the arrival sequence of online vertices.\nSince any maximal matching has size at least n∗/2, a greedy algorithm trivially attains a competitive ratio\nof 1/2. Indeed, Karp et al. [1990] show that no deterministic algorithm can guarantee better than 1 /2−o(1).\nMeanwhile, the randomized ranking algorithm of Karp et al. [1990] attains an asymptotic competitive ratio of\n1−1/ewhich is also known to be optimal [Karp et al., 1990, Goel and Mehta, 2008, Birnbaum and Mathieu,\n2008, Vazirani, 2022].\nIn practice, advice (also called predictions or side information) is often available for these online instances.\nFor example, online advertisers often aggregate past traffic data to estimate the future traffic and corresponding\nuser demographic. While such advice may be imperfect, it may nonetheless be useful in increasing revenue\nand improving upon aforementioned worst-case guarantees. Designing algorithms that utilize such advice in a\nprincipled manner falls under the research paradigm of learning-augmented algorithms . A learning-augmented\n∗Equal contribution\n1arXiv:2405.09784v3  [cs.LG]  23 May 2024\n\nalgorithm is said to be (i) a-consistent if it is a-competitive with perfect advice and (ii) b-robust if it is\nb-competitive with arbitrary advice quality.\nGoal 1.1. Letβbe the best-known competitive ratio attainable by any classical advice-free online algorithm.\nCan we design a learning-augmented algorithm for the online bipartite matching problem that is 1-consistent\nandβ-robust?\nClearly, Goal 1.1 depends on the form of advice as well as a suitable measure of its quality. Setting these\ntechnicalities aside for now, we remark that Goal 1.1 strikes the best of all worlds: it requires that a perfect\nmatching be obtained when the advice is perfect, while not sacrificing performance with respect to advice-free\nalgorithms when faced with low-quality advice. In other words, there is potential to benefit, but no possible\nharm when employing such an algorithm. We make the following contributions in pursuit of Goal 1.1.\n1. Impossibility under adversarial arrivals\nWe show that under adversarial arrivals, learning augmented algorithms, no matter what form the advice takes,\ncannot be both 1-consistent and strictly more than 1/2-robust. The latter is worse than the competitive ratio\nof 1−1/eguaranteed by known advice-free algorithms [Karp et al., 1990].\n2. Achieving Goal 1.1 under the random arrival model\nWe propose an algorithm TestAndMatch achieving Goal 1.1 under the weaker random arrival model , in which\nan adversary controls the online vertices Vbut its arrival order is randomized. Our advice is a histogram over\ntypes of online vertices; in the context of online advertising this corresponds to a forecast of the user demographic\nand which ads they can be matched to. TestAndMatch assumes perfect advice while simultaneously testing\nfor its accuracy via the initial arrivals. If the advice is deemed useful, we mimic the matching suggested by\nit; else, we revert to an advice-free method. The testing phase is kept short (sublinear in n) by utilizing\nstate-of-the-art L1estimators from distribution testing. We analyze our algorithm’s performance as a function\nof the quality of advice, showing that its competitive ratio gracefully degrades to βas quality of advice decays.\nTo the best of our knowledge, our work is the first that shows how one can leverage techniques from the property\ntesting literature to designing learning-augmented algorithms.\nWhile our contributions are mostly theoretical, we give and discuss various practical extensions of TestAnd-\nMatch , and also show preliminary experiments in Appendix E.\n2 Preliminaries and related work\nAn online bipartite instance is defined by a bipartite graph G= (U∪V, E) where UandVare the set of\nnoffline and nonline vertices respectively. A type of an online vertex v∈Vrefers to the subset of offline\nvertices {u∈U| {u, v} ∈E}that it is neighbors with; there are 2npossible types and at most nof them\nare realized through V. The types of vertices vi∈Vare revealed one at a time in an online fashion, when\nthe corresponding vertex arrives and one has to decide whether (and how) to match the newly arrived vertex\nirrevocably. A matching in the graph Gis a set of edges M⊆Esuch that for every vertex w∈U∪V, there is\nat most one edge in Mincident to w. Given two vectors of length k, we denote the L1-distance between them\nasL1(x, y) =||x−y||1=Pk\ni=1|xi−yi|. For any set S, 2Sdenotes its power set (set of all subsets of S).\nIn this work, we focus on the classic unweighted online bipartite matching (see Mehta [2013] for other\nvariants) where the final offline graph has a matching of size n∗≤n.\nArrival models. The degree of control an adversary has over Vaffects analysis and algorithms. The\nadversarial arrival model is the most challenging, with both the final graph Gand the order in which online\nvertices arrive chosen by the adversary. Here, an algorithm’s competitive ratio is given by (1). In random\narrival models ,Gremains adversarial but the arrival order is random. For this paper, we assume the Random\nOrder setting, where an adversary chooses a G, but the arrival order of Vis a uniformly random permutation.\nIn this setting, the competitive ratio is defined as\nmin\nG=(U∪V,E)EV’s arrival seq.E[# matches by A]\nn∗. (2)\n2\n\nTwo even easier random arrival models exist: (i) known-IID model [Feldman et al., 2009], where the adversary\nchooses a distribution over types (which is known to us), and the arrivals of Vare chosen by sampling i.i.d.\nfrom this distribution, and (ii) unknown-IID model , which is the same as known-IID but with the distributions\nare not revealed to us. The competitive ratios between these arrival models are known to exhibit a hierarchy of\ndifficulty [Mehta, 2013]:\nAdversarial ≤Rand. Order ≤Unknown-IID ≤Known-IID\nAs our Random Order setting is the most challenging amongst these random arrival models, our methods also\napply to the unknown-IID and known-IID settings.\n2.1 Advice-free online bipartite matching\nTable 1 summarizes known results about attainable competitive ratios and impossibility results in the adversarial\nand Random Order arrival models. In particular, observe that there is a gap between the upper and lower\nbounds in the Random Order arrival model which remains unresolved.\nAdversarial Random Order\ndet. algo. 1 /2 1 −1/e\ndet. hardness 1 /2 3 /4\nrand. algo. 1 −1/e 0.696\nrand. hardness 1 −1/e+o(1) 0 .823\nTable 1: Known competitive ratios for the classic unweighted online bipartite matching problem for deterministic\n(det.) and randomized (rand.) algorithms under the adversarial and Random Order arrival models. Note that\n1−1/e≈0.63.\nOn the positive side of things, the deterministic Greedy algorithm which matches newly arrived vertex\nwith any unmatched offline neighbor attains a competitive ratio of at least 1 /2 in the adversarial arrival model\nand at least 1 −1/ein the random arrival model [Goel and Mehta, 2008]. Meanwhile, the randomized Ranking\nalgorithm of Karp et al. [1990] achieves a competitive ratio of 1 −1/ein the adversarial arrival model. In the\nRandom Order arrival model, Ranking achieves a strictly larger competitive ratio, shown to be at least 0.653\nin Karande et al. [2011] and 0.696 in Mahdian and Yan [2011]. However, Karande et al. [2011] showed that\nRanking cannot beat 0.727 in general; so, new ideas will be required if one believes that the tight competitive\nratio bound is 0.823 [Manshadi et al., 2012].\nOn the negative side, the following example highlights the key difficulty faced by online algorithms. Consider\nthe gadget for n= 2 in Fig. 1, where the first online vertex v1neighbors with both u1andu2and the second\nonline vertex v2neighbors with only one of u1oru2. Even when promised that the true graph is either G1orG2,\nany online algorithm needs to correctly guess whether to match v1with u1oru2to achieve perfect matching\nwhen v2arrives.\nG1u1\nu2v1\nv2G2u1\nu2v1\nv2\nFigure 1: Gadget for n= 2. Red edges observed when v2arrives.\nBy repeating the gadget of Fig. 1 multiple times sequentially, any deterministic algorithm can only hope\nto attain competitive ratios of 1 /2 and 3 /4 in the adversarial and random arrival models respectively. For\nrandomized algorithms, Karp et al. [1990] showed that Ranking is essentially optimal for the adversarial arrival\nmodel since no algorithm can achieve a competitive ratio better than 1 −1/e+o(1). In the Random Order\narrival model, Goel and Mehta [2008] showed (in their Appendix E) that a ratio better than 5 /6≈0.83 cannot\nbe attained by brute force analysis of a 3 ×3 gadget bipartite graph. Subsequently, Manshadi et al. [2012]\nshowed that no algorithm (deterministic or randomized) can achieve a competitive ratio better than 0 .823.\nTechnically speaking, the hardness result of Manshadi et al. [2012] is for the known IID model introduced\nby Feldman et al. [2009], but this extends to the Random Order arrival model since the former is an easier\n3\n\nsetting; e.g. see Theorem 2.1 in [Mehta, 2013] for an explanation. Under the easier known IID model, the\ncurrent state of the art algorithms achieve a competitive ratio of 0.7299 using linear programming [Jaillet and\nLu, 2014, Brubach et al., 2016, 2020].\n2.2 Learning-augmented algorithms for matching\nLearning-augmented algorithms as a whole have received significant attention since the seminal work of Lykouris\nand Vassilvitskii [2021], where they investigated the online caching problem with predictions; their result was\nfurther improved by Rohatgi [2020], Antoniadis et al. [2020a], Wei [2020]. Algorithms with advice was also\nstudied for the ski-rental problem [Gollapudi and Panigrahi, 2019, Wang et al., 2020, Angelopoulos et al.,\n2020], non-clairvoyant scheduling [Purohit et al., 2018], scheduling [Lattanzi et al., 2020, Bamas et al., 2020a,\nAntoniadis et al., 2022], augmenting classical data structures with predictions (e.g. indexing [Kraska et al.,\n2018] and Bloom filters [Mitzenmacher, 2018]), online selection and matching problems [Antoniadis et al., 2020b,\nD¨ utting et al., 2021], online TSP [Bernardini et al., 2022, Gouleakis et al., 2023], a more general framework of\nonline primal-dual algorithms [Bamas et al., 2020b], and causal graph learning [Choo et al., 2023].\nAamand et al. [2022] studied the adversarial arrival models with offline vertex degrees as advice. While\ntheir algorithm is optimal under the Chung-Lu-Vu random graph model [Chung et al., 2003], the class of offline\ndegree advice is unable to attain 1-consistency. Feng et al. [2021] propose a two-stage vertex-weighted variant,\nwhere advice is a proposed matching for the online vertices arriving in the first stage. Jin and Ma [2022] showed\nin this setting a tight robustness-consistency tradeoff and derive a continuum of algorithms tracking this Pareto\nfrontier. Antoniadis et al. [2020b] studied settings with random vertex arrival and weighted edges. Their advice\nis a prediction on edge weights adjacent to Vunder an optimal offline matching. Furthermore, their algorithm\nand analysis uses a hyper-pamareter quatifying confidence in the advice, leading to different consistency and\nrobustness tradeoffs. Another relevant work is the LOMAR method proposed by Li et al. [2023]. Using a\npre-trained reinforcement learning (RL) model along with a switching mechanism based on regret to guarantee\nrobustness with respect to any provided expert algorithm, they claim “for some tuning parameter ρ∈[0,1],\nLOMAR isρ-competitive against our choice of expert online algorithm”. We differ from LOMAR in two key\nways:\n1.Our method does not require any pre-training phase and directly operate on the sequence of online vertices\nthemselves. This means that whatever mistakes made during our “testing” phase contributes to our\ncompetitive ratio; a key technical contribution is the use of distribution testing to ensure that the number\nof such mistakes incurred is sublinear.\n2.The robustness guarantee of Li et al. [2023] is substantially weaker than what we provide. Suppose the\nexpert used by LOMAR isβ-competitive, just like how we use the state-of-the-art algorithm as the\nbaseline. Although Li et al. [2023] does not analyze the consistency guarantee of their method, one can\nsee that LOMAR is (1 −ρ)-consistent and ρ·β-robust (ignoring the B≥0 hyperparameter). LOMAR\ncan only be 1-consistent when ρ= 0, i.e. it blindly follows the RL-based method; but then it will have\nno robustness guarantees. In other words, LOMAR cannot simultaneously achieve 1-consistency and\nρ·β-robustness without knowing the RL quality. In contrast, our method is simultaneously 1-consistent\nand≈β-robust without knowing the quality of our given advice; we evaluate its quality as vertices arrive.\nTable 2 compares the consistency-robustness tradeoffs.\n[Jin and Ma, 2022] LOMAR Ours\nRobustness R ρ ·β ≈β\nConsistency 1 −(1−√\n1−R)21−ρ 1\nTable 2: Consistency-robustness guarantees of methods that can achieve 1-consistency. Here, R∈[0,3/4] and\nρ∈[0,1]. Note that [Jin and Ma, 2022] is for the 2-staged setting.\nMore broadly, Lavastida et al. [2020, 2021] learn and exploit parameters of the online matching problem\nand provide PAC-style guarantees. Dinitz et al. [2022] studied the use of multiple advice and seek to compete\nwith the best on a per-instance basis. Finally, others suggest using advice to speedup offline matching via\n“warm-start” heuristics [Dinitz et al., 2021, Chen et al., 2022, Sakaue and Oki, 2022].\n4\n\n2.3 Distribution testing and distance estimation\nIn this work, we will use results from Jiao et al. [2018] for the problem of L1distance estimation. This is closely\nrelated to tolerant identity testing , where the tester’s task is to distinguish whether a distribution pisε1-close to\nsome known distribution qfrom the case where pisε2-far from q, according to some natural distance measure.\nThe following theorem states the number of samples from an unknown distribution pthat needed by the\nalgorithm in Jiao et al. [2018] to get an estimate of L1(p, q) for some reference distribution qwith additive error\nεand error probability δ.1\nTheorem 2.1 (adapted from Jiao et al. [2018]) .Fix a reference distribution qover a domain Tof size\n|T|=rand let s∈ O\u0010\nr·log(1/δ)\nε2·logr\u0011\nbe an even integer. There exists an algorithm that draws s1+s2IID samples\nfrom an unknown distribution pover T, where s1, s2∼Poisson (s/2), and outputs an estimate ˆL1such that\n|ˆL1−L1(p, q)| ≤εwith success probability at least 1−δ.\nThe algorithm of Theorem 2.1 uses a standard technique in distribution testing known as Poissonization\nwhich aims to eliminate correlations between samples at the expense of not having a fixed sample size. Instead,\nthe number of samples follows a Poisson distribution and we treat its mean as the sample complexity. As\na consequence, the known result regarding the concentration of the Poisson distribution would be helpful in\nbounding the overall algorithmic success probability, e.g. see [Canonne, 2019].\nLemma 2.2. For any m > 0and any x >0, we have Pr[|X−m| ≥x]≤2e−x2\n2(m+x), where X∼Poisson( m).\n3 Impossibility for adversarial arrival model\nUnfortunately, Goal 1.1 is unattainable under the adversarial arrival model. Our construction is based on\ngeneralizing the gadget in Fig. 1 to state Theorem 3.1.\nTheorem 3.1. For even n, there exists input graphs G1andG2such that no advice can distinguish between the\ntwo within n/2online arrivals. Consequently, an algorithm cannot be both 1-consistent and strictly more than\n1/2-robust.\nProof. Consider the restricted case where there are only two possible final offline graphs G(1)= (U∪V(1), E(1))\nandG(2)= (U∪V(2), E(2)) where\nE(1)=n\n{u(1)\nj, v(1)\nj},{u(1)\nj+n/2, v(1)\nj}: 1≤j≤n/2o\n∪n\n{u(1)\nj−n/2, v(1)\nj}:n/2 + 1≤j≤no\nE(2)=n\n{u(2)\nj, v(2)\nj},{u(2)\nj+n/2, v(2)\nj}: 1≤j≤n/2o\n∪n\n{u(2)\nj, v(2)\nj}:n/2 + 1≤j≤no\nWe will even restrict the first n/2 to be exactly v(i)\n1, . . . , v(i)\nn/2, where i∈ {1,2}is the chosen input graph by the\nadversary. See Fig. 2 for an illustration.\nSuppose Giwas the chosen graph, for i∈ {1,2}. In this restricted problem input setting, the strongest\npossible advice is knowing the bit isince all other viable advice can be derived from this bit. Thus, for the sake\nof a hardness result, it suffices to only consider the advice of ˆi∈ {1,2}.\nWithin the first n/2 arrivals, any algorithm cannot distinguish and will behave in the same manner. Suppose\nthere is a 1-consistent algorithm Agiven bit ˆi. In the first n/2 steps, Aneeds to match vjtouj+n/2ifˆi= 1\nandvjtoujforˆi= 2. However, if i̸=ˆi, then Awill not be able to match any remaining arrivals and hence be\nat most 1 /2-robust.\nIn fact, Theorem 3.1 can be strengthened: for any α∈[0,1/2], no algorithm can be simultaneously\n(1−α)-consistent and strictly more than (1 /2 +α)-robust. The proof is essentially identical and deferred to\nAppendix A.\nWhile Theorem 3.1 appears simple, we stress that hardness results for learning-augmented algorithms are\nrare, since the form of advice and its utilization is arbitary. For instance, Aamand et al. [2022] only showed\nthat when advice is the true degrees of the offline vertices, there exist inputs such that any learning-augmented\nalgorithm can only achieve a competitive ratio of at most 1 −1/e+o(1).\n1It is our understanding that the tester proposed by Jiao et al. [2018] requires a significant amount of hyperparameter tuning\nand no off-the-shelf implementation is available Han [2024].\n5\n\nG1\nu1\n...\nun\n2\n...un\n2+1\nunv1\n...\nun\n2\n...vn\n2+1\nvnG2\nu1\n...\nun\n2\n...un\n2+1\nunv1\n...\nun\n2\n...vn\n2+1\nvn\nFigure 2: Illustration of G1andG2for Theorem 3.1\n4 Imperfect advice for random arrival model\nIn this section, we present our learning-augmented algorithm TestAndMatch which is 1-consistent, ( β−o(1))-\nrobust, and achieves a smooth interpolation on an appropriate notion of advice quality, where βis any achieveable\ncompetitive ratio by some advice-free baseline algorithm. As discussed in Section 2, the best known competitive\nratio of β= 0.696 is achieveable using Ranking [Karp et al., 1990] but it is unknown if it can be improved. In\nfact,TestAndMatch is a meta-algorithm that uses any advice-free baseline algorithm as a blackbox and so\nour robustness guarantee improves as βimproves.\nUsing realized type counts as advice. Given the final offline graph G∗= (U∪V, E) with maximum\nmatching size n∗≤n, we can classify each online vertex based on their types, i.e., the set of offline vertices they\nare adjacent to [Borodin et al., 2020]. Define the vector c∗∈Z2nindexed by the possible types 2U, such that\nc∗(t) is the number of times type t∈2Uoccurs in G∗. Even though there are 2npossible types, the number of\nrealized types is at most n. Let T∗⊆2Ube the set of types with non-zero counts in c∗. Since |U|=|V|=n,c∗\nis sparse and contains r∗=|T∗| ≤n≪2nnon-zero elements; see Fig. 3. Note that c∗fully determines G∗for\nour purposes, as vertices may be permuted but n∗remains identical.\nu1\nu2\nu3\nu4v1\nv2\nv3\nv4Type counts c∗inG∗\nType Count\n{u1, u3} 1\nT∗{u2, u3} 1\n{u1, u2, u4} 2\n2U\\T∗. . . 0\nFigure 3: For n= 4, there may be 24= 16 possible types but at most n= 4 of them can ever be non-zero.\nHere, c∗({u1, u3}) = 1 , c∗({u2, u3}) = 1 and c∗({u1, u2, u4}) = 2. We see that type {u1, u2, u4}appears twice\ninc∗and|T∗|= 3.\nIn this work, we consider advice to be an estimate of the realized type counts ˆc∈Z2nwith non-zero entries\ninˆT⊆2U. As before, we assume that ˆcsums to nand contains ˆr=|ˆT| ≤n≪2nnon-zero entries. Just like c∗,\nˆcfully defines some “advice graph” ˆG= (U∪V,ˆE) that we can find a maximum matching for in polynomial\ntime. We discuss the practicality of obtaining such advice in Appendix B.\nThroughout this section, we will use star ( ·)∗and hatˆ(·)to denote ground truth and advice quantities\nrespectively. In particular, we use n∗≤nandˆn≤nto denote the maximum matching size in the final offline\ngraph G∗and advice graph ˆGrespectively. Note that star ( ·)∗quantities are not known and exist purely for the\npurpose of analysis.\n6\n\nAlgorithm 1 TestAndMatch\ninput Advice ˆcwith ˆr=|ˆT|,Baseline advice-free algorithm with competitive ratio β <1, error threshold\nε >0, failure rate δ=δ′+δpoiforδpoi=O\u0010\n1\npoly(ˆr)\u0011\n1:Compute advice matching ˆMfrom ˆ c\n2:ifˆn\nn≤βthen\n3: RunBaseline on all arrivals\n4:end if\n5:Define sˆr,ε,δ=O\u0010\n(ˆr+1)·log(1/δ′)\nε2·log(ˆr+1)\u0011\n6:Define testing threshold τ= 2\u0000ˆn\nn−β\u0001\n−ε\n7:RunMimic onsˆr,ε,δ·p\nlog(ˆr+ 1) arrivals while keeping track of the online arrivals in a set A\n8:ifMinimaxTest (sˆr,ε,δ,ˆc\nn, A, τ, δ′) = “Pass” then\n9: RunMimic on the remaining arrivals\n10:else\n11: RunBaseline on the remaining arrivals\n12:end if\nIntuition behind TestAndMatch. Ifˆc=c∗, one trivially obtains a 1-consistency by solving for a maximum\nmatching ˆMon the advice graph ˆGand then mimicking matches based on ˆMas vertices arrive. While ˆc̸=c∗\nin general, we may consider distributions p∗=c∗/nandq=ˆc/nand test if p∗is close to qinL1distance via\nTheorem 2.1; this is done sample efficiently using just the first o(n) online vertices (Section 4.2). If L1(p∗, q) is\nless than some threshold τ, we conclude ˆc≈c∗and continue mimicking ˆM, enjoying a competitive ratio close\nto 1. If not, we revert to Baseline . Crucially, each wrong match made during the testing phase hurts our final\nmatching size by at most a constant, yielding a competitive ratio of β−o(1).\nTestAndMatch is described in Algorithm 1, which takes as input a number of additional parameters ( δ,ϵ,\netc) and subroutines that we will explain in a bit. For now, we state our main result describing the performance\nofTestAndMatch in terms of the competitive ratio.\nTheorem 4.1. For any advice ˆcwith|ˆT|=ˆr,ε >0andδ >1\npoly(ˆr), let ˆL1be the estimate of L1(p∗, q)\nobtained from k=sˆr,ε,δ·p\nlog(ˆr+ 1) IID samples of p∗.TestAndMatch produces a matching of size mwith\ncompetitive ratio of at leastˆn\nn−L1(p,q)\n2≥βwhen ˆL1≤2\u0000ˆn\nn−β\u0001\n−ε, and at least β·(1−k\nn)otherwise, with\nsuccess prob. 1−δ.\nFor sufficiently large nand constants ε, δ, we have sˆr,ε,δ·p\nlog(ˆr+ 1)∈o(1), so Theorem 4.1 implies a lower\nbound on the achieved competitive ratio ofm\nn∗(see Fig. 4) where\nm\nn∗≥m\nn≥(\nˆn\nn−L1(p∗,q)\n2when ˆL1≤2\u0000ˆn\nn−β\u0001\n−ε\nβ·(1−o(1)) otherwise\nUnder random order arrivals, the competitive ratio is measured in expectation over all possible arrival\nsequences. One can easily convert the guarantees of Theorem 4.1 to one in expectation by assuming the extreme\nworst case scenario of obtaining 0 matches whenever the tester fails. So, the expected competitive ratio is\nsimply (1 −δ) factor of the bounds given in Theorem 4.1. Setting δ= 0.001, we get a robustness guarantee of\nβ·(1−o(1))·0.999 in expectation. Note that our guarantees hold regardless of what value of εis used. In the\nevent that a very small εis chosen and the test always fails, we are still guaranteed the robustness guarantees\nof≈β. One possible default for εcould be to assume that the optimal offline matching has size nand just set\nit to half the threshold value, i.e. set ε= ˆn/n−β.\nRemark about lines 4 and 6 in TestAndMatch. As we subsequently require Poisson (sˆr,ε,δ) IID samples\nfrom p∗for testing, we collect sˆr,ε,δ·p\nlog(ˆr+ 1) online arrivals into the set A. Note that E[Poisson (sˆr,ε,δ)] =\nsˆr,ε,δandPoisson (sˆr,ε,δ)≤sˆr,ε,δ·p\nlog(ˆr+ 1) with high probability. This additional slack ofp\nlog(ˆr+ 1) allows\nfor Theorem 4.1 to hold with high probability (as opposed to constant) while ensuring that the competitive\nratio remains in the β·(1−o(1)) regime. Finally, when r∈Ω(n), we remark that sˆr,ε,δis sublinear in nonly\nfor sufficiently large n; see Section 5 for some practical modifications.\nThe rest of this section is devoted to describing Algorithm 1 and proving Theorem 4.1. We study in\nSection 4.1 how mimicking poor advice quality impacts matching sizes, yielding conditions where mimicking is\n7\n\nˆn\nn\nβ\nβ·(1−on(1))\n1 2\u0000ˆn\nn−β\u0001\n−2ε0L1(p∗, q)Lower bound on achieved\ncompetitive ratio (w.p. ≥1−δ)\nFigure 4: A (conservative) competitive ratio plot forˆn\nn> β. IfMinimaxTest (Algorithm 3) succeeds, we have\nL1(p∗, q)<2\u0000ˆn\nn−β\u0001\n−2εwhenever ˆL1<2\u0000ˆn\nn−β\u0001\n−ε. Observe that there is a smooth interpolation between\nthe achieveable competitive ratio as L1(p∗, q) degrades whilst paying only o(1) for robustness.\nAlgorithm 2 Mimic\ninput Matching ˆM, advice counts ˆ c, arrival type label t\n1:ifc(t)>0then\n2: Mimic an arbitrary unused type tmatch in ˆM\n3: Decrement c(t) by 1\n4:end if\n5:return c ▷Updated counts\ndesirable, which we test for via Theorem 2.1. Section 4.2 describes transformations to massage our problem\ninto the form required by Theorem 2.1. Lastly, we tie up our analysis of Theorem 4.1 in Section 4.3.\n4.1 Effect of advice quality on matching sizes\nGiven an advice ˆcof type counts, we first solve optimally for a maximum matching ˆMon the advice graph\nˆGand then mimic the matches for online arrivals whenever possible; see Algorithm 2. That is, whenever new\nvertices arrive, we match according to some unused vertex of the same type if possible and leave it unmatched\notherwise.\nIt is useful to normalize counts as p∗=c∗/nandq=ˆc/n. These are distributions on the realized and\npredicted (by advice) counts, and have sparse support T∗andˆT.\nNow, suppose ˆMhas matching size ˆn≤n. By definition of L1(c∗,ˆc) and Mimic , one would obtain a matching\nof size at least ˆn−L1(c∗,ˆc)/2 by blindly following advice. This yields a competitive ratio ofˆn−L1(c∗,ˆc)/2\nn∗ .\nRearranging, we see that Mimic outperforms the advice-free baseline (in terms of worst case guarantees) if and\nonly if\nˆn−L1(c∗,ˆc)/2\nn∗> β⇐⇒L1(p∗, q)<2\nn(ˆn−βn∗)\nThe above analysis suggests a natural way to use advice type counts: use Mimic ifL1(p∗, q)≤2\nn(ˆn−βn∗),\nandBaseline otherwise. Note that one should always just use Baseline wheneverˆn\nn∗< β, matching the\nnatural intuition of ignoring advice of poor quality.\nUnfortunately, as we only know nbut not n∗, our algorithm conservatively checks whether L1(p∗, q)<\n2 (ˆn/n−β), and so the resulting guarantee is conservative since n∗≤n.\n4.2 Estimating advice quality via property testing\nAsc∗is unknown, we cannot obtain L1(p∗, q). However, p∗andqare distributions and we can apply the\nproperty testing method of Theorem 2.1 to estimate L1(p∗, q) to some ε >0 accuracy. Applying Theorem 2.1\nraises two difficulties.\n8\n\nAlgorithm 3 MinimaxTest (s,ˆc\nn, A, τ, δ′)\ninput Sample size s, distribution q= ˆc/n,sp\nlog(ˆr+ 1) online arrivals A, testing threshold τ, failure rate δ′\n1:Compute s1, s2∼Poisson( s/2)\n2:ifs1+s2> sp\nlog(ˆr+ 1)then\n3:return “Fail” ▷occurs w.p. δpoi≤1/poly (ˆr)\n4:end if\n5:Collect s1+s2IID samples from p∗=c∗\nnby running SimulateP with A.\n6:Run algorithm of Theorem 2.1 to obtain estimate ˆL1such that |ˆL1−L1(p, q)| ≤εwith probability 1 −δ′\n7:return ˆL1< τ\nSimulating IID arrivals. Under the Random Order arrival model (Section 2), online vertices arrive “without\nreplacement”, which is incompatible with Theorem 2.1. Thankfully, we can apply a standard trick to simulate\nIID “sampling with replacement” from p∗by “re-observing arrivals”. See SimulateP (Algorithm 4) in the\nappendix for details.\nOperating in reduced domains. Strictly speaking, the domain of p∗andqcould be as large as 2n, since any\none of these types may occur. If all of these types occur with non-zero probability, then applying Theorem 2.1\nfor testing could take a near-exponential (in n) number of online vertex arrivals, which is clearly impossible.\nHowever, as established earlier, p∗andqenjoy sparsity; in particular, ˆcand thus qcontain 0 in all but at most\nˆr=|ˆT| ≤n≪2nentries. The key insight is to express L1distances by operating on ˆT, plus an additional\ndummy type t0which has 0 counts in ˆc. Whenever we observe an online vertex with type t∈T∗\\ˆT, we classify\nit as t0. Specifically,\nL1(p∗, q) =X\nt∈2U|p∗(t)−q(t)|=X\nt∈ˆT∪T∗|p∗(t)−q(t)|=X\nt∈ˆT|p∗(t)−q(t)|+X\nt∈T∗\\ˆTp∗(t),\nwhich we can view as an L1distance on distributions with support ˆT∪{t0}. Thus, the domain size when applying\nTheorem 2.1 is ˆ r+ 1≤n+ 1. For any constant ϵ, δ > 0, the required samples is sˆr,ε,δ·p\nlog(ˆr+ 1)∈o(n).\nNow that these difficulties are overcome, the estimation of L1(p∗, q) =L1(c∗\nn,ˆc\nn) is done via MinimaxTest\n(Algorithm 3), whose correctness follows from Theorem 2.1.\nLemma 4.2. Suppose MinimaxTest uses the estimator of Theorem 2.1 and passes if and only if ˆL1< τ.\nGiven sˆr,ε,δ·p\nlog(ˆr+ 1) online arrivals in a set A, we have L1(p∗, q)<2(ˆn/n−β)whenever MinimaxTest\npasses. The success probability of MinimaxTest is at least 1−δ.\nProof. The algorithm of Theorem 2.1 guarantees tells us that |ˆL1−L1(p∗, q)| ≤εwith probability at least\n1−δ′. Therefore, when MinimaxTest passes, we are guaranteed that L1(p∗, q)≤ˆL1+ε < τ +ε= 2(ˆn/n−β).\nMeanwhile, in the analysis of Theorem 2.1, one actually needs to use s1+s2IID samples from p∗, where\ns1, s2∼Poisson (sˆr,ε,δ′), which can be simulated from the arrival set A; seeSimulateP (Algorithm 4) in the\nappendix. By Lemma 2.2, we may assume that s1+s2≤swith probability at least 1 −δpoi(s). Taking a union\nbound over the failure probability of the “Poissonization” event and the estimator, we see that the overall\nsuccess probability is at least 1 −(δ′+δpoi) = 1−δ.\n4.3 Tying up our analysis of TestAndMatch\nIf we run Baseline from the beginning due toˆn\nn≤β, then we trivially recover a β-competitive ratio. The\nfollowing lemma gives a lower bound on the obtained matching size if we performed MinimaxTest but decided\nswitch to Baseline due to the estimated ˆL1being too large.\nLemma 4.3. Suppose we run an arbitrary algorithm for the first k∈[n]online arrivals and then switch to\nBaseline for the remaining n−konline arrivals. If jmatches made in the first karrivals, where 0≤j≤k,\nthen the overall produced matching size is at least β·(n−k−j) +j.\nProof. Any match made in the first karrivals decreases the maximum attainable matching size by at most two,\nexcluding the match made . As the maximum attainable matching size was originally n, the maximum attainable\nmatching size on the postfix sequence after the kis at least n−k−j. Since Baseline has competitive ratio β,\nrunning Baseline on the remaining n−ksteps will produce a matching of size at least β·(n−k−j). Thus,\nthe overall produced matching size is at least β·(n−k−j) +j.\n9\n\nThe proof of Theorem 4.1 requires the following lemma.\nLemma 4.4. For any advice ˆcwith|ˆT|=ˆr,ε > 0andδ >1\npoly(ˆr), let ˆL1be the estimate of L1(p∗, q)\ninMinimaxTest . IfMinimaxTest succeeds, then TestAndMatch produces a matching of size mwith\ncompetitive ratiom\nn∗at leastˆn\nn−L1(p,q)\n2≥βwhen ˆL1≤2\u0000ˆn\nn−β\u0001\n−ε, and at least β·(1−sˆr,ε,δ·√\nlog(ˆr+1)\nn)\notherwise.\nProof. We consider each case separately.\nCase 1 :ˆL1≤2\u0000ˆn\nn−β\u0001\n−ε\nTestAndMatch executed Mimic for all online arrivals, yielding a matching of size m≥ˆn−L1(c∗,ˆc)\n2. Since\nMinimaxTest succeeds, |ˆL1−L1(p, q)| ≤ε, soL1(p, q)≤ˆL1+ε≤2\u0000ˆn\nn−β\u0001\n−ε+ε= 2\u0000ˆn\nn−β\u0001\n. Therefore,\nm\nn∗≥m\nn≥ˆn\nn−L1(c∗,ˆc)\n2n=ˆn\nn−L1(p∗, q)\n2≥β\nCase 2 :ˆL1>2\u0000ˆn\nn−β\u0001\n−ε\nTestAndMatch executes Baseline after an initial batch of k=sˆr,ε,δ·p\nlog(ˆr+ 1) arrivals that follow Mimic .\nSuppose we made jmatches via Mimic before MinimaxTest . Then, Lemma 4.3 tells us that the overall\nproduced matching size is at least m≥β·(n−k−j) +j. Since β <1, we have β·(n−k−j) +j≥β·(n−k).\nTherefore,\nm\nn∗≥m\nn≥β·(n−sˆr,ε,δ·p\nlog(ˆr+ 1))\nn=β· \n1−sˆr,ε,δ·p\nlog(ˆr+ 1)\nn!\nTheorem 4.1 follows from bounding the failure probability.\nProof of Theorem 4.1. The competitive ratio guarantees follow directly from Lemma 4.4, given that Minimax-\nTest succeds. Therefore, it only remains to bound the failure probability, which equals that probability that\nMinimaxTest fails. This can happen if either line 3 is executed (event E1) or the algorithm in line 5 fails\n(event E2).\nThe event E1occurs when the one of the Poisson random variables in line 1 of Algorithm 3 exceed the\nexpectation by a√log ˆrfactor. Since s1, s2∼Poisson (s/2), we have that ( s1+s2)∼Poisson (s). Thus, by\nLemma 2.2 we have that:\nδpoi= Pr[|(s1+s2)−s|> sp\nlog ˆr]≤2e−s2log ˆr\n2(s+s√log ˆr)=O\u0010\nˆr−s\n2(1+√log ˆr)\u0011\n=O\u00121\npoly(ˆr)\u0013\nfor the value of s=O\u0010\n(ˆr+1)·log(1/δ′)\nε2·log(ˆr+1)\u0011\nchosen.\nCombining the above with Lemma 4.2 via union bound yields Pr(failure )≤Pr(E1) +Pr(E2)≤δpoi+δ′=\nδ.\n5 Practical considerations\nWhile our contributions are mostly theoretical, we discuss some practical considerations here. In particular, we\nwould like to highlight that there is no existing practical implementation of the algorithm of Theorem 2.1 by\nJiao et al. [2018]. As is the case for most state-of-the-art distribution testing algorithms, this implementation is\nhighly non-trivial and requires the use of optimal polynomial approximations over functions, amongst other\ncomplicated constructions.2For completeness, we implemented a proof-of-concept based on the empirical L1\nestimation; see Appendix E. While it is known that the estimation error scales with the sample size in the form\nΩ(r/ε2), we observe good empirical performance when ris sublinear in nor when combined with some of the\npractical extensions that we discussed below.\nSection 5.1 and Section 5.2 can be viewed as ways to extend the usefulness of a given advice. Section 5.3\nprovides a way to “patch” an advice with ˆn < n to one with perfect matching, without hurting the provable\nguarantees. Section 5.4 gives a pre-processing step that can be prepended to any procedure: by losing o(1), one\ncan test whether |T∗|is small and if so learn p∗up to εerror to fully exploit it.\n2The tester proposed by Jiao et al. [2018] requires a significant amount of hyperparameter tuning and no off-the-shelf\nimplementation is available Han [2024]; see Appendix E for more comments.\n10\n\n5.1 Remapping online arrival types\nConsider the graph example in Fig. 3 with type counts c∗and we are given some advice count ˆ cas follows:\nTypes T∗c∗count Types ˆTˆccount\n{u1, u3} 1 {u1} 1\n{u2, u3} 1 {u3} 1\n{u1, u2, u4} 2 {u4} 1\n{u2, u4} 1\nWhile one can verify that both the true graph G∗and the advice graph ˆGhave perfect matching, L1(c∗,ˆc) = 4\nsince as T∗and ˆThave disjoint types. From the perspective of our earlier analysis, ˆcwould be deemed as a\npoor quality advice and one should default to Baseline .\nHowever, a closer look reveals there exists a mapping σfrom T∗toˆTsuch that one can credibly “mimic”\nthe proposed matching of ˆGas online vertices arrive. For example, when an online vertex vwith neighborhood\ntype{u1, u3}arrive, one can “ignore” the edge u3∼vand treat it as if vhad the type {u1}. Similarly, {u2, u3}\ncould be treated as {u3}, the first instance of {u1, u2, u4}could be treated as {u2, u4}, and the second instance\nof{u1, u2, u4}could be treated as {u4}. Running Mimic under such a remapping of online types would then\nproduce a perfect matching! We discuss how to perform such remappings in Appendix C.2.\n5.2 Coarsening of advice\nWhile Theorem 4.1 has good asymptotic guarantees as n→ ∞ , the actual number of vertices nis finite in\npractice. In particular, when nis “not large enough”, TestAndMatch will never utilize the advice and always\ndefault to Baseline for all problem instances where n≪sˆr,ε,δ.\nIn practice, while the given advice types may be diverse, there could be many “overlapping subtypes” and a\nnatural idea is to “coarsen” the advice by grouping similar types together in an effort to reduce the resultant\nsupport size of the advice (and hence sˆr,ε,δ). Fig. 5 illustrates an extreme example where we could decrease the\nsupport size from nto 2 while still maintaining a perfect matching. In Appendix C.1, we explain two possible\nways to coarsen ˆ c.\nˆG\nu1\n...\nun\n2\n...un\n2+1\nunv1\n...\nun\n2\n...vn\n2+1\nvnˆG′\nu1\n...\nun\n2\n...un\n2+1\nunv1\n...\nun\n2\n...vn\n2+1\nvn\nFigure 5: Consider ˆGmade by taking the union of two complete bipartite graphs ( ˆG′) and adding the red dashed\nedges. By connecting vitou(i+n/2)mod n,|ˆT|=r=n. Meanwhile, if we coarsen ˆcintoˆc′by ignoring the red\ndashed edges, ˆG′still has a maximum matching of size ˆn′=nwhile|ˆT′|=r′= 2, thus requiring significantly\nless samples to test since sˆr′,ε,δ≪sˆr,ε,δ. Furthermore, if G∗=ˆG′, then L1(c∗,ˆc) = 2 nand we will reject the\nadvice ˆ cif we do not coarsen it first.\n5.3 Advice does not have perfect matching\nAs the given advice ˆcis arbitrary, it could be the case that any maximum matching of size ˆnin the graph ˆG\nimplied by ˆcis not perfect, i.e. ˆn < n . A natural idea would be to “patch” ˆcinto some other type count ˆc′\nwhich has a maximum matching size of ˆn′=nin the tweaked graph ˆG′. This can be done by augmenting ˆc\n11\n\nwith additional edges between the unmatched vertices in the advice graph to obtain ˆc′. In Appendix C.3, we\nshow how to do this in a way that running TestAndMatch onˆc′does not worsen the provable guarantees as\ncompared to directly using ˆ c.\n5.4 True distribution has small support size\nIf the support size of the true types is o(n), a natural thing to do is to learn c∗up to some εaccuracy while\nforgoing some o(n) initial matches, and then obtain ≈1−εcompetitive ratio on the remaining arrivals. Though\nthis is wholly possible in the random arrival model, it crucially depends on c∗having at most o(n) types.\nAlthough we do not know the support size of c∗a priori, we can again employ techniques from property testing.\nFor any desired support size kand constant ε, Valiant and Valiant [2017], Wu and Yang [2019] tell us that\nO(k\nlogk) samples are sufficient for us to estimate the support size of a discrete distribution up to additive error\nofεk. Therefore, for any k∈o(n) and constant ε, given any algorithm ALG under the random arrival model\nachieving competitive ratio α, we can first spend o(1) arrivals to test whether c∗is supported on (1 + ε)·k\ntypes:\n•If “Yes”, then we can spend another O(k/ε2)⊆o(1) arrivals to estimate c∗up to εaccuracy, i.e. we can\nform ˆ cwith L1(c∗,ˆc)≤ε, then exploit ˆ cviaMimic .\n•If “No”, use ALG and achieve a comp. ratio of α−o(1).\nThe choice of kis flexible in practice, depending on how much one is willing to lose in the o(1) in the “No”\ncase.\n6 Discussion and future directions\nWe studied the online bipartite matching problem with respect to Goal 1.1. We showed that it is impossible\nunder the adversarial arrival model and designed a meta algorithm TestAndMatch for the random arrival\nmodel that is 1-consistent and β·(1−o(1))-robust while using histograms over arrival types as advice. The\nguarantees TestAndMatch degrades gracefully as the quality of the advice worsens, and improves whenever\nthe state-of-the-art βimproves. There are several interesting follow-up questions:\n1.Other versions of online bipartite matching.\nWhether the ideas presented in this work can be generalized to other versions of the online bipartite\nmatching problem is indeed an interesting question. The hardness results of Theorem 3.1 directly translate\nas the unit weight version is a special case of the general case with vertex or edge weights, implying\nimpossibility more general settings. Algorithmically, we believe that the TestAndMatch framework\nshould generalize. However, it would require a different advice quality metric in the space of edge weights\n(e.g., something like earthmover distance), along with a corresponding sample efficient way to test this\nquality with sublinear samples so that one can still achieve a competitive ratio of β·(1−o(1)) when the\ntest detects that the advice quality is bad.\n2.Consistency and robustness tradeoff.\nOur algorithm is a meta-algorithm that is both 1-consistent and β·(1−o(1))-robust, where the robustness\nguarantee improves with the state-of-the-art (with respect to β). As, it is impossible for any algorithm to\nbe strictly better than 1-consistent (by definition of competitive ratio) or strictly better than β-robust (by\ndefinition of β), our algorithm (weakly-)pareto-dominates all other possible algorithm for this problem up\nto an 1 −o(1) multiplicative factor in the robustness guarantee. Can this 1 −o(1) multiplicative factor be\nremoved?\n3.Beyond consistency and robustness.\nTestAndMatch ’s performance guarantee is based on the L1distance over type histograms. This is very\nsensitive to certain types of noise, e.g., adding or removing edges at random (Erdos-Renyi). However,\nSection 5 suggests there are practical extensions that hold even when L1is large, implying it is a non-ideal\nmetric despite satisfying consistency and robustness. Is there another criterion that could fill this gap?\n4.Going beyond Mimic .\nOur current approach exploits advice solely through Mimic , which arbitrarily chooses onematching ˆMto\n12\n\nfollow. Is there a more intelligent way of doing so? For example, Feldman et al. [2009] constructed two\nmatchings to “load balance” in the known IID setting.\n5.Is there a graph where advice coarsening recovers perfect matching while Ranking does not\nhave a competitive ratio close to 1?\nRanking is known to have a competitive ratio of 1 −1/√\nkif there exist kdisjoint perfect matchings in\nthe graph [Karande et al., 2011]. Beyond trivial settings where there are no perfect matchings or having a\npattern connecting to just 1 offline vertex (so that there is at most 1 disjoint perfect matching), we do not\nhave an example with a formal proof that advice coarsening recovers a perfect matching while Ranking\ndoes not have a competitive ratio close to 1. We suspect that one may not be able to construct a graph\nwith few disjoint matchings and few patterns. To see why, fix some graph with a perfect matching and\nsuppose there are qtypes t1, t2, . . . , t qof sizes s1, . . . , s q. By “circularly permuting the matches”, we see\nthat there will be k=min(s1, . . . , s q) disjoint perfect matchings. However, this does not totally invalidate\nTestAndMatch in general. For example, consider the following augmentation to our approach: if ˆc\nhaskdisjoint perfect matchings after coarsening, one can run Ranking instead of Mimic and switch to\nBaseline if the test fails later. By doing so, one pays only an additive 1 /√\nkin consistency by running\nRanking instead of Mimic in the event that the advice was perfect. Note that Baseline may be different\nfromRanking as it is still unknown what is the true β∈[0.696,0.823]. In particular, if β >0.727, then\nBaseline cannot be Ranking [Karande et al., 2011].\n6.Other online problems with random arrivals.\nTestAndMatch did not exploit any specific properties of bipartite matching, and we suspect it may be\ngeneralized to a certain class of online problems.\nAcknowledgements\nThis research/project is supported by the National Research Foundation, Singapore under its AI Singapore\nProgramme (AISG Award No: AISG-PhD/2021-08-013). AB and TG were supported by National Research\nFoundation Singapore under its NRF Fellowship Programme (NRF-NRFFAI1-2019-0002). We would like to\nthank the reviewers for valuable feedback and discussions. DC and CKL thank Anupam Gupta for discussions\nabout learning-augmented algorithms. DC would also like to thank Cl´ ement Canonne and Yanjun Han for\ndiscussions about distribution testing, and Yongho Shin about discussions about learning-augmented algorithms.\nImpact statement\nWhile the contributions of this paper is mostly theoretical, one should be wary of possible societal impacts if\nonline matching algorithms are implemented in practice. For instance, our proposed methods did not explicitly\naccount for possible fairness issues and such concerns warrant further investigation before being operationalized\nin real-world settings.\nReferences\nAnders Aamand, Justin Chen, and Piotr Indyk. (Optimal) Online Bipartite Matching with Degree Information.\nAdvances in Neural Information Processing Systems , 35:5724–5737, 2022.\nMohammad Ali Alomrani, Reza Moravej, and Elias B Khalil. Deep policies for online bipartite matching: A\nreinforcement learning approach. arXiv preprint arXiv:2109.10380 , 2021.\nSpyros Angelopoulos, Christoph D¨ urr, Shendan Jin, Shahin Kamali, and Marc Renault. Online Computation\nwith Untrusted Advice. In 11th Innovations in Theoretical Computer Science Conference (ITCS 2020) .\nSchloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2020.\nAntonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, and Bertrand Simon. Online Metric\nAlgorithms with Untrusted Predictions. In International Conference on Machine Learning , pages 345–355.\nPMLR, 2020a.\n13\n\nAntonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online matching problems\nwith machine learned advice. Advances in Neural Information Processing Systems , 33:7933–7944, 2020b.\nAntonios Antoniadis, Peyman Jabbarzade, and Golnoosh Shahkarami. A Novel Prediction Setup for Online\nSpeed-Scaling. In 18th Scandinavian Symposium and Workshops on Algorithm Theory (SWAT 2022) . Schloss\nDagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2022.\n´Etienne Bamas, Andreas Maggiori, Lars Rohwedder, and Ola Svensson. Learning Augmented Energy Minimiza-\ntion via Speed Scaling. Advances in Neural Information Processing Systems , 33:15350–15359, 2020a.\nEtienne Bamas, Andreas Maggiori, and Ola Svensson. The Primal-Dual method for Learning Augmented\nAlgorithms. Advances in Neural Information Processing Systems , 33:20083–20094, 2020b.\nGiulia Bernardini, Alexander Lindermayr, Alberto Marchetti-Spaccamela, Nicole Megow, Leen Stougie, and\nMichelle Sweering. A Universal Error Measure for Input Predictions Applied to Online Graph Problems. In\nAdvances in Neural Information Processing Systems , 2022.\nBenjamin Birnbaum and Claire Mathieu. On-line bipartite matching made simple. Acm Sigact News , 39(1):\n80–87, 2008.\nAllan Borodin, Christodoulos Karavasilis, and Denis Pankratov. An experimental study of algorithms for online\nbipartite matching. Journal of Experimental Algorithmics (JEA) , 25:1–37, 2020.\nBrian Brubach, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. New algorithms, better\nbounds, and a novel model for online stochastic matching. In 24th Annual European Symposium on Algorithms\n(ESA 2016) . Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2016.\nBrian Brubach, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Online stochastic matching:\nNew algorithms and bounds. Algorithmica , 82(10):2737–2783, 2020.\nCl´ ement L Canonne. A short note on poisson tail bounds. Available at\nhttp://www.cs.columbia.edu/ ccanonne/files/misc/2017-poissonconcentration.pdf, 2019.\nJustin Chen, Sandeep Silwal, Ali Vakilian, and Fred Zhang. Faster fundamental graph algorithms via learned\npredictions. In International Conference on Machine Learning , pages 3583–3602. PMLR, 2022.\nDavin Choo, Themistoklis Gouleakis, and Arnab Bhattacharyya. Active causal structure learning with advice.\nInInternational Conference on Machine Learning , pages 5838–5867. PMLR, 2023.\nFan Chung, Linyuan Lu, and Van Vu. Spectra of random graphs with given expected degrees. Proceedings of\nthe National Academy of Sciences , 100(11):6313–6318, 2003.\nMichael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Faster matchings\nvia learned duals. Advances in neural information processing systems , 34:10393–10406, 2021.\nMichael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Algorithms with\nprediction portfolios. Advances in neural information processing systems , 35:20273–20286, 2022.\nPaul D¨ utting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with Advice. In Proceedings\nof the 22nd ACM Conference on Economics and Computation , pages 409–429, 2021.\nJon Feldman, Aranyak Mehta, Vahab Mirrokni, and Shan Muthukrishnan. Online stochastic matching: Beating\n1-1/e. In 2009 50th Annual IEEE Symposium on Foundations of Computer Science , pages 117–126. IEEE,\n2009.\nYiding Feng, Rad Niazadeh, and Amin Saberi. Two-stage stochastic matching with application to ride hailing.\nInProceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA) , pages 2862–2877. SIAM,\n2021.\nGagan Goel and Aranyak Mehta. Online budgeted matching in random input models with applications to\nAdwords. In SODA , volume 8, pages 982–991, 2008.\nSreenivas Gollapudi and Debmalya Panigrahi. Online Algorithms for Rent-or-Buy with Expert Advice. In\nInternational Conference on Machine Learning , pages 2319–2327. PMLR, 2019.\n14\n\nThemis Gouleakis, Konstantinos Lakis, and Golnoosh Shahkarami. Learning-Augmented Algorithms for Online\nTSP on the Line. In 37th AAAI Conference on Artificial Intelligence . AAAI, 2023.\nYanjun Han. Personal communication (20 Jan 2024), 2024.\nPatrick Jaillet and Xin Lu. Online stochastic matching: New algorithms with better bounds. Mathematics of\nOperations Research , 39(3):624–646, 2014.\nJiantao Jiao, Yanjun Han, and Tsachy Weissman. Minimax estimation of the l{1}distance. IEEE Transactions\non Information Theory , 64(10):6672–6706, 2018.\nBilly Jin and Will Ma. Online bipartite matching with advice: Tight robustness-consistency tradeoffs for the\ntwo-stage model. Advances in Neural Information Processing Systems , 35:14555–14567, 2022.\nChinmay Karande, Aranyak Mehta, and Pushkar Tripathi. Online bipartite matching with unknown distributions.\nInProceedings of the forty-third annual ACM symposium on Theory of computing , pages 587–596, 2011.\nRichard M Karp, Umesh V Vazirani, and Vijay V Vazirani. An optimal algorithm for on-line bipartite matching.\nInProceedings of the twenty-second annual ACM symposium on Theory of computing , pages 352–358, 1990.\nTim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The Case for Learned Index\nStructures. In Proceedings of the 2018 international conference on management of data , pages 489–504, 2018.\nSilvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online Scheduling via Learned\nWeights. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms , pages\n1859–1877. SIAM, 2020.\nThomas Lavastida, Benjamin Moseley, R Ravi, and Chenyang Xu. Learnable and instance-robust predictions\nfor online matching, flows and load balancing. arXiv preprint arXiv:2011.11743 , 2020.\nThomas Lavastida, Benjamin Moseley, R Ravi, and Chenyang Xu. Using predicted weights for ad delivery. In\nSIAM Conference on Applied and Computational Discrete Algorithms (ACDA21) , pages 21–31. SIAM, 2021.\nPengfei Li, Jianyi Yang, and Shaolei Ren. Learning for edge-weighted online bipartite matching with robustness\nguarantees. In International Conference on Machine Learning , pages 20276–20295. PMLR, 2023.\nThodoris Lykouris and Sergei Vassilvitskii. Competitive Caching with Machine Learned Advice. Journal of the\nACM (JACM) , 68(4):1–25, 2021.\nMohammad Mahdian and Qiqi Yan. Online Bipartite Matching with Random Arrivals: An Approach Based\non Strongly Factor-Revealing LPs. In Proceedings of the forty-third annual ACM symposium on Theory of\ncomputing , pages 597–606, 2011.\nVahideh H Manshadi, Shayan Oveis Gharan, and Amin Saberi. Online stochastic matching: Online actions\nbased on offline statistics. Mathematics of Operations Research , 37(4):559–573, 2012.\nAranyak Mehta. Online matching and ad allocation. Foundations and Trends ®in Theoretical Computer\nScience , 8(4):265–368, 2013.\nMichael Mitzenmacher. A Model for Learned Bloom Filters, and Optimizing by Sandwiching. Advances in\nNeural Information Processing Systems , 31, 2018.\nManish Purohit, Zoya Svitkina, and Ravi Kumar. Improving Online Algorithms via ML Predictions. Advances\nin Neural Information Processing Systems , 31, 2018.\nDhruv Rohatgi. Near-Optimal Bounds for Online Caching with Machine Learned Advice. In Proceedings of the\nFourteenth Annual ACM-SIAM Symposium on Discrete Algorithms , pages 1834–1845. SIAM, 2020.\nShinsaku Sakaue and Taihei Oki. Discrete-convex-analysis-based framework for warm-starting algorithms with\npredictions. Advances in Neural Information Processing Systems , 35:20988–21000, 2022.\nGregory Valiant and Paul Valiant. The power of linear estimators. In 2011 IEEE 52nd Annual Symposium on\nFoundations of Computer Science , pages 403–412. IEEE, 2011.\n15\n\nGregory Valiant and Paul Valiant. Estimating the unseen: improved estimators for entropy and other properties.\nJournal of the ACM (JACM) , 64(6):1–41, 2017.\nVijay V Vazirani. Online Bipartite Matching and Adwords (Invited Talk). In 47th International Symposium\non Mathematical Foundations of Computer Science (MFCS 2022) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur\nInformatik, 2022.\nShufan Wang, Jian Li, and Shiqiang Wang. Online Algorithms for Multi-shop Ski Rental with Machine Learned\nAdvice. Advances in Neural Information Processing Systems , 33:8150–8160, 2020.\nAlexander Wei. Better and Simpler Learning-Augmented Online Caching. In Approximation, Randomization,\nand Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2020) . Schloss Dagstuhl-\nLeibniz-Zentrum f¨ ur Informatik, 2020.\nYihong Wu and Pengkun Yang. Chebyshev polynomials, moment matching, and optimal estimation of the\nunseen. The Annals of Statistics , 47(2):857–883, 2019.\n16\n\nA Extended variant of Theorem 3.1\nLet us first prove the case when the algorithm Ais deterministic, but α∈[0,1/2]. We will again use G1andG2\nof Fig. 2 (replicated below for convenience as Fig. 6) as a counterexample. Our argument follows that of the\ncase where α= 0.\nG1\nu1\n...\nun\n2\n...un\n2+1\nunv1\n...\nun\n2\n...vn\n2+1\nvnG2\nu1\n...\nun\n2\n...un\n2+1\nunv1\n...\nun\n2\n...vn\n2+1\nvn\nFigure 6: (Restated) Illustration of G1andG2for Theorem 3.1\nSpecial case: Ais deterministic. As before, we observe that any algorithm cannot distinguish between\ntheG1andG2after the first n/2 arrivals. Suppose Ais (1−α)-consistent. Without loss of generality, by\nsymmetry of the argument, suppose G∗=G2andAis given advice bit ˆi= 2.\nSinceAis (1−α)-consistent, it has to make at leastn\n2−(1−α)·nmatches in the firstn\n2arrivals3, leaving\nat most α·nunmatched offline vertices amongst {u1, . . . u n\n2}. Meanwhile, if G∗=G1instead, there can only be\nat most α·nmatches amongst the remainingn\n2arrivals {vn\n2+1, . . . , v n}, resulting in a total matching size of at\nmostn\n2+α·n=\u00001\n2+α\u0001\n·n. That is, any deterministic Athat is (1 −α)-consistent cannot be strictly more\nthan\u00001\n2+α\u0001\n-robust.\nGeneral case where Acould be randomized. Unfortunately, randomization does not appear to help\nmuch, as we can repeat all of the above arguments in expectation. That is, if ˆi= 2, it follows from consistency\nthat in expectation, at least (1 −α)·nof all vertices must be eventually matched, meaning that in expectation\nthere must ben\n2−α·nmatches in the first half. Now, if G1was the true graph, then in expectation we only\nhave α·npossible matches to make in the second half, thus we have a maximum of\u00001\n2+α\u0001\n·nmatches in\nexpectation when ˆiis wrong.\nB Examples of realized type counts as advice\nExample 1: Online Ads. The canonical example of online bipartite matching is that of online ads [Mehta,\n2013]. Recall that the online vertices are advertisement slots (also called impressions) and the offline vertices are\nadvertisers. We can see that the distribution over types can be possibly forecasted by machine learning models\n(and in fact, indirectly used [Alomrani et al., 2021] for bipartite matching) and used as advice. This directly\ngives us q, possibly bypassing ˆ c. Regardless, the more accurate the forecasting, the lower L1(p∗, q) will be.\nExample 2: Food allocation. Consider a conference organizer catering lunch. As a cost-cutting measure,\nthey cater exactly one food item per attendee, based on their self-reported initial dietry preferences reported\nduring registration (each attendee may report more than one item). During the conference, attendees will queue\nup in random order, sequentially reporting their preferences once again and being assigned their food. Organizers\nhave the flexibility to assign food items based on this new reporting of preferences (or, in a somewhat morally\nquestionable fashion refuse to serve the attendee—though in the unweighted setting, reasonable algorithms\nshould not have to do this!). Alas, a fraction of attendees claim a different preference from their initial preference,\ne.g., because they were fickle, or did not take initial dietry preference questionnaire seriously. Given that food\n3Otherwise, even if the remainingn\n2vertices are matched, Acannot achieve (1 −α)·ntotal matches, violating (1 −α)-consistency\n17\n\nis already catered, how should the conference organizers sequentially distribute meals to minimize hungry\nattendees?\nThe attendees are represented by nonline vertices, while each of the noffline vertices represent one of k\ntypes of food item4. The attendees’ initial preference gives our advice q(the distribution over types of food\nprefernces), which also describes a perfect matching. This preference may differ from the distribution over true\npreferences reported on the day of the conference p. However, one can reasonable assume that only a small\nfraction of attendees exhibit such a mismatch, meaning that the L1(p∗, q) is fairly small and advice should be\naccepted most of the time.\nExample 3: Centralized labor Allocation. Suppose there are nemployees and mjobs. There are η\ndifferent qualifications. This is represented by a binary matrix {0,1}n,η, where Xi,k= 1, if employee iposseses\nqualification k. Therefore, the i-th row of X,Xiis a length ηboolean string containing all of i’s skills.\nFor employee ito perform a job, Xineeds to satisfy a boolean formula (say, given in conjunctive form).\nThis is quite reasonable, e.g., to be an AI researcher, it needs to have knowledge of some programming language\n(Python, Matlab, etc.), some statistics (classical or modern), and some optimization (whether discrete or\ncontinuous). In the bipartite graph, employee ihas an edge to job jif and only if Xisatisfies this formula.\nIn this case, the qualifications of each employee are known by the company, who has access to their employees.\nGiven the qualifications, the set of jobs that may be performed can be computed offline and used as advice.\nThis advice may not be entirely correct: for example, employees may have picked up new skills (hence there\nmay be more edges than we thought, but no less). Of course, there could also be some employees with phoney\nqualifications; this fraction is not too high.\nOne interesting property about this application is that advice may only be imperfect in the sense that edges\ncould be added. This means that if we just mimicked, we are guaranteed to get at least ˆn. Also, the coarsening\nmethod is more easily applied.\nCPractical considerations and extensions to our learning-augmented\nalgorithm\nC.1 Advice coarsening\nWhile Theorem 4.1 has good asymptotic guarantees as n→ ∞ , the actual number of vertices nis finite in\npractice. In particular, when nis “not large enough”, TestAndMatch will never utilize the advice and always\ndefault to Baseline for all problem instances where n≪sˆr,ε,δ.\nIn practice, while the given advice types may be diverse, there could be many “overlapping subtypes” and a\nnatural idea is to “coarsen” the advice by grouping similar types together in an effort to reduce the resultant\nsupport size of the advice (and hence sˆr,ε,δ). Fig. 5 illustrates an extreme example where we could decrease the\nsupport size from nto 2 while still maintaining a perfect matching.\nWhile one could treat this coarsening subproblem as an optimization pre-processing task. For completeness,\nwe show later how one may potentially model the coarsening optimization as an integer linear program (ILP) but\nremark that it does not scale well in practice. That said, there are many natural scenarios where a coarsening\nis readily available to us. For instance, in the online advertising, market studies typically classify users into\n“types” (with the number of types significantly less than n) where each type of user typically have a “core set”\nof suitable ads though the actual realized type of each arrival may be perturbed due to individual differences.\nAnother way to reduce the required samples for testing is to “bucket” the counts which are below a certain\nthreshold to reduce the number of distinct types within the advice. The newly created bucket type will then be\na union of the types that are being grouped together.\nC.1.1 ILP for advice coarsening\nHere, we give an integer linear program (ILP) that takes in any number |ˆT|=ˆrof desired groupings as input\nand produces a grouping proposed advice count ˆcˆronˆrlabels that implies the maximum possible matching.\nRecall that the a smaller number of resulting groups ˆrdirectly translates to fewer samples sˆr,ε,δrequired in\nTestAndMatch . So, to utilize this ILP, one can solve for decreasing values of r=|ˆL|,|ˆL| −1, . . . , 1 and\nevaluate the resulting maximum matching size ˆnrfor each proposed advice count ˆcr. Then, one can either use\n4For practical settings, the types of food items is generally much smaller thatn n.\n18\n\nthe smallest possible rwhich still preserves the size of maximum matching or even combine this with the idea\nfrom Section 5.3 if one needs to further decrease r.\nWe propose to update the labels by taking intersections of the patterns, i.e. for any resulting group gi, we\ndefine its label pattern as ∩v∈giN(v). Since taking intersections only restricts the edges which can be used in\nforming a maximum matching, this ensures that Mimic will always be able to mimic any proposed matching\nimplied by the grouped patterns.\nExplanation of constants and variables\n•Given the nonline input patterns, bi,jis a Boolean constant indicating whether online vertex i∈[n] does\nnothave j∈[n] as a neighbor in its pattern.\n•Main decision variable: xi,jwhether edge from online vertex ito offline vertex jis part of the matching.\n•Auxiliary variable: zi,ℓis an indicator whether online vertex i∈[n] is assigned to group ℓ∈[k].\n•Product variable: wi,j,ℓ=zi,ℓ·zj,ℓis an indicator whether both online vertices iandjare in group ℓ\nThe ILP\nmaxX\n(i,j)∈Exi,j\ns.t.X\nj∈[n]\n(i,j)∈Exi,j≤1 ∀i∈[n] ( C1)\nX\ni∈[n]\n(i,j)∈Exi,j≤1 ∀j∈[n] ( C2)\nxi,j≤1−wi,q,ℓ·bq,j ∀(i, j)∈E, q∈[n], ℓ∈[k] ( C3)\nwi,j,ℓ≤zi,ℓ ∀i∈[n], ℓ∈[k] ( C4)\nwi,j,ℓ≤zj,ℓ ∀j∈[n], ℓ∈[k] ( C5)\nwi,j,ℓ≥zi,ℓ+zj,ℓ−1 ∀i, j∈[n], ℓ∈[k] ( C6)\nkX\nℓ=1zi,ℓ= 1 ∀i∈[n] ( C7)\nxi,j∈ {0,1} ∀ (i, j)∈E\nzi,ℓ∈ {0,1} ∀ i∈[n], ℓ∈[k]\nwi,j,ℓ∈ {0,1} ∀ i, j∈[n], ℓ∈[k]\nExplanation of constraints\n•(C1, C2) Standard matching constraints.\n•(C3) Can only use edge ( i, j) if it is not “disabled” due to intersections. As long as some other vertex in\nthe same group as idoes nothave j, the edge ( i, j) will be disabled.\n•(C4, C5, C6) Encoding wi,j,ℓ=zi,ℓ·zj,ℓ.\n•(C7) Every vertex assigned exactly one group.\nC.2 Remapping online arrival types\nRecall the example described in Section 5.1 and how remapping helps obtain a perfect matching. In fact,\nremappings can only increase the number of matches as these vertices would have been left unmatched otherwise\nunder Mimic . Note that the proposed remappings always maps an online type to a subset so that any subsequent\nproposed matching can be credibly performed.\nIn an offline setting, given c∗andˆc, one can efficiently compute a mapping σthat maximizes overlap using\na max-flow formulation (see Appendix C.2.1) and then redefine the quality of ˆcin terms of L1(σ(c∗),ˆc). As this\nis impossible in an online setting, we propose a following simple mapping heuristic: when type Larrives, map it\nto the largest subset of A⊆Lwith the highest remaining possible match count. Note that it may be the case\nthat all subset types of Lno longer have a matching available to mimic from ˆM. In the example above, we first\nmapped {u1, u2, u4}to{u2, u4}and then to {u4}as ˆconly had one count for {u2, u4}.\n19\n\nC.2.1 Computing the optimal remapping σvia a maximum flow formulation\nConsider the offline setting where we are given the true counts c∗and the advice counts ˆ c.\nSuppose c∗hasrnon-zero counts, represented by: ⟨L∗\n1, c∗\n1⟩,⟨L∗\n2, c∗\n2⟩, . . .⟨L∗\nr, c∗\nr⟩, wherePr\ni=1c∗\ni=n.\nSuppose ˆ chassnon-zero counts, represented by: ⟨ˆL1,ˆc1⟩,⟨ˆL2,ˆc2⟩, . . .⟨ˆLs,ˆcs⟩, wherePs\ni=1ˆci=n.\nTo compute a remapping from c∗toˆcto maximize the number of resulting overlaps, consider the following\nmax flow formulation on a directed graph G= (V, E) with |V|=r+s+ 2 nodes:\n•Create a node for each of L∗\n1, . . . , L∗\nr,ˆL1, . . . , ˆLs.\n•Create a “source” and a “destination” node.\n•Add an edge with a capacity c∗\nifrom the “source” node to each of the L∗\ninodes, for i∈ {1, . . . , r }\n•(∗) Add an edge from L∗\nitoˆLjwith capacity c∗\niifˆLj⊆L∗\ni, fori∈ {1, . . . , r }andj∈ {1, . . . , s }.\n•Add an edge with a capacity ˆ cjfrom each of the ˆLjnodes to the “destination” node, for j∈ {1, . . . , s }.\n•Compute the maximum flow from “source” to “destination”.\nSince the graph has integral edge weights, the maximum flow is integral and the flow across each edge is\nintegral. The resultant maximum flow is the maximum attainable overlap between a remapped c∗andˆc, and\nwe can obtain the remapping σby reading off the flows between on the edges from ( ∗).\nC.3 Augmenting advice to perfect matching\nThe following lemma tells us that there is an explicit way of augmenting ˆcto form a new advice ˆc′such that\nusing ˆc′inTestAndMatch does not hurt the provable theoretical guarantees as compared to directly using ˆc.\nLemma C.1. Letˆcbe an arbitrary type count with labels ˆTimplying a graph ˆGwith maximum matching size ˆn.\nThere is an explicit way to augment ˆcto obtain ˆc′with labels ˆT′such that the implied graph ˆG′has maximum\nmatching size ˆn′=n. Furthermore, running TestAndMatch with a slight modification of Mimic on(ˆc′,ˆT′)\nproduces a matching of size mwhere\nm\nn∗≥m\nn≥(\nˆn\nn−L1(p∗,q)\n2when ˆL1≤2 (1−β)−ε\nβ−o(1) otherwise\nProof. Suppose we are given an arbitrary pattern count ˆcand corresponding labels ˆLsuch that the corresponding\ngraph ˆGhas maximum matching ˆMof size ˆn < n . Let us fix any arbitrary maximum matching ˆM. Denote\nAU⊆Uas the set of k=n−ˆnoffline vertices and AV⊆Vas the set of konline vertices that are unmatched\ninˆM. We construct a new graph ˆG′by adding a complete bipartite graph of size konAU∪AVtoˆG. By\nconstruction, the resulting graph ˆG′has a maximum matching of size ˆn′=ndue to the modified adjacency\npatterns of the online vertices AV.\nWe now explain how to modify the pattern counts and labels accordingly. Define the new set of labels ˆL′as\nˆLwith a new pattern called “New”. Then, we subtract away the counts of AVfrom ˆcand add a count of kto\nthe label “New” to obtain a new pattern count ˆ c′. By construction, we see that |ˆL′|=|ˆL|+ 1 and\nL1(ˆc,ˆc′) =|ˆc(“New”) −ˆc′(“New”) |+X\nℓ∈ˆL|ˆc(ℓ)−ˆc′(ℓ)|=k+k= 2k\nNote that c∗(“New”) = 0. By triangle inequality, we also see that\nL1(c∗,ˆc′)≤L1(c∗,ˆc) +L1(ˆc,ˆc′)≤L1(c∗,ˆc) + 2k\nSlight modification of Mimic. Mimic will now be informed of the sets AUandAValong with the\nproposed matching ˆMfor the online vertices V\\AV. Then, whenever an online vertex varrives whose pattern\ndoes not match any in ˆL, we first try to match vto an unmatched neighbor in AUif possible before leaving it\nunmatched. Observe that this modified procedure can only increase the number of resultant matches since we\ndo not disrupt any possible matchings under ( ˆc,ˆL) while only possibly increasing the matching size via the\ncomplete bipartite graph between AUandAV.\n20\n\nTo complete the analysis, we again consider whether Mimic was executed throughout the online arrivals\nor we switched to Baseline , as in the analysis of Theorem 4.1. Note that now ˆL1is an estimate of L1(c∗,ˆc′)\ninstead of L1(c∗,ˆc) and the threshold is 2\u0010\nˆn′\nn−β\u0011\n−ε= 2(1−β)−εinstead of 2\u0000ˆn\nn−β\u0001\n−εsince ˆn′=n.\nAlso, recall that k=n−ˆn.\nCase 1 :ˆL1<2(1−β)−ε\nThen, TestAndMatch executed Mimic throughout for all online arrivals, yielding a matching of size m≥\nn−L1(c∗,ˆc′)\n2. Therefore,\nm\nn∗≥m\nn≥1−L1(c∗,ˆc′)\n2n≥1−L1(c∗,ˆc) + 2k\n2n= 1−L1(p, q)\n2−n−ˆn\nn=ˆn\nn−L1(p, q)\n2\nCase 2 :ˆL1≥2(1−β)−ε\nRepeat the exact same analysis as in Theorem 4.1 but with ˆrreplaced by ˆr′=|ˆT′|=|ˆT|+ 1 = ˆr+ 1 yields a\nmatching size of at least β·n−sˆr+1,ε,δ·p\nlog(ˆr+ 1), where\nsˆr,ε,δ=O\u0012(ˆr+ 1)·log 1/δ\nε2·log(ˆr+ 1)\u0013\nandsˆr+1,ε,δ·p\nlog(ˆr+ 1)∈o(1).\nD Deferred proofs\nAlgorithm 4 SimulateP\ninput Array Aof online arrivals so far and number of desired i.i.d. samples s, where s≤ |A|\noutput Ts\np∗ ▷si.i.d. samples from p∗\n1:Ts\np∗← ∅ ▷Collect simulated i.i.d. arrivals from p∗\n2:i←0\n3:while |Ts\np∗|< sdo\n4:ifBernoulli( i/n) == 1 then\n5: x←Pick uniformly at random from the set {A[0], . . . , A [i−1]}\n6:else\n7: x←A[i] ▷Uniform at random from c∗under the random arrival model\n8: i←i+ 1\n9:end if\n10: Add xtoTs\np∗\n11:end while\n12:return Ts\np∗\nLemma D.1. In the output of SimulateP (Algorithm 4), Ts\np∗contains si.i.d. samples from the realized type\ncount distribution p∗=c∗/nwhile using at most sfresh online arrivals.\nProof. With probability i/n, we choose a uniform at random item from {A[0], . . . , A [i−1]}. With probability\n1−i/n, we pick the next item A[i] from the existing arrivals which was uniform at random under the random\narrival model assumption. Since we could possibly reuse arrivals, Ts\np∗is formed by using at most sfresh\narrivals.\nD.1 Proof of Theorem 2.1\nTheorem 2.1 (adapted from Jiao et al. [2018]) .Fix a reference distribution qover a domain Tof size\n|T|=rand let s∈ O\u0010\nr·log(1/δ)\nε2·logr\u0011\nbe an even integer. There exists an algorithm that draws s1+s2IID samples\nfrom an unknown distribution pover T, where s1, s2∼Poisson (s/2), and outputs an estimate ˆL1such that\n|ˆL1−L1(p, q)| ≤εwith success probability at least 1−δ.\n21\n\nProof. Using Theorem 2 in Jiao et al. [2018], we get that using s= Θ(r\nε2logr), their estimator has εadditive\nerror in expectation. Therefore, by using 100 ·ssamples, we can achive ε/10 additive error in expectation, i.e\nE[|ˆL1−L1(p, q)|] =ε/10. By Markov’s inequality, we get:\nPr[|ˆL1−L1(p, q)|> ε]≤1/10\nThus, by repeating the entire algorithm O(log(1/δ)) times and choosing the median ˜L1of the resulting estimates,\nwe get:\nPr[|˜L1−L1(p, q)|> ε]≤δ\nE Proof of concept\nIt is our understanding that the tester proposed by Jiao et al. [2018] requires a significant amount of hyperpa-\nrameter tuning and no off-the-shelf implementation is available [Han, 2024]. One may consider using an older\nmethod by Valiant and Valiant [2011] which is also sublinear in the number of samples but their proposed\nalgorithm is for non-tolerant testing and requires a non-trivial code adaptation before it is applicable to L1\nestimation.\nAs a proof-of-concept, we implemented TestAndMatch with the empirical L1estimator and study the\nresultant competitive ratio under degrading advice quality. The source code is available at https://github.\ncom/cxjdavin/online-bipartite-matching-with-imperfect-advice .\nE.1 Implementation details\nFrom Section 2, we know that the state-of-the-art advice-less algorithm for random order arrival is the Ranking\nalgorithm of Karp et al. [1990] which achieve a competitive ratio of β= 0.696 [Mahdian and Yan, 2011].\nFor our testing threshold, we set ε=ˆn/n−βso that τ= 2(ˆn/n−β)−ε=ˆn/n−β. We also implemented\nthe following practical extensions to TestAndMatch which we discussed in Section 5:\n1. Sigma remapping (Section 5.1)\n2. Bucketing so that ˆ r/ε2< n(Section 5.2)\n3. Patching so that ˆ n′=n(Section 5.3)\nWe tested 4 variants of TestAndMatch , one with all extensions enabled and three others that disables\none extension at a time (for ablation testing).\nE.2 Instances\nOur problem instances are generated from the synthetic hard known IID instance of Manshadi et al. [2012]\nwhere any online algorithm achieves a competitive ratio of at most 0.823 in expectation:\n•LetYkdenote the set of online vertices with krandom offline neighbors (out of\u0000n\nk\u0001\n)\n•Letm=c∗\n2.5\n2·n, where c∗\n2.5= 0.81034 is some constant defined in Manshadi et al. [2012] (not to be\nconfused with our type counts c∗)\n•Sample mrandom online vertices from Y2, i.e. each online vertex is adjacent to a random subset of 2\noffline vertex.\n•Sample mrandom online vertices from Y3, i.e. each online vertex is adjacent to a random subset of 3\noffline vertex.\n•Sample n−2mrandom online vertices from Yn, i.e. each online vertex is adjacent to every offline vertex.\n•Permute the online vertices for a random order arrival\nHere, the support size of any generated type count c∗is roughly 0 .8ndue to the samples from Y2andY3.\n22\n\nE.3 Corrupting advice\nStarting with perfect advice ˆ c=c∗, we corrupt the advice by an αparameter using two types of corruption.\n1. Pick a random α∈[0,1] fraction of online vertices\n2.Generate a random type for each of them by independently connecting to each offline vertex with\nprobabilitylnn\n10n.\n3.Type 1 corruption (add extra connections): Define the new type as the union of the old vertex type and\nthe new random type.\n4. Type 2 corruption (replace connections): Define the new type as the new random type.\nAs a remark, our random type generation biases towards a relatively sparse corrupted graph.\nE.4 Preliminary results\nWe generated 10 random graph instances with n= 2000 offline and nonline vertices. Fig. 7 illustrates the\nresulting plots with error bars.\nFigure 7: n= 2000, averaged over 10 runs. TaM refers to our implementation of TestAndMatch .\nIn all cases, we see that the attained competitive ratio is highest when all extensions are enabled. We also\nsee that the degradation below the baseline is not very severe ( <0.1 for all cases, even when not all extensions\nare enabled).\nUnsurprisingly, the competitive ratios of Ranking and “TaM without bucket” coincide because because\nr/ε2> nand we always default to baseline without performing any tests (to maintain robustness).\nFor corruption type 1, the “sigma remapping” extension makes our algorithm robust against additive edge\ncorruption, and so the “patching” extension has no further impact.\n23",
  "textLength": 76290
}