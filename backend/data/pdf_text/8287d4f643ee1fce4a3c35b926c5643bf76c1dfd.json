{
  "paperId": "8287d4f643ee1fce4a3c35b926c5643bf76c1dfd",
  "title": "One Model to Rule them All: Towards Zero-Shot Learning for Databases",
  "pdfPath": "8287d4f643ee1fce4a3c35b926c5643bf76c1dfd.pdf",
  "text": "One Model to Rule them All:\nTowards Zero-Shot Learning for Databases\nBenjamin Hilprecht\nTechnical University of Darmstadt\nGermanyCarsten Binnig\nTechnical University of Darmstadt\nGermany\nAbstract\nIn this paper, we present our vision of so called zero-shot learn-\ning for databases which is a new learning approach for database\ncomponents. Zero-shot learning for databases is inspired by recent\nadvances in transfer learning of models such as GPT-3 and can\nsupport a new database out-of-the box without the need to train\na new model. Furthermore, it can easily be extended to few-shot\nlearning by further retraining the model on the unseen database.\nAs a first concrete contribution in this paper, we show the feasi-\nbility of zero-shot learning for the task of physical cost estimation\nand present very promising initial results. Moreover, as a second\ncontribution we discuss the core challenges related to zero-shot\nlearning for databases and present a roadmap to extend zero-shot\nlearning towards many other tasks beyond cost estimation or even\nbeyond classical database systems and workloads.\n1 Introduction\nMotivation. Building computer systems often involves solving\ncomplex problems in all layers of those systems. To reduce complex-\nity when building those computer systems and solve the problems\nin a tractable manner, these systems have heavily relied on heuris-\ntics or simplified analytical models in the past. Very recent work in\nthe systems community, however, has outlined a broad scope where\nmachine learning vastly outperforms these traditional heuristics.\nThis is also the case for databases, where existing DBMS compo-\nnents have been replaced with learned counterparts such as learned\ncost and cardinality estimation models [ 9,11,13,23,28,31] as well\nas learned query optimizers [ 15,20–22] or even learned indexes\n[6–8, 14] and learned query scheduling strategies [19, 27].\nThe predominant approach that has been used in the past for\nlearned database components is workload-driven learning. The idea\nof workload-driven learning is to capture the behavior of a DBMS\ncomponent by running a representative set of queries over a given\ndatabase and then use the observations to train the underlying\nmodel. For example, for learned cardinality estimation models such\nas [13,28] a set of queries must be executed to collect query plans\nand their cardinalities, which serve as training data for learning a\nmodel that can be used to estimate the cardinalities for new queries.\nThe very same procedure is applied if workload-driven learning\nis used for the other DBMS components such as learned physical\ndesign advisors (e.g., an advisor for index selection) [ 18,34] or other\ncomponents.\nHowever, a major obstacle to these workload-driven approaches\nis the collection of training data. For example, in [ 13,28] it was\nshown that thousands of query plans and their true cardinalities are\nneeded for training the model to achieve a high accuracy. Running\nsuch a set of training queries on potentially very large databases\nto collect the training data can take hours or even days while theactual training of the underlying models often only takes a few\nminutes. And unfortunately, the training data collection needs to\nbe repeated for every new database that needs to be supported.\nTo reduce the high cost of training data collection, reinforcement\nlearning (RL) has been used to execute training queries [ 10,17,18,\n34] in a more targeted manner (i.e., letting the RL agent decide\nwhich queries to execute next). However, even with reinforcement\nlearning still a large amount of training queries needs to be executed\nfor learning a model. Moreover, training the model is not a one-\ntime effort since similar to workload-driven approaches the learning\nprocedure needs to be repeated for every new database at hand.\nA different direction that has thus been proposed to avoid the\nexpensive training data collection by running queries on a new\ndatabase are so called data-driven approaches [ 11,31,32] that learn\na model purely from the underlying data. A prime example where\ndata-driven learning is a perfect fit is cardinality estimation. How-\never, data-driven learning is no silver bullet either since for some\nDBMS components the information about the runtime behavior of\nqueries is required. One such example is learned physical cost esti-\nmation where the runtime behavior of queries needs to be captured\nby a model to make predictions. A similar observation holds for\nmany other database tasks such as physical design tuning or knob\ntuning where the effects of a certain decision on the runtime of a\nworkload need to be learned.\nVision and Contributions. In this paper, we thus present our vi-\nsion of so called zero-shot learning for databases which is a new\nlearning approach for database components that can support a\nbroad set of tasks on the one hand but does not require to collect\ntraining data for supporting a new database on the other hand. In\nthat regard, zero-shot learning for databases combines the benefits\nof data-driven learning and workload-driven learning. The gen-\neral idea behind zero-shot learning for databases is motivated by\nrecent advances in transfer learning of models. Similar to other\napproaches such as GPT-3 [ 3] which enables zero-shot learning for\nNLP, a zero-shot model for databases is trained on a wide collection\nof different databases and workloads and can thus generalize to\na completely new database and workload without the need to be\ntrained particularly on that database.\nAs a core contribution in this paper, we discuss how such an\napproach of zero-shot learning for databases could work and we\nalso show the feasibility of this approach for the task of physical\ncost estimation. In our initial results for physical cost estimation, we\nshow that zero-shot models can significantly outperform workload-\ndriven approaches even when providing workload-driven models\nwith a large number of training queries for a particular database at\nhand whereas zero-shot models can support them out-of-the-box.\nMoreover, we believe that the real power of zero-shot learning\nstems from the fact that it is a general principle that can be usedarXiv:2105.00642v4  [cs.DB]  3 Jan 2022\n\nBenjamin Hilprecht and Carsten Binnig\nfor various learned database tasks. For example, we already have\ninitial promising results suggesting that zero-shot learning can not\nonly be used for physical cost estimation on a new database but\nalso for physical design tuning and, in particular, index selection\non a database the model has not seen before.\nFinally, an important aspect of zero-shot models is that zero-shot\nlearning can easily be extended to few-shot learning . Hence, instead\nof using the zero-shot model out-of-the box (which already can\nprovide good performance), one can fine-tune the model with only\na few training queries on an unseen database or task. Compared to\nworkload-driven learning, few-shot learning will require way fewer\ntraining queries for adaptation since the general system behavior\nis already internalized by the zero-shot model.\nOutline. The remainder of this paper is structured as follows:\nSection 2 first gives an overview of zero-shot learning for databases\nand discusses the core challenges related to zero-shot learning.\nSection 3 then discusses the case study of using our approach for\nlearning a zero-shot physical cost model. Moreover, in this sec-\ntion we also present our initial experimental results. Afterwards,\nSection 4 discusses a research roadmap for zero-shot learning for\ndatabases beyond cost estimation. Finally, we conclude with a peak\ninto the future in Section 5.\n2 Zero-Shot Learning for Databases\nIn this section, we first give a brief overview of how zero-shot\nlearning for databases works in general and then discuss the core\nchallenges related to enable this approach in an efficient manner.\n2.1 Overview of the Approach\nFigure 1 shows the high-level idea that is behind our vision of\nzero-shot learning for databases. During the learning phase, similar\nto workload-driven learning, for zero-shot learning we have to\nexecute a representative workload and collect training data.\nThe main difference to workload-driven learning though, which\nmakes our approach attractive, is that zero-shot models generalize to\nunseen databases out-of-the-box . To allow a zero-shot model to make\npredictions about unseen databases without the need to retrain\nthe model for this particular database, we provide a new method\nof representing queries as we discuss below (cf. Key Challenges).\nThis transferable representation is at the core of learning zero-shot\nmodels in a generalizable way and thus enables them to make\npredictions for queries on a new database (e.g., for physical cost\nestimation) that the model has never seen before.\nMoreover, for being able to generalize to new databases, a zero-\nshot model is trained on different databases. While this might seem\nto cause high upfront costs before a zero-shot model can be used,\nit is important to note that the training data collection is a one-\ntime-effort which is very different from workload-driven learning\nthat needs to collect training data for every new database a model\nshould support. Moreover, cloud database providers such as AWS,\nMicrosoft, or Google, typically already have significant amounts of\nsuch information available since they keep logs of their customer\nworkloads and could thus apply zero-shot learning right away\nwithout the need to collect training data in the first place.\nFinally, a last important aspect is that zero-shot learning is not\nonly generalizable across databases but is a new learning approach\nDB1\nDB2\n...\nDBn+ Workload1\n+ Workload 2\n+ Workload nRuntimes, Ressources, ...\nTraining  \nDataRuntimes, Ressources, ...\nRuntimes, Ressources, ...Training a Zero-Shot Model\nFeatures Labels Zero-Shot Model\nDBx+ Workloadx Runtimes, Ressources, ...\nFeatures Predictions(one-time-effort)\nInference on Unseen Database\n(for every new database)\nZero-Shot ModelFigure 1: Overview of zero-shot learning for databases. In\nline with other zero-shot approaches such as GPT-3 which\nenables zero-shot learning for NLP, a zero-shot model for\ndatabases can generalize to a completely new database and\nworkload without the need to be trained on that particular\ndatabase.\nthat can be applied to a variety of database tasks that range from\nphysical cost estimation, design tuning or knob tuning to query\noptimization and scheduling as we discuss in Section 3 and Sec-\ntion 4. To enable zero-shot models to generalize to different tasks\nthough, the models need to be capable of capturing not only infor-\nmation about query plans and their runtimes but also information\nabout other aspects (e.g., how indexes or changes in the database\nconfiguration influence the query runtime) as we discuss later.\n2.2 Key Challenges\nEnabling zero-shot learning for databases comes with various re-\nsearch challenges. In the following, we discuss the key challenges\nthat we think are at the core to make zero-shot learning for databases\nefficient and accurate.\nTransferable Representation of Database and Queries. State-of-the-\nart workload-driven models [ 13,28] can only leverage training data\nfrom a single database and thus they cannot simply be trained on a\nvariety of databases to obtain zero-shot models. The reason is that\nthe query representation is not transferable to an unseen database.\nFor instance, attributes names (e.g., those used in filter predicates)\nare typically encoded using a one-hot encoding assigning each\ncolumn present in the database a specific position in a feature\nvector. Hence, the column production_year of the IMDB dataset\nmight be encoded using the vector (0,1,0)(assuming that there\nare only three columns in total). If the same model is now used to\npredict query costs for the SSB dataset, the second column in the\ndatabase might be region , which has very different semantics (i.e.,\nvery different data distributions or even a different data type). As\nsuch, cost models based on non-transferable representations will\nproduce estimates that are most likely way off. In fact, such non-\ntransferable feature encodings are used in various places of query\nrepresentations such as table names as part of plan operators or\nliterals in filter predicates. Hence, for zero-shot models we require a\nnovel representation of queries that is transferable across databases\nwhile still being expressive enough to enable accurate estimations.\n\nOne Model to Rule them All:\nTowards Zero-Shot Learning for Databases\nAggregate\nHash Join\nSeq ScanHash\nSeq Scan\ntitlemovie_companies > ...\nproduction_yearMIN(...)\n ...= ...\ntitle_idmovie_id = ...\ncompany_type_id\nSELECT MIN(t.production_year ) FROM movie_companies  mc,title t  \nWHERE t. id=mc.movie_id  AND t.production_year >1990 AND\nmc.company_type_id =2;Operator (One-Hot) CardinalityTuple  \nWidthGraph Encoding\nPredicate Operator (One-Hot)...\nData T ype (One-Hot) Width ...\n1          0           0 4 ...\nNo T uples No Pages\n21 211          0           0 1 4 ...\n0          0           0           1 ......0          0           1 230K 4 ...\n0          1           0 550K 4 ...\nExample QueryEncode Physical Plan Operators, Predicates\nTables and Columns as a GraphT ransferable  Featurization\nNode Featurization generalizes\nacross DatabasesZero-Shot Encoding  \n(Transferable Representation)\n+\nFigure 2: Graph encodings with transferable features as a\nzero-shot encoding. The query is represented as a graph\nwith different node types (for plan operators, predicates, ta-\nbles, columns etc.) and nodes are annotated with transfer-\nable features. The representation allows the model to gener-\nalize across databases since features remain consistent.\nWe will now introduce query graph encodings with transferable\nfeatures (cf. Figure 2) which generalize across databases and have\nthe potential to be applied in various zero-shot learned database\ncomponents. While graph-based encodings have already been used\nto represent query plan operators and predicates [ 28], we in con-\ntrast encode the entire query as a graph (including tables, columns\netc.) and use transferable features per node allowing models using\nthis representation to generalize across databases. For instance,\nan involved column production_year would now be represented\nusing a graph node with transferable features (e.g., the data type).\nIf the same model is now deployed for a different database such as\nSSB, the corresponding columns would be represented using differ-\nent graph nodes with their corresponding data characteristics and\nthus the representation is not inconsistent for different databases\n(in contrast to one-hot encodings of columns).\nWhile the previously presented representation already allows\nto represent queries in a very expressive way, extensions might\nbe necessary depending on the specific task that should be solved.\nWhen designing a representation for a specific task, it is important\nthat the representation (i) captures all important aspects such that\nthe models are able to solve the task at hand and (ii) that the repre-\nsentation is consistent for different databases (i.e., transferable).\nTraining Data Collection and Robustness. A second key challenge\nto enable zero-shot learning is clearly the training data collection\nfor learning a zero-shot cost model. Here an important question is\nhow many and which databases and workloads a zero-shot model\nneeds to observe during training to make robust decisions on un-\nseen databases. As we show in our initial experiments for zero-shot\ncost estimation in Section 3, for example, already a relatively smallnumber of databases along with the respective workload informa-\ntion (e.g., the featurized query plans and runtimes) is sufficient to\ngeneralize robustly and even outperform existing workload-driven\napproaches. However, clearly we need to develop more theoretical\nfoundations to help guide us as to whether or not a zero-shot model\nhas seen sufficiently many databases and queries.\nOne way to address this could be to evaluate the model on test\ndatabases that have not been used during training similar to the\ncommon practice in machine learning to evaluate a model on a\nholdout set. While this could provide an initial model validation,\nclearly more theoretical foundations are needed depending on the\nconcrete task. A related question in this respect is how to create\nthe training databases and workloads if they are not yet available\n(as for cloud providers). An interesting direction here is to use\na synthetic approach and generate databases / workloads with\ndifferent characteristics.\nSeparation of Concerns. Finally, a last important aspect of zero-\nshot models is to decide what should be learned by the model to\nfulfill its core promise and when to separate concerns. For exam-\nple, workload-driven approaches often prefer end-to-end learning,\ni.e., to make predictions for a query plan (e.g., the runtime), they\ninternalize both the data characteristics (e.g., the data size and dis-\ntributions) as well as the system characteristics (e.g., the runtime\ncomplexity of database operators) in one model.\nHowever, since the data characteristics can be entirely different\nfor a new database, such an end-to-end approach will not work\nfor zero-shot learning. Hence, we suggest that data characteristics\nfor zero-shot learning should be captured by separate data-driven\nmodels (such as [ 11,31]). For example, a feature that can be cap-\ntured by a data-driven model are the input- and output-cardinalities\nof operators in a query plan. That way, when using cardinalities\nas input features for the zero-shot models, these models learn to\npredict the runtime behavior of operators based on input/output\nsizes that can be derived for any database which again enables a\ntransferable representation of queries that does not depend on the\nconcrete data distribution of a single database.\nOne could now argue that this violates the core promise of zero-\nshot learning since data-driven models need to be learned for each\nnew database. However, data-driven models can be derived from a\ndatabase without running any training query and typically a sam-\nple of the database is enough to train these models. Moreover, for\ncardinality estimation we could even use simple non-learned esti-\nmators (e.g., histograms) as input for the zero-shot models. As we\nshow in our initial results in Section 3, even those simple estimators\noften provide sufficient evidence for our zero-shot cost models to\nproduce accurate estimates.\nTo summarize, a key question in this context is to decide what a\nzero-shot model should learn and which aspects should be treated\nseparately. Clearly a guide for this question is to think about what\nis tied to a particular data distribution and which aspects hold\nin general which should then be included in the zero-shot model.\nMoreover, as we discuss later, for design tuning or query optimiza-\ntion another question is how to combine zero-shot models with\noptimization procedures or other learning approaches (e.g., value\nnetworks) to implement efficient search strategies.\n\nBenjamin Hilprecht and Carsten Binnig\n3 Case Study: Cost Estimation\nIn this case study, we demonstrate how zero-shot learning can be\nused for physical cost estimation. We envision this to be a potential\ncore building block for zero-shot models for many other DBMS\ntasks as we discuss in the next section.\n3.1 Zero-Shot Cost Estimation\nThe main promise of zero-shot cost estimation is that a trained\nmodel can predict the query runtime on a new database out-of-\nthe-box. In the following, we give a brief overview of how we\nimplemented our initial prototype for zero-shot cost estimation for\nPostgres and contrast it to recent workload-driven approaches for\ncost estimation using the example query plan.\nAt the core, we use a transferable query representation as in-\ntroduced in Figure 2 and propose a new architecture to capture\nthe graph structure. As depicted in the figure, each node in this\ngraph represents a physical operator (as opposed to a logical op-\nerator) to capture the differences in runtime complexity during\nlearning. In addition, we use nodes to represent involved tables,\ncolumns, aggregations and predicates whereas for each node we\nuse transferable features. For instance, the movie_companies table\nuses generalizable features such as the number of tuples and pages.\nNote that for state-of-the-art workload-driven learning, the table\nwould instead be represented as a one-hot encoded vector which\ndoes not enable generalization across databases as discussed before.\nMoreover, as mentioned before, for zero-shot models we want\nthe model to learn the general runtime behavior of operators in\na DBMS (i.e., system characteristics). Hence, the zero-shot model\nshould learn system characteristics separate from data character-\nistics. This is very different from workload-driven models which\nlearn both aspects end-to-end in one model as mentioned before.\nFor instance, workload-driven models include the values involved\nin filter predicates (e.g., 1990 ) in the featurization of a query and\nthus learn the selectivity of the filter operation implicitly. In con-\ntrast, for zero-shot models we only encode the predicate structure\n(to represent the general computational complexity) and explicitly\nuse estimated cardinalities from a data-driven model or the query\noptimizer as input.\nFinally, a last important aspect is our proposed model architec-\nture as well as the learning and inference procedure for a featurized\nplan. Here, we exploit that the graph encoding results in DAGs\nwhere the root node of the plan are also the root nodes of the\nDAGs. The learning overall happens in three steps: we first encode\nthe features of the individual nodes in a fixed-size hidden vector\n(the initial hidden states). The hidden states of the individual plan\nnodes are afterwards combined using a bottom-up message pass-\ning phase in the DAG. Finally, the hidden state of the root node\nis fed into a multilayer perceptron (MLP) which predicts the final\nruntime. In particular in the message passing phase, the DAG is\ntraversed bottom up. The hidden states of the children are summed\nup (similar to the DeepSets [ 33] architecture) and combined with\nthe hidden state of the parent node using an MLP to update the\nhidden state. This process is repeated until the root node is reached\nand the information of the entire tree is combined. For inference\nto make a prediction for a query plan on a new database, a new\nDAG is constructed using the node-specific MLPs and the featuresare propagated through the tree up to the root node which then\npredicts the runtime for the new query.\n3.2 Initial Evaluation\nSetup and Baselines In an initial experiment, we trained a zero-\nshot cost estimation model on workloads we executed on a set of\npublicly available datasets that cover a range of databases with a\ndifferent number of tables and database sizes. We then predicted the\nruntimes for a workload on an entirely unseen database to validate\nthat zero-shot cost estimation can provide high accuracies.\nAs baselines, we used state-of-the-art workload-driven approaches\nfor cost estimation. In particular, we used the end-to-end model of\n[28] called E2E and the MSCN architecture [ 13] that was initially\nproposed for cardinality estimation. In addition, we use a simple\nlinear model that obtains actual runtimes from the internal cost\nmetric of the Postgres optimizer (called Scaled Optimizer Cost).\nTraining of Baselines and Zero-Shot Models For the workload-\ndriven models, we collected training data of different sizes ranging\nfrom a small training set size of 100queries up to very large training\nsets with 50 ,000queries (similar to [ 28]). Note, that for every new\ndatabase such training queries need to be executed and the runtimes\nneed to be collected before a workload-driven model can be trained.\nMoreover, if the database is updated and data characteristics change,\nthe training data collection needs to be repeated.\nFor training the zero-shot model, we also need to collect training\ndata. Overall, this gathering of the training data is clearly a signifi-\ncant effort. However, as mentioned before this is a one-time effort\nand the resulting model can be reused across different databases.\nTo decide which number of training databases and workloads is\nsufficient, we evaluated the performance on a holdout test database\nas we added additional training databases. For each of the training\ndatabases we randomly generated 5,000training queries which\nwe used as training data. After 19 databases, the performance stag-\nnated and we can thus conclude that already a moderate number\nof training databases is sufficient for zero-shot models to gener-\nalize. In total the workload size for zero-shot learning was thus\nin a similar ballpark compared to the maximum size we used for\ntraining the workload-driven baselines. Moreover, the queries for\nzero-shot learning and workload-driven learning were similar and\ncovered up to five-way joins with up to five numerical and categor-\nical predicates and up to three aggregates. However, different from\na workload-driven model, the zero-shot model was not trained on\nthe database it should make a prediction on.\nInitial Results To evaluate the trained models, we used our zero-\nshot model as well as the other baselines to predict the runtimes\nof the commonly used scale ,synthetic and job-light benchmarks\n[13] on the IMDB database. For zero-shot models, we show two\nversions: one that that uses the Postgres cardinalities as input as\nwell as one version, which uses exact cardinalities (as an upper\nbaseline to show how accurate zero-shot models can become).\nAs a result, we report the commonly used Q-error which is the\nfactor the predicted runtime deviates from the true runtime. The\nadvantage of zero-shot learning over workload-driven approaches\nis that no queries on the test database are required for training. To\ndemonstrate this tradeoff, we vary the number of training queries\nthat can be used for the workload-driven baselines and compare\nthe accuracy with zero-shot learning in Figure 3. Overall, zero-shot\n\nOne Model to Rule them All:\nTowards Zero-Shot Learning for Databases\n102103104\nNumber of Training Queries1.52.02.5Median Q-Error\nScale\n102103104\nNumber of Training Queries1.52.02.5\nSynthetic\n102103104\nNumber of Training Queries23\nJOB-light\n102103104\nNumber of Training Queries02550Execution Time (h)\nMSCN (Workload-Driven)\nE2E (Workload-Driven)\nScaled Optimizer Costs (Postgres)\nZero-Shot\n(Exact Cardinalities)\nZero-Shot\n(Est. Cardinalities)\nFigure 3: Estimation Errors of Workload-Driven Models for a varying Number of Training Queries compared with Zero-Shot\nCost Models. The zero-shot models were trained using query executions on entirely different databases and thus do not require\nany queries on the IMDB database. In contrast, even the most accurate workload-driven model (E2E) requires approximately\n104query executions on an unseen database for a comparable performance with zero-shot models which is roughly equivalent\nto13hours of executed workload. Since zero-shot models do not require any additional queries it is significantly cheaper to\ndeploy them for a new database.\nlearning can predict the runtimes very accurately. Since the IMDB\ndataset was never used for one of the training queries this shows,\nthat zero-shot learning can generalize to unseen databases. Inter-\nestingly, even the zero-shot model using only cardinality estimates\nof the Postgres optimizer is still very accurate.\nIn contrast, the workload-driven E2E models [ 28] are less accu-\nrate than zero-shot models even for a large set of training queries on\nthe IMDB database for the scale and synthetic benchmarks. For the\nsimpler job-light queries that rarely contain range predicates, the\nE2E model is on par with the zero-shot model for the larger training\nsets. However, still the E2E models cannot match the performance\nof zero-shot learning with exact cardinalities. In addition, we note\nthat the MSCN models are significantly less accurate since they use\na much simpler featurization based on one-hot encodings (and not\na tree-based featurization). Moreover, note that even though we\nrepeated all measurements multiple times and report the median\nthere are still some peaks in the reported Q-errors of MSCN due to\na particularly high variance.\nWhile our initial results are promising, in future we plan to\nconduct more extensive experiments that show the robustness of\nzero-shot learning in several dimensions (e.g., more complex queries\nbut also other databases).\n4 Beyond Cost Estimation\nIn the following, we will discuss how zero-shot models can be\nextended beyond cost estimation.\n4.1 Physical Design and Knob Tuning\nA first clear extension of zero-shot cost models as described in Sec-\ntion 3 is to allow them to support a so called “What-If” mode. This\nenables zero-cost models to predict the runtime of a query given\na certain physical design or a database configuration (also called\nknob configuration). For example, one could then ask the model\nhow the runtime of a query changes if a certain index would exist\nor how the runtime changes if the buffer size would be increased.\nBoth these tasks — physical design and knob tuning — are classi-\ncal problems of DBMSs that have been addressed in the past already\nby using optimization approaches [ 1,4,5,24,25]. However, the\nmain problem was that these approaches relied on inexact cost\nestimates coming from classical optimizer cost models that were\nextended to support a “What-If” mode. For that reason, recent\napproaches have suggested to use workload-driven learning — in\nmany cases reinforcement learning [ 2,10,16,18,26,30,34]. Whilethese approaches have been shown to be more accurate than the\nmore classical approaches, they again need to first run training\nqueries under different physical layouts or knob configurations for\nevery new database.\nHence, to avoid these high-training costs for every new database\none could use a zero-shot cost model in a “What-If” mode. To\nshow the feasibility of this direction, we extended our zero-shot\ncost model to support also decisions towards index tuning. At\nthe core, the zero-shot model for index tuning should be able to\nsupport predictions of the runtime as if a certain index would exist\nin a database. For training a zero-shot cost model that can answer\nsuch questions, we again used the 19 databases as training data\nthat we also used in Section 3. However, we additionally created\na random but fixed set of indexes per database before running\nthe training queries. The zero-shot cost model could recognize for\nwhich training query an index was used since the physical operators\nin a query plan change (e.g., an index scan instead of a table scan\nwas used). The zero-shot model could thus learn how the runtime\nchanges for query plans, which use an index scan compared to\nquery plans which do not use an index scan.\nFor showing that the learned model could estimate the runtime\nof queries correctly given a certain index, we again use the IMDB\ndatabase for the evaluation that the zero-shot model had not seen\nbefore. For testing, we asked the model to estimate the runtime\nof queries if an index would exist again for randomly selected\nattributes of queries. The estimation errors for zero-shot learning\nfor this workload are given in Table 1 (last line). As we can see,\nthe estimations are still very accurate but clearly the maximum\nQ-error increases compared to the results for zero-shot cost models\nin Section 3 before (upper lines).\nTo further improve the quality of zero-shot cost models for in-\ndex tuning one might need to think about a more sophisticated\nworkload sampling or provide additional characteristics for indexes\n(e.g., expected index height) as input features to a zero-shot model\nthat could be derived with additional data-driven models. Further-\nmore, we think that we could use zero-shot models to build other\ndesign advisors (e.g., for materialized views) or support zero-shot\nknob tuning to select an optimal database configuration for a given\nworkload without having seen the database for training. Finally, for\nknob tuning one could also think about using zero-shot models to\nonly guide the search initially to a good start configuration (i.e., to\nnarrow down the search space) and then use online approaches for\n\nBenjamin Hilprecht and Carsten Binnig\nZero-Shot (Exact Card.) Zero-Shot (Estimated Card.)\nWorkload median 95th max median 95th max\nScale 1.19 1.93 3.93 1.26 2.46 4.70\nSynthetic 1.17 1.90 4.40 1.21 2.17 6.88\nJOB-light 1.18 1.85 2.47 1.33 2.56 4.00\nIndex 1.21 2.51 10.73 1.33 3.59 24.62\nTable 1: Estimation errors (Q-errors) of zero-shot models for\nindex tuning (last line) compared to zero-shot cost models\nwithout What-if support (upper lines).\nfine-tuning the knobs since knobs can be changed easily compared\nto the high cost of changing a physical layout.\n4.2 Query Optimization\nAnother direction for zero-shot learning are end-to-end learned\noptimizers and not just the learning of cost models. Recently, it\nwas also proposed to replace query optimizers that typically rely\non heuristics (i.e., simple cost models) and manual engineering\nby machine learning models [ 15,20–22]. While initial results are\npromising and even commercial optimizers can be outperformed by\nlearned ones, current approaches are also dominated by reinforce-\nment leaning or workload-driven learning in general. Again, all\nthese approaches are database-dependent and cannot generalize to\nunseen databases. Moreover, for learning an optimizer a huge num-\nber of queries has to be executed to learn what is a good plan for a\ngiven query. We envision that this overhead for unseen databases\ncan be eliminated completely using zero-shot learning.\nAn initial naïve approach for this could be to use the devised\nzero-shot cost estimation model to evaluate candidate plans and\nthus better guide the query optimizer to plans with low costs. For\ninstance, zero-shot cost estimation models could be used in conjunc-\ntion with classical dynamic programming or even approaches like\nBao [20]. However, with more sophisticated approaches, we think\nthat zero-shot learning could potentially replace classical heuristics\nlike dynamic programming entirely by devising zero-shot value\nnetworks to learn search strategies for query optimization. Value\nnetworks [29] have shown to learn policies that involve planning-\nbased reasoning. This way, zero-shot query optimizers could come\nup with plans that classical optimizers would not have considered\nwhile avoiding the burden to run thousands of queries to train the\nlearned optimizer for every new database.\n4.3 Discussion\nIn addition to design advisors, knob tuning, or database optimizers\nthere are many more DBMS components that could benefit from\nzero-shot learning. For example, zero-shot cost models could be\nused to predict not only the runtime but also other aspects such as\nresource consumption and thus be used also for runtime decisions\n(e.g., query scheduling). Moreover, by extending the features of\nthe“What-If” mode, we could also support hardware aspects and\npredict the runtime of queries on an unseen hardware, e.g., to select\nan optimal cloud instance for a given workload.\nAnother interesting question is how zero-shot learning should\nbe integrated into the overall DBMS architecture. Here we envision\na route where zero-shot cost models as presented in Section 3 form a\n“kind-of” central brain in a DBMS that can be leveraged by various\nDBMS components that complement such a central componentwith more targeted models. These additional models could for ex-\nample be zero-shot models that focus on learning particular search\nstrategies or specific data-driven models to capture interesting data\ncharacteristics as we discussed before.\nFinally, as mentioned before it can be beneficial to fine-tune a\nzero-shot model also on the unseen database. The resulting few-\nshot models leverage the observed workload on the database similar\nto workload-driven models and thus likely offer more accurate pre-\ndictions. However, the main difference to workload-driven models\nis that our approach also offers accurate out-of-the-box predictions\nfor unseen databases by using zero-shot models and also requires\nfewer queries for adaptation on an unseen database since the gen-\neral system behavior is already internalized by the zero-shot model.\nAs such, it is significantly more efficient to fine-tune a model for\nunseen databases than to train one from scratch every time as it is\nnecessary for workload-driven models.\n5 Looking into the Future\nIn this paper, we have shown a new approach for learned database\ncomponents that can support new databases without running any\ntraining query on that database. Moreover, zero-shot models can\nbe fine-tuned on the unseen database for more accurate predictions\nresulting in few-shot models. While we have focused on single-\nnode databases and classical database workloads in the first place,\nwe believe that zero-shot models can be applied more broadly. One\ndirection are distributed DBMSs where zero-shot models can be\nextended to support tasks such as to optimize a distributed data\nlayout. Another direction is to extend zero-shot models for other\ntypes of data-intensive workloads (e.g., data streaming).\nMoreover, when thinking more broadly, zero-shot models seem\nto also be an attractive model for any system builder and can be also\nused at various levels of granularity to predict the performance of\nindividual components (e.g., very fine-grained on the data structure\nand algorithm level) or very coarse-grained (at the system level).\nFor example, when being used for data structures and algorithms,\nzero-shot models would be an efficient vehicle for self-designing\ndata structures [ 12]. To conclude, we think that zero-shot learning\nopens up many avenues of research since it provides not only a\nmore sustainable way to build learnable system components but\nit also seems to be a general paradigm that can be applied more\nbroadly and at different levels.\n6 Acknowledgments\nWe thank the reviewers for their feedback and comments. This\nresearch and development project is funded by the German Fed-\neral Ministry of Education and Research (BMBF) within the “The\nFuture of Value Creation – Research on Production, Services and\nWork” program and managed by the Project Management Agency\nKarlsruhe (PTKA). The author is responsible for the content of\nthis publication. In addition, the research was partly funded by the\nHochtief project AICO (AI in Construction), the HMWK cluster\nproject 3AI(The Third Wave of AI), as well as the DFG Collabora-\ntive Research Center 1053 (MAKI). Finally, we want to thank the\nAmazon Redshift team for valuable discussions.\n\nOne Model to Rule them All:\nTowards Zero-Shot Learning for Databases\nReferences\n[1]S. Agrawal, S. Chaudhuri, and V. R. Narasayya. Automated selection of material-\nized views and indexes in sql databases. In Proceedings of the 26th International\nConference on Very Large Data Bases , VLDB ’00, page 496–505, San Francisco, CA,\nUSA, 2000. Morgan Kaufmann Publishers Inc.\n[2]S. Alabed and E. Yoneki. High-dimensional bayesian optimization with multi-task\nlearning for rocksdb. Proceedings of the 1st Workshop on Machine Learning and\nSystems , 2021.\n[3]T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Nee-\nlakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger,\nT. Henighan, R. Child, A. Ramesh, D. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen,\nE. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Rad-\nford, I. Sutskever, and D. Amodei. Language models are few-shot learners. In\nH. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances\nin Neural Information Processing Systems , volume 33, pages 1877–1901. Curran\nAssociates, Inc., 2020.\n[4]N. Bruno and S. Chaudhuri. Automatic physical database tuning: A relaxation-\nbased approach. In Proceedings of the 2005 ACM SIGMOD International Conference\non Management of Data , SIGMOD ’05, page 227–238, New York, NY, USA, 2005.\nAssociation for Computing Machinery.\n[5]S. Chaudhuri and V. R. Narasayya. An efficient cost-driven index selection tool\nfor microsoft sql server. In Proceedings of the 23rd International Conference on\nVery Large Data Bases , VLDB ’97, page 146–155, San Francisco, CA, USA, 1997.\nMorgan Kaufmann Publishers Inc.\n[6]J. Ding, U. F. Minhas, J. Yu, C. Wang, J. Do, Y. Li, H. Zhang, B. Chandramouli,\nJ. Gehrke, D. Kossmann, D. Lomet, and T. Kraska. Alex: An updatable adaptive\nlearned index. In Proceedings of the 2020 ACM SIGMOD International Conference\non Management of Data , SIGMOD ’20, page 969–984, New York, NY, USA, 2020.\nAssociation for Computing Machinery.\n[7]J. Ding, V. Nathan, M. Alizadeh, and T. Kraska. Tsunami: A learned multi-\ndimensional index for correlated data and skewed workloads. Proc. VLDB Endow. ,\n14(2):74–86, Oct. 2020.\n[8]A. Galakatos, M. Markovitch, C. Binnig, R. Fonseca, and T. Kraska. Fiting-tree: A\ndata-aware index structure. In Proceedings of the 2019 International Conference on\nManagement of Data , SIGMOD ’19, page 1189–1206, New York, NY, USA, 2019.\nAssociation for Computing Machinery.\n[9]B. Hilprecht, C. Binnig, T. Bang, M. El-Hindi, B. Hättasch, A. Khanna,\nR. Rehrmann, U. Röhm, A. Schmidt, L. Thostrup, and T. Ziegler. DBMS fitting:\nWhy should we learn what we already know? In 10th Conference on Innovative\nData Systems Research, CIDR 2020, Amsterdam, The Netherlands, January 12-15,\n2020, Online Proceedings . www.cidrdb.org, 2020.\n[10] B. Hilprecht, C. Binnig, and U. Röhm. Learning a partitioning advisor for cloud\ndatabases. In Proceedings of the 2020 ACM SIGMOD International Conference on\nManagement of Data , SIGMOD ’20, page 143–157, New York, NY, USA, 2020.\nAssociation for Computing Machinery.\n[11] B. Hilprecht, A. Schmidt, M. Kulessa, A. Molina, K. Kersting, and C. Binnig.\nDeepdb: Learn from data, not from queries! Proc. VLDB Endow. , 13(7):992–1005,\nMar. 2020.\n[12] S. Idreos, K. Zoumpatianos, S. Chatterjee, W. Qin, A. Wasay, B. Hentschel, M. S.\nKester, N. Dayan, D. Guo, M. Kang, and Y. Sun. Learning data structure alchemy.\nIEEE Data Eng. Bull. , 42(2):47–58, 2019.\n[13] A. Kipf, T. Kipf, B. Radke, V. Leis, P. A. Boncz, and A. Kemper. Learned cardinali-\nties: Estimating correlated joins with deep learning. In CIDR 2019, 9th Biennial\nConference on Innovative Data Systems Research, Asilomar, CA, USA, January\n13-16, 2019, Online Proceedings , 2019.\n[14] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The case for learned index\nstructures. In Proceedings of the 2018 International Conference on Management of\nData , SIGMOD ’18, pages 489–504, New York, NY, USA, 2018. ACM.\n[15] S. Krishnan, Z. Yang, K. Goldberg, J. Hellerstein, and I. Stoica. Learning to\noptimize join queries with deep reinforcement learning. ArXiv , abs/1808.03196,\n2018.\n[16] H. Lan, Z. Bao, and Y. Peng. An index advisor using deep reinforcement learning.\nCIKM ’20, page 2105–2108, New York, NY, USA, 2020. Association for ComputingMachinery.\n[17] T. Li, Z. Xu, J. Tang, and Y. Wang. Model-free control for distributed stream data\nprocessing using deep reinforcement learning. Proc. VLDB Endow. , 11(6):705–718,\nFeb. 2018.\n[18] X. Liang, A. J. Elmore, and S. Krishnan. Opportunistic view materialization with\ndeep reinforcement learning. CoRR , abs/1903.01363, 2019.\n[19] H. Mao, M. Schwarzkopf, S. B. Venkatakrishnan, Z. Meng, and M. Alizadeh.\nLearning scheduling algorithms for data processing clusters. In Proceedings of\nthe ACM Special Interest Group on Data Communication , SIGCOMM ’19, page\n270–288, New York, NY, USA, 2019. Association for Computing Machinery.\n[20] R. Marcus, P. Negi, H. Mao, N. Tatbul, M. Alizadeh, and T. Kraska. Bao: Learning\nto steer query optimizers, 2020.\n[21] R. Marcus, P. Negi, H. Mao, C. Zhang, M. Alizadeh, T. Kraska, O. Papaem-\nmanouil, and N. Tatbul. Neo: A learned query optimizer. Proc. VLDB Endow. ,\n12(11):1705–1718, July 2019.\n[22] R. Marcus and O. Papaemmanouil. Deep reinforcement learning for join order\nenumeration. In Proceedings of the First International Workshop on Exploiting\nArtificial Intelligence Techniques for Data Management , aiDM’18, New York, NY,\nUSA, 2018. Association for Computing Machinery.\n[23] R. Marcus and O. Papaemmanouil. Plan-structured deep neural network models\nfor query performance prediction. Proc. VLDB Endow. , 12(11):1733–1746, July\n2019.\n[24] D. Narayanan, E. Thereska, and A. Ailamaki. Continuous resource monitoring for\nself-predicting dbms. In Proceedings of the 13th IEEE International Symposium on\nModeling, Analysis, and Simulation of Computer and Telecommunication Systems ,\nMASCOTS ’05, page 239–248, USA, 2005. IEEE Computer Society.\n[25] R. Nehme and N. Bruno. Automated partitioning design in parallel database\nsystems. In Proceedings of the 2011 ACM SIGMOD International Conference on\nManagement of Data , SIGMOD ’11, page 1137–1148, New York, NY, USA, 2011.\nAssociation for Computing Machinery.\n[26] T. Schmied, D. Didona, A. Döring, T. Parnell, and N. Ioannou. Towards a general\nframework for ml-based self-tuning databases. In Proceedings of the 1st Workshop\non Machine Learning and Systems , EuroMLSys ’21, page 24–30, New York, NY,\nUSA, 2021. Association for Computing Machinery.\n[27] Y. Sheng, A. Tomasic, T. Zhang, and A. Pavlo. Scheduling OLTP transactions via\nlearned abort prediction. In Proceedings of the Second International Workshop on\nExploiting Artificial Intelligence Techniques for Data Management, aiDM@SIGMOD\n2019, Amsterdam, The Netherlands, July 5, 2019 , pages 1:1–1:8, 2019.\n[28] J. Sun and G. Li. An end-to-end learning-based cost estimator. Proc. VLDB Endow. ,\n13(3):307–319, Nov. 2019.\n[29] A. Tamar, S. Levine, P. Abbeel, Y. Wu, and G. Thomas. Value iteration networks.\nIn D. D. Lee, M. Sugiyama, U. von Luxburg, I. Guyon, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems 29: Annual Conference on\nNeural Information Processing Systems 2016, December 5-10, 2016, Barcelona, Spain ,\npages 2146–2154, 2016.\n[30] T. Wang, S. Ferlin, and M. Chiesa. Predicting cpu usage for proactive autoscaling.\nInProceedings of the 1st Workshop on Machine Learning and Systems , EuroMLSys\n’21, page 31–38, New York, NY, USA, 2021. Association for Computing Machinery.\n[31] Z. Yang, A. Kamsetty, S. Luan, E. Liang, Y. Duan, X. Chen, and I. Stoica. Neurocard:\nOne cardinality estimator for all tables. Proc. VLDB Endow. , 14(1):61–73, Sept.\n2020.\n[32] Z. Yang, E. Liang, A. Kamsetty, C. Wu, Y. Duan, X. Chen, P. Abbeel, J. M. Heller-\nstein, S. Krishnan, and I. Stoica. Deep unsupervised cardinality estimation. PVLDB ,\n13(3):279–292, 2019.\n[33] M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J.\nSmola. Deep sets. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fer-\ngus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information\nProcessing Systems , volume 30, pages 3391–3401. Curran Associates, Inc., 2017.\n[34] J. Zhang, Y. Liu, K. Zhou, G. Li, Z. Xiao, B. Cheng, J. Xing, Y. Wang, T. Cheng, L. Liu,\nM. Ran, and Z. Li. An end-to-end automatic cloud database tuning system using\ndeep reinforcement learning. In Proceedings of the 2019 International Conference\non Management of Data , SIGMOD ’19, page 415–432, New York, NY, USA, 2019.\nAssociation for Computing Machinery.",
  "textLength": 47527
}