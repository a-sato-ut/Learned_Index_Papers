{
  "paperId": "bb01af4ea02f1d10a8ee2c95b4a6276a7dc5c530",
  "title": "Similarity Metrics Enforcement in Seasonal Agriculture Areas Classification",
  "pdfPath": "bb01af4ea02f1d10a8ee2c95b4a6276a7dc5c530.pdf",
  "text": "remote sensing  \nArticle\nSimilarity Metrics Enforcement in Seasonal\nAgriculture Areas Classiﬁcation\nMarcio A. S. Santos1,*\n, Eduardo D. Assad2\n, Angelo C. Gurgel3\nand Nizam Omar1\n1Computing and Informatics School, Mackenzie Presbyterian University—Rua da Conslação, 930 Consolação,\nSão Paulo SP 01302-90, Brazil; omar@makenzie.br\n2Embrapa Informatica Agropecu ´aria, Environmental Modeling Lab—Av. Andre Tosello,\n209 Unicamp Campus, Campinas SP 13083-886, Brazil; eduardo.assad@embrapa.br\n3Get´ulio Vargas Foundation/São Paulo School of Economics—Rua Itapeva, 474 Bela Vista,\nSão Paulo SP 01332-000, Brazil; angelo.gurgel@fgv.br\n*Correspondence: marcioassantos@live.com or 71606815@mackenzista.com.br; Tel.: +55-(19)-99113-6236\nReceived: 2 April 2020; Accepted: 27 May 2020; Published: 2 June 2020\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\nAbstract: Accurate identiﬁcation of agriculture areas is a key piece in the building blocks strategy\nof environment and economics resources management. The challenge requires one to deal with\nlandscape complexity, sensors and data acquisition limitations through a proper computational\napproach to timely deliver accurate information. In this paper, a Machine Learning (ML) based\nmethod to enhance the classiﬁcation process of areas dedicated to seasonal crops (row crops)\nis proposed. To this objective, a broad exploration of data from Moderate Resolution Imaging\nSpectro-radiometer sensors (MODIS) was made using pixel time-series combined with time-series\nsimilarity metrics. The experiment was performed in Brazil, covered 61% of the total agriculture\nareas, ﬁve different states speciﬁcally selected to demonstrate biome differences and the country’s\ndiversity. The validation was made against independent data from EMBRAPA (Brazilian Agriculture\nResearch Corporation), RapidEye Sensor Scene Maps. For the eight tested algorithms, the results\nwere enhanced and demonstrate that the method can rate the classiﬁcation accuracy up to 98.5%,\naverage value for the tested algorithms. The process can be used to timely monitor large areas\ndedicated to row crops and enables the application of state of art classiﬁcation techniques, two levels\nclassiﬁcation process, to identify crops according to each speciﬁc need within the areas.\nKeywords: remote sensing; agriculture; time series similarity metrics; machine learning; land use\ndynamics\n1. Introduction\nThe identiﬁcation of agriculture areas is valuable information for the scientiﬁc community,\ngovernment agencies, farmers, and other members of the society. Agriculture main commodity\nareas are monitored on a global scale to predict production, yield, demand, prices, climate risks, and so\nforth [ 1–5]. Related statistics are produced and published to reduce the economic externalities impact\nand to balance market information asymmetry [ 6,7]. Ongoing, accurate, and timely crop information\nremains a challenge, as data becomes available long after the harvesting time, and the machine learning\nclassiﬁcation is dependent on reliable data sources and processing needs enhancements, despite the\navailable capacity [ 8–10]. The accuracy of the latest results in distiguishing crops of agriculture areas\nrange from 84% to 95% [ 11–14]. The state of the art publications in agriculture remote sensing explore\nthe importance of machine learning applied in combined data sources and types in order to enhance\nthe process and accuracy for multiple crops as classes.\nWhen it comes to process improvements and machine learning, Convolutional Neural Networks\n(CNN) was applied to achieved signiﬁcant results in image recognition tasks by automatically\nRemote Sens. 2020 ,12, 1791; doi:10.3390/rs12111791 www.mdpi.com/journal/remotesensing\n\nRemote Sens. 2020 ,12, 1791 2 of 14\nlearning a hierarchical feature representation from raw data, and through combinations of time series\n(temporal dimension) with 2D texture images (spatial dimension) to enhance features that could not\nbe gained in a single dimension. The uniﬁed frame work, times series, and CNN, demonstrated\ncompetitive accuracy when compared with the existing deep architectures and the state-of-the\nart time series algorithms [ 15]. The exploration of synergies between different sources of data to\nimprove classiﬁcation of high-level spatial features produced by hierarchical learning (i.e., scene\nlabeling) to contrast with low-level features such as spectral information (morphological properties)\nhas also been made. Temporal and angular features played more important roles in classiﬁcation\nperformance, especially abundant vegetation growth information. Multispectral and hyper-spectral\nfusion successfully discriminated natural vegetation types diversity [ 16]. Also using fusion methods\ntechniques, in this case to mitigate spatiotemporal limitations of multi and hyper-spectral data from\nmultiple sensors, a compatibility between the hyper-spectral data and Sentinel-2 (multi spectral) data\nhas been validated. The method opened new possibilities for classifying complex and heterogeneous\nland covers in multiple environments with the combination multiple data sources [ 17]. On the other\nside, when accuracy enhancement is the major focus, an automated mapping process for soybean and\ncorn using crop phenology characteristics with time series and topographic features from multiple\nsources combined was proposed by Reference [ 18]. The classiﬁcation achievements range from 87% to\n95%, which is an increase of 2.86% on previous published works [ 19]. For the case of row-crop areas in\nBrazil, as is the case of this work, international publications that addresses this need were observed.\nA experiment that covered 3 crops (corn, soybeans and cotton) in Mato Grosso, used time series\ncorrelation coefﬁcient and successive classiﬁcations has been performed to detect agricultural areas.\nThe approach was capable to achieve 95% accuracy and kappa index of 0.98 [ 14]. In another study,\na rigorous multiyear evaluation of the applicability of time-series for crop classiﬁcation in Mato Grosso\nwas performed. The conclusion showed progress in reﬁned crop-speciﬁc classiﬁcation and appointed\nthe need for grouping of crops as classes. The results were consistently near or above 80% accuracy and\nKappa values were above 0.60. The authors also highlight the need for additional research to evaluate\nagricultural intensiﬁcation and extensiﬁcation in this region of the world [ 20]. The combination of\ndifferent channels (red and near-infrared) were explored with ﬁve algorithms (Maximum Likelihood,\nSupport Vector Machines, Random Forest, Decision Tree, and Neural Networks). The methods accuracy\nranged from 85% to 95%, and demonstrated that 250 m imagery is efﬁcient to map ﬁelds down to\n20 ha. Results also suggested that cropland diversity could be addressed using regional and speciﬁc\nlandscapes training sets [ 13]. As a reference, the accuracy assessment of a supervised classiﬁcation on\nLandsat 8 satellite images was performed. The results indicated that the object classiﬁcation was better\nthan the classiﬁcations by pixel and the best thematic map was generated by the SEGCLASS classiﬁer.\nThe accuracy achieved was 74% and kappa index 0.57 [21].\nIn common is that References [ 11–13,18,21–24] share the best results in the crop classiﬁcation\nwith their methodologies within the studied area, and present the challenges related to the limited\namount of training data to scale up the process. As each of the studies was performed within unique\nﬁeld information and conditions, including different crop varieties contrasted, the results cannot be\ncompared properly.\nIn this research the aim is to propose a process to enhance classiﬁcation accuracy in agriculture\nareas dedicated to row crops and put them in evidence to support the land monitoring process and\ngenerate a ﬁrst knowledge layer to support speciﬁcs needs and ﬁne-tuning classiﬁcation. Although time\nseries has been extensively explored to classify agriculture and it is a well-stablished process [ 25,26],\nthe combination of time series and similarity metrics to explore the classiﬁcation as proposed is a\nnovel, explore the crop growing season cycle of a variety of temporary crops with multiple algorithms.\n1.1. Remote Sensing\nThe use of the pixel as a sensor in remote sensing to monitor agriculture cycles requires quality\nimages and ﬁne specs to be granularly classiﬁed accordingly to each unique purpose, so unexpected\n\nRemote Sens. 2020 ,12, 1791 3 of 14\ndynamics can be detected and properly managed [ 8,9], (e.g., crop phenology stage, chemicals\nadministration, mechanization, and irrigation management, among others). The critical components\nfor remote sensing are: accurate and current information for training the classiﬁers; an affordable\nsource of data that qualiﬁes for the speciﬁc objective; a storage and processing capacity [ 10,27,28].\nBy using MODerate-resolution Imaging Spectrometer (MODIS) products that include the Enhanced\nVegetation Index (EVI) [ 29], among others, we have access to a complete record of data from each\nof the Terra and Aqua MODIS sensors, at varying spatial (250 m, 0.05 degree) and temporal (8-day)\nresolutions validated with accuracies depicted by a pixel reliability ﬂag and with globally averaged\nuncertainties of 0.015 units. Further, the MODIS/EVI combination is a robust set for exploring seasonal\ncrops (soybeans) [ 22]. The spatial resolution adopted are consistent in expressing accurate cropland\ninformation in ﬁelds that are larger than 20 ha [ 13], and appropriate to this task [ 30]. This experiment\nrelies on the achievements and speciﬁcations above to explore the spectral dynamics of extensive areas,\nin accordance with the speciﬁcs purpose stablished for this research.\n1.2. Brazilian Agriculture in Numbers\nIn Brazil, agriculture represents almost a quarter of the country GDP’s, 24.1% in 2017 [ 31].\nAccording to the Brazilian Institute of Geography and Statistics (IBGE) rural census [ 32], the harvested\narea during the 2016/2017 season represented 7.9% of the total area with 73,797,057 hectare (ha)\ndedicated for temporary and semi-temporary crops and another 5,184,813 ha for permanent crops,\nwith the ﬁnal results published in 2019. For the purpose of this study, detailed statistics of the studied\nareas are summarized on the Table 1. The column “Total” shows the total area (country/State).\nThe column “Agriculture” presents the harvested area (country/State). It is important to highlight\nthat, due to geographical and environmental conditions, which include climate and/or technologies\n(e.g., irrigation), it is common to have multiple crops per year in tropical areas. Therefore, the conclusion\nis that the harvests are larger than the total area dedicated to agriculture, a total of 67,547,537 ha\naccording to EMBRAPA [33,34] and MAPA [35].\nThe main crops cultivated locally are presented below, in Table 2, and the data is organized as a\npercentage of total area occupied to provided a land use perspective view, and put in evidence of a\nlarger area per crop cultivated.\nTable 1. Studied areas (ha).\nCountry/State Total Agriculture (%)\nBrazil (BR) 851,605,394 67,547,537 7.9\nGoias (GO) 34,011,178 6,106,279 17.9\nMinas Gerais (MG) 58,652,212 4,814,438 8.2\nMato grosso (MT) 90,336,619 14,872,045 16.5\nParaná (PR) 19,930,792 8,776,871 44.0\nSão Paulo (SP) 24,822,362 6,835,741 27.5\nState Subtotal 227,753,038 41,405,374 61.3\nSource: https://censos.ibge.gov.br/agro/2017/.\nTable 2. Temporary crops.\nCrop Type Area (ha) Fraction of Total (%)\nSoybean 30,622,460 45.3%\nCorn 17,985,764 26.6%\nSugar cane 9,153,709 13.6%\nBeans 3,069,622 2.1%\nWheat 1,796,065 2.6%\nRice 1,778,190 2.6%\nManioc 943,323 1.4%\nCotton 910,057 1.3%\nTotal area 64,660,183 93.7%\nSource: https://censos.ibge.gov.br/agro/2017/.\n\nRemote Sens. 2020 ,12, 1791 4 of 14\n2. Methods\n2.1. Studied Area\nThe study was performed over Brazil at the state level, see Figure 1. The locations were selected to\nbring the diversity (biome, crop, climate, etc.) and its complexity into the analysis. The states studied\nwere: Goiás (GO), Minas Gerais (MG), Mato Grosso (MT), Parana (PR) and São Paulo (SP), Table 1.\nIn this study the growing season (phonological) cycle is the key aspect taken in consideration, crop\nrecognition requires speciﬁcs and may be performed in accordance to them, combining scenes and the\ngrowing season maps.\nFigure 1. The experiment was performed over GO, MG, MT, PR, and SP , and a country-wide view.\n2.2. IBGE Census\nAs a reference in this study, IBGE Agriculture census data was used to contrast results, that is,\nquantify the total area and row crop areas for each studied state. The original numbers were\nconsolidated and published by municipalities and by state, consequently. For this research objective\nthe productive clusters are represented in maps and at the state level, without municipal geopolitical\nboundaries. The preliminary census results were published in 2018 and ﬁnal results late in 2019.\n2.3. Ontology\nThe use of expert knowledge management based on ontology process to support the collective\nunderstanding of a single event ( Data driven approach ) was applied to proper address crop growing\nseason speciﬁcs to expand the comprehension possibilities in a multidisciplinary context [ 36]. The same\nauthor deﬁned ontology scope as being the “specialist of speciﬁcs”, meaning the understanding of\na domain group. In this environment the essential is the potential for information and knowledge\nsharing [ 37]. The proposed Ontology is presented in the concept map below, Figure 2, where the\ntarget class are highligted and the proﬁles are demonstrated. The data was segmented in accordance\nto the Global Food Security (GFS) [ 38] and MODIS ontology into two large classes, Agriculture and\nOther. Agriculture, as the target class, included: Irrigated and dry seasonal crops areas potentially\nfeaturing corn, soybean, cotton, barley, potato, alfalfa, sorghum, rye, canola, peanut, manioc, and beet.\n\nRemote Sens. 2020 ,12, 1791 5 of 14\nThe Others class included: perennial and semi-perennial/semi-temporary crops, natural vegetation\n(forest, cerrado, amazon forest, tropical forest), pasture, urban areas, and water surface, among others.\nThe agriculture class areas are those where we expected to ﬁnd a high level of EVI values dynamics,\nwhich is the purpose of this study, and is also compatible with the objective of the sensor selected. As a\nreference, the proﬁle images that are representing the target group are from SatVeg [ 39]. Only the crops\nthat can be found within the region and are described as part of sensor ontology are here in evidence.\nFigure 2. A concept map of the ontology used—Target groups highlighted above share seasonal\ncharacteristics with each other and within the time frame selected from EVI collected maps. Sources:\nEMBRAPA, MODIS, IBGE.\n2.4. Datasets Processing\nThe criteria for the selection of the sensor was based on the most recent publications and goal,\nas cited above. The .tiff (Tagged Image Format) dataset ﬁles were downloaded from the MODIS\nrepository as .hdf (Hierarchical Data Format) ﬁles according to provided guidelines, and then framed\nin accordance to each studied state and a country view. The experiment was performed using EVI\nfrom MOD13Q1 with 250 m of spatial resolution.\nAccord to the methodology outlined as a ﬂowchart in Figure 3, a large amount of random\nPixels Time Series (PTS) were extracted from each studied area to achieve 99%+1\n\u00001of conﬁdence\nlevel, with 17,000 points for each dataset, and 5 datasets per state. PTS values were extracted as\nvectors and stored as .csv (Comma Separated Values) ﬁles using a expert system created for this\npurpose. Each vector contained the pixel position, EVI raw data as time series values, and calculated\ncomputational distances, with similarity metrics proposed. The data were then pre-classiﬁed into\ntwo large groups, Agriculture and Others. Agriculture was the target group, which expected areas\nwith high spectral dynamics level, and the Others group contained lower dynamics level areas. Each\nexperiment used 20% of data set for training.\nGiven the inherent complexity of vegetation and environments which are all reﬂected within\nthe region selected, for each state, a group of similarity metrics were selected and tested as a way to\nput in evidence the expected characteristics and work as a hybrid index in the classiﬁcation process,\nas in Reference [ 40]. The computational distances used in this experiment are: Manhattan distance,\nMinkowski distance, Sum, Mean, Median, Standard deviation, Coefﬁcient of Variation, Variance,\nand Difference [ 41,42]. All the similarity metrics that used the distances were calculated for each pixel\ntime-series. In particular, the Minkowski distance used has been explored by References [ 43,44] to\n\nRemote Sens. 2020 ,12, 1791 6 of 14\ncluster time series that have different temporal resolutions, as the case for the Dynamic Time Warp\n(DTW), and in this case it was used to measure the length of the time-series. The possible values for\nthecare useful to accommodate the time difference into the time series. The equation is demonstrated\nbelow, Equation (1):\nD(p,q) = (n\nå\ni=1jpi\u0000qijc)1/c. (1)\nwhere: the distance D,pand qare the data points ( xi+1and xi, respectively) and used c=2.\nFigure 3. Process Flow—Target groups selected—Agriculture & Other. Elaborated by the authors.\n2.5. Time-Frame\nFor this research, 36 raster layers from the MODIS sensor were used, with an 18 month time frame\ncoverage, from July 2016 to December of 2017 to match IBGE census data also used as a reference in\nthis study. The time frame selected meets the objective of measuring annual dynamics for temporary\ncrops, thus excluding semi-temporary crops (e.g., sugarcane) from the analysis.\n2.6. Validation\nTree levels of validation were considered—the classiﬁcation accuracy, the concordance between\nalgorithms, and the computational metrics relevance. EMBRAPA scene maps were used as an external\nreference data source to contrast and validate accuracy. The spatial resolution of the the validation\nmaps was 5 m to provide quality data for the training set used, to preserve the characteristics that are\nrelevant to the experiment [8], and to match the ﬁeld size.\nThe classiﬁcation accuracy validation was made according to the proposed ontology, a confusion\nmatrix used to contrast results as True-Positive (TP), False-Negative (FN), False-Positive (FP) and\nTrue-Negative (TN). Accuracy stands for all that were correctly classiﬁed, as in the Equation (2),\nand recall stands for positives that were correctly classiﬁed, as in the Equation (3), below:\naccuracy =TP+TN\nTP+FP+TN+FN, (2)\nrecall =TP\nTP+FN. (3)\nThe concordance between algorithms assessment were made using the Cohen’s Kappa coefﬁcient\nor simply ( k), which has been largely used to evaluated classiﬁcation algorithms performance as\ndescribed in Reference [ 45]. Kappa values ranges from \u00001to1, where\u00001represents “complete\ndisagreement”, 0 is a “random classiﬁcation”, and 1 is a “perfect agreement”.\n\nRemote Sens. 2020 ,12, 1791 7 of 14\nThe computational metrics used are the sensitivity and speciﬁcity, Equations (4) and (5) below,\nwhere we expect to identify the impact of the selected similarity metrics composition on the\nclassiﬁcation process of the target group.\nsensitivity =truepositive\npositive(4)\nspeci f icity =truenegative\nnegative, (5)\nwhere “true positive” is the number of correctly predicted areas, “positive” is the number of agriculture,\n“true negative” is the number of correctly predicted as others, and “negative” is the number of others\nshown in the classiﬁcation.\nThe impact of each similarity metric as an attribute over the target class was evaluated using\nShannon entropy index to reveal in a [0:1] scale the cluster behavior [ 46,47]. The calculation of the\ndistances was made according to the Equation below, Equation (6):\nEi=\u0000n\nå\ni=1pilog(pi), (6)\nwhere Eis the information strengh of the attibute nover the class i, and pis the probability of the class\ninn.\n2.7. Computation Tolls\nAll data manipulation and tests were performed using RR\rlanguage, MatlabR\r,RapidMinerR\r, and\nQGISR\r. Using these tools to evaluate the effectiveness of the proposal, we explored the data with eight\nMachine Learning algorithms: Naive Bayes, Logistic Regression, Decision Tree, Gradient Boosted Tree,\nGeneralized Linear Model, Deep Learning, Random Forest. This collection represents most of the\nalgorithms used in the cited publications.\nThe data used were min-max normalized to comply with the classiﬁcation tolls specs. The values\nwere linearly reduced to a scale between [0:1], where 0 and 1 are the minimum and maximum values,\nrespectively. The zis the normalized value accord to Equation (7) below:\nzi=xi\u0000min(x)\nmax (x)\u0000min(x). (7)\n3. Results\nBy performing the study as proposed, we observed that the addition improved the speciﬁcity\nand sensitivity of the algorithms. The sensitivity of the algorithms can be veriﬁed by contrasting ROC\ncomparison curve (detection probability in machine learning). The Figure 4 shows the classiﬁcation\nprocess for data without similarity metrics and Figure 5 shows the sme process for data with similarity\nmetrics. Speciﬁcity raised from 98.6% to 99.2% with a direct effect on accuracy, sensitivity enhancement\nfrom 94.62% to 97.4% which improved processing performance despite the data dimensional increase.\nAs we can verify, data with similarity metrics increased sensitivity for all tested algorithms.\nThe enhancement for each method is demonstrated below, Table 3, where the results for each\nstate are presented. The caption MT, GO, MG, SP and PR are the abbreviations of the states mentioned\non Section 2.1. The columns RD and DSM represent the accuracy with the different type od data,\nRaw Data (RD) and Data with Similarity Metrics (DSM). It is important to point the difference in\nresults between the algorithms, these differences reﬂect the way each of them internally organizes the\ndata toward the best solution.\nThe concordance of the algorithms index (Kappa) and the enhancement range achieved for each\nmethod with Raw Data and Data with Similarity Metrics (RD-DSM) is demonstrated in the Table 4.\n\nRemote Sens. 2020 ,12, 1791 8 of 14\nThe highest impact was achieved with Deep Learning, increased the accuracy from 83.9% to 98.6%\nwith Kappa index of 0.95. However, the highest accuracy was achieved with Gradient Boosted Tree,\nresults were enhanced from 95.2% to 99.6% and with Kappa index of 0.96.\nFigure 4. ROC—Classiﬁcation process effectiveness—Data witout similarity metrics on the data set.\nComparison—Naive Bayes, Logistic Regression, Decision Tree, Gradient Boosted Tree, Generalized\nLinear Model, Deep Learning, Random Forest.\nFigure 5. ROC—Classiﬁcation process effectiveness—Data with similarity metrics as part of the data\nset. Comparison—Naive Bayes, Logistic Regression, Decision Tree, Gradient Boosted Tree, Generalized\nLinear Model, Deep Learning, Random Forest.\nThe hierarchal clustering analysis below, Figure 6, put in evidence the hierarchal importance of\neach metric for the process. The relevance of each attribute is calculated accord to Shannon information\nand the normalized score is represented hierarchically. The Minkowski distance played a key part in\n\nRemote Sens. 2020 ,12, 1791 9 of 14\nthe classiﬁcation process and demonstrated to be very representative of the target class, highest score.\nCanberra distance, Standard deviation, Mean, Coefﬁcient of Variation, and Variance were also very\nrelevant in the high score process, but not as decisive. The removal of the Manhattan distance, Sum,\nMedian, and Difference had no impact on the process accuracy.\nTable 3. Accuracy classiﬁcation results.\nAlgorithms GO MG MT PR SP\nRD DSM RD DSM RD DSM RD DSM RD DSM\nNaive Bayes 88.4 94.5 84.2 93.8 85.8 93.1 89.2 94.1 80.0 90.5\nGeneralized Linear Model 93.4 98.4 96.9 99.3 94.9 99.3 91.1 98.4 89.7 97.8\nLogistic Regression 97.4 97.4 97.7 98.6 97.4 98.9 91.0 98.7 96.3 97.8\nDeep Learning 83.9 97.9 86.9 99.2 88.9 99.2 85.1 98.2 83.9 97.6\nDecision Tree 85.2 98.6 92.3 99.4 92.3 99.1 85.1 98.7 86.5 97.5\nRandon Forest 85.8 98.2 92.3 99.3 95.8 99.6 86.9 98.9 76.2 97.6\nGradient Boosted Trees 96.0 98.4 97.1 99.4 97.4 99.6 96.0 98.8 95.2 97.8\nSupport Vector Machine 97.9 98.3 98.1 99.5 97.8 99.1 97.4 98.9 97.0 92.2\nRD: Raw data and SM: Data with Similarity metrics.\nTable 4. Concordance.\nTested Models (RD-DSM )Kappa\nNaive Bayes 80.0–93.8% 0.89\nGeneralized Linear Model 89.7–99.3% 0.97\nLogistic Regression 91.0–99.3% 0.96\nDeep Learning 83.9–98.6% 0.95\nDecision Tree 86.2–99.4% 0.94\nRandon Forest 86.6–99.5% 0.97\nGradient Boosted tree 95.2–99.6% 0.96\nSupport Vector Machine 97.0–99.5% 0.95\nAverage 88.7 –98.6% 0.95\nFigure 6. Shannon information with Euclidian distance for the key main decision levels. In this case:\nMinkowski Distance (Minkowski); Coefﬁcient of Variation (CV); Standard Deviation (SD); Canberra\ndistance (Canberra); Mean value (Mean).\n\nRemote Sens. 2020 ,12, 1791 10 of 14\nThe correlation between a group of indexes found in the bibliography were also evaluated as\nalternatives to the EVI. Results are presented in Table 5, where the correlations are contrasted. From this\nperspective, none of the indexes were found as strong enough to be used as alternative or to be replaced\nwithin the same method.\nTable 5. Correlation.\nCorrelação EVI NDVI NIR MIR\nEVI 1\nNDVI 0.1964 1\nNIR 0.6510 0.1088 1\nMIR 0.3227 0.3283 0.2417 1\nFinally, from the process it was possible to generate a scene map layer identifying row crops areas,\nas presented on Figure 7, below. The ﬁgure shows where the row crops clusters are located.\nFigure 7. Country view without geopolitical boundaries.\n4. Discussion\nAs presented in the Results section, the proposed approach enhanced the classiﬁcation accuracy\nfor all tested methods. The similarity metrics in combination with time series improved the average\naccuracy from 88.7% to 98.5%, as presented on Table 4. Therefore, the proper selection of similarity\nmetrics showed potential to enhance the classiﬁcation efﬁciency, increase classiﬁcation accuracy\nwithout extra processing time.\nThe results achieved are higher than all previous work that addressed classiﬁcation of agriculture\nrow crop areas in Brazil and, in particular, the results achieved by References [ 13,14,20–22,24] as\npresented in Table 6. In regard to Reference [ 14], which achieved the highest result prior to this work,\n\nRemote Sens. 2020 ,12, 1791 11 of 14\ndespite the large area, they only study one state (Mato Grosso) and tree crops. The second highest\nresult achieved [ 13], compared results for 6 algorithms and results ranged from 84% to 96%, covered\n5 countries and noticed the lowest accuracy for Brazil (84%). The same author appointed as a key\nﬁnding that “the site effect dominates the method effect”.\nTable 6. Results contrasted.\nAuthor Area (ha) Accuracy Kappa Comments\nPublications that share at least one common aspect: Brazil as studied area\n[14] 5,617,250 95.0% 0.98 - 3 tree seasonal crops in Mato grosso/\n[13] 507,728 84.0% - used the same algorithms, achieved 84% accuracy for Brazil/\n[22] 724,293 84.0% 0.56 - differentiated Soybean and non-soybean/\n[24] 1600 83.0% 0.78 - used high spatial resolution images/\n[21] 9658 74.6% 0.57 - seasonal crops group as part of the results/\nInternational Publications that share at least one similarity\n[48] 258,500 97.0% - seasonal crops group as part of the results/\n[12] 2,800,000 94.6% - seasonal crops classiﬁcation/\nIt is important to highlight that in Brazil we have summer crop season which is in general rainy\nand cloudy, more than 90% of the production is rainfed. According to References [ 49,50], less than\n40% of temporal images are useful for analysis. In this context, in this research, we bring the need for\nthe combination of high temporal resolution with high spatial resolution for validation, MODIS and\nRapidEye, respectively.\nAccording to Reference [ 48] the combination of temporal and spectral information can improve\nclassiﬁcation accuracy than only using spectral information, 10–15% higher. In this work, we\ndemonstrated that the proper similarity metric can enhance time series classiﬁcation accuracy, 3–14%,\n10% on average for the tested algorithms. In fact, the combination created condition to increase\nspeciﬁcity (accuracy) and sensibility (convergence). Both aspects are demonstrated on Figures 4 and 5\nabove. The sensibility, in this case the positive impact on the classiﬁcation process, for each of the\nalgorithms were different. Below we present the sensibility for each one of the algorithms:\n\u000f Low: Suport Vector Machine, Deep Learning, Gradient Boosted Tree\n\u000f Moderate: Naive Bayes\n\u000f High: Logistic Regression, Decision Tree, Gradient Boosted Tree, Random Forest\nTwo level classiﬁcation strategy, as proposed by Reference [ 18], or multi-level as used by [ 14] are\na possibility from the achieved results. The layer identifying temporary crop clusters, as presented on\nFigure 7, meets the demand presented by References [12,20,22,48], among others.\nAnother important aspect is the potential of the process to remotely identify agricultural areas as\na dynamic census process. Timely spatial information about productive areas with a high conﬁdence\nlevel ( 99%+1\n\u00001) is relevant for policy makers and for the private sector. This information can support\nIBGE statics and contribute to their monitoring process. In regard to private sector, precision agriculture\nservices can be provided in large scale when geospatial data organized and available.\nThe process also demonstrated some limits that are related to the objective of each search and\ncomplexity of the environment. An accurate time-frame collection of maps is required to enhance the\nuniqueness of the target. It is also important to remember that on top of spectral resolution, temporal\nand spatial resolutions are key to put in evidence speciﬁcs of cultivars. Therefore, sugarcane and\ncultivated pasture have speciﬁcs in growing season, and requires speciﬁcs in spectral and temporal\nresolution to enhance the classiﬁcation process [51].\n\nRemote Sens. 2020 ,12, 1791 12 of 14\n5. Conclusions\nThis study explored the classiﬁcation of agriculture areas dedicated to temporary crops using\nwell-known ML algorithms to examine time-series from a collection of vegetative indexes in\ncombination with similarity metrics. As a conclusion we have that:\n\u000f As the primary objective, the results demonstrated that the approach enhanced the classiﬁcation\naccuracy for all tested algorithms. This is the highest accuracy for the classiﬁcation of agriculture\nareas in Brazil, 99.6% with kappa index of 0.96 using Gradient Boosted Tree algoriothm;\n\u000f The similarity metrics worked to increase the accuracy within the context proposed, EVI data\nreﬂecting the growing season dynamics of temporary crops. The similarity metric added 3–14%\npoints to the accuracy;\n\u000f The process increased accuracy and without extra computational cost.\n\u000f The results are robust to support policy maker and precision farming, 99%+1\n\u00001of conﬁdence level.\nThe ﬁeld knowledge (scene map generated) allows crop level classiﬁcation improvements, that is,\ncrop differentiation using the available techniques accordingly to each speciﬁc need. This information\nis useful for further research and also to support the private sector and public sectors on monitoring\nand spatial planning of annual crops in Brazil.\nTo enhance results and explore the approach, modiﬁcations in the Minkowski equation, cvalue,\nshould be tested to address speciﬁcs in phenology time frame. The size of the data set for training\nshould be quantiﬁed, it is expected that the a smaller data set size would maintain accuracy. Moreover,\nDTW can be used to explore the differences in growing season for the two levels crop classiﬁcation\nprocess, among others. Speciﬁcs in computational costs and cloud computing beneﬁts should also be\nexplored and demonstrated.\nAuthor Contributions: M.A.S.S.: Conceptualization of this study, Methodology, Software coding and\nmanipulation, Validation Methodology, Writing—Original draft preparation; E.D.A.: Review of the methodology\nand validation process; A.C.G.: Writing review; N.O.: Supervisor. All authors have read and agreed to the\npublished version of the manuscript.\nFunding: This research received no external funding.\nAcknowledgments: We thank Mackenzie Presbyterian Univesity, Embrapa Agroinformatica, Fundação Getúlio\nVargas, Capes, for the support with this research. We also thank Vanessa Pugliero and Eduardo Pavão from\nEmbrapa for the support with organization of the information used during the validation process.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n1. Johansson, R.; Luebehusen, E.; Morris, B.; Shannon, H.; Meyer, S. Monitoring the impacts of weather and\nclimate extremes on global agricultural production. Weather Clim. Extrem. 2015 ,10, 65–71. [CrossRef]\n2. Shi, Z.H.; Li, L.; Yin, W.; Ai, L.; Fang, N.F.; Song, Y.T. Use of multi-temporal Landsat images for analyzing\nforest transition in relation to socioeconomic factors and the environment. Int. J. Appl. Earth Obs. Geoinf.\n2011 ,13, 468–476. [CrossRef]\n3. Kaliraj, S.; Chandrasekar, N.; Magesh, N.S. Evaluation of multiple environmental factors for site-speciﬁc\ngroundwater recharge structures in the Vaigai River upper basin, Tamil Nadu, India, using GIS-based\nweighted overlay analysis. Environ. Earth Sci. 2015 ,74, 4355–4380. [CrossRef]\n4. Herman, E.; Haesen, D.; Rem, F.; Urbano, F.; Tote, C.; Bydekerke, L. Monitoring the impacts of weather and\nclimate extremes on global agricultural production. ISPRS J. Photogramm. Remote Sens. 2015 ,53, 154–162.\n[CrossRef]\n5. Lahousse, T.; Chang, K.T.; Lin, Y.H. Landslide mapping with multi-scale object-based image analysis-a case\nstudy in the Baichi watershed, Taiwan. Nat. Hazards Earth Syst. Sci. 2011 ,11, 2715–2726. [CrossRef]\n6. Coase, R.H. The Nature of the Firm 1937. Economica 1937 ,4, 386–405. [CrossRef]\n7. Barzel, Y.; Kochin, L.A. Ronald Coase on the Nature of Social Cost as a Key to the Problem of the Firm.\nScand. J. Econ. 1992 ,94, 19–31. [CrossRef]\n\nRemote Sens. 2020 ,12, 1791 13 of 14\n8. Guijarro, M.; Pajares, G.; Riomoros, I.; Herrera, P .J.; Burgos-Artizzu, X.P .; Ribeiro, A. Automatic segmentation\nof relevant textures in agricultural images. Comput. Electron. Agric. 2011 ,75, 75–83. [CrossRef]\n9. Mulyono, S.; Pianto, T.A.; Fanany, M.; Basaruddin, T. An ensemble incremental approach of Extreme\nLearning Machine (ELM) For paddy growth stages classiﬁcation using MODIS remote sensing images.\nAdv. Comput. Sci. Inf. Syst. 2013 , 309–314. [CrossRef]\n10. Jones, H.G.; Vaughan, R.A. Remote Sensing of Vegetation: Principles, Techniques and Applications ; Oxford:\nNew York, NY, USA, 2010; p. 353. [CrossRef]\n11. Cariou, C.; Chehdi, K. Unsupervised nearest neighbors clustering with application to hyperspectral Images.\nIEEE J. Sel. Top. Signal Process. 2015 ,9, 1105–1116. [CrossRef]\n12. Kussul, N.; Lavreniuk, M.; Skakun, S.; Shelestov, A. Deep Learning Classiﬁcation of Land Cover and Crop\nTypes Using Remote Sensing Data. IEEE Geosci. Remote Sens. Lett. 2017 ,14, 778–782. [CrossRef]\n13. Waldner, F.; De Abelleyra, D.; Verón, S.R.; Zhang, M.; Wu, B.; Plotnikov, D.; Bartalev, S.; Lavreniuk, M.;\nSkakun, S.; Kussul, N.; et al. Towards a set of agrosystem-speciﬁc cropland mapping methods to address the\nglobal cropland diversity. Int. J. Remote Sens. 2016 ,37. [CrossRef]\n14. Arvor, D.; Jonathan, M.; Meirelles, M.S.P .; Dubreuil, V .; Durieux, L. Classiﬁcation of MODIS EVI time series\nfor crop mapping in the state of Mato Grosso, Brazil. Int. J. Remote Sens. 2011 ,32, 7847–7871. [CrossRef]\n15. Hatami, N.; Gavet, Y.; Debayle, J. Classiﬁcation of Time-Series Images Using Deep Convolutional\nNeural Networks. In Proceedings of the 10th International Conference Machine Vision, Vienna, Austria,\n13–15 November 2017; pp. 1–9. [CrossRef]\n16. Rezaee, M.; Mahdianpari, M.; Zhang, Y.; Salehi, B. Deep Convolutional Neural Network for Complex\nWetland Classiﬁcation Using Optical Remote Sensing Imagery. IEEE J. Sel. Top. Appl. Earth Obs.\nRemote Sens. 2018 . [CrossRef]\n17. Transon, J.; D’Andrimont, R.; Maugnard, A.; Defourny, P . Survey of hyperspectral Earth Observation\napplications from space in the Sentinel-2 context. Remote Sens. 2018 ,10, 157. [CrossRef]\n18. Chen, B.; Huang, B.; Xu, B. Multi-source remotely sensed data fusion for improving land cover classiﬁcation.\nISPRS J. Photogramm. Remote Sens. 2017 ,124, 27–39. [CrossRef]\n19. Huang, B.; Wei, D.K.; Li, H.X.; Zhuang, Y.L. Using a rough set model to extract rules in dominance-based\ninterval-valued intuitionistic fuzzy information systems. Inf. Sci. 2013 ,221, 215–229. [CrossRef]\n20. Brown, J.C.; Kastens, J.H.; Coutinho, A.C.; de Castro Victoria, C.; Bishop, C.R. Classifying\nmultiyear agricultural land use data from Mato Grosso using time-series MODIS vegetation index data.\nRemote Sens. Environ. 2013 ,130, 39–50. [CrossRef]\n21. Mastella, A.F.; Vieira, C.A. Acurácia temática para classiﬁcação de imagens utilizando abordagens por pixel\ne por objetos. Rev. Bras. Cartogr. 2018 ,70, 1618–1643. [CrossRef]\n22. Silva Junior, C.; Frank, T.; Rodrigues, T. Discriminação de áreas de soja por meio de imagens EVI/MODIS e\nanálise baseada em geo-objeto. Rev. Bras. Eng. Agrícola Ambient. 2014 ,18, 44–53. [CrossRef]\n23. Eerens, H.; Haesen, D.; Rembold, F.; Urbano, F.; Tote, C.; Bydekerke, L. Image time series processing for\nagriculture monitoring. Environ. Model. Softw. 2014 ,53, 154–162. [CrossRef]\n24. Furtado, L.F.D.A.; Francisco, C.N.; de Almeida, C.M. Análise de Imagem Baseada em Objeto Para Classiﬁcação\ndas Fisionomias da Vegetação em Imagens de Alta Resolução Espacial ; Unesp Geociências; UNESP , Ed.; UNESP:\nSão Paulo, Brazil, 2013; Volume 32, pp. 441–451.\n25. Abade, N.A.; De Carvalho, O.A.; Guimarães, R.F.; De Oliveira, S.N. Comparative analysis of MODIS\ntime-series classiﬁcation using support vector machines and methods based upon distance and similarity\nmeasures in the brazilian cerrado-caatinga boundary. Remote Sens. 2015 ,7, 12160–12191. [CrossRef]\n26. Tu, B.; Kuang, W.; Zhao, G.; Fei, H. Hyperspectral Image Classiﬁcation via Superpixel Spectral Metrics\nRepresentation. IEEE Signal Process. Lett. 2018 ,25, 1520–1524. [CrossRef]\n27. Bailey, J.T.; Boryan, C.G. Remote Sensing Applications in Agriculture at the USDA National Agricultural Statistics\nService ; Technical Report; USDA: Washington, DC, USA, 2010.\n28. Hatﬁeld, J.L.; Gitelson, A.A.; Schepers, J.S.; Walthall, C.L. Application of spectral remote sensing for\nagronomic decisions. Agron. J. 2008 ,100, 117–131. [CrossRef]\n29. NASA. Modis Data Products. Available online: https://modis.gsfc.nasa.gov/data/dataprod/ (accessed on\n27 July 2019).\n30. Angel, C.; Asha, S. A Survey on Ambient Intelligence in Agricultural Technology. Int. J. Biol. Biomol. Agric.\nFood Biotechnol. Eng. 2015 ,9, 210–213. [CrossRef]\n\nRemote Sens. 2020 ,12, 1791 14 of 14\n31. CEPEA. Center for Applied Economics Studies. Available online: https://www.cepea.esalq.usp.br/\n(accessed on 20 June 2019).\n32. IBGE. Brazilian Institute of Geography and Statistics. Rural Census. Available online: https://censos.ibge.\ngov.br/agro/2017/templates/censo_agro/resultadosagro/index.html (accessed on 20 November 2019).\n33. EMBRAPA. Brazilian Agricultural Research Corporation. Availabel online: www.embrapa.br/ (accessed on\n26 July 2019).\n34. EMBRAPA Informática. Embrapa Agricultural Informatics. Available online: https://www.embrapa.br/\nen/informatica-agropecuaria (accessed on 23 July 2019).\n35. MAPA. Ministry of Agriculture, Livestock and Food Supply. Available online: http://www.agricultura.gov.\nbr (accessed on 26 July 2019).\n36. Gruber, T.R. A translation approach to portable ontology speciﬁcations. Knowl. Acquis. 1993 ,5, 199–220.\n[CrossRef]\n37. Oliveira, A.B.F.; Werneck, V .M.B. Construindo ontologias a partir de recursos existentes: Uma prova de\nconceito no domínio da educação. IME USP 2003 ,15, 226. [CrossRef]\n38. GFS. Global Food Security. Available online: www.cropland.org (accessed on 27 July 2019).\n39. EMBRAPA. Vegetation Temporal Analysis System. Available online: https://www.satveg.cnptia.embrapa.\nbr/satveg/login.html (accessed on 26 July 2019).\n40. Kraska, T.; Beutel, A.; Chi, E.H.; Dean, J.; Polyzotis, N. The Case for Learned Index Structures. CoRR 2017 .\n[CrossRef]\n41. Mnih, V .; Kavukcuoglu, K.; Silver, D.; Rusu, A.A.; Veness, J.; Bellemare, M.G.; Graves, A.; Riedmiller, M.;\nFidjeland, A.K.; Ostrovski, G.; et al. Human-level control through deep reinforcement learning. Nature\n2015 ,518, 529–541. [CrossRef]\n42. Zhou, J. Enhancing Time Series Clustering by Incorporating Multiple Distance Measures with\nSemi-Supervised Learning. J. Comput. Sci. Technol. 2015 ,30, 859–873. [CrossRef]\n43. Montero, P .; Vilar, J. TSclust: An R Package for Time Series Clustering. JSS J. Stat. Softw. 2014 ,62, 1–43.\n[CrossRef]\n44. Lee, K.S.; Jin, D.; Yeom, J.M.; Seo, M.; Choi, S.; Kim, J.J.; Han, K.S. New Approach for Snow Cover Detection\nthrough Spectral Pattern Recognition with MODIS Data. J. Sens. 2017 ,2017 . [CrossRef]\n45. Pereira, M.E.; Ferreira, F.D.O.; Martins, A.H.; Cupertino, C.M. Introdução ao processamento de imagem de\nsensoriamento remoto. Estudos de Psicologia 2002 ,7, 389–397. [CrossRef]\n46. Rocchini, D.; Foody, G.M.; Nagendra, H.; Ricotta, C.; Anand, M.; He, K.S.; Schmidtlein, S.; Feilhauer, H.;\nAmici, V .; Kleinschmit, B.; et al. Uncertainty in ecosystem mapping by remote sensing. Comput. Geosci.\n2013 , 128–135. [CrossRef]\n47. Stanton, J. An Introduction to Data Science. Syracuse Univ. 2012 , 1–157. [CrossRef]\n48. Cai, Y.; Guan, K.; Peng, J.; Wang, S.; Seifert, C.; Wardlow, B.; Li, Z. A high-performance and in-season classi\nﬁ cation system of ﬁ eld-level crop types using time-series Landsat data and a machine learning approach.\nRemote Sens. Environ. 2018 ,210, 35–47. [CrossRef]\n49. Luiz, A.J.B.; Eberhardt, I.D.R.; Schultz, B.; Formaggio, A.R. Visualização de dados de imagens de\nsensoriamento remoto. Rev. da Estatística UFOP 2014 ,III, 260–265.\n50. Rezende, C.L.; Scarano, F.R.; Assad, E.D.; Joly, C.A.; Metzger, J.P .; Strassburg, B.B.N.; Mittermeier, R.A.\nFrom hotspot to hopespot: An opportunity for the Brazilian Atlantic Forest. Perspect. Ecol. Conserv.\n2018 ,16, 208–214. [CrossRef]\n51. Zhou, Z.; Huang, J.; Wang, J.; Zhang, K.; Kuang, Z.; Zhong, S.; Song, X. Object-oriented classiﬁcation\nof sugarcane using time-series middle-resolution remote sensing data based on AdaBoost. PLoS ONE\n2015 ,10, e0142069. [CrossRef]\nc\r2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access\narticle distributed under the terms and conditions of the Creative Commons Attribution\n(CC BY) license (http://creativecommons.org/licenses/by/4.0/).",
  "textLength": 43001
}