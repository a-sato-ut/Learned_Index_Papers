{
  "paperId": "81349e937986746baa6569b2b19f6f3091357ed0",
  "title": "Algorithmic Complexity Attacks on Dynamic Learned Indexes",
  "pdfPath": "81349e937986746baa6569b2b19f6f3091357ed0.pdf",
  "text": "Algorithmic Complexity Attacks on Dynamic Learned Indexes\nRui Yang\nUniversity of Virginia\nqgh4hm@virginia.eduEvgenios M. Kornaropoulos\nGeorge Mason University\nevgenios@gmu.eduYue Cheng\nUniversity of Virginia\nmrz7dp@virginia.edu\nABSTRACT\nLearned Index Structures (LIS) view a sorted index as a model that\nlearns the data distribution, takes a data element key as input, and\noutputs the predicted position of the key. The original LIS can only\nhandle lookup operations with no support for updates, rendering it\nimpractical to use for typical workloads. To address this limitation,\nrecent studies have focused on designing efficient dynamic learned\nindexes. ALEX, as the first and one of the representative dynamic\nlearned index structures, enables dynamism by incorporating a\nseries of design choices, including adaptive key space partition-\ning, dynamic model retraining, and sophisticated engineering and\npolicies that prioritize read/write performance. While these design\nchoices offer improved average-case performance, the emphasis on\nflexibility and performance increases the attack surface by allowing\nadversarial behaviors that maximize ALEXâ€™s memory space and\ntime complexity in worst-case scenarios.\nIn this work, we present the first systematic investigation of\nalgorithmic complexity attacks (ACAs) targeting the worst-case\nscenarios of ALEX. We introduce new ACAs that fall into two cat-\negories, space ACAs and time ACAs, which target the memory\nspace and time complexity, respectively. First, our space ACA on\ndata nodes exploits ALEXâ€™s gapped array layout and uses Multiple-\nChoice Knapsack (MCK) to generate an optimal adversarial inser-\ntion plan for maximizing the memory consumption at the data node\nlevel. Second, our space ACA on internal nodes exploits ALEXâ€™s\ncatastrophic cost mitigation mechanism, causing an out-of-memory\n(OOM) error with only a few hundred adversarial insertions. Third,\nour time ACA generates pathological insertions to increase the dis-\nparity between the actual key distribution and the linear models of\ndata nodes, deteriorating the runtime performance by up to 1,641Ã—\ncompared to ALEX operating under legitimate workloads.\nPVLDB Reference Format:\nRui Yang, Evgenios M. Kornaropoulos, and Yue Cheng. Algorithmic\nComplexity Attacks on Dynamic Learned Indexes. PVLDB, X(X): XXX -\nXXX, 2023.\ndoi:XX.XX/XXX.XX\nPVLDB Artifact Availability:\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/ds2-lab/aca-dlis.\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. X, No. X ISSN 2150-8097.\ndoi:XX.XX/XXX.XX1 INTRODUCTION\nIndex structures are essential to database systems for efficient data\nstorage and retrieval. Traditional database index structures pre-\ncisely organize each and every data item to balance tradeoffs in\nquery performance and memory efficiency. Recent work by Kraska,\nBeutel, Chi, Dean, and Polyzotis [ 35] proposes to replace the tradi-\ntional database index with a hierarchy of machine learning (ML)\nmodels, which is called Learned Index Structure (LIS). The insight\nis that a sorted index can be viewed as a model, which learns the\ndata distribution, takes a data element key as input, and outputs\nthe location of the key stored in a storage medium (e.g., a disk).\nUnder LIS, a query starts by consulting a root model at the top\nof the hierarchy in order to predict the child model to use, and\nperforms a model traversal downwards the model hierarchy until\nit reaches a leaf node; the leaf node is also a model that will return\nthe predicted position of the key from a densely packed array.\nThe very first LIS proposed in the literature could only handle\nread-only data with no support for update operations. This limi-\ntation made LIS unusable for dynamic read-write workloads. To\naddress this gap, various dynamic index structures have been intro-\nduced, including ALEX [ 19], PGM [ 22], LIPP [ 61], and APEX [ 38],\namong others. In our work, we select ALEX [ 19] as our target for\nour algorithmic complexity attacks (ACAs), because not only is\nALEX the first dynamic learned index (DLIS), but also (1) ALEX\nhasqualitative features that make it a strong candidate for real\ndeployment, and (2) there is strong quantitative evidence that ALEX\nis the most efficient and well-rounded DLIS that can support real\nworkloads, see the recent benchmark studies [ 56,60] that rank\nALEX highly across all tested performance metrics. Similar to LIS,\nALEX organizes models in a tree structure and serves requests by\ntraversing the tree from top to bottom. Unlike LIS, ALEX allows\nboth the internal nodes and leaf nodes (data nodes that store the\ndata element) to dynamically grow and shrink at difference rates.\nTo achieve efficient lookup and insertion operations, ALEX uses\nan array with gaps (called a gapped array ). ALEX also introduces\nheuristic-guided, dynamic node expansion/splitting mechanisms,\npaired with model retraining, to adapt to workload changes.\nThe dynamism of ALEX over LIS is achieved by enabling (1) adap-\ntive key space repartitioning, (2) dynamic model retraining, and\n(3) sophisticated engineering that prioritizes performance. While\nthese design choices offer improved average-case performance, the\nemphasis on flexibility and performance increases the attack surface\nby allowing adversarial behaviors that maximize ALEXâ€™s space and\ntime complexity in worst-case scenarios . These worst-case scenar-\nios can be exploited by a type of attack method called algorithmic\ncomplexity attacks (ACAs) [ 14,28]. ACAs are a class of Denial-of-\nService (DoS) attacks, where an attacker uses a small amount of\nadversarial inputs to induce a large amount of work in the target\nsystem, pushing the system into consuming all available resources.\n1arXiv:2403.12433v1  [cs.DB]  19 Mar 2024\n\nTable 1: A summary of targeted ALEX designs and character-\nistics of the proposed ACAs. Data-Node\nSpace ACAInternal-Node\nSpace ACATime ACA\nMemory\nOver-provisioningâœ“\nExploited Design ChoiceML Prediction\nError Mitigationâœ“ âœ“\nKeyspace\nPartitioningâœ“\nTargeted ComponentInternal Node âœ“\nData Node âœ“ âœ“\nBlack-box âœ“ âœ“\nAttack Setting Gray-box âœ“ âœ“\nWhite-box âœ“ âœ“\nTargeted ResourceMemory (space) âœ“ âœ“\nCPU (time) âœ“\nThe key observation of this paper is that ALEXâ€™s various design\nchoices to handle dynamic workload (including the gapped array\nlayout, the cost models to guide node resizing and model retraining)\nlack worst-case guarantees, which can be exploited by attackers.\nOur Contributions. In this paper, we perform a security analysis\non ALEXâ€™s design choices and present three new ACAs. To the best\nof our knowledge, our work is the first to systematically analyze\nalgorithmic complexity vulnerabilities of dynamic learned indexes.\nThe three ACAs fall into two categories, which target the space and\ntime complexity aspects of the ALEX index structure.\nâ€¢The first category of attacks that we introduce concerns ACA\nthat targets the memory space complexity dimension of ALEX. We\ndiscover a set of adversarial input cases that cause significant mem-\nory consumption increases at both the data node level and internal\nnode level. First, our space ACA on data nodes exploits the design\nthat ALEX uses a gapped array layout with dispersed empty space\ncalled gaps for performance to perform a memory space complexity\nattack. This attack models ALEXâ€™s global data node structure as\na knapsack problem and uses Multiple-Choice Knapsack (MCK)\nto generate an optimal insertion plan for maximizing the memory\nconsumption at the data node level. Second, our space ACA on\ninternal nodes issues duplicate keys to trigger ALEXâ€™s catastrophic\ncost mitigation mechanism, where ALEX needs to recursively split\na data node with the hope to bring the duplicate-key-induced cost\ndown to below the threshold; the catastrophic outcome of this at-\ntack is that, with just a small amount of insertions for duplicate\nkeys, ALEX repeatedly applies recursive-split operations and ex-\nponentially increases the size of the internal nodeâ€™s pointer array,\nwhich, in turn, exhausts all available memory resources on the host.\nâ€¢The second category of attacks is time ACAs, wherein we design\nan attack method aimed at increasing the number of model-retrain\noperations. This attack generates pathological insertions that con-\nsist of consecutive keys to deviate the actual key distribution from\nthe linear model of a set of randomly chosen (under black-box at-\ntacks) or deliberately chosen (under white-box or gray-box attacks)\ndata nodes. The outcome of this attack is a dramatically increased\nruntime performance overhead caused by model retraining.\nâ€¢Our ACAs expose vulnerabilities that contradict the intended\nbenefits of space efficiency and performance, which are the original\ndesign goals of LIS [ 35], thereby stressing the need for new designs\nof dynamic learned indexes with worst-case guarantees.\nSummary of Our Proposed ACAs. In this work, we propose\nthree different ACAs and summarize their features in Table 1. For\neach ACA, we explain the exploited ALEX design choices, the tar-\ngeted components, the attack settings, and the target resources.The details are as follows: (1) Our space ACA on data nodes is\ndesigned to target the memory space resource of the target host. It\nexploits the memory over-provisioning design choice of ALEX to\nmaximize ALEXâ€™s memory consumption by expanding the capacity\nof data nodes. The effectiveness of this ACA depends on the key\ndistribution of the workload and the adversarial budget size. It can\nbe mounted in both white-box and gray-box settings. (2) Our space\nACA on internal nodes also targets the memory space resource but\nwith a different approach. This attack aims to exhaust the target\nhostâ€™s memory resources, by causing an OOM event. It exploits two\ndesign components of ALEX: recursive splitting of a data node and\nkey-space based partitioning that halves the keyspace regardless of\nhow keys are distributed in it. This attack requires the target data-\nbase to support duplicate keys and can be mounted in a black-box\nsetting. (3) Our time ACA targets the hostâ€™s CPU resource, to maxi-\nmize the number of retrains to deteriorate the performance of the\nindex. The effectiveness of this attack can be affected by the work-\nloadâ€™s key distribution, the read/write ratio, and the adversarial\nbudget size. It can be mounted in all three settings.\nOverview of Our Findings. We conduct an extensive set of ex-\nperiments on real-world datasets. For space ACA on data nodes,\nwe increase the memory usage by up to 31% compared to base-\nline ALEX with a budget size ranging from 1%to30%of various\nworkload sizes. In the case of space ACA on internal nodes, our\ninternal-node ACA is capable of depleting the entire memory re-\nsources of the host machine with just a few hundred of adversarial\ninsertions. Our time ACAs cause a throughput degradation of ALEX\nby up to 1,641Ã—with a small adversarial budget (ranging from 2.5%\nto10%of the workload size for write-heavy workloads and 0.5%to\n2%of the workload size for read-heavy workloads).\n2 PRELIMINARIES\n2.1 Static Learned Index Structures\nKraska et al. [ 35] propose to replace the traditional index structures\nwith a hierarchy of learned models that they call Learned Index\nStructures (LIS). The insight of LIS is that the task of locating a key\nğ‘˜within a set of linearly ordered keys can be reduced to approx-\nimating the probability that a randomly chosen key would take\na value less or equal to ğ‘˜, i.e.,ğ‘ƒğ‘Ÿ(ğ‘‹â‰¤ğ‘˜)=ğ‘…ğ‘ğ‘›ğ‘˜(ğ‘˜)/ğ‘›, whereğ‘‹\nis the random variable that follows the empirical distribution of\ntheğ‘›keys andğ‘…ğ‘ğ‘›ğ‘˜(.)is a function that takes a key as an input\nand outputs its relative position among the ğ‘›keys. This probability\nis captured by the cumulative distribution function (CDF); there-\nfore, the task of locating a key reduces to learning the CDF of the\nsorted key set . In a CDF plot, the ğ‘‹-axis represents the keys, and the\nğ‘Œ-axis represents the rank of the keys. To approximate the entire\nkey distribution, LIS introduces the Recursive Model Index (RMI), a\ntree-structured, multi-stage architecture where models at a higher\nstage direct the queries to models at a lower stage to fine-tune the\nprecision of the predicted key location.\n2.2 ALEX: Dynamic Learned Index Structure\nA limitation of LIS [ 35] is that it only supports lookup operations\non read-only data. Thus, it is not applicable to scenarios where\nwrite operations are needed. A follow-up system called ALEX [19]\nwas the first dynamic learned index structure that extends the idea\n2\n\nM\nLegend\nGapped Array Linear Regression Model\nData\nNodeInternal\nNodeExponential Search Binary Search Lookup Path\nKey Gap\nPointer ArrayMRedundant PointersM\nMMMAdaptive RMI   \nMMRoot Internal Node\nMKeyFigure 1: An illustration of ALEX.\nof LIS. At ALEXâ€™s core is a dynamic, tree-based index structure that\nconsists of, much like the commonly-used B+tree structures [ 50],\na hierarchy of two types of nodes, namely ( ğ‘–)internal nodes and\n(ğ‘–ğ‘–)data nodes . Contrary to B+tree structures, each ALEX node is\naccompanied by a learning model (i.e., linear regression) that, as we\nexplain in the following, serves different functionality depending\non whether it is a data node or an internal node.\nThe Role of Internal Nodes. An internal node stores a linear\nmodel and a pointer array that points to its children nodes. On a\nhigh level, the model takes as an input a key and outputs a location\nof its pointer array. Each entry of the pointer array is a reference\nto a model from the next level of the tree. We emphasize that all\nthe entries of the pointer array point to child nodes; in case the\narray has more slots than the number of child nodes, then ALEX\nallows multiplicities for pointers, also called redundant pointers\n(see Figure 1). The following process generates redundant pointers:\nSuppose that a node ğ‘‹is split (a mechanism that is described in\ndetail later); if ğ‘‹â€™s parent node has a single pointer in its pointer\narray associated with ğ‘‹, then the pointer array of ğ‘‹â€™s parent needs\nto be doubled to accommodate the two new nodes from ğ‘‹â€™s split.\nAll the previous pointers are transferred to the new doubled-size\narray, and each pointer doubles its entries in the new array; that is\nif the sibling ğ‘Œofğ‘‹had 4 pointers pointing at it, in the new pointer\narray, there are 8 pointers that point to ğ‘Œ. The relation between the\ninternal node and its children is the following: internal node ğ‘‹is\nresponsible for handling lookups/updates on a partition [ğ›¼,ğ›½]of the\nkey space, while each of the children nodes of ğ‘‹is responsible for a\nnon-overlapping (fine-grained) partition of [ğ›¼,ğ›½]; the role ofğ‘‹is to\npropagate a lookup/update to the right partition. At the last level of\nthe tree, partitions are associated with a data node that hosts keys\nthat are distributed â€œroughlyâ€ linearly in the associated partition\n(see Figure 1). In summary, working in conjunction with the data\nnodes, internal nodes serve two critical functions: (1) Internal nodes\ndirect queries from top to bottom to the right data nodes; (2) Internal\nnodes enable requests to be progressively directed to fine-grained\n(and variable size) partitions of the keyspace.\nThe Role of Data Nodes. A data node stores a linear model and a\ngapped array to store data elements. The empty spaces of the gapped\narray, i.e., the â€œgapsâ€, are initially distributed uniformly during thenode creation. ALEX relies on these gaps to efficiently absorb new\ninsertions and respond to lookups. The density is defined as the\nratio between the current number of keys in the gapped array and\nits total capacity. Each data node maintains the fraction of gaps\nbetween a fixed lower density limit ğ‘‘ğ‘™and a fixed upper density limit\nğ‘‘â„, which are (by default) set to 0.6and 0.8, respectively.\nLookups. ALEX locates a key by performing a tree traversal from\nthe top of the tree to the bottom. The query is directed from a\nparent internal nodeâ€™s linear model to one of its children/nodes\nuntil the query reaches a data node, also known as a leaf node in\nthe context of a B+tree. Once the traversal reaches the correct data\nnode, its linear model predicts the key position in the gapped array.\nDuring lookups, ALEX returns the key, if found, in the predicted\nposition; otherwise, there is a prediction error and ALEX performs\nan exponential search on the gapped array to find the key.\nInsertions. For insertions, ALEX directly inserts the key into the\npredicted position; in case an existing key already occupies the pre-\ndicted position, ALEX shifts existing keys toward the direction of\nthe closest gap to create an empty slot for the new key. ALEX guar-\nantees accurate placement of data by using model-based insertions\nto ensure that: (1) for insertions, the input key is always inserted\ninto the model-predicted position, and (2) for lookups, records are\nlocated close to the predicted position when possible.\nAdapting to Workloads. As the number of gaps decreases in a\ndata node, the performance of both insertions and lookups degrades.\nTo provide a good average-case performance, ALEX dynamically\nexpands or splits data nodes to adapt to workload changes. ALEX\ndoes not wait until a data node becomes 100% full; instead, ALEX\nexpands a data nodeâ€™s gapped array when the used space increase\nbeyond the chosen upper-density limit. ALEX uses linear cost mod-\nels to determine if, after the updates, the trained model of a data\nnode deviates from the true distribution of keys. The cost model\nuses simple heuristics to compare (1) the expected (modeled) cost\ncomputed at the data node creation time to (2) the real-time empiri-\ncal cost calculated by counting the number of exponential searches\n(for mispredicted lookups) and memory shifts (for insertions that\ncause key shifts) that have occurred since data nodeâ€™s creation.\nHandling Corner Cases. In addition, ALEX introduces heuristics\nto handle edge cases when a data nodeâ€™s cost increases beyond a\nthreshold. Such edge cases are deemed as â€œcatastrophicâ€ events that\nsignificantly deteriorate ALEXâ€™s performance. In these cases, ALEX\nsplits the data node affected by a catastrophic event to reduce the\ncost. ALEX implements two kinds of splits: splitting sideways and\nsplitting downwards . A sideways split, which is the more common\ncase, directly partitions a data nodeâ€™s key space in half and assign\nthe first half of redundant pointers (if any) to the left child data node\nand the second half of redundant pointers to the right child data\nnode. If the parent internal node runs out of redundant pointers,\nALEX doubles the size of the parent nodeâ€™s pointer array and adjusts\nits linear model parameters (the intercept and the slope) accordingly.\nDownwards splits only happen when splitting sideways is no longer\npossible. That is, the pointer array of the parent internal node is\n16MB (can be tuned at initialization).\n2.3 Algorithmic Complexity Attacks\nIn ACAs [ 14], an attacker uses a small number of adversarial inputs\nto introduce a disproportional amount of work to the target system,\n3\n\npushing the system into using all available resources. ACAs are\ntailored to the algorithmic approach at hand and force a worst-\ncase performance for the system. ACAs can be categorized into\ntime ACA where an attacker aims to exhaust the CPU resources [ 5,\n36,47,49], and space ACA , where an attacker aims to exhaust the\nmemory or disk resources [ 25]. Take the hash-table attacks [ 14]\nas a time ACA example. A hash table can degrade to a linked list\nwith carefully chosen inputs whose hash values map to the same\nbucket. Decompression bombs [ 28] exploit the capability of efficient\ncompression algorithms to mount a space ACA by decompressing\nfiles and quickly consuming a large amount of storage space.\nML for systems is gaining traction and is becoming an increas-\ningly powerful tool for improving modern computer systems [ 9,\n35,40,41,54,59]. However, incorporating ML into complex com-\nputer systems inevitably expands the attack surface, leading to\nincreasing vulnerabilities. Poisoning attacks [ 8,21,64,65] consider\nadversaries that deliberately augment the training data to manipu-\nlate the results of ML models. Kornaropoulos et al. [ 33] were the\nfirst to demonstrate poisoning attacks (which can be thought of as a\ntime ACA) against the original, static LIS. However, when it comes\nto dynamic LIS like ALEX, the impact of injecting poisoning keys\nis not well understood. This is primarily due to ALEXâ€™s ability to\ndynamically adapt its key space partitioning and retrain its models,\nwhich helps mitigate the effects of the poisoning attack.\nSimilar to data structures that are vulnerable to ACAs, ML sys-\ntems commonly employ ML models that are trained to optimize\naverage-case objectives. However, these ML systems often lack\nrobust guarantees regarding worst-case complexity. As we demon-\nstrate in this work, an attacker can exploit ALEXâ€™s worst-case\ncomplexityâ€”node splits or expansionsâ€”by inserting deliberately\nchosen inputs to mount space and time ACAs.\n2.4 Threat Model\nAttackerâ€™s Goal. ALEX [ 19] offers the ability to adjust its shape\nto a dynamic workload adaptively. In this work, our focus is on\nadversaries who insert maliciously chosen keys into ALEX to trig-\nger worst-case behaviors, ultimately using all available machine\nresources. The motives behind such adversarial behaviors vary de-\npending on the potential gains and the context of the application,\nsuch as a competitor seeking to degrade performance or a denial-\nof-service attack. Specifically, in Â§3.1 and Â§3.2, our objective for\nspace ACAs is to use all hostâ€™s memory. In Â§3.3, the time ACAs aim\nto degrade the throughput of ALEX.\nAttackerâ€™s Knowledge. In this work we study white-box, gray-box,\nand black-box attacks. In the white-box scenario, the attacker has\nfull access to the inner-working of the ALEX under attack, including\nparameters of the linear regression models and internal structures\n(data nodes, internal nodes, and keys). White-box attacks [ 5,10,14â€“\n16] are a natural first step towards assessing the robustness of a\ntarget system since they quantify the maximum damage , i.e., act as\nan upper bound to any future black-box attack, which an adversary\ncan make to a system. Previously proposed ACAs have primarily\nbeen developed in the white-box setting. For example, in [14], the\nadversary has full knowledge of the targeted hash table (or binary\ntree) in all three scenarios examined, namely ACAs against Perlâ€™s\nhash tables, Squid web proxy, and Bro intrusion detection. Similarly,in [15,16], the adversary has full knowledge of the control rules of\nOpen vSwitch (OVS) so as to mount an ACA.\nAttackerâ€™s Capabilities. We assume that the attacker can per-\nform insertions into the target ALEX instance. There are several\nscenarios where an attacker can insert data to a target DB. First,\nshared DBs are extensively used in many application scenarios (but\nnot yet using the LIS paradigm). Companies such as Meta deploy\ndatabase systems that are shared by multiple applications [ 11], e.g.,\nUDB, ZippyDB, and UP2X. Another example is Googleâ€™s DB infras-\ntructure, including Bigtable [ 12], together with the learned index\nsystem built atop Bigtable [ 4], serves many concurrent users and\napplications. If the above systems used an LIS, malicious users could\npotentially mount ACAs to target shared DB services. Furthermore,\nthe YCSB benchmark is synthesized based on the workload patterns\nof real-world, multi-tenant database systems [ 13]. Second, crowd-\nsourced databases [ 23,32,42,46] allow users to contribute their\ndata. In such a setting, an attacker can contribute to these datasets\nso as to poison/attack the learned index. Even if the attacker does\nnot have access to the exact dataset, it is enough to have knowledge\nof the underlying distribution in order to devise an approach for\ngenerating maliciously crafted keys (e.g., the black-box setting of\nour space ACA on data nodes). Many real-world applications use\ncrowd-sourced databases, e.g. OpenStreetMap [ 2] and Amazonâ€™s\nMechanical Turk (AMT) [1].\nTerminology. For space ACAs, we denote the number of adversar-\nial insertions as ğ‘and the number of legitimate insertions as ğ‘™. We\ntest our attacks on different adversarial budget scenarios between\n5%to30%, i.e., different parameterization of 100Â·(ğ‘/(ğ‘+ğ‘™)). For\ntime ACAs, we use ğ‘to denote the number of adversarial insertions,\nğ‘™to denote the number of legitimate insertions, and ğ‘to denote the\nlookup operations on the legitimate keys. In this case, the adversar-\nial budget definition changes to 100Â·(ğ‘/(ğ‘+ğ‘™+ğ‘)). We evaluate\nthe effect of adversarial insertions under two workloads: (1)write-\nheavy and(2)read-heavy. The write-heavy workload consists of\n50%inserts and 50%lookups, while the read-heavy workload has a\nratio of 10%inserts and 90%lookups.\n3 ALGORITHMIC COMPLEXITY ATTACKS\nAGAINST ALEX INDEX STRUCTURE\nIn this section, we present three ACAs that aim to manipulate the\nresource utilization of the ALEX. Two of these attacks focus on\nmemory consumption, while the third targets CPU usage. We begin\nby introducing a space ACA that focuses on data nodes in Â§3.1.\nNext, in Â§3.2, we present a space ACA that exploits the structure\nofinternal nodes of ALEX. Finally, in Â§3.3, we present a time ACA\nthat degrades the throughput of ALEX. Our attack exposition is\norganized as follows: (1) presenting the ALEX design choice that\nthe attack relies on, (2) the attack method, and (3) evaluation.\n3.1 Space ACA on Data Nodes\nIn this subsection, we propose our first space ACA, which targets\nthe memory utilization of the host system through exploiting the\ndata node over-provision logic. Our experiments show that our\nattack uses up to 30%more memory than ALEX [ 19] compared to\nusing legitimate keys. We tested the attack on all four datasets used\nin the original ALEX paper [19] and reported the results.\n4\n\n3.1.1 Exploitable Design Choice. ALEX relies on model-based inser-\ntion(see â€œInsertionsâ€ paragraph in Â§2.2) to decide a memory location\nfor an inserted key. The driving force of model-based insertion is\nthe gapped array, a data structure that balances the efficiency/frag-\nmentation trade-off in this dynamic setting.\nTrade-offs in Gapped Array. The gapped array prioritizes the\nspeed of insertion over memory usage. Specifically, due to the\nmodel-based insertion, the gapped array guarantees efficient inser-\ntion with an ğ‘‚(ğ‘™ğ‘œğ‘”ğ‘)time complexity (see [ 19] for the analysis).\nHowever, the way of inserting (i.e., forcefully placing the key in\nthe predicted location by shifting existing keys to make space) in-\ntroduces long consecutive segments of allocated keys. As a result,\nin case of a lookup of a shifted key, ALEXâ€™s original prediction\nis wrong, which triggers a â€œcorrectiveâ€ search mechanism that lo-\ncates the shifted key. To compensate for slower lookups caused by\nlong consecutive segments, ALEX preemptively migrates to a larger\ngapped array before it reaches 100% capacity. Specifically, ALEX\nintroduces lower and upper density limits, ğ‘‘ğ‘™=0.6andğ‘‘â„=0.8,\nfor each gapped array. A data node is considered fullif it reaches\nthe upper limit ğ‘‘â„. Once a data node is full, ALEX performs either\na node expansion or a node split, depending on the calculation of\nthe data nodeâ€™s cost model (Â§3.2). After the above action, ALEX\nincreases the capacity of the new data node(s) to#records\nğ‘‘ğ‘™.\nOn Exploiting the Over-Provisioning Logic. Notice that given\nthe described over-provisioning approach, the empty space in a\ngapped can be at most 40%(which occurs when being at ğ‘‘ğ‘™capacity,\ni.e., right after a split/expansion) and at least 20%(which occurs\nwhen being at ğ‘‘â„capacity, i.e., before a split/expansion). We make\nthe following observation: If the attacker constructs an insertion se-\nquence that pushes a gapped array to ğ‘‘â„=0.8density, then the very\nnext insertion to this data node will trigger a split/expansion which\nwill initialize the new gapped with 40%empty space. We study the\nproblem of how to craft such insertion sequences and maximize\nthe memory allocation by exploiting the over-provisioning logic.\nInterestingly, since each split/expansion increases the empty space\nproportionally to the data nodeâ€™s relative size, we can see that some\ndata nodes may give us more empty space than others. Thus, the\nattacker has to choose which data node to target first.\n3.1.2 Attack Method. An attackerâ€™s goal is to maximize the mem-\nory usage of ALEX, given a limited budget of adversarially chosen\nkeys. A greedy strategy is to process the data nodes in descending\norder of size, and add as many keys as needed to each processed\nnode so as to cause a split/expansion, continuing until the budget\nis exhausted. However, such a greedy approach is not optimal.\nWhy the Greedy Approach Does Not Work? Consider the case\nwhere the largest data node requires ğ‘‹keys to reach ğ‘‘â„density and\nperform a split/expansion. Let ğ‘Œbe the number of keys correspond-\ning to the available budget, if ğ‘Œis smaller than ğ‘‹, then the greedy\napproach will â€œwasteâ€ the entire budget without causing a single\nsplit/expansion. This example signals that a different algorithmic\napproach is needed to optimaly allocate the available budget.\nTowards a Knapsack Formulation. In the following, we detail\nhow the attackerâ€™s choice of which data node to target to use the\navailable budget better can be seen as a knapsack problem (KP).\nKnapsack is a fundamental problem in combinatorial optimization\nwith numerous applications to resource allocation scenarios. InKP, there are ğ‘›items, each of which with value ğ‘£ğ‘–and weight ğ‘¤ğ‘–,\nand the objective is to choose a subset ğ‘†of items so that their\nvalue is as high as possible while their overall weight is less than a\ngiven upper-bound ğ‘Š. In more technical terms, in this work, we\nare interested in the 0-1 Knapsack Problem where each item ğ‘–is\nassociated with a variable ğ‘¥ğ‘–âˆˆ{0,1}which takes value 1if theğ‘–-th\nobject is chosen as part of ğ‘†and 0otherwise.\nTowards mapping the above terminology to our space ACA, a\ndata node can be seen as an item. Let ğ‘–âˆˆ[1,ğ‘›]be an indexing of\nthe data nodes. The â€œweightâ€ of a data node corresponds to the\nnumber of keys ğ‘˜ğ‘–that are required to be inserted until the next\nexpansion/split. The â€œvalueâ€ of the data node corresponds to the\nfree space (in bytes) ğ‘“ğ‘–of the data nodeâ€™s gapped array after the next\nexpansion/split. Finally, the â€œbudgetâ€ is the number of keys ğµthe\nattacker can insert. In this formulation, the goal is to pick a subset ğ‘†\nof data nodes, denoted by assigning {ğ‘¥ğ‘–=1}ğ‘–âˆˆğ‘†and{ğ‘¥ğ‘–=0}ğ‘–âˆ‰ğ‘†, so\nas to maximize the objective functionâˆ‘ï¸\nğ‘–âˆˆ[1,ğ‘›]ğ‘¥ğ‘–Â·ğ‘“ğ‘–while satisfying\nthe constraintâˆ‘ï¸\nğ‘–âˆˆ[1,ğ‘›]ğ‘¥ğ‘–Â·ğ‘˜ğ‘–<ğµandğ‘¥ğ‘–âˆˆ{0,1}. Notice that the\nsolution from the above formulation tells the attacker how many\nkeys need to be allocated to each data node but not which keys to\ninsert. Recall that each data node is responsible for a consecutive\nrange of the key domain. Therefore, when the attacker wants to\ngenerateğ‘˜ğ‘–keys to be inserted into a data node, (s)he can simply\nchoose uniformly at random among the corresponding range.\nExtending to Multiple-Choice Knapsack. The above formula-\ntion of 0-1 KP is a good start but it is missing a large number of\npotential strategies for the attacker. Specifically, once the ğ‘–-th data\nnode is chosen (by assigning ğ‘¥ğ‘–=1), the aforementioned formu-\nlation gives no option to consider expanding the same data node\nagain. Thus, in case of an instance where optimal space ACA is\ngiven by extending/splitting the same data node multiple times, the\nabove formulation will give a suboptimal solution.\nIn the following, we present how to extend our KP formulation\nto account for such scenarios. Multiple-Choice Knapsack (MCK)\nis a variant of KP where the items are subdivided into ğ‘šclasses.\nMCK has all the previously described constraints of KP plus an\nadditional constraint that ensures that exactly one item is chosen\nfrom each class of the ğ‘šclasses. The main insight for extending our\nformulation is to consider each data node as a class of its own and\ngenerateğ‘šdistinct scenarios. In each scenario of a data node, the\ninserted keys cause a different number of expansions/splits. Thus,\nwehard-code additional scenarios, each describing the same data\nnode being targeted multiple times. The constraint that â€œonly one\nout ofğ‘šchoices is allowedâ€ guarantees that we wonâ€™t choose the\nsame data node to expand, for example, both once and twice. The\nlast step to reach our final formulation is to introduce a scenario,\nthe(ğ‘š+1)-th one, that allows a data node not to be chosen at all.\nTo capture the MCK notation, we introduce the sub-index ğ‘—that\ntakes values from 1toğ‘š+1and denotes which scenario is chosen\nfor the corresponding data node. Thus, ğ‘¥ğ‘–ğ‘—indicates whether the\nğ‘—-th scenario of the ğ‘–-th data node is chosen, ğ‘“ğ‘–ğ‘—indicates the free\nspace that the attacker generates by targeting the ğ‘–-th data node to\nbe expanded/split multiple times according to the ğ‘—-th scenario, and\nğ‘˜ğ‘–ğ‘—indicates the number of keys that the attacker needs to insert\nto theğ‘–-th data node to be expanded/split multiple times according\nto theğ‘—-th scenario. The complete formulation is the following:\n5\n\nmaxğ‘¥ğ‘– ğ‘—âˆ‘ï¸‚ğ‘›\nğ‘–=1âˆ‘ï¸‚ğ‘š+1\nğ‘—=1ğ‘¥ğ‘–ğ‘—Â·ğ‘“ğ‘–ğ‘—\ns.t.âˆ‘ï¸‚ğ‘›\nğ‘–=1âˆ‘ï¸‚ğ‘š+1\nğ‘—=1ğ‘¥ğ‘–ğ‘—Â·ğ‘˜ğ‘–ğ‘—â‰¤ğµ,\nâˆ‘ï¸‚ğ‘š+1\nğ‘—=1ğ‘¥ğ‘–ğ‘—=1,âˆ€ğ‘–âˆˆ[1,ğ‘›]\nğ‘¥ğ‘–ğ‘—âˆˆ{0,1}(1)\nWhite-Box & Gray-Box Extensions. The following details how\nthe MCK formulation applies to white-box and gray-box attacks. In\nthe white-box scenario, the attacker has access to all the data nodes\nof the target ALEX. Subsequently, the attacker uses an MCK solver\nto determine an offline plan of which data nodes to target and then\nproceeds to insert adversarial keys based on the generated plan. In\nthe gray-box scenario, the attacker has only distributional knowledge\nabout the target ALEX key distribution. In this case, the attacker\ngenerates synthetic data using distributional knowledge and locally\nconstructs a substitute ALEX index. Utilizing this substitute ALEX,\nthe attacker generates a plan using the MCK solver and inserts the\nresulting sequence of keys to the target ALEX.\nDiscussion. For simplicity, in this work, we assume a gray-box\nsetting from which the attacker has access to the key distribution\n(modeled using a Kernel Density Estimation technique); but one\ncan instead query the targeted ALEX instance in the black-box\nsetting and learn an approximation of the key distribution . After this\nstep, the black-box attack proceeds exactly like the gray-box. That\nis, it samples the approximated key distribution to build a local\nsubstitute model; it then crafts an attack on the local model and\napplies the adversarial payload to the target model.\n3.1.3 Evaluation. We implement the MCK solver using Googleâ€™s\nOR-Tools [ 48]. For the substitute ALEX, we use scikit-learn â€™s\nKernel Density Estimation library [ 3]. The bandwidth parameter for\nKDE takes values{0.5,1,1.5}and the kernel parameter is tophat .\n(Refer to [ 3] for detailed information on the above parameters.)\nWe tested our data-node space ACA on an EC2 m5.4xlarge VM\ninstance with 16 vCPUs and 64GB memory. We tested the white-\nbox and gray-box attacks five times and measure the mean increase\nin memory consumption compared to the memory usage under a\nlegitimate workload with the same number of keys (insertions).\nDatasets. We tested four datasets with 8-byte keys: Longitudes\nand Longlat use 8-byte double -precision floating pointer numbers\nas keys, while YCSB and Lognormal use 8-byte intas keys. The\nLongitude workload contains keys that represent the longitudes\nof locations drawn from the OpenStreeMaps public dataset [ 2]. The\nLonglat workload contains mixed keys that combine the longitude\nand latitude information from the OpenStreetMap dataset by ap-\nplying the transformation ğ‘˜=180âˆ—âŒŠğ‘™ğ‘œğ‘›ğ‘”ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’âŒ‹+ğ‘™ğ‘ğ‘¡ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’ to each\npair of the longitude and latitude value. The YCSB workload [ 13]\ngenerates keys that represent user IDs uniformed distributed across\nthe whole 64-bit intrange. The Lognormal workload generates keys\nthat follow the log-normal distribution with ğœ‡=0andğœ=0.\nTested Methods. We evaluated our attack by comparing its mem-\nory consumption to the memory footprint of a normal sequence of\ninsertions. We used different workload sizes (50M keys, 100M keys,\nand 150M keys). We tested the following scenarios:\nâ€¢Baseline : We construct an ALEX instance by inserting legitimate\nkeys drawn from the original datasets until reaching a target\nworkload size and measured the memory usage of ALEX. Thememory usage of the baseline is not shown in Figure 2 as all bars\nare normalized with respect to the baseline.\nâ€¢White-box Attack : The white-box attack follows three steps:\n(1) initialize an ALEX with ğ‘™keys from legitimate keys of the\noriginal dataset; (2) run the MCK solver that takes the following\ninformation as input: one array that details how much budget\nwould be needed if one were to trigger ğ¸splits/expansions (where\nthe parameter ğ¸takes values 0,20,21, and 22; thus, theğ‘—from\nEq. (3.2.1) considers four scenarios) for each of the ğ‘›data nodes\ngiven the current state of the ALEX instance; the other array\ndetails the free memory increase from triggering ğ¸splits/expan-\nsions for each of the ğ‘›data nodes given the current state of the\nALEX instance; and an fixed budget ğµ; given the input, the MCK\nsolver generates the attack plan; (3) perform the sequence of\ninsertions based on the plan generated from the previous step.\nâ€¢Gray-box Attack : The gray-box attack follows five steps: (1) Use\na Kernel Density Estimation (KDE) model to approximate the\ndistribution of the original dataset. The KDE model takes as in-\nput the original dataset, a â€œbandwidthâ€ parameter, and a â€œkernelâ€\nparameter; (2) initialize an ALEX with ğ‘™keys from legitimate\nkeys of the original dataset; (3) construct a substitute ALEX in-\nstance by sampling ğ‘™keys from the learned KDE model; (4) run\nthe MCK solver using the data node information from the instan-\ntiated substitute ALEX and budget ğµ; (5) issue the sequence of\ninsertions based on the plan generated from the previous step.\nResults. Figure 2 presents normalized memory increases for gray-\nbox and white-box attacks with respect to the baseline. We observe\nthat, across all four datasets for the three workload sizes, both white-\nbox and gray-box attacks result in an increase in memory consump-\ntion. Notably, under the white-box setting, the four datasets have a\nmemory increase between 12.76%(for YCSB) and 15.32%(for YCSB)\nwith only 1%of budget size. The memory gap between white-box at-\ntacks and gray-box attacks is particularly striking for Longitude and\nLonglat , while this gap is relatively smaller for YCSB and Lognormal ;\nthere is even no difference for YCSB 150M. (shown in Figure 2(i)).\nThis is because Longitude and Longlat are not accurately approxi-\nmated by the given number of samples to the KDE, which affects\nthe performance of the attack. On the other hand, the other two\ndatasets are much more linear. E.g., YCSB dataset is highly linear,\nwhich results in ALEX using fewer data nodes to store keys.\nThere are no obvious differences for all three expansion parame-\nters (1, 2, and 4) for budget sizes below 30%under white-box attacks.\nThis is because, when the budget is relatively small, one expansion\nis sufficient to generate an optimal solution. Whereas at least two ex-\npansions are needed for 30%in order to maximize memory increases.\nwhite_box_2 and white_box_4 perform better than white_box_1 for\nmost of the cases. However, there are rare cases where white_box_4\nperforms worse than white_box_1 and white_box_2 as shown in Fig-\nure 2(d) and Figure 2(e). This is likely due to the computational time\nconstraint we configured for the MCK solver implemented using\nthe OR-Tools: we set a maximum search time of 100 seconds to\nstrike a balance between solution optimality and time efficiency. If\neither the optimal solution was found within the time limit, or the\nconfigured time period elapsed, whichever condition was met first,\nthe MCK solver returned the computed attack plan. We believe that\nthis uncommon event appeared due to the non-linearity nature of\n6\n\n1% 3% 5% 10% 20% 30%010203040Mem increase (%)(a)Longitude : 50M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (b)Longitude : 100M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (c)Longitude : 150M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%)whitebox_1\nwhitebox_2whitebox_4\ngraybox_1_0.5graybox_1_1\ngraybox_1_1.5\n(d)Longlat : 50M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (e)Longlat : 100M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (f)Longlat : 150M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%)\n(g)YCSB : 50M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (h)YCSB : 100M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (i)YCSB : 150M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%)\n(j)Lognormal : 50M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (k)Lognormal : 100M keys.\n1% 3% 5% 10% 20% 30%010203040Mem increase (%) (l)Lognormal : 150M keys\nFigure 2: Memory increases of space ACA on data nodes. This figure shows the normalized (with respect to the baseline) memory increase\nfor white-box and gray-box attacks using four datasets and varying ALEX sizes of 50 million, 100 million, and 150 million. The X-axis is the\npercentage of attackerâ€™s budget with respect to the total keys ranging from 1% to 30%; the Y-axis is the normalized memory increase from our\nattacks. whitebox_E denotes a white-box attack that allows at most ğ¸expansion(s) or split(s) for any data node for the MCK optimization; for\ngraybox_E_b ,ğ¸denotes a gray-box attack that allows at most ğ¸expansion(s) or split(s) for any data node during the MCK optimization, and ğ‘is\nthe â€œbandwidthâ€ parameter for KDE. Each data point is the mean of five runs. The error bars are depicted in red.\ntheLonglat dataset. This non-linearity resulted in the creation of\na large number of data nodes, which required a longer computa-\ntional time period to search for the optimal solution. The memory\nincreases under gray-box attacks largely depend on how close the\nstate of the substitute ALEX instance to the target ALEX instance\nis and the linearity of the original datasetâ€™s key distribution.\nIn summary, white-box attacks achieved 12.76%to33%memory\nconsumption increases, depending on the configuration of the ex-\npansion parameter and the attackerâ€™s budget. On the other hand,\ngray-box attacks are not as close to the damage made by white-box\nattacks because the substitute ALEX instance of a gray-box setting\nmay deviate from the true ALEX instance.\nPotential Mitigation. Instead of using extra â€œgapsâ€ at data-node\nlevel to absorb inserts, one can potentially use a delta buffer to serve\ninserts. The granularity of the delta buffer could be index-level (e.g.,\nPGM [ 22]) or node-level (e.g., FITing-Tree [ 24]) depending on spe-\ncific goals. These buffers typically are allocated as fixed size and\nmerged within them [ 22] or with existing data [ 24]. Once a merge\nprocess is triggered, the buffer will be emptied and reuse. Adding\ndelta buffers is an intrusive design choice that might break certainexisting properties of ALEX: while eliminating the gapped array\ndesign can potentially defend against our space ACA, one poten-\ntial side effect is the extra memory copy overhead when merging\nbuffered inserts into a node array, which will further affect the\nperformance of ALEX.\n3.2 Space ACA on Internal Nodes\nIn this subsection, we present our internal node ACA that exhausts\nthe memory consumption of the host. This attack exploits multiple\ndesign choices of ALEX, which combined lead to a cascading storage\nincrease. We show how the current design of ALEX is problematic\nwhen it comes to duplicate keys. We note that supporting duplicate\nkeys is a necessary functionality in index structures.\n3.2.1 Exploitable Design Choice. Recall that ALEX performs inser-\ntions by traversing the tree downwards until it identifies the data\nnode associated with the range to which the input key belongs.\nOur next attack uses several mechanisms of ALEXâ€™s insertion to\ncause infinite splits using only a single insertion. To achieve this\ndevastating overhead, the attacker has to insert multiple copies of\n7\n\nM01020M1M11131315â€¦200insert(13)Sideways splitsM05101520M1M16M111313â€¦201Sideways splitsM05102015M1M11M1313â€¦201M16Sideways splits â€¦This insert triggers recursive splits(a)(b)(c)M02.5520â€¦M1M11M162#sideways_splits + 1  \nM1313â€¦201â€¦â€¦(d)Figure 3: A Space ACA insertion of duplicate key 13 that causes recursive splits and ultimately results in an OOM error. (a) The\nright data node (in light red) has accumulated 200 duplicate keys 13, exceeding the cost threshold; (b) Inserting one more key 13 triggers a sideways\nsplit; (c-d) Attempting to lower the cost, ALEX recursively (cascadingly) sideways splits; the size of the internal nodeâ€™s pointer array keeps growing\nexponentially until reaching the maximum internal node size or ultimately causing an OOM; for the former case, ALEX performs a downwards\nsplit to create a new internal node at a lower level and then continues sideways splits; this cascading process continues until OOM.\nthe same key, i.e., duplicate keys . In the following, we unravel the\nseries of events that cause an unbounded number of splits.\nImpact of Inserting Duplicates on a Gapped Array. Suppose\nthat a data node already stores a key ğœ…. Letâ€™s first analyze the case\nwhereğœ…is inserted again. ALEX traverses the tree and lands on the\nsame data node where the original ğœ…resides. The linear model of\nthe data node points to the entry in the gapped array where the\nâ€œolderâ€ keyğœ…is stored. Since this position is occupied, ALEX shifts\nthe oldğœ…to create a gap for the new ğœ…. When the placement is\ndone, the two ğœ…entries appear consecutively in the gapped array.\nThe above description holds when the attacker inserts yet another\ncopy ofğœ…, in which case, ALEX shifts both of the older ğœ…entries\nto end up with three consecutive copies. The takeaway message is\nthat after a duplicate key insertion, the following conditions hold:\n(1) ALEX performs at least as many shifts in the gapped array as\nthe number of identical keys already reside in it, and (2) duplicate\nkeys are allocated consecutively.\nImpact of Duplicates on the Cost Model. As a next step, we\ndiscuss how conditions (1) and (2) from above affect the cost model\nof the corresponding data node. The first thing worth pointing\nout is that periodically, the cost model assesses its accuracy (by\ncalculating the cost), and if the model deviates from the current\nset of keys, the cost is deemed too high, and ALEX triggers the\nso-called catastrophic event . When this occurs, the data node is\nforced to perform a sideways split (as opposed to an expansion or\na downward split). A sideways split of the data node â€œredistributesâ€\nthe keys of the problematic data node to two new data nodes in\nthe hope that each new data node will have a much lower cost.\nUnfortunately, conditions (1) and (2) from the previous paragraph\nboth significantly affect the cost of their data node. The reason\nis that the number of shifts that have occurred so far is a crucial\nmetric of the cost model; therefore, condition (1) exacerbates the\ncost on that front. In the same vein, long consecutive segments of\nkeys in the gapped array, i.e., condition (2), increase the number of\nsteps in the exponential search, which is the other crucial metric\nof the cost model. Thus, the hope is that the sideways split will\nredistribute the keys and reduce the cost.\nWhat Happens During a Split? When ALEX needs to perform\na sideways split, it will split the data node by equally partitioning\nits key space into half. We emphasize here that the word split does\nnot refer to partitioning the set of keys of the data node in twoequal-sized subsets but rather partitioning the key space into two\nkey ranges of equal length. This subtle but crucial detail is one of\nthe main reasons the attack works so well. To be more precise, when\na data node ğ‘is split, ALEX generates two new data nodes, e.g., ğ‘ğ¿\nandğ‘ğ‘…, and each of them is responsible for half of ğ‘â€™s key space.\nAs a next step, ALEX relocates the keys of ğ‘that fall under the left\nkey space to ğ‘ğ¿and the keys that fall under the right key space to\nğ‘ğ‘…. We note here that this partition of keys can be unbalanced (in\nfact, our attack capitalizes on that possibility). As a final step, ALEX\nchecks the parent of ğ‘, denoted as ğ‘ƒğ‘, to identify how many entries\nofğ‘ƒğ‘â€™s pointer array are associated with ğ‘. If there is more than\none pointer to ğ‘(an instance of the so-called redundant pointers\nfrom Section 2.2) then half of them are redirected to point to ğ‘ğ¿and\nthe other half to ğ‘ğ‘…. The interesting (for our attack) case occurs\nwhenğ‘ƒğ‘has only a single pointer to ğ‘. In that case, ğ‘ƒğ‘isforced to\ndouble the size of its pointer array. Thus, each entry of ğ‘ƒğ‘â€™s pointer\narray now occupies two entries in the new pointer array, which\nmeans thatğ‘ƒğ‘can now assign one pointer to ğ‘ğ¿and one toğ‘ğ‘….\nWhy Splits Do Not Reduce Cost from Duplicates? The Achillesâ€™\nheel of this design is their strategy of halving the key space (and\nredistributing the allocated keys accordingly) as opposed to halving\nthe set of allocated keys directly. To illustrate this point, consider the\ncase where there are hundreds of duplicate copies of ğœ…. Then halving\nthe key space means that all the hundreds of entries will move to\none of the brand new data nodes (this is the unbalanced scenario\nwe mentioned before). When a new data node is created, ALEX\nsequentially re-inserts the corresponding keys one by one to this\nnew node. Unfortunately, this sequence of operations follows the\nmodel-based insertion which means that all hundreds of repeated\nğœ…entries will re-introduce conditions (1) &(2) in the brand new\ndata node. The last piece of the puzzle is the following observation:\nif the conditions (1) and (2) in the new data node are severe enough\nto increase the cost and result in yet another catastrophic event, the\nnewly introduced data node will have a high cost that will trigger\nanother split. If ALEX reaches the above state by a single insertion,\nthen the host will experience a recursive sequence of splits where\neach of them doubles its parentâ€™s pointer array. This cascading\neffect of an exponentially growing memory allocations will only\nstop when the host machine runs out of memory.\nAn illustration of the Attack. Suppose we have a data node\nresponsible for the key space [0,20). Letâ€™s assume, for the sake of\n8\n\nthe illustration, that the parent node has a pointer array of length\ntwo and that the key ğœ…=13has 200 copies that appear in the\nright data node (see Figure 3(a)). Then, when the attacker inserts\nkeyğœ…=13again, the cost that the cost model calculates increases\nso much that it triggers a catastrophic event and, consequently, a\nsideways split. As a result, the old light-red colored data node that\nwas responsible for key space [10,20)is split to the left (red colored\nagain) data node responsible for key space [10,15)and a right data\nnode responsible for [15,20). Given that the parent node only had\na single pointer to the old data node, the sideways split triggers a\ndoubling of the parentâ€™s pointer array (see Figure 3(b)). The crucial\npart is that all 201 entries of key 13moved to the new left data node\nin Figure 3(b); therefore, the cost of this new data is too high, which\ntriggers yet another split (see Figure 3(c)). This time the key space\nof the data node with the 201 entries of 13has key space[12.5,15),\nand due to the lack of available pointers on the parent node, another\ndoubling of the pointer array takes place. Figure 3(d) illustrates that\nthe pointer array (colored in dark red) grows exponentially, and all\nentries of 13move to a data node with a refined key space partition.\nOverall, the â€œbatchâ€ of copies of ğœ…=13move to data nodes with\nmore and more fine-grained key space:\n[10,20)â†’[ 10,15)â†’[ 12.5,15)â†’[ 12.5,13.75)â†’[ 12.5,13.125)â†’[ 12.8125,13.125)\nâ†’[ 12.96875,13.125)â†’[ 12.96875,13.046875)â†’[ 12.96875,13.0078125)â†’...\n3.2.2 Attack Method. For the internal node attack, we consider a\nblack-box setup where the attacker has no knowledge of the key\ndistribution of the targeted ALEX structure. To mount the attack,\nthe adversary generates a key that falls anywhere in the key range\nand inserts the duplicate key to ALEX. Typically, a few hundred\nduplicate insertions are sufficient o trigger OOM on the host ma-\nchine. Detecting this attack can be challenging since the attacker\ncan interleave duplicate insertions with legitimate workload traffic,\nleading to an eventual OOM crash of the ALEX database server.\n3.2.3 Comparison with Concurrent Work. In the following, we high-\nlight the differences between our proposed attack and that from\na recently released concurrent manuscript by Schuster et al. [ 51]\n(referred to as SZEGP ). The effectiveness of our approach, compared\ntoSZEGP , is validated through our experiments in Â§3.2.4, where our\nattack achieves comparable damage with up to 300,000Ã—fewer keys.\nSZEGP is parameterized by ğ‘,ğ¾ and works as follows: (1) being a\nblack-box attack, SZEGP randomly samples ğ‘keys from the original\ndataset to roughly estimate the global key distribution; (2) SZEGP\npicks a random position in the key range and inserts ğ¾consecutive\nkeys left to the position. If the keys are floating point, then SZEGP\ngenerates keys in 10âˆ’13increments, if the keys are integers then it\ngenerates keys in 1increments. (3) SZEGP repeats Step#2 until the\nbudget is exhausted or an OOM error is triggered.\nComparison with SZEGP .While our internal-node space ACA and\nSZEGP share the common goal of doubling the size of parent nodesâ€™\npointer array, our attack uses fundamentally different insights to\ndeliver a much more effective attack, as outlined below:\nâ€¢Identifying a Data Node : Our attack can be applied to any\ndata node, whereas SZEGP is only effective when applied to the\nleft-most data node of a sub-tree. Thus, SZEGP needs to guess a\nkey-area for the cluster and blindly (due to the black-box setting)Table 2: Effectiveness of the space ACA on internal node. In\ntheOOMrows,âœ“denotes a triggered OOM. Otherwise, the values show\nthe memory consumption after the specified budget is used.\nOur attack Schuster et al. (SZEGP )\nHost memory (GB) 64 128 256 384 64 128 256 384\nLongitudeOOM âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ 244GB 244GB\nBudget 423 479 472 441 63M 116M 200M 200M\nLonglatOOM âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“\nBudget 428 441 437 437 2069 2069 2069 2069\nYCSBOOM âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“ âœ“\nBudget 662 653 692 679 1024 1024 1024 1024\nLognormalOOM âœ“ âœ“ âœ“ âœ“ 5GB 5GB 5GB 5GB\nBudget 526 589 564 551 200M 200M 200M 200M\nhit a range of the key distribution with a very specific ALEX sub-\nstructure. More often than not, SZEGP does not meet the above\nstringent requirement and as a result â€œwastesâ€ valuable budget.\nâ€¢Effect on Landed Data Node : Our attack guarantees that all\ninserted keys will end up in the same data node (due to the fact\nthat all keys are identical), which translates to doubling the same\npointer array, and thus, delivering a faster OOM. Whereas the\nconsecutive keys inserted by SZEGP may only partially land to\nthe left-most data node while the rest spill to a nearby data node.\nâ€¢ALEXâ€™s Handling of Insertions : Our attack guarantees that\nallinserted keys will be moved to a single new data node after\nthe split, whereas SZEGP (consecutive) inserted keys may be re-\ndistributed to both new data nodes from the split. Consequently,\nforSZEGP , ALEX may indeed reduce the cost by a sideways split.\nâ€¢Requirement on Adversarial Budget : Our attack operates\nusing a small adversarial budget; typically, a few hundred is\nsufficient to trigger an OOM event. Conversely, SZEGP relies on\nadversarial insertions falling into the leftmost data node within\na sub tree; to accomplish such an allocation their attacker needs\nto use a significantly larger budget.\n3.2.4 Evaluation. We evaluate the internal node attacks on AWS\nEC2 m5virtual machine (VM) instances with the RAM configuration\nranging from 64GB to 384GB. We use the four datasets from the\nprevious subsection: longitudes ,longlat ,YCSB, and lognormal .\nTo compare, we initialized an ALEX instance with 10 million legit-\nimate keys from the dataset using bulk_load() , and then mounted\nthe attack. For SZEGP , we used the same parameter configurations\nas the ones used in [ 51], whereğ‘=1,000andğ¾=10,000. We\nrecorded the number of adversarial insertions used and the total\namount of memory consumed by ALEX under both types of attacks.\nThe results presented in Table 2 comprehensively compare our\nmethod and SZEGP . Our attack method consistently induced an OOM\nevent on all VM configurations tested across all four datasets, with\nonly 423-692 adversarial insertions. On the other hand, SZEGP trig-\ngered OOM in only two out of the four datasets, i.e., Longlat and\nYCSB, by using 3.83Ã—and 0.55Ã—more budget than our method to\nexhaust 64GB of host memory. The difference in the effectiveness\nbetween the two attack methods is striking in datasets Lognormal\nand Longitudes , where SZEGP requires more than 105Ã—budget and\nin most cases, it doesnâ€™t trigger an OOM. In Figure 4, we take a\nmore detailed view of the comparison between the two methods on\nLongtitudes . Figure 4 shows the memory consumption as a function\nof the number of adversarial insertions and runtime on a 256GB\nEC2 VM. The proposed attack brings the data node to a state where\n9\n\n10M50M 100M 150M 200M\n# adversarial insertions1GB10GB100GB256GBMem consumptionOOM\nPlateaued at 244GB\nOur attack\nSZEGP(a) Memory consumption vs. insertions.\n0 200 400\nTime (second)1GB10GB100GB256GBMem consumptionCascading \n splitsCascading \n splits\nKeeps inserting \n attack keysKeeps inserting \n attack keys\nOur attack\nSZEGP (b) Memory consumption vs. runtime.\nFigure 4: Memory usage as a function of the number of ad-\nversarial insertions for the longitudes dataset.\na single insertion will exhaust all available memory regardless of\nwhether the host memory is 1GB or 1TB. Figure 4(a) illustrates this\npoint: no matter how much the defender increases the hostâ€™s mem-\nory, once the trigger insertion takes place all memory is consumed.\nOur space ACA attack only required 472 insertions of duplicate\nkeys to trigger cascading splits at a memory consumption rate of\n0.84GB/sec until all the 256GB RAM is exhausted (Figure 4(b)).\nSZEGP required contiguous and cumulative adversarial insertions,\nultimately reaching a memory usage plateau of around 244GB with\n3Â·105Ã—more budget. For the Lognormal dataset, SZEGP used up all\nthe 200 million budget keys but only caused about 5GB memory\nincrease. These results demonstrate the effectiveness of our method.\nPotential Mitigation. One may argue that this attack can be miti-\ngated by using a capacity-based partitioning mechanism that pro-\nduces equally sized data nodes. This defense mechanism could\npotentially reduce the cost of a data node, as the duplicate keys will\neventually be spread across multiple data nodes. However, incorpo-\nrating capacity-based partitioning will break ALEXâ€™s sophisticated\ndesign for the following reasons: (1) the ultimate goal of key space\npartitioning is to make sure that each data node covers a sub-key\nspace whose key distribution is roughly linear; and (2) key space\npartitioning enables ALEX to use simple linear models for internal\nnodes. Capacity-based partitioning would have required internal\nnodes to use expressive, non-linear models as it is highly likely\nthat the key distribution within a child data node is non-linear. An-\nother possible defense is by disabling the option for duplicate keys.\nHowever, this will inevitably hurt the versatility and flexibility of\nALEX as a core database index structure. In the next section we\ndiscover the feasibility of mitigating our attack by changing how\nALEX handles catastrophic events.\n3.3 Time ACA\nIn this subsection, we introduce a new category of ACA that aims to\ndeteriorate ALEXâ€™s time performance. In Â§3.2, we introduced a space\nACA that exploits the fact that catastrophic events trigger sideways\nsplits. A potential mitigation of our space ACA is the following:\nin case of a catastrophic event, perform an expansion operation\ninstead of a sideways split. As we show in the following, when\nexpansions happen in the context of a catastrophic event, ALEX\nneeds to retrain the linear regression model of the corresponding\ndata node. However, retraining is a time-consuming operation (a\nfact that we capitalize on in our time ACA). In this subsection, weanalyze a hypothetical scenario where ALEX is patched to miti-\ngate our space ACA vulnerability and now performs an expansion\ninstead of a sideways split in case of a catastrophic event1.\n3.3.1 Exploitable Design Choice. Recall that a catastrophic event\nhappens when ALEX detects that the cost of a data node is too\nhigh. A reason that contributes to the high cost is that the linear re-\ngression model prediction is no longer accurate to support efficient\nlookups and insertions. While applying an expansion instead of a\nsplit thwarts our attack from Â§3.2, it will cause inaccurate models\nthat result in significant runtime performance cost due to increased\ntraining cost. An attacker can exploit this observation of the modi-\nfied ALEX by strategically inserting sequences of densely clustered\nkeys to carefully chosen data nodes to cause a discrepancy between\nthe key distributions and the linear models of the data nodes.\n3.3.2 Attack Method. The goal of an attacker is to leverage the\nabove-described observation to deteriorate the performance of\nALEX by increasing its time performance [ 14,18,58]. This will re-\nsult in: (1) query latency increase when serving highly-concurrent\nrequests, and (2) ultimately, a DoS when the request processing\ncapability offered by the database tier is not able to catch up with\nthe speed of query backlog accumulation. Data node expansion\nimplies that the current model of the data node is no longer accu-\nrate, thus a model retraining is required. However, retraining will\nnot fix the inaccuracy issue, simply because the key distribution\nof the data node is no longer linear . Such inaccuracy will cause\nmore exponential searches for lookups and more memory shifts\nfor insertions. More importantly, expanding a data node in ALEX\nis a time-consuming process due to the overhead of linear model\nretraining and memory copy. Therefore, an effective adversarial\nstrategy for degrading ALEXâ€™s performance is to continuously trig-\nger â€œcatastrophicâ€ expansions (see Â§2.2) in large data nodes. To this\nend, we investigate time ACA strategies in three different settings:\nwhite-box, gray-box, and black-box.\nThe white-box setting assumes that the attacker has complete\nknowledge of the target ALEX, including keys and the global key\ndistribution. In this case, the attacker targets the largest data node.\nSpecifically, the attacker inserts a total number of ğ‘attacking keys\ninto the middle position of the largest segment within the largest\ndata node. The attacker spreads the budget of ğ‘keys across batches\nwith a size of ğµ, whereğµis set to 200 and 600 in our tests and all\nkeys within a single batch are consecutive keys with an incremental\ndifference of 10âˆ’13fordouble -typed keys and 1forint-typed keys.\nIn the gray-box setting, the attacker knows the approximate\ndistribution of the keys but does not know the exact keys. With\nthe distribution, the attacker utilizes a kernel density estimation\n(KDE) [ 3] method to construct a substitute ALEX structure that\napproximates the structure of the target (original) ALEX. The sub-\nstitute ALEX is designed to have the same size as the target ALEX\nand contains different keys, which fall within the same key range\nand follow the same key distribution. Subsequently, the attacker\ndevises an attack plan by generating attacking keys targeting the\nlargest data node in the substitute ALEX, same as the strategy used\nin the white-box attack. The attacker then inserts the ğ‘budget\nkeys to the target ALEX in ğ‘/ğµbatches during the workload.\n1We also tested the vulnerability of vanilla ALEX to our time ACA in Â§3.3.3.\n10\n\n2.5 5.0 7.5 10.0\nPercentage (% total requests)0.02.55.0Throughput (M ops/s)\nWrite-heavy\n0.5 1.0 1.5 2.0\nPercentage (% total requests)010Throughput (M ops/s)\nRead-heavy\n5 10 15 20Percentage (% total inserts)\n5 10 15 20Percentage (% total inserts)\n(a)YCSB .\n2.5 5.0 7.5 10.0\nPercentage (% total requests)0.02.55.0Throughput (M ops/s)\nWrite-heavy\n0.5 1.0 1.5 2.0\nPercentage (% total requests)0510Throughput (M ops/s)\nRead-heavy\n5 10 15 20Percentage (% total inserts)\n5 10 15 20Percentage (% total inserts)\n (b)Lognormal .\n2.5 5.0 7.5 10.0\nPercentage (% total requests)024Throughput (M ops/s)\nWrite-heavy\n0.5 1.0 1.5 2.0\nPercentage (% total requests)0510Throughput (M ops/s)\nRead-heavy\n5 10 15 20Percentage (% total inserts)\n5 10 15 20Percentage (% total inserts)\n (c)Longitude .\n2.5 5.0 7.5 10.0\nPercentage (% total requests)02Throughput (M ops/s)\nWrite-heavy\n0.5 1.0 1.5 2.0\nPercentage (% total requests)0246Throughput (M ops/s)\nRead-heavy\n5 10 15 20Percentage (% total inserts)\n5 10 15 20Percentage (% total inserts)\nVanilla-ALEX\nWhite-box200\nWhite-box600\nGray-box200\nGray-box600\nBlack-box200\nBlack-box600\nVanilla-white-box200\nVanilla-white-box600\nVanilla-gray-box200\nVanilla-gray-box600\nVanilla-black-box200\nVanilla-black-box600 (d)Longlat .\nFigure 5: The throughput for different attack settings and percentages of adversarial insertions for vanilla ALEX and modified\nALEX. We varied the percentage of adversarial insertions with respect to (w.r.t.) the total number of inserts from 5%to20%. The topğ‘‹-axis\nshows the ratios of adversarial insertions to the total number of insertion requests in the workload. The bottom ğ‘‹-axis shows the normalized\nratios of adversarial insertions to the total number of requests in the workloads: e.g., a ratio of 2.5%for a write-heavy workload w.r.t. the bottom\nğ‘‹-axis means, out of the 10ğ‘€requests, 2.5%of them are adversarial insertions generated by the attacker; by referring to the top ğ‘‹-axis, 2.5%of\ntotal requests means 5%of total inserts as our write-heavy workload has a 50% : 50% read:write ratio. Vanilla-ALEX is our baseline performance\nwithout any adversarial manipulation. To measure the performance of our attacks, we applied them to both vanilla/original ALEX and modified\nALEX. Vanilla-white-box200 denotes a white-box attack applied to the vanilla ALEX. White-box200 means a white-box attack mounted against\nthe modified ALEX. The values after the attack setting denote the batch sizes; e.g., White-box200 means the white-box attack with a batch size of\n200. Each data point is the average of five runs with error bars showing the min-max variance.\nLastly, the black-box setting assumes that the attacker does not\nknow about the key distribution but can probe the existing key\nrange of ALEX via sampling. The attacker then randomly choose\nğ‘/ğµlocations from within the estimated key range and insert the\nğ‘/ğµbatches of attacking keys to mount the time ACA.\n3.3.3 Evaluation. We evaluated the time ACAs on an EC2 m5VM\ninstance with 96 vCPUs and 384GB memory. We used the average\nthroughput as the performance metric. We mounted our time ACA\nagainst both the vanilla ALEX (the original ALEX) and our modi-\nfied ALEX (patched to mitigate the space ACA vulnerabilities as\ndiscussed at the beginning of Â§3.3). We conducted the experiments\nusing a write-heavy and a read-heavy workload drawn from the\nfour datasets. The write-heavy workload consists of 50%inserts and\n50%lookups, while the read-heavy workload has an insert:lookup\nratio of 10% : 90% . Both workloads have a total of 10 million opera-\ntions. The lookup keys were selected from all existing keys in one of\nthe four datasets, following a Zipfian distribution. Given a dataset,\nwe first initialized an ALEX by using the first 10 million keys via\nbulk_load() and then initiated the 10-million-request workload. We\nissued a total of 10 batches for all attack settings.\nFigure 5 shows the throughput comparisons between a modified\nALEX (with expansion-only mode as described in Â§3.3) and the\nvanilla ALEX in different attack settings with baseline. For write-\nheavy workloads, the white-box attacks and gray-box attacks inmodified ALEX achieved an average throughput degradation be-\ntween 31Ã—and 1,641Ã—across all batch size and budget parameters,\ncompared to the baseline ALEX.\nThis is because all attack keys were inserted into the largest\ndata node, causing the biggest damage to performance. Black-box\nattacks, on the other hand, saw relatively fluctuating performance\ntrends for longitude ,longlat , and lognormal (Figure 5(c)â€“5(b)), due\nto the fact that the ALEX trees constructed under these three\ndatasets had many data nodes. As a result, a single batch of ad-\nversarial insertions may end up falling into more than one data\nnode, with reduced likelihood of triggering a â€œcatastrophicâ€ expan-\nsion. Interestingly, the performance degradation on YCSB increases\nas both the batch size as well as the attack budget increase, as shown\nin Figure 5(a), because there were much fewer data nodes used in\nALEX to store the linearly distributed keys in the YCSB dataset,\nwhich increased the chances of a â€œcatastrophicâ€ expansion being\ntriggered and minimized the attack budget wastage. As a result, the\nthroughput of Black-box600 decreases sharply as the budget ratio\nincreases; with only 2%of requests being adversarial insertions, our\nblack-box-based time ACA caused a performance degradation of up\nto11Ã—compared to the baseline case for the read-heavy workload\n(see the bottom sub-figure of Figure 5(a)), almost approaching the\nsame level of degradation caused by a white-box attack. For attacks\nagainst vanilla ALEX, our time ACA achieved 2.1Ã—to8.8Ã—per-\nformance degradation on write-heavy workload and up to 11.99Ã—\non read-heavy workload for longitude compare to baseline ALEX\n(note that we were not able to collect the throughput results as our\n11\n\ntime ACA triggered an OOM event on YCSB and lognormal against\nthe vanilla ALEX). Figure 6 provides additional insight into the\nthroughput performance drops under different attack assumptions.\nBoth gray-box and white-box approaches incur significant higher\nnumber of retrains when compared to ALEX with legitimate work-\nload and the black-box setting. This indicates that the decrease in\nthroughput can be primarily attributed to the number of retrains.\nALEX Black-box Gray-box White-box\nAttack assumption0K2K4K6K# retrains\n(a) Read-heavy Workload.\nALEX Black-box Gray-box White-box\nAttack assumption0K10K20K30K# retrains (b) Write-heavy Workload.\nFigure 6: Number of retrains under various attack assump-\ntions for Longitudes . Adversarial insertions are 20%of the total\nnumber of insertions. Each bar in the plot represents the average\nof five runs with red-colored error bars showing the variance.\nPotential Mitigation. One possible defense is to apply more robust\nML models (e.g., polynomial regression) to represent the empirical\nCDF of keys at data-node level. An important caveat of this mitiga-\ntion strategy is that applying more expressive ML models deviates\nfrom the original motivation of using piece-wise linear regression\nmodels to approximate empirical data distribution CDF, and the\ntime overhead of model training and inference might outweigh the\nrobustness these complicated models introduce.\n4 RELATED WORK\nOther Learned Index Structures. LIS use ML models to replace\ntraditional index structures based on the observation that index\nstructures can be viewed as a CDF [ 35]. FITING-Tree [ 24] employs\npiece-wise linear functions with a predetermined error bound dur-\ning construction. In terms of dynamism of LIS, a method of min-\nimizing error caused by updating index was proposed by Hadian\nand Heinis in [ 26]. The work by Tang et al. [ 57] studies the dis-\ntribution of the workload and propose to re-train the model as\nthe queries pattern change. Other works propose learned multi-\ndimensional index structure [ 20,44]. PGM [ 22] proposes models\nthat utilize an auto-tuned RMI design to optimize space and latency\nwhile supporting updates by using an index-level shared write\nbuffer (a strategy similar to the LSM-tree structure [ 45]). Based on\nPGM, RadixSpline [ 31] proposes an RMI that features an alternate\nlinear interpolation based indexing. Lately, a line of works aim\nto improve dynamic learned index structure in robustness, con-\ncurrency, persistence, and the capability to operate under limited\nDRAM resources [ 37â€“39,61,62,66]. Inspired by LIS, SageDB [34]\nis a database system that adapts to an application through code\nsynthesis and learning techniques. A set of works benchmark the\nperformance of learned index structures [ 30,43,56,60]. Our work\nfills a missing gap in the literature by investigating ACAs against\nemerging dynamic learned index structure [19, 38].\nAlgorithmic Complexity Attacks. ACAs were initially intro-\nduced [ 14] to exploit worst-case algorithmic design choices in com-\nmon data structures such as hash tables. Several other studies ex-\nplored ACAs across diverse applications, such as hash tables [ 6,7],regular expression matching [ 17,52,63], automata-based multi-\nstring pattern matching [ 53], PDF (portable document file) decom-\npression [ 27], and TCP reassembly [ 18,58]. [36,49] propose solu-\ntions that automatically detect inputs that cause algorithmic com-\nplexity vulnerabilities. On the defense side, SurgeProtector [5]\nproposes a general framework to make network functions resilient\nagainst ACAs. None of these works explore vulnerabilities of dy-\nnamic learned indexes, which we do in this work.\nData Poisoning Attacks. The literature on data poisoning at-\ntacks [ 8,21,64,65] focuses on adversaries who intentionally aug-\nment the training data to manipulate the outcomes of predictive\nmodels. For instance, Biggio et al. [ 8] introduced maliciously crafted\ntraining data to alter the decision function of support vector ma-\nchines (SVMs) and increase the test error. Yang et al. [ 65] proposed\ngradient-based methods to generate poisoning points for neural net-\nworks. Suciu et al. [ 55] presented a framework to evaluate realistic\nadversaries conducting poisoning attacks on machine learning algo-\nrithms. The study by Jagielski et al. [ 29] proposes an optimization\nframework for poisoning attacks on linear regression and intro-\nduced a defense mechanism named Trim. The ACAs we propose in\nthis work are different from data poisoning attacks. The objective\nof poisoning attacks is to maximize the mathematical function that\ncaptures the error of the ML model, whereas our ACAs maximize\nthe use of critical resources based on how the system is designed\n(which cannot always be captured by a simple error function).\nComparison with KRT. The poisoning attacks presented in [ 33]\nfocus on static learned index structures. This means that all inserted\nkeys in [ 33] are chosen during the initialization. On the contrary,\nin this work our attacks are performed on a dynamic LIS and the\nkeys are chosen based on the current state of the LIS. Another dif-\nference is that at the core of the attacks [ 33] is the observation that\ninjections of keys in cumulative distribution functions cause a cas-\ncading error effect. The above error cannot be dealt with at runtime\ndue to the static nature of the LIS. On the contrary, the attacks in\nthis work are centered around the runtime expansion mechanisms\nwhen dealing with full-occupancy of a node or increased errors.\nThese mechanisms only appear in the dynamic setting.\n5 CONCLUSION\nWe present a comprehensive study that focuses on the security as-\npects of an emerging dynamic learned index structure. We propose\nnew ACAs that exploit design choices that balance the trade-off in\nALEXâ€™s memory usage and runtime efficiency. Our attacks aim to\noverload the memory and CPU resources. We evaluate the effective-\nness of these ACAs through extensive experiments. Our findings\nhave demonstrated that our space ACAs cause out-of-memory with\nonly a few hundred adversarial insertions and our time ACAs lead\nto a significant degradation in throughput by up to three orders of\nmagnitude, compared to ALEX. Our findings can be used to inform\nthe future generations of robust learned-index-based systems that\nare not prone to adversarial manipulations.\nACKNOWLEDGMENTS\nWe are grateful to the anonymous reviewers for their valuable\nfeedback and comments. This work was sponsored in part by NSF\ngrants: CCF-2318628, CCF-1919113, OAC-2106446, CNS-2154732,\nand the Meta Security Research Award.\n12\n\nREFERENCES\n[1]2010. Amazon Mechanical Turkon . Retrieved Decmber 10, 2023 from https:\n//www.mturk.com/\n[2]2017. OpenStreetMap Public Data Set Now Available on AWS . Retrieved\nDecmber 10, 2023 from https://aws.amazon.com/about-aws/whats-new/2017/\n06/openstreetmap-public-data-set-now-available-on-aws/\n[3] 2023. KernelDensity . Retrieved Decmber 10, 2023 from https://scikit-learn.org/\nstable/modules/generated/sklearn.neighbors.KernelDensity.html\n[4]Hussam Abu-Libdeh, Deniz AltÄ±nbÃ¼ken, Alex Beutel, Ed H. Chi, Lyric Pankaj\nDoshi, Tim Klas Kraska, Xiaozhou (Steve) Li, Andy Ly, and Chris Olston (Eds.).\n2020. Learned Indexes for a Google-scale Disk-based Database . https://arxiv.org/\npdf/2012.12501.pdf\n[5] Nirav Atre, Hugo Sadok, Erica Chiang, Weina Wang, and Justine Sherry. 2022.\nSurgeProtector: Mitigating Temporal Algorithmic Complexity Attacks Using\nAdversarial Scheduling. In Proceedings of the ACM SIGCOMM 2022 Conference\n(Amsterdam, Netherlands) (SIGCOMM â€™22) . Association for Computing Machin-\nery, New York, NY, USA, 723â€“738. https://doi.org/10.1145/3544216.3544250\n[6] Noa Bar-Yosef and Avishai Wool. 2007. Remote Algorithmic Complexity Attacks\nagainst Randomized Hash Tables. In E-business and Telecommunications - 4th\nInternational Conference, ICETE 2007, Barcelona, Spain, July 28-31, 2007, Revised\nSelected Papers (Communications in Computer and Information Science) , Joaquim\nFilipe and Mohammad S. Obaidat (Eds.), Vol. 23. Springer, 162â€“174. https:\n//doi.org/10.1007/978-3-540-88653-2_12\n[7]Udi Ben-Porat, Anat Bremler-Barr, and Hanoch Levy. 2013. Vulnerability of\nNetwork Mechanisms to Sophisticated DDoS Attacks. IEEE Trans. Comput. 62, 5\n(2013), 1031â€“1043. https://doi.org/10.1109/TC.2012.49\n[8] Battista Biggio, Ignazio Pillai, Samuel Rota BulÃ², Davide Ariu, Marcello Pelillo,\nand Fabio Roli. 2013. Is Data Clustering in Adversarial Settings Secure?. In\nProceedings of the 2013 ACM Workshop on Artificial Intelligence and Security\n(Berlin, Germany) (AISec â€™13) . Association for Computing Machinery, New York,\nNY, USA, 87â€“98. https://doi.org/10.1145/2517312.2517321\n[9] Matthew Butrovich, Wan Shen Lim, Lin Ma, John Rollinson, William Zhang, Yu\nXia, and Andrew Pavlo. 2022. Tastes Great! Less Filling! High Performance and\nAccurate Training Data Collection for Self-Driving Database Management Sys-\ntems. In Proceedings of the 2022 International Conference on Management of Data\n(Philadelphia, PA, USA) (SIGMOD â€™22) . Association for Computing Machinery,\nNew York, NY, USA, 617â€“630. https://doi.org/10.1145/3514221.3517845\n[10] Xiang Cai, Yuwei Gui, and Rob Johnson. 2009. Exploiting Unix File-System Races\nvia Algorithmic Complexity Attacks. In 2009 30th IEEE Symposium on Security\nand Privacy . 27â€“41. https://doi.org/10.1109/SP.2009.10\n[11] Zhichao Cao, Siying Dong, Sagar Vemuri, and David H.C. Du. 2020. Characteriz-\ning, Modeling, and Benchmarking RocksDB Key-Value Workloads at Facebook.\nIn18th USENIX Conference on File and Storage Technologies (FAST 20) . USENIX\nAssociation, Santa Clara, CA, 209â€“223. https://www.usenix.org/conference/\nfast20/presentation/cao-zhichao\n[12] Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C. Hsieh, Deborah A. Wal-\nlach, Mike Burrows, Tushar Chandra, Andrew Fikes, and Robert E. Gruber. 2006.\nBigtable: A Distributed Storage System for Structured Data. In 7th USENIX Sym-\nposium on Operating Systems Design and Implementation (OSDI 06) . USENIX\nAssociation, Seattle, WA. https://www.usenix.org/conference/osdi-06/bigtable-\ndistributed-storage-system-structured-data\n[13] Brian F. Cooper, Adam Silberstein, Erwin Tam, Raghu Ramakrishnan, and Russell\nSears. 2010. Benchmarking Cloud Serving Systems with YCSB. In Proceedings\nof the 1st ACM Symposium on Cloud Computing (Indianapolis, Indiana, USA)\n(SoCC â€™10) . Association for Computing Machinery, New York, NY, USA, 143â€“154.\nhttps://doi.org/10.1145/1807128.1807152\n[14] Scott A. Crosby and Dan S. Wallach. 2003. Denial of Service via\nAlgorithmic Complexity Attacks. In 12th USENIX Security Sympo-\nsium (USENIX Security 03) . USENIX Association, Washington, D.C.\nhttps://www.usenix.org/conference/12th-usenix-security-symposium/denial-\nservice-algorithmic-complexity-attacks\n[15] Levente Csikor, Dinil Mon Divakaran, Min Suk Kang, Attila KÅ‘rÃ¶si, BalÃ¡zs\nSonkoly, DÃ¡vid Haja, Dimitrios P. Pezaros, Stefan Schmid, and GÃ¡bor RÃ©tvÃ¡ri.\n2019. Tuple Space Explosion: A Denial-of-Service Attack against a Software\nPacket Classifier. In Proceedings of the 15th International Conference on Emerg-\ning Networking Experiments And Technologies (Orlando, Florida) (CoNEXT â€™19) .\nAssociation for Computing Machinery, New York, NY, USA, 292â€“304. https:\n//doi.org/10.1145/3359989.3365431\n[16] Levente Csikor, Vipul Ujawane, and Dinil Mon Divakaran. 2020. On the Feasibility\nand Enhancement of the Tuple Space Explosion Attack against Open vSwitch.\nhttps://arxiv.org/abs/2011.09107.\n[17] James C. Davis, Christy A. Coghlan, Francisco Servant, and Dongyoon Lee. 2018.\nThe Impact of Regular Expression Denial of Service (ReDoS) in Practice: An\nEmpirical Study at the Ecosystem Scale. In Proceedings of the 2018 26th ACM\nJoint Meeting on European Software Engineering Conference and Symposium on\nthe Foundations of Software Engineering (Lake Buena Vista, FL, USA) (ESEC/FSE\n2018) . Association for Computing Machinery, New York, NY, USA, 246â€“256.\nhttps://doi.org/10.1145/3236024.3236027[18] Sarang Dharmapurikar and Vern Paxson. 2005. Robust TCP Stream\nReassembly in the Presence of Adversaries. In 14th USENIX Security\nSymposium (USENIX Security 05) . USENIX Association, Baltimore, MD.\nhttps://www.usenix.org/conference/14th-usenix-security-symposium/robust-\ntcp-stream-reassembly-presence-adversaries\n[19] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li, Han-\ntian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann, David\nLomet, and Tim Kraska. 2020. ALEX: An Updatable Adaptive Learned Index. In\nProceedings of the 2020 ACM SIGMOD International Conference on Management of\nData (Portland, OR, USA) (SIGMOD â€™20) . Association for Computing Machinery,\nNew York, NY, USA, 969â€“984. https://doi.org/10.1145/3318464.3389711\n[20] Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. 2020.\nTsunami: A Learned Multi-Dimensional Index for Correlated Data and Skewed\nWorkloads. Proc. VLDB Endow. 14, 2 (oct 2020), 74â€“86. https://doi.org/10.14778/\n3425879.3425880\n[21] Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong. 2020. Local Model\nPoisoning Attacks to Byzantine-Robust Federated Learning. In 29th USENIX\nSecurity Symposium (USENIX Security 20) . USENIX Association, 1605â€“1622. https:\n//www.usenix.org/conference/usenixsecurity20/presentation/fang\n[22] Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-Index: A Fully-\nDynamic Compressed Learned Index with Provable Worst-Case Bounds. Proc.\nVLDB Endow. 13, 8 (apr 2020), 1162â€“1175. https://doi.org/10.14778/3389133.\n3389135\n[23] Michael J. Franklin, Donald Kossmann, Tim Kraska, Sukriti Ramesh, and Reynold\nXin. 2011. CrowdDB: Answering Queries with Crowdsourcing. In Proceedings of\nthe 2011 ACM SIGMOD International Conference on Management of Data (Athens,\nGreece) (SIGMOD â€™11) . Association for Computing Machinery, New York, NY,\nUSA, 61â€“72. https://doi.org/10.1145/1989323.1989331\n[24] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim\nKraska. 2019. FITing-Tree: A Data-Aware Index Structure. In Proceedings of\nthe 2019 International Conference on Management of Data (Amsterdam, Nether-\nlands) (SIGMOD â€™19) . Association for Computing Machinery, New York, NY, USA,\n1189â€“1206. https://doi.org/10.1145/3299869.3319860\n[25] Gaston H. Gonnet. 1981. Expected Length of the Longest Probe Sequence in\nHash Code Searching. J. ACM 28, 2 (apr 1981), 289â€“304. https://doi.org/10.1145/\n322248.322254\n[26] Ali Hadian and Thomas Heinis. 2019. Considerations for Handling Updates in\nLearned Index Structures. In Proceedings of the Second International Workshop on\nExploiting Artificial Intelligence Techniques for Data Management (Amsterdam,\nNetherlands) (aiDM â€™19) . Association for Computing Machinery, New York, NY,\nUSA, Article 3, 4 pages. https://doi.org/10.1145/3329859.3329874\n[27] Nathan Hauke and David Renardy. 2019. Denial of Service with a Fistful of\nPackets: Exploiting Algorithmic Complexity Vulnerabilities. Retrieved Decem-\nber 10, 2023 from https://www.blackhat.com/us-19/briefings/schedule/#denial-\nof-service-with-a-fistful-of-packets-exploiting-algorithmic-complexity-\nvulnerabilities-16445\n[28] Adam Jacobson and David Renardy. 2019. Algorithmic Complexity Vulnerabilities:\nAn Introduction . Retrieved Decmber 10, 2023 from https://twosixtech.com/\nalgorithmic-complexity-vulnerabilities-an-introduction/\n[29] Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru,\nand Bo Li. 2021. Manipulating Machine Learning: Poisoning Attacks and Coun-\ntermeasures for Regression Learning. arXiv:1804.00308 [cs.CR]\n[30] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2019. SOSD: A Benchmark for Learned\nIndexes. https://arxiv.org/abs/1911.13014.\n[31] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: A Single-Pass Learned\nIndex. In Proceedings of the Third International Workshop on Exploiting Artificial\nIntelligence Techniques for Data Management (Portland, Oregon) (aiDM â€™20) .\nAssociation for Computing Machinery, New York, NY, USA, Article 5, 5 pages.\nhttps://doi.org/10.1145/3401071.3401659\n[32] Aniket Kittur, Boris Smus, Susheel Khamkar, and Robert E. Kraut. 2011. Crowd-\nForge: Crowdsourcing Complex Work. In Proceedings of the 24th Annual ACM\nSymposium on User Interface Software and Technology (Santa Barbara, California,\nUSA) (UIST â€™11) . Association for Computing Machinery, New York, NY, USA,\n43â€“52. https://doi.org/10.1145/2047196.2047202\n[33] Evgenios M. Kornaropoulos, Silei Ren, and Roberto Tamassia. 2022. The Price\nof Tailoring the Index to Your Data: Poisoning Attacks on Learned Index Struc-\ntures. In Proceedings of the 2022 International Conference on Management of Data\n(Philadelphia, PA, USA) (SIGMOD â€™22) . Association for Computing Machinery,\nNew York, NY, USA, 1331â€“1344. https://doi.org/10.1145/3514221.3517867\n[34] Tim Kraska, Mohammad Alizadeh, Alex Beutel, Ed H. Chi, Ani Kristo, Guillaume\nLeclerc, Samuel Madden, Hongzi Mao, and Vikram Nathan. 2019. SageDB: A\nLearned Database System. In 9th Biennial Conference on Innovative Data Systems\nResearch, CIDR 2019, Asilomar, CA, USA, January 13-16, 2019, Online Proceedings .\nwww.cidrdb.org. http://cidrdb.org/cidr2019/papers/p117-kraska-cidr19.pdf\n[35] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe Case for Learned Index Structures. In Proceedings of the 2018 International\n13\n\nConference on Management of Data (Houston, TX, USA) (SIGMOD â€™18) . As-\nsociation for Computing Machinery, New York, NY, USA, 489â€“504. https:\n//doi.org/10.1145/3183713.3196909\n[36] Caroline Lemieux, Rohan Padhye, Koushik Sen, and Dawn Song. 2018. PerfFuzz:\nAutomatically Generating Pathological Inputs. In Proceedings of the 27th ACM\nSIGSOFT International Symposium on Software Testing and Analysis (Amsterdam,\nNetherlands) (ISSTA 2018) . Association for Computing Machinery, New York,\nNY, USA, 254â€“265. https://doi.org/10.1145/3213846.3213874\n[37] Pengfei Li, Yu Hua, Jingnan Jia, and Pengfei Zuo. 2021. FINEdex: A Fine-Grained\nLearned Index Scheme for Scalable and Concurrent Memory Systems. Proc. VLDB\nEndow. 15, 2 (oct 2021), 321â€“334. https://doi.org/10.14778/3489496.3489512\n[38] Baotong Lu, Jialin Ding, Eric Lo, Umar Farooq Minhas, and Tianzheng Wang. 2021.\nAPEX: A High-Performance Learned Index on Persistent Memory. Proc. VLDB\nEndow. 15, 3 (nov 2021), 597â€“610. https://doi.org/10.14778/3494124.3494141\n[39] Chaohong Ma, Xiaohui Yu, Yifan Li, Xiaofeng Meng, and Aishan Maoliniyazi.\n2022. FILM: A Fully Learned Index for Larger-Than-Memory Databases. Proc.\nVLDB Endow. 16, 3 (nov 2022), 561â€“573. https://doi.org/10.14778/3570690.\n3570704\n[40] Hongzi Mao, Mohammad Alizadeh, Ishai Menache, and Srikanth Kandula. 2016.\nResource Management with Deep Reinforcement Learning. In Proceedings of\nthe 15th ACM Workshop on Hot Topics in Networks (Atlanta, GA, USA) (HotNets\nâ€™16). Association for Computing Machinery, New York, NY, USA, 50â€“56. https:\n//doi.org/10.1145/3005745.3005750\n[41] Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng,\nand Mohammad Alizadeh. 2019. Learning Scheduling Algorithms for Data\nProcessing Clusters. In Proceedings of the ACM Special Interest Group on Data\nCommunication (Beijing, China) (SIGCOMM â€™19) . Association for Computing Ma-\nchinery, New York, NY, USA, 270â€“288. https://doi.org/10.1145/3341302.3342080\n[42] Adam Marcus, Eugene Wu, David Karger, Samuel Madden, and Robert Miller.\n2011. Human-Powered Sorts and Joins. Proc. VLDB Endow. 5, 1 (sep 2011), 13â€“24.\nhttps://doi.org/10.14778/2047485.2047487\n[43] Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra,\nAlfons Kemper, Thomas Neumann, and Tim Kraska. 2020. Benchmarking Learned\nIndexes. Proc. VLDB Endow. 14, 1 (sep 2020), 1â€“13. https://doi.org/10.14778/\n3421424.3421425\n[44] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learn-\ning Multi-Dimensional Indexes. In Proceedings of the 2020 ACM SIGMOD In-\nternational Conference on Management of Data (Portland, OR, USA) (SIGMOD\nâ€™20). Association for Computing Machinery, New York, NY, USA, 985â€“1000.\nhttps://doi.org/10.1145/3318464.3380579\n[45] Patrick Oâ€™Neil, Edward Cheng, Dieter Gawlick, and Elizabeth Oâ€™Neil. 1996. The\nLog-Structured Merge-Tree (LSM-Tree). Acta Inf. 33, 4 (jun 1996), 351â€“385.\nhttps://doi.org/10.1007/s002360050048\n[46] Hyunjung Park, Hector Garcia-Molina, Richard Pang, Neoklis Polyzotis, Aditya\nParameswaran, and Jennifer Widom. 2012. Deco: A System for Declarative\nCrowdsourcing. Proc. VLDB Endow. 5, 12 (aug 2012), 1990â€“1993. https://doi.org/\n10.14778/2367502.2367555\n[47] Luis Pedrosa, Rishabh Iyer, Arseniy Zaostrovnykh, Jonas Fietz, and Katerina\nArgyraki. 2018. Automated Synthesis of Adversarial Workloads for Network\nFunctions. In Proceedings of the 2018 Conference of the ACM Special Interest Group\non Data Communication (Budapest, Hungary) (SIGCOMM â€™18) . Association for\nComputing Machinery, New York, NY, USA, 372â€“385. https://doi.org/10.1145/\n3230543.3230573\n[48] Laurent Perron and Vincent Furnon. 2023. OR-Tools . Google. Retrieved Decmber\n10, 2023 from https://developers.google.com/optimization/cp/cp_solver/\n[49] Theofilos Petsios, Jason Zhao, Angelos D. Keromytis, and Suman Jana. 2017.\nSlowFuzz: Automated Domain-Independent Detection of Algorithmic Com-\nplexity Vulnerabilities. In Proceedings of the 2017 ACM SIGSAC Conference on\nComputer and Communications Security (Dallas, Texas, USA) (CCS â€™17) . Asso-\nciation for Computing Machinery, New York, NY, USA, 2155â€“2168. https:\n//doi.org/10.1145/3133956.3134073\n[50] Raghu Ramakrishnan and Johannes Gehrke. 2002. Database Management Systems\n(3 ed.). McGraw-Hill, Inc., USA.[51] Roei Schuster, Jin Peng Zhou, Thorsten Eisenhofer, Paul Grubbs, and Nicolas\nPapernot. 2023. Learned Systems Security .\n[52] Yuju Shen, Yanyan Jiang, Chang Xu, Ping Yu, Xiaoxing Ma, and Jian Lu. 2018.\nReScue: Crafting Regular Expression DoS Attacks. In Proceedings of the 33rd\nACM/IEEE International Conference on Automated Software Engineering (Mont-\npellier, France) (ASE â€™18) . Association for Computing Machinery, New York, NY,\nUSA, 225â€“235. https://doi.org/10.1145/3238147.3238159\n[53] Govind Sreekar Shenoy, Jordi Tubella, and Antonio GonzÃ¡lez. 2012. Improving\nthe Resilience of an IDS against Performance Throttling Attacks. In Security\nand Privacy in Communication Networks - 8th International ICST Conference, Se-\ncureComm 2012, Padua, Italy, September 3-5, 2012. Revised Selected Papers (Lecture\nNotes of the Institute for Computer Sciences, Social Informatics and Telecommuni-\ncations Engineering) , Angelos D. Keromytis and Roberto Di Pietro (Eds.), Vol. 106.\nSpringer, 167â€“184. https://doi.org/10.1007/978-3-642-36883-7_11\n[54] Zhenyu Song, Daniel S. Berger, Kai Li, and Wyatt Lloyd. 2020. Learning Relaxed\nBelady for Content Distribution Network Caching. In 17th USENIX Symposium\non Networked Systems Design and Implementation (NSDI 20) . USENIX Associ-\nation, Santa Clara, CA, 529â€“544. https://www.usenix.org/conference/nsdi20/\npresentation/song\n[55] Octavian Suciu, Radu Marginean, Yigitcan Kaya, Hal Daume III, and Tudor\nDumitras. 2018. When Does Machine Learning FAIL? Generalized Transferability\nfor Evasion and Poisoning Attacks. In 27th USENIX Security Symposium (USENIX\nSecurity 18) . USENIX Association, Baltimore, MD, 1299â€“1316. https://www.\nusenix.org/conference/usenixsecurity18/presentation/suciu\n[56] Zhaoyan Sun, Xuanhe Zhou, and Guoliang Li. 2023. Learned Index: A Compre-\nhensive Experimental Evaluation. Proc. VLDB Endow. 16, 8 (jun 2023), 1992â€“2004.\nhttps://doi.org/10.14778/3594512.3594528\n[57] Chuzhe Tang, Zhiyuan Dong, Minjie Wang, Zhaoguo Wang, and Haibo Chen.\n2019. Learned Indexes for Dynamic Workloads. https://arxiv.org/abs/1902.00655.\n[58] Juha-Matti Tilli. 2018. CVE-2018-5390: Linux Kernel TCP Reassembly Algorithm\nLets Remote Users Consume Excessive CPU Resources on the Target System . Re-\ntrieved Decmber 10, 2023 from https://ubuntu.com/security/cve-2018-5390\n[59] Dana Van Aken, Andrew Pavlo, Geoffrey J. Gordon, and Bohan Zhang. 2017.\nAutomatic Database Management System Tuning Through Large-Scale Machine\nLearning. In Proceedings of the 2017 ACM International Conference on Management\nof Data (Chicago, Illinois, USA) (SIGMOD â€™17) . Association for Computing Machin-\nery, New York, NY, USA, 1009â€“1024. https://doi.org/10.1145/3035918.3064029\n[60] Chaichon Wongkham, Baotong Lu, Chris Liu, Zhicong Zhong, Eric Lo, and\nTianzheng Wang. 2022. Are Updatable Learned Indexes Ready? Proc. VLDB\nEndow. 15, 11 (jul 2022), 3004â€“3017. https://doi.org/10.14778/3551793.3551848\n[61] Jiacheng Wu, Yong Zhang, Shimin Chen, Jin Wang, Yu Chen, and Chunxiao Xing.\n2021. Updatable Learned Index with Precise Positions. Proc. VLDB Endow. 14, 8\n(apr 2021), 1276â€“1288. https://doi.org/10.14778/3457390.3457393\n[62] Shangyu Wu, Yufei Cui, Jinghuan Yu, Xuan Sun, Tei-Wei Kuo, and Chun Jason\nXue. 2022. NFL: Robust Learned Index via Distribution Transformation. Proc.\nVLDB Endow. 15, 10 (jun 2022), 2188â€“2200. https://doi.org/10.14778/3547305.\n3547322\n[63] Valentin WÃ¼stholz, Oswaldo Olivo, Marijn J. Heule, and Isil Dillig. 2017. Static\nDetection of DoS Vulnerabilities in Programs That Use Regular Expressions. In\nProceedings, Part II, of the 23rd International Conference on Tools and Algorithms\nfor the Construction and Analysis of Systems - Volume 10206 . Springer-Verlag,\nBerlin, Heidelberg, 3â€“20. https://doi.org/10.1007/978-3-662-54580-5_1\n[64] Huang Xiao, Battista Biggio, Gavin Brown, Giorgio Fumera, Claudia Eckert, and\nFabio Roli. 2015. Is Feature Selection Secure against Training Data Poisoning?.\nInProceedings of the 32nd International Conference on International Conference on\nMachine Learning - Volume 37 (Lille, France) (ICMLâ€™15) . JMLR.org, 1689â€“1698.\n[65] Chaofei Yang, Qing Wu, Hai Li, and Yiran Chen. 2017. Generative Poisoning\nAttack Method Against Neural Networks . Retrieved Decmber 10, 2023 from\nhttps://arxiv.org/abs/1703.01340\n[66] Zhou Zhang, Zhaole Chu, Peiquan Jin, Yongping Luo, Xike Xie, Shouhong Wan,\nYun Luo, Xufei Wu, Peng Zou, Chunyang Zheng, Guoan Wu, and Andy Rudoff.\n2022. PLIN: A Persistent Learned Index for Non-Volatile Memory with High\nPerformance and Instant Recovery. Proc. VLDB Endow. 16, 2 (oct 2022), 243â€“255.\nhttps://doi.org/10.14778/3565816.3565826\n14",
  "textLength": 96572
}