{
  "paperId": "eb111c2ef14bd93adc7c92ce9d82371be6818728",
  "title": "Private Algorithms with Private Predictions",
  "pdfPath": "eb111c2ef14bd93adc7c92ce9d82371be6818728.pdf",
  "text": "Learning-Augmented Private Algorithms for Multiple Quantile Release\nMikhail Khodak1Kareem Amin2Travis Dick2Sergei Vassilvitskii2\nAbstract\nWhen applying differential privacy to sensitive\ndata, we can often improve performance using\nexternal information such as other sensitive data,\npublic data, or human priors. We propose to use\nthe learning-augmented algorithms (or algorithms\nwith predictions) framework—previously applied\nlargely to improve time complexity or competitive\nratios—as a powerful way of designing and\nanalyzing privacy-preserving methods that can\ntake advantage of such external information\nto improve utility. This idea is instantiated\non the important task of multiple quantile\nrelease, for which we derive error guarantees\nthat scale with a natural measure of prediction\nquality while (almost) recovering state-of-the-art\nprediction-independent guarantees. Our analysis\nenjoys several advantages, including minimal\nassumptions about the data, a natural way of\nadding robustness, and the provision of useful\nsurrogate losses for two novel “meta” algorithms\nthat learn predictions from other (potentially\nsensitive) data. We conclude with experiments\non challenging tasks demonstrating that learning\npredictions across one or more instances can lead\nto large error reductions while preserving privacy.\n1. Introduction\nThe differentially private (DP) release of statistics such as\nthe quantile qof a private dataset xPRnis an inevitably\nerror-prone task because we are by deﬁnition precluded\nfrom revealing exact information about the instance at\nhand (Dwork & Roth, 2014). However, DP instances rarely\noccur in a vacuum: even in the simplest practical settings,\nwe usually know basic information such as the fact that all\nindividuals have a nonnegative age. Often, the dataset we\nare considering is drawn from a similar population as a pub-\n1Carnegie Mellon University; work done in part as an intern\nat Google Research - New York.2Google Research - New York.\nCorrespondence to: Mikhail Khodak <khodak@cmu.edu >.\nProceedings of the 40thInternational Conference on Machine\nLearning , Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright\n2023 by the author(s).lic dataset zPRNand should thus have similar quantiles,\na case known as the public-private setting (Liu et al., 2021;\nBie et al., 2022). Alternatively, in what we call sequential re-\nlease , we aim to release the quantiles of each of a sequence\nof datasets x1;:::;xTone-by-one. These could be gener-\nated by a stationary or other process that allows information\nderived from prior releases to inform predictions of future\nreleases. In all of these settings, we might hope to incorpo-\nrate external information to reduce error, but approaches for\ndoing so tend to be ad hoc and assumption-heavy.\nWe propose that the framework of learning-augmented\nalgorithms —a.k.a. algorithms with predictions (Mitzen-\nmacher & Vassilvitskii, 2021)—provides the right tools for\nderiving DP algorithms in this setting, and instantiate this\nidea for multiple quantile release (Gillenwater et al., 2021;\nKaplan et al., 2022). Algorithms with predictions is an\nexpanding ﬁeld of algorithm design that constructs methods\nwhose instance-dependent performance improves with\nthe accuracy of some prediction about the instance. The\ngoal is to bound the cost Cxpwqof running on instance x\ngiven a prediction wby some metric Uxpwqof the quality\nof the prediction on that instance. Motivated by practical\nsuccess (Liu et al., 2012; Kraska et al., 2018) and as a type\nof beyond-worst-case analysis (Roughgarden, 2020), such\nalgorithms can target a wide variety of cost measures, e.g.\ncompetitive ratios in online algorithms (Anand et al., 2020;\nBamas et al., 2020; Diakonikolas et al., 2021; D ¨utting et al.,\n2021; Indyk et al., 2022; Yu et al., 2022; Christianson et al.,\n2023; Jiang et al., 2020; Kumar et al., 2018; Lykouris &\nVassilvitskii, 2021; Rohatgi, 2020), space complexity in\nstreaming algorithms (Du et al., 2021), and time complexity\nin graph algorithms (Dinitz et al., 2021; Chen et al., 2022;\nSakaue & Oki, 2022) and distributed systems (Lattanzi\net al., 2020; Lindermayr & Megow, 2022; Scully et al.,\n2022). Departing from such work, we instead aim to design\nlearning-augmented algorithms whose cost Cxpwqcaptures\nthe error of some statistic—in our case quantiles—computed\nprivately on instance an xgiven a prediction w. We are\ninterested in bounding this cost in terms of the quality of\nthe external information provided to our algorithm, Uxpwq.\nWhile incorporating external information into DP is well-\nstudied, c.f. public-private methods (Bie et al., 2022; Liu\net al., 2021) and private posterior inference (Dimitrakakis\net al., 2017; Geumlek et al., 2017; Seeman et al., 2020), by\n1arXiv:2210.11222v2  [cs.CR]  8 May 2023\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nderiving and analyzing a learning-augmented algorithm for\nmultiple quantiles we show numerous comparative advan-\ntages, including:\n1.Minimal assumptions about the data, in our case even\nfewer than needed by the unaugmented baseline.\n2.Existing tools for studying the robustness of algorithms\nto noisy predictions (Lykouris & Vassilvitskii, 2021).\n3.Co-designing algorithms with predictions together with\nmethods for learning those predictions from data (Kho-\ndak et al., 2022), which we show is crucial for both the\npublic-private and sequential release settings.\nAs part of this analysis we derive a learning-augmented ex-\ntension of the ApproximateQuantiles (AQ) method\nof Kaplan et al. (2022) that (nearly) matches its worst-case\nguarantees while being much better if a natural measure\nUxpwqof prediction quality is small. By studying Ux, we\nmake the following contributions to multiple quantiles:\n1.The ﬁrst robust algorithm, even for one quantile, that\navoids assuming the data is bounded on some interval,\nspeciﬁcally by using a heavy-tailed prior.\n2.A provable way of ensuring robustness to poor priors,\nwithout losing the consistency of good ones.\n3.A novel connection between DP quantiles and censored\nregression that leads to (a) a public-private release al-\ngorithm and (b) a sequential release scheme, both with\nruntime and error guarantees.\nFinally, we integrate these techniques to signiﬁcantly\nimprove the accuracy of public-private and sequential\nquantile release on several real and synthetic datasets.\n2. Related work\nThere has been signiﬁcant work on incorporating external\ninformation to improve DP methods. A major line of work\nis the public-private framework, where we have access\nto public data that is related in some way to the private\ndata (Liu et al., 2021; Amid et al., 2022; Li et al., 2022; Bie\net al., 2022; Bassily et al., 2022). The use of public data\ncan be viewed as using a prediction, but such work starts by\nmaking (often strong) distributional assumptions on the pub-\nlic and private data; we instead derive instance-dependent\nupper bounds with minimal assumptions that we then apply\nto such public-private settings. Furthermore, our frame-\nwork allows us to ensure robustness to poor predictions\nwithout distributional assumptions, and to derive learning\nalgorithms using training data that may itself be sensitive.\nAnother approach is to treat DP mechanisms (e.g. the\nexponential) as Bayesian posterior sampling (Dimitrakakis\net al., 2017; Geumlek et al., 2017; Seeman et al., 2020).\nOur work can be viewed as an adaptation where we give\nexplicit prior-dependent utility bounds. To our knowledge,\nno such guarantees exist in the literature. Moreover, while\nour focus is quantile estimation, the predictions-basedframework that we advocate is much broader, as many\nDP methods—including for multiple quantiles—combine\nmultiple queries that must be considered jointly.\nOur approach for augmenting DP with external information\ncenters the algorithms with predictions framework, where\npast work has focused on using predictions to improve met-\nrics related to time, space, and communication complexity.\nWe make use of existing techniques from this literature, in-\ncluding robustness-consistency tradeoffs (Lykouris & Vassil-\nvitskii, 2021) and the online learning of predictions (Khodak\net al., 2022). Tuning DP algorithms has been an important\ntopic in private machine learning, e.g. for hyperparameter\ntuning (Chaudhuri & Vinterbo, 2013) and federated learn-\ning (Andrew et al., 2021), but these have not to our knowl-\nedge considered incorporating per-instance predictions.\nThe speciﬁc task we focus on is DP quantiles, a well-studied\nproblem (Gillenwater et al., 2021; Kaplan et al., 2022), but\nwe are not aware of work adding outside information. We\nalso make the important contribution of an effective method\nfor removing data-boundedness assumptions. Our algorithm\nbuilds upon the state-of-the-art work of Kaplan et al. (2022),\nwhich is also our main source for empirical comparison.\n3. Augmenting a private algorithm\nThe basic requirement for a learning-augmented algorithm\nis that the cost Cxpwqof running it on an instance xwith\nprediction wshould be upper bounded—usually up to\nconstant or logarithmic factors—by a metric Uxpwqof the\nquality of the prediction on the instance. We denote this by\nCxÀUx. In our work the cost Cxpwqwill be the error of\na privately released statistic, as compared to some ground\ntruth. We will use the following privacy notion:\nDeﬁnition 3.1 (Dwork & Roth (2014)) .Algorithm Ais\np\";\u000eq-differentially private if for all subsets Sof its range,\nPrtApxqPSu¤e\"PrtAp~ xqPSu\u0000\u000ewhenever x\u0012~ x\nareneighboring , i.e. they differ in at most one element.\nUsing\"-DP to denotep\";0q-DP, the broad goal of this work\nwill be to reduce the error Cxpwqof\"-DP multiple quantile\nrelease while ﬁxing the privacy level \".\n3.1. Problem formulation\nA good guarantee for a learning-augmented algorithm will\nhave several important properties that formally separate its\nperformance from naive upper bounds UxÁCx. The ﬁrst,\nconsistency , requires it to be a reasonable indicator of strong\nperformance in the limit of perfect prediction:\nDeﬁnition 3.2. A learning-augmented guarantee CxÀUx\niscx-consistent ifCxpwq¤cxwheneverUxpwq\u00100.\nHerecxis a prediction-independent quantity that should\ndepend weakly or not at all on problem difﬁculty (in the\ncase of quantiles, the minimum separation between data\n2\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\npoints). Consistency is often presented via a tradeoff with\nrobustness (Lykouris & Vassilvitskii, 2021), which bounds\nhow poorly the method can do when the prediction is bad,\nin a manner similar to a standard worst-case bound:\nDeﬁnition 3.3. A learning-augmented guarantee CxÀUx\nisrx-robust if it impliesCxpwq¤rxfor all predictions w.\nUnlike consistency, robustness usually depends strongly on\nthe difﬁculty of the instance x, with the goal being to not do\nmuch worse than a prediction-free approach. Note that the\nlatter is trivially robust but not (meaningfully) consistent,\nsince it ignores the prediction; this makes clear the need for\nconsidering the two properties via tradeoff between them.\nAs discussed further in Section 4.2, this existing language\nfor quantifying robustness is one of the advantages of\nusing the framework of learning-augmented algorithms for\nincorporating external information into DP methods. We\nreport robustness-consistency trade-offs for our quantile\nrelease algorithms in the same section.\nA last desirable property of the prediction quality measure\nUxpwqis that it should be useful for making good predic-\ntions. One way to formalize this is to require Uxtto be learn-\nable from multiple instances xt. For example, we could ask\nforonline learnability, i.e. the existence of an algorithm that\nmakes predictions wtPWin some action space Wgiven\ninstances x1;:::;xt\u00011whose regret is sublinear in T:\nDeﬁnition 3.4. The regret of actions w1;:::;wTP\nWon the sequence of functions Ux1;:::;U xTis\nmaxwPW°T\nt\u00101Uxtpwtq\u0001Uxtpwq.\nSublinear regret implies average prediction quality as good\nas that of the optimal prediction in hindsight, up to an\nadditive term that vanishes as TÑ8 . SinceUxtroughly\nupper-bounds the error Cxt, this means that asymptotically\nthe average error is governed by the average prediction\nquality minwPW1\nT°T\nt\u00101Uxtpwqof the optimal wPW. A\ncrucial observation here is that sublinear regret can often be\nobtained by making the function Uxamenable to familiar\ngradient-based online convex optimization methods such\nas online gradient descent (Khodak et al., 2022). Doing so\nalso enables instance-dependent linear prediction: setting\nwtusing a learned function of some instance features ft.\nWe demonstrate the usefulness of both learning and\nrobustness-consistency analysis in two applications where it\nis reasonable to have external information about the sensitive\ndataset(s). In the public-private setting, the prediction wis\nobtained from a public dataset x1that is assumed to be sim-\nilar to xbut is not subject to privacy-protection. In sequen-\ntial release , we privately release information about each\ndataset in a sequence x1;:::;xT; the release at time tcan\ndepend on xtand on a prediction wt, which can be derived\n(privately) from past observations. In Section 5 we show\nthat sequential release can be posed directly as a privateonline learning problem, while the public-private setting\ncan be approached via online-to-batch conversion (Cesa-\nBianchi et al., 2004). Both are thus directly enabled by\ntreating the prediction quality measures Uxtas surrogate\nobjectives for the actual cost functions Cxand applying\nstandard optimization techniques (Khodak et al., 2022).\nWith these desiderata of algorithms with predictions guar-\nantees in-mind, we now move to deriving them for quantile\nrelease. The robustness and learnability of the resulting\nprediction quality measures Uxare discussed in Section 4.\n3.2. Warm-up: Releasing one quantile\nGiven a quantile qPp0;1qand a sorted dataset xPRnofn\ndistinct points, we want to release oPrxrtqnus;xrtqnu\u00001sq,\ni.e. such that the proportion of entries less than oisq. As in\nprior work (Kaplan et al., 2022), the error of owill be the\nnumber of points between it and the desired interval:\nGapqpx;oq\u0010||ti:xris ou|\u0001 tqnu|\u0010| max\nxris oi\u0001tqnu|\n(1)\nGapqpx;oqis constant on intervals Ik\u0010 pxrks;xrk\u00001ss\nin the partition by xofR(letI0\u0010 p\u00018;xr1ssand\nIn\u0010 pxrns;8q), so we also say that Gapqpx;Ikqis the\nsame as Gapqpx;oqfor someoin the interior of Ik.\nFor single quantile release we choose perhaps the most natu-\nral way of specifying a prediction for a DP algorithm: via the\nbase measure \u0016:RÞÑR¥0of the exponential mechanism:\nTheorem 3.1 (McSherry & Talwar (2007)) .If the util-\nityupx;oqof an outcome oof a query over dataset\nxhas sensitivity maxo;x\u0012~ x|upx;oq \u0001up~ x;oq| ¤ \u0001\nthen the exponential mechanism , which releases ow.p.\n9expp\"\n2\u0001upx;oqq\u0016poqfor some base measure \u0016, is\"-DP .\nThe utility function we use is uq\u0010\u0001Gapq, so since this is\nconstant on each interval Ikthe mechanism here is equiva-\nlent to sampling kw.p.9expp\"uqpx;Ikq{2q\u0016pIkqand then\nsamplingofromIkw.p.9\u0016poq. While the idea of spec-\nifying a prior for EM is well-known, the key idea here is\nto obtain a prediction-dependent bound on the error that\nreveals a useful measure of the quality of the prediction. In\nparticular, we can show (c.f. Lemma A.1) that running EM\nin this way yields othat w.p.¥1\u0001\fsatisﬁes\nGapqpx;oq¤2\n\"log1{\f\n\tpq;\"q\nxp\u0016q¤2\n\"log1{\f\n\tpqq\nxp\u0016q(2)\nwhere the quantity \tpq;\"q\nx\u0010³\nexpp\u0001\"\n2Gapqpx;oqq\u0016poqdo\nis the inner product between the prior and the EM score\nwhile \tpqq\nx\u0010lim\"Ñ8\tpq;\"q\nx\u0010\u0016ppxrtqnus;xrtqnu\u00001ssqis\nthe probability that the prior assigns to the optimal interval.\nThis suggests two metrics of prediction quality: the neg-\native log-inner-products Upq;\"q\nxp\u0016q\u0010\u0001 log \tpq;\"q\nxp\u0016qand\nUpqq\nxp\u0016q\u0010\u0001 log \tpqq\nxp\u0016q. Both make intuitive sense: we\n3\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nexpect predictions \u0016that assign a high probability to in-\ntervals that the EM score weighs heavily to perform well,\nand EM assigns the most weight to the optimal interval.\nThere are also many ways that these metrics are useful.\nFor one, in the case of perfect prediction—i.e. if \u0016as-\nsigns probability one to the optimal interval Itqnu—then\n\tpq;\"q\nxp\u0016q\u0010\tpqq\nxp\u0016q\u00101, yielding an upper bound on the\nerror of only2\n\"log1\n\f. Secondly, as we will see, both are\nalso amenable for analyzing robustness (the mechanism’s\nsensitivity to incorrect priors) and learning. A ﬁnal and\nimportant quality is that the guarantees using these metrics\nhold under no extra assumptions. Between the two, the ﬁrst\nmetric provides a tighter bound on the utility loss while the\nsecond does not depend on \", which may be desirable.\nIt is also fruitful to analyze the metrics for speciﬁc priors.\nWhen xis in a bounded interval pa;bqand\u0016poq\u00101oPpa;bq\nb\u0001a\nis the uniform measure, then \tpqq\nxp\u0016q¥ x\nb\u0001a, where xis\nthe minimum distance between entries; thus we recover past\nbounds, e.g. Kaplan et al. (2022, Lemma A.1), that implic-\nitly use this measure to guarantee Gapqpx;oq¤2\n\"logb\u0001a\n\f x.\nHere the support of the uniform distribution is correct by\nassumption as the data is assumed bounded. However, an-\nalyzing \tpqq\nxalso yields a novel way of removing this as-\nsumption: if we suspect the data lies in pa;bq, we set\u0016to\nbe the Cauchy prior with locationa\u0000b\n2and scaleb\u0001a\n2. Even\nif we are wrong about the interval, there exists an R¡0s.t.\nthe data lies in the interval pa\u0000b\n2\bRq, so using the Cauchy\nyields \tpqq\nx¥2pb\u0001aq x{\u0019\npb\u0001aq2\u00004R2and thus the following guarantee:\nCorollary 3.1 (of Lem. A.1) .If the data lies in the interval\npa\u0000b\n2\bRqand\u0016is the Cauchy measure with locationa\u0000b\n2\nand scaleb\u0001a\n2then the output of the exponential mechanism\nsatisﬁes Gapqpx;oq¤2\n\"log\u0002\n\u0019b\u0001a\u00004R2\nb\u0001a\n2\f x\nw.p.¥1\u0001\f.\nIfR\u0010b\u0001a\n2, i.e. we get the interval right, then the bound is\nonly an additive factor2\n\"log\u0019worse than before, but if we\nare wrong then performance degrades as Oplogp1\u0000R2qq,\nunlike the OpRqerror of the uniform prior. Note our use of\na heavy-tailed distribution here: a sub-exponential density\ndecays too quickly and leads to error OpRqrather than\nOplogp1\u0000R2qq. We can also adapt this technique if we\nknow only a single-sided bound, e.g. if values must be\npositive, by using an appropriate half-Cauchy distribution.\n3.3. Releasing multiple quantiles\nTo simultaneously estimate quantiles q1;:::;qmwe adapt\ntheApproximateQuantiles method of (Kaplan et al.,\n2022), which assigns each qito a node in a binary tree and,\nstarting from the root, uses EM with the uniform prior to\nestimate a quantile before sending the data below the out-\ncomeoto its left child and the data above oto its right child.\nThus each entry is only involved in rlog2msexponentialmechanisms, and so for data in pa;bqthe maximum Gapqi\nacross quantiles is O\u0001\nlog2m\n\"logmpb\u0001aq\n\f x\t\n, which is much\nbetter than the naive bound of a linear function of m.\nGiven one prior \u0016ifor eachqi, a naive extension of (2)gets\na similar polylogpmqbound (c.f. Lem A.2); notably we ex-\ntend the Cauchy-unboundedness result to multiple quantiles\n(c.f. Cor. A.1). However the upper bound is not a determin-\nistic function of \u0016i, as it depends on restrictions of xand\u0016i\nto subsetspoj;okqof the domain induced by the outcomes\nof EM for quantiles qjandqkearlier in the tree. It thus\ndoes not encode a direct relationship between the prediction\nand instance data and is less amenable for learning.\nWe instead want guarantees depending on a more natural\nmetric, e.g. one aggregating \tpqi;\"iq\nxp\u0016iqfrom the previous\nsection across pairs pqi;\u0016iq. The core issue is that the data\nsplitting makes the probability assigned by a prior \u0016ito data\noutside the interval poj;okqinduced by the outcomes of\nquantilesqjandqkearlier in the tree not affect the distribu-\ntion ofoi. One way to handle this is to assign this probability\nmass to the edges of poj;okq, rather than the more natural\nconditional approach of ApproximateQuantiles . We\nrefer to this as “edge-based prior adaptation” and use it\nto bound Gapmax\u0010maxiGapqipx;oiqvia the harmonic\nmean \tp\"q\nxof the inner products \tpqi;\"iq\nxp\u0016iq:\nTheorem 3.2 (c.f. Thm. A.1) .Ifm\u00102k\u00011for some\nk, quantiles q1;:::;qmare uniformly spaced, and for\neach we have a prior \u0016i:RÞÑR¥0, then running\nApproximateQuantiles with edge-based prior\nadaptation (c.f. Algorithm 2) is \"-DP , and w.p.¥1\u0001\f\nGapmax¤2\n\"\u001elog2pm\u00001qrlog2pm\u00001qslogm{\f\n\tp\"q\nx\nfor \tp\"q\nx\u0010\u0003m¸\ni\u001011{m\n\tpqi;\"iq\nxp\u0016iq\u000b\u00011 (3)\nHere\"i\u0010\"\nrlog2pm\u00001qsand\u001e\u00101\u0000?\n5\n2is the golden ratio.\nThe golden ratio is due to a Fibonacci-type recurrence\nbounding the maximum Gapqiat each depth of the tree.\n\tp\"q\nxdepends only on xand predictions \u0016i, and it yields\na nice error metric Up\"q\nx\u0010\u0001log \tp\"q\nx\u0010log°m\ni\u00101eUpqi;\"iq\nx .\nHowever, the dependence of the error on mis worse than\nofApproximateQuantiles , as\u001elog2mis roughly\nOpm0:7q. The bound is still sublinear and thus better than\nthe naive baseline of running EM mtimes.\nThe ~Op\u001elog2mqdependence results from error compound-\ning across depths of the tree, so we can try to reduce depth\nby going from a binary to a K-ary tree. This involves run-\nning EMK\u00011times at each node—and paying K\u00011more\nin budget—to split the data into Ksubsets; the resulting\nestimates may also be out of order. However, by showing\n4\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nFigure 1. Maximum gap as a function of mfor different variants of\nAQ when using the Uniform prior, evaluated on 1000 samples from\na standard Gaussian (left) and the Adult “age” dataset (right). The\ndashed and solid lines correspond to \"\u00101and 0.1, respectively.\nthat sorting them back into order does not increase the error\nand then controlling the maximum Gapqiat each depth via\nanother recurrence relation, we prove the following:\nTheorem 3.3 (c.f. Thm. A.2) .For anyq1;:::;qm,\nusingK\u0010 rexppa\nlog 2 logpm\u00001qqsand edge-based\nadaptation guarantees \"-DP and w.p. ¥1\u0001\fhas\nGapmax¤2\u00192\n\"exp\u0001\n2a\nlogp2qlogpm\u00001q\t\nlogm{\f\n\tp\"q\nx.\nThe rate in mis both sub-polynomial and super-poly-\nlogarithmic ( opm\u000bqand!plog\u000bmq @\u000b¡0); while\nasymptotically worse than the prediction-free original\nresult (Kaplan et al., 2022), for almost any practical value of\nm(e.g.mPr3;1012s) it does not exceed a small constant\n(e.g. nine) times log3m. Thus if the error \u0001log \tp\"q\nxof the\nprediction is small—i.e. the inner products between priors\nand EM scores are large on (harmonic) average—then we\nmay do much better with this approach.\nWe compare K-ary AQ with edge-based adaptation to regu-\nlar AQ on two datasets in Figure 1. The original is better at\nhigher\"but similar or worse at higher privacy. We also ﬁnd\nthat conditional adaptation is only better on discretized data\nthat can have repetitions, a case where neither method pro-\nvides guarantees. Overall, we ﬁnd that our prior-dependent\nanalysis covers a useful algorithm, but for consistency with\npast work and due to its better performance at high \"we\nwill focus on the original binary approach in experiments.\n4. Utility of learning-augmented algorithms\nIn the previous section we derived a data-dependent function\nUp\"q\nx\u0010\u0001log \tp\"q\nxthat upper bounds the error of quantile\nrelease using priors \u00161;:::;\u0016m. As in the single-quantile\ncase, we can construct a looser, \"-independent upper bound\nUx\u0010\u0001log \t x\u0010logm¸\ni\u00101eUpqiq\nx¥Up\"q\nx (4)\nusing the harmonic mean \txof\tpqiq\nx. We next summarize\nthe usefulness of these upper bounds for understanding and\napplying DP methods with external information. Note that\nall three aspects below are crucial in our experiments.4.1. Minimal assumptions and new insights\nOur guarantees require no extra data assumptions: in-fact,\nthe ﬁrst outcome of our analysis was removing a bounded-\nness assumption. This contrasts with past public-private\nwork (Liu et al., 2021; Bie et al., 2022), which makes\ndistributional assumptions, and is why we can apply these\nresults to two very distinct settings in Section 5.\n4.2. Ensuring robustness\nWhile we incorporate external information into DP-\nalgorithms because we hope to improve performance, if\nnot done carefully it may lead to worse results. For exam-\nple, a quantile prior concentrated away from the data may\nhave error depending linearly on the distance to the optimal\ninterval. Ideally an algorithm that uses a prediction will be\nrobust, i.e. revert back to worst-case guarantees if the pre-\ndiction is poor, without signiﬁcantly sacriﬁcing consistency,\ni.e. performing well if the prediction is good.\nUsing the formalization of these properties in Deﬁnitions 3.2\nand 3.3, algorithms with predictions provides a conve-\nnient way to deploy them by parameterizing the robustness-\nconsistency tradeoff, in which methods are designed to be\nrxp\u0015q-robust and cxp\u0015q-consistent for a user-speciﬁed pa-\nrameter\u0015Pr0;1s(Bamas et al., 2020; Lykouris & Vassilvit-\nskii, 2021). For quantiles, we can obtain an elegant param-\neterized tradeoff by interpolating prediction priors with a\n“robust” prior. In particular, since \tpq;\"q\nx is linear we can pick\n\u001ato be a trusted prior such as the uniform or Cauchy and for\nany prediction \u0016use\u0016p\u0015q\u0010p1\u0001\u0015q\u0016\u0000\u0015\u001ainstead. Setting\n\tpq;\"q\nxp\u0016p\u0015qq\u0010p 1\u0001\u0015q\tpq;\"q\nxp\u0016q\u0000\u0015\tpq;\"q\nxp\u001aqin(2)yields:\nCorollary 4.1 (of Lem. A.1; c.f. Cor. B.1) .For quan-\ntileq, applying EM with prior \u0016p\u0015q\u0010 p1\u0001\u0015q\u0016\u0000\u0015\u001ais\u0001\n2\n\"log1{\f\n\u0015\tpq;\"q\nxp\u001aq\t\n-robust and\u0001\n2\n\"log1{\f\n1\u0001\u0015\t\n-consistent.\nThus w.h.p. error is simultaneously at most2\n\"log1\n\u0015worse\nthan that of only using the robust prior \u001aand we only have\nerror2\n\"log1{\f\n1\u0001\u0015if the prediction \u0016is perfect, i.e. if it is only\nsupported on the optimal interval. This is easy to extend to\nthe multiple-quantile metric \u0001log \tp\"q\nx. In fact, we can even\ninterpolate between the polylogpmqprediction-free guaran-\ntee of past work and our learning-augmented guarantee with\nthe worse dependence on m; thus if the prediction is not\ngood enough to overcome this worse rate we can still ensure\nthat we do not do much worse than the original guarantee.\nCorollary 4.2 (of Lem. A.2 & Thm. A.1; c.f. Cor. B.2) .If\nwe run binary AQ on data in the interval pa\u0000b\n2\bRqfor\nunknownR¡0and use the prior \u0016p\u0015q\ni\u0010p1\u0001\u0015q\u0016\u0000\u0015\u001a\nfor eachqi, where\u001ais Cauchypa\u0000b\n2;b\u0001a\n2q, then the al-\ngorithm is\u0002\n2\n\"rlog2ms2log\u0002\n\u0019mb\u0001a\u00004R2\nb\u0001a\n2\u0015\f x\n\n-robust and\n\u0001\n2\n\"\u001elog2mrlog2mslogm{\f\n1\u0001\u0015\t\n-consistent.\n5\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nThese results show the advantage of our framework in de-\nsigning algorithms that make robust use of possibly noisy\npredictions. Notably, related public-private work that stud-\nies robustness still assumes source and target data are Gaus-\nsian (Bie et al., 2022), whereas we make no distributional\nassumptions. We demonstrate the importance of this robust-\nness technique throughout our experiments in Section 5.\n4.3. Learning\nA last important use for prior-dependent bounds is as surro-\ngate objectives for optimization. As we show in Section 5,\nbeing able to learn across upper bounds Ux1;:::;U xTof\na sequence of (possibly sensitive) datasets xtis useful for\nboth the public-private and sequential release. Algorithms\nwith predictions guarantees are often sufﬁciently nice to do\nthis using off-the-shelf online learning (Khodak et al., 2022),\na property that largely holds for our upper bounds as well.\nMost saliently, the bound Upq;\"q\nx\u0010\u0001log \tpq;\"q\nx is a convex\nfunction of an inner product \tpq;\"q\nx between the EM score\nand the prior \u0016; thus by discretizing one can learn over a\nlarge family of piecewise-constant priors, which themselves\nLipschitz priors over a bounded domain. The same is\ntrue of the multiple quantile bound Up\"q\nxbecause it is the\nlog-sum-exp over Upqi;\"iq\nx and thus also convex. Thus\nin theory we can (privately) online learn the sequence\nUp\"q\nxtwith low-regret w.r.t. any set of mLipschitz priors\n(c.f. Theorem B.2). However, in-practice we may not want\nto learn in the high dimensions needed by the discretization,\nand rather than ﬁxed priors we may wish to learn a mapping\nfrom dataset-speciﬁc features. In Section 5 we thus focus on\nlearning the less-expressive family of location-scale models.\n5. Applications\nWe now consider our two applications from the\nintroduction—public-private and sequential release—using\na speciﬁc class of location-scale priors, which for some\nmeasuref:RÞÑR¥0have form\u0016\u0017;\u001bpxq\u00101\n\u001bf\u0000x\u0001\u0017\n\u001b\b\nfor\n\u0017PRand\u001b¡0. Such families allows us to model both the\nlocation of a quantile using \u0017\u0010xw;fy—where wPRdis\na linear model from public features fPRdabout the dataset\nxPRn—and our uncertainty about it using \u001b, all while\nstaying in reasonable dimensions. Note that in this section\nwe use only the \"-independent bound Ux, asUp\"q\nxdoes not\nyield a convex objective; furthermore, while we mainly\ndiscuss the single-quantile bound Upqq\nxfor simplicity, the\ngeneral results (c.f. Section C) extend naturally to the case\nofm¡1because it is the log-sum-exp of the former.\n5.1. Convexity vs. robustness of location-scale models\nWe must ﬁrst determine which location-scale family to use,\nas this include Gaussians with mean \u0017and variance \u001b2,\nLaplace with mean \u0017and scale\u001b, Cauchy with location \u0017and scale\u001b, and more. To make this decision, we consider\ntwo desiderata: (1) the prior should be robust in the way the\nCauchy is robust, i.e. being wrong about the data location\nshould not harm us too much, and (2) it should be easy to\nlearn the parameters \u0017and\u001b, e.g. by optimizing Upqq\nxp\u0016\u0017;\u001bq.\nWhile not necessary, one way of ensuring (2) is convexity of\nUpqq\nx, which we focus on as it enables efﬁcient algorithms.\nHere we make use of a connection between these upper\nbounds and the likelihood of censored regression (Pratt,\n1981), which for noise \u0018iPRmodels a relationship\nbetween features fiPRdand a variable yi\u0010xw;fiy\u0000\u0018i\nwhen information about yiis only provided in terms\nof an interval rai;biqcontaining it (e.g. an individual’s\nincome bracket, not their exact income). If \u0018iis from a\nlocation-scale distribution with \u0017\u00100the log-likelihood\ngiven datapoints pai;bi;fiqis\nLtai;bi;fiun\ni\u00101pw;\u001bq\u0010n¸\ni\u00101log»bi\nai1\n\u001bf\u0002y\u0001xw;fiy\n\u001b\ndy(5)\nObserve that for a\u0010xrtqnusandb\u0010xrtqnus\u00001we have\nUpqq\nxp\u0016xw;fy;\u001bq\u0010\u0001 log\u0016xw;fy;\u001bppa;bsq\n\u0010\u0001log»b\na1\n\u001bf\u0002o\u0001xw;fy\n\u001b\ndo(6)\nwhich is the negative of La;b;fpw;\u001bq. We thus adopt the\nreparameterization of Burridge (1981), who showed that\n(5)is concave w.r.t. pv;\u001eq \u0010 pw\n\u001b;1\n\u001bqwheneverfislog-\nconcave , a property satisﬁed by the Gaussian and Laplace\nfamilies but not the Cauchy. Therefore, for such fwe have\nthat`pqq\nxpxv;fy;\u001eq\u0010Upqq\nxp\u0016xv;fy\n\u001e;1\n\u001eqis convex w.r.t. pv;\u001eq.\nUnfortunately, we show that no log-concave fis robust, in\nthe sense that for any R¡0there exists a dataset of points\nin the interval p\u0012\bRqns.t.Upqq\nxp\u0016\u0012;1q \u0010\npRq(rather\nthanOplogp1\u0000R2qqas shown for the Cauchy family in\nCorollary 3.1). On the other hand, log-concave location-\nscale families are the only ones for which Upqq\nxis convex,\nboth for the original parameterization and that of Burridge\n(1981). We record these facts in the following theorem:\nTheorem 5.1 (c.f. Thm. C.1) .Let\u0016\u0017;\u001bbe a location-scale\nfamily associated with a continuous measure f:RÞÑR¥0.\n1.Iffis log-concave then Da;b¡0s.t. for anyR¡0,\n Pp0;R\n2ns,q¥1\nn, and\u0012PRthere exists xPp\u0012\bRqn\nwithminixri\u00001s\u0001xris\u0010 s.t.Upqq\nxp\u0016\u0012;1q\u0010aR\u0000logb\n .\n2.Iffis not log-concave then there exists xPRnwith\nminixri\u00001s\u0001xris¡0s.t.Upqq\nxp\u0016\u0012;1qis non-convex in \u0012.\nNote the latter dataset is not degenerate: for fstrictly log-\nconvex overra;bs, anyxwhose optimal interval has length\n b\u0001a\n2has non-convex Upqq\nxp\u0016\u0012;1q\u0010\u0001 log \tpqq\nxp\u0016\u0012;1q.\n6\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nWe must thus choose between having a robust location-scale\nfamily like the Cauchy or an easy-to-optimize log-concave\none. As we can ensure robustness of the learned prior post-\nhocusing the approach of Section 4.2, we choose the latter.\nSpeciﬁcally, we use the Laplace prior, as it is in some sense\nthe most robust log-concave distribution (it has loss \u0002pRq\nifxPp\u0012\bRqn, whereas e.g. the Gaussian has loss \u0002pR2q)\nand because it yields a numerically stable closed-form\nexpression (40) for `pqq\nxp\u0012;\u001eq(unlike e.g. the Gaussian).\n5.2. Augmenting quantile release using public data\nWe turn to two applications that depend on optimizing upper\nbounds`pqq\nxp\u0012;\u001eqon the performance of quantile release\nusing the Laplace prior with scale1\n\u001eand location\u0012\n\u001e. While\nour ﬁnal objective is small Gapq, we will mainly discuss\noptimizing`pqq\nx\u0010Upqq\nx, or its expectation if xis drawn\nfrom some distribution. In the former case this directly\nbounds (w.h.p.) the cost of multiple quantile release via the\ntheoretical results in Section 3 because Ux¥\u0001 log \tp\"q\nx,\nwhile a bound on ExUxcan bound EGapmaxby setting\n\f. For example, \f\u00102\u00192\n\"nexpp2a\nlogp2qlogpm\u00001qqin\nTheorem 3.3 implies Gapmaxhas expectation at most\nO\u0002\nexp\u0001\n2a\nlogp2qlogpm\u00001q\tlogp\"mnq\u0000ExUx\n\"\n(7)\nOur ﬁrst application is the frequently studied setting where\nwe have a large public dataset x1PRNand want to use it to\nimprove the release of statistics of a smaller private dataset\nxPRn. To apply our quantile release method, we must use\nx1to construct a prior \u00161for each that makes Upqq\nxp\u00161qsmall.\nIf the entries of xandx1are sampled i.i.d. from similar\ndistributions DandD1, respectively, the convexity of Upqq\nx\nsuggests using stochastic optimization ﬁnd a prior \u0016that ap-\nproximately minimizes the expectation Ez\u0012D1nUzp\u0016qusing\nsamples of size ndrawn from x1. We provide a guarantee\nfor a variant of this generic approach that runs online gradi-\nent descent (OGD) with separate learning rates for \u0012and\u001e\non samples drawn without replacement from x1:\nTheorem 5.2 (c.f. Thm. C.2) .IfDandD1have bounded\ndensities with bounded support then there exists an algo-\nrithm optimizing Ux1\ntoverTdatasets x1\ntof sizendrawn\nfromx1PRNwithout replacement that runs in time\nOpmNqand returns a set \u00161ofmLaplace priors s.t. w.h.p.\nEx\u0012DnUxp\u00161q¤ min\n\u0016PLapm\nB;\u001bmin;\u001bmaxEx\u0012DnUxp\u0016q\n\u0000~O\u0002\nTVqpD;D1q\u0000cmn\nN\n(8)\nwhere LapB;\u001bmin;\u001bmaxis the set of Laplace priors with loca-\ntions inr\bBsand scales inr\u001bmin;\u001bmaxsandTVqpD;D1q\nis the total variation distance between the joint distribu-\ntions of the order statistics \npxrtqinus;xrtqinu\u00001sq(m\ni\u00101for\nx\u0012Dnand!\npx1\nrtqinus;x1\nrtqinu\u00001sq)m\ni\u00101forx1\u0012D1n.\nFigure 2. Public-private release of nine quantiles using one hun-\ndred samples from the Adult age (left) and hours (right) datasets.\nThe public data is the Adult training set while private data is test.\nFigure 3. Public-private release of nine quantiles on one hundred\nsamples from the Goodreads rating (left) and page count (right)\ndatasets, with \"\u00101. The public data is the “History” genre while\nprivate data is sampled from a mixture of it and “Poetry.”\nForN\"mn, the suboptimality of \u00161for the upper bound\nUxwill depend on the statistical distance between the quan-\ntile intervals of DandD1: even if DandD1are dissimilar,\nsimilar order statistic distributions will ensure good perfor-\nmance. Note, as in Section 4.2, we can hedge against large\nTVqpD;D1qby mixing the output \u00161with a robust prior.\nWe evaluate this approach, which we call Public Fit or\nPubFit , on Adult (Kohavi, 1996) and Goodreads (Wan\n& McAuley, 2018), both used previously for DP quan-\ntiles (Gillenwater et al., 2021; Kaplan et al., 2022). Because\nour guarantees improve with different step-sizes for \u0012and\n\u001e, we use COCOB (Orabona & Tomassi, 2017)—an OGD\nvariant that provably sets per-coordinate step-sizes without\nthe need for tuning—as PubFit ’s stochastic solver. We\nalso test a robust version where its output is mixed with a\nhalf-Cauchy distribution, and three baselines: the Uniform\nprior, just using the quantiles of the public data ( public\nquantiles ), and using the public quantiles to set the loca-\ntion parameters of mCauchy priors ( public Cauchy ).\nAdult tests the D\u0010D1case, with its “train” set the public\ndataset and a hundred samples from “test” as private.\nFigure 2 shows that public quantiles does best at\nsmall\", as is expected with no distribution shift, but it\ncannot adapt to the empirical distribution of a small number\nof private points, and so is worse at \"¡1. Among the\nrest,PubFit is most similar to public-quantiles at\nsmall\"but still does well at large \".\nWe use the Goodreads “History” and “Poetry” genres to\nevaluate under distribution shift by ﬁtting on all but a\n7\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nsmall fraction of data from the former and releasing quan-\ntiles of samples from varying mixtures of the two datasets.\nAs expected, the performance of public quantiles\ndeteriorates with more samples from “Poetry.” For book\nratings, PubFit is best among the remaining methods,\nbut without much change with distribution shift, possibly\ndue to an incomplete ﬁt of the data. For page counts,\nthePubFit methods and public Cauchy both do as\nwell as public-quantiles when most data is from\n“History,” but PubFit (robust) deteriorates least—and\nmuch less than regular PubFit —as the distribution shifts.\nThis highlights the importance of robustness analysis, and\nsuggest the former as a good method to start with, as it takes\nadvantage of similar public and private distributions (Fig. 2)\nwhile never doing much worse than the default method (Uni-\nform) when the the distributions are dissimilar (Fig. 3).\n5.3. Sequentially setting priors using past sensitive data\nOur second application is sequential release, which we do\nnot believe has been studied, but arises naturally if e.g. we\nwish to release daily statistics from a continuous stream of\ndata. Here we have a sequence of datasets x1;:::;xT, each\nwith associated public features f1;:::;fTPRd(e.g. day of\nthe week), and we wish to minimize the average maximum\ngap1\nT°T\nt\u00101maxiGapqipxt;ot;iq, whose expectation can\nbe bounded (7)in terms of1\nT°T\nt\u00101Uxt. For simplicity, we\nassume individuals do not occur in multiple datasets xt, e.g.\nwe are releasing the median age of new users of a service.\nNote the natural way to avoid this assumption is to compose\nthe privacy budgets at each time; empirically our methods\nare especially useful in the low privacy regime this entails.\nOur analysis suggests that we can apply online learning here,\ne.g. doing the following at each tstarting with a prior \u00161:\n1. releaseotusing the prior \u0016tand suffer Gapqpxt;otq\n2. update to \u0016t\u00001using online learning on the loss `pqq\nxt\nBecause`pqq\nxtp\u0012;\u001eq \u0010Upqq\nxtp\u0016\u0012\n\u001e;1\n\u001eqis convex for Laplace\npriors, online convex optimization (OCO) (Shalev-Shwartz,\n2011) lets us compete with the best prior in hindsight accord-\ning to the upper bounds Upqq\nxtp\u0016tq, or with the best linear map\nwto locationsxw;fty. We can again hedge against poor\npredictions by mixing with a constant robust distribution.\nHowever, we face the difﬁculty that online learning on losses\n`pqq\nxtleaks information about xt. There are two natural solu-\ntions. One is to use part of the budget \"1 \"on a DP online\nlearner (Jain et al., 2012; Smith & Thakurta, 2013) and hope\nthat the reduction in budget allocated to quantile release is\nmade up for by the improved priors. Alternatively, we can\nreplace`with a proxy loss^`that does not depend on the data\nand optimize it using regular OCO. The ﬁrst can be done\nwith provable guarantees by applying DP-FTRL (Kairouz\net al., 2021), again using two different step-sizes:Theorem 5.3 (c.f. Thm. C.3) .Consider a sequence of\ndatasets xtPr\bBsntwith bounded features ftand suppose\nwe set Laplace priors \u0016t;i\u0010\u0016xvt;i;fty\n\u001et;i;1\n\u001et;ivia two DP-\nFTRL algorithms applied separately to the variables viand\n\u001eiof the losses`xtpxvi;fty;\u001eiqwith budgets\"1\n2, with respec-\ntive step-sizes ~\u0002\u0001b\n\"1\n\u001b2\nminTam\nd\t\nand~\u0002\u0001b\n\"1?m\n\u001b2\nmin\u001b2maxT\t\n.\nThis isp\"1;\u000e1q-DP and w.h.p. has regret\n1\nTT¸\nt\u00101Uxtp\u0016tq\u0001 min\nwiPr\bBsd\n\u001biPr\u001bmin;\u001bmaxs1\nTT¸\nt\u00101Uxtp\u0016xwi;fty;\u001biq\n\u0010~O\u0004\n\u0005d3\n4\u0000\u001bmax\n\u001bmind\nm\n\"1Tc\nmlog2\n\u000e1\f\n\r(9)\nThus we can do as well as any sequence of Laplace priors\n\u0016twith locations determined by a ﬁxed linear map from\nft, up to a term that decreases at rate ~Op1?\nTq. Furthermore,\nrunning quantile release with budget \"\u0001\"1ensures\np\";\u000e1q-DP for each dataset xt. Note that using different\nstep-sizes allows us to separate the difﬁculty of learning\nad-dimensional linear map from the difﬁculty of learning\na scale parameter of magnitude at most \u001bmax.\nUnfortunately, DP-FTRL is too noisy to learn competitive\npriors, except with a lot of stationary data (c.f. Fig. 4 (left)).\nOne issue is that its DP guarantee is too strong, as it it\nallows swapping out the entire dataset xtrather than a\nsingle entry. It is unclear if a better sensitivity is possible for\nUxt, as changing an entry can ﬂip the sign of the gradient\nwhile preserving magnitude. We show (c.f. Lem. B.1) that it\nis possible for the \"-dependent bound Up\"q\nxtover piecewise-\nconstant priors—remarkably sensitivity decreases with\n\"—but that upper bound is non-convex for location-scale\nfamilies, which are preferable for model learning.\nOur second solution involves recognizing that Upqq\nxtdepends\nonly on the optimal interval rxtrtqnus;xtrtqnu\u00001sq, whose\nlocation and size we have (public) estimates for: the former\nvia the quantile estimate otand the size is lower-bounded by\nthe underlying data discretization, which we have access to\nin-practice (e.g. age is reported in years, bicycle trip length\nin seconds). We use this information to construct proxy\nlosses ^`pqq\notpxv;fty;\u001eq, which do not depend on xtand so\nbe learned with (standard) OCO. As our DP-FTRL analysis\nagain showed the importance of different step-sizes, we\nagain use the COCOB optimizer here.\nWe evaluate sequential release on three online tasks, each\nconsisting of a sequence of datasets needing quantiles:\n1.Synthetic: each dataset is generated such that the quan-\ntiles are ﬁxed linear functions of a random Gaussian\nfeature vector, plus noise.\n8\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\n2.CitiBike: the data are the lengths of a day’s bicycle trips,\nwith the date and NYC weather information features.\n3.BBC: the data are the Flesch readability scores of the\ncomments on a headline posted to Reddit’s worldnews\nforum, with date and headline text information features.\nIn addition to the proxy approach, which we call PubProx ,\nwe evaluate static priors—the uniform, Cauchy, and\nhalf-Cauchy (if nonnegative)—and an approach we call\nPubPrev , which uses a Laplace prior centered around the\nprevious step’s released quantile. Note that using the Uni-\nform is equivalent to ApproximateQuantiles (AQ).\nFor both PubProx andPubPrev we ensure robustness by\nmixing with a Cauchy (or half-Cauchy, if nonnegative) dis-\ntribution with coefﬁcient 0.1; this nearly always improves\nperformance for these methods, likely by ensuring their\ntraining data is not too noisy. To see its effectiveness, note\nhow in Figure 4 (right) both augmented methods are almost\nalways better when made robust, especially PubPrev ; in\nfact, non-robust PubPrev is unable to do better than Uni-\nform after around day 1600, when the start of the COVID-19\npandemic signiﬁcantly affects bicycle trips.\nOur main comparisons is time-aggregated performance as\na function of \"(c.f. Figs. 5 and 6). All except perhaps Syn-\nthetic demonstrate signiﬁcant improvement by our methods\nover the Uniform (AQ) baseline, especially at small \". On\nSynthetic and CitiBike, both tasks with features for which a\nlinear model should provide some beneﬁt, we see in Figure 5\nthatPubProx is indeed the best across all except perhaps\nthe lowest privacy settings. For BBC, Figure 6 reveals a\nlarge difference between mean and median performance\n(note the difference in y-axis scales), with PubProx doing\nbest for the typical headline but the Cauchy doing better on-\naverage due to better performance on headlines with many\ncomments. The result suggests that in highly noisy settings,\nthe learning-based scheme should help, but it might not over-\ncome the robustness of a static Cauchy prior in-expectation.\nOverall, the results demonstrate the strength of the Cauchy\nand half-Cauchy priors, both as unbounded substitutes\nfor the Uniform and as a means of robustifying learning-\naugmented algorithms. They also demonstrate the utility\nof our upper bound in providing an objective for learning,\nalbeit using proxy data rather the DP online learning:\nPubProx usually does better than PubPrev despite using\nthe same information. Overall, PubProx performs the best\nat most privacy levels in all evaluation settings (Synthetic,\nCitiBike, and BBC) except when the mean is used as the\nmetric for BBC (Fig. 6, left), where it does almost as well as\nthe best. Narrowing the performance gap with non-private\nOCO (c.f. Fig. 4 (left), where we run COCOB directly on\n`pqq\nxt)—remains an important research direction.\nCode to reproduce our results is available at https://\ngithub.com/mkhodak/private-quantiles .\nFigure 4. Comparison of sequential release over time on Synthetic\n(left,log10\"\u0010\u00011{2) and CitiBike (right, log10\"\u0010\u00012) tasks.\nFigure 5. Time-averaged performance of the sequential release of\nnine quantiles on the Synthetic (left) and CitiBike (right) tasks.\nFigure 6. Time-aggregated mean (left) and median (right) perfor-\nmance of sequential release of nine quantiles on the BBC task.\n6. Conclusion\nThis work introduces the framework of private algorithms\nwith private predictions, an extension of the algorithms with\npredictions setup to DP methods. Using the application\nof multiple quantile release, we provide strong theoretical\nand empirical evidence of its utility as a way of integrating\nexternal information in privacy-preserving algorithms. We\nbelieve this way of studying DP methods is highly appli-\ncable and will see a great deal of future work in ﬁnding\nnew applications for incorporating predictions or improv-\ning the approaches described here. Some speciﬁc areas to\nexplore include other important dataset statistics (Biswas\net al., 2020) and iterative data analysis methods (Gupta et al.,\n2012; Hardt & Rothblum, 2010) and . For multiple quantile\nrelease, our work directly suggests open questions, includ-\ning obtaining algorithms with poly-logarithmic dependence\nonm, more natural prior adaptation schemes, and ways to\nuse non-independent priors.\nAcknowledgments\nThis work was supported in part by a Facebook PhD\nFellowship.\n9\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nReferences\nAgarwal, N. and Singh, K. The price of differential privacy\nfor online learning. In Proceedings of the 34th Interna-\ntional Conference on Machine Learning , 2017.\nAmid, E., Ganesh, A., Mathews, R., Ramaswamy, S., Song,\nS., Steinke, T., Suriyakumar, V . M., Thakkar, O., and\nThakurta, A. Public data-assisted mirror descent for pri-\nvate model training. In Proceedings of the 39th Interna-\ntional Conference on Machine Learning , 2022.\nAnand, K., Ge, R., and Panigrahi, D. Customizing ML pre-\ndictions for online algorithms. In Proceedings of the 37th\nInternational Conference on Machine Learning , 2020.\nAndrew, G., Thakkar, O., McMahan, H. B., and Ra-\nmaswamy, S. Differentially private learning with adaptive\nclipping. In Advances in Neural Information Processing\nSystems , 2021.\nBalcan, M.-F., Khodak, M., Sharma, D., and Talwalkar,\nA. Learning-to-learn non-convex piecewise-Lipschitz\nfunctions. In Advances in Neural Information Processing\nSystems , 2021.\nBamas, E., Maggiori, A., and Svensson, O. The primal-dual\nmethod for learning augmented algorithms. In Advances\nin Neural Information Processing Systems , 2020.\nBassily, R., Mohri, M., and Suresh, A. T. Private domain\nadaptation from a public source. arXiv, 2022.\nBie, A., Kamath, G., and Singhal, V . Private estimation\nwith public data. In Advances in Neural Information\nProcessing Systems , 2022.\nBiswas, S., Dong, Y ., Kamath, G., and Ullman, J. Coin-\nPress: Practical private mean and covariance estimation.\nInAdvances in Neural Information Processing Systems ,\n2020.\nBoucheron, S., Lugosi, G., and Massart, P. Concentration\nInequalities: A Nonasymptotic Theory of Independence .\nCaledon Press, 2012.\nBurridge, J. A note on maximum likelihood estimation for\nregression models using grouped data. Journal of the\nRoyal Statistical Society. Series B (Methodological) , 43\n(1):41–45, 1981.\nCesa-Bianchi, N., Conconi, A., and Gentile, C. On the gen-\neralization ability of on-line learning algorithms. IEEE\nTransactions on Information Theory , 50(9):2050–2057,\n2004.\nChaudhuri, K. and Vinterbo, S. A. A stability-based valida-\ntion procedure for differentially private machine learning.\nInAdvances in Neural Information Processing Systems ,\n2013.Chen, J. Y ., Silwal, S., Vakilian, A., and Zhang, F. Faster\nfundamental graph algorithms via learned predictions.\nInProceedings of the 40th International Conference on\nMachine Learning , 2022.\nChristianson, N., Shen, J., and Wierman, A. Optimal\nrobustness-consistency tradeoffs for learning-augmented\nmetrical task systems. In Proceedings of the 26th Interna-\ntional Conference on Artiﬁcial Intelligence and Statistics ,\n2023.\nCover, T. M. Universal portfolios. Mathematical Finance ,\n1:1–29, 1991.\nCule, M. and Samworth, R. Theoretical properties of the\nlog-concave maximum likelihood estimator of a multi-\ndimensional density. Electronic Journal of Statistics , 4:\n254–270, 2010.\nDavid, H. A. and Nagaraja, H. N. Order Statistics . John\nWiley & Sons, Inc., 2003.\nDiakonikolas, I., Kontonis, V ., Tzamos, C., Vakilian, A.,\nand Zariﬁs, N. Learning online algorithms with distribu-\ntional advice. In Proceedings of the 38th International\nConference on Machine Learning , 2021.\nDimitrakakis, C., Nelson, B., Zhang, Z., Mitrokotsa, A.,\nand Rubinstein, B. I. P. Differential privacy for bayesian\ninference through posterior sampling, 2017.\nDinitz, M., Im, S., Lavastida, T., Moseley, B., and Vassilvit-\nskii, S. Faster matchings via learned duals. In Advances\nin Neural Information Processing Systems , 2021.\nDu, E., Wang, F., and Mitzenmacher, M. Putting the “learn-\ning” into learning-augmented algorithms for frequency\nestimation. In Proceedings of the 38th International Con-\nference on Machine Learning , 2021.\nD¨utting, P., Lattanzi, S., Leme, R. P., and Vassilvitskii, S.\nSecretaries with advice. In Proceedings of the 22nd ACM\nConference on Economics and Computation , 2021.\nDwork, C. and Roth, A. The algorithmic foundations of dif-\nferential privacy. Foundations and Trends in Theoretical\nComputer Science , 9(3-4):211–407, 2014.\nGeumlek, J., Song, S., and Chaudhuri, K. R ´enyi differential\nprivacy mechanisms for posterior sampling. In Advances\nin Neural Information Processing Systems , 2017.\nGillenwater, J., Joseph, M., and Kulesza, A. Differentially\nprivate quantiles. In Proceedings of the 38th International\nConference on Machine Learning , 2021.\nGupta, A., Roth, A., and Ullman, J. Iterative constructions\nand private data release. In Theory of Cryptography\nConference , 2012.\n10\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nHardt, M. and Rothblum, G. A multiplicative weights mech-\nanism for privacy-preserving data analysis. In 51st An-\nnual IEEE Symposium on Foundations of Computer Sci-\nence, 2010.\nHazan, E., Agarwal, A., and Kale, S. Logarithmic regret al-\ngorithms for online convex optimization. Machine Learn-\ning, 69:169–192, 2007.\nIndyk, P., Mallmann-Trenn, F., Mitrovi ´c, S., and Rubinfeld,\nR. Online page migration with ML advice. In Proceed-\nings of the 25th International Conference on Artiﬁcial\nIntelligence and Statistics , 2022.\nJain, P., Kothari, P., and Thakurta, A. Differentially pri-\nvate online learning. In Proceedings of the 25th Annual\nConference on Learning Theory , 2012.\nJiang, Z., Panigrahi, D., and Sun, K. Online algorithms for\nweighted paging with predictions. In Proceedings of the\n47th International Colloquium on Automata, Languages,\nand Programming , 2020.\nKairouz, P., McMahan, B., Song, S., Thakkar, O., Thakurta,\nA., and Xu, Z. Practical and private (deep) learning\nwithout sampling or shufﬂing. In Proceedings of the 38th\nInternational Conference on Machine Learning , 2021.\nKaplan, H., Schnapp, S., and Stemmer, U. Differentially\nprivate approximate quantiles. In Proceedings of the 39th\nInternational Conference on Machine Learning , 2022.\nKhodak, M., Balcan, M.-F., Talwalkar, A., and Vassilvitskii,\nS. Learning predictions for algorithms with predictions.\nInAdvances in Neural Information Processing Systems ,\n2022.\nKivinen, J. and Warmuth, M. K. Exponentiated gradient\nversus gradient descent for linear predictors. Information\nand Computation , 132:1–63, 1997.\nKohavi, R. Scaling up the accuracy of Naive-Bayes classi-\nﬁers: a decision-tree hybrid. In Proceedings of the Second\nInternational Conference on Knowledge Discovery and\nData Mining , 1996.\nKraska, T., Beutel, A., Chi, E. H., Dean, J., and Polyzotis,\nN. The case for learned index structures. In Proceedings\nof the 2018 International Conference on Management of\nData , 2018.\nKumar, R., Purohit, M., and Svitkina, Z. Improving online\nalgorithms via ML predictions. In Advances in Neural\nInformation Processing Systems , 2018.\nLattanzi, S., Lavastida, T., Moseley, B., and Vassilvitskii, S.\nOnline scheduling via learned weights. In Proceedings of\nthe 2020 ACM-SIAM Symposium on Discrete Algorithms ,\n2020.Li, T., Zaheer, M., Reddi, S., and Smith, V . Private adaptive\noptimization with side information. In Proceedings of\nthe 39th International Conference on Machine Learning ,\n2022.\nLindermayr, A. and Megow, N. Permutation predictions\nfor non-clairvoyant scheduling. In Proceedings of the\n34th ACM Symposium on Parallelism in Algorithms and\nArchitectures , 2022.\nLiu, T., Vietri, G., Steinke, T., Ullman, J., and Wu, Z. S.\nLeveraging public data for practical private query release.\nInProceedings of the 38th International Conference on\nMachine Learning , 2021.\nLiu, Z., Chen, Y ., Bash, C., Wierman, A., Gmach, D., Wang,\nZ., Marwah, M., and Hyser, C. Renewable and cooling\naware workload management for sustainable data centers.\nInACM SIGMETRICS Performance Evaluation Review ,\n2012.\nLoper, E. and Bird, S. NLTK: The natural language toolkit.\narXiv, 2002.\nLykouris, T. and Vassilvitskii, S. Competitive caching with\nmachine learned advice. Journal of the ACM , 68(4), 2021.\nMcMahan, H. B. A survey of algorithms and analysis for\nadaptive online learning. Journal of Machine Learning\nResearch , 18, 2017.\nMcSherry, F. and Talwar, K. Mechanism design via differ-\nential privacy. In Proceedings of the 48th Annual IEEE\nSymposium on Foundations of Computer Science , 2007.\nMitzenmacher, M. and Vassilvitskii, S. Algorithms with\npredictions. In Roughgarden, T. (ed.), Beyond the Worst-\nCase Analysis of Algorithms . Cambridge University Press,\nCambridge, UK, 2021.\nOrabona, F. and Tomassi, T. Training deep networks without\nlearning rates through coin betting. In Advances in Neural\nInformation Processing Systems , 2017.\nPennington, J., Socher, R., and Manning, C. D. GloVe:\nGlobal vectors for word representation. In Proceedings\nof the 2014 Conference on Empirical Methods in Natural\nLanguage Processing , 2014.\nPratt, J. W. Concavity of the log likelihood. Journal of\nthe American Statistical Association , 76(373):103–106,\n1981.\nRohatgi, D. Near-optimal bounds for online caching with\nmachine learned advice. In Proceedings of the 2020\nACM-SIAM Symposium on Discrete Algorithms , 2020.\nRoughgarden, T. Beyond Worst-Case Analysis of Algorithms .\nCambridge University Press, 2020.\n11\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nSakaue, S. and Oki, T. Discrete-convex-analysis-based\nframework for warm-starting algorithms with predictions.\nInAdvances in Neural Information Processing Systems ,\n2022.\nScully, Z., Grosof, I., and Mitzenmacher, M. Uniform\nbounds for scheduling with job size estimates. In Pro-\nceedings of the 13th Innovations in Theoretical Computer\nScience Conference , 2022.\nSeeman, J., Slavkovic, A., and Reimherr, M. Private pos-\nterior inference consistent with public information: A\ncase study in small area estimation from synthetic census\ndata. In Proceedings of the International Conference on\nPrivacy in Statistical Databases , 2020.\nShalev-Shwartz, S. Online learning and online convex opti-\nmization. Foundations and Trends in Machine Learning ,\n4(2):107–194, 2011.\nSmith, A. and Thakurta, A. (Nearly) optimal algorithms\nfor private online learning in full-information and bandit\nsettings. In Advances in Neural Information Processing\nSystems , 2013.\nWan, M. and McAuley, J. J. Item recommendation on\nmonotonic behavior chains. In Proceedings of the 12th\nACM Conference on Recommender Systems , 2018.\nYu, C., Shi, G., Chung, S.-J., Yue, Y ., and Wierman, A. Com-\npetitive control with delayed imperfect information. In\nProceedings of the American Control Conference , 2022.\nZinkevich, M. Online convex programming and generalized\ninﬁnitesimal gradient ascent. In Proceedings of the 20th\nInternational Conference on Machine Learning , 2003.\n12\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nA. Section 3 details\nA.1. Quantile estimation via a prediction-dependent prior\nThe base measure \u0016of DP mechanisms such as the exponential is the starting point of many approaches to incorporating\nexternal information, especially ones focused on Bayesian posterior sampling (Dimitrakakis et al., 2017; Geumlek et al.,\n2017; Seeman et al., 2020); while it is also our approach to single-quantile estimation with predictions, a key difference here\nis the focus on utility guarantees depending on both the prediction and instance, which is missing from this past work. In the\nquantile problem, given a quantile qand a sorted dataset xPRnofndistinct points, the goal is to release a number othat\nupper bounds exactly tqnuof the entries. A natural error metric, Gapqpx;oq, is the number of entries between the released\nnumberoand tqnu, and we can show that prediction-dependent bound using astraightforward application of EM with utility\n\u0001Gapq:\nLemma A.1. ReleasingoPRw.p.9expp\u0001\"Gapqpx;oq{2q\u0016poqis\"-DP , and w.p. 1\u0001\f\nGapqpx;oq¤2\n\"\u0002\nlog1\n\f\u0001log \tpq;\"q\nxp\u0016q\n¤2\n\"\u0002\nlog1\n\f\u0001log \tpqq\nxp\u0016q\n(10)\nwhere \tpq;\"q\nxp\u0016q \u0010°n\ni\u00100expp\u0001\"Gapqpx;Iiq{2q\u0016pIiq \u0010³\nexpp\u0001\"Gapqpx;oq{2q\u0016poqdois the inner product\nbetween\u0016and the exponential score while \tpqq\nxp\u0016q \u0010\u0016pItqnuqis the measure of the optimal interval (note\nmaxkuqpx;Ikq\u0010\u0001 Gapqpx;Itqnuq\u00100and so \tpqq\nxp\u0016q¤\tpq;\"q\nxp\u0016q@\"¡0).\nProof.\"-DP follows from uqhaving sensitivity one and the guarantee of EM with base measure \u0016(McSherry & Talwar,\n2007, Theorem 6). For the error, since we sample an interval Ikand then sample oPIkwe have\nPrtGapqpx;oq¥\ru\u0010Prtuqpx;Ikq¤\u0001\ru\u0010n¸\nj\u00100Prtk\u0010ju1uqpx;Ijq¤\u0001\r\n¤n¸\nj\u00100expp\u0001\"\r\n2q\u0016pIjq°n\ni\u00100expp\"\n2uqpx;Iiqq\u0016pIiq¤expp\u0001\"\r\n2q\n\tpq;\"q\nxp\u0016q(11)\nThe result follows by substituting \ffor the failure probability and solving for \r.\nWe can also analyze the error metrics in this bound for speciﬁc measures \u0016. In particular, if the points are in a bounded interval\npa;bqand we use the uniform measure \u0016poq\u00101oPpa;bq{pb\u0001aqthen\tpq;\"q\nxp\u0016q¥ x\nb\u0001a, where x\u0010minkxrk\u00001s\u0001xrks,\nand we exactly recover the standard bound of2\n\"logb\u0001a\n\f x, e.g. the one in (Kaplan et al., 2022, Lemma A.1) (indeed their\nanalysis implicitly uses this measure). However, our approach also allows us to remove the boundedness assumption, which\nitself can be viewed as a type of prediction, as one needs external information to assume that the data, or at least the quantile,\nlies within the interval pa;bq. Taking this view, we can use the prediction to set the location \u0017PRand scale\u001b¡0of a\nCauchy prior \u0016\u0017;\u001bpoq\u0010\u001b{p\u0019p\u001b2\u0000po\u0001\u0017q2qqwithout committing to pa;bqactually containing the data. Since we know\nthat the optimal interval pxrtqnus;xrtqnu\u00001ssis a subset ofpa\u0000b\n2\bRqfor someR¡0, setting\u0017\u0010a\u0000b\n2and\u001b\u0010b\u0001a\n2yields\n\tpqq\nxp\u0016\u0017;\u001bq¥\u001b\n\u0019xrtqnu\u00001s\u0001xrtqnus\n\u001b2\u0000maxkPttqnu;tqnu\u00001up\u0017\u0001xrksq2¥\u001b\n\u0019min\nkxrk\u00001s\u0001xrks\n\u001b2\u0000R2¥2pb\u0001aq x{\u0019\npb\u0001aq2\u00004R2(12)\nIfR\u0010b\u0001a\n2, i.e. we get the interval containing the data correct, then substituting the above into Lemma A.1 recovers\nthe guarantee of the uniform prior up to an additive factor2\n\"log\u0019. However, whereas for the uniform prior we have no\nperformance guarantees if the interval is incorrect, using the Cauchy prior the performance degrades gracefully as the error\n(R) grows. While this ﬁrst result can be viewed as designing a better prediction-free algorithm, it can also be viewed as\nmaking more robust use of the external information about the interval containing the data.\n13\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nA.2. Multiple-quantile release using multiple priors\nTo estimate m¡1quantilesq1;:::;qmat once, we adapt the recursive approach of (Kaplan et al., 2022), whose method\nApproximateQuantiles implicitly constructs a binary tree with a quantile qiat each node and uses the exponential\nmechanism to compute the quantile ~qi\u0010pqi\u0001qiq{pqi\u0001qiqof the dataset ^ xiof points in the original dataset xrestricted\nto the interval p^ai;^biq; hereqi qiandqi¡qiare quantiles appearing earlier in the tree whose respective estimates ^ai\nand^bidetermine the sub-interval (if there is no earlier quantile on the left and/or right of qiwe useqi\u00100;^ai\u0010aand/or\nqi\u00101;^bi\u0010b). Because each datapoint only participates in Oplog2mqexponential mechanisms, the approach is able to run\neach mechanism with budget \np\"{log2mqand thus only suffer error logarithmic in the number of quantiles m, a signiﬁcant\nimprovement upon running one EM with budget \"{mon the entire dataset for each quantile, which has error Opmqin the\nnumber of quantiles.\nWe can apply prior-dependent guarantees to ApproximateQuantiles —pseudocode for a generalized version of which\nis provided in Algorithm 2—by recognizing that implicitly the method assigns a uniform prior \u0016ito each quantile qiand\nthen running EM with the conditional prior ^\u0016irestricted to the interval r^ai;^bisdetermined by earlier quantiles in the binary\ntree. An extension of the argument in Equation 11 (c.f. Lemma A.2) then yields a bound on the error of the estimate oi\nreturned for quantile qiin terms of the prior-EM inner-product computed with this conditional prior ^\u0016iover the subset ^ xi:\nPrtGapqipx;oiq¥\ru¤exp\u0000\"i\n2p^\ri\u0001\rq\b\n\tp~qi;\"iq\n^ xip^\u0016iqfor ^\ri\u0010p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq (13)\nNote that the error is offset by a weighted combination ^\riof the errors of the estimates of quantiles earlier in the tree.\nControlling this error allows us to bound the maximum error of any quantile via the harmonic mean of the inner products\nbetween the exponential scores and conditional priors:\nLemma A.2. Algorithm 2 with K\u00102and\"i\u0010\"{rlog2ms@iis\"-DP and w.p.¥1\u0001\fhas\nmax\niGapqipx;oiq¤2\n\"rlog2ms2logm\n\f^\tp\"q\nxfor ^\tp\"q\nx\u0010\u0003m¸\ni\u001011{m\n\tp~qi;\"iq\n^ xip^\u0016iq\u000b\u00011\n(14)\nProof. The privacy guarantee follows as in (Kaplan et al., 2022, Lemma 3.1). Setting the above probability bound (13) to\n\f^\tp\"q\nx\nm\tp\"iq\n~qip^ xi;^\u0016iqfor eachiwe have w.p.¥1\u0001\fthatGapqipx;oiq¤2\n\u0016\"logm\n\f^\tp\"q\nx\u0000^\ri@i. Now letkibe the depth of quantile\nqiin the tree. If ki\u00101theniis the root node so ^\ri\u00100and we have Gapqipx;oiq¤2\n\u0016\"logm\n\f^\tp\"q\nx. To make an inductive\nargument, we assume Gapqipx;oiq¤2k\n\u0016\"logm\n\f^\tp\"q@is.t.ki¤k, and so for any is.t.ki\u0010k\u00001we have that\nGapqipx;oiq¤2\n\u0016\"logm\n\f^\tp\"q\nx\u0000p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq¤2pk\u00001q\n\u0016\"logm\n\f^\tp\"q\nx(15)\nThus Gapqipx;oiq¤2ki\n\u0016\"logm\n\f^\tp\"q\nx@i, so usingki¤rlog2msand\u0016\"\u0010\"\nrlog2msyields the result.\nSetting ^\u0016ito be uniform on r^ai;^bisexactly recovers both the algorithm and guarantee of (Kaplan et al., 2022, Theorem 3.3).\nAs before, we can also extend the algorithm to the inﬁnite interval:\nCorollary A.1. If all priors are Cauchy with locationa\u0000b\n2and scaleb\u0001a\n2and the data lies in the interval pa\u0000b\n2\bRqthen\nw.p.¥1\u0001\fthe maximum error is at most2\n\"rlog2ms2log\u0002\n\u0019mb\u0001a\u00004R2\nb\u0001a\n2\f x\n.\nHowever, while this demonstrates the usefulness of Lemma A.2 for obtaining robust priors on inﬁnite intervals, the associated\nprediction measure ^\tp\"q\nxis imperfect because it is non-deterministic: its value depends on the random execution of the\nalgorithm, speciﬁcally on the data subsets ^ xiand priors ^\u0016i, which forinot at the root of the tree are affected by the DP\nmechanisms of i’s ancestor nodes. In addition to not being given fully speciﬁed by the prediction and data, this makes ^\tp\"q\ndifﬁcult to use as an objective for learning. A natural more desirable prediction metric is the harmonic mean of the inner\nproducts between the exponential scores and original priors\u0016iover the original dataset x, i.e. the direct generalization of\nour approach for single quantiles.\n14\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nUnfortunately, the conditional restriction of \u0016ito the interval r^ai;^bisremoves the inﬂuence of probabilities assigned to\nintervals between points notin this interval. To solve this, we propose a different edge -restriction of \u0016ithat assigns\nprobabilities \u0016ipp\u00018;^aiqqand\u0016ipp^bi;8qq of being outside the interval r^ai;^bisto atoms on its edges ^aiand^bi, respectively.\nDespite not using any information from points outside ^ xi, this approach puts probabilities assigned to intervals outside\nr^ai;^bisto the edge closest to them, allowing us to extend the previous probability bound (13) to depend on the original\nprior-EM inner-product (c.f. Lemma D.3):\nPrtGapqipx;oiq¥\ru¤expp\"p^\ri\u0001\r{2qq{\tpqi;\"iq\nxp\u0016iq (16)\nHowever, the stronger dependence of this bound on errors ^\riearlier in the tree lead to an ~Op\u001elog2mq\u0010Opm0:7qdependence\nonm, where\u001e\u00101\u0000?\n5\n2is the golden ratio:\nTheorem A.1. If the quantiles are uniform negative powers of two then Algorithm 2 with K\u00102, edge-based prior\nadaptation, and \"i\u0010\"{rlog2pm\u00001qs@iis\"-DP and w.p.¥1\u0001\fhas\nmax\niGapqipx;oiq¤2\n\"\u001elog2pm\u00001qrlog2pm\u00001qslogm\n\f\tp\"q\nxfor \tp\"q\nx\u0010\u0003m¸\ni\u001011{m\n\tpqi;\"iq\nxp\u0016iq\u000b\u00011\n(17)\nProof. Since ~qi\u00101{2@i, setting the new probability bound equal to\f\tp\"q\nx\nm\tpqi\"iq\nxp\u0016iqyields that w.p. ¥1\u0001\f\nGapqipx;oiq¤2\n\u0016\"logm\n\f\tp\"q\nx\u00002^\ri\u00102\n\u0016\"logm\n\f\tp\"q\nx\u0000Gapqipx;^aiq\u0000Gapqipx;^biq@i (18)\nIf for eachk¤rlog2mswe deﬁneEkto be the maximum error of any quantile of at most depth kin the tree then since one\nofqiandqiis at depth at least one less than qiand the other is at depth at least two less than qiwe haveEk¤2Ak\n\u0016\"logm\n\f\tp\"q\nxfor recurrent relation Ak\u00101\u0000Ak\u00011\u0000Ak\u00012withA0\u00100andA1\u00101. SinceAk\u0010Fk\u00001\u00011for Fibonacci sequence\nFj\u0010\u001ej\u0001p1\u0001\u001eqj\n?\n5, we have\nmax\niGapqipx;oiq\u0010max\nkEk¤2\u001erlog2pm\u00001qs\u00001\n\u0016\"?\n5logm\n\f\tp\"q\nx\u00102\u001erlog2pm\u00001qs\u00001\n\"?\n5rlog2pm\u00001qslogm\n\f\tp\"q\nx(19)\nThus while we have obtained a performance guarantee depending only on the prediction and the data via the harmonic\nmean \tp\"q\nxof the true prior-EM inner-products, the dependence on mis now polynomial. Note that it is still sublinear,\nwhich means it is better than the naive baseline of running mindependent exponential mechanisms. Still, we can do much\nbetter—in-fact asymptotically better than any power of m—by recognizing that the main issue is the compounding error\ninduced by successive errors to the boundaries of sub-intervals. We can reduce this by reducing the depth of the tree using\naK-ary rather than binary tree and instead paying K\u00011times the privacy budget at each depth in order to naively release\nvalues forK\u00011quantiles. This can introduce out-of-order quantiles, but by Lemma D.4 swapping any two out-of-order\nquantiles does not increase the maximum error and so this issue can be solved by sorting the K\u00011quantiles before using\nthem to split the data. We thus have the following prediction-dependent performance bound for multiple quantiles:\nTheorem A.2. If we run Algorithm 2 with K\u0010rexppa\nlog 2 logpm\u00001qqs, edge-based adaptation, and \"i\u0010\u0016\"\nkp\nifor some\npowerp¡1,kithe depth of qiin theK-ary tree, and \u0016\"\u0010\"\nK\u00011\u0001°rlogKpm\u00001qs\nk\u001011\nkp\t\u00011\n, then the result satisﬁes \"-DP\nand w.p.¥1\u0001\fwe have maxiGapqipx;oiq¤2\u00192\n\"exp\u0001\n2a\nlogp2qlogpm\u00001q\t\nlogm\n\f\tp\"q\nxifp\u00102and more generally\nmaxiGapqipx;oiq¤cp\n\"exp\u0001\n2a\nlogp2qlogpm\u00001q\t\nlogm\n\f\tp\"q\nx, wherecpdepends only on p.\n15\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nProof. The privacy guarantee follows as in (Kaplan et al., 2022, Lemma 3.1) except before each split we compute K\u00011\nquantiles with K\u00011times less budget. As in the previous proof, we have w.p. ¥1\u0001\fthat\nGapqipx;oiq¤2\n\"ilogm\n\f\tp\"q\nx\u00002^\ri\u00102k2\ni\n\u0016\"logm\n\f\tp\"q\nx\u00002p1\u0001~qiqGapqipx;^aiq\u00002~qiGapqipx;^biq@i (20)\nIf for eachk¤rlogKpm\u00001qswe deﬁneEkto be the maximum error of any quantile of at most depth kin the tree then\nsince bothqiandqiare at depth at least one less than qiwe haveEk¤2Ak\n\u0016\"logm\n\f\tp\"q\nx, whereAk\u0010kp\u00002Ak\u00011and\nA1\u00101. For the case of p\u00102,Ak¤6\u00042kand1{\u0016\"\u0010K\u00011\n\"°rlogKpm\u00001qs\nk\u001011\nk2¤\u00192\n6\"pK\u00011qso we have that\nmax\niGapqipx;oiq\u0010max\nkEk¤12\n\u0016\"2rlogKpm\u00001qslogm\n\f\tp\"q\nx¤2\u00192\n\"pK\u00011q2rlogKpm\u00001qslogm\n\f\tp\"q\nx(21)\nSubstituting K\u0010rexppa\nlog 2 logpm\u00001qqsand simplifying yields the result. For p¡1,Ak¤2k\u00012\u0000\n2\u0000\b\u00001\n2;\u0001p;2\b\b\n,\nwhere \bis the Lerch transcendent, and 1{\u0016\"¤K\u00011\n\"\u0010ppq, where\u0010is the Riemann zeta function. Therefore\nmax\niGapqipx;oiq\u0010max\nkEk¤2rlogKpm\u00001qs\n2\u0016\"\u0002\n2\u0000\b\u00021\n2;\u0001p;2\n\nlogm\n\f\tp\"q\nx¤cp\n\"pK\u00011q2rlogKpm\u00001qslogm\n\f\tp\"q\nx\n(22)\nforcp\u0010\u0000\n1\u0000\b\u00001\n2;\u0001p;2\b\n{2\b\n\u0010ppq.\nSimilarly to Theorem A.1, the proof establishes a recurrence relationship between the maximum errors at each depth.\nNote that in addition to the K-ary tree this bound uses depth-dependent budgeting to remove a Oplog2mq-factor; the\nconstant depending upon the parameter p¡1of the latter has a minimum of roughly 8:42atp\u00131:6. As discussed\nbefore, the new dependence ~O\u0001\nexp\u0001\n2a\nlogp2qlogpm\u00001q\t\t\nonmis sub-polynomial, i.e opm\u000bq@\u000b¡0. While it is\nalso super-polylogarithmic, its shape for any practical value of mis roughly Oplog2\n2mq, making the result of interest as a\njustiﬁcation for the negative log-inner-product performance metric.\nA.3. Experimental details\nFor the experiments in Section 3, speciﬁcally Figures 3, we evaluate three variants of the algorithm on data drawn from a\nstandard Gaussian distribution and from the Adult “age” dataset (Kohavi, 1996). In both cases we use 1000 samples and run\neach experiment 40 times, reporting the average performance. As we do for all datasets, we use reasonable guesses of mean,\nscale, and bounds on each dataset to set priors. As in this section we report the Uniform, we need to specify its range; for\nGaussian we use r\u000110;10s, while for “age” we use r10;120s.\nThe original AQ algorithm of Kaplan et al. (2022) is now fully speciﬁed. We test two variants of our K-ary modiﬁcation:\none with edge-based adaptation, and the other using the original conditional adaptation. For both cases we set Kas a\nfunction ofmaccording to the formula in Theorem 3.3, and we set the power pof the depth-dependent budget discounting\nto 1.5, which is close to the theoretically optimal value of around 1.6 (c.f. Thm A.2).\n16\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nB. Section 4 details\nB.1. Robustness-consistency tradeoffs\nWhile prediction-dependent guarantees work well if the prediction is accurate, without safeguards they may perform catas-\ntrophically poorly if the prediction is incorrect. Quantiles provide a prime demonstration of the importance of robustness, as\nusing priors allows for approaches that may assign very little probability to the interval containing the quantile. For example,\nif one is conﬁdent that it has a speciﬁc value xPpa;bqone can specify a more concentrated prior, e.g. the Laplace distribution\naroundx. Alternatively, if one believes the data is drawn i.i.d. from some a known distribution then \u0016can be constructed via\nits CDF using order statistics (David & Nagaraja, 2003, Equation 2.1.5). These reasonable approaches can result in distri-\nbutions with exponential or high-order-polynomial tails, using which directly may work poorly if the prediction is incorrect.\nLuckily, for our negative log-inner-product error metric it is straightforward to show a parameterized robustness-consistency\ntradeoff by simply mixing the prediction prior \u0016with a robust prior \u001a:\nCorollary B.1. For any prior \u0016:RÞÑR¥0, robust prior \u001a:RÞÑR¥0, and robustness parameter \u0015Pr0;1s, releasing\noPRw.p.9expp\u0001\"Gapqpx;oq{2q\u0016p\u0015qpoqfor\u0016p\u0015q\u0010 p1\u0001\u0015q\u0016\u0000\u0015\u001ais\u0001\n2\n\"log1{\f\n\u0015\tpq;\"q\nxp\u001aq\t\n-robust and\u0001\n2\n\"log1{\f\n1\u0001\u0015\t\n-\nconsistent w.p. ¥1\u0001\f.\nProof. Apply Lemma A.1 and linearity of \tpq;\"q\nxp\u0016p\u0015qq\u0010p 1\u0001\u0015q\tpq;\"q\nxp\u0016q\u0000\u0015\tpq;\"q\nxp\u001aq.\nThus if the interval is ﬁnite and we set \u001ato be the uniform prior, using \u0016p\u0015qin the algorithm will have a high probability\nguarantee at most2\n\"log1\n\u0015-worse than the prediction-free guarantee of Kaplan et al. (2022, Lemma A.1), no matter how\npoor\u0016is for the data, while also guaranteeing w.p. ¥1\u0001\fthat the error will be at most2\n\"log1{\f\n1\u0001\u0015if\u0016is perfect. A similar\nresult holds for the case of an inﬁnite interval if we instead use a Cauchy prior. Corollary B.1 demonstrates the usefulness\nof the algorithms with predictions framework for not only quantifying improvement in utility using external information\nbut also for making the resulting DP algorithms robust to prediction noise.\nThe above argument for single-quantiles is straightforward to extend to the negative log of the harmonic means of the inner\nproducts. In-fact for the binary case with uniform quantiles we can trade-off between polylogpmq-guarantees similar to\nthose of Kaplan et al. (2022) and our prediction-dependent bounds:\nCorollary B.2. Consider priors \u00161;:::;\u0016m:RÞÑR¥0, Cauchy prior \u001a:RÞÑR¥0with locationa\u0000b\n2and scale\nb\u0001a\n2, and robustness parameter \u0015P r0;1s. Then running Algorithm 2 on quantiles that are uniform negative powers\nof two with K\u00102, edge-based prior adaptation, \"i\u0010\u0016\"\u0010\"{rlog2ms@i, and priors \u0016p\u0015q\ni\u0010\u0015\u001a\u0000p1\u0001\u0015q\u0016i@iis\u0002\n2\n\"rlog2ms2log\u0002\n\u0019mb\u0001a\u00004R2\nb\u0001a\n2\u0015\f x\n\n-robust and\u0001\n2\n\"\u001elog2mrlog2mslogm{\f\n1\u0001\u0015\t\n-consistent w.p. ¥1\u0001\f.\nProof. Apply Lemma A.2, Theorem A.1, and the linearity of inner products making up ^\tp\"q\nxand\tp\"q\nx.\nB.2. Learning predictions, privately\nPast work, e.g. the public-private framework (Liu et al., 2021; Bassily et al., 2022; Bie et al., 2022), has often focused\non domain adaptation-type learning where we adapt a public source to private target. We avoid assuming access to large\nquantities of i.i.d. public data and instead assume numerous tasks that can have sensitive data and may be adversarially\ngenerated. As discussed before, this is the online setting where we see loss functions deﬁned by a sequence of datasets\nx1;:::;xTand aim to compete with best ﬁxed prediction in-hindsight. Note such a guarantee can also be converted into\nexcess risk bounds (c.f. Appendix E.1).\nB.2.1. N ON-EUCLIDEAN DP-FTRL\nBecause the optimization domain is not well-described by the `2-ball, we are able to obtain signiﬁcant savings in dependence\non the dimension and in some cases even in the number of instances Tby extending the DP-FTRL algorithm of (Kairouz\net al., 2021) to use non-Euclidean regularizers, as in Algorithm 1. For this we prove the following regret guarantee:\n17\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nTheorem B.1. Let\u00121;:::;\u0012Tbe the outputs of Algorithm 1 using a regularizer \u001e: \u0002ÞÑRthat is strongly-convex w.r.t.\n}\u0004}. Suppose@tPrTsthat`xtp\u0004qisL-Lipschitz w.r.t. }\u0004}and its gradient has `2-sensitivity \u00012. Then w.p.¥1\u0001\f1\nwe have@\u0012\u0006P\u0002that\nT¸\nt\u00101`p\u0012t;xtq\u0001`p\u0012\u0006;xtq¤\u001ep\u0012\u0006q\u0001\u001ep\u00121q\n\u0011\u0000\u0011L\u0003\nL\u0000\u0003\nG\u0000Cd\n2 logT\n\f1\u000b\n\u001b\u00012a\nrlog2Ts\u000b\nT (23)\nwhereG\u0010Ez\u0012Np0p;Ipqsup}y}¤1xz;yy \u0010Ez\u0012Np0p;1q}z}\u0006is the Gaussian width of the unit }\u0004}-ball andCis the\nLipschitz constant of }\u0004}\u0006w.r.t.}\u0004}2. Furthermore, for any \"1¤2 log1\n\u000e1, setting\u001b\u00101\n\"1b\n2rlog2Tslog1\n\u000e1makes the\nalgorithmp\"1;\u000e1q-DP .\nProof. The privacy guarantee follows from past results for tree aggregation (Smith & Thakurta, 2013; Kairouz et al., 2021).\nFor alltPrTswe use the shorthand rt\u0010r\u0012`xtp\u0012tq; we can then deﬁne ~\u0012t\u0010arg min\u0012P\u0002\u001ep\u0012q\u0000\u0011°t\ns\u00101xrs;\u0012yand\nbt\u0010gt\u0001°t\ns\u00101rs. Then\nT¸\nt\u00101`xtp\u0012tq\u0001`xtp\u0012\u0006q¤T¸\nt\u00101xrt;\u0012t\u0001\u0012\u0006y\u0010T¸\nt\u00101xrt;~\u0012t\u0001\u0012\u0006y\u0000T¸\nt\u00101xrt;\u0012t\u0001~\u0012ty\n¤\u001ep\u0012\u0006q\u0001\u001ep\u00121q\n\u0011\u0000\u0011T¸\nt\u00101}rt}2\n\u0006\u0000T¸\nt\u00101}rt}\u0006}~\u0012t\u0001\u0012t}\n¤\u001ep\u0012\u0006q\u0001\u001ep\u00121q\n\u0011\u0000\u0011L\u0003\nLT\u0000T¸\nt\u00101}bt}\u0006\u000b(24)\nwhere the ﬁrst inequality follows from the standard linear approximation in online convex optimization (Zinkevich, 2003),\nthe second by the regret guarantee for online mirror descent (Shalev-Shwartz, 2011, Theorem 2.15), and the last by applying\nMcMahan (2017, Lemma 7) with \u001e1p\u0004q\u0010\u001ep\u0004q\u0000\u0011°t\ns\u00101xrs;\u0004y, p\u0004q\u0010\u0011xbt;\u0004y, and\u001e2p\u0004q\u0010\u001ep\u0004q\u0000\u0011xgt;\u0004y, yielding\n}~\u0012t\u0001\u0012t}¤\u0011}bt}\u0006@tPrTs. The ﬁnal guarantee follows by observing that the tree aggregation protocol adds noise\nbt\u0012Np0p;\u001b2\u00012\n2rlog2tsqto each preﬁx sum and applying the Gaussian concentration of Lipschitz functions (Boucheron\net al., 2012, Theorem 5.6).\nThe above proof of this result follows that of the Euclidean case, which can be recovered by setting G\u0010Op?\ndq,C\u00101,\nand\u00012\u0010OpLq.1In addition to the Lipschitz constants L, a key term that can lead to improvement is the Gaussian width\nGof the unit}\u0004}-ball, which for the Euclidean case is Op?\ndqbut e.g. for}\u0004}\u0010}\u0004} 1isOp?logdq. Note that a related\ndependence on the Laplace width of \u0002appears in Agarwal & Singh (2017, Theorem 3.1), although their guarantee only\nholds for linear losses and is not obviously extendable. Thus Theorem B.1 may be of independent interest for DP online\nlearning.\nB.2.2. L EARNING PRIORS FOR ONE OR MORE QUANTILES\nWe now turn to learning priors \u0016t\u0010\u0000\n\u0016tr1s;\u0004\u0004\u0004;\u0016trms\b\nto privately estimate mquantilesq1;:::;qmon each of a sequence of\nTdatasets xt. We will aim to set \u00161;:::;\u0016Ts.t. if at each time twe run Algorithm 2 with privacy \"¡0then the guarantees\ngiven by Lemmas A.1 and A.2 will be asymptotically at least as good as those of the best set of measures in Fm, where F\nis some class of measures on the ﬁnite interval pa;bq. The latter we will assume to be known and bounded. Note that in this\nsection almost all single-quantile results follow from setting m\u00101, so we study it jointly with learning for multiple quantiles.\nIgnoring constants, the loss functions implied by our prediction-dependent upper bounds for multiple-quantiles are the\nfollowing negative log-harmonic sums of prior-EM inner-products:\nUp\"q\nxtp\u0016q\u0010logm¸\ni\u001011\n\tpqi;\"iq\nxtp\u0016risq\u0010logm¸\ni\u001011\n³b\naexpp\u0001\"iGapqipxt;oq{2q\u0016rispoqdo(25)\n1As of this writing, the most recent arXiv version of Kairouz et al. (2021, Theorem C.1) has a typo leading to missing a Lipschitz\nconstant in the bound, conﬁrmed via correspondence with the authors.\n18\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nAlgorithm 1: Non-Euclidean DP-FTRL. For the InitializeTree ,AddToTree , andGetSum subroutines see\nKairouz et al. (2021, Section B.1).\nInput: Datasets x1;:::;xTarriving in a stream in arbitrary order, domain \u0002Rp, step-size\u0011¡0, noise scale\n\u001b¡0,`2-sensitivity \u00012¡0, regularizer \u001e: \u0002ÞÑR\ng1Ð0p\nTÐInitializeTree (T;\u001b2;\u00012) // start tree aggregation\nfort\u00101;:::;T do\n\u0012tÐarg min\u0012P\u0002\u001ep\u0012q\u0000\u0011xgt;\u0012y\nsuffer`xtp\u0012tq\nTÐAddToTree (T;t;r\u0012`xtp\u0012tq) // add gradient to tree\ngt\u00001ÐGetSum (T;t) // estimate°t\ns\u00101r\u0012`xsp\u0012sq\nWe focus on minimizing regret max\u0016PFm°T\nt\u00101Up\"q\nxtp\u0016tq\u0001Up\"q\nxtp\u0016qover these losses for priors \u0016risin a class FV;dof proba-\nbility measures that are piecewise V-Lipschitz over each of dintervals uniformly partitioning ra;bq. This is chosen because it\ncovers the class FV;1ofV-Lipschitz measures and the class of F0;dof discrete measures that are constant on each of the din-\ntervals. The latter can be parameterized by WP4m\nd, so that the losses have the form Up\"q\nxtp\u0016Wq\u0010log°m\ni\u00101xst;i;Wrissy\u00011\nforst;iPRd\n¥0. This can be seen by setting st;irjs\u0010d\nb\u0001a³a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011qexpp\u0001\"iGapqipxt;oq{2qdoand\n\u0016Wrispoq \u0010d\nb\u0001aWri;jsover the interval\u0010\na\u0000b\u0001a\ndpj\u00011q;a\u0000b\u0001a\ndj\b\n. Finally, for \u0015P r0;1swe also let\nFp\u0015q\u0010tp1\u0001\u0015q\u0016\u0000\u0015\nb\u0001a:\u0016PFudenote the class of mixtures of measures \u0016PFwith the uniform measure.\nAs detailed in Appendix E.2, losses of the form \u0001logxst;\u0004y, i.e. those above when m\u00101, have been studied in (non-private)\nonline learning (Hazan et al., 2007; Balcan et al., 2021). However, specialized approaches, e.g. those taking advantage\nexp-concavity, are not obviously implementable via preﬁx sums of gradients, the standard approach to private online\nlearning (Smith & Thakurta, 2013; Agarwal & Singh, 2017; Kairouz et al., 2021). Still, we can at least use the fact that\nwe are optimizing over a product of simplices to improve the dimension-dependence by applying Non-Euclidean DP-FTRL\nwith entropic regularizer \u001epWq\u0010mxW;logWy, which yields an m-way exponentiated gradient (EG) update (Kivinen\n& Warmuth, 1997). To apply its guarantee for the problem of learning priors for quantile estimation, we need to bound the\nsensitivity of the gradients rWUp\"q\nxtp\u0016Wqto changes in the underlying datasets xt. This is often done via a bound on the\ngradient norm, which in our case is unbounded near the boundary of the simplex. We thus restrict to \r-robust priors for some\n\rPp0;1sby constraining WP4m\ndto have entries lower bounded by \r{d—a domain where }rWUp\"q\nxtp\u0016Wq}1¤d{\r\n(c.f. Lemma E.1)—and bounding the resulting approximation error; we are not aware of even a non-private approach that\navoids this except by taking advantage of exp-concavity (Hazan et al., 2007).\nWe thus have a bound of 2d{\ron the`2-sensitivity. However, this may be too loose since it allows for changing the entire\ndataset xt, whereas we are only interested in changing one entry. Indeed, for small \"we can obtain a tighter bound:\nLemma B.1. The`2-sensitivity of rwUp\"q\nxtp\u0016wqisd\n\rmint2;e~\"m\u00011u, where ~\"m\u0010p1\u00001m¡1qmaxi\"i.\nProof form\u00101; c.f. Appendix E.2.1. Let~ xtbe a neighboring dataset of xtand letUp\"q\n~ xtp\u0016Wq \u0010 \u0001 logx~ st;wybe the\ncorresponding loss. Note that maxoPra;bs|Gapqpxt;oq\u0001Gapqp~ xt;oq|¤1so\n~ strjs\u0010»a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011qexp\u0001\n\u0001\"\n2Gapqp~ xt;oq\t\ndoPe\b\"\n2»a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011qexp\u0001\n\u0001\"\n2Gapqpxt;oq\t\ndo\u0010e\b\"\n2strjs (26)\nTherefore since m\u00101we denote w\u0010Wr1s,st\u0010st;1, and~ st\u0010~ st;1and have\n}rwUp\"q\nxtp\u0016wq\u0001rwUp\"q\n~ xtp\u0016wq}2\u0010gffed¸\nj\u00101\u0002strjs\nxst;wy\u0001~ strjs\nx~ st;wy\n2\n\u0010gffed¸\nj\u00101s2\ntrjs\nxst;wy2\u0002\n1\u0001~ strjsxst;wy\nstrjsx~ st;wy\n2\n¤}rwUp\"q\nxtp\u0016wq}1max\nj|1\u0001\u0014j|(27)\nwhere\u0014j\u0010~ strjsxst;wy\nstrjsx~ st;wyPstrjsexpp\b\"\n2qxst;wy\nstrjsxst;wyexpp\b\"\n2qPexpp\b\"qby Equation 26. The result follows by taking the minimum with the\nbound on the Euclidean norm of the gradient (Lemma E.1).\n19\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nSincee\"\u00011¤2\"for\"Pp0;1:25s, for small\"this allows us to add less noise in DP-FTRL. With this sensitivity bound,\nwe apply Algorithm 1 using the entropic regularizer to obtain the following result:\nTheorem B.2. Ford¥2;\rPp0;1{2sif we run Algorithm 1 on Up\"q\nxtp\u0016Wq\u0010log°m\ni\u001011\n\tpqi;\"iq\nxtp\u0016Wqover\r-robust priors\nwith step-size \u0011\u0010\rm\ndc\nlogpdq{T\n1\u0000\u0001\n2?\nlogpmdq\u0000b\n2 logT\n\f1\t\n\u001b?\nlogrlog2Tsmint1;~\"muand regularizer \u001epWq\u0010mxW;logWythen for\nanyV¥0,\u0015Pr0;1s, and\f1Pp0;1swe will have regret\nmax\n\u0016risPFp\u0015q\nV;dT¸\nt\u00101Up\"q\nxtp\u0016Wtq\u0001Up\"q\nxtp\u0016q¤VmT\n\rd\u0016 pb\u0001aq3\u00002 maxt\r\u0001\u0015;0uTlog 2\n\u00002md\n\rgffe\u0003\n1\u0000\u0003\n4a\nlogpmdq\u00002d\n2 logT\n\f1\u000b\n\u001ba\nrlog2Tsmint1;~\"mu\u000b\nTlogd\n(28)\nw.p.¥1\u0001\f1, where \u0016 is the harmonic mean of  xt\u0010minkxtrk\u00001s\u0001xtrksand~\"m\u0010p1\u00001m¡1qmaxi\"i. For any\n\"1¤2 log1\n\u000e1setting\u001b\u00101\n\"1b\n2rlog2Tslog1\n\u000e1makes this procedure p\"1;\u000e1q-DP .\nProof. For set of\r-robust priors \u001as.t.\u001aris\u0010mint1\u0001\r\u0000\u0015;1u\u0016ris\u0000maxt\r\u0001\u0015;0u\nb\u0001aandWP4m\nds.t.Wri;js\u0010\nb\u0001a\nd³a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011q\u001arispoqdowe can divide the regret into three components:\nT¸\nt\u00101Up\"q\nxtp\u0016Wtq\u0001Up\"q\nxtp\u0016q\u0010T¸\nt\u00101Up\"q\nxtp\u0016Wtq\u0001Up\"q\nxtp\u0016Wq\u0000T¸\nt\u00101Up\"q\nxtp\u0016Wq\u0001Up\"q\nxtp\u001aq\u0000T¸\nt\u00101Up\"q\nxtp\u001aq\u0001Up\"q\nxtp\u0016q(29)\nThe ﬁrst summation is the regret of DP-FTRL with regularizer \u001e, which is strongly convex w.r.t. }\u0004}1. The Gaussian\nwidth of its unit ball is 2a\nlogpmdq, by Lemma E.1 the losses ared\n\r-Lipschitz w.r.t. }\u0004} 1, and by Lemma B.1 the\n`2-sensitivity is \u00012\u0010d\n\rmint2;e~\"m\u00011u ¤2d\n\rmint1;~\"mu, so applying Theorem B.1 yields the boundm2logd\n\u0011\u0000\n\u0011d2T\n\r2\u0001\n1\u0000\u0001\n4?logd\u00002b\n2 logT\n\f1\t\n\u001ba\nrlog2Tsmint1;\"u\t\n. The second summation is a sum over the errors due to\ndiscretization, where we have\nT¸\nt\u00101Up\"q\nxtp\u0016Wq\u0001Up\"q\nxtp\u001aq\u0010T¸\nt\u00101logm¸\ni\u00101xst;i;Wrisy\u00011\u0001logm¸\ni\u001011\n³b\naexpp\u0001\"iGapqipxt;oq{2q\u001arispoqdo\n¤T¸\nt\u00101m¸\ni\u00101³b\naexpp\u0001\"i\n2Gapqipxt;oqq\u001arispoqdo\u0001xst;i;Wrisy\nxst;i;Wrisy\n¤T¸\nt\u00101m¸\ni\u00101°d\nj\u00101³a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011qexpp\u0001\"i\n2Gapqipxt;oqqp\u001arispoq\u0001\u0016Wrispoqqdo\n\r xt{pb\u0001aq\n¤T¸\nt\u00101m¸\ni\u00101°d\nj\u00101³a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011q|\u001arispoq\u0001\u001arispoi;jq|do\n\r xt{pb\u0001aq¤VmT\n\rd\u0016 pb\u0001aq3(30)\nwhere the ﬁrst inequality follows by concavity, the second by using the deﬁnition of Wto see thatxst;i;Wrisy \u0010³b\naexpp\u0001\"i\n2Gapqipxt;oqq\u0016Wrispoqdo¥\r xt\nb\u0001a, the third by H ¨older’s inequality and the mean value theorem for some\noi;jPpa\u0000b\u0001a\ndpj\u00011q;a\u0000b\u0001a\ndjq, and the fourth by the Lipschitzness of \u001arisPFp\rq\nV;d. The third summation is a sum over the\nerrors due to \r-robustness, with the result following by Up\"q\nxtp\u001aq\u0001Up\"q\nxtp\u0016q¤Up\"q\nxtp\u0016q\u0001logp1\u0001maxt\r\u0001\u0015;0uq\u0001Up\"q\nxtp\u0016q¤\n2 maxt\r\u0001\u0015;0ulog 2 .\n20\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nNote that in the case of V¡0or\u0015\u00100we will need to set d\u0010!Tp1qor\r\u0010oTp1qin order to obtain sublinear regret.\nThus for these more difﬁcult classes our extension of DP-FTRL to non-Euclidean regularizers yields improved rates, as in\nthe Euclidean case the ﬁrst term has an extra4?\nd-factor. The following provides some speciﬁc upper bounds derived from\nTheorem B.2:\nCorollary B.3. For each of the following classes of priors there exist settings of d(where needed) and \r¡0in Theorem B.2\nthat guarantee obtain the following regret w.p. ¥1\u0001\f1:\n1.\u0015-robust and discrete \u0016risPFp\u0015q\n0;d:~O\u0002\ndm\n\u0015c\u0001\n1\u0000mint1;~\"mu\n\"1\t\nT\n2.\u0015-robust andV-Lipschitz\u0016risPFp\u0015q\nV;1:~O\u0002\nm\n\u0015b\nV\n\u0016 4c\u0001\n1\u0000mint1;~\"mu\n\"1\t\nT3\n3. discrete\u0016risPF0;d:~O\u0002?\ndm4c\u0001\n1\u0000mint1;~\"mu\n\"1\t\nT3\n4.V-Lipschitz\u0016risPFV;1:~O\u0002?m4b\nV\n\u0016 8c\u0001\n1\u0000mint1;~\"mu\n\"1\t\nT7\nThus competing with \u0015-robust priors with discrete PDFs enjoys the fastest regret rate of ~Op?\nTq, while either removing\nrobustness or competing with any V-Lipschitz prior has regret ~OpT3{4q, and doing both has regret ~OpT7{8q. When\ncomparing to Lipschitz priors we also incur a dependence on the inverse of minimum datapoint separation, which may\nbe small. A notable aspect of all the bounds is that the regret improves with small\"due to the sensitivity analysis in\nLemma B.1; indeed for \"\u0010Op\"1qthe regret bound only has a Oplog1\n\u000e1q-dependence on the privacy guarantee. Finally,\nfor\u0015-robust priors we can also apply the logb\u0001a\n\u0015 -boundedness of \u0001log \tpq;\"q\nxp\u0016qand standard online-to-batch conversion\n(e.g. Cesa-Bianchi et al. (2004, Proposition 1) to obtain the following sample complexity guarantee:\nCorollary B.4. For any\u000b¡0and distribution Dover ﬁnite datasets xof -separated points from pa;bq, if we run\nthe algorithm in Theorem B.2 on T\u0010\n\u0002\nlog1\n\f1\n\u000b2\u0001\nd2m2\n\u00152\u0001\n1\u0000mint1;~\"mu\n\"1\t\n\u0000log21\n\u0015 \t\ni.i.d. samples from Dthen\nw.p.¥1\u0001\f1the average ^W\u00101\nT°T\nt\u00101Wtof the resulting iterates satisﬁes Ex\u0012Dlog°m\ni\u001011\n\tpqi;\"iq\nxp\u0016^Wrisq¤\nmin\u0016risPFp\u0015q\n0;dEx\u0012Dlog°m\ni\u001011\n\tpqi;\"iq\nxp\u0016risq\u0000\u000b. For\u000b-suboptimality w.r.t. \u0016risPFp\u0015q\nV;1the sample complexity is\n\n\u0002\nlog1\n\f1\n\u000b2\u0001\nV2m2\n\u00154 2\u000b2\u0001\n1\u0000mint1;~\"mu\n\"1\t\n\u0000log21\n\u0015 \t\n.\n21\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nC. Section 5 details\nC.1. Location-scale families\nA location-scale model is a distribution parameterized by a location \u0017PRand scale\u001bPR¥0whose density has the form\n\u0016\u0017;\u001bpxq\u00101\n\u001bf\u0000x\u0001\u0017\n\u001b\b\nfor some centered probability measure f:RÞÑR¥0.\nC.1.1. I MPOSSIBILITY OF SIMULTANEOUS ROBUSTNESS AND CONVEXITY\nTheorem C.1. Letf:RÞÑR¥0be a centered probability measure and for each \u0012P\u0002deﬁne\u0016\u0012pxq\u0010fpx\u0001\u0012q.\n1. Iffis continuous then Uxp\u0016\u0012qis convex in \u0012for all sorted dataset xPRnif and only if fis log-concave.\n2.There exist constants a;b¡0s.t. for any r¡0, P p0;R\n2ns,q¥1\nn, and\u0012PRthere exists a sorted dataset\nxPp\u0012\bRqnwithminiPrn\u00011sxri\u00001s\u0001xris\u0010 s.t.Upqq\nxp\u0016\u0012q\u0010aR\u0000logb\n .\nProof. For the ﬁrst direction of the ﬁrst result, consider any \u0012;\u00121PRand\u0015Pr0;1s. We have that\nUpqq\n\u0006xp\u0016\u0015\u0012\u0000p1\u0001\u0015q\u00121q\u0001\u0001\n\u0015Upqq\nxp\u0016\u0012q\u0001p1\u0001\u0015qlogUpqq\nxp\u0016\u00121\t\n\u0010log\tpqq\nxp\u0016\u0012q\u0015\tpqq\nxp\u0016\u00121q1\u0001\u0015\n\tpqq\nx\u0016\u0015\u0012\u0000p1\u0001\u0015q\u00121q(31)\nso it sufﬁces to show that \txpqqp\u0016\u0015\u0012\u0000p1\u0001\u0015q\u00121q¥\tpqq\nxp\u0016\u0012q\u0015\tpqq\nxp\u0016\u00121q1\u0001\u0015. By the log-concavity of fwe have\n\u0016\u0015\u0012\u0000p1\u0001\u0015q\u00121p\u0015x\u0000p1\u0001\u0015qyq\u0010fp\u0015px\u0001\u0012q\u0000p1\u0001\u0015qpy\u0001\u00121qq¥fpx\u0001\u0012q\u0015fpy\u0001\u00121q1\u0001\u0015\u0010\u0016\u0012pxq\u0015\u0016\u00121pyq1\u0001\u0015(32)\nfor allx;yPR. Therefore by the Pr ´ekopa-Leindler inequality we have that\n\tpqq\nxp\u0016\u0015\u0012\u0000p1\u0001\u0015q\u00121q\u0010»xrtqnu\u00001s\nxrtqnus\u0016\u0015\u0012\u0000p1\u0001\u0015q\u00121pxqdx¥\u0003»xrtqnu\u00001s\nxrtqnus\u0016\u0012pxqdx\u000b\u0015\u0003»xrtqnu\u00001s\nxrtqnus\u0016\u00121pxqdx\u000b1\u0001\u0015\n\u0010\txpqqp\u0016\u0012q\u0015\tpqq\nxp\u0016\u00121q1\u0001\u0015(33)\nFor the second direction, by assumption Da c;b¡cs.t.a\nfpxqfpyq ¡fpx\u0000y\n2q@x;yP ra;bs, i.e.fis strictly\nlog-convex on ra;bs. LetxPRnbe any dataset s.t. xrtqnu\u00001s\u0001xrtqnus¤b\u0001a\n2and set\u0012\u0010xrtqnus\u0001a,\u00121\u0010xrtqnus\u0001a\u0000b\n2.\nThen we have\nd»xrtqnu\u00001s\nxrtqnus\u0016\u0012pxqdx»xrtqnu\u00001s\nxrtqnus\u0016\u00121pxqdx\u0010d»xrtqnu\u00001s\nxrtqnusa\n\u0016\u0012pxq2dx»xrtqnu\u00001s\nxrtqnusa\n\u0016\u00121pxq2dx\n¥»xrtqnu\u00001s\nxrtqnusa\n\u0016\u0012pxq\u0016\u00121pxqdx\n\u0010»xrtqnu\u00001s\nxrtqnusa\nfpx\u0001\u0012qfpx\u0001\u00121qdx\n¡»xrtqnu\u00001s\nxrtqnusf\u0002\nx\u0001\u0012\u0000\u00121\n2\ndx\u0010»xrtqnu\u00001s\nxrtqnus\u0016\u0012\u0000\u00121\n2pxqdx(34)\nwhere the ﬁrst inequality is H ¨older’s and the second is due to the strict log-convexity of fonra;bs. Taking the logarithm of\nboth sides followed by their negatives completes the proof.\nFinally, for the second result, since fis centered and log-concave, by Cule & Samworth (2010, Lemma 1)\nthere exist constants C;c¡ 0s.t.\u0016\u0012pxq ¤Cexpp\u0001c|x\u0001\u0012|q @\u0012PR. Let x\u0010\u0000\n\u0012\u0000R\u0001n \u0012\u0000R\u0001pn\u00011q \u0004\u0004\u0004\u0012\u0000R\u00012 \u0012\u0000R\u0001 \b\n, so that|xrtqnus\u0001\u0012|¥|xr1s\u0001\u0012|\u0010R\u0001n ¥R\n2.\nThen\n\tpqq\nxp\u0016\u0012q\u0010»xrtqnu\u00001s\nxrtqnus\u0016\u0012pxqdx¤C expp\u0001c|xrtqnus\u0001\u0012|q¤C expp\u0001cR{2q (35)\nsoUpqq\nxp\u0016q\u0010\u0001 log \tpqq\nxp\u0016\u0012q¥log1\nC \u0000cR\n2.\n22\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nVariants of the ﬁrst result have been shown in the censored regression literature (Burridge, 1981; Pratt, 1981). In fact,\nBurridge (1981) shows convexity of Upqq\nxp\u0016xv;fy\n\u001e;1\n\u001eqw.r.t.pv;\u001eqPRd\u0002R¡0, i.e. simultaneous learning of a feature map and\ninverse scale. Convexity of Ux\u0010\u0001log \t x\u0010log°m\ni\u001011\n\tpqiq\nx\u0010log°m\ni\u00101expp\u0001log \tpqiq\nxqfollows because log°m\ni\u00101exi\nis convex and non-decreasing in each argument. Note that for the converse direction, the dataset xis not a degenerate case;\nin-fact iffis strictly log-convex over an interval ra;bsthen any dataset whose optimal interval has length smaller thanb\u0001a\n2\nwill yield a non-convex Upqq\nxp\u0016\u0012q.\nC.1.2. T HE CASE OF THE LAPLACIAN\nFor the Laplace prior with a\u0010xrtqnusandb\u0010xrtqnu\u00001swe have\n\u0001log\tpqq\nxp\u0016\u0012\n\u001e;1\n\u001eq\n\u0010log 2\u0001log\u0002\nsign\u0002\nb\u0001\u0012\n\u001e\n\u0002\n1\u0001exp\u0002\n\u0001\u0007\u0007\u0007\u0007b\u0001\u0012\n\u001e\u0007\u0007\u0007\u0007\u001e\n\n\u0001sign\u0002\na\u0001\u0012\n\u001e\n\u0002\n1\u0001exp\u0002\n\u0001\u0007\u0007\u0007\u0007a\u0001\u0012\n\u001e\u0007\u0007\u0007\u0007\u001e\n\n\n(36)\nFor\u0012 a\u001ethis simpliﬁes to\nlog 2\u0001log\u0000\ne\u0012\u0001a\u001e\u0001e\u0012\u0001b\u001e\b\n\u0010log 2\u0001log\u0001\npeb\u0001a\n2\u001e\u0001ea\u0001b\n2\u001eqe\u0012\u0001a\u0000b\n2\u001e\t\n\u0010\u0007\u0007\u0007\u0007\u0012\u0001a\u0000b\n2\u001e\u0007\u0007\u0007\u0007\u0001log\u0002\nsinh\u0002b\u0001a\n2\u001e\n\n(37)\nand similarly for \u0012¡b\u001eit becomes\nlog 2\u0001log\u0000\neb\u001e\u0001\u0012\u0001ea\u001e\u0001\u0012\b\n\u0010log 2\u0001log\u0001\npeb\u0001a\n2\u001e\u0001ea\u0001b\n2\u001eqea\u0000b\n2\u001e\u0001\u0012\t\n\u0010\u0007\u0007\u0007\u0007a\u0000b\n2\u001e\u0001\u0012\u0007\u0007\u0007\u0007\u0001log\u0002\nsinh\u0002b\u0001a\n2\u001e\n\n(38)\nOn the other hand for \u0012Pra\u001e;b\u001esit is\nlog 2\u0001log\u0001\n2\u0001e\u0001|b\u001e\u0001\u0012|\u0001e\u0001|a\u001e\u0001\u0012|\t\n\u0010log 2\u0001log\u0000\n2\u0001e\u0012\u0001b\u001e\u0001ea\u001e\u0001\u0012\b\n\u0010log 2\u0001log\u0001\ne\u0001b\u0001a\n2\u001e\u0001\n2eb\u0001a\n2\u001e\u0001e\u0012\u0001a\u0000b\n2\u001e\u0001ea\u0000b\n2\u001e\u0001\u0012\t\t\n\u0010b\u0001a\n2\u001e\u0000log 2\u0001log\u0001\n2eb\u0001a\n2\u001e\u0001e\u0012\u0001a\u0000b\n2\u001e\u0001ea\u0000b\n2\u001e\u0001\u0012\t\n\u0010b\u0001a\n2\u001e\u0001log\u0002\neb\u0001a\n2\u001e\u0001cosh\u0002\n\u0012\u0001a\u0000b\n2\u001e\n\n(39)\nThus we have\nUpqq\nxp\u0016\u0012\n\u001e;1\n\u001eq\u0010#\nb\u0001a\n2\u001e\u0001log\u0000\nexp\u0000b\u0001a\n2\u001e\b\n\u0001cosh\u0000\n\u0012\u0001a\u0000b\n2\u001e\b\b\nif\u0012Pra\u001e;b\u001es\u0007\u0007\u0012\u0001a\u0000b\n2\u001e\u0007\u0007\u0001log\u0000\nsinh\u0000b\u0001a\n2\u001e\b\b\nelse(40)\nSuppose xP r\bBsnand has the optimal interval has separation  ¡0,\u0012\n\u001eP r\bBs, and1\n\u001eP r\u001bmin;\u001bmaxs. Then\n\u001ePr1{\u001bmax;1{\u001bminsand\u0012Pr\bB{\u001bmins, and so\nUpqq\nxp\u0016\u0012\n\u001e;1\n\u001eq¤2B\n\u001bmin\u0000log2\u001bmax\n (41)\nFor\u0012R ra\u001e;b\u001es, the derivative w.r.t. \u0012always has magnitude 1. Within the interval, the derivative w.r.t. \u0012is\n\u0001sinhpa\u0000b\n2\u001e\u0001\u0012q\nexppb\u0001a\n2\u001eq\u0001coshp\u0012\u0001a\u0000b\n2\u001eq, which attains its extrema at the endpoints a\u001eandb\u001e, where its magnitude is also 1. Out-\nside the interval, the derivative w.r.t. \u001ehas magnitude\n\u0007\u0007\u0007\u0007a\u0000b\n2sign\u0002a\u0000b\n2\u001e\u0001\u0012\n\u0001b\u0001a\n2coth\u0002b\u0001a\n2\u001e\n\u0007\u0007\u0007\u0007¤|a\u0000b|\n2\u0000b\u0001a\n2coth\u0002b\u0001a\n2\u001e\n¤|a\u0000b|\n2\u0000b\u0001a\n2\u00022{\u001e\npb\u0001aq\u00001\n\u0010|a\u0000b|\n2\u0000b\u0001a\n2\u00001\n\u001e(42)\n23\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nwhile inside the interval the derivative w.r.t. \u001eisb\u0001a\n2\u0001pb\u0001aqexppb\u0001a\n2\u001eq\u0001pa\u0000bqsinhpa\u0000b\n2\u001e\u0001\u0012q\n2pexppb\u0001a\n2\u001eq\u0001coshpa\u0000b\n2\u001e\u0001\u0012qq, which again attains its extrema\nat the endpoints a\u001eandb\u001e, yielding magnitudes\nb\u0001a\n2\u0000b\u0001a\n2\u0002\ncoth\u0002b\u0001a\n2\u001e\n\u00001\n\u0000|a\u0000b|\n2¤b\u0001a\n2\u00022{\u001e\npb\u0001aq\u00003\n\u0000|a\u0000b|\n2¤1\n\u001e\u00003\n2pb\u0001aq\u0000|a\u0000b|\n2(43)\nThus we have\n|B\u0012Upqq\nxp\u0016\u0012\n\u001e;1\n\u001eq|¤1 and|B\u001eUpqq\nxp\u0016\u0012\n\u001e;1\n\u001eq|¤4B\u0000\u001bmax (44)\nC.2. Public-private release\nC.2.1. G UARANTEES\nTheorem C.2. Suppose for N¥nwe have a private dataset x\u0012Dnand a public dataset x1\u0012D1N, both drawn\nfrom\u0014-bounded distributions over r\bBs. Use i.i.d. draws from the public dataset to construct T\u0010tN{nudatasets\nx1\nt\u0012D1nand run online gradient descent on the resulting losses `x1\ntp\u0012; q\u0010LSEip`pqiq\nxtp\u0012ris;\u001erisqqover the parameter\nspace\u0012Pr\bB{\u001bminsmstarting at\u0012\u00100mand\u001ePr1{\u001bmax;1{\u001bminsmstarting at the midpoint, with stepsize Bam\nTfor\u0012\nand\u001bmax\u0001\u001bmin\n4B\u0000\u001bmaxam\nTfor\u001e, obtaining iterates p\u00121;\u001e1q;:::;p\u0012T;\u001eTq. Return the priors \u0016i\u0010\u0016\u0016\u0012ris\n\u0016\u001eris;1\n\u0016\u001erisfor\u0016\u0012\u00101\nT°T\nt\u00101\u0012t\nand\u0016\u001e\u00101\nT°T\nt\u00101\u001etthe average of these iterates. Then \u00161\u0010\u0000\n\u00161\u0004\u0004\u0004\u0016m\b\nsatisﬁes\nEx\u0012DnUxp\u00161q¤ min\n\u0016PLapm\nB;\u001bmin;\u001bmaxEx\u0012DnUxp\u0016q\u00002\u00022B\n\u001bmin\u0000log4\u0014mpn\u00001qN\u001bmax\n\f1\nTVqpD;D1q\n\u0000pB\u00004B\u001bmax\u0000\u001b2\nmaxqc\nmpn\u00001q\nN\u00002\u00024B\n\u001bmin\u0000log4\u0014mpn\u00001qN\u001bmax\n\f1\nd\n2pn\u00001q\nNlog4\n\f1\n\u0000pn\u00001q\f1\nN\u0002\n3\u00004B\n\u001bmin\u00004 log2\u0014pn\u00001qN?2m\u001bmax\n\f1\n(45)\nwhere LapB;\u001bmin;\u001bmaxis the set of Laplace priors with locations in r\bBsand scales inr\u001bmin;\u001bmaxs.\nProof. Deﬁne D1\n nto be the conditional distribution over z\u0012D1ns.t. z¥ , with associated density \u001a1\n pzq\u0010\u001a1pzq1 z¥ \n1\u0001p1\n ,\nwherep1\n \u0010³\n z  \u001a1pzq¤\u0014n2 . Then we have for any \u0016\u0006PLapm\nB;\u001bmin;\u001bmaxthat\nEz\u0012DnUxp\u00161q\u0010Ez\u0012DnUzp\u00161q\u0001Ez\u0012D1nUzp\u00161q\u0000Ez\u0012D1nUzp\u00161q\u0001Ez\u0012D1\n nUzp\u00161q\u0000Ez\u0012D1\n nUzp\u00161q\n¤»\nUzp\u00161qp\u001apzq\u0001\u001a1pzqq\u0000»\nUzp\u00161qp\u001a1pzq\u0001\u001a1\n pxqq\u0000Ez\u0012D1\n nUzp\u0016\u0006q\u0000E \n¤Ez\u0012DnUxp\u0016\u0006q\u0000»\npUzp\u00161q\u0000Uxp\u0016\u0006qq|\u001apzq\u0001\u001a1pxq|\u0000»\npUzp\u00161q\u0000Uzp\u0016\u0006qq|\u001a1pzq\u0001\u001a1\n pzq|\u0000E \n(46)\nwhere E is the error of running online gradient descent with the speciﬁed step-sizes on samples z1\nt\u0012D1\n nfort\u00101;:::;T .\nNow if zhas entries drawn i.i.d. from a \u0014-bounded distribution Dn(orD1n), then we have that\n» \n0\u001a zpyqdy\u0010Prp z¤ :z\u0012Dnq¤npn\u00011qmax\nzPRPrp|z\u0001z1|¤ :z1\u0012Dq¤\u0014n2 (47)\nwhere\u001a zis the density of  zforz\u0012Dn(not to be confused with the conditional density \u001a overz); the same holds for\nthe analog\u001a1\n zforD1n. Since this holds for all  ¥0andlog1\nyis monotonically decreasing on y¡0, this means the worst-\ncase measure that \u001a zcan be is constant over r0; sand thus³ \n0\u001a zpyqlog1\nydy¤\u0014n2³ \n0log1\nydy\u0010\u0014n2 p1\u0000log1\n q,\nand similarly for \u001a1\n z. We then bound the ﬁrst integral, noting that Uz\u0010LSEipUpqiq\nzq ¤ maxiUpqiq\nz\u0000logm¤\n24\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\n2B\n\u001bmin\u0000log2m\u001bmax\n zand that the r.v.  zdepends only on the joint distribution over the order statistics of DnandD1n:\n»\npUzp\u00161q\u0000Uzp\u0016\u0006qq|\u001apzq\u0001\u001a1pzq|¤»\u00022B\n\u001bmin\u0000log2m\u001bmax\n z\n|\u001apzq\u0001\u001a1pzq|\n¤2\u00022B\n\u001bmin\u0000log2m\u001bmax\n \nTVqpD;D1q\u0000»\n z  |\u001apzq\u0001\u001a1pzq|log1\n z\n¤2\u00022B\n\u001bmin\u0000log2m\u001bmax\n \nTVqpD;D1q\u0000» \n0p\u001a zpyq\u0000\u001a1\n zpyqqlog1\nydy\n¤2\u00022B\n\u001bmin\u0000log2m\u001bmax\n \nTVqpD;D1q\u00002\u0014n2 \u0002\n1\u0000log1\n \n(48)\nFor the second integral we have for p1\n \u0010³\n z  \u001a1pzq¤\u0014n2 that\n»\npUzp\u00161q\u0000Uzp\u0016\u0006qq|\u001a1pzq\u0001\u001a1\n pzq|\n\u0010»\n z¥ pUxp\u00161q\u0000Uzp\u0016\u0006qq\u0007\u0007\u0007\u0007\u0007\u001a1pzq\u0001\u001a1pzq\n1\u0001p1\n \u0007\u0007\u0007\u0007\u0007\u0000»\n z  pUzp\u00161q\u0000Uzp\u0016\u0006qq\u001a1pzq\n\u00102p1\n \n1\u0001p1\n »\n z¥ \u00022B\n\u001bmin\u0000log2m\u001bmax\n \n\u001a1pzq\u0000»\n z  \u00022B\n\u001bmin\u0000log2m\u001bmax\n z\n\u001a1pzq\n\u00102p1\n \u00024B\n\u001bmin\u0000log4m2\u001b2\nmax\n \n\u0000»\n z  \u001a1pzqlog1\n z\n¤2\u0014n2 \u00024B\n\u001bmin\u0000log4m2\u001b2\nmax\n \n\u0000\u0014n2 \u0002\n1\u0000log1\n \n(49)\nFinally, we bound E . By\u0014-boundedness of D1, the probability that DtPrTss.t. z1\nt  @tPrTsis at most\u0014n2T , so if\nwe set \u0010\f1\n2\u0014n2Tthen w.p.¥1\u0001\f1{2the sampling z1\ntfromx1as speciﬁed is equivalent to rejection sampling from D1\n n,\non which the functions Uzare bounded by2B\n\u001bmin\u0000log2m\u001bmax\n . Therefore with probability ¥1\u0001\f1{2by Shalev-Shwartz\n(2011, Theorem 2.21) and Theorem E.1 we have that w.p. 1\u0001\f1{2\nE ¤pB\u0000p\u001bmax\u0001\u001bminqp4B\u0000\u001bmaxqqcm\nT\u00002\u00024B\n\u001bmin\u0000log2m\u001bmax\n \nc\n2\nTlog4\n\f1\n\u0010pB\u00004B\u001bmax\u0000\u001b2\nmaxqc\nmpn\u00001q\nN\u00002\u00024B\n\u001bmin\u0000log2m\u001bmax\n \nd\n2pn\u00001q\nNlog4\n\f1(50)\nCombining terms and substituting the selected value for  yields the result.\nC.2.2. E XPERIMENTAL DETAILS\nFor our public-private experiments we evaluate several methods on the Adult (“age” and “hours” categories) and Goodreads\n(“rating” and “page count” categories). For the former we use the train set as the public data, while for the latter we use the\n“History” genre as the public data and the “Poetry” genre as the private data (Wan & McAuley, 2018). The public data are used\nto ﬁt Laplace location and scale parameters using the COCOB optimizer run until progress stops. We use the implementation\nhere: https://github.com/anandsaha/nips.cocob.pytorch . All evaluations are averages of forty trials.\nWe use the following reasonable guesses for locations \u0017, scales\u001b, and quantile ranges ra;bsfor these distributions:\n• age:\u0017\u001040,\u001b\u00105,a\u001010,b\u0010120\n• hours:\u0017\u001040,\u001b\u00102,a\u00100,b\u0010168\n• rating:\u0017\u00102:5,\u001b\u00100:5,a\u00100,b\u00105\n• page count: \u0017\u0010200,\u001b\u001025,a\u00100,b\u00101000\n1\u0001q\nNote that, here and elsewhere, using q-dependent range for bonly helps the Uniform prior, which is the baseline. The scales\n\u001bare used to set the scale parameter of the Cauchy distribution for public quantiles —its location is ﬁxed by the\npublic quantiles. Meanwhile the locations \u0017are used to set to scale parameter of the half-Cauchy prior used to mix with\nPubFit for robustness (using coefﬁcient 0.1 on the robust prior). We choose this prior because the data are all nonnegative.\n25\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nC.3. Sequential release\nC.3.1. G UARANTEES\nTheorem C.3. Consider a sequence of datasets xtP r\bRsntand associated feature vectors ftP r\bFsd. Suppose\nwe set the component priors \u0016t;iof\u0016tas the Laplace distributions \u0016t;i\u0010\u0016xvt;ifty\n\u001et;i;1\n\u001et;i, where vt;iP r\bB{\u001bminsd\nand\u001eiPr1{\u001bmax;1{\u001bminsare determined by separate runs of DP-FTRL with budgets p\"1{2;\u000e1{2qand step-sizes \u00111\u0010\nB\nF\u001bminc\n2m\"1\n1\nrlog2pT\u00001qsT\u0001\n1\u0000b\n2mdlogT\n\f1log1\n\u000e1\t, and\u00112\u00101{\u001bmin\nB\u0000\u001bmaxc\nm\"1\n2\n2rlog2pT\u00001qsT\u0001\n1\u0000b\n2mlogT\n\f1log1\n\u000e1\t. Then we have regret\nmax\nwiPr\bBsd\n\u001biPr\u001bmin;\u001bmaxsT¸\nt\u00101Uxtp\u0016tq\u0001Uxtp\u0016xwi;fty;\u001biq¤BpF\u00001q\u0000\u001bmax\n\u001bmingffemd rlog2pT\u00001qsT\u0003\n4\u00008\n\"1d\n2mdlogT\n\f1log2\n\u000e1\u000b\n(51)\nFor sufﬁciently small \"1(including\"1¤1) we can instead simplify the regret to\n4\n\u001bmin\u0001\nBFd3\n4\u0000B\u0000\u001bmax\tgffemrlog2pT\u00001qsT\n\"1d\n2mlogT\n\f1log2\n\u000e1(52)\nProof. Note that\nm¸\nj\u00101}rvjLSEip`pqiq\nxt;ftq}2\n2¤}ft}2\n2m¸\nj\u00101\u0003\nexpp`pqjq\nxt;ftq\n°m\ni\u00101expp`pqiq\nxt;ftq\u000b2\n¤F2d (53)\nand\nm¸\nj\u00101pB\u001ejLSEip`pqiq\nxt;ftqq2¤p4B\u0000\u001bmaxq2m¸\nj\u00101\u0003\nexpp`pqjq\nxt;ftq\n°m\ni\u00101expp`pqiq\nxt;ftq\u000b2\n¤p4B\u0000\u001bmaxq2(54)\nand so applying Theorem B.1 twice with the assumed budgets and step-sizes yields\nmax\nwiPr\bBsd\n\u001biPr\u001bmin;\u001bmaxsT¸\nt\u00101Uxtp\u0016tq\u0001Uxtp\u0016xwi;fty;\u001biq\u0010 max\nviPr\bB\n\u001bminsd\n\u001eiPr1\n\u001bmax;1\n\u001bminsT¸\nt\u00101LSEip`pqiq\nxt;ftpvt;i;\u001et;iqq\u0001LSEip`pqiq\nxt;ftpvi;\u001eiqq\n¤m¸\ni\u00101}v1;i\u0001vi}2\n2\n2\u00111\u0000\u00111rlog2pT\u00001qsT\u0003\n1\u00002\n\"1d\n2mdlogT\n\f1log2\n\u000e1\u000bm¸\nj\u00101}rvjLSEip`pqiq\nxt;ftq}2\n2\n\u0000m¸\ni\u00101p\u001e1;i\u0001\u001eiq2\n2\u00112\u0000\u00112rlog2pT\u00001qsT\u0003\n1\u00002\n\"1d\n2mlogT\n\f1log2\n\u000e1\u000bm¸\nj\u00101pB\u001ejLSEip`pqiq\nxt;ftqq2\n¤2B2md\n\u00111\u001b2\nmin\u0000\u00111rlog2pT\u00001qsTF2d\u0003\n1\u00002\n\"1d\n2mdlogT\n\f1log2\n\u000e1\u000b\n\u0000m\n2\u00112\u001b2\nmin\u0000\u00112rlog2pT\u00001qsTpB\u0000\u001bmaxq2\u0003\n1\u00002\n\"1d\n2mlogT\n\f1log2\n\u000e1\u000b\n¤2BF\n\u001bmingffe2md rlog2pT\u00001qsT\u0003\n1\u00002\n\"1d\n2mdlogT\n\f1log2\n\u000e1\u000b\n\u00002\n\u001bminpB\u0000\u001bmaxqgffe2mrlog2pT\u00001qsT\u0003\n1\u00002\n\"1d\n2mlogT\n\f1log2\n\u000e1\u000b\n¤2\n\u001bminpBpF\u00001q\u0000\u001bmaxqgffemd rlog2pT\u00001qsT\u0003\n1\u00002\n\"1d\n2mdlogT\n\f1log2\n\u000e1\u000b(55)\n26\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nC.3.2. E XPERIMENTAL DETAILS\nFor sequential release we consider the following tasks:\n•Synthetic is a stationary dataset generation scheme in which we randomly sample a one standard Gaussian vector\nafor each feature dimension (we use ten) and another bof sizem\u00002, which we sort. On each day tofT\nwe sample the public feature vector ft, also from a standard normal, and the “ground truth” quantiles qion that\nday are then set by xa;fty\u0000bri\u00001s. We generate the actual data by sampling from the uniform distributions on\nrxa;fty\u0000bris;xa;fty\u0000bri\u00001ss. The number of points we sample is determined by t100{pm\u00001quplus different\nPoisson-distributed random variable for each; in the “noiseless” setting used in Figure 4 (left) the Poisson’s scale is\nzero, so the “ground truth” quantiles are correct for the dataset, while for Figure 5 (left) we use a Poisson with scale\nﬁve. For the noiseless setting we use 100K timesteps, while for the noisy setting we use 2500.\n•CitiBike consists of data downloaded from here: https://s3.amazonaws.com/tripdata/index.html ,\nWe take the period from September 2015 through November 2022, which is roughly 2500 days, although days with\nless than ten trips—seemingly data errors—are ignored. For each day we include a feature vector containing seven\ndimensions for the day of the week, one dimension for a sinusoidal encoding of the day of the year, and six weather\nfeatures from the Central Park station downloaded from here https://www.ncei.noaa.gov/cdo-web/ ,\nspeciﬁcally average wind speed, precipitation, snowfall, snow depth, maximum temperature, and minimum temperature.\nThese are scaled to lie within similar ranges.\n•BBC consists of Reddit’s worldnews corpus downloaded from here: https://zissou.infosci.cornell.\nedu/convokit/datasets/subreddit-corpus/corpus-zipped/ . We ﬁnd all conversations corre-\nsponding to a post of a BBC article, speciﬁed by the domain bbc.co.uk , and collect those with at least\nten comments. We compute the Flesch readability score of each comment using the package here https:\n//github.com/textstat/textstat . The datasets for computing quantiles are then the collection of scores\nfor each headline; the size is roughly 10K, corresponding to articles between 2008 and 2018. As features we combine a\nseven-dimensional day-of-the-week encoding, sinusoidal features for the day of the year and the time of day of the\npost, information about the post itself (whether it is gilded, its own Flesch score, and the number of tokens), and ﬁnally\na 25-dimensional embedding of the title, set using a normalized sum of GloVe embeddings (Pennington et al., 2014) of\nthe tokens, excluding English stop-words via NLTK (Loper & Bird, 2002).\nWe again use reasonable guesses of data information to set the static priors, and to initialized the learning schemes.\n• Synthetic: \u0017\u00100,\u001b\u00101,a\u0010\u0001100,b\u0010100\n• CitiBike:\u0017\u001010,\u001b\u00101,a\u00100,b\u001050{p1\u0001qq\n• BBC:\u0017\u001050,\u001b\u001010,a\u0010\u0001100\u0001100{p1\u0001qq,b\u0010100\u0000100q\nWe useaandbfor the static Uniform distributions, \u0017and\u001bfor the static Cauchy distributions, in the case of nonnegative\ndata (CitiBike) we use \u0017for the scale of the half-Cauchy distribution, and for the learning schemes we initialize their Laplace\npriors to be centered at \u0017with scale\u001b. We again use the COCOB optimizer for non-private and proxy learning, and for robust-\nness we mix with the Cauchy (or half-Cauchy for nonnegative data) with coefﬁcient 0.1 on the robust prior. For the PubPrev\nmethod, we set its scale using \u001b. For DP-FTRL, we heavily tune it to show the possibility of learning on the synthetic\ntask; the implementation is adapted from the one here: https://github.com/google-research/DP-FTRL . All\nresults are reported as averages over forty trials.\n27\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nD. Additional proofs for multiple quantile release\nLemma D.1. In Algorithm 2, for any iPrmswe have\n1.Gap~qip^ xi;oq¤Gapqipx;oq\u0000^\ri@oPR\n2.Gapqipx;oq¤Gap~qip^ xi;oq\u0000^\ri@oPr^ai;^bis\nwhere ^\ri\u0010p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq.\nProof. ForoPr^ai;^biswe apply the triangle inequality twice to get\nGap~qip^ xi;oq\u0010| max\n^ xrjs oj\u0001t~qi^niu|\n\u0010|max\n^ xrjs oj\u0000max\nxrjs ^aij\u0001tqinu\u0000tqinu\u0001max\nxrjs ^aij\u0001t~qi^niu|\n¤Gapqipx;oq\u0000\u0007\u0007\u0007\u0007\u0007t~qiptqinu\u0001tqinuqu\u0000tqinu\u0001max\nxrjs ^aij\u0001t~qipmax\nxrjs ^bij\u0001max\nxrjs ^aijqu\u0007\u0007\u0007\u0007\u0007\n¤Gapqipx;oq\u0000p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq(56)\nand again to get\nGapqipx;oq\u0010| max\nxrjs oj\u0001tqinu|\n\u0010|max\n^ xrjs oj\u0000max\nxrjs ^aij\u0001t~qi^niu\u0000t~qi^niu\u0001tqinu|\n¤Gap~qip^ xi;oq\u0000\u0007\u0007\u0007\u0007\u0007max\nxrjs ^aij\u0001t~qipmax\nxrjs ^bij\u0000max\nxrjs ^aijqu\u0001t~qiptqinu\u0001tqinuqu\u0001tqinu\u0007\u0007\u0007\u0007\u0007\n¤Gap~qip^ xi;oq\u0000p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq(57)\nForo ^aiwe use the fact that maxxrjs oj¤maxxrjs ^aijand the triangle inequality to get\nGap~qip^ xi;oq\u0010 t~qi^niu\n\u0010t~qipmax\nxrjs ^bij\u0001max\nxrjs ^aijqu\n¤t~qimax\nxrjs ^biju\u0000tp1\u0001~qiqmax\nxrjs ^aiju\u0001max\nxrjs oj\n\u0010t~qimax\nxrjs ^biju\u0000tp1\u0001~qiqmax\nxrjs ^aiju\u0001max\nxrjs oj\u0000tqinu|\u0001 t~qiptqinu\u0001tqinuqu\u0001tqinu\n¤Gapqipx;oq\u0000p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq(58)\nForo¡^biwe use the fact that maxxrjs ^bij¤maxxrjs ojand the triangle inequality to get\nGap~qip^ xi;oq\u0010 tp1\u0001~qiq^niu\n\u0010tp1\u0001~qiqpmax\nxrjs ^bij\u0001max\nxrjs ^aijqu\n¤max\nxrjs oj\u0001t~qimax\nxrjs ^bij\u0001tp1\u0001~qiqmax\nxrjs ^aij\n\u0010max\nxrjs oj\u0001t~qimax\nxrjs ^bij\u0001tp1\u0001~qiqmax\nxrjs ^aij\u0001tqinu\u0000t~qiptqinu\u0001tqinuqu\u0000tqinu\n¤Gapqipx;oq\u0000p1\u0001~qiqGapqipx;^aiq\u0000~qiGapqipx;^biq(59)\n28\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nLemma D.2. For any\r¡0the estimate oiof the quantile qiby Algorithm 2 satisﬁes\nPrtGapqipx;oiq¥\ru¤expp\"ip^\ri\u0001\rq{2q\n\tp~qi;\"iq\n^ xip^\u0016iq(60)\nProof. We usekito denote the interval ^Ipjq\nksampled at index iin the algorithm and note that oicorresponds to the released\nnumberoat that index. Since oiPr^ai;^bis, applying Lemma D.1 yields\nPrtGapqipx;oiq¥\ru\u0010^ni¸\nj\u00100Prtki\u0010ju1Gapqipx;^Ipiq\njq¥\r\n\u0010ni¸\nj\u00100expp\u0001\"Gap~qip^ xi;^Ipiq\njq{2q^\u0016ip^Ipiq\njq1Gapqipx;^Ipiq\njq¥\r\n°^ni\nl\u00100expp\"u~qip^ xi;^Ipiq\nlq{2q^\u0016ip^Ilq\n¤expp\"^\ri{2q\n\tp~qi;\"iq\n^ xip^\u0016iqni¸\nj\u00100expp\u0001\"Gapqipx;^Ipiq\njq{2q^\u0016ip^Ipiq\njq1Gapqipx;^Ipiq\njq¥\r\n¤expp\"p^\ri\u0001\rq{2q\n\tp~qi;\"iq\n^ xip^\u0016iq(61)\nLemma D.3. For any\r¡0the estimate oiof the quantile qiby Algorithm 2 with edge-based prior adaptation satisﬁes\nPrtGapqipx;oiq¥\ru¤expp\"p^\ri\u0001\r{2qq\n\tpqi;\"iq\nxp\u0016iq(62)\nProof. Applying Lemma D.1 yields the following lower bound on \tp\"iq\n~qip^ xi;^\u0016iq:\n^ni¸\nl\u00100expp\"u~qip^ xi;^Ipiq\nlq{2q^\u0016ip^Ipiq\nlq\u0010expp\"u~qip^ xi;^Ipiq\n0q{2q\u0016ipp\u00018;^aisq\u0000expp\"u~qip^ xi;^Ipiq\n^niq{2q\u0016ipr^bi;8qq\n\u0000^ni¸\nl\u00100expp\"u~qip^ xi;^Ipiq\nlq{2q\u0016ip^Ilq\n\u0010max xrjs ^aij¸\nl\u00100expp\u0001\"Gap~qip^ xi;IlXp\u00018;^aisq{2q\u0016ipIlXp\u00018;^aisq\n\u0000n¸\nl\u0010maxxrjs ^bijexpp\u0001\"Gap~qip^ xi;IlXr^bi;8qq{2q\u0016ipIlXr^bi;8qq\n\u0000maxxrjs ^bij¸\nl\u0010max xrjs ^aijexpp\u0001\"Gap~qip^ xi;IlXr^ai;^bisq\u0016ipIlXr^ai;^bisq\n¥\tpqi;\"iq\nxp\u0016iqexpp\u0001\"^\ri{2q(63)\nSubstituting into Lemma A.2 yields the result.\n29\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nLemma D.4. Supposeq0 q1are two quantiles and o0¡o1. Then\nmax\ni\u00100;1Gapqipx;oiq¥max\ni\u00100;1Gapqipx;o1\u0001iq (64)\nProof. We consider four cases. If tq0|x|u¤maxxrjs o1jand tq1|X|u¤maxxrjs o0jthen\ntq0|x|u¤minttq1|x|u;max\nxrjs o1ju¤maxttq1|x|u;max\nxrjs o1ju¤ max\nxrjs o0j (65)\nand so\nmax\ni\u00100;1Gapqipx;oiq\u0010 max\nxrjs o0j\u0001tq0|x|u¥max\ni\u00100;1GapqipX;oi\u00011q (66)\nIftq0|X|u¤maxxrjs o1jand tq1|x|u¡maxxrjs o0jthen\ntq0|x|u¤max\nxrjs o1j¤max\nxrjs o0j tq1|x|u (67)\nand so both improve after swapping. If tq0|x|u¡maxxrjs o1jand tq1|x|u¡maxxrjs o0jthen\nmax\nxrjs o1j¤minttq0|x|u;max\nxrjs o0ju¤maxttq0|x|u;max\nxrjs o0ju¤ tq1|x|u (68)\nand so\nmax\ni\u00100;1Gapqipx;oiq\u0010 max\nxrjs o1j\u0001tq1|x|u¥max\ni\u00100;1Gapqipx;oi\u00011q (69)\nFinally, if tq0|x|u¡maxxrjs o1jand tq1|x|u¤maxxrjs o0jthen\nmax\nxrjs o1j tq0|x|u¤tq1|x|u¤max\nxrjs o0j (70)\nso swapping will make the new largest error for each quantile at most as large as the other quantile’s current error.\n30\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nE. Additional proofs for online learning\nE.1. Online-to-batch conversion\nTheorem E.1. Suppose an online algorithm sees a sequence `x1p\u0004q;:::;` xTp\u0004q: \u0002ÞÑr0;Bsof convex losses whose data\nx1;:::;xTare drawn i.i.d. from some distribution D, and let\u00121;:::;\u0012Tbe its predictions. If max\u0012P\u0002°T\nt\u00101`xtp\u0012tq\u0001\n`xtp\u0012q¤RT,^\u0012\u00101\nT°T\nt\u00101\u0012t, andT\u0010\n\u0001\nT\u000b\u0000B2\n\u000b2log1\n\f1\t\nforT\u000b\u0010min2RT¤T\u000bT, then w.p.¥1\u0001\f1\nEx\u0012D`xp^\u0012q¤min\n\u0012P\u0002Ex\u0012D`xp\u0012q\u0000\u000b (71)\nProof. This is a formalization of a standard procedure; we follow the argument in Khodak et al. (2022, Lemma A.1).\nApplying Jensen’s inequality, Cesa-Bianchi et al. (2004, Proposition 1), the assumption that regret is ¤RT, and Hoeffding’s\ninequality yields\nEx\u0012D`xp^\u0012q¤1\nTT¸\nt\u00101Ex\u0012D`xp\u0012tq¤1\nTT¸\nt\u00101`xtp\u0012tq\u0000Bc\n2\nTlog2\n\f1¤min\n\u0012P\u00021\nTT¸\nt\u00101`xtp\u0012q\u0000RT\nT\u0000Bc\n2\nTlog2\n\f1\n¤min\n\u0012P\u0002Ex\u0012D`xp\u0012q\u0000RT\nT\u00002Bc\n2\nTlog2\n\f1(72)\nw.p.¥1\u0001\f1. Substituting the lower bound on Tyields the result.\nE.2. Negative log-inner-product losses\nFor functions of the form ftp\u0016q \u0010 \u0001 log³b\nastpoq\u0016poqdo, Balcan et al. (2021) showed ~OpT3{4qregret for the case\nstpoqPt0;1u@oPra;bsusing a variant of exponentiated gradient with a dynamic discretization. Notably their algorithm\ncan be extended to (non-privately) learn \u0001log \tpqq\nxtp\u0016q, sincestin this case is one on the optimal interval and zero elsewhere.\nHowever, the changing discretization and dependence of the analysis on the range of stsuggests it may be difﬁcult to\nprivatize their approach. The discretized form \u0001logxst;wyis more heavily studied, arising in portfolio management (Cover,\n1991). It enjoys the exp-concavity property, leading to OpdlogTqregret using the EWOO method (Hazan et al., 2007).\nHowever, EWOO requires maintaining and sampling from a distribution deﬁned by a product of inner products, which\nis inefﬁcient and similarly difﬁcult to privatize. Other algorithms, e.g. adaptive FTAL (Hazan et al., 2007), also attain\nlogarithmic regret for exp-concave functions, but the only private variant we know of is non-adaptive and only guarantees\nOp?\nTq-regret for non-strongly-convex losses (Smith & Thakurta, 2013). The adaptivity, which is itself data-dependent,\nseems critical for taking advantage of exp-concavity.\nLemma E.1. Ifftp\u0016Wq\u0010\u0001 log°m\ni\u001011{m\nxst;i;Wrisyforst;iPRd\n¥0then}rWftp\u0016Wq}1¤d{\r@WP4m\nds.t.Wri;js¥\n\r{d@i;jfor some\rPp0;1s.\nProof.\n}rWftp\u0016Wq}1\u0010m¸\ni\u00101}rWrisftp\u0016Wq}1\u0010\u0003m¸\ni\u001011\nxst;i;Wrisy\u000b\u00011m¸\ni\u00101d¸\nj\u00101st;irjs\nxst;i;Wrisy2\n¤\u0003m¸\ni\u001011\nxst;i;Wrisy\u000b\u00011m¸\ni\u001011\nxst;i;WrisdWrisy¤d{\r(73)\nwhere the ﬁrst inequality follows by Sedrakyan’s inequality and the second by Wri;js¥\r{d.\n31\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nE.2.1. P ROOF OF LEMMA B.1 FORm¡1\nProof. Let~ xtbe a neighboring dataset of xtconstructed by adding or removing a single element, and let Up\"q\n~ xtbe the\ncorresponding loss function. We note that changing from xtto~ xtchanges the value of Gapqipxt;oqat any point oPra;bs\nby at most\b1and so the value of the exponential score at any point oPra;bsis changed by at most a multiplicative factor\nexpp\u0001\"i{2qin either direction. Therefore\n~ st;irjs\u0010»a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011qexpp\u0001\"iGapqip~ xt;oq{2qdo\nPexpp\b\"i{2q»a\u0000b\u0001a\ndj\na\u0000b\u0001a\ndpj\u00011qexpp\u0001\"iGapqipxt;oq{2qdo\u0010expp\b\"i{2qst;irjs(74)\nwhere\bindicates the interval between values.\n}rWUp\"q\nxtpWq\u0001rWUp\"q\n~ xtpWq}F\n\u0010gfffem¸\ni\u00101d¸\nj\u00101\u0004\n\u0005\u0003m¸\ni1\u001011\nxst;i1;Wri1sy\u000b\u00011st;irjs\nxst;i;Wrisy2\u0001\u0003m¸\ni1\u001011\nx~ st;i1;Wri1sy\u000b\u00011~ st;irjs\nx~ st;i;Wrisy2\f\n\r2\n\u0010\u0003m¸\ni1\u001011\nxst;i1;Wri1sy\u000b\u00011gfffem¸\ni\u00101d¸\nj\u00101\u0003\nst;irjs\nxst;i;Wrisy2\u0001~ st;irjs\nx~ st;i;Wrisy2°m\ni1\u001011\nxst;i1;Wri1sy°m\ni1\u001011\nx~ st;i1;Wri1sy\u000b2\n\u0010\u0003m¸\ni1\u001011\nxst;i1;Wri1sy\u000b\u00011gfffem¸\ni\u00101d¸\nj\u00101s2\nt;irjs\nxWt;i;Wrisy4\u0004\n\u00051\u0001xgt;i;xrisy2\nx~ st;i;Wrisy2°m\ni1\u00101~ st;irjs\nxst;i1;Wri1sy°m\ni1\u00101st;irjs\nx~ st;i1;Wri1sy\f\n\r2\n¤\u0003m¸\ni1\u001011\nxst;i1;Wri1sy\u000b\u00011m¸\ni\u00101d¸\nj\u00101st;irjs\nxst;i;Wrisy2|1\u0001\u0014i;j|¤d\n\rmax\ni;j|1\u0001\u0014i;j|(75)\nwhere we have\n\u0014i;j\u0010xst;i;Wrisy2\nx~ st;i;xrisy2m°\ni1\u00101~ st;irjs\nxst;i1;Wri1sy\nm°\ni1\u00101st;irjs\nx~ st;i1;Wri1syPxst;i;Wrisy2\nxst;i;Wrisy2expp\b\"iqm°\ni1\u00101st;irjsexpp\b\"i1\n2q\nxst;i1;Wri1sy\nm°\ni1\u00101st;irjs\nxst;i1;Wri1syexpp\b\"i1\n2q\u0010expp\b2 max\ni\"iq (76)\nSubstituting into the previous inequality and taking the minimum with the `1bound on the gradient of the losses from\nLemma E.1 yields the result.\nE.2.2. S ETTINGS OF \rANDdFOR COROLLARY B.3\n1.\u0015-robust and discrete \u0016risPFp\u0015q\n0;d:\r\u0010\u0015\n2.\u0015-robust andV-Lipschitz\u0016risPFp\u0015q\nV;1:\r\u0010\u0015andd\u0010Sd\nVpb\u0001aq3\n\u0016 c\u0001\n1\u0000mint1;~\"mu\n\"1\t\nTW\n3. discrete\u0016risPF0;d:\r\u0010?\nmd4b\n1\u0000mint1;~\"mu{\"1\nT\n4.V-Lipschitz\u0016risPFV;1:\r\u0010?m4b\nVpb\u0001aq3\n\u0016 8b\n1\u0000mint1;~\"mu{\"1\nTand\nd\u0010Sd\nVpb\u0001aq3\n\u0016 c\u0001\n1\u0000mint1;~\"mu\n\"1\t\nTW\n32\n\nLearning-Augmented Private Algorithms for Multiple Quantile Release\nAlgorithm 2: ApproximateQuantiles with predictions\nInput: sorted unrepeated data xPpa;bqn, ordered quantiles q1;:::;qmPp0;1q,\npriors\u00161;:::;\u0016m:RÞÑR¥0, prior adaptation rule rPfconditional,edge g,\nprivacy parameters \"1;:::;\"m¡0, branching factor K¥2\n// runs single-quantile algorithm on datapoints ^ x\nMethod quantile( ^ x,q,\",\u0016):\nOutput:oPpa;bqw.p.9expp\u0001\"Gapqp^ x;oq{2q\u0016poq\nMethod recurse( j,q,q,^a,^b):\n// determines K\u00011indices iwhose quantiles to compute at this node\nif|j|¥Kthen\niÐ\u0000\njrr|j|{Kss;\u0004\u0004\u0004;jrrpK\u00011q|j|{Kss\b\nelse\niÐj\n// restricts dataset to the interval p^a;^bq\nkiÐminxrks¡^ak\nkiÐmaxxrks ^bk\n^ xiÐ\u0000xrkis;\u0004\u0004\u0004;xrkis\b\n// sets relative quantiles ~qiand restricts priors to the interval r^a;^bs\nforj\u00101;:::;|i|do\n~qirjsÐpqirjs\u0001qq{pq\u0001qq\nifr\u0010conditional then\n^\u0016irjspoqÐ\u0016irjspoq\n\u0016irjspr^a;^bsq1oPr^a;^bs\nelse\n^\u0016irjspoqÐ\u0016irjspoq1oPp^a;^bq\u0000\u0016irjspp\u00018;^asq\u000epo\u0001^aq\u0000\u0016irjspr^b;8qq\u000epo\u0001^bq\n// computes K\u00011quantiles oiand sorts the results\noiÐ\u0000quantile( ^ xi;~qir1s;\"ir1s{|i|;^\u0016ir1s),\u0004\u0004\u0004,quantile( ^ xi;~qir|i|s;\"ir|i|s{|i|;^\u0016ir|i|s)\b\noiÐsort( oi)\n// recursively computes remaining indices on the Kintervals induced by oi\nif|j| Kthen\noÐoi\nelse\noÐconcat(recurse(\u0000\njr1s;\u0004\u0004\u0004;jrr|j|{Ks\u00011s\b\n;q;qir1s;^a;or1s),\u0000\nor1s\b\n)\nforj\u00102;:::;|i|do\noÐconcat( o;recurse(\u0000\njrrpj\u00011q|j|{Ks\u00001s;\u0004\u0004\u0004;jrrj|j|{Ks\u00011s\b\n;qirj\u00011s;qirjs;orj\u00011s;orjs))\noÐconcat( o;\u0000\norjs\b\n)\noÐconcat( o,recurse(\u0000\njrrpK\u00011q|j|{Ks\u00001s;\u0004\u0004\u0004;jr|j|s\b\n;qirK\u00011s;q;orK\u00011s;^b))\nOutput: o\nOutput: recurse(\u0000\n1;\u0004\u0004\u0004;m\b\n;0;1;\u00018;8)\n33",
  "textLength": 111675
}