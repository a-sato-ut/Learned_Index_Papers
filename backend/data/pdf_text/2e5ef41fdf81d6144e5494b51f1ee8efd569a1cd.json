{
  "paperId": "2e5ef41fdf81d6144e5494b51f1ee8efd569a1cd",
  "title": "Learned Adaptive Indexing",
  "pdfPath": "2e5ef41fdf81d6144e5494b51f1ee8efd569a1cd.pdf",
  "text": "Learned Adaptive Indexing\nSuvam Kumar Das and Suprio Ray\nUniversity of New Brunswick\nFredericton, Canada\n{suvam.das,sray}@unb.ca\nABSTRACT\nIndexes can significantly improve search performance in relational\ndatabases. However, if the query workload changes frequently or\nnew data updates occur continuously, it may not be worthwhile to\nbuild a conventional index upfront for query processing. Adaptive\nindexing is a technique in which an index gets built on the fly as a\nbyproduct of query processing. In recent years, research in data-\nbase indexing has taken a new direction where machine learning\nmodels are employed for the purpose of indexing. These indexes,\nknown as learned indexes , can be more efficient compared to tra-\nditional indexes such as B+-tree in terms of memory footprints\nand query performance. However, a learned index has to be con-\nstructed upfront and requires training the model in advance, which\nbecomes a challenge in dynamic situations when workload changes\nfrequently. To the best of our knowledge, no learned indexes exist\nyet for adaptive indexing.\nWe propose a novel learned approach for adaptive indexing. It is\nbuilt on the fly as queries are submitted and utilizes learned mod-\nels for indexing data. To enhance query performance, we employ\na query workload prediction technique that makes future work-\nload projection based on past workload data. We have evaluated\nour learned adaptive indexing approach against existing adaptive\nindexes for various query workloads. Our results show that our\napproach performs better than others in most cases, offering 1.2 Ã—â€“\n5.6Ã—improvement in query performance.\nKEYWORDS\nAdaptive Indexing, Learned Index, Learned Sort, Query Forecasting\n1 INTRODUCTION\nIndexes in a data system enhance data retrieval speed, improve\nperformance, and ensure data consistency. Although an index in-\ncurs additional storage overhead, with its help the data system can\nquickly narrow down the data it needs to process a query, thus\nreducing the number of disk accesses and improving query perfor-\nmance. In relational databases, for decades, B+-tree [ 1] has been\na dominant approach for indexing and answering range searches.\nThis structure is able to retrieve the position of a sorted keyin loga-\nrithmic time with respect to the total number of keys, but requires\nthe storage of all keys as part of the index organization. Hash-based\nindexes [ 2] are very effective in answering equality searches in al-\nmost constant time. Indexes such as Bloom Filters [ 3] can efficiently\ncheck the existence of a record.\nTraditional indexes, such as the B+-tree are constructed prior to\nquery execution and they require scanning the entire dataset once\nduring the index construction. But in some scenarios, the queries\nmay be localized to a specific portion of a dataset, or the workload is\ndynamic and the dataset keeps on changing due to continuous data\nupdates. In these situations, it may not be worthwhile to create anindex on the entire dataset in a database table. Rather, indexes are\nbuilt on the fly as a by product of query execution. Once a sufficient\nnumber of queries are executed, an index on the complete dataset\nis built as part of the query execution. This is known as adaptive\nindexing . Some of the indexes built on this concept are database\ncracking [4, 5] and adaptive merging [6, 7].\nIn recent years, researchers have developed indexes that utilize\nlearned models to predict the location of a key value by learning\nthe distribution within the lookup keys. Learning based models\nleverage techniques such as Linear Regression [ 8], Radix Spline\nInterpolation [ 9]. They are trained on a subset of the lookup keys\nto â€œlearnâ€ the Cumulative Distribution Function. Then the model is\nused to predict the location given any key. This technique has been\ntermed as a learned index [10], and this can enhance or even replace\ntraditional index structures due to its smaller memory footprint\nand better search performance. Learned index approaches, such as\nthe FITing tree [ 8] and the PGM index [ 11] have been developed\nbased on this idea and have been shown to be superior to B+-trees\nin terms of storage space requirement and search time. Learned\nindexes have also been incorporated in other domains [12â€“14].\nHowever, a learned index needs to be built upfront and it incurs\nadditional cost associated with training the learned model. This\nbecomes a challenge for dynamic situations where, the dataset is\nfrequently updated or becomes stale and needs discarded whenever\nnew batch of data arrives. Hence, it may not be worthwhile to create\na learned index upfront under these scenarios, as the time spent on\ncreating the index on dynamic data could rather be used to answer\nthousands of user queries. On the other hand, to the best of our\nknowledge, no work has been done to incorporate the advantages\nof learned approaches for incremental construction of adaptive\nindexes yet, which could result in enhanced query performance\ncompared to the present adaptive indexes.\nTo address the limitations of existing approaches, we propose\na novel Learned Adaptive Index (LAI) .ğ¿ğ´ğ¼is general purpose and\nuses any learned index for its construction. Following the concepts\nof adaptive indexing, ğ¿ğ´ğ¼is incrementally built as a by product\nof query execution. Each query tries to find all ğ‘¥in the dataset,\nsuch thatğ‘¥âˆˆ[ğ‘™,â„], whereğ‘™,â„are the query boundaries. Unlike\ntraditional learned indexes which creates an index on the entire\ndataset, inğ¿ğ´ğ¼a learned index gets created on a partition of the\ninput dataset depending on the query ranges. As an advantage, ğ¿ğ´ğ¼\ncan maintain different types of learned indexes in different parti-\ntions, e.g. a FITing tree [ 8] on one partition and a PGM Index [ 11]\non another, creating an ensemble of learned indexes. This can prove\nto be beneficial, for instance, in situations where a specific portion\nof the dataset is updatable, leaving the rest of the data untouched.\nIn such a situation ğ¿ğ´ğ¼can maintain an updatable learned index\nsuch as ALEX [ 15] for the updatable partition and static learned\nindexes such as RadixSpline [9] for the other partitions.\n1arXiv:2508.03471v1  [cs.DB]  5 Aug 2025\n\nSuvam Kumar Das and Suprio Ray\nLearned indexes require the data to be sorted, but ğ¿ğ´ğ¼also works\nfor queries on unsorted data. We partition and reorganize the input\ndata based on the query boundaries such that all the ğ‘˜ğ‘’ğ‘¦ğ‘  answering\nthe query fall within a single partition. Depending on the partition\nsize to sort, we toggle between traditional sorting and a Learned\nSort technique similar to [ 16], which has been shown to enhance\nsorting time on large datasets.\nIn enterprise data-driven applications, not all queries are sub-\nmitted at the same time for execution. Rather, a set of queries are\nusually submitted within a particular time interval, which can be\nconsidered as a â€˜batchâ€™ of query workload. We employ a statistical\nforecasting technique for query workload prediction, to predict\nthe future queries using the past queries. Since modern hardware\nsupports many CPU cores, while a current batch of queries is still in\nexecution, once a fixed number of queries are received, the forecast-\ning process can be launched simultaneously, without affecting the\noverall system performance. Once the next batch of query is fore-\ncasted, our index is updated based on them. This enables automated\nand predictive index maintenance, where the next batch of query\nworkload is predicted and the index is updated upfront for them\nonly. This approach can be beneficial for workloads whose queries\nfollow a pattern and are predictable based on the current queries.\nTherefore,ğ¿ğ´ğ¼may be considered as an hybrid between traditional\nindex such as B+-tree and adaptive index, where we predict and\nbuild the index upfront only for the next batch of queries.\nWe have conducted extensive experimental evaluation to com-\npare the performance of ğ¿ğ´ğ¼ against other adaptive indexes for\nvarious query workloads on a synthetic dataset of 100M keys. Our\nexperiments show that ğ¿ğ´ğ¼outperforms the other approaches for\nmost of the workloads. We also demonstrate that with query work-\nload prediction ğ¿ğ´ğ¼achieves performance improvement of 5.2 Ã—â€“\n19.3Ã—for some of the workloads, compared to the approach that\ndo not use workload prediction.\nTo summarize, the key contributions of the paper are:\nâ€¢We propose ğ¿ğ´ğ¼that can integrate learned index with adap-\ntive indexing.\nâ€¢We present a number of different query scenarios and show\nhowğ¿ğ´ğ¼handles each of them.\nâ€¢We present a Learned Sort technique for ğ¿ğ´ğ¼and based on\nthe partition size to sort, we toggle between learned and\ntraditional sorting to enhance overall sorting time.\nâ€¢We present a query workload prediction approach that can\npredict the next batch of queries from the past batch, update\nthe index a priori for the predicted workload batch.\nâ€¢We conduct extensive experimental evaluation with a syn-\nthetic dataset of size 100M, by executing 10 (ten) different\nquery workloads.\nThe rest of the paper is organized as follow. In Section 2 we\nmention about the related work. Then in Section 3 we introduce\nğ¿ğ´ğ¼ and give a brief description of all the query scenarios that\ncan appear. Section 4 explains our approach and the algorithms in\ndetails. In Section 5 we explain how we incorporate Learned Sort\ninğ¿ğ´ğ¼. Section 6 mentions about query forecasting and updating\nour index on the fly . We discuss about our experimental evaluation\nin Section 7 and finally conclude in Section 8.2 RELATED WORK\nIn this section, the related work is presented in detail. Here, we\ndivide the discussion into two parts, Learned Access Methods and\nAdaptive Indexes.\n2.1 Learned Access Methods\nHere we look into the existing works done focusing on the usage\nof ML and interpolation techniques to create Learned Indexes and\nhow these techniques are employed on the other paradigms of data\nanalytics.\n2.1.1 Learned Index. Incorporating ML techniques to create data-\nbase indexes has created a new avenue of research in query pro-\ncessing, known as Learned Indexes. Here ML models are trained to\nmodel the CDF of the dataset, which are then used for predicting\nthe position of search keys in a sorted list. RMI [ 10] was the first\nlearned index to be proposed, which is a hierarchical structure of\nneural networks. But this introduced space-time tradeoffs due to the\ncomplexity of the ML models adopted. To address this, FITing-Tree\n[8] was introduced that uses a simple linear model at the leaf level\nof a B+-tree index. Experimentally it was found that the FITing-\ntree improved the execution time performance of the B+-tree with\na space saving of orders of magnitude. However, these indexes\nare built in static datasets and work for read-only workloads. Up-\ndates are not handled by these indexes. This limitation renders\nthe Learned Index unusable for dynamic, read-write workloads,\ncommon in many use cases. To address this issue, researchers later\nproposed updatable learned indexes, such as ALEX [ 15] and PGM-\nIndex [ 11]. Apart from point lookups, both these indexes support\nadditional operations such as range queries, inserts, updates and\ndeletes. Another limitation of RMI is that it cannot be constructed\nover a single pass of the input data, whereas ALEX and PGM can\nbe. However, the complexity to insert an element in both of these\nindexes is logarithmic in the number of levels (similar to inserts\nin a B+-tree). But there are applications (e.g. LSM trees) where it\nis much more important to efficiently build the index. To address\nthis researchers proposed RadixSpline (RS) [ 9], the first single-pass\nlearned index with a constant complexity to insert each element.\nRS utilizes the spline-based interpolation method and it is not only\nefficient to build, but also competitive with state-of-the-art RMI\nmodels in size and lookup performance. The positions of the key\nvalues predicted by these models are not always precise and often\nrequires a local search around the predicted position to find the\nkey. This degrades the overall performance of the index. Recently,\nLIPP [ 17] was developed, which trains the learned models for the\nentire data set and places the data at the predicted positions. When\nmultiple data records are assigned to the same position, a new node\nis created at the position to hold them. This however, does not\nconsider the data distribution of the keys and often results in long\ntraversal paths. Later DIstribution-driven Learned Index tree (DILI)\n[18], was proposed where a concise and computation-efficient lin-\near regression model is used for each node. The indexes proposed\nso far only considered a single dimension, whereas queries often\ninvolve predicates spanning over multiple dimensions. To address\nthis scenario, Flood [ 19], the first learned multi-dimensional in-\nmemory index, was introduced. But Flood was not very efficient in\nhandling skewed query workloads and correlated data. To address\n2\n\nLearned Adaptive Indexing\nthis, the idea of Flood was extended to propose Tsunami [ 20], an\nin-memory read-optimized learned multi-dimensional index for\ncorrelated data and skewed workloads. The indexes discussed so\nfar were for single standalone systems. We developed a distributed\nlearned index and a distributed partition-wise index join algorithm\nbased on this index to answer join queries for DaskDB [ 21], our\nnovel scalable data science system, which supports unified data\nanalytics and in situ SQL query processing on heterogeneous data\nsources.\nInspired by the idea of learned indexes over columnar data, learned\nindexes were developed for other scenarios as well. FLIRT [ 12] and\nSWIX [ 22] were proposed for sliding windows over data streams. A\nfew learned indexes such as RSMI [23], LISA [13], SPRIG [24] and\nIH-tree/IH-tree+/C-IH-tree+ [ 25] were proposed for spatial data.\nTo incorporate learned methods in metric space indexing, LIMS\n[14] and LMI [26] were proposed.\n2.1.2 Learned Approaches In Other Paradigms. Apart from creat-\ning indexes, ML techniques have been found to be useful in other\naspects of data analytics as well. Using learned models in several\nwell-known operations such as hashing, sorting and joins have been\nshown to be more effective than the traditional approaches. Under\ncertain conditions (e.g. when keys are generated from a uniform\nrandom distribution), replacing hash functions with learned models\nachieve improvement in terms of hash collisions, hash table size,\nand probe latency while maintaining the compute efficiency almost\nthe same [ 27]. By approximating the emperical CDF of the keys,\nlearned models can be utilized for sorting datasets, as shown in\nLearned Sort [ 16] and PCF Learned Sort [ 28]. It has been shown that\nlearned variants of Index Nested Loop Join and Sort-based Joins\ncan outperform the state-of-the-art techniques by using CDF-based\npartitioning and learned indexes [29].\n2.2 Adaptive Indexes\nAdaptive indexing such as database cracking [4,5] and adaptive\nmerging [6,7] allow for building an index incrementally in response\nto queries, rather than building it upfront. Database cracking pro-\ngressively partitions and sorts a column by quicksort while an-\nswering range queries. When a column is queried by a predicate\nfor the first time, a new cracker index is created. As predicates of\nsubsequent queries are applied on the column, the cracker index is\nrefined by range partitioning until a minimum size is reached. The\nkeys in a cracker index are partitioned into disjoint key ranges, but\nleft unsorted within each key range. Each range query analyzes the\ncracker index, scans key ranges that fall entirely within the query\nrange, and uses the two end points of the query range to further\npartition the appropriate two key ranges. While database cracking\nworks as an incremental quick sort, adaptive merging functions as\nan incremental external merge sort on block-access devices such\nas disks, in addition to main memory. Under adaptive merging, the\nfirst query to use a given column in a predicate produces sorted\nruns, ideally stored in a partitioned B-tree, and subsequent queries\nupon that same column perform merge steps. Each merge step af-\nfects key ranges that are relevant to actual queries, avoiding any\neffort on all other key ranges. This merge logic executes as a side\neffect of query execution. Database cracking has a low initialization\ncost, but converges to a full index slowly, whereas adaptive merging\nLearned Adaptive Index (LAI) â€“ Basic Idea\n13  16  4  9  2  12  7  1  19  3  14  11  8  6\nQ1 : 9 â‰¤ A â‰¤ 13\n7  1  4  3  2  8  6  9  11  12  13   16  19  14  \n3  1  2  4  6  7  8   9  11  12  13   14  16  19   Q2 : 6â‰¤ A â‰¤ 19(9, 13, pos9, pos13) M1\n(6, 8, pos6, pos8)\n(9, 13, pos9, pos13)\n(14, 19, pos14, pos19)M1M2\nM3Update \nPartition Table \nUpdate \nPartition Table Partition Table TFigure 1: An illustration of LAI\nhas a relatively high initialization cost but converges rapidly. A\nhybrid combination of the two [ 30] applying cracking on the initial\npartitions and sorting on the final one was proposed to achieve both\nlightweight initialization and quick convergence. These approaches\nblindly cracked the data space based on each query ranges thus\nfailing in terms of workload robustness . Hence these approaches\nworked well with random queries, but faltered in scenarios when\nsuccessive queries ask for consecutive items in the data space.\nTo address this, researchers later proposed Stochastic Database\nCracking [4], where apart from the query region, the data space is\nalso cracked at arbitrary positions. Instead of reorganizing the data\nspace based on the queries only, this approach makes it partially\nquery-driven and partially random. The authors proposed multiple\ntechniques that are based on this approach, such as ğ·ğ·ğ¶ , in which\nthe array is recursively halved until the resulting piece is sufficiently\nsmall. Then it cracks this piece based on the query region only.\nHowever, this technique requires finding the median of a partition\nfor optimal partitioning. As calculating median is expensive, in\nğ·ğ·ğ‘… , the array is cracked based on random pivots. These auxiliary\noperations incurs a considerable high overload for the first few\nqueries. This is addressed by ğ·ğ·1ğ¶andğ·ğ·1ğ‘…, which are variants\nofğ·ğ·ğ¶ andğ·ğ·ğ‘… . They perform the auxiliary operations at most\nonce.ğ‘€ğ·ğ· 1ğ‘…works likeğ·ğ·1ğ‘…, with the difference that it does\nnot perform the final cracking step based on the query bounds.\nInstead, the qualified tuples are detected while cracking a data piece\nbased on a random pivot and then they are materialized in a new\narray.ğ´ğ¼ğ¶ğ¶ 1ğ‘…andğ´ğ¼ğ¶ğ‘† 1ğ‘…are variants of Crack-Crack (ğ´ğ¼ğ¶ğ¶)and\nCrack-Sort(ğ´ğ¼ğ¶ğ‘†)methods [ 30]. In addition to the cracking and\npartition/merge logic, they also incorporate DD1R-like stochastic\ncracking in one pass during query processing.\n3 OUR APPROACH: LEARNED ADAPTIVE\nINDEX\nInspired by the idea of learned indexes and the advantages in terms\nof storage consumption and query execution over the traditional\nindexes, we propose to integrate learned indexes with adaptive\nindexing. We call this approach Learned Adaptive Index (LAI) , which\ncan efficiently process Range Queries . A Range Query is defined as\nfollows.\nDefinition 3.1 (Range Query). Given an array ğ´(sorted or un-\nsorted) and an interval [ğ‘™,â„], find allğ‘¥âˆˆğ´, such thatğ‘™â‰¤ğ‘¥â‰¤â„.\n3\n\nSuvam Kumar Das and Suprio Ray\nThe basic concepts behind ğ¿ğ´ğ¼are illustrated in Fig. 1. Let ğ´is\nan unsorted array, and a Range Query Q1 is submitted, where ğ‘„1 :\n9â‰¤ğ´â‰¤13. The idea is to crack A based on the query endpoints i.e.\n9 and 13, such that three disjoint partitions ğ‘ƒ1,ğ‘ƒ2andğ‘ƒ3are created\nwhereğ‘ƒ1contains all values <9,ğ‘ƒ2contains all values within the\nrange[9,13](marked in red), and finally ğ‘ƒ3contains the rest of the\nvalues greater than 13. As can be seen in the figure, ğ‘ƒ2answersğ‘„1\nand thus the entire partition is returned to the user. This partition\nis then sorted using a standard sorting algorithm, and a learned\nindexğ‘€1is created on this partition. Finally, a tuple of the form\n(9,13,ğ‘ğ‘œğ‘  9,ğ‘ğ‘œğ‘  13,ğ‘€1)is stored in a 1-D Partition Table ğ‘‡, where\nğ‘ğ‘œğ‘ 9andğ‘ğ‘œğ‘ 13are the positions of 9 and 13 respectively in ğ‘‡. When\nanother query ğ‘„2: 6â‰¤ğ´â‰¤19is submitted, we scan ğ‘‡to identify\nthat 6 lies in ğ‘ƒ1whereas 19 belongs to ğ‘ƒ3. It is easy to identify the\nstart and end indexes of the partitions ğ‘ƒ1,ğ‘ƒ3from T, since an entry\ninğ‘‡stores both the key as well as its position in ğ´. Next, we crack ğ‘ƒ1\nbased on 6 to find all elements â‰¥6and sort them (shown in green)\nto create a learned model ğ‘€2. Similarly we crack ğ‘ƒ3based on 19 and\nfind all keysâ‰¤19and then sort them (shown in green) to create\nanother learned model ğ‘€3. We find that the maximum element in\nğ‘ƒ1is 8 and the minimum in ğ‘ƒ3is 14. We create two tuples of the\nform(6,8,ğ‘ğ‘œğ‘  6,ğ‘ğ‘œğ‘  8,ğ‘€2)and(14,19,ğ‘ğ‘œğ‘  14,ğ‘ğ‘œğ‘  19,ğ‘€3). Finally to\nanswerğ‘„2all elements in ğ´[ğ‘ğ‘œğ‘ 6:ğ‘ğ‘œğ‘ 19]are returned. In order to\nimprove search time, the entries in ğ‘‡are inserted in such a way that\nthey remain sorted by the boundary interval [ğ‘™,â„]. Thus the tuple\n(6,8,ğ‘ğ‘œğ‘  6,ğ‘ğ‘œğ‘  8,ğ‘€2)appears before(9,13,ğ‘ğ‘œğ‘  9,ğ‘ğ‘œğ‘  13,ğ‘€1), whereas\n(14,19,ğ‘ğ‘œğ‘  14,ğ‘ğ‘œğ‘  19,ğ‘€3)appears after it. As and when more queries\narrive,ğ´gets further refined and new entries are inserted in ğ‘‡, until\nenough queries are submitted so that an index gets created on the\nentire array ğ´. Subsequently submitted queries can be directly\nanswered by using ğ‘‡only. When one or both of the end points of\na query already fall(s) within a sorted partition, its corresponding\nlearned model is consulted to obtain the position(s) of the key(s).\nNext, we discuss our approach in detail.\n3.1 Query scenarios\nFor a query ğ‘„to find allğ‘¥âˆˆğ´, such thatğ‘™â‰¤ğ‘¥â‰¤â„is invoked,\none of the following cases holds, which are also shown in Fig. 2.\nIn the figure, the black outer rectangle represents the entire data\nrange, whereas the red solid rectangles represent those partitions\nthat have been sorted by previous queries, and learned indexes\nis/are constructed for those partitions. The white spaces represent\nunsorted partitions, which have not been touched by any query yet.\nNote that, initially before any query arrives, the entire unsorted\narrayğ´is considered to be a single partition:\nCase 1 : Bothğ‘™andâ„reside within an unsorted partition. This can\nbe divided into two sub-scenarios:\ni.Sorted partition(s) already exists between ğ‘™andâ„. This\nhappens when both the end points of ğ‘„covers or overlaps\nexisting sorted partition(s), as shown in Fig. 2a.\nii.No sorted partition exists between ğ‘™andâ„, i.e. both end-\npoints belong to a single unsorted partition, as shown in\nFig. 2b. This situation always arises when a query is issued\nfor the first time on ğ´. Or there might be existing sorted\npartitions before and/or after this query range.\nl h (a) Case 1(i): ğ‘™andâ„overlap existing partition(s)\nl h \n(b) Case 1(ii): ğ‘™andâ„fall within a single unsorted partition\nl h \n(c) Case 2:ğ‘™andâ„fall within a single sorted partition\nl h \n(d) Case 3:ğ‘™andâ„fall in two different sorted partitions\nl h \n(e) Case 4: Only ğ‘™falls within a sorted partition\nl h \n(f) Case 5: Only â„falls within a sorted partition\nFigure 2: Different query scenarios\nCase 2 : Bothğ‘™andâ„belong to the same sorted partition, as shown\nin Fig. 2c.\nCase 3 : Bothğ‘™andâ„belong to different sorted partitions, as shown\nin Fig. 2d.\nCase 4 : Onlyğ‘™belongs to an already sorted partition, but â„does\nnot, as shown in Fig. 2e.\nCase 5 :ğ‘™does not belong to an already sorted partition, but only â„\ndoes, as shown in Fig. 2f.\nNext, we discuss each scenario in detail. For the purpose of this dis-\ncussion, we assume that each scenario begins with the the following\nconditions:\nU1 U2 U3 U6 U5 U4 S1 S5 S3 S2 S4 \nFigure 3: Example Situation\nâ€¢The arrayğ´has been divided into disjoint sorted and un-\nsorted partitions as a result of queries submitted prior to ğ‘„\nas shown in Fig. 3. There are 6 unsorted partitions ğ‘ˆ1âˆ’ğ‘ˆ6\n(shown in white) and 5 sorted partitions ğ‘†1âˆ’ğ‘†5(shown in\nred). Although in our example situation, we always have an\nunsorted partition between two sorted partitions, in a real-\nlife scenario it is possible to have two contiguous sorted\npartitions without an unsorted partition in between, as we\ndiscuss later in this section.\n4\n\nLearned Adaptive Indexing\nâ€¢For each sorted partition ğ‘†ğ‘–, a tuple of the form ğ‘‡ğ‘–â‰¡(ğ‘™ğ‘–,\nâ„ğ‘–,ğ‘ğ‘œğ‘ ğ‘™ğ‘–,ğ‘ğ‘œğ‘ â„ğ‘–,ğ‘€ğ‘–) is stored in the 1-D partition table ğ‘‡,\nwhereğ‘™ğ‘–,â„ğ‘–are the corresponding low and high values of\nğ‘†ğ‘–,ğ‘ğ‘œğ‘ ğ‘™ğ‘–,ğ‘ğ‘œğ‘ â„ğ‘–are the locations of ğ‘™ğ‘–,â„ğ‘–inğ´, andğ‘€ğ‘–is the\ncorresponding learned index (any existing one-dimensional\nlearned index model could be used here). The entries of\nğ‘‡are sorted by the the interval [ğ‘™,â„]i.e.[ğ‘™ğ‘–,â„ğ‘–]<[ğ‘™ğ‘—,â„ğ‘—]\nimpliesğ‘‡ğ‘–appears before ğ‘‡ğ‘—. It is evident, that for all ğ‘¥ğ‘–,ğ‘¥ğ‘—âˆˆ\nğ‘†ğ‘–,ğ‘†ğ‘—, ifğ‘†ğ‘–appears before ğ‘†ğ‘—inğ´, thenğ‘¥ğ‘–<ğ‘¥ğ‘—. This is\nbecause, before creating each ğ‘†ğ‘–, it was first cracked based\nonğ‘™ğ‘–, followed by â„ğ‘–ensuring that all values ğ‘¥ğ‘–âˆˆğ‘†ğ‘–,ğ‘™ğ‘–â‰¤\nğ‘¥ğ‘–â‰¤â„ğ‘–always holds.\nâ€¢Ifğ‘†ğ‘–appears before ğ‘ˆğ‘—inğ´, this implies that for all ğ‘¥ğ‘—âˆˆ\nğ‘ˆğ‘—,ğ‘¥ğ‘—>â„ğ‘–. Conversely, if ğ‘†ğ‘–appears after ğ‘ˆğ‘—it implies that\nfor allğ‘¥ğ‘—âˆˆğ‘ˆğ‘—,ğ‘¥ğ‘—<ğ‘™ğ‘–. Thus ifğ‘†ğ‘–,ğ‘ˆğ‘—,ğ‘†ğ‘˜appears in order,\nthenâ„ğ‘–<ğ‘¥ğ‘—<ğ‘™ğ‘˜, for allğ‘¥ğ‘—. Furthermore, if ğ‘ˆğ‘–appears\nbeforeğ‘ˆğ‘—, thenğ‘¥ğ‘–<ğ‘¥ğ‘—for allğ‘¥ğ‘–,ğ‘¥ğ‘—âˆˆğ‘ˆğ‘–,ğ‘ˆğ‘—.\nAn important consideration is how to identify, whether one or both\nthe endpoint(s) of a query reside(s) in a sorted or an unsorted partition.\nThis can be determined by scanning ğ‘‡. Sinceğ‘‡stores the intervals\nof the sorted partition in a sorted manner, performing a binary\nsearch over the stored interval can give us the stored partition in\nwhich the endpoint(s) reside. If no such partitions exist, then it\nmust belong to an unsorted partition.\n4 ALGORITHMS\nAs new queries are submitted, we consult the Partition Table T , to\nidentify the scenario (Cases 1 â€“ 5) that is applicable for this query.\nThen, the algorithm corresponding to that case is invoked. Now\nwe discuss each case in details along with the algorithms. For the\npurpose of this discussion, we assume that the following helper\nmethods exist:\nâ€¢ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğ‘†ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘ğ‘ƒğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  (ğ‘‡,ğ‘™,â„): This method searches\nthe partition table ğ‘‡to find those partitions in which ğ‘™(orâ„)\nmay lie, and return the positions ( ğ‘‡ğ‘™,ğ‘‡â„) of those partitions\nin T. Ifğ‘™(orâ„) does not lie inside any partition, then ğ‘‡ğ‘™(or\nğ‘‡â„) is returned as -1.\nâ€¢ğ‘–ğ‘ ğ‘‚ğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘ğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦(ğ‘‡,ğ‘™,â„): This method scans ğ‘‡and checks\nwhether the query boundaries ğ‘™andâ„spans across one or\nmultiple sorted partitions or not. If yes, then it returns True,\notherwise False .\nâ€¢ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘(ğ‘‡,ğ‘˜): Given a key ğ‘˜, scanğ‘‡and return the\nboundaries ( ğ‘1,ğ‘2) of the gap in which ğ‘˜lies.\nâ€¢ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜(ğ‘1,ğ‘2,ğ‘˜): Crack i.e. rearrange the sub-array A[ ğ‘1:\nğ‘2] onğ‘˜, such that all values <ğ‘˜are on the left, while\nvaluesâ‰¥ğ‘˜are on the right of ğ‘˜.\nâ€¢ğ‘”ğ‘’ğ‘¡ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥(ğ‘‡,ğ‘ğ‘œğ‘ ): Given a position ğ‘ğ‘œğ‘ , this method\nextracts the stored tuple (ğ‘™,â„,ğ‘ğ‘œğ‘ ğ‘™,ğ‘ğ‘œğ‘ â„,ğ‘€)atğ‘‡[ğ‘ğ‘œğ‘ ]and\nthen returns learned model ğ‘€.\nâ€¢ğ‘”ğ‘’ğ‘¡ğµğ‘œğ‘¢ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ (ğ‘‡,ğ‘ğ‘œğ‘ ): Given a position ğ‘ğ‘œğ‘ , this method\nextracts the stored tuple (ğ‘™,â„,ğ‘ğ‘œğ‘ ğ‘™,ğ‘ğ‘œğ‘ â„,ğ‘€)atğ‘‡[ğ‘ğ‘œğ‘ ]and\nthen returns the boundary (ğ‘ğ‘œğ‘ ğ‘™,ğ‘ğ‘œğ‘ â„).\nâ€¢ğ‘”ğ‘’ğ‘¡ğ´ğ‘™ğ‘™ğºğ‘ğ‘ğ‘ (ğ‘‡,ğ‘ 1,ğ‘2): Given two indices ğ‘1andğ‘2of the\nglobal array ğ´, return the list of ğ‘”ğ‘ğ‘ğ‘  , such that each ğ‘”ğ‘ğ‘\nğ‘ˆis denoted in the form ğ‘ˆâ‰¡(ğ‘ˆ1,ğ‘ˆ2), where(ğ‘ˆ1,ğ‘ˆ2)are\nthe boundaries of ğ‘ˆ.â€¢ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€,ğ‘˜): Given a key ğ‘˜, this method finds the position\nofğ‘˜in the global array A, using the learned model ğ‘€.\nAlgorithm 1: query(ğ‘™,â„)\nInput: A queryğ‘„to find allğ‘¥from a global array ğ´, such that\nğ‘™â‰¤ğ‘¥â‰¤â„\nOutput: The sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]satisfyğ‘„\n1(ğ‘‡ğ‘™,ğ‘‡â„):=ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğ‘†ğ‘œğ‘Ÿğ‘¡ğ‘’ğ‘‘ğ‘ƒğ‘ğ‘Ÿğ‘¡ğ‘–ğ‘¡ğ‘–ğ‘œğ‘›ğ‘  (ğ‘‡,ğ‘™,â„);\n2ifğ‘‡ğ‘™= -1 andğ‘‡â„= -1then\n3 ifisOverlapQuery(T,l,h) = True then\n4(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ):=ğ‘’ğ‘¥ğ‘’ğ‘ğ‘¢ğ‘¡ğ‘’ğ‘‚ğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘ğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦ (ğ‘™,â„)//Case 1(i);\n5 else\n6(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ):=ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥(ğ‘™,â„)//Case 1(ii);\n7else ifğ‘‡ğ‘™=ğ‘‡â„then\n8(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ):=ğ‘”ğ‘’ğ‘¡ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ğ‘ ğ¹ğ‘Ÿğ‘œğ‘šğ‘†ğ‘ğ‘šğ‘’ğµğ‘œğ‘¢ğ‘›ğ‘‘ (ğ‘™,â„,ğ‘‡ğ‘™)//Case\n2;\n9else ifğ‘‡ğ‘™â‰¥1andğ‘‡â„â‰¥1then\n10(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ):=\nğ‘”ğ‘’ğ‘¡ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ğ‘ ğ¹ğ‘Ÿğ‘œğ‘šğ·ğ‘–ğ‘“ğ‘“ğ‘’ğ‘Ÿğ‘’ğ‘›ğ‘¡ğµğ‘œğ‘¢ğ‘›ğ‘‘ (ğ‘™,â„,ğ‘‡ğ‘™,ğ‘‡â„)//Case 3;\n11else ifğ‘‡ğ‘™â‰¥1andğ‘‡â„=âˆ’1then\n12(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ):=ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜ğ¹ğ‘œğ‘Ÿğ»ğ‘–ğ‘”â„ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ (ğ‘™,â„,ğ‘‡ğ‘™)//Case 4;\n13else\n14(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ):=ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜ğ¹ğ‘œğ‘Ÿğ¿ğ‘œğ‘¤ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ (ğ‘™,â„,ğ‘‡â„)//Case 5;\n15returnğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ];\nThe driver algorithm query , as shown in Algorithm 1, is executed\nevery time a query is submitted. Based on the query boundaries\n(ğ‘™,â„)and the current state of ğ‘‡, any one of the cases 1â€“5 is satisfied\nand the corresponding algorithm gets invoked. From the query\nboundaries we try to identify the entry in ğ‘‡, which may contain\nğ‘™(andâ„) and get the position of entries (ğ‘‡ğ‘™,ğ‘‡â„)(Line 1) . If such\na position is not found for both the boundaries (i.e. ğ‘‡ğ‘™=ğ‘‡â„=âˆ’1)\n(Lines 2â€“6) , we try to identify and act accordingly if the query\nbelongs to Case 1(i) (Lines 3â€“4) orCase 1(ii) (Lines 5â€“6) . If\nğ‘‡ğ‘™=ğ‘‡â„, then Case 2 is invoked (Lines 7â€“8) . The query belongs to\nCase 3 when bothğ‘‡ğ‘™,ğ‘‡â„â‰¥1(Lines 9â€“10) . Ifğ‘‡ğ‘™â‰¥1, butğ‘‡â„=âˆ’1,\nthen the scenario belongs to Case 4 (Lines 11â€“12) . If none of the\nconditions are satisfied, then the situation falls under Case 5 (Lines\n13â€“14) . We get the index positions (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )in which all the key\nvalues satisfying the query lies (Line 15) . Finally, the values in\nthe sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]are returned as the query result. As a\nby-product of this query the Partition Table T gets further updated\nif possible.\n4.1 Case 1: Both ğ‘™andâ„resides in an unsorted\npartition\nAs mentioned earlier, this scenario can arise in two situations, which\nare described next.\n4.1.1 Case 1(i) : Sorted partition(s) already exists between ğ‘™\nandâ„.This scenario is depicted in Fig. 4 and Algorithm 2 shows\nthe steps in details. Let us assume that ğ‘™andâ„reside inğ‘ˆ3and\nğ‘ˆ5respectively, which have ğ‘†3,ğ‘ˆ4andğ‘†4in between. First, the\npartition table ğ‘‡is scanned (as stated above) to find the unsorted\npartitions in which ğ‘™andâ„reside. They are denoted by ğ‘ˆğ‘™andğ‘ˆâ„(in\nthis case it is ğ‘ˆ3andğ‘ˆ5). Letğ‘ğ‘™,ğ‘ğ‘™be the lower and upper indexes\nforğ‘ˆğ‘™, andğ‘â„,ğ‘â„forğ‘ˆâ„(Lines 1â€“2) . Next, we crack the partition\n5\n\nSuvam Kumar Das and Suprio Ray\nU1 U2 U3 U6 U5 U4 S1 S5 S3 S2 S4 l h \nU1 S1 U2 S2 S3 U7 S4 U8 S5 U6 S6 S7 l \nS8 h After executing query Q \nFigure 4: Sorted partition(s) already exists between ğ‘™andâ„\nAlgorithm 2: executeOverlapQuery (ğ‘™,â„)\nInput: A queryğ‘„to find allğ‘¥from a global array ğ´, such that\nğ‘™â‰¤ğ‘¥â‰¤â„\nOutput: The pair (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ) such that all element in\nğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]satisfyğ‘„\n1(ğ‘ğ‘™,ğ‘ğ‘™):=ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘(ğ‘‡,ğ‘™)//Get the indices for gap ğ‘ˆğ‘™;\n2(ğ‘â„,ğ‘â„):=ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘(ğ‘‡,â„)//Get the indices for gap ğ‘ˆâ„;\n3(ğ‘™ğ‘ğ‘œğ‘ ,_):=ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜ğ¹ğ‘œğ‘Ÿğ¿ğ‘œğ‘¤ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ (ğ‘™,ğ´[ğ‘ğ‘™],_);\n4(_,â„ğ‘ğ‘œğ‘ ):=ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜ğ¹ğ‘œğ‘Ÿğ»ğ‘–ğ‘”â„ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ (ğ´[ğ‘â„],â„,_);\n5ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ¹ğ‘œğ‘Ÿğ´ğ‘™ğ‘™ğºğ‘ğ‘ğ‘  (ğ‘ğ‘™,ğ‘â„)//Build learned index for all gaps;\n6return(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\nAlgorithm 3: buildIndexForAllGaps (ğ‘ğ‘œğ‘ 1,ğ‘ğ‘œğ‘  2)\nInput:ğ‘ğ‘œğ‘  1,ğ‘ğ‘œğ‘  2are two indices\nOutput: Build index for all gaps between ğ‘ğ‘œğ‘  1andğ‘ğ‘œğ‘  2and\nupdate the partition table ğ‘‡\n1ğ‘”ğ‘ğ‘ğ¿ğ‘–ğ‘ ğ‘¡ :=ğ‘”ğ‘’ğ‘¡ğ´ğ‘™ğ‘™ğºğ‘ğ‘ğ‘ (ğ‘‡,ğ‘ğ‘œğ‘  1,ğ‘ğ‘œğ‘  2);\n2for(ğ‘1,ğ‘2)âˆˆğ‘”ğ‘ğ‘ğ¿ğ‘–ğ‘ ğ‘¡ do\n3ğ‘™ğ‘œğ‘¤ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ =ğ‘šğ‘–ğ‘›(ğ´[ğ‘1:ğ‘2])//Get min value in the gap;\n4â„ğ‘–ğ‘”â„ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ =ğ‘šğ‘ğ‘¥(ğ´[ğ‘1:ğ‘2])//Get max value in the gap;\n5ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥(ğ‘™ğ‘œğ‘¤ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’,â„ğ‘–ğ‘”â„ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ )//Build index for these\nvalues;\n6return ;\nğ‘ˆğ‘™, i.e the sub-array ğ´[ğ‘ğ‘™:ğ‘ğ‘™] onğ‘™. Performing this operation\nresults inğ‘ˆğ‘™to be shuffled so that all values â‰¥ğ‘™appear to the right\nofğ‘™. Here we sort the sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ :ğ‘ğ‘™]and create a learned\nindexğ‘€ğ‘™. We store the low and high values of the sorted sub-array\nalong with ğ‘€ğ‘™inğ‘‡(Line 3) . Similarly, ğ‘ˆâ„is cracked based on\nâ„ensuring that all values â‰¤â„fall on the left of â„(Line 4) . The\nsteps for lines 3 ( ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜ğ¹ğ‘œğ‘Ÿğ¿ğ‘œğ‘¤ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ ) and 4 (ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜ğ¹ğ‘œğ‘Ÿğ»ğ‘–ğ‘”â„ğ‘‰ğ‘ğ‘™ğ‘¢ğ‘’ )\nare later described in Algorithms 8 and 7 respectively. Again, we\nsortğ´[ğ‘â„:â„ğ‘ğ‘œğ‘ ], and create a learned index ğ‘€â„and add the\ncorresponding entries to ğ‘‡again. Let the positions of ğ‘™andâ„after\ncrackingğ‘ˆğ‘™andğ‘ˆâ„beğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ respectively. By this approach, the\noriginal unsorted ğ‘ˆğ‘™gets refined into an unsorted partition on the\nleft ofğ‘™ğ‘ğ‘œğ‘ and a sorted partition on the right of ğ‘™ğ‘ğ‘œğ‘ (e.g.,ğ‘ˆ3gets\nrefined into ğ‘ˆ7andğ‘†6). The effect is similar for ğ‘ˆâ„too (e.g.,ğ‘ˆ5\ngets refined to ğ‘†8andğ‘ˆ8). Then, we check for any whole unsorted\npartitions falling within ğ‘ğ‘™andğ‘â„by searching ğ‘‡, which we denote\nasgaps. The gaps can be identified from ğ‘‡, by taking into account of\nthe fact that if two sorted partitions are contiguous, then the higher\nindex of the first partition should be one less than the lower index\nof the second partition. If that is not the case, then there are ğ‘”ğ‘ğ‘ğ‘ in between the two sorted partitions. The lower index of the gapis\none more than the higher index of the first partition, whereas the\nhigher index is one less than the lower index of the second partition.\nOnce all such gaps within ğ‘ğ‘™andğ‘â„are identified (in our example,\nthere is only one gapwhich isğ‘ˆ4), they are sorted and a learned\nmodel is built over them and the necessary informations are added\ntoğ‘‡(in our example, ğ‘ˆ4is converted to ğ‘†7) (Line 5 , details shown\nlater in Algorithm 3). Finally (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )are returned (Line 6) from\nwhich all entries ğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]are returned as the query result.\nAlgorithm 3 shows the steps for building a learned model over\nall the gaps between the boundaries ğ‘ğ‘œğ‘ 1andğ‘ğ‘œğ‘ 2. We get the list\nof all unsorted partition boundaries between ğ‘ğ‘œğ‘ 1,ğ‘ğ‘œğ‘  2(Line 1) .\nWe iterate through all the unsorted boundaries (Lines 2â€“5) and do\nthe following for each of them. We identify the minimum (Line 3)\nand maximum (Line 4) for a partition and then build an index for\nthis range and update ğ‘‡accordingly (Line 5) . Algorithm 3 is used\nin the other cases as well, as we will see next.\nl h \nl h After executing query Q \nFigure 5: Both ğ‘™andâ„belong to the same unsorted partition\nAlgorithm 4: buildIndex(ğ‘™,â„)\nInput:ğ‘™,â„are query boundaries. Build a learned index for the\nportionğ‘ƒof the global array ğ´such thatğ‘™â‰¤ğ‘¥â‰¤â„, where\nğ‘¥âˆˆğ‘ƒ\nOutput: The pair (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ), the two indices of ğ‘ƒ\n1(ğ‘ğ‘™,ğ‘ğ‘™):=ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘(ğ‘‡,ğ‘™)//Get the indices for the gap;\n2ğ‘™ğ‘ğ‘œğ‘ :=ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜(ğ‘ğ‘™,ğ‘ğ‘™,ğ‘™)//Crack the gap on ğ‘™and get its position;\n3â„ğ‘ğ‘œğ‘ :=ğ‘ğ‘Ÿğ‘ğ‘ğ‘˜(ğ‘™ğ‘ğ‘œğ‘ ,ğ‘ğ‘™,â„)//Crack the gap on â„and get its position;\n4ğ‘ ğ‘œğ‘Ÿğ‘¡(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )//Sort the array within the indices (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\n5ğ‘€:=ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )//Build a learned index;\n6ğ‘’ğ‘›ğ‘¡ğ‘Ÿğ‘¦ :=(ğ‘™,â„,ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ,ğ‘€);\n7ğ‘–ğ‘›ğ‘ ğ‘’ğ‘Ÿğ‘¡(ğ‘‡,ğ‘’ğ‘›ğ‘¡ğ‘Ÿğ‘¦)//Update T sorted by the interval [ ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ];\n8return(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\n4.1.2 Case 1(ii) : Both ğ‘™andâ„belong to the same unsorted\npartition .This is always the case when the first query is submitted,\nbut this can occur in other scenarios too, as we see from Fig. 5.\nAlgorithm 4 shows this scenario. Let both endpoints belong to an\nunsorted partition ğ‘ˆğ‘–(ğ‘ˆ4in our case). In such a situation, ğ‘ˆğ‘–is\nbroken into a sorted partition and possibly into multiple unsorted\npartitions by cracking based onğ‘™andâ„(Lines 1â€“3) , and then sorting\nthe sub-array (Line 4) , as shown in the previous scenario. Finally a\nlearned index model is built over this new sorted partition (Line\n5)and entries in ğ‘‡are added accordingly (Lines 6â€“7) . Finally, all\nentries within the new sorted partitions are returned as the query\n6\n\nLearned Adaptive Indexing\nresults (Line 8) . In our example, ğ‘ˆ4is broken into ğ‘ˆ7,ğ‘†6andğ‘ˆ8,\nand the necessary information for ğ‘†6is added toğ‘‡.\n4.2 Case 2: Both ğ‘™andâ„belong to the same\nsorted partition\nAlgorithm 5: getResultsFromSameBound (ğ‘™,â„,ğ‘ğ‘œğ‘ )\nInput:ğ‘™,â„are query boundaries. ğ‘ğ‘œğ‘ is the index of partition in ğ‘‡\nin which the query boundaries lie.\nOutput: The pair (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ) such that all element in\nğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]satisfy the query boundary\n1ğ‘€:=ğ‘”ğ‘’ğ‘¡ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ (ğ‘‡,ğ‘ğ‘œğ‘ )//Get the learned index from\nT[pos];\n2ğ‘™ğ‘ğ‘œğ‘ :=ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€,ğ‘™)//Get the position of ğ‘™from M;\n3â„ğ‘ğ‘œğ‘ :=ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€,â„)//Get the position of â„from M;\n4return(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\nThis scenario is depicted in Fig. 2c and this is a simple case to\nhandle as there is no need to reorganize the data. Algorithm 5 shows\nthe steps of this scenario. After issuing the query, we scan ğ‘‡to find\nthat both the query endpoints belong to a sorted partition ğ‘†ğ‘–(say).\nWe select the corresponding learned index ğ‘€ğ‘–(Line 1) and use that\nto find the locations of ğ‘™andâ„(Lines 2â€“3) , and all entries between\nthese locations ( Line 4) are returned as the query results.\n4.3 Case 3: Both ğ‘™andâ„belong to different\nsorted partitions\nl h \nl h After executing query Q \nFigure 6: Both ğ‘™andâ„belong to different sorted partitions\nThis scenario is depicted in Fig. 6 and the steps are illustrated in\nAlgorithm 6. Let ğ‘™andâ„belong to two different sorted partitions ğ‘†ğ‘™\nandğ‘†â„, which in our example are ğ‘†2andğ‘†4. Since both the query\nendpoints belong to a sorted partition, we retrieve their learned\nindexes (Lines 1â€“2) and use them to determine the positions of ğ‘™and\nâ„. Ifğ‘™ğ‘ğ‘œğ‘ andâ„ğ‘ğ‘œğ‘ are the indexes for ğ‘™andâ„respectively (Lines\n3â€“4) , then all the elements in the sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]are\nincluded in the query result. We also try to find all ğ‘”ğ‘ğ‘ğ‘  occurring\nbetweenğ‘†ğ‘™andğ‘†â„, sort them and build learned indexes over them,\nand finally add all the necessary information to ğ‘‡(Lines 5â€“7) .\nFinally, all entries between (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )(Line 8) are returned as the\nquery result. In our example, ğ‘ˆ3andğ‘ˆ4are theğ‘”ğ‘ğ‘ğ‘  betweenğ‘†2\nandğ‘†4, which are converted into ğ‘†6andğ‘†7.Algorithm 6: getResultsFromDifferentBound (ğ‘™,â„,ğ‘ğ‘œğ‘ ğ‘™,ğ‘ğ‘œğ‘ â„)\nInput:ğ‘™,â„are query boundaries. ğ‘ğ‘œğ‘ ğ‘™,ğ‘ğ‘œğ‘ â„is the indices of\npartition inğ‘‡in whichğ‘™,â„respectively lie.\nOutput: The pair (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ) such that all element in\nğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]satisfy the query boundary\n1ğ‘€ğ‘™:=ğ‘”ğ‘’ğ‘¡ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ (ğ‘‡,ğ‘ğ‘œğ‘ ğ‘™)//Get the learned index for ğ‘™;\n2ğ‘€â„:=ğ‘”ğ‘’ğ‘¡ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ (ğ‘‡,ğ‘ğ‘œğ‘ â„)//Get the learned index for â„;\n3ğ‘™ğ‘ğ‘œğ‘ :=ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€ğ‘™,ğ‘™)//Get the position of ğ‘™fromğ‘€ğ‘™;\n4â„ğ‘ğ‘œğ‘ :=ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€â„,â„)//Get the position of â„fromğ‘€â„;\n5(ğ‘ğ‘™,ğ‘ğ‘™):=ğ‘”ğ‘’ğ‘¡ğµğ‘œğ‘¢ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ (ğ‘‡,ğ‘ğ‘œğ‘ ğ‘™)//Get the boundaries having ğ‘™;\n6(ğ‘â„,ğ‘â„):=ğ‘”ğ‘’ğ‘¡ğµğ‘œğ‘¢ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ (ğ‘‡,ğ‘ğ‘œğ‘ â„)//Get the boundaries having\nâ„;\n7ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ¹ğ‘œğ‘Ÿğ´ğ‘™ğ‘™ğºğ‘ğ‘ğ‘  (ğ‘ğ‘™,ğ‘â„)//Build learned index for all gaps;\n8return(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\nU1 U2 U6 U5 U4 S1 S5 S3 S2 S4 l h \nU1 S1 U2 S2 S3 S4 U5 S5 U6 l h After executing query Q \nS6 S7 U7 U3 \nFigure 7: Only ğ‘™belongs to an already sorted partition\nAlgorithm 7: crackForHighValue (ğ‘™,â„,ğ‘ğ‘œğ‘ ğ‘™)\nInput:ğ‘™,â„are query boundaries. ğ‘ğ‘œğ‘ ğ‘™is the index of partition in ğ‘‡\nin whichğ‘™falls.\nOutput: The pair (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ) such that all element in\nğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]satisfy the query boundary\n1ğ‘€ğ‘™:=ğ‘”ğ‘’ğ‘¡ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ (ğ‘‡,ğ‘ğ‘œğ‘ ğ‘™)//Get the learned index for ğ‘™;\n2ğ‘™ğ‘ğ‘œğ‘ :=ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€ğ‘™,ğ‘™)//Get the position of ğ‘™fromğ‘€ğ‘™;\n3(ğ‘ğ‘™,ğ‘ğ‘™):=ğ‘”ğ‘’ğ‘¡ğµğ‘œğ‘¢ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ (ğ‘‡,ğ‘ğ‘œğ‘ ğ‘™)//Get the boundaries having ğ‘™;\n4(ğ‘â„,ğ‘â„):=ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘(ğ‘‡,â„)//Get the indices for gap ğ‘ˆâ„;\n5ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ¹ğ‘œğ‘Ÿğ´ğ‘™ğ‘™ğºğ‘ğ‘ğ‘  (ğ‘ğ‘™,ğ‘â„)//Build learned index for all gaps;\n6ğ‘šğ‘–ğ‘›ğ‘‰ğ‘ğ‘™ =ğ‘šğ‘–ğ‘›(ğ´[ğ‘â„:ğ‘â„])//Get minimum value in ğ‘ˆâ„;\n7(_,â„ğ‘ğ‘œğ‘ ):=ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥(ğ‘šğ‘–ğ‘›ğ‘‰ğ‘ğ‘™,â„)//Build index for [minVal, h];\n8return(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\n4.4 Case 4: Only ğ‘™belongs to an already sorted\npartition\nThis scenario is depicted in Fig. 7 and Algorithm 7 describes the\nsteps in details. Using ğ‘‡, we can determine the sorted and unsorted\npartitions where ğ‘™andâ„reside. Since ğ‘™belongs to a sorted partition,\nwe use the corresponding learned index to identify the index of ğ‘™,\ni.e.ğ‘™ğ‘ğ‘œğ‘ (Lines 1â€“2) . Similar to previous scenarios, we try to find\nallğ‘”ğ‘ğ‘ğ‘  , except the one that contains â„, and then sort them, build\nlearned indexes over them and update ğ‘‡(Lines 3â€“5) . We finally\nidentify theğ‘”ğ‘ğ‘that contains â„and find the minimum value ğ‘šğ‘–ğ‘›ğ‘‰ğ‘ğ‘™\nin that gap (Line 6) . Then, we build an index for [ğ‘šğ‘–ğ‘›ğ‘‰ğ‘ğ‘™,â„]and get\nthe position of â„i.e.â„ğ‘ğ‘œğ‘ (Line 7) . All entries between (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )\n(Line 8) are returned as the query result. In our example, ğ‘™lies\ninğ‘†2, whereasâ„belongs toğ‘ˆ4.ğ‘™ğ‘ğ‘œğ‘ gets calculated by using the\nlearned index of ğ‘†2.ğ‘ˆ4gets broken into the sorted partition ğ‘†7and\n7\n\nSuvam Kumar Das and Suprio Ray\nan unsorted partition ğ‘ˆ7. The gapğ‘ˆ3gets converted to a sorted\npartitionğ‘†6and gets added to ğ‘‡.\n4.5 Case 5: Only â„belongs to an already sorted\npartition\nU1 U2 U3 U6 U5 U4 S1 S5 S3 S2 S4 l h \nU1 S1 U2 S2 S3 S4 U5 S5 U6 l h After executing query Q \nS7 S6 U7 \nFigure 8: Only â„belongs to an already sorted partition\nAlgorithm 8: crackForLowValue(ğ‘™,â„,ğ‘ğ‘œğ‘ â„)\nInput:ğ‘™,â„are query boundaries. ğ‘ğ‘œğ‘ â„is the index of partition in ğ‘‡\nin whichâ„falls.\nOutput: The pair (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ) such that all element in\nğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]satisfy the query boundary\n1ğ‘€â„:=ğ‘”ğ‘’ğ‘¡ğ¿ğ‘’ğ‘ğ‘Ÿğ‘›ğ‘’ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ (ğ‘‡,ğ‘ğ‘œğ‘ â„)//Get the learned index for â„;\n2â„ğ‘ğ‘œğ‘ :=ğ‘“ğ‘–ğ‘›ğ‘‘(ğ‘€â„,â„)//Get the position of â„fromğ‘€â„;\n3(ğ‘â„,ğ‘â„):=ğ‘”ğ‘’ğ‘¡ğµğ‘œğ‘¢ğ‘›ğ‘‘ğ‘ğ‘Ÿğ‘–ğ‘’ğ‘ (ğ‘‡,ğ‘ğ‘œğ‘ â„)//Get the boundaries having\nâ„;\n4(ğ‘ğ‘™,ğ‘ğ‘™):=ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘ğ‘ (ğ‘‡,ğ‘™)//Get the indices for gap ğ‘ˆğ‘™;\n5ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ¹ğ‘œğ‘Ÿğºğ‘ğ‘ (ğ‘ğ‘™,ğ‘â„)//Build learned index for all gaps;\n6ğ‘šğ‘ğ‘¥ğ‘‰ğ‘ğ‘™ =ğ‘šğ‘ğ‘¥(ğ´[ğ‘ğ‘™:ğ‘ğ‘™])//Get maximum value in ğ‘ˆğ‘™;\n7(ğ‘™ğ‘ğ‘œğ‘ ,_):=ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥(ğ‘™,ğ‘šğ‘ğ‘¥ğ‘‰ğ‘ğ‘™)//Build index for [l, maxVal];\n8return(ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ );\nThis scenario is very similar to the previous scenario and is\nshown in Fig. 8. Here, instead of â„,ğ‘™is cracked. The steps are shown\nin Algorithm 8. Taking a similar approach to the previous case,\nwe find the index of â„(Lines 1â€“2) . Next, we try to find all ğ‘”ğ‘ğ‘ğ‘  ,\nexcept the one that contains ğ‘™, sort, build learned indexes over\nthem and update ğ‘‡(Lines 3â€“5) . We finally identify the ğ‘”ğ‘ğ‘that\ncontainsğ‘™and find the maximum value ğ‘šğ‘ğ‘¥ğ‘‰ğ‘ğ‘™ in that gap (Line\n6). Then, we build an index for [ğ‘™,ğ‘šğ‘ğ‘¥ğ‘‰ğ‘ğ‘™]and get the position\nofğ‘™i.e.ğ‘™ğ‘ğ‘œğ‘ (Line 7) . All entries between (ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ )(Line 8) are\nreturned as the query result. Note that similar to the example for\nthe previous scenario, cracking the unsorted partition where ğ‘™lies\nto getğ‘™ğ‘ğ‘œğ‘ , can break it into a sorted and an unsorted partition. In\nour example, ğ‘™lies withinğ‘ˆ3and gets broken into ğ‘ˆ7andğ‘†6.â„lies\ninğ‘†4and then uses the learned index to calculate â„ğ‘ğ‘œğ‘ . All theğ‘”ğ‘ğ‘ğ‘ \nare converted to a sorted partition and stored in ğ‘‡(in our example\nğ‘ˆ4gets converted into ğ‘†7).\n5 LEARNED SORT\nWhen a partition gets cracked, ğ‘™andâ„are placed in their actual\nsorted positions ğ‘ğ‘œğ‘ ğ‘™andğ‘ğ‘œğ‘ â„respectively. To create the learned\nindexğ‘€, it is required to sort the sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ +1 :â„ğ‘ğ‘œğ‘ âˆ’1].\nTo sort the sub-array after cracking, a learned sorting technique\nInsert key into \npredicted \nposition No \ncollision \nInsert key into \na spill bucket Collision \nSort the \nspill bucket Merge \nkeyAre all \nkeys \nchecked\n?\nGet next key NoYes\nLinear \nRegression Preliminary \nsorted array \nFinal Sorted \nArray Figure 9: Learned Sort technique used in LAI\n(similar to [ 16]) is used instead of a traditional sorting in our ap-\nproach. This results in a shorter query execution time compared to\nusing traditional sorting algorithms. Since initially there are two\ndata points in their actual sorted positions within the sub-array,\nwe use them i.e.(ğ‘™,ğ‘ğ‘œğ‘ ğ‘™)and(â„,ğ‘ğ‘œğ‘ â„)to build a Linear Regression\nmodel to approximate the CDF of the actual dataset. This model is\nsubsequently used to predict the sorted positions of all keys within\nthe sub-array. The steps of our learned sorting approach are shown\nin Fig. 9.\nAlgorithm 9: LearnedSort(ğ´,ğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ ,ğ¿ğ‘…)\nInput:ğ´â€“ Input Array\nğ‘™ğ‘ğ‘œğ‘ ,â„ğ‘ğ‘œğ‘ â€“ indices ofğ‘™andâ„respectively\nğ¿ğ‘…â€“ Linear Regression Model\nOutput: Sorted sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ :â„ğ‘ğ‘œğ‘ ]\n1ğ‘†:={}//Spill bucket, intialized to empty;\n2ğ‘¡ğ‘’ğ‘šğ‘ =ğ´[ğ‘™ğ‘ğ‘œğ‘ +1 :â„ğ‘ğ‘œğ‘ âˆ’1]//Copy all keys to a temporary\narray;\n3ğ´[ğ‘™ğ‘ğ‘œğ‘ +1 :â„ğ‘ğ‘œğ‘ âˆ’1].ğ‘ğ‘™ğ‘’ğ‘ğ‘Ÿ()//Clear the sub-array;\n4forğ‘˜ğ‘’ğ‘¦âˆˆğ‘¡ğ‘’ğ‘šğ‘ do\n5ğ‘ğ‘Ÿğ‘’ğ‘‘ =ğ¿ğ‘….ğ‘”ğ‘’ğ‘¡(ğ‘˜ğ‘’ğ‘¦)//Get predicted sorted position of key;\n6 ifğ´[ğ‘ğ‘Ÿğ‘’ğ‘‘].ğ‘–ğ‘ ğ¸ğ‘šğ‘ğ‘¡ğ‘¦()=ğ‘‡ğ‘Ÿğ‘¢ğ‘’ then\n7ğ´[ğ‘ğ‘Ÿğ‘’ğ‘‘]=ğ‘˜ğ‘’ğ‘¦ //Place the key if position is empty;\n8 else\n9ğ‘†.ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(ğ‘˜ğ‘’ğ‘¦)//Append key to the spill bucket;\n10ğ‘†.ğ‘ ğ‘œğ‘Ÿğ‘¡()//Sort the spill bucket;\n11ğ‘šğ‘’ğ‘Ÿğ‘”ğ‘’(ğ´[ğ‘™ğ‘ğ‘œğ‘ +1 :â„ğ‘ğ‘œğ‘ âˆ’1],ğ‘†)//In-place merge A with S;\n12return ;\nAlgorithm 9 describes the steps of our learned sorting technique.\nA spill bucket S is maintained that is initialized to be empty (Line 1) .\nAll elements in the sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ +1 :â„ğ‘ğ‘œğ‘ âˆ’1]are copied into\na temporary array and the sub-array is cleared (Lines 2â€“3) . Next\nwe iterate through all keys in the temporary array (Line 4) and\npredict its sorted position using the Linear Regression model (Line\n5). If the predicted position is empty in ğ´, we place the key in that\nposition (Lines 6â€“7) . Otherwise, if the predicted position is already\noccupied by another key, we append it to spill bucket ğ‘†(Lines 8â€“9) .\nAfter all keys are iterated over, we get a partially sorted sub-array\nofğ´and an unsorted spill bucket ğ‘†. The spill bucket ğ‘†is then sorted\nand later merged in-place with the partially sorted sub-array of ğ´\n(Lines 10â€“11), resulting in a sorted sub-array ğ´[ğ‘™ğ‘ğ‘œğ‘ +1 :â„ğ‘ğ‘œğ‘ âˆ’1].\nOur experiments show that Learned Sort works well when the\ndataset is large enough. When sorting a smaller dataset, a traditional\nsorting is the better option. Hence, when the size of the dataset\nreaches a threshold, ğœ, we use our Learned Sort approach. When the\ndata set size is <ğœ, traditional sorting can be used. In our case, to\n8\n\nLearned Adaptive Indexing\n00.20.40.60.81Traditional Sort Learned Sort\nDataset SizeTime (milliseconds)\nFigure 10: Traditional vs Learned Sort\nidentify a suitable ğœ, we conducted experiments that involve sorting\nrandom integer dataset of different sizes (1K â€“ 15K). For this, we\ncompared the default sorting algorithm of C++ standard library,\nIntrosort with the Learned Sort. The results are shown in Fig. 10.\nFrom the figure, we see that up until the dataset size of 6K, the\nperformance (i.e. time required to sort the dataset) of a Introsort is\nslightly better than the Learned Sort, after which the performance\nof Learned Sort continues to improve as the dataset size increases.\nHence, we set ğœ=6K. Asğ¿ğ´ğ¼requires intermittent sorting of the\nquery region, we choose Learned Sort when the size of the region\nto be sorted is >6K, otherwise, we use traditional sorting.\n6 QUERY WORKLOAD PREDICTION AND\nINDEX UPDATE\nIn a real-world scenario, not all queries are submitted at the same\ntime, instead several queries are submitted simultaneously or during\na certain time interval. These queries can be processed together as\na workload â€˜batchâ€™. In customer-centric use cases, there could be\npeak times and off-peak times, with potentially short time intervals\nwhen no query is running i.e. â€˜short down timesâ€™. Additionally, in\nmany scenarios, the queries often follow a fixed pattern. In this\ncase, future queries are predictable from the previous queries, as\nshown in Fig. 11.\nLow High\nQuery SequenceValue Domain\n(a) Actual Queries\nLow High Pred_Low Pred_High\nQuery SequenceValue Domain (b) Predicted Queries\nFigure 11: Sequential ZoomIn Queries\nThe figure shows the query workload pattern in a Sequential\nZoomIn workload. In this workload, the queries zoom into a spe-\ncific region of the data space and then shift to a different region.\nThe zoom-in follows a linear trend both in terms of ğ‘™ğ‘œğ‘¤andâ„ğ‘–ğ‘”â„\nboundaries, followed by a steady ğ‘—ğ‘¢ğ‘šğ‘ to another region. Fig. 11a\nshows the actual query ranges. If there are sufficient number of\nqueries in the past, which maintains the ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ (i.e. constant\ndifference between consecutive ğ‘™orâ„values, e.g. between 1ğ‘ ğ‘¡to 5ğ‘¡â„\nand again between 6ğ‘¡â„to 10ğ‘¡â„queries in Fig. 11) and the ğ‘—ğ‘¢ğ‘šğ‘ğ‘  (i.e.\nsudden but constant change in ğ‘™orâ„after fixed set of queries, e.g.a constant jump between queries 5ğ‘¡â„and 6ğ‘¡â„and again between\n10ğ‘¡â„and 11ğ‘¡â„query in Fig. 11), then a future query workload can\nbe predicted, as shown in Fig. 11b. Thus, when enough queries are\nexecuted, these can be utilized to â€˜learnâ€™ the query patterns and\nforecast the next batch of queries by invoking a workload prediction\nalgorithm in a separate thread. Since, modern CPUs support hun-\ndreds of cores, this would not affect the overall query performance.\nThe query ranges can be considered as a â€˜time-seriesâ€™ data and so\nstatistical methods for time series analysis and forecasting, such\nas ARIMA, can be employed for query workload forecasting. For\neach workload, the query patterns are different. Hence, it may be\nchallenging for a single prediction model to forecast queries from\ndifferent workloads.\nAlgorithm 10: PredictWorkload(Î”,ğ‘†,ğ‘‡)\nInput: Î”â€“ Past query batch\nğ‘†â€“ Set of forecasting methods\nğ‘‡â€“ Existing Partition Table constructed so far\nOutput: Forecasted query batch Î”ğ‘“\n1ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘  ={};\n2forğ‘€âˆˆğ‘†do\n3ğ‘€ğ´ğ‘†ğ¸ =ğ‘€.ğ‘ğ‘ğ‘ğ‘™ğ‘¦(Î”)//Get MASE for ğ‘€;\n4ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘ .ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘((ğ‘€,ğ‘€ğ´ğ‘†ğ¸));\n5ğ‘€ğ‘™= forecasting method having least ğ‘€ğ´ğ‘†ğ¸ inğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ‘  ;\n6Î”ğ‘“=ğ‘€ğ‘™.ğ‘“ğ‘œğ‘Ÿğ‘’ğ‘ğ‘ğ‘ ğ‘¡(Î”);\n7ğ‘‡.ğ‘¢ğ‘ğ‘‘ğ‘ğ‘¡ğ‘’(Î”ğ‘“);\n8return ;\nOur approach for query workload prediction is shown in Algo-\nrithm 10. In this, we maintain a fixed set of methods ğ‘†(such as\nARIMA, AdaBoost, and Random Forest). To simplify matters, we\nassume that each workload batch contains Î”number of queries.\nAfter the execution of a workload batch, our ğ¿ğ´ğ¼structure is incre-\nmentally updated. While the execution is in progress, the system\nlaunches the workload prediction task in a separate thread. In this\ntask, every forecasting method ğ‘€âˆˆğ‘†is applied over Î”(Lines 1â€“4) ,\nafter which the method ( ğ‘€ğ‘™) having the least MASE (Mean Absolute\nScaled Error) is chosen (Line 5) . Then,ğ‘€ğ‘™is utilized to forecast\nthe next batch of queries Î”ğ‘“(Line 6) . Once Î”ğ‘“is generated, it is\nused to further update ğ¿ğ´ğ¼based on the forecasted queries (Line\n7). In workloads, such as Sequential ZoomIn of Fig. 11, the forecasts\ncan be quite accurate due to the nature of the queries. Hence, when\nthe next batch of queries is submitted, the query executor takes ad-\nvantage ofğ¿ğ´ğ¼to answer the queries. It takes negligible amount of\ntime to answer them, since the index is already built by Î”ğ‘“(Case 2 ).\nFor workloads where the Î”ğ‘“is not very similar to the next batch of\nÎ”queries, it can still be advantageous as it mostly falls in one of the\ncases except Case 1(i) . This process of query workload prediction\nand index updating continues as new batches of queries appear.\nOur experimental results, as we discussed in the next section, reveal\nthat this approach leads to a significant performance improvement\nin terms of cumulative query execution time.\n7 EXPERIMENTAL EVALUATION\nIn this section, we present our experimental evaluation of LAIin\nvarious settings.\n9\n\nSuvam Kumar Das and Suprio Ray\nLow High\nQuery SequenceValue Domain\n(a) Random\nLow High\nQuery SequenceValue Domain (b) Sequential Random\nLow High\nQuery SequenceValue Domain (c) Sequential Alternate\nLow High\nQuery SequenceValue Domain (d) Sequential Inverse\nLow High\nQuery SequenceValue Domain (e) Sequential Overlap\nLow High\nQuery SequenceValue Domain\n(f) ZoomIn\nLow High\nQuery SequenceValue Domain (g) Sequential ZoomIn\nLow High\nQuery SequenceValue Domain (h) ZoomOut\nLow High\nQuery SequenceValue Domain (i) Sequential ZoomOut\nLow High\nQuery SequenceValue Domain (j) Periodic\nFigure 12: Synthetic Query Workloads\n7.1 Experimental Setup\nLAIwas implemented in C++ and its performance was compared\nagainst other adaptive indexing technique such as database crack-\ning ( CRACK ) and stochastic cracking algorithms [ 4], such as DDC,\nDDR, DD1C, DD1R, MDD1R, AICC1R and AICS1R . The C++ imple-\nmentations of CRACK and the other stochastic cracking algorithms\nwere obtained from [ 31]. All the implementations were compiled\nwith-O3 flag enabled. Queries were executed on a randomly shuf-\nfled dataset Ahaving all keys between [0, 100M). The queries were\nof the form: Find allğ‘¥âˆˆA such that ğ‘™â‰¤ğ‘¥â‰¤â„. The queries were\nexecuted from ten different synthetic workloads â€“ Random, Se-\nquential Random, Sequential Alternate, Sequential Inverse, Sequential\nOverlap, ZoomIn, Sequential ZoomIn, ZoomOut, Sequential ZoomOut\nandPeriodic . The type of queries across each workload is shown in\nFig. 12. The experiments were conducted on a system with Intel(R)\nCore(TM) i5-1035G1, having Ubuntu 24.04 LTS.\n7.1.1 Workload Details. From the figure, it is observed that for\nRandom , bothğ‘™andâ„were generated randomly. In Sequential Ran-\ndom, for the odd numbered queries ğ‘™was random, whereas for the\neven onesğ‘™was sequentially increased. However, â„was still random.\nInSequential Alternate , for the odd numbered queries ğ‘™was ran-\ndomly generated but â„was gradually decreased and vice-versa (i.e.\nğ‘™increased but â„was random) for the even numbered queries. For\nSequential Inverse ,â„sequentially decreased, but ğ‘™was random. Se-\nquential Overlap is the reverse of Sequential Inverse , whereğ‘™sequen-\ntially increased but â„was random. In case of ZoomIn ,ğ‘™gradually\nincreased whereas â„gradually decreased. Sequential ZoomIn con-\ntains zoom-in queries distributed across the data space. ZoomOut\nis the opposite of ZoomIn whereğ‘™gradually decreased, whereas â„\ngradually increased. In Sequential ZoomOut , zoom-out queries are\ndistributed across the data space, similar to Sequential ZoomIn . In\nPeriodic , the difference between landhremains constant, but the\nquery boundary changes such that the boundaries of the initial few\nqueries are disjoint from each other and span the entire data space.\nThen the remaining queries have ğ‘™that falls within the previous\nquery range, but not â„.7.1.2 Learned Index Implementation. Although any learned\nindex model can be used for LAI, we chose Radix-Spline (RS) [ 9,32]\nbecause, its build time is quite fast, since it is built over a single-\npass of the data and has efficient execution time compared to other\nlearned indices.\n7.1.3 Performance Metric. For each query workload, we mea-\nsured the cumulative query execution time for 20K queries of ğ¿ğ´ğ¼\nandğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ (ğ¿ğ´ğ¼without query forecasting) and compared their\nperformance with the other adaptive indexes. For LAI, we had set\nour forecasting window to 1000 queries, i.e. after every 1000 actual\nqueries ( Î”), we are forecasting the next 1000 queries ( Î”ğ‘“) and use\nit to update ğ¿ğ´ğ¼upfront for the next batch of user queries. Unlike\nğ¿ğ´ğ¼, inğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ query forecasting is disabled and thus ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ is\nupdated only when the user queries are submitted.\n7.2 Experimental Results\nWe present our evaluation of ğ¿ğ´ğ¼against other adaptive indexing\napproaches, and then demonstrate the performance improvement\nofğ¿ğ´ğ¼due to query workload prediction.\n7.2.1 Evaluating LAI with other approaches on different\nquery workloads. The results of the experiments are shown in\nFig. 13. From the figure we see that the performance of both ğ¿ğ´ğ¼\nandğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ , in-terms of cumulative query execution time, is al-\nmost the same for Random, Sequential Random, Sequential Alternate,\nSequential Inverse, Sequential Overlap, and ZoomIn queries (Figs.\n13a â€“ 13f). But there is a significant improvement in the cumu-\nlative query execution time of ğ¿ğ´ğ¼compared to ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ for the\nremaining four workloads (Figs. 13g â€“ 13j). To show the benefits\nof query workload prediction, we also measure the frequency and\nthe total execution time of these four workloads that each of the\nquery spends in different cases (shown in Fig. 14) as explained in\nSection 3. From Figs. 12g â€“ 12j, we see that both the endpoints of\nthe queries from these four workloads follow a pattern and are\nthus quite predictable. Thus, query workload forecasting offers an\nadvantage in these situations. Although the execution times for the\nfirst query in both ğ¿ğ´ğ¼andğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ are high, but as more queries\nare submitted, their performance starts to improve. For ğ¿ğ´ğ¼the\n10\n\nLearned Adaptive Indexing\nCRACKDDCDDRDD1CDD1RMDD1RAICC1RAICS1RLAILAI_wofc\n0246810121416\nQueriesCumulative Query Time (s)\n(a) Random\n024681012\nQueriesCumulative Query Time (s) (b) Sequential Random\n024681012\nQueriesCumulative Query Time (s) (c) Sequential Alternate\n024681012\nQueriesCumulative Query Time (s) (d) Sequential Inverse\n024681012\nQueriesCumulative Query Time (s) (e) Sequential Overlap\n0123456\nQueriesCumulative Query Time (s)\n(f) ZoomIn\n0123456\nQueriesCumulative Query Time (s) (g) Sequential ZoomIn\n01000200030004000\nQueriesCumulative Query Time (s) (h) ZoomOut\n010002000300040005000\nQueriesCumulative Query Time (s) (i) Sequential ZoomOut\n0102030405060\nQueriesCumulative Query Time (s) (j) Periodic\nFigure 13: Evaluation on different Query Workloads\n1(i)1(ii)2345050001000015000200002500030000\n0219998\n000 04019960\n000LAI LAI_wofc\nCaseFrequency\n(a) Sequential ZoomIn - Freq\n1(i)1(ii)2345050001000015000200002500030000\n999\n1019000\n0019999\n10000LAI LAI_wofc\nCaseFrequency (b) ZoomOut - Freq\n1(i)1(ii)2345050001000015000200002500030000\n998\n23818962\n0019960\n40\n0000LAI LAI_wofc\nCaseFrequency (c) Sequential ZoomOut - Freq\n1(i)1(ii)2345050001000015000200002500030000\n0100\n019000\n900\n0 0100\n0019900\n0LAI LAI_wofc\nCaseFrequency (d) Periodic - Freq\n1(i)1(ii) 23450123456\n0.00.3\n0.0\n0.0\n0.0\n0.0\n0.05.5\n0.0\n0.0\n0.0\n0.0LAI LAI_wofc\nCaseTime (seconds)\n(e) Sequential ZoomIn - Time\n1(i)1(ii)2345010002000300040005000\n184.5\n0.5\n0.0\n0.3\n0.0\n0.03596.9\n0.5\n0.0\n0.0\n0.0\n0.0LAI LAI_wofc\nCaseTime (seconds) (f) ZoomOut - Time\n1(i)1(ii)23450100020003000400050006000\n255.0\n0.3\n0.0\n0.0\n0.0\n0.04551.2\n5.5\n0.0\n0.0\n0.0\n0.0LAI LAI_wofc\nCaseTime (seconds) (g) Sequential ZoomOut - Time\n1(i)1(ii)23450102030405060\n0.07.6\n0.0\n0.02.0\n0.0\n0.07.6\n0.0\n0.048.1\n0.0LAI LAI_wofc\nCaseTime (seconds) (h) Periodic - Time\nFigure 14: Casewise evaluation of frequency and execution time on Sequential ZoomIn, ZoomOut, Sequential ZoomOut and\nPeriodic Workloads\ncumulative query execution time almost remains constant after\n1K queries across all workloads, but for ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ , it keeps linearly\nincreasing for Sequential ZoomIn, ZoomOut, Sequential ZoomOut\nandPeriodic workloads (Figs. 13g â€“ 13j) after 1K queries. This sug-\ngests that the cumulative query execution time is dominated by\nthe first 1K queries in case of LAI, after which the execution time\nremains constant due to query forecasting, especially for the last\nfour workloads (Figs. 13g â€“ 13j).\nBothğ¿ğ´ğ¼andğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ perform better than the other adaptive\nindexes for Random, Sequential Random, Sequential Alternate, Se-\nquential Inverse andSequential Overlap queries (Figs. 13a â€“ 13e).\nSo, in these workloads, our Learned Adaptive Index provides the\nbest performance even when queries are not forecasted using our\nworkload prediction approach. The query forecasting does not helpmuch in these scenarios, since at least one of the endpoints is ran-\ndomly generated, so it is hard to forecast the actual query patterns.\nSo, we may be able to forecast one query endpoint (which follows\na pattern, such as the â„ğ‘–ğ‘”â„ value in Fig. 12d), but not the other\nendpoint. Therefore, our approach works well when at least one of\nthe endpoints follows random pattern.\nForğ‘ğ‘œğ‘œğ‘šğ¼ğ‘› (Fig. 13f), the cumulative execution time for CRACK\nwas large (around 350 seconds) compared to the other approaches\n(around 5.5 seconds). Due to this reason, when we plotted them, it\nwas hard to distinguish the performance of the other approaches.\nHence, we removed CRACK from this figure. Similar to the previous\nexperiments, here also both ğ¿ğ´ğ¼andğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ have a high initializa-\ntion time, and as more queries are submitted its performance nearly\nconverges to that of the other adaptive indexes. From Fig. 12f, we\n11\n\nSuvam Kumar Das and Suprio Ray\nsee that after the first query, all the subsequent queries entirely\nfalls within the first query, leading us to Case 2 . In this case all the\nsubsequent queries are completely answered from the index built\nfrom the first query. Due to this reason the cumulative execution\ntime of both ğ¿ğ´ğ¼andğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ remains almost the same as the first\nquery. Hence, there is no advantage of query workload prediction\nin this scenario as well.\nIn case of Sequential ZoomIn (Fig. 13g)ğ¿ğ´ğ¼performs the best,\nwhereas the performance of ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ is not good enough compared\nto the other indexes (in spite of having similar execution times\nuntil 1K queries), showcasing the advantage that we get from query\nworkload prediction. For these workloads, multiple small ZoomIn\nqueries are spread across the data space. As shown in Figs. 14a and\n14e, in the absence of query forecasting, when the ranges of the\nqueries move to a different data region, they cannot take advantage\nof the index built so far. Because, the indexes exist for the previous\ndata region only. Thus quite a few queries fall under Case 1(ii)\n(around 40). This is responsible for taking most of the time and the\nrest of the queries belong to Case 2 . Inğ¿ğ´ğ¼, as we were able to\nforecast the queries in the workload with reasonably high accuracy,\nthis resulted in only 2 queries falling under Case 1(ii) and the\nremaining under Case 2 . Using query workload prediction, the\nreduction in the number of queries falling under Case 1(ii) in\nLAI has resulted in significantly reduced query execution times.\nAlthough around 19.9K queries fall under Case 2 for bothğ¿ğ´ğ¼\nandğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ , answering them using our learned index is quite fast\nand it takes negligible amount of time compared to the cumulative\nexecution time. Hence, the time values appear as 0 in Fig. 14e.\n7.2.2 Evaluating query workload prediction. ForZoomout,\nSequential ZoomOut andPeriodic workloads (Figs. 13h â€“ 13j) we\nonce again can observe significant improvement in query execution\ntime withğ¿ğ´ğ¼compared to ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ . Similar to the previous case,\nthe performance of ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ is not good enough in comparison to\nthe other approaches. The performance of ğ¿ğ´ğ¼is always better than\nCRACK in all the three workloads and is also better than AICS1R in\ncase of Periodic workload . As we previously mentioned, in case of\nLAI, the cumulative query execution time is dominated by the first\n1K queries, after which the query workload forecasting comes into\neffect. We can see from Figs. 12h â€“ 12j that the ranges of the current\nqueries are not completely covered by previous queries. This leads\nus to always creating an index for the uncovered portion of the\ncurrent query. For ZoomOut (Fig. 12h), we always need to build an\nindex on a portion of the dataset having both the endpoints, as the\nentire range of the previous query is completely within the current\nquery (Case 1(i)) . We see from Figs. 14b and 14f that ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘\nspent all the time to handle Case 1(i) , except for the first query\nthat belonged to Case 1(ii) . Inğ¿ğ´ğ¼, the first query also belonged\ntoCase 1(ii) , the next 999 queries belonged to Case 1(i) . The rest\n19K queries fell under Case 3 due to query forecasting, which were\nanswered instantly. For Sequential ZoomOut (Fig. 12i), we execute\nZoomIn , whose range is distributed across the entire data space\n(shown in Figs. 14c and 14g). This leads to a combination of fewer\nscenarios of Case 1(ii) and the rest being Case 1(i) forğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ ,\nboth of which are expensive. In ğ¿ğ´ğ¼, for the first 1K queries, 998\nand 2 queries belonged to Case 1(i) andCase 1(ii) respectively,\nwhich contributed to the entire execution time. From the remaining19K queries, 38 queries fell under Case 2 , and the remaining under\nCase 3 , which were answered almost instantly. For Periodic (Fig.\n12j), as shown in Figs. 14d and 14h, in case of ğ¿ğ´ğ¼ğ‘¤ğ‘œğ‘“ğ‘ , 100 queries\nbelonged to Case 1(ii) since the query ranges were disjoint. The rest\n19.9K queries belonged to Case 4 , whereâ„had to be cracked always\nand consumed most of the execution time. With query workload\nprediction in LAI, out of the first 1K queries 100 belonged to Case\n1(ii) and the rest of 900 queries fell under Case 4 . It took most\nof the time for the first 1K queries as LAIhad to be updated for\neach of them. Due to query workload forecasting, indexes existed\nfor the rest 19K queries, which were answered quickly, since they\nbelonged to Case 3 .\n8 CONCLUSION\nBoth learned indexes andadaptive indexes have their own advan-\ntages. We propose Learned Adaptive Index (LAI) , where we incor-\nporate learned indexes for the purpose of adaptive indexing and\nhence bring the advantages of both worlds. To enhance query per-\nformance, we use Learned Sort instead of traditional sorting tech-\nniques. For faster query execution, we perform workload prediction\nand updateğ¿ğ´ğ¼ on-the-fly . We evaluate our approach against other\nadaptive indexes against various query workloads and show that it\noutperforms for most of them.\nAs a future work, we plan to investigate towards improving the\nperformance of ğ¿ğ´ğ¼on workloads, such as ZoomOut and Periodic .\nWe also aim to extend ğ¿ğ´ğ¼to handle multi-dimensional indexing.\nREFERENCES\n[1] D.J Abel. A b+-tree structure for large quadtrees. Computer Vision, Graphics, and\nImage Processing , 27(1):19â€“31, 1984.\n[2]Ronald Fagin, Jurg Nievergelt, Nicholas Pippenger, and H. Raymond Strong.\nExtendible hashingâ€”a fast access method for dynamic files. ACM Trans. Database\nSyst., 4(3):315â€“344, 1979.\n[3]Burton H. Bloom. Space/time trade-offs in hash coding with allowable errors.\nCommun. ACM , 13(7):422â€“426, 1970.\n[4] Felix Halim, Stratos Idreos, Panagiotis Karras, and Roland H. C. Yap. Stochastic\ndatabase cracking: towards robust adaptive indexing in main-memory column-\nstores. Proc. VLDB Endow. , 5(6):502â€“513, 2012.\n[5] Stratos Idreos, Martin L. Kersten, and Stefan Manegold. Database cracking. In\nCIDR , page 68â€“78, 2007.\n[6] Goetz Graefe and Harumi Kuno. Adaptive indexing for relational keys. In 2010\nIEEE 26th International Conference on Data Engineering Workshops (ICDEW 2010) ,\npages 69â€“74, 2010.\n[7] Goetz Graefe and Harumi Kuno. Self-selecting, self-tuning, incrementally opti-\nmized indexes. In Proceedings of the 13th International Conference on Extending\nDatabase Technology , EDBT â€™10, page 371â€“381. Association for Computing Ma-\nchinery, 2010.\n[8] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim\nKraska. Fiting-tree: A data-aware index structure. In Proceedings of the 2019\nInternational Conference on Management of Data , SIGMOD â€™19, page 1189â€“1206.\nAssociation for Computing Machinery, 2019.\n[9] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. Radixspline: a single-pass learned index.\nInProceedings of the Third International Workshop on Exploiting Artificial Intel-\nligence Techniques for Data Management , aiDM â€™20, New York, NY, USA, 2020.\nAssociation for Computing Machinery.\n[10] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case\nfor learned index structures. In Proceedings of the 2018 International Conference\non Management of Data , SIGMOD â€™18, page 489â€“504, New York, NY, USA, 2018.\nAssociation for Computing Machinery.\n[11] Paolo Ferragina and Giorgio Vinciguerra. The pgm-index: a fully-dynamic\ncompressed learned index with provable worst-case bounds. Proc. VLDB Endow. ,\n13(8):1162â€“1175, 2020.\n[12] Yang Guang, Liang Liang, Ali Hadian, and Thomas Heinis. Flirt: A fast learned\nindex for rolling time frames. In Proceedings of the International Conference on\nExtending Database Technology (EDBT) , page 234â€“246, 2023.\n12\n\nLearned Adaptive Indexing\n[13] Pengfei Li, Hua Lu, Qian Zheng, Long Yang, and Gang Pan. Lisa: A learned index\nstructure for spatial data. In Proceedings of the 2020 ACM SIGMOD International\nConference on Management of Data , SIGMOD â€™20, page 2119â€“2133. Association\nfor Computing Machinery, 2020.\n[14] Yao Tian, Tingyun Yan, Xi Zhao, Kai Huang, and Xiaofang Zhou. A learned\nindex for exact similarity search in metric spaces. IEEE Trans. on Knowl. and\nData Eng. , 35(8):7624â€“7638, 2023.\n[15] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\nDavid Lomet, and Tim Kraska. Alex: An updatable adaptive learned index. In\nProceedings of the 2020 ACM SIGMOD International Conference on Management of\nData , SIGMOD â€™20, page 969â€“984. Association for Computing Machinery, 2020.\n[16] Ani Kristo, Kapil Vaidya, Ugur Ã‡etintemel, Sanchit Misra, and Tim Kraska. The\ncase for a learned sorting algorithm. In Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data , SIGMOD â€™20, page 1001â€“1016.\nAssociation for Computing Machinery, 2020.\n[17] Jiacheng Wu, Yong Zhang, Shimin Chen, Jin Wang, Yu Chen, and Chunxiao\nXing. Updatable learned index with precise positions. Proc. VLDB Endow. ,\n14(8):1276â€“1288, 2021.\n[18] Pengfei Li, Hua Lu, Rong Zhu, Bolin Ding, Long Yang, and Gang Pan. Dili: A\ndistribution-driven learned index. Proc. VLDB Endow. , 16(9):2212â€“2224, 2023.\n[19] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. Learning\nmulti-dimensional indexes. In Proceedings of the 2020 ACM SIGMOD International\nConference on Management of Data , SIGMOD â€™20, page 985â€“1000, New York, NY,\nUSA, 2020. Association for Computing Machinery.\n[20] Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. Tsunami:\na learned multi-dimensional index for correlated data and skewed workloads.\nProc. VLDB Endow. , 14(2):74â€“86, 2020.[21] Alex Watson, Suvam Kumar Das, and Suprio Ray. Daskdb: Scalable data science\nwith unified data analytics and in situ query processing. In 2021 IEEE 8th Inter-\nnational Conference on Data Science and Advanced Analytics (DSAA) , pages 1â€“10,\n2021.\n[22] Liang Liang, Guang Yang, Ali Hadian, Luis Alberto Croquevielle, and Thomas\nHeinis. Swix: A memory-efficient sliding window learned index. Proc. ACM\nManag. Data , 2(1), 2024.\n[23] Jianzhong Qi, Guanli Liu, Christian S. Jensen, and Lars Kulik. Effectively learning\nspatial indices. Proc. VLDB Endow. , 13(12):2341â€“2354, 2020.\n[24] Songnian Zhang, Suprio Ray, Rongxing Lu, and Yandong Zheng. Sprig: A learned\nspatial index for range and knn queries. In Proceedings of the 17th International\nSymposium on Spatial and Temporal Databases , SSTD â€™21, page 96â€“105. Associa-\ntion for Computing Machinery, 2021.\n[25] Songnian Zhang, Suprio Ray, Rongxing Lu, and Yandong Zheng. Efficient learned\nspatial index with interpolation function based learned model. IEEE Transactions\non Big Data , 9(2):733â€“745, 2023.\n[26] Matej Antol, Jaroslav Olâ€™ha, TerÃ©zia SlaninÃ¡kovÃ¡, and Vlastislav Dohnal. Learned\nmetric index â€” proposition of learned indexing for unstructured data. Information\nSystems , 100:101774, 2021.\n[27] Ibrahim Sabek, Kapil Vaidya, Dominik Horn, Andreas Kipf, and Tim Kraska.\nWhen are learned models better than hash functions?, 2021.\n[28] Atsuki Sato and Yusuke Matsui. Pcf learned sort: a learning augmented sort\nalgorithm with ğ‘œ(ğ‘›log logğ‘›)expected complexity, 2024.\n[29] Ibrahim Sabek and Tim Kraska. The case for learned in-memory joins, 2022.\n[30] Stratos Idreos, Stefan Manegold, Harumi Kuno, and Goetz Graefe. Merging\nwhatâ€™s cracked, cracking whatâ€™s merged: adaptive indexing in main-memory\ncolumn-stores. Proc. VLDB Endow. , 4(9):586â€“597, 2011.\n[31] Stochastic Database Cracking. https://github.com/felix-halim/scrack.\n[32] RadixSpline: A Single-Pass Learned Index.\nhttps://github.com/learnedsystems/RadixSpline.\n13",
  "textLength": 69378
}