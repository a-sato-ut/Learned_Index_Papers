{
  "paperId": "4e0cfe0823d85cc1108a17b4fbb7429d4613f3d1",
  "title": "Towards Learning-Augmented Peer-to-Peer Networks: Self-Stabilizing Graph Linearization with Untrusted Advice",
  "pdfPath": "4e0cfe0823d85cc1108a17b4fbb7429d4613f3d1.pdf",
  "text": "Towards Learning-Augmented Peer-to-Peer Networks:\nSelf-Stabilizing Graph Linearization with Untrusted Advice\nVijeth Aradhya * Christian Scheideler†\nAbstract\nDistributed peer-to-peer systems are widely popular due to their decentralized nature,\nwhich ensures that no peer is critical for the functionality of the system. However, fully decen-\ntralized solutions are usually much harder to design, and tend to have a much higher overhead\ncompared to centralized approaches, where the peers are connected to a powerful server. On\nthe other hand, centralized approaches have a single point of failure. Thus, is there some way\nto combine their advantages without inheriting their disadvantages? To that end, we consider\na supervised peer-to-peer approach where the peers can ask a potentially unreliable supervisor\nforadvice . This is in line with the increasingly popular algorithmic paradigm called algorithms\nwith predictions orlearning-augmented algorithms , but we are the first to consider it in the context\nof peer-to-peer networks.\nSpecifically, we design self-stabilizing algorithms for the fundamental problem of distributed\ngraph linearization , where peers are supposed to recover the “sorted line” network from any\ninitial network after a transient fault. With the help of the supervisor, peers can recover the\nsorted line network in O(logn)time, if the advice is correct; otherwise, the algorithm retains its\noriginal recovery time (i.e., without any supervisor). A crucial challenge that we overcome is to\ncorrectly compose multiple self-stabilizing algorithms, that is, one that processes and exploits\nthe advice, and another that does not rely on the advice at all. Our key technical contributions\ncombine ideas from the fields of overlay networks and proof-labeling schemes. Finally, we give\na matching lower bound of Ω(logn)for the recovery time of any algorithm if the advice can\nbe corrupted, where nis the network size.\nKeywords : distributed algorithms, overlay networks, self-stabilization, proof-labeling schemes\n*National University of Singapore, Singapore.\n†Paderborn University, Germany.\n1arXiv:2504.02448v1  [cs.DC]  3 Apr 2025\n\nContents\n1 Introduction 3\n1.1 Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.3 Network Model & Problem Definition . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2 Preliminaries 8\n2.1 Dual-State Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2 Universal Overlay Primitives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.3 Local Certification of Spanning Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n3 Sybil Resistant, Compact and Robust Advice 9\n3.1 Network Snapshot and Properties of Advice . . . . . . . . . . . . . . . . . . . . . . . 9\n3.2 Building a Global Structure from any Snapshot . . . . . . . . . . . . . . . . . . . . . . 9\n3.3 Locally Verifying the Advised sorted Path . . . . . . . . . . . . . . . . . . . . . . . . . 10\n3.4 Tree-to-Path Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n4 Flyovers: Fast Stabilization via Routing 12\n4.1 Variables, High-Level Design, and Initialization . . . . . . . . . . . . . . . . . . . . . 13\n4.2 Construction and Verification of Flyover . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4.3 Verification of Connectivity Certificate . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n5 Analysis Sketch 17\nA Pseudocodes 26\nA.1 Flyover Pseudocode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\nA.2 Tree-to-Path Pseudocode . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nA.2.1 Sequential Tree-to-Path . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nA.2.2 Distributed Tree-to-Path . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nA.3 Helper Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\nB Tree-to-Path Analysis 34\nC Self-Stabilization Analysis 35\nC.1 Basic Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\nC.2 Flyover-Related Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\nC.3 Helpful Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\nC.4 Connectivity Preservation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\nC.5 Flyover Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\nC.6 Fast Information Dissemination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nC.7 Concurrent Advices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nC.8 Fast Detection of Bad Advice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\nC.9 Putting Everything Together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\nC.10 Lower Bound for Convergence Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\nD Helpful Figures and Tables 50\n2\n\n1 Introduction\nTraditionally, online algorithms augmented with advice is an area of research where one attempts\nto measure how much knowledge of the future is necessary to achieve a given competitive ratio\n[15, 27]. However, the advice might not always be helpful since it is usually hard to predict the fu-\nture sufficiently well. Ideally, we would like that bad advice does not result in a competitive ratio\nthat is worse than what is achieved without any advice. Motivated by recent advances in machine\nlearning, a new line of research has thus looked at algorithms with predictions [65]. In this frame-\nwork [64], the algorithm takes advantage of an extra piece of information, called “prediction” (also\ncalled “advice” or “hint”), to achieve (near) optimal performance if the prediction is good, while\nalso not performing (much) worse than an algorithm without prediction, if the prediction is bad.\nWhile competitive analysis in the sequential online setting has been predominant for modeling\ntemporal uncertainty (i.e., the input is arriving piece by piece, and decisions need to be made on the\nfly), problems in distributed networks typically arise from spatial uncertainty where the input itself\nis divided among several compute nodes, and all nodes collectively perform global computation\n[4, 42, 69, 75]. To surmount the uncertainty, many researchers have investigated trade-offs between\nthe size of advice and the network’s performance for many problems (e.g., [26, 32–34, 37, 51]),\nseeking to minimize the information needed to efficiently solve them. Recently, however, there\nhas been a growing trend towards designing distributed algorithms that can not only exploit the\nadvice for better performance, but are also robust (i.e., retain their native performance without any\nadvice) when the advice is unreliable [1, 14, 38, 41].\nWe initiate the study of algorithms with untrusted advice for peer-to-peer systems, where the\npeers continuously execute local algorithms to maintain a desirable network with certain con-\nnectivity properties. As these systems are highly dynamic (for e.g., due to churn, link failures,\nmemory corruption, etc), such algorithms should quickly recover the network after any failure. To\nthat end, we consider the self-stabilization framework [21] that requires the system to converge to\na desirable state after any transient fault which can arbitrarily corrupt the system state. Following\nthe pioneering work of Dijkstra [21], self-stabilization has been promising for modeling recovery\nin distributed systems (e.g., [8, 13, 16, 17, 24, 43, 60]); for books, see [22, 76].\nSpecifically, we consider a network model where there is a supervisor that can be contacted\nby the peers if they need advice. Supervised networks have been considered in the past (e.g.,\n[2, 29, 35, 53]), but there only the case has been studied that the advice is reliable. In that scenario,\nthe peers can trust all the connections suggested by the supervisor, which would make the self-\nstabilization problem for overlay networks very easy: simply suggest the set of peers some peer\nshould ideally be connected to. But if the advice can be corrupted, for example, an advice to\nconnect to non-existing peers, then a malicious supervisor could easily start so-called Sybil attacks\n[25], i.e., attacks integrating many potentially malicious peers into the peer-to-peer (P2P) system,\nthat were previously not part of it.\nTo prevent such attacks, the advice of the supervisor must be limited to peers that a peer is\nalready connected to. Indeed, this scenario has been recently considered in [72], but that work\nonly considered how quickly a well-behaved supervisor can compute a near-optimal schedule for\ntransforming any initial overlay network into the desired overlay network, given that it can only\nsuggest network transformations by pointing to connections that the peers currently have. Bad\nadvice can be hard for peers to identify since they are only aware of their local neighborhood. It is\ncrucial that the advice does not throw the stabilization process backwards so that the peers never\n3\n\nFigure 1: Illustration for Graph Linearization . In peer-to-peer networks, there is a directed edge\n(u,v)if a node uhas the idof a node v(i.e., node ucan send messages to node v). Since the id of a\nnode can also be sent in a message, the network can change over time. Here, the nodes recover the\nsorted path: (v1,v2, . . . , v5).\nconverge to the desired network. Further, a crucial challenge is that self-stabilizing algorithms\nmust converge from any initial state, including arbitrarily bad advice from the supervisor.\nDespite the obstacles, we develop a generic self-stabilizing mechanism for solving the funda-\nmental problem of distributed graph linearization (topological sorting) [36, 45, 66, 67, 73], where\neach peer connects to its adjacent peer(s) in the topological sorted order to form the so-called\nsorted line network, no matter what kind of advice is given. This is achieved by a modular de-\nsign of separately executing lightweight self-stabilizing algorithms that process the advice, and any\nself-stabilizing algorithm that converges to the sorted line network without any advice.\nOur advice messages are of small size (per peer), and enable the peers to quickly build a hyper-\ncubic structure that facilitates efficient information exchange. Using that structure, a peer is able\nto connect to any other peer in the network. Crucially, the advice is also verifiable in the sense that\nif the advice is bad, the peers can quickly detect it and stop making any additional connections\ndue to that advice. Indeed, an added advantage of being able to detect bad advice in the self-\nstabilization setting is that the peers can quickly return to a state where they are again ready to\nreceive (correct) advice from the supervisor.\nOrganization. First, we describe our contributions, related work, and model. In Section 2, we\nstate a few preliminaries. In Section 3, we describe all the different aspects of the advice. In Section\n4, we provide the key details of the self-stabilizing processes. Finally, we give the analysis sketch\nin Section 5. All the algorithms and their full analysis are provided in the Appendix.\n1.1 Our Contributions\nWe take the first steps towards efficiently and robustly augmenting advice for efficient recovery\nof P2P networks. Specifically, we provide self-stabilizing algorithms for graph linearization , which\nhas been a foundation (i.e., an intermediate step) for many self-stabilizing networks (see, a recent\nsurvey of [30]). Our solution achieves an optimal self-stabilization time if the supervisor is honest;\notherwise, it retains the self-stabilization time of any solution without supervision.\nTo that end, we develop a novel and generic approach in which the supervisor needs to send\nonly one O(logn)-bit sized advice message to any peer, where ndenotes the network size. Sur-\nprisingly, despite this small advice, peers can quickly build a hypercubic structure that can be used\ntosecurely create new connections among peers. Specifically, every peer connects to its neighbor(s)\nin the sorted line network in O(logn)rounds, if the advice messages are correct; otherwise, each\npeer rejects its advice in O(logn)rounds, and stops making any additional edge manipulations\ndue to that advice. This is done in part by an interesting connection to the field of proof-labeling\nschemes [52], and the following key technical ingredient (which may be of independent interest)\n4\n\nfor overlay networks.\nTheorem 1.1 (Informal, Tree-to-Path) .There is a distributed algorithm for forming a path overlay from\na (labelled) tree overlay in O (1)rounds, whilst adding O (1)edges per peer.\nFor robustness against a (potentially) malicious supervisor, the peers (simultaneously) run\na “base algorithm A0,” which when run independently (i.e., without any supervisor) is known\nto self-stabilize in R (A0)rounds. When a peer receives an advice message, it executes a set of\nalgorithms (cf. Section 4), designed to expedite the base algorithm, so that the network can quickly\nself-stabilize. Combined with our design of advice, we get the following upper bounds (based on\nthe supervisor) for converging to the sorted line network.\nTheorem 1.2 (Upper Bound) .The network self-stabilizes in O (logn)rounds if the supervisor is honest;\notherwise, the network self-stabilizes in O (R(A0) +logn)rounds.\nFinally, we prove that this logarithmic convergence time barrier is unavoidable for any algo-\nrithm if the advice can be arbitrarily corrupted. In particular, since a malicious supervisor could\npotentially inject adversarial ids into the system [25], a peer must not make connections to any ar-\nbitrary peer id given in the advice. Thus, this constraint, that new edges can only be added to any\npeer’s current neighborhood, leads to the following lower bound (for converging to any network).\nTheorem 1.3 (Lower Bound) .There exists some initial configuration such that the convergence time for\nany pair of supervisor and overlay algorithms is Ω(logn)rounds.\n1.2 Related Work\nPeer-to-peer (P2P) systems have been in the spotlight for several decades (see, e.g., [59, 62, 70,\n71, 74]), due to their multifaceted architectures that give rise to different algorithmic challenges\nin many distributed systems, including but not limited to load-balancing (e.g., [28, 48]), overlay\nnetworks (e.g., [61, 68]), agreement (e.g., [6, 7]), publish/subscribe systems (e.g., [12, 18, 19]), Sybil\ndefense (e.g., [20, 40]), etc.\nIn many P2P systems, a cornerstone problem is building and maintaining a desirable overlay\nnetwork. Since these systems need to be highly resilient to failures, researchers have extensively\nworked on self-stabilizing algorithms for several networks; for e.g., variants of Skip and Chord\ngraphs [9, 44, 49], hypertrees and radix trees [5, 23], small-world graph [50], metric graph [39], etc;\nfor a comprehensive survey, see [30].\nGraph linearization is the main building block for many of the above self-stabilizing networks.\nSpecifically, a linearization algorithm (e.g. [67]) forms an ordering of peers (e.g. based on their ids),\nwhose structure is then exploited to build other components of the desired network. To the best\nof our knowledge, the state-of-the-art algorithm [44] that can recover the sorted line network runs\ninO(log2n)rounds. Notably, the Transitive Closure Framework (TCF) [10] is a generic approach\nfor the peers to recover any (locally-checkable) network in O(logn)rounds, but it is not scalable\nas it requires the peers to first form a clique network (i.e., each peer’s degree necessarily increases\ntoΩ(n)), and then converge to the desired network.\nRecently, the algorithmic framework of using predictions [65] has gained immense popularity\nin several fields of algorithms (e.g., [11, 47, 55, 56, 58, 63]) including distributed and networked\nalgorithms, for e.g., contention resolution [38], TCP acknowledgment [41], buffer management [1]\nand graph algorithms [14]. These algorithms are given an extra string of bits called “prediction”\n5\n\nto solve the problem. Typically, the prediction would give information about some “structure” of\nthe given input. However, the main challenge is to design robust algorithms (incl. the prediction)\nthat can retain their original performance regardless of what the prediction is, whilst performing\nmuch better if the prediction is helpful.\n1.3 Network Model & Problem Definition\nEntities. The system has two entities: nodes and a supervisor.\nNodes are computing entities that aim to distributively form a target topology , denoted by G∗,\nthrough their connections, where we say that two nodes are “connected” if they can communicate\n(i.e., send/receive messages) with each other. We colloquially use the word “network” (formally\ndefined soon) to capture the set of nodes and their connections. The number of nodes is denoted\nbyn. Furthermore, the nodes do not have any global knowledge (e.g., network size, shared clock,\netc). The nodes always execute the algorithms prescribed to them.\nAsupervisor is a single computing entity, designed to help the nodes form the target topology\nG∗through communication with the nodes to learn the (current) network, compute over it, and\npropose connections between nodes. If the supervisor follows its algorithm, we say that the super-\nvisor is honest ; otherwise, it is said to be malicious . There is no restriction on the messages sent by a\nmalicious supervisor, which may even include suggestions for connecting to non-existing nodes.\nNode ids. Each node has a unique identifier (id). Each node’s memory consists of two types of\nvariables: address and non-address variables. The address variables are exclusively used to store\nthe ids of other nodes (referred to as neighbors ), whereas the non-address variables cannot be used\nto store node ids.\nCommunication Rounds. The system proceeds in synchronous rounds, i.e., a message sent by\na node in any round is received by its recipient at the beginning of the next round. In every\nround, each node runs the given algorithms, given its variables’ assignments (and messages in the\nchannel), resulting in changes to its memory and new messages being sent.\nComm. among Nodes. Each node ucan send a message to another node vif the node uhas\nnode v’s id in its memory. If a message is sent to any node u, then it is added to node u’schannel\nu.Ch. Once a message is added to any node’s channel, the node is able to read the contents of\nthe message, after which the message is removed from the channel. In general, a node is not\ninformed about the (id of the) sender of a message, unless the sender explicitly adds its own id to\nthe message.\nStates and Configurations. Consider the standard state model for self-stabilization [21]. The\nvariables and channel of a node are stored in its register (aka, mutable memory) and each node has\nread/write access to its register. Each node also has a non-mutable memory that contains its id\nand the code of our algorithms. The set of values assigned to the variables and channel of a node\nis called the state of a node. Moreover, the tuple of states of all nodes is called the configuration ,\nand the (simultaneous) execution of the code by all the nodes, over consecutive rounds, forms a\nsequence of configurations.\nAs we consider a distributed message-passing system where the communication links can\nthemselves change over time, each node needs to explicitly communicate some information about\nits own state to (some of) node ids stored in its register, for the network to reach the target topology\n(see, [30, 44]), unlike in the standard model [21], where every node reads its own register and the\nregisters of all its neighbors, executes the algorithms and updates its register, in any given step.\n6\n\nCommunication Graph and Network. LetGC= (V,EC=EC∪IC)be the communication graph\nover the set of nodes Vin configuration C, where there exists an explicit edge (u,v)∈ECif a node\nv’s id is stored in any address variable of node u’s memory, or an implicit edge (u,v)∈ICif a node\nv’s id is in node u’s channel. The network is simply the communication graph restricted to explicit\nedges.\nComm. between Supervisor and Nodes. The supervisor is aware of the node membership\nin the system, i.e., ids of all the nodes. It can send a request to any node to learn the (current)\ncommunication graph. Moreover, the supervisor can send advice messages to help nodes quickly\nconverge to the desired target topology. As is typical, we assume that the supervisor cannot forge\nmessages sent by nodes.\nFunctions, Rules and Actions. Each node runs a sequence of algorithms , and each algorithm con-\nsists of a sequence of functions . A function has the form, ⟨Label⟩:⟨Guard ⟩ → ⟨ Rule 1; Rule 2; . . . ⟩,\nwhere label is the function name, guard is a Boolean predicate over the node’s variables, and rules\ndefine the actions by the node, where an action (typically) refers to either updating a local variable\nor sending a new message. Each rule is itself of the form ⟨Guard ⟩ → ⟨ Action 1; Action 2; . . . ⟩.\nPseudocodes. Each line in a function is typically dedicated to a single rule, but if there are\nmultiple rules in a line, then the last set of actions in that line belongs to the last rule. Moreover,\na function may callanother function in any of its rules. (In the standard state model [21], the\nalgorithms are directly defined by a set of rules; we extend it for better readability.)\nLocal Computation. In each round, each node checks the guard of every function in the specified\norder; if the guard is satisfied, the node executes the rules in the function. Similarly, a node checks\nthe guard of a rule; if it is satisfied, the node proceeds to execute the actions in it. Whereas, if no\nguard is specified, the function or rule is always executed.\nProblem Definition\nGiven any (weakly) connected communication graph, the nodes must form (and stay in) the target\ntopology. For graph linearization, the target topology is the network where each node is connected\nto its neighbor(s) in the sorted order, based on their ids. As the nodes also need to process the\nadvice given by the supervisor, we allow them to store a small number of extra edges, which help\nin quickly linearizing the network.\nInitial, Target and Legal Configurations. LetCandT ⊆ C be the set of allpossible configurations\nand the set of target configurations, respectively. Let Ibe the set of initial configurations where\n∀C∈ C,GCis weakly connected ⇐⇒ C∈ I. (We need only weak connectivity for the initial\nconfiguration, so the non-address variables can be arbitrarily corrupted.)\nThe “sorted path” network [67] is the target topology, G∗= (V,E∗), where ∀u,v∈V,(u=\nsucc(v)∨v=succ(u))⇐⇒ (u,v)∈E∗, where succ(u) = min({v|v.id>u.id}). Thus, Tis the\nset of configurations where the network is G∗.\nLetNC(u) ={v|(u,v)∈EC}denote the set of all edges stored by a node uin any con-\nfiguration C. LetLbe the set of legal configurations such that for each node u,∀C′∈ L ,∃C∈\nT,NC(u)⊆NC′(u)and∀C′∈ L ,∀C∈ T ,|NC′(u)|=O(|NC(u)|+logn). In other words, we\nallow every node to store at most logarithmic number of extra edges (i.e., besides the edges in the\nsorted path) in a legal configuration.\nSelf-Stabilization. We say that an algorithm is self-stabilizing if the network, starting from any\ninitial configuration, reaches a legal configuration ( convergence ), and stays in one ( closure ).\n7\n\nFigure 2: The universal communication primitives, used by our algorithms, incl. base algorithm.\n2 Preliminaries\n2.1 Dual-State Approach\nWe rely on a dual-state algorithm design, where the nodes always run a “base algorithm” A0(in the\nbackground), and an algorithm Ais executed for processing the advice given by the supervisor.\nMoreover, the base algorithm is known to self-stabilize in R (A0)rounds, without any interaction\nwith the supervisor. The objective of algorithm Ais to use the advice for introducing the neighbors\ninG∗to each other in O(logn)rounds, whilst adding as few additional edges as possible.\nWe distinguish the memory (including channel) used for the algorithms AandA0as M(A)\nand M (A0), respectively. Since these algorithms are run in tandem, to ensure connectivity for the\nbase algorithm, we define a “Flush” operation, denoted by Flush (·), that moves a given set of\nnode ids to any (arbitrary) address variable(s) of M (A0); this definition is as general as possible\nso that our approach works for any base algorithm.\n2.2 Universal Overlay Primitives\nLet us recall the four universal communication primitives (for edge manipulations) in the design\nof distributed self-stabilizing overlay algorithms (see, e.g., [30, 72]); see Figure 2.\nWhile preserving connectivity, they are used to transform any weakly connected graph to any\nother weakly connected graph.\n2.3 Local Certification of Spanning Tree\nOur algorithm for the supervised setting exploits a classic result in distributed computing: local\ncertification of spanning tree [3]. In general, in local certification, there exist a prover and a dis-\ntributed verifier ( fixed network of nodes). The prover assigns a small certificate to each node. Every\nnode inspects its certificate and the certificates of its neighbors to verify a given network property\n(e.g., spanning tree). If that property is specified correctly at each node, there exists a certificate\nassignment so that each node “accepts” its certificate; otherwise, regardless of what certificates are\nassigned by the prover, at least one node “rejects” its certificate. If the verification algorithm has\naccess to the node id, that type of certification is called proof-labeling scheme [52]. For more details,\nwe refer to a recent survey [31].\nSpecifically, for each node, a certificate for a spanning tree , with any node chosen as the root,\nconsists of the information: id of the root, id of the parent (in that tree), and distance of the node\nfrom the root. To locally verify the encoded spanning tree, each node carries out twochecks: (1)\nevery neighboring node has the same root id, and (2) its distance is onemore than the distance of\nits parent (called “distance-check”); and the root node checks that its distance is 0.\n8\n\n3 Sybil Resistant, Compact and Robust Advice\nHere, we provide the key intuition and details of the advice.\n3.1 Network Snapshot and Properties of Advice\nFirst, if the supervisor does not know anything about the current communication graph, there is no\nhope of giving useful advice because the supervisor should be restricted to a node’s neighborhood\nwhenever an edge is proposed. However, as P2P systems are dynamic, the communication graph\ncould have changed. Thus, there should be some mechanism where the nodes can send their\nneighborhoods when requested by the supervisor. Once the neighborhood is sent, a node can\nmaintain it for O(1)rounds, while continuing to run the base algorithm. (The details on this\ninteraction with the supervisor are given in Section A.2.2.) For simplicity, we assume that the\nsupervisor has access to a snapshot of the network, on which the advice can be computed, and that\nthe snapshot is maintained by the nodes.\nGiven any network snapshot, the supervisor can compute a (close to) minimum sequence of\nthe universal primitives (cf. Section 2.2), so that the network forms the target topology (see [72]\nfor details). However, since the nodes do not have any global information (e.g., round number,\netc), they would need to fully trust the supervisor for proposing appropriate edges to eventually\nform the target topology. This can be problematic for the convergence time as well as the number\nof edges stored by the nodes over time. Thus, there should be some mechanism by which a node\ncanquickly verify whether the proposed edges are indeed helpful, whilst also limiting the number\nof additional edges stored due to the supervisor.\nDesirable Properties. Based on these insights, we propose that the advice message at any given\nnode has the following properties to achieve both efficiency and robustness.\n1.Sybil-Resistant. For each node u, and for any node id vpresent in node u’s advice message\nbut not present in node u’s memory or channel, node uneither assigns vto any variable (i.e.\nstore in its memory), nor sends vto any other node (i.e., circulate it in the network).\n2.Compact. Size of the advice is small, i.e., a message of size at most O(logn)bits is given to\neach node.\n3.Robust. If any node received an incorrect advice, every node rejects its advice (if that node\nhad received advice), and restores the dedicated memory for handling advice (i.e., memory\nM(A)), in O(logn)rounds; whereas, if every node received correct advice, the nodes will be\nin a legal configuration in O(logn)rounds.\n3.2 Building a Global Structure from any Snapshot\nGiven the properties of advice, we describe two immediate challenges towards designing the ad-\nvice. First, we should be able to connect every pair of nodes that are adjacent in the sorted-path\ntopology but may be situated far away from each other in any given snapshot, in O(logn)rounds.\nSecond, if any node received an incorrect advice, the other nodes should be informed about it in\nO(logn)rounds by a scalable mechanism so that they can also quickly reject their advice.\nOne can observe that the above challenges arise from a lackof aglobal structure in the network.\nThus, our first attempt is to build a lightweight structure, specifically a hypercube , from the advice\n9\n\nFigure 3: Five nodes hierarchically introduce their neighbors to each other to form exponentially\nspaced-out shortcuts . Ifv4needs to send a message mto the node with virtual id 4 (i.e., v5),mis\nfirst forwarded to the “closest” shortcut (wrt. virtual ids ), i.e., v2; this is repeatedly done until m\neventually reaches v5.\ngiven to the nodes. Building a hypercubic overlay can be used to “kill two birds with one stone”:\nfirst, a node can rely on a local routing algorithm, where a message from a source is forwarded\nto the next node and so on until it reaches the destination, to initiate a new connection (e.g., for\nforming the sorted path); second, if a node detects any fault with the advice, it can quickly inform\nthe other nodes in the hypercube, after which the nodes can leave the hypercubic structure.\nNow, we enlist the steps for building a hypercubic structure.\n1.Snapshot to Tree. Supervisor chooses a rooted spanning tree in the snapshot. As part of the\nadvice, each node is given the id of its parent and the distance to the root.\n2.Tree to Path. Each node performs a local transformation (see Section 3.4, for the Tree-to-Path\nalgorithm), so that all the nodes are part of a single path . As part of the advice, nodes are\ngiven unique “virtual ids,” going from 1 to n, from one end of that path to the other.\n3.Path to Hypercube. By a pointer-doubling approach [46] (over that path), each node hierarchi-\ncally introduces its neighbors to each other. Thus, in O(logn)rounds, every node connects\nto “shortcuts,” at distances of 1, 2, 4, . . . from it, forming what we call a “flyover” which is a\nhypercubic structure1; for e.g., see Figure 3.\n4.Routing. Once the nodes form a flyover, every node can route messages to any other node\n[57] (c.f. Figure 3), using the virtual ids and shortcuts , inO(logn)rounds.\nAt this point, an astute reader may note that multiple flyovers could form in different parts of\nthe network, whereas some nodes may not even have received any advice. Such concurrency issues\nare exactly what makes this problem of handling a malicious supervisor difficult. In Section 4.2,\nwe outline how this flyover is carefully constructed and verified, and how small information (i.e.,\na unique identifier for flyover) is exchanged between the nodes (within and outside the flyover),\nto quickly detect faulty advice.\n3.3 Locally Verifying the Advised sorted Path\nAfter we have a desriable global structure (i.e., all the nodes forming a flyover over a sequentially\nnumbered path), one natural approach is that for each node, as part of its advice, send the virtual\nid (i.e., position on that numbered path) of its neighbor(s) in the target topology. Each node can\nthen quickly route its own id over the hypercubic structure to the node with that virtual id to create\na new connection, thereby forming the “advised” target topology. But as the nodes have a local\nview, they cannot easily verify if the actual target topology was indeed formed.\n1Note that a hypercube is technically defined for a network size that is a power of 2. In general, flyover belongs to a\nfamily of hypercubic networks, and that path and collection of shortcut edges contain the hypercube edges.\n10\n\nFor example, let the sorted path be (u1,u2, . . . , un), where u1is the node with the smallest node\nid. If the advice for node uiconsists of the virtual ids of nodes ui−1and ui+1, the node uican send\nits own node id to them via “hypercubic routing” (by virtual ids and shortcuts; e.g., see Figure 3)\n[57], and make a connection to them. Once these edges are added, each node can locally verify that\nit has at most 2 edges, and if it has 2 edges, it is the “middle” node id (in sorted order). But a bad\nsupervisor can give advice so that the paths (u1, . . . , un/2)and(un/2, . . . , un)are formed, without\nany node detecting any fault with the advice. In other words, the “advised” sorted path (i.e.,\nconnections suggested by the supervisor via virtual ids) do not form a single connected component.\nBeing able to (distributively) detect if any two components of the overlay are connected, is a non-\ntrivial task with the best-known technique (i.e., linear-probing), requiring O(n)rounds [30].\nAlgorithm 1 Supervisor Algorithm\nRequire: Snapshot (connected and undirected graph) GS= (V,ES).\n1:LetAdv(u)denote the advice message sent to a node u. Moreover, if Adv(u).x=y, then\n“x=y” appears in the advice message for the node u; Let dist T(u,v)denote the distance\nbetween any nodes uand vin a tree T;\n2:/ / Relevant graphs (definitions)\n3:LetTSbe a labelled rooted spanning tree in GSwith any node ras root, and l(·):V→ { 0, 1}\nas the labeling where l(r) =0∧(∀v∈V,l(v) =l(r) +dist TS(v,r)mod 2 );\n4:LetPSbe (undirected version of) the path returned by Tree-to-Path algorithm (see, Section 3.4)\nover input TS;\n5:Let G∗= ( V,E∗)be the (undirected) sorted path where ∀u,v∈V,u=succ(v)∨v=\nsucc(u)⇐⇒ (u,v)∈E∗;\n6:LetT∗be the rooted spanning tree, called the sorted-path tree , in the sorted path G∗with node\nras the root;\n7:foreach node u∈Vdo\n8: / / Virtual id (i.e., position on the path; cf. Section 3.2)\n9: Adv(u).vID :=dist PS(u,r) +1;\n10: / / To verify the “advised” sorted path (cf. Section 3.3)\n11: u̸=r→Adv(u).c-par :=dist PS(u′,r) +1, where u′is the parent of uinT∗; / / Virtual id of\nu’s parent in T∗\n12: Adv(u).c-dist :=dist T∗(u,r);\n13: / / For the Tree-to-Path Algorithm (cf. Section 3.4)\n14: u̸=r→Adv(u).par:=node id of u’s parent in TS;\n15: Adv(u).dist:=dist TS(u,r);\n16:end for\nTo fix such connectivity-related issues in the advised sorted path, we make use of local certification\nof a spanning tree (cf. Section 2.3). Specifically, the sorted path G∗isencoded as a rooted spanning\ntree called “sorted-path tree T∗,” where the root is the node whose virtual id is 1. As part of\nadvice, each node is given the virtual id of its parent, and the distance to the root, in the tree T∗.\nSee Algorithm 1, and Figure 4 for a pictorial example. In local certification, the verification of the\ncertificates is carried out over a fixed network, but in our case, the nodes in T∗may not even be\nconnected. Thus, each node uses the hypercubic structure for routing and connecting to its parent\ninT∗. Moreover, that structure is also used to quickly disseminate the node id of the root in T∗\n11\n\nFigure 4: An example of the advice and its outcome (cf. Algorithm 1), where the sorted path G∗\nis(v1, . . . , v5). Here, the (red) dashed edges form the output of the Tree-to-Path Algorithm, and\nthe (blue) dotted edges depict the encoded tree T∗. Note that those dotted edges are formed via\nrouting over the flyover (hypercubic structure).\nto all the nodes. In Section 4.3, we explain how the formation and verification of the tree T∗is\naccomplished via routing over the hypercubic structure.\n3.4 Tree-to-Path Algorithm\nLetT= (l(·),r,V,E)be a labelled rooted undirected tree, where Vis the set of vertices, r∈V\nis the root, l(·):V→ { 0, 1}is alabel function on vertices where l(v) = ( l(r) +dist(r,v))mod 2,\nand Eis the set of edges. Let CT(v) ={u|dist(u,v) =1∧dist(v,r)<dist(u,r)}be the children of\nv∈Vin the tree T, and there is a total order (for e.g., based on ids) on CT(v) ={u1, . . . , uq}such\nthat u1<· · ·<uqfor any q≥1. Let Beg (P)and End (P)of a directed path Pof size at least 2,\ndenote the vertex with no incoming edge and the vertex with no outgoing edge, respectively.\nWe briefly describe the Tree-to-Path algorithm that takes a labelled rooted tree as input, and out-\nputs a directed path. See Figure 5 for the pictorial description. Specifically, the algorithm takes in\na tree T= (l(·),r,V,E)as input, and outputs a directed path Pwhere Beg (P) =rand End (P) =\nmin(CT(r))ifl(r) = 0, whereas it outputs a directed path Pwhere Beg (P) = max(CT(r))and\nEnd(P) = rifl(r) = 1. We incorporate this alternation based on labels for maintaining the in-\nvariant that Beg (P)and End (P)are at a distance of 1. Such a simple, fast and local algorithm is\namenable to be made self-stabilizing. In Section A.2.2, we give the self-stabilizing version of the\nalgorithm that converts any (connected) overlay to a path overlay, using the given advice, in O(1)\nrounds.\n4 Flyovers: Fast Stabilization via Routing\nWe rely on the dual-state approach (cf. Section 2.1), where a node executes a set of algorithms (for\nhandling the advice) for helping the base algorithm to quickly form the sorted path.\nIn this section, we give the intuition and pseudocodes for three self-stabilizing processes, that\nare concurrently executed to help the nodes form the sorted path in O(logn)rounds, if the advice\nis correct; otherwise, every node ignores the advice in O(logn)rounds, whilst still executing the\nbase algorithm. Before delving into the details, we outline the design of our solution, and also\ndescribe the roles of all the variables for it.\n12\n\nFigure 5: Cases in Tree-to-Path Algorithm for any node viwhere iis its order (e.g., via total order\non ids) in set C(P(vi)), i.e., LeftSib (vi) ={vj|j<i}and RightSib (vi) ={vj|j>i}.L(v),P(v)\nand C(v)are label, parent and children of a node v(resp.). Dashed arrow depicts an edge in the\nfinal path.\n4.1 Variables, High-Level Design, and Initialization\nWe refer to the hypercubic structure that a node belongs to as a flyover , as the nodes “bypass” the\ncurrent network to find “short paths” to other nodes. Recall that a flyover is built on some path\n(over all the nodes) formed due to the advice (cf. Section 3.4).\nVariables. First, we explain all the variables of any node uthat make up a flyover.\n1.u.Land u.Rdenote the sets of left and right shortcuts (resp.); recall, shortcuts are node ids that\nare at distance 1, 2, 4, . . . on the path. u.S=u.L∪u.Ris the set of all shortcuts. Moreover,\nwe refer to u.Sl(i)and u.Sr(i)as the “ i-level” left and right shortcut (resp.).\n2.u.vID is used for storing the virtual id ; recall, the virtual id is provided in the advice, which\nis used to determine its position on the path. (This is not to be confused with the unique id of\na node, see Section 1.3; when we just refer to “id,” we mean the unique id of the node.) By\ndesign, the node with noleft shortcut has virtual id 1.\n3.u.flyID is used for storing a “unique identifier” for the flyover, called the flyover id . By design,\nthe node id of the node with noleft shortcut, determines the flyover id.\n13\n\n4.u.exitis a binary variable indicating if the node should exitthe flyover. If any node exits the\nflyover, it runs only the base algorithm (until it receives a new advice).\nWe also use three variables for storing and verifying what we refer to as connectivity certificate ,\nbased on the local certification of spanning tree; these variables are used for certifying the sorted-\npath tree T∗. (Algorithm 1 has the definition of T∗.)\n1.u.c-par is used for storing the virtual id of the parent of node uin the sorted-path tree T∗.\n2.u.c-dist is used for storing the distance from the root to node uin the sorted-path tree T∗.\n3.u.c-ids is used for storing the node ids of node u’s neighbors in the sorted-path topology G∗.\nOur Design. A node uupdates the variables u.vID,u.c-par and u.c-dist (if it’s not part of a flyover)\nwhen it receives the advice. (See Algorithm 1 for how those values are determined.) The Tree-to-\nPath algorithm is then executed, and based on its position, the first left and right shortcuts, i.e.,\nu.Sl(1)and u.Sr(1), are updated to its left and right neighbors on the path (resp.). Subsequently,\nthe nodes build the flyover over the path via pointer-doubling, where the (i+1)-level shortcuts\nare formed from the i-level shortcuts; see Figure 3. By design, the node id of the “leftmost” node\n(in the path), say, node vwith v.L=∅∧v.R̸=∅, is the flyover id , and is propagated to the rest of\nthe nodes in flyover, i.e., for any node u,u.flyID is initially assigned its own node id (as a default\nvalue), but is eventually assigned the flyover id. Moreover, node vis the only node with v.vID=1\nand v.c-dist =0, as it is the root in the sorted-path tree T∗. See Figure 4 for an illustration.\nTo verify the connectivity certificate, i.e., execute distance-checks (cf. Section 3.3), each node\nu̸=vmust send the distance u.c-dist to the node with virtual id u.c-par , say node w, on the flyover.\nHowever, since node umay not have a direct connection to node w, it sends u.c-dist to the closest\nleft or right shortcut (depending on the virtual ids, i.e., u.vID and u.c-par ), and so on, until this\nmessage eventually reaches node wwhose virtual id is u.c-par . This is a standard method for\nrouting a message between any pair of nodes in a hypercubic structure [57], on which we further\nprovide details below. Finally, once the node wreceives this message, it adds node id utow.c-ids\nif the distances match, i.e., w.c-dist =u.c-dist−1 (to form the sorted path). Moreover, every node\nuchecks that it is sorted with respect to node ids in u.c-ids (to verify the sorted path).\nInit Function. Our design results in a few simple tests that are executed in every round; see\nAlgorithm 2. Here, the NextStop (x)function returns the i-level left or right shortcut, whose\nvirtual id, u.vID±2i, is closest to x; if it is not possible to do so (e.g., u.vID<xand a right shortcut\ndoes not exist), then the function returns “ ∅”. see Algorithm 3 for its description. Observe that\nif any of the tests fail, u.exitis updated to 1. In that case, node urejects the flyover, i.e., it sends\n⟨RejFlyover ⟩message to all the node ids, flushes those ids (see Section 2.1 for the “flush” operation),\nand sets all the variables to the default values.\n4.2 Construction and Verification of Flyover\nHere, we explain the first two self-stabilizing processes concerned with the flyover structure. As\nthe flyover is symmetrically built over some path, for readability, we provide the explanations with\nrespect to right shortcuts (if they exist), which similarly apply for left shortcuts. Recall that if a\nnode vis ai-level (right) shortcut of node u, then node vshould be of distance 2ito (the right of)\nnode uon the path.\n14\n\nAlgorithm 2 Init\n1:BasicChecks\n2:(∃⟨RejFlyover ⟩ ∈u.Ch)→u.exit:=1;\n3: / / Flyover structure\n4: u.S=∅∧(u.c-ids̸=∅∨u.flyID̸=u.id)→u.exit:=1;\n5:(u.L̸=∅∧u.vID≤1)→u.exit:=1;\n6:(u.L=∅∧u.R̸=∅)∧(u.vID̸=1∨u.flyID̸=u.id)→u.exit:=1;\n7: / / Connectivity certificate\n8:(u.vID=1∧u.c-dist̸=0)→u.exit:=1;\n9:(u.vID>1∧u.c-dist≤0)→u.exit:=1;\n10: (u.S̸=∅∧u.vID>1)∧(NextStop (u.c-par) =∅)→u.exit:=1;\n11: / / Sorted-path topology\n12:|u.c-ids|>2→u.exit:=1;\n13:|u.c-ids|=2∧(u.id>max(u.c-ids))→u.exit:=1;\n14:|u.c-ids|=2∧(u.id<min(u.c-ids))→u.exit:=1;\n15:\n16:RejectFlyover :u.exit=1→\n17: / / Inform and flush the node ids part of node u’s flyover\n18: SendRejFly ((u.S∪ {u.flyID} ∪u.c-ids)\\u.id);\n19: / / Set the variables to their default values\n20: u.L:=∅;u.R:=∅;u.vID :=0;u.flyID :=u.id;\n21: u.exit:=0;u.c-par :=0;u.c-dist :=−1;u.c-ids :=∅;\nOur algorithms consist of a precise set of conditions for both, sending a particular message,\nand for specific actions to be taken (for e.g., update the set of shortcuts, or set the exit variable to\n1) after receiving a message. Moreover, if any node uis not part of any flyover (i.e., u.S=∅), and\nreceives a message regarding a flyover, then node usends ⟨RejFlyover ⟩message to the node ids\npart of that message, and flushes them.\nAlgorithm 4 provides the sequence of rules that govern the construction of the flyover.\nA node usends its own node id to its first right shortcut, u.Sr(1), using the ⟨TestLine-R ⟩mes-\nsage, to verify whether that information is correct. Consequently, the node that receives the mes-\nsage, sends ⟨RejFlyover ⟩message to node u, and flushes it, if node uis not its left neighbor.\nA node usends its i-level left shortcut u.Sl(i), including its own id, to its i-level right shortcut\nu.Sr(i), using ⟨FlyConst-R ⟩message, so that u.Sr(i)can add or verify its (i+1)-level left shortcut.\nThis set of rules facilitates a pointer-doubling style, bottom-up flyover construction over the path\n(regardless of any shortcuts that may already exist). Consequently, the node that receives the\nmessage, say node w, sets w.Sl(i+1) = u.Sl(i)only if |w.L|=iand w.Sl(i) = u; otherwise, it\nsends ⟨RejFlyover ⟩to nodes uand u.Sl(i), and flushes them.\nAlgorithm 5 gives the sequence of rules for the verification of virtual id and flyover id.\nA node usends the value 2(i−1)+u.vID to node u.Sr(i), using ⟨TestvID ⟩message, to verify\nthe distance of its i-level right shortcut (over the path that the flyover is constructed on). Conse-\nquently, the node that receives the message, say node w, sets w.exit=1 if its virtual id does not\nmatch the value.\nA node usends its u.flyID (flyover id), using ⟨TestFlyID ⟩message, to all node ids, except\n15\n\nAlgorithm 3 Helper Functions (Executed Only When Called)\n1:NextStop (val)\n2:(val<1∨val=u.vID)→Return “ ∅”;\n3:(u.S=∅∨u.vID<1)→Return “ ∅”;\n4:(val>u.vID∧u.R=∅)→Return “ ∅”;\n5:(val<u.vID∧u.L=∅)→Return “ ∅”;\n6: if(val>u.vID)then\n7: Return u.Sr(argmini∈|u.R|(|u.vID+2(i−1)−vID|));\n8: else\n9: Return u.Sl(argmini∈|u.L|(|u.vID−2(i−1)−vID|));\n10: end if\n11:\n12:SendRejFly (nodes )\n13: SEND( ⟨RejFlyover ⟩) to ids in nodes ;Flush (nodes );\nu.flyID , in memory (incl. M u(A0), memory of base algorithm), if either node uis the leftmost\nnode, or u.flyID has been updated (i.e., u.flyID̸=u.id). Furthermore, a node u, when it is ready\nto receive advice from the supervisor (i.e., u.S=∅∧u.vID=0), sends “ ⊥” to all the node ids\nusing⟨TestFlyID ⟩message. Crucially, this exchange of information (i.e., flyover id) acts as a simple\nmechanism for handling a supervisor that concurrently sends bad advice to nodes in different\nparts of the network, in that it helps the nodes quickly detect if there is a flyover constructed over\nany subset of nodes. Consequently, the node that receives the message, say node w, sets w.flyID\ntou.flyID , only if it is not the leftmost node, and w.flyID has not been updated yet (i.e., w.flyID\nis assigned to w.id). Finally, if w.flyID does not match u.flyID , node wsets w.exit=1, and sends\n⟨RejFlyover ⟩message to node u.flyID , and flushes it.\n4.3 Verification of Connectivity Certificate\nHere, we explain the self-stabilizing process for verifying and forming the sorted-path topology.\nAlgorithm 6 provides the sequence of rules for routing and verifying connectivity certificates.\nFirst, each node ubegins this process after its flyover id u.flyID has been updated (i.e., u.flyID̸=\nu.id). Recall that each node usends u.flyID , via⟨TestFlyID ⟩message, to all node ids in memory, to\nensure that a single flyover exists. Thus, the node id of the root in tree T∗(i.e., node with virtual id\n1; see Algorithm 1) gets stored and verified by each node.\nA node uneeds to send u.c-dist (i.e., distance to the root in T∗), to the node with virtual id\nu.c-par , say node v. For doing so, the node u routes both u.c-dist and u.id, using ⟨TestCert ⟩message,\nvia an appropriate left or right shortcut (based on the virtual ids), and so on, until the message\nreaches node v. Recall, NextStop (x)returns the i-level left or right shortcut, whose virtual id,\nu.vID±2i, is closest to x. In a hypercubic structure, a message can be routed this way in O(logn)\nrounds, as the distance to the intended destination is halved each time.\nConsequently, the node that receives the message, say node w̸=v, assigns w.exit=1,\nand sends ⟨RejFlyover ⟩message to node u, if the message cannot be further forwarded (i.e.,\nNextStop (u.c-par)function returns “ ∅”). Finally, when the node vreceives it, if the virtual ids\nand distances match (i.e., v.vID=u.c-par and v.c-dist =u.c-dist−1), node vadds the node id uto\n16\n\nAlgorithm 4 Flyover Construction\n1:TestFlyoverConstruction\n2: u.R̸=∅→SEND( ⟨TestLine-R, u.id⟩) tou.Sr(1);\n3: u.L̸=∅→SEND( ⟨TestLine-L, u.id⟩) tou.Sl(1);\n4: if(u.R̸=∅∧u.L̸=∅)then\n5: foreach iin{1, . . . , min (|u.R|,|u.L|)}do\n6: SEND( ⟨FlyConst-R, u.Sl(i),i,u.id⟩) tou.Sr(i);\n7: SEND( ⟨FlyConst-L, u.Sr(i),i,u.id⟩) tou.Sl(i);\n8: end for\n9: end if\n10:\n11:/ / Here, we omit code for a “. . . -L” msg due to similarity in handling a “. . . -R” msg\n12:R_TestFlyoverConstruction\n13: foreach received message ⟨TestLine-R, sen⟩do\n14: (u.L̸=∅∧u.Sl(1)̸=sen∨u.L=∅)→u.exit:=1;\n15: u.S=∅∨u.exit=1→SendRejFly ({sen});\n16: end for\n17: foreach received message ⟨FlyConst-R, w,i,sen⟩do\n18: u.L=∅∨(|u.L| ≥i∧u.Sl(i)̸=sen)→u.exit:=1;\n19: |u.L| ≥(i+1)∧u.Sl(i+1)̸=w→u.exit:=1;\n20: (u.exit=0)∧(1<|u.L|<i)→Flush ({sen,w});\n21: (u.exit=0)∧(|u.L|=i∧u.Sl(i) =sen)→u.Sl(|u.L|+1):=w; / / Update shortcut!\n22: u.S=∅∨u.exit=1→SendRejFly ({sen,w});\n23: end for\nv.c-ids , and sends its own node id to node u, so that node ustores it in u.c-ids ; otherwise, the node\nvsets v.exit=1, and sends ⟨RejFlyover ⟩to node u, and flushes it.\n5 Analysis Sketch\nIn this section, we describe the analysis sketch for all the critical aspects of our algorithms. The\npseudocodes are given in Section A, and the full analyses are given in Section B and C.\nFirstly, we show that the edges added by the Tree-to-Path algorithm (c.f. Figure 5; see Al-\ngorithm 10 for the pseudocode.) form a single (directed) path over the nodes. We use a proof\nby induction over the height of a labbelled rooted tree. We consider two base cases for the trees\nof height equal to 1, with the label of the root equal to either 0 or 1, where the height of a tree\nT= (l(·),r,V,E)is equal to max v∈V(dist T(r,v)). For the inductive case, we consider any tree\nT= (l(·),r,V,E)of height greater than 1, and then show that the algorithm outputs a directed\npath Pwhere Beg (P) =rand End (P)is min (CT(r))ifl(r) =0; whereas it outputs a directed path\nPwhere Beg (P)is max (CT(r))and End (P) =rifl(r) =1.\nTheorem 5.1. The Tree-to-Path Algorithm takes a labelled rooted tree T = (l(·),r,V,E)where l (r) = 0\nas input, and outputs a directed path P = (V,E′)where Beg(P) =r and End(P) =min(CT(r)).\nNext, we show that the construction of shortcuts over that path happens in O(logn)rounds,\n17\n\nAlgorithm 5 Flyover Metadata\n1:TestFlyoverMetadata\n2: / / Propagate the flyover id if it is updated\n3: prop-flyID := (u.vID=1)∨(u.vID>1∧u.flyID̸=u.id);\n4: prop-flyID →SEND( ⟨TestFlyID, u.flyID⟩) to all ids, except u.flyID , in memory;\n5: / / Ready to receive advice; inform other nodes about it\n6:(u.S=∅∧u.vID=0)→SEND( ⟨TestFlyID, ⊥⟩) to all ids in memory;\n7: / / Check that shortcuts are exponentially spaced-out\n8:|u.R| ≥1→SEND( ⟨TestvID, (u.vID+2(i−1))⟩) tou.Sr(i)for all i∈[|u.R|];\n9:|u.L| ≥1→SEND( ⟨TestvID, (u.vID−2(i−1))⟩) tou.Sl(i)for all i∈[|u.L|];\n10:\n11:R_TestFlyoverMetadata\n12: foreach received message ⟨TestvID, vID⟩do\n13: (u.S=∅)∨(u.S̸=∅∧u.vID̸=vID)→u.exit=1;\n14: end for\n15: foreach received message ⟨TestFlyID, flyID⟩do\n16: if(u.L̸=∅∧u.exit=0)then\n17: u.flyID =u.id∧flyID̸=⊥ → u.flyID :=flyID ; / / Update flyID!\n18: end if\n19: (u.S̸=∅∧u.flyID̸=flyID)→u.exit=1;\n20: (u.S=∅∧flyID̸=⊥)→u.exit=1;\n21: u.exit=1→SendRejFly ({flyID});\n22: end for\nimplying that information (e.g., ⟨RejFlyover ⟩messages) can be quickly disseminated in any fly-\nover. Thus, if the flyover is not correctly built, i.e., virtual ids are not consecutive, or shortcuts are\nnot exponentially spaced-out, or flyover id is not properly assigned, then due to Algorithms 2, 4\nand 5, some node detects and propagates the fault in the flyover, cueing other nodes to also exit\nthe flyover.\nHowever, if a flyover is “internally correct,” and is formed over a subset of nodes, then some\nkey information needs to be exchanged between the nodes inside and outside the flyover. To that\nend, we rely on Algorithm 5 where every node sends its flyover id to all node ids in the memory.\nAs all our algorithms rely on the universal primitives (cf. Section 2.2) that preserve (weak) con-\nnectivity, there must exist an (incoming/outgoing) edge to that flyover in any round. By carefully\ncarrying out a case-by-case analysis of how that edge can show up in a node’s memory, we prove\nthe following lemma.\nLemma 5.2. Consider any set of nodes B ={v1, . . . , v|B|}in any round r, where |B|<n and (v1.L=\n∅∧v|B|.R=∅)and(∀i∈[|B| −1],vi.Sr(1) = vi+1∧vi+1.Sl(1) = vi). By round r +O(logn), at\nleast one node u ∈B assigns u .exit=1.\nMoreover, we prove that if all the nodes indeed form a single flyover, but if the connections\nsuggested by the supervisor (via virtual ids) do not form G∗(see Section 3.3 for a discussion), then\ndue to Algorithms 2 and 6 (i.e., routing the connectivity certificates), at least one node quickly\ndetects the bad advice.\n18\n\nAlgorithm 6 Connectivity Certificate\n1:TestConnCert :(u.vID>1∧u.flyID̸=u.id)→\n2: SEND( msg) toNextStop (u.c-par)where msg is⟨TestCert, u.id,u.c-par ,u.c-dist⟩; / / Route\n3:\n4:R_TestConnCert\n5: prop-flyID := (u.vID=1)∨(u.vID>1∧u.flyID̸=u.id);\n6: foreach received message ⟨TestCert, w,vID,dist⟩do\n7: / / Distances don’t match / Unable to route\n8: (u.vID=vID)∧(dist−1̸=u.c-dist)→u.exit:=1;\n9: (u.vID̸=vID)∧(NextStop (vID) =∅)→u.exit:=1;\n10: if(u.S=∅∨u.exit=1)then\n11: SendRejFly ({w});\n12: else\n13: ifu.vID=vIDthen\n14: u.c-ids :=u.c-ids∪ {w}; / / Accept id!\n15: SEND( ⟨IntroCert, u.id⟩) tow; / / Bidirected edge\n16: else\n17: ¬prop-flyID →Flush ({w});\n18: prop-flyID →SEND( ⟨TestCert, w,vID,dist⟩) to NextStop (vID); / / Route, if flyID is\nupdated\n19: end if\n20: end if\n21: end for\n22: foreach received message ⟨IntroCert, w⟩do\n23: u.c-ids :=u.c-ids∪ {w}; / / Bidirected edge\n24: end for\nClaim 5.3. Let V ={v1, . . . , vn}and(v1.L=∅∧vn.R=∅)and(∀i∈[n−1],vi.Sr(1) = vi+1∧\nvi+1.Sl(1) = vi)and(∀i∈[n],vi.vID=i∧vi.flyID =v1). Let G′= (V,E′)such that (u,v)∈\nE′⇐⇒ (u.vID=v.c-par∧v.c-dist =u.c-dist +1)∨(v.vID=u.c-par∧v.c-dist =u.c-dist−1). If\n∀i∈[n]\\ {1},∃ui∈V,vi.c-par =ui.vID where (ui.c-dist =vi.c-dist−1), then G′is same as G∗.\nProof Sketch. Due to Algorithm 2, the following invariants are satisfied for each node u∈V.\n1. (Tree Distance) (u.L=∅=⇒u.c-dist =0)and(u.L̸=∅=⇒u.c-dist>0).\n2. (Degree Constraint; Locally Sorted) E′′(u)̸=∅=⇒(|E′′(u)|=1)∨(|E′′(u)|=2∧\nmin(|E′′(u)|)<u.id<max(|E′′(u)|)), where E′′(u) ={v|(u,v)∈E′}.\nThe above invariants ensure that there can be only one node uwith u.c-dist =0, and that node is v1.\nMoreover, the degree of any node in G′is at most 2; if a node’s degree is 2, then its own id is neither\ngreater nor less than both the node ids of its neighbors. Given the premise of the lemma, for any\nnode u∈V\\ {v1}, there is a node p(u)such that u.c-par =p(u).vIDand p(u).c-dist =u.c-dist−1.\nWe use proof by contradiction to show that G′is indeed G∗. First, there cannot be a cycle in G′,\nas the distance checks (i.e., from a node uto its parent p(u)) cannot be satisfied at all the nodes (cf.\nSection 2.3). Moreover, G′cannot be a spanning forest because all the nodes, via flyover id, can\n19\n\nverify that there is only one “root node,” which is node v1with its distance v1.c-dist =0. Thus,\nG′forms a spanning tree. Combining the second invariant mentioned earlier, i.e., each node has\ndegree at most 2, the tree must be a path. Finally, that path has to be the sorted path G∗due to the\nsecond invariant because every node checks that its locally sorted with its neighbors in G′.\nFinally, we give a lower bound on the convergence time given that the nodes are restricted\nto make edge manipulations in their current neighborhood. The key observation is that if the\ndistance between any two nodes uand visDin round r, the distance between them is at least\nD/2tin round r+t, even if all nodes introduce all the node ids in their memory to each other in\nevery round. Thus, if the nodes uand vshould be adjacent in the target topology, it takes Ω(logn)\nrounds for node uto obtain the node id v(or vice versa) in the worst-case.\nTheorem 5.4. For any Sybil-resistant network, there exists an initial configuration such that the conver-\ngence time for any pair of supervisor and overlay algorithms is Ω(logn)rounds.\nReferences\n[1] Vamsi Addanki, Maciej Pacut, and Stefan Schmid. Credence: Augmenting datacenter switch\nbuffer sharing with ML predictions. In Proc. NSDI , pages 613–634, 2024. 3, 5\n[2] Yehuda Afek, Gal Giladi, and Boaz Patt-Shamir. Distributed computing with the cloud. Dis-\ntributed Comput. , 37(1):1–18, 2024. doi:10.1007/S00446-024-00460-W . 3\n[3] Yehuda Afek, Shay Kutten, and Moti Yung. Memory-efficient self stabilizing protocols for\ngeneral networks. In Proc. WDAG , pages 15–28, 1990. doi:10.1007/3-540-54099-7\\_2 . 8,\n38\n[4] Amirreza Akbari, Navid Eslami, Henrik Lievonen, Darya Melnyk, Joona Särkijärvi, and\nJukka Suomela. Locality in online, dynamic, sequential, and distributed graph algorithms.\nInProc. ICALP , pages 10:1–10:20, 2023. doi:10.4230/LIPICS.ICALP.2023.10 . 3\n[5] James Aspnes and Yinghua Wu. O(logn)-time overlay network construction from graphs\nwith out-degree 1. In Proc. OPODIS , pages 286–300, 2007. doi:10.1007/978-3-540-77096-\n1\\_21 . 5\n[6] John Augustine, Gopal Pandurangan, and Peter Robinson. Fast byzantine agreement in dy-\nnamic networks. In Proc. PODC , pages 74–83, 2013. doi:10.1145/2484239.2484275 . 5\n[7] John Augustine, Gopal Pandurangan, Peter Robinson, and Eli Upfal. Distributed agreement\nin dynamic peer-to-peer networks. J. Comput. Syst. Sci. , 81(7):1088–1109, 2015. doi:10.1016/\nJ.JCSS.2014.10.005 . 5\n[8] Baruch Awerbuch, Shay Kutten, Yishay Mansour, Boaz Patt-Shamir, and George Varghese.\nTime optimal self-stabilizing synchronization. In Proc. STOC , pages 652–661, 1993. doi:\n10.1145/167088.167256 . 3\n[9] Andrew Berns. Network scaffolding for efficient stabilization of the chord overlay network.\nInProc. SP AA , pages 417–419, 2021. doi:10.1145/3409964.3461827 . 5\n20\n\n[10] Andrew Berns, Sukumar Ghosh, and Sriram V . Pemmaraju. Building self-stabilizing overlay\nnetworks with the transitive closure framework. Theor. Comput. Sci. , 512:2–14, 2013. doi:\n10.1016/J.TCS.2013.02.021 . 5\n[11] Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, and Manish Purohit. Online linear optimiza-\ntion with many hints. In Proc. NeurIPS , 2020. 5\n[12] Silvia Bianchi, Pascal Felber, and Maria Gradinariu. Content-based publish/subscribe using\ndistributed r-trees. In Proc. Euro-Par , pages 537–548, 2007. doi:10.1007/978-3-540-74466-\n5\\_57 . 5\n[13] Lélia Blin and Sébastien Tixeuil. Compact deterministic self-stabilizing leader election on a\nring: the exponential advantage of being talkative. Distributed Comput. , 31(2):139–166, 2018.\ndoi:10.1007/S00446-017-0294-2 . 3\n[14] Joan Boyar, Faith Ellen, and Kim S. Larsen. Distributed graph algorithms with predictions.\nCoRR , abs/2501.05267, 2025. arXiv:2501.05267 ,doi:10.48550/ARXIV.2501.05267 . 3, 5\n[15] Joan Boyar, Lene M. Favrholdt, Christian Kudahl, Kim S. Larsen, and Jesper W. Mikkelsen.\nOnline algorithms with advice: A survey. ACM Comput. Surv. , 50(2):19:1–19:34, 2017. doi:\n10.1145/3056461 . 3\n[16] Janna Burman, Ho-Lin Chen, Hsueh-Ping Chen, David Doty, Thomas Nowak, Eric E. Sever-\nson, and Chuan Xu. Time-optimal self-stabilizing leader election in population protocols. In\nProc. PODC , pages 33–44, 2021. doi:10.1145/3465084.3467898 . 3\n[17] Janna Burman and Shay Kutten. Time optimal asynchronous self-stabilizing spanning tree.\nInProc. DISC , pages 92–107, 2007. doi:10.1007/978-3-540-75142-7\\_10 . 3\n[18] Raphaël Chand and Pascal Felber. Semantic peer-to-peer overlays for publish/subscribe net-\nworks. In Proc. Euro-Par , pages 1194–1204, 2005. doi:10.1007/11549468\\_130 . 5\n[19] Gregory V . Chockler, Roie Melamed, Yoav Tock, and Roman Vitenberg. Constructing scalable\noverlays for pub-sub with many topics. In Proc. PODC , pages 109–118, 2007. doi:10.1145/\n1281100.1281118 . 5\n[20] Varsha Dani, Thomas P . Hayes, Seth Pettie, and Jared Saia. Fraud detection for random walks.\nInProc. ITCS , pages 36:1–36:22, 2024. doi:10.4230/LIPICS.ITCS.2024.36 . 5\n[21] Edsger W. Dijkstra. Self-stabilizing systems in spite of distributed control. Commun. ACM ,\n17(11):643–644, 1974. doi:10.1145/361179.361202 . 3, 6, 7\n[22] Shlomi Dolev. Self-Stabilization . MIT Press, 2000. 3\n[23] Shlomi Dolev and Ronen I. Kat. Hypertree for self-stabilizing peer-to-peer systems. Dis-\ntributed Comput. , 20(5):375–388, 2008. doi:10.1007/S00446-007-0038-9 . 5\n[24] Shlomi Dolev and Jennifer L. Welch. Self-stabilizing clock synchronization in the presence of\nbyzantine faults. J. ACM , 51(5):780–799, 2004. doi:10.1145/1017460.1017463 . 3\n21\n\n[25] John R. Douceur. The sybil attack. In First International Workshop on Peer-to-Peer Systems,\nIPTPS, Revised Papers , 2002. doi:10.1007/3-540-45748-8\\_24 . 3, 5\n[26] Faith Ellen, Barun Gorain, Avery Miller, and Andrzej Pelc. Constant-length labeling schemes\nfor deterministic radio broadcast. ACM Trans. Parallel Comput. , 8(3):14:1–14:17, 2021. doi:\n10.1145/3470633 . 3\n[27] Yuval Emek, Pierre Fraigniaud, Amos Korman, and Adi Rosén. Online computation with\nadvice. In Proc. ICALP , pages 427–438, 2009. 3\n[28] Pascal Felber, Peter G. Kropf, Eryk Schiller, and Sabina Serbu. Survey on load balancing\nin peer-to-peer distributed hash tables. IEEE Commun. Surv. Tutorials , 16(1):473–492, 2014.\ndoi:10.1109/SURV.2013.060313.00157 . 5\n[29] Michael Feldmann, Christina Kolb, Christian Scheideler, and Thim Strothmann. Self-\nstabilizing supervised publish-subscribe systems. In Proc. IPDPS , pages 1050–1059, 2018.\ndoi:10.1109/IPDPS.2018.00114 . 3\n[30] Michael Feldmann, Christian Scheideler, and Stefan Schmid. Survey on algorithms for self-\nstabilizing overlay networks. ACM Comput. Surv. , 53(4):74:1–74:24, 2021. doi:10.1145/\n3397190 . 4, 5, 6, 8, 11\n[31] Laurent Feuilloley. Introduction to local certification. Discret. Math. Theor. Comput. Sci. , 23(3),\n2021. doi:10.46298/DMTCS.6280 . 8, 38\n[32] Pierre Fraigniaud, Cyril Gavoille, David Ilcinkas, and Andrzej Pelc. Distributed computing\nwith advice: information sensitivity of graph coloring. Distributed Comput. , 21(6):395–403,\n2009. doi:10.1007/S00446-008-0076-Y . 3\n[33] Pierre Fraigniaud, David Ilcinkas, and Andrzej Pelc. Communication algorithms with advice.\nJ. Comput. Syst. Sci. , 76(3-4):222–232, 2010. doi:10.1016/J.JCSS.2009.07.002 .\n[34] Pierre Fraigniaud, Amos Korman, and Emmanuelle Lebhar. Local MST computation with\nshort advice. Theory Comput. Syst. , 47(4):920–933, 2010. doi:10.1007/S00224-010-9280-9 . 3\n[35] Roy Friedman, Gabriel Kliot, and Alex Kogan. Hybrid distributed consensus. In Proc.\nOPODIS , pages 145–159, 2013. doi:10.1007/978-3-319-03850-6\\_11 . 3\n[36] Dominik Gall, Riko Jacob, Andréa W. Richa, Christian Scheideler, Stefan Schmid, and Hanjo\nTäubig. A note on the parallel runtime of self-stabilizing graph linearization. Theory Comput.\nSyst. , 55(1):110–135, 2014. doi:10.1007/S00224-013-9504-X . 4\n[37] Cyril Gavoille, David Peleg, Stéphane Pérennes, and Ran Raz. Distance labeling in graphs. J.\nAlgorithms , 53(1):85–112, 2004. doi:10.1016/J.JALGOR.2004.05.002 . 3\n[38] Seth Gilbert, Calvin Newport, Nitin H. Vaidya, and Alex Weaver. Contention resolution with\npredictions. In Proc. PODC , pages 127–137, 2021. doi:10.1145/3465084.3467911 . 3, 5\n[39] Robert Gmyr, Jonas Lefèvre, and Christian Scheideler. Self-stabilizing metric graphs. Theory\nComput. Syst. , 63(2):177–199, 2019. doi:10.1007/S00224-017-9823-4 . 5\n22\n\n[40] Diksha Gupta, Jared Saia, and Maxwell Young. Bankrupting sybil despite churn. J. Comput.\nSyst. Sci. , 135:89–124, 2023. doi:10.1016/J.JCSS.2023.02.004 . 5\n[41] Sungjin Im, Benjamin Moseley, Chenyang Xu, and Ruilong Zhang. Online dynamic ac-\nknowledgement with learned predictions. In Proc. INFOCOM , pages 1–10, 2023. doi:\n10.1109/INFOCOM53939.2023.10228882 . 3, 5\n[42] Sandy Irani and Yuval Rabani. On the value of coordination in distributed decision making.\nSIAM J. Comput. , 25(3):498–519, 1996. doi:10.1137/S0097539794261428 . 3\n[43] Riko Jacob, Andréa W. Richa, Christian Scheideler, Stefan Schmid, and Hanjo Täubig. Skip+:\nA self-stabilizing skip graph. J. ACM , 61(6):36:1–36:26, 2014. doi:10.1145/2629695 . 3\n[44] Riko Jacob, Andréa W. Richa, Christian Scheideler, Stefan Schmid, and Hanjo Täubig. Skip+:\nA self-stabilizing skip graph. J. ACM , 61(6):36:1–36:26, 2014. doi:10.1145/2629695 . 5, 6, 26\n[45] Riko Jacob, Stephan Ritscher, Christian Scheideler, and Stefan Schmid. Towards higher-\ndimensional topological self-stabilization: A distributed algorithm for delaunay graphs.\nTheor. Comput. Sci. , 457:137–148, 2012. doi:10.1016/J.TCS.2012.07.029 . 4\n[46] Joseph F. JáJá. An Introduction to Parallel Algorithms . Addison-Wesley, 1992. 10, 41\n[47] Tanqiu Jiang, Yi Li, Honghao Lin, Yisong Ruan, and David P . Woodruff. Learning-augmented\ndata stream algorithms. In Proc. ICLR , 2020. 5\n[48] David R. Karger and Matthias Ruhl. Simple efficient load-balancing algorithms for peer-to-\npeer systems. Theory Comput. Syst. , 39(6):787–804, 2006. doi:10.1007/S00224-006-1246-6 .\n5\n[49] Sebastian Kniesburges, Andreas Koutsopoulos, and Christian Scheideler. Re-chord: a self-\nstabilizing chord overlay network. In Proc. SP AA , pages 235–244, 2011. doi:10.1145/\n1989493.1989527 . 5\n[50] Sebastian Kniesburges, Andreas Koutsopoulos, and Christian Scheideler. A self-stabilization\nprocess for small-world networks. In Proc. IPDPS , pages 1261–1271, 2012. doi:10.1109/\nIPDPS.2012.115 . 5\n[51] Amos Korman, Shay Kutten, and David Peleg. Proof labeling schemes. Distributed Comput. ,\n22(4):215–233, 2010. doi:10.1007/S00446-010-0095-3 . 3\n[52] Amos Korman, Shay Kutten, and David Peleg. Proof labeling schemes. Distributed Comput. ,\n22(4):215–233, 2010. doi:10.1007/S00446-010-0095-3 . 4, 8, 38\n[53] Kishore Kothapalli and Christian Scheideler. Supervised peer-to-peer systems. In Proc. IS-\nP AN , pages 188–193, 2005. doi:10.1109/ISPAN.2005.81 . 3\n[54] Andreas Koutsopoulos, Christian Scheideler, and Thim Strothmann. Towards a universal\napproach for the finite departure problem in overlay networks. Inf. Comput. , 255:408–424,\n2017. doi:10.1016/J.IC.2016.12.006 . 36\n23\n\n[55] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proc. SIGMOD , pages 489–504, 2018. doi:10.1145/3183713.3196909 . 5\n[56] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online\nscheduling via learned weights. In Proc. SODA , pages 1859–1877, 2020. doi:10.1137/1.\n9781611975994.114 . 5\n[57] Frank Thomson Leighton. Introduction to parallel algorithms and architectures: Arrays· trees·\nhypercubes . M. Kaufmann Publishers, 1992. 10, 11, 14\n[58] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned ad-\nvice. J. ACM , 68(4):24:1–24:25, 2021. doi:10.1145/3447579 . 5\n[59] Dahlia Malkhi, Moni Naor, and David Ratajczak. Viceroy: a scalable and dynamic emulation\nof the butterfly. In Proc. PODC , pages 183–192, 2002. doi:10.1145/571825.571857 . 5\n[60] Fredrik Manne, Morten Mjelde, Laurence Pilard, and Sébastien Tixeuil. A new self-stabilizing\nmaximal matching algorithm. Theor. Comput. Sci. , 410(14):1336–1345, 2009. doi:10.1016/J.\nTCS.2008.12.022 . 3\n[61] Yifan Mao, Soubhik Deb, Shaileshh Bojja Venkatakrishnan, Sreeram Kannan, and Kannan\nSrinivasan. Perigee: Efficient peer-to-peer network design for blockchains. In Proc. PODC ,\npages 428–437, 2020. doi:10.1145/3382734.3405704 . 5\n[62] Petar Maymounkov and David Mazières. Kademlia: A peer-to-peer information system\nbased on the XOR metric. In Proc. IPTPS , pages 53–65, 2002. doi:10.1007/3-540-45748-\n8\\_5 . 5\n[63] Michael Mitzenmacher. A model for learned bloom filters and optimizing by sandwiching.\nInProc. NeurIPS , 2018. 5\n[64] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. In Beyond the\nWorst-Case Analysis of Algorithms , pages 646–662. Cambridge University Press, 2020. doi:\n10.1017/9781108637435.037 . 3\n[65] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. Commun. ACM ,\n65(7):33–35, 2022. doi:10.1145/3528087 . 3, 5\n[66] Rizal Mohd Nor, Mikhail Nesterenko, and Sébastien Tixeuil. Linearizing peer-to-peer sys-\ntems with oracles. In Proc. SSS , pages 221–236, 2013. doi:10.1007/978-3-319-03089-0\\_16 .\n4\n[67] Melih Onus, Andréa W. Richa, and Christian Scheideler. Linearization: Locally self-\nstabilizing sorting in graphs. In Proc. ALENEX , 2007. doi:10.1137/1.9781611972870.10 .\n4, 5, 7, 26\n[68] Gopal Pandurangan, Prabhakar Raghavan, and Eli Upfal. Building low-diameter P2P net-\nworks. In Proc. FOCS , pages 492–499, 2001. doi:10.1109/SFCS.2001.959925 . 5\n[69] Christos H. Papadimitriou and Mihalis Yannakakis. Linear programming without the matrix.\nInProc. STOC , pages 121–129, 1993. doi:10.1145/167088.167127 . 3\n24\n\n[70] Sylvia Ratnasamy, Paul Francis, Mark Handley, Richard M. Karp, and Scott Shenker. A\nscalable content-addressable network. In Proc. SIGCOMM , pages 161–172, 2001. doi:\n10.1145/383059.383072 . 5\n[71] Antony I. T. Rowstron and Peter Druschel. Pastry: Scalable, decentralized object location,\nand routing for large-scale peer-to-peer systems. In Proc. Middleware , pages 329–350, 2001.\ndoi:10.1007/3-540-45518-3\\_18 . 5\n[72] Christian Scheideler and Alexander Setzer. On the complexity of local graph transformations.\nInProc. ICALP , pages 150:1–150:14, 2019. doi:10.4230/LIPICS.ICALP.2019.150 . 3, 8, 9\n[73] Christian Scheideler, Alexander Setzer, and Thim Strothmann. Towards establishing mono-\ntonic searchability in self-stabilizing data structures. In Proc. OPODIS , pages 24:1–24:17, 2015.\ndoi:10.4230/LIPICS.OPODIS.2015.24 . 4\n[74] Ion Stoica, Robert Tappan Morris, David R. Karger, M. Frans Kaashoek, and Hari Balakr-\nishnan. Chord: A scalable peer-to-peer lookup service for internet applications. In Proc.\nSIGCOMM , pages 149–160, 2001. doi:10.1145/383059.383071 . 5\n[75] Jukka Suomela. Survey of local algorithms. ACM Comput. Surv. , 45(2):24:1–24:40, 2013. doi:\n10.1145/2431211.2431223 . 3\n[76] Sébastien Tixeuil. Self-stabilizing algorithms. In Algorithms and Theory of Computation Hand-\nbook, pages 26:1–26:45. Chapman & Hall/CRC, 2010. 3\n25\n\nA Pseudocodes\nIn every round, each node executes the flyover algorithms (cf. Section A.1), distributed Tree-to-\nPath algorithms (cf. Section A.2.2), and then the base algorithm (in that order). In Section D, we\noutline the list of all variables used by our algorithms.\nTransferring the “advised” neighbors to base algorithm. For any node u, the variable u.c-idis\nused to store its neighbors on the “advised” topology (i.e., connections made by routing over the\nhypercubic structure due to the advice). Thus, in every round, the ids stored in that variable (if it is\nnonempty) are added to the address variable(s) of the base algorithm, used to store the neighbors\nof the target topology, before the algorithm is executed. If the supervisor is honest, this helps the\nnodes obtain the explicit edges required for the base algorithm to stabilize. However, if the advice\nis corrupted in any way, then by design, all nodes reject their advice (i.e. execute RejectFlyover\nfunction) in O(logn)rounds, and for any node u,u.c-idbecomes empty.\nChoice of base algorithm. In general, any base algorithm that self-stabilizes to the sorted line\nusing the overlay primitives (cf. Section 2.2) can be chosen. We only require that the algorithm use\nthe Delegate-after-Reversal or DR primitive (cf. Definition C.7), in place of the Delegate primitive,\nto facilitate information exchange in both directions. (Note that this mechanism is already part\nof many existing algorithms, including [44, 67].) The DR primitive first delegates an edge in the\nreverse direction, and then it is immediately set to the intended direction. This primitive can\neither be implemented in a single round with a “preprocessing” phase (where the edge-reversal\nhappens; see, e.g., Skip+ algorithm [44] where nodes create bidirected links in such a phase), or\nsimply in two rounds in our model.\nAs examples, if the base algorithm is the classic Linearization algorithm [67], the network self-\nstabilizes in O(n)rounds if the supervisor is malicious; if the base algorithm is the Skip+ algorithm\n[44] (that converges to a topology where the sorted-path is part of it, and the degree of each node\nisO(logn)), the network self-stabilizes in O(log2n)rounds if the supervisor is malicious. Both of\nthose algorithms can be directly used in our setting.\nA.1 Flyover Pseudocode\n26\n\nAlgorithm 7 Init\n1:BasicChecks\n2:(∃⟨RejFlyover ⟩ ∈u.Ch)→u.exit:=1;\n3:(u.S=∅)∧(u.c-ids̸=∅∨u.flyID̸=u.id)→u.exit:=1;\n4:(u.L=∅∧u.R̸=∅)∧(u.vID̸=1∨u.flyID̸=u.id)→u.exit:=1;\n5:(u.L̸=∅)∧(u.vID≤1)→u.exit:=1;\n6:(u.vID=1∧u.c-dist̸=0)∨(u.vID>1∧u.c-dist =0)→u.exit:=1;\n7:(u.S̸=∅∧u.vID>1)∧(NextStop (u.c-par) =∅)→u.exit:=1;\n8:|u.c-ids|>2→u.exit:=1;\n9:(|u.c-ids|=2)∧(u.id>max(u.c-ids)∨u.id<min(u.c-ids))→u.exit:=1;\n10:\n11:RejectFlyover :u.exit=1→\n12: flyids := (u.S∪ {u.flyID} ∪u.c-ids)\\u.id;\n13: SEND( ⟨RejFlyover ⟩) to ids in flyids ;Flush (flyids);\n14: u.L:=∅;u.R:=∅;u.vID :=0;u.flyID :=u.id;\n15: u.exit:=0;u.c-par :=0;u.c-dist :=−1;u.c-ids :=∅;\nAlgorithm 8 Test Flyover and Connectivity Certificate\n1:TestFlyoverConstruction\n2: u.R̸=∅→SEND( ⟨TestLine-R, u.id⟩) tou.Sr(1);\n3: u.L̸=∅→SEND( ⟨TestLine-L, u.id⟩) tou.Sl(1);\n4: if(u.R̸=∅∧u.L̸=∅)then\n5: ∀i∈[min(|u.R|,|u.L|)], SEND( ⟨FlyConst-R, u.Sl(i),i,u.id⟩) tou.Sr(i);\n6: ∀i∈[min(|u.R|,|u.L|)], SEND( ⟨FlyConst-L, u.Sr(i),i,u.id⟩) tou.Sl(i);\n7: end if\n8:\n9:TestConnCertificate :(u.vID>1∧u.flyID̸=u.id)→\n10: SEND( ⟨TestCert, u.id,u.c-par ,u.c-dist⟩) toNextStop (u.c-par);\n11:\n12:TestFlyoverMetadata\n13: prop-flyID := (u.vID=1)∨(u.vID>1∧u.flyID̸=u.id);\n14:|u.R| ≥1→SEND( ⟨TestvID, (u.vID+2(i−1))⟩) tou.Sr(i)for all i∈[|u.R|];\n15:|u.L| ≥1→SEND( ⟨TestvID, (u.vID−2(i−1))⟩) tou.Sl(i)for all i∈[|u.L|];\n16: (u.S=∅∧u.vID=0)→SEND( ⟨TestFlyID, ⊥⟩) to all ids in memory;\n17: prop-flyID →SEND( ⟨TestFlyID, u.flyID⟩) to all ids, except u.flyID , in memory;\n27\n\nAlgorithm 9 Response Functions (Flyover Related)\n1:R_TestFlyoverConstruction\n2: / / Here, we omit code for a “. . . -L” msg due to similarity in handling a “. . . -R” msg\n3: foreach received message ⟨msg,sen⟩where msg∈ {TestLine-R, TestLine-L }do\n4: (msg=TestLine-R )∧((u.L̸=∅∧u.Sl(1)̸=sen)∨u.L=∅)→u.exit:=1;\n5: u.S=∅∨u.exit=1→SEND( ⟨RejFlyover ⟩) tosen;Flush ({sen});\n6: end for\n7: foreach received message ⟨msg,w,i,sen⟩where msg∈ {FlyConst-R, FlyConst-L }do\n8: ifmsg=FlyConst-R then\n9: (|u.L| ≥i∧u.Sl(i)̸=sen)∨u.L=∅→u.exit:=1;\n10: |u.L| ≥(i+1)∧u.Sl(i+1)̸=w→u.exit:=1;\n11: u.exit=0∧(1<|u.L|<i)→Flush ({sen,w});\n12: u.exit=0∧(|u.L|=i∧u.Sl(i) =sen)→u.Sl(|u.L|+1):=w;\n13: end if\n14: u.S=∅∨u.exit=1→SEND( ⟨RejFlyover ⟩) to{sen,w};Flush ({sen,w});\n15: end for\n16:\n17:R_TestConnCertificate\n18: foreach received message ⟨TestCert, w,vID,dist⟩do\n19: prop-flyID := (u.vID=1)∨(u.vID>1∧u.flyID̸=u.id);\n20: (u.vID=vID)∧(dist−1̸=u.c-dist)→u.exit:=1;\n21: (u.vID̸=vID)∧(NextStop (vID) =∅)→u.exit:=1;\n22: if(u.S=∅∨u.exit=1)then\n23: SEND( ⟨RejFlyover ⟩) tow;Flush ({w});\n24: else\n25: u.vID̸=vID∧ ¬prop-flyID →Flush ({w});\n26: u.vID̸=vID∧prop-flyID →SEND( ⟨TestCert, w,vID,dist⟩) toNextStop (vID);\n27: u.vID=vID→u.c-ids :=u.c-ids∪ {w}; SEND( ⟨IntroCert, u.id⟩tow;\n28: end if\n29: end for\n30: foreach received message ⟨IntroCert, w⟩do\n31: u.c-ids :=u.c-ids∪ {w};\n32: end for\n33:\n34:R_TestFlyoverMetadata\n35: foreach received message ⟨TestvID, vID⟩do\n36: (u.S=∅)∨(u.S̸=∅∧u.vID̸=vID)→u.exit=1;\n37: end for\n38: foreach received message ⟨TestFlyID, flyID⟩do\n39: if(u.L=∅∧u.R̸=∅)∧(u.exit=0)then\n40: (u.flyID =u.id∧flyID̸=⊥)→u.flyID :=flyID ;\n41: end if\n42: (u.S̸=∅∧u.flyID̸=flyID)∨(u.S=∅∧flyID̸=⊥)→u.exit=1;\n43: u.exit=1→SEND( ⟨RejFlyover ⟩) toflyID ;Flush ({flyID});\n44: end for\n28\n\nA.2 Tree-to-Path Pseudocode\nIn this subsection, we first provide the pseudocode of the (centralized) Tree-to-Path algorithm\ndescribed in Section 3.4. Then, we give the pseudocode for the distributed implementation of the\nsame algorithm, which also includes the interaction with the supervisor.\nA.2.1 Sequential Tree-to-Path\nA.2.2 Distributed Tree-to-Path\nHere, we describe the self-stabilizing algorithms for receiving and processing the advice message.\nWe explicitly address the interaction between the supervisor and the nodes, and also show that it\ncan be combined with the rest of the algorithms.\nFrom the (honest) supervisor’s perceptive, if there is any node that is not part of any flyover,\nand has its exit variable set to 1, that node would request for advice. Once the supervisor receives\nthe first request, it waits forO(logn)rounds until allthe nodes are not part of any flyover, and\nhave their exit variables set to 1. (Note that by design, if the advice or flyover is not correct, every\nnode executes RejectFlyover function of Algorithm 2 in O(logn)rounds; see Section C.8 in the\nanalysis.) At this point, the supervisor learns the “network snapshot,” by requesting each node to\nsend its neighborhood, that is, the ids stored in its memory or channel.\nFrom the perspective of any node u, to avoid being unnecessarily contacted by the supervisor,\nit should not be part of any flyover (that is, u.S̸=∅), nor should its u.exitvariable be set to 1,\nwhile processing an advice message (i.e., during the interaction with the supervisor). After being\nrequested for the neighborhood by the supervisor, every node can store and maintain its current\nneighborhood for O(1)rounds to process the advice given by the supervisor. This is achieved by\nsetting and tracking a “timer” variable that indicates that the advice is being processed.\nWe explain the additional variables of a node uthat are used in the following algorithms.\n1.u.tis used as a timer variable which is set to 5 when the supervisor requests for its current\nneighborhood; u.tis decremented by 1 in every round, until it becomes 0 again.\n2.u.distis used for storing the distance from the root, in a rooted spanning tree of the current\nsnapshot, given by the supervisor; see Algorithm 1 for the details. This distance is primarily\nused by nodes for calculating the label in the Tree-to-Path algorithm (cf. Section 3.4), and is\nalso used for quickly checking that any subset of “parent” ids (in the advice) do not form a\ncycle, using the distance-checks in local certification (cf. Section 3).\n29\n\nAlgorithm 10 Tree-to-Path\nRequire: Let the input to the algorithm be a (labelled) rooted tree T= (l(·),r,V,E)where l(r) =0\nand|V| ≥2. For any v∈V, letC(v) ={u|dist(u,v) =1∧dist(v,r)<dist(u,r)}.\nEnsure: Output of the algorithm is a directed path graph Pwhere Beg (P) =r.\n1:forv∈Vand C(v)̸=∅do\n2: Assign a total ordering on C(v) ={u1, . . . , uq}such that u1<· · ·<uqforq≥1;\n3:end for\n4:LetE′←∅;\n5:forv∈Vand v̸=rand l(v) =1do\n6: Letpv∈Vsuch that v∈C(pv); / / Parent of v\n7: LetRSib={w|w>v∧w∈C(pv)}; / / Right siblings (via the total ordering)\n8: ifRSib=∅and C(v) =∅then\n9: Add (directed) edge (pv,v)toE′;\n10: else if RSib=∅and C(v)̸=∅then\n11: Add (directed) edge (pv, max (C(v)))toE′;\n12: else if RSib̸=∅and C(v) =∅then\n13: Add (directed) edge (min(RSib),v)toE′;\n14: else\n15: Add (directed) edge (min(RSib), max (C(v)))toE′;\n16: end if\n17:end for\n18:forv∈Vand v̸=rand l(v) =0do\n19: Letpv∈Vsuch that v∈C(pv); / / Parent of v\n20: LetLSib={w|w<v∧w∈C(u)}; / / Left siblings (via the total ordering)\n21: ifLSib=∅and C(v) =∅then\n22: Add (directed) edge (u,pv)toE′;\n23: else if LSib=∅and C(v)̸=∅then\n24: Add (directed) edge (min(C(v)),pv)toE′;\n25: else if LSib̸=∅and C(v) =∅then\n26: Add (directed) edge (v, max (LSib))toE′;\n27: else\n28: Add (directed) edge (min(C(v)), max (LSib))toE′;\n29: end if\n30:end for\n31:Output P= (V,E′);\n30\n\nAlgorithm 11 Init2\n1:BasicChecks2\n2: u.t>5→u.t:=5;u.t<0→u.t:=0;\n3: u.t>0→u.t:=u.t−1; / / Decrement u.r(until 0)\n4: u.t≤1∧(u.S=∅∨u.exit=1)→u.vID :=0; / / Reset vIDif flyover is not formed\n5:\n6:SnapshotReq :u.S=∅∧u.exit=0∧u.t=0→\n7: ifthere exists a message ⟨RequestSnapshot ⟩then\n8: u.t:=5;snap :=Set of all ids in M u(A0); / / Set up timer and neighborhood\n9: SEND( ⟨Intro, u.id⟩) to all nodes in snap ;∀v∈snap , SEND( ⟨Intro, v⟩) to thyself;\n10: SEND( ⟨Neighborhood, snap⟩) to supervisor;\n11: end if\nAlgorithm 12 Local Advice Verification\n1:GetAdvice\n2: busy :=¬(u.S=∅∧u.exit=0∧u.t>1);\n3: snap :=∅;(∀⟨Intro, v⟩ ∈u.Ch)→snap :=snap∪ {v};\n4: if(⟨Advice, · · · ⟩ ∈ u.Ch)∧(¬busy)∧(u.t=4)then\n5: if⟨Advice, · · · ⟩ is well-formed (e.g., Adv(u).par∈snap , etc) then\n6: Update relevant variables (e.g., u.vID,u.c-dist ,u.dist);\n7: SEND( ⟨TestAdvice, u.dist,u.id⟩) toAdv(u).par;\n8: end if\n9: end if\n10: Flush (snap);\n11:\n12:CertifyTree\n13: ignore _msg :=¬(u.S=∅∧u.exit=0∧u.t>1);children :=∅;\n14: foreach received message ⟨TestAdvice, dist,v⟩do\n15: children :=v∪children ;(u.dist̸=dist−1)→ignore _msg :=1;\n16: end for\n17: (¬ignore _msg∧children ̸=∅)→SetupLocalTransform (children );\n18: Flush (children );\n31\n\nAlgorithm 13 Distributed Tree-to-Path\n1:LocalTransform\n2: ignore _msg :=¬(u.S=∅∧u.exit=0∧u.t>1);\n3: children :=∅;parent :=⊥;r-sib :=⊥;l-sib :=⊥;\n4: foreach received message ⟨Verified, msg,v⟩where msg∈ {parent, sib+, sib-, child }do\n5: (msg=parent ∧parent ̸=⊥)→ignore _msg :=1;\n6: (msg=sib-∧l-sib̸=⊥)→ignore _msg :=1;\n7: (msg=sib+∧r-sib̸=⊥)→ignore _msg :=1;\n8: (msg=parent ∧ ¬ignore _msg)→parent :=v;\n9: (msg=sib-∧ ¬ignore _msg)→l-sib :=v;\n10: (msg=sib+∧ ¬ignore _msg)→r-sib :=v;\n11: (msg=child∨ignore _msg=1)→children :=v∪children ;\n12: end for\n13: (parent =⊥ ∧ u.dist̸=0)∨(parent ̸=⊥ ∧ u.dist<1)→ignore _msg :=1;\n14: (ignore _msg=0∧parent ̸=⊥)→ExecuteTransform (parent ,r-sib,l-sib,children );\n15: Flush ({parent ,r-sib,l-sib} ∪children );\n16:\n17:JoinPath\n18: ignore _msg :=¬(u.S=∅∧u.exit=0∧u.t>1);flyL :=⊥;flyR :=⊥;\n19: foreach received message ⟨msg,v⟩where msg∈ {Path+, Path- }do\n20: (msg=Path-∧(u.vID=1∨flyL̸=⊥))→ignore _msg :=1;\n21: (msg=Path+ ∧flyR̸=⊥)→ignore _msg :=1;\n22: (msg=Path-∧ ¬ignore _msg)→flyL :=v;\n23: (msg=Path+ ∧ ¬ignore _msg)→flyR :=v;\n24: ignore _msg=1→Flush ({v});\n25: end for\n26: / / First left and right shortcuts in the flyover\n27: ignore _msg=0→u.Sl(1):=flyL;u.Sr(1):=flyR;\n28: Flush ({flyL,flyR});\nA.3 Helper Functions\n32\n\nAlgorithm 14 Helper Functions (Flyover Related)\n1:NextStop (val)\n2:(val<1∨val=u.vID)∨(u.S=∅∨u.vID<1)→Return “ ∅”;\n3:(val>u.vID∧(u.R=∅))∨(val<u.vID∧(u.L=∅))→Return “ ∅”;\n4: if(val>u.vID)then\n5: Return u.Sr(argmini∈|u.R|(|u.vID+2(i−1)−vID|));\n6: else\n7: Return u.Sl(argmini∈|u.L|(|u.vID−2(i−1)−vID|));\n8: end if\nAlgorithm 15 Helper Functions (Advice Related)\n1:SetupLocalTransform (children )\n2: Consider a total order on children ={u1, . . . , uq}such that u1<· · ·<uqforq>1;\n3: SEND( ⟨Verified, parent, u.id⟩) to all ids in children ;\n4: SEND( ⟨Verified, sib+, uj⟩) touj−1forq≥j>1;\n5: SEND( ⟨Verified, sib-, uj⟩) touj+1forq>j≥1;\n6: SEND( ⟨Verified, child, w⟩) to self, for each w∈children ;\n7:\n8:ExecuteTransform (parent ,right _sib,left_sib,children )\n9: Let the total ordering on children ={u1, . . . , uq}such that u1<· · ·<uqforq>1;\n10: / / Path+ messages (i.e., right shortcut) follow the orientation as in Algorithm 10.\n11: for(u.dist̸=0)∧((u.dist mod 2 ) =1)do\n12: ifright _sib=⊥ ∧ children =∅then\n13: SEND( ⟨Path+, u.id⟩) toparent ; SEND( ⟨Path-, parent⟩) to self;\n14: else if right _sib=⊥ ∧ children ̸=∅then\n15: SEND( ⟨Path+, max (children )⟩) toparent ; SEND( ⟨Path-, parent⟩) to max (children );\n16: else if right _sib̸=⊥ ∧ children =∅then\n17: SEND( ⟨Path+, u.id⟩) toright _sib; SEND( ⟨Path-, right _sib⟩) to self;\n18: else\n19: SEND( ⟨Path+, max (children )⟩) toright _sib; SEND( ⟨Path-, right _sib⟩) to max (children );\n20: end if\n21: end for\n22: for(u.dist̸=0)∧((u.dist mod 2 ) =0)do\n23: ifleft_sib=⊥ ∧ children =∅then\n24: SEND( ⟨Path-, u.id⟩) toparent ; SEND( ⟨Path+, parent⟩) to self;\n25: else if left_sib=⊥ ∧ children ̸=∅then\n26: SEND( ⟨Path-, min (children )⟩) toparent ; SEND( ⟨Path+, parent⟩) to min (children );\n27: else if left_sib̸=⊥ ∧ children =∅then\n28: SEND( ⟨Path-, u.id⟩) toleft_sib; SEND( ⟨Path+, left_sib⟩) to self;\n29: else\n30: SEND( ⟨Path-, min (children )⟩) toleft_sib; SEND( ⟨Path+, left_sib⟩) to min (children );\n31: end if\n32: end for\n33\n\nB Tree-to-Path Analysis\nTheorem B.1. Algorithm 10 takes a (labelled) rooted tree T = (l(·),r,V,E)where l (r) =0as input, and\noutputs a directed path graph P = (V,E′), where Beg(P) =r and End(P) =min(CT(r)).\nProof. The height of a rooted tree T, denoted by H(T), is equal to max v∈V(dist(r,v)). For each\nnode v, letC(v) ={u|dist(u,v) =1∧dist(v,r)<dist(u,r)}. For each node v∈Vwhere C(v)̸=\n∅, there is a total ordering (e.g., based on ids) on C(v) ={u1, . . . , uk}such that u1<· · ·<uk.\nWe inductively prove the following statements over the height of a tree, with the base cases as\nthe set of trees of height 1 (and the label of root can either be 0 or 1).\n1. Algorithm 10 takes in any rooted tree Tb= (l(·),p,V,E)where l(p) = 0, and outputs a\n(directed) path graph P= (V,E′)where Beg (P) =pand End (P)is min (C(p))for|V| ≥2.\n2. Algorithm 10 takes in any rooted tree Tb= (l(·),p,V,E)where l(p) = 1, and outputs a\n(directed) path graph P= (V,E′)where Beg (P)is max (C(p))and End (P) =pfor|V| ≥2.\nConsider the base case of any rooted tree Tb= (l(·),p,V,E)where l(p) = 0 and |V| ≥ 2 and\nH(Tb) =1. Let C(p) ={p1, . . . , pq}such that p1<· · ·<pqfor any q≥1. Algorithm 10 adds the\nfollowing edges, resulting in a path P, where Beg (P) =pand End (P)is min (C(p)).\n1. The (directed) edge (p,pq)is added.\n2. For 1 ≤r<q, the (directed) edge (pr+1,pr)is added.\nSimilarly, consider the base case of any rooted tree Tb= (l(·),p,V,E)where l(p) = 1 and\n|V| ≥2 and H(Tb) =1. Let C(p) ={p1, . . . , pq}such that p1<· · ·<pqfor any q≥1. Algorithm\n10 adds the following edges, resulting in a path P, where Beg (P) =max(C(p))and End (P)isp.\n1. The (directed) edge (p1,p)is added.\n2. For 1 ≤r<q, the (directed) edge (pr+1,pr)is added.\nWe introduce some notation for the inductive cases, where T= (l(·),p,V,E)is any rooted tree\nofH(T) = h+1 for any h≥1. For any node p, let C′(p) ={u|u∈C(p)∧C(u)̸=∅}. Let\nTw= (l(·),w,Vd(w),Ed(w))be the subtree rooted at wand l(w) =l(p) +dist(p,w)mod 2, where\nVd(w) ={u|dist(u,w)<dist(u,p)}and Ed(w) ={(u,v)|(u,v)∈E∧ {u,v} ∈ Vd(w)}. By\ninduction, Algorithm 10 outputs a path, denoted by A(Tv), for each subtree Tvrooted at v∈C′(p).\nConsider any rooted tree Twhere l(p) =0. Algorithm 10 adds the following (directed) edges,\nresulting in a (directed) path P= (V,E′)where Beg (P) =pand End (P)is min (C(p)).\n1. Either (p, Beg(A(Tpq))or(p,pq)is added based on whether pq∈C′(p)orpq/∈C′(p). By\ninduction, Beg (A(Tpq))is max (C(pq))and End (A(Tpq))ispq, ifpq∈C′(p), asl(pq) =1.\n2. Similarly, if there exists an rsuch that, 1 ≤r<q, we consider these exhaustive set of cases.\n(a) If pr,pr+1∈C′(p), then the edge (End(A(Tpr+1), Beg(A(Tpr))is added. By induction,\nBeg(A(Tpr))is max (C(pr))and End (A(Tpr+1))ispr+1, ifpr,pr+1∈C′(p), asl(pr) = 1\nand l(pr+1) =1.\n(b) If pr+1∈C′(p)and pr/∈C′(p), then the edge (End(A(Tpr+1),pr)is added. By induction,\nEnd(A(Tpr+1))ispr+1, ifpr+1∈C′(p), asl(pr+1) =1.\n34\n\n(c) If pr+1/∈C′(p)and pr∈C′(p), then edge (pr+1, Beg(A(Tpr))is added. By induction,\nBeg(A(Tpr))is max (C(pr)), ifpr∈C′(p), asl(pr) =1.\n(d) If pr,pr+1/∈C′(p), then edge (pr+1,pr)is added. (Same as base case where l(p) =0.)\nSimilarly, consider any rooted tree Twhere l(p) = 1. Algorithm 10 adds the following (directed)\nedges, resulting in a (directed) path P= (V,E′)where Beg (P) =max(C(p))and End (P)isp.\n1. Either (End(A(Tp1),p)or(p1,p)is added based on whether p1∈C′(p)orp1/∈C′(p). By\ninduction, End (A(Tp1))is min (C(p1))and Beg (A(Tp1))isp1, ifp1∈C′(p), asl(p1) =0.\n2. Similarly, if there exists an rsuch that, 1 ≤r<q, we consider these exhaustive set of cases.\n(a) If pr,pr+1∈C′(p), then the edge (End(A(Tpr+1), Beg(A(Tpr))is added. By induction,\nBeg(A(Tpr))isprand End (A(Tpr+1))is min (C(pr+1)), ifpr,pr+1∈C′(p), asl(pr) = 0\nand l(pr+1) =0.\n(b) If pr+1∈C′(p)and pr/∈C′(p), then the edge (End(A(Tpr+1),pr)is added. By induction,\nEnd(A(Tpr+1))is min (C(pr+1)), ifpr+1∈C′(p), asl(pr+1) =0.\n(c) If pr+1/∈C′(p)and pr∈C′(p), then edge (pr+1, Beg(A(Tpr))is added. By induction,\nBeg(A(Tpr))ispr, ifpr∈C′(p), asl(pr) =0.\n(d) If pr,pr+1/∈C′(p), then edge (pr+1,pr)is added. (Same as base case where l(p) =1.)\nC Self-Stabilization Analysis\nC.1 Basic Definitions\nDefinition C.1. We use Mu(A0)to represent the (internal) memory (including the channel buffer) that a\nnode u uses for executing algorithm A0respectively. Moreovoer, we use R(A0)for the (best-known) upper\nbound for the (self-stabilization) convergence of the algorithm A0(when it is independently executed).\nDefinition C.2. We use the term flyover-related variables to refer to the set of variables in Section A.1.\nSimilarly, we use the term advice-related variables to refer to the set of variables in Section A.2.2.\nDefinition C.3. We say that a node u executes a flush operation on a set of node ids, if it stores them in\nany set of address variables in Mu(A0)(i.e., memory allocated to algorithm A0).\nDefinition C.4. Let Adv (u)be an advice message at node u. Moreover, when we refer to Adv (u).x=y,\nthen x =y has appeared in the advice. Adv (u)is said to be well-formed if the following conditions hold.\n1. Adv (u).par∈ {⊥ , id}, where idis present in its memory.\n2. If Adv (u).par=⊥, then Adv (u).dist=0,Adv(u).vID=1,Adv(u).c-dist =0; else Adv (u).dist>\n0,Adv(u).vID>1and Adv (u).c-dist>0.\n3. Adv (u).vID∈Nand Adv (u).c-par∈N.\nDefinition C.5. We say that a node u is in dual-state if u.S̸=∅. Furthermore, if node u updates a\npreviously non-empty u .S to∅, then we say that node u has exited from the dual-state .\n35\n\nDefinition C.6. A node u is said to process an advice message if u enters Line 6 in Algorithm 12. An\nadvice message, for any node u, is said to be effective if node u enters dual-state before u .t≤1. We say\nthat a node u is attentive , orready to receive advice , if u .S=∅∧u.exit=0∧u.t=0.\nDefinition C.7. (Delegate-after-Reversal; DR Primitive) A node u is said to use DR primitive for\nalgorithm A0in round r, if the following conditions hold during the execution of algorithm A0.\n1. If node u is required to delegate an edge (u,w)to node v, i.e., send the id of node w to node v, for\ne.g., via some message ⟨msg, w⟩, then (1) node u first sends ⟨Rev, v, msg, w⟩to node w, and (2) once\nnode w receives ⟨Rev, v⟩, node w sends its own id to node v (for e.g., by message ⟨msg, w⟩).\n2. If node u is required to send some message ⟨msg, w1, . . . , w2, . . . , wt⟩for some t ≥1to node v, then\n(1) node u first sends ⟨Rev, v, msg, w1, . . . , w2, . . . , wt⟩to node w 1, and for all 1<j≤t, node u\nsends⟨Rev, v⟩to node w j, and (2) once node w 1receives ⟨Rev, v, msg, w1, . . . , w2, . . . , wt⟩, node w 1\nsends⟨msg, w1, . . . , w2, . . . , wt⟩to node v, and for all 1<j≤t, once node w jreceives ⟨Rev, v⟩,\nnode w jsends its own id to node v.\nThe message complexity of DR primitive is O (1)factor to that of “Delegate” primitive (see, e.g., [54]).\nDefinition C.8. The network is robust against a supervisor , ors-robust , if these two conditions hold.\n1.(Sybil Resistance) For each node u, and for any node id v present in node u’s advice message but not\npresent in node u’s memory or channel, node u neither assigns v to any of its variables (i.e. store in\nits memory) nor sends v to any other id present in its memory or channel (i.e., send it to other nodes).\n2.(Robustness) If all nodes do not form a single, correctly configured flyover, then all nodes exit the\ndual-state (thereby rejecting any “supervisor-induced” overlay) in O (logn)rounds.\nC.2 Flyover-Related Definitions\nDefinition C.9. We say that a set of nodes B ⊆V is a backbone , where |B| ≥2, if the following conditions\nhold. For ease of exposition, wlog, we denote the set B as {v1,v2, . . .}.\n1.(Wings) (v1.L=∅∨v1.Sl(1)/∈B)and(v|B|.R=∅∨v|B|.Sr(1)/∈B).\n2.(Spine) ∀i∈[|B| −1],vi.Sr(1) =vi+1∧vi+1.Sl(1) =vi.\nIf for all u ∈V\\B,u∪B is not a backbone, then B is said to be a maximal backbone . A maximal backbone\nis said to be winged maximal backbone if v1.L̸=∅∨v|B|.R̸=∅.\nDefinition C.10. We say that a set of nodes B ⊆V is an ouroboros if any of the following conditions\nhold. For ease of exposition, wlog, we denote the set B as {v1,v2, . . .}.\n1.(Perfect Ring) (v1.Sl(1) =v|B|∧v|B|.Sr(1) =v1)and∀i,vi.Sr(1) =vi+1∧vi+1.Sl(1) =vi.\n2.(Stylish Ring) (v1.Sl(1)∈B∨v|B|.Sr(1)∈B)and∀i,vi.Sr(1) =vi+1∧vi+1.Sl(1) =vi.\nIf for all u ∈V\\B,u∪B is not an ouroboros, then B is said to be a maximal ouroboros .\nDefinition C.11. An node u in a dual-state, is said to be lost, if it is not in any backbone or ouroboros.\n36\n\nDefinition C.12. We say that a backbone B ⊆V is a flyover if the following conditions hold. Let v 1∈B\nsuch that (v1.L=∅∨v1.Sl(1)∈V\\B). For all i ∈[|B| −1], let v i+1∈B such that v i.Sr(1) =vi+1.\n1.(Virtual IDs) ∀i∈[|B| −1], vi+1.vID=vi.vID+1.\n2.(Hypercube) ∀i∈[|B| −1],∀j∈[⌊log2(|B| −i)⌋+1],(vi.Sr(j) =vi+2j−1∧vi+2j−1.Sl(j) =vi).\nDefinition C.13. Consider a maximal backbone B ={v1,v2, . . .} ⊆ V where (v1.L=∅∨v1.Sl(1)∈\nV\\B)and∀i∈[|B| −1],vi.Sr(1) = vi+1. Let G∗\nB= (B,E∗\nB)such that (u,v)∈E∗\nB⇐⇒ (u=\nsucc B(v)∨v=succ B(u)), where succ B(u) = min({w.id|(w∈B)∧(w.id>u.id)}). Let T∗\nBbe the\nrooted spanning tree in the graph G∗\nBwith node v 1as the root. Then, B is said to be correctly configured\nif the following conditions hold.\n1.∀i∈[|B|],vi.vID=i and v i.flyID =v1.id.\n2.∀i∈[|B| −1],vi.c-par =pi.vID where p idenotes the parent of v iin T∗\nB.\n3.∀i∈[|B|], E∗\nB(vi)⊆vi.c-ids where E∗(vi)denotes the edge-set of v iin G∗\nB.\n4.∀i∈[|B|],vi.c-dist =dist T∗\nB(vi,v1)where dist T∗\nB(u,v)is the distance between v 1and v iin T∗\nB.\nDefinition C.14. A node u, with u .S̸=∅, in round r, is said to be in a precarious dual-state if any of the\nfollowing conditions are satisfied.\n1. u is a lost node.\n2. u belongs to a maximal ouroboros.\n3. u belongs to either a maximal backbone of size less than n, or maximal backbone of size equal to n but\nsome node sets its exit variable to 1 in any round r′∈ {r,r+1, . . . r+3⌈logn⌉}.\nDefinition C.15. The network is said to be stable in any round r if for each node u ∈V,u.S̸=∅but u is\nnot in a precarious dual-state.\nC.3 Helpful Observations\nRemark C.16. For any node u, the following invariants are ensured (via BasicChecks function).\n1.u.S=∅=⇒u.flyID =u.id∧u.c-ids=∅.\n2.u.L=∅∧u.R̸=∅=⇒u.vID=1∧u.flyID =u.id∧u.c-dist =0.\n3.u.L̸=∅=⇒u.c-dist>0∧u.vID>1.\n4.(u.S̸=∅∧u.vID>1) =⇒u.c-par can be “reached,” i.e., via left or right neighbors.\n5.u.c-ids̸=∅=⇒(|u.c-ids|=1)∨(|u.c-ids|=2∧min(u.c-ids)<u.id<max(u.c-ids)).\nRemark C.17. Due to FlushFlyover function, whenever any node uexits from dual-state, all ids\npart of node u’s flyover variables (including u.flyID ) receive ⟨RejFlyover ⟩message. For any node\nu, if some node id v̸=uis stored in the set {u.flyID} ∪u.S∪u.c-ids , it can only be removed from\nthat set in the FlushFlyover function.\n37\n\nRemark C.18. If a node uexecutes SnapshotReq function (or, node uisattentive ) in round r>1,\nthen u.S=∅∧u.exit=0∧u.t=0 in that round. Since u.S=∅∧u.exit=0 condition is satisfied,\nand u.Sand u.exitcan be set to ∅and 0 (resp.) only in FlushFlyover function, node usends ⊥\nto all ids in its memory (and channel) in round rdue to TestFlyoverMetadata function. This is\nbecause either, FlushFlyover function was executed in round r(in which case, u.vID is set to 0),\nor, both u.Sand u.exitwere already equal to ∅and 0 (resp.) at the beginning of round r, in which\ncase, u.vIDwas set to 0 in BasicChecks2 function (in Algorithm 11) in round r−1.\nClaim C.19. Let B ={v1, . . . , v|B|}be a maximal backbone where (v1.L=∅∧v|B|.R=∅)and(∀i∈\n[|B| −1],vi.Sr(1) =vi+1)and(∀i∈[|B|],vi.vID=i∧vi.flyID =v1). Consider the following graphs.\n•Let G∗\nB= (B,E∗\nB)such that (u,v)∈E∗\nB⇐⇒ (u=succ B(v)∨v=succ B(u)), where succ B(u) =\nmin({w.id|(w∈B)∧(w.id>u.id)}).\n•Let G′\nB= (B,E′\nB)such that (u,v)∈E′\nB⇐⇒ (u.vID=v.c-par∧v.c-dist =u.c-dist +1)∨\n(v.vID=u.c-par∧v.c-dist =u.c-dist−1).\nIf for all i ∈[|B|]\\ {1},∃ui∈B,vi.c-par =ui.vID where (ui.c-dist =vi.c-dist−1), then G′\nBis G∗\nB.\nProof. Due to Remark C.16, the following invariants are (locally) maintained. For each node u∈B,\n1. (Tree Distance) (u.L=∅=⇒u.c-dist =0)and(u.L̸=∅=⇒u.c-dist>0).\n2. (Degree Constraint; Locally Sorted) E′(u)̸=∅=⇒(|E′(u)|=1)∨(|E′(u)|=2∧\nmin(|E′(u)|)<u.id<max(|E′(u)|)), where E′(u) ={v|(u,v)∈E′\nB}.\nThese invariants ensure there is only one node uwith u.c-dist =0, and that node is v1. Moreover,\nthe degree of any node in G′is at most 2; if a node’s degree is 2, then its own id is neither greater\nnor less than both the node ids of its neighbors. Given the premise of the lemma, for any node\nu∈V\\ {v1}, there is a node p(u)such that u.c-par =p(u).vIDand p(u).c-dist =u.c-dist−1.\nFirst, we show that G′\nBforms a spanning tree (with degree at most 2, i.e., a path) using a key\nidea behind the classic O(logn)-bits proof-labelling scheme of a spanning tree (see, e.g., [3, 31, 52]).\nIn that scheme, each node is given a “certificate” consisting of the root node id, a parent node id\n(among its neighbors) and the distance from the root (in a rooted spanning tree), where the “root”\nis the (only) node with its distance equal to 0 (and has no parent). Then, each node examines the\ncertificates of its neighbors in the graph, and checks the distance (i.e., from its parent) and the\nroot ids (i.e., whether they are same). If any certificate is incorrectly assigned, then there exists\n(at least) one node that “rejects” its certificate. Otherwise, if each certificate is correctly assigned\n(with respect to some rooted spanning tree), then each node “accepts” its certificate.\nWe use proof by contradiction to show that G′is indeed G∗. First, there cannot be a cycle in\nG′, as the distance checks (i.e., from a node uto its parent p(u)) cannot be satisfied at all nodes (cf.\nSection 2.3). Moreover, G′cannot be a spanning forest because all the nodes, via flyover id, can\nverify that there is only one “root node,” i.e., node v1with distance v1.c-dist =0. Thus, G′forms\na spanning tree. Combining the second invariant mentioned earlier, i.e., each node has degree at\nmost 2, the tree must be a path. Finally, that path has to be the sorted-path G∗due to the second\ninvariant because every node checks that its locally sorted with its neighbors in G′.\nClaim C.20. Let p∈B, q /∈B and p ∈Mq(A0)in any round r, where B is a backbone. If node q uses the\nDR primitive (as in Definition C.7) in round r, then at least one of the following statements is true:\n38\n\n•either edge (q,p)exists in round r +1,\n•or edge (p′,q′)where p′∈B and q′/∈B exists, by round r +2.\nProof. Let us first consider the “normal” execution of algorithm A0(i.e, without DR primitive) in\nround r. As it preserves weak connectivity, there can be two (exhaustive) cases in round r+1.\n1.(q,p)still exists.\n2. Some path P= (q,v0, . . . , vt)exists, where v0∈Mq(A0),vt=pand∀i∈[t],vi/∈Mq(A0).\nIn the path P, color a node blue if it is present in B; otherwise, color it red. Consider the edges\n(regardless of their directions): (q,v0), . . . ,(vt−1,vt). There is at least one pair of adjacent nodes\ncolored differently. If node qruns algorithm A0with the DR primitive in round r, due to reversal\nof edges, in either round r+1 or r+2, there exists an edge (p′,q′)where p′∈Band q′/∈B.\nC.4 Connectivity Preservation\nLemma C.21. If the initial communication graph is weakly connected, then the communication graph in\nany round r ≥1is also weakly connected.\nProof. Consider a node id vin some node u(whether in its channel or address variables, i.e., vis\npresent in a message sent to u, orvis assigned to some variable in u). Ifvis present in u, then uand\nvare (weakly) connected. On the other hand, if vis “delegated,” i.e., usends the id of vto another\nnode w, then we need to show that uand vare (weakly) connected via some path (u,v1, . . . , vt)\nwhere vt=vfor some t≥1. Thus, we focus on all the possible cases in our algorithms where\na node id could be delegated, and a node id is present in a received message, to show that the\nnetwork remains weakly connected in the next round.\n• First, by design, every node runs an algorithm A0(in parallel, for converging to target topol-\nogy) that preserves connectivity (i.e., following the universal overlay primitives for edge\nmanipulations). Moreover, if nodes use the DR primitive (instead of “Delegate” primitive)\nwhile running algorithm A0, connectivity is still preserved (as the direction of delegated\nedge is only opposite to the intended direction, but is subsequently reversed; see Definition\nC.7) after edge manipulations by algorithm A0in any round.\n• In the TestFlyoverConstruction ,TestFlyoverMetadata and TestConnCertificate functions,\nif node usends vto some other node, then valso remains in node u.\n• We analyze the response functions that process the received messages.\nInR_TestFlyoverConstruction function, node uprocesses two types of messages. For any\nmessage ⟨msg,sen⟩,senis stored in, either u.Sor M u(A0). For any message ⟨msg,w,i,sen⟩,w\nand senare stored in either u.Sor M u(A0).\nInR_TestFlyoverMetadata function, for any message ⟨TestFlyID, flyID⟩, there are two cases:\nflyID is stored in either u.flyID or M u(A0).\nInR_TestConnCertificate function, for any message ⟨TestCert, w,vID,dist⟩, there are three\ncases: (1) wis sent to node u′∈u.S, in which case, there is a path (u,u′,w), or (2) ustores w\ninu.c-ids , or (3) ustores win M u(A0); for any message ⟨IntroCert, w⟩,ustores winu.c-ids .\n39\n\n• We turn our attention to distributed tree-to-path algorithms (cf. Section A.2.2). In GetAdvice\nfunction, for any message ⟨Intro, v⟩, node ustores vin M u(A0). InCertifyTree function, for\nany message ⟨TestAdvice, dist,v⟩, node ustores vin M u(A0). Similarly, in LocalTransform\nfunction, for any message ⟨Verified, msg,v⟩, node ustores vin M u(A0). In JoinPath func-\ntion, for any message ⟨msg,v⟩, there are two cases: node ustores veither in u.Sor M u(A0).\nC.5 Flyover Construction\nLemma C.22. Consider any backbone B ={v1, . . . , v|B|}, where |B| ≥3and(v1.L=∅∨v1.Sl(1)/∈B)\nand∀i∈[|B| −1],vi.Sr(1) =vi+1, in any round r. For any i ∈[k]and k =⌊log2(|B| −1)⌋, if all nodes\nin B have their exit variable set to 0in all rounds r ,r+1, . . . , r+i′where i′≥i, then in any round r +i′,\nthe following statements hold true.\n1.(Virtual IDs) ∀j∈[|B| −1],vj+1.vID=vj.vID+1.\n2.(Endpoints) |v1.R| ≥(i+1)and|v|B|.L| ≥(i+1).\n3.(Hypercube Edges) ∀j∈[i],v1.Sr(j) =v1+2jand∀j∈[i],v|B|.Sl(j) =v|B|−2j.\nProof. If the first statement is true in round r, then it remains true until some node exits dual-state;\notherwise, some node sets its exit variable to 1 due to TestFlyoverMetadata function. Recall\nthat vIDis assigned when a node receives an advice (see Algorithm 12). Moreover, for any node u,\nonce u.vID is assigned, then it can only be updated in FlushFlyover function (which is executed\nonly after u.exit= 1). As no node in Bsets its exit variable to 1 until round r+i′for any i′≥iand\ni∈[k], the statement holds true in round r+i′for any i′≥1.\nFor latter statements, we use induction over the size of a backbone. Let any backbone of size s\nbeBs={u1, . . . , us}, where (u1.L=∅∨u1.Sl(1)/∈Bs)and∀i∈[s−1],ui.Sr(1) = ui+1. For the\nbase case, consider s=3 where Bs={u1,u2,u3}. In round r, node u2sends⟨FlyConst-R, u1, 1,u2⟩\nand⟨FlyConst-L, u3, 1,u2⟩messages to node u3and u1respectively. Since the nodes do not set\ntheir exit variables to 1 in both rounds rand r+1, node u1assigns u3tou1.Sr(2)and node u3\nassigns u1tou3.Sl(2)in round r+1 (if they have not already done so), which also implies that\n|u1.R| ≥ 2 and |u3.L| ≥ 2 in round r+1. Recall that for any node u, for any j≥1, once u.Sl(j)\noru.Sr(j)is assigned, then it can only removed (or updated) in FlushFlyover function (which is\nexecuted only after u.exit=1). As no node in Bsets its exit variable to 1 until round r+i′for any\ni′≥iand i∈[k]where k=1 (for s=3), these statements hold true in round r+i′for any i′≥1.\nFor inductive case, we assume that the statements are true for any backbone of size (s−1)≥3,\nand then show that they hold true for any backbone Bs={u1, . . . , us}. To that end, we split the\nproof into two cases, for any p>1 and p∈N, either s̸=2p+1 or s=2p+1.\nIn the first case, where s̸=2p+1,k=⌊log2(s−1)⌋=⌊log2(s−2)⌋. Consider the two\nbackbones B1\ns={u1,u2, . . . , us−1}and B2\ns={u2,u3, . . . , us}. For any i∈[k], if all nodes in Bs\nhave their exit variable set to 0 in all rounds r, . . . , r+i′where i′≥i, then in any round r+i′, the\nstatements hold true, independently, for B1\nsand B2\ns. Thus, they also hold true for backbone Bs.\nIn the second case, where s=2p+1,k=⌊log2(s−1)⌋=⌊log2(s−2)⌋+1. Consider the\ntwo backbones B1\ns={u1,u2, . . . , us′}and B2\ns={us′,us′+1, . . . , us}where s=2s′−1. For any\ni∈[k−1], if all nodes in Bshave their exit variable set to 0 in rounds r, . . . , r+i′where i′≥i,\n40\n\nthen in any round r+i′, the statements hold true, independently, for B1\nsand B2\ns, which implies, in\nround r+k−1,u1.Sr(k) = us′and us′.Sl(k) = u1and us.Sl(k) = us′and us′.Sr(k) = us. In round\nr+k−1, node us′sends⟨FlyConst-R, u1,k,us′⟩and⟨FlyConst-L, us,k,us′⟩messages to node usand\nu1respectively. Since the nodes do not set their exit variables to 1 in rounds r+k−1 and r+k,\nnode u1assigns ustou1.Sr(k+1)and node usassigns u1tous.Sl(k+1)in round r+k(if they have\nnot already done so), which implies that |u1.R| ≥k+1 and|u3.L| ≥k+1 in round r+k. Recall\nthat for any node u, for any j≥1, once u.Sl(j)oru.Sr(j)is assigned, then it can only removed\n(or updated) in FlushFlyover function (which is executed only after u.exit=1). As no node in Bs\nsets its exit variable to 1 until round r+i′for any i′≥iand i∈[k]where k=⌊log2(s−1)⌋, these\nstatements hold true in round r+i′for any i′≥1.\nCorollary C.23. Consider any backbone B in any round r. If all nodes in B have their exit variable set to\n0in all rounds r ,r+1, . . . , r+i where i ≥ ⌊log2(|B| −1)⌋, then in any round r +i, B is a flyover.\nC.6 Fast Information Dissemination\nLemma C.24. Consider any backbone B in any round r. If there exists a node u ∈B such that u .exit=1\nat round r, then by round r +2⌊log|B|⌋, all nodes in B would’ve exited from the dual-state (at least once).\nProof. LetdB(p,q)denote the distance between any two nodes {p,q} ⊆ Bover the backbone B\nin round r. We recursively define it in the following way. (Note that this distance remains same,\nthroughout the execution, as it is defined for backbone Bat round r.)\ndB(p,q) =\n\n0 if p=q,\n(dB(p.Sl(1),q)) + 1 if (q.L=∅∨q.Sl(1)/∈B),\ndB(p,q.Sl(1)) + 1 if (p.L=∅∨p.Sl(1)/∈B),\n|dB(p,r)−(dB(q,r)|otherwise, where r∈B∧(r.L=∅∨r.Sl(1)/∈B).\nLetDB(v) = min w∈B∧w.exit=1dB(w,v)denote the minimum distance, over all nodes in Bthat\nhave their exit variable set to 1, to the node v∈B.\nIf at round r′∈ {r, . . . , r+2⌊log|B|⌋ − 1}, if either (v.L̸=∅∧v.Sl(1)∈B∧v.Sl(1).exit=1)or\n(v.R̸=∅∧v.Sr(1)∈B∧v.Sr(1).exit=1), i.e., DB(v)<2, then node vexits the dual-state in round\nr′+1. This is due to Remark C.17, every node, in FlushFlyover function, sends ⟨RejFlyover ⟩to\nall ids in its flyover-related address variables. Moreover, if DB(v)≥2 in round r, then we show\nthat it decreases exponentially over time (due to flyover construction, i.e., pointer doubling [46]).\nConsider a backbone Bk={v1,k,v2,k, . . .}in round r+k, where (v1,k.L=∅∨v1,k.Sl(1)/∈Bk)\nand∀i∈[|Bk| −1],vi,k.Sr(1) =vi+1,k, and B0=B. In round r+k, consider a node wthat satisfies\ndB(w,v) = DB(v)≥2, and the backbone Bk={v1,k, . . . , v|Bk|,k}, part of the original backbone\nB, such that either (v1,k=w∧v|Bk|,k=v)or(v1,k=v∧v|Bk|,k=w)is true. For any k≥1, by\nLemma C.22, we know that ∀j∈[k],v1,k.Sr(j) = v1+2j,kand∀j∈[k],v|Bk|,k.Sl(j) = v|Bk|−2j,k. Thus,\nby round r+2⌊log|B|⌋ − 1, either node vexited the dual-state, or DB(v)<2.\nC.7 Concurrent Advices\nClaim C.25. Consider any set of nodes Q ⊂V that process advice messages in round r. For any node\nv∈Q, if the advice is effective, then for any node u /∈Q, then u /∈v.S after v enters dual-state.\n41\n\nProof. Once any node receives an advice, if the node id present in it, is also part of its memory (i.e.,\ninsnap variable), then the node proceeds to check that the distance (i.e., in dist variable) matches\nwith its “parent” node id (as in the advice). See Algorithm 12 for more details. This back-and-forth\nverification of advice between a node and its parent in a synchronous system, before executing the\ntree-to-path transformation (i.e., Algorithm 13), ensures that they must have processed the advice\nin the same round. If any node u/∈Qis not part of this back-and-forth communication, then it is\nnot part of SetupLocalTransform function in Algorithm 12, which in turn, implies that it is also\nnot part of LocalTransform and JoinPath functions in Algorithm 13. Thus, ∀v∈Q,u/∈v.S.\nLemma C.26. Let D be the set of nodes in dual-state in any round r >5. Let D′be the set of nodes that\ntransition to dual-state in round r +1. For any pair of nodes u ∈D and v ∈D′, u/∈v.S in round r +1.\nProof. Consider the following (exhaustive) cases for any node u∈Din round r.\n1. Node uwas always in dual-state from round 1.\n2. Node uprocessed an advice message in a round r′≤r−3, as the distributed tree-to-path\nalgorithms (cf. Section A.2.2) takes 3 rounds, until node uenters dual-state.\nEach node in D′, as it enters dual-state in round r+1, processed an advice message at round r−2.\nLetQbe the set of nodes that processed advice messages in round r−2. Clearly, u/∈Q(asu.t̸=0\noru.S̸=∅in that round). Thus, by Claim C.25, any pair of nodes u∈Dand v∈D′,u/∈v.S.\nC.8 Fast Detection of Bad Advice\nLemma C.27. Let B ={v1, . . . , v|B|}be a maximal backbone in round r >5, where either (v1.Sl(1)/∈B)\nor(v|B|.Sr(1)/∈B)is satisfied. Let L be the set of lost nodes in round r. There is at least node in B that sets\nitsexit variable to 1 by round r +2. Moreover, every node in L sets its exit variable to 1 by round r +2.\nProof. We provide the proof for the backbone B, but the same argument applies to the lost nodes\ninL. Wlog, let node v1.L̸=∅; similar argument also applies to v|B|ifv|B|.R̸=∅.\nNode v1sends⟨TestLine-L ⟩tov1.Sl(1)in round r. But v1.Sl(1), in round r+1, by Lemma C.26,\nas it holds that (v1.Sl(1)).Sr(1)̸=v1, sends ⟨RejFlyover ⟩tov1(regardless whether v1.Sl(1)in a\ndual-state or not). Node v1itsexit variable set to 1 by round r+2.\nLemma C.28. Each node in a maximal ouroboros O in round r >5, exits dual-state in O (log|O|)rounds.\nProof. By Lemma C.26, the size of any maximal ouroboros (or maximal backbone) doesn’t increase\nover time (i.e., for any round r′>r, if some node u/∈O, then u/∈Oin round r′). Let us consider\nthe two cases of maximal ouroboros (as in Definition C.10) in round r.\n1. If Ois a perfect ring, then at least one pair of consecutive nodes in Oset their exit variables\nto 1 by round r+1, as by design, every node uin its dual-state, usends u.vID+1 to u.Sr(1)\nand u.vID−1 to u.Sl(1)in every round. Let L⊆Obe the set of nodes that are lost in\nround r+2; they exit from dual-state by round r+4 by Lemma C.27. The set of nodes\nO′⊆(O\\L), that are in dual-state but not lost in round r+2, forms a partition of maximal\nwinged backbones as every node u∈Oin round r, has u.L̸=∅∧u.R̸=∅. By Lemma C.27,\ncombined with Lemma C.24, by round r+O(log|O|), all nodes in O′exit the dual-state.\n42\n\n2. If Ois a stylish ring, then there is at least one node u∈Osuch that,\n{u.Sl(1),u.Sr(1)} ⊆ O∧((v=u.Sl(1)∧v.Sr(1)̸=u)∨(v=u.Sr(1)∧v.Sl(1)̸=u)).\nNode usends ⟨TestLine-R ⟩and⟨TestLine-L ⟩messages in round r. In round r+1, (at least)\none of the recipients, sets the exit variable to 1, and sends back ⟨RejFlyover ⟩to node u.\nBy round r+2, node uexits the dual-state. Let L⊆Obe the set of nodes that are lost\nin round r+2; they exit from dual-state by round r+4 by Lemma C.27. The set of nodes\nO′⊆O\\(M∪L)that are in dual-state but not lost in round r+2, form a partition of\nmaximal winged backbones, as every node v∈O′in round r, has v.L̸=∅∧v.R̸=∅. By\nLemma C.27 and Lemma C.24, by round r+O(log|O|), all nodes in O′exit the dual-state.\nLemma C.29. Consider any maximal backbone B ⊆V in any round r >5, where B is not winged. If all\nnodes in B have their exit variable set to 0in all rounds r ,r+1, . . . , T, then the following statements hold.\n1. If T ≥r+2⌈log|B|⌉, then in any round r′∈ {r+2⌈log|B|⌉, . . . , T}, B is a flyover, and for all\nu∈B,u.flyID =v.id where v .L=∅.\n2. If T ≥r+3⌈log|B|⌉, and for all u ∈B,u.S⊆B, then in any round r′∈ {r+3⌈log|B|⌉, . . . , T},\nbackbone B is correctly configured.\nProof. First, by Lemma C.26, the size of any maximal backbone doesn’t increase over time (i.e., for\nany round r′≥r, if some node v/∈Bin round r, then v/∈Bin round r′). Since Bisnota winged\nmaximal backbone, i.e., there exist v1and v|B|nodes in Bsuch that (v1.L=∅)and(v|B|.R=∅).\nDue to our algorithm design, we recall the possible changes of flyover-related variables for\nany node uwhose u.S̸=∅and u.exit=0.\n1. The variables vID,c-par ,c-dist are initially updated after receiving an advice message from\nthe supervisor (see GetAdvice function). But they can only be updated again once the node\nexecutes FlushFlyover function (i.e., after u.exit=1).\n2. If u.L=∅∧u.R̸=∅, then u.flyID =u.id; otherwise, the variable flyID can be assigned\nsome other id in R_TestFlyoverMetadata function. Importantly, once u.flyID̸=u.id, it can\nonly be updated again once the node executes FlushFlyover function (i.e., after u.exit=1).\n3. The variables L,Randc-ids can be updated over time in that the existing ids in the variables\ncannot be removed but new ids can be added. Thus, this means that u.Sl(1)and u.Sr(1)can\nbe updated again once the node executes FlushFlyover function (i.e., after u.exit=1).\nAs all nodes have their exit variable set to 0, let us go over the required variable changes of a\ncorrectly configured flyover (as in Definitions C.12 and C.13). Wlog, let B={v1,v2, . . . , v|B|}. If\nthe following events do not happen, then ∃v∈B,v.exit =1 by round r+3⌊log|B|⌋.\n1. (Virtual IDs) As v1.L=∅,v1.vID must be equal to 1. For all i∈[|B|], in round r+1, due to\ntheTestFlyoverMetadata function, vimust be equal to i.\n2. (Hypercube Edges) By Lemma C.22 (and Corollary C.23), by round r+⌊log|B|⌋, backbone\nBis a flyover (as per Definition C.12) due to the TestFlyoverConstruction function.\n43\n\n3. (Flyover ID) By round r+2⌊log|B|⌋, for all i∈[|B|],vi.flyID must be equal to v1due to the\nTestFlyoverMetadata function (as Bmust be a flyover by round r+⌊log|B|⌋).\n4. (Connectivity Certificate) At round r+2⌊log|B|⌋, the prop-flyID variable is set to 1 for any\nnode u∈B, as the clause (u.vID=1)∨(u.vID>1∧u.flyID =v1)is satisfied. For all i∈\n[|B|]\\{1}, node viroutes the vi.c-dist−1 value (over the flyover) to the node with the virtual\nIDvi.c-par using the NextStop function. The message must be routed to some node within\nthe flyover, and that node verifies the message with its c-dist variable. Combined with the\ntests in the BasicChecks function, this results in adding the appropriate neighboring ids in\nthe sorted-path graph over backbone B(as per Definition C.13) by the next ⌈log|B|⌉rounds.\nCorollary C.30. Let all nodes form a single backbone in round r. If all nodes have their exit variable set\nto 0 in all rounds r ,r+1, . . . , r+3⌈logn⌉, then the (sub)network over ∀u∈V, M u(A0), includes the\nsorted-path topology in round r +3⌈logn⌉.\nLemma C.31. Consider a maximal backbone B ={v1, . . . , v|B|}in any round r >5, where |B|<n and\n(v1.L=∅∨v1.Sl(1)/∈B)and∀i∈[|B| −1],vi.Sr(1) =vi+1. By round r +O(logn), at least one node\nin B will set its exit variable to 1.\nProof. First, by Lemma C.26, the size of any maximal backbone doesn’t increase over time (i.e., for\nany round r′>r, if some node u/∈B, then u/∈Bin round r′).\nIfBis a maximal winged backbone in round r, then by Lemma C.27, at least one node in Bsets\nitsexit variable set to 1 by round r+2. Thus, for the rest of the proof, we consider the scenario\nwhere Bisnota winged maximal backbone, i.e., (v1.L=∅)and(v|B|.R=∅).\nFurthermore, for the rest of the proof, we consider the scenario where, no node in Bsets its exit\nvariable to 1 by round r+2⌈logn⌉. (Otherwise, that would only support the lemma statement.)\nBy Lemma C.29, in any round r′≥r+2⌈logn⌉,Bis a flyover, and ∀u∈B,u.flyID =v1.\nRecall that the communication graph is weakly connected in any round (due to Lemma C.21).\nWe split the proof into multiple cases (and subcases), analyzing how the backbone Bgets affected\nfrom the existence of a directed edge (p,q)in round r′, where (p∈B∧q/∈B)or(p/∈B∧q∈B).\nCase 1. Node id pis stored in q’s flyover-related variables, i.e., p∈q.S∪ {q.flyID} ∪q.c-ids . In\nall the following subcases, some node in Bwill set its exit variable to 1 by round r′+O(logn).\n1. If q.S=∅, then qsends⟨RejFlyover ⟩to all ids in q.S∪ {q.flyID} ∪q.c-ids (see, Remark C.17.).\n2. If q.S̸=∅, and any one of the following scenarios holds: qis a lost node, or qis in a maximal\nouroboros or maximal winged backbone. By Lemma C.27 and Lemma C.28, qexits the dual-\nstate by round r′+O(logn), and sends ⟨RejFlyover ⟩to all ids in q.S∪ {q.flyID} ∪q.c-ids .\n3. If q.S̸=∅, and qis in a maximal backbone Bq, where Bqisnotwinged. Let q′be the node in\nBqwhere q′.L=∅. Clearly, Bq∩B=∅(as both are maximal), so p.flyID /∈Bqand q′/∈B. If\nsome node in Bqexits dual-state by round r′+2⌈logn⌉, then by Lemma C.24, qexits the dual-\nstate by round r′+4⌈logn⌉and sends ⟨RejFlyover ⟩to all ids in q.S∪ {q.flyID} ∪q.c-ids . On\nthe other hand, if no node in Bqsets its exit variable to 1 until round r′+2⌈logn⌉, then by\nLemma C.29, the prop-flyID variable is set to 1 in q, after which q′=q.flyID is sent to p, due\ntoTestFlyoverMetadata function, causing pto set its exit variable to 1, as p.flyID̸=q.flyID .\n44\n\nCase 2. Node id qis stored in (memory or channel of) p. As all nodes in Bhave their prop-flyID\nvariable set to 1, node qreceives ⟨TestFlyID, p.flyID⟩in round r′+1. Based on q’s memory in round\nr′+1, we consider the following subcases.\n1. If(q.S̸=∅∧q.flyID̸=p.flyID)∨(q.S=∅), then due to R_TestFlyoverMetadata function,\nqsends ⟨RejFlyover ⟩top.flyID in round r′+1, causing node p.flyID to set its exit to 1.\n2. If(q.S̸=∅∧q.flyID =p.flyID), then we resort to Case 1 (where pisp.flyID ).\nCase 3. Node id pis in Mq(A0). If node quses the DR primitive (see, Definition C.7), i.e., sends\nnode id pto another node, within algorithm A0, by round r′+O(logn), then by Claim C.20, there\nwould exist an edge (p′,q′), where p′∈Band q′∈B, in the next two rounds. In that scenario, we\ncan resort to Case 2. Thus, we analyze the following subcases, where pis always in Mq(A0).\n1. If q.S=∅, then in O(1)rounds, q.t=0 as it is decremented by 1 in every round (and it can\nbe at most 5). (See, BasicChecks2 function in Section A.2.2.) When q.t≤1,q.vIDis set to 0,\ncausing node qto send ⟨TestFlyID, ⊥⟩to all ids in TestFlyoverMetadata function (before q\nprocesses a new advice message; see Remark C.18). Then, pwould set its exit variable to 1.\n2. If q.exitis set to 1 in the next O(logn)rounds, then q.Sand q.vIDare set to ∅and 0 (resp.). In\nthat round, node qsends ⟨TestFlyID, ⊥⟩to all ids in TestFlyoverMetadata function (before\nqprocesses a new advice message; see Remark C.18), causing pto set its exit variable to 1.\n3. If q.S̸=∅∧q.exit=0 for the next O(logn)rounds, then by Lemma C.27 and C.28, qmust\nbelong to a maximal backbone Bq, where Bqisnotwinged. Let q′be the node in Bqwhere\nq′.L=∅. Clearly, Bq∩B=∅(as both are maximal), so p.flyID /∈Bqand q′/∈B. By Lemma\nC.29, the prop-flyID variable is set to 1 in q, after which q′=q.flyID /∈Bis sent to p, due to\nTestFlyoverMetadata function, causing pto set its exit variable to 1, as p.flyID̸=q.flyID .\nCase 4. Node id pis present in a flyover-related message of q. In each of the following subcases,\nwe can resort to either Case 1 or Case 3.\n1. In R_TestFlyoverConstruction function, node qprocesses two types of messages. For any\nmessage ⟨msg,sen⟩,senis stored in, either q.Sor M q(A0). For any message ⟨msg,w,i,sen⟩,w\nand senare stored in either q.Sor M q(A0).\nInR_TestFlyoverMetadata function, for any message ⟨TestFlyID, flyID⟩,flyID is stored in\neither q.flyID or M q(A0).\n2. In R_TestConnCertificate function, for any message ⟨IntroCert, w⟩,ustores qinu.c-ids . For\nany message ⟨TestCert, w,vID,dist⟩, there are three scenarios: (1) wis sent to some node\nq′∈q.S, or (2) qstores winq.c-ids , or (3) qstores win M q(A0). In the first scenario, as the\nprop-flyID variable is set to 1, node qwould have sent q.flyID top. Ifq.flyID̸=p.flyID , then\npwould set its exit variable to 1. Otherwise, if q.flyID̸=p.flyID , we resort to Case 1, where\np′=p.flyID∈Bis stored in node q’s flyover-related variable.\nCase 5. Finally, node id pis present in a advice-related message of q(see, algorithms in Section\nA.2.2). In each of those algorithms, whenever a node qprocesses any message, it simply flushes\nthe node ids present in the message to Mq(A0)at the end. Thus, we resort to Case 3.\n45\n\nC.9 Putting Everything Together\nClaim C.32. If a node is in a precarious dual-state in round r, it exits dual-state by round r +O(logn).\nProof. For the first three cases of the precarious dual-state property (see Definition C.14), if all\nnodes do not form a single backbone, then by Lemma C.27, Lemma C.28 and Lemma C.31, com-\nbined with fast information dissemination (i.e., Lemma C.24), every node exits the dual-state in\nO(logn)rounds. However, if the network forms a single backbone, and if some node is sets its\nexit variable to 1 by round r+3⌈logn⌉, then again, combined with Lemma C.24, every node exits\nthe dual-state by round r+O(logn).\nTheorem C.33. The network is s-robust.\nProof. By design (see, GetAdvice function in Algorithm 12, and Definition C.4 for “well-formed”\nadvice), for any node u, (1) there can be only onenode id present in any advice message, and (2)\nthat id must already be present in the snap variable when the advice is received at node u. Thus, the\nsupervisor cannot add arbitrary connections to any node, ensuring the Sybil resistance property.\nIf any node is in a precarious dual-state (see Definition C.14), then by Claim C.32, it exits the\ndual-state in O(logn)rounds. On the other hand, if no node is in a precarious dual-state, and\nthe network forms a single backbone, and no node sets its exit variable to 1 for Θ(logn)rounds,\nthen by Lemma C.29, the backbone is a correctly configured flyover (i.e., the supervisor provided\ncorrect advice messages), i.e., by Corollary C.30, the network is in an almost-legal configuration.\nMoreover, this observation implies that even if the supervisor is malicious (e.g., providing “bad”\nadvice messages), the network quickly rejects the “supervised-induced” subnetwork (from any\narbitrary configuration). Thus, the network also achieves the robustness property, which would\nallow an honest supervisor to quickly (i.e., in O(logn)rounds) contact all nodes, provide correct\nadvice messages to repair the network.\nClaim C.34. Consider a node id v in any flyover-related or advice-related message of a node u in round r.\nBy round r +1, one of the following events happen, where w =u.flyID in round r.\n1. v∈u.S∪ {u.flyID} ∪u.c-ids.\n2. v∈Mu(A0).\n3. v.flyID =w.\n4. w∈Mv(A0).\nProof. Similar to the proof of Lemma C.21, we provide a case-by-case analysis depending on the\nmessage that the node id vis part of.\n1. If u.S=∅, in functions, R_TestFlyoverConstruction ,R_TestFlyoverMetadata and R_TestConnCertificate ,\nnode id vstraightaway gets added to M u(A0)in round r.\n2. If vbelongs to any function in the distributed tree-to-path algorithms (cf. Section A.2.2),\nagain, node id vstraightaway gets added to M u(A0)in round r.\n46\n\n3. In R_TestFlyoverConstruction function, node uprocesses two types of messages. For any\nmessage ⟨msg,sen⟩,senis stored in, either u.Sor M u(A0). For any message ⟨msg,w,i,sen⟩,w\nand senare stored in either u.Sor M u(A0).\nInR_TestFlyoverMetadata function, for any message ⟨TestFlyID, flyID⟩, there are two cases:\nflyID is stored in either u.flyID or M u(A0).\n4. In R_TestConnCertificate function, for any message ⟨TestCert, v,vID,dist⟩, there are three\ncases: (1) vis sent to node u′∈u.S, or (2) ustores vinu.c-ids , or (3) ustores vin M u(A0);\nin the first case, before vis sent to an id u′∈u.S,umust’ve sent ⟨TestFlyID, u.flyID⟩tovin\nround r(as the prop-flyID variable is set to 1). In round r+1, node vstores u.flyID in either\nv.flyID , or M v(A0). And, for any message ⟨IntroCert, v⟩,ustores vinu.c-ids .\nTheorem C.35. If supervisor is honest, then the network reaches an almost-legal configuration in O (logn)\nrounds; otherwise, it reaches an almost-legal configuration in 2R(A0) +O(logn)rounds.\nProof. We denote the subnetwork formed by edges in ∀u∈V, M u(A0)as N(A0). Recall that the\ncommunication graph is always weakly connected (in any round) due to Lemma C.21.\nFirst, we introduce some notation for showing that N(A0)would be (weakly) connected. Let\nthe (directed) edge (u,v)in the communication graph in any round r≥1; we define the color of\nan edge (u,v)in the following way.\n1. If(v/∈Mu(A0))∧(v/∈u.S∪ {u.flyID} ∪u.c-ids), but node id vis present in a flyover-related\nor advice-related message in u, then the color of (u,v)is red.\n2. If(v/∈Mu(A0))∧(v∈u.S∪ {u.flyID} ∪u.c-ids), then the color of (u,v)is blue.\n3. If v∈Mu(A0), then the color of the edge (u,v)is green. Similarly, we say that a path between\nany pair of nodes (ignoring edge directions) is a green path if all edges in it are green.\nWe proceed to show that N (A0)forms a single (weakly) connected component, i.e., there exists\na green path between any pair of nodes, in O(logn)rounds, regardless of the initial configuration\nand any node’s interactions with the supervisor. If N (A0)is weakly connected, then it always\nremains a single (weakly) connected component in any subsequent round, as Algorithm A0is a\nself-stabilizing overlay algorithm (i.e., it preserves connectivity from any initial configuration),\nand importantly, nodes do not delete connections from the memory (incl. channel) dedicated to\nAlgorithm A0while interacting with the supervisor (cf. Theorem C.33).\nTowards that end, consider any pair of nodes uand vthat do nothave any green path between\nthem in any round r≥1. As the communication graph is weakly connected, there exists some\n(undirected, i.e., ignoring edge directions) path P= (u,v1, . . . , vt), where vt=vfort≥1, in that\nround. Consider any edge e= (p,q)belonging to P; the following invariants hold in round r+1.\n1. If eis red, then eturns either blue or green, due to Claim C.34.\n2. If eis blue, then eeither remains blue or turns green, due to Remark C.17.\n3. If eis green, then due to the guarantee that Algorithm A0preserves connectivity, there exists\nsome green path Pe= (p,q1, . . . , qt′), where qt′=qfort′≥1.\n47\n\nWe proceed to show that any blue edge turns green in O(logn)rounds. Consider any blue\nedge e= (p,q), where the node id qbelongs to a flyover-related address variable of node p. In the\nfollowing (exhaustive) cases, nodes pand qend up with a green path between them.\n1. If p.S=∅, then all flyover-related address variables of pare straightaway flushed to M p(A0).\n2. If pis in a precarious dual-state, then by Claim C.32, pexits dual-state in O(logn)rounds.\n3. If the network forms a single backbone, and if all nodes have their exit variables set to 0 in\nall rounds r,r+1, . . . , r+3⌈logn⌉. By Corollary C.30, N (A0)becomes (weakly) connected.\nIf N(A0)is (weakly) connected (regardless of any supervisor interaction), the network reaches\nan almost-legal configuration in 2R (A0)rounds. This is because each node uexecutes Algorithm\nA0(in the background), and it is guaranteed that Algorithm A0, when executed independently,\nconverges to the target topology G∗in R(A0)rounds. There is an extra factor of 2, in our upper\nbound, because “Delegation” (of a node id by any node via a message), that takes a single round, is\nimplemented in two rounds as “Delegate-after-Reversal” (see Definition C.7). Thus, if supervisor\nis not honest, the network reaches an almost-legal configuration in 2R (A0) +O(logn)rounds.\nIf the supervisor is honest, we can leverage the (correct) advice for showing fast stabilization.\nFirst, we show that within O(logn)rounds, there exists at least one attentive node, in which case,\nthe supervisor is contacted for help. Once the supervisor is contacted by a node, the supervisor\nwaits for O(logn)rounds until all nodes become attentive. Then, the supervisor sends the correct\nadvice messages, leading to all nodes forming a correctly-configured flyover in O(logn)rounds.\nFinally, each node finds its predecessor and successor (in the sorted-path topology G∗) in the c-id\nvariable, due to Corollary C.30, as no node sets its exit variable to 1.\nTowards that end, we prove the following arguments.\n1. If N (A0)does not include G∗inO(logn)rounds, then there exists at least one attentive node\ninO(logn)rounds. (If G∗is already included, then we are done.)\n2. If there is one attentive node, then all nodes become attentive in O(logn)rounds.\nConsider the following (exhaustive) cases in any round r>5.\n1. By Claim C.32, any node in a precarious dual-state exits dual-state in O(logn)rounds.\n2. If the network forms a single backbone, and if all nodes have their exit variables set to 0 in\nall rounds r,r+1, . . . , r+3⌈logn⌉. By Corollary C.30, N (A0)becomes (weakly) connected.\nFor any node u,u.tdecreases by one in every round (and u.tcan be at most 5). (See BasicChecks2\nfunction in Section A.2.2). By Claim C.34, if there is any node id vin any flyover-related or advice-\nrelated message of any node u(where u.S=∅), then it is flushed to M u(A0). Once node uexits\ndual-state, it becomes attentive (i.e., u.S=∧u.exit=0∧u.t=0) in O(1)rounds. Thus, either all\nnodes become attentive in O(logn)rounds, or N(A0)includes the target topology G∗.\nC.10 Lower Bound for Convergence Time\nTheorem C.36. For an s-robust network, there exists some initial configuration such that the convergence\ntime for any pair of supervisor and overlay algorithms is Ω(logn)rounds.\n48\n\nProof. Consider an initial configuration where two nodes uand vare at a distance D=Ω(n)in the\ncommunication graph. However, these nodes are meant to be adjacent in target topology G∗. If\nthere is a pair of supervisor and self-stabilizing overlay algorithm for which this network reaches\nan almost-legal configuration in o(logD)rounds, then we can show a contradiction that the nodes\nuand vwere at a distance d<Din the initial state.\nRecall that the nodes of an s-robust network do not arbitrarily create connections of any node\nid present in the advice message. In particular, a node can only add (directed) edges between any\ntwo ids present in its memory or channel. Thus, even if the supervisor is aware of memory states\n(incl. channels) of all nodes, and is allowed to interact with any subsets of nodes simultaneously,\nit is still limited in its power to create new connections.\nLettbe the minimum number of rounds (from that initial configuration at round 1) taken for\nnode uto acquire the id of node v(or vice versa) in its channel. Let S= (a1,a2, . . . , at=u)be the\nsequence of nodes from round 1 to tholding the id of v(until it reached u). For ease of exposition,\nlet us consider the class of distributed overlay algorithms that only add new (directed) edges, i.e,\ndo not remove existing edges. If we arrive at a contradiction for this class of algorithms, then it\nalso applies to all other algorithms.\nTo that end, observe that for this class of algorithms, the ids in Smust initially belong to some\npath P(regardless of directions) from vtou. The key observation is that for i∈[t−1], between ai\nand ai+1in the path P, there can be at most 2i−1−1 nodes (and 2i−1edges), i.e., node ai+1cannot be\ntoo far from node aiin the initial communication graph. This is because even if all nodes introduce\nall ids stored in their respective memories (incl. channels) to each other via messages in all rounds,\neach node can only learn all ids in its 2j-hop neighborhood in jrounds. Thus, the total number of\nedges (i.e., distance between vand u) in this path Pis at most 2t.\nTherefore, we arrive at a contradiction that if there exists a pair of supervisor and self-stabilizing\noverlay algorithm for which the network reached an almost-legal configuration in t=o(logD)\nrounds, then uand vmust have been at a distance of at most 2t<Din the initial configuration.\n49\n\nD Helpful Figures and Tables\nFigure 6: Intuition for the Tree-to-Path algorithm.\nVariable Store node ids?\nu.L ✓\nu.R ✓\nu.vID ✗\nu.flyID ✓\nu.c-par ✗\nu.c-dist ✗\nu.c-ids ✓\nu.exit ✗\nTable 1: Flyover variables of a node u.Variable Store node ids?\nu.t ✗\nu.dist ✗\nTable 2: Advice variable of a node u.\n50",
  "textLength": 133794
}