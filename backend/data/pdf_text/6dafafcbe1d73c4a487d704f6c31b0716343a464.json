{
  "paperId": "6dafafcbe1d73c4a487d704f6c31b0716343a464",
  "title": "Challenges and future directions for energy, latency, and lifetime improvements in NVMs",
  "pdfPath": "6dafafcbe1d73c4a487d704f6c31b0716343a464.pdf",
  "text": "Vol.:(0123456789)Distributed and Parallel Databases (2023) 41:163–189\nhttps://doi.org/10.1007/s10619-022-07421-x\n1 3\nChallenges and future directions for energy, latency, \nand lifetime improvements in NVMs\nSaeed Kargar1 · Faisal Nawab2\nAccepted: 7 September 2022 / Published online: 21 September 2022 \n© The Author(s) 2022\nAbstract\nRecently, non-volatile memory (NVM) technology has revolutionized the land-\nscape of memory systems. With many advantages, such as non volatility and near \nzero standby power consumption, these byte-addressable memory technologies \nare taking the place of DRAMs. Nonetheless, they also present some limitations, \nsuch as limited write endurance, which hinders their widespread use in today’s sys-\ntems. Furthermore, adjusting current data management systems to embrace these \nnew memory technologies and all their potential is proving to be a nontrivial task. \nBecause of this, a substantial amount of research has been done, from both the data-\nbase community and the storage systems community, that tries to improve various \naspects of NVMs to integrate these technologies into the memory hierarchy. In this \nwork, which is the extended version of Kargar and Nawab (Proc. VLDB Endowment \n14(12):3194–3197, 2021), we explore state-of-the-art work on deploying NVMs in \ndatabase and storage systems communities and the ways their limitations are being \nhandled within these communities. In particular, we focus on (1) the challenges that \nare related to high energy consumption, low write endurance and asymmetric read/\nwrite costs and (2) how these challenges can be solved using hardware and soft-\nware solutions, especially by reducing the number of bit flips in write operations. \nWe believe that this area has not gained enough attention in the data management \ncommunity and this tutorial will provide information on how to integrate recent \nadvances from the NVM storage community into existing and future data manage-\nment systems.\nKeywords Non-volatile memory · Write endurance · Energy consumption · \nReducing bit flips\n * Saeed Kargar \n skargar@ucsc.edu\n Faisal Nawab \n nawabf@uci.edu\n1 CSE Department, UC Santa Cruz, Santa Cruz, CA, USA\n2 CSE Department, UC Irvine, Irvine, CA, USA\n\n164 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n1 Introduction\nNowadays, we are witnessing the emergence of new non-volatile memory (NVM) \ntechnologies that are remarkably changing the landscape of memory systems. They \nare persistent, have high density, byte addressable, and require near-zero standby \npower [1], which makes them of great interest in the database and storage systems \ncommunities. Furthermore, NVMs provide up to 10x higher bandwidth and 100x \nlower access latency compared to SSDs [2, 3]. However, because they also present \nsome limitations, such as limited write endurance, which is significantly lower than \nDRAM write endurance, and high write energy consumption (Fig.  1), adopting the \ncurrent systems to use NVM while maximizing their potential is proving to be chal-\nlenging. Additionally, unlike flash storage, cells are written individually in many \nNVM technologies such as PCM. This means that some cells may receive a much \nhigher number of writes than others during a given period, and as a result wear out \nsooner. So, any system design needs to take these limitations into consideration \nbefore deciding to utilize NVMs.\nThe scientific community has conducted an extensive amount of research on inte-\ngrating these new technologies in current systems. Furthermore, these emerging \ntechnologies are carving out their own place in the memory hierarchy. As persistent \nmemories are usually larger than DRAM in capacity, researchers in database com-\nmunity usually take advantage of its consistency to boost performance of the system \nby making the in-memory database persistent, which results in capacity expansion \nFig. 1  Comparison of device properties of memory and storage technologies [4]\n\n165\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \nand recovery cost reduction. However, when designing a database management sys-\ntem, it is critical to fully consider the characteristics of NVMs to take advantage \nof their hardware potentials. For example, most NVM technologies have limited \nwrite endurance, which needs special considerations when using them as a memory \ndevice. Another characteristic is their asymmetric write/read costs in most NVM \ntechnologies. So, the databases systems or data structures that are designed for them \nusually avoid write operations as much as possible.\nTherefore, in this tutorial we survey recent work in both storage and database \ncommunities, where a substantial amount of work has been done in the adoption of \nNVMs. In particular, we focus on the common limitations that are shared among \nmost NVMs—i.e. low write endurance, high energy consumption, and intrinsic \nasymmetric properties of reads and writes. Table  1 compares the main character -\nistics of these memory technologies. This tutorial provides information on how to \nintegrate recent advances from the NVM storage community into existing and future \ndata management systems.\nContributions In this paper, which is the extended version of [4], we focus on \nthe techniques for improving NVM’s performance, lifetime and energy consumption \nalthough these challenges might vary from technology to technology. For example, \nwhile limited lifetime is a key challenge in most NVM technologies, it might not \nbe an issue in Optane and FeRAM. In this work, we, especially, explore how the \nmentioned challenges are related to the number of bit flips in write operations in one \nof the most mature and widespread NVM technologies, i.e. phase change memory \n(PCM). Figure  2 shows an overview of this paper. In Sect.  2, we present a back -\nground on key terms, concepts, and properties of different NVM technologies. In \nSect.  2.3, we underscore the motivation for and challenges in improving lifetime, \nenergy consumption and latency of the NVM device. Further, we classify the impor -\ntance of works based on three main views to give an overall view of the whole field. \nWe discuss three main methods for overcoming some of the limitations that most \nTable 1  Device properties of emerging nonvolatile memories\nSeries storage class memory device property\nCost/bit Reliability Flexibility Write \nendur -\nanceWrite \nEnergyScalability Write \nlatencyDensity\nPCM ✓ ✓ ✓ ✗ ✗ ✓ ✗ ✓\nFeRAM ✗ ✗ ✓ ✓ ✓ ✗ ✓ ✗\nSTT-RAM ✗ ✗ ✗ ✓ ✗ ✗ ✓ ✗\nReRAM ✓ ✗ ✓ ✗ ✗ ✓ ✗ ✓\nSRAM ✗ ✗ ✗ ✓ ✗ ✗ ✓ ✗\nNAND \nFlash✓ ✗ ✓ ✗ ✗ ✗ ✓ ✓\nNOR \nFlash✗ ✓ ✓ ✗ ✗ ✗ ✗ ✗\n3D XPoint ✓ ✓ ✓ ✗ ✗ ✓ ✗ ✓\n\n166 Distributed and Parallel Databases (2023) 41:163–189\n1 3\nNVM technologies have in common in Sects.  3 and 4. In Sect.  4 we elaborate bit flip \nreduction technique, which is the main focus of this survey. We conclude this paper \nin Sect. 5 with a brief mention of future research challenges.\nScope For sake of a concise presentation, we limit the scope of this paper as fol-\nlows. Although We discuss the storage and hardware-level techniques to improve \nperformance, energy consumption and lifetime of various NVM technologies, in this \nwork, we specifically explore the potential of decreasing bit flips in various aspects \nof PCMs. We believe that this paper will be useful not only for memory designers \nand database and storage researchers who are new to this field but also for research-\ners from other fields, such as IoT, distributed systems, and HPC, who are interested \nto integrate NVMs in their work.\n2  Background and motivation\nWe now introduce some concepts which will be useful throughout this paper. We \nrefer the reader to previous works for a detailed background on NVM architecture \n[5–7].\n2.1  NVM properties\nNon-volatile memory has the potential of transforming the memory architecture in \ndata management systems due to their characteristics such as persistency, high den-\nsity, byte addressability, and requiring near-zero standby power [1]. However, they \nalso have their own drawbacks that may vary from technology to technology: some \nhave problems with write endurance, some have higher write latency than the read \nlatency, some have low density and do not scale well, and so on. So, researchers \nhave been trying to overcome these limitations to efficiently utilize them.Paper Organization\n2.Background and Motivation\n2.1.NVM properties\n2.1.NVM technologies\n2.2.Motivation\n2.2.1.Write endurance\n2.2.2.Energy consumption\n2.2.3.Latency\n2.3.Solutions\n3.Techniques for Protecting NVM\n3.1.Wear leveling\n3.2.Decreasing write\namplification/\n4.Bit Flip Reduction\n4.1.RBW-based\ntechniques\n4.2.Write awareness\n4.2.1.AI-based\nmethods\n4.2.2.Data\nstructure-based\nmethods\n5.Conclusiona nd\nfuture work\nFig. 2  Organization of the paper\n\n167\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \nAs far as write endurance is concerned, most NVM technologies, such as PCM, \nReRAM, 3D XPoint and Flash memory, have lower write endurance  (105–109) com-\npared to the traditional memory technologies, such as DRAM, which have virtually \nunlimited lifetime  (1016). Even in some NVM technologies such as STT-RAM with \nhigher lifetime (at least  1012), certain usage conditions, such as frequent accesses \nwith a high applied bias voltage or a long pulse, may aggravate their lifetime and \nreliability [79, 80]. Furthermore, in many use cases, some of NVM technologies, \nsuch as PCM, STT-RAM and ReRAM, are used in the lower-level cache hierarchies \ninstead of memory level, which expose them to aggressively high number of writes. \nSo, in these cases, write endurance can prevent the adoption of NVM in lower-level \ncaches.\nImproving NVM lifetime is not the only concern that researchers need to deal \nwith. NVM write operations demand a significant amount of current and power. \nFor flipping an individual bit in PCM, for instance, it requires around 50 pJ/b com-\npared to writing a DRAM page, which needs only 1 pJ/b [23]. Table  2 shows some \nselected studies that are done in recent years to improve lifetime, performance or \nenergy efficiency of different NVM technologies. To solve these main limitations, \nresearchers usually use one or a combination of the following techniques: (1) design-\ning new data structures and database management systems based on the limitations \nof NVMs, (2) redesign the existing data structures, which are proved to be efficient, \nto be more NVM-friendly, and (3) designing some special hardware-level or soft-\nware-level solutions to meet the limitations of NVMs or alleviate their drawbacks.\n2.2  NVM technologies\nDespite having so many benefits over DRAMs, NVM technologies have lots of \nlimitations in common, such as high energy consumption, low write endurance and \nasymmetric read/write costs, which needs to be considered before using them. So, \nresearchers come up with different solutions to deal with these limitations, from \nredesigning the conventional data structures to proposing hardware-level methods, \nto deploy these new technologies in their systems. Among all the challenges that \nTable 2  Selected studies \ncategorized by their contributionContribution Series selected studies\nLifetime improvement [4, 8–17]\n[18–27]\n[28–34]\nPerformance [4, 15–17, 26, 28, 35–38]\n[39–45]\n[46–55]\n[56–64]\nEnergy efficiency [4, 9, 13, 18, 23–27, 35]\n[41, 65–71]\n[72–78]\n\n168 Distributed and Parallel Databases (2023) 41:163–189\n1 3\nNVMs face, in this paper, we focus on (1) low endurance, high energy consump-\ntion, and asymmetric read/write related problems and (2) how researchers in differ -\nent communities, from databases to storage systems to embedded systems and dis-\ntributed systems, overcome these limitations. Table  3 classifies the research studies \nfrom Table  2 based on their memory technologies. The NVM technologies that we \ncover are:\nSpin-Torque Transfer RAM (STT-RAM), which is a variation of MRAM, \nswitches the memory states using spin-transfer torque. Using spin-polarized cur -\nrent for setting bits makes the cell structure simple and small. The most notice-\nable advantage of this memory is to have a high efficiency and write endurance \neven compared to DRAM. These characteristics make it as one of the top alterna-\ntives to the current technologies such as DRAM and NOR Flash. Despite having \nthe mentioned advantages, this technology comes at a price: having low density \nwhich makes it hard to scale  [81].\nResistive RAM(ReRAM) is one of the most promising NVM technologies that \ncan take the place of DRAM. It’s simple structure, easy fabrication, high scalabil-\nity, and compatibility with the existing CMOS technology make this technology \na good candidate to be used in many applications in various fields from Neuro-\nmorphic Computing to logic applications. In ReRAM, by applying current to a \ncell, the state of the cell can be switched. Despite all its advantages, it has some \ndrawbacks, such as having low write endurance and inconsistent switching mech-\nanism, which makes researchers look for methods to improve its performance and \nmitigate its disadvantages to use it in the existing systems [82].\nPhase-Change Random Access Memory (PCM), which is probably the \nmost mature of the NVM technologies, consists of phase-change materials \nthat switches between two different phases with distinct properties: an amor -\nphous phase, with high electrical resistivity, and a crystalline phase, with \nlow electrical resistivity. So, in PCMs, there are two main operations: SET \noperation and RESET operation. These operations are controlled by electri-\ncal current as follows: while in the RESET operation High-power are used \nto place the memory cell into the high-resistance RESET state, for the SET \nTable 3  Selected studies \ncategorized by their SCM typeSCM Type Series selected studies\nPCM [4, 18–20, 22–26, 30, 34]\n[35, 36, 40, 43, 53, 67, 71, 77, 78]\nReRAM [8–11, 17, 18, 29, 66, 72, 75, 76]\nSTT-RAM [8, 11–14, 31–33]\n[41, 42, 63, 65, 70, 73]\nNAND Flash [15, 16, 28, 37, 45, 46, 49]\n[51, 54, 56, 61, 64]\n3D XPoint [25–27, 38, 40, 43, 44, 47, 48, 50]\n[51, 52, 55, 57–60, 62, 69]\n\n169\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \noperation, moderate power but longer duration pulses are used to return the \ncell to the low-resistance SET state. Although PCM scales well and has write \nendurance comparable to that of NAND Flash  (108–109), which makes it a \nviable alternate for future high-speed storage devices. However, its asymmet-\nric read/write costs in terms of energy consumption and latency, and lower \nwrite endurance compared to DRAM  (1016), limit the PCM adoption in sys-\ntem architecture.\n3D XPoint is a recent NVM technology that is developed by the Intel and \nMicron jointly since 2015. This technology is usually considered as a type \nof PCM although Intel has never disclosed its technical details [82]. This \ntechnology presents many advantages, such as having a high density and low \naccess latency, which makes it probably one of the best candidates to replace \nDRAM. However, this technology pose some challenges, which need to be \nconsidered. First, its write energy consumption is relatively high. Second, \nalthough its write latency is relatively low, it is still orders of magnitude high \ncompared to DRAM. Furthermore, its memory cell write endurance  (108–109) \nis orders of magnitude lower than that for DRAM although it is claimed that \nit is enough to survive continuous operation as the main memory for a few \nyears [83].\nFlash memory is an electronic NVM storage medium that can be electrically \nerased and reprogrammed. It is probably the most wide-spread NVM technol-\nogy since it has the performance better than traditional storage. There are two \ntypes of nonvolatile semiconductor flash memory: NOR and NAND. While \nNOR Flash has low latency and can be programmed at byte granularity, which \nis suitable for IoT system devices like GPS and e-readers that do not require \nas much memory, NAND Flash is more like HDD with page-based program-\ning granularity, which is suitable for sequential data such as video, audio, and \nso on [84]. Despite all the mentioned advantages, this technology shares some \ndisadvantages that most NVM technologies have in common: having lim-\nited write endurance, low density, energy constraints, asymmetric read/write \nlatency and persistence.\nFeRAM, which has similar structure as DRAM bit cell except, achieve nonvol-\natility, it utilizes a ferroelectric layer instead of a dielectric layer. This technol-\nogy has been gaining popularity, especially in industrial IoT applications and \nautonomous vehicles field, for its unique characteristics such as having very \nhigh life endurance, low write time speed, and low write energy consumption \n[83]. However, like any other technology in NVM category, it faces some lim-\nitations that hinders this technology from its widespread use, such as much \nlower storage densities than Flash, storage capacity limitations and higher cost.\nFigure  3 illustrates the number of studies that are carried out in the three main \ncategories, i.e., improving lifetime (LIF), performance (Perf), and energy con-\nsumption (EC), on different types of NVM technologies from 2009. These results \ncan reveal how much each of the mentioned fields could draw researchers’ atten-\ntion in different NVM technologies over time. In this figure, we try to give some \ndirection for future work to those researchers who are new to this field.\n\n170 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n2.3  Motivation for bit flip reduction\n2.3.1  Write endurance\nMost NVM technologies, such as PCM, ReRAM, 3D XPoint and Flash memory, \nhave low write endurance (the number of writes that can be applied to a segment \nof storage media before it becomes unreliable.) The write endurance in these tech-\nnologies is on the order of  105–109 writes, which is significantly lower than DRAM \nwrite endurance (in the order of  1016 write) [4, 5]. Even in some NVM technologies \nsuch as STT-RAM, which has an endurance of at least  1012 writes, certain usage \nconditions, such as frequent accesses with a high applied bias voltage or a long \npulse, may aggravate their lifetime and reliability [79, 80]. Furthermore, in many \nuse cases, some of these technologies, such as PCM, STT-RAM and ReRAM, are \nused in the lower-level cache hierarchies instead of memory level, which expose \nthem to aggressively high number of writes. So, in these cases, write endurance can \nprevent the adoption of NVM in lower-level caches.\nTable  2 illustrates some of the selected studies that are proposed recently in an \nattempt to solve the limited write endurance of NVMs. Although most of the solu-\ntions that are presented to improve the lifetime of NVM, such as reducing write \namplification, local write optimization and memory awareness, can be applied to \nvarious NVM technologies with write endurance problem, in this paper, we focus on \nPCM and how its lifetime can be improved through bit flip reduction.\nAs mentioned earlier, PCM is currently the most mature and widespread of \nthe NVM memory technologies under research. It is used in different memory \n(a)PCM (b)NAN DFlash (c)ReRAM\n(d)STT-RAM (e)3DXPoint (f)Others\nFig. 3  The number of studies that are done to improve the lifetime (LIF), energy consumption (EC), and \nperformance (Perf) of different NVM technologies\n\n171\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \nhierarchies from L2 cache to storage medium, which makes it of great importance \nin terms of replacing conventional memory technologies. In Sect.  4, we explore the \neffects of reducing the number of bit flips on various aspects of PCM from perfor -\nmance to energy consumption and lifetime. Based on the experiments that we have \ndone in that section, we will show that not only does reducing the number of written \ncells increase the average lifetime of the device, but also it decreases the system’s \npower consumption and improves the system’s latency significantly. We also believe \nthat this area has not gained enough attention in the data management community \nand this tutorial will provide information on how to integrate recent advances from \nthe NVM storage community into existing and future data management systems.\n2.3.2  Energy consumption\nBit flip reduction represents the design principle of minimizing how many bits are \nflipped from 0 to 1 or 1 to 0 when a write is applied to a memory segment. In a PCM \ndevice, as the number of bit flips decreases, the write endurance improves. Reducing \nthe number of written cells also means that the energy consumption of the system \ndrops significantly. For instance, based on an experiment conducted by [66], when \nthe number of different bits in the write data and the overwritten content varies from \n0 to 100%, the energy consumption can vary from nearly 0 to over 10,000 pJ. So, \ntargeting bit flip reduction is a worthy investment in the NVM context, and there are \na large body of research, such as [18, 23, 25–27, 66, 67], targeting bit flip reduction \nto extend the NVM lifetime and decrease their energy consumption.\nTo see how this difference affects the system’s energy consumption, we have \nconducted a simple experiment on a real Optane memory device (Sect.  4). For the \nexperiment, we have used the Persistent Memory Development Kit (PMDK) [85], \nformerly known as NVML. As we will see in the results, reducing the number of \nbit flips can have positive effects on the energy consumption of the NVM device. \nThis experiment alongside the ones that we have done to analyze the impacts of bit \nflip reduction on latency and lifetime of PCMs show that reducing the number of bit \nflips in the NVM devices, such as PCM, whose controllers are optimized by only \nflipping bits when the old value of a cell differs from the value being written to it \ncan lead to improvement in lifetime, latency, and energy consumption of the device.\n2.3.3  Latency\nNot only does reducing the number of bit flips save the energy consumption of the \nsystem, but also it can improve the latency of write operations. Figure  6 (the top \none) shows that write latency also improves when bit flips are reduced. The main \nreason behind this is when the content of the old data and the data that is being \nwritten is similar, the total number of writes can also be reduced, which results in \nimproving write latency. This process can reduce the number of writes in two ways: \n(1) the first way is by writing new items in-place to replace a similar old value in \nterms of hamming distance. This leads to decreasing NVM word writes (i.e., the \nnumber of modified words in a cache line.) (2) In the second way, writing similar \ncontents decreases the number of NVM line writes, respectively cache lines needed \n\n172 Distributed and Parallel Databases (2023) 41:163–189\n1 3\nto be written per item. For example, suppose that the page size in a system is 4 KB \nas shown in Fig.  1 [25]. In this scenario, if the items are similar to each other in \nterms of the hamming distance, fewer number of cache lines are needed to fulfill the \nrequest (suppose each part in Fig.  4 is a cache line). This enables PNW to decrease \nNVM word writes in addition to NVM line writes.\n2.4  Solutions\nThere have been plenty of methods proposed for improving NVM write endurance \nand energy consumption from hardware-focused methods to software-focused ones. \nAccording to their general strategies, these methods can be categorized into three \nmain groups:\n(1) The storage community developed write optimization techniques that are mostly \nbased on a Read-Before-Write (RBW) pattern [86]. In RBW, a write operation \nw to a memory location x  is always preceded with a read of x . The value to be \nwritten by w  is compared with the old content of x , and only the bits that are \ndifferent are written. This reduces the number of flipped bits, which increases \nwrite endurance [86]. Other approaches built on RBW to increase write endur -\nance by masking or changing the value to be written if it leads to reducing bit \nflips [87– 91]. Flip-N-Write (FNW), for example, checks whether flipping the \nbits of the write operation would lead to decreasing the number of bit flips [ 87].\n(2) The data management community tackled the problem of write endurance by \nminimize write operations via techniques such as caching [92– 94] and delayed \nmerging [40, 43], or by designing specialized data structures that require fewer \nwrites [24]. Therefore, data structures that are designed to be deployed on NVM \nshould be designed in a way to exploit the advantages and avoid the disadvan-\ntages of the technologies. For example, data structures for disks are block-ori-\nented and work the best for sequential access. However, those designed for flash \nreduce write amplification, which is the main concern in flash technologies [23]. \nAs we will explain later, techniques that focus on reducing write amplification \ncan result in increasing write endurance although this is not always the case [ 23].\n(3) The proposed methods in the third group also increase the write endurance of \nPCMs through a new approach called memory-awareness. The main idea behind \nthis approach is to take advantage of having knowledge of the memory content \nin advance because read operations are less expensive than write operations in \nPCMs. Prior methods pick the memory location for a write operation arbitrarily \n(new data items select an arbitrary location in memory, and updates to data items \nFig. 4  An example of replacing a memory content with a similar content used in PNW [25]\n\n173\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \noverwrite the previously-chosen location.) The methods in this group judiciously \npick a memory location that is similar to the value to be written. When the new \nvalue and the value to be overwritten are similar, this means that the number of \nbit flips is going to be lower. There are lots of methods that use this approach as \nthe backbones of their methods, which will be explored in Sect.  4.2.\n3  Techniques for protecting NVM\nIn this section, we present the main concerns, challenges, and limitations of state-of-\nthe-art methods that have utilized NVMs in their designs by dividing them into three \nmain groups based on the trends and solutions they propose to solve the problem of \nwrite endurance and energy consumption. We also identify the short- and long-term \nresearch opportunities in this space.\n3.1  Wear leveling\nWear leveling has been studied extensively for Flash-based storage devices [95–99]. \nIn these methods, the wear-leveling algorithms usually keep track of the storage \nblocks and remap those blocks that are written heavily in a given time quanta to the \nlowest wear-out blocks. In storage class memory, wear leveling has almost the same \nobjective, which is extending the lifetime of NVM devices by distributing the writes \nevenly across the memory blocks of NVM so that no hot  area reaches its maxi-\nmum lifespan by extremely high concentration of write operations [18, 66, 87, 88, \n100–102]. These methods usually are implemented in the memory controller level \nto protect NVMs. Wear-leveling is usually transparent for upper-level applications \nand they can simply access to the same content using the same logical address (LA) \n(they are unaware of the physical address where the data are stored.) According to \nthe mapping strategies, existing wear-leveling schemes can be divided into two main \ngroups:\n(1) Table-based wear-leveling (TBWL) techniques that store the LAs, their cor -\nresponding physical addresses (PA), and the frequency of accesses. In this way, \nthe storage table of the wear-leveling can be eliminated. When the number of \nwrites to a specific physical address (PA) goes beyond a threshold, its content is \nswapped by the wear-leveling method [18, 103].\n  For example, In [104], the authors propose Fine-Grain Wear Leveling \n(FGWL), which shifts cache lines within a page to achieve uniform wear out of \nall lines in the page. Also, when a PCM page is read, it is realigned. The pages \nare written from the Write Queue to the PCM in a line-shifted format. For a \nsystem with 4 lines per page, for instance, the rotate amount is between 0 and 3 \nlines. The rotate value of 0 means the page is stored in a traditional manner. If \nit is 1, then the Line 0 of the address is being shifted one line and stored in Line \n1 of the physical PCM page, line 1 of the address in stored in line 2, line 2 in \n3, and finally, line 3 of address space is stored in Line 0. When a PCM page is \n\n174 Distributed and Parallel Databases (2023) 41:163–189\n1 3\nread, it is realigned. The pages are written from the Write Queue to the PCM in \na line-shifted format.\n  Self-adaptive wear-leveling (SAWL) algorithm [18] is another wear-leveling \nscheme that dynamically adjusts the wear-leveling granularity to accommodate \nmore useful addresses in the cache, thus improving cache hit rate. This method \ndistributes the writes across the cells of entire memory, thus achieving suitable \ntradeoff between the lifetime and cache hit rate.\n(2) Algebraic-based wear-leveling methods [101, 105, 106] are another group that \ntry to distribute the incoming writes to avoid concentrating writes on specific \nphysical locations and creating the hot areas. To this end, they usually replace \nthe address-mapping table in the table-based wear-leveling algorithms with \nhardware structure, which are more space efficient [101]. In this way, they can \nincrease the lifetime of NVMs orders of magnitude compared to the based line \nwhere there is no wear-leveling.\nStart-Gap [101] is one of the first methods that proposed a wear-leveling \nmethod based on the algebraic mapping between the logical and physical \naddresses. In this technique, there are two registers (Start and Gap) that do the \nwear-leveling. When a new write comes to the memory, Start-Gap moves one \nline from its location to a neighboring location. While the Gap register keeps \ntrack of the number of lines moved, Start register counts the number of times \nthat all the available lines have moved. Finally, the mapping between logical \nand physical address is done by a simple arithmetic operation of Gap and Start \nregisters, which eliminates the need for storing the address-mapping table in the \nmemory.\nIn [107], the authors propose a hardware-based wear-leveling scheme named \nSecurity Refresh, which performs dynamic randomization for placing PCM data. \nIn this method, an embedded controller inside each PCM is responsible for pre-\nventing adversaries from tampering the bus interface or aggregating meaningful \ninformation via side channels [107]. They also applied designed some attacks to \nanalyze the wear-out distribution using Security Refresh.\nAlthough wear-leveling strategies have been successful in preventing crea-\ntion of hot locations and extending the lifetime of NVMs, the controller cannot \nguarantee that some cells will not wear out much faster than the average. The \nreason is that distributing writes evenly across the memory space does not nec-\nessarily mean that the individual cells within the words also be flipped/written \nevenly. That is why, in some extreme cases, even with the protection of state-\nof-the-art wear-leveling schemes, wear-out attacks such as Remapping Timing \nAttack[108] and Row Buffer Hit [109] can wear out NVM as fast as 137 seconds \n[109]. Therefore, hardware techniques such as FNW [87], CDE [88], FPC [11], \nand Flip-Mirror-Rotate [90], which will be explained in the next section, have \nbeen proposed to focus on reducing the number of bit flips within a given word \ninstead of just distributing writes uniformly across the device.\n\n175\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \n3.2  Reducing write amplification\nMany data storage and indexing solutions target the reduction of write amplification \nto optimize the utilization of I/O bandwidth. This is done via various techniques, \nincluding delaying the consolidation of writes [40, 43], caching [92–94], and others \n[24]. With the introduction of NVM to the memory hierarchy, it turns out that reduc-\ning write amplification can have the positive side-effect of increasing NVM write \nendurance since less data is written. However, this is not an easy task to do due to \nthe fact that all the existing data structures and database systems have been designed \nfor DRAMs and HDDs, where the challenges of the lifespan of memory segments \nand the energy consumption of writes are not as significant in DRAM/HDD as they \nare in NVM. However, as discussed before, when it comes to NVMs, write opera-\ntion needs to be performed wisely. So, the proposed methods in this group reduce \nthe write amplification in an attempt to decrease the average number of updated \ncells and as a result increases the lifetime of NVMs.\nTo achieve this, many methods re-design existing data structures and database \nsystems to mitigate the write amplification issue caused by them instead of design-\ning and building new ones from scratch. The reason behind this is that existing data \nstructures and database systems have undergone decades of research that makes \nthem extremely efficient and makes building alternatives from scratch an arduous \ntask.\nLog-Structured Merge-tree (LSM-tree) is one of those data structures that has \nbeen widely adopted for use in the storage layer of modern NoSQL systems, and as a \nresult, has attracted a large body of research, from both the database community and \nthe storage systems community, that try to improve various aspects of LSM-trees \nby using NVMs [37, 38, 40]. NoveLSM [40] is one of these methods. This method \nis a persistent LSM-based key-value storage system designed to take advantage of \nhaving a NVM in its design. To tackle NVM’s limited write endurance, NoveLSM \ncomes up with a new design, where only the parts of the key/value store that do not \nneed to be changed frequently, such as immutable memtables, are handled by NVM. \nOn the other hand, other parts, such as mutable memtables, which need constant \nupdates and data movements, are placed on DRAM, which do not have any restric-\ntions on write operation.\nWiscKey [37] is another work, which proposes a persistent LSM-tree-based key-\nvalue store, which has been derived from the popular LSM-tree implementation, \nLevelDB. Although, like the other methods in this category, WiscKey focuses on \ndecreasing write amplification, it achieve this through a different and simple way, \nwhich is separating keys from values. This method observes that since the index-\ning is done by keys, and not values, they do not need to be bundled together when \nthey are stored in the LSM-tree. So, in this method, only keys are kept sorted in \nthe LSM-tree, while values are stored separately in a log. Through this insight, they \nhave reduced write amplification by avoiding the unnecessary movement of values \nwhile sorting. Although this technique is originally proposed for SSDs, it can be \ngeneralized to storage class memories, which suffer from the same limitation.\nAnother data structure that has been redesigned to utilize NVMs is B+-Trees, \nwhich is used widely in K/V data stores [47, 93]. Fingerprinting Persistent Tree \n\n176 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n(FPTree) [94] is a hybrid SCM-DRAM persistent and concurrent B+-Tree that is \ndesigned specifically for NVMs. This method aims to decrease write amplification \non NVMs. To do so, in this method, leaf nodes are persisted in SCM while inner \nnodes are placed in DRAM and rebuilt upon recovery.\nLB+-Tree [44] is another method that changes the structure of the conventional \ndata structures to take advantage of NVMs. In this work, to improve the insertion \nperformance of LB+-Tree, three techniques are proposed: (1) entry moving, which \ncreates empty slots in the first line of a leaf node to reduce the number of NVM line \nwrites, (2) logless node split, which targets the logging overhead, and (3) distributed \nheaders. LB+-Tree improves the performance of the insertion operation compared \nto the other methods.\nDPTree (Differential Persistent Tree) [110] batches multiple writes in DRAM \npersistently and later merge them into a PM component to decrease the persistence \noverhead, which is imposed to the system because of the persist primitive that the \nexisting PM index structures use to guarantee consistency in case of failure.\nIn [111], the authors target the tail latency of tree-based index structures, which \nthe result of the internal structural refinement operations (SROs) and the inter-thread \ninterferences. To reach to this aim, uTree introduces a shadow linked-list layer to the \nleaf nodes of a B+-tree to minimize the SRO overhead. This method has succeeded \nin improving throughput and latency.\nHash-based indexing structures have also been good candidates to utilize NVMs \ndue to their nature of typically causing high write amplification and that they are \nvastly used in various applications and systems [24, 27, 112, 113]. A lot of effort has \nbeen made to improve hash-based indexing structures for byte-addressable persistent \nmemory, and almost all of them focus on decreasing the write amplification to reach \ntheir goal. Path hashing [24] is an example of these hash-based indexes, which is \ndesigned specifically for NVMs. The basic idea of path hashing is to leverage a posi-\ntion sharing method to resolve the hash-collision problem, which usually results in a \nhigh number of extra writes or write amplifications.\nDash [114] proposes a persistent hashing scheme that aims to solve the perfor -\nmance (scalability) and functionality challenges that persistent hash tables face by \nreducing both unnecessary reads and writes. To achieve this, Dash takes advantage \nof some previous techniques, such as fingerprinting, optimistic locking, and com-\nbine them with some novel methods such as bucket load balancing technique. They \nhave tested their method on real Optane DCPMM and the results show that Dash can \nimprove throughput significantly. It is worth noting that the methods that the meth-\nods that we mentioned in this section are just some examples of the whole group of \nmethods (Table 2) that utilize NVMs in their work in different ways.\nAll these methods offer different advantages and disadvantages. These methods \ninvite exploring how they can be integrated with existing data management sys-\ntems to enable them to improve the lifetime of NVMs. Some of these methods are \nindependent from the application (and often implemented as a hardware method) \nwhich means that augmenting them within existing data management systems is \na straight-forward task. Other approaches—especially ones based on masking—\nrequire domain knowledge on the application using them. There is an opportunity \nfor data management researchers to find ways to adapt these methods to work with \n\n177\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \nexisting data management systems. This would entail learning the write patterns of \ndata management systems and translating this knowledge into appropriate masking \ntechniques that are based on the methods presented above.\n4  Bit flip reduction\nAlthough reducing write amplification is a promising way to extend the PCMs’ lifes-\npan, it does not necessarily lead to the best opportunities to reduce bit flipping and \nincreasing write endurance [23, 25]. This is because—unlike flash—PCM cells are \nwritten individually, which means that the number of flipped bits is more important \nto optimize than the number of written words [23]. Therefore, focusing on reducing \nbit flips is a viable solution that can both save energy and extend the life of PCMs.\nTo see how this difference affects NVM’s performance in terms of lifetime, \nenergy consumption, and latency, we have conducted some experiments on a PCM \ndevice and a real Optane memory. Figure  5 shows the lifetime of a PCM device is \nFig. 5  The impact of capacity and swapping period on PCM’s lifetime when the percentage of hamming \ndistance between the write data and the overwritten content changes\n\n178 Distributed and Parallel Databases (2023) 41:163–189\n1 3\naffected by the number of bit flips that occur during write operations. As we can see \nin this figure, when the average percentage of the hamming distance between the \nold value of the cell and the value that is going to be written increases, the lifetime \nof the device decreases. This figure also shows swapping period plays an impor -\ntant role in the lifetime of the device. Based on the results, for a certain hamming \ndistance, when the swapping period is high, the device lasts longer because having \nlower swapping period means more write amplification, which increases the overall \nflipping bits. However, setting lower swapping period increases the risk of certain \ncells being worn out sooner than others, especially when there is a malicious attack. \nFigure  5 also shows that when the capacity of the device is low, e.g., in mobile and \nembedded systems, memory cells can wear out faster.\nTo see how bit flip reduction affects the latency and energy consumption of a \nNVM device, we have conducted a simple experiment on a real Optane memory \ndevice (Sect.  4) using the Persistent Memory Development Kit (PMDK) [85], for -\nmerly known as NVML. In this test, first, we allocate a contiguous region of N \nOptane blocks of 256B. During each “round” of the experiment, we first initialize all \nthe blocks with random data, and then update the blocks with new data with content \nthat is x% different than the data that is already in the block (hamming distance). \nWe use PMDK’s transactions to persist writes. We measure the latency and energy \nconsumption of the socket for each round. Figure  6 shows that by overwriting simi-\nlar content, which needs less bit flipping, we can save a huge amount of energy and \nimprove latency.\nGenerally, the existing bit flipping reduction methods can be divided into two \nmain categories: RBW-based techniques and Memory-awareness.\n4.1  RBW‑based techniques\nOne of the most important characteristics of Read Before Write (RBW) technique \nand its variants is their simplicity and efficiency in dealing with the lifetime issue \nof NVM. So, there has been a large body of research that uses various types of this \nmethod in their works. In this category, there are various techniques, such as caching \n[92–94] and the RBW technique [86], to decrease the number of bit flips.\nRBW is one of the most popular techniques, which has been widely utilized by \nvarious approaches [87–91], to reduce the number of bit flips is the RBW technique \n[86], in which the content of an old memory block is read before it is overwritten \nwith the new data (Fig.  7). This technique replaces each PCM write operation with a \nmore efficient read-modify-write operation. Reading before writing allows compar -\ning the bits of the old and new data, updating only the bits that differ.\nFlip-n-Write (FNW) [87] is one of the most popular methods and became the \nbuilding block of many other techniques in this area. This method compares the cur -\nrent content of the memory location (the old data) with the content to-be-written \n(the new data). This enables FNW to decide whether to write the new data in its \noriginal format or to flip it before writing it if that leads to reducing the number of \nbit flips. (A flag is used so that future operations know whether to flip the content \n\n179\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \nFig. 6  The latency and memory energy consumption on a real Intel Optane memory device for read and \nwrite operations with different percentages of hamming distance\nFig. 7  Read Before Write \n(RBW) technique\n\n\n180 Distributed and Parallel Databases (2023) 41:163–189\n1 3\nbefore reading.) This method guarantees that the number of bit flips in PCM is \nalways less than half the total number of written bits (excluding the flag bit).\nDCW [88] finds common patterns and then compresses data to reduce the num-\nber of bit flips in PCM. Like Flip-N-Write, DCW replaces a write operation with a \nread-modify-write process. It starts comparing the new data and the old data from \nthe first bit to the last one. The most significant difference between DCW and Frip-\nN-Write is that in DCW, the maximum number of bit flips is still N (the word width).\nCaptopril [89] is another recent proposal for reducing bit flips in PCMs. This \nmethod masks some “hot locations”, where bits are flipped more, to reduce the num-\nber of bit flips. In this method, the authors compare every write with 4 predefined \nsequences of bits to decide which bits need to be flipped and which ones need to be \nwritten in their original form. This method suffers from relatively high overhead. \nMore importantly, it is rigid and would only work on predefined applications.\nFlip-Mirror-Rotate [90] is another method that is built upon Flip-N-Write [87] \nand FPC [91] to reduce the number of flipped bits. Like Captopril, this method uses \nonly predefined patterns to mask some bits, which means it would only work on pre-\ndefined applications.\nMinShift [115] proposes reduces the total number of update bits to SCMs. The \nmain idea of this method is that if the hamming distance falls between two spe-\ncific bounds, the new data is rotated to change the hamming distance. Although this \nmethod is simple, it suffers from high overhead.\nIn [116], the authors use a combination of MinShift and Flip-N-Write to decrease \nthe number of written bits. They compute the minimum amount of some possible \nstates to choose a pattern to encode the data. This method has advantages and disad-\nvantages of both methods.\n4.2  Memory‑awareness\nAs we discussed earlier, the writing operations in PCM takes much more energy \nthan reading operation. To save energy, the PCM controller can avoid writing to a \ncell whose content is the desired value. It means that the lifetime of the cell and \nthe consumed energy in the write operation depends on the number of bits that are \nactually being flipped by the write rather than the number of words or bits that are \nwritten.\nAlthough focusing on bit flipping reduction technique seems a reasonable choice, \nthe methods in this category fail to achieve its full potential because the existing \nmethods miss a crucial opportunity. Prior methods pick the memory location for a \nwrite operation arbitrarily (new data items select an arbitrary location in memory, \nand updates to data items overwrite the previously-chosen location.) This misses the \nopportunity to judiciously pick a memory location that is similar to the value to be \nwritten. When the new value and the value to be overwritten are similar, this means \nthat the number of bit flips is going to be lower. Reducing the number of bit flips \nincreases write endurance and reduces power consumption. This approach is called \nmemory awareness.\n\n181\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \n4.2.1  Content‑aware methods\nThe methods in this group, by being aware of the memory content, try to redirect \nwrite requests to overwrite specific memory locations based on their content-aware \nreplacement policies to decrease the energy consumption of the system and extend \nthe lifetime of the device. For example, the authors in [102] proposes an encoded \ncontent-aware cache replacement policy to reduce the total switched bits in spin-\ntorque magnetic random-access memory (STT-MRAM) caches. To do this, instead \nof replacing the LRU block, the victim block is chosen among the blocks whose \ncontents are most similar to the missed one. To avoid the comparison of the entire \n512 bits of the blocks, each block is encoded using 8 bits, which incur low space \noverhead. The reason behind this encoding is that when the contents of two blocks \nare dominated by certain bit value, there is a good chance that the content similarity \nof the two blocks is high, hence may lower the switch bits when one double word \nreplaces the other [102].\nData Content-aware (DATACON) [66] is a recent mechanism that reduces the \nlatency and energy of PCM writes by redirecting the write requests to a new physi-\ncal address within memory to overwrite memory locations containing all-zeros or \nall-ones depending on the content of the incoming writes. DATACON is imple-\nmented inside the memory controller. To keep track of the all-zeros and all-ones \nmemory locations and their address translations, the memory controller needs to \nmaintain a table. Although this method takes advantage of being content aware, it \nneeds to be implemented inside the existing memory controller, which is non-trivial \ntask. Moreover, the average number of bit flips it can save is highly dependent on the \nworkload since it uses two fixed patterns to save bit flips.\nIn [23], the authors modifies the common data structures based on the idea of \npointer distance to minimize the number of bit flips on PCMs. In this method, \ninstead of building a doubly-linked list, for instance, XOR linked lists are used, \nwhich allows each node to store only the XOR between the previous and next node \ninstead of storing the previous and next nodes. The results show that storing the \nXOR of two pointers, which are likely to contain similar higher-order bits, reduces \nthe number of bit flips, which can lead to reducing power consumption.\nAnother method that leverages memory awareness in its structure is called Ham-\nming-Tree [26], which is an auxiliary data structure that can be augmented with \nexisting indexes. Hamming-Tree is a data structure that organizes free memory loca-\ntions based on their hamming distance. It can be built upon any existing tree-based \ndata structure—whether they are designed for PCM or not—to improve their perfor -\nmance in terms of PCM write endurance. One of the unique qualities of this method, \nwhich makes it highly adoptable by any existing key/value stores, is its ability to \nbe augmented with a data indexing structure from B+-tree to LSM-based persistent \nK/V stores to cache optimized PCM index, and write-friendly hashing schemes. In \nthis method, the data indexing structure handles the regular indexing of keys and \nvalues, and Hamming-Tree handles the mapping of free memory locations for future \nwrites and updates. This method also reduces bit flipping considerably.\n\n182 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n4.2.2  AI‑based methods\nMachine learning and deep learning are changing the world by transforming all \nsegments from power systems to transport to storage systems and database sys-\ntems [117– 119]. Using machine learning in the field of PCMs is not new, but \nutilizing a machine learning-based method to extend the lifetime of PCMs was \nintroduced in [25].\nPredict and Write (PNW) [25] is a memory-aware mechanism that uses \nmachine learning to extend the lifetime of PCMs. PNW is a K/V store that is \ndesigned specifically for PCMs. This method uses a clustering-based approach \nto extend the lifetime of PCMs using machine learning. Writes are directed to \nclusters with similar content to reduce the number of bit flips. Like the previous \nmethods in Sect.  4.1, PNW also targets bit flip reduction but through software \ntechniques. PNW decreases the number of bit flips for PUT/UPDATE operations \nby determining the best memory location an updated value should be written to. \nThis method leverages the indirection level of K/V-stores to freely choose the tar -\nget memory location for any given write based on its value. In this method, PCM \naddresses are organized in a dynamic address pool clustered by the similarity of \nthe data values they refer to.\nThis recent AI-based direction has a high potential to improve the performance \nof the existing wear-leveling methods that use conventional techniques such as fixed \npatterns. Also, this new direction is in its infancy and can be improved in many \nways, such as using efficient autonomous clustering methods [117, 120] or utilize \nadvanced deep learning methods that are capable of learning the existing patterns \namong the existing data dynamically [121].\n5  Conclusion and future work\nNVMs promise to be an indispensable part of future memory systems due to their \nunique characteristics such as non volatility, byte addressability, high density, high \nscalability, and requiring near-zero standby power. They can revolutionize the per -\nformance, energy efficiency, and processing footprint of existing systems from stor -\nage systems to edge and cloud environments to distributed database systems and \nblockchain decentralized applications [5, 122–127]. However, their main limita-\ntions, especially limited write endurance and high write energy consumption, pose \nserious challenges for their full adoption, which needs to be taken into consideration \nto leverage their full potential.\nThere is an opportunity now for researchers in data management systems to adopt \nsolutions to overcome these limitations of NVMs that would be essential for their \nadoption and success. Specifically, in this paper, we present the low-hanging fruits \nand approaches of augmenting existing techniques from the NVM storage commu-\nnity to be adopted in data management systems. Also, we outline future opportuni-\nties in the area of memory-awareness that promises to increase the efficacy of exist-\ning techniques to improve the lifetime and energy efficiency of PCM devices.\n\n183\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \nOpen Access This article is licensed under a Creative Commons Attribution 4.0 International License, \nwhich permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, provide a link to the Creative \nCommons licence, and indicate if changes were made. The images or other third party material in this \narticle are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line \nto the material. If material is not included in the article’s Creative Commons licence and your intended \nuse is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permis-\nsion directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/\nlicenses/by/4.0/.\nReferences\n 1. Hameed, F.: Efficient stt-ram last-level-cache architecture to replace dram cache. In: MEMSYS \n2017, pp. 141–151 (2017)\n 2. Caulfield, A.M., De, A., Coburn, J., Mollow, T.I., Gupta, R.K., Swanson, S.: Moneta: A high-\nperformance storage array architecture for next-generation, non-volatile memories. In: 2010 \n43rd Annual IEEE/ACM International Symposium on Microarchitecture, pp. 385–395. IEEE \nComputer Society, Washington DC (2010)\n 3. Dulloor, S.R., Kumar, S., Keshavamurthy, A., Lantz, P., Reddy, D., Sankaran, R., Jackson, J.: \nSystem software for persistent memory. In: Proceedings of the Ninth European Conference on \nComputer Systems, pp. 1–15 (2014)\n 4. Kargar, S., Nawab, F.: Extending the lifetime of nvm: challenges and opportunities. Proc. \nVLDB Endowment 14(12), 3194–3197 (2021)\n 5. Mittal, S., Vetter, J.S.: (2015): A survey of software techniques for using non-volatile memories \nfor storage and main memory systems. TPDS 27(5), 1537–1550 (2015)\n 6. Xia, F.: A survey of phase change memory systems. J. Comput. Sci. Technol. 30(1), 121–144 \n(2015)\n 7. Boukhobza, J., Rubini, S., Chen, R., Shao, Z.: Emerging NVM: a survey on architectural inte-\ngration and research challenges. ACM Trans. Des. Autom. Electron. Syst. (TODAES) 23(2), \n1–32 (2017)\n 8. Agarwal, S., Kapoor, H.K.: Improving the lifetime of non-volatile cache by write restriction. \nIEEE Trans. Comput. 68(9), 1297–1312 (2019)\n 9. Palangappa, P.M., Mohanram, K.: Compex++ compression-expansion coding for energy, \nlatency, and lifetime improvements in mlc/tlc nvms. ACM Trans. Architect. Code Optim. \n(TACO) 14(1), 1–30 (2017)\n 10. García, A.A., de Jong, R., Wang, W., Diestelhorst, S.: Composing lifetime enhancing techniques \nfor non-volatile main memories. In: Proceedings of the International Symposium on Memory \nSystems, pp. 363–373 (2017)\n 11. Guo, Y., Hua, Y., Zuo, P.: Dfpc: A dynamic frequent pattern compression scheme in nvm-\nbased main memory. In: 2018 Design, Automation & Test in Europe Conference & Exhibition \n(DATE), pp. 1622–1627. IEEE Computer Society, Washington DC (2018)\n 12. Agarwal, S., Kapoor, H.K.: Targeting inter set write variation to improve the lifetime of non-\nvolatile cache using fellow sets. In: 2017 IFIP/IEEE International Conference on Very Large \nScale Integration (VLSI-SoC), pp. 1–6. IEEE Computer Society, Washington DC (2017)\n 13. Safayenikoo, P., Asad, A., Fathy, M., Mohammadi, F.: Exploiting non-uniformity of write \naccesses for designing a high-endurance hybrid last level cache in 3d cmps. In: 2017 IEEE 30th \nCanadian Conference on Electrical and Computer Engineering (CCECE), pp. 1–5. IEEE Com-\nputer Society, Washington DC (2017)\n 14. Safayenikoo, P., Asad, A., Fathy, M., Mohammadi, F.: A new traffic compression method for \nend-to-end memory accesses in 3D chip-multiprocessors. In: 2017 IEEE 30th Canadian Con-\nference on Electrical and Computer Engineering (CCECE), pp. 1–4. IEEE Computer Society, \nWashington DC (2017)\n 15. Deguchi, Y., Takeuchi, K.: 3d-nand flash solid-state drive (SSD) for deep neural network weight \nstorage of iot edge devices with 700x data-retention lifetime extention. In: 2018 IEEE Interna-\ntional Memory Workshop (IMW), pp. 1–4. IEEE Computer Society, Washington DC (2018)\n\n184 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n 16. Shi, J., Zhang, H., Bai, Y., Han, G., Jia, G.: A novel data aggregation preprocessing algorithm \nin flash memory for IoT based power grid storage system. IEEE Access 6 , 57279–57290 (2018)\n 17. Yang, J., Lin, Y., Fu, Y., Xue, X., Chen, B.: A small area and low power true random number \ngenerator using write speed variation of oxidebased rram for iot security application. In: 2017 \nIEEE International Symposium on Circuits and Systems (ISCAS), pp. 1–4. IEEE Computer \nSociety, Washington DC (2017)\n 18. Huang, J., Hua, Y., Zuo, P., Zhou, W., Huang, F.: An efficient wear-level architecture using self-\nadaptive wear leveling. In: 49th International Conference on Parallel Processing-ICPP, pp. 1–11 \n(2020)\n 19. Pourshirazi, B., Beigi, M.V., Zhu, Z., Memik, G.: Writeback-aware llc management for pcm-\nbased main memory systems. ACM Trans. Des. Autom. Electron. Syst. (TODAES) 24(2), 1–19 \n(2019)\n 20. Akram, S., Sartor, J.B., McKinley, K.S., Eeckhout, L.: Write-rationing garbage collection for \nhybrid memories. ACM SIGPLAN Not. 53(4), 62–77 (2018)\n 21. Wu, J., Dong, J., Fang, R., Zhang, W., Wang, W., Zuo, D.: Wdbt: Non-volatile memory wear char -\nacterization and mitigation for DBT systems. J. Syst. Softw. 187, 111247 (2022)\n 22. Song, S., Das, A., Kandasamy, N.: Exploiting inter-and intra-memory asymmetries for data map-\nping in hybrid tiered-memories. In: Proceedings of the 2020 ACM SIGPLAN International Sym-\nposium on Memory Management, pp. 100–114 (2020)\n 23. Bittman, D.: Optimizing systems for byte-addressable {NVM} by reducing bit flipping. In: 17th \n{USENIX} Conference on File and Storage Technologies ({FAST} 19), pp. 17–30 (2019)\n 24. Zuo, P., Hua, Y.: A write-friendly hashing scheme for non-volatile memory systems. In: Proceed-\nings of MSST (2017)\n 25. Kargar, S., Litz, H., Nawab, F.: Predict and write: Using k-means clustering to extend the lifetime \nof nvm storage. In: 2021 IEEE 37th International Conference on Data Engineering (ICDE), pp. \n768–779. IEEE Computer Society, Washington DC (2021)\n 26. Kargar, S., Nawab, F.: Hamming tree: The case for memory-aware bit flipping reduction for nvm \nindexing. In: CIDR (2021)\n 27. Huang, K., Yan, Y., Huang, L.: Revisiting persistent hash table design for commercial non-volatile \nmemory. In: 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE), pp. \n708–713. IEEE Computer Society, Washington DC (2020)\n 28. Liu, C.-Y., Lee, Y., Jung, M., Kandemir, M.T., Choi, W.: Prolonging 3D NAND SSD lifetime via \nread latency relaxation. In: Proceedings of the 26th ACM International Conference on Architec-\ntural Support for Programming Languages and Operating Systems, pp. 730–742 (2021)\n 29. Cai, Y., Lin, Y., Xia, L., Chen, X., Han, S., Wang, Y., Yang, H.: Long live time: improving life-\ntime and security for NVM-based training-in-memory systems. IEEE Trans. Comput. Aided Des. \nIntegr. Circuits Syst. 39(12), 4707–4720 (2020)\n 30. Zhou, F., Wu, S., Jia, Y., Gao, X., Jin, H., Liao, X., Yuan, P.: Vail: A victim-aware cache policy to \nimprove nvm lifetime for hybrid memory system. Parallel Comput. 87, 70–76 (2019)\n 31. Carlos, E., Pablo, I., Teresa, M., Llaberia, J.M., Viñals, V.: L2C2: Last-level compressed-cache \nNVM and a procedure to forecast performance and lifetime. arXiv preprint (2022). arXiv: 2204. \n09504\n 32. Rani, K., Kapoor, H.K.: Write variation aware buffer assignment for improved lifetime of non-\nvolatile buffers in on-chip interconnects. IEEE Trans. Very Large Scale Integration (VLSI) Syst. \n27(9), 2191–2204 (2019)\n 33. Agarwal, S., Kapoor, H.K.: Improving the performance of hybrid caches using partitioned victim \ncaching. ACM Trans. Embed. Comput. Syst. (TECS) 20(1), 1–27 (2020)\n 34. Hakert, C., Kühn, R., Chen, K.-H., Chen, J.-J., Teubner, J.: Octo+: Optimized checkpointing of b+ \ntrees for non-volatile main memory wear-leveling. In: 2021 IEEE 10th Non-Volatile Memory Sys-\ntems and Applications Symposium (NVMSA), pp. 1–6. IEEE Computer Society, Washington DC \n(2021)\n 35. Guo, Y., Hua, Y., Zuo, P.: A latency-optimized and energy-efficient write scheme in nvm-based \nmain memory. IEEE Trans. Comput. Aided Des. Integr. Circuits Syst. 39(1), 62–74 (2018)\n 36. Chu, Z., Luo, Y., Jin, P.: An efficient sorting algorithm for non-volatile memory. Int. J. Softw. Eng. \nKnowl. Eng. 31(11–12), 1603–1621 (2021)\n 37. Lu, L., Pillai, T.S., Gopalakrishnan, H., Arpaci-Dusseau, A.C., Arpaci-Dusseau, R.H.: Wisckey: \nSeparating keys from values in SSD-conscious storage. ACM Trans. Storage (TOS) 13(1), 1–28 \n(2017)\n\n185\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \n 38. Dai, Y., Xu, Y., Ganesan, A., Alagappan, R., Kroth, B., Arpaci-Dusseau, A., Arpaci-Dusseau, R.: \nFrom WiscKey to Bourbon: a learned index for log-structured merge trees. In: 14th {USENIX} \nSymposium on Operating Systems Design and Implementation ({OSDI} 20), pp. 155–171 (2020)\n 39. Li, J., Pavlo, A., Dong, S.: NVMRocks: RocksDB on non-volatile memory systems (2017)\n 40. Kannan, S.: Redesigning lsms for nonvolatile memory with novelsm. In: 2018 {USENIX} Annual \nTechnical Conference ({USENIX} {ATC} 18), pp. 993–1005 (2018)\n 41. Cai, H., Wang, Y., de Barros Naviner, L.A., Yang, J., Zhao, W.: Exploring hybrid stt-mtj/cmos \nenergy solution in near-/sub-threshold regime for IoT applications. IEEE Trans. Magn. 54(2), 1–9 \n(2017)\n 42. Prasad, R.S., Chaturvedi, N., Gurunarayanan, S.: A low power high speed MTJ based non-volatile \nsram cell for energy harvesting based IoT applications. Integration 65, 43–50 (2019)\n 43. Li, W.: Hilsm: an lsm-based key-value store for hybrid nvm-ssd storage systems. In: Proceedings of \nthe 17th ACM International Conference on Computing Frontiers, pp. 208–216 (2020)\n 44. Liu, J.: Lb+ trees: optimizing persistent index performance on 3dxpoint memory. Proc. VLDB \nEndowment 13(7), 1078–1090 (2020)\n 45. Balmau, O., Didona, D., Guerraoui, R., Zwaenepoel, W., Yuan, H., Arora, A., Gupta, K., Konka, \nP.: {TRIAD}: Creating synergies between memory, disk and log in log structured {Key-Value} \nstores. In: 2017 USENIX Annual Technical Conference (USENIX ATC 17), pp. 363–375 (2017)\n 46. Eisenman, A., Cidon, A., Pergament, E., Haimovich, O., Stutsman, R., Alizadeh, M., Katti, S.: \nFlashield: a hybrid key-value cache that controls flash write amplification. In: 16th USENIX Sym-\nposium on Networked Systems Design and Implementation (NSDI 19), pp. 65–78 (2019)\n 47. Hu, J., et al.: Understanding and analysis of b+ trees on nvm towards consistency and efficiency. \nCCF Trans. High Perform. Comput. (2020). https:// doi. org/ 10. 1007/ s42514- 020- 00022-z\n 48. Wang, Q., Li, J., Lee, P.P., Ouyang, T., Shi, C., Huang, L.: Separating data via block invalidation \ntime inference for write amplification reduction in logstructured storage. In: Proceedings of USE-\nNIX FAST (2022)\n 49. Chakraborttii, C., Litz, H.: Reducing write amplification in flash by death-time prediction of logi-\ncal block addresses. In: Proceedings of the 14th ACM International Conference on Systems and \nStorage, pp. 1–12 (2021)\n 50. Zhang, W., Zhao, X., Jiang, S., Jiang, H.: Chameleondb: a key-value store for optane persistent \nmemory. In: Proceedings of the Sixteenth European Conference on Computer Systems, pp. 194–\n209 (2021)\n 51. Chen, H., Ruan, C., Li, C., Ma, X., Xu, Y.: {SpanDB}: A fast, {Cost-Effective}{LSM-tree} based \n{KV} store on hybrid storage. In: 19th USENIX Conference on File and Storage Technologies \n(FAST 21), pp. 17–32 (2021)\n 52. Xanthakis, G., Saloustros, G., Batsaras, N., Papagiannis, A., Bilas, A.: Parallax: hybrid key-value \nplacement in LSM-based key-value stores. In: Proceedings of the ACM Symposium on Cloud \nComputing, pp. 305–318 (2021)\n 53. Zhang, B., Du, D.H.: NVLSM: a persistent memory key-value store using log-structured merge \ntree with accumulative compaction. ACM Trans. Storage (TOS) 17(3), 1–26 (2021)\n 54. Kim, S., Son, Y.: Optimizing key-value stores for flash-based SSDS via key reshaping. IEEE \nAccess 9, 115135–115144 (2021)\n 55. Li, C., Chen, H., Ruan, C., Ma, X., Xu, Y.: Leveraging nvme ssds for building a fast, cost-effective, \nLSM-tree-based KV store. ACM Trans. Storage (TOS) 17(4), 1–29 (2021)\n 56. Doekemeijer, K., Trivedi, A.: Key-value stores on flash storage devices: a survey. arXiv preprint \n(2022). arXiv: 2205. 07975\n 57. Conway, A., Gupta, A., Chidambaram, V., Farach-Colton, M., Spillane, R., Tai, A., Johnson, R.: \n{SplinterDB}: closing the bandwidth gap for {NVMe}{Key-Value} stores. In: 2020 USENIX \nAnnual Technical Conference (USENIX ATC 20), pp. 49–63 (2020)\n 58. Cui, L., He, K., Li, Y., Li, P., Zhang, J., Wang, G., Liu, X.-G.: Swapkv: a hotness aware in-memory \nkey-value store for hybrid memory systems. IEEE Trans. Knowl. Data Eng. (2021)***\n 59. Sun, P., Xue, D., You, L., Yan, Y., Huang, L.: Hyperkv: a high performance concurrent key-value \nstore for persistent memory. In: 2021 IEEE Intl Conf on Parallel & Distributed Processing with \nApplications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social \nComputing & Networking (ISPA/BDCloud/SocialCom/SustainCom), pp. 125–134. IEEE Com-\nputer Society, Washington DC (2021)\n\n186 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n 60. Krishnan, R.M., Kim, W.-H., Fu, X., Monga, S.K., Lee, H.W., Jang, M., Mathew, A., Min, C.: \n{TIPS}: Making volatile index structures persistent with {DRAM-NVMM} tiering. In: 2021 USE-\nNIX Annual Technical Conference (USENIX ATC 21), pp. 773–787 (2021)\n 61. Lee, H., Lee, M., Eom, Y.I.: Partial tiering: A hybrid merge policy for log structured key-value \nstores. In: 2021 IEEE International Conference on Big Data and Smart Computing (BigComp), pp. \n20–23. IEEE Computer Society, Washington DC (2021)\n 62. Friedman, M., Petrank, E., Ramalhete, P.: Mirror: making lock-free data structures persistent. In: \nProceedings of the 42nd ACM SIGPLAN International Conference on Programming Language \nDesign and Implementation, pp. 1218–1232 (2021)\n 63. Shi, Y., Oh, S., Huang, Z., Lu, X., Kang, S.H., Kuzum, D.: Performance prospects of deeply scaled \nspin-transfer torque magnetic random-access memory for in-memory computing. IEEE Electron \nDevice Lett. 41(7), 1126–1129 (2020)\n 64. Balmau, O., Guerraoui, R., Trigonakis, V., Zablotchi, I.: Flodb: Unlocking memory in persistent \nkey-value stores. In: Proceedings of the Twelfth European Conference on Computer Systems, pp. \n80–94 (2017)\n 65. Safayenikoo, P., Asad, A., Fathy, M., Mohammadi, F.: An energy efficient non-uniform last level \ncache architecture in 3d chip-multiprocessors. In: 2017 18th International Symposium on Quality \nElectronic Design (ISQED), pp. 373–378. IEEE Computer Society, Washington DC (2017)\n 66. Song, S., Das, A., Mutlu, O., Kandasamy, N.: Improving phase change memory performance with \ndata content aware access. In: Proceedings of the 2020 ACM SIGPLAN International Symposium \non Memory Management, pp. 30–47 (2020)\n 67. Song, S., Das, A., Mutlu, O., Kandasamy, N.: Aging-aware request scheduling for non-volatile \nmain memory. In: Proceedings of the 26th Asia and South Pacific Design Automation Conference, \npp. 657–664 (2021)\n 68. Kamath, A.K., et al.: Storage class memory: principles, problems, and possibilities. arXiv preprint \n(2019). arXiv: 1909. 12221\n 69. Chen, L., Zhao, J., Wang, C., Cao, T., Zigman, J., Volos, H., Mutlu, O., Lv, F., Feng, X., Xu, G.H., \net al.: Unified holistic memory management supporting multiple big data processing frameworks \nover hybrid memories. ACM Trans. Comput. Syst. (TOCS) 39(1–4), 1–38 (2022)\n 70. Lai, J., Cai, J., Chu, J.: A congestion-aware hybrid SRAM and STT-RAM buffer design for net-\nwork-on-chip router. IEICE Electron. Express  (2022). https:// doi. org/ 10. 1587/ elex. 19. 20220 078\n 71. Liu, L., Yang, S., Peng, L., Li, X.: Hierarchical hybrid memory management in OS for tiered mem-\nory systems. IEEE Trans. Parallel .Distrib. Syst. 30(10), 2223–2236 (2019)\n 72. Huang, T., Dai, G., Wang, Y., Yang, H.: Hyve: Hybrid vertex-edge memory hierarchy for energy-\nefficient graph processing. In: 2018 Design, Automation & Test in Europe Conference & Exhibi-\ntion (DATE), pp. 973–978. IEEE Computer Society, Washington DC (2018)\n 73. Zhao, H., Zhao, J.: Leveraging mlc stt-ram for energy-efficient cnn training. In: Proceedings of the \nInternational Symposium on Memory Systems, pp. 279–290 (2018)\n 74. Sun, B., Liu, D., Yu, L., Li, J., Liu, H., Zhang, W., Torng, T.: Mram co-designed processing-in-\nmemory cnn accelerator for mobile and iot applications. arXiv preprint (2018). arXiv: 1811. 12179\n 75. Song, S., Balaji, A., Das, A., Kandasamy, N.: Design-technology co-optimization for NVM-based \nneuromorphic processing elements. ACM Trans. Embedded Comput. Syst. (TECS) (2022). https:// \ndoi. org/ 10. 1145/ 35240 68\n 76. Kosta, A., Soufleri, E., Chakraborty, I., Agrawal, A., Ankit, A., Roy, K.: Hyperx: A hybrid rram-\nsram partitioned system for error recovery in memristive xbars. In: 2022 Design, Automation & \nTest in Europe Conference & Exhibition (DATE), pp. 88–91. IEEE Computer Society, Washington \nDC (2022)\n 77. Shin, D., Jang, H., Oh, K., Lee, J.W.: An energy-efficient dram cache architecture for mobile plat-\nforms with pcm-based main memory. ACM Trans. Embed. Comput. Syst. (TECS) 21(1), 1–22 \n(2022)\n 78. Ho, C.-C., Wang, W.-C., Hsu, T.-H., Jiang, Z.-D., Li, Y.-C.: Approximate programming design for \nenhancing energy, endurance and performance of neural network training on nvm-based systems. \nIn: 2021 IEEE 10th Non-Volatile Memory Systems and Applications Symposium (NVMSA), pp. \n1–6. IEEE Computer Society, Washington DC (2021)\n 79. Kang, W., Zhang, L., Zhao, W., Klein, J.-O., Zhang, Y., Ravelosona, D., Chappert, C.: Yield and \nreliability improvement techniques for emerging nonvolatile STT-MRAM. IEEE J. Emerg. Sel. \nTop. Circuits Syst. 5(1), 28–39 (2014)\n\n187\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \n 80. Reed, E., Alameldeen, A.R., Naeimi, H., Stolt, P.: Probabilistic replacement strategies for improv -\ning the lifetimes of NVM-based caches. In: Proceedings of the International Symposium on Mem-\nory Systems, pp. 166–176 (2017)\n 81. Puglia, G.O.: Non-volatile memory file systems: a survey. IEEE Access 7, 25836–25871 (2019)\n 82. Zahoor, F., Azni Zulkifli, T.Z., Khanday, F.A.: Resistive random access memory (RRAM): an \noverview of materials, switching mechanism, performance, multilevel cell (MLC) storage, mod-\neling, and applications. Nanoscale Res. Lett. 15(1), 1–26 (2020)\n 83. Akram, S.: Performance evaluation of intel optane memory for managed workloads. ACM Trans. \nArchitect. Code Optim. (TACO) 18(3), 1–26 (2021)\n 84. Alsalibi, A.I., Shambour, M.K.Y., Abu-Hashem, M.A., Shehab, M., Shambour, Q., Muqat, R.: \nNonvolatile memory-based Internet of Things: a survey. In: Artificial Intelligence-based Internet of \nThings Systems, pp. 285–304. Springer, Cham (2022)\n 85. https:// pmem. io. Accessed Feb 2022\n 86. Yang, B.-D.: A low power phase-change random access memory using a data-comparison write \nscheme. In: ISCAS 2007, pp. 3014–3017. IEEE Computer Society, Washington DC (2007)\n 87. Cho, S., Lee, H.: Flip-n-write: A simple deterministic technique to improve pram write perfor -\nmance, energy and endurance. In: MICRO 2009, pp. 347–357 (2009)\n 88. Dgien, D.B.: Compression architecture for bit-write reduction in non-volatile memory technolo-\ngies. In: NANOARCH 2014, pp. 51–56. IEEE Computer Society, Washington DC (2014)\n 89. Jalili, M., Sarbazi-Azad, H.: Captopril: Reducing the pressure of bit flips on hot locations in non-\nvolatile main memories. In: DATE 2016, pp. 1116–1119. IEEE Computer Society, Washington DC \n(2016)\n 90. Palangappa, P.M., Mohanram, K.: Flip-mirror-rotate: an architecture for bit-write reduction and \nwear leveling in non-volatile memories. In: GLSVLSI 2015, pp. 221–224 (2015)\n 91. Alameldeen, A., Wood, D.: Frequent pattern compression: a significance-based compression \nscheme for L2 caches. Technical report, University of Wisconsin-Madison Department of Com-\nputer Sciences (2004)\n 92. Arulraj, J.: Let’s talk about storage and recovery methods for non-volatile memory database sys-\ntems. In: Proceedings of the 2015 ACM SIGMOD International Conference on Management of \nData, pp. 707–722 (2015)\n 93. Chen, S., Jin, Q.: Persistent b+-trees in non-volatile main memory. Proc. VLDB Endowment 8(7), \n786–797 (2015)\n 94. Oukid, I.: Fptree: A hybrid scm-dram persistent and concurrent b-tree for storage class memory. In: \nProceedings of the 2016 International Conference on Management of Data, pp. 371–386 (2016)\n 95. Liu, Z., Liu, T., Guo, J., Wu, N., Wen, W.: An ecc-free mlc stt-ram based approximate memory \ndesign for multimedia applications. In: 2018 IEEE Computer Society Annual Symposium on VLSI \n(ISVLSI), pp. 142–147. IEEE Computer Society, Washington DC (2018)\n 96. Kokolis, A., Skarlatos, D., Torrellas, J.: Pageseer: Using page walks to trigger page swaps in hybrid \nmemory systems. In: 2019 IEEE International Symposium on High Performance Computer Archi-\ntecture (HPCA), pp. 596–608. IEEE Computer Society, Washington DC (2019)\n 97. Kültürsay, E., Kandemir, M., Sivasubramaniam, A., Mutlu, O.: Evaluating STT-RAM as an energy-\nefficient main memory alternative. In: 2013 IEEE International Symposium on Performance Anal-\nysis of Systems and Software (ISPASS), pp. 256–267. IEEE Computer Society, Washington DC \n(2013)\n 98. Gleixner, B., Pellizzer, F., Bez, R.: Reliability characterization of phase change memory. In: 2009 \n10th Annual Non-Volatile Memory Technology Symposium (NVMTS), pp. 7–11. IEEE Computer \nSociety, Washington DC (2009)\n 99. Ban, A.: Wear leveling of static areas in flash memory. Google Patents. US Patent 6,732,221 \n(2004)\n 100. Che, Y., Yang, Y., Awad, A., Wang, R.: A lightweight memory access pattern obfuscation frame-\nwork for NVM. IEEE Comput. Architect. Lett. 19(2), 163–166 (2020)\n 101. Qureshi, M.K., Karidis, J., Franceschini, M., Srinivasan, V., Lastras, L., Abali, B.: Enhancing life-\ntime and security of pcm-based main memory with start-gap wear leveling. In: 2009 42nd Annual \nIEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 14–23. IEEE Computer \nSociety, Washington DC (2009)\n 102. Zeng, Q., Peir, J.-K.: Content-aware non-volatile cache replacement. In: 2017 IEEE International \nParallel and Distributed Processing Symposium (IPDPS), pp. 92–101. IEEE Computer Society, \nWashington DC (2017)\n\n188 Distributed and Parallel Databases (2023) 41:163–189\n1 3\n 103. Zhou, P., Zhao, B., Yang, J., Zhang, Y.: A durable and energy efficient main memory using phase \nchange memory technology. ACM SIGARCH Comput. Architect. News 37(3), 14–23 (2009)\n 104. Qureshi, M.K.: Scalable high performance main memory system using phase-change memory \ntechnology. In: ISCA ’09, pp. 24–33 (2009)\n 105. Seong, N.H., Woo, D.H., Lee, H.-H.S.: Security refresh: prevent malicious wear-out and increase \ndurability for phase-change memory with dynamically randomized address mapping. ACM \nSIGARCH Comput. Architect. News 38(3), 383–394 (2010)\n 106. Thoziyoor, S., Ahn, J.H., Monchiero, M., Brockman, J.B., Jouppi, N.P.: A comprehensive memory \nmodeling tool and its application to the design and analysis of future memory hierarchies. ACM \nSIGARCH Comput. Architect. News 36(3), 51–62 (2008)\n 107. Young, V., Nair, P.J., Qureshi, M.K.: Deuce: write-efficient encryption for non-volatile memories. \nACM SIGARCH Comput. Architect. News 43(1), 33–44 (2015)\n 108. Huang, F., Feng, D., Xia, W., Zhou, W., Zhang, Y., Fu, M., Jiang, C., Zhou, Y.: Security rbsg: \nProtecting phase change memory with security-level adjustable dynamic mapping. In: 2016 IEEE \nInternational Parallel and Distributed Processing Symposium (IPDPS), pp. 1081–1090. IEEE \n(2016)\n 109. Mao, H., Zhang, X., Sun, G., Shu, J.: Protect non-volatile memory from wear-out attack based on \ntiming difference of row buffer hit/miss. In: Design, Automation & Test in Europe Conference & \nExhibition (DATE), 2017, pp. 1623–1626. IEEE Computer Society, Washington DC (2017)\n 110. Zhou, X., Shou, L., Chen, K., Hu, W., Chen, G.: Dptree: differential indexing for persistent mem-\nory. Proc. VLDB Endowment 13(4), 421–434 (2019)\n 111. Chen, Y., Lu, Y., Fang, K., Wang, Q., Shu, J.: utree: a persistent b+-tree with low tail latency. Proc. \nVLDB Endowment 13(12), 2634–2648 (2020)\n 112. Ma, Z., Sha, E.H.-M., Zhuge, Q., Jiang, W., Zhang, R., Gu, S.: Towards the design of efficient \nhash-based indexing scheme for growing databases on non-volatile memory. Future Gen. Comput. \nSyst. 105, 1–12 (2020)\n 113. Xia, F.: Hikv: A hybrid index key-value store for dram-nvm memory systems. In: USENIX ATC \n17, pp. 349–362 (2017)\n 114. Lu, B., Hao, X., Wang, T., Lo, E.: Dash: scalable hashing on persistent memory. arXiv preprint \n(2020). arXiv: 2003. 07302\n 115. Luo, X.: Enhancing lifetime of nvm-based main memory with bit shifting and flipping. In: RTCSA \n2014, pp. 1–7. IEEE Computer Society, Washington DC (2014)\n 116. Dong, W.: Minimizing update bits of nvm-based main memory using bit flipping and cyclic shift-\ning. In: HPCC 2015, CSS 2015, and ESS 2015, pp. 290–295. IEEE Computer Society, Washington \nDC (2015)\n 117. Gu, B., Kargar, S., Nawab, F.: Efficient dynamic clustering: capturing patterns fromhistorical clus-\nter evolution. arXiv preprint (2022). arXiv: 2203. 00812\n 118. Andalibi, M., Hajihosseini, M., Teymoori, S., Kargar, M., Gheisarnejad, M.: A time-varying deep \nreinforcement model predictive control for dc power converter systems. In: 2021 IEEE 12th Inter -\nnational Symposium on Power Electronics for Distributed Generation Systems (PEDG), pp. 1–6. \nIEEE Computer Society, Washington DC (2021)\n 119. Kraska, T.: The case for learned index structures. In: SIGMOD 2018, pp. 489–504 (2018)\n 120. Huang, S., Kang, Z., Xu, Z., Liu, Q.: Robust deep k-means: an effective and simple method for data \nclustering. Pattern Recogn. 117, 107996 (2021)\n 121. Sharif, A., Li, J.P., Saleem, M.A., Manogran, G., Kadry, S., Basit, A., Khan, M.A.: A dynamic \nclustering technique based on deep reinforcement learning for internet of vehicles. J. Intell. Manuf. \n32(3), 757–768 (2021)\n 122. Gazzaz, S., Chakraborty, V., Nawab, F.: Croesus: multi-stage processing and transactions for \nvideo-analytics in edge-cloud systems. arXiv preprint (2021). arXiv: 2201. 00063\n 123. Kargar, S., Mohammad-Khanli, L.: Fractal: An advanced multidimensional range query lookup \nprotocol on nested rings for distributed systems. J. Netw. Comput. Appl. 87, 147–168 (2017)\n 124. Nawab, F., Chakrabarti, D.R., Kelly, T., Morrey III, C.B.: Procrastination beats prevention: timely \nsufficient persistence for efficient crash resilience. In: EDBT, pp. 689–694 (2015)\n 125. Nawab, F.: Wedgechain: a trusted edge-cloud store with asynchronous (lazy) trust. In: 2021 IEEE \n37th International Conference on Data Engineering (ICDE), pp. 408–419. IEEE Computer Society, \nWashington DC (2021)\n\n189\n1 3 Distributed and Parallel Databases (2023) 41:163–189 \n 126. Nawab, F., Sadoghi, M.: Blockplane: A global-scale byzantizing middleware. In: 2019 IEEE 35th \nInternational Conference on Data Engineering (ICDE), pp. 124–135. IEEE Computer Society, \nWashington DC (2019)\n 127. Gu, B., Li, Z., Liu, A., Xu, J., Zhao, L., Zhou, X.: Improving the quality of web-based data imputa-\ntion with crowd intervention. IEEE Trans. Knowl. Data Eng. 33(6), 2534–2547 (2019)\nPublisher’s Note Springer Nature remains neutral with regard to jurisdictional claims in published maps \nand institutional affiliations.",
  "textLength": 81300
}