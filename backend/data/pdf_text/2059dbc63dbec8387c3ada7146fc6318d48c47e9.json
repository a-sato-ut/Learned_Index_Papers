{
  "paperId": "2059dbc63dbec8387c3ada7146fc6318d48c47e9",
  "title": "Optimizing Learned Bloom Filters by Sandwiching",
  "pdfPath": "2059dbc63dbec8387c3ada7146fc6318d48c47e9.pdf",
  "text": "Optimizing Learned Bloom Filters by Sandwiching\nMichael Mitzenmacher1\nAbstract — We provide a simple method for improving the\nperformance of the recently introduced learned Bloom ﬁlters ,\nby showing that they perform better when the learned function\nis sandwiched between two Bloom ﬁlters.\nI. I NTRODUCTION\nRecent work has introduced the learned Bloom ﬁlter [2].\nAs formalized in [3], the learned Bloom ﬁlter, like a standard\nBloom ﬁlter, provides a compressed representation of a set\nof keysKthat allows membership queries. Given a key y, a\nlearned Bloom ﬁlter will always return yes if yis inK, and\nwill generally return no if yis not inK, but may return false\npositives. What makes a learned Bloom ﬁlter interesting is\nthat it uses a function that can be obtained by “learning” the\nsetKto help determine the appropriate answer. Speciﬁcally,\nwe recall the following deﬁnition from [3]:\nDeﬁnition 1: Alearned Bloom ﬁlter on a set of positive keys\nKand negative keys Uis a function f:U![0;1]and\nthreshold\u001c, whereUis the universe possible query keys,\nand an associated standard Bloom ﬁlter B, referred to as a\nbackup ﬁlter. The backup ﬁlter is set to hold the set of keys\nfz:z2K;f(z)< \u001cg. For a query y, the learned Bloom\nﬁlter returns that y2K iff(y)\u0015\u001c, or iff(y)< \u001c and\nthe backup ﬁlter returns that y2K. The learned Bloom ﬁlter\nreturnsy =2K otherwise.\nIn less mathematical terms, a learned Bloom ﬁlter consists\nof pre-ﬁlter before a Bloom ﬁlter, where the backup Bloom\nﬁlter now acts to prevent false negatives. The pre-ﬁlter\nsuggested in [2] comes from a neural network and estimates\nthe probability an element is in the set, allowing the use of\na backup Bloom ﬁlter that can be substantially smaller than\na standard Bloom ﬁlter for the set of keys K. If the function\nfhas a sufﬁciently small representation, then the learned\nBloom ﬁlter can be correspondingly smaller than a standard\nBloom ﬁlter for the same set.\nGiven this formalization of the learned Bloom ﬁlter, and\nthe additional analysis from [3] for determining the false\npositive rate of a learned Bloom ﬁlter, it seems natural to\nask whether this structure can be improved. Here we show,\nperhaps surprisingly, that a better structure is to use a Bloom\nﬁlter before using the function f, in order to remove most\nqueries for keys not in K. We emphasize that this initial\nBloom ﬁlter does not declare that an input yis inK, but\npasses on all matching elements the learned function f, and\nit returnsy =2K when the Bloom ﬁlter shows the element is\nnot inK. Then, as before, we use the function fto attempt\n1School of Engineering and Applied Sciences, Harvard University. Sup-\nported in part by NSF grants CCF-1563710, CCF-1535795, and CCF-\n1320231. This work was done while visiting Microsoft Research.to remove false positives from the initial Bloom ﬁlter, and\nthen use the backup ﬁlter to allow back in keys from Kthat\nwere false negatives for f. Because we have two layers of\nBloom ﬁlters surrounding the learned function f, we refer to\nthis as a sandwiched learned Bloom ﬁlter . The sandwiched\nlearned Bloom ﬁlter is represented pictorially in Figure 1.\nIn hindsight, our result that sandwiching improves per-\nformance makes sense. The purpose of the backup Bloom\nﬁlter is to remove the false negatives arising from the\nlearned function. If we can arrange to remove more false\npositives up front, then the backup Bloom ﬁlter can be quite\nporous, allowing most everything that reaches it through,\nand therefore can be quite small. Indeed, our analysis shows\nthat the backup ﬁlter can be remarkably small, so that as\nthe budget of bits available for the Bloom ﬁlters increases,\nany additional bits should go to the initial Bloom ﬁlter. We\npresent our analysis below.\nII. A NALYZING SANDWICHED LEARNED BLOOM\nFILTERS\nWe model the sandwiched learned Bloom ﬁlter as follows.\nThe middle of the learned Bloom ﬁlter we treat as an oracle\nfor the keysK, wherejKj=m. For keys not inKthere is an\nassociated false positive probability Fp, and there are Fnm\nfalse negatives for keys in K. (The value Fnis like a false\nnegative probability, but given Kthis fraction is determined\nand known according to the oracle outcomes.) This oracle\ncan represent the function fassociated with Deﬁnition 1 for\nlearned Bloom ﬁlters, but might also represent other sorts\nof ﬁlter structures as well. Also, as described in [3], we\nnote that in the context of a learned Bloom ﬁlter, the false\npositive rate is necessarily tied to the query stream, and so in\ngeneral may be an empirically determined quantity; see [3]\nfor further details and discussion on this point. Here we show\nhow to optimize over a single oracle, although in practice we\nmay possibly choose from oracles with different values Fp\nandFn, in which case we can optimize for each set of value\nand choose the best suited to the application.\nWe assume a total budget of bmbits to be divided between\nan initial Bloom ﬁlter of b1mbits and a backup Bloom ﬁlter\nofb2mbits. To model the false positive rate of a Bloom\nﬁlter that uses jbits per stored key, we assume the false\npositive rate falls as \u000bj. This is the case for a standard Bloom\nﬁlter (where \u000b\u00190:6185 when using the optimal number of\nhash functions, as described in the survey [1]), as well as\nfor a static Bloom ﬁlter built using a perfect hash function\n(where\u000b= 1=2, again described in [1]). The analysis can\nbe modiﬁed to handle other functions for false positives in\nterms ofjin a straightforward manner. It is important toarXiv:1803.01474v1  [cs.DS]  5 Mar 2018\n\nnote that ifjKj=m, the backup Bloom ﬁlter only needs to\nholdmFnkeys, and hence we take the number of bits per\nstored key to be b2=Fn. Note that if we ﬁnd the best value of\nb2isb, then no initial Bloom ﬁlter is needed, but otherwise,\nan initial Bloom ﬁlter is helpful.\nThe false positive rate of a sandwiched learned Bloom\nﬁlter is then\n\u000bb1(Fp+ (1\u0000Fp)\u000bb2=Fn):\nTo see this, note that for y =2K,yﬁrst has to pass through the\ninitial Bloom ﬁlter, which occurs with probability \u000bb1. Then\nyeither causes a false positive from the learned function f\nwith probability Fp, or with remaining probability (1\u0000Fp)\nit yields a false positive on the backup Bloom ﬁlter, with\nprobability\u000bb2=Fn.\nAs\u000b;Fp;Fnandbare all constants for the purpose of this\nanalysis, we may optimize for b1in the equivalent expression\nFp\u000bb1+ (1\u0000Fp)\u000bb=Fn\u000bb1(1\u00001=Fn):\nThe derivative with respect to b1is\nFp(ln\u000b)\u000bb1+ (1\u0000Fp)\u0012\n1\u00001\nFn\u0013\n\u000bb=Fn(ln\u000b)\u000bb1(1\u00001=Fn):\nThis equals 0 when\nFp\n(1\u0000Fp)\u0010\n1\nFn\u00001\u0011=\u000b(b\u0000b1)=Fn=\u000bb2=Fn:\nThis yields that the false positive rate is minimized when\nb2=Fnlog\u000bFp\n(1\u0000Fp)\u0010\n1\nFn\u00001\u0011:\nThis result may be somewhat surprising, as here we see\nthatb2is a constant, independent of b. That is, the number\nof bits used for the backup ﬁlter is not a constant fraction\nof the total budgeted number of bits bm, but a ﬁxed number\nof bits; if the number of budgeted bits increases, one should\nsimply increase the size of the initial Bloom ﬁlter as long as\nthe backup ﬁlter is appropriately sized.\nIn hindsight, returning to the expression for the false\npositive rate\n\u000bb1(Fp+ (1\u0000Fp)\u000bb2=Fn);\nwe can see the intuition for why this would be the case. If we\nthink of sequentially distributing the bmbits among the two\nBloom ﬁlters, the expression shows that bits assigned to the\ninitial ﬁlter (the b1bits) reduce false positives arising from\nthe learned function (the Fpterm) as well as false positives\narising subsequent to the learned function (the (1\u0000Fp)\nterm), while the backup ﬁlter only reduces false positives\narising subsequent to the learned function. Initially we would\nprovide bits to the backup ﬁlter to reduce the (1\u0000Fp)rate\nof false positives subsequent to the learned function. Indeed,\nbits in the backup ﬁlter drive down this (1\u0000Fp)term rapidly,\nbecause the backup ﬁlter holds fewer keys from the original\nset, leading to the b2=Fn(instead of just a b2) in the exponent\nin the expression \u000bb2=Fn. Once the false positives comingthrough the backup Bloom ﬁlter reaches an appropriate level,\nwhich, by plugging in the determined optimal value for b2,\nwe ﬁnd is\nFp=\u00121\nFn\u00001\u0013\n;\nthen the tradeoff changes. At that point the gains from\nreducing the false positives from the backup Bloom ﬁlter are\nsmaller than the gains obtained by using the initial Bloom\nﬁlter.\nAs an example, using numbers roughly corresponding to\nsettings tested in [2], suppose we have a learned function\nfwhereFn= 1=2andFp= 1=100. For convenience we\nconsider\u000b= 1=2(that corresponds to perfect hash function\nbased Bloom ﬁlters). Then\nb2= (log299)=2\u00193:315:\nDepending on our Bloom ﬁlter budget parameter b, we obtain\ndifferent levels of performance improvement by using the\ninitial Bloom ﬁlter. At b= 8 bits per key, the false positive\nrate drops from approximately 0:010015 to0:000777 , over\nan order of magnitude. Even at b= 6 bits per key, the\nfalse positive rate drops from approximately 0:010242 to\n0:003109 .\nIf one wants to consider a ﬁxed false positive rate and con-\nsider the space savings from using the sandwiched approach,\nthat is somewhat more difﬁcult. The primary determinant of\nthe overall false positive rate is the oracle’s false positive\nprobability Fp. The sandwich optimization allows one to\nachieve better overall false positive with a larger Fp; that is,\nit can allow for weaker, and correspondingly smaller, oracles.\nA possible further advantage of the sandwich approach is\nthat it makes learned Bloom ﬁlters more robust. As discussed\nin [3], if the queries given to a learned Bloom ﬁlter do\nnot come from the same distribution as the queries from\nthe test set used to estimate the learned Bloom ﬁlter’s false\npositive probability, the actual false positive probability may\nbe substantially larger than expected. The use of an initial\nBloom ﬁlter mitigates this problem, as this issue affects the\nsmaller number of keys that pass the initial Bloom ﬁlter.\nIn any case, we suggest that given that the sandwich\nlearned Bloom ﬁlter is a relatively simple modiﬁcation if\none chooses to use a learned Bloom ﬁlter, we believe that\nthe sandwiching method will allow greater application of the\nlearned Bloom ﬁlter methodology.\nREFERENCES\n[1] A. Broder and M. Mitzenmacher. Network applications of bloom\nﬁlters: A survey. Internet Mathematics , 1(4):485-509, 2004.\n[2] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The Case\nfor Learned Index Structures. https://arxiv.org/abs/1712.\n01208 , 2017.\n[3] M. Mitzenmacher. A Model for Learned Bloom Filters and Related\nStructures. https://arxiv.org/abs/1802.00884 , 2018.\n\nLearned\t\r  Oracle\t\r  \nBackup\t\r  Filter\t\r  \nInput\t\r  \nPosi6ves\t\r  Nega6ves\t\r  \nPosi6ves\t\r  \nNega6ves\t\r  \nLearned\t\r  Oracle\t\r  \nBackup\t\r  Filter\t\r  \nPosi6ves\t\r  \nPosi6ves\t\r  Nega6ves\t\r  \nPosi6ves\t\r  \nNega6ves\t\r  \nIni6al\t\r  Filter\t\r  \nInput\t\r  \nNega6ves\t\r  Fig. 1. The left side shows the original learned Bloom ﬁlter. The right side shows the sandwiched learned Bloom ﬁlter.",
  "textLength": 10870
}