{
  "paperId": "77b3d679f25ec2123e8acac9fefdd508819bba8a",
  "title": "ActiveReach: an active learning framework for approximate reachability query answering in large-scale graphs",
  "pdfPath": "77b3d679f25ec2123e8acac9fefdd508819bba8a.pdf",
  "text": "TYPEOriginal Research\nPUBLISHED /one.tnum/nine.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\nDOI/one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nOPENACCESS\nEDITEDBY\nRuoming Jin,\nKent State University, United States\nREVIEWEDBY\nDong Li,\nFacebook, United States\nFeng Zhang,\nChina University of Geosciences Wuhan,\nChina\n*CORRESPONDENCE\nZohreh Raghebi\nzohreh.raghebi@ucdenver.edu\nRECEIVED /zero.tnum/two.tnum May /two.tnum/zero.tnum/two.tnum/four.tnum\nACCEPTED /three.tnum/one.tnum October /two.tnum/zero.tnum/two.tnum/four.tnum\nPUBLISHED /one.tnum/nine.tnum November /two.tnum/zero.tnum/two.tnum/four.tnum\nCITATION\nRaghebi Z and Banaei-Kashani F (/two.tnum/zero.tnum/two.tnum/four.tnum)\nActiveReach: an active learning framework for\napproximate reachability query answering in\nlarge-scale graphs. Front. Big Data /seven.tnum:/one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum.\ndoi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nCOPYRIGHT\n©/two.tnum/zero.tnum/two.tnum/four.tnum Raghebi and Banaei-Kashani. This is\nan open-access article distributed under the\nterms of the Creative Commons Attribution\nLicense (CC BY) . The use, distribution or\nreproduction in other forums is permitted,\nprovided the original author(s) and the\ncopyright owner(s) are credited and that the\noriginal publication in this journal is cited, in\naccordance with accepted academic practice.\nNo use, distribution or reproduction is\npermitted which does not comply with these\nterms.ActiveReach: an active learning\nframework for approximate\nreachability query answering in\nlarge-scale graphs\nZohreh Raghebi *and Farnoush Banaei-Kashani\nDepartment of Computer Science and Engineering, University of C olorado Denver, Denver, CO,\nUnited States\nWith graph reachability query, one can answer whether there exis ts a path\nbetween two query vertices in a given graph. The existing reachabil ity query\nprocessing solutions use traditional reachability index str uctures and can only\ncompute exact answers, which may take a long time to resolve in larg e graphs.\nIncontrast,withanapproximatereachabilityquery,onecanoﬀera compromise\nby enabling users to strike a trade-oﬀ between query time and th e accuracy of\nthequeryresult.Inthisstudy,weproposeaframework,dubbedA ctiveReach,for\nlearningindexstructurestoanswerapproximatereachabilityqu ery.ActiveReach\nis a two-phase framework that focuses on embedding nodes in a reach ability\nspace. In the ﬁrst phase, we leverage node attributes and positio nal information\nto create reachability-aware embeddings for each node. These emb eddings are\nthen used as nodes’ attributes in the second phase. In the second p hase, we\nincorporate the new attributes and include reachability inform ation as labels in\nthe training data to generate embeddings in a reachability space. In addition,\ncomputing reachability for all training data may not be practical. T herefore,\nselecting a subset of data to compute reachability eﬀectively and e nhance\nreachability prediction performance is challenging. ActiveReach addresses this\nchallenge by employing an active learning approach in the second p hase to\nselectively compute reachability for a subset of node pairs, thu s learning the\napproximate reachability for the entire graph. Our extensiv e experimental study\nwithvariousrealattributedlarge-scalegraphsdemonstrate stheeﬀectivenessof\neach component of our framework.\nKEYWORDS\nreachabilityquery,reachabilitylearning,indexlearning,gra phlearning,graphmining\n/one.tnum Introduction\nGraphs have evolved into a general conceptual abstraction that can model complex\nconnections between objects. Developing a scalable method for the analysis of large-\nscale graphs, such as biological, road, and social networks, is a challenging task. An\ninteresting graph analysis application is to verify whether a vertex is reachable from\nanother.Reachabilityquerieshavebeenusedextensivelyindiverseapplications,including\nsocialnetworks,biologicalnetworks,andcommunicationnetworks.\nFrontiersin BigData /zero.tnum/one.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nGiven a graph Gwith vertices Vand edges E, one extreme\nsolution to answer reachability queries is to pre-compute the full\ntransitive closure of G. The transitive closure (TC) of a graph G=\n(V,E) is a graph TC=(V,E+) such that for all v,winVthere is\nan edge (v,w) inE+if and only if there is a path from vtowinG.\nBypre-computingtheTC,onecananswerreachabilityqueriesvery\neﬃciently.However,TCrequiresalargespaceandcomputingTCis\nverytime-consuming;hence,usingTCisaveryexpensivesolution\nfor large graphs ( Yildirim et al., 2010 ). On the other extreme, one\ncan use depth ﬁrst search (DFS) or breadth ﬁrst search (BFS) of\nthe graph. With DFS or BFS, we traverse the input graph from\nquery source node until the destination node is reached, or it is\nfoundthatnopathfromsourcetodestinationexists.Thisapproach\nrequires no pre-computation but takes O(V+E) time to answer\na query, which is impractical for large graphs. Existing index-\nbased solutions ( Yildirim et al., 2010 ;Agrawal et al., 1989 ;Wang\net al., 2006 ;Chen, 2009 ;Jagadish, 1990 ;Veloso et al., 2014 ;Zhou\net al., 2017 ;Seufert et al., 2013 ;Bramandia et al., 2008 ;Jin et al.,\n2009;van Schaik and de Moor, 2011 ;Jin et al., 2012 ;Cheng et al.,\n2015;Schenkel et al., 2005 ;Tri-ssl and Leser, 2007 ) trade oﬀ pre-\ncomputation and online search, compromising index construction\ntimeandspaceforquerytime.Themainpurposeofthesemethods\nis to suﬃciently pre-compute reachability information to guide\nonline search for query processing. However, exact reachability\nquery answering using such index-based solution is still too time-\nconsuming with high memory usage to be practical in large-scale\ngraphsformanyapplications.Forsuchapplications,aquickanswer\nthat approximates the query result may be preferred as a practical\ncompromise. This is particularly useful solution for applications\nthat do not require exact answers in the ﬁrst place. Unfortunately,\nexisting index-based reachability query processing methods spend\nseveral minutes or hours to provide answers, even for moderately\nsized graphs ( Iyer et al., 2018b ;Zhang et al., 2007 ;Iyer et al.,\n2018a).\n/one.tnum./one.tnum Applications\nSurprisingly, approximate reachability arises in a variety of\nscenarios. In network security, it is just suﬃcient to have a rough\nestimate of the probability of reachability to speciﬁc ﬁle systems\n(Muñoz González et al., 2017 ). Another application known as\ninﬂuencemaximization,whosemainapplicationisviralmarketing\n(Zhu et al., 2017 ;Jin et al., 2011 ), with approximate reachability\nwe can determine nodes that can be inﬂuenced by a given set\nof nodes without spending lots of resources to calculate exact\nanswer (Kempe et al., 2003 ;Zhao et al., 2011 ;Iyer et al., 2018b ).\nIn the study of viral disease epidemics, transmission of the virus\nfrom a group of carrier individuals to a group of receivers can\nbe answered with approximate reachability ( Raghebi and Banaei-\nKashani, 2018 ). Instead of pre-computing the entire reachability\nset, we can consume less storage and computation resources to\napproximatelyanswerthereachabilityqueries.Inmobilenetworks\nand routing applications, we can determine the probability of\nreceiving a packet from the source node to the destination node\n(Ghoshetal.,2007 ).Toward this end, in this study we introduce ActiveReach ,\na learning-based framework to learn reachability for processing\napproximatereachabilityqueriesinlargegraphs.Tothebestofour\nknowledge, we are the ﬁrst to introduce approximate reachability\nqueries and propose a learned index for eﬃciency answering\nof such queries. Our proposed learned reachability indexes are\nsubject to the same advantages and disadvantages as previously\nproposed learned index structure ( Kraska et al., 2018 ). However,\nwe argue that learning index structures that can accurately predict\nreachability are particularly a suitable approach for processing\napproximatereachabilityqueries.\nWith ActiveReach, we calculate embeddings for nodes to\npreserve reachability information. ActiveReach utilizes three key\ntypes of information to learn reachability. First, ActiveReach\nleveragestheconceptthatnodessharingsimilarattributesaremore\nlikely to be reachable. For example, in social networks, if two\nmembers exhibit similar interests and attributes, the probability of\nthem belonging to the same communities and being reachable is\nsigniﬁcantly higher ( Backstrom et al., 2006 ). Second, ActiveReach\nconsiders that nodes that are closer in terms of graph distance\nare more likely to be reachable ( Kempe et al., 2003 ). Finally,\nincorporatingreachabilityinformationfromthegraphcanenhance\nthereachabilitylearningprocess.ActiveReachisdesignedbasedon\nthesefundamentalprinciples.\nActiveReach is a two-phase framework that computes\nembeddings for attributed graphs using position-aware graph\nneuralnetworksintheﬁrstphase.Inthesecondphase,ActiveReach\nutilizes pre-computed embeddings as node attributes and\nemploys an active learning solution. This solution actively selects\nrepresentative pairs of nodes to calculate reachability between\nthem to be added to the training set to improve reachability\nprediction performance. The more eﬀective the method is in\nselectively computing reachability given a ﬁxed budget, the better\nthe learned model will perform. We consider three strategies for\nselecting pairs of nodes to be labeled. These strategies include\nreachability prediction uncertainty, graph structure information,\nandinformationdensityintheembeddedspace.\nTo summarize, we make the following contributions in this\nstudy:\n•Wedeﬁneapproximatereachabilityquery.\n•We introduce a framework to learn new reachability index\nstructures for approximate reachability query processing\neﬃciently.\n•Weintroduceanactivelearningstrategytoselectinformative\nand representative nodes to calculate reachability and label\ndata.\n•Weperformanextensiveexperimentalstudywithvarioussets\nofgraphdatasetstoevaluatetheperformanceofourproposed\nsolutionsforapproximatereachabilityqueryprocessing.\nThe remainder of this study is organized as follows. In Section\n2, we review the related work on reachability query processing,\ngraph embedding, active learning, and index structure learning, in\nrelation to our proposed algorithm. In Sections 3, 4, we formalize\nour problem, and in Section 5, we present our ActiveReach\nalgorithm. In Section 6, we present our experimental results, and\nFrontiersin BigData /zero.tnum/two.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nﬁnally, we conclude the study and discuss future directions of this\nstudyinSection7.\n/two.tnum Related work\n/two.tnum./one.tnum Reachability query processing\nInthissection,wepresentthebodyofliteratureonreachability\nquery processing on graphs. At one extreme, the transitive closure\n(TC)oftheinputgraphcanbeprecomputedtoanswerreachability\nqueries. With this approach, since reachability between all pairs\nof vertices is precomputed, reachability can be answered in O(1).\nHowever, this requires O(n2) storage for large-scale graphs, where\nnis the size of the graph vertex set. On the other hand, DFS\n(Depth First Search) and BFS (Breadth First Search) can be used\nfor reachability query processing without pre-computation. These\napproaches do not leverage pre-computation and fail to scale\nfor large graphs. To balance query time and size of the pre-\ncomputed reachability, various families of index-based solutions\nare proposed in the literature that maintains a compact version\nof the transitive closure ( Agrawal et al., 1989 ;Jagadish, 1990 ;Jin\net al., 2008 ;Wang et al., 2006 ;Jin et al., 2012 ;Cohen et al., 2002 ;\nWei et al., 2014 ;Bramandia et al., 2008 ;Jin et al., 2009 ;Sengupta\net al., 2019 ;Jin and Wang, 2013 ) and/or improve eﬃciency of\nonline search for reachability query processing ( Yildirim et al.,\n2010;Jin et al., 2008 ;Seufert et al., 2013 ;Su et al., 2017 ;Wei et al.,\n2014). Some of these methods are eﬃcient while they use large\nmemory to be fast, and some of them are slow while memory-\nwise eﬃcient. However, in our algorithm, we use a user-deﬁned\nparameter to select a portion of the data as the training set and\nwe apply graph neural networks to learn reachability. We brieﬂy\nreviewthesefamiliesofindex-basedsolutionsforreachabilityquery\nprocessingbelow.\n/two.tnum./one.tnum./one.tnum Interval labeling\nA large family of reachability query processing methods relies\non interval labeling, where a complete interval set (related to\ntree and non-tree edges) is assigned to each vertex to encode the\nset of vertices reachable from each vertex ( Agrawal et al., 1989 ;\nWang et al., 2006 ;Jin et al., 2012 ;van Schaik and de Moor, 2011 ;\nTri-ssl and Leser, 2007 ;Shirani-Mehr et al., 2012 ;Raghebi and\nBanaei-Kashani, 2018 ). Comparative studies ( Veloso et al., 2014 ;\nSeufertetal.,2013 )haveshownthatwhilefastinqueryanswering,\nthe large size of the index structures required for interval\nlabeling is a major bottleneck in scalability of these methods for\nlargegraphs.\n/two.tnum./one.tnum./two.tnum HOP labeling\nAnother family of reachability methods is based on HOP\nlabeling ( Bramandia et al., 2008 ). With this approach, TC is\nencodedrecursivelybymaintainingthereachabilityinformationin\na distributed manner distributed across graph nodes ( Bramandia\net al., 2008 ;Jin et al., 2009 ;Schenkel et al., 2005 ;Su et al., 2017 ;\nJin and Wang, 2013 ;Wei et al., 2014 ). With these methods, eachTABLE/one.tnum Comparisonofindex-basedsolutionsforreachabilityq uery\nprocessing.\nMethod Index\nsizeConstruction\ntimeQuery\ntimeApproximate\nInterval\nlabelingHigh High Low -\nHop\nlabelingMedium High Medium -\nOnline\nsearchLow Low High -\nBackbone Medium High Medium -\nActiveReach Low-high Low-high Low /check\nvertex records lists of vertices reachable from the vertex (out-\nreach) as well as a list of vertices reachable to the vertex (in-\nreach). The main drawback of this family of methods is the long\nindex construction time. Sengupta et al. (2019) andLeskovec\net al. (2005) use random walk to answer reachability query. In\nSengupta et al. (2019) , they generate in-reach and out-reach sets\nforsourceanddestinationquerynodesusingrandomwalksduring\nquery processing. They do not precompute any index structure\nand during query processing apply ﬁrst-order random walks to\nanswer reachability queries. They consider that the next node to\nbe visited is only impacted by the current node. But in many\nreal-world applications such as web-based graphs, next page visit\nis not only based on the previous visit but also impacted by\nthe sequence of last clicks. This type of relationship is called\nhigher-order dependencies. The ﬁrst-order random walk does not\ncapture higher-order dependencies ( Tang et al., 2015 ;Ou et al.,\n2016). In addition, to have an accurate result, this method should\ngenerate long enough random walks so that with a reasonable\nnumber of random walks, two reachable nodes are visited. This\ncategory of methods is very time-consuming to run especially for\nsparsegraphs.\n/two.tnum./one.tnum./three.tnum Fast online search\nThis family of methods ( Yildirim et al., 2010 ;Seufert et al.,\n2013) focuses on speeding up the online search rather than\npre-computing reachability. Toward this end, the online search\nmethods create partial labeling information for each vertex and\nutilize this information to reduce the query time by pruning the\nsearch space. Unlike interval labeling and hop labeling which pre-\ncompute reachability information comprehensively, in fast online\nsearch only partial reachability information is stored during index\nconstruction to be used during query processing. A prominent\nrepresentativeinthisfamilyisGRAIL( Yildirimetal.,2010 ).GRAIL\nassigns each vertex multiple reduced interval labels where each\ninterval is generated with random DFS traversal of a graph. The\nintervalisusedtodeterminewhetheravertexcanbeprunedwhen\nit cannot reach the query target vertex. Wei et al. (2014) andSu\netal.(2017) areanothercategoryofresearchwhichusek-min-wise\nindependentpermutationandbloomﬁlterlabeling,respectively,to\nencode in-reach and out-reach set in a way to prune the search\nspacesimilartoGRAILduringqueryprocessing.\nFrontiersin BigData /zero.tnum/three.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\n/two.tnum./one.tnum./four.tnum Reachability backbone\nMethods in this family introduced the concept of reachability\nbackbone to improve the scalability of the traditional reachability\nindexesincludingintervallabelingandhoplabelingapproaches( Jin\net al., 2012 ). In this study, the main idea is to identify and pre-\ncompute reachability information for a subset of the graph (i.e.,\nthe backbone) that can most inform reachability queries for the\nentiregraph.SCARAB( Jinetal.,2012 )isoneoftherepresentatives\nof this family. To answer reachability query between two vertices,\nSCARAB veriﬁes whether and how query vertices have access to\nthe backbone vertices and then searches the backbone to resolve\nreachability between access points to the backbone. Since the size\nof the reduced backbone graph is small, one can use a diﬀerent\nindex-based structure to process backbone reachability queries.\nFor instance, SCARAB uses GRAIL ( Yildirim et al., 2010 ) for\nreachabilityqueryprocessingonbackbone.\nInTable1, we show comparison summary between traditional\nindex-based solutions. In this table, “High” refers to the analysis\ncomplexity of O(n2) and above, and “Low” refers to constant\nto linear time complexity. For ActiveReach, complexity depends\non the query budget and graph embedding is computed in an\noﬄinemanner.\n/two.tnum./two.tnum Graph embedding\nMany approaches are proposed to represent graphs in a\nlow dimensional space, such as Locally Linear Embedding (LLE)\n(Roweis and Saul, 2000 ), IsoMap ( Tenenbaum et al., 2000 ), and\nLaplacianEigenmaps( BelkinandNiyogi,2001 ).Theseapproaches\nuse singular value decomposition (SVD) or principal component\nanalysis (PCA) as a dimension reduction method to learn node\nrepresentationinlowdimensionalspace.Morerecently,acategory\nofmethodshasbeenintroduced,inspiredbylanguagemodels[e.g.,\nSkipgram ( Mikolov et al., 2013 )] to learn node representations for\nlarge-scale graphs. Deepwalk ( Perozzi et al., 2014 ) is one of the\npioneering works in this category, which uses uniform random\nwalks to transform graph into node sequences and generates\nnode representations by using the skip-gram model (similar to\nword2vec). LINE ( Tang et al., 2015 ) is another method in this\ncategory which deﬁnes two functions as ﬁrst-order proximity\nand second-order proximity to capture ﬁrst-hop and second-hop\nrelational information between vertices. Node2vec ( Grover and\nLeskovec, 2016 ) utilizes random walks in a bias way to learn node\nembeddings.TheauthorsstudyBFSandDFSsuchasrandomwalks\nto capture diﬀerent similarity measures between nodes. Another\nstudy that extends Deepwalk to capture higher order proximity is\nHOPE(Ouetal.,2016 ).HOPEusesKatz( Katz,1953 )andpagerank\n(Song et al., 2009 ) as similarity functions to preserve transitivity\nwhile learning node representations. A comprehensive survey on\ngraph embedding methods is detailed in this study ( Goyal and\nFerrara, 2018 ). Graph neural networks (GNNs) are also very\npopular these days to realize node status propagation on graphs.\nIn fact, GNN can be deﬁned as a generalization of traditional\nconvolutional neural network (CNN) models for graph-structure\ndata.Forexample,awidelyusedGNNmodel,graphconvolutional\nnetwork (GCN) ( Ying et al., 2018 ), deﬁnes the graph convolutionoperation on graph nodes. In this study, a graph node collects\nnode status information from its connected neighbors and update\nits own status. GraphSage ( Hamilton et al., 2017 ) is another study\nwhich proposed a method to only sample a ﬁxed size of neighbor\nnodes for graph convolution with much lower complexity. Graph\nattention network (GAT) ( Veli˘ckovi´c et al., 2017 ) also is another\nrecentworkwhichintroducedtheattentionmechanismintoGNN.\nGAT introduces weighted aggregation of neighbor status on more\nimportant neighbor nodes. A comprehensive survey on GNN and\nitsvariationsisdetailedinthisstudy( WuZ.etal.,2021 ).Ingeneral,\nmost of these solutions embed two nodes closely only if they are\nclose and well-connected in the graph. There is another category\nofGNNsthatleveragepositioninformationofnodestolearntheir\nembeddings ( You et al., 2019 ). This type of GNNs is eﬃcient for\nposition-awaretaskswherethedistanceofnodesisimportant( You\netal.,2019 ).\nIn contrast with all existing study on graph embedding,\nActiveReachembedsgraphnodesinreachabilityspace(ratherthan\nproximityspace),whereintheembeddedspacegraphnodesreside\nin the vicinity of reachable nodes (rather than local nodes) in the\noriginalgraph.Wedemonstratethisbyexperimentation.\n/two.tnum./three.tnum Index structure learning\nKraska et al. (2018) introduced the idea that traditional index\nstructurescanbeimprovedbylearningindexstructures.Themain\nidea is to learn the distribution and structure of the data to obtain\na compact index representation. This study demonstrated that\nlearned models have the potential to provide signiﬁcant beneﬁts\nover traditional index structures. For example, in Mitzenmacher\n(2018), it is shown that a Bloom ﬁlter can be used as a binary\nclassiﬁer predicting whether a key exists in a set. In Ortiz et al.\n(2018),authorsproposedtheideaoftrainingadeeplearningmodel\nto predict query cardinalities. Instead of using basic traditional\nstatistics about data distribution to estimate cardinalities, in this\nstudyamodelistrainedtolearnthemainpropertiesofthedatato\nlearn sub-query representations used to determine the cardinality\nof diﬀerent types of queries for query planning. To the best of our\nknowledge, our study is the ﬁrst to introduce a learned index for\nreachabilityqueryprocessingongraphs.\n/two.tnum./four.tnum Active learning\nActive learning is a strategic approach that intelligently selects\nspeciﬁc data points for labeling to optimize model performance.\nThis method has received extensive attention and study due to\nits eﬃcacy in enhancing model accuracy ( Settles, 2009 ). In recent\nyears,GNNshavebecomepopularinvariousgraphlearningtasks,\nsuch as node classiﬁcation or link prediction, as highlighted in\nrecent studies ( Goyal and Ferrara, 2018 ). However, a common\nchallenge arises from the impracticality of labeling all nodes or\nedges in many cases, which notably impacts the performance of\nGNNs. While active learning has been applied for addressing low\nlabel ratios in various data types such as text and images, adapting\nFrontiersin BigData /zero.tnum/four.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nit to work eﬀectively with graph-structured data is challenging\n(Settles,2009 ).\nRecently, there has been some research focusing on active\nlearning in graphs. In Gao et al. (2018) andCai et al. (2017) ,\nan active learning strategy is introduced for node classiﬁcation. A\nnode selection strategy that combines multiple criteria, including\ngraphstructuralinformationandmodeluncertainty,isintroduced.\nAnotherstudy( WuY.etal.,2021 )alsoproposeddiﬀerentselection\ncriteria and applied a multi-armed bandit method to learn the\nweights of the selection metrics dynamically. None of the prior\nresearch has proposed methods for actively selecting informative\npairsofnodestocapturemaximumreachability.\n/three.tnum Problem deﬁnition\nIn this section, we deﬁne several concepts, including the\nconceptofapproximatereachabilityquery.\n/three.tnum./one.tnum Exact reachability query\nIn graph G, a reachability query between pair of vertices ( u,v)\nreturns true to indicate the vertices are reachable if there exists a\npath(pu,v)fromutov.\n/three.tnum./two.tnum Transitive closure\nLetG=(V,E) be a graph, where VandEare the set of\nverticesandedges,respectively.Matrix Aisthereachabilitymatrix\nortransitiveclosure(TC)of G,whereifnode ucanreachnode vin\nG,thenthecorrespondingelement Auv=1,otherwise Auv=0.\n/three.tnum./three.tnum Approximate reachability query\nGiven a graph G, sparsity ratio α, and a pair of nodes ( u,v)\ninG, approximate reachability query returns the probability that\nvis reachable from u. The sparsity ratio α(0≤α≤1) and the\naccordingly query budget b(b=α|V|2distinct pairs of nodes)\nare user-deﬁned parameters that determine the number of pair of\nnodes to be labeled to enable learning approximate reachability.\nWithb, user can limit both the memory size and the amount of\ntimeanapproximatereachabilityqueryprocessingmethodcanuse\nto partially pre-compute TC toward learning an index structure to\nanswer approximate reachability queries on the entire graph G. In\nthis study, |V|2is the size of the reachability matrix Rof the graph\nG. In our implementation, we call the graph generated from the\nreachabilitymatrixasreachabilitygrap.Weusereachabilitymatrix\nandreachabilitygraphinterchangeablyinthestudy.\n/four.tnum Preliminaries\n/four.tnum./one.tnum GCN\nGivenagraph G=(V,E)withNnodesvi∈V,edges(vi,vj)∈\nE, an adjacency matrix A∈RN∗N, a degree matrix Dii=/summationtextAij,a node feature matrix X∈RN∗F, GCN (Kipf and Welling, 2017 )\nis an eﬃcient variant of convolutional neural networks (CNN),\noperates directly on graphs, using their structural data. It can\naddress the task of node classiﬁcation within a graph where labels\nare only provided for only a limited portion of nodes (semi-\nsupervisedlearning).Speciﬁcally,thearchitectureofaggregationis\nsummarizedas\nH(l+1)=σ(˜D−1\n2˜A˜D−1\n2HlWl) (1)\nGCN has made two main improvements: A self-connection is\nadded to each node in the adjacency matrix, and the adjacency\nmatrixisthennormalizedbasedonthedegrees.Weﬁnallyobtained\n˜Aand˜D.Hlrepresentstheembeddingofthenodesin lthlayer,Wl\nrepresents the weight matrix for the lthlayer, and σrepresents the\nnon-linearity.\n/four.tnum./two.tnum Position-aware embedding\nOne of the limitations of current GNN architectures is their\ninability to encode the positional information of nodes within\nthe graph structure. This gap is addressed by Position-aware\ngraph neural networks (P-GNNs). position-aware graph neural\nnetworks (P-GNNs) ( You et al., 2019 ) represent a novel category\nof graph neural networks designed to produce node embeddings\nby incorporating a node’s distance information relative to all other\nnodesinthegraph.\nThis is how P-GNN generates a node’s embedding. P-GNN\ninitially chooses several node sets known as anchor sets. Next, it\ntrainsanon-linearaggregationmethod,whichutlizesnodefeature\ndata from each anchor set and adjusts it based on the distance\nbetweenthenodeandtheanchorset.AP-GNNconsistsofmultiple\nP-GNN layers. In particular, in the lthP-GNN layer, it begins\nby sampling krandom anchor sets Si. Every dimension of the\nembedding is determined through a process involving three steps:\ninitially computing the message from each node in the anchor\nset using a message computation function F, applying a message\naggregationfunction,andultimatelysubjectingtheresulttoanon-\nlinear transformation to obtain a scalar, achieved through weights\nwandnon-linearity σ(Youetal.,2019 ).\n/five.tnum Baseline solutions\nIn this section, we outline baseline solutions, including a naive\napproach and the adoption of existing reachability processing\nmethodstoprovideanapproximateversion.\n•Naive solution : As a naive solution for partial computation of\nRwith query budget b, one can select bpairs of nodes from\nthegraphuniformlyatrandom.BFSisthenexecutedbetween\nselected pairs of nodes to compute reachability in the matrix.\nThisalgorithmisreferredtoasrandompairsampling(RP).\n•Tree cover : This family of reachability methods uses online\nsearch to answer reachability queries by computing labeling\ninformation to eﬃciently prune the search space ( Yildirim\net al., 2010 ;Jin et al., 2008 ;Veloso et al., 2014 ). One\nFrontiersin BigData /zero.tnum/five.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nof the representative methods in this category is GRAIL\n(Yildirim et al., 2010 ) which uses min-post labeling directly\non the input graph G. In the experiments, we propose an\napproximate solution to select most reachable vertices for\npartial computation of Rbased on the GRAIL approach.\nWe generate diverse spanning trees which have various\nreachability information using multiple DFS traversals with\nlimited length l. The starting vertex of DFS is selected\nrandomly. The order of traversal of the children changes\nproportionaltotheirsumofindegreeandoutdegree.Westart\nDFS traversal within length of luntilbelements of matrix R\narecomputed.\n•2-Hop labeling : As explained in Section 2, hop labeling\nmethods ( Yano et al., 2013 ;Jin and Wang, 2013 ;Wei\net al., 2014 ) utilize intermediary vertices for recursively\nencoding reachability. We adopt and adapt this approach\nfor partial computation of Rby executing multiple depth\nlimitedBFStraversalsfromselectednodes uandcomputethe\ncorrespondingelementinmatrix Rifreachabilitytoanyofits\nchildrenvis not computed yet. If vertex vis reachable from a\nnodewhosereachabilityisalreadycomputed, vispruned.\n•Landmark : This family of methods reduces the size of\nthe original graph by extracting recurrent reachability\ninformation to form a reachability backbone. We select\nSCARAB as a representative method from this family ( Jin\net al., 2012 ). To introduce an approximate backbone-based\nmethod, we extract the reachability backbone based on the\nconcept of vertex cover. The vertex cover of the input graph\nGis a set of vertices S, where for each edge ( u,v)∈E, we\nhave ({u,v} ∩S)/ne}ationslash= ∅(Cheng et al., 2012 ). A vertex cover S\nis called a minimum vertex cover if it is the smallest vertex\ncover among all vertex covers of G. To compute belements\nofthereachabilitymatrix R,weﬁrstcomputea2-approximate\nminimum vertex cover Sof the input graph G, and then, we\nperformBFSon Gtodeterminereachabilitybetweeneachpair\nofvertices u,v∈Suntilbelementsofmatrix Rarecomputed.\n•Forest ﬁre sampling : In Forest Fire sampling ( Leskovec et al.,\n2005), we enhance the sampling process by prioritizing\nvertices with higher degrees, contrasting with the naive\napproach of random pair sampling. This method begins\nby randomly selecting a vertex vand then probabilistically\nincluding some of its outgoing edges to neighboring nodes.\nThenumberofselectedneighborsischosenfromageometric\ndistribution with a mean ofpf\n(1−pf), wherepfis called the\nburning probability. We adopt this sampling method as\nfollows. We deﬁne the probability for a vertex ito be selected\nto be proportional to its Pagerank score ( Song et al., 2009 ) in\nthegraphandthisprocesscontinuesuntilthequerybudgetis\nexhausted.\n/six.tnum ActiveReach\nFigure1 depicts our proposed framework for approximate\nreachability query processing, dubbed ActiveReach. Transitive\nclosure of Gcan be represented as a reachability graph,\nwhere reachability prediction means predicting links between\nnodes within this graph. Reachavility graph is constructedfrom transitive closure, where if node ucan reach node v\ninG, then the corresponding element is 1, otherwise 0. The\nend-to-end solution works as follows. We begin by partially\npopulating the reachability graph which allows us to predict\nreachability for the entire graph. To compute the reachability\ngraph partially, given a query budget one can randomly select\npairs of nodes from the original graph to calculate reachability\n(baseline solution). After computing partial reachability graph, we\ncan then use graph embedding techniques to learn the embedding\nof the nodes in the partial reachability graph, which we call\n“reachability embedding.” Finally, we can use link prediction\nmethods to predict reachability for the remaining portion of\nthegraph.\nHowever, the baseline solution described above has two issues.\nFirst,thereachabilitygraphonlyprovidesconnectivitydata,lacking\nsuﬃcient information for reachability learning. In particular, the\nreachabilitygraphdoesnothaveinformationaboutnodeattributes\nin the original graph, not about placement of the nodes in\nthe original graph, both of which are important for accurate\nreachabilityestimation.\nFor example, in social networks, as demonstrated in Grover\nand Leskovec (2016) , nodes with similar attributes show a higher\nprobability of reachability due to homophily . Moreover, there\nis likely a decrease in the probability of reachability as the\ndistance between nodes increases in the original graph. To this\nend, in Phase 1 of our proposed solution, we enhance the\nreachabilitygraphbyincorporatingnodes’attributesandpositional\ninformation as shown in Figure1a. Second, random selection of\nthe pairs of nodes to generate the partial reachability graph is\nnot an eﬀective sampling approach to inform the link prediction\nmethods that predict the reachability during the query time.\nInstead, in the second phase of ActiveReach, we propose an\nactive learning solution to intelligently select the most informative\npairs of nodes to capture maximum amount of reachability\ninformation from the selected pairs to best inform prediction of\nthe links in the reachability graph during query time, as illustrated\ninFigure1b .\nTo further elaborate, with ActiveReach, we learn reachability\nindexes in two phases. First, given an attributed graph G, we apply\nP-GNN to learn node embedding utilizing node’s attributes and\npositional information in Gas shown in Figure1a. The generated\nembedding is used as the node’s attributes in the reachability\ngraph. Second, starting from a reachability graph with new node’s\nattributes and small set of initial labeled pair of nodes, we apply\na graph embedding (GCN) to learn reachability. In each iteration,\nwe leverage active learning to select informative pair of nodes\nto calculate reachability if the query budget is not reached as\nshown in Figure1b . With ActiveReach not only we can learn an\nindex to predict approximate reachability between pairs of query\nnodesbutalsogenerateareachabilityembeddingspacewhereeach\nnode inGis represented by a vector in the embedded space. The\nreachability embedding space can be used for other downstream\nlearning tasks beyond approximate reachability query processing.\nIn general, we collect our training set (based on the query budget)\nintheactivelearningmannerandlearnreachability.Duringonline\nquery processing, we return the probability of reachability for a\ngivenpairofnodes.Next,weexplaineachphaseindetail.\nFrontiersin BigData /zero.tnum/six.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nFIGURE/one.tnum\nActiveReach overview: (a)Attributed graph as input and generating reachability aware e mbedding using position-aware embedding. Here, the\nvectors correspond to the original nodes’ attributes. (b)Reachability graph utilizes GCN to predict reachability and leveraging activelearning to select\ninformative pairs of nodes to generate the partial reachabilit y graph. The vectors assigned to nodes here represent the new attr ibutes generated from\nthe position-aware embedding.\n/six.tnum./one.tnum Reachability aware attributes\nThe reachability graph, derived from the reachability matrix,\nlacks suﬃcient information on its own. Reachability graph is not\naware of nodes’ attributes and positional data. Since reachability\ncomputation requires positional awareness, employing structure-\naware GNNs proves ineﬃcient for this task. To improve this, we\nutilize P-GNN to enrich nodes in the reachability graph with new\nattributes preserving their positional information in the original\nattributed graph G. In the ﬁrst phase, P-GNN combines both\nnode attributes and positional data to generate reachability-aware\nembedding for each node to enhance reachability learning in the\nsecondphase.\n/six.tnum./two.tnum Active learning strategy\nTocomputereachabilitymatrixgivenquerybudget b,weneed\nto select bpairs of nodes to calculate reachability and generate\na training data set. Since computing reachability is time and\nmemory expensive, we propose an active learning strategy to\nintelligently choose the pairs of nodes to label them to capture\nmaximum reachability information from the graph with a ﬁxed\nquery budget bshown in Figure1b . The more informative pair of\nnodesselected,thehighertheaccuracyofthegeneratedreachability\nindex in approximate reachability query answering. To compute\nreachability and label pair of nodes, we use BFS as simplicity.\nAny reachability computation method suitable for a given graph\nstructurecanbeusedinthisstep.\n/six.tnum./two.tnum./one.tnum Model prediction uncertainty\nIn this study, we explore uncertainty, a widely adopted\ntechnique in active learning literature. By employing uncertainty\nmetrics,wecanselectpairsofnodeswhereourclassiﬁcationmodel\nshows the highest uncertainty. Entropy calculates a measure ofTABLE/two.tnum Statisticsonrealdatasets.\nDatasets Nodes Edges Avg degree Features\nCora 19,793 126,842 6.4 1,433\nPubMed 19,717 88,648 4.4 500\nFlicker 89,250 899,756 10 500\nYelp 716,847 13,954,819 19.4 300\nReddit 232,965 114,618,780 492 602\nDBpedia 8,099,955 71,527,515 8.8 15\nuncertainty in predicting reachability for node pairs viandvj.\nInformationentropyiscalculatedasfollows:\nentropy(vi,vj)=C/summationdisplay\nc=1P(Yijc=1)log(P(Yijc=1)) (2)\nwhereP(Yijc=1)istheprobabilityofpath vi,vjbelongingtoclass c\npredictedbypathprediction.Thelargervalueforentropyindicates\nourmodelismoreuncertainaboutreachabilityof vjfromvi.\n/six.tnum./two.tnum./two.tnum Embedded space information\nOne challenge to select the most informative pairs of nodes\nonly based on the model uncertainty is that we might ﬁnd\nnoisesandoutlierswhicharenotrepresentative.Usinguncertainty\nmetrics may lead us to explore unrepresentative regions of the\ngraph. Here, we introduce a selection measurement based on\nthe reachability embedding space. This parameter selects pairs\nof nodes which are most representative in the embedded space.\nInformation density is higher in the dense regions of embedded\nspace. Computing reachability between nodes from each dense\nregion has reachability information from parts of graphs with\ndiﬀerent reachability patterns. To this end, we ﬁrst apply K-means\nFrontiersin BigData /zero.tnum/seven.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nFIGURE/two.tnum\nReachability prediction performance (F/one.tnum).\nontheembeddingsofallunlabelednodesandsecondcalculatethe\nEuclideandistancebetweeneachnodeoftheclusterandthecluster\ncenter. The pairs of nodes closer to the center of their clusters are\nselected.Here,weshowhowwecalculatedistanceofnode vitothe\ncenterofembeddingcluster(CC).\ndistance(vi)=1\n1+Euc(embedvi,CCvi)(3)\ndensity(vi,vj)=distance(vi)+distance(vj) (4)\nwhereEuc()istheEuclideandistance, embedviistheembeddingof\nnodeviandCCviisthecenteroftheclusterthat vibelongsto.After\nthecomputationofnodedistancestotheirrespectiveclustersinthe\nembeddedspace,weselectpairsofnodes viandvjcharacterizedby\nthehighestdistancesum.\n/six.tnum./two.tnum./three.tnum Graph structure\nTo select nodes which are most informative in terms of\nreachability in graph, we select the pairs of nodes based on their\nimportancebasedonthegraphstructure.Forinstance,reachability\nbetweennodeslocateonmultipleshortestpathsisverycritical.The\ngraphicalstructureisthencalculatedtomeasurerepresentativenessfor unlabeled pair of nodes. There are various metrics in the\nliterature ( Song et al., 2009 ) measuring the importance of nodes\n(e.g., degree, PageRank, closeness, and betweenness centrality). In\nthis study, we use betweenness of nodes to show how they are\nimportant in the graph. Betweenness centrality ( Kintali, 2008 ) of\nanodeviisthenumberoftheshortestpathsthat viispartof.\nbetweenness (vi)=σvi\nσ(5)\ncentrality(vi,vj)=betweenness (vi)+betweenness (vj) (6)\nwhere σviisthenumberofshortestpaths vibelongsto,and σisall\ntheshortestpaths.Aftercomputingbetweenness,weselectpairsof\nnodesviandvjcharacterizedbythehighestbetweennesssum.\n/six.tnum./two.tnum./four.tnum Combination of diﬀerent criteria\nTo have a fair comparison between diﬀerent selection criteria\nandmakescorescomparable,weneedtonormalizescores.Tothis\nend, we convert them into percentiles as in Zhang et al. (2016) .\nDenote Percentile (u,v) as the percentile of pair of nodes in terms\nFrontiersin BigData /zero.tnum/eight.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nFIGURE/three.tnum\nIndex construction time.\nof each metric. We deﬁne the selection criteria to select the pair of\nnodesforlabelingasfollows:\nα∗Pentoropy+β∗Pdensity+γ∗Pcentrality (7)\nwhere α+β+γ=1.\n/six.tnum./two.tnum./five.tnum Complexity analysis\nUsing position-aware embedding in phase 1, typically each\nanchor set contains m nodes, therefore there are O(mnlog2n)\nmessage communications because every node communicates with\nO(log2n)anchorsetsinagraphwithnnodesandeedges.Basedon\ntheYouetal.(2019) ,foreachanchorset,weonlyaggregatemessage\nfromthenodeclosesttoagivennode vwhicheliminatesthefactor\nm in the complexity of position-aware embedding, reducing the\ncomplexityto O(nlog2n)(Youetal.,2019 ).Inphase2,thenumber\nof communications is O(ne) for the graph embedding. K-means\ntimecomplexityis O(n2).Theoverallcomplexityis O(ne).\n/seven.tnum Experimental evaluation\nIn this section, we will ﬁrst present our experimental\nmethodology, and then, we will review our experimental resultsfocusing on reachability prediction performance, ablation study,\nandparametersensitivityanalysisfortheproposedsolution.\n/seven.tnum./one.tnum Datasets\nWe performed our experiments using both real and synthetic\ndatasets.Speciﬁcationsoftheselectedrealdatasetsareillustratedin\nTable2.\n•CoraThis dataset is a citation graph ( Sen et al., 2008 ). Each\ndocumentisrepresentedasanode,andifonedocumentcites\nanother, there is a citation between them. A bag-of-words\nembeddingforeachdocumentisusedasafeatureset.\n•PubmedThisdatasetisalsoacitationgraph( Senetal.,2008 ),\nwhere each citation link between documents is represented\nas an edge. Each document in the graph is equipped with a\nbag-of-wordsembedding,servingasitsnodefeatures.\n•FlickerIn the Flickr dataset ( Zeng et al., 2020 ), each node\ncorresponds to a user, while an edge denotes a follow\nrelationship between two users. Node features are derived\nfromthe500mostcommontagsassociatedwiththeirphotos.\n•YelpdatasetdenotesanactiveuseronYelp( Zengetal.,2020 ),\nwhere edges between nodes indicate friendship relationships.\nFrontiersin BigData /zero.tnum/nine.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nFIGURE/four.tnum\nIndex size.\nNode features have details from user reviews. Utilizing\nword2vec ( Mikolov et al., 2013 ), the reviews are transformed\ninto300-dimensionalvectorsandusedasnodefeatures.\n•RedditReddit/one.tnumIn this graph, nodes represent posts from\nusers, and an edge is assigned between two nodes if the\ncorrespondingusershavepostsonthesametopic.Thisdatais\nfrom Reddit posts in September 2014. The embedding of the\nposttitle,thescoreoftheposts,andthenumberofcomments\noneachpostarecombinedandusedasfeaturesforeachnode.\n•DBpediaFor DBpedia,/two.tnumeach vertex represents an entity, and\neach edge denotes a relationship between two entities. The\nkeywordsofeachentityareembeddedandusedasfeatures.\n/seven.tnum./two.tnum Query budget b\nWe choose the query budget bbetween 5% to 30% of |V2|for\na given dataset. With smaller values of b, the performance of the\nalgorithmswillbelower.\n/one.tnum Available at: http://snap.stanford.edu/graphsage/ (accessed December\n/two.tnum/zero.tnum/one.tnum/seven.tnum).\n/two.tnum Available at: https://www.dbpedia.org/ (accessed December /two.tnum/zero.tnum/one.tnum/six.tnum)./seven.tnum./three.tnum Alternative solutions\nWe evaluate performance of ActiveReach comparing with\nrepresentativeindex-basedsolutionsfromtherelatedstudy( Zhang\net al., 2023 ). We discussed the adapted version of traditional\nindex-based solutions in Section 5. We use index-based solutions\nto complete reachability matrix given a query budget b. We\nthen apply GCN ( Ying et al., 2018 ) on the reachabity graph to\ngenerateembeddings.Here,weexplaintheparametersweusedfor\nbaselinesolutions.\n•Tree cover : We use fast online search (GRAIL) with random\nselectionofstartingnodesandDFSlength l=40.\n•2-Hop labeling : We use 2-hop labeling with random selection\nofstartingnodesandBFSlengthof l=20.\n/seven.tnum./four.tnum Reachability prediction performance\nTo evaluate the performance of ActiveReach, ﬁrst we measure\nreachability prediction performance. For GCN, we follow the\nexperimental setup used in state-of-the-art semi-supervised graph\nembedding methods ( Ying et al., 2018 ). The number of initially\nlabeled pairs of nodes is set as 40, as used in Ying et al. (2018) .\nFrontiersin BigData /one.tnum/zero.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nFIGURE/five.tnum\nDiﬀerent active learning strategies.\nFIGURE/six.tnum\nPosition-aware embedding and attributes.\nWe used the setups from You et al. (2019) to implement position-\naware embedding for the attributed graphs. In particular, after\ngenerating embeddings, we learn a classiﬁer that can receive the\nembeddedvectorsoftwonodesandpredicttheexistenceofapathbetweenthemintheoriginalgraph.Theprobabilityofreachability\nis generated by our classiﬁer. To achieve this, after learning the\nreachability embedding of vertices, given two nodes uandv, we\npredict the existence of a path between them ( pathu,v) by learning\nFrontiersin BigData /one.tnum/one.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nTABLE/three.tnum Statisticsonsyntheticdatasets.\nDatasets Nodes Edges Avg Dag\nrand10m 10M 20M 2\nrand10m 10M 50M 5\nrand10m 10M 100M 10\na classiﬁer f(x), wherexis the set of features for pathu,v. We use\nHadamard ( Grover and Leskovec, 2016 ) as a binary operator for\nconcatenating the embedding vectors. Random Forest with 100\ntrees and a maximum depth of 10 is used as the classiﬁer. We\nconsider threshold of 0.5 for our binary classiﬁer. BFS is used\nto compute reachability for the pair of nodes selected from the\nactive learning strategy. Note that each method is executed 100\ntimes, and average result is reported. In this experiment, we show\nhow increasing the query budget impacts reachability accuracy.\nFigure2illustrates the results for each dataset. We do not show\nresults for the Pubmed dataset because its results are similar to\nthose of the Cora dataset. From the ﬁgure, ActiveReach shows\nthe best performance across all datasets, especially for the Cora\ndataset, which has a very large number of attributes per node. For\nthe Reddit dataset which has a very high average degree (dense\ndataset), ActiveReach performs very well. This is because in dense\ndatasets, most nodes have access to distant nodes due to the\nhigh average degree, increasing the chance to learn reachability\ninformation from neighbors. From the Figure, we also observe\nthat tree cover (GRAIL) has the best performance among index-\nbased and sampling solutions and it does so with a small DFS\nlength. GRAIL does not work well for the Cora data set which\nis sparse. Overall, 2-hop labeling does not perform well because\nit uses its query budget mostly traversing a local neighborhood\nespecially for dense datasets. In addition, Baseline, Landmark,\nand ForestFire are among the worst performing methods to\ncapture reachability information with all datasets. Landmark only\ncomputes reachability between minimum vertex covers and graph\nembedding cannot predict the reachability of pairs of nodes with\nlimited neighborhood information. In addition, Forest Fire is\nnot able to capture enough reachability information from nodes\nlocated far apart in the input graph, especially in sparse graphs.\nOverall, ActiveReach which utilizes nodes’ attributes, position-\naware embedding, and active learning strategy performs better.\nActiveReach uses its budget to cover representative nodes from\nvariouspartsofthegraphwhilecapturingenoughlocalreachability\ninformation. This demonstrates that both local and global graph\nstructureaswellasnodes’attributesareessentialtocharacterizethe\ngraphreachability,asexpected.\nIn addition, we compare the time it takes for each method to\npartially compute matrix R.Figure3shows that ActiveReach takes\nmoretimeduetotheposition-awareembeddingandactivelearning\nstrategy. From index-based solutions, tree cover (GRAIL) takes\nlonger to compute Respecially in dense graphs. Landmark and\nForest Fire spend longer to compute the matrix for sparse datasets\nincomparisonwithdensedatasets.Itisworthnotingthatthequery\ntime, or inference time, is minimal and remains unaﬀected by the\nquerybudget.We also evaluate memory consumption during execution of\nthesemethods;theresultsofthisexperimentareshownin Figure4.\nTree cover (GRAIL), 2-hop labeling, and Landmark have larger\nmemory footprints compared to other methods. For instance,\ncreatingmultipletree-cover in GRAIL and minimumvertex-cover\nin Landmark, which are both time and memory consuming, are at\nthecoreofthesealgorithms.\n/seven.tnum./five.tnum Active learning performance\nAs mentioned before, ActiveReach intelligently selects\nrepresentative pairs of nodes to complete the reachability matrix.\nWe consider diﬀerent combinations of active learning strategies\nas shown in Figure5while ﬁxing the query budget at 0.05% |V2|.\nAsillustratedintheﬁgure,wecannotpreserveenoughreachability\ninformation with only using graph structural information.\nStructural information works well only for dense graphs such\nas Reddit and DBpedia datasets. With utilizing embedded\ninformation especially for sparse graphs (Cora), better results are\nachieved. The reason is that in sparse graphs such as Cora, nodes’\nattributes and position information from nodes apart from each\nother are very important to learn reachability which are captured\nfrom the embedding strategy. In datasets with a small number\nof attributes such as DBpedia, the embedding strategy has less\nimpact in comparison with the structural strategy. In addition,\nit is worth mentioning that depending on the graph structure,\nactive learning strategies can vary signiﬁcantly. For instance, the\nchoice of clustering method is crucial in sparse graphs, while\ncomputing betweenness centrality can be challenging in dense\ngraphs. ActiveReach oﬀers ﬂexibility for users to choose the\noptimalquerybudgetandactivelearningstrategyaccordingtothe\nspeciﬁcapplicationandcharacteristicsoftheinputdata.\nInFigure6, we show the impact of node’s attributes\nand position-aware embedding on the reachability\npredictionperformance.\nThe ﬁgure illustrates that our method does not work well\nwithoutnodes’attributesespeciallyforsparsegraphssuchasCora.\nNodes’ attributes preserve similarity for distant nodes which is\nhard to capture their reachability information in sparse graphs.\nHowever, the impact of nodes’ attributes is less for dense graphs\nsuch as Reddit. In addition, position-aware embedding preserves\ndistance of nodes and this information is essential for graphs\nwith large diameter such as DBpedia. Leveraging position-aware\nembeddings worksverywell forcommunitygraphs suchasReddit\nwhich reachable nodes are closer to each other. Adding attributes\nworksbestforcitationnetworksthatencodekeywordembeddings\nasasimilaritymeasuretopreservereachability.\n/seven.tnum./six.tnum Parameter sensitivity study\nWithournextexperiment,weevaluatedtheimpactofthedata\nparameters and method parameters. For this experiment, we use\nthe synthetic dataset explained in Table3to have more control on\nthegraphstructure.\nFrontiersin BigData /one.tnum/two.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nFIGURE/seven.tnum\nParameter sensitivity: (a)accuracy vs. graph density, (b)accuracy vs. dimension, and (c)accuracy vs. threshold.\nFIGURE/eight.tnum\nParameter sensitivity: (a)Impact of graph structure for sparse graph. (b)Impact of graph structure for medium dense graph. (c)Impact of graph\nstructure for very dense graph.\nFigure7 illustrates how changing ( Figure7a) graph density\nand (Figure7b ) number of dimensions of the embedding space\naﬀects the accuracy. We ﬁx the query budget at 0.05% |V2|and use\nRandomForest with 100 trees and a max depth of 10. In Figure7a,\nwe show how performance changes for datasets with diﬀerent\ndensities. As most of the query budget is used for local traversal\nin dense datasets, with smaller query budgets path prediction\naccuracy is higher in comparison with sparse datasets. We also\nobserve that with larger query budgets, accuracy is higher for\nsparse dataset. In Figure7b , we also observe that performance\ntends to saturate once the number of dimensions of the embedded\nspace reaches approximately 128. In Figure7c, we also show that\nhow changing the prediction threshold or conﬁdence and query\nbudget impact the accuracy. This ﬁgure shows that by increasing\nthe threshold and decreasing the query budget, F1 decreases.\nPredictionthresholdorconﬁdencecanbedeﬁnedasauser-deﬁned\nparameter. Obviously as the user-deﬁned threshold increases, the\nperformance bar is higher for our solution and the F1 score will\ndecrease. We also show that the notion of the query budget is\northogonal to the concept of prediction conﬁdence. While the\nprediction conﬁdence is generated at the inference time (online),\nthe query budget determines the time the user would like to invest\nin construction of the index (oﬀ line). Of course, the larger thequerybudgetandtheinvestment,thehigherpredictionconﬁdence\nis expected. The threshold can be adjusted depending on the\napplication’ssensitivitytoreachabilitypredictions.Forexample,in\napplicationssuchasinﬂuencemaximization,lowerconﬁdencemay\nbe acceptable, while virus propagation detection requires higher\nconﬁdencelevels.\nWe also examine how diﬀerent graph structures aﬀect the\nperformance of path prediction. As illustrated in Figure8a, in\nsparse graphs, pagerank and betweenness preserve reachability\nbetter than degree. The reason is that with small average degree,\ntheneighborreachabilityinformationisnotenough.Asthedensity\nincreases( Figure8b )theimpactofnodebetweennessishigherthan\npagerank.However,inverydensegraphsasillustratedin Figure8c,\nnode degree shows the importance of nodes and can preserve\nreachabilityinformationsimilartopagerank.\n/eight.tnum Conclusion and future work\nIn this study, we introduced ActiveReach, an approximate\nreachability query processing method. With our proposed\nmethod, we learn an index structure to answer approximate\nreachability queries by partially precomputing reachability\nFrontiersin BigData /one.tnum/three.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\ninformation represented by the sparse transitive closure of the\ninput graph. ActiveReach leverages position-aware embedding\nand nodes’ attributes to preserve reachability and intelligently\nselects pair of nodes to label during training. Our experimental\nresults demonstrate the eﬃcacy and eﬃciency of ActiveReach in\nanswering approximate reachability queries in real large graphs\nwith limited resources (time and memory). In the future, we\nplan to extend our proposed framework to process various\ntypes of reachability queries including reachability search and\ntop-kreachability.\nData availability statement\nThe original contributions presented in the study are included\nin the article/supplementary material, further inquiries can be\ndirectedtothecorrespondingauthor.\nAuthor contributions\nZR: Conceptualization, Investigation, Writing – original draft,\nWriting – review & editing. FB-K: Conceptualization, Writing –\noriginaldraft,Writing–review&editing.Funding\nThe author(s) declare ﬁnancial support was received for\nthe research, authorship, and/or publication of this article. We\nappreciate the funding support received from the Department of\nEducation under the GAANN P200A180007 project, that enabled\nthisresearch.\nConﬂict of interest\nThe authors declare that the research was conducted in the\nabsence of any commercial or ﬁnancial relationships that could be\nconstruedasapotentialconﬂictofinterest.\nPublisher’s note\nAll claims expressed in this article are solely those of the\nauthors and do not necessarily represent those of their aﬃliated\norganizations, or those of the publisher, the editors and the\nreviewers. Any product that may be evaluated in this article, or\nclaim that may be made by its manufacturer, is not guaranteed or\nendorsedbythepublisher.\nReferences\nAgrawal, R., Borgida, A., and Jagadish, H. V. (1989). Eﬃcient management of\ntransitive relationshipsinlargedata andknowledge bases. SIGMODRec .18,253–262.\ndoi:10.1145/66926.66950\nBackstrom,L.,Huttenlocher,D.,Kleinberg,J.,andLan,X.(2 006).“Groupformation\nin large social networks: Membership, growth, and evolution,” inProceedings of\nthe 12th ACM SIGKDD International Conference on Knowledge Discovery and Dat a\nMining,KDD’06 (NewYork,NY,USA:AssociationforComputingMachinery),44 –54.\ndoi:10.1145/1150402.1150412\nBelkin, M., and Niyogi, P. (2001). “Laplacian eigenmaps and spect ral techniques\nfor embedding and clustering,” in Proceedings of the 14th International Conference on\nNeural Information Processing Systems: Natural and Synthetic, NIP S’01(Cambridge,\nMA,USA:MITPress),585–591.doi:10.7551/mitpress/1120.0 03.0080\nBramandia, R., Choi, B., and Ng, W. K. (2008). “On incrementa l maintenance\nof 2-hop labeling of graphs,” in Proceedings of the 17th International Conference\non World Wide Web, WWW ’08 (New York, NY, USA: ACM), 845–854.\ndoi:10.1145/1367497.1367611\nCai, H., Zheng, V. W., and Chang, K. C.-C. (2017). Active learn ing for graph\nembedding. arXivpreprintarXiv:1705.05085 .\nChen, Y. (2009). “General spanning trees and reachability query evaluation,”\ninProceedings of the 2Nd Canadian Conference on Computer Science and\nSoftware Engineering, C3S2E ’09 (New York, NY, USA: ACM), 243–252.\ndoi:10.1145/1557626.1557665\nCheng, J., Shang, Z., Cheng, H., Wang, H., and Yu, J. (2012). “ K-reach:\nwho is in your small world,” in Proceedings of the VLDB Endowment , 5.\ndoi:10.14778/2350229.2350247\nCheng, Y., Yuan, Y., Chen, L., and Wang, G. (2015). “The reacha bility query\nover distributed uncertain graphs,” in 2015 IEEE 35th International Conference on\nDistributedComputingSystems ,786–787.doi:10.1109/ICDCS.2015.109\nCohen, E., Halperin, E., Kaplan, H., and Zwick, U. (2002). “Reach ability and\ndistancequeriesvia2-hoplabels,”in ProceedingsoftheThirteenthAnnualACM-SIAM\nSymposium on Discrete Algorithms, SODA ’02 (Philadelphia, PA, USA: Society for\nIndustrialandAppliedMathematics),937–946.\nGao,L.,Yang,H.,Zhou,C.,Wu,J.,Pan,S.,andHu,Y.(2018). “Activediscriminative\nnetwork representation learning,” in Proceedings of the Twenty-Seventh International\nJoint Conference on Artiﬁcial Intelligence, IJCAI-18 (International Joint Conferences\nonArtiﬁcialIntelligenceOrganization),2142–2148.doi:10 .24963/ijcai.2018/296\nGhosh,J.,Ngo,H.Q.,Yoon,S.,andQiao,C.(2007).“Onarout ingproblemwithin\nprobabilisticgraphsanditsapplicationtointermittentlyconnec tednetworks,”in IEEEINFOCOM 2007 -26th IEEE International Conference on Computer Communications ,\n1721–1729.doi:10.1109/INFCOM.2007.201\nGoyal, P., and Ferrara, E. (2018). Graph embedding techniques,\napplications, and performance: a survey. Knowl.-Based Syst . 151, 78–94.\ndoi:10.1016/j.knosys.2018.03.022\nGrover, A., and Leskovec, J. (2016). “Node2vec: scalable featu re learning for\nnetworks,” in Proceedings of the 22Nd ACM SIGKDD International Conference on\nKnowledgeDiscoveryandDataMining,KDD’16 (NewYork,NY,USA:ACM),855–864.\ndoi:10.1145/2939672.2939754\nHamilton, W. L., Ying, R., and Leskovec, J. (2017). “Inductiv e representation\nlearningonlargegraphs,”in AdvancesinNeuralInformationProcessingSystems,30 .\nIyer,A.P.,Liu,Z.,Jin,X.,Venkataraman,S.,Braverman,V .,andStoica,I.(2018a).\n“Asap: fast, approximate graph pattern mining at scale,” in OSDI’18(USA: USENIX\nAssociation),745–761.\nIyer, A. P., Panda, A., Venkataraman, S., Chowdhury, M., Ake lla, A., Shenker, S.,\net al. (2018b). “Bridging the gap: towards approximate graph analy tics,” inGRADES-\nNDA’18(New York, NY, USA: Association for Computing Machinery), 74 5–761.\ndoi:10.1145/3210259.3210269\nJagadish, H. V. (1990). A compression technique to materialize transitive closure.\nACMTrans.Datab.Syst .15,558–598.doi:10.1145/99935.99944\nJin, R., Liu, L., Ding, B., and Wang, H. (2011). Distance-con straint\nreachability computation in uncertain graphs. Proc. VLDB Endow . 4, 551–562.\ndoi:10.14778/2002938.2002941\nJin, R., Ruan, N., Dey, S., and Xu, J. Y. (2012). “Scarab: Scali ng reachability\ncomputation on large graphs,” in Proceedings of the 2012 ACM SIGMOD\nInternational Conference on Management of Data, SIGMOD ’12 (New York, NY,\nUSA: Association for Computing Machinery), 169–180. doi: 10 .1145/2213836.\n2213856\nJin, R., and Wang, G. (2013). Simple, fast, and scalable reachabili ty oracle. CoRR,\nabs/1305.0502 .\nJin, R., Xiang, Y., Ruan, N., and Fuhry, D. (2009). “3hopp: a hig h-\ncompression indexing scheme for reachability query,” in Proceedings of the\n2009 ACM SIGMOD International Conference on Management of Data,\nSIGMOD’09 (New York, NY, USA: ACM), 813–826. doi: 10.1145/1559845.\n1559930\nJin,R.,Xiang,Y.,Ruan,N.,andWang,H.(2008).“Eﬃcientlya nsweringreachability\nqueries on very large directed graphs,” in Proceedings of the 2008 ACM SIGMOD\nFrontiersin BigData /one.tnum/four.tnum frontiersin.org\n\nRaghebi and Banaei-Kashani /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fdata./two.tnum/zero.tnum/two.tnum/four.tnum./one.tnum/four.tnum/two.tnum/seven.tnum/one.tnum/zero.tnum/four.tnum\nInternational Conference on Management of Data, SIGMOD’08 (New York, NY, USA:\nACM),595–608.doi:10.1145/1376616.1376677\nKatz, L. (1953). A new status index derived from sociometric analysis.\nPsychometrika 18,39–43.doi:10.1007/BF02289026\nKempe,D.,Kleinberg,J.,andTardos,E.(2003).“Maximizingt hespreadofinﬂuence\nthrough a social network,” in Proceedings of the Ninth ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining, KDD ’03 (New York, NY, USA:\nAssociationforComputingMachinery),137–146.doi:10.114 5/956755.956769\nKintali, S. (2008). Betweenness centrality: algorithms and low er bounds. CoRR,\nabs/0809.1906 .\nKipf, T. N., and Welling, M. (2017). Semi-supervised classiﬁcati on with graph\nconvolutionalnetworks. arXivpreprintarXiv:1609.02907 .\nKraska, T., Beutel, A., Chi, E. H., Dean, J., and Polyzotis, N. ( 2018). “The case\nfor learned index structures,” in Proceedings of the 2018 International Conference on\nManagement of Data, SIGMOD ’18 (New York, NY, USA: Association for Computing\nMachinery),489–504.doi:10.1145/3183713.3196909\nLeskovec,J.,Kleinberg,J.,andFaloutsos,C.(2005).“Graphso vertime:densiﬁcation\nlaws, shrinking diameters and possible explanations,” in Proceedings of the Eleventh\nACMSIGKDDInternationalConferenceonKnowledgeDiscoveryinDataMinin g,KDD\n’05(NewYork,NY,USA:ACM),177–187.doi:10.1145/1081870.10 81893\nMikolov, T., Chen, K., Corrado, G. S., and Dean, J. (2013). Eﬃci ent estimation of\nwordrepresentationsinvectorspace. arXivpreprintarXiv:1301.3781,3781 .\nMitzenmacher, M. (2018). “A model for learned bloom ﬁlters and o ptimizing\nby sandwiching,” in Advances in Neural Information Processing Systems (Curran\nAssociates,Inc.),464–473.doi:10.1007/978-1-4614-826 5-9_751\nMu noz González, L., Sgandurra, D., Paudice, A., and Lupu, E. C. ( 2017). Eﬃcient\nattackgraphanalysisthroughapproximateinference. ACMTrans.Priv.Secur .20,1–30.\ndoi:10.1145/3105760\nOrtiz, J., Balazinska, M., Gehrke, J., and Keerthi, S. S. (2018 ). “Learning\nstate representations for query optimization with deep reinfo rcement learning,” in\nProceedings of the Second Workshop on Data Management for End-To-End Ma chine\nLearning, DEEM’18 (New York, NY, USA: Association for Computing Machinery).\ndoi:10.1145/3209889.3209890\nOu, M., Cui, P., Pei, J., Zhang, Z., and Zhu, W. (2016). “Asymm etric transitivity\npreservinggraphembedding,”in Proceedingsofthe22NdACMSIGKDDInternational\nConference on Knowledge Discovery and Data Mining, KDD’16 (New York, NY, USA:\nACM),1105–1114.doi:10.1145/2939672.2939751\nPerozzi,B.,Al-Rfou,R.,andSkiena,S.(2014).“Deepwalk:Onli nelearningofsocial\nrepresentations,”in Proceedingsofthe20thACMSIGKDDInternationalConferenceon\nKnowledgeDiscoveryandDataMining,KDD’14 (NewYork,NY,USA:ACM),701–710.\ndoi:10.1145/2623330.2623732\nRaghebi, Z., and Banaei-Kashani, F. (2018). “Eﬃcient proces sing of probabilistic\nsingle and batch reachability queries in large and evolving spatio temporal contact\nnetworks,” in 2018 IEEE International Conference on Big Data (Big Data) , 556–561.\ndoi:10.1109/BigData.2018.8622578\nRoweis,S.T.,andSaul,L.K.(2000).Nonlineardimensionality reductionbylocally\nlinearembedding. Science290,2323–2326.doi:10.1126/science.290.5500.2323\nSchenkel, R., Theobald, A., and Weikum, G. (2005). “Eﬃcient cre ation and\nincremental maintenance of the hopi index for complex xml docum ent collections,”\nin21stInternationalConferenceonDataEngineering(ICDE’05) ,360–371.\nSen, P., Namata, G., Bilgic, M., Getoor, L., Galligher, B., and Elia ssi-\nRad, T. (2008). Collective classiﬁcation in network data. AI Magazine 29:93.\ndoi:10.1609/aimag.v29i3.2157\nSengupta, N., Bagchi, A., Ramanath, M., and Bedathur, S. (201 9). “Arrow:\napproximating reachability using random walks over web-scale gr aphs,” in\n2019 IEEE 35th International Conference on Data Engineering (ICDE) , 470–481.\ndoi:10.1109/ICDE.2019.00049\nSettles,B.(2009). Activelearningliteraturesurvey .TechnicalReport.\nSeufert, S., Anand, A., Bedathur, S., and Weikum, G. (2013). “ Ferrari:\nﬂexible and eﬃcient reachability range assignment for graph ind exing,” in 2013\nIEEE 29th International Conference on Data Engineering (ICDE) , 1009–1020.\ndoi:10.1109/ICDE.2013.6544893\nShirani-Mehr,H.,Banaei-Kashani,F.,andShahabi,C.(201 2).Eﬃcientreachability\nquery evaluation in large spatiotemporal contact datasets. Proc. VLDB Endow . 5,\n848–859.doi:10.14778/2311906.2311912\nSong,H.H.,Cho,T.W.,Dave,V.,Zhang,Y.,andQiu,L.(2009) .“Scalableproximity\nestimation and link prediction in online social networks,” in Proceedings of the 9thACMSIGCOMMConferenceonInternetMeasurement,IMC’09 (NewYork,NY,USA:\nAssociationforComputingMachinery),322–335.doi:10.114 5/1644893.1644932\nSu, J., Zhu, Q., Wei, H., and Yu, J. X. (2017). Reachability quer ying: can it be even\nfaster?IEEETrans.Knowl.DataEng .29,683–697.doi:10.1109/TKDE.2016.2631160\nTang,J.,Qu,M.,Wang,M.,Zhang,M.,Yan,J.,andMei,Q.(201 5).“Line:large-scale\ninformation network embedding,” in Proceedings of the 24th International Conference\nonWorldWideWeb (ACM).doi:10.1145/2736277.2741093\nTenenbaum, J. B., de Silva, V., and Langford, J. C. (2000). A glo bal\ngeometric framework for nonlinear dimensionality reduction .Science290:2319.\ndoi:10.1126/science.290.5500.2319\nTri-ssl, S., and Leser, U. (2007). “Fast and practical indexin g and querying of very\nlarge graphs,” in Proceedings of the 2007 ACM SIGMOD International Conference\non Management of Data, SIGMOD ’07 (New York, NY, USA: ACM), 845–856.\ndoi:10.1145/1247480.1247573\nvan Schaik, S. J., and de Moor, O. (2011). “A memory eﬃcient re achability data\nstructure through bit vector compression,” in Proceedings of the 2011 ACM SIGMOD\nInternational Conference on Management of Data, SIGMOD’11 (New York, NY, USA:\nACM),913–924.doi:10.1145/1989323.1989419\nVeli˘ckovi´c, P., Cucurull, G., Casanova, A., Romero, A., Lió, P., and Bengi o, Y.\n(2017).Graphattentionnetworks. arXivpreprintarXiv:1710.10903 .\nVeloso, R. R., Cerf, L., Meira, W., and Zaki, M. J. (2014). “Rea chability queries in\nverylargegraphs:Afastreﬁnedonlinesearchapproach,”in EDBT.\nWang,H.,He,H.,Yang,J.,Yu,P.S.,andYu,J.X.(2006).“Dua llabeling:answering\ngraphreachabilityqueriesinconstanttime,”in 22ndInternationalConferenceonData\nEngineering(ICDE’06) ,75–75.doi:10.1109/ICDE.2006.53\nWei, H., Yu, J. X., Lu, C., and Jin, R. (2014). Reachability quer ying: an\nindependent permutation labeling approach. Proc. VLDB Endow . 7, 1191–1202.\ndoi:10.14778/2732977.2732992\nWu, Y., Xu, Y., Singh, A., Yang, Y., and Dubrawski, A. (2021). Active learning for\ngraphneuralnetworksvianodefeaturepropagation. arXivpreprintarXiv:1910.07567 .\nWu,Z.,Pan,S.,Chen,F.,Long,G.,Zhang,C.,andYu,P.S.(202 1).Acomprehensive\nsurvey on graph neural networks. IEEE Trans. Neural Netw. Lear. Syst . 32, 4–24.\ndoi:10.1109/TNNLS.2020.2978386\nYano,Y.,Akiba,T.,Iwata,Y.,andYoshida,Y.(2013).“Fast andscalablereachability\nqueries on graphs by pruned labeling with landmarks and paths,” in Proceedings of\nthe 22nd ACM International Conference on Information and Knowledge Mana gement,\nCIKM ’13 (New York, NY, USA: Association for Computing Machinery), 16 01–1606.\ndoi:10.1145/2505515.2505724\nYildirim,H.,Chaoji,V.,andZaki,M.J.(2010).Grail:Scalabler eachabilityindexfor\nlargegraphs. Proc.VLDBEndow .3,276–284.doi:10.14778/1920841.1920879\nYing, R., He, R., Chen, K., Eksombatchai, P., Hamilton, W. L., and Leskovec, J.\n(2018).“Graphconvolutionalneuralnetworksforweb-scalerec ommendersystems,”in\nProceedingsofthe24thACMSIGKDDInternationalConferenceonKnowledgeDi scovery\nDataMining (ACM).doi:10.1145/3219819.3219890\nYou, J., Ying, R., and Leskovec, J. (2019). “Position-aware graph neural networks,”\ninInternationalConferenceonMachineLearning .\nZeng,H.,Zhou,H.,Srivastava,A.,Kannan,R.,andPrasanna ,V.(2020).Graphsaint:\ngraphsamplingbasedinductivelearningmethod. arXivpreprintarXiv:1907.04931 .\nZhang,C.,Bonifati,A.,andÖzsu,M.T.(2023).“Anoverview ofreachabilityindexes\nongraphs,”in Companionofthe2023InternationalConferenceonManagementofData,\nSIGMOD ’23 (New York, NY, USA: Association for Computing Machinery), 61 –68.\ndoi:10.1145/3555041.3589408\nZhang,S., Yang, J.,and Cheedella, V. (2007). “Monkey: approxim ate graph mining\nbased on spanning trees,” in 2007 IEEE 23rd International Conference on Data\nEngineering ,1247–1249.doi:10.1109/ICDE.2007.368984\nZhang, Y., Lease, M., and Wallace, B. C. (2016). “Active discri minative text\nrepresentation learning,” in Proceedings of the AAAI Conference on Artiﬁcial\nIntelligence .doi:10.1609/aaai.v31i1.10962\nZhao, X., Sala, A., Zheng, H., and Zhao, B. Y. (2011). Fast and s calable analysis of\nmassivesocialgraphs. arXivpreprintarXiv:1107.5114 .\nZhou,J.,Zhou,S.,Yu,J.X.,Wei,H.,Chen,Z.,andTang,X.(2 017).“Dagreduction:\nfast answering reachability queries,” in Proceedings of the 2017 ACM International\nConference on Management of Data, SIGMOD ’17 (New York, NY, USA: ACM),\n375–390.doi:10.1145/3035918.3035927\nZhu, R., Zou, Z., and Li, J. (2017). Towards eﬃcient top-k relia bility search on\nuncertaingraphs. Knowl.Inf.Syst .50,723–750.doi:10.1007/s10115-016-0961-9\nFrontiersin BigData /one.tnum/five.tnum frontiersin.org",
  "textLength": 72811
}