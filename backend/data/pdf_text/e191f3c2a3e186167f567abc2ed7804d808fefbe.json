{
  "paperId": "e191f3c2a3e186167f567abc2ed7804d808fefbe",
  "title": "Active causal structure learning with advice",
  "pdfPath": "e191f3c2a3e186167f567abc2ed7804d808fefbe.pdf",
  "text": "Active causal structure learning with advice\nDavin Choo\nNational University of SingaporeThemis Gouleakis\nNational University of Singapore\nArnab Bhattacharyya\nNational University of Singapore\nAbstract\nWe introduce the problem of active causal structure learning with advice. In the typical well-studied\nsetting, the learning algorithm is given the essential graph for the observational distribution and is asked to\nrecover the underlying causal directed acyclic graph (DAG) G∗while minimizing the number of interventions\nmade. In our setting, we are additionally given side information about G∗as advice, e.g. a DAG Gpurported\nto be G∗. We ask whether the learning algorithm can benefit from the advice when it is close to being\ncorrect, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the\nsame space as the growing body of research on algorithms with predictions . When the advice is a DAG G,\nwe design an adaptive search algorithm to recover G∗whose intervention cost is at most O(max{1,logψ})\ntimes the cost for verifying G∗; here, ψis a distance measure between GandG∗that is upper bounded\nby the number of variables n, and is exactly 0 when G=G∗. Our approximation factor matches the\nstate-of-the-art for the advice-less setting.\n1 Introduction\nAcausal directed acyclic graph on a set Vofnvariables is a Bayesian network in which the edges model direct\ncausal effects. A causal DAG can be used to infer not only the observational distribution of Vbut also the\nresult of any intervention on any subset of variables V′⊆V. In this work, we restrict ourselves to the causally\nsufficient setting where there are no latent confounders, no selection bias, and no missingness in data.\nThe goal of causal structure learning is to recover the underlying DAG from data. This is an important\nproblem with applications in multiple fields including philosophy, medicine, biology, genetics, and econometrics\n[Rei56, Hoo90, KWJ+04, Woo05, RW06, ES07, SC17, RHT+17, POS+18]. Unfortunately, in general, it is\nknown that observational data can only recover the causal DAG up to an equivalence class [Pea09, SGSH00].\nHence, if one wants to avoid making parametric assumptions about the causal mechanisms, the only recourse\nis to obtain experimental data from interventions [EGS05, EGS06, Ebe10].\nSuch considerations motivate the problem of interventional design where the task is to find a set of in-\nterventions of optimal cost which is sufficient to recover the causal DAG. There has been a series of recent\nworks studying this problem [HG08, HLV14, SKDV15, KDV17, LKDV18, GKS+19, SMG+20, CSB22, CS23]\nunder various assumptions. In particular, assuming causal sufficiency, [CSB22] gave an adaptive algorithm\nthat actively generates a sequence of interventions of bounded size, so that the total number of interventions\nis at most O(logn) times the optimal.\nTypically though, in most applications of causal structure learning, there are domain experts and prac-\ntitioners who can provide additional “advice” about the causal relations. Indeed, there has been a long\nline of work studying how to incorporate expert advice into the causal graph discovery process; e.g. see\n[Mee95a, SSG+98, DCJ11, FNB+11, LB18, ASC20, FH20]. In this work, we study in a principled way how\nusing purported expert advice can lead to improved algorithms for interventional design.\nBefore discussing our specific contributions, let us ground the above discussion with a concrete problem of\npractical importance. In modern virtualized infrastructure, it is increasingly common for applications to be\nmodularized into a large number of interdependent microservices. These microservices communicate with each\nother in ways that depend on the application code and on the triggering userflow. Crucially, the communication\ngraph between microservices is often unknown to the platform provider as the application code may be private\nand belong to different entities. However, knowing the graph is useful for various critical platform-level tasks,\n1arXiv:2305.19588v1  [cs.LG]  31 May 2023\n\nsuch as fault localization [ZPX+19], active probing [TJG+19], testing [JBT+19], and taint analysis [CLO07].\nRecently, [WAJ+23] and [ICM+22] suggested viewing the microservices communication graph as a sparse causal\nDAG. In particular, [WAJ+23] show that arbitrary interventions can be implemented as fault injections in a\nstaging environment, so that a causal structure learning algorithm can be deployed to generate a sequence of\ninterventions sufficient to learn the underlying communication graph. In such a setting, it is natural to assume\nthat the platform provider already has an approximate guess about the graph, e.g. the graph discovered in\na previous run of the algorithm or the graph suggested by public metadata tagging microservice code. The\nresearch program we put forth is to design causal structure learning algorithms that can take advantage of\nsuch potentially imperfect advice1.\n1.1 Our contributions\nIn this work, we study adaptive intervention design for recovering non-parametric causal graphs with expert\nadvice . Specifically, our contributions are as follows.\n•Problem Formulation . Our work connects the causal structure learning problem with the burgeoning\nresearch area of algorithms with predictions orlearning-augmented algorithms [MV22] where the goal is to\ndesign algorithms that bypass worst-case behavior by taking advantage of (possibly erroneous) advice or\npredictions about the problem instance. Most work in this area has been restricted to online algorithms,\ndata structure design, or optimization, as described later in Section 2.5. However, as we motivated above,\nexpert advice is highly relevant for causal discovery, and to the best of our knowlege, ours is the first\nattempt to formally address the issue of imperfect advice in this context.\n•Adaptive Search Algorithm . We consider the setting where the advice is a DAG Gpurported to be\nthe orientations of all the edges in the graph. We define a distance measure which is always bounded by\nn, the number of variables, and equals 0 when G=G∗. For any integer k≥1, we propose an adaptive\nalgorithm to generate a sequence of interventions of size at most kthat recovers the true DAG G∗, such\nthat the total number of interventions is O(logψ(G, G∗)·logk) times the optimal number of interventions\nof size k. Thus, our approximation factor is never worse than the factor for the advice-less setting in\n[CSB22]. Our search algorithm also runs in polynomial time.\n•Verification Cost Approximation . For a given upper bound k≥1, a verifying intervention set for a\nDAG G∗is a set of interventions of size at most kthat, together with knowledge of the Markov equivalence\nclass of G∗, determines the orientations of all edges in G∗. The minimum size of a verifying intervention\nset for G∗, denoted νk(G∗), is clearly a lower bound for the number of interventions required to learn\nG∗(regardless of the advice graph G). One of our key technical results is a structural result about ν1.\nWe prove that for any two DAGs GandG′within the same Markov equivalence class, we always have\nν1(G)≤2·ν1(G′) and that this is tight in the worst case. Beyond an improved structural understanding\nof minimum verifying intervention sets, which we believe is of independent interest, this enables us to\n“blindly trust” the information provided by imperfect advice to some extent.\nSimilar to prior works (e.g. [SMG+20, CSB22, CS23]), we assume causal sufficiency and faithfulness while\nusing ideal interventions. Under these assumptions, running standard causal discovery algorithms (e.g. PC\n[SGSH00], GES [Chi02]) will always successfully recover the correct essential graph from data. We also assume\nthat the given expert advice is consistent with observational essential graph. See Appendix A for a discussion\nabout our assumptions.\n1.2 Paper organization\nIn Section 2, we intersperse preliminary notions with related work. Our main results are presented in Section 3\nwith the high-level technical ideas and intuition given in Section 4. Section 5 provides some empirical validation.\nSee the appendices for full proofs, source code, and experimental details.\n1Note however that the system in [WAJ+23] is not causally sufficient due to confounding user behavior and [ICM+22] does\nnot actively perform interventions. So, the algorithm proposed in this work cannot be used directly for the microservices graph\nlearning problem.\n2\n\n2 Preliminaries and Related Work\nBasic notions about graphs and causal models are defined in Appendix B. To be very brief, if G= (V, E)\nis a graph on |V|=nnodes/vertices where V(G),E(G), and A(G)⊆E(G) denote nodes, edges, and arcs\nofGrespectively, we write u∼vto denote that two nodes u, v∈Vare connected in G, and write u→v\noru←vwhen specifying a certain direction. The skeleton skel(G) refers to the underlying graph where all\nedges are made undirected. A v-structure inGrefers to a collection of three distinct vertices u, v, w ∈V\nsuch that u→v←wandu̸∼w. Let G= (V, E) be fully unoriented. For vertices u, v∈V, subset of\nvertices V′⊆Vand integer r≥0, we define dist G(u, v) as the shortest path length between uandv, and\nNr\nG(V′) ={v∈V: min u∈V′dist G(u, v)≤r} ⊆Vas the set of vertices that are r-hops away from V′inG.\nA directed acyclic graph (DAG) is a fully oriented graph without directed cycles. For any DAG G, we denote\nits Markov equivalence class (MEC) by [ G] and essential graph by E(G). DAGs in the same MEC have the\nsame skeleton and the essential graph is a partially directed graph such that an arc u→vis directed if u→v\ninevery DAG in MEC [ G], and an edge u∼vis undirected if there exists two DAGs G1, G2∈[G] such that\nu→vinG1andv→uinG2. It is known that two graphs are Markov equivalent if and only if they have\nthe same skeleton and v-structures [VP90, AMP97] and the essential graph E(G) can be computed from Gby\norienting v-structures in skel( G) and applying Meek rules (see Appendix D). In a DAG G, an edge u→vis a\ncovered edge ifPa(u) =Pa(v)\\ {u}. We use C(G)⊆E(G) to denote the set of covered edges of G.\n2.1 Ideal interventions\nAnintervention S⊆Vis an experiment where all variables s∈Sis forcefully set to some value, independent of\nthe underlying causal structure. An intervention is atomic if|S|= 1 and bounded size if|S| ≤kfor some k≥1;\nobservational data is a special case where S=∅. The effect of interventions is formally captured by Pearl’s do-\ncalculus [Pea09]. We call any I ⊆2Vaintervention set : an intervention set is a set of interventions where each\nintervention corresponds to a subset of variables. An ideal intervention onS⊆VinGinduces an interventional\ngraph GSwhere all incoming arcs to vertices v∈Sare removed [EGS05]. It is known that intervening on S\nallows us to infer the edge orientation of any edge cut by SandV\\S[Ebe07, HEH13, HLV14, SKDV15, KDV17].\nWe now give a definition and result for graph separators.\nDefinition 1 (α-separator and α-clique separator, Definition 19 from [CSB22]) .LetA, B, C be a partition of\nthe vertices Vof a graph G= (V, E). We say that Cis an α-separator if no edge joins a vertex in Awith a\nvertex in Band|A|,|B| ≤α· |V|. We call Cis an α-clique separator if it is an α-separator and a clique.\nTheorem 2 ([GRE84], instantiated for unweighted graphs) .LetG= (V, E)be a chordal graph with |V| ≥2\nandpvertices in its largest clique. There exists a 1/2-clique-separator Cinvolving at most p−1vertices. The\nclique Ccan be computed in O(|E|)time.\nFor ideal interventions, an I-essential graph EI(G) ofGis the essential graph representing the Markov\nequivalence class of graphs whose interventional graphs for each intervention is Markov equivalent to GSfor\nany intervention S∈ I. There are several known properties about I-essential graph properties [HB12, HB14]:\nEvery I-essential graph is a chain graph2with chordal3chain components. This includes the case of I=∅.\nOrientations in one chain component do not affect orientations in other components. In other words, to fully\norient any essential graph E(G∗), it is necessary and sufficient to orient every chain component in E(G∗).\nFor any intervention set I ⊆ 2V, we write R(G,I) =A(EI(G))⊆Eto mean the set of oriented arcs in\ntheI-essential graph of a DAG G. For cleaner notation, we write R(G, I) for single interventions I={I}for\nsome I⊆V, and R(G, v) for single atomic interventions I={{v}}for some v∈V. For any interventional\nsetI ⊆2V, define GI=G[E\\R(G,I)] as the fully directed subgraph DAG induced by the unoriented arcs\ninEI(G), where G∅is the graph obtained after removing all the oriented arcs in the observational essential\ngraph due to v-structures. See Fig. 1 for an example. In the notation of R(·,·), the following result justifies\nstudying verification and adaptive search via ideal interventions only on DAGs without v-structures, i.e. moral\nDAGs (Definition 4): since R(G,I) =R(G∅,I)˙∪R(G,∅), any oriented arcs in the observational graph can be\nremoved before performing any interventions as the optimality of the solution is unaffected.4\n2A partially directed graph is a chain graph if it does notcontain any partially directed cycles where all directed arcs point in\nthe same direction along the cycle.\n3A chordal graph is a graph where every cycle of length at least 4 has an edge that is not part of the cycle but connects two\nvertices of the cycle; see [BP93] for an introduction.\n4The notation A˙∪Bdenotes disjoint union of sets AandB.\n3\n\nTheorem 3 ([CS23]) .For any DAG G= (V, E)and intervention sets A,B ⊆2V,\nR(G,A ∪ B ) =R(GA,B)˙∪R(GB,A)˙∪(R(G,A)∩R(G,B))\nDefinition 4 (Moral DAG) .A DAG Gis called a moral DAG if it has no v-structures. So, E(G) = skel( G).\n2.2 Verifying sets\nAverifying set Ifor a DAG G∈[G∗] is an intervention set that fully orients GfromE(G∗), possibly with\nrepeated applications of Meek rules (see Appendix D), i.e. EI(G∗) =G∗. Furthermore, if Iis a verifying set\nforG∗, then so is I ∪Sfor any additional intervention S⊆V. While there may be multiple verifying sets in\ngeneral, we are often interested in finding one with a minimum size.\nDefinition 5 (Minimum size verifying set) .An intervention set I ⊆2Vis called a verifying set for a DAG G∗\nifEI(G∗) =G∗.Iis aminimum size verifying set ifEI′(G∗)̸=G∗for any |I′|<|I|.\nFor bounded size interventions, the minimum verification number νk(G) denotes the size of the minimum\nsize verifying set for any DAG G∈[G∗]; we write ν1(G) for atomic interventions. That is, any revealed\narc directions when performing interventions on E(G∗) respects G. [CSB22] tells us that it is necessary and\nsufficient to intervene on a minimum vertex cover of the covered edges C(G) in order to verify a DAG G, and\nthatν1(G) is efficiently computable given GsinceC(G) induces a forest.\nTheorem 6 ([CSB22]) .Fix an essential graph E(G∗)andG∈[G∗]. An atomic intervention set Iis a minimal\nsized verifying set for Gif and only if Iis a minimum vertex cover of covered edges C(G)ofG. A minimal\nsized atomic verifying set can be computed in polynomial time since the edge-induced subgraph on C(G)is a\nforest.\nFor any DAG G, we use V(G)⊆2Vto denote the set of all atomic verifying sets for G. That is, each\natomic intervention set in V(G) is a minimum vertex cover of C(G).\n2.3 Adaptive search using ideal interventions\nAdaptive search algorithms have been studied in earnest [HG08, HB14, SKDV15, SMG+20, CSB22, CS23] as\nthey can use significantly less interventions than non-adaptive counterparts.5\nMost recently, [CSB22] gave an efficient algorithm for computing adaptive interventions with provable\napproximation guarantees on general graphs.\nTheorem 7 ([CSB22]) .Fix an unknown underlying DAG G∗. Given an essential graph E(G∗)and intervention\nset bound k≥1, there is a deterministic polynomial time algorithm that computes an intervention set I\nadaptively such that EI(G∗) =G∗, and|I|has size\n1.O(log(n)·ν1(G∗))when k= 1\n2.O(log(n)·log(k)·νk(G∗))when k >1.\nMeanwhile, in the context of local causal graph discovery where one is interested in only learning a subset\nof causal relationships, the SubsetSearch algorithm of [CS23] incurs a multiplicative overhead that scales\nlogarithmically with the number of relevant nodes when orienting edges within a node-induced subgraph.\nDefinition 8 (Relevant nodes) .Fix a DAG G∗= (V, E) and arbitrary subset V′⊆V. For any intervention set\nI ⊆2Vand resulting interventional essential graph EI(G∗), we define the relevant nodes ρ(I, V′)⊆V′as the\nset of nodes within V′that is adjacent to some unoriented arc within the node-induced subgraph EI(G∗)[V′].\nFor an example of relevant nodes, see Fig. 1: For the subset V′={A, C, D, E, F }in (II), only {A, C, D }\nare relevant since incident edges to EandFare all oriented.\nTheorem 9 ([CS23]) .Fix an unknown underlying DAG G∗. Given an interventional essential graph EI(G∗),\nnode-induced subgraph Hwith relevant nodes ρ(I, V(H))and intervention set bound k≥1, there is a determin-\nistic polynomial time algorithm that computes an intervention set Iadaptively such that EI∪I′(G∗)[V(H)] =\nG∗[V(H)], and|I′|has size\n1.O(log(|ρ(I, V(H))|)·ν1(G∗))when k= 1\n2.O(log(|ρ(I, V(H))|)·log(k)·νk(G∗))when k >1.\nNote that k= 1 refers to the setting of atomic interventions and we always have 0 ≤ |ρ(I, V(H))| ≤n.\n5If the essential graph E(G∗) is a path of nnodes, then non-adaptive algorithms need Ω( n) atomic interventions to recover G∗\nwhileO(logn) atomic interventions suffices for adaptive search.\n4\n\nA B\nC D\nE\nF(I)A B\nC D\nE\nF(II)A B\nC D\nE\nF(III)A B\nC D\nE\nF(IV)\nFigure 1: (I)Ground truth DAG G∗;(II) Observational essential graph E(G∗) where C→E←Dis a\nv-structure and Meek rules orient arcs D→FandE→F;(III) G∅=G[E\\R(G,∅)] where oriented arcs\ninE(G∗) are removed from G∗;(IV) MPDAG ˜G∈[G∗] incorporating the following partial order advice\n(S1={B}, S2={A, D}, S3={C, E, F }), which can be converted to required arcs B→AandB→D.\nObserve that A→Cis oriented by Meek R1 via B→A∼C, the arc A∼Dis still unoriented, the arc B→A\ndisagrees with G∗, and there are two possible DAGs consistent with the resulting MPDAG.\n2.4 Expert advice in causal graph discovery\nThere are three main types of information that a domain expert may provide (e.g. see the references given in\nSection 1):\n(I) Required parental arcs: X→Y\n(II) Forbidden parental arcs: X̸→Y\n(III) Partial order or tiered knowledge: A partition of the nvariables into 1 ≤t≤nsetsS1, . . . , S tsuch that\nvariables in Sicannot come after Sj, for all i < j .\nIn the context of orienting unoriented X∼Yedges in an essential graph, it suffices to consider only information\nof type (I): X̸→Yimplies Y→X, and a partial order can be converted to a collection of required parental\narcs.6\nMaximally oriented partially directed acyclic graphs (MPDAGs), a refinement of essential graphs under\nadditional causal information, are often used to model such expert advice and there has been a recent growing\ninterest in understanding them better [PKM17, Per20, GP21]. MPDAGs are obtained by orienting additional\narc directions in the essential graph due to background knowledge, and then applying Meek rules. See Fig. 1\nfor an example.\n2.5 Other related work\nCausal Structure Learning Algorithms for causal structure learning can be grouped into three broad cat-\negories, constraint-based, score-based, and Bayesian. Previous works on the first two approaches are described\nin Appendix C. In Bayesian methods, a prior distribution is assumed on the space of all structures, and the\nposterior is updated as more data come in. [Hec95] was one of the first works on learning from interventional\ndata in this context, which spurred a series of papers (e.g. [HGC95, CY99, FK00, HMC06]). Research on\nactive experimental design for causal structure learning with Bayesian updates was initiated by [TK00, TK01]\nand [Mur01]. [MM13] considered a combination of Bayesian and constraint-based approaches. [CBP16] and\n[ASY+19] have used active learning and Bayesian updates to help recover biological networks. While possibly\nimperfect expert advice may be used to guide the prior in the Bayesian approach, the works mentioned above\ndo not provide rigorous guarantees about the number of interventions performed or about optimality, and so\nthey are not directly comparable to our results here.\n6For every edge X∼Ywith X∈SiandY∈Sj, enforce the required parental arc X→Yif and only if i < j .\n5\n\nAlgorithms with predictions Learning-augmented algorithms have received significant attention since\nthe seminal work of [LV21], where they investigated the online caching problem with predictions. Based on\nthat model, [PSK18] proposed algorithms for the ski-rental problem as well as non-clairvoyant scheduling.\nSubsequently, [GP19], [WLW20], and [ADJ+20] improved the initial results for the ski-rental problem. Sev-\neral works, including [Roh20, ACE+20, Wei20], improved the initial results regarding the caching problem.\nScheduling problems with machine-learned advice have been extensively studied in the literature [LLMV20,\nBMRS20, AJS22]. There are also results for augmenting classical data structures with predictions (e.g. in-\ndexing [KBC+18] and Bloom filters [Mit18]), online selection and matching problems [AGKK20, DLPLV21],\nonline TSP [BLMS+22, GLS23], and a more general framework of online primal-dual algorithms [BMS20].\nIn the above line of work, the extent to which the predictions are helpful in the design of the corresponding\nonline algorithms, is quantified by the following two properties. The algorithm is called (i) α-consistent if\nit isα-competitive with no prediction error and (ii) β-robust if it is β-competitive with any prediction error.\nIn the language of learning augmented algorithms or algorithms with predictions, our causal graph discovery\nalgorithm is 1-consistent and O(logn)-robust when competing against the verification number ν1(G∗), the\nminimum number of interventions necessary needed to recover G∗. Note that even with arbitrarily bad advice,\nour algorithm uses asymptotically the same number of interventions incurred by the best-known advice-free\nadaptive search algorithm [CSB22].\n3 Results\nOur exposition here focuses on interpreting and contextualizing our main results while deferring technicalities\nto Section 4. We first focus on the setting where the advice is a fully oriented DAG eG∈[G∗] within the Markov\nequivalence class [ G∗] of the true underlying causal graph G∗, and explain in Appendix E how to handle the\ncase of partial advice. Full proofs are provided in the appendix.\n3.1 Structural property of verification numbers\nWe begin by stating a structural result about verification numbers of DAGs within the same Markov equivalence\nclass (MEC) that motivates the definition of a metric between DAGs in the same MEC our algorithmic\nguarantees (Theorem 14) are based upon.\nTheorem 10. For any DAG G∗with MEC [ G∗], we have that max G∈[G∗]ν1(G)≤2·minG∈[G∗]ν1(G).\nTheorem 10 is the first known result relating the minimum and maximum verification numbers of DAGs\ngiven a fixed MEC. The next result tells us that the ratio of two is tight.\nLemma 11 (Tightness of Theorem 10) .There exist DAGs G1andG2from the same MEC with ν1(G1) =\n2·ν1(G2).\nTheorem 10 tells us that we can blindly intervene on any minimum verifying set eV∈ V(eG) of any given\nadvice DAG eGwhile incurring only at most a constant factor of 2 more interventions than the minimum\nverification number ν(G∗) of the unknown ground truth DAG G∗.\n3.2 Adaptive search with imperfect DAG advice\nRecall the definition of r-hop from Section 2. To define the quality of the advice DAG eG, we first define the\nnotion of min-hop-coverage which measures how “far” a given verifying set of eGis from the set of covered edges\nofG∗.\nDefinition 12 (Min-hop-coverage) .Fix a DAG G∗with MEC [ G∗] and consider any DAG eG∈[G∗]. For any\nminimum verifying set eV∈ V(eG), we define the min-hop-coverage h(G∗,eV)∈ {0,1,2, . . . , n }as the minimum\nnumber of hops such that both endpoints of covered edges C(G∗) ofG∗belong in Nh(G∗,eV)\nskel(E(G∗))(eV).\nUsing min-hop-coverage, we now define a quality measure ψ(G∗,eG) for DAG eG∈[G∗] as an advice for\nDAG G∗.\n6\n\na c\nbd\nezn . . . z2 z1\nG∗a c\nbd\nezn . . . z2 z1\neG\nFigure 2: Consider the moral DAGs G∗andeG∈[G∗] onn+ 5 nodes, where dashed arcs represent the covered\nedges in each DAG. A minimum sized verifying set eV={a, e, z 2} ∈ V (eG) ofeGis given by the boxed vertices\non the right. As N1\nskel(G∗)(eV) ={a, b, c, d, e, z 1, z2, z3}includes both endpoints of all covered edges of G∗, we\nsee that h(G∗,eV) = 1. Intervening on eV={a, e, z 2}inG∗orients the arcs b→a←c,c←e→d, and\nz3→z2→z1respectively which then triggers Meek R1 to orient c→bviae→c∼band to orient z4→z3\nviae→c→. . .→z4∼z3(after a few invocations of R1), so {a, b, e, z 1, z2, z3}willnotbe relevant nodes\ninEeV(G∗). Meanwhile, the edge c∼dremains unoriented in EeV(G∗), so ρ(eV , N1\nskel(G∗)(eV)) =|{c, d}|= 2.\nOne can check that ψ(G∗,eG) = 2 while ncould be arbitrarily large. On the other hand, observe that ψis\nnotsymmetric: in the hypothetical situation where we use G∗as an advice for eG, the min-hop-coverage has\nto extend along the chain z1∼. . .∼znto reach {z1, z2}, soh(G∗, V∗)≈nandψ(eG, G∗)≈nsince the entire\nchain remains unoriented with respect to any V∗∈ V(G∗).\nDefinition 13 (Quality measure) .Fix a DAG G∗with MEC [ G∗] and consider any DAG eG∈[G∗]. We define\nψ(G∗,eG) as follows:\nψ(G∗,eG) = max\neV∈V(eG)\f\f\fρ\u0010\neV , Nh(G∗,eV)\nskel(E(G∗))(eV)\u0011\f\f\f\nBy definition, ψ(G∗, G∗) = 0 and max G∈[G∗]ψ(G∗, G)≤n. In words, ψ(G∗,eG) only counts the relevant\nnodes within the min-hop-coverage neighborhood after intervening on the worst possible verifying set eVofeG.\nWe define ψvia the worst set because any search algorithm cannot evaluate h(G∗,eV), since G∗is unknown,\nand can only consider an arbitrary eV∈ V(eG). See Fig. 2 for an example.\nOur main result is that it is possible to design an algorithm that leverages an advice DAG eG∈[G∗] and\nperforms interventions to fully recover an unknown underlying DAG G∗, whose performance depends on the\nadvice quality ψ(G∗,eG). Our search algorithm only knows E(G∗) andeG∈[G∗] but knows neither ψ(G∗,eG)\nnorν(G∗).\nTheorem 14. Fix an essential graph E(G∗) with an unknown underlying ground truth DAG G∗. Given an\nadvice graph eG∈[G∗] and intervention set bound k≥1, there exists a deterministic polynomial time algorithm\n(Algorithm 1) that computes an intervention set Iadaptively such that EI(G∗) =G∗, and|I|has size\n1.O(max{1,logψ(G∗,eG)} ·ν1(G∗)) when k= 1\n2.O(max{1,logψ(G∗,eG)} ·logk·νk(G∗)) when k >1.\nConsider first the setting of k= 1. Observe that when the advice is perfect (i.e. eG=G∗), we use\nO(ν(G∗)) interventions, i.e. a constant multiplicative factor of the minimum number of interventions necessary.\nMeanwhile, even with low quality advice, we still use O(logn·ν(G∗)) interventions, asymptotically matching\nthe best known guarantees for adaptive search without advice. To the best of our knowledge, Theorem 14 is\nthe first known result that principally employs imperfect expert advice with provable guarantees in the context\nof causal graph discovery via interventions.\nConsider now the setting of bounded size interventions where k >1. The reason why we can obtain such\na result is precisely because of our algorithmic design: we deliberately designed an algorithm that invokes\nSubsetSearch as a black-box subroutine. Thus, the bounded size guarantees of SubsetSearch given by\nTheorem 9 carries over to our setting with a slight modification of the analysis.\n7\n\n4 Techniques\nHere, we discuss the high-level technical ideas and intuition behind how we obtain our adaptive search algorithm\nwith imperfect DAG advice. See the appendix for full proofs; in particular, see Appendix F for an overview of\nTheorem 10.\nFor brevity, we write ψto mean ψ(G∗,eG) and drop the subscript skel( E(G∗)) ofr-hop neighborhoods in this\nsection. We also focus our discussion to the atomic interventions. Our adaptive search algorithm (Algorithm 1)\nuses SubsetSearch as a subroutine.\nWe begin by observing that SubsetSearch (E(G∗), A) fully orients E(G∗) into G∗if the covered edges of G∗\nlie within the node-induced subgraph induced by A.\nLemma 15. Fix a DAG G∗= (V, E) and let V′⊆Vbe any subset of vertices. Suppose IV′⊆Vis the set of\nnodes intervened by SubsetSearch (E(G∗), V′). IfC(G∗)⊆E(G∗[V′]), then EIV′(G∗) =G∗.\nMotivated by Lemma 15, we design Algorithm 1 to repeatedly invoke SubsetSearch on node-induced\nsubgraphs Nr(eV), starting from an arbitrary verifying set eV∈ V(eG) and for increasing values of r.\nFori∈N∪{0}, let us denote r(i)∈N∪{0}as the value of rin the i-th invocation of SubsetSearch , where\nwe insist that r(0) = 0 and r(j)> r(j−1) for any j∈N. Note that r= 0 simply implies that we intervene\non the verifying set eV, which only incurs O(ν1(G∗)) interventions due to Theorem 10. Then, we can appeal to\nLemma 15 to conclude that E(G∗) is completely oriented into G∗in the t-th invocation if r(t)≥h(G∗,eV).\nWhile the high-level subroutine invocation idea seems simple, one needs to invoke SubsetSearch atsuitably\nchosen intervals in order to achieve our theoretical guarantees we promise in Theorem 14. We now explain\nhow to do so in three successive attempts while explaining the algorithmic decisions behind each modification\nintroduced.\nAs a reminder, we do not know G∗and thus do not know h(G∗,eV) for any verifying set eV∈ V(eG) of\neG∈[G∗].\nNaive attempt: Invoke for r= 0,1,2,3, . . .\nThe most straightforward attempt would be to invoke SubsetSearch repeatedly each time we increase rby 1\nuntil the graph is fully oriented – in the worst case, t=h(G∗,eV). However, this may cause us to incur way\ntoo many interventions. Suppose there are nirelevant nodes in the i-th invocation. Using Theorem 9, one can\nonly argue that the overall number interventions incurred is O(Pt\ni=0logni·ν(G∗)). However,P\nilognicould\nbe significantly larger than log(P\nini) in general, e.g. log 2 + . . .+ log 2 = ( n/2)·log 2≫logn. In fact, if G∗\nwas a path on nvertices v1→v2→. . .→vnandeG∈[G∗] misleads us with v1←v2←. . .←vn, then this\napproach incurs Ω( n) interventions in total.\nTweak 1: Only invoke periodically\nSince Theorem 9 provides us a logarithmic factor in the analysis, we could instead consider only invoking\nSubsetSearch after the number of nodes in the subgraph increases by a polynomial factor . For example, if we\ninvoked SubsetSearch with nipreviously, then we will wait until the number of relevant nodes surpasses n2\ni\nbefore invoking SubsetSearch again, where we define n0≥2 for simplicity. Since log ni≥2 logni−1, we can\nsee via an inductive argument that the number of interventions used in the final invocation will dominate the\ntotal number of interventions used so far: nt≥2 lognt−1≥lognt−1+ 2 log nt−2≥. . .≥Pt−1\ni=0logni. Since\nni≤nfor any i, we can already prove that O(logn·ν1(G∗)) interventions suffice, matching the advice-free\nbound of Theorem 7. However, this approach and analysis does nottake into account the quality of eGand is\ninsufficient to relate ntwith the advice measure ψ.\nTweak 2: Also invoke one round before\nSuppose the final invocation of SubsetSearch is on r(t)-hop neighborhood while incurring O(lognt·ν1(G∗))\ninterventions. This means that C(G∗) lies within Nr(t)(eV) but notwithin Nr(t−1)(eV). That is, Nr(t−1)(eV)⊊\nNh(G∗,eV)(eV)⊆Nr(t)(eV). While this tells us that nt−1≤ |ρ(eV , Nr(t−1)(eV))|<|ρ(eV , Nh(G∗,eV)(eV))|=ψ, what\nwe want is to conclude that nt∈ O(ψ). Unfortunately, even when ψ=r(t−1) + 1, it could be the case\nthat|ρ(eV , Nh(G∗,eV)(eV))| ≪ |Nr(t)(eV)|as the number of relevant nodes could blow up within a single hop (see\nFig. 3). To control this potential blow up in the analysis, we can introduce the following technical fix: whenever\n8\n\nv1 v2 v3v4\nv5\n...\nvnG∗\nv1 v2 v3v4\nv5\n...\nvneG\neV={v1}\nFigure 3: Consider the ground truth DAG G∗with unique minimum verifying set {v2}and an advice DAG\neG∈[G∗] with chosen minimum verifying set eV={v1}. So, h(G∗,eV) = 1 and ideally we want to argue that our\nalgorithm uses a constant number of interventions. Without tweak 2 and n0= 2, an algorithm that increases\nhop radius until the number of relevant nodes is squared will notinvoke SubsetSearch until r= 3 because\nρ(eV , N1) = 1 < n2\n0andρ(eV , N2) = 2 < n2\n0. However, ρ(eV , N3) =n−1 and we can only conclude that the\nalgorithm uses O(logn) interventions by invoking SubsetSearch on a subgraph on n−1 nodes.\nwe want to invoke SubsetSearch onr(i), first invoke SubsetSearch onr(i)−1 and terminate earlier if the\ngraph is already fully oriented into G∗.\nPutting together\nAlgorithm 1 presents our full algorithm where the inequality ρ(Ii, Nr\nskel(E(G∗))(eV))≥n2\nicorresponds to the\nfirst tweak while the terms CiandC′\nicorrespond to the second tweak.\nIn Appendix H, we explain why our algorithm (Algorithm 1) is simply the classic “binary search with\nprediction”7when the given essential graph E(G∗) is an undirected path. So, another way to view our result\nis ageneralization that works on essential graphs of arbitrary moral DAGs.\nFor bounded size interventions, we rely on the following known results.\nTheorem 16 (Theorem 12 of [CSB22]) .Fix an essential graph E(G∗)andG∈[G∗]. If ν1(G) =ℓ, then\nνk(G)≥ ⌈ℓ\nk⌉and there exists a polynomial time algo. to compute a bounded size intervention set Iof size\n|I| ≤ ⌈ℓ\nk⌉+ 1.\nLemma 17 (Lemma 1 of [SKDV15]) .Let(n, k, a )be parameters where k≤n/2. There exists a polynomial\ntime labeling scheme that produces distinct ℓlength labels for all elements in [n]using letters from the integer\nalphabet {0} ∪[a]where ℓ=⌈logan⌉. Further, in every digit (or position), any integer letter is used at most\n⌈n/a⌉times. This labelling scheme is a separating system: for any i, j∈[n], there exists some digit d∈[ℓ]\nwhere the labels of iandjdiffer.\nTheorem 16 enables us to easily relate ν1(G) with νk(G) while Lemma 17 provides an efficient labelling\nscheme to partition a set of nnodes into a set S={S1, S2, . . .}of bounded size sets, each Siinvolving at most\nknodes. By invoking Lemma 17 with a≈n′/kwhere n′is related to ν1(G), we see that |S| ≈n′\nk·logk. As\nνk(G)≈ν1(G)/k, this is precisely why the bounded intervention guarantees in Theorem 7, Theorem 9 and\nTheorem 14 have an additional multiplicative log kfactor.\n5 Empirical validation\nWhile our main contributions are theoretical, we also performed some experiments to empirically validate that\nour algorithm is practical, outperforms the advice-free baseline when the advice quality is good, and still being\nat most a constant factor worse when the advice is poor.\nMotivated by Theorem 3, we experimented on synthetic moral DAGs from [WBL21b]: For each undi-\nrected chordal graph, we use the uniform sampling algorithm of [WBL21b] to uniformly sample 1000 moral\nDAGs eG1, . . . ,eG1000and randomly choose one of them as G∗. Then, we give {(E(G∗),eGi)}i∈[1000] as input to\nAlgorithm 1.\n7e.g. see https://en.wikipedia.org/wiki/Learning_augmented_algorithm#Binary_search\n9\n\nAlgorithm 1 Adaptive search algorithm with advice.\nInput : Essential graph E(G∗), advice DAG eG∈[G∗], intervention size k∈N\nOutput : An intervention set Isuch that each intervention involves at most knodes and EI(G∗) =G∗.\n1:LeteV∈ V(eG) be any atomic verifying set of eG.\n2:ifk= 1then\n3: Define I0=eVas an atomic intervention set.\n4:else\n5: Define k′= min {k,|eV|/2},a=⌈|eV|/k′⌉ ≥2, and ℓ=⌈loga|C|⌉. Compute labelling scheme on eVwith\n(|eV|, k, a) via Lemma 17 and define I0={Sx,y}x∈[ℓ],y∈[a], where Sx,y⊆eVis the subset of vertices whose\nxthletter in the label is y.\n6:end if\n7:Intervene on I0and initialize r←0,i←0,n0←2.\n8:while EIi(G∗) still has undirected edges do\n9: ifρ(Ii, Nr\nskel(E(G∗))(eV))≥n2\nithen\n10: Increment i←i+ 1 and record r(i)←r.\n11: Update ni←ρ(Ii, Nr\nskel(E(G∗))(eV))\n12: Ci←SubsetSearch (EIi(G∗), Nr−1\nskel(E(G∗))(eV), k)\n13: ifEIi−1∪Ci(G∗) still has undirected edges then\n14: C′\ni←SubsetSearch (EIi−1∪Ci(G∗), Nr\nskel(E(G∗))(eV), k)\n15: Update Ii← I i−1∪Ci∪C′\ni.\n16: else\n17: Update Ii← I i−1∪Ci.\n18: end if\n19: end if\n20: Increment r←r+ 1.\n21:end while =\n22:return Ii\nFig. 4 shows one of the experimental plots; more detailed experimental setup and results are given in\nAppendix I. On the X-axis, we plot ψ(G∗,eV) =\f\f\fρ\u0010\neV , Nh(G∗,eV)\nskel(E(G∗))(eV)\u0011\f\f\f, which is a lower bound and proxy8\nforψ(G∗,eG). On the Y-axis, we aggregate advice DAGs based on their quality measure and also show (in\ndashed lines) the empirical distribution of quality measures of all DAGs within the Markov equivalence class.\nAs expected from our theoretical analyses, we see that the number of interventions by our advice search\nstarts from ν1(G∗), is lower than advice-free search of [CSB22] when ψ(G∗,eV) is low, and gradually increases\nas the advice quality degrades. Nonetheless, the number of interventions used is always theoretically bounded\nbelow O(ψ(G∗,eV)·ν1(G∗)); we do not plot ψ(G∗,eV)·ν1(G∗) since plotting it yields a “squashed” graph as\nthe empirical counts are significantly smaller. In this specific graph instance, Fig. 4 suggests that our advice\nsearch outperforms its advice-free counterpart when given an advice DAG eGthat is better than ∼40% of all\npossible DAGs consistent with the observational essential graph E(G∗).\n6 Conclusion and discussion\nIn this work, we gave the first result that utilizes imperfect advice in the context of causal discovery. We do\nso in a way that the performance (i.e. the number of interventions in our case) does not degrade significantly\neven when the advice is inaccurate, which is consistent with the objectives of learning-augmented algorithms.\nSpecifically, we show a smooth bound that matches the number of interventions needed for verification of\nthe causal relationships in a graph when the advice is completely accurate and also depends logarithmically\non the distance of the advice to the ground truth. This ensures robustness to “bad” advice, the number of\ninterventions needed is asymptotically the same as in the case where no advice is available.\nOur results do rely on the widely-used assumptions of sufficiency and faithfulness as well as access to ideal\n8We do not know if there is an efficient way to compute ψ(G∗,eG) besides the naive (possibly exponential time) enumeration\nover all possible minimum verifying sets.\n10\n\nFigure 4: Experimental plot for one of the synthetic graphs G∗, with respect to 1000 ≪ |[G∗]| ≈1.4×\n106uniformly sampled advice DAGs eGfrom the MEC [ G∗]. The solid lines indicate the number of atomic\ninterventions used while the dotted lines indicate the empirical cumulative probability density of eG. The true\ncumulative probability density lies within the shaded area with probability at least 0.99 (see Appendix I for\ndetails).\niterventions; see Appendix A for a more detailed discussion. Since wrong causal conclusions may be drawn when\nthese assumptions are violated by the data, thus it is of great interest to remove/weaken these assumptions\nwhile maintaining strong theoretical guarantees in future work.\n6.1 Interesting future directions to explore\nPartial advice In Appendix E, we explain why having a DAG eGas advice may not always be possible and\nexplain how to extend our results to the setting of partial advice by considering the worst case DAG consistent\nwith the given partial advice A. The question is whether one can design and analyze a better algorithm than\na trivial max eG∈A. For example, maybe one could pick eG= argminG∈Amax H∈[G∗]ψ(H, G)? The motivation is\nas follows: If [ G∗] is a disc in R2andψis the Euclidean distance, then eGshould be the point within Athat is\nclosest to the center of the disc. Note that we can only optimize with respect to max H∈[G∗]because we do not\nactually know G∗. It remains to be seen if such an object can be efficiently computed and whether it gives a\nbetter bound than max eG∈A.\nIncorporating expert confidence The notion of “confidence level” and “correctness” of an advice are\northogonal issues – an expert can be confidently wrong. In this work, we focused on the case where the expert\nis fully confident but may be providing imperfect advice. It is an interesting problem to investigate how to\nprincipally handle both issues simultaneously; for example, what if the advice is not a DAG eG∈[G∗] in the\nessential graph but a distribution over all DAGs in [ G∗]? Bayesian ideas may apply here.\nBetter analysis? Empirically, we see that the log factor is a rather loose upper bound both for blind search\nand advice search. Can there be a tighter analysis? [CSB22] tells us that Ω(log n·ν1(G∗)) is unavoidable when\nE(G∗) is a path on nvertices with ν1(G∗) = 1 but this is a special class of graphs. What if ν1(G∗)>1? Can\nwe give tighter bounds in other graph parameters? Furthermore, in some preliminary testing, we observed that\nimplementing tweak 2 or ignoring it yield similar empirical performance and we wonder if there is a tighter\nanalysis without tweak 2 that has similar guarantees.\n11\n\nAcknowledgements\nThis research/project is supported by the National Research Foundation, Singapore under its AI Singapore\nProgramme (AISG Award No: AISG-PhD/2021-08-013). TG and AB are supported by the National Research\nFoundation Fellowship for AI (Award NRF-NRFFAI-0002), an Amazon Research Award, and a Google South\n& Southeast Asia Research Award. Part of this work was done while the authors were visiting the Simons\nInstitute for the Theory of Computing. We would like to thank Kirankumar Shiragur and Joy Qiping Yang\nfor valuable feedback and discussions.\nReferences\n[ACE+20] Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, and Bertrand Simon. Online\nMetric Algorithms with Untrusted Predictions. In International Conference on Machine Learning ,\npages 345–355. PMLR, 2020.\n[ADJ+20] Spyros Angelopoulos, Christoph D¨ urr, Shendan Jin, Shahin Kamali, and Marc Renault. On-\nline Computation with Untrusted Advice. In 11th Innovations in Theoretical Computer Science\nConference (ITCS 2020) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2020.\n[AGKK20] Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and Online\nMatching Problems with Machine Learned Advice. Advances in Neural Information Processing\nSystems , 33:7933–7944, 2020.\n[AJS22] Antonios Antoniadis, Peyman Jabbarzade, and Golnoosh Shahkarami. A Novel Prediction Setup\nfor Online Speed-Scaling. In 18th Scandinavian Symposium and Workshops on Algorithm Theory\n(SWAT 2022) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2022.\n[AMP97] Steen A. Andersson, David Madigan, and Michael D. Perlman. A characterization of Markov\nequivalence classes for acyclic digraphs. The Annals of Statistics , 25(2):505–541, 1997.\n[And13] Holly Andersen. When to expect violations of causal faithfulness and why it matters. Philosophy\nof Science , 80(5):672–683, 2013.\n[ASC20] Bryan Andrews, Peter Spirtes, and Gregory F Cooper. On the Completeness of Causal Discovery\nin the Presence of Latent Confounding with Tiered Background Knowledge. In International\nConference on Artificial Intelligence and Statistics , pages 4002–4011. PMLR, 2020.\n[ASY+19] Raj Agrawal, Chandler Squires, Karren Yang, Karthikeyan Shanmugam, and Caroline Uhler.\nABCD-Strategy: Budgeted Experimental Design for Targeted Causal Structure Discovery. In\nInternational Conference on Artificial Intelligence and Statistics , pages 3400–3409. PMLR, 2019.\n[BLMS+22] Giulia Bernardini, Alexander Lindermayr, Alberto Marchetti-Spaccamela, Nicole Megow, Leen\nStougie, and Michelle Sweering. A Universal Error Measure for Input Predictions Applied to\nOnline Graph Problems. In Advances in Neural Information Processing Systems , 2022.\n[BMRS20] ´Etienne Bamas, Andreas Maggiori, Lars Rohwedder, and Ola Svensson. Learning Augmented\nEnergy Minimization via Speed Scaling. Advances in Neural Information Processing Systems ,\n33:15350–15359, 2020.\n[BMS20] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The Primal-Dual method for Learning\nAugmented Algorithms. Advances in Neural Information Processing Systems , 33:20083–20094,\n2020.\n[BP93] Jean R. S. Blair and Barry W. Peyton. An introduction to chordal graphs and clique trees. In\nGraph theory and sparse matrix computation , pages 1–29. Springer, 1993.\n[Can20] Cl´ ement L Canonne. A short note on learning discrete distributions. arXiv preprint\narXiv:2002.11457 , 2020.\n[CBP16] Hyunghoon Cho, Bonnie Berger, and Jian Peng. Reconstructing Causal Biological Networks\nthrough Active Learning. PLoS ONE , 11(3):e0150611, 2016.\n12\n\n[Chi95] David Maxwell Chickering. A Transformational Characterization of Equivalent Bayesian Network\nStructures. In Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence ,\nUAI’95, page 87–98, San Francisco, CA, USA, 1995. Morgan Kaufmann Publishers Inc.\n[Chi02] David Maxwell Chickering. Optimal Structure Identification with Greedy Search. Journal of\nMachine Learning Research , 3:507–554, 2002.\n[CLO07] James Clause, Wanchun Li, and Alessandro Orso. Dytan: A Generic Dynamic Taint Analysis\nFramework. In Proceedings of the 2007 international symposium on Software testing and analysis ,\npages 196–206, 2007.\n[CMKR12] Diego Colombo, Marloes H. Maathuis, Markus Kalisch, and Thomas S. Richardson. Learning high-\ndimensional directed acyclic graphs with latent and selection variables. The Annals of Statistics ,\npages 294–321, 2012.\n[CS23] Davin Choo and Kirankumar Shiragur. Subset verification and search algorithms for causal DAGs.\nInInternational Conference on Artificial Intelligence and Statistics , 2023.\n[CSB22] Davin Choo, Kirankumar Shiragur, and Arnab Bhattacharyya. Verification and search algorithms\nfor causal DAGs. Advances in Neural Information Processing Systems , 35, 2022.\n[CY99] Gregory F. Cooper and Changwon Yoo. Causal Discovery from a Mixture of Experimental and\nObservational Data. In Proceedings of the Fifteenth conference on Uncertainty in artificial intel-\nligence , pages 116–125, 1999.\n[DCJ11] Cassio P De Campos and Qiang Ji. Efficient Structure Learning of Bayesian Networks using\nConstraints. The Journal of Machine Learning Research , 12:663–689, 2011.\n[DLPLV21] Paul D¨ utting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with Advice.\nInProceedings of the 22nd ACM Conference on Economics and Computation , pages 409–429, 2021.\n[Ebe07] Frederick Eberhardt. Causation and Intervention. Unpublished doctoral dissertation, Carnegie\nMellon University , page 93, 2007.\n[Ebe10] Frederick Eberhardt. Causal Discovery as a Game. In Causality: Objectives and Assessment ,\npages 87–96. PMLR, 2010.\n[EGS05] Frederick Eberhardt, Clark Glymour, and Richard Scheines. On the number of experiments suf-\nficient and in the worst case necessary to identify all causal relations among N variables. In\nProceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence , pages 178–\n184, 2005.\n[EGS06] Frederick Eberhardt, Clark Glymour, and Richard Scheines. N-1 Experiments Suffice to Determine\nthe Causal Relations Among N Variables. In Innovations in machine learning , pages 97–112.\nSpringer, 2006.\n[ES07] Frederick Eberhardt and Richard Scheines. Interventions and Causal Inference. Philosophy of\nscience , 74(5):981–995, 2007.\n[FH20] Zhuangyan Fang and Yangbo He. IDA with Background Knowledge. In Conference on Uncertainty\nin Artificial Intelligence , pages 270–279. PMLR, 2020.\n[FK00] Nir Friedman and Daphne Koller. Being Bayesian about Network Structure. In Proceedings of the\n16th Conference on Uncertainty in Artificial Intelligence , pages 201–210, 2000.\n[FNB+11] M Julia Flores, Ann E Nicholson, Andrew Brunskill, Kevin B Korb, and Steven Mascaro. In-\ncorporating expert knowledge when learning Bayesian network structure: A medical case study.\nArtificial intelligence in medicine , 53(3):181–204, 2011.\n[GKS+19] Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Kocaoglu,\nEnric Boix-Adser` a, and Guy Bresler. Sample Efficient Active Learning of Causal Trees. Advances\nin Neural Information Processing Systems , 32, 2019.\n13\n\n[GLS23] Themis Gouleakis, Konstantinos Lakis, and Golnoosh Shahkarami. Learning-Augmented Algo-\nrithms for Online TSP on the Line. In 37th AAAI Conference on Artificial Intelligence . AAAI,\n2023.\n[GP19] Sreenivas Gollapudi and Debmalya Panigrahi. Online Algorithms for Rent-or-Buy with Expert\nAdvice. In International Conference on Machine Learning , pages 2319–2327. PMLR, 2019.\n[GP21] Richard Guo and Emilija Perkovic. Minimal Enumeration of All Possible Total Effects in a Markov\nEquivalence Class. In International Conference on Artificial Intelligence and Statistics , pages\n2395–2403. PMLR, 2021.\n[GRE84] John R Gilbert, Donald J Rose, and Anders Edenbrandt. A separator theorem for chordal graphs.\nSIAM Journal on Algebraic Discrete Methods , 5(3):306–313, 1984.\n[HB12] Alain Hauser and Peter B¨ uhlmann. Characterization and Greedy Learning of Interventional\nMarkov Equivalence Classes of Directed Acyclic Graphs. The Journal of Machine Learning Re-\nsearch , 13(1):2409–2464, 2012.\n[HB14] Alain Hauser and Peter B¨ uhlmann. Two Optimal Strategies for Active Learning of Causal Models\nfrom Interventions. International Journal of Approximate Reasoning , 55(4):926–939, 2014.\n[Hec95] David Heckerman. A Bayesian Approach to Learning Causal Networks. In Proceedings of the\nEleventh conference on Uncertainty in artificial intelligence , pages 285–295, 1995.\n[HEH13] Antti Hyttinen, Frederick Eberhardt, and Patrik O. Hoyer. Experiment Selection for Causal\nDiscovery. Journal of Machine Learning Research , 14:3041–3071, 2013.\n[HG08] Yang-Bo He and Zhi Geng. Active Learning of Causal Networks with Intervention Experiments\nand Optimal Designs. Journal of Machine Learning Research , 9:2523–2547, 2008.\n[HGC95] David Heckerman, Dan Geiger, and David M. Chickering. Learning Bayesian Networks: The\nCombination of Knowledge and Statistical Data . Machine learning , 20:197–243, 1995.\n[HLV14] Huining Hu, Zhentao Li, and Adrian Vetta. Randomized Experimental Design for Causal Graph\nDiscovery. Advances in Neural Information Processing Systems , 27, 2014.\n[HMC06] David Heckerman, Christopher Meek, and Gregory Cooper. A Bayesian Approach to Causal\nDiscovery. Innovations in Machine Learning , pages 1–28, 2006.\n[Hoo90] Kevin D Hoover. The logic of causal inference: Econometrics and the Conditional Analysis of\nCausation. Economics & Philosophy , 6(2):207–234, 1990.\n[ICM+22] Muhammad Azam Ikram, Sarthak Chakraborty, Subrata Mitra, Shiv Saini, Saurabh Bagchi, and\nMurat Kocaoglu. Root Cause Analysis of Failures in Microservices through Causal Discovery. In\nAdvances in Neural Information Processing Systems , 2022.\n[JBT+19] Saurabh Jha, Subho Banerjee, Timothy Tsai, Siva KS Hari, Michael B Sullivan, Zbigniew T\nKalbarczyk, Stephen W Keckler, and Ravishankar K Iyer. ML-based Fault Injection for Au-\ntonomous Vehicles: A Case for Bayesian Fault Injection. In 2019 49th annual IEEE/IFIP inter-\nnational conference on dependable systems and networks (DSN) , pages 112–124. IEEE, 2019.\n[KBC+18] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The Case for Learned\nIndex Structures. In Proceedings of the 2018 international conference on management of data ,\npages 489–504, 2018.\n[KDV17] Murat Kocaoglu, Alex Dimakis, and Sriram Vishwanath. Cost-Optimal Learning of Causal\nGraphs. In International Conference on Machine Learning , pages 1875–1884. PMLR, 2017.\n[KWJ+04] Ross D. King, Kenneth E. Whelan, Ffion M. Jones, Philip G. K. Reiser, Christopher H. Bryant,\nStephen H. Muggleton, Douglas B. Kell, and Stephen G. Oliver. Functional genomic hypothesis\ngeneration and experimentation by a robot scientist. Nature , 427(6971):247–252, 2004.\n14\n\n[LB18] Andrew Li and Peter Beek. Bayesian Network Structure Learning with Side Constraints. In\nInternational conference on probabilistic graphical models , pages 225–236. PMLR, 2018.\n[LKDV18] Erik M. Lindgren, Murat Kocaoglu, Alexandros G. Dimakis, and Sriram Vishwanath. Experimen-\ntal Design for Cost-Aware Learning of Causal Graphs. Advances in Neural Information Processing\nSystems , 31, 2018.\n[LLMV20] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online Scheduling\nvia Learned Weights. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete\nAlgorithms , pages 1859–1877. SIAM, 2020.\n[LV21] Thodoris Lykouris and Sergei Vassilvitskii. Competitive Caching with Machine Learned Advice.\nJournal of the ACM (JACM) , 68(4):1–25, 2021.\n[Mee95a] Christopher Meek. Causal Inference and Causal Explanation with Background Knowledge. In\nProceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence , UAI’95, page\n403–410, San Francisco, CA, USA, 1995. Morgan Kaufmann Publishers Inc.\n[Mee95b] Christopher Meek. Strong completeness and faithfulness in Bayesian networks. In Proceedings of\nthe Eleventh conference on Uncertainty in artificial intelligence , pages 411–418, 1995.\n[Mit18] Michael Mitzenmacher. A Model for Learned Bloom Filters, and Optimizing by Sandwiching.\nAdvances in Neural Information Processing Systems , 31, 2018.\n[MM13] Andr´ es R Masegosa and Seraf´ ın Moral. An interactive approach for Bayesian network learning\nusing domain/expert knowledge. International Journal of Approximate Reasoning , 54(8):1168–\n1181, 2013.\n[Mur01] Kevin P Murphy. Active Learning of Causal Bayes Net Structure. Technical report, UC Berkeley,\n2001.\n[MV22] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with Predictions. Communications of\nthe ACM , 65(7):33–35, 2022.\n[Pea09] Judea Pearl. Causality: Models, Reasoning and Inference . Cambridge University Press, USA, 2nd\nedition, 2009.\n[Per20] Emilija Perkovic. Identifying causal effects in maximally oriented partially directed acyclic graphs.\nInConference on Uncertainty in Artificial Intelligence , pages 530–539. PMLR, 2020.\n[PKM17] Emilija Perkovic, Markus Kalisch, and Marloes H Maathuis. Interpreting and using CPDAGs\nwith background knowledge. In Proceedings of the 2017 Conference on Uncertainty in Artificial\nIntelligence (UAI2017) , pages ID–120. AUAI Press, 2017.\n[POS+18] Jean-Baptiste Pingault, Paul F O’reilly, Tabea Schoeler, George B Ploubidis, Fr¨ uhling Rijsdijk,\nand Frank Dudbridge. Using genetic data to strengthen causal inference in observational research.\nNature Reviews Genetics , 19(9):566–580, 2018.\n[PSK18] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving Online Algorithms via ML Predic-\ntions. Advances in Neural Information Processing Systems , 31, 2018.\n[Rei56] Hans Reichenbach. The Direction of Time , volume 65. University of California Press, 1956.\n[RHT+17] Maya Rotmensch, Yoni Halpern, Abdulhakim Tlimat, Steven Horng, and David Sontag. Learning\na Health Knowledge Graph from Electronic Medical Records. Scientific reports , 7(1):1–11, 2017.\n[Roh20] Dhruv Rohatgi. Near-Optimal Bounds for Online Caching with Machine Learned Advice. In\nProceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms , pages 1834–\n1845. SIAM, 2020.\n[RW06] Donald B Rubin and Richard P Waterman. Estimating the Causal Effects of Marketing Interven-\ntions Using Propensity Score Methodology. Statistical Science , pages 206–222, 2006.\n15\n\n[SC17] Yuriy Sverchkov and Mark Craven. A review of active learning approaches to experimental design\nfor uncovering biological networks. PLoS computational biology , 13(6):e1005466, 2017.\n[SGSH00] Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, Prediction,\nand Search . MIT press, 2000.\n[SKDV15] Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G. Dimakis, and Sriram Vishwanath.\nLearning Causal Graphs with Small Interventions. Advances in Neural Information Processing\nSystems , 28, 2015.\n[SMG+20] Chandler Squires, Sara Magliacane, Kristjan Greenewald, Dmitriy Katz, Murat Kocaoglu, and\nKarthikeyan Shanmugam. Active Structure Learning of Causal DAGs via Directed Clique Trees.\nAdvances in Neural Information Processing Systems , 33:21500–21511, 2020.\n[SSG+98] Richard Scheines, Peter Spirtes, Clark Glymour, Christopher Meek, and Thomas Richardson. he\nTETAD Project: Constraint Based Aids to Causal Model Specification. Multivariate Behavioral\nResearch , 33(1):65–117, 1998.\n[SWU21] Liam Solus, Yuhao Wang, and Caroline Uhler. Consistency guarantees for greedy permutation-\nbased causal inference algorithms. Biometrika , 108(4):795–814, 2021.\n[TJG+19] Cheng Tan, Ze Jin, Chuanxiong Guo, Tianrong Zhang, Haitao Wu, Karl Deng, Dongming Bi, and\nDong Xiang. NetBouncer: Active Device and Link Failure Localization in Data Center Networks.\nInProceedings of the 16th USENIX Conference on Networked Systems Design and Implementation ,\npages 599–613, 2019.\n[TK00] Simon Tong and Daphne Koller. Active Learning for Parameter Estimation in Bayesian Networks.\nAdvances in Neural Information Processing Systems , 13, 2000.\n[TK01] Simon Tong and Daphne Koller. Active Learning for Structure in Bayesian Networks. In Inter-\nnational joint conference on artificial intelligence , volume 17, pages 863–869. Citeseer, 2001.\n[URBY13] Caroline Uhler, Garvesh Raskutti, Peter B¨ uhlmann, and Bin Yu. Geometry of the faithfulness\nassumption in causal inference. The Annals of Statistics , pages 436–463, 2013.\n[VP90] Thomas Verma and Judea Pearl. Equivalence and Synthesis of Causal Models. In Proceedings\nof the Sixth Annual Conference on Uncertainty in Artificial Intelligence , UAI ’90, page 255–270,\nUSA, 1990. Elsevier Science Inc.\n[WAJ+23] Qing Wang, Jesus Rios Aliaga, Saurabh Jha, Karthikeyan Shanmugam, Frank Bagehorn, Xi Yang,\nRobert Filepp, Naoki Abe, and Larisa Shwartz. Fault Injection based Interventional Causal Learn-\ning for Distributed Applications. In Innovative Applications of Artificial Intelligence Conference ,\n2023.\n[WBL21a] Marcel Wien¨ obst, Max Bannach, and Maciej Li´ skiewicz. Extendability of Causal Graphical Mod-\nels: Algorithms and Computational Complexity. In Uncertainty in Artificial Intelligence , pages\n1248–1257. PMLR, 2021.\n[WBL21b] Marcel Wien¨ obst, Max Bannach, and Maciej Li´ skiewicz. Polynomial-Time Algorithms for Count-\ning and Sampling Markov Equivalent DAGs. In Proccedings of the 35th Conference on Artificial\nIntelligence, AAAI , 2021.\n[Wei20] Alexander Wei. Better and Simpler Learning-Augmented Online Caching. In Approximation, Ran-\ndomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM\n2020) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2020.\n[WLW20] Shufan Wang, Jian Li, and Shiqiang Wang. Online Algorithms for Multi-shop Ski Rental with\nMachine Learned Advice. Advances in Neural Information Processing Systems , 33:8150–8160,\n2020.\n[Woo05] James Woodward. Making Things Happen: A Theory of Causal Explanation . Oxford University\nPress, 2005.\n16\n\n[WSYU17] Yuhao Wang, Liam Solus, Karren Yang, and Caroline Uhler. Permutation-based Causal Inference\nAlgorithms with Interventions. Advances in Neural Information Processing Systems , 30, 2017.\n[ZPX+19] Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Chao Ji, Dewei Liu, Qilin Xiang, and Chuan He. Latent\nerror prediction and fault localization for microservice applications by learning from system trace\nlogs. In Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering\nConference and Symposium on the Foundations of Software Engineering , pages 683–694, 2019.\n[ZS02] Jiji Zhang and Peter Spirtes. Strong Faithfulness and Uniform Consistency in Causal Inference . In\nProceedings of the Nineteenth conference on Uncertainty in Artificial Intelligence , pages 632–639,\n2002.\n17\n\nA Remark about assumptions\nUnder causal sufficiency , there are no hidden confounders (i.e. unobserved common causes to the observed\nvariables). While causal sufficiency may not always hold, it is still a reasonable assumption to make in certain\napplications such as studying gene regulatory networks (e.g. see [WSYU17]).\nFaithfulness assumes that independencies that occur in the data do not occur due to “cancellations” in\nthe functional relationships, but rather due to the causal graph structure. It is known [Mee95b, SGSH00]\nthat, under many natural parameterizations and settings, the set of unfaithful parameters for any given causal\nDAG has zero Lebesgue measure (i.e. faithfulness holds; see also Section 3.2 of [ZS02] for a discussion about\nfaithfulness). However, one should be aware that the faithfulness assumption may be violated in reality\n[And13, URBY13], especially in the presence of sampling errors in the finite sample regime.\nIdeal interventions assume hard interventions (forcefully setting a variable value) and the ability to obtain\nas many interventional samples as desired, ensuring that we always recover the directions of all edges cut by\ninterventions. Without this assumption, we may fail to correctly infer some arc directions and our algorithms\nwill only succeed with some success probability.\nOur assumption that the given expert advice is consistent with observational essential graph is purely for\nsimplicity and can be removed by deciding which part of the given advice to discard so that the remaining advice\nis consistent. However, we feel that deciding which part of the inconsistent advice to discard will unnecessarily\ncomplicate our algorithmic contributions without providing any useful insights, and thus we made such an\nassumption.\nB Additional Preliminaries\nFor any set A, we denote its powerset by 2A. We write {1, . . . , n }as [n] and hide absolute constant multiplicative\nfactors in nusing standard asymptotic notations O(·), Ω(·), and Θ( ·). The indicator function 1predicate is 1 if\nthe predicate is true and 0 otherwise. Throughout, we use G∗to denote the (unknown) ground truth DAG, its\nMarkov equivalence class by [ G∗] and the corresponding essential graph by E(G∗). We write A˙∪BandA\\B\nto represent the disjoint union and set difference of two sets AandBrespectively.\nB.1 Graph basics\nWe consider partially oriented graphs without parallel edges.\nLetG= (V, E) be a graph on |V|=nnodes/vertices where V(G),E(G), and A(G)⊆E(G) denote nodes,\nedges, and arcs of Grespectively. The graph Gis said to be fully oriented if A(G) =E(G), fully unoriented if\nA(G) =∅, and partially oriented otherwise. For any subset V′⊆VandE′⊆E, we use G[V′] and G[E′] to\ndenote the node-induced and edge-induced subgraphs respectively. We write u∼vto denote that two nodes\nu, v∈Vare connected in G, and write u→voru←vwhen specifying a certain direction. The skeleton\nskel(G) refers to the underlying graph where all edges are made undirected. A v-structure inGrefers to a\ncollection of three distinct vertices u, v, w ∈Vsuch that u→v←wandu̸∼w. A directed cycle refers to a\nsequence of k≥3 vertices where v1→v2→. . .→vk→v1. An acyclic completion / consistent extension of a\npartially oriented graph refers to an assignment of edge directions to the unoriented edges E(G)\\A(G) such\nthat the resulting fully oriented graph has no directed cycles.\nSuppose G= (V, E) is fully unoriented. For vertices u, v∈V, subset of vertices V′⊆Vand integer r≥0,\ndefine dist G(u, v) as the shortest path length between uandv,dist G(V′, v) = min u∈V′dist G(u, v), and\nNr\nG(V′) ={v∈V:dist G(v, V′)≤r} ⊆Vas the set of vertices that are r-hops away from V′, i.e. r-hop\nneighbors of V′. We omit the subscript Gwhen it is clear from context.\nSuppose G= (V, E) is fully oriented. For any vertex v∈V, we write Pa(v),Anc(v),Des(v) to denote the\nparents, ancestors and descendants of vrespectively and we write Des[v] =Des(v)∪{v}andAnc[v] =Anc(v)∪\n{v}to include vitself. We define Ch(v)⊆Des(v) as the set of direct children ofv, that is, for any w∈Ch(v) there\ndoes notexists z∈V\\ {v, w}such that z∈Des(v)∩Anc(w). Note that, Ch(v)⊆ {w∈V:v→w} ⊆Des(v).\nB.2 Causal graph basics\nA directed acyclic graph (DAG) is a fully oriented graph without directed cycles. By representing random\nvariables by nodes, DAGs are commonly used as graphical causal models [Pea09], where the joint probability\ndensity ffactorizes according to the Markov property: f(v1, . . . , v n) =Qn\ni=1f(vi|pa(v)), where pa(v) denotes\n18\n\nthe values taken by v’s parents. One can associate a (not necessarily unique) valid permutation / topological\nordering π:V→[n] to any (partially directed) DAG such that oriented arcs ( u, v) satisfy π(u)< π(v) and\nunoriented arcs {u, v}can be oriented as u→vwithout forming directed cycles when π(u)< π(v).\nFor any DAG G, we denote its Markov equivalence class (MEC) by [ G] and essential graph by E(G). DAGs\nin the same MEC have the same skeleton and the essential graph is a partially directed graph such that an\narcu→vis directed if u→vinevery DAG in MEC [ G], and an edge u∼vis undirected if there exists\ntwo DAGs G1, G2∈[G] such that u→vinG1andv→uinG2. It is known that two graphs are Markov\nequivalent if and only if they have the same skeleton and v-structures [VP90, AMP97]. In fact, the essential\ngraph E(G) can be computed from Gby orienting v-structures in the skeleton skel( G) and applying Meek rules\n(see Appendix D). An edge u→vis acovered edge [Chi95] if Pa(u) =Pa(v)\\ {u}. We use C(G)⊆E(G) to\ndenote the set of covered edges of G. The following is a well-known result relating covered edges and MECs.\nLemma 18 ([Chi95]) .IfGandG′belong in the same MEC if and only if there exists a sequence of covered\nedge reversals to transform between them.\nC Additional Related Works on Causal Structure Learning\nConstraint-based algorithms, such as ours, use information about conditional independence relations to iden-\ntify the underlying structure. From purely observational data, the PC [SGSH00], FCI [SGSH00] and RFCI\nalgorithms [CMKR12] have been shown to consistently recover the essential graph, assuming causal sufficiency,\nfaithfulness, and i.i.d. samples. The problem of recovering the DAG using constraints from interventional\ndata was first studied by [EGS06, EGS05, Ebe07]. Many recent works [HLV14, SKDV15, KDV17, LKDV18,\nGKS+19, SMG+20, CSB22, CS23] have followed up on these themes.\nScore-based methods maximize a particular score function over the space of graphs. For observational data,\nthe GES algorithm [Chi02] uses the BIC to iteratively add edges. Extending the GES, [HB12] proposed the\nGIES algorithm that uses passive interventional data to orient more edges. Hybrid methods, like [SWU21] for\nobservational and [WSYU17] for interventional data, use elements of both approaches.\nD Meek rules\nMeek rules are a set of 4 edge orientation rules that are sound and complete with respect to any given set of\narcs that has a consistent DAG extension [Mee95a]. Given any edge orientation information, one can always\nrepeatedly apply Meek rules till a unique fixed point (where no further rules trigger) to maximize the number\nof oriented arcs.\nDefinition 19 (The four Meek rules [Mee95a], see Fig. 5 for an illustration) .\nR1Edge{a, b} ∈E(G)\\A(G) is oriented as a→bif∃c∈Vsuch that c→aandc̸∼b.\nR2Edge{a, b} ∈E(G)\\A(G) is oriented as a→bif∃c∈Vsuch that a→c→b.\nR3Edge{a, b} ∈E(G)\\A(G) is oriented as a→bif∃c, d∈Vsuch that d∼a∼c,d→b←c, and c̸∼d.\nR4Edge{a, b} ∈E(G)\\A(G) is oriented as a→bif∃c, d∈Vsuch that d∼a∼c,d→c→b, and b̸∼d.\na bc\na bcR1\na bc\na bcR2\nda c\nb da c\nbR3\nad c\nb ad c\nbR4\nFigure 5: An illustration of the four Meek rules\nThere exists an algorithm (Algorithm 2 of [WBL21a]) that runs in O(d· |E(G)|) time and computes the\nclosure under Meek rules, where dis the degeneracy of the graph skeleton9.\n9Ad-degenerate graph is an undirected graph in which every subgraph has a vertex of degree at most d. Note that the\ndegeneracy of a graph is typically smaller than the maximum degree of the graph.\n19\n\nE Imperfect partial advice via MPDAGs\nIn the previous sections, we discuss advice that occurs in the form of a DAG eG∈[G∗]. However, this may be\ntoo much to ask for in certain situations. For example:\n•The Markov equivalence class may be too large for an expert to traverse through and propose an advice\nDAG.\n•The expert only has opinions about a subset of a very large causal graph involving millions of nodes /\nedges.\nAs discussed in Section 2.4, we can formulate such partial advice as MPDAGs. Given a MPDAG as expert\nadvice, a natural attempt would be to sample a DAG eGfrom it to use the full advice. Unfortunately, it is\n#P-complete even to count the number of DAGs consistent with a given MPDAG in general [WBL21b] and\nwe are unaware of any efficient way to sample uniformly at random from it. Instead, we propose to pick an\narbitrary DAG eGas advice within the given MPDAG: pick any unoriented edge, orient arbitrarily, apply Meek\nrules, repeat until fully oriented. The following result follows naturally by maximizing over all possible DAGs\nconsistent with the given partial advice.\nTheorem 20. Fix an essential graph E(G∗) with an unknown underlying ground truth DAG G∗. Given a set A\nof DAGs consistent with the given partial advice and intervention set bound k≥1, there exists a deterministic\npolynomial time algorithm that computes an intervention set Iadaptively such that EI(G∗) =G∗, and|I|has\nsize\n1.O(max{1,log max eG∈Aψ(G∗,eG)} ·ν1(G∗))\n2.O(max{1,log max eG∈Aψ(G∗,eG)} ·logk·νk(G∗))\nwhen k= 1 and k >1 respectively.\nF Technical Overview for Theorem 10\nAs discussed in Section 2, it suffices to prove Theorem 10 with respect to moral DAGs.\nOur strategy for proving Theorem 10 is to consider two arbitrary DAGs Gs(source) and Gt(target) in the\nsame equivalence class and transform a verifying set for Gsinto a verifying set for Gtusing Lemma 18 (see\nAlgorithm 2 for the explicit algorithm10). Instead of proving Theorem 10 by analyzing the exact sequence of\ncovered edges produced by Algorithm 211when transforming between the DAGs Gmin= argminG∈[G∗]ν1(G)\nandGmax= argmaxG∈[G∗]ν1(G), we will prove something more general.\nAlgorithm 2 [Chi95]: Transforms between two DAGs within the same MEC via covered edge reversals\nInput : Two DAGs Gs= (V, E s) and Gt= (V, E t)\nOutput : A sequence seqof covered edge reversals that transforms GstoGt\n1:seq← ∅\n2:while Gs̸=Gtdo\n3: Fix an arbitrary valid ordering πforGs.\n4: LetA←A(Gs)\\A(Gt) be the set of differing arcs.\n5: Lety←argminy∈V:PaA(y)̸=∅{π(y)}.\n6: Letx←argmaxz∈PaA(y){π(z)}.\n7: Add x→ytoseq. ▷[Chi95, Lemma 2]: x→y∈ C(Gs)\n8: Update Gsby replacing x→ywith y→x.\n9:end while\n10:return seq\nObserve that taking both endpoints of any maximal matching of covered edges is a valid verifying set that\nis at most twice the size of the minimum verifying set. This is because maximal matching is a 2-approximation\nto the minimum vertex cover. Motivated by this observation, our proof for Theorem 10 uses the following\n10Lemma 2 of [Chi95] guarantees that x→yis a covered edge of the current Gswhenever step 9 is executed.\n11The correctness of Algorithm 2 is given in [Chi95] where the key idea is to show that x→yfound in this manner is a covered\nedge. This is proven in Lemma 2 of [Chi95].\n20\n\ntransformation argument (Lemma 23): for two DAGs GandG′that differ only on the arc direction of a single\ncovered edge x∼y, we show that given a conditional-root-greedy (CRG) maximal matching12on the covered\nedges of G, we can obtain another CRG maximal matching of the same size on the covered edges of G′, after\nreversing x∼yand transforming GtoG′.\nSo, starting from Gs, we compute a CRG maximal matching, then we apply the transformation argument\nabove on the sequence of covered edges given by Algorithm 2 until we get a CRG maximal matching of Gtof\nthe same size . Thus, we can conclude that the minimum vertex cover sizes of GsandGtdiffer by a factor of\nat most two. This argument holds for anypair of DAGs ( Gs, Gt) from the same MEC.\nWe now define what is a conditional-root-greedy (CRG) maximal matching. As the set of covered edges\nC(G) of any DAG Ginduces a forest (see Theorem 6), we define the CRG maximal matching using a particular\ngreedy process on the tree structure of C(G). The CRG maximal matching is unique with respect to a fixed\nvalid ordering πofGand subset S. We will later consider CRG maximal matchings with S=A(Gs)∩A(Gt),\nwhere the arc set Sremains unchanged throughout the entire transformation process .\nDefinition 21 (Conditional-root-greedy (CRG) maximal matching) .Given a DAG G= (V, E) with a valid\nordering πGand a subset of edges S⊆E, we define the conditional-root-greedy (CRG) maximal matching\nMG,πG,Sas the unique maximal matching on C(G) computed via Algorithm 3: greedily choose arcs x→y\nwhere the xhas no incoming arcs by minimizing πG(y), conditioned on favoring arcs outside of S.\nAlgorithm 3 Conditional-root-greedy maximal matching\nInput : A DAG G= (V, E), a valid ordering πG, a subset of edges S⊆E\nOutput : A CRG maximal matching MG,πG,S\n1:Initialize MG,πG,S← ∅andC← C(G)\n2:while C̸=∅do\n3: x←argminz∈ {u∈V|u→v∈C}{πG(z)} ▷ xis a root (i.e. no incoming arcs)\n4: y←argminz∈V:x→z∈C{πG(z) +n2· 1x→z∈S}\n5: Add the arc x→ytoMG,πG,S\n6: Remove all arcs with xoryas endpoints from C\n7:end while\n8:return MG,πG,S\nTo prove the transformation argument (Lemma 23), we need to first understand how the status of covered\nedges evolve when we perform a single edge reversal. The following lemma may be of independent interest\nbeyond this work.\nLemma 22 (Covered edge status changes due to covered edge reversal) .LetG∗be a moral DAG with MEC\n[G∗] and consider any DAG G∈[G∗]. Suppose G= (V, E) has a covered edge x→y∈ C(G)⊆Eand we\nreverse x→ytoy→xto obtain a new DAG G′∈[G∗]. Then, all of the following statements hold:\n1.y→x∈ C(G′). Note that this is the covered edge that was reversed.\n2. If an edge edoes not involve xory, then e∈ C(G) if and only if e∈ C(G′).\n3. If x∈ChG(a) for some a∈V\\ {x, y}, then a→x∈ C(G) if and only if a→y∈ C(G′).\n4. If b∈ChG(y) and x→b∈E(G) for some b∈V\\{x, y}, then y→b∈ C(G) if and only if x→b∈ C(G′).\nUsing Lemma 22, we derive our transformation argument.\nLemma 23. Consider two moral DAGs G1andG2from the same MEC such that they differ only in one\ncovered edge direction: x→y∈E(G1) and y→x∈E(G2).\nLet vertex abe the direct parent of xinG1, if it exists. Let S⊆Ebe a subset such that a→x∈Sand\nx→y, y→x̸∈S(ifadoes not exist, ignore condition a→x∈S).\nSuppose πG1is an ordering for G1such that y= argminz:x→z∈C(G1){πG1(z) +n2· 1x→z∈S}and denote\nMG1,πG1,Sas the corresponding CRG maximal matching for C(G1). Then, there exists an explicit modification\nofπG1toπG2, and MG1,πG1,Sto a CRG maximal matching MG2,πG2,SforC(G2) such that |MG1,πG1,S|=\n|MG2,πG2,S|.\n12A special type of maximal matching (see Definition 21).\n21\n\nTo be precise, given πG1, we will define πG2in our proofs as follows:\nπG2(v) =\n\nπG1(x) if v=y\nπG1(u) if v=x\nπG1(y) if v=u\nπG1(v) else(1)\nAs discussed earlier, Theorem 10 follows by picking Gs= argmaxG∈[G∗]ν1(G) and Gt= argminG∈[G∗]ν1(G),\napplying Algorithm 2 to find a transformation sequence of covered edge reversals between them, and repeatedly\napplying Lemma 23 with the conditioning set S=A(Gs)∩A(Gt) to conclude that GsandGthave the\nsame sized CRG maximal matchings, and thus implying that min G∈[G∗]ν1(G) = ν1(Gs)≤2·ν1(Gt) =\n2·argmaxG∈[G∗]ν1(G). Note that we keep the conditioning set Sunchanged throughout the entire transformation\nprocess from GstoGt.\nFor an illustrated example of conditional-root-greedy (CRG) maximal matchings and how we update the\npermutation ordering, see Fig. 6 and Fig. 7.\na\nx y\nb u1\n2 4\n3 5 G1a\nx y\nb u1\n3 2\n4 5 G2\nFigure 6: Consider the following simple setup of two DAGs G1andG2which agree on all arc directions except\nforx→yinG1andy→xinG2. Dashed arcs represent the covered edges in each DAG. The numbers below\neach vertex indicate the πG1andπG2orderings respectively. In G1,u= argminz∈ChG1(x){πG1(z)}. Observe\nthat Eq. (1) modifies the ordering only for {x, y, u}(in blue) while keeping the ordering of all other vertices\nfixed. Suppose S=A(G1)∩A(G2) ={a→b, a→x, a→y, a→u, x→b, x→u, y→b}. With respect to πG1\nandS, The conditional-root-greedy maximal matchings (see Algorithm 3) are MG1,πG1,S={a→x, y→b}\nandMG2,πG2,S={a→y, x→b}.\nx y\nb u1 3\n2 4 G1x y\nb u2 1\n3 4 G2\nFigure 7: Consider the following simple setup of two DAGs G3andG4which agree on all arc directions except\nforx→yinG3andy→xinG4. Dashed arcs represent the covered edges in each DAG. The numbers below\neach vertex indicate the πG3andπG4orderings respectively. Observe that C(G3) ={x→u, x→y, y→b}.\nIf we define S=A(G3)∩A(G4) ={x→b, x→u, y→b}, we see that the conditional-root-greedy maximal\nmatchings (see Algorithm 3) are MG3,πG3,S={x→y}andMG4,πG4,S={y→x}. Note that Algorithm 3\ndoes notchoose x→u∈ C(G1) despite π(u)< π(y) because x→u∈S, soπ(y)< π(u) +n2.\nG Deferred proofs\nG.1 Preliminaries\nOur proofs rely on some existing results which we first state and explain below.\n22\n\nLemma 24 (Lemma 27 of [CSB22]) .Fix an essential graph E(G∗)andG∈[G∗]. IfI ⊆2Vis a verifying set,\nthenIseparates all unoriented covered edge u∼vofG.\nLemma 25 (Lemma 28 of [CSB22]) .Fix an essential graph E(G∗)andG∈[G∗]. IfI ⊆2Vis an intervention\nset that separates every unoriented covered edge u∼vofG, then Iis a verifying set.\nLemma 24 tells us that we have to intervene on one of the endpoints of anycovered edge in order to orient\nit while Lemma 25 tells us that doing so for all covered edges suffices to orient the entire causal DAG.\nG.2 Verification numbers of DAGs within same MEC are bounded by a factor of\ntwo\nWe use the following simple lemma in our proof of Lemma 22.\nLemma 26. For any covered edge x→yin a DAG G= (V, E), we have y∈ChG(x). Furthermore, each\nvertex only appears as an endpoint in the collection of covered edges C(G)at most once.\nProof. For the first statement, suppose, for a contradiction, that y̸∈Ch(x). Then, there exists some z∈V\\\n{x, y}such that z∈Des(x)∩Anc(y). Fix an arbitrary ordering πforGand let z∗= argmaxz∈Des(x)∩Anc(y){π(z)}.\nThen, we see that z∗→ywhile z∗̸→xsince z∗∈Des(x). So, x→ycannot be a covered edge. Contradiction.\nFor the second statement, suppose, for a contradiction, that there are two covered edges u→x, v→x∈\nC(G) that ends with x. Since u→x∈ C(G), we must have v→u. Since v→x∈ C(G), we must have u→v.\nWe cannot have both u→vandv→usimultaneously. Contradiction.\nLemma 22 (Covered edge status changes due to covered edge reversal) .LetG∗be a moral DAG with MEC\n[G∗] and consider any DAG G∈[G∗]. Suppose G= (V, E) has a covered edge x→y∈ C(G)⊆Eand we\nreverse x→ytoy→xto obtain a new DAG G′∈[G∗]. Then, all of the following statements hold:\n1.y→x∈ C(G′). Note that this is the covered edge that was reversed.\n2. If an edge edoes not involve xory, then e∈ C(G) if and only if e∈ C(G′).\n3. If x∈ChG(a) for some a∈V\\ {x, y}, then a→x∈ C(G) if and only if a→y∈ C(G′).\n4. If b∈ChG(y) and x→b∈E(G) for some b∈V\\{x, y}, then y→b∈ C(G) if and only if x→b∈ C(G′).\nProof. The only parental relationships that changed when we reversing x→ytoy→xarePaG′(y) =\nPaG(y)\\{x}andPaG′(x) =PaG(x)∪{y}. For any other vertex u∈V\\{x, y}, we have PaG′(u) =PaG(u). The\nfirst two points have the same proof: as parental relationships of both endpoints are unchanged, the covered\nedge status is unchanged.\n3. Since x→y∈ C(G), we have a→y∈E(G). We prove both directions separately.\nSuppose a→x∈ C(G). Then, PaG(a) =PaG(x)\\{a}. Since x→y∈ C(G), then PaG(x) =PaG(y)\\{x}.\nSo, we have PaG′(a) =PaG(a) =PaG(x)\\ {a}=PaG(y)\\ {x, a}=PaG′(y)\\ {a}. Thus, a→y∈ C(G′).\nSuppose a→x̸∈ C(G). Then, one of the two cases must occur:\n(a) There exists some vertex usuch that u→aandu̸→xinG.\nSince x→yis a covered edge, u̸→ximplies u̸→yinG. Therefore, a→y̸∈ C(G′) due to u→a.\n(b) There exists some vertex vsuch that v→xandv̸→ainG.\nThere are two possibilities for v̸→a:v̸∼aorv←a. Ifv̸∼a, then v→x←ais a v-structure. If\nv←a, then x̸∈Ch(a) since we have a→v→x. Both possibilities lead to contradictions.\nThe first case implies a→y̸∈ C(G′) while the second case cannot happen.\n4. We prove both directions separately.\nSuppose y→b∈ C(G). Then, PaG(y) =PaG(b)\\ {y}. Since x→y∈ C(G), then PaG(x) =PaG(y)\\ {x}.\nSo, we have PaG′(b)\\ {x}=PaG(b)\\ {x}=PaG(y)∪ {y} \\ {x}=PaG(x)∪ {y}=PaG′(x). Thus,\nx→b∈ C(G′).\nSuppose y→b̸∈ C(G). Then, one of the two cases must occur:\n23\n\n•There exists some vertex u→yandu̸→b.\nSince x→yis a covered edge, u→yimplies u→x. Therefore, x→b̸∈ C(G′) due to u̸→b.\n•There exists some vertex v→bandv̸→y.\nThere are two possibilities for v̸→y:v̸∼yorv←y. Ifv̸∼y, then v→b←yis a v-structure. If\nv←y, then b̸∈Ch(y) since we have y→v→b. Both possibilities lead to contradictions.\nThe first case implies x→b̸∈ C(G′) while the second case cannot happen.\nLemma 23. Consider two moral DAGs G1andG2from the same MEC such that they differ only in one\ncovered edge direction: x→y∈E(G1) and y→x∈E(G2).\nLet vertex abe the direct parent of xinG1, if it exists. Let S⊆Ebe a subset such that a→x∈Sand\nx→y, y→x̸∈S(ifadoes not exist, ignore condition a→x∈S).\nSuppose πG1is an ordering for G1such that y= argminz:x→z∈C(G1){πG1(z) +n2· 1x→z∈S}and denote\nMG1,πG1,Sas the corresponding CRG maximal matching for C(G1). Then, there exists an explicit modification\nofπG1toπG2, and MG1,πG1,Sto a CRG maximal matching MG2,πG2,SforC(G2) such that |MG1,πG1,S|=\n|MG2,πG2,S|.\nProof. Define u= argminz∈ChG1(x){πG1(z)}as the lowest ordered child of x. Note that Algorithm 3 chooses\nx→yinstead of x→uby definition of y. This implies that x→u∈Swhenever u̸=y.\nLet us define πG2as follows:\nπG2(v) =\n\nπG1(x) if v=y\nπG1(u) if v=x\nπG1(y) if v=u\nπG1(v) else\nClearly, πG1(x)< πG1(y) and πG2(x)> πG2(y). Meanwhile, for any other two adjacent vertices vandv′,\nobserve that πG1(v)< πG1(v′)⇐⇒ πG2(v)< πG2(v′) soπG2agrees with the arc orientations of πG1except\nforx∼y. See Fig. 6 for an illustrated example.\nDefine vertex bas follows:\nb= argminz∈V:z∈Des(x) and y→z∈C(G1){πG1(z) +n2· 1x→z∈S}\nIf vertex bexists, then we know that b∈ChG1(y) and x→b∈ C(G2) by Lemma 26 and Lemma 22. By\nminimality of b, Definition 21 will choose y→bif picking a covered edge starting with yforMG1,πG1,S. So,\nwe can equivalently define vertex bas follows:\nb= argminz∈V:z∈Des(y) and x→z∈C(G2){πG2(z) +n2· 1x→z∈S}\nBy choice of πG2, Definition 21 will choose x→bif picking a covered edge starting with xforMG2,πG2,S.\nWe will now construct a same-sized maximal matching MG2,πG2,Sfrom MG1,πG1,S(Step 1), argue that it is\nmaximal matching of C(G2) (Step 2), and that it is indeed a conditional-root-greedy matching for C(G2) with\nrespect to πG2andS(Step 3). There are three cases that cover all possibilities:\nCase 1 Vertex aexists, a→x∈MG1,πG1,S, and vertex bexists.\nCase 2 Vertex aexists, a→x∈MG1,πG1,S, and vertex bdoes not exist.\nCase 3 a→x̸∈MG1,πG1,S.\nThis could be due to vertex anot existing, or a→x̸∈ C(G1), or MG1,πG1,Scontaining a covered edge\nending at asoa→xwas removed from consideration.\nStep 1: Construction of MG2,πG2,Ssuch that |MG2,πG2,S|=|MG1,πG1,S|.\nBy Lemma 22, covered edge statuses of edges whose endpoints do not involve xorywill remain unchanged.\nBy definition of y, we know that Definition 21 will choose x→yif picking a covered edge starting with xfor\nMG1,πG1,S.\nSince a→x∈MG1,πG1in cases 1 and 2, we know that there is no arcs of the form x→ ·inMG1,πG1,S.\nSince there is no arc of the form · →xinMG1,πG1,Sin case 3, we know that x→y∈MG1,πG1,S.\nCase 1 Define MG2,πG2,S=MG1,πG1,S∪ {a→y, x→b} \\ {a→x, y→b}.\n24\n\nCase 2 Define MG2,πG2,S=MG1,πG1,S∪ {a→y} \\ {a→x}.\nCase 3 Define MG2,πG2,S=MG1,πG1,S∪ {y→x} \\ {x→y}.\nBy construction, we see that |MG2,πG2,S|=|MG1,πG1,S|.\nStep 2: MG2,πG2,Sis a maximal matching of the covered edge C(G2)ofG2.\nTo prove that MG2,πG2,Sis a maximal matching of C(G2), we argue in three steps:\n2(i) Edges of MG2,πG2,Sbelong to C(G2).\n2(ii) MG2,πG2,Sis a matching of C(G2).\n2(iii) MG2,πG2,Sis maximal matching of C(G2).\nStep 2(i): Edges of MG2,πG2,Sbelong to C(G2).\nBy Lemma 22, covered edge statuses of edges whose endpoints do not involve xorywill remain unchanged.\nSince MG1,πG1,Sis a matching, it has at most one edge einvolving endpoint xand at most one edge e′involving\nendpoint y(e′could be e).\nCase 1 Since bexists, the edges in MG1,πG1,Swith endpoints involving {x, y}area→xandy→b. By\nLemma 22, we know that a→y, x→b∈ C(G2).\nCase 2 Since bdoes not exist, the only edge in MG1,πG1,Swith endpoints involving {x, y}isa→x. By\nLemma 22, we know that a→y∈ C(G2).\nCase 3 Since a→x̸∈MG1,πG1,S, we have x→y∈MG1,πG1,Sby minimality of y.\nIn all cases, we see that MG2,πG2,S⊆ C(G2).\nStep 2(ii): MG2,πG2,Sis a matching of C(G2).\nIt suffices to argue that there are notwo edges in MG2,πG2,Ssharing an endpoint. Since MG1,πG1,Sis a\nmatching, this can only happen via newly added endpoints in MG2,πG2,S.\nCase 1 The endpoints of newly added edges are exactly the endpoints of removed edges.\nCase 2 Since we removed a→xand added a→y, it suffices to check that there are no edges in MG1,πG1,S\ninvolving y. This is true since bdoes not exist in Case 2.\nCase 3 The endpoints of newly added edges are exactly the endpoints of removed edges.\nTherefore, we conclude that MG2,πG2,Sis a matching of C(G2).\nStep 2(iii): MG2,πG2,Sis a maximal matching of C(G2).\nFor any u→v∈ C(G2), we show that there is some edge in MG2,πG2,Swith at least one of uorvis an\nendpoint. By Lemma 22, covered edge statuses of edges whose endpoints do not involve xorywill remain\nunchanged, so it suffices to consider |{u, v} ∩ {x, y}| ≥1.\nWe check the following 3 scenarios corresponding to |{u, v} ∩ {x, y}| ≥1 below:\n(i)y∈ {u, v}.\nThe endpoints of MG2,πG2always contains y.\n(ii)y̸∈ {u, v}andx→v∈ C(G2), for some v∈V\\ {x, y}.\nSince x→v∈ C(G2) and y→xinG2, it must be the case that y→vinG2. Since G1andG2agrees on\nall arcs except x∼y, we have that y→vinG1as well. Since x→v∈ C(G2), we know that v∈ChG2(x)\nvia Lemma 26. So, we have y→v∈ C(G1) via Lemma 22. Since the set {v:y→v∈ C(G1)}is\nnon-empty, vertex bexists. In both cases 1 and 3, the endpoints of MG2,πG2includes x.\n(iii)y̸∈ {u, v}andu→x∈ C(G2), for some u∈V\\ {x, y}.\nBy Lemma 26, we know that x∈ChG2(u). Meanwhile, since y→x∈ C(G2), we must have u→yinG2.\nHowever, this implies that x̸∈ChG2(u) since u→y→xexists. This is a contradiction, so this situation\ncannot happen.\nAs the above argument holds for any u→v∈ C(G2), we see that MG2,πG2is maximal matching for C(G2).\n25\n\nStep 3: MG2,πG2,Sis a conditional-root-greedy maximal matching.\nWe now compare the execution of Algorithm 3 on ( πG1, S) and ( πG2, S). Note that Sremains unchanged.\nWe know the following:\n•Since πG2(y) =πG1(x) and a→x∈S, ifaexists and a→xis chosen by Algorithm 3 on ( πG1, S),\nthen it means that there are noa→varc in C(G1) such that a→v̸∈S. So, a→ywill be chosen by\nAlgorithm 3 on ( πG2, S) ifaexists.\n•Since πG2(y) =πG1(x),xis chosen as a root by Algorithm 3 on ( πG1, S) if and only if yis chosen as a\nroot by Algorithm 3 on ( πG2, S).\n•By definition of b, if it exists, then y→b∈MG1,πG1,S⇐⇒ x→b∈MG2,πG2,S.\n•By the definition of πG2, we see that Algorithm 3 makes the “same decisions” when choosing arcs rooted\nonV\\ {a, x, y, b }.\nTherefore, MG2,πG2,Sis indeed a conditional-root-greedy maximal matching for C(G2) with respect to πG2\nandS.\nTheorem 10. For any DAG G∗with MEC [ G∗], we have that max G∈[G∗]ν1(G)≤2·minG∈[G∗]ν1(G).\nProof. Consider any two DAGs Gs, Gt∈[G∗]. To transform Gs= (V, E s) toGt= (V, E t), Algorithm 2 flips\ncovered edges one by one such that |Es\\Et|decreases in a monotonic manner. We will repeatedly apply\nLemma 23 with S=A(Gs)∩A(Gt) on the sequence of covered edge reversals produced by Algorithm 2.\nLetπGsbe an arbitrary ordering for Gsand we compute an initial conditional-root-greedy maximal matching\nforC(Gs) with respect to some ordering πGsand conditioning set S. To see why Lemma 23 applies at each\nstep for reversing a covered edge from x→ytoy→x, we need to ensure the following:\n1. If xhas a parent vertex a(i.e.x∈ChG1(a)), then a→x∈S.\nIfa→x̸∈S, then then a→xis a covered edge that should be flipped to transform from GstoGt.\nHowever, this means that Algorithm 2 would pick a→xto reverse instead of picking x→yto reverse.\nContradiction.\n2.x→y, y→x̸∈S.\nThis is satisfied by the definition of S=Es∩Etsince reversing x→ytoy→ximplies that neither of\nthem are in S.\n3.y= argminz:x→z∈C(G1){πG1(z) +n2· 1x→z∈S}.\nSince x→y̸∈S, this is equivalent to checking if y= argminz:x→z∈C(G1){πG1(z)}. This is satisfied by\nline 7 of Algorithm 2.\n4.MG1,πG1,Sis a conditional-root-greedy maximal matching for C(G1) with respect to some ordering πG1\nand conditioning set S.\nThis is satisfied since we always maintain a conditional-root-greedy maximal matching and Sis unchanged\nthroughout.\nBy applying Lemma 23 with S=A(Gs)∩A(Gt) repeatedly on the sequence of covered edge reversals\nproduced by Algorithm 2, we see that there exists a conditional-root-greedy maximal matching MGs,πGsfor\nC(Gs) and a conditional-root-greedy maximal matching MGt,πGtforC(Gt) such that |MGs,πGs|=|MGt,πGt|.\nThe claim follows since maximal matching is a 2-approximation to minimum vertex cover, and the verifi-\ncation number ν(G) of any DAG Gis the size of the minimum vertex cover of its covered edges C(G).\nLemma 11 (Tightness of Theorem 10) .There exist DAGs G1andG2from the same MEC with ν1(G1) =\n2·ν1(G2).\nProof. See Fig. 8.\n26\n\na\nc b\nd\nG1a\nc b\nd\nG2\nFigure 8: The ratio of 2 in Theorem 10 is tight: G1andG2belong in the same MEC with ν(G1) = 2 and\nν(G2) = 1. The dashed arcs represent the covered edges and the boxed vertices represent a minimum vertex\ncover of the covered edges.\nG.3 Adaptive search with imperfect advice\nLemma 15. Fix a DAG G∗= (V, E) and let V′⊆Vbe any subset of vertices. Suppose IV′⊆Vis the set of\nnodes intervened by SubsetSearch (E(G∗), V′). IfC(G∗)⊆E(G∗[V′]), then EIV′(G∗) =G∗.\nProof. By Theorem 9, SubsetSearch fully orients edges within the node-induced subgraph induced by V′,\ni.e.SubsetSearch will perform atomic interventions on IV′⊆Vresulting in EIV′(G∗)[V′] =G∗[V′]. Since\nC(G∗)⊆E(G∗[V′]) and all covered edges C(G∗) were oriented, then according to Lemma 24, it must be the\ncase that V∗⊆ IV′for some minimum vertex cover V∗ofC(G∗), so we see that R(G∗, V∗)⊆R(G∗,IV′). By\nLemma 25, we have R(G∗, V∗) =A(G∗) and so SubsetSearch (E(G∗), V′) fully orients E(G∗).\nWe will now prove our main result (Theorem 14) which shows that the number of interventions needed is a\nfunction of the quality of the given advice DAG. Let us first recall how we defined the quality of a given advice\nand restate our algorithm.\nDefinition 13 (Quality measure) .Fix a DAG G∗with MEC [ G∗] and consider any DAG eG∈[G∗]. We define\nψ(G∗,eG) as follows:\nψ(G∗,eG) = max\neV∈V(eG)\f\f\fρ\u0010\neV , Nh(G∗,eV)\nskel(E(G∗))(eV)\u0011\f\f\f\nTheorem 14. Fix an essential graph E(G∗) with an unknown underlying ground truth DAG G∗. Given an\nadvice graph eG∈[G∗] and intervention set bound k≥1, there exists a deterministic polynomial time algorithm\n(Algorithm 1) that computes an intervention set Iadaptively such that EI(G∗) =G∗, and|I|has size\n1.O(max{1,logψ(G∗,eG)} ·ν1(G∗)) when k= 1\n2.O(max{1,logψ(G∗,eG)} ·logk·νk(G∗)) when k >1.\nProof. Consider Algorithm 1. Observe that n0= 2 ensures that n2\n0> n 0.\nIn this proof, we will drop the subscript skel( E(G∗)) when we discuss the r-hop neighbors Nr\nskel(E(G∗))(·).\nWe first prove the case where k= 1 then explain how to tweak the proof for the case of k >1.\nIf Algorithm 1 terminates when i= 0, then I=I0=eVand Theorem 10 tells us that |I| ∈ O (ν1(G∗)).\nNow, suppose Algorithm 1 terminates with i=t, for some final round t >0. As Algorithm 1 uses an\narbitrary verifying set of eGin step 3, we will argue that O(max{1,log|Nh(G∗,eV)(eV)|}·ν(G∗)) interventions are\nused in the while-loop, for any arbitrary chosen eV∈ V(eG). The theorem then follows by taking a maximization\nover all possibilities in V(eG).\nIn Line 12, r(i) records the hop value such that ρ(Ii, Nr(i)(eV))≥n2\ni, for any 0 ≤i < t. By construction of\nthe algorithm, we know the following:\n1. For any 0 < i≤t,\nni=ρ(Ii, Nr(i)(eV))≥n2\ni−1> ρ(Ii, Nr(i)−1(eV)) (2)\nbecause r(i)−1 did nottrigger Algorithm 1 to record r(i).\n27\n\nAlgorithm 1 Adaptive search algorithm with advice.\nInput : Essential graph E(G∗), advice DAG eG∈[G∗], intervention size k∈N\nOutput : An intervention set Isuch that each intervention involves at most knodes and EI(G∗) =G∗.\n1:LeteV∈ V(eG) be any atomic verifying set of eG.\n2:ifk= 1then\n3: Define I0=eVas an atomic intervention set.\n4:else\n5: Define k′= min {k,|eV|/2},a=⌈|eV|/k′⌉ ≥2, and ℓ=⌈loga|C|⌉. Compute labelling scheme on eVwith\n(|eV|, k, a) via Lemma 17 and define I0={Sx,y}x∈[ℓ],y∈[a], where Sx,y⊆eVis the subset of vertices whose\nxthletter in the label is y.\n6:end if\n7:Intervene on I0and initialize r←0,i←0,n0←2.\n8:while EIi(G∗) still has undirected edges do\n9: ifρ(Ii, Nr\nskel(E(G∗))(eV))≥n2\nithen\n10: Increment i←i+ 1 and record r(i)←r.\n11: Update ni←ρ(Ii, Nr\nskel(E(G∗))(eV))\n12: Ci←SubsetSearch (EIi(G∗), Nr−1\nskel(E(G∗))(eV), k)\n13: ifEIi−1∪Ci(G∗) still has undirected edges then\n14: C′\ni←SubsetSearch (EIi−1∪Ci(G∗), Nr\nskel(E(G∗))(eV), k)\n15: Update Ii← I i−1∪Ci∪C′\ni.\n16: else\n17: Update Ii← I i−1∪Ci.\n18: end if\n19: end if\n20: Increment r←r+ 1.\n21:end while\n22:return Ii\n2. By Theorem 9 and Eq. (2), for any 1 ≤i≤t,\n|Ci| ∈ O (logρ(Ii, Nr(i)−1(eV))·ν1(G∗))⊆ O(logni−1·ν1(G∗))\n|C′\ni| ∈ O (logρ(Ii, Nr(i)(eV))·ν1(G∗)) ⊆ O(logni·ν1(G∗))(3)\nNote that the bound for |C′\ni|is an over-estimation (but this is okay for our analytical purposes) since some\nnodes previously counted for ρ(Ii, Nr(i)(eV)) may no longer be relevant in EIi∪Ci(G∗) after intervening\nonCi.\n3. Since ni−1≤√nifor any 0 < i≤t, we know that nj≤n1/2t−j\nt for any 0 ≤j≤t. So, for any 0 ≤t′≤t,\nwe have\nt′X\ni=0log(ni)≤t′X\ni=0log\u0012\nn1/2t′−i\nt′\u0013\n=t′X\ni=0log(nt′)\n2t′−i≤2·log(nt′) (4)\n4. By definition of t, h(G∗,eV), and Lemma 15,\nr(t−1)< h(G∗,eV)≤r(t) (5)\nand\nNr(t−1)(eV)⊊Nh(G∗,eV)(eV)⊆Nr(t)(eV) (6)\nCombining Eq. (2), Eq. (3), and Eq. (4), we get\nt−1X\ni=1(|Ci|+|C′\ni|)∈ O  t−1X\ni=1logni−1+ log ni!\n·ν1(G∗)!\n⊆ O t−1X\ni=1logni·ν1(G∗)!\n⊆ O(lognt−1·ν1(G∗))\n(7)\n28\n\nTo relate |It|with|Nh(G∗,eV)(eV)|, we consider two scenarios depending on whether the essential graph was\nfully oriented after intervening on CtorC′\nt.\nScenario 1: Fully oriented after intervening on Ct, i.e.EIt−1∪Ct(G∗) =G∗.Then,\nIt=Ct˙∪ It−1=Ct˙∪(Ct−1˙∪C′\nt−1)˙∪ It−2=. . .=Ct˙∪t−1[\ni=1(Ci˙∪C′\ni)˙∪eV\nIn this case, h(G∗,eV) =r(t)−1. By definition, nt−1≤ |Nr(t−1)(eV)|and we have\nnt−1≤ |Nr(t−1)(eV)|<|Nh(G∗,eV)(eV)| (8)\nsince Nr(t−1)(eV)⊊Nh(G∗,eV)(eV). So,\n|It| − |eV|=|Ct|+t−1X\ni=1(|Ci|+|C′\ni|)\n∈ O(lognt−1·ν1(G∗)) +O(lognt−1·ν1(G∗)) By Eq. (3) and Eq. (7)\n⊆ O\u0010\nlog|Nh(G∗,eV)(eV)| ·ν1(G∗)\u0011\nEq. (8)\nScenario 2: Fully oriented after intervening on C′\nt, i.e.EIt−1∪Ct∪C′\nt(G∗) =G∗.Then,\nIt=Ct˙∪C′\nt˙∪ It−1=. . .=Ct˙∪C′\nt˙∪t−1[\ni=1(Ci˙∪C′\ni)˙∪eV\nIn this case, h(G∗,eV) =r(t) and Nh(G∗,eV)(eV) =Nr(t)(eV). So,\nnt≤ |Nr(t)(eV)|=|Nh(G∗,eV)(eV)| (9)\nSo,\n|It| − |eV|=|Ct|+|C′\nt|+t−1X\ni=1(|Ci|+|C′\ni|)\n∈ O((log nt−1+nt)·ν1(G∗)) +O(lognt−1·ν1(G∗)) By Eq. (3) and Eq. (7)\n⊆ O\u0010\nlog|Nh(G∗,eV)(eV)| ·ν1(G∗)\u0011\nEq. (9)\nSince|eV| ∈ O (ν1(G∗)), we can conclude\n|It| ∈ O\u0010\nν(G∗) + log |Nh(G∗,eV)(eV)| ·ν1(G∗)\u0011\n⊆ O\u0010\nmaxn\n1,log|Nh(G∗,eV)(eV)|o\n·ν1(G∗)\u0011\nin either scenario, as desired. The theorem then follows by taking a maximization over all eV∈ V(eG).\nAdapting the proof for k >1\nBy Theorem 16, νk(G∗)≥ ⌈ν1(G∗)/k⌉. So,|I0| ∈ O (logk·νk(G∗)) via Lemma 17. The rest of the proof\nfollows the same structure except that we use the bounded size guarantee of Theorem 9, which incurs an\nadditional multiplicative log kfactor.\nPolynomial running time\nBy construction, the Algorithm 1 is deterministic. Furthermore, Algorithm 1 runs in polynomial time\nbecause:\n•Hop information and relevant nodes can be computed in polynomial time via breadth first search and\nmaintaining suitable neighborhood information.\n•It is known that performing Meek rules to obtain essential graphs takes polynomial time ([WBL21a]).\n•Algorithm 1 makes at most two calls to SubsetSearch whenever the number of relevant nodes is squared.\nEach SubsetSearch call is known to run in polynomial time (Theorem 9). Since this happens each time\nthe number of relevant nodes is squared, this can happen at most O(logn) times.\n29\n\nTheorem 20. Fix an essential graph E(G∗) with an unknown underlying ground truth DAG G∗. Given a set A\nof DAGs consistent with the given partial advice and intervention set bound k≥1, there exists a deterministic\npolynomial time algorithm that computes an intervention set Iadaptively such that EI(G∗) =G∗, and|I|has\nsize\n1.O(max{1,log max eG∈Aψ(G∗,eG)} ·ν1(G∗))\n2.O(max{1,log max eG∈Aψ(G∗,eG)} ·logk·νk(G∗))\nwhen k= 1 and k >1 respectively.\nProof. Apply Theorem 14 while taking a maximization over all possible advice DAGs eGconsistent with the\ngiven partial advice.\nH Path essential graph\nIn this section, we explain why our algorithm (Algorithm 1) is simply the classic “binary search with predic-\ntion”13when the given essential graph E(G∗) is an undirected path on nvertices. So, another way to view our\nresult is a generalization that works on essential graphs of arbitrary moral DAGs.\nWhen the given essential graph is a path E(G∗) onnvertices, we know that there are npossible DAGs in\nthe Markov equivalence class where each DAG corresponds to choosing a single root node and having all edges\npointing away from it. Observe that a verifying set of any DAG is then simply the root node as the set of of\ncovered edges in any rooted tree are precisely the edges incident to the root.\nTherefore, given any eG∈[G∗], we se that h(G∗,eV) measures the number of hops between the root of the\nadvice DAG eGand the root of the true DAG G∗. Furthermore, by Meek rule R1, whenever we intervene on\na vertex uon the path, we will fully orient the “half” of the path that points away from the root while the\nsubpath between uand the root remains unoriented (except the edge directly incident to u). So, one can see\nthat Algorithm 1 is actually mimicking exponential search from the root of eGtowards the root of G∗. Then,\nonce the root of G∗lies within the r-hop neighborhood H,SubsetSearch usesO(log|V(H)|) interventions,\nwhich matches the number of queries required by binary search within a fixed interval over |V(H)|nodes.\nI Experiments\nIn this section, we provide more details about our experiments.\nAll experiments were run on a laptop with Apple M1 Pro chip and 16GB of memory. Source code imple-\nmentation and experimental scripts are available at\nhttps://github.com/cxjdavin/active-causal-structure-learning-with-advice .\nI.1 Experimental setup\nFor experiments, we evaluated our advice algorithm on the synthetic graph instances of [WBL21b]14on graph\ninstances of sizes n={16,32,64}. For each undirected chordal graph instance, we do the following:\n1. Set m= 1000 as the number of advice DAGs that we will sample.\n2. Use the uniform sampling algorithm of [WBL21b] to uniformly sample madvice DAGs eG1, . . . ,eGm.\n3. Randomly select G∗from one of eG1, . . . ,eGm.\n4. For each eG∈ {eG1, . . . ,eGm},\n•Compute a minimum verifying set eVofeG.\n•Define and compute ψ(G∗,eV) =\f\f\fρ\u0010\neV , Nh(G∗,eV)\nskel(E(G∗))(eV)\u0011\f\f\f.\n•Compute a verifying set using ( E(G∗),eG) as input to Algorithm 1.\n13e.g. see https://en.wikipedia.org/wiki/Learning_augmented_algorithm#Binary_search\n14See Appendix E of [WBL21b] for details about each class of synthetic graphs. Instances are available at https://github.com/\nmwien/CliquePicking/tree/master/aaai_experiments\n30\n\n5. Aggregate the sizes of the verifying sets used based on ψ(G∗,eV) and compute the mean and standard\ndeviations.\n6. Compare against verification number ν1(G∗) and the number of interventions used by the fully adaptive\nsearch (without advice, which we denote as “blind search” in the plots) of [CSB22].\n7. Compute the empirical distribution of the quality measure amongst the madvice DAGs, then use standard\nsample complexity arguments for estimating distributions up to εerror in TV distance to compute a\nconfidence interval for which the true cumulative probability density of all DAGs within the MEC lies\nwithin15. To be precise, it is known that for a discrete distribution Ponkelements, when there are\nm≥max{k/ε2,(2/ε2)·ln(2/δ)}uniform samples, the probability that the TV distance between the true\ndistribution Pand the empirical distribution Pis less than εis at least 1 −δ. Since the upper bound on\nthe domain size of quality measure is the number of nodes n, by setting m= 1000 and δ= 0.01, we can\ncompute ε= max {p\nn/m,p\n(2/m)·ln(2/δ)}and conclude that the probability that the true cumulative\nprobability density of all DAGs within the MEC lies within εdistance (clipped to be between 0 and 1)\nof the empirical distribution is at least 99%.\nI.2 Experimental remarks\n•The uniform sampling code of [WBL21b] is written in Julia and it uses a non-trivial amount of memory,\nwhich may make it unsuitable for running on a shared server with memory constraints.\n•Note that ψ(G∗,eV)≤ψ(G∗,eG) = max eV∈V(eG)\f\f\fρ\u0010\neV , Nh(G∗,eV)\nskel(E(G∗))(eV)\u0011\f\f\f. We use ψ(G∗,eV) as a proxy for\nψ(G∗,eG) because we do not know if there is an efficient way to compute the latter besides the naive\n(possibly exponential time) enumeration over all possible minimum verifying sets.\n•We also experimented with an “unsafe” variant of Algorithm 1 where we ignore the second tweak of\nintervening one round before. In our synthetic experiments, both variants use a similar number of\ninterventions.\n•We do not plot the theoretical upper bounds O(logψ(G∗,eV)·ν1(G∗)) or O(logn·ν1(G∗)) because\nthese values are a significantly higher than the other curves and result in “squashed” (and less interest-\ning/interpretable) plots.\n•Even when ψ(G∗,eV) = 0, there could be cases where [CSB22] uses more interventions than ν1(G∗). For\nexample, consider Fig. 8 with G∗=G2andeG=G1. After intervening on eV={b, c}, the entire graph\nwill be oriented so the ψ(G∗,eV) = 0 while ν1(G∗) = 1 <2 =|eV|. Fortunately, Theorem 10 guarantees\nthat|eV| ≤2·ν1(G∗).\n•Note that the error bar may appear “lower” than the verification number even though all intervention\nsizes are at least as large as the verification number. For instance, if ν1(G∗) = 6 and we used (6 ,6,7)\ninterventions on three different eG’s, each with ψ(G∗,eV) = 0. In this case, the mean is 6 .3333. . .while\nthe standard deviation is 0 .4714. . ., so the error bar will display an interval of [5 .86. . . ,6.80. . .] whose\nlower interval is below ν1(G∗) = 6.\nI.3 All experimental plots\nFor details about the synthetic graph classes, see Appendix E of [WBL21b]. Each experimental plot is for\none of the synthetic graphs G∗, with respect to 1000 ≪ |[G∗]|uniformly sampled advice DAGs eGfrom the\nMEC [ G∗]. The solid lines indicate the number of atomic interventions used while the dotted lines indicate the\nempirical cumulative probability density of eG. The true cumulative probability density lies within the shaded\narea with probability at least 0.99.\n15For example, see Theorem 1 of [Can20].\n31\n\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 9: Subtree-logn synthetic graphs\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 10: Subtree-2logn synthetic graphs\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 11: Subtree-sqrtn synthetic graphs\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 12: Interval synthetic graphs\n32\n\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 13: peo-2 synthetic graphs\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 14: peo-4 synthetic graphs\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 15: Thickening-3 synthetic graphs\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 16: Thickening-logn synthetic graphs\n33\n\n(a)n= 16\n (b)n= 32\n (c)n= 64\nFigure 17: Thickening-sqrtn synthetic graphs\n34",
  "textLength": 103212
}