{
  "paperId": "6fe0f2a6a7174fae6268a83cb5ad1aba2b36e199",
  "title": "Learning-Augmented Algorithms with Explicit Predictors",
  "pdfPath": "6fe0f2a6a7174fae6268a83cb5ad1aba2b36e199.pdf",
  "text": "arXiv:2403.07413v1  [cs.LG]  12 Mar 2024Learning-Augmented Algorithms with Explicit Predictors\nMarek Eli´ aˇ s∗, Haim Kaplan†, Yishay Mansour‡, Shay Moran§\nAbstract\nRecent advances in algorithmic design show how to utilize pr edictions obtained by ma-\nchine learning models from past and present data. These appr oaches have demonstrated an\nenhancement in performance when the predictions are accura te, while also ensuring robust-\nness by providing worst-case guarantees when predictions f ail. In this paper we focus on\nonline problems; prior research in this context was focused on a paradigm where the predictor\nis pre-trained on past data and then used as a black box (to get the predictions it was trained\nfor). In contrast, in this work, we unpack the predictor and i ntegrate the learning problem it\ngives rise for within the algorithmic challenge. In particu lar we allow the predictor to learn\nas it receives larger parts of the input, with the ultimate go al of designing online learning al-\ngorithms speciﬁcally tailored for the algorithmic task at h and. Adopting this perspective, we\nfocus on a a number of fundamental problems, including cachi ng and scheduling, which have\nbeen well-studied in the black-box setting. For each of the p roblems we consider, we introduce\nnew algorithms that take advantage of explicit learning alg orithms which we carefully design\ntowards optimizing the overall performance. We demonstrat e the potential of our approach\nby deriving performance bounds which improve over those est ablished in previous work.\n1 Introduction\nWe study online algorithmic problems within the realm of learning-augme nted algorithms. A\nlearning-augmented algorithm possesses the capability to work in co njunction with an oracle that\nsupplies predictive information regarding the data it is expected to p rocess. This innovative ap-\nproachhasbeendiscussedinlandmarkstudiesbyKraskaetal.[2018 ]andLykourisandVassilvitskii\n[2021], situating it neatly within the “beyond worst-caseanalysis” fr amework[Roughgarden, 2020,\nchap. 30].\nIn this framework, studies typically deﬁne predictions speciﬁcally ta ilored to the problem at\nhand, which could presumably be learned from historical data. Pred ictions might include, for\ninstance, the anticipated next request time for a page in a caching p roblem or the expected\nduration of a job in a scheduling task. These predictions are access ible either before or together\nwith the online requests, allowing the algorithm to utilize them for perf ormance enhancement\n(measured by competitive ratio or regret). The objective is for th e algorithm’s performance to\ngracefully decrease as prediction accuracy declines, ensuring it ne ver underperforms the baseline\nachievable without predictions.\n∗Bocconi University, Milan, IT\n†Tel Aviv University, and Google Research, supported by Isra el Science Foundation (ISF) grants 1595/19 and\n1156/23, and by the Blavatnik Research Foundation.\n‡Tel Aviv University, and Google Research. Yishay Mansour ha s received funding from the European Research\nCouncil (ERC) under the European Union’s Horizon 2020 resea rch and innovation program (grant agreement No.\n882396), by the Israel Science Foundation, the Yandex Initi ative for Machine Learning at Tel Aviv University and\na grant from the Tel Aviv University Center for AI and Data Sci ence (TAD).\n§Departments of Mathematics, Computer Science, and Data and Decision Sciences, Technion, and Google Re-\nsearch. Shay Moran is a Robert J. Shillman Fellow; he acknowl edges support by ISF grant 1225/20, by BSF grant\n2018385, by an Azrieli Faculty Fellowship, by Israel PBC-VA TAT, by the Technion Center for Machine Learning\nand Intelligent Systems (MLIS), and by the the European Unio n (ERC, GENERALIZATION, 101039692). Views\nand opinions expressed are however those of the author(s) on ly and do not necessarily reﬂect those of the Euro-\npean Union or the European Research Council Executive Agenc y. Neither the European Union nor the granting\nauthority can be held responsible for them.\n1\n\nDespite the elegance of these results, the ad-hoc nature of the p redictions, the absence of\nstandardized quality measures, and the often overlooked proces s of prediction generation and its\nassociated costs, have been largely neglected. We believe that add ressing these aspects is likely to\nyield substantial improvements.\nConsider week-day and festive traﬃc patterns in a city – a simple exa mple of a setting with\ntwo typical inputs requiring very diﬀerent predictive and algorithmic strategies. Achieving a\ngood performance in such setting requires a learning component in t he algorithm which discerns\nbetween the festive and week-day input instances and suggests a n appropriate routing strategy.\nSuch learning components are already present (explicitly or implicitly) in works on combining\nalgorithms in a black-box manner [Dinitz et al., 2022, Emek et al., 2021, A nand et al., 2022,\nAntoniadis et al., 2023], where a switch between algorithms is made aft er incurring a high cost.\nOur approach goes one step further. It is based on making the com putation of the predictions\nan integral part of the algorithmic task at hand. We do this by making all the data (historical\nand current) directly available to the online algorithm (rather than s ummarizing it into ad-hoc\npredictions). This allows the algorithm to learn the input sequence ba sed on its preﬁx (the\nshorter the better) and adapt the algorithmic strategy before in curring signiﬁcant cost. E.g., in\nthe example above week-day and festive traﬃc patterns can be ea sily discerned already in early\nmorning when the traﬃc is low and possibly suboptimal routing decision s have negligible impact\non the overall cost.\nIn more detail, we model the past data through the assumption tha t the algorithm is equipped\nwith prior knowledge comprising a set of ‘likely’ input instances. Here, ’likely’ means that the\nactual input is expected to be well approximated by one of these ins tances. Typically, each\ninput instance does not provide a full description of the input seque nce. Instead, it oﬀers speciﬁc\nstatisticsorcharacteristicsthat canbe collectedfrompastdata andrepresentessentialinformation\nof the input sequence. Borrowing terminology for learning theory, we call this set a hypothesis\nclassand denote it by H. More speciﬁcally, His a collection of hypotheses, where each hypothesis,\nh(I), consists of information regarding a speciﬁc possible input instanc eIof the algorithmic task.\nIn the simplest setting each hypothesis could be the input instance it self (h(I) =I). Like the\nsequence of pages to arrive in a caching instance, or a set of jobs t o arrive in a scheduling instance.\nIn other situations, an hypothesis h(I) could be a more compact summary of the instance I, such\nas the distribution of the arriving jobs (what fraction are of each “ type”). However, in all cases\nthat we consider, each hypotheses h(I) provides suﬃcient information about the instance in order\nto determine an oﬄine optimal solution OPT( I).\nWe distinguish between realizable andagnostic settings. In the realizable setting, we make the\nassumption that the actual input sequence that the online algorith m has to serve, perfectly aligns\nwith one of the hypotheses in H. That is, if Iis the real input, then h(I)∈ H. In theagnostic set-\nting we remove this assumption and consider arbitrary inputs. Our g oal is to deliver performance\nguarantees that improve if the actual input is “close” (deﬁned in a s uitable manner) to the hy-\npothesis class H. The realizable case is interesting mostly from a theoretical perspe ctive as a very\nspecialcaseoftheagnosticsetting. Itssimplicitymakesitalogicals tartingpointofastudy.1Ifthe\ncurrent instance does not match any hypothesis perfectly (in the realizable setting) or is far from\nH(in the agnostic setting), we can still achievegood performance us ing robustiﬁcation techniques,\nsee e.g. [Wei, 2020, Antoniadis et al., 2023, Lattanzi et al., 2020, Lind ermayr and Megow, 2022].\nOur methodology is to split the algorithm into two parts. One (called predictor ) produces\npredictions based on the provided hypothesis class ( H) and the part of the input seen so far. Its\ngoal is to produce the best prediction for the instance at hand whic h could be a hypothesis from H\norsomeothersuitableinstancedesignedbasedon H. Thesecondpartistheonlinealgorithmitself.\nIt uses the prediction of the ﬁrst part to serve the input sequenc e with low cost. In particular, it\ncan compute the oﬄine optimal solution for the prediction and serve the input sequence according\nto this solution.\nThe predictor is the learning component of our algorithm. It solves a learning task which\n1Boosting technique, which had a great impact on applied and p ractical machine learning, was developed while\nstudying relationship between weak and strong PAC learning in the realizable setting.\n2\n\ncaching load balancing non-clairvoyant scheduling\nrealizable OPT+ klogℓ O (logℓ)OPT OPT+ ℓ√\n2OPT\nagnostic OPT+ O(µ∗+klogℓ) O(logℓ)ALG∗OPT+µ∗+O(n5/3logℓ)\nprevious works OPT+ O(µ∗+k+√Tklogℓ)O(logℓ)ALG∗(1+ǫ)OPT+O(1/ǫ5)µ∗\n[Emek et al., 2021] [Dinitz et al., 2022] [Dinitz et al., 2022]\nFigure 1: Summary of our results. Notation: ℓ=|H|;kandT: cache size and instance length\nrespectively in caching; m: the number of machines in load balancing; n: the number of jobs in\nnon-clairvoyant scheduling; µ∗: distance of the input from the hypothesis class in caching and\nnon-clairvoyant scheduling; ALG∗: cost of the best algorithmic strategy suggested by H.\nis associated with the algorithmic problem at hand. For example, the le arning task associated\nwith caching is a variant of online learning with two kinds of costs: the s maller cost is due to a\nmisprediction of an individual request and the larger one due to switching to a diﬀerent predicted\nsequence. The costs are chosen to reﬂect the impact of the two e vents on the overall performance\nof the algorithm.\nWe consider this new way to model a setting of “online algorithm with pr edictions” as one of\nour core contributions (in addition to the algorithms for the speciﬁc problems that we describe\nbelow). In a sense, our technique interpolates in an interesting way between the learning challenge\n(from historical data) and the algorithmic challenge, while addressin g both of them.\n1.1 Performance bounds of our algorithms\nWe propose algorithms (within our framework) for three fundamen tal online algorithmic prob-\nlems: caching, load balancing, and non-clairvoyant scheduling. For c aching and non-clairvoyant\nscheduling, we achieve a (small) additive regret compared to the oﬄin e optimal solution instead\nof a multiplicative competitive ratio. For load balancing, we achieve a co mpetitive ratio with log-\narithmic dependence on the size ℓof the hypothesis class. Our results are summarized in Figure 1,\nwhile the full description is deferred to Section 2.\nOur bounds depend on the size of the hypothesis class which we assu me to be restricted in the\nsense that not every instance Iis close to some hypothesis in H. This ensures that there is some\nstructure in the input instances which can be learnt. With an unrest rictedH, every input would\nbe possible and we would be in the classical online setting. A large datas et of past instances may\nbe summarized to a smaller hypothesis class using a clustering approa ch proposed by Dinitz et al.\n[2022]. The size of the hypothesis class then describes the uncerta inty about the input.\nRecent worksby Dinitz et al. [2022] and Emek et al. [2021]consider alg orithms with access to a\nportfolioofpredictorstryingtoachieveperformancecomparable tothebestone. Ourresultscanbe\ninterpreted in their setting by consideringthe output ofeach pred ictorin the portfolioas ahypoth-\nesis. We achieve comparable and sometimes better results (see Figu re 1 for comparison) using ar-\nguablysimplerapproach,separatingthelearningandalgorithmicpar tandsolvingthemseparately.\nOrganization\nSection 2 describes our main contributions including the description o f the problems studied and\nthe approachwhich leadsto ourresults. The surveyofthe related literaturein Section 3is followed\nby a warm-up in Section 4 containing an exposition of our approach in a simple setting. Section\n5 and the Appendix contain the technical part of the paper.\n2 Main Results\nOur study focuses on three fundamental online algorithmicproblem s: caching, load balancing, and\nnon-clairvoyantscheduling. Foreachoftheseproblems, wedeﬁne learningtasksand deviseexplicit\n3\n\nand eﬃcient predictors for solving them. We demonstrate how thes e predictors can be integrated\ninto algorithms designed to tackle the respective online problems. A k ey feature of our approach is\nthe modular separation of the learning and algorithmic components. By decoupling these aspects,\nwe develop simpler algorithms that often yield improved bounds compa red to previous works in\nthe ﬁeld.\n2.1 Caching\nIn the caching problem, the input is a sequence of page requests. T he online algorithm holds a\ncache of size k, and it must ensure that the currently requested page is always av ailable in the\ncache. If the requested page is absent from the cache, a page fa ult occurs, prompting the page to\nbe loaded into the cache. If the cache is already full, another page m ust be evicted to make room.\nThe ultimate objective is to minimize the number of page faults.\nIn the oﬄine scenario, where the input sequence is known ahead of t ime, an optimal algo-\nrithm adheres to the intuitive policy of removing a page that will not be requested again for the\nlongest time. This algorithm, known as Furthest in the Future (FitF) [Belady, 1966], achieves the\nminimum possible number of page faults.\nThe Learning Task: “Sequence Prediction with Switching Cos t”\nIn this context we consider a variant of the classical learning task o f sequence prediction that\nincludes a switching cost. More precisely, the objective of the pred ictor is to predict the sequence\nofpagerequestsdenoted by r1,r2,...,rT. In eachround t, the predictorpresentsaprediction forall\nremaining requests in the sequence πt,πt+1,...,πT. At the conclusion of the round, the predictor\nseesrtand incurs a loss of 1[ πt/\\e}atio\\slash=rt] if the prediction was incorrect. After observing rt, the\npredictor can choose to alter the subsequent predictions to π′\nt+1,...,π′\nT. Each time the predictor\ndecidestomodify thepredictions, aswitchingcostof kisincurred(rememberthat k≥1represents\nthe size of the cache). Thus, the total loss of the predictor is equ al to the number of prediction\nerrors plus ktimes the number of switches.\nHypotheses. Each hypothesis in our class His a possible input sequence. In the realizable\nscenario, we operate under the assumption that the actual input matches one of the hypotheses\nwithin the class. In the agnostic case we relax this assumption and pr ovide guarantees that scale\nwith the Hamming distance between the input sequence and the hypo thesis class.\nIn the realizable case we design a deterministic predictor whose tota l loss is at most klogℓ\n(recall that ℓ=|H|). It is based on majority vote or the halving algorithm [Littlestone, 1 987]. An\ninteresting and subtle point is that our predictor is improper, meanin g it occasionally predicts the\nremaining sequence of page requests in a manner that does not align with any of the hypotheses in\nH. To incorporate such improper predictors, we need to use an optim al oﬄine caching algorithm\nthat is monotone in the following sense: applying the algorithm on an inp ut sequence r1,...,r T\nproduces a caching policy which is simultaneously optimal for all preﬁx esr1,...,r tfort≤T.\nFortunately, Belady’s FitF algorithm has this property, as outlined in Observation 4.\nForthe agnosticsetting, wedesignarandomizedpredictorwith ama ximumtotallossof O(µ⋆+\nklnℓ), where µ⋆is the Hamming distance of the actual input sequence from the class H. This\npredictorutilizesamultiplicative-weightrule[LittlestoneandWarmuth ,1994],anditslearningrate\nis speciﬁcally adapted to to achieve an optimal balance between the c ost of changing predictions\n(switching costs) and the inaccuracies in the predictions themselve s (prediction errors).\nOur ﬁnal caching algorithm incorporates a predictor for this proble m in such a way that at\neach round t, it applies Belady’s FitF algorithm to the predicted suﬃx of the sequen ceπt,...,πT.\nWe then show that the cumulative loss of the predictor serves as an upper bound on the additional\nnumber of page faults that our algorithm experiences compared to the oﬄine optimal algorithm.\nOverall we obtain the following guarantees for our caching strateg y:\nTheorem 1 (Caching) .LetHbe a hypothesis class of size ℓandIbe an input instance with\noﬄine optimum value OPT(I). There is a deterministic algorithm for the realizable sett ing (i.e.,\n4\n\nI∈ H) which has cost at most OPT(I)+klogℓ. There is a randomized algorithm for the agnostic\nsetting with expected cost at most OPT(I)+(5+6 /k)µ⋆+(2k+1)lnℓ, whereµ⋆is the Hamming\ndistance between Iand the best hypothesis in H.\nOur algorithms can be robustiﬁed, i.e., we can ensure that their cost is not larger than\nO(logk)OPT(I) while loosing only a constant factor in the dependency on µ⋆and lnℓin our\nadditive regret bound, see Section 7.2 for details. Note that the pr evious methods used to achieve\nrobustness for caching usually lose an additive term linear in OPT( I), see [Wei, 2020, Blum and\nBurch, 2000, Antoniadis et al., 2023]. In Section 7.3, we describe how to extend our results to\nthe setting where each hypothesis, instead of a complete instance , is a set of parameters of some\nprediction model producing next-arrival predictions. In Section 7 .4, we show that the dependency\nonℓ,k, andµ⋆in Theorem 1 cannot be improved by more than a constant factor. O ur result\nis an improvement over the O(µ⋆+k+√Tklogℓ) regret bound of Emek et al. [2021] whenever\nT=ω(klogℓ).\n2.2 Load Balancing\nIn online load balancing on unrelated machines, we have mmachines numbered from 1 to mand\na total of njobs. The jobs arrive sequentially, and the objective is to assign ea ch job to one of\nthe machines upon its arrival in order to minimize the makespan , which is the total time that\nthe busiest machine is actively working. Each job is characterized by its type, which is an m-\ndimensional vector p. The value p(i) indicates the time required for the i-th machine to complete\nthe job. As the jobs arrive, the algorithm observes the job’s type and makes a decision on which of\nthemmachines to schedule it. These scheduling decisions are made in an onlin e manner, without\nknowledge of future jobs.\nIn the oﬄine setting, the ordering of the jobs in the input sequence does not play any role.\nIn fact, an instance of load balancing is suﬃciently described by the n umber of jobs of each type\nwhich need to be scheduled and these numbers are available to the alg orithm in advance. A\n2-approximation algorithm by Lenstra, Shmoys, and Tardos [1990] based on linear programming\nachieves a makespan that is at most twice the makespan of the optim al schedule.\nThe Learning Task: Forecasting Demand\nThe learning problem that arises in this context of makespan minimizat ion is a rather natural one\nandmightbeinterestingin othercontexts. Thegoalofthe predict oristoforecast, foreachpossible\njob type p, the number of jobs of type pthat are expected to arrive. The predictor maintains a\nprediction that includes an upper bound, denoted as np, on the number of jobs of each possible\njob type p. Similar to caching, the learning problem involves two distinct costs: p rediction errors\nand switching costs. A prediction error occurs when the actual nu mber of jobs of a particular\ntype exceeds the predicted upper bound np. The cost of a prediction error is determined by the\ntype of the job that witnessed it. A switching cost occurs when the predictor decides to modify its\nprediction (i.e., the predicted upper bounds np’s). The cost of such a modiﬁcation is the makespan\nassociated with the new prediction.2\nHypotheses. In load balancing each hypothesis fin our class Hpredicts the frequency of\nthe jobs of each type p. That is, for each type pit assigns a number fp∈[0,1] which represents\nthe fraction of jobs in the input whose type is p. We stress that the hypothesis does not predict\nthe actual number of jobs of each type, nor does it even predict t he total number of jobs in the\ninput. In practice, the numbers fpcan be estimated by past statistics. With the knowledge of\nthe correct hypothesis f, we are able to produce an integral assignment of jobs to machines at a\nlow cost. Previously studied machine-weight predictions [Lattanzi e t al., 2020] allow producing a\nfractional assignment which requires a costly rounding procedure [Li and Xian, 2021].\n2Note that the oﬄine optimal makespan does not depend on the or der of the jobs, it only depends on the number\nof jobs of each type, and hence, it is a function of the predict ed numbers npfor the types p.\n5\n\nIn the realizable scenario, we operate under the assumption that t he actual input matches one\nof the hypotheses within the class. In the agnostic case we relax th is assumption and provide\nguarantees that scale with the maximum (multiplicative) approximatio n error between the true\nfrequencies and those predicted by the best hypothesis (see belo w).\nIntherealizablecase,wedesignasimplerandomizedpredictor,ensu ringthatthetotalexpected\nloss is at most O(OPT(I)·logℓ) (recall that ℓ=|H|), where OPT( I) represents the makespan of\nthe input instance I.3The key idea is to guess the total number of jobs in the input sequen ce and\naccordingly to scale the frequencies in each hypothesis to predict t he number of jobs npof each\ntype. The randomized predictor maintains a random hypothesis con sistent with the processed\njobs. Whenever one of the predicted counts npis violated, the predictor switches to a randomly\nchosen consistent hypothesis from H, resembling the classical randomized marking strategy in\ncaching [Fiat et al., 1991].\nWe additionally present a deterministic predictor with loss of at most O(OPT(I)·log(|H|)·\nlogτ), whereτisthe numberofjob typeswith non-zerofrequencyin at leastoneo fthe hypotheses.\nThe deterministic rule predicts the median among the counts npprovided by the hypotheses for\neach job type p. The analysis of this deterministic learning rule is more intricate than t hat of the\nrandomized one. The crucial insight is that the produced “medians” prediction can be scheduled\nwithin makespan at most O(OPT(I)logτ). Our predictors in the agnostic setting are based on\nthose in the realizable case.\nOur scheduling algorithm incorporates a predictor for this problem in such a way that at\neach round t, it behaves in accordance with the algorithm of Lenstra et al. [1990], applied to the\npredicted upper bounds np’s. We demonstrate that the cumulative loss of the predictor serve s as\nan upper bound on the makespan. We obtain the following result:\nTheorem 2 (Load balancing) .There are algorithms using a deterministic and randomized p re-\ndictor respectively which, given a hypothesis class Hof sizeℓand an instance Iwith makespan\nOPT(I), satisfy the following. In the realizable setting (i.e., h(I)∈ H, whereh(I)is the distribu-\ntion corresponding to I), they produce a schedule whose makespan is at most O(logℓlogτOPT(I))\nandO(logℓOPT(I))in expectation, respectively, where τis the number of job types with non-zero\nfrequency in at least one of the hypotheses. In the agnostic c ase they produce a schedule with\nmakespan at most O(αβlogℓlogτOPT(I))andO(αβlogℓOPT(I))in expectation, respectively,\nwhereαandβdescribe the multiplicative error of the best hypothesis f⋆∈ H.\nIn agnostic case, the multiplicative error of hypothesis fwith respect to an instance with\nfrequencies f∗is deﬁned as follows. If there is a job type psuch that fp/\\e}atio\\slash= 0 and f⋆\np= 0, we\ndeﬁneα:=n+1, where ndenotes the number of jobs in the input instance. Otherwise, we de ﬁne\nα:= max{fp/f⋆\np|f⋆\np/\\e}atio\\slash= 0}. Similarly, if there is a job type psuch that fp= 0 and f⋆\np/\\e}atio\\slash= 0, we\ndeﬁneβ:=n+1. Otherwise, β:= max{f⋆\np/fp|fp/\\e}atio\\slash= 0}. We have α,β≤n+1.\nOur algorithmscan be robustiﬁed so that their competitive ratio4is never largerthan O(logm)\n(the best possible competitive ratio in the worst-casesetting [Azar et al., 1992]), while loosingonly\na constant factor in the bounds mentioned in Theorem 2, see Sectio n 5.5. In Section 5.7, we show\nthatourcompetitiveratiointherealizablecasecannotbeimprovedb ymorethanaconstantfactor.\nPrevious works focused on predictions assigning weight to each mac hine which indicates its\nexpected load [Lattanzi et al., 2020], and acquiring a solution for the fractional variant of the\nproblem. Dinitz et al. [2022] showed how to aggregate outputs of ℓalgorithms into a single\nfractionalsolution, loosingafactorof O(logℓ) comparedto the best ofthe algorithms. Afractional\nsolution can be rounded online, loosinga factor of Θ/parenleftbigloglogm\nlogloglog m/parenrightbig\nin the competitive ratio[Lattanzi\net al., 2020, Li and Xian, 2021]. Instead, we use job-type frequen cies which allow us to produce\nan integral solution directly without the costly rounding procedure . However, our approach can\nbe used to aggregate outputs of any ℓalgorithms, preserving integrality of their solutions, see\nSection 5.6.\n3We refer to the makespan of the optimal schedule for an instan ce as the makespan of the instance.\n4The maximum ratio between the cost of the algorithm and the oﬄ ine optimal solution over all instances.\n6\n\n2.3 Non-clairvoyant Scheduling\nWe consider a non-clairvoyant scheduling problem in which a single mach ine is assigned the task\nof completing a set of njobs, denoted as j1,j2,...,j n. The scheduler’s objective is to determine\nthe order in which these jobs should be scheduled such that the sum of their completion times is\nminimized.\nThe optimal ordering is obtained by sorting the jobs in ascending ord er of their processing\ntimes. However, in the non-clairvoyant setting, the scheduler doe s not know these processing\ntimes. To address this challenge, the scheduler is allowed to preempt a job before it is completed,\nmeaning that it can interrupt the ongoing execution of a job and rep lace it with another job. The\nremaining portion of the preempted job is then rescheduled for com pletion at a later time.\nThe Learning Task: Comparing Job Durations\nIn the learning task explored within this context, the objective is fo r the predictor to learn the\noptimal ordering of jobs. We investigate two variants of this learnin g problem, one suited to the\nrealizable setting and one suited to the agnostic setting.\nIn the realizable case, we adopt a similar approachto the previous se ctions. Here, each hypoth-\nesis within the class provides predictions for the processing times of allnjobs. We then design\na predictor that learns the correct hypothesis in an online fashion. Our overall scheduling algo-\nrithm in the realizable case operates by always scheduling ﬁrst the jo b with the shortest predicted\nprocessing time.\nIn the agnostic setting we follow a diﬀerent methodology which is more in line with statistical\nlearning. We use here a weaker type of hypotheses: each hypothe sis is a permutation of the njobs,\nindicating a prediction of the optimal ordering, without specifying th e exact processing times.\nIn this learning task, the predictor is provided with a training set con sisting of a small subset\nof the jobs that is sampled uniformly. For each job in the training set the predictor sees their\nlengths. Using this training set, the predictor generates a permut ationπof thenjobs.\nEach permutation πis associated with a loss5which reﬂects the performance of a scheduler\nthat follows the order suggested by π. In particular, the loss is deﬁned in such a way that the\noptimal permutation has the best (lowest) loss, and more generally permutations with faster\ncompletion times have smaller losses. The predictor we design for this task uses the training set\nto approximate the loss of every permutation in the class H, and outputs the one which minimizes\nthe (approximated) loss.\nIn order to avoid scaling issues, we formulate our guarantees for in stances with maximum job\nlength at most 1.6\nTheorem 3 (Completion Time) .Consider an input instance I, letOPT(I)denote the oﬄine\noptimal value of its total completion time objective, and le tHbe a hypothesis class of size ℓ. We\nassume, without loss of generality, that the maximum job len gth inIis at most 1. Then, there is\na deterministic algorithm which achieves total completion time at most OPT(I)+ℓ/radicalbig\n2OPT(I)in\nthe realizable setting (i.e., I∈ H). In the agnostic setting, there is a randomized algorithm t hat\nwith high probability achieves total completion time of at m ostOPT(I) +µ∗+O(n5/3log1/3ℓ),\nwhereµ∗is the diﬀerence between the total completion time of the bes t hypothesis in the class and\nOPT.\nNote that the value of OPT( I) is quadratic in nunless the size of a vast majority of jobs in I\nis either 0 or vanishing as ngrows.\n5Formally, the loss of a permutation πis the expected value of the following random variable: samp le a pair of\njobs uniformly at random; if the ordering of the jobs in πplaces the longer job before the shorter one, output the\ndiﬀerence between their respective lengths. Conversely, i f the ordering in πdoes not violate the length ordering,\noutput zero. Notice that the optimal permutation has 0 loss a nd moreover expected loss of any permutation πis\nproportional to the regret; that is, to the diﬀerence betwee n the objective achieved by πand the one achieved by\nthe optimal permutation, as shown by Lindermayr and Megow [2 022].\n6If a solution for instance Ihas total completion time objective OPT( I)+R, then the same solution on a scaled\ninstance I′obtained from Iby multiplying all job lengths by αhas objective α(OPT(I)+R) = OPT( I′)+αR.\n7\n\nWe have also found an unexpected separation: there is an algorithm for the realizable setting\nwith regret at most nlogℓon input instances containing jobs of only two distinct lengths (Sec-\ntion 6.1). On the other hand, there is no algorithm with regret o(ℓn) on instances with at least\nthree distinct lengths (Section 6.3).\nPreviouswork by Dinitz et al. [2022]showed the following. For any ǫ >0, there is an algorithm\nwhich achieves expected total completion time (1+ ǫ)OPT+O(1/ǫ5)µ∗under certain assumptions\nabout input. Therefore, their bound always gives a regret linear in O PT and a higher dependency\nonµ∗.\nAny algorithms can be robustiﬁed by running it at speed (1 −δ) simultaneously with the\nRound Robin algorithm at speed δ. This way, we get O(δ−1)-competitive algorithm in the worst\ncase, because the schedule produced by Round Robin is 2-competit ive with respect to the optimal\nschedule processed at speed δ. Dinitz et al. [2022] used the same approach to robustify their algo-\nrithm, incurring the factor1\n1−δon top of their bound quoted above. This procedure unfortunate ly\nworsens the performance of the original algorithm by a constant f actor, i.e., such robustiﬁcation\nof our algorithm achieves additive regret only with respect to1\n1−δOPT(I).\n3 Related Work\nThe closest works to ours are by Dinitz et al. [2022] and Emek et al. [20 21]. Dinitz et al. [2022]\ndesign algorithms with access to multiple predictors. They study (oﬄ ine) min-cost bipartite\nmatching, non-clairvoyant scheduling, and online load balancing on un related machines.7The\nmain diﬀerence from our approach is conceptual: while we treat the t ask of identifying the best\nprediction as an independent modular learning problem, they treat it as an integral part of their\nalgorithms. In the case of load balancing, they propose an O(logℓ)-competitive algorithm which\ncombinessolutions of ℓprediction-basedalgorithmsintoa fractionalsolution. A fractiona lsolution\ncan be rounded online, incurring an additional multiplicative factor of Θ(loglogm\nlogloglog m) wheremis\nthe number of machines, see [Lattanzi et al., 2020, Li and Xian, 202 1]. For non-clairvoyant\nscheduling for minimizing total completion time, they propose an algor ithm which works under\nthe assumption that no set of at most loglog njobs has a large contribution to OPT. Their\nalgorithm achieves a total completion time of (1 + ǫ)OPT+O(ǫ−5)µ∗for anyǫ >0, where µ∗\ndenotes the diﬀerence between the cost of the best available pred iction and the cost of the oﬄine\noptimum.\nEmek et al. [2021] study caching with ℓpredictors which predict either the whole instance, or\nthe next arrival time of the currently requested page. Based on e ach prediction, they build an\nalgorithm with performance depending on the number of mistakes in t his prediction. Then, they\ncombine the resulting ℓalgorithms using the technique of Blum and Burch [2000] to build a single\nalgorithm with a performance comparable to the best of them. Note that our approach is in a\nsense opposite to theirs: we use online learning techniques to build a s ingle predictor comparable\nto the best of the given ℓpredictions and then we use this predictor in a simple algorithm. Their\nalgorithm has a regret bound of O(µ⋆+k+√Tklogℓ), where Tis the length of the sequence, k\nis the size of the cache, and µ∗is either the hamming distance of the actual input sequence from\nthe closest predicted sequence or the number of mispredicted nex t arrival times in the output of\nthe best predictor. This bound is larger than ours unless Tis very small, e.g., o(klogℓ).\nTherearenumerousworksondata-drivenalgorithmdesign, seeth esurvey[Balcan,2021]. They\nconsider (potentially inﬁnite) hypothesis classes containing parame trizations of various algorithms\nand utilize learning techniques to identify the best hypothesis given it s performance on past data.\nThe main diﬀerence from our work is that the hypothesis is chosen du ring the analysis of past\ndata and before receiving the current input instance. In our case , learning happens as we receive\nlarger and larger parts of the current input instance.\n7They state their result for a special case called restricted assignment, because no ML-augmented algorithms\nfor unrelated machines were known at that time. However, the y mention in the paper that their approach works\nalso for unrelated machines.\n8\n\nThere are papers that consider our problems in a setting with a single black-box predictor\nwhich corresponds to our agnostic setting with a hypothesis class o f size 1. For caching, these are\n[Lykouris and Vassilvitskii, 2021, Rohatgi, 2020, Wei, 2020, Antoniad is et al., 2023]. For online\nloadbalancing onunrelated machines and its special caserestricted assignment, there areworkson\nalgorithms using predicted weights [Lattanzi et al., 2020, Li and Xian , 2021]. The papers [Purohit\net al., 2018, Wei and Zhang, 2020, Im et al., 2021, Lindermayr and Me gow, 2022] address the\nproblem of non-clairvoyant scheduling.\nOther related papers are by Bhaskara et al. [2020] who studied onlin e linear optimization with\nseveral predictions, and [Anand et al., 2022, Antoniadis et al., 2023] who designed algorithms\ncompetitive with respect to a dynamic combination of several predic tors for online covering and\nthe MTS problem, respectively. There are also works on selecting th e single best prediction for a\nseries of input instances online [Khodak et al., 2022] and oﬄine [Balcan e t al., 2021]. The main\ndiﬀerence from our work is that they learn the prediction before so lving the input instance while\nwe learn the prediction adaptively as we gain more information about t he input instance.\nOther relevant works are on various problems in online learning which c onsider switching costs\n[Cesa-Bianchi et al., 2013, Altschuler and Talwar, 2018] and on online smoothed optimization\n[Goel et al., 2019, Zhang et al., 2021, Chen et al., 2018].\nSince the seminal papers of Lykouris and Vassilvitskii [2021] and Kra ska et al. [2018], many\nworks on ML-augmented algorithms appeared. There are by now so many of these works that\nis not possible to survey all of them here. Instead, we refer to the survey of Mitzenmacher and\nVassilvitskii [2020] and to the website maintained by Lindermayr and M egow [2023].\nCaching in oﬄine setting was studied by Belady [1966]. Sleator and Tarj an [1985], laying\nthe foundations of online algorithms and competitive analysis, showe d that the best competitive\nratio achievable by a deterministic caching online algorithm is k. Fiat et al. [1991] proved that\nthe competitive ratio of randomized caching algorithms is Θ(log k). Non-clairvoyant scheduling\nwith the total completion time objective was studied by Motwani et a l. [1993] who showed that\nRound-Robin algorithm is 2-competitive and that this is the best poss ible competitive ratio. Azar\net al. [1992] proposed an O(logm)-competitive algorithm for online load balancing on unrelated\nmachines and showedthat this is the best possible. In oﬄine setting, Lenstraet al. [1990]proposed\na 2-approximation algorithm and this remains the best known algorith m. There was a recent\nprogress on special cases [Svensson, 2012, Jansen and Rohwedd er, 2017].\n4 Warm-up: Caching in the Realizable Setting\nIn this section, we describe the simplest use case of our approach a nd that is caching in the\nrealizable setting. In caching, we have a universe of pages U, a cache of size kand its initial\ncontentx0∈/parenleftbigU\nk/parenrightbig\n. As it is usual, we assume that Ucontains k”blank” pages b1,...,b kwhich are\nnever requested and x0={b1,...,b k}, i.e., we start with an empty cache. We receive a sequence\nof requests r1,...,r T∈U\\ {b1,...,b k}online. At each time step t, we need to ensure that rt\nis present in the cache, i.e., our cache xt∈/parenleftbigU\nk/parenrightbig\ncontains rt. Ifrt/∈xt−1we say that there is a\npage fault and we choose xt∈/parenleftbigU\nk/parenrightbig\nsuch that rt∈xt. This choice needs to be made without the\nknowledge of the future requests.\nWe measure the cost of a solution to a caching instance by counting t he number of page\nloads (or, equivalently, page evictions) performed when transition ing from xt−1toxtat each time\nt= 1,...,T. Denoting d(xt−1,xt) =|xt\\xt−1|, the total cost of the solution x=x1,...,x Tis\ncost(x) =T/summationdisplay\nt=1d(xt−1,xt).\nOﬄinealgorithm FitF. AnintuitiveoﬄineoptimalalgorithmFitFwasproposedbyBelady\n[1966]: if there is a page fault at time t, it evicts a page from xt−1which is requested furthest in\nthe future (FitF). In case there are pages which will never be requ ested again, it breaks the ties\narbitrarily. The following monotonicity property will be useful in our a nalysis.\n9\n\nObservation 4. Consider a request sequence r1,...,r T. For any t≤T, the cost incurred until\ntimetby FitF algorithm for sequence r1,...,r Tis the same as the cost incurred by FitF algorithm\nfor sequence r1,...,r t.\nTo see why this observation holds, it is enough to notice that the solu tion produced by FitF on\nr1,...,r Tuntil time tis the same as the solution of FitF on r1,...,r twhich breaks ties according\nto the arrival times in rt+1,...,r T.\nLearning task. In the realizable setting, we are given a class Hofℓhypotheses r1,...,rℓ∈\nUTsuch that the actual input sequence of requests ris one of them (but we do not know which\none). We split the task of designing an algorithm for this setting into t wo parts. First, we design\nan (improper) predictor that maintainsa predicted sequence π=π1,...,π T. This predictormakes\na small number of switches (changes to π) until it determines the correct hypothesis. Second, we\ndesign an algorithm which uses an access to such predictor and its pe rformance depends on the\nnumber of switches made by the predictor.\nPredictor. Our Predictor 1 below is based on a majority rule. It maintains a set Aof\nall hypotheses (sequences) in the class Hwhich are consistent with the past requests. In time\nt= 1 the set Ais initialized to be the entire class, i.e. A=H, and it is updated whenever the\ncurrent request rtdiﬀers from the predicted request πt(i.e., when there is a prediction error). The\nprediction πused by our predictor is deﬁned based on the set Aas follows: We set πt:=rtand,\nforτ=t+1,...,T, we choose πτto be the request agreeing with the largest number of hypotheses\ninA. This way, the predicted sequence πis modiﬁed exactly after time-steps twhenπt/\\e}atio\\slash=rt, and\nwhenever this happens at least half of the hypotheses in Aare removed. Observe that we assume\nthe realizable setting and hence at all times Acontains the hypothesis which is consistent with\nthe input sequence. In particular Ais never empty. This implies the following lemma:\nLemma 5. In realizable setting, Predictor 1 with a class Hofℓhypotheses makes σ≤logℓ\nswitches and the ﬁnal prediction is consistent with the whol e input.\nPredictor 1: Majority predictor for caching in realizable setting\n1fort= 1,...,Tdo\n2ift= 1or prediction πtdiﬀers from the real request rtthen // make a switch\n3 A:={i∈ {1,...,ℓ} |ri\nτ=rτ∀τ= 1,...t}; // consistent hypotheses\n4 updateπt=rtandπτ= argmax p∈U|{i∈A|ri\nτ=p}|for each τ=t+1,...,T;\nAlgorithm. Our overall algorithm (See Algorithm 2) uses Predictor 1 and maintain s the\nFitF solution x1,...,x T∈/parenleftbigU\nk/parenrightbig\nfor the current prediction πat timet. Then it changes the cache\ntoxt. This solution needs to be recomputed whenever πis modiﬁed.\nAlgorithm 2: caching, realizable setting\n1fort= 1,...,Tdo\n2ifthere is a switch then\n3 receiveπfrom the predictor;\n4 compute FitF solution x1,...,x Tforπ;\n5move to xt.\nLemma 6. Consider an input sequence rand letOPT(r)denote the cost of the optimal oﬄine\nsolution for this sequence. Algorithm 2 with a predictor whi ch makes σswitches and its ﬁnal\nprediction is consistent with rincurs cost at most\nOPT(r)+kσ.\n10\n\nProof.At every switch, we pay at most kfor switching the cache from the FitF solution of the\nprevious predicted sequence to the cache of the newly computed o ne. Thus it suﬃces to show that\nin between these switches, our algorithm has the same number of pa ge faults as OPT.\nDenotet1,...,tσthe times when switches happen; for convenience, we also deﬁne t0= 1,\ntσ+1=T+ 1. We denote π0,...,πσthe predictions such that πi−1was predicted before the\nith switch and πiafter. Let κj\nibe the cost of the FitF solution for πjpaid during time steps\nti,...,ti+1−1, fori= 0,...,σ. In this notation, the cost of OPT is/summationtextσ\ni=0κσ\ni, sinceπσ=r(recall\nthatris the input sequence), while, excluding the switching cost considere d above, the cost of the\nalgorithm is/summationtextσ\ni=0κi\ni, because it pays κi\niduring time steps ti,...,ti+1−1 when following a FitF\nsolution for πi. We use induction on ito show that κj\ni=κσ\nifor each j=i,...,σ. This implies/summationtextσ\ni=0κσ\ni=/summationtextσ\ni=0κi\ni. This essentially follows from Obsevation 4 and the fact that all sequ ences\nπj,j=i,...,σagree on the preﬁx up to time ti+1−1. The formal details follow.\nIn the base case with i= 0, Observation 4 implies that FitF solutions for each πiincur the\nsame cost during time steps 1 ,...,t1−1 and we have κ1\n0=···=κσ\n0. Fori >0, the cost of the FitF\nsolution for each πjwithj≥iduring time steps 1 ,...,ti+1−1 is/summationtexti\nm=0κj\nm=/summationtexti−1\nm=0κσ\nm+κj\niby\ninduction hypothesis. Using Observation 4,/summationtexti−1\nm=0κσ\nm+κi\ni=···=/summationtexti−1\nm=0κσ\nm+κσ\niand therefore\nκj\ni=κσ\nifor each j=i,...,σ.\nIn total, the algorithm incurs cost\nALG(r)≤σ/summationdisplay\ni=0κi\ni+σk=σ/summationdisplay\ni=0κσ\ni+σk= OPT(r)+σk.\nCombining lemmas 5 and 6, we get an algorithm for caching in a realizable s etting with the\nfollowing guarantee.\nTheorem 7. There is an algorithm for caching in realizable setting whic h, given a class Hofℓ\nhypotheses, achieves regret at most klogℓ.\nThe agnostic setting, methods of adding robustness to caching alg orithms, and lower bounds\nare discussed in Section 7.\n5 Online Load Balancing on Unrelated Machines\nWe are given a set Mofmmachines and a sequence of jobs arriving online. At each time step, w e\nreceive some job jdescribed by a vector pj, wherepj(i) is its processing time on machine i∈M.\nWe say that the job jhastypepj. We have to assign job jto one of the machines immediately\nwithout knowledge of the jobs which are yet to arrive. Our objectiv e is to build a schedule of\nminimum makespan , i.e., denoting Jithe set of jobs assigned to a machine i, we minimize the\nmaximum load/summationtext\nj∈Jipj(i) over all i∈M. The best competitive ratio achievable in online setting\nis Θ(logm) [Azar et al., 1992]. In oﬄine setting, there is a 2-approximation alg orithm.\nProposition 8 (Lenstra et al. [1990]) .There is an oﬄine 2-approximation algorithm for load\nbalancing on unrelated machines.\nHere we use the competitive ratio to evaluate the performance of our algorithms. We say that\na (randomized) algorithm ALG achieves competitive ratio r(or that ALG is r-competitive), if\nE[cost(ALG( I))]≤r·cost(OPT( I)) +αholds for every instance I, where OPT( I) denotes the\noﬄine optimal solution for instance Iandαis a constant independent of I.\nLearning task. We are given a class Hofℓhypotheses H1,...,H ℓ, each specifying the\nfrequency fp≥0 for every job type such that/summationtext\npfp= 1. For simplicity, we assume that there\nis a constant δ >0 such that all frequencies in all hypotheses are integer multiples of δ. For a\nhypothesis Hwith frequencies fpand an integer h≥1, we deﬁne a scaling H(h) as an instance\ncontaining hfp/δjobs of type p, for each p. This way, any type pwithfp/\\e}atio\\slash= 0 is represented by at\nleast a single job in H(1). We denote c0the largest makespan of H(1) over all hypotheses H∈ H.\n11\n\nWe say that an instance I′isconsistent with the input so far, if the following holds for every\njob type p: the number of jobs of type pin instance I′is greater or equal to the number of jobs\nof typepwhich already arrived in the input sequence.\nWe note that the value cof the makespan of the real instance can be guessed (up to a fact or of\ntwo) by doubling while loosing only a constant factor in the competitive ratio. Using doubling and\na 2-approximationoﬄine algorithm(Proposition8), wecan alsoﬁnd a s calingIiofeach hypothesis\nHisuch that the makespan of Iiis between cand 4c. Therefore, we start by assuming that we\nhave the value of cand the scaled instances I1,...,I ℓin advance, and postpone the discussion of\nﬁnding them to Section 5.3. We begin with the realizable setting, where the task of the predictor\nis either to identify an instance Iiconsistent with the whole input or return ERR which signals an\nincorrectvalue of c. Agnostic caseis consideredin Section 5.4and robustiﬁcationofour algorithms\nin Section 5.5. Section 5.7 contains lower bounds.\n5.1 Predictors\nWe propose a deterministic and a randomized predictors for the rea lizable setting. Each of these\npredictors receives c– the guessed value of the makespan of the real instance – and ℓprob-\nlem instances I1,...,I ℓwhose makespan is between cand 4ccreated by scaling the hypotheses\nH1,...,H ℓ. For each pandi, we denote ni\npthe number of jobs of type pin instance Ii. Both\npredictors switch to a new prediction whenever they discover that , for some p, the number of jobs\nof typepwhich arrived so far is already larger than their predicted number. A t each switch, they\nupdate a set A⊆ {1,...,ℓ}of instances which are consistent with the input up to the current\nmoment, i.e., the number of jobs of type pwhich appeared so far is at most ni\npfor allpandi∈A.\nThere is a simple proper predictor which makes ℓswitches. This predictor starts by predicting\naccording to an arbitrary instance. Whenever the current instan ce stops being consistent with the\njobs arrived so far, it removes this instance from A, and switches to an arbitrary instance still in\nA. In what follows, we provide a more sophisticated predictors with low er number of switches.\nDeterministic predictor. Our deterministic predictor is improper. At each switch, it pre-\ndicts a “median” instance ˜Icreated from the instances in Aas follows. For each type p,˜Icontains\n˜npjobs of type p, where ˜npis a median of ni\npover alli∈A. This way, whenever the number of\njobs of type pexceeds ˜np, at least half of the instances are removed from A. OnceAis empty, the\nalgorithm returns ERR. In the realizable setting, this happens when the guess of cis not correct.\nPredictor 3: load balancing on unrelated machines, deterministic\n1A:={1,...,ℓ}\n2choose ˜npas a median of {ni\np|i= 1,...,ℓ}for each job type p// switch to initial ˜I\n3fortime step when, for some pthe(˜np+1)st job of type parrivesdo\n4A:= set of instances consistent with the input so far\n5ifA=∅thenreturn ERR\n6foreach job type pdo\n7 choose ˜npas a median of {ni\np|i∈A}. // switch to a new ˜I\nLemma 9. Predictor 3 maintains a prediction which is always consiste nt with the jobs arrived\nso far. Given ℓinstances of makespan between cand4c, it makes σ≤logℓswitches before it\neither identiﬁes an instance Ii⋆consistent with the whole input, or returns ERR if there is no such\ninstance. The makespan of each prediction is at most 4clogτ, whereτis the number of distinct\njob types present in the instances I1,...,I ℓ.\nProof.First, note that whenever a number of jobs of some type exceeds the prediction, Predictor3\nswitches to a new prediction consistent with this number.\n12\n\nConsider a switch when the number of jobs of type pexceeds ˜np. Since ˜npwas chosen as a\nmedian of ni\npoveri∈A, the size of Adecreases by factor of at least 2 by this switch. Therefore,\nwe have at most log ℓswitches.\nNow, we bound the makespan of ˜Iby 4clogτ, where˜Iis the prediction constructed from the\ncurrent set of instances A. We do this by constructing a schedule for ˜I. We say that an instance\nIicovers type p, ifni\np≥˜np. By the construction of ˜I, we have that for every p, at least half of\nthe instances in Acoverp. This implies that we can ﬁnd an instance Iicovering half of the job\ntypes. Indeed, consider a matrix Mwhose columns correspond to instances iinAand its rows\ntoτ′≤τdiﬀerent job types ppresent in instances of A. We deﬁne Mp,ias 1 ifIicoverspand 0\notherwise. Since every row has at least |A|/2 ones, there are at least τ′|A|/2 ones in Mso there\nmust be a column iofMcontaining τ′/2 ones.\nSo, we pick Iiand add all its jobs to the schedule, using a schedule of Iiof makespan at most\n4c. Then we remove ifromA, and remove all job types covered by Iifrom˜I.|A|decreases by\n1,τ′decreases by factor of 2, and we still have that every remaining jo b type is covered by at\nleast|A|/2 instances: This follows since for any type pnot covered by Ii, the number of instances\ncovering it remains the same while |A|decreases by 1. Therefore, after iterating this process at\nmost log τtimes we cover all job types using makespan at most 4 clogτ.\nRandomized predictor. Our randomized predictor is proper. At each switch, it predicts\nan instance Ii, whereiis chosen from Auniformly at random. We show that it satisﬁes the same\nbound on the number of switches as Predictor 3, but the makespan of its predictions is much\nsmaller.\nPredictor 4: load balancing on unrelated machines, randomized\n1A:={1,...,ℓ}choosei∈Auniformly at random\n2set ˜np=ni\npfor each job type p // switch to initial ˜I\n3fortime step when, for some pthe(˜np+1)st job of type parrivesdo\n4A:= set of instances consistent with the input so far\n5ifA=∅thenreturn ERR\n6choosei∈Auniformly at random\n7set ˜np=ni\npfor each job type p // switch to a new ˜I\nLemma 10. Predictor 4 maintains a prediction which is always consiste nt with the jobs arrived\nso far. Given ℓinstances of makespan between cand4c, it makes σ≤logℓswitches in expectation\nbefore it either identiﬁes an instance Ii⋆consistent with the whole input, or returns ERR if there\nis no such instance. Each prediction has makespan at most 4c.\nProof.First, note that whenever a number of jobs of some type exceeds the prediction, Predictor4\nswitches to a new prediction consistent with this number.\nNow, we bound the expected numberofswitchesdone by Predictor 4in the styleofthe airplane\nseat problem. For every i= 1,...,ℓ, deﬁnetias the time step when an arriving job of type p\nexceedsni\np, or∞if no such time step exists. Note that for every instance iwhich is inconsistent\nwith the input, tiis ﬁnite. The instances are eliminated in the order of increasing ti. Since we\nchooseiuniformly at random over the remaining instances, we have tj≤tifor at least half of\nthe inconsistent instances (in expectation). The formal proof th en follows from the traditional\nanalysis of the lost boarding pass problem, see e.g. [Grimmett and Stir zaker, 2021].\n5.2 Algorithm\nOuralgorithmuses a predictorwhosepredictions arealwaysconsist ent with the jobs arrivedso far.\nAt each switch, it computes a 2-approximation of the optimal solutio n for the predicted instance\nusing the algorithm from Proposition 8 and schedules jobs based on t his solution until the next\nswitch.\n13\n\nAlgorithm 5: load balancing on unrelated machines\n1foreach incoming job jdo\n2ifthis is the ﬁrst job or there was a switch then\n3 get a new prediction ˜Ifrom the predictor or return ERR\n4 compute Lenstra(˜I)\n5assignjto a machine based on Lenstra(˜I)\nLemma 11. Given a predictor which makes σswitches and produces predictions that are always\nconsistent with the jobs arrived so far and have makespan at m ostκ, Algorithm 5 uses makespan\nat most 2κσand either schedules all jobs in the input sequence or report s ERR if none of the\ninstances is consistent with the input sequence.\nProof.At each switch, Algorithm 5 starts building a new schedule for the pre dicted instance with\nmakespan at most 2 κ. Therefore the total makespan is at most 2 κσ.\n5.3 Guessing the Optimal Makespan and Scaling\nFirst, we discuss how to ﬁnd a scaling of a hypothesis Hthat has the required makespan. Let c\nbe our estimate of OPT such that c≤OPT≤2c. We start with h= 1 and keep doubling huntil\nLenstra(H(h)) becomes at least 2 c. (and at most 4 c). Since Lenstra is a 2-approximation, we\nknow that when Lenstra(H(h))≥2cthen OPT( H(h))≥c. Since this is the smallest hfor which\nLenstra(H(h))≥2cwe know that OPT( H(h/2))≤2cso OPT( H(h))≤4c.\nAlgorithm 6 is our scheduling algorithm. We start with the initial guess o fc0for the optimal\nsolution, where c0is an upper bound on the makespan of H(1) for each H∈ H. At each iteration\nwe double our guess c. We scale the hypotheses to build instances with makespan between cand\n4c. We run Algorithm 5 with these instances until it returns error. We k eep iterating until the\nwhole input is processed.\nAlgorithm 6: guessing the optimal makespan by doubling\n1forc=c0,...,21c0,22c0,23c0,...do\n2fori= 1,...,ℓdo\n3 ﬁnd scaling hi\ncsuch that Ii:=Hi(hi\nc) has makespan between cand 4c\n4Run Algorithm 5 with I1,...,I ℓ\n5ifnot ERR thenﬁnish: all the jobs are scheduled\nLemma 12. If Algorithm 6 uses makespan at most γcin an iteration with guess c, then it uses\nmakespan at most O(γ)c⋆, wherec⋆denotes the value of cin the last iteration.\nProof.The total makespan used by the algorithm is at most\nlog(c⋆/c0)/summationdisplay\ni=02ic0γ≤2c⋆γ.\nLemma 13. Letc⋆be the value of cin the last iteration of Algorithm 6 in the realizable settin g.\nThen the makespan of the oﬄine optimal solution is at least c⋆/2.\nProof.LetHi⋆bethecorrecthypothesisdescribingtheinputinstance I. Weknowthat Hi⋆(hi⋆\nc⋆/2)/subsetnoteql\nI, otherwise Algorithm 6 would terminate in the previous iteration. We h ave\nc⋆/2≤OPT(Hi⋆(hi⋆\nc⋆/2))≤OPT(I),\n14\n\nimplying OPT( I)≥c⋆/2. The ﬁrst inequality is by the choice of hi⋆\nc⋆/2and the last one since\nHi⋆(hi⋆\nc⋆/2)/subsetnoteqlI.\nTheorem 14. There are algorithms for the realizable setting with determ inistic and randomized\npredictors which, given a hypothesis class Hof sizeℓ, achieve competitive ratio O(logℓlogτ)and\nO(logℓ)respectively, where τis the total number of diﬀerent job types in H.\nProof.CombiningLemmas12and13,themakespanachievedbyAlgorithm6isa tmostO(γOPT).\nBy Lemmas 9, 10, and 11, we have γ= logℓlogτin case of the deterministic Predictor 3 and\nγ= logℓin case of the randomized Predictor 4.\n5.4 Agnostic Setting\nThe algorithm above works also in the agnostic setting. Let fpandf⋆\npbe the frequency of job\ntypepaccording to a hypothesis H∈ Hand its true frequency, respectively. If there is a job type\npsuch that fp/\\e}atio\\slash= 0 and f⋆\np= 0, we deﬁne αH:=n+1, where ndenotes the number of jobs in the\ninput instance. Otherwise, we deﬁne αH:= max{fp/f⋆\np|f⋆\np/\\e}atio\\slash= 0}. Similarly, if there is a job type\npsuch that fp= 0 and f⋆\np/\\e}atio\\slash= 0, we deﬁne βH:=n+1. Otherwise, βH:= max{f⋆\np/fp|fp/\\e}atio\\slash= 0}.\nNote that both αHandβHare at most n+1: the smallest f⋆\np>0 is at least 1 /nfor the job types\nrepresented by a single job and the same holds for the scaling H(1) of each hypothesis H∈ H.\nLetH∈ Hbe a hypothesis achieving the smallest product αHβH. We call a pair ( α,β), where\nα=αHandβ=βHthe error of hypothesis class H.\nWe prove the following variant of Lemma 13 for agnostic setting, in th e case with α,β≤n.\nLemma 15. Letc⋆be the value of cin the last iteration of Algorithm 6 in the agnostic setting,\ngiven a hypothesis class Hwith error α,β≤n. Then, the makespan of the oﬄine optimal solution\nis at leastc⋆\nO(αβ).\nProof.The main idea here is that even if all hypothesis are incorrect, Algorit hm 6 terminates\nonce the input instance Iis subsumed by a large enough scaling of some hypothesis. Consider\nthe correct hypothesis H⋆forIconsisting of real frequencies f⋆\npfor each job type p(H⋆may not\nbe inHin the agnostic setting) and the best hypothesis H∈ H(such that α,β=αH,βH). We\nassume below that αandβare integers, otherwise we round them up to the closest integers.\nWe have the following: I=H⋆(h) for some integer scaling h. Since, f⋆\np≤βfp, we have\nH⋆(h)⊆H(βh). Therefore,inthelastiterationofAlgorithm6,wehave c⋆withinaconstantfactor\nfrom the optimum makespan of H(βh) Similarly, since fp≤αf⋆\np, we have that H(βh)⊆H⋆(αβh)\nwhich implies that the optimum makespan of H(βh) is at most αOPT(H⋆(βh))≤αβOPT(I).\nAltogether, we have c⋆≤O(αβOPT(I)).\nTheorem 16. There are algorithms for the agnostic setting with determin istic and randomized\npredictors which, given a hypothesis class Hof sizeℓwith error (α,β), achieve competitive ratio\nO(αβlogℓlogτ)andO(αβlogℓ),respectively, where τis the total number of diﬀerent job types in\nH.\nProof.Consider an algorithm which schedules all jobs of type psuch that fp= 0 according to all\nhypotheses in Hto the machine argmin i∈[m]pi, i.e., the machine which can process the job fastest.\nLetJ0denote the set of such jobs. All other jobs in I\\J0are scheduled using Algorithm 6. The\nresulting makespan is at most\n|J0|OPT+γc∗≤ |J0|OPT+O(αβγ)OPT\nwherec∗is the value of cin the last iteration of Algorithm 6 processing jobs in I\\J0. This is\nbecause, for every j∈J0, we have OPT ≥mini∈[m]pi. The inequality follows from lemmas 15\nand 12.\nIf|J0|>0, then at least one of αandβis at least n+1. Therefore, our makespan is always\nat mostαβγOPT. By lemmas 9, 10, and 11, we have γ= logℓlogτin case of the deterministic\nPredictor 3 and γ= logℓin case of the randomized Predictor 4.\n15\n\n5.5 Achieving Robustness\nWith large α,β, the competitive ratio in Theorem 16 might be worse than O(logm) which is\nachievable without predictions, i.e., Algorithm 6 is not robust. This can be ﬁxed easily: once\nAlgorithm 5 returns ERR at iteration c, we run a classical online algorithm by Azar et al. [1992]\nas long as it uses makespan γc. That is, we stop it as soon as its makespan go above γc(and we\ndo not schedule the job that makes it go above γc. This increases the makespan of the solution\nby factor at most 2 and ensures that OPT ≥γc/O(logm).\nAlgorithm 7: robust variant of Algorithm 6\n1forc=c0,...,21c0,22c0,23c0,...do\n2fori= 1,...,ℓdo\n3 ﬁnd scaling hi\ncsuch that Ii:=Hi(hi\nc) has makespan between cand 4c\n4Run Algorithm 5 with I1,...,I ℓ\n5Run Online algorithm of Azar et al. [1992] as long as it uses makespan of at mostγc\n6ifall jobs are scheduled thenﬁnish\nThe following lemma holds both in realizable and in the agnostic setting.\nLemma 17. The makespan of the solution produced by Algorithm 7 is at mos t a constant factor\nhigher than of Algorithm 6. Moreover, its competitive ratio is always bounded by O(logm).\nProof.Algorithm 6 terminates once it ﬁnds c⋆andi, such that the actual instance Iis a subset of\nHi(hi\nc⋆). With the same c⋆, Algorithm 7 terminates as well. While Algorithm 6 uses a makespan\nof at most γc⋆in each iteration, Algorithm 7 uses makespan of at most 2 γc⋆in each iteration.\nNow we prove the O(logm) bound on the competitive ratio. Consider I′⊆Ithe set of jobs\nassigned to machines by the online algorithm of Azar et al. [1992] in the next to last iteration\n(line 5 of Algorithm 7). We have OPT( I)≥OPT(I′)≥γc⋆/2\nO(logm)because the online algorithm\nisO(logm)-competitive and it required makespan γc⋆/2 in the second to last iteration. Since\nAlgorithm 7 uses makespan at most O(γc⋆) by Lemma 12, the bound on its competitive ratio\nfollows.\n5.6 A note on combining arbitrary integral algorithms\nDinitz et al. [2022] considered a portfolio of ℓalgorithms for load balancing on unrelated machines\nandproposedawaytocombinetheiroutputs in asinglefractionalso lutionofcostatmost O(logℓ)-\ntimes higher than the cost of the best algorithm in the portfolio. Suc h solution can be rounded\nonline only by loosing an additional factor of Θ(loglog m/logloglog m).\nOur approach described above can be used to produce directly an in tegral solution as far as\nall the algorithms in the portfolio are integral. The cost of this solutio n is at most O(logℓ)-times\nhigher than the cost of the best algorithm in the portfolio.\nWe guess the value cof the makespan achieved by the best algorithm in the potfolio using\nthe doubling trick, loosing a constant factor due to this guessing as in Section 5.3. We create a\nrandomized predictor similar to Predictor 4 as follows. Start with the set of active algorithms\nA:={1,...,ℓ}and predict an algorithm chosen from Auniformly at random. Once its makespan\nexceedsc, we update Ato include only those algorithms whose current makespan is at most\nc, choose one of them uniformly at random and iterate. We continue e ither until all jobs are\nscheduled or until Ais empty which signals an incorrect guess of c. At each time step, we schedule\nthe current job based on a decision of the algorithm currently chos en by the predictor, paying at\nmostcwhile following a single algorithm. An argument as in the proof of Lemma 1 0 shows that\nour predictor switches O(logℓ) algorithms in expectation at each iteration.\n16\n\n5.7 Lower Bound\nOur lower bound holds for a special case of load balancing on unrelate d machines called restricted\nassignment , where processing of each job jis restricted to a subset Sjof machines, i.e., its\nprocessing time is 1 on all machines belonging to Sjand +∞otherwise. Our construction requires\nm≥ℓmachines and is inspired by the construction of Azar et al. [1992] ( ℓis number of hypothesis\ninHas before). Since we can ensure that all jobs have inﬁnite process ing time on machines\nℓ+1,...,m, we can assume that ℓ=mand that ℓis a power of two.\nWe construct ℓinstances of restricted assignment on ℓmachines, each with makespan c∈N.\nIn instance i∈ {1,...,ℓ}, there are cℓ/2jjobs restricted to machines whose index agrees with iin\nthej−1 most signiﬁcant bits, for j= 1,...,logℓ. In particular, each instance starts with cℓjobs\nwhich can be processed on any machine. The jobs arrive in iterations fromj= 1 to log ℓ(from\nless restricted to more restricted). If numbers iandi′have a common preﬁx of length j−1, then\ninstances iandi′have the same jobs in the ﬁrst jiterations.\nOptimal solution for instance ican be described as follows: For each j= 1,...,logℓ, schedule\nallcℓ/2jjobs evenly on machines whose index agrees with iup to bit j−1 but disagrees with i\nin bitj: There are ℓ/2j−1−ℓ/2j=ℓ/2jsuch machines. We leave all the machines which agree\nwithiin the ﬁrst jbits empty for the following iterations. Since, for each j, we schedule cℓ/2j\njobs evenly on ℓ/2jmachines, their load is c.\nTheorem 18. There is no (randomized) algorithm which, with a hypothesis class of size ℓ≤m,\nthat achieves competitive ratio o(logℓ).\nProof.The adversary chooses the correct instance ibit by bit, ﬁxing the jth bitijat the end\nof iteration jdepending on the behavior of the algorithm. Bit ijis chosen according to the\nfollowing procedure: Given the knowledge of the distribution over alg orithm’s decisions, count\nthe expected number of jobs from iterations 1 ,...,jassigned to machines whose ﬁrst jbits are\ni1,...,ij−1,0. If this number is higher than the expected number of jobs assign ed to machines\nwith preﬁx i1,...,ij−1,1, then choose ij= 0. Otherwise, choose ij= 1.\nFor each j= 1,...,logℓ, we denote Mjthe set of machines with preﬁx i1,...,ij, withM0=\n{1,...,ℓ}. We show by induction on jthat at least1\n2jcℓ/2jjobs are assigned to the machines\nbelonging to Mjin expectation. This way, Mlogℓcontains a single machine with expected load at\nleast1\n2clogℓ.\nThe base case j= 1 of the induction holds: We assign cℓjobs toℓmachines in M0andi1is\nchosen so that machines in M1get at least half of them, in expectation. For j >1, the expected\nnumber of jobs from iterations up to j−1 assigned to machines in Mj−1is at least1\n2(j−1)cℓ/2j−1\nby the induction hypothesis. There are cℓ/2jjobs restricted to machines in Mj−1scheduled in\niteration j. Therefore, the total expected number of jobs from iterations 1,...,jassigned to\nmachines in Mj−1is at least\n1\n2(j−1)cℓ\n2j−1+cℓ\n2j=jcℓ\n2j.\nSinceijis chosen such that the machines in Mjare assigned at least half of the jobs assigned to\nmachines in Mj−1in expectation, the expected number of jobs assigned to Mjis at leastc\n2jℓ/2j.\nWhile the makespan for the instance iisc, the machine in Mlogℓhas expected load at least\n1\n2clogℓ, showing that the competitive ratio of the algorithm is at least1\n2logℓ.\n6 Non-clairvoyant Scheduling\nWe have a single machine and njobs available from time 0 whose lengths p1,...,p nare unknown\nto the algorithm. We know the length pjof the job jonly once it is ﬁnished. If it is not yet\nﬁnished and it was already processed for time xj, we only know that pj≥xj. Our objective is to\nminimize the sum of the completion times of the jobs. To avoid scaling iss ue in our regret bounds,\nwe assume that the length of each job is at most 1. Note that if a solu tion for instance Ihas total\ncompletion time objective OPT( I) +R, then the same solution on a scaled instance I′obtained\n17\n\nfromIby multiplying all job lengths by αhas objective α(OPT(I)+R) = OPT( I′)+αR. There\nis a 2-competitive Round Robin algorithm which runs all unﬁnished jobs simultaneously with the\nsame rate [Motwani et al., 1993]. Consider an algorithm which schedule s the jobs in order 1 ,...,n,\ndenoting p1,...,p ntheir lengths. Then, its total completion time objective can be expr essed as\nn/summationdisplay\nj=1j/summationdisplay\ni=1pj=n/summationdisplay\nj=1pj(n−j+1).\nThis objective is minimal if p1≤ ··· ≤pnwhich is the ordering chosen by the optimal algorithm\nShortest Job First (SJF) for the clairvoyant setting where we kno w lengths of all the jobs in\nadvance [Motwani et al., 1993].\nLearning task. We are given a class Hofℓhypotheses, each of them speciﬁes length of\nall jobs, denoting pi\njthe length of job jaccording to the hypothesis Hi. A predictor uses Hto\nproduce prediction π, whereπjis the predicted length of the job j. We call a predictor monotone\nif, at each time step, it maintains a prediction which is consistent with o ur knowledge about job\nlengths and πj≤pjholds for every job j(i.e., it never overestimates a length of a job). We\npropose a monotone predictor only for the realizable setting. Non- clairvoyant scheduling in the\nagnostic setting is considered in Section 6.2 with a diﬀerent kind of hyp otheses.\nPredictor. We propose a monotone predictor which works as follows. At the beg inning, we\nstart with A:={1,...,ℓ}. At each time instant t, we remove from Aeach hypothesis isuch that\nthere is some job jwhich was already processed for time xj> pi\nj. Whenever Achanges, we switch\nto a new prediction by updating the predicted lengths of unﬁnished j obs as follows. For every\nunﬁnished job, we predict the smallest length speciﬁed by any instan ce inA.\nPredictor 8: non-clairvoyant scheduling, realizable setting\n1fort= 0or whenever some hypothesis is removed from Ado\n2U:= set of unﬁnished jobs\n3forj∈Udoπj:= min{pi\nj|i∈A}// switch: update pred. unfinished jobs\nLemma 19. In the realizable setting, Predictor 8 is monotone and makes σ≤ℓswitches.\nProof.Switch happens whenever xj=πjfor some unﬁnished job j. In that case, the hypothesis\npredicting πjfor jobjis removed from A; therefore there can be at most ℓswitches.\nIn the realizable setting, there is a hypothesis i⋆which is correct and is never removed from\nA. Therefore, at each time instant, we have πj≤πi⋆\nj=pjfor any job j.\nAlgorithm. At each time instant, our algorithm receives the newest prediction f rom the\npredictor and always processes the job whose current predicted length is the smallest. When a\nswitch happens, it interrupts the processing of the current job, leaving it unﬁnished.\nAlgorithm 9: non-clairvoyant scheduling\n1foreach time instant tdo\n2U:= set of unﬁnished jobs\n3get the newest prediction πfrom the predictor\n4run jobj:= argmin j∈U{πj}\nLemma 20. With a monotone predictor which makes σswitches, Algorithm 9 produces a schedule\nwith total completion time at most OPT(I)+σ/radicalbig\n2OPT(I)on an input instance Iwith job lengths\nbounded by 1and oﬄine optimal completion time of OPT(I).\n18\n\nProof.We relabel the jobs so that p1≤ ··· ≤pn. The optimal solution is to schedule them in this\nexact order, always running the shortest unﬁnished job, achievin g total completion time\nOPT(I) =n/summationdisplay\ni=1pi·(n−i+1).\nAt each switch of the predictor, our algorithm leaves the current j ob unﬁnished. On the other\nhand, whenever a job jis completed, it must have been the shortest unﬁnished job, becau se it\nwas the unﬁnished job with the shortest πjand we have pj≤πj≤πj′≤pj′for any unﬁnished\njobj′by the monotony of the predictor. Therefore, the total complet ion time of the algorithm is\nALG(I)≤n/summationdisplay\ni=1(Ci+pi)·(n−i+1),\nwhereCiis the time between the completion of jobs i−1 andispent processing jobs which were\nleft unﬁnished due to a switch – we denote the set of these jobs by Qi. Algorithm 9 processes a\njobjonly when πj≤πj′for all unﬁnished jobs j′. Therefore, each job j∈Qican contribute to\nCiat mostπj≤πi≤pi, by the monotony of the predictor. Therefore we can bound the c ost of\nthe algorithm as follows:\nALG(I) = OPT( I)+n/summationdisplay\ni=1Ci·(n−i+1)≤n/summationdisplay\ni=1/summationdisplay\nj∈Qipi(n−i+1).\nNote that σ=/summationtextn\ni=1|Qi|. So, the sum in the right-hand side contains σsummands and each of\nthem can be bounded by/radicalbig\n2OPT(I), since we have\n/parenleftbig\npi(n−i+1)/parenrightbig2≤2pi(n−i+1)2\n2≤2n/summationdisplay\nk=ipi(n−k+1)≤2n/summationdisplay\nk=ipk(n−k+1)≤2OPT(I).\nThe ﬁrst inequality follows since pi≤1 and the third inequality since pi≤pkfor each k≥i.\nTherefore, we have\nALG(I)−OPT(I)≤σ/radicalbig\n2OPT(I).\nLemma 19 and Lemma 20 imply the following theorem.\nTheorem 21. Consider an instance Iwith maximum job length 1 and let OPT(I)be the oﬄine\noptimal completion time of I. There is an algorithm for the realizable setting which, giv en a\nhypothesis class Hof sizeℓ, achieves objective value at most OPT(I)+ℓ/radicalbig\n2OPT(I).\n6.1 Instances with Two Distinct Lengths\nConsiderthe casein which the largerjobs havelength 1 and the smalle rones havelength λ∈[0,1).\nWe propose the following predictor which makes only log ℓswitches and constructs its prediction\nbased on the majority rule.\nPredictor 10: non-clairvoyant scheduling with two distinct lengths\n1fortime instant tdo\n2ift= 0or some prediction was shown to be wrong then\n3 A:= set of instances consistent with the input so far\n4 U:= set of unﬁnished jobs\n5 forj∈Udoπj:= argmax x=1,λ|{pi\nj=x|i∈A}|// majority prediction\nBy its deﬁnition, Predictor10 makesa switch everytime its prediction is shown to be incorrect.\nThe following lemma bounds its total number of switches.\n19\n\nLemma 22. Predictor 10 makes makes at most logℓswitches in total.\nProof.When a prediction πjis shown to be incorrect, the predictor makes a switch and the size\nofAdecreases by at least factor of 2, because the length of jwas predicted to be πjby at least\nhalf of the hypotheses in A. Therefore, there can be at most log ℓswitches.\nOur algorithm works as follows. If there is an unﬁnished job jwithπj=λ, it runs it to\ncompletion. Otherwise, it chooses an unﬁnished job predicted to ha ve length 1 uniformly at\nrandom and runs it to completion. The following lemma is useful for the analysis.\nAlgorithm 11: non-clairvoyant scheduling with two distinct lengths\n1fortime step 0and whenever some job is ﬁnished do\n2update the prediction π\n3U:= set of unﬁnished jobs\n4ifthere isj∈Us.t.πj=λthenrunjuntil it is completed\n5elsechoosejfromUuniformly at random and run it to completion\nLemma 23. Consider two schedules without preemption such that the sec ond one diﬀers from the\nﬁrst one by moving a single job of size 1 earlier, jumping over djobs. Then the total completion\ntime of the second schedule is larger by at most d−/summationtextd\ni=1piwherep1,...,p dare the processing\ntimes of the jobs which were delayed. This diﬀerence is at mos t(1−λ)d. If all these djobs have\nlengthλ, then the diﬀerence is exactly (1−λ)d.\nProof.Thecompletiontimeofthejobweshifted earliergetsmallerby/summationtextd\ni=1pi, andthecompletion\ntime of the djobs which were delayed increases by at most 1. All other completion times do not\nchange.\nLemma 24. Algorithm 11 for instances with job lengths in {1,λ}with a predictor which makes\na switch whenever its prediction is shown to be incorrect and makesσswitches in total produces\na schedule with expected total completion time at most OPT(I)+σ(1−λ)n, whereOPT(I)is the\ntotal completion time of the oﬄine optimal solution.\nProof.The oﬄine optimum schedules all jobs of length λbefore the jobs of length 1. If we ﬁnish a\njob and there was no switch, the prediction of its length was correc t. We write σ=σ′+σ′′, where\nσ′is the number of times we process a job with incorrect predicted leng thλ(type-1 switch) and\nσ′′is the number of times we process a job with incorrect predicted leng th 1 (type-2 switch).\nEvery type-1 switch causes a job of length 1 to be scheduled befor e at most njobs of length λ.\nBy Lemma 23, the schedule produced by the algorithm is more expens ive than the solution where\ntheseσ′jobswereexecutedlastbyatmost σ′(1−λ)n. Itremainstoanalyzebyhowmuchthismod-\niﬁed schedule, in whichtype-1switchesneverhappen, ismoreexpen sivethan the optimalschedule.\nWe split the time horizon into intervals moments when a type-2 switch h appens (recall that\nthe switch happens right after we scheduled a short job with predic ted length 1). There are σ′′+1\nintervals i= 0,1,...,σ′′. We denote by qithe number of jobs of predicted length λscheduled ﬁrst\nin theith interval (including the ﬁrst job causing the type-2 switch) and b ymithe number of\njobs of predicted length 1 scheduled thereafter in the ith interval. Let nidenote the total number\nof unﬁnished jobs when we ﬁnish scheduling the qijobs of predicted length λ, and let sibe the\nnumber of unﬁnished jobs of length λat that time. We have qi=si−1−si.\nWith this notation and using Lemma 23, the regret of the algorithm is\n(1−λ)σ′′−1/summationdisplay\ni=0misi\nThis is because the optimal schedule processes jobs of length λﬁrst and our schedule can be con-\nstructed by moving (one by one) mijobs of length 1 forward, leaving sijobs of length λbehind\nfor each i= 1,...,σ′′.\n20\n\nSince we choose to process a random job of predicted length 1 we ha veE[mi|ni,si] =ni+1\nsi+1≤\nn\nsi, as we are drawing from nijobs without replacement until the ﬁrst of sijobs of size λis drawn.\nTherefore E[mi|si]≤n/siandE[misi] =/summationtextn\nj=1P(si=j)E[misi|si=j]≤n. So, the expected\nregret in case a type-1 switch never happens is\n(1−λ)σ′′−1/summationdisplay\ni=0E[misi]≤(1−λ)nσ′′.\nTherefore, the cost of the algorithm is ALG ≤OPT+(1 −λ)nσ.\nLemma 22 and Lemma 24 together imply the following theorem.\nTheorem 25. Consider an instance Iwith jobs of length either 1 or λfor some ﬁxed λ∈(0,1).\nThere is an algorithm which, given a hypothesis class Hof sizeℓ, produces a schedule with expected\ntotal completion time at most OPT(I) +σ(1−λ)nin the realizable setting (i.e., I∈ H), where\nOPT(I)is the total completion time of the oﬄine optimal solution.\n6.2 Agnostic Setting\nWe propose an algorithm for the agnostic setting with a diﬀerent typ e of hypotheses, each speci-\nfying an optimal ordering of the jobs rather than their lengths. Giv en a class of such hypotheses\nH, the predictor maintains an ordering πand, at each switch, it can change the ordering of the\nunﬁnished jobs. Let J={1,...,n}be the set of all jobs. We call a mistakeevery inversion in this\nordering, i.e., two jobs i,j∈Jsuch that pi< pjbutπ(j)< π(i). For every pair of jobs {i,j}, we\ndeﬁne\nµ(π,{i,j}) =/braceleftBigg\n(pi−pj)+ifπ(i)< π(j)\n(pj−pi)+otherwise.\nIf the order of i jinπis incorrect, then µ(π,{i,j}) is the weight of this mistake. Otherwise, it is\nequal to 0. For a set of pairs of jobs P⊆/parenleftbigJ\n2/parenrightbig\n, where/parenleftbigJ\n2/parenrightbig\ndenotes the set of all pairs of jobs, we\ndenoteµ(π,P) =/summationtext\n{i,j}∈Pµ(π,{i,j}), andµ(π) =µ(π,/parenleftbigJ\n2/parenrightbig\n) is the total weight of mistakes in π.\nProposition 26 (Lindermayr and Megow [2022]) .LetOPTdenote the cost of the oﬄine optimal\nsolution and cost(π)the cost of the solution where the jobs are processed accordi ng to the ordering\nπ. Thencost(π)−OPT =µ(π).\nPredictor. It has a parameter m. First, it samples mpairs of jobs, P={{ji,j′\ni} |i=\n1,...,m}. The initial predicted permutation starts with these jobs, i.e., j1,j′\n1,...,j m,j′\nmand the\nrest of the jobs follow in an arbitrary order. Once the lengths of th e jobs in Pare determined,\nthe predictor calculates µ(h,P) for each h∈ H. Then, it makes a switch to its ﬁnal prediction by\nordering the jobs not contained in Paccording to the hypothesis with the smallest µ(h,P).\nPredictor 12: non-clairvoyant scheduling, agnostic case\n1At time 0: sample mpairs of jobs P\n2When the last job in Pis completed:\n3forh∈ Hdocompute µ(h,P)\n4Switch to a new prediction based on ˆhwith minimum µ(ˆh,P)\nPredictor 12 makes only one switch which happens at the moment whe n the last job from P\nis completed.\nLemma 27. Letπbe the ﬁnal prediction produced by Predictor 12 during its on ly switch. With\nprobability (1−δ), we have µ(π)≤µ(h∗)+O(n5/3(logℓ\nδ)1/3), whereh∗denotes the best hypothesis\ninH.\n21\n\nProof.The total weight of the mistakes in the last prediction can be bounde d by\nµ(π)≤µ(ˆh)+2mn, (1)\nwhereˆhis the hypothesis chosen at line 4. This follows because the 2 mjobs belonging to Pwhich\nare at the beginning of πhave length at most 1 and each of them delays the completion of at mo st\nnjobs. We need to show that, with high probability, we have to show th atµ(ˆh) similar to µ(h∗).\nFor each hypothesis h∈ Hand a pair {i,j} ∈/parenleftbig[n]\n2/parenrightbig\nchosen uniformly at random, we denote\nρh=E[µ(h,{i,j})] =µ(h)//parenleftbign\n2/parenrightbig\n. Since the pairs in Pare chosen uniformly at random, we have\nE[µ(h,P)] =ρhmfor each h∈ H. Now we use Hoeﬀding’s concentration inequality [Vershynin,\n2018, Thm 2.2.6] to show that µ(h,P) is close to its expectation with a high probability. Choosing\nm= log(2ℓ/δ)/2ǫ2, whereǫis a parameter to be decided later, we have\nP/parenleftbig\n|µ(h,P)−ρhm|> ǫm/parenrightbig\n≤2exp/parenleftbig\n−2(ǫm)2/m/parenrightbig\n= 2exp(−2ǫ2m)≤δ/ℓ,\nforeachh∈ H. So, by aunion bound, with probabilityat least1 −δ, wehave |µ(h,P)−ρhm| ≤ǫm\nfor all hypothesis h∈ Hand the chosen hypothesis ˆhmust have ρˆh≤ρh⋆+2ǫ. Multiplying by/parenleftbign\n2/parenrightbig\nwe getµ(ˆh)≤µ(h∗)+2ǫ/parenleftbign\n2/parenrightbig\nwith probability 1 −δ.\nThe total weight of mistakes in the ﬁnal prediction πis bounded as follows:\nµ(π)≤µ(h∗)+2ǫ/parenleftbiggn\n2/parenrightbigg\n+log(2ℓ/δ)\nǫ2n.\nWe choose ǫ=O/parenleftbiglog(ℓ/δ)\nn/parenrightbig1/3, getting µ(π)≤µ(h∗)+O/parenleftbig\nn5/3(logℓ\nδ)1/3/parenrightbig\nwith desired probability.\nAlgorithm. At each step, it chooses the ﬁrst unﬁnished job in the predicted or dering and\nruns it until it is completed.\nAlgorithm 13: non-clairvoyant scheduling, agnostic case\n1foreach time instant tdo\n2run the ﬁrst unﬁnished job according to the current prediction π\nLemma 28. Given a predictor which makes switches only at moments when s ome job is completed,\nnever changes ordering of ﬁnished jobs, and the total weight of the mistakes in its ﬁnal predictions\nisµ, the regret of Algorithm 13 is µ.\nProof.If switches happen only at job completions then Algorithm 13 never p reempts any job\nbefore it is ﬁnished. Since, the predictor changes only the ordering of the unﬁnished jobs during,\nthe algorithm processes jobs in the order suggested by the ﬁnal p rediction. By Proposition 26, the\ndiﬀerence between the cost incurred by the algorithm and the oﬄine optimum is equal to µ.\nAlgorithm 13 when run with Predictor 12 ﬁrst processes jobs in P. Once the last job in Pis\ncompleted, Predictor12switchesto its ﬁnal prediction by updating the orderingofunﬁnished jobs,\nfulﬁlling the conditions of Lemma 28. Together with Lemma 27, we get t he following theorem.\nTheorem 29. Consider an instance Iwith maximum job length 1. There is an algorithm for the\nagnostic setting which, given a hypothesis class Hof sizeℓwith error µ, produces a schedule with\ntotal completion time at most OPT(I)+µ+O(n5/3(logℓ\nδ)1/3)with probability at least (1−δ).\n22\n\n6.3 Lower Bound\nIn this section, we prove a lower bound for instances with three dist inct job lengths. The instances\nused in our construction will use only integer job lengths and the follo wing technical lemma helps\nsimplifying the exposition of the lower bound.\nLemma 30. Consider instance of non-clairvoyant scheduling with jobs of integer lengths. Any\nonline algorithm Aon this instance can be converted to an online algorithm A′with no larger cost\nwhich interrupts and starts processing of jobs only at integ er time steps.\nProof.Lett1,...,tNbe time instants such that the processed part of some job in the sc hedule\nproduced by Areaches an integer value. We use the following notation: The milestone ireached\nat timetiis described by ki∈Nandji∈ {1,...,n}meaning that kiunits of job jibecome\ncompleted at ti. Since jobs are guaranteed to have integral lengths, algorithm Adiscovers new\ninformation about job lengths only at times t1,...,tN. Namely, at time t, it knows that the length\nof a jobjis max{ki|ti≤tandji=j}ifjis ﬁnished, and at least max {ki+1|ti≤tandji=j}\nifjis unﬁnished.\nWe describe algorithm A′which reaches the milestones 1 ,...,Nin the same order as A,\nreaching milestone iat timei≤ti. At time t= 0, it chooses job j1and processes it for a single\ntime unit, reaching milestone 1 with j1andk1= 1 at time 1 ≤t1. Having imilestones reached at\ntime step i∈1,...,N−1,A′chooses job ji+1and processes it for a single time unit. Since the\nprevious milestone involving ji+1was already reached by A′,ji+1is processed for ki+1time units,\nreaching milestone i+1. We have ti+1≥i+1, because reaching each milestone requires a single\nunit of computational time and no algorithm can reach i+1 milestones before time i+1.\nSince all jobs have integer lengths, they can be completed only when some milestone is reached.\nSinceA′reachesallmilestonesnolaterthan A, itstotalcompletiontimeisatmosttheoneachieved\nbyA.\nLemma 31. Consider two schedules such that the second one diﬀers from t he ﬁrst one by moving\nat least a single unit of some job jearlier, jumping over completion times of djobs, while the\ncompletion time of jdoes not change. Then the total completion time of the second schedule is\nlarger by at least d.\nConsider two schedules such that the second one diﬀers from t he ﬁrst one by moving a whole\njobjof size 3 earlier, jumping over djobs of size at most 2. Then the total completion time of\nthe second schedule is larger by at least d.\nProof.First case: the completion times of ddelayed jobs increase by 1 and all other completion\ntimes remain the same.\nSecond case: the completion time of jdecreases by at most 2 d, while the completion times of\nthe delayed jobs increase by 3. All other completion times do not cha nge.\nTheorem 32. There is a hypothesis class of size ℓsuch that no algorithm for non-clairvoyant\nscheduling in realizable setting can achieve a regret bound o(ℓn).\nProof.We construct ℓinstanceswith n≥2ℓ2jobs. The job lengths will be 1 ,2,3. However, wecan\nrescale the time to make an execution of a job of size 3 to last 1 time un it. Such rescaling changes\nboth the optimal and algorithm’s total completion time as well as their diﬀerence by factor of 3.\nThe ﬁrst ℓ2jobs are divided into ℓblocks of ℓjobs each. The ith block includes jobs ( i−1)ℓ+\n1,(i−1)ℓ+ 2,...,iℓ. The jobs in the ith block have length 1 in instance iand 3 in all other\ninstances. The jobs ℓ2+1,...,nhave length 2 in all instances.\nThe correct instance is picked uniformly at random. By Yao’s principle (see, e.g., [Borodin\nand El-Yaniv, 1998]), it is enough to prove a lower bound for any dete rministic algorithm on this\nrandomized instance to get a lower bound for any randomized algorit hm. The optimal solution\nof any of these instances is to schedule ℓjobs of size 1 ﬁrst, then n−ℓ2jobs of size 2, and ﬁnally\nℓ2−ℓjobs of size 3.\nWe assume that the algorithm starts and preempts jobs only in integ ral time steps. This\nassumption is without loss of generality by Lemma 30. When deciding wh ich job to run at time\n23\n\nt∈N, it can choose either a job from 1 ,...ℓ2or a job from ℓ2+ 1,...n. If it runs a job from\n1,...,ℓ2for at least 1 time unit, it discovers the length of all jobs in the same b lock. If the true\nsize of the job was 1 and the job is ﬁnished, it also discovers the true instance. We denote by\nA⊆ {1,...,ℓ}the set of blocks such that the algorithm still does not know the leng ths of the jobs\nin these blocks. We consider the following two cases:\n•Algorithm runs a job j∈ {ℓ2+1,...,n}: such a job has size 2 in all instances. If the correct\ninstance is not yet determined and there are still ℓunﬁnished jobs of length 1, this action\nworsens the algorithm’s schedule by ℓ, by Lemma 31.\n•Algorithm runs a job j∈ {1,...,ℓ2}: the length of jis 1 with probability 1 /|A|ifjbelongs\nto a block i∈Aand 0 otherwise. If it is 1, the algorithm determines the correct inst ance and\nsuﬀers no more regret. Otherwise, |A|decreases by 1. If ALG processes this job completely,\nit suﬀers regret ≥rtby Lemma 31, where rtis the number of unﬁnished jobs of size 2. If it\nprocesses the job for at least 1 time unit without ﬁnishing it, it also su ﬀers regret ≥rt.\nOne of the following complementary events occurs with probability at least 1/2: When the\nﬁrst job of size 1 is scheduled, either (1) rt<(n−ℓ2)/2 or (2)rt≥(n−ℓ2)/2.\nIf the event (1) occurs, at least ( n−ℓ2)/2 jobs of size 2 are scheduled before the ﬁrst job of\nsize 1, each of them causes regret at least ℓ. Withn≥2ℓ2, we have the regret at least Ω( ℓn).\nIn case event (2) occurs, we calculate how many jobs of size 3 are s cheduled before the ﬁrst\njob of size 1 in expectation. If each job j∈ {1,...,ℓ2}chosen by the algorithm belongs to\na diﬀerent block, it will runℓ2+1\nℓ+1≥ℓ/2 jobs of size 3 before it runs the ﬁrst job of size 1 in\nexpectation. Otherwise, the expectation is even higher. Therefo re, the algorithm suﬀers regret at\nleast (ℓ/2)rt≥(ℓ/2)(n−ℓ2)/2≥(ℓ/2)(n/4) = Ω(ℓn).\n7 Caching\nWe describe extensions of our results from Section 4 to agnostic se tting and setting with a more\nnatural hypotheses. We also prove our lower bounds.\n7.1 Agnostic Setting\nIn agnostic setting, we are given a set of ℓhypotheses H={r1,...,rℓ}which does not necessarily\ncontains the input sequence r. The number of mistakes of hypothesis riis deﬁned as the number\nof time steps t∈ {1,...,T}such that ri\nt/\\e}atio\\slash=rt. The best hypothesis is the one with the smallest\nnumber of mistakes.\nPredictor: At each time step t, the predictor chooses a hypothesis iat random according to\nthe probability distribution produced by the HEDGE algorithm [Littlest one and Warmuth, 1994,\nFreund and Schapire, 1997]. If iis diﬀerent from the hypothesis chosen at time t−1, there is a\nswitch to a new prediction πwhich is consistent with the previous prediction until time tand, for\nτ=t,...,T, the predictor updates πτ:=ri\nτ.\nWe construct a sequence of loss functions as an input to HEDGE: At timet, the loss of\nhypothesis iis 1 if it predicts an incorrect request and 0 otherwise. At each time s tept, HEDGE\ngives us a probability distribution ξtover the hypotheses. The predictor samples a hypothesis\nfrom this distribution in the following way. Let fbe a min-cost ﬂow of the probability mass\nfrom distribution ξt−1to distribution ξt(i.e.,/summationtextℓ\nj=1fij=ξt−1\niand/summationtextℓ\ni=1fij=ξt\nj), where ﬂow fij\nhas cost 1 if i/\\e}atio\\slash=jand 0 otherwise.8Note that the cost of this ﬂow/summationtext\ni/ne}ationslash=jfijis equal to Total\nVariation Distance (TVD) between ξt−1andξt. If hypothesis iwas chosen at time t−1 as a\n8In our situation, the min-cost ﬂow fijcan be expressed using an explicit formula: we deﬁne δ=ξt−ξt−1and\nwritefij= (−δi)+δ+\nj/summationtextℓ\nm=1δ+\nmfor each i,j∈ {1,...,ℓ}, using notation x+:= max{0,x}.\n24\n\nsample from ξt−1, then the predictor switches to a hypothesis jwith probability fij/ξt−1\ni. This\nway, the probability of choosing jat timetis\nℓ/summationdisplay\ni=1P(ichosen at t−1)P(switching to j|ichosen at t−1) =ℓ/summationdisplay\ni=1ξt−1\nifij\nξt−1\ni=ξt\nj\nand the probability of a switch occurring is/summationtext\ni/ne}ationslash=jfij= TVD( ξt−1,ξt). See Predictor 14 for a\nsummary.\nPredictor 14: caching, agnostic setting\n1η:= ln1\n1−1/k; // Learning rate parameter\n2w:= (1,...,1),ξ0:=w/ℓ;\n3predict a hypothesis sampled from ξ0;\n4fort= 1,...,Tdo\n5fori∈ {1,...,ℓ}s.t.ri\nt/\\e}atio\\slash=rtdo\n6 wi:=wiexp(η) ; // loss of instance iis 1: update wiusing HEDGE\n7ξt\ni:=wi//summationtextℓ\ni=1wifor each i= 1,...,ℓ;// Update distribution over hypotheses\n8compute min-cost ﬂow ffromξt−1toξt, so that/summationtextℓ\ni=1fij=ξt\nj;\n9if the previous prediction was hypothesis i, switch to jw.p.fij/ξt−1\ni;\nThefollowingperformancebound ofthe HEDGEalgorithmcanbe foun d, e.g., in [Cesa-Bianchi\nand Lugosi, 2006, Thm 2.4].\nProposition 33. Letµ⋆be the loss of the best of the hypotheses. Then, the expected l oss of the\nHEDGE algorithm with learning rate parameter ηis\nµ≤ηµ⋆+lnℓ\n1−exp(−η).\nTheprobabilitydistributionproducedbyHEDGEisrelativelystable. We canboundTVD( ξt−1,ξt)\nas a function of ηand the expected loss incurred by HEDGE at time t.\nProposition 34 (Blum and Burch [2000] (Thm 3)) .Letξt−1andξtbe probability distributions\nof HEDGE learning rate parameter ηat times t−1andtrespectively. Then, we have\nTVD(ξt−1,ξt)≤η/summationdisplay\ni,ri\nt/ne}ationslash=rtξt\ni.\nLemma 35. Letµ⋆be the number of mistakes of the best hypothesis. The predict or for the agnostic\nsetting makes µmistakes and σswitches in expectation, where\nµ≤(1+1/k)µ⋆+klnℓandσ≤(1/k+1/k2)µ.\nProof.The number of mistakes made by Predictor 14 is equal to the loss ach ieved by HEDGE\nalgorithm. By Proposition 33, we have\nµ≤ηµ⋆+lnℓ\n1−exp(−η). (2)\nWe choose η:= ln1\n1−1/kwhich is ≤1/k+ 1/k2, whenever k≥4. This is to make kσ=kηµ\ncomparable to µ. We substitute this upper bound in 2, and get\nµ≤(ln1\n1−1/k)µ⋆+lnℓ\n1/k≤(1+1/k)µ⋆+klnℓ.\n25\n\nAt each time step t, Predictor 14 makes a switch with probability/summationtext\ni/ne}ationslash=jfij= TVD(ξt−1,ξt).\nBy Proposition 34, the expected number of switches made by our pr edictor is\nσ≤T/summationdisplay\nt=1η/summationdisplay\ni,ri\nt/ne}ationslash=rtξt\ni=ηµ≤(1/k+1/k2)µ,\nsince/summationtext\ni,ri\nt/ne}ationslash=rtξt\niis the expected number of mistakes at time t.\nAlgorithm. OuralgorithmfollowstheFitFsolutionrecomputedateachswitch. If ithappens\nthat the current request rtis not served by this solution (i.e., there is a mistake in the prediction),\nthe algorithm loads rtad-hoc and removes it instantly in order to return to the FitF solutio n.\nAlgorithm 15: caching, agnostic setting\n1fort= 1,...,Tdo\n2ift= 1or there is a switch then\n3 recompute x1,...,x Tthe FitF solution for the current prediction;\n4move to xt;\n5ifrt/∈xtthen\n6 loadrt, evicting an arbitrary page, and serve rt;\n7 return back to xt;\nIf the predictor makes 0 mistakes, i.e., µ= 0, then rt/∈xtnever happens and this algorithm\nis the same as the one for the realizable case (but note that the pre dictor is diﬀerent). If µ >0,\nthen it suﬀers an additional cost of 2 for every mistake.\nLemma 36. Consider an input sequence rand letOPT(r)be the cost of the optimal oﬄine\nsolution for this sequence. If the predictor makes µmistakes and σswitches during this sequence,\nthen the algorithm above has cost at most\nOPT(r)+4µ+kσ.\nProof.Fort= 1,...,T, letπtdenote the prediction made for rtat timet. Here,πt=rtif the\npredictorwasright ordecided to makea switch. Otherwise, the pre dictorchoseto suﬀer a mistake.\nIf the real input was π1,...,π T, the cost of the algorithm would be at most OPT( π)+kℓby\nLemma6. Since πandrdiﬀerinµtimesteps,thecostofthealgorithmisatmostOPT( π)+kσ+2µ.\nNow, note that we can use the optimal solution x1,...,x Tforrto produce a solution for πof\ncostatmostOPT( r)+2µ: whenever πt/∈xt(this canhappenonlyif πt/\\e}atio\\slash=rt), weevictanarbitrary\npage to load πt, serve the request and return back to xt. This implies OPT( π)≤OPT(r)+2µ.\nTherefore, the cost of our algorithm is at most\nOPT(r)+4µ+kσ.\nTheorem 37. With a class Hofℓhypothesis, Algorithm 15 has expected cost at most\nOPT+(5+6 /k)µ⋆+(2k+1)lnℓ\nwhereµ⋆denotes the minimum number of mistakes over hypotheses in HandOPTthe cost of the\noﬄine optimum.\nProof.By Lemma 36 and Lemma 34, the cost of the algorithm is at most\nOPT(r)+4µ+kσ\n≤OPT(r)+4(1+1 /k)µ⋆+klnℓ+k(1/k+1/k2)(1+1/k)µ⋆+k(1/k+1/k2)klnℓ\n≤OPT(r)+(5+6 /k)µ⋆+(2k+1)lnℓ.\n26\n\n7.2 Achieving Robustness\nWe can robustify our algorithms both for the realizable and agnostic setting in the following\nway. We partition the input sequence into intervals such that the co st paid by OPT in interval\niis 2ik. Note that we start with an empty cache and OPT ≥kon any non-trivial instance: if\nOPT≤k, less than kdistinct pages were requested and any lazy algorithm is optimal. In ea ch of\nthese intervals, we ﬁrst run our algorithm until its cost reaches 2iklogk. Then, we switch to an\narbitrary worst-case algorithm with competitive ratio O(logk) for the rest of the time window.\nLemma 38. Consider an algorithm ALGwhich, given a predictor making µmistakes and σ\nswitches achieves regret αµ+βkσ. We can construct an algorithm ALG′which is O(logk)-\ncompetitive in the worst case and its regret is always bounde d byO(α)µ+O(β)kσ.\nProof.We denote Gthe set of intervals iwhere ALG paid cost ALG i≤2iklogk. The cost of\nALG′is then\nALG′≤/summationdisplay\ni∈GALGi+/summationdisplay\ni/∈G(O(logk)2ik+2k),≤/summationdisplay\ni∈GALGi+/summationdisplay\ni/∈GO(logk)2ik,\nwhere 2kdenotes the cost of switching to the worst-casealgorithm and bac k to ALG. This already\nshows that ALG′isO(logk)-competitive: we have ALG′≤O(logk)OPT, because OPT pays 2ik\nin window i.\nTo show that it still preserves good regret bounds, note that αµi+βkσi≥2iklogkin each\nintervali /∈G, whereσidenotes the number of switches and µithe number of mistakes in interval\ni. Therefore, we have\nALG′≤ALG+O(α)µ+O(β)kσ.\n7.3 Extension to Next-arrival-time Predictions\nIn order to compute a step of FitF, we either need to know the whole request sequence or, at least,\ntimes of next arrivals of the pages in our current cache. Lykouris a nd Vassilvitskii [2021] proposed\nacquiring a prediction of the next arrival time (NAT) of each page wh en requested. Precise NAT\npredictions allow us to simulate FitF. Lykouris and Vassilvitskii [2021], R ohatgi [2020], Wei [2020]\nproposed algorithms able to use them even if they are not precise.\nOur result can be extended to setting where each hypothesis is not an explicit caching instance\ngiven in advance but rather a set of prediction models which generat e the relevant parts of the\ninstance over time. Consider models generating next-arrival-time p redictions, as considered by\nLykouris and Vassilvitskii [2021]. Given the part of the sequence see n so far, they produce a next\narrival time of the currently requested page. Using this informatio n, we can compute the FitF\nsolution to an instance which fully agrees with the predictions. Moreo ver, we can easily detect\nmistakes by comparing the currently requested page with the page which was predicted to arrive\nat the current moment. Therefore, Theorem 7 and Theorem 37 ho ld also with Hcontaining ℓ\nmodels producing next-arrival-time predictions.\n7.4 Lower Bounds\nLemma 39. In realizable setting, there is an input instance and a class Hofℓhypotheses such\nthat any (randomized) algorithm has regret at leastk\n2logℓ.\nProof.Letℓbe power of two. We use universe of pages U={1,...,2k}and deﬁne sequences\na= 1,...,kandb=k+1,...,2k. By concatenating aandbin a speciﬁc manner, we construct\nbuilding blocks of the input sequence and the hypotheses: σ0=akba2k+1andσ1=akbbkbak.\nHereakdenotes a sequence aiteratedktimes, and both blocks are chosen to have equal length.\nFor each i= 1,...,ℓ, we use its binary representation bi\n1bi\n2···bi\nlogℓto construct a hypothesis\nri=σbi\n1σbi\n2···σbi\nlogℓfrom blocks σ0andσ1. Note that for any input sequence constructed from\nblocksσ0andσ1, we can construct an oﬄine solution such that:\n27\n\n•at the beginning and at the end of each block, its cache content is {1,...,k}.\n•during block σ0, it keeps pages 1 ,...,k−1 in cache, paying kfor page faults during sequence\nband 1 for loading page k, i.e.,k+1 page faults in total\n•during block σ1, it pays 2 k, because it replaces the whole cache with {k+1,...,2k}during\nthe ﬁrst occurrence of band then with {1,...,k}after the last occurrence of b.\nFor each i= 1,...,logℓ, we issue akb– the common preﬁx of σ0andσ1– and compute ni\nthe expected number of pages from {1,...,k}in the cache. Note that any algorithm has to pay\nat leastkduringakbsince it contains 2 kdistinct pages. If ni< k/2, we issue a2k+1, completing\nblockσ0. Otherwise, we issue bkbak, completing block σ1.\nIn the ﬁrst case, its expected cost will be at least k+(k−ni)> k+k/2, because the algorithm\nwill have at least k−nipage faults during the sequence a2k+1at the end of σ0.\nIn the second case, the expected cost of the algorithm will be at lea stk+ni+k≥2k+k/2,\nwherekpage faults are during akb,nipage faults during bk, and another kpage faults during for\nbak(contains 2 kdistinct pages). In both cases, the diﬀerence from the cost of th e oﬄine solution\nis at least k/2.\nThis way, we constructed an instance j∈ {1,...,ℓ}with binary representation b1b2···blogℓ,\nwherebi= 0 ifni< k/2 andbi= 1 otherwise. Moreover, in each iteration i= 1,...,logℓ, the\nalgorithm pays at least by k/2 more compared to the oﬄine solution.\nLemma 40. There is no deterministic algorithm which, given a predicte d request sequence with\nµmistakes achieves regret smaller than µ.\nProof.We construct a predicted instance π= ((1,...,k,0)(2,...,k)(0,1,...,k))nwhich is given\nto the algorithm ALG. We construct a real instance which is constru cted online based on ALG’s\ndecisions.\nFor any iteration i= 1,...,n, we build a corresponding part of the real instance which diﬀers\nfrom the predicted one in at most one request and show that ALG ha s one more page fault\ncompared to a described adversarial strategy ADV which starts a nd ends each iteration with\ncache content {1,...,k}.\nFirst, any algorithm has a page fault during (1 ,...,k,0) because k+ 1 distinct pages are\nrequested, so both ALG and ADV pay 1. At the moment when 0 is requ ested, ALG must be\nmissing some page from p∈ {1,...,k}. Ifp= 1, ADV evicts kinstead and the real request\nsequence continues with (2 ,...,k−1,1) instead of (2 ,...,k), causing a single mistake in the\nprediction. ALG has a page fault during this part, while ADV has no pag e fault. If p∈ {2,...,k},\nADV evicts 1 and the real request sequence continues as predicte d without any mistake, causing\na page fault to ALG, while ADV has no page fault. In the last part (0 ,1,...,k), both ALG and\nADV have a page fault. So, ALG had at least 3 page faults while ADV only 2, and there was at\nmost one mistake.\nTherefore, the total cost of ALG is at least 3 nwhile ADV pays 2 n. Sinceµ≤n, the regret of\nALG is at least µ.\nReferences\n[1] J.M. Altschulerand K. Talwar. Online learningoveraﬁnite actionse t with limited switching.\nArXiv, abs/1803.01548, 2018.\n[2] K. Anand, R. Ge, A. Kumar, and D. Panigrahi. Online algorithms with multiple predictions.\nInICML, volume 162 of Proceedings of Machine Learning Research , pages 582–598. PMLR,\n2022.\n[3] A. Antoniadis, C. Coester, M. Eli´ as, A. Polak, and B. Simon. Mixing predictions for online\nmetric algorithms. CoRR, abs/2304.01781, 2023. doi: 10.48550/arXiv.2304.01781. UR L\nhttps://doi.org/10.48550/arXiv.2304.01781 .\n28\n\n[4] A. Antoniadis, C. Coester, M. Eli´ aˇ s, A. Polak, and B. Simon. Onlin e metric algorithms\nwith untrusted predictions. ACM Trans. Algorithms , 19(2), apr 2023. ISSN 1549-6325. doi:\n10.1145/3582689. URL https://doi.org/10.1145/3582689 .\n[5] Y. Azar, J. Naor, and R. Rom. The competitiveness of on-line ass ignments. J. Algorithms ,\n18:221–237, 1992.\n[6] M.-F. Balcan. Data-Driven Algorithm Design , page 626–645. Cambridge University Press,\n2021. doi: 10.1017/9781108637435.036.\n[7] M.-F. Balcan, T. Sandholm, and E. Vitercik. Generalization in portf olio-based al-\ngorithm selection. Proceedings of the AAAI Conference on Artiﬁcial Intelligen ce,\n35(14):12225–12232, May 2021. doi: 10.1609/aaai.v35i14.17 451. URL\nhttps://ojs.aaai.org/index.php/AAAI/article/view/17 451.\n[8] L. A. Belady. A study of replacement algorithms for virtual-stor age computer. IBM Syst. J. ,\n5(2):78–101, 1966. doi: 10.1147/sj.52.0078. URL https://doi.org/10.1147/sj.52.0078 .\n[9] A. Bhaskara, A. Cutkosky, R. Kumar, and M. Purohit. Online linea r optimization with many\nhints. In NeurIPS , 2020.\n[10] A. Blum and C. Burch. On-line learning and the metrical task syst em problem. Mach. Learn. ,\n39(1):35–58, 2000. doi: 10.1023/A:1007621832648.\n[11] A. Borodin and R. El-Yaniv. Online computation and competitive analysis . Cambridge Uni-\nversity Press, 1998. ISBN 978-0-521-56392-5.\n[12] N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games . Cambridge Univer-\nsity Press, 2006. ISBN 978-0-521-84108-5. doi: 10.1017/CBO9 780511546921. URL\nhttps://doi.org/10.1017/CBO9780511546921 .\n[13] N. Cesa-Bianchi, O. Dekel, and O. Shamir. Online learning with switc hing costs and other\nadaptive adversaries. ArXiv, abs/1302.4387, 2013.\n[14] N. Chen, G. Goel, and A. Wierman. Smoothed online convexoptimiz ation in high dimensions\nvia online balanced descent. ArXiv, abs/1803.10366, 2018.\n[15] M. Dinitz, S. Im, T. Lavastida, B. Moseley, and S. Vassilvitskii. Alg orithms with prediction\nportfolios. In NeurIPS , 2022.\n[16] Y. Emek, S. Kutten, and Y. Shi. Online paging with a vanishing regr et. InITCS, 2021.\n[17] A. Fiat, R. M. Karp, M. Luby, L. A. McGeoch, D. D. Sleator, and N. E. Young.\nCompetitive paging algorithms. Journal of Algorithms , 12(4):685–699, 1991. ISSN\n0196-6774. doi: https://doi.org/10.1016/0196-6774(91)9 0041-V. URL\nhttps://www.sciencedirect.com/science/article/pii/0 19667749190041V .\n[18] Y. Freund and R. E. Schapire. A decision-theoretic generalizat ion of on-line learning\nand an application to boosting. Journal of Computer and System Sciences , 55(1):119–\n139, 1997. ISSN 0022-0000. doi: https://doi.org/10.1006/j css.1997.1504. URL\nhttps://www.sciencedirect.com/science/article/pii/S 002200009791504X .\n[19] G. Goel, Y. Lin, H. Sun, and A. Wierman. Beyond online balanced de scent: An optimal\nalgorithmfor smoothed online optimization. In Neural Information Processing Systems , 2019.\n[20] G. R. Grimmett and D. R. Stirzaker. The lost boarding pass and o ther practical problems.\nThe Mathematical Gazette , 105(563):216–221, 2021. doi: 10.1017/mag.2021.49.\n[21] S. Im, R. Kumar, M. M. Qaem, and M. Purohit. Online knapsack wit h frequency predictions.\nInNeurIPS , pages 2733–2743, 2021.\n29\n\n[22] K. Jansen and L. Rohwedder. On the Conﬁguration-LP of the Restricted Assignment\nProblem, pages 2670–2678. 2017. doi: 10.1137/1.9781611974782.176 . URL\nhttps://epubs.siam.org/doi/abs/10.1137/1.9781611974 782.176.\n[23] M. Khodak, M.-F. F. Balcan, A. Talwalkar, and S. Vassilvitskii. Lea rningpredictionsfor algo-\nrithms with predictions. In Advances in Neural Information Processing Systems , volume 35,\npages 3542–3555, 2022.\n[24] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The c ase for learned index\nstructures. In Proceedings of SIGMOD’18 , pages 489–504, 2018. doi: 10.1145/3183713.3196\n909.\n[25] S. Lattanzi, T. Lavastida, B. Moseley, and S. Vassilvitskii. Online schedul-\ning via learned weights. In Proceedings of the 2020 ACM-SIAM Symposium\non Discrete Algorithms, SODA 2020 , pages 1859–1877. SIAM, 2020. URL\nhttps://doi.org/10.1137/1.9781611975994.114 .\n[26] J. K. Lenstra, D. B. Shmoys, and ´E. Tardos. Approximation algorithms for scheduling unre-\nlated parallel machines. Math. Program. , 46:259–271, 1990. doi: 10.1007/BF01585745. URL\nhttps://doi.org/10.1007/BF01585745 .\n[27] S. Li and J. Xian. Online unrelated machine load balancing with pred ictions revisited. In\nM. Meila and T. Zhang, editors, Proceedings of the 38th International Conference on Machin e\nLearning , volume 139of Proceedings of Machine Learning Research , pages 6523–6532.PMLR,\n18–24 Jul 2021.\n[28] A. Lindermayr and N. Megow. Permutation predictions for non- clairvoyant scheduling. In\nSPAA, pages 357–368. ACM, 2022.\n[29] A. Lindermayr and N. Megow. Algorithms with predictions.\nhttps://algorithms-with-predictions.github.io , 2023. URL\nhttps://algorithms-with-predictions.github.io . Online: accessed 2023-07-12.\n[30] N. Littlestone. Learning quickly when irrelevant attributes abo und: A new linear-threshold\nalgorithm. In 28th Annual Symposium on Foundations of Computer Science (s fcs 1987) ,\npages 68–77, 1987. doi: 10.1109/SFCS.1987.37.\n[31] N. Littlestone and M. K. Warmuth. The weighted majority algorit hm.Inf.\nComput., 108(2):212–261, 1994. doi: 10.1006/inco.1994.1009. URL\nhttps://doi.org/10.1006/inco.1994.1009 .\n[32] T. Lykouris and S. Vassilvitskii. Competitive caching with machine le arned advice. J. ACM,\n68(4):24:1–24:25, 2021.\n[33] M. Mitzenmacher and S. Vassilvitskii. Algorithms with predictions. InBeyond the Worst-\nCase Analysis of Algorithms , pages 646–662. Cambridge University Press, 2020.\n[34] R. Motwani, S. Phillips, and E. Torng. Non-clairvoyant scheduling . InProceedings of the\nFourth Annual ACM-SIAM Symposium on Discrete Algorithms , SODA ’93, page 422–431,\nUSA, 1993. Society for Industrial and Applied Mathematics. ISBN 0 898713137.\n[35] M. Purohit, Z. Svitkina, and R. Kumar. Improving online algorithm s via ML predictions. In\nNeurIPS , 2018.\n[36] D. Rohatgi. Near-optimal bounds for online caching with machine learned advice. In SODA,\n2020.\n[37] T. Roughgarden, editor. Beyond the Worst-Case Analysis of Algorithms . Cambridge\nUniversity Press, 2020. ISBN 9781108637435. doi: 10.1017/978 1108637435. URL\nhttps://doi.org/10.1017/9781108637435 .\n30\n\n[38] D.D.SleatorandR.E.Tarjan. Amortizedeﬃciencyoflistupdat eandpagingrules. Commun.\nACM, 28(2):202–208, 1985. doi: 10.1145/2786.2793.\n[39] O. Svensson. Santa claus schedules jobs on unrelated machine s.SIAM J. Comput. , 41(5):\n1318–1341, 2012. doi: 10.1137/110851201. URL https://doi.org/10.1137/110851201 .\n[40] R. Vershynin. High-Dimensional Probability: An Introduction with Appli cations in Data\nScience. CambridgeSeriesinStatisticalandProbabilisticMathematics.Camb ridgeUniversity\nPress, 2018. doi: 10.1017/9781108231596.\n[41] A. Wei. Better and simpler learning-augmented online caching. In APPROX/RANDOM ,\n2020.\n[42] A. Wei and F. Zhang. Optimal robustness-consistency trade -oﬀs for learning-augmented\nonline algorithms. In Advances in Neural Information Processing Systems , volume 33, pages\n8042–8053, 2020.\n[43] L. Zhang, W. Jiang, S. Lu, and T. Yang. Revisiting smoothed onlin e learning. In Neural\nInformation Processing Systems , 2021.\n31",
  "textLength": 108395
}