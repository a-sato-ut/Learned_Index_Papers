{
  "paperId": "40393d6994f79aa65f365ae4029579a350d5418e",
  "title": "Clustering Plotted Data by Image Segmentation",
  "pdfPath": "40393d6994f79aa65f365ae4029579a350d5418e.pdf",
  "text": "CLUSTERING PLOTTED DATA BY IMAGE SEGMENTATION\nTarek Naous\nAmerican University of BeirutSrinjay Sarkar\nVinAI ResearchAbubakar Abid, James Zou\nStanford University\nABSTRACT\nClustering algorithms are one of the main analytical meth-\nods to detect patterns in unlabeled data. Existing clustering\nmethods typically treat samples in a dataset as points in a\nmetric space and compute distances to group together simi-\nlar points. In this paper, we present a wholly different way\nof clustering points in 2-dimensional space, inspired by how\nhumans cluster data: by training neural networks to perform\ninstance segmentation on plotted data. Our approach, Visual\nClustering , has several advantages over traditional clustering\nalgorithms: it is much faster than most existing clustering al-\ngorithms (making it suitable for very large datasets), it agrees\nstrongly with human intuition for clusters, and it is by default\nhyperparameter free (although additional steps with hyperpa-\nrameters can be introduced for more control of the algorithm).\nWe describe the method and compare it to ten other clus-\ntering methods on synthetic data to illustrate its advantages\nand disadvantages. We then demonstrate how our approach\ncan be extended to higher dimensional data and illustrate its\nperformance on real-world data. The implementation of Vi-\nsual Clustering is publicly available and can be applied to any\ndataset in a few lines of code.\nIndex Terms ‚ÄîClustering, Segmentation, Neural Net-\nworks, Unsupervised learning\n1. INTRODUCTION\nNumerous applications require the classiÔ¨Åcation of unlabeled\nsamples in dataset into disjointed clusters such that samples\nwithin the same cluster are similar yet samples in different\nclusters differ meaningfully. Many such clustering algorithms\nhave been developed satisfying different desiderata for appli-\ncations in Ô¨Åelds such as image processing [1], biomedicine\n[2], and spatial data [3].\nThe most commonly used clustering algorithms, such as\nK-means clustering [4] , Gaussian mixture clustering [5], and\nDBSCAN [6], treat samples as points in a metric (usually Eu-\nclidean) space and group together points based on distances\nto other points or to computed exemplars. For example, the\nK-means clustering identiÔ¨Åes optimal centroids in the metric\nspace to which the distance of all samples in the dataset are\nminimized. The Gaussian mixture algorithm assumes the data\nis sampled from a mixture of Gaussians and produces clus-ters in the data to maximize the likelihood, which happens\nwhen data points are close to the centers of the Gaussian dis-\ntributions. DBSCAN is a density-based clustering algorithm\nwhich does not assume the number of clusters for the given\ndataset, but considers a group of point belonging to the same\ncluster if there are a certain number of points in the neighbor-\nhood the selected point. The clusters are expanded by recur-\nsively considering distances to all other points.\nSince most of these algorithms involve measuring dis-\ntances between points, they scale poorly to large datasets\nwith millions or billions of samples. In our work, we in-\ntroduce a completely different kind of clustering algorithm,\ndesigned for two-dimensional datasets for large datasets. Our\napproach, which we call visual clustering , is inspired by\nhow humans cluster data: rather than computing distances,\nwe segment data points into clusters based on the shape of\nlarge regions within the dataset. We simulate this process by\ntraining neural networks to perform instance segmentation on\nplotted data. Our approach has several advantages over tradi-\ntional clustering algorithms: (1) Because the main step in the\nalgorithm is running a prediction from one neural network,\nit is much faster than most existing clustering algorithms\nand scales easily to datasets with millions or billions of sam-\nples. (2) As we show on many kinds of datasets, it agrees\nstrongly with human intuition for clusters, moreso than many\nother clustering algorithms. (3) The core algorithm is hy-\nperparameter free, although we suggest additional steps with\nhyperparameters that can be introduced for more control of\nthe algorithm. Our implementation is publicly available1.\nClustering has been applied in the literature to solve var-\nious problems in deep learning and computer vision such as\nunsupervised image segmentation [7] facial landmark detec-\ntion [8], and image grouping [9, 10]. However, no previous\nwork has leveraged the fast inference time of trained neu-\nral network models to perform clustering. Developing deep\nlearning models that can replace classical algorithms has been\nstudied in the literature for various problems such as sorting\n[11], solving mixed integer problems [12], or even replacing\nindex structures in data management systems [13]. To the best\nof our knowledge, our work is the Ô¨Årst to introduce an algo-\nrithm based on a supervised deep learning model to perform\nclustering of numerical datasets.\n1https://github.com/tareknaous/visual-clusteringarXiv:2110.05187v1  [cs.LG]  6 Oct 2021\n\nU-NetBinary  \nSegmentation2\nPredicted Mask 2-D Input Matrix\nùëãDatasetPlotting1\nLabel Map Clustered DatasetCluster \nAssignment4\nConnected -\nComponent \nAnalysis \n+ \nWatershedInstance \nSeparation3Dimensionality\nReductionImage Denoising Max FilteringFig. 1 : Diagrammatic view of our Visual Clustering algorithm. Dotted lines infer optional steps. The algorithm Ô¨Årst creates\na matrix representation of the dataset that is used as input to a binary segmentation model (U-Net). Connected component\nanalysis and watershed are applied to the predicted binary mask to separate the different instances in the image, resulting in a\nlabel map from which cluster assignment is Ô¨Ånally performed.\n2. METHODS\n2.1. Core Algorithm\nOur proposed Visual Clustering algorithm is illustrated in Fig-\nure 1 and consists of four main steps that we describe in this\nsection. Consider the dataset X2Rm\u00022that we would like\nto cluster. We start by the plotting step where Xis represented\nin a two-dimensional matrix form, denoted by I(X). This is\ndone by Ô¨Årst linearly shifting the values of both features to be\n2[0;256] and then Ô¨Ålling a zero-initialized 256\u0002256matrix\nby a value of 1 for each sample in the dataset according to\nits coordinates. In case the dataset was high-dimensional, we\napply Principal Component Analysis (PCA) and use the Ô¨Årst\ntwo principle components as features. The matrix, which can\nbe visualized as an image, is then fed as an input to the sec-\nond step of binary segmentation where a pre-trained binary\nsegmentation model is used. We adopt the U-Net architecture\n[14] for binary segmentation and train it in supervised fashion\non images of plotted datasets, which were synthetically gen-\nerated, and their binary masks. The U-Net model predicts a\npixel-level binary mask ^M(I(X)).\nThe predicted binary mask by the trained U-Net model\ncontains information on where cluster areas are located.\nHowever, the binary mask alone does not indicate how many\nclusters there are in the image. Hence, the next step in our\napproach is separating the instances (or clusters) present in\nthe binary mask. To do this, we apply Connected Component\nAnalysis on the predicted mask followed by a Watershed\ntransformation for instance separation. This results in a la-\nbel map Lwhere pixels belonging to the same cluster are\nassigned the same label value. The Ô¨Ånal step in our approach\nis cluster assignment, where we assign a cluster label to each\nsample in the dataset based on its location in the label map.2.2. Training the Binary Segmentation Model\nTo train the U-Net model for binary segmentation, we gener-\nated 1,000 synthetic datasets of blob-shaped clusters. To cre-\nate the label for each dataset, we computed the convex hull\nof each cluster in the dataset. The convex hulls are then used\nto form a the binary mask label. When the hulls of two clus-\nters were intersecting beyond a threshold of 30%, they were\njoined together to form one cluster. If the intersection was\nbelow the threshold, the hulls were subtracted to separate the\nclusters in the binary mask. The U-Net model achieved a test-\nset Intersection-Over-Union (IOU) of 88.7%.\n2.3. Handling Inseparable Clusters with Image Denoising\nThe developed binary segmentation model segments the im-\nage in a way that identiÔ¨Åes disconnected clusters. If two or\nmore clusters intersect, the model is likely to combine these\nclusters into one. This holds true especially in real world\ndatasets where clusters are more likely to be inseparable. To\navoid this problem, we introduce an optional pre-processing\nstep of image denoising to Ô¨Ålter out low density areas in the\nimage and emphasize high density areas. This helps discon-\nnect cluster regions that seem to be connected by sparse data\npoints. We speciÔ¨Åcally denoise the image through a median\nÔ¨Ålter, where increasing the size of the Ô¨Ålter will eliminate low\ndensity areas and emphasize high density ones more severely.\n2.4. Handling Unassigned Points with Max Filtering\nWhen assigning labels to each point in the dataset in the Ô¨Ånal\nstep of the algorithm, many points will fall in regions that are\noutside but near the cluster area. These may be points that de-\nviate from where the majority of the points in the cluster are\nlocated and thus would be ignored by the binary segmenta-\ntion model. Unassigned points may also be low density areas\nthat were Ô¨Åltered out in the image denoising step, if used. To\n\nFig. 2 : Comparison of Visual Clustering with classical clustering algorithms on synthetic datasets with several cluster shapes.\nBottom right numbers indicate the Adjusted Mutual Information Score between the ground truth labeling and the predicted\nlabeling. Scores that are above 0.95 are highlighted in bold. Visual Clustering and DBSCAN are the only two algorithms that\nachieves nearly perfect matches with ground-truth labeling on all synthetic datasets.\naddress this, we perform an optional maximum Ô¨Åltering op-\neration on the label map to increase the area of each cluster,\nhelping cover nearby unassigned points. The degree in which\nwe would like to increase the cluster areas is controlled by the\nsize of the max Ô¨Ålter, where a larger Ô¨Ålter size will result in\nlarger cluster areas.\n3. RESULTS\n3.1. Clustering Performance on Synthetic Datasets and\nComputation Time Comparison\nThe performance of our visual clustering approach is com-\npared to multiple classical clustering algorithms on synthetic\ndatasets of various cluster shapes in Figure 2. Although the\nsegmentation model used in our algorithm was only trained\non blob-shaped clusters, it is able to successfully segment\nclusters independently of their shape. On datasets that have\nmore complex patterns, such as circle or moon-shaped clus-\nters, our algorithm provides clustering results that are more\nin-line with human intuition compared to the results of K-\nmeans, AfÔ¨Ånity Propagation, or Gaussian Mixture. While\nother algorithms such as DBSCAN or Spectral Clustering\nagree with human intuition, they suffer from a large com-\nputation time and cannot be used to cluster large datasets\nefÔ¨Åciently.\nThe computation time of the segmentation model, in-\nstance separation algorithms, and Ô¨Åltering techniques are\nindependent of the number of samples in the dataset. As our\nalgorithm is a completely vision-based approach, it provides\na great computation time advantage. However, the computa-Number of Samples\nAlgorithm 10K 50K 100K 500K 1M 2M\nVisual Clustering 0.292 0.571 0.909 3.686 7.222 14.096\nK-Means 0.155 0.541 1.103 5.470 9.519 18.956\nAfÔ¨Ånity Propagation 175.35 1 1 1 1 1\nMeanShift 3.482 101.82 1 1 1 1\nSpectral Clustering 0.052 0.509 0.796 7.455 20.001 53.559\nWard 1.994 27.965 93.564 1 1 1\nAgglomerative Clustering 1.177 12.154 39.886 1 1 1\nDBSCAN 0.093 0.357 0.837 7.604 20.009 52.648\nOptics 16.515 1 1 1 1 1\nBIRCH 1.298 7.390 14.320 1 1 1\nGaussian Mixture 0.089 0.358 0.726 3.047 5.949 11.962\nTable 1 : End-to-end computation time (in seconds) compar-\nison of Visual Clustering with classical clustering algorithms\nfor an increasing number of samples. 1indicates a computa-\ntion time beyond 3 minutes and hence was not included. Vi-\nsual Clustering is as fast as Gaussian Mixture and faster than\nall the other classical algorithms on large datasets.\ntion time of the plotting and cluster assignment steps in our\nalgorithm increase linearly with the number of samples. In\nTable 1, we show an end-to-end computation time compar-\nison between visual clustering (including the plotting time)\nand classical algorithms for an increasing number of sam-\nples. Visual Clustering achieves a very fast computation time\nthat is almost identical to Gaussian Mixture, which was the\nfastest classical algorithm among the ones tested, and faster\nperformance than K-Means clustering. Visual Clustering also\noutperforms all the rest of the classical algorithms in terms\nof computation time. Therefore, Visual Clustering achieves a\ncompromise between slow classical algorithms like AfÔ¨Ånity\nPropagation that can cluster complex patterns in a human\n\nInput datasetDenoised input\nwith ùê∑=10Visual Clustering \nresults with ùëÄ=1Visual Clustering \nresults with ùëÄ=70\nba\nc\nùëò-means clustering\nresults with ùëò=6\nProjected input\ndataset with PCADenoised input\nwith ùê∑=5Visual Clustering \nresults with ùëÄ=1Visual Clustering \nresults with ùëÄ=60ùëò-means clustering\nresults with ùëò=10\nProjected input\ndataset with PCADenoised input\nwith ùê∑=10Visual Clustering \nresults with ùëÄ=1Visual Clustering \nresults with ùëÄ=20ùëò-means clustering\nresults with ùëò=3\nFig. 3 : Results of the Visual Clustering algorithm on three real-world datasets compared with k-means clustering. Dstands for\nthe kernel size of the median Ô¨Ålter. Mstands for the kernel size of the max Ô¨Ålter. Dataset (a)consists of urban road accidents\ncoordinates. It contains 2 features and 360,177 samples. Dataset (b)consists of geo-magnetic Ô¨Åeld data for indoor localisation.\nIt contains 13 features and 58,374 samples. Dataset (c)consists of individual household electric power consumption data. It\ncontains 7 features and 2,075,259 samples. Both datasets (b)and(c)are reduced to two dimensions using PCA. We note that\nwe cannot conclude which algorithm provides the best clustering since no ground truth labels are available in these datasets.\nintuitive manner while having a very fast computation time\nlike Gaussian Mixture or K-Means.\n3.2. Performance on Real-world Datasets\nWe evaluate Visual Clustering on three real-world datasets\nobtained from the UCI repository among which one is two-\ndimensional and the two others are of higher dimension. The\nclustering results on those datasets are shown in Figure 3. In\nreal world datasets, clusters are more likely to not be visually\nseparable. For the Ô¨Årst two datasets ( aandb), the image de-\nnoising step shows its effectiveness in emphasizing high den-\nsity regions in the dataset and eliminating low density regions.\nThis helps the binary segmentation model capture more clus-\nters as they become visually separable. The majority of the\npoints that belong to low density regions were then recaptured\nby performing max Ô¨Åltering on the label map prior to cluster\nassignment.\nThe third dataset (dataset c) presents a more challenging\ncase for Visual Clustering where most of the points in the\nplot are connected through the same pattern. While visually\nit would be intuitive to identify the three main lines shown\nmore clearly after denoising as three different clusters, the al-\ngorithm instead considers them as one cluster. This is because\nVisual Clustering relies on binary segmentation and connectcomponent analysis which makes it difÔ¨Åcult to identify sev-\neral clusters on connected patterns, which could or could not\nbe desirable output based on the domain expertise of users. In\nthis respect, our future work will focus on improving the Vi-\nsual Clustering algorithm to enable further Ô¨Çexibility in seg-\nmentation in a way that provides an ability in placing multiple\nclusters on connected patterns. We will also investigate the\nproblem of assigning clusters to sparse points in the dataset\nwhich do not get covered even after performing max Ô¨Åltering\non the label map.\n4. CONCLUSION\nWe introduced Visual Clustering, a fast clustering algorithm\nbased on a trained image segmentation model. Visual Clus-\ntering is inspired by how humans cluster data: by plotting\ndatasets in 2D and identifying groups of similar points. Our\nexperiments on real and synthetic datasets and comparisons\nto ten classical clustering algorithms show that Visual Clus-\ntering achieves clustering results that are in-line with human\nintuition in a fast computation time that outperforms almost\nall the rest of the classical algorithms, making it efÔ¨Åcient for\nusage on very large datasets.\n\n5. REFERENCES\n[1] Thrasyvoulos N Pappas and Nikil S Jayant, ‚ÄúAn adap-\ntive clustering algorithm for image segmentation,‚Äù in\nInternational Conference on Acoustics, Speech, and Sig-\nnal Processing, . IEEE, 1989, pp. 1667‚Äì1670.\n[2] Rui Xu and Donald Wunsch, ‚ÄúClustering algorithms in\nbiomedical research: A review,‚Äù Biomedical Engineer-\ning, IEEE Reviews in , vol. 3, pp. 120 ‚Äì 154, 02 2010.\n[3] Martin Ester, Hans-Peter Kriegel, J ¬®org Sander, Xiaowei\nXu, et al., ‚ÄúA density-based algorithm for discovering\nclusters in large spatial databases with noise.,‚Äù in KDD ,\n1996, vol. 96, pp. 226‚Äì231.\n[4] Xin Jin and Jiawei Han, K-Means Clustering , pp. 695‚Äì\n697, Springer US, Boston, MA, 2017.\n[5] Xin Jin and Jiawei Han, Expectation Maximization\nClustering , pp. 382‚Äì383, Springer US, Boston, MA,\n2010.\n[6] Erich Schubert, J ¬®org Sander, Martin Ester, Hans Peter\nKriegel, and Xiaowei Xu, ‚ÄúDbscan revisited, revis-\nited: why and how you should (still) use dbscan,‚Äù ACM\nTransactions on Database Systems (TODS) , vol. 42, no.\n3, pp. 1‚Äì21, 2017.\n[7] Lei Zhou and Weiyufeng Wei, ‚ÄúDIC: deep image clus-\ntering for unsupervised image segmentation,‚Äù IEEE Ac-\ncess, vol. 8, pp. 34481‚Äì34491, 2020.\n[8] Xuan-Bac Nguyen, Duc Toan Bui, Chi Nhan Duong,\nTien D Bui, and Khoa Luu, ‚ÄúClusformer: A transformer\nbased clustering approach to unsupervised large-scale\nface and visual landmark recognition,‚Äù in Proceedings\nof the IEEE/CVF Conference on Computer Vision and\nPattern Recognition , 2021, pp. 10847‚Äì10856.\n[9] Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shim-\ning Xiang, and Chunhong Pan, ‚ÄúDeep adaptive image\nclustering,‚Äù in Proceedings of the IEEE International\nConference on Computer Vision , 2017, pp. 5879‚Äì5887.\n[10] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and\nMatthijs Douze, ‚ÄúDeep clustering for unsupervised\nlearning of visual features,‚Äù in Proceedings of the Eu-\nropean Conference on Computer Vision (ECCV) , 2018,\npp. 132‚Äì149.\n[11] Xiaoke Zhu, Taining Cheng, Qi Zhang, Ling Liu, Jing\nHe, Shaowen Yao, and Wei Zhou, ‚ÄúNN-sort: Neural\nnetwork based data distribution-aware sorting,‚Äù arXiv\npreprint arXiv:1907.08817 , 2019.\n[12] Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid\nvon Glehn, Pawel Lichocki, Ivan Lobov, BrendanO‚ÄôDonoghue, Nicolas Sonnerat, Christian Tjandraat-\nmadja, Pengming Wang, et al., ‚ÄúSolving mixed inte-\nger programs using neural networks,‚Äù arXiv preprint\narXiv:2012.13349 , 2020.\n[13] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and\nNeoklis Polyzotis, ‚ÄúThe case for learned index struc-\ntures,‚Äù in Proceedings of the 2018 International Confer-\nence on Management of Data , 2018, pp. 489‚Äì504.\n[14] Olaf Ronneberger, Philipp Fischer, and Thomas Brox,\n‚ÄúU-net: Convolutional networks for biomedical image\nsegmentation,‚Äù in International Conference on Med-\nical image computing and computer-assisted interven-\ntion. Springer, 2015, pp. 234‚Äì241.",
  "textLength": 19604
}