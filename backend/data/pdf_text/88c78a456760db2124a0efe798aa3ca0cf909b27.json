{
  "paperId": "88c78a456760db2124a0efe798aa3ca0cf909b27",
  "title": "A Pluggable Learned Index Method via Sampling and Gap Insertion",
  "pdfPath": "88c78a456760db2124a0efe798aa3ca0cf909b27.pdf",
  "text": "A Pluggable Learned Index Method via\nSampling and Gap Insertion\nYaliang Liâˆ—, Daoyuan Chenâˆ—, Bolin Ding, Kai Zeng, and Jingren Zhou\nAlibaba Group\n{yaliang.li, daoyuanchen.cdy, bolin.ding, zengkai.zk, jingren.zhou}@alibaba-inc.com\nABSTRACT\nDatabase indexes facilitate data retrieval and benefit broad applica-\ntions in real-world systems. Recently, a new family of index, named\nlearned index, is proposed to learn hidden yet useful data distribu-\ntion and incorporate such information into the learning of indexes,\nwhich leads to promising performance improvements. However,\nthe â€œlearningâ€ process of learned indexes is still under-explored. In\nthis paper, we propose a formal machine learning based framework\nto quantify the index learning objective , and study two general and\npluggable techniques to enhance the learning efficiency andlearning\neffectiveness for learned indexes. With the guidance of the formal\nlearning objective, we can efficiently learn index by incorporating\nthe proposed sampling technique, and learn precise index with en-\nhanced generalization ability brought by the proposed result-driven\ngap insertion technique.\nWe conduct extensive experiments on real-world datasets and\ncompare several indexing methods from the perspective of the in-\ndex learning objective. The results show the ability of the proposed\nframework to help to design suitable indexes for different scenarios.\nFurther, we demonstrate the effectiveness of the proposed sampling\ntechnique, which achieves up to 78x construction speedup while\nmaintaining non-degraded indexing performance. Finally, we show\nthe gap insertion technique can enhance both the static and dy-\nnamic indexing performances of existing learned index methods\nwith up to 1.59x query speedup. We will release our codes and pro-\ncessed data for further study, which can enable more exploration\nof learned indexes from both the perspectives of machine learning\nand database.\n1 INTRODUCTION\nDatabase indexes have been extensively studied in the database\ncommunity for past decades, resulting in fruitful designed index\nmethods and broad real-world applications, e.g., [1,9,41,50]. The\nrelated topics become even more important in the era of big data\nas tremendous data are generating and collecting from numerous\nsources at every second. Recently, a new family of index, namely\nlearned index, has attracted increasing attention due to its promis-\ning results in terms of both index size and query time [ 13,16,19,29].\nThe research direction of learned index is opened up by [ 29],\nwhich regards the traditional indexes such as B+Tree as models that\npredict the actual location within a sorted array for a queried key.\nFrom this view, indexes can be machine learning models trained\nfrom data to be indexed, and the hidden distribution information\nof data (for example, patterns and regular trends) can be leveraged\nto optimize the â€œindexingâ€ components of traditional indexes. For\nexample, to achieve small index size, the index storage layout of\nâˆ—The first two authors contributed equally to this work and are joint first authors.B+Tree, i.e., the height-balanced tree, can be replaced by a small\ntree whose nodes are machine learning models with a few learn-\nable parameters [ 29], or a small B+Tree whose nodes maintain the\nlearned parameters of a few piece-wise linear segments [ 19] rather\nthan the whole data. To achieve fast query speed, the index query-\ning algorithm of B+Tree is changed from traversing internal nodes\nwith multiple comparisons and branches to inferences of machine\nlearning models with a few numeric calculations [13, 16].\nHowever, the â€œlearningâ€ of learned indexes is still under-explored\nin existing learned index methods. First, how to compare different\nlearned indexes with evaluation from the perspective of machine\nlearning, such as learning objectives and capacity of chosen models?\nFor different data with varied hidden patterns and different resource\nconstraints, a formal learning objective can help us to design and\noptimize learned index. Second, few existing learned index methods\nstudy the cost of index learning while the sizes of real-world data\nare heavily increasing. Can we reduce the learning cost of learned\nindexes to enhance their applicability for large-scale datasets? Third,\nexisting learned index methods explore few about distributions of\nthe data to be learned. Can we deeply explore the data distribution\ninformation to further improve the learned index performance?\nMotivated by these three questions, in this paper, we propose a\nformal machine learning based framework to measure the index\nlearning objective , and study two general and pluggable learning-\noriented techniques, i.e.,sampling to enhance the learning effi-\nciency , and data redistribution via gap insertion to improve the\nindex performance from the view of learning effectiveness .\nFirst, to formally quantify the learning objective and learning\nquality of learned indexes, we regard the learned indexes as en-\ncoding mechanisms that compress data information into learned\nmodels and measure the learned index using the minimum descrip-\ntion length (MDL) principle [ 22]. By formulating an MDL-based\nobjective function as the learning objective, we connect two impor-\ntant concepts of machine learning, overfitting and underfitting, to\nthe flexible learning of indexes. With the help of the index learn-\ning objectives, we discuss how to compare existing learned index\nmethods and design suitable learned indexes for different scenarios.\nSecond, to reduce the learning cost and accelerate the index con-\nstruction especially for large-scale datasets, we propose to learn\nindex with sampled small subsets. By capturing the data distribu-\ntion information hidden in the data, it is possible to learn the index\nwith a small subset of data while achieving high learning effective-\nness. We theoretically prove the feasibility of learning index with\nsampling, and provide the asymptotic guideline on how large the\nsample should be in order to learn an index having a comparable\nperformance with the index learned on the whole dataset.\nLast but not the least, to enhance the performance and general-\nization ability of off-the-shelf learned indexes with few extra efforts,arXiv:2101.00808v1  [cs.DB]  4 Jan 2021\n\nwe study what a data distribution can be beneficial to index learn-\ning, and propose a data re-distribution technique via gap insertion.\nSpecifically, we design a result-driven strategy to estimate the gaps\nthat should be inserted in a data-dependent manner, and propose\na gap-based data layout and strategy to physically place keys on\npositions with gaps inserted. In comparison to the original distri-\nbution, the re-distributed data is easier to be learned and can boost\nthe performance of static indexing operations. Surprisingly, the\nresult-driven gap insertion also enables us to handle dynamic in-\ndexing scenarios well, which is due to the reason that the estimated\ngap-inserted positions can be predictively reserved for possible\ninserted keys in the dynamic workloads.\nWe conduct comprehensive experiments on four wildly adopted\nreal-world datasets. We compare several index methods [ 1,16,19,\n29] from the perspective of the proposed MDL-based framework,\nand examine these methods in terms of learning objective, model\nregularization and model capacity, providing a new understand-\ning of them. Further, we apply the proposed two general learning-\noriented techniques, sampling and data re-distribution via gap inser-\ntioninto existing learned index methods. Promising improvements\nare achieved for both these two techniques: The proposed sampling\ntechnique achieves up to 78x construction speedup, meanwhile\nmaintaining non-degraded query performance and reasonable pre-\ndiction preciseness; The gap insertion technique significantly im-\nproves the preciseness of learned indexes and achieves up to 1.59x\nquery speedup over strong learned index baselines. Finally, we also\nshow that the learned indexes with gap insertion can achieve good\nperformance on dynamic workloads.\nTo summarize, we make the following contributions: (1) We\npropose an MDL-based framework that enables formal analysis of\nlearning objectives and comparison of different learned indexes,\nand more importantly, the framework can guide us to design flexible\nlearned indexes for various scenarios; (2) We propose a pluggable\nsampling technique that can improve the learning efficiency of\nlearned index, which is practical and useful for index construction\nacceleration, especially on large-scale datasets; (3) We propose a\npluggable technique, data re-distribution via gap insertion , to better\nutilize the hidden distribution information of indexed data, which\nimproves the preciseness and generalization ability of learned in-\ndexes; (4) We conduct comprehensive experiments to verify the\neffectiveness of the proposed techniques, and we will release our\ncodes and datasets to promote further studies. With these contribu-\ntions, we hope to better connect the database community with the\nmachine learning community to enhance each other for the topic\nof learned indexes.\n2 PRELIMINARY\nIndexes as Mechanisms . Letâ€™s first formalize the task of learning\nindex from data: Given a database Dwithğ‘›records (rows), assume\nthat a range index structure will be built on a specific column ğ‘¥. For\neach record ğ‘–âˆˆ[ğ‘›], the value of this column, ğ‘¥ğ‘–, is adopted as the\nkey, andğ‘¦ğ‘–is the position where the record is stored (for the case of\nprimary indexes ), or the position of the pointer to the record (for the\ncase of secondary indexes ).ğ‘¦ğ‘–can be interpreted as the position of\nğ‘¥ğ‘–in an array sorted by ğ‘¥ğ‘–, and to support range queries, a database\nto be indexed needs to satisfy the key-position monotonicity.Definition 1 (Key-position Monotonicity). For a set of key-\nposition pairs{(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}, the key-position monotonicity means that,\nfor anyğ‘¥ğ‘–andğ‘¥ğ‘—,ğ‘¦ğ‘–<ğ‘¦ğ‘—iffğ‘¥ğ‘–<ğ‘¥ğ‘—.\nThe task of learned index aims to train and learn a predictive\nindex mechanism ğ‘€(ğ‘¦|ğ‘¥)fromD:ğ‘€takes a recordâ€™s key ğ‘¥as input\nand outputs a predicated position Ë†ğ‘¦â†ğ‘€(ğ‘¥)in the sorted array for\ndata access. From this perspective, classic index structures such\nas B+tree [ 1,24], Bâˆ—tree [ 10] and Prefix B-tree [ 4] can be also\nregarded as such a mechanism designed by experts, which gives\nthe exact position or the page number for a given key.\nPrediction-Correction Decomposition . The learning of an in-\ndex mechanism ğ‘€is essentially to approximate the joint distribu-\ntion of keys and positions. Ideally, the predicted position Ë†ğ‘¦should\nbe exactly the same as the true position of a record ğ‘¥, i.e., Ë†ğ‘¦=ğ‘¦.\nHowever, in general, Ë†ğ‘¦is different with ğ‘¦since it is difficult to per-\nfectly fit a real-world dataset containing complex patterns. Thus,\nthe query process of ğ‘¥can be decomposed into a â€œpredictionâ€ step\nthat gives prediction Ë†ğ‘¦based onğ‘¥usingğ‘€, and a â€œcorrectionâ€ step\nthat finds the true position ğ‘¦of indexed record based on Ë†ğ‘¦.\nFor example, considering B-Tree index, it gives the page number\nË†ğ‘¦where the record ğ‘¥is located in, and requires a further page scan to\nget the exact position of this particular record. For learned indexes,\nafter getting the predicted position Ë†ğ‘¦through machine learning\nmodel inference, we also need to conduct, e.g., a binary/exponential\nsearch around Ë†ğ‘¦to find the true position ğ‘¦where the record is\nstored. The cost of this â€œcorrectionâ€ step depends on the difference\n|Ë†ğ‘¦âˆ’ğ‘¦|. Indeed, one goal is to minimize the difference between Ë†ğ‘¦and\nğ‘¦. But the difference can be non-zero, which provides the flexibility\nto adjust the cost of â€œpredictionâ€ step for a mechanism, i.e., how\nmuch space we need to store ğ‘€and how much time we need to\ncalculateğ‘€(ğ‘¥). This raises several questions: can we evaluate a\nlearned index from the costs of these two decomposed steps? And\nwhat roles do these two steps play in the index learning?\n3 AN MDL-BASED FRAMEWORK\nIn this section, we formally quantify the index mechanisms using\nthe Minimum Description Length (MDL) principle [ 21,22]. We first\nconnect the above prediction-correction decomposition of index\nmechanisms with MDL, then formulate the learning objective of\nindex mechanisms with two general terms that can encode various\nindexing criteria, and finally discuss the physical meanings of the\nproposed concepts with several instantiations of index mechanisms.\n3.1 Measuring Mechanism with Minimum\nDescription Length\nThe idea of MDL is to regard both the given data Dand a mecha-\nnismğ‘€as codes, and regard the learning as appropriately encoding\nor compressing the data Dusingğ‘€. Then we can use the code length\nordescription length to measure the â€œsimplicityâ€ of a mechanism:\nThe more we learn the hidden patterns in the data and reduce its\nredundancy, the shorter the description lengths for the compressed\ndata and the learned mechanism. Specifically, the description length\nof a mechanism ğ‘€is decomposed into ğ¿(ğ‘€)andğ¿(D|ğ‘€):ğ¿(ğ‘€)in-\ndicates the description length of the mechanism itself, and ğ¿(D|ğ‘€)\nindicates the conditional description length of Dgivenğ‘€, which\ncan be interpreted as how many extra bits do we need to exactly\n2\n\ndescribeDusingğ‘€. In the context of learned index, we can link\nğ¿(ğ‘€)andğ¿(D|ğ‘€)to the prediction andcorrection respectively.\nFormally, in this paper, we will use the MDL criteria to measure\nthe quality of an index mechanism ğ‘€asMDL(ğ‘€,D)=ğ¿(ğ‘€)+\nğ¿(D|ğ‘€). To be more specific, the two terms:\nâ€¢ğ¿(ğ‘€)measures the cost of using ğ‘€for prediction, i.e., getting\nthe predicted position Ë†ğ‘¦based on the key ğ‘¥, which is usually\nproportional to the size of ğ‘€;\nâ€¢ğ¿(D|ğ‘€)=E{ğ‘¥,ğ‘¦}âˆˆDğ¿(ğ‘¦,Ë†ğ‘¦)measures the average cost of\ngetting the true position ğ‘¦based on the predicted position Ë†ğ‘¦,\nin the position correction step.\nTwo Example Instantiations. To better illustrate the idea of MDL,\nletâ€™s consider two instantiations of mechanism ğ‘€, classic B-tree\nand polynomial function. For a classic B-tree, ğ¿(ğ‘€)denotes the\ncost of traversing index tree, which is usually proportional to the\nheight of the index tree â„, i.e.,ğ¿(ğ‘€)âˆâ„. The concrete form of\nğ¿(ğ‘€)=ğ‘“(â„)depends on several implementation details of B-tree,\nsuch as the maximum number of children a node can have, or the\nminimum number of children an internal (non-root) node can have.\nThe second term ğ¿(D|ğ‘€)denotes the cost of page scan in the leaf\nnode, which is a function of page size ğ‘ , i.e.,ğ¿(D|ğ‘€)=ğ‘“(ğ‘ ). When\nbinary scan is adopted, ğ‘“(ğ‘ )is a linear function of log(ğ‘ ).\nFor the second example, letâ€™s consider the case that a polynomial\nfunction is learned to act as the mechanism, that is ğ‘€(ğ‘¥)=Ãğ‘‡\nğ‘¡=0ğ‘ğ‘¡Â·\nğ‘¥ğ‘¡+ğ‘ğ‘¡, whereğ‘ğ‘¡andğ‘ğ‘¡are learnable parameters for a corresponding\ndegreeğ‘¡, andğ‘‡is the highest degree. In this example, ğ¿(ğ‘€)can be\nmeasured as O(ğ‘‡), because O(ğ‘‡)multiplications are needed to get\nthe predicted position Ë†ğ‘¦based on the key ğ‘¥. For the second term in\nMDL,ğ¿(D|ğ‘€)=E{ğ‘¥,ğ‘¦}âˆˆDğ¿(ğ‘¦,Ë†ğ‘¦)=E{ğ‘¥,ğ‘¦}âˆˆD(log(|ğ‘¦âˆ’Ë†ğ‘¦|)+1)if\nbinary search is adopted for the correction step.\n3.2 Objective Function for Learned Indexes\nFrom the above discussion of two instantiations, we can see the\nMDL provides a criterion to formally analyze and compare differ-\nent indexes, including both classic B-tree and machine learning\nbased indexes. This enables us to design suitable index structures\nfor various scenarios. Formally, given the data Dand a family of\npossible mechanisms M, the process of learning index from data\ncan be formulated as to find the best mechanism ğ‘€âˆ—that minimizes\nthe description length as follows:\nğ‘€âˆ—=arg min\nğ‘€âˆˆMMDL(ğ‘€,D)=arg min\nğ‘€âˆˆM(ğ¿(ğ‘€)+ğ›¼ğ¿(D|ğ‘€)),(1)\nwhereğ›¼is a coefficient to balance the two terms in MDL. From\nthe view of machine learning, Dis fed into the learning procedure\nstated in Equation (1) and the description length (ğ‘€,D)acts as\nthe objective function to be minimized. By fitting the dataset, the\nlearning procedure finds an optimal mechanism ğ‘€to predict the\npositionğ‘¦based on given ğ‘¥. If a mechanism achieves minimum\ndescription length, it learns and stores the underlying key-position\ndistribution information about data in the most compact form. For\nexample, given a toy data D={(2,1),(4,2),(5,3),(6,4),(8,5)},\nthe learned index can represent it as ğ‘€(ğ‘¥)=Round(0.7ğ‘¥âˆ’0.5).\nInstead of storing the key-position pairs, only parameters of ğ‘€are\nneeded to store, which reduces the redundancy of raw data and\ncompresses the information to store. Although the distributions ofreal-world data are not so simple, various patterns can be mined\nby machine learning methods, and be expressed in compact forms.\nIn Equation (1), three factors ğ¿(ğ‘€),ğ¿(ğ·|ğ‘€)andğ›¼act as the\nknobs to tune the performance of learned indexes, and next we will\ngive more discussion about these factors.\nChoice ofğ¿(ğ‘€)andğ¿(ğ·|ğ‘€).To learn an index mechanism from\ndata, the first step is to choose the concrete forms of these two terms\nin the above framework. As the list of keys and corresponding posi-\ntions{(ğ‘¥,ğ‘¦)}are given and the underlying physical storage format\nis fixed, we can first choose a specific search method for the correc-\ntion step, and thus the concrete form of ğ¿(D|ğ‘€)=E{ğ‘¥,ğ‘¦}âˆˆDğ¿(ğ‘¦,Ë†ğ‘¦)\ncan be determined. For ğ¿(ğ‘€), it has more flexibility. It can be set as\nthe number of operations to calculate ğ‘€(ğ‘¥), the number of model\nparameters in ğ‘€, or the summarization of the ğ‘-norm of all model\nparameters, etc. The choice of ğ¿(ğ‘€)can be made by considering\nthe requirements of database systems and the constraints of compu-\ntation resources ( e.g., on-disk or in-memory) to fit various scenarios.\nFor example, existing learned index method PGM [ 16] implicitly\nadoptsğ¿(D|ğ‘€)=ğ‘™ğ‘œğ‘”(|Ë†ğ‘¦âˆ’ğ‘¦)|)+ 1since it uses a binary search,\nandğ¿(ğ‘€)to be the number of learned model parameters as it uses\nan optimal linear segmentation learning algorithm.\nOverfitting v.s. Underfitting. When learning to build the in-\ndex from data, the coefficient ğ›¼in Equation (1) plays an impor-\ntant role. From the perspective of machine learning, ğ¿(ğ·|ğ‘€)=\nE{ğ‘¥,ğ‘¦}âˆˆğ·ğ¿(ğ‘¦,Ë†ğ‘¦)measures the prediction loss on training data ğ·,\nwhileğ¿(ğ‘€)is the regularization term of learned model. These two\nterms are usually contradicted: We can learn a very complex model\nM to make the prediction loss on training data zero or close to zero,\nwhich leads to a small ğ¿(ğ·|ğ‘€)while a large ğ¿(ğ‘€), the so-called\noverfitting phenomenon [ 8,46]; On the other hand, if we learn a\nsimple model, ğ¿(ğ‘€)is small while ğ¿(ğ·|ğ‘€)is large as the model is\ntoo simple to make precious predictions, the so-called underfitting\nphenomenon. The coefficient ğ›¼makes a trade-off between these\ntwo terms and aims to learn an index mechanism having the min-\nimum description length, i.e., a relatively simple model ğ‘€while\nalso having a small prediction loss on training data.\nğ›¼in Existing Index Methods. For existing index methods, there\nare some tunable parameters playing the role of ğ›¼to adjust the ğ¿(ğ‘€)\nterm andğ¿(ğ·|ğ‘€)term in MDL. For example, the page size of B+\nTree, the tree depth and the layer width of RMI [ 29], and the error\nboundğœ–of FITting-Tree [ 19] and PGM [ 16]. These parameters are to\nbe tuned for a given Dand reflect the degree we want to fit D: With\na small page size, a deep and wide model tree, and a small ğœ–, these\nindex mechanisms will substantially gain small perdition errors\nğ¿(D|ğ‘€)and usually large ğ¿(ğ‘€)such as large index sizes or long\nprediction times. In other words, these parameters implicitly act\nas the regularization factors in index learning. In the experiments\n(Section 6.2), we will investigate the trade-offs of several index\nmechanisms with different ğ›¼s in more detail.\n4 LEARNING INDEX WITH SAMPLING\nAs formulated above, we aim to choose ğ‘€from a candidate family\nMto minimize the objective function ğ¿(ğ‘€)+ğ›¼ğ¿(D|ğ‘€), for a given\ndatasetD. When|D|is large, it is an expensive learning task. In fact,\nit is expensive just to evaluate the loss ğ¿(D|ğ‘€). In this section, we\nwill investigate a computationally efficient solution via sampling.\n3\n\n4.1 Accelerating Index Construction\nRecall that the cost of the correction step (corresponding to the\ntermğ¿(D|ğ‘€)in the MDL objective function) is proportional to\nlog|ğ‘¦âˆ’ğ‘€(ğ‘¥)|=log|ğ‘¦âˆ’Ë†ğ‘¦|when binary search is adopted (refer\nto above Two Example Instantiations ). Letâ€™s focus on the objective\nfunction in the following form:\nğ¿(D|ğ‘€)=E(ğ‘¥,ğ‘¦)âˆˆD[ğ¿(ğ‘¦,ğ‘€(ğ‘¥))]=E(ğ‘¥,ğ‘¦)âˆˆD[log|ğ‘¦âˆ’ğ‘€(ğ‘¥)|].\nLetEbe the maximum absolute prediction error, i.e., the maximum\nabsolute value of all differences between predicated positions and\ntrue positions:âˆ€(ğ‘¥,ğ‘¦) âˆˆD,|ğ‘€(ğ‘¥)âˆ’ğ‘¦| â‰¤E . We have such an\nupper bound ğ¿(ğ‘¦,ğ‘€(ğ‘¥))â‰¤ logE, for any(ğ‘¥,ğ‘¦)âˆˆD and a binary\nor an exponential search. Thus, we can show that a small sample\nfromDsuffices to approximate ğ¿(D|ğ‘€):\nProposition 1. Given thatğ¿(ğ‘¦,ğ‘€(ğ‘¥))â‰¤ logE, we draw a ran-\ndom sampleDğ‘ fromDwith|Dğ‘ |=ğ‘›ğ‘ . For any candidate mecha-\nnismğ‘€, we can estimate ğ¿(D|ğ‘€)using\nğ¿(Dğ‘ |ğ‘€)=1\nğ‘›ğ‘ âˆ‘ï¸\n(ğ‘¥,ğ‘¦)âˆˆD ğ‘ ğ¿(ğ‘¦,ğ‘€(ğ‘¥)),\ns.t., with probability as most 1âˆ’ğ›¿, we have\n\f\fğ¿(Dğ‘ |ğ‘€)âˆ’ğ¿(D|ğ‘€)\f\fâ‰¤logEâˆš2ğ‘›ğ‘ Â·âˆšï¸‚\nlog2\nğ›¿.\nProof. Here we provide a proof sketch due to the space limita-\ntion. Letâ€™s consider the random sample {(ğ‘¥,ğ‘¦)âˆˆDğ‘ }. Indeed, we\nhave\nE[ğ¿(Dğ‘ |ğ‘€)]=1\nğ‘›ğ‘ âˆ‘ï¸\n(ğ‘¥,ğ‘¦)âˆˆD ğ‘ E[ğ¿(ğ‘¦,ğ‘€(ğ‘¥))]=ğ¿(D|ğ‘€).\nSinceğ¿(ğ‘¦,ğ‘€(ğ‘¥))âˆˆ[ 0,logE], we apply Hoeffdingâ€™s inequality to\nfinish the proof.\nWe can interpret ğ¿(D|ğ‘€)as the expected cost of the correction\nstep. Theoretically, we only need to estimate it with an error up to\na constant factor ( e.g., no more than the size of a page). To this end,\nwe only need to draw a small sample.\nTheorem 1. Consider the optimization problem:\nğ‘€âˆ—=arg min\nğ‘€âˆˆMMDL(ğ‘€,D)=arg min\nğ‘€âˆˆM(ğ¿(ğ‘€)+ğ›¼ğ¿(D|ğ‘€)).\nWe can solve it on a random sample ğ·ğ‘ with sizeğ‘ =O(ğ›¼2log2E)as\nË†ğ‘€âˆ—=arg min\nğ‘€âˆˆMMDL(ğ‘€,Dğ‘ )\ns.t.,MDL(Ë†ğ‘€âˆ—,D)â‰¤ MDL(ğ‘€âˆ—,D)+ O(1)with high probability.\nProof. Indeed, we have\nMDL(Ë†ğ‘€âˆ—,D)âˆ’ MDL(ğ‘€âˆ—,D)\n=MDL(Ë†ğ‘€âˆ—,D)âˆ’ MDL(Ë†ğ‘€âˆ—,ğ‘†)+MDL(Ë†ğ‘€âˆ—,Dğ‘ )\nâˆ’MDL(ğ‘€âˆ—,Dğ‘ )+MDL(ğ‘€âˆ—,Dğ‘ )âˆ’MDL(ğ‘€âˆ—,D)\nâ‰¤|ğ¿(D| Ë†ğ‘€âˆ—)âˆ’ğ¿(Dğ‘ |Ë†ğ‘€âˆ—)|+0+|ğ¿(D|ğ‘€âˆ—)âˆ’ğ¿(Dğ‘ |ğ‘€âˆ—)|,\nwhere MDL(Ë†ğ‘€âˆ—,Dğ‘ )âˆ’MDL(ğ‘€âˆ—,Dğ‘ )â‰¤0if from the optimality of\nË†ğ‘€âˆ—. Using Proposition 1, both terms |ğ¿(D| Ë†ğ‘€âˆ—)âˆ’ğ¿(Dğ‘ |Ë†ğ‘€âˆ—)|and\n|ğ¿(D|ğ‘€âˆ—)âˆ’ğ¿(Dğ‘ |ğ‘€âˆ—)|can be bounded to complete the proof.We can interpret Theorem 1 as follows. For the purpose of min-\nimizing the MDL function considered in Equation (1), it suffices\nto learn the index ğ‘€on a small random sample with size as small\nasO\u0010\nğ›¼2log2E\u0011\n. Further, the parameter ğ›¼controls how much we\nweigh the cost of the correction step in relative to the size of the\nindexğ¿(ğ‘€)in our goal. The larger the weight is, the larger sample\nwe need to draw in order to learn the index; in other words, more de-\ntails about the data are needed to learn an index in finer granularity.\nIt should be noticed that there must be some constants hidden in the\nbig O notation, which does matter in practice; however, the above\ntheorem enables us to speed up index learning with small samples,\nand serves as an asymptotic guideline on how large the sample\nneeds to be. We will show that the proposed sampling technique\ncan achieve significant construction speedup while maintaining\ncomparable query performance in experiments (Section 6.3).\n4.2 Discussion\nEin Existing Learned Index Methods . Now letâ€™s examine the\nmaximum prediction error Efor several existing learned index\nmethods. FITing-Tree [ 19] and PGM [ 16] introduce an error bound\nğœ–to limit the maximum absolute difference between the actual\nand predicted position of any key, and thus Ecan be set asE=ğœ–.\nFor RMI [ 29], recall that the maximum prediction errors, (ğ‘¦â€²âˆ’ğ‘¦)\nwhereğ‘¦â€²can be larger or less than ğ‘¦, are recorded during the train-\ning, and thusEcan be bounded by the maximum value of them:\nE=ğ‘šğ‘ğ‘¥(|ğ‘šğ‘ğ‘¥_ğ‘ğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘£ğ‘’ _ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ|,|ğ‘šğ‘–ğ‘›_ğ‘›ğ‘’ğ‘”ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ _ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿ|). For these\nexisting learned index methods, we can see that Es are usually far\nsmaller than|D|, indicating that we can learn an index mecha-\nnism efficiently via sampling a small subset of D. In experiments\n(Section 6.3), we will see that these three learned index methods re-\nquire different numbers of samples to achieve non-degraded perfor-\nmances and their numbers of samples meet our asymptotic analysis\nO\u0010\nğ›¼2log2E\u0011\nwith different ğ›¼s and differentEs.\nUnseen Keys in Sampling . Interestingly enough, the sampling\ntechnique can bridge two indexing scenarios, static indexing and\ndynamic indexing, which correspond to two machine learning con-\ncepts, overfitting and generalization. In static indexing scenarios,\nwe only need to consider how to overfit Dsince all{ğ‘¥ğ‘–,ğ‘¦ğ‘–}to be\nindexed can be accessed during the learning. However, when learn-\ning on a sampled subset data Dğ‘ , the learned index mechanism ğ‘€\nhas to consider the model generalization ability to precisely predict\npositions for unseen dataDâˆ’ğ‘ =Dâˆ’Dğ‘ . While for dynamic index-\ning scenarios including possible inserted data, similarly, a learned\nindex mechanism ğ‘€needs to be generalized to unseen new keys.\nThis inspires us that if we can learn an indexing mechanism having\ngood generalization ability from a small sampled data Dğ‘ , we will\nbe able to learn a dynamic index that has good generalization ability\nand can handle inserted keys. Thus, as shown in the example of\nFigure 1(a), besides index construction speedup, the sampling tech-\nnique also improves the model generalization ability. This seems\ncontradicted with machine learning theory: usually the generation\nbound can be improved when we have more data, not fewer data.\nHowever, for learned index, the data pairs are not independent and\na small sample can be enough to learn the correlation between keys\nand their positions. Moreover, the sampling technique can help to\n4\n\nlearn the underlying distribution of Dbetter by extracting more\ngeneral patterns (red segments in Figure 1(a)) from Dğ‘ and alleviate\nthe overfitting (blue segments in Figure 1(a)) caused by some noisy\nkeys in the unseen Dâˆ’ğ‘ .\n(a) Sampling\n (b) Gap Insertion\nFigure 1: Examples of learned index with sampling and gap\ninsertion.\n5 LEARNING INDEX WITH GAP INSERTION\n5.1 Gap insertion\nAs discussed above, the proposed sampling technique can somehow\nimprove the generalization ability of learned index methods. Here\nwe explore more along this direction: Can we further enhance the\ngeneralization ability of learned index methods and improve their\npreciseness? In the fruitful research work of index structure in\nthe database community, there are some ideas about how to leave\ncertain empty space for dynamic data, such as Packed Memory\nArray [ 5] or Gapped Array [ 13]. Actually, we can further leverage\nthe empty space to re-distribute the data such that the updated key-\nposition distribution is easy to be learned and the generalization\nability of index can be further enhanced.\nLetâ€™s consider the example in Figure 1(b): Can we insert some\ngaps, move the original data ( i.e., blue dots) to the gap-inserted data\n(i.e., green dots), and learn the index as red segments? If so, the\nnewly learned index ( i.e., red segments) fits the gap-inserted data\nbetter and has better generalization ability. However, we should\nnote that the number of inserted gaps cannot be very large since\nthe gaps can increase storage and query costs, which are also part\nof the optimization goals.\nResult-Driven Gap Insertion . The gap insertion can be formu-\nlated as a position manipulation problem: given a set of data D=\n{ğ‘¥ğ‘–,ğ‘¦ğ‘–}ğ‘›\nğ‘–=1with the monotonicity of key-position, how to insert\ngaps and adjust each recordâ€™s position from ğ‘¦ğ‘–toğ‘¦ğ‘”\nğ‘–while preserv-\ning the monotonicity of key-position, such that the preciseness of\nlearned mechanism can be improved? Formally, let Dğ‘”={ğ‘¥ğ‘–,ğ‘¦ğ‘”\nğ‘–}ğ‘›\nğ‘–=1\nbe a gap-inserted data and ğ‘¢ğ‘–=ğ‘¦ğ‘”\nğ‘–âˆ’ğ‘¦ğ‘”\nğ‘–âˆ’1âˆ’1be the number of\ninserted gaps between ğ‘¥ğ‘–âˆ’1andğ‘¥ğ‘–. Thenğ‘¦ğ‘”\nğ‘–=ğ‘¦ğ‘–+Ã\n1â‰¤ğ‘—â‰¤ğ‘–ğ‘¢ğ‘—and\nwe aim to find a manipulated Dğ‘”that maximizes the objective:\nmax\n{ğ‘¦ğ‘”\nğ‘–}âˆ‘ï¸\n{ğ‘¥ğ‘–,ğ‘¦ğ‘–}âˆˆDğ¿(ğ‘¦ğ‘–,ğ‘€âˆ—\nD(ğ‘¥ğ‘–))âˆ’ğ¿(ğ‘¦ğ‘”\nğ‘–,ğ‘€âˆ—\nDğ‘”(ğ‘¥ğ‘–))\ns.t.âˆ€ğ‘–:ğ‘¢ğ‘–âˆˆZâ‰¥0,andğ‘›âˆ‘ï¸\nğ‘–=1ğ‘¢ğ‘–â‰¤ğœŒÂ·ğ‘›,\nâˆ€ğ‘–:ğ‘¦ğ‘”\nğ‘–=ğ‘¦ğ‘–+âˆ‘ï¸\n1â‰¤ğ‘—â‰¤ğ‘–ğ‘¢ğ‘—,âˆ€ğ‘–,ğ‘—:ğ‘¦ğ‘”\nğ‘–<ğ‘¦ğ‘”\nğ‘—,iffğ‘¥ğ‘–<ğ‘¥ğ‘—,(2)whereğœŒindicates the gap ratio that defines at most how many gaps\n(i.e.,ğœŒÂ·ğ‘›) can be introduced, ğ‘€âˆ—\nDandğ‘€âˆ—\nDğ‘”indicate the optimal\nlearned index mechanism from original data Dand gap-inserted\ndataDğ‘”respectively.\nInspired by block coordinate gradient descent [ 6], here we de-\nscribe a two-step result-driven solution to solve the optimization\nproblem in Equation (2): The solution first proposes a new index\nmechanism ğ‘€â€²that can achieve better preciseness than the index\nmechanism on the original data, and then move records to ğ‘¦ğ‘”that\nare as close as possible to the positions predicted by ğ‘€â€². In other\nwords, as the new index mechanism ğ‘€â€²meets our optimization\ngoal, i.e., reducing the prediction error, we can â€œbackward inferenceâ€\nğ‘¦ğ‘”using the predictions from ğ‘€â€²and learn a mechanism ğ‘€Dğ‘”from\nthe estimated gap-inserted data Dğ‘”.\nGap!\",$%!\",&%'(%\")*!\",+%!\",*!\",&Gaps,\",*,\",&,\",$,\",+\u0001\u0001\u0001\u0001'(%\"KeyPositionfor'(%-InsertionOriginalSegmentHypotheticalSegment\nFigure 2: The illustration of result-driven gap insertion.\nSpecifically, since the linear models are adopted in existing\nlearned index methods including RMI, FITing-Tree and PGM, here\nwe discuss how to manipulate the positions for linear models based\non the proposed result-driven solution. Considering that real-world\ndatasets usually cannot be indexed with only one linear model, we\nfirst learn an index mechanism with ğ¾linear segments to glob-\nally split the data, then locally insert gaps for each linear segment.\nLetâ€™s consider the example in Figure 2: for the ğ‘˜-th linear segment\n(ğ‘˜âˆˆ[1,ğ¾]), we can propose a hypothetical linear model shown in\nred line by connecting two anchoring points after gap insertion:\nthe first data point {ğ‘¥ğ‘˜,1,ğ‘¦ğ‘”\nğ‘˜,1}and the last data point {ğ‘¥ğ‘˜,ğ‘š,ğ‘¦ğ‘”\nğ‘˜,ğ‘š}.\nFor the first data point, ğ‘¦ğ‘”\nğ‘˜,1=ğ‘¦ğ‘˜,1+Ã\nğ‘—<=ğ‘˜ğ‘ˆğ‘—whereğ‘ˆğ‘—is the\nnumber of total inserted gaps in the previous ğ‘—-th segment, while\nfor the last data point, ğ‘¦ğ‘”\nğ‘˜,ğ‘š=ğ‘¦ğ‘˜,ğ‘š+Ã\nğ‘—<=ğ‘˜ğ‘ˆğ‘—+ğœŒ(ğ‘¦ğ‘˜,ğ‘šâˆ’ğ‘¦ğ‘˜,1)\nasğœŒ(ğ‘¦ğ‘˜,ğ‘šâˆ’ğ‘¦ğ‘˜,1)is the total number of gaps to be inserted in the\nğ‘˜-th segment. In this way, the gap-inserted positions ğ‘¦ğ‘”\nğ‘˜,ğ‘–can be\ncalculated as:\nğ‘¦ğ‘”\nğ‘˜,ğ‘–=ğ‘¦ğ‘”\nğ‘˜,1+(ğ‘¥ğ‘˜,ğ‘–âˆ’ğ‘¥ğ‘˜,1)Ã—ğ‘¦ğ‘”\nğ‘˜,ğ‘šâˆ’ğ‘¦ğ‘”\nğ‘˜,1\nğ‘¥ğ‘˜,ğ‘šâˆ’ğ‘¥ğ‘˜,1,\n=ğ‘¦ğ‘˜,1+âˆ‘ï¸\nğ‘—<=ğ‘˜ğ‘ˆğ‘—+(ğ‘¥ğ‘˜,ğ‘–âˆ’ğ‘¥ğ‘˜,1)Ã—(ğ‘¦ğ‘˜,ğ‘šâˆ’ğ‘¦ğ‘˜,1)(1+ğœŒ)\nğ‘¥ğ‘˜,ğ‘šâˆ’ğ‘¥ğ‘˜,1.(3)\nFrom a geometric perspective, the data after inserting gaps are\nplaced along the red hypothetical line and consequently, the data\nis re-distributed to meet our â€œexpected linear resultsâ€. Note that\nthe estimated ğ‘¦ğ‘”s can be non-integers and we will discuss how to\nphysically place the keys according to their ğ‘¦ğ‘”s in Section 5.2. Now\nletâ€™s first theoretically examine the effectiveness of the proposed\nresult-driven gap insertion technique.\n5\n\nTheoretical Analysis . In this section, we will theoretically show\nthat the index mechanism learned on Dğ‘”achieves better preciseness\nand tighter generalization bound than the one learned on D. Here\nwe leverage the information bottleneck principle [ 47] to quantify\nthe mutual information between the input keys and the positions\nto be predicted, and analyze the preciseness and generalization for\nindexes learned on Dğ‘”andD.\nLetâ€™s consider the index learning task in the context of infor-\nmation compression: The key ğ‘¥âˆˆX and the position ğ‘¦âˆˆY are\nboth random variables, and there are some statistical dependencies\nbetweenğ‘¥andğ‘¦. The index learning task can be regarded as to\nfind an optimal compact representation Ëœğ‘¥ofğ‘¥, which compresses ğ‘¥\nby removing the un-related parts of ğ‘¥that have no contribution to\nthe prediction of ğ‘¦; and then learn the correlation between Ëœğ‘¥ofğ‘¦.\nFormally, the index learning task is minimizing ğ¼(ğ‘¥;Ëœğ‘¥)âˆ’ğ›½ğ¼(Ëœğ‘¥;ğ‘¦),\nwhereğ¼()indicates the mutual information and ğ›½is a coefficient to\nadjust the trade-off between the degree of compression ğ¼(ğ‘¥;Ëœğ‘¥)and\nthe degree of preserving predictive information ğ¼(Ëœğ‘¥;ğ‘¦).\nLetËœXbe the set of minimal sufficient statistics of Xwith respect\ntoY,i.e.,âˆ€ğ‘¥âˆˆX,Ëœğ‘¥âˆˆËœX,ğ‘¦âˆˆY :ğ‘(ğ‘¥|Ëœğ‘¥,ğ‘¦)=ğ‘(ğ‘¥|Ëœğ‘¥). In the context\nof index learning, we interpret ËœXas the optimal hidden compact\nrepresentation of keys X. Note ËœX=Xis always sufficient for Y\nwhile usually not the optimal compact one with minimal |ËœX|. Then\nwe can see that|ËœX|becomes smaller on Dğ‘”after inserting gaps into\nthe original dataD, which makes the index learning easier and\nimproves the index preciseness. To clarify the reason, recall that\nwe insert gaps based on several hypothetical linear models. As\nthe linearity of transformed data increases, the linear correlation\nbetween keys and gap-inserted positions increases accordingly. In\nother words, we need less data information to learn the parameters\nof linear models, resulting in redundant ËœXand smaller|ËœX|. In the\nextreme case, ËœXcan have only one trivial Ëœğ‘¥, that is ËœX={ğ‘¥1âˆ’1}, if\nthe whole transformed data is on a simple line (e.g., ğ‘¦=ğ‘¥âˆ’ğ‘¥1+1).\nBesides, we can show that the index learned on Dğ‘”achieves a\ntighter generalization bound after inserting gaps into the original\nD. Let Ë†ğ¼()be the empirical estimate of the mutual information for\na given data, which is a sample of size ğ‘›from the joint distribu-\ntion{X,Y}. Shamir et al. [ 47] prove that the generalization error\nğ¸(Ëœğ‘¥,ğ‘¦)=|ğ¼(Ëœğ‘¥;ğ‘¦)âˆ’Ë†ğ¼(Ëœğ‘¥;ğ‘¦)|can be bounded in a data-dependent\nform with a probability of at least 1âˆ’ğ›¿:\nğ¸(Ëœğ‘¥,ğ‘¦)â‰¤(3|ËœX|+ 2)âˆšï¸\nğ‘™ğ‘œğ‘”(4/ğ›¿)\nâˆš\n2ğ‘›+(|Y|+ 1)(|ËœX|+ 1)âˆ’4\nğ‘›.(4)\nIn summary, the generation error between the optimal hidden com-\npact representation and the empirical estimates from finite sample\nDorDğ‘”is bounded in ğ‘‚(|ËœX||Y|âˆšğ‘›).\nNow letâ€™s compare the bounds on the original data Dand the\ngap-inserted dataDğ‘”. Note that we transform the original ğ‘¦intoğ‘¦ğ‘”\nwith a one to one mapping due to the key-position monotonicity,\nand thus the|Y|and data size ğ‘›remain the same. The other factor\n|ËœX|does matter, and it becomes smaller after gap insertion as we\nanalyzed above. As a result, the index mechanism learned on Dğ‘”has\na tighter generation bound than the index mechanism learned on D,\nand it can generalize to possible keys better. Later, we will discuss\nhow the proposed gap insertion technique can handle dynamicscenarios in Section 5.3 and experimentally confirm its advantages\nin Section 6.4.\nGap Insertion for Non-Linear Models . So far, our discussion\nabout the proposed gap insertion is based on a collection of linear\nmodels. However, the idea of results-driven gap insertion is general\nand easy to be extended to other non-linear models. Specifically,\nas long as the non-linear models to be learned are monotonically\nincreasing functions, we can also introduce the non-linear hypothet-\nical lines by anchoring a few points whose transformed positions\ncan be determined. Then based on the hypothetical lines, we can\ninference the positions for the keys of other non-anchoring points\nto fit hypothetical models.\n5.2 Physical Implementation of Gaps\nPhysical Key Placement . We have discussed how to logically esti-\nmate the gaps to be inserted such that a better index can be learned\non the gap-inserted data. However, as the estimated positions can\nbe non-integral, we need to round them into integers and physically\nplace the keys according to their adjusted positions. This is non-\ntrivial since we have to maintain the key-position monotonicity\nduring the placement. Letâ€™s assume two anchoring keys ğ‘¥ğ‘–andğ‘¥ğ‘—\nwhereğ‘¥ğ‘–<ğ‘¥ğ‘—, whose physical positions are integers and have been\ndetermined to be ğ‘¦ğ‘”\nğ‘–andğ‘¦ğ‘”\nğ‘—respectively. In practice, the first and\nlast points of each learned segment can be such anchoring points\n(please refer to Result-Driven Gap Insertion above). Consider ğ‘šnon-\nanchoring keys to be placed, whose keys are larger than ğ‘¥ğ‘–and less\nthanğ‘¥ğ‘—, we need to choose suitable positions to place them. On\none hand, the rounding of estimated (non-integral) positions may\nlead to conflicted ğ‘¦ğ‘”s. On the other hand, there may be more than\nğ‘šavailable positions used for physical placement, i.e., ğ‘¦ğ‘”\nğ‘—âˆ’ğ‘¦ğ‘”\nğ‘–>ğ‘š.\n\u0004\u000b\r\f\u000b\r\t\u0002\u000f\u000f\u0006\u0010\u0002\r\u0007\n\u000e\u000f\u000b\r\t\u0003\b\u0010\u0005\u000e\r\u0001\u0002\r\u0007\n\u000e\u000f\u000b\r\t\u0003\b\u0010!\"!#!$!$%&'(=(\"*+,'(=(\"*+,\nFigure 3: Illustration of linking array based key placement.\nTo address this problem, we propose a linking array based key\nplacement strategy as shown in Figure 3. We place a key ğ‘¥ğ‘™ac-\ncording to its predicted position ğ‘€(ğ‘¥ğ‘™). If two keys get conflicted\npredictions, we place them on an external linking array with the\nsame position. This strategy reduces the differences between physi-\ncal positions and result-driven estimated positions by fully utilizing\nthe prediction ability of learned index ğ‘€, at the price of introduc-\ning potential disambiguation costs to determine exact positions in\nthe linking arrays, and increasing storage costs for linking arrays.\nWe also explore two other strategies to balance the advantage of\naccurate prediction and the disadvantage of extra cost, and experi-\nmental results show that the strategy presented above works well\nin practice. Due to the space limitation, we omit the details and\nkeep with the above linking array based key placement strategy.\nAs a result, we place all data in a gapped array ğºand several\nlinking arraysA={ğ´ğ‘–}. A linking array ğ´ğ‘–contains the ğ‘–-th occu-\npied key inğºand at least one other key having the same position\n6\n\nğ‘¦ğ‘”=ğ‘–inğº. Theğ‘–-th occupied key in ğºwill be the minimum keys\nofğ´ğ‘–, i.e.,ğº(ğ‘–)=ğ‘šğ‘–ğ‘›(ğ´ğ‘–). Clearly, the key-position monotonicity\nis maintained for keys in the first-level gapped array. Next, we will\ndescribe how to read ( i.e., lookup operation) and write ( i.e., dynamic\nscenario) with the gap-based array.\nLookup Operation . As mentioned above, in the gapped array ğº,\nthere are more positions than the number of indexed keys, i.e.,\nğ‘¦ğ‘”\nğ‘—âˆ’ğ‘¦ğ‘”\nğ‘–>ğ‘š. Further, the proposed linking arrays can increase\nthe number of unoccupied positions. So how to conduct lookup\noperations on such data layout? The key idea here is to maintain a\ntotal order for keys in the first-level gapped array ğº, such that the\nunoccupied positions in ğºare comparable to indexed keys. Specifi-\ncally, we set the key of unoccupied position to be the key of the first\noccupied position at its right hand, and use an additional indicator\nto indicate that such unoccupied positions have no payloads. In this\nway, we can define a comparison rule for the situation of having the\nsame key but different payloads: a key pointing to an empty pay-\nload is smaller than the same key pointing to a non-empty payload,\nand thus the ğºis totally ordered.\nIn practical, if the searched positions point to the secondary\nlinking arrays, we conduct a linear scan on the linking arrays due\nto the fact that there are usually a limited number of keys with the\nsame conflicted predicted position.\n5.3 Dynamic Scenario\nHandling Dynamic Scenarios . Dynamic operations, especially\ninserting new keys, are challenging for learned index since the\nmachine learning models may need to be re-trained to maintain\nprecise predictions. Thanks to the proposed gap insertion, we can\nintroduce a simple yet effective extension to efficiently support dy-\nnamic operations, meanwhile, maintaining comparable prediction\npreciseness without model re-training. This is because we have re-\ndistributed the data by introducing gaps in a result-driven manner.\nFurther, we place keys directly according to their predicted posi-\ntions and allow position conflicts, thus the unoccupied positions are\ndata-dependently reserved for possible inserted new keys. In other\nwords, we can insert new keys based on their predicted positions\nby a learned index ğ‘€. These positions can be either unoccupied\nor occupied, and for both cases, the inserted data follow hidden\nkey-position distribution already learned by ğ‘€, such thatğ‘€can\nmaintain preciseness at no price or a small price of correction cost\nin the lookup operation.\nSpecifically, given a key ğ‘¥to be inserted, we expect to place ğ‘¥on\nthe position as close as possible to its predicted position by ğ‘€. Mean-\nwhile, to simplify the lookup operation after new data insertion, we\nneed to maintain the total order for ğºwith corresponding linking\narraysA:âˆ€ğ´ğ‘–âˆ’1âˆˆA, ğº(ğ‘–âˆ’1)=ğ‘šğ‘–ğ‘›(ğ´ğ‘–âˆ’1)â‰¤ğ‘šğ‘ğ‘¥(ğ´ğ‘–âˆ’1)<ğº(ğ‘–).\nUsingğ‘€, we first get ğ‘¥â€™s predicted position Ë†ğ‘¦and its upper boundâ€™s\npositionğ‘¦ğ‘¢ğ‘inğº, i.e., the position of largest key in ğºthat is less\nthan or equal to ğ‘¥, and then we insert ğ‘¥in eitherğº(Ë†ğ‘¦)(unoccupied\ncase) or the linking array ğ´ğ‘¦ğ‘¢ğ‘âˆ’1(occupied case) to maintain the\nkey-position monotonicity and the total order of ğº.\nFor the delete operation, first, we look up the ğ‘¥to be deleted.\nIfğ‘¥is stored in a linking array ğ´, we can easily remove ğ‘¥fromğ´\nwhen|ğ´|>2, or make the corresponding position an occupied one\nwith the other key in ğ´, and delete ğ´when|ğ´|=2. Otherwise, thedeletion will make an unoccupied position, and we need to update\nthe keys inğºwhose values are the same as ğ‘¥, by setting them as\nthe key atğ‘¥â€™s upper boundâ€™s position ğ‘¦ğ‘¢ğ‘, i.e.,âˆ€ğ‘¦ğ‘—:ğº(ğ‘¦ğ‘—)=ğ‘¥, set\nğº(ğ‘¦ğ‘—)â†ğº(ğ‘¦ğ‘¢ğ‘). For the update operation, we can look up the\ndata to be updated using its key and simply reset its payload value.\n5.4 Reducing Cost of Gap Insertion\nNow letâ€™s analyze the cost of the proposed gap-based index learn-\ning. Recall that we first learn an index with ğ¾linear segments on\noriginal dataD={ğ‘¥ğ‘–,ğ‘¦ğ‘–}ğ‘›\nğ‘–=1, then we generate gap-inserted data\nDğ‘”={ğ‘¥ğ‘–,ğ‘¦ğ‘”\nğ‘–}ğ‘›\nğ‘–=1and re-learn a better index on Dğ‘”. With existing\nlearned index methods such as FITing-Tree [ 19] and PGM [ 16], the\ncost of these three steps are all ğ‘‚(ğ‘›). Although the complexity of\nthe proposed gap-based index learning is still ğ‘‚(ğ‘›), we introduce\nsome extra training costs due to the inserted gaps. Fortunately, we\ncan leverage the sampling technique mentioned in Section 4 to\nfurther reduce the learning cost using small sampled data, and thus\nmaintain high learning efficiency.\nCombining Sampling and Gap Insertion . Formally, with a sam-\nple rateğ‘ âˆˆ(0,1.0]and the sample size ğ‘›ğ‘ =ğ‘›âˆ—ğ‘ , we first learn index\nğ‘€on a sampled subset Dğ‘ ={ğ‘¥ğ‘–,ğ‘¦ğ‘–}ğ‘›ğ‘ \nğ‘–=1ofD. Then we use all the\nğ¾segments of ğ‘€to estimate the positions of anchoring keys, physi-\ncally place other non-anchoring keys based on their predicted posi-\ntions from proposed hypothetical models, and get the gap-inserted\ndatasetDğ‘ ,ğ‘”={ğ‘¥ğ‘–,ğ‘¦ğ‘”\nğ‘–}ğ‘›ğ‘ \nğ‘–=1. Finally we re-learn an index mechanism\nonDğ‘ ,ğ‘”, and get the whole gap-inserted data Dğ‘”={ğ‘¥ğ‘–,ğ‘¦ğ‘”\nğ‘–}ğ‘›\nğ‘–=1by\nphysically placing the un-sampled keys Dâˆ’ğ‘ =Dâˆ’Dğ‘ intoDğ‘ ,ğ‘”.\nSumming up, we can learn an index with a data scale of ğ‘›ğ‘ and\nphysically maintain the whole data layout in ğ‘‚(ğ‘›). In Section 6.4.2,\nwe will experimentally show that by combining sampling and gap\ninsertion techniques, both the preciseness and efficiency of existing\nlearned index methods can be significantly improved.\n6 EXPERIMENTS\nIn this section, we conduct experiments aiming to answer the fol-\nlowing questions: (1) What are the strengths and weaknesses of the\nexisting learned index methods evaluated by the proposed MDL\nframework (Section 6.2)? (2) Can we improve the learning efficiency\nof the learned index by the sampling technique (Section 6.3)? (3)\nCan we enhance the learning effectiveness of learned index by the\nproposed result-driven gap insertion technique (Section 6.4)?\n6.1 Experimental Settings\nWe conduct all the experiments on a Linux server with an Intel\nXeon Platinum 8163 2.50GHz CPU, whose L1 cache size, L2 cache\nsize and L3 cache size are 32KiB, 1MiB and 33MiB respectively.\nBaselines . We compare a traditional and three learned index meth-\nods, which are also adopted as base methods to incorporate the\nplug-in sampling and gap insertion techniques.\nB+Tree: we use a standard in-memory B+ Tree implementation,\nstx::btree (v0.9) [ 7]. Following [ 19,29], we evaluate the B+ Tree\nindex with dense pages, i.e., the filling factor = 100%.\n7\n\nRecursive Model Index (RMI) [29]: RMI is a hierarchy learned\nindex method consisting of typically two-layer or three-layer ma-\nchine learning models. Following previous works [ 13,16,29], we\nadopt a two-layer RMI with linear models.\nFITing-Tree [19]: This is an error-guaranteed learned index method\nusing a greedy shrinking cone algorithm to learn piece-wise linear\nsegments. The learned segments are organized by a B+ Tree and\nhere we adopt the stx::btree to organize these learned segments.\nPiecewise Geometric Model (PGM) [16]: PGM is a state-of-the-art\nerror-guaranteed learned index method, which improves FITing-\nTree by learning an optimal number of linear segments. There\nare three PGM variants based on binary search, CSS-Tree[ 43] and\nrecursive construction. Here we evaluate its recursive version since\nit beats the other two variants.\nDatasets . We conduct experiments on four wildly adopted real-\nworld datasets that cover different data scales, key types, data dis-\ntributions and patterns:\nWeblogs [16,19,29]: The Weblogs dataset contains about 715M\nlog entries requesting to a university web server. The index keys\nare unique log timestamps. This dataset contains typical non-linear\ntemporal patterns caused by school online transactions, such as\ndepartment events and class schedule arrangements.\nIoT[16,19]: The IoT dataset contains about 26M recordings from\ndifferent IoT sensors in a building. The index keys are unique times-\ntamps of the recordings. This dataset has more complex temporal\npatterns than Weblogs, since IoT data are more diverse (e.g., motion,\ndoor, etc.) and prone to noise during the data collection.\nLongitude and LatiLong [13,16,19,29]: These two datasets con-\ntain location-based data that are collected around the world from\nOpen Street Map [38]. The index keys of Longitude are the longitude\ncoordinates of about 1.8M buildings and points of interest. Similar\nto [13], the index keys of LatiLong is compounded of latitudes and\nlongitudes as ğ‘˜ğ‘’ğ‘¦=90Ã—ğ‘™ğ‘ğ‘¡ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’+ğ‘™ğ‘œğ‘›ğ‘”ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’ .\nEvaluation Metrics . For the storage cost evaluation, we measure\ntheindex size . We use 64-bit payloads for all baselines and 64-bit key\npointers for all datasets. The index size of B+ Tree is the sum of the\nsizes of inner nodes and the sizes of leaf nodes including payloads.\nThe index size of RMI is the sum of payloads and the sizes of linear\nmodels, including slopes, intercepts, maximum positive/negative\nprediction errors storing as double-precision floats. The index sizes\nof Fitting-Tree and PGM are the sum of payloads and the sizes of\ntheir linear segment models, including slopes and intercepts storing\nas double-precision floats.\nFor the efficiency evaluation, we measure several kinds of time\ncosts in nanoseconds, including the index construction time , the\nindex prediction time per query ( i.e., getting predicted position Ë†ğ‘¦\ngiven queried key ğ‘¥), the index correction time per query ( i.e., getting\nthe true position ğ‘¦given Ë†ğ‘¦) and the overall query time per query\n(i.e.., gettingğ‘¦givenğ‘¥). Besides, we calculate the Mean Absolute\nError (MAE) between predicted positions and true positions as\n1\n|ğ·|Ã\nğ‘¥âˆˆğ·|ğ‘¦âˆ’Ë†ğ‘¦|). MAE is a metric widely adopted for machine\nlearning algorithms and determines the index correction time in\nthe context of learned index.6.2 Comparison under MDL Framework\nThe proposed MDL-based framework quantifies an index as terms\nofğ¿(ğ‘€)andğ¿(D|ğ‘€). In this subsection, we compare several exist-\ning index methods to demonstrate several performance trade-offs\nbetweenğ¿(ğ‘€)andğ¿(D|ğ‘€), and the impact of varying the mecha-\nnism familyM. We demonstrate the results on IoT dataset and omit\nthe results on the other three datasets due to the space limitation\nand similar conclusions.\n6.2.1 Performance Trade-Off. From the view of machine learning,\nğ¿(D|ğ‘€)measures the prediction loss on training data while ğ¿(ğ‘€)\nplays a regularization role of the learned model. These two terms are\nusually contradicted and can be balanced by the coefficient ğ›¼that\ncontrols performance trade-offs. As analyzed in Section 3.2, several\nparameters of existing index methods implicitly take the role of\nğ›¼: the number of the layer-2 models in RMI is proportional to ğ›¼,\nwhile the page size of B+ Tree and error bound ğœ–of Fitting-Tree and\nPGM are inversely proportional to ğ›¼. Here we vary these tunable\nparameters to study various performance trade-offs by adopting\ndifferentğ¿(ğ‘€)andğ¿(D|ğ‘€).\nTrade-off between Storage Cost and Query Efficiency. We\nfirst setğ¿(D|ğ‘€)=ğ‘¡ğ‘(D|ğ‘€)indicating the overall query time per\nquery andğ¿(ğ‘€)=ğ‘†ğ¼ğ‘ğ¸(ğ‘€)indicating the index size to explore\nthe trade-off between storage cost and query efficiency. We plot the\ncurves of overall query time per query and index size by varying\nğ›¼s of different methods in Figure 4.\nFigure 4: Trade-off between storage cost and query efficiency\nof four index methods.\nOverall speaking, all the four methods have consistent trade-\noff trends: a smaller ğ›¼achieves a smaller index size, but leads to\nlarger query time, as it penalizes less on the term ğ¿(D|ğ‘€). Here\nwe test several ğ›¼s for each method, and among them, some choices\ngain good trade-offs (e.g., ğœ–=128for FITing-Tree). These results\nnaturally raise an open question: what is the â€œbestâ€ space-time\ntrade-off and how to achieve it by tuning ğ›¼? In practice, it depends\non the demand of users. PGM has explored both ends of the space-\ntime trade-off by varying the degree of linear approximation and\nsearching an ğœ–that achieves minimal space or minimal query time.\n8\n\nğ‘‡ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ğ‘‡ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘‡ğ‘ğ‘œğ‘Ÿğ‘Ÿğ‘’ğ‘ğ‘¡ğ‘‡ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘ğ‘™ğ‘™ Index Size MAE\nB+ Tree (pageSize=256) 7,770,595,420 305 338 643 489,877,504 63.5005\nRMI (|ğ‘€|=100k) 682,842,396 68 539 607 128,720,736 173.513\nFITing (ğœ–=128,|ğ‘€|=11,830) 788,580,446 106 203 309 121,910,880 27.3392\nPGM (ğœ–=128,|ğ‘€|=8,813) 1,556,264,268 121 224 355 121,740,264 36.817\nTable 1: Performance comparison on the IoT dataset for B-tree with dense page, RMI, Fitting-tree and PGM. For RMI, FITing-\nTree and PGM,|ğ‘€|indicates their numbers of last-layer linear models. ğ‘‡indicate time in ns, and the index size is in bytes.\nIn the context of MDL, we can explicitly incorporate the prefer-\nence of users into the objective functions. And then the fruitful\nideas of hyper-parameter optimization [ 17] can be incorporated to\nautomatically search an optimal ğ›¼to achieve preferable trade-offs.\nAlso note that the query time of B+ Tree increases heavily from\npage size 256 to 512 since the index begins to fall out of the L1-cache.\nInspired by this phenomenon, we can see an interesting future\ndirection: designing cache-sensitive regularization in index learning.\nFor example, we can harness the information about the size of cache\nlines into the objective function by gate-control techniques [11].\nTrade-off between Prediction and Correction. We then drill\ndown the index querying process and explore the trade-offs be-\ntween prediction cost and correction cost. To measure the pre-\ndiction cost, we set ğ¿(ğ‘€)=ğ‘¡ğ‘(ğ‘€), whereğ‘¡ğ‘(ğ‘€)means the pre-\ndiction time . To measure the correction cost, we can set ğ¿(D|ğ‘€)\nto be the correction time ,i.e.ğ¿(D|ğ‘€)=ğ‘¡ğ‘(D|ğ‘€), or MAE ,i.e.,\nğ¿(D|ğ‘€)=1\n|D|Ã\nğ‘¥âˆˆD|ğ‘¦âˆ’Ë†ğ‘¦|.\nFigure 5: Trade-off between prediction time and correction\ncost of four index methods.\nWe plot the prediction time and correction cost (including correc-\ntion time andMAE ) for different index methods in Figure 5. As the\nparameterğ›¼increases ( i.e., page size and error bound decrease as\nthey are inversely proportional to ğ›¼), the prediction time of B+Tree,\nFITing-Tree and PGM both increase while their correction costs\ndecrease. From the view of MDL, a more complex ğ¿(ğ‘€), requiring\na longer prediction time, usually make precise predictions and thus\nsmaller correction cost ğ¿(D|ğ‘€). Here RMI is a bit different as its\nprediction time keeps almost the same as ğ›¼changes. This is dueto the fact that the major part of inference in RMI is calculating\nğ¿linear functions through a ğ¿layer tree (here ğ¿is 2), which is\nindependent of the tunable number of the layer-2 models.\nBesides, the results in terms of MAE and correction time of all\nthe index methods have the consistent increasing trends: all of\nthem increase as ğ›¼increases, while with different increasing speeds\n(see the different gaps between red lines and green lines). This\nmeets our expectation since the evaluated index methods use a bi-\nnary search within certain ranges: page size for B+ Tree, maximum\npositive/negative errors for RMI, and ğœ–for FITing-Tree and PGM.\nMeanwhile, the MAEs are bounded by these values and approxi-\nmatively reflect the correction time. Note that the MAE are usually\nsmaller than these fixed search ranges, which allow us to further\nuse exponential search to speed up the correction as studied in [ 13].\nAnother observation is that the prediction time is usually larger\nthan the correction time for B+Tree, FITing-Tree and PGM. Compar-\ning to their lookups within a continuous memory in the correction\nstage, their recursive lookups in the prediction stage tend to incur\nmore costs, which are due to the organization of hierarchical mod-\nels. This inspires us to design learned index having as few layers as\npossible, which is adopted by RMI method.\n6.2.2 The Effect of Model Capacity. We have studied the impact of\nvarying the regularization coefficient ğ›¼for different index methods.\nNow we study the intrinsic property of the mechanism by com-\nparing different model capacity, or say, comparing the different\nfamilies of learning models.\nTo fairly compare these four index methods, we choose the most\nfavorableğ›¼s for each of them, which are the values of ğ›¼s closest\nto the intersections of their time-space trade-off lines in Figure 4.\nThe results are summarized in Table 1. We can see that all the three\nlearned index methods achieve much smaller storage costs while\nfaster lookup speeds than traditional B+Tree. Among the three\nlearned index methods, we observe that FITing-Tree and PGM have\nmuch smaller MAE, better query efficiency, and smaller index size\nthan RMI. However, RMI method requires less construction time\nsince it doesnâ€™t need the organization of learned segments, such\nas an assistant B+Tree for FITing-Tree and a recursive strategy for\nPGM. Note that with the same ğœ–=128, PGM achieves a smaller in-\ndex size than FITing-Tree by learning the optimal number of linear\nsegments, while FITing-Tree adopts a greedy learning algorithm\nthat leads to more segments than PGM.\n6.3 Learned Indexes with Sampling\nRecall that existing learn index methods including RMI, FITing-Tree\nand PGM need to scan at least one pass of the whole data to learn\nseveral sub-models, and further organize the learned sub-models\nby a model tree or a B+Tree. There is a great potential to reduce\n9\n\nthe data scanning cost with smaller data, and reduce the index or-\nganization cost with fewer sub-models to be learned. Here we plug\nthe proposed sampling technique into these learned index methods\nto accelerate the index learning. Specifically, given a sample rate\nğ‘ âˆˆ(0,1.0], we first get a sampled dataset Dğ‘ by randomly sampling\nğ‘ Ã—|D| keys fromD, then learn the indexes from Dğ‘ , and finally\ntest the indexes on the whole dataset D. When directly applying\nthis procedure with original RMI, FITing-Tree and PGM methods,\nwe found some pretty large prediction errors caused by few unsam-\npled keys that cannot be covered by learned sub-models ( i.e., linear\nsegments here). Fortunately, we can eliminate these large errors\nby some simple yet effective patches. For FITing-Tree and PGM,\nwe connect the adjacent segments learned from Dğ‘ to cover all the\nun-sampled keys. For RMI, we propose a RMI-Nearest-Seg patch,\nwhich re-assigns a key covered by an un-trained (empty) sub-model\nto its nearest trained sub-model. Since the sampling may cause few\nviolations of error bounds, we adopt the exponential search to find\nthe searching boundary around the predicted position.\n0.2 0.4 0.6 0.8 1.0\nSample Rate6668707274Mean\nAbsolute Error (AE) for Patched PGM\n606264666870\nSTD1 <= s <= 0.1\n0.2 0.4 0.6 0.8 1.0\nSample Rate350400450500550600650Query Time (ns)Build Time and Overall Query Time for Patched PGM\n0.250.500.751.001.251.50\nBuild Time (ns)1e9\n103\n102\n101\nSample Rate350400450500550600650Query Time (ns)\n0.00.51.01.52.0\nBuild Time (ns)1e8\nOverall Query Time\nBuild Time\nMean of AE\nSTD of AE103\n102\n101\nSample Rate050100150200250300Mean\n0.1 <= s <= 0.001\n100150200250300\nSTD\n1 <= s <= 0.1 0.1 <= s <= 0.001Mean of AE\nSTD of AE\nOverall Query Time\nBuild Time\nFigure 6: MAE, build time and overall query time of PGM\nindex with varied ğ‘ . The gray and green horizontal dotted\nlines indicate the MAE of ğ‘€Dandğœ–=256respectively.\nBy varyingğ‘ from 1.0 to 0.001, we evaluate the MAE ,build time\nandquery time for all patched learned indexes on all the datasets.\nThe results of PGM on IoT dataset are shown in Figure 6, the other\ntwo index methods or on other datasets have similar conclusions\nand we omit those results due to the space limitation. In Figure\n6, the two right subfigures show the results for extremely small\nsample rates ( i.e., 0.1 to 0.001). For comparison, letâ€™s denote the\nindex learned from the original whole data Dasğ‘€D. In the top-\nright subfigure, the gray and green horizontal dotted lines indicate\nthe MAE of ğ‘€Dand the adopted error bound ğœ–=256respectively.\nConstruction Speedup . From Figure 6, we can see that the patched\nPGM gains significant construction speedup (e.g., the build time\ndecrease from 1.63ğ‘’9whenğ‘ =1to1ğ‘’8whenğ‘ =0.01, which be-\ncomes about 78x smaller), while maintaining non-degraded query\nperformance (e.g., when ğ‘ =0.01, the MEA is still very close tothe one ofğ‘€D, the gray dotted line). Generally speaking, the build\ntime linearly decreases as the sample rate decreases. On the other\nhand, the curves of MAE and query time are near-horizontal when\nthe sample rate decreases until the very small one (e.g., ğ‘ =0.0025).\nThese results show that we can significantly accelerate the learning\nof index with the proposed sampling technique while the learned\nindex is still precise.\nGeneralization Improvement . As discussed in Section 4.2, the\nsampling technique can improve the generalization ability of learned\nindex methods, which leads to a fewer number of learned segments\nand correspondingly smaller index size. We conduct statistics of the\nnumber of learned segments for patched FITing-Tree and patched\nPGM, and the results are illustrated in Figure 7.\n0.00.20.40.60.81.0Sample Rate120001300014000150001600017000Number of Learned Segments\nPatched FITing-TreePatched PGMIoT\nSample Rate0.00.20.40.60.81.05000100001500020000Number of Learned SegmentsLongtitude\n0.00.20.40.60.81.0Sample Rate5000750010000125001500017500Number of Learned Segments\nFigure 7: Number of learned segments for patched FITing-\nTree and patched PGM with varied ğ‘ .\nWe can observe that the numbers of learned segments of both\npatched FITing-Tree and PGM decrease as sample rates decrease.\nThis is because that as the sampled dataset becomes smaller, learned\nindex methods can extract more general patterns in the data as some\nnoisy keys are discarded. So some adjacent learned segments hav-\ning similar slopes can be merged, and the generalization ability\nimproves. Note that PGM adopts an optimal piece-wise segmenta-\ntion learning algorithm, and thus it is more stable than FITing-Tree\nthat adopts a greedy learning algorithm.\nTheğ›¼Adjustment . To gain more insights about the proposed\nsampling technique, here, we vary the tunable ğ›¼of learned index\nmethods and check their the smallest â€œsafeâ€ sampled data size ğ‘›ğ‘ ğ‘ğ‘“ğ‘’\nthat maintains a non-degraded performance.\n102103\nError Bound104105\nPatched FITing-Tree\nPatched PGM104105\nNumber of Layer-2 Models106Smallest Safe Sampled Data Size\nSmallest Safe Sampled Data Size\nRMI-Nearest-Seg\nFigure 8: The smallest â€œsafeâ€ sampled data size ğ‘›ğ‘ ğ‘ğ‘“ğ‘’to main-\ntain a non-degraded performance, by varying ğ›¼of different\nlearned index methods on IoT dataset.\nThe results are shown in Figure 8. Recall that in Section 4, we\ntheoretically show that it suffices to learn the index on a small\n10\n\nFigure 9: Boxplots of performance for PGM index with gap insertion on IoT dataset.\nsample with size as small as ğ‘‚(ğ›¼2ğ‘™ğ‘œğ‘”2E)in Theorem 1. Apply-\ning simple log transformation, we can get ğ‘™ğ‘œğ‘”(ğ‘‚(ğ›¼2ğ‘™ğ‘œğ‘”2E))=\nğ‘‚(4ğ‘™ğ‘œğ‘”ğ‘™ğ‘œğ‘”EÃ—ğ‘™ğ‘œğ‘”(ğ›¼))=ğ‘‚(ğ‘™ğ‘œğ‘”(ğ›¼)). That is, the ğ‘™ğ‘œğ‘”(ğ‘›ğ‘ ğ‘ğ‘“ğ‘’)for\nthese methods are asymptotically linear to ğ‘™ğ‘œğ‘”(ğ›¼). In Figure 8, the\nx-axis and y-axis represent ğ›¼andğ‘›ğ‘ ğ‘ğ‘“ğ‘’ with log transformation\nrespectively, and the linear trends of those plots match the above\ntheoretical analysis (again, note that the number of layer-2 models\nin RMI is proportional to ğ›¼, while the error bound of Fitting-Tree\nand PGM are inversely proportional to ğ›¼). With a smaller ğ›¼, we can\nachieve non-degraded performance with fewer samples, while a\nlargerğ›¼requires us to draw more samples since more details about\nthe data are needed to learn an index in finer granularity.\n6.4 Learned Indexes with Gap Insertion\nAs discussed in Section 5, we propose to learn precise index by\nadjusting the distribution of keys and positions, at the cost of gap\ninsertion and index re-training. The cost can be further reduced\nby combining the sampling technique. In this section, we empiri-\ncally examine the effectiveness and efficiency of the proposed gap\ninsertion technique.\n6.4.1 Static Scenarios. We conduct experiments on all the adopted\ndatasets and the three learned index methods, by varying the gap\ninsertion rate ğœŒfrom 0.5 to 0.001 and the sample rate ğ‘ from 1 to\n0.005. Due to similar results and space limitation, we only report the\nresults for PGM and IoT dataset here. The overall query time and\nother detailed performance numbers are summarized as boxplots\nin Figure 9, where each box indicates the middle 50% experimental\npoints and the â€œNo Gapâ€ boxes represent the baseline index ğ‘€D\nlearned without gap insertion.\nClearly, indexes learned on the gap-inserted datasets gain sig-\nnificantly smaller overall query times comparing with the baseline\n(e.g., the speedup is up to 1.59x), which verifies the effectiveness\nof the gap insertion technique. Note that the overall query time is\nthe overall performance including the advantage of improved MAE\nand the disadvantage of additional index size. To further analyze\nthe detailed performance, we further break down the overall query\ntimes into the prediction time and corrections time, and also plot\nMAE and index size in Figure 9. Comparing with the baseline with-\nout gap insertion, we can see that PGM with gap insertion achieves\nslightly better prediction time and much better correction time. To\nexplain the improvements, we can check the MAE results, which\nshow a significant improvement. However, the index size, including\nthe size of introduced gaps and linking arrays, becomes larger and\nreduce the benefits brought by the MAE improvements. So in total,\nthe correction time shows an averaged 2x improvement, and theoverall query time shows an averaged 1.4x speedup, which is less\nthan the improvement in terms of MAE. These results and analysis\nshow that our gap insertion technique can learn preciser indexes,\nand thus improve overall performance.\n6.4.2 Effect of Gap Insertion and Sampling. Above we analyze the\noverall performance of the gap insertion and sampling techniques,\nhere we discuss the performance of various cases with specific ğ‘ \nandğœŒ, as illustrated in Figure 10.\nLinking ArrayOverall Query TimeMean of MAE\nsample rate0.00.20.40.60.81.0gap rate0.00.10.20.30.40.5Overall Time (ns)sample rate0.00.20.40.60.81.0gap rate0.00.10.20.30.40.5Overall Time (ns)Sample Rate0.00.20.40.60.81.0Gap Rate0.00.10.20.30.40.5Overall Time (ns)\n50048046044042040038065585144373023\n0.00.20.40.60.81.00.00.10.20.30.40.5Mean of Absolute ErrorGap RateSample RateMAE\nFigure 10: The performance of PGM with varied ğ‘ andğœŒ.\nOverall speaking, comparing with the results without gap in-\nsertion and sampling ( ğ‘ =1,ğœŒ=0,i.e., the left upper concern in\neach subfigure), large gap rates and moderate sample rates achieve\nmuch smaller MAE and significant query efficiency improvements,\nverifying the effectiveness of proposed sampling and gap insertion\ntechniques again. Specifically, a larger ğœŒallows us to transform the\ndata distribution and enhance the patterns via the result-driven\ngap insertion. For the sampling technique, we can observe that it\nbehaves a bit different from the results in Section 6.3, where both\nreasonable MAE and query time can be maintained as ğ‘ decreases\nfrom 1.0 to 0.1. Here the reasonable MAE will be maintained but\noverall query time will decrease firstly and then increase slightly.\nThis is because that when combining the sampling and gap inser-\ntion, with a very small ğ‘ , we need to put more un-sampled keys\ninto the linking arrays, resulting in an increased total query time.\n6.4.3 Dynamic Performance. As mentioned in Section 5.3, our pro-\nposed techniques can be easily extended to handle the dynamic sce-\nnarios. To show how the performance varies with different dynamic\nscenarios, as an example here, we evaluate PGM with dynamic link-\ning arrays on both read-heavy and write-heavy workloads. Specifi-\ncally, we randomly split the IoT dataset into Dğ‘–ğ‘›ğ‘–ğ‘¡andDâˆ’\nğ‘–ğ‘›ğ‘–ğ‘¡with\nwrite proportion ğ‘¤,i.e.,D=Dğ‘–ğ‘›ğ‘–ğ‘¡+Dâˆ’\nğ‘–ğ‘›ğ‘–ğ‘¡,|ğ·âˆ’\nğ‘–ğ‘›ğ‘–ğ‘¡|=ğ‘¤Â·|ğ·|. We\nchooseğ‘¤=0.3andğ‘¤=0.7for read-heavy and write-heavy work-\nloads respectively, and randomly split Dâˆ’\nğ‘–ğ‘›ğ‘–ğ‘¡intoğµequal-sized data\n11\n\nbatchesDâˆ’\n1,...,ğ·âˆ’\nğµ. We initially learn the index on Dğ‘–ğ‘›ğ‘–ğ‘¡and then\ninsertDâˆ’\nğ‘–ğ‘›ğ‘–ğ‘¡in batches. After inserting the ğ‘-th batch, we evaluate\nits MAE, prediction time, correction time and overall query time\nby randomly querying the data we have seen so far.\nNo Gap 0\n(No Write)2 4 6 8 10\nInserted Batch200250300350400450500Time Per Query (ns)\nRead-Heavy Workload\n0.580.590.600.610.620.63Gap Fraction\nPredict Time Correction Time Overall Query Time Gap Fraction\nNo Gap 0\n(No Write)2 4 6 8 10\nInserted Batch100200300400500600700800Time Per Query (ns)\nWrite-Heavy Workload\n0.620.630.640.650.660.670.680.69Gap Fraction\nFigure 11: The performance of PGM with linking arrays on\ndynamic scenarios.\nThe left subfigure in Figure 11 shows the querying-related time\nand gap fraction after each batch insertion for the read-heavy work-\nload. As more new data are inserted into the reserved unoccupied\npositions, the fraction of available gaps decreases as expected. For\nquerying-related performance, the prediction time remains the\nsame, while the correction and overall query time slightly increase\nas some new data are placed into the linking arrays. Note that\nduring the insertion procedure, the index with dynamic linking\narrays achieves about 1.364x faster correction speed and 1.227x\nfaster overall lookup speed than the index without gap insertion\ntechnique (the leftmost points in the left subfigure of Figure 11,\nand this baseline can access to all the data D), showing the great\npotentials of the gap-based index to handle dynamic scenarios. In\nthe right subfigure, we also plot the results for write-heavy work-\nload, which shows similar trends as read-heavy workload. The only\ndifference is that the correction and overall query time increases\na bit faster than the ones in ready-heavy workload, as we have\nmore new data to insert in the write-heavy workload. All these\nresults confirm that the proposed method can effectively leverage\nthe reserved gaps and maintain comparable query performance for\ndynamic scenarios.\n7 RELATED WORK\nLearned Indexes . There have been many well-studied traditional\nindexes, such as tree-based [ 3,4,20,26,32,40,44], hash-based\n[41,50] and bitmap-based [ 2,9,25,42,51]. Recently, the learned\nindexes gain increasing interest, which learn and utilize the hidden\ndistribution of data to be indexed. Recursive Model Index (RMI)\n[29] firstly introduces the idea of predicting positions of keys with\nmachine learning models. FITing-Tree [ 19] greedily learns piece-\nwise linear segments with a pre-defined bounded error, and PGM\n[16] further improves FITing-Tree by finding the optimal number\nof learned segments given an error bound. ALEX [ 13] proposes\nan adaptive RMI with workload-specific optimization, achieving\nhigh performance on dynamic workloads. RadixSpline [ 28] gains\ncompetitive performance to RMI with a radix structure and a single-\npass training. In addition to single-dimensional indexes, existing\nmethods also explore the multi-dimensional scenarios, such as Flood\n[37], Tsunami [14], NEIST [52] and LISA [33].Our work is kind of complimentary to above existing learned\nindex methods. We propose an MDL-based learning framework to\nquantify the learning objective and propose two pluggable tech-\nniques that can be incorporated by existing methods to further\nenhances their performance as shown in experiments.\nSampling in Index . Sampling has also been explored in partial\nindex [ 45,48], tail index [ 18], cost estimation [ 12,13] and index\nlayout estimation [ 31,37]. Different from sampling a user-interested\nsubset in partial indexes [ 48] or a rare subset in tail index [ 18], we\nadopt a uniform sampling in our experiments. ALEX [ 13] samples\neveryğ‘›-th key of data to predict the cost of data node for bulk\nloading. Flood [ 37] trains RMI on each dimension and samples data\nto estimate how often certain dimensions are used. Different from\nALEX and Flood, we propose the sampling technique for learning\nacceleration, and we also provide some theoretical analysis that is\nfurther confirmed by experimental results.\nGapped Structure . To support dynamic operations, several gapped\ndata structures have been studied to reserve gaps between ele-\nments, including Packed Memory Array (PMA) [ 5], Packed-Memory\nQuadtree [ 49], B+Tree that reserves continuous gaps at the end of\ndata arrays, and ALEX [ 13] that adopts a gapped array with key\nshifts and model-based insertion. PMA and B+Tree reserve gaps\nthat are independent with different data distributions, while our\nmethod and ALEX reserve data-dependent gap using learned mod-\nels. Further, different from ALEX, we use linking arrays to simplify\nthe dynamic operations and make the key-position distribution of\ngap-inserted data suitable for possible inserted data.\nMachine Learning based Database . We compare several learned\nindexes from the perspective of minimum description length [ 21,\n22], which falls in the category of machine learning based database.\nRecently, there are many works facilitating database components\nwith machine learning, such as query optimization [ 15,27,30,35,\n36,39], workload forecasting [ 34], memory prefetchers [ 23], and\nselectivity estimation [53].\n8 CONCLUSION\nLearned index gains promising performance by learning and utiliz-\ning the hidden distribution of the data to be indexed. To facilitate\nthe learned index from the view of machine learning, we propose a\nminimum description length based framework that can formally\nquantify index learning objective and help to design suitable learn-\ning indexes for different scenarios. Besides, we study two general\nand pluggable techniques, i.e., the sampling technique to enhance\nlearning efficiency with theoretical guidance, and the result-driven\ngap insertion technique to enhance learning effectiveness in terms\nof index preciseness and generalization ability. Extensive exper-\niments demonstrate the efficiency and effectiveness of the pro-\nposed framework and the two pluggable techniques, which boost\nexisting learned index methods by up to 78x construction speedup\nmeanwhile maintaining non-degraded performance, and up to 1.59x\nquery speedup on both static and dynamic indexing scenarios. With\nthis paper, we hope to provide a deeper understanding of current\nlearned index methods from the perspective of machine learning,\nand promote more explorations of learned index from both the\nperspective of machine learning and database.\n12\n\nREFERENCES\n[1]David J Abel. 1984. A B+-tree structure for large quadtrees. Computer Vision,\nGraphics, and Image Processing 27, 1 (1984), 19â€“31.\n[2] Manos Athanassoulis et al. 2016. UpBit: Scalable In-Memory Updatable Bitmap\nIndexing. In SIGMOD . 1319â€“1332.\n[3]Manos Athanassoulis and Anastasia Ailamaki. 2014. BF-tree: Approximate Tree\nIndexing. In PVLDB . 1881â€“1892.\n[4]Rudolf Bayer and Karl Unterauer. 1977. Prefix B-trees. TODS 2, 1 (1977), 11â€“26.\n[5]Michael A Bender and Haodong Hu. 2007. An adaptive packed-memory array.\nTODS 32, 4 (2007), 26.\n[6]Dimitri P Bertsekas. 1997. Nonlinear programming. Journal of the Operational\nResearch Society 48, 3 (1997), 334â€“334.\n[7] Timo Bingmann. 2013. STX B+ Tree. https://panthema.net/2007/stx-btree/.\n[8]Christopher M Bishop. 2006. Pattern recognition and machine learning . springer.\n[9]Chee-Yong Chan and Yannis E. Ioannidis. 1998. Bitmap Index Design and Evalu-\nation. In SIGMOD . 355â€“366.\n[10] Yun-Chih Chang, Yao-Wen Chang, Guang-Ming Wu, and Shu-Wei Wu. 2000.\nB*-Trees: a new representation for non-slicing floorplans. In DAC . 458â€“463.\n[11] Junyoung Chung, Ã‡aglar GÃ¼lÃ§ehre, Kyunghyun Cho, and Yoshua Bengio. 2014.\nEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.\nArXiv abs/1412.3555 (2014).\n[12] Andrew Crotty, Alex Galakatos, Emanuel Zgraggen, Carsten Binnig, and Tim\nKraska. 2016. The case for interactive data exploration accelerators (IDEAs). In\nHILDA . 1â€“6.\n[13] Jialin Ding, Umar Farooq Minhas, Hantian Zhang, Yinan Li, Chi Wang, Badrish\nChandramouli, Johannes Gehrke, Donald Kossmann, and David B. Lomet. 2020.\nALEX: An Updatable Adaptive Learned Index. SIGMOD , 969â€“984.\n[14] Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. 2020.\nTsunami: A Learned Multi-dimensional Index for Correlated Data and Skewed\nWorkloads. arXiv preprint arXiv:2006.13282 (2020).\n[15] Anshuman Dutt, Chi Wang, Azade Nazi, Srikanth Kandula, Vivek Narasayya,\nand Surajit Chaudhuri. 2019. Selectivity Estimation for Range Predicates Using\nLightweight Models. PVLDB 12, 9, 1044â€“1057.\n[16] Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-index: a fully-dynamic\ncompressed learned index with provable worst-case bounds. PVLDB 13, 8, 1162â€“\n1175.\n[17] Matthias Feurer and Frank Hutter. 2019. Hyperparameter optimization. In\nAutomated Machine Learning . Springer, Cham, 3â€“33.\n[18] Alex Galakatos, Andrew Crotty, Emanuel Zgraggen, Carsten Binnig, and Tim\nKraska. 2017. Revisiting reuse for approximate query processing. PVLDB 10, 10,\n1142â€“1153.\n[19] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim\nKraska. 2019. FITing-Tree: A Data-aware Index Structure. In SIGMOD . 1189â€“\n1206.\n[20] Goetz Graefe and Per-Ã…ke Larson. 2001. B-Tree Indexes and CPU Caches. In\nICDE . 349â€“358.\n[21] Peter GrÃ¼nwald and Teemu Roos. 2019. Minimum description length revisited.\narXiv preprint arXiv:1908.08484 (2019).\n[22] Peter D GrÃ¼nwald and Abhijit Grunwald. 2007. The minimum description length\nprinciple . MIT press.\n[23] Milad Hashemi, Kevin Swersky, Jamie A. Smith, Grant Ayers, Heiner Litz, Jichuan\nChang, Christos Kozyrakis, and Parthasarathy Ranganathan. 2018. Learning\nMemory Access Patterns. In ICML .\n[24] Hosagrahar V Jagadish, Beng Chin Ooi, Kian-Lee Tan, Cui Yu, and Rui Zhang.\n2005. iDistance: An adaptive B+-tree based indexing method for nearest neighbor\nsearch. TODS 30, 2 (2005), 364â€“397.\n[25] Theodore Johnson. 1999. Performance Measurements of Compressed Bitmap\nIndices. In PVLDB . 278â€“289.\n[26] Changkyu Kim, Jatin Chhugani, Nadathur Satish, Eric Sedlar, Anthony D Nguyen,\nTim Kaldewey, Victor W Lee, Scott A Brandt, and Pradeep Dubey. 2010. FAST:\nfast architecture sensitive tree search on modern CPUs and GPUs. In SIGMOD .\n339â€“350.\n[27] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and Alfons\nKemper. 2018. Learned Cardinalities: Estimating Correlated Joins with Deep\nLearning. arXiv preprint arXiv:1809.00677 (2018).\n[28] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. arXiv preprint arXiv:2004.14541 (2020).\n[29] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In SIGMOD . 489â€“504.\n[30] Sanjay Krishnan, Zongheng Yang, Ken Goldberg, Joseph Hellerstein, and Ion\nStoica. 2018. Learning to optimize join queries with deep reinforcement learning.\narXiv preprint arXiv:1808.03196 (2018).\n[31] Christian A Lang and Ambuj K Singh. 2001. Modeling high-dimensional index\nstructures using sampling. In SIGMOD . 389â€“400.\n[32] Viktor Leis et al .2013. The Adaptive Radix Tree: ARTful Indexing for Main-\nmemory Databases. In ICDE . 38â€“49.[33] Pengfei Li, Hua Lu, Qian Zheng, Long Yang, and Gang Pan. 2020. LISA: A Learned\nIndex Structure for Spatial Data. In SIGMOD . 2119â€“2133.\n[34] Lin Ma, Dana Van Aken, Ahmed Hefny, Gustavo Mezerhane, Andrew Pavlo,\nand Geoffrey J Gordon. 2018. Query-based workload forecasting for self-driving\ndatabase management systems. In SIGMOD . 631â€“645.\n[35] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A learned\nquery optimizer. PVLDB .\n[36] Ryan Marcus and Olga Papaemmanouil. 2018. Towards a hands-free query\noptimizer through deep learning. arXiv preprint arXiv:1809.10212 (2018).\n[37] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learn-\ning Multi-dimensional Indexes. In SIGMOD . 985â€“1000.\n[38] OpenStreetMap contributors. 2017. Planet dump retrieved from\nhttps://planet.osm.org . https://www.openstreetmap.org.\n[39] Jennifer Ortiz, Magdalena Balazinska, Johannes Gehrke, and S Sathiya Keerthi.\n2018. Learning state representations for query optimization with deep reinforce-\nment learning. arXiv preprint arXiv:1803.08604 (2018).\n[40] Patrick Oâ€™Neil, Edward Cheng, Dieter Gawlick, and Elizabeth Oâ€™Neil. 1996. The\nlog-structured merge-tree (LSM-tree). Acta Informatica 33, 4 (1996), 351â€“385.\n[41] Rasmus Pagh and Flemming Friche Rodler. 2004. Cuckoo hashing. Journal of\nAlgorithms 51, 2 (2004), 122 â€“ 144.\n[42] Ali Pinar et al .2005. Compressing Bitmap Indices by Data Reorganization. In\nICDE . 310â€“321.\n[43] Jun Rao and Kenneth A Ross. 1998. Cache conscious indexing for decision-support\nin main memory. In VLDB . 78â€“89.\n[44] Jun Rao and Kenneth A. Ross. 2000. Making B+-Trees Cache Conscious in Main\nMemory. In SIGMOD . 475â€“486.\n[45] Praveen Seshadri and Arun Swami. 1995. Generalized partial indexes. In ICDE .\nIEEE, 420â€“427.\n[46] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding machine learning:\nFrom theory to algorithms . Cambridge university press.\n[47] Ohad Shamir, Sivan Sabato, and Naftali Tishby. 2010. Learning and generalization\nwith the information bottleneck. Theoretical Computer Science 411, 29-30 (2010),\n2696â€“2711.\n[48] Michael Stonebraker. 1989. The case for partial indexes. SIGMOD Record 18, 4\n(1989), 4â€“11.\n[49] Julio Toss, Cicero AL Pahins, Bruno Raffin, and JoÃ£o LD Comba. 2018. Packed-\nMemory Quadtree: A cache-oblivious data structure for visual exploration of\nstreaming spatiotemporal big data. Computers & Graphics 76 (2018), 117â€“128.\n[50] Jingdong Wang, Ting Zhang, Nicu Sebe, Heng Tao Shen, et al .2017. A survey on\nlearning to hash. PAMI 40, 4 (2017), 769â€“790.\n[51] Kesheng Wu et al .2006. Optimizing Bitmap Indices with Efficient Compression.\nTODS (2006), 1â€“38.\n[52] Sai Wu, Zhifei Pang, Gang Chen, Yunjun Gao, Cenjiong Zhao, and Shili Xiang.\n2019. NEIST: a Neural-Enhanced Index for Spatio-Temporal Queries. TKDE\n(2019).\n[53] Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan Duan, Xi Chen,\nPieter Abbeel, Joseph M Hellerstein, Sanjay Krishnan, and Ion Stoica. 2019. Selec-\ntivity Estimation with Deep Likelihood Models. arXiv preprint arXiv:1905.04278\n(2019).\n13",
  "textLength": 78575
}