{
  "paperId": "f6b59c09c1e44187da76baef1b2a77dc5c056a93",
  "title": "ESL: A High-Performance Skiplist with Express Lane",
  "pdfPath": "f6b59c09c1e44187da76baef1b2a77dc5c056a93.pdf",
  "text": "Citation: Na, Y.; Koo, B.; Park, T.;\nPark, J.; Kim, W.-H. ESL: A\nHigh-Performance Skiplist with\nExpress Lane. Appl. Sci. 2023 ,13,\n9925. https://doi.org/10.3390/\napp13179925\nAcademic Editors: Tian-Fu Lee, I-Pin\nChang and Tung-Kuan Liu\nReceived: 30 July 2023\nRevised: 29 August 2023\nAccepted: 31 August 2023\nPublished: 1 September 2023\nCopyright: © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\napplied  \nsciences \nArticle\nESL: A High-Performance Skiplist with Express Lane\nYedam Na1, Bonmoo Koo1, Taeyoon Park2, Jonghyeok Park3\nand Wook-Hee Kim1,*\n1Department of Computer Science and Engineering, Konkuk University, Seoul 05029, Republic of Korea\n2Department of Smart ICT Convergence, Konkuk University, Seoul 05029, Republic of Korea\n3Division of Computer Engineering, Hankuk University of Foreign Studies, Yongin 17035, Republic of Korea\n*Correspondence: wookhee@konkuk.ac.kr\nAbstract: With the increasing capacity and cost-efﬁciency of DRAM in multi-core environments,\nin-memory databases have emerged as fundamental solutions for delivering high performance.\nThe index structure is a crucial component of the in-memory database, which, leveraging fast\naccess to DRAM, plays an important role in the performance improvement and scalability of in-\nmemory databases. A skiplist is one of the most widely used in-memory index structures and it\nhas been adopted by popular databases. However, skiplists suffer from poor performance due to\ntheir structural limitations. In this work, we propose ESL, a high-performance and scalable skiplist.\nESL efﬁciently enhances the performance of traverse operations by optimizing index levels for the\nCPU cache. With CPU cache-optimized index levels, we synergistically leverage a combination of\nexponential and linear searches. In addition, ESL reduces synchronization overhead by updating the\nindex levels asynchronously, while tolerating inconsistencies. In our YCSB evaluation, ESL improves\nthroughput by up to 2.8 \u0002over other skiplists in high-level evaluations. ESL also shows lower tail\nlatency than other skiplists by up to 35 \u0002. Also, ESL consistently shows higher throughput in our\nreal-world workload evaluation.\nKeywords: skiplist; in-memory data structure; in-memory database; scalability; index structure\n1. Introduction\nDatabase systems are essential software systems that efﬁciently manage large amounts\nof data. They provide various functionalities for the user’s convenience. Also, database\nsystems provide strong data consistency guarantees by providing durability and crash\nconsistency. However, these functionalities and crash consistency protocols can burden the\nperformances of database systems [1–6].\nThe data amounts have been continuously increasing [ 7]. In-memory databases are\nwidely used solutions because they provide high throughput with low latency. However,\ndue to their high costs and physical capacity limitations, in-memory databases are focusing\nmore on scalability and cost-efﬁciency. Recently, the cost of DRAM has decreased [ 8].\nMoreover, emerging memory technologies, such as persistent memory [ 9] and CXL-based\nmemory [10], are expected to increase the memory capacity.\nThe increasing number of cores and computational power in servers [ 11–14] presents\nan opportunity to improve the performance of in-memory databases. As most servers have\nmultiple cores, in-memory databases can process the queries in a concurrent manner. Hence,\nhardware advancements offer the potential to synergistically improve the performance of\nin-memory databases by leveraging modern hardware.\nIn-memory databases mainly operate within DRAM-based memory spaces, making\nindex structures play a key role in these databases. Index structures can be categorized\nas ordered indices and hash-based indices. Ordered indices offer moderate search perfor-\nmance but good range query performance. Hash indices provide high performance for\npointer queries, yet they lag in terms of range query performance.\nAppl. Sci. 2023 ,13, 9925. https://doi.org/10.3390/app13179925 https://www.mdpi.com/journal/applsci\n\nAppl. Sci. 2023 ,13, 9925 2 of 17\nTree-based index structures, such as B+-tree [ 15–18], are widely used as representative\nordered indices. Tree-based index structures show good performance in both point queries\nand range queries. However, tree-based data structures require structure modiﬁcation\noperation (SMO), and these operations can reduce the query performance due to their\ncomplexity. For instance, the split operation of the B+-tree creates a new node and moves\nhalf of the entries to the new node. The parent entry of the new node is added to the parent\nnode. This split operation is repeated until the node has enough space.\nBy virtue of simplicity, the beauty of a skiplist [ 19] lies in its ability to offer a more\nstraightforward and cost-effective SMO compared to a tree-based structure. There is no\nsplit and merge operation in a skiplist. Instead, it adds a new node to the existing ones by\nconnecting the new node’s next pointer to the previous nodes.\nAs a result, most LSM-tree-based databases, such as LevelDB [ 20], RocksDB [ 21],\nHbase [ 22], and MongoDB [ 23], adopt a skiplist as the data structure for their MemTable.\nA skiplist is composed of multiple levels of linked lists, simplifying the SMOs. A skiplist\ngenerates multiple levels of each entry probabilistically and maintains them to reduce the\ncache misses when traversing the data structure. A skiplist can be divided into multiple\nlevels, denoted as index levels and data levels. The index levels provide the shortest path\nto the target data node in the data level. While the multiple levels of each entry reduce\ncache misses, a skiplist can still suffer from performance degradation due to cache misses.\nAdditionally, these multiple levels can extend the tail latencies of write queries, which\ninclude insert and delete operations; the insert and delete operations involve updates to\nthe index level.\nSeveral efforts were made to improve the performance of a skiplist. Cache-Sensitive\nSkiplist [ 24] merges upper-level entries into a single array. Parallel in-memory Skiplist [ 25]\nmerges multiple entries of neighbors of the same level into the skiplist. No Hot Spot\nSkiplist [ 26] adopts asynchronous updates for the index levels of a skiplist to reduce the\nlatency of the write operation. NUMASK [ 27] considers NUMA awareness by replicating\nindex levels to each NUMA socket.\nPrevious studies focused on either reducing the length of the critical path or reducing\nthe cache misses. However, we could not ﬁnd the skiplist, which considers both reducing\nthe length of the critical path and reducing the cache misses. However, to the best of our\nknowledge, previous studies required additional rebalancing operations to judiciously\nrebuild the index levels.\nIn this work, we propose a high-performance and scalable skiplist, denoted as the\nExpress Skiplist ( ESL). We aim to achieve superior performance for both read and write\noperations without any compromises, ensuring high scalability.\nThe contributions of the paper are as follows:\n• We propose a new in-memory skiplist, denoted as ESL , which is composed of a cache-\noptimized index level (COIL), a link-based data level, and a parent of data level (PDL)\nbetween the COIL and the data level.\n• We exploit the asynchronous update for the COIL and the PDL and update them using\nmultiple background threads.\n• We develop a technique to accelerate the read performance and tolerate inconsistencies.\nOur technique combines the exponential search [ 28] and linear search to accelerate the\nread operation and tolerate the inconsistencies in the COIL caused by the background\nthread shift operation.\nThe rest of the paper is organized as follows. In Section 2, we explain the background\nand motivation of this work. Section 3 describes the design overview of ESL. Section 4\npresents the details of the design of ESL . Section 5 shows how we implement ESL . Section 6\nshows the performance evaluation and experimental analysis of ESL. We discuss the\nlimitations of ESL and a skiplist for emerging storage devices in Section 7; we conclude the\npaper in Section 8.\n\nAppl. Sci. 2023 ,13, 9925 3 of 17\n2. Background\nIn this section, we explain the background of this work. First, we provide a brief\nintroduction of several variants of skiplists and introduce the concept of endurable transient\ninconsistency for designing scalable data structures (Figure 1).\n109910 9930 10 3015 99\n10 40 15 99 30H\nH\n10 15 30 40 99 H\n(a) Cache -Sensitive SkipList (b) NUMASK10 99\n10 99 30\n10 30 99\n10 40 15 99 30H\nH\nH\nH10 99\n10 99 30\n10 30 15 99H\nH\nHNUMA 0 NUMA 1\nFigure 1. Skiplist structures.\n2.1. Skiplist\nA skiplist [ 19] is one of the most widely used data structures in storage systems, such\nas RocksDB [ 21], LevelDB [ 20], Hbase [ 22], and so on. A skiplist is a scalable data structure\nthat is composed of multiple levels. In a skiplist, a higher level is a sparse-linked list, as it\nprovides opportunities to skip nodes in the lower level. A skiplist can be divided into two\nparts, index levels and data levels. The data level is the lowest skiplist level and contains\nall of the data of the skiplist. Index levels contain all of the skiplist levels, except for the\ndata level, and provide the shortest path to the target data node in the data level. A skiplist\ndoes not need complicated structure-modiﬁed operations (SMO), such as split and merge\noperations in tree-based data structures.\nA skiplist may fall short of the expected performance because it suffers from perfor-\nmance degradation from cache misses in linked-list-based structures. Also, adding more\nkey–value pairs to additional index levels results in overhead and extended tail latency.\nThere are multiple variants of skiplists [ 24–27] aimed at overcoming these main limitations\nof a skiplist.\n2.1.1. Cache-Conscious Skiplist\nSome research efforts were made to fundamentally reduce cache misses in a skiplist\nstructure. In the following works, researchers focused on reducing cache misses by merging\nmultiple nodes.\nCache-Sensitive Skiplist (CSSL) [24] is a variant of a skiplist, which reduces the number of\ncache misses by merging the multiple nodes in the index levels into a single array, denoted\nas afast lane . The fast lane is a consecutive array that contains all nodes, with the exception\nof the data level, which contains all data in the skiplist. As the nodes are in a single array\nand stored in a sorted manner, the data structure is more cache-friendly. CSSL includes\nanother array, denoted as the proxy lane , which consists of the data stored at the data level.\nSince the proxy lane is the array, it accelerates the process of ﬁnding a target data node not\nfound at higher levels. However, because the nodes of both index levels and data levels in\na skiplist are stored in separate arrays, numerous shift operations are required for node\ninsertion or deletion. As shown in [ 24], CSSL delays the fast lane and proxy lane updates\nto mitigate the shift operation overhead. However, it leads to the periodic reconstruction of\nthe fast lane and proxy lane, which may hinder overall performance.\nParallel in-memory Skiplist (PSL) [25] is a skiplist that merges multiple nodes into a node\nthat is similar to the B+-tree node. This structure enables reducing the number of cache\nmisses in the traversing skiplist. The Parallel in-memory Skiplist also defers updates of\nhigher index levels and rebuilds the structure when the number of updates reaches the\nthreshold using background threads. Since it periodically rebuilds the whole index structure\nin an asynchronous manner, the background threads can be the performance bottleneck.\n\nAppl. Sci. 2023 ,13, 9925 4 of 17\n2.1.2. Asynchronous Update for Index Levels\nA skiplist, with its simpler structure compared to a tree-based structure, ensures that\nits SMO is relatively cost-effective. However, the SMO entails overhead in the execution of\neach skiplist operation. In order to reduce the overhead along the critical path, previous\nstudies have leveraged asynchronous updates.\nNo Hot Spot Skiplist (NHSSL) [26] decouples each level within the skiplist and updates\nthe index levels asynchronously using background threads. The NHSSL hides the update\noverhead for index levels and employs the additional rebalancing operation to enhance\nthe skiplist.\nNUMASK [27] is an improved version of NHSSL, so it also exploits asynchronous updates\nfor index levels. In addition, NUMASK considers NUMA awareness by replicating index\nlevels for every NUMA socket. Also, NUMASK adds an additional level—denoted as the\nintermediate layer —to the index level to efﬁciently ﬁnd the data, which are stored in the\nNUMA remote socket.\n2.2. Tree-Based In-Memory Index Structure\nIndex structures are fundamental building blocks in the storage system. Numerous\nstudies have aimed to improve the index structure performance. CSB+-tree [16] makes the\nB+-tree CPU cache-efﬁcient by removing child pointers. Since the node only includes the\nkeys, the read operation is more efﬁcient. FAST [29] is an architecture-optimized index\nstructure, tailored for modern CPUs and GPUs. CSB+-tree and FAST are designed for read-\nintensive workloads; they are not good for write-intensive workloads. ESL is designed for\nboth read- and write-intensive workloads. Blink-Hash [30] employs a node structure, which\nis a combination of the hash table and a blink-tree to efﬁciently process the time-series\nworkload with keys sorted in ascending order in ascending order. ESL is designed for the\nvarious workloads of key–value stores, which can be in random order. Recent studies were\nconducted on index structures for near-data processing. In particular, process-in-memory\n(PIM) has emerged as a promising near-data processing hardware. HybriDS [ 31] employs a\nhybrid approach, which combines a skiplist with B+-tree. PIM-tree [ 32] develops the push–\npull search with a hybrid tree structure, which combines shadow subtrees and chunked\nskiplists. Also, the concept of the learned index [ 33] has been proposed. The basic idea\nof the learned index is to replace the internal nodes with models to ﬁnd the target data\nnodes. Initially, the learned index did not support the write operation. ALEX [ 34] provides\nwrite operations for the learned index. PLIN [ 35] optimizes the learned index structure for\nnon-volatile memory, and ROLEX [ 36] leverages the learned index for key–value stores for\ndisaggregated memory.\n2.3. Endurable Transient Inconsistency\nEndurable transient inconsistency [17,37,38] is a concept used for designing highly\nscalable index structures in multi-core systems. The basic idea of endurable transient\ninconsistency revolves around the idea that readers can ﬁnd the target data, even if the index\nstructure is in a transient state. In the FastFair [ 17] B+-tree, the reader can detect transient\ninconsistency by ﬁnding duplicate pointers. They can determine the target leaf node by\ntraversing, using the sibling pointer of the leaf node. HydraLIST [ 37] and PACTree [ 38]\nalso traverse their leaf nodes when their internal nodes indicate the neighboring node of\nthe target node. A skiplist is a data structure that is well-suited for adopting endurable\ntransient inconsistency. This is because a skiplist can also ﬁnd the target node by traversing\nthe level, even if the upper levels indicate the neighboring node.\n\nAppl. Sci. 2023 ,13, 9925 5 of 17\n3. Design Overview\n3.1. Design Goal of ESL\nIn order to design a high-performance and scalable skiplist structure, we aim to fulﬁll\nthe following two design goals.\nMulti-core scalability. Most computer systems, from embedded devices to servers in\nthe data center, have multiple core numbers, so the skiplist structure should be able to\nefﬁciently exploit multiple cores.\nCache Efﬁciency Since the CPU caches have lower latency than the main memory, the key\nto improving the performance of a skiplist, such as the in-memory data structure, is to\nefﬁciently leverage the CPU caches.\n3.2. Cache-Optimized Index Level (COIL) with Express Lane\nThe main reason for the huge performance degradation in the legacy skiplist is the\nnumber of cache misses encountered while traversing several linked list nodes. There is no\nguarantee that the neighboring nodes will be located closely; thus, moving to the next level\nresults in another cache miss. To resolve the performance degradation from cache misses,\nwe designed the cache-optimized index level (COIL). The basic idea of the COIL is to merge\nthe nodes from the same level to a consecutive array. All levels are sorted and consecutively\nstored, so we leverage the exponential search to accelerate the read performance. The index\nlevel in the COIL that employs exponential search is denoted as the express lane . When ESL\nﬁnds a larger key than the given key, ESL triggers a linear search to leverage the advantages\nof the CPU cache and prefetcher. To add/remove the new data in the levels, we leverage\n8-byte atomic write operations for a shift operation similar to that of the failure-atomic shift\noperation [17].\nThe express lane is starkly different from the fast lane/proxy lane in CSSL as the\nexpress lane consists of multiple index levels, and it implements exponential search. Fur-\nthermore, the express lane is updated asynchronously, so it does not require an additional\nrebuilding process in CSSL.\n3.3. Lock-Free Data Level and Parent of the Data Level (PDL)\nThe data level holds all data in the ESL . Also, all the foreground threads concurrently\naccess this data level for reading or updating its contents. Hence, ESL adopts a lock-free\nlinked list for the data level, ensuring scalable and concurrent access. Since the data are\nindependently stored in a linked list node, they can provide ﬁne-grained synchronization.\nHence, the scalability of ESL can be enhanced. We also leverage a lock-free linked list for\ntheparent of the data level (PDL), which is managed by the background thread. Since the\nlowest level of the index level would have a higher chance of being selected, there can be\nmany data, which may lead to large shift operations. Thus, ESL reduces the shift operation\noverhead by adopting a lock-free linked list instead of an array.\n3.4. Asynchronous Update of the COIL and the PDL\nThe shift operation would incur huge overhead when large numbers of data are stored\nat the index level. In a skiplist, the write operation should update the lowest-level linked\nlist as well as the upper levels. The upper levels would be determined with probability.\nIn this case, the shift operation would lengthen the elapsed time for the write operation.\nTo shorten the elapsed time for the write operation, ESL exploits background threads to\nasynchronously update the upper levels. The foreground threads ﬁrst traverse the upper\nlevels and then ﬁnd the target location at the data level. The foreground threads update the\nlinked list and then write the operation log entry and insert it into the operation log. The\nbackground threads read the operation log entry and then conduct the operation for the\ngiven levels.\n\nAppl. Sci. 2023 ,13, 9925 6 of 17\n3.5. Synchronization\nESL is composed of three levels: the COIL, the data level, and the PDL. As mentioned\ninSection 3.4 , we decouple these into three levels and asynchronously update the COIL\nand the PDL. Hence, ESL adopts two different synchronization strategies.\nCOIL : We adopt the read-optimized write exclusive (ROWEX) [39] protocol for the COIL.\nTraversing the COIL is an essential operation in ESL, as every operation has to ﬁnd the\ntarget location using the COIL. The foreground threads do not modify the COIL; only the\nbackground threads update the COIL. Hence, ESL leverages the ROWEX protocol, which\nprovides a non-blocking read operation with only a writer.\nThe data level and the PDL :ESL exploits the lock-free linked list for the data level and\nthe PDL. The main advantage of using a lock-free linked list for the data level is that the\nforeground threads can read or update the data level simultaneously without blocking.\nAlso, the lock-free linked list helps minimize the tail latency [ 40]. Since each key–value\npair is stored in a single linked list node, in the critical section, ESL only has to conduct a\npointer update operation to connect the newly created data node.\nThe PDL is also based on a lock-free linked list, so the multiple background threads\ncan update simultaneously, and do not incur a shift operation. The PDL is located above\nthe data level, so it has a higher chance to add new data. Thus, exploiting a lock-free linked\nlist is helpful in reducing the background thread overhead.\nOperation log : The operation log in ESL works in a lock-free manner. The operation log\nqueue is implemented using compare-and-swap (CAS) instructions. The foreground threads\nﬁrst acquire the log space by increasing the tailof the operation log. The foreground threads\ncan write the operation log entries only when they successfully update the allocation index\nnumber. Similarly, the background threads have to update the head using a CAS operation\nbefore processing the operation log entries.\n4. Design of ESL\nIn this section, we propose a new skiplist, denoted as ESL, and present its overall\nstructure, semantics, and concurrency control scheme.\n4.1. Structure of ESL\nFigure 2 presents the overall structure of ESL .ESL consists of the COIL, the data level,\nand the parent of the data level (PDL). The COIL is composed of arrays of nodes. The nodes\nin the same level are merged into the same array. Figure 3 describes the COIL structure.\nThe data level and the PDL are the lock-free linked lists, as shown in Figure 4. The data\nlevel keeps all data from ESL. The PDL is the lowest index level. ESL adopts the PDL as\nthe base level of its index levels to circumvent the shift operation (see Section 4.2). The\nbackground threads read the operation log entries from the operation log and add these\nentries to their respective index levels in an asynchronous manner.\n4.2. Write Operation (Insert/Update/Delete)\nThe write operation in ESL ﬁrst traverses the COIL and then ﬁnds the target locations\nin the PDL and the data level. In the PDL and the data level, the writer performs the write\noperation in a lock-free manner and writes the operation log entry.\nInsert. Since a skiplist is a probabilistic data structure, it needs to generate a random\nnumber to determine the level for a given key–value pair. When the level is determined,\nthe writer allocates a new data node at the data level and writes the key–value pair. After\nallocating the data node, the writer traverses the COIL ( 1in Figure 2) and the PDL,\n(2), ﬁnds the target location at the data level ( 3in Figure 2), and then adds it using\nthe CAS instruction to atomically connect the newly created data node ( 4in Figure 2).\nFinally, the writer creates a new operation log entry and adds it to the operation log ( 5in\nFigure 2). The background threads will process the operation using the operation log in an\nasynchronous manner.\n\nAppl. Sci. 2023 ,13, 9925 7 of 17\nUpdate. The update operation of ESL does not create a new key–value pair. Instead, it\nchanges the pointer value in the existing data node at the data level, which has the same\nkey. Hence, the update operation of ESL requires traversing the COIL, the PDL, and the\ndata level. Within the data level, the writer ﬁnds the target data node. After ﬁnding the\ntarget data node, the writer changes the pointer value atomically using the CAS instruction.\nIn the update operation, ESL does not employ an asynchronous update for this update\noperation since there is no update operation for the COIL.\nDelete. ESL’s delete operation traverses the COIL and the PDL, similar to the insert and\nupdate operation. If the writer ﬁnds the index node, which has the same key as the given\nkey, the writer logically deletes the index node by marking it as a deleted node. After\nmarking the node, the writer moves to the lower level and logically deletes the index node\nat the index level. At the PDL and the data level, the writer ﬁnds the target node and deletes\nthe data node by disconnecting the pointer from the previous node. After disconnecting\nthe pointer, the writer deletes the data node. In order to safely reclaim the memory space,\nESL uses epoch-based memory reclamation [ 37,38,41,42]. Note that since the index node in\nthe lowest level of the COIL and the PDL has the target node’s virtual address instead of\nthe index, deleting the data node from the PDL does not hurt the correctness.\n10 99\n10 30 99\n10 15 30 40 99\n10 15\n2030 40 99Ins/k:20/Lev:2\nTraverse \nthe COIL\nTraverse \nthe Data ListAdd the new Data List nodeWrite a new oplog entry \nAdd the keyAdd the key\nCOIL\nData List\nBG Thread 0FG Thread PData List\nTraverse \nthe PData List\n… 150 300\n120…\n…\n…Express  Lane\nFigure 2. An illustration of the ESL structure and an example of the insert operation. 1The\nforeground thread traverses the COIL to ﬁnd the target node in the PDL. 2The foreground thread\nﬁnds the target data node by traversing the PDL. 3The foreground thread moves to the target data\nnode at the data level. 4The foreground thread adds the new data node using a CAS operation.\n5The foreground thread writes the operation log entry. 1,2The background thread reads the\noperation log entry from the operation log and adds the new data to the index level according to the\noperation log entry.\nVersion  \nLockSize of the \nLevelKey-Value pairs\nKey \n(8Byte)\nNext_Elem\n(8Byte)\nShortCut\n(8Byte)\nFigure 3. Layout of index levels in the COIL. Each entry of an index level consists of an 8-byte key,\n8-byte next_elem, an index of the key at the next level, and an 8-byte shortcut. next_elem is an index\nnumber at the next level. The shortcut is a pointer to the data node.\n\nAppl. Sci. 2023 ,13, 9925 8 of 17\n…\nKey\n(8 Byte)\nPtr\n(8 Byte)\nFigure 4. Layout of linked lists used in the PDL and the data level. Each node has an 8-byte key and\nan 8-byte value.\n4.3. Asynchronous Update\nESL updates the PDL and the COIL using single or multiple background threads\n(1,2in Figure 2). The asynchronous updates are invoked by an insert operation to add\nan entry to the index levels. The insert operations for the PDL and the COIL are shown in\nFigure 5. Updating the COIL entails shift operation; thus, the performance degradation is\nproportional to the number of shift operations. Figure 6 shows how the background thread\nupdates the COIL. In order to make the reader tolerable to the transient inconsistency, the\nbackground thread writes the data to the index level in order. First, the background thread\nreserves a space for storing a new entry ( 1,2,3in Figure 6, so it shifts the keys, as shown\nin Figure 6. The background thread writes the next_elem (4) and then writes the shortcut\naddress ( 5), which indicates the data node. Lastly, the background thread writes the key\n(6). We add the mfence instruction to guarantee the ordering of the store instruction, a\npractice consistent with previous studies [17,18,38,40].\nNote that the background threads do not delete the entry or decrease the index number,\nwhich is stored as a value of the entry.\n10\n10 30\n10 15 30 40\n10 15 20 30 4010\n10 30\n10 15 30 40\n10 15 20 30 4020\nAdding the new entry to Data Level Adding the new entry to PDL\nAdding the new entry to COIL10\n10 30\n10 15 30 40\n10 15 20 30 40203010\n10 20\n10 15 30 40\n10 15 20 30 402030\nFigure 5. An illustration of ESL’s async update. The foreground thread inserts new data into the\ndata level 1; a background thread inserts the data to the PDL 2and the COIL 3.\n\nAppl. Sci. 2023 ,13, 9925 9 of 17\n10 30\n0 3\n0x10 0x40key\nnext_elem\nshortcut10 30\n0 3\n0x10 0x40310 30\n0 3\n0x10 0x403\n0x4010 30\n0 3\n0x10 0x4030\n3\n0x40\nkey\nnext_elem\nshortcut10 30\n0 3\n0x10 0x4030\n3\n0x4010 30\n0 2\n0x10 0x4030\n3\n0x4010 30\n0 2\n0x10 0x7030\n3\n0x4010 20\n0 2\n0x10 0x7030\n3\n0x40Copy the next_elem\n Copy the shortcut\n Copy the key\nWrite the next_elem\n Write the shortcut\n Write the key\nFigure 6. An illustration of the shift operation. ESL moves the next_elem, the shortcut, and the key\nin order.\n4.4. Non-Blocking Read\nESL’s read operation is composed of three phases: (1) Finding the parent node of\nthe target data node or its neighboring node from the COIL. (2) Finding the target data\nnode or its neighboring node from the PDL. (3) Finding the target data node from the data\nlevel. The read operation of ESL is trivial; however, there can be inconsistent states at each\nlevel because the background threads may update the index levels asynchronously. ESL\ntolerates these inconsistent states, as follows:\nTolerating Inconsistencies in the COIL. In the read operation, the reader traverses the\nindex levels. To accelerate the performance, ESL leverages an exponential search to skip\nthe unnecessary key comparison. When the exponential search reduces the traverse range,\nthe reader searches for the proper key using a linear search. In the search operation, the\nreader ﬁrst compares the key of the index level and then moves to the next data until the\nreader ﬁnds the same key as the given key. In this case, the reader moves to the data node\nat the data level directly. When the reader reaches the key larger than the given key, it\nmoves to the next index level.\nInESL ’s insert operation (see Section 4.2), within the COIL, keys, values, and shortcuts\nare shifted in the same direction as the read operation. The key is updated last, as shown\nin Figure 6. Hence, the reader will not encounter a key larger than the speciﬁed key. If a\nreader arrives at the node adjacent to the target node, they will traverse further to locate\nthe desired node.\nESL’s delete operation (Section 4.2) in the COIL does not shift the data in the index\nlevels. Instead, it logically deletes the key–value pair by setting the value to 0 or NULL.\nHence, there is no shift operation in the delete operation.\nTolerating Inconsistencies in the PDL/DL. The read operation at the data level or PDL is\nintuitive. Since the PDL and DL are lock-free linked lists, the linked list node, which is\nbeing created, is not visible to the reader until it is connected by the next pointer . Hence, the\nreader can ﬁnd a consistent state only.\nTolerating Inconsistencies between the COIL and the PDL/DL. Since the index levels\nand the PDL/DL are decoupled, the reader will reach another node, which is the neighbor\nof the target node. Similar to that of the COIL, the reader traverses the PDL or DL to ﬁnd\nthe target node.\n4.5. Concurrency Control\n4.5.1. Version-Based Locking Protocol for Updating the COIL\nIn the COIL, ESL leverages the version-based locking protocol to prevent the write/write\nconﬂict for updating the COIL. Since ESL allows, at most, one writer to increase the\n\nAppl. Sci. 2023 ,13, 9925 10 of 17\nversion value, when the version number is odd, other writers wait until the version number\nbecomes even. The version number is updated using atomic instructions. Note that the read\noperation in the COIL does not acquire the read lock as ESL employs the ROWEX protocol.\n4.5.2. Lock-Free Operation Log\nESL uses the lock-free operation log to hand over the work from the foreground thread\nto the background thread. Figure 7 illustrates how the operation log works with multiple\nthreads, guaranteeing atomicity using a CAS operation. The operation log features two\nvariables that store the index values: one for the head and the other for the tail of the\noperation log. The head is used for multiple threads. Before processing the operation log,\nthe background thread updates the head of the operation log atomically. The background\nthread can process only when the head is successfully updated. The foreground thread\nupdates the tail of the operation log atomically when it writes the operation log entry to\nthe operation log. The operation log entry consists of the operation, the key–value pair, the\npath, and the level. The path information includes the entries in the index level and the\nPDL that the writer visited.\nIns/k:20/Lev:2FG Thread 0\nFG Thread 1CAS\n(Success)\nCAS\n(Fail)BG ThreadCAS\n(Success) Ins/k:30/Lev:3\nFigure 7. An illustration of the operation log. A head is updated by the background threads and a\ntail is updated by the foreground threads.\n5. Implementation\nWe implement ESL using C++ and use the xorshift random number generator [43] to\ngenerate the level value of each node randomly.\n6. Evaluation\n6.1. Experimental Environment\nHardware. We performed experiments on a machine equipped with two NUMA sockets,\neach featuring an Intel Xeon Gold 5318Y processor with 24 physical cores. The machine\noffers a memory space of 768 GB DDR4 DRAM.\nWorkload. We used the YCSB workload [ 44], one of the representative workloads of\nkey–value stores, as well as the Amazon AWS OpenStreetMap workload [45] to represent\nreal-world scenarios for evaluating the performance of ESL.\nIn the YCSB evaluation, the YCSB workload consists of four workloads, workloads\nA–D . Workload A is composed of 50% of the update operations and 50% of the read\noperations. Workload B and workload D are composed of 5% of update operations and\n95% of read operations. Workload C is composed of 100% of the read workload. Note that\nwe did not include the results of the workload E evaluation, as the competitors did not\nimplement the scan operation.\nIn the real-world workloads, we used three datasets, denoted as longitudes ,longlat , and\nlognormal . The workloads are composed of the combinations of read and insert operations.\nWe conducted two types of workloads—the read-intensive workload and write-intensive\nworkload—similar to the previous study [ 34]. The read-intensive workload consists of 95%\nof read operations and 5% of insert operations. In the write-intensive workload, the ratio of\nthe read operations and the write operations is the same (i.e., 50% read operations and 50%\ninsert operations).\nIn each experiment, we inserted 1 million 8-byte keys and 8-byte values in the\nload phase. After inserting the key–value pairs, we conducted the evaluation with\n1 million operations. For the default settings of competitors, the maximum level value was\nlog2(number _o f_data )[46,47]. Similar to previous work [ 26,27,46], we used the default\n\nAppl. Sci. 2023 ,13, 9925 11 of 17\nmaximum level of 19 (i.e., log2(1Million )). We also evaluated the maximum level of 5. We\ndenoted the maximum level of 19 as the high level and the maximum level of 5 as the\nlow level.\nCompetitors We compared the performance of ESL against other skiplist data structures.\nWe included the No Hot Spot Skiplist (NHSSL) [ 26] and NUMASK [ 27]. We used the\npublicly available version of NHSSL and NUMASK in Synchrobench [ 46,47]. We could\nnot evaluate the Cache-Sensitive Skiplist (CSSL) [ 24] because the open-sourced version did\nnot consider the multi-thread and randomized key insertion. The implementation of the\nParallel in-memory Skiplist (PSL) [25] was not open-sourced as of writing this paper.\n6.2. Throughput\n6.2.1. High Level (Maximum Level 19)\nWe conducted the performance evaluation using the YCSB workload. In this experi-\nment, we set the maximum level value to 19 and used multiple threads, reaching up to 48.\nESL outperformed other skiplists by up to 2.8 \u0002for all YCSB workloads. This corroborates\nour design goal of reducing cache misses and guaranteeing scalable access in a lock-free\nmanner. Interestingly, in our evaluation, NHSSL demonstrated superior performance when\ncompared to NUMASK, as shown in Figure 8. We analyzed the elapsed time for the query\nin Section 6.4.\n10,00020,00030,00040,00050,00060,000\n0 16 32 4810,00020,00030,00040,00050,00060,000\n0 16 32 4810,00020,00030,00040,00050,00060,00070,000\n0 16 32 4810,00020,00030,00040,00050,00060,00070,00080,000\n0 16 32 48\nKOps/sec\n# threadsYCSB A\nNHSSL\n# threadsYCSB B\nESL\n# threadsYCSB C\nNUMASK\n# threadsYCSB D\nFigure 8. Performance comparison of the skiplists for the YCSB workload (level 19).\n6.2.2. Low Level (Maximum Level 5)\nWe evaluated the skiplists with a maximum level of 5. Figure 9 presents the skiplist\nperformances with a maximum level of 5. In the lower level, each skiplist level has more\ndata. In general, the index performances were degraded because they lost the opportunity\nto skip keys as the level was low. ESL shows a superior read performance due to the COIL\nwith an exponential search. Also, the lock-free linked list-based PDL and the data level\nreduced the synchronization overhead. The experimental results show that all workloads,\nincluding workloads A–D, had similar performance trends, as shown in Figure 9 .ESL\nshowed a performance enhancement of up to 19.9 \u0002, attributable to its cache-optimized\nCOIL, the lock-free linked list-based data level, and the PDL. When the number of threads\nincreased from 16 to 32, the performance improvement of ESL and NHSSL moderated\nbecause of the NUMA effect. Since the data number at each level increased, the NUMA\nremote latency had more of an impact on the ESL and NHSSL performances. NUMASK\nuses NUMA local index levels, resulting in fewer NUMA remote accesses compared to\nESL and NHSSL.\nAs the data levels of all the skiplists in the evaluation used a lock-free linked list, the\ncontention was not that high, even with the update workload. Also, the skiplist’s update\noperation in this paper only changed the pointer value in the data node, so it did not trigger\nthe SMO.\n\nAppl. Sci. 2023 ,13, 9925 12 of 17\n05001000150020002500300035004000\n0 16 32 4805001000150020002500300035004000\n0 16 32 4805001000150020002500300035004000\n0 16 32 4805001000150020002500300035004000\n0 16 32 48\nKOps/sec\n# threadsYCSB A\nNHSSL\n# threadsYCSB B\nESL\n# threadsYCSB C\nNUMASK\n# threadsYCSB D\nFigure 9. Performance comparison of the skiplists for the YCSB workload (level 5).\n6.3. Tail Latency\n6.3.1. High Level (Maximum Level 19)\nIn this experiment, we conﬁgured the skiplists to have a maximum level of 19 and\nused 48 threads, as shown in Figure 10. ESL has the lowest latency, both in terms of median\nand tail latency. The COIL of ESL efﬁciently reduces the traverse time and minimizes\nsynchronization overhead during traversal. ESL achieves up to 35 \u0002shorter latency than\nother skiplists in the YCSB workload. NHSSL and NUMASK leverage the lock-free linked\nlist-based level, so they do not have signiﬁcant synchronization overhead, but they suffer\nfrom performance degradation from the cache misses that are inherited from the linked list.\nNUMASK shows lower tail latency than NHSSL because of its index-level replication for\neach NUMA socket.\n0100200300400500600\n50 99 99.9 99.990100200300400500600\n50 99 99.9 99.990100200300400500600\n50 99 99.9 99.99020040060080010001200\n50 99 99.9 99.99\nLatency ( ms)\nPercentile (%)YCSB A\nNHSSL\nPercentile (%)YCSB B\nESL\nPercentile (%)YCSB C\nNUMASK\nPercentile (%)YCSB D\nFigure 10. Tail latency comparison (Level 19).\n6.3.2. Low Level (Maximum Level 5)\nFigure 11 shows the tail latency of a skiplist when the maximum level is 5 and the\nnumber of threads is 48. Since the level is lower than the previous experiment, the number\nof nodes in each level is increased. Hence, the tail latencies of indices are increased. NHSSL\nshows the highest latency because the number of linked list traverse operations increased.\nMoreover, NUMA remote accesses further contribute to the latency delay. NUMASK\nshows better tail latency as it reduces the number of NUMA remote accesses by replicating\nthe index levels. ESL shows short tail latency in our evaluation thanks to the COIL and\nlock-free linked list-based PDL and the data level.\n02004006008001000\n50 99 99.9 99.9902004006008001000\n50 99 99.9 99.9902004006008001000\n50 99 99.9 99.99020040060080010001200\n50 99 99.9 99.99\nLatency ( ms)\nPercentile (%)YCSB A\nNHSSL\nPercentile (%)YCSB B\nESL\nPercentile (%)YCSB C\nNUMASK\nPercentile (%)YCSB D\nFigure 11. Tail Latency comparison (Level 5).\n\nAppl. Sci. 2023 ,13, 9925 13 of 17\n6.4. Performance Breakdown\nWe analyzed the skiplist performances by measuring the elapsed time for each compo-\nnent in the skiplists. We conducted the YCSB workload using 48 threads in the experiment.\n6.4.1. High Level (Maximum Level 19)\nFigure 12a presents the elapsed time for each component in the skiplist. ESL and\nNHSSL spend the most time traversing index levels. The experimental results show that\nNUMASK uses more time traversing the data level than NHSSL. This causes performance\ndegradation, as described in Section 6.2. Note that traversing the PDL overhead in ESL\nis trivial because its lock-free linked list eliminates a lot of shift operations, which are\ninevitable in the array data structure. Also, the elapsed time for traversing the data level in\nESL is shorter than in the other skiplist.\n6.4.2. Low Level (Maximum Level 5)\nFigure 12b shows the performance breakdown of the skiplists when the maximum\nlevel is 5. For all skiplists, most of their time is spent traversing index levels as there are\nmore data than in the high-level (maximum-level 19) case. ESL reduces the traversing\nindex level time under NHSSL and NUMASK by 14.5 \u0002and 2.1 \u0002, respectively. In the\nlow-level case, the NUMA remote accesses have a signiﬁcant impact on the performance of\ntraversing the index levels. Index levels of NHSSL consist of linked lists, so the NUMA\nremote access latency is reﬂected due to the cache misses. NUMASK replicates the search\nlayer to each socket; it reduces the number of NUMA remote accesses, but it still suffers\nfrom the cache misses inherited from the linked list-based structure. The time for traversing\nthe PDL and the data level is much shorter than the time for traversing index levels. We\nalso include the elapsed time for traversing the PDL and the data level in Table 1.\n00.511.522.53\nN E U N E U N E U N E U050100150200250300350\nN E U N E U N E U N E U\ntime (us)(a) High Level (Maximum Level 19)\nIndex LevelData LevelPDL\nYCSB D YCSB C YCSB B YCSB A(b) Low Level (Maximum Level 5)\nIndex LevelData LevelPDL\nYCSB D YCSB C YCSB B YCSB A\nFigure 12. Performance breakdown for workloads A–D. In this experiment, N stands for NHSSL, E\nstands for ESL, U stands for NUMASK. Elapsed time for traversing the PDL and the data level is\nrelatively short at a low level, so we added a table for presenting the time, as shown in Table 1.\nTable 1. Elapsed time for traversing the PDL and the data level at a low level ( \u0016s). In this experiment,\nN stands for NHSSL; E stands for ESL; U stands for NUMASK.\nA B C D\nNPDL 0 0 0 0\nData level 0.25 0.28 0.26 0.21\nEPDL 0.17 0.16 0.16 0.14\nData level 0.25 0.21 0.21 0.17\nUPDL 0 0 0 0\nData level 0.42 0.41 0.40 0.30\n\nAppl. Sci. 2023 ,13, 9925 14 of 17\n6.5. Cache Miss\nWe measured the number of cache misses of the skiplists with YCSB workloads using\nperf [48]. We conducted tests on both low and high levels of the skiplists with 48 threads.\nAs shown in Figure 13, ESL shows fewer cache misses than other skiplists because the\nCOIL design is cache-friendly. ESL reduces the number of cache misses by up to 15.7 \u0002.\nAll skiplists show fewer cache misses in the YCSB workload D because workload D reads\nthe latest updated data. Interestingly, NUMASK shows more cache misses than NHSSL.\nThis is because NUMASK leverages multiple search layers, and each search layer is stored\non the corresponding NUMA memory. In this case, the search layer may not be in a\nconsistent state, and it may lead to more linked list traverses, which increase the number of\ncache misses.\n01020304050\nYCSB A YCSB B YCSB C YCSB D0102030405060\nYCSB A YCSB B YCSB C YCSB D\nNumber of Cache Misses ( \u0002106) (a) High Level (Maximum Level 19)\nNHSSL\nESL\nNUMASK\nNumber of Cache Misses ( \u0002106) (b) Low Level (Maximum Level 5)\nNHSSL\nESL\nNUMASK\nFigure 13. Number of cache misses of the skiplist with YCSB workloads.\n6.6. Real-World Workload\nWe conducted the throughput evaluation with the AWS OpenStreetMap real-world\nworkload, as mentioned in Section 6.1. We set the maximum level of skiplists to 19, as in the\nhigh level. The longitude dataset comprises 8-byte double-type data, representing longitude\nvalues. The longlat dataset is a set of 8-byte double keys. Each key is a combination of\nlongitude and latitude. The lognormal dataset is a set of 8-byte integer keys with a lognormal\ndistribution. We used 48 threads in this evaluation.\nAs shown in Figure 14, ESL exhibits lower throughput in both read-intensive and\nwrite-intensive workloads compared to YCSB workloads because the insert operation trig-\ngers an asynchronous update of the COIL, which may lead to dirty CPU cache lines. The\nCOIL consists of consecutive arrays, so making dirty cache lines can degrade the perfor-\nmance. Despite the performance degradation, ESL consistently shows better performance\nthan other skiplists. In the experiment with the read-intensive workload, ESL outperforms\nother skiplists because of its cache-friendly design. The ESL performance is degraded in\nthe write-intensive workload because of the asynchronous update of the COIL.\n01020304050\nlongitudes longlat lognormal0510152025303540\nlongitudes longlat lognormal\nThroughput (MOps)Throughput for Read Intensive Workload\nNHSSL\nESL\nNUMASK\nThroughput (MOps)Throughput for Write Intensive Workload\nNHSSL\nESL\nNUMASK\nFigure 14. Throughput of the skiplists with the real-world workload.\n7. Discussion\n7.1. Limitations of ESL\nLimitations of the asynchronous update. The COIL of the ESL shifts the key–value pairs\nto add a new one to each index level. Even though the ESL leverages asynchronous updates\nfor the COIL and the PDL, the overhead of the shift operation can be too high when the\n\nAppl. Sci. 2023 ,13, 9925 15 of 17\nnumber of key–value pairs is too large. In that case, ESL can add more background threads\nor exploit a more lock-free linked list to the upper level of the PDL. Also, the asynchronous\nupdate makes the cache line dirty, so the traverse overhead of concurrent threads can\nbe larger.\nCache misses when moving to the lower level. In the original skiplist, each node keeps\nthe pointers of all levels. Hence, moving to the next level does not incur the cache misses.\nHowever, ESL merges the key–value pairs in the same level, so each level is separated.\nThus, moving to the next level in ESL accompanies cache misses.\n7.2. Skiplist for Emerging Storage Media\nSince the skiplist is used as the key component of the storage system stack, there have\nbeen previous research efforts to improve the skiplists for emerging storage media, such\nas persistent memory. The atomic skiplist (AS) and atomic and selective consistency skiplist\n(ASCS) [ 49] are designed for persistent memory. They insert and delete an entry in order.\nHence, they can guarantee data consistency without logging. Also, ASCS ensures the\npersistence of the lowest index level and the data level to reduce the persistence overhead.\nThe partitioned hierarchical skiplist (PhaST) [50] is another skiplist designed for persistent\nmemory. PhaST also stores data nodes at the data level in persistent memory and index\nlevels in DRAM. Also, PhaST partitions the key range and uses another index cache\nto reduce the cache misses during skiplist traversal. NoveLSM [51] employs persistent\nskiplist-based MemTable to mitigate the serialization/deserialization overheads in the LSM\ntree-based key–value store. ListDB [52] merges the log of the key–value store with the\npersistent skiplist to reduce the redundant writes in the LSM-tree-based key–value store.\nThe previous studies focus on reducing persistence overhead; however, ESL mainly targets\nvolatile DRAM-based main memory systems. Also, ESL can be extended to the persistent\nversion by storing the data layer in persistent memory.\n8. Conclusions\nWe presented ESL , a high-performance skiplist. ESL uses arrays of nodes in the index\nlevel, denoted as the COIL , combined with exponential search to obtain high performance\nand scalability. In order to reduce the length of the critical section, ESL leverages asyn-\nchronous updates for updating the COIL. At the data level of ESL, we exploit a lock-free\nlinked list to reduce synchronization overhead. We introduced the PDL, the lowest index\nlevel of the COIL, which employs a lock-free linked list to signiﬁcantly minimize shift\noperations. In addition, we described how ESL’s foreground threads tolerate the incon-\nsistencies caused by background threads. In the performance evaluation, we compared\nthe performance of ESL against NHSSL andNUMASK . The evaluation results show that\nESL achieves up to 2.8 \u0002higher throughput than other in-memory skiplists in high-level\nevaluations. In the tail latency evaluation, ESL registers 35 \u0002lower tail latency compared\nto other skiplists.\nAuthor Contributions: Conceptualization, methodology, Y.N., B.K. and W.-H.K.; software, Y.N., B.K.\nand T.P .; validation, Y.N., T.P ., J.P . and W.-H.K.; writing—original draft preparation, Y.N. and W.-H.K.;\nwriting—review and editing, Y.N., J.P . and W.-H.K.; supervision, W.-H.K.; project administration,\nW.-H.K.; funding acquisition, W.-H.K. All authors have read and agreed to the published version of\nthe manuscript.\nFunding: This paper was supported by Konkuk University in 2022.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: The data used in the paper is available from the corresponding author\nupon request.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\n\nAppl. Sci. 2023 ,13, 9925 16 of 17\nReferences\n1. Wang, T.; Johnson, R. Scalable Logging Through Emerging Non-volatile Memory. In Proceedings of the 40th International\nConference on Very Large Data Bases (VLDB), Hangzhou, China, 1–5 September 2014.\n2. Arulraj, J.; Perron, M.; Pavlo, A. Write-behind Logging. In Proceedings of the 42nd International Conference on Very Large Data\nBases (VLDB), New Delhi, India, 5–9 September 2016.\n3. Oh, G.; Kim, S.; Lee, S.W.; Moon, B. SQLite Optimization with Phase Change Memory for Mobile Applications. In Proceedings\nof the 41st International Conference on Very Large Data Bases (VLDB), Kohala Coast, HI, USA, 31 August–4 September 2015;\npp. 1454–1465.\n4. Park, J.H.; Oh, G.; Lee, S.W. SQL Statement Logging for Making SQLite Truly Lite. In Proceedings of the 43rd International\nConference on Very Large Data Bases (VLDB), Munich, Germany, 28 August–1 September 2017; pp. 513–525.\n5. Seo, J.; Kim, W.H.; Baek, W.; Nam, B.; Noh, S.H. Failure-Atomic Slotted Paging for Persistent Memory. In Proceedings of the\n22nd ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),\nXi’an, China, 8–12 April 2017.\n6. Kim, W.H.; Kim, J.; Baek, W.; Nam, B.; Won, Y. NVWAL: Exploiting NVRAM in Write-Ahead Logging. In Proceedings of the\n21st ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),\nAtlanta, GA, USA, 2–6 April 2016.\n7. Volume of Data/Information Created, Captured, Copied, and Consumed Worldwide from 2010 to 2020, with Forecasts from 2021\nto 2025. Available online: https://www.statista.com/statistics/871513/worldwide-data-created/ (accessed on 28 August 2023).\n8. DRAM and NAND Flash Prices Expected to Fall Further in 2Q23 Due to Weak Server Shipments and High Inventory Levels, Says\nTrendForce. Available online: https://www.trendforce.com/presscenter/news/20230509-11667.html (accessed on 28 August 2023).\n9. Anandtech. Intel Launches Optane DIMMs Up To 512GB: Apache Pass Is Here! 2018. Available online: https://www.anandtech.\ncom/show/12828/intel-launches-optane-dimms-up-to-512gb-apache-pass-is-here (accessed on 6 June 2023).\n10. CXL Consortium. Compute Express Link: The Breakthrough CPU-to-Device Interconnect 2020. Available online: https://www.\ncomputeexpresslink.org/ (accessed on 1 July 2023).\n11. Kozyrakis, C.; Kansal, A.; Sankar, S.; Vaid, K. Server Engineering Insights for Large-Scale Online Services. IEEE Micro 2010 ,\n30, 8–19. [CrossRef]\n12. Spec CPU2016 Results. Available online: https://www.spec.org/cpu2006/results/ (accessed on 28 August 2023).\n13. Spec CPU2017 Results. Available online: https://www.spec.org/cpu2017/results/ (accessed on 28 August 2023).\n14. 50 Years of Microprocessor Trend Data. Available online: https://github.com/karlrupp/microprocessor-trend-data (accessed on\n28 August 2023).\n15. Lehman, P .L.; Yao, S.B. Efﬁcient Locking for Concurrent Operations on B-Trees. ACM Trans. Database Syst. 1981 ,6, 650–670.\n[CrossRef]\n16. Rao, J.; Ross, K.A. Making B+- Trees Cache Conscious in Main Memory. In Proceedings of the 2000 ACM SIGMOD/PODS\nConference, Dallas, TX, USA, 16–18 May 2000; pp. 475–486.\n17. Hwang, D.; Kim, W.H.; Won, Y.; Nam, B. Endurable Transient Inconsistency in Byte-addressable Persistent B+-tree. In Proceedings\nof the 16th USENIX Conference on File and Storage Technologies (FAST), Oakland, CA, USA, 12–15 February 2018; pp. 187–200.\n18. Liu, J.; Chen, S.; Wang, L. LB+-Trees: Optimizing Persistent Index Performance on 3DXPoint Memory. Proc. VLDB Endow. 2020 ,\n13, 1078–1090. [CrossRef]\n19. Pugh, W. Skip Lists: A Probabilistic Alternative to Balanced Trees. Commun. ACM 1990 ,33, 668–676. [CrossRef]\n20. Google. LevelDB. Available online: https://github.com/google/leveldb (accessed on 20 July 2023).\n21. Facebook. RocksDB. Available online: http://rocksdb.org/ (accessed on 20 July 2023).\n22. Apache. Welcome to Apache HBase™. Available online: https://hbase.apache.org/ (accessed on 20 July 2023).\n23. MongoDB. Available online: https://www.mongodb.org/ (accessed on 20 July 2023).\n24. Sprenger, S.; Zeuch, S.; Leser, U. Cache-Sensitive Skip List: Efﬁcient Range Queries on Modern CPUs. In Data Management on New\nHardware: 7th International Workshop on Accelerating Data Analysis and Data Management Systems Using Modern Processor and Storage\nArchitectures, ADMS 2016 and 4th International Workshop on In-Memory Data Management and Analytics, IMDM 2016, New Delhi,\nIndia, 1 September 2016, Revised Selected Papers 4 ; Blanas, S., Bordawekar, R., Lahiri, T., Levandoski, J.J., Pavlo, A., Eds.; Lecture\nNotes in Computer Science; Springer: Cham, Switzerland, 2016; Volume 10195, pp. 1–17. [CrossRef]\n25. Xie, Z.; Cai, Q.; Jagadish, H.; Ooi, B.C.; Wong, W.F. Parallelizing Skip Lists for In-Memory Multi-Core Database Systems. In\nProceedings of the 33rd IEEE International Conference on Data Engineering (ICDE), San Diego, CA, USA, 19–22 April 2017.\n[CrossRef]\n26. Crain, T.; Gramoli, V .; Raynal, M. No Hot Spot Non-blocking Skip List. In Proceedings of the 33rd International Conference on\nDistributed Computing Systems (ICDCS), Philadelphia, PA, USA, 8–11 July 2013; pp. 196–205.\n27. Daly, H.; Hassan, A.; Spear, M.F.; Palmieri, R. NUMASK: High Performance Scalable Skip List for NUMA. In Proceedings of the\n31st International Conference on Distributed Computing (DISC), New Orleans, LA, USA, 16–20 October 2017; pp. 18:1–18:19.\n28. Bentley, J.L.; Yao, A.C.C. An almost optimal algorithm for unbounded searching. Inf. Process. Lett. 1976 ,5, 82–87. [CrossRef]\n29. Kim, C.; Chhugani, J.; Satish, N.; Sedlar, E.; Nguyen, A.D.; Kaldewey, T.; Lee, V .W.; Brandt, S.A.; Dubey, P . FAST: Fast Architecture\nSensitive Tree Search on Modern CPUs and GPUs. In Proceedings of the 2010 ACM SIGMOD International Conference on\nManagement of Data, New York, NY, USA, 6–10 June 2010; SIGMOD’10, pp. 339–350. [CrossRef]\n\nAppl. Sci. 2023 ,13, 9925 17 of 17\n30. Cha, H.; Hao, X.; Wang, T.; Zhang, H.; Akella, A.; Yu, X. Blink-hash: An Adaptive Hybrid Index for In-Memory Time-Series\nDatabases. Proc. VLDB Endow. 2023 ,16, 1235–1248. [CrossRef]\n31. Choe, J.; Crotty, A.; Moreshet, T.; Herlihy, M.; Bahar, R.I. Hybrids: Cache-conscious concurrent data structures for near-\nmemory processing architectures. In Proceedings of the 34th ACM Symposium on Parallelism in Algorithms and Architectures,\nPhiladelphia, PA, USA, 11–14 July 2022; pp. 321–332.\n32. Kang, H.; Zhao, Y.; Blelloch, G.E.; Dhulipala, L.; Gu, Y.; McGuffey, C.; Gibbons, P .B. PIM-tree: A Skew-resistant Index for\nProcessing-in-Memory. In Proceedings of the 2023 ACM Workshop on Highlights of Parallel Computing, New York, NY, USA,\n16 June 2023; pp. 13–14.\n33. Kraska, T.; Beutel, A.; Chi, E.H.; Dean, J.; Polyzotis, N. The Case for Learned Index Structures. In Proceedings of the 2018\nInternational Conference on Management of Data, New York, NY, USA, 22–27 June 2018; SIGMOD’18, pp. 489–504. [CrossRef]\n34. Ding, J.; Minhas, U.F.; Yu, J.; Wang, C.; Do, J.; Li, Y.; Zhang, H.; Chandramouli, B.; Gehrke, J.; Kossmann, D.; et al. ALEX: An\nUpdatable Adaptive Learned Index. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of\nData, New York, NY, USA, 14–19 June 2020; SIGMOD’20, pp. 969–984. [CrossRef]\n35. Zhang, Z.; Chu, Z.; Jin, P .; Luo, Y.; Xie, X.; Wan, S.; Luo, Y.; Wu, X.; Zou, P .; Zheng, C.; et al. PLIN: A Persistent Learned Index for\nNon-Volatile Memory with High Performance and Instant Recovery. Proc. VLDB Endow. 2022 ,16, 243–255. [CrossRef]\n36. Li, P .; Hua, Y.; Zuo, P .; Chen, Z.; Sheng, J. ROLEX: A Scalable RDMA-oriented Learned Key-Value Store for Disaggregated\nMemory Systems. In Proceedings of the 21st USENIX Conference on File and Storage Technologies (FAST 23), Santa Clara, CA,\nUSA, 21–23 February 2023; pp. 99–114.\n37. Mathew, A.; Min, C. HydraList: A Scalable In-Memory Index Using Asynchronous Updates and Partial Replication. In\nProceedings of the 46th International Conference on Very Large Data Bases (VLDB), Tokyo, Japan, 31 August–4 September 2020.\n38. Kim, W.H.; Krishnan, R.M.; Fu, X.; Kashyap, S.; Min, C. PACTree: A High Performance Persistent Range Index Using PAC\nGuidelines. In Proceedings of the 28th ACM Symposium on Operating Systems Principles (SOSP), Virtual, 26–29 October 2021;\npp. 424–439.\n39. Leis, V .; Scheibner, F.; Kemper, A.; Neumann, T. The ART of Practical Synchronization. In Proceedings of the International\nWorkshop on Data Management on New Hardware, San Francisco, CA, USA, 27 June 2016; pp. 3:1–3:8.\n40. Chen, Y.; Lu, Y.; Fang, K.; Wang, Q.; Shu, J. UTree: A Persistent B+-Tree with Low Tail Latency. Proc. VLDB Endow. 2020 ,\n13, 2634–2648. [CrossRef]\n41. Hart, T.E.; McKenney, P .E.; Brown, A.D.; Walpole, J. Performance of Memory Reclamation for Lockless Synchronization. J. Parallel\nDistrib. Comput. 2007 ,67, 1270–1285. [CrossRef]\n42. McKenney, P .E. Structured Deferral: Synchronization via Procrastination. ACM Queue 1998 ,20, 20–39. [CrossRef]\n43. Marsaglia, G. Xorshift RNGs. J. Stat. Softw. 2003 ,8, 1–6. [CrossRef]\n44. Cooper, B.F.; Silberstein, A.; Tam, E.; Ramakrishnan, R.; Sears, R. Benchmarking Cloud Serving Systems with YCSB. In\nProceedings of the 1st ACM Symposium on Cloud Computing (SoCC), Indianapolis, IN, USA, 10–11 June 2010; pp. 143–154.\n45. Amazon AWS OpenStreetMap. Available online: https://registry.opendata.aws/osm/ (accessed on 23 August 2023).\n46. Gramoli, V . More Than You Ever Wanted to Know About Synchronization: Synchrobench, Measuring the Impact of the\nSynchronization on Concurrent Algorithms. In Proceedings of the 20th ACM Symposium on Principles and Practice of Parallel\nProgramming (PPoPP), San Francisco, CA, USA, 7–11 February 2015; pp. 1–10.\n47. Synchrobench. Available online: https://github.com/gramoli/synchrobench (accessed on 1 July 2023).\n48. Linux Perf Wiki. Available online: https://perf.wiki.kernel.org/index.php/Main_Page (accessed on 23 August 2023).\n49. Xiao, R.; Feng, D.; Hu, Y.; Wang, F.; Wei, X.; Zou, X.; Lei, M. Write-Optimized and Consistent Skiplists for Non-Volatile Memory.\nIEEE Access 2021 ,9, 69850–69859. [CrossRef]\n50. Li, Z.; Jiao, B.; He, S.; Yu, W. PhaST: Hierarchical Concurrent Log-Free Skip List for Persistent Memory. IEEE Trans. Parallel Distrib.\nSyst. 2022 ,33, 3929–3941. [CrossRef]\n51. Kannan, S.; Bhat, N.; Gavrilovska, A.; Arpaci-Dusseau, A.; Arpaci-Dusseau, R. Redesigning LSMs for Nonvolatile Memory with\nNoveLSM. In Proceedings of the 2018 USENIX Annual Technical Conference (ATC), Boston, MA, USA, 11–13 July 2018.\n52. Kim, W.; Park, C.; Kim, D.; Park, H.; ri Choi, Y.; Sussman, A.; Nam, B. ListDB: Union of Write-Ahead Logs and Persistent SkipLists\nfor Incremental Checkpointing on Persistent Memory. In Proceedings of the 16th USENIX Symposium on Operating Systems\nDesign and Implementation (OSDI 22), Carlsbad, CA, USA, 11–13 July 2022; pp. 161–177.\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.",
  "textLength": 60798
}