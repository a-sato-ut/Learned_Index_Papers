{
  "paperId": "2b216fc05f5eab65d1c33e00c1d7819a00a5f8f2",
  "title": "ChainedFilter: Combining Membership Filters by Chain Rule",
  "pdfPath": "2b216fc05f5eab65d1c33e00c1d7819a00a5f8f2.pdf",
  "text": "ChainedFilter: Combining Membership Filters by Chain Rule\nHaoyu Li\nUT Austin\nPeking UniversityLiuhui Wang\nUniversity of PennsylvaniaQizhi Chen\nPeking UniversityJianan Ji\nPeking University\nYuhan Wu\nPeking UniversityYikai Zhao\nPeking UniversityTong Yangâˆ—\nPeking UniversityAditya Akellaâˆ—\nUT Austin\nABSTRACT\nMembership (membership query/membership testing) is a funda-\nmental problem across databases, networks and security. However,\nprevious research has primarily focused on either approximate\nsolutions, such as Bloom Filters, or exact methods, like perfect\nhashing and dictionaries, without attempting to develop a an inte-\ngral theory. In this paper, we propose a unified and complete theory,\nnamely chain rule, for general membership problems, which en-\ncompasses both approximate and exact membership as extreme\ncases. Building upon the chain rule, we introduce a straightfor-\nward yet versatile algorithm framework, namely ChainedFilter, to\ncombine different elementary filters without losing information.\nOur evaluation results demonstrate that ChainedFilter performs\nwell in many applications: (1) it requires only 26% additional space\nover the theoretical lower bound for implicit static dictionary, (2)\nit requires only 0.22 additional bit per item over the theoretical\nlower bound for lossless data compression, (3) it reduces up to 31%\nexternal memory access than raw Cuckoo Hashing, (4) it reduces\nup to 36% P99 tail point query latency than Bloom Filter under the\nsame space cost in RocksDB database, and (5) it reduces up to 99.1%\nfilter space than original Learned Bloom Filter.\n1 INTRODUCTION\nMembership has been a fundamental problem for over fifty years,\nplaying a significant role in databases [ 1], networks [ 2] and security\n[3]. For instance, LSM-Tree based storage engines employ Bloom\nFilter [ 4â€“6] to accelerate K-V stores; Routers and switches leverage\nBloom Filter to classify, forward, and drop network packets [ 7â€“9];\nBitcoin miners use Invertable Bloom Lookup Tables (IBLT) to reduce\nthe amount of information for block propagation and reconciliation\n[10â€“12].\nGiven a universeUand a subsetSofğ‘›items, membership\naims to determine whether an item ğ‘¥âˆˆU is inS. Specially, a mem-\nbership algorithm must say â€œyesâ€ if ğ‘¥is inSand may produce a\nsmall false positive rate ğœ–ifğ‘¥is not inS. In this paper, we further\ndefine negative-positive ratio ğœ†:=|U\\S|/|S|1and divide mem-\nbership problems into three categories ( Figure 1 ):approximate\nmembership , whereğœ–â‰ 0andğœ†â†’+âˆ ;exact membership ,\nwhereğœ–=0andğœ†<+âˆ; and general membership , whereğœ–â‰ 0\nandğœ†<+âˆ. According to our taxonomy, both approximate and the\nexact memberships are the extreme cases of general membership.\nBut in history, the membership problems were not classified in this\nmanner. In 1978, [ 13] proposed separate space lower bounds for\napproximate and exact memberships. Since the two expressions\nâˆ—Co-corresponding authors.\n1The number of items not in Sdivide the number of items in S.have significantly different forms, in the following decades, people\nregarded the approximate and the exact memberships as two sepa-\nrate research directions, but never tried to unify them to develop an\nintegral theory for general membership problems, until this work.\nxconstruction begin\ninput ğ’®ğ’®andğ’°ğ’°\\ğ’®ğ’®\nconstruct stage 1 ( â„±1)\nquery stage 1\nconstruct stage 2 ( â„±2)\noutputâ„±=â„±1&â„±2\nendğ’®ğ’®andğ’®ğ’®â€™(ğ’®ğ’®â€™:false positive items)input item ğ‘’ğ‘’\nâ„±1&â„±2ğ‘’ğ‘’=1?\noutput false\nendyes\noutput truenopositive and negative items\nquery beginx\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±=â„±0\nelementary filtersâ‘ \nâ‘¡\nâ‘¢\nâ‘ â‘¡â‘¢\nstep num .insert\nquerypositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\nğœ†ğœ†=âˆğœ–ğœ–â‰ 0membership\nğœ–ğœ–=0\nğœ†ğœ†<âˆ ğœ†ğœ†<âˆ\napproximate\nmembershipgeneral\nmembershipexact\nmembershipextreme\ncaseextreme\ncase\n(ğœ†ğœ†â†’âˆ) (ğœ–ğœ–â†’0)\nFigure 1: Our taxonomy.\nBuild on [ 13],we develop a unified space lower bound ğ‘›ğ‘“(ğœ–,ğœ†)\nfor general membership problems, which encompasses the\nprior theoretical results as extreme cases . Given a false posi-\ntive rateğœ–and a negative-positive ratio ğœ†, we have the following\nexpression (where ğ»(Â·)denotes Shannonâ€™s entropy, ignore ğ‘œ(1)\nterms):\nï£±ï£´ï£´ï£´ï£´ ï£²\nï£´ï£´ï£´ï£´ï£³ğ‘“(ğœ–,ğœ†)=ğ‘“\u0000ğœ–â€²,ğœ†\u0001\n|   {z   }\nFirst stage+ğ‘“\u0000ğœ–/ğœ–â€²,ğœ–â€²ğœ†\u0001\n|         {z         }\nSecond stage,âˆ€ğœ–â€²âˆˆ[ğœ–,1](Chain rule) ;\nğ‘“(0,ğœ†)=(ğœ†+1)ğ»\u0010\n1\nğœ†+1\u0011\n(Exact membership bound [13]) .\nCertainly, we can derive the arithmetic representation of ğ‘“by\nsettingğœ–inchain rule to zero2. However, we choose to retain the\nrecursive formula because it offers valuable insights: According\nto the chain rule, any membership problem can be losslessly\nfactorized into two (or multiple) stages. The first stage involves\na coarse membership algorithm that may yield some false positive\nitems, while the second stage employs an accurate membership\nalgorithm to efficiently handle the remaining small percentage of\nfalse positive items, especially when the negative-positive ratio is\nvery large. The chain rule reveals a non-trivial observation that the\nfactorization process incurs zero information loss. This observation\nserves as inspiration for algorithm design and provides a solid\ntheoretical foundation for future research in the field of membership\nproblems.\n2ğ‘“(ğœ–,ğœ†)=ğ‘›(ğœ†+1)ğ»\u00001\nğœ†+1\u0001âˆ’ğ‘›(ğœ–ğœ†+1)ğ»\u00001\nğœ–ğœ†+1\u0001.\n1arXiv:2308.13632v1  [cs.DB]  25 Aug 2023\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\nMeanwhile, we acknowledge that the chain rule has certain limi-\ntations. First, it does not fully support dynamic memberships since\nit necessitates the identification of all false positive items before\nconstructing the second stage. Moreover, we discover that the loss-\nless property no longer holds for dynamic memberships ( Section\n4.3.1 ). Second, our chain rule theory is based on the assumption\nthat all positive items are randomly selected from the universe,\nwhich may not perfectly accommodate real-world scenarios where\nitem keys follow specific data distributions ( Section 5.5 ).\nâ€¢Paper Organization and Key Contributions.\n(A, Â§2) We propose a space lower bound for general membership\nproblems and derive an elegant factorization theorem called chain\nrule. This theorem allows us to divide any membership problem\ninto sub-problems without losing information.\n(B, Â§4) Building upon the chain rule, we introduce the versatile\nChainedFilter framework, which enables the combination of multi-\nstage membership algorithms, such as Bloomier Filters, to construct\nmore efficient algorithms. The framework is compatible with as-\nsorted elementary filters, supports different combining operators\n(e.g. ANDandNAND ), and can handle certain dynamic scenarios.\n(C, Â§5) We evaluate the performance of ChainedFilter in data\ncompressing, classifying and filtering applications. Experimental\nresults show that although our utilization of chain rule in this\npaper is simple and rudimentary, the ChainedFilter can significantly\noutperform existing works: (1) it requires only 26% additional space\nover the theoretical lower bound for implicit static dictionary, (2)\nit requires only 0.22 additional bit per item over the theoretical\nlower bound for lossless data compression, (3) it reduces up to\n31% external memory access than raw Cuckoo Hashing [ 14], (4) it\nreduces up to 36% P99tail point query latency than Bloom Filter\nunder the same space cost in RocksDB database [ 15], and (5) it\nreduces up to 99.1% filter space than original Learned Bloom Filter\n[16â€“19]. We release our open source code on GitHub [20].\nChain rule|        {z        }\n(A, Â§2) Theorydesignâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ ChainedFilter|             {z             }\n(B, Â§4) Algorithmdeployâˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’ Applications\n|            {z            }\n(C, Â§5) Implementation\n2 CHAIN RULE THEORY\n2.1 Definition and Notations\nGiven a universeUand arbitrary subset SâŠ‚U , where|U|and\n|S|are known, the membership problem is to determine whether a\nqueried item ğ‘¥âˆˆU is inS.\nIn this paper, we call a membership algorithm as a filter . This\ndefinition is broader than what people commonly use3. A filter is an\nindicator function F(Â·) :Uâ†¦â†’{ 0,1}with one-sided error, which\nmeansâˆ€ğ‘¥âˆˆS (positive item),F(ğ‘¥)=1has zero false negative;\nforğ‘¥âˆˆ U\\S (negative item), we allow a small false positive\nrateğœ–âˆˆ[0,1]s.t.F(ğ‘¥)=1. Moreover, we define ğœ†:=|U\\S|/|S|\nas the negative-positive ratio , and we denote the membership\nproblem as(ğœ–,ğœ†). This definition encompasses both approximate\n(ğœ–â‰ 0andğœ†â†’+âˆ ) and exact ( ğœ–=0andğœ†<+âˆ) membership\nproblems as extreme cases. Unless specified otherwise, we assume\nthat a filter is designed to handle static membership problems. If a\nmembership filter also supports dynamic insertions of new items,\n3E.g., in prior arts, people often call an exact membership algorithm as a â€œdictionaryâ€.Symbol Description\nU Universe (positive and negative items)\nS The set of positive items\nğ’® The set of all possible sets of positive items ( S)\nğ‘› The number of positive items ( |S|)\nğœ– False positive rate\nğœ† Negative-positive ratio ( |U\\S|/|S| )\nğ‘¥ An item\nğ¶ Any constant greater than 1\nğ‘€ The number of buckets in one hash table\nğ‘Ÿ|U|/( 2ğ‘€)\nğ‘ The number of SSTables in one level of LSM-Tree\nğœ A mapping from ğ’®toâ„±\nXFÃ\nSâˆˆğœâˆ’1(F)S\nF(Â·) A specific filter\nâ„± The set of all possible filters ( F)\nğ‘›ğ‘“(Â·,Â·) Space lower bound for membership problems\nğ‘›ğ‘“F(Â·,Â·) Space cost of the membership filter F(Â·)\nğ»(Â·) Shannonâ€™s entropy\nâ„ğ›¼(Â·)ğ›¼-bit hash value of an item\nğ‘“ğ›¼(Â·)ğ›¼-bit fingerprint of an item\nğ‘‡[Â·] Hash table\nBF/CF/EF Bloomier Filter, ChainedFilter, elementary filter\nTable 1: Commonly used symbols.\nwe explicitly refer to it as a \"dynamic filter.\" For quick reference, We\nlist all commonly used symbols in Table 14. We will define some\nof these symbols in later sections.\n2.2 Space Lower Bound\nIn this part, we present a unified and complete space lower bound\nfor general membership problems.\nTheorem 2.1. (Space Lower Bound ) Ignoreğ‘œ(ğ‘›)terms. Letğ‘›ğ‘“(ğœ–,ğœ†)\n:=ğ‘›inf\nFF(ğœ–,ğœ†)be the space lower bound for general membership\nproblem(ğœ–,ğœ†), we have\nğ‘“(ğœ–,ğœ†)=(ğœ†+1)ğ»\u00121\nğœ†+1\u0013\nâˆ’(ğœ–ğœ†+1)ğ»\u00121\nğœ–ğœ†+1\u0013\n,\nwhereğ»(ğ‘):=âˆ’ğ‘logğ‘âˆ’(1âˆ’ğ‘)log(1âˆ’ğ‘)is Shannonâ€™s entropy .\nProof. The key idea of this proof follows the technique of [ 13],\nexcept we take both ğœ–andğœ†into account. Given a membership\nproblem (ğœ–,ğœ†), we analysis all possible mappings from input sets\nto all possible filters, and use information theory to derive a lower\nbound of the space cost.\nGiven the universe Uand the negative-positive ratio ğœ†, we start\nby defining the set ğ’®:={SâŠ‚U :|S|=ğ‘›}as the set of all possible\nsets of positive items, and â„±as the set of all filter instances. Given\nanySâˆˆğ’®, we draw a filter instance Fâˆˆâ„±which has zero false\nnegative. We denote this drawing method as a mapping ğ‘“:ğ’®â†¦â†’â„±.\nNote that more than one set in ğ’®may map to a same filter F, so the\ninverse mapping ğœâˆ’1(F)âŠ‚ğ’®may have more than one element.\n4Elementary filter (the last row of Table 1 ): When we combine several sub-filters to\nform a larger one, each sub-filter is called an elementary filter.\n2\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\nActually, we have\nâˆ‘ï¸\nFâˆˆâ„±|ğœâˆ’1(F)|=|ğ’®|=\u0012|U|\n|U\\S|\u0013\nand|â„±|â©½2ğ‘›ğ‘“(ğœ–,ğœ†).\nSince the filterFhas zero false negative, so for every ğ‘¥âˆˆXF:=Ã\nSâˆˆğœâˆ’1(F)S, we haveF(ğ‘¥)=1(Figure 2 ).\nF (possible) ğœğœ S\nexample â‘ :|F| =1\nÏµ=(2 + 2 + 2 + 2 + 2 + 2) / 24\nexample â‘¡:|F| =2\nÏµ=(1 + 1 + 2 + 1 + 2 + 2) / 24\nexample â‘¢:|F| =3\nÏµ=(1 + 1 + 0 + 1 + 1 + 1) / 24Examples :\nx\nFigure 2: Some examples when U={1,2,3,4}and|S|=2\n(i.e.ğ’®={{1,2},{1,3},{1,4},{2,3},{2,4},{3,4}}). All connec-\ntions are possible (but maybe not unique) mappings. The\nmapping should ensure that the filter has a zero false\nnegative rate. For instance, in example 2, ğœmaps the in-\nput positive setS={1,2}(the first row on the left) to\nthe first green filter Fs.t.XF={1,2,3}. In other words,\nF(1)=1,F(2)=1,F(3)=1(false positive), and F(4)=0.\nThe next two formulae are the critical observations in our proof:\nOn the one hand, since the elements in ğœâˆ’1(F)are different from\neach other, we have\n\u0012|XF|\n|S|\u0013\nâ©¾|ğœâˆ’1(F)| ;\nOn the other hand, for a specific Sâˆˆğœâˆ’1(F) and for allğ‘¥âˆˆU,\nF(ğ‘¥)=1incurs false positive iff ğ‘¥âˆˆğ‘‹F\\S. Therefore, the overall\nfalse positive rate is\nğœ–=Ã\nFâˆˆâ„±|ğœâˆ’1(F)||XF\\S|\n|U\\S|\nÃ\nFâˆˆâ„±|ğœâˆ’1(F)|.\nNow letğœƒ>0, our main idea of the following proof is to divide\nâ„±into two parts â„±1:={Fâˆˆâ„±:|ğ‘‹F\\S|â©¾ğœƒğ‘›}andâ„±2:=â„±\\â„±1,\nthen bound their false positive rate respectively.\nConsider the monotonically increasing function ğ‘”(ğ‘):=exp{ğ‘›((ğ‘+\n1)ln(ğ‘+1)âˆ’ğ‘lnğ‘)}(ğ‘>0). To start with, we prove âˆ€ğœ€âˆˆ(0,1),âˆƒğ‘0>\n0,ğ‘ .ğ‘¡.âˆ€F âˆˆâ„±1,whenğ‘›>ğ‘0,ğœ€ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›is uniformly less\nthan|ğ‘‹F\\S|.Initially, given ğœ€<ğœ€â€²<1, we can select ğ‘1=(ğœ€â€²âˆ’\nğœ€)âˆ’1s.t. whenğ‘›>ğ‘1,we haveğœ€ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›<ğœ€â€²ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›\nâˆ’1<âŒŠğœ€â€²ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›âŒ‹.Next, according to Stirlingâ€™s formula\nlimğ‘›â†’+âˆğ‘›!âˆš\n2ğœ‹ğ‘›\u0010ğ‘’\nğ‘›\u0011ğ‘›\n=1,\nwe can select ğ‘0>ğ‘1which only relies on ğœ€andğœƒ, s.t.âˆ€ğ‘›>ğ‘0,\u0000âŒŠğœ€â€²ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›âŒ‹+|S|\n|S|\u0001<2ğ‘”(ğœ€â€²ğ‘”âˆ’1(|ğœâˆ’1(F)|)) <ğ‘”(ğ‘”âˆ’1(|ğœâˆ’1(F)|))\n=|ğœâˆ’1(F)|â©½\u0000|XF|\n|S|\u0001â‡’ğœ€ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›<âŒŠğœ€â€²ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›âŒ‹<\n|ğ‘‹F\\S|holds for allFâˆˆâ„±1.Similarly, when ğ‘›â†’+âˆ,we have|ğœâˆ’1(F)| <ğ‘”(2ğœƒ)for all\nFâˆˆâ„±2. Thereforeâˆ‘ï¸\nFâˆˆâ„±1|ğœâˆ’1(F)|â©¾|ğ’®|âˆ’ğ‘”(2ğœƒ)|â„±|.\nTo take a step further, consider â„(ğ‘):=ğ‘ğ‘”âˆ’1(ğ‘):=ğ‘¥ğ‘.Because\ndâ„(ğ‘)\ndğ‘=ğ‘¦+ğ‘/\u0012dğ‘”âˆ’1(ğ‘¦)\ndğ‘¦\u0013\n=ğ‘¦+1\nğ‘›ln(ğ‘¦+1)âˆ’ğ‘›lnğ‘¦\nincreases as ğ‘¦increases (so as ğ‘=ğ‘”âˆ’1(ğ‘¦)increases), we find â„\nconvex. According to Jensenâ€™s inequality, we have\nğœ–â©¾Ã\nFâˆˆâ„±1|ğœâˆ’1(F)||XF\\S|\n|U\\S|\nÃ\nFâˆˆâ„±|ğœâˆ’1(F)|â©¾Ã\nFâˆˆâ„±1|ğœâˆ’1(F)|ğœ€ğ‘”âˆ’1(|ğœâˆ’1(F)|)ğ‘›\n|ğ’®|ğœ†ğ‘›\nâ©¾ğœ€\n|ğ’®|ğœ†Â©Â­\nÂ«âˆ‘ï¸\nFâˆˆâ„±1|ğœâˆ’1(F)|ÂªÂ®\nÂ¬ğ‘”âˆ’1Â©Â­Â­\nÂ«Ã\nFâˆˆâ„±1|ğœâˆ’1(F)|\n|â„±1|ÂªÂ®Â®\nÂ¬\nâ©¾ğœ€\nğœ†\u0012\n1âˆ’ğ‘”(2ğœƒ)|â„±|\n|ğ’®|\u0013\nğ‘”âˆ’1\u0012|ğ’®|\n|â„±|âˆ’ğ‘”(2ğœƒ)\u0013\n.\nLetğœ€â†’1,ğœƒâ†’0and ignoreğ‘œ(ğ‘›), we have\nğœ–ğœ†â©¾ğ‘”âˆ’1\u0012|ğ’®|\n|â„±|\u0013\nâ‡’ğ‘”(ğœ–ğœ†)â©¾|ğ’®|\n|â„±|â©¾ğ‘”(ğœ†)\n2ğ‘›ğ‘“(ğœ–,ğœ†).\nTherefore\nğ‘“(ğœ–,ğœ†)â©¾1\nğ‘›logğ‘”(ğœ†)\nğ‘”(ğœ–ğœ†)=log \n(ğœ†+1)ğœ†+1\nğœ†ğœ†!\nâˆ’log \n(ğœ–ğœ†+1)ğœ–ğœ†+1\n(ğœ–ğœ†)ğœ–ğœ†!\n.\nItâ€™s easy to verify that ğ‘“(ğœ–,ğœ†)â©½1+ğ‘œ(1)\nğ‘›(logğ‘”(ğœ†)âˆ’logğ‘”(ğœ–ğœ†))(con-\nsider the example\u0000|XF|\n|S|\u0001=(|ğ’®|/|â„±|)(1+ğ‘œ(1))). So\nğ‘“(ğœ–,ğœ†)=(ğœ†+1)ğ»\u00121\nğœ†+1\u0013\nâˆ’(ğœ–ğœ†+1)ğ»\u00121\nğœ–ğœ†+1\u0013\nis the space lower bound. â–¡\nRemark. Theorem 2.1 connects the approximate and the exact\nmembership query problems. When ğœ–â‰ 0andğœ†â†’+âˆ ,ğ‘“(ğœ–,+âˆ)=\nlog1/ğœ–degenerates to the space lower bound of approximate mem-\nberships. When ğœ–=0andğœ†<+âˆ,ğ‘“(0,ğœ†)=(ğœ†+1)ğ»(1/(ğœ†+1))\ndegenerates to the space lower bound of exact memberships [13].\n2.3 Chain Rule\nIn this part, we delve deeper and derive our chain rule theory,\nwhich is arithmetically equivalent to the space lower bound but\nprovides insights into the essence of membership problems. As a\npreliminary, please note that in our context, the term â€œmembership\nproblemâ€ is different from the term â€œmembership filterâ€. When\nreferring to an abstract â€œproblemâ€, we focus on the theoretical\nspace lower bound. While when discussing a specific â€œfilterâ€, we\nfocus on a practical algorithm that may not be space-optimal.\nTo begin, letâ€™s consider encoding ğ‘›positive items and ğœ†ğ‘›negative\nitems with a false positive rate of ğœ–1ğœ–2. Intuitively, we can factorize\nthe problem into two stages: first, encoding all positive items and the\nğœ†ğ‘›negative items with a false positive rate of ğœ–1, and then encoding\nthe positive items and the remaining ğœ†ğœ–1ğ‘›false positive items with\n3\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\na false positive rate of ğœ–2. It is evident that if we solve the two sub-\nproblems, we can address the primary problem. Hence, the two sub-\nproblems should not be easier than the primary problem. However,\nsince the positive items are encoded twice in separate stages, it\nmay seem that the two-stage factorization incurs additional space\noverhead, and we might need to make careful trade-offs to avoid\naccumulating inherent space costs caused by the factorization.\nSurprisingly, Theorem 2.1 reveals that all our concerns and\nworries are unnecessary. Because\nğ‘“(ğœ–1ğœ–2,ğœ†)=(ğœ†+1)ğ»\u00121\nğœ†+1\u0013\nâˆ’(ğœ–1ğœ–2ğœ†+1)ğ»\u00121\nğœ–1ğœ–2ğœ†+1\u0013\n=\u0012\n(ğœ†+1)ğ»\u00121\nğœ†+1\u0013\nâˆ’(ğœ–1ğœ†+1)ğ»\u00121\nğœ–1ğœ†+1\u0013\u0013\n+\u0012\n(ğœ–1ğœ†+1)ğ»\u00121\nğœ–1ğœ†+1\u0013\nâˆ’(ğœ–1ğœ–2ğœ†+1)ğ»\u00121\nğœ–1ğœ–2ğœ†+1\u0013\u0013\n=ğ‘“(ğœ–1,ğœ†)+ğ‘“(ğœ–2,ğœ–1ğœ†),\nwe find the factorization is completely lossless (ignoring ğ‘œ(1)\nterms), which means we can arbitrarily decompose any membership\nproblem into an arbitrary number of sub-problems without incur-\nring any additional space cost. In other words, if all the elementary\nfilters used in the combination are space-optimal, the resulting com-\nbined membership filter will also be space-optimal5. Instead, when\nwe combine imperfect membership filters to solve a membership\nproblem, the only source of space overhead stems from that the\nfilters cannot optimally solve the sub-problems. The factorization\nprocess itself does not introduce any additional space overhead. In\nlater chapters, we will use Bloomier Filters as a straightforward\nexample to show how to appropriately factorize a membership\nproblem into sub-problems and enhance overall performance. But\nbefore that, let us rewrite the expressions as ğœ–=ğœ–1ğœ–2andğœ–â€²=ğœ–1,\nand present the conclusion in a recursive form:\nTheorem 2.2. (Chain Rule Theory )\n(\nğ‘“(ğœ–,ğœ†)=ğ‘“(ğœ–â€²,ğœ†)+ğ‘“(ğœ–/ğœ–â€²,ğœ–â€²ğœ†),âˆ€ğœ–â€²âˆˆ[ğœ–,1];\nğ‘“(0,ğœ†)=(ğœ†+1)ğ»\u0010\n1\nğœ†+1\u0011\n.\nItâ€™s easy to verify that the above equation set is equivalent to the\nspace lower bound in Theorem 2.1 (you can check it by setting\nğœ–=0), but this form is more elegant and may provide more insights.\n3 BLOOMIER FILTER\nIn this section, we present two variants derived from the Bloomier\nFilter [ 21,22], which belong to approximate and exact membership\nalgorithms, respectively6. InSection 4 , we combine these elemen-\ntary filters by chain rule to construct ChainedFilter. The reason we\nintroduce Bloomier Filters as elementary filters is that they are easy\nto describe and implement, but readers can also use other elemen-\ntary filters to achieve special properties, like smaller filter space,\n5As an extreme example, when ğœ–2=1, the equation ğ‘“(ğœ–1,ğœ†)=ğ‘“(ğœ–1,ğœ†)+ğ‘“(1,ğœ–1ğœ†)\nalso holds because the second stage filter can always report true and thus does not\ncontribute to the space cost.\n6The approximate Bloomier Filter is also referred to as XOR filter [ 23] or binary\nfuse filter [ 24]. For consistency, we use the term â€œBloomier Filterâ€ interchangeably\nthroughout this paper.smaller construction space or supporting dynamic exclusions. We\ndiscuss more related works in Section 6 .\nOverview. Bloomier Filter is a compact perfect hashing algo-\nrithm that supports both approximate and exact membership query\nby encoding item ğ‘’â€™s fingerprint ğ‘“ğ›¼(ğ‘’)âˆˆ{ 0,1}ğ›¼into the hash table.\nSpecifically, to build an approximate membership algorithm, the\nBloomier Filter encodes an ğ›¼-bit fingerprint ğ‘“ğ›¼(ğ‘’)=â„ğ›¼(ğ‘’)for every\npositive item; to build an exact membership algorithm, the Bloomier\nFilter maps every item to a one-bit hash value â„1(ğ‘’)âˆˆ{ 0,1}and en-\ncodesğ‘“1(ğ‘’)=â„1(ğ‘’)(resp.ğ‘“1(ğ‘’)=âˆ¼â„1(ğ‘’)) for every positive (resp.\nnegative) item. The query result of an item ğ‘’depends on whether its\nhash value matches the fingerprint in the hash table. For interested\nreaders, we present the detailed descriptions of Bloomier Filter in\nthe next three paragraphs. Skipping them and directly reading\nthe Remark does not affect the comprehension of this paper .\nAlgorithm. Suppose we already have the entire universe of all\n|U|possible items7whose value are either zero or one. To construct\nthe hash table, we first initialize the hash table by all zero, mark\nall items as â€œnot matchedâ€ and let the variable ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ =|U|. the\nBloomier Filter maps every not-matched item ğ‘’toğ‘—different slots\nğ‘ ğ‘’\n[1..ğ‘—]. Then, it repeats the following operations (called the peeling\nprocess) until all items are â€œmatchedâ€: (1) It selects a slot ğ‘ that\nis mapped by only one item ğ‘’08; (2) It marks the insertion place\n(ip) ofğ‘’0asğ‘ (ğ‘’0)=ğ‘ , and the insertion order (io) of ğ‘’0asğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ ;\n(3) It marks ğ‘’0as â€œmatchedâ€, peels ğ‘’0and decreases ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ by one.\nFinally, it inserts items in ğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ : for itemsğ‘’fromğ‘œğ‘Ÿğ‘‘ğ‘’ğ‘Ÿ =1to|U|,\nit encodes(âŠ•ğ‘—\nğ‘–=1ğ‘ ğ‘’\nğ‘–)âŠ•ğ‘“ğ›¼(ğ‘’)(whereâŠ•means XOR) into the slot ğ‘ (ğ‘’).\nTo query an item ğ‘’, the Bloomier Filter reports âŠ•ğ‘—\nğ‘–=1ğ‘ ğ‘’\nğ‘–as the result.\nExample. Suppose we have |U|=3itemsğ‘’1,ğ‘’2andğ‘’3. To\nconstruct the hash table, the Bloomier Filter first maps ğ‘’1toğ‘–=3\nslotsğ‘ 1,ğ‘ 2,ğ‘ 3; mapsğ‘’2toğ‘ 1,ğ‘ 3,ğ‘ 4; and mapsğ‘’3toğ‘ 2,ğ‘ 4,ğ‘ 5. Then the\nfilter (1) selects slot ğ‘ 5which is only mapped by ğ‘’3, marksğ‘’3with\n(ip = 5, io = 3) and peels ğ‘’3; (2) selectsğ‘ 2which is only mapped by\nğ‘’1, marksğ‘’1with (ip = 2, io = 2) and peels ğ‘’1; (3) selects ğ‘ 1which\nis only mapped by ğ‘’2, marksğ‘’2with (ip = 1, io = 1) and peels ğ‘’2.\nFinally, the filter (1) inserts ğ‘ 1withğ‘ 1âŠ•ğ‘ 3âŠ•ğ‘ 4âŠ•ğ‘“ğ›¼(ğ‘’2)=ğ‘“ğ›¼(ğ‘’2)(io\n= 1); (2) inserts ğ‘ 2withğ‘ 1âŠ•ğ‘ 2âŠ•ğ‘ 3âŠ•ğ‘“ğ›¼(ğ‘’1)=ğ‘“ğ›¼(ğ‘’2)âŠ•ğ‘“ğ›¼(ğ‘’1)(io =\n2); (3) inserts ğ‘ 5withğ‘ 2âŠ•ğ‘ 4âŠ•ğ‘ 5âŠ•ğ‘“ğ›¼(ğ‘’3)=ğ‘“ğ›¼(ğ‘’2)âŠ•ğ‘“ğ›¼(ğ‘’1)âŠ•ğ‘“ğ›¼(ğ‘’3)\n(io = 3). To query the items, the Bloomier Filter reports ğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦(ğ‘’1)=\nğ‘ 1âŠ•ğ‘ 2âŠ•ğ‘ 3=(ğ‘“ğ›¼(ğ‘’2))âŠ•(ğ‘“ğ›¼(ğ‘’2)âŠ•ğ‘“ğ›¼(ğ‘’1))âŠ•0=ğ‘“ğ›¼(ğ‘’1),ğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦(ğ‘’2)=\nğ‘ 1âŠ•ğ‘ 3âŠ•ğ‘ 4=(ğ‘“ğ›¼(ğ‘’2))âŠ•0âŠ•0=ğ‘“ğ›¼(ğ‘’2),andğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦(ğ‘’3)=ğ‘ 2âŠ•ğ‘ 4âŠ•ğ‘ 5=\n(ğ‘“ğ›¼(ğ‘’2)âŠ•ğ‘“ğ›¼(ğ‘’1))âŠ• 0âŠ•(ğ‘“ğ›¼(ğ‘’2)âŠ•ğ‘“ğ›¼(ğ‘’1)âŠ•ğ‘“ğ›¼(ğ‘’3))=ğ‘“ğ›¼(ğ‘’3).\nTheory. The theory underlying the Bloomier Filter is highly\nnon-trivial [ 10]. The peeling process mentioned above is actually\nequivalent to finding the 2-core of random hypergraph. If the num-\nber of potential slots is greater than ğ‘ğ‘, whereğ‘is any constant\nlarger than\nğ‘âˆ’1\nğ‘—:=\u0010\nsupn\nğ›¼âˆˆ(0,1):âˆ€ğ‘¥âˆˆ(0,1),1âˆ’ğ‘’âˆ’ğ‘—ğ›¼ğ‘¥ğ‘—âˆ’1<ğ‘¥o\u0011âˆ’1\n,\nthe peeling process will succeed with high probability 1âˆ’ğ‘œ(1). We\ndenoteğ‘âˆ’1\nğ‘—as the threshold which achieves its minimum value 1.23\nwhenğ‘—=3. Recently, this result is optimized by [ 25] (2021) which\nproposes a new distribution of hyperedges. The author selects ğ‘—slots\n7Bloomier Filter is a static algorithm and does not support dynamic scenarios.\n8If the algorithm cannot find such a slot, it reports construction fail and terminates.\nBut the theory later proves that the algorithm will succeed with high probability.\n4\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\nuniformly at random from a range of |U|/(ğ‘§+1)slots, improving\nthe threshold close to ğ‘â€²âˆ’1\nğ‘—, whereğ‘â€²âˆ’1\nğ‘—can be arbitrarily close to 1\n(e.g.ğ‘â€²âˆ’1\n3â‰ˆ1.12,ğ‘â€²âˆ’1\n4â‰ˆ1.05whenğ‘§=120). InSection 5 , we set\nğ‘—=3,ğ‘§=120,andğ¶=1.13to conduct experiments.\nRemark. To conclude, the Bloomier Filter can derive space-efficient\napproximate ( ğ¶ğ‘›log1/ğœ–bits) and exact ( ğ¶|U|bits) membership fil-\nters, whereğ¶can be an arbitrary constant close to 1. Interestingly, the\ntwo formulae have completely different forms, which seemingly leave\nroom for improvement. This simple observation inspires us to bridge\nthe gap between the two variants to obtain a better theoretical result.\n4 CHAINEDFILTER\n4.1 Key Insight\nWe use the exact membership ChainedFilter as an example to\nillustrate our key insight. Now letâ€™s recap the theoretical results\nof the approximate and the exact variants of Bloomier Filters (BF)\nshown in the Remark ofSection 3 :(\nğ‘“ğµğ¹(ğœ–,ğœ†)â©½ğ‘“ğµğ¹(ğœ–,+âˆ)=ğ¶log 1/ğœ–(Approximate) ;\nğ‘“ğµğ¹(0,ğœ†)=ğ¶(ğœ†+1) (Exact).\nAccording to Theorem 2.2 , we can losslessly factorize a mem-\nbership problem ( 0,ğœ†) into two sub-problems ( ğœ–â€²,ğœ†) and ( 0,ğœ–â€²ğœ†), and\nuse Bloomier Filters as elementary filters to form ChainedFilter s.t.\nğ‘“ğ¶ğ¹(0,ğœ†)=ğ‘“ğµğ¹(ğœ–â€²,ğœ†)+ğ‘“ğµğ¹(0,ğœ–â€²ğœ†)â©½ğ¶log 1/ğœ–â€²+ğ¶(ğœ–â€²ğœ†+1).\nBecauseğœ–â€²can be any value between 0 and 1, we can minimize\nğ‘“ğ¶ğ¹(0,ğœ†)toğ¶log(2ğ‘’ğœ†ln2)by setting9ğœ–â€²=1/(ğœ†ln2).Such an\nintuitive technique amazingly makes ğ‘“ğ¶ğ¹(0,ğœ†)less than 1.11ğ‘“(0,ğœ†).\nAlgorithm 1: ChainedFilter for Exact Membership Query\nInput: UniverseUand subsetS,|U|/|S| =ğœ†>1/ln 2.\nOutput: A filterF:Uâ†¦â†’{ 0,1}s.t.F(ğ‘’)=1iffğ‘’âˆˆğ‘†.\n1Function Construct (U,S):\n2Setlog 1/ğœ–=âŒŠlogğœ†âŒ‹and the false positive set Sâ€²=âˆ….\n3Construct an approximate membership filter F1s.t.\n\u001aF1(ğ‘’)=1,âˆ€ğ‘’âˆˆS;\nP[F1(ğ‘’)=0]=ğœ–,âˆ€ğ‘’âˆˆU\\S.\nFor allğ‘’âˆˆU\\S satisfyingF1(ğ‘’)=1 :Insertğ‘’intoSâ€².\n4Construct an exact filter F2s.t.\n\u001aF2(ğ‘’)=1,âˆ€ğ‘’âˆˆS;\nF2(ğ‘’)=0,âˆ€ğ‘’âˆˆSâ€².\nreturnF(Â·) :=F1(Â·)&F2(Â·).\nThis exact membership example demonstrates the potential of\nthe chain rule. We summarize it in Algorithm 1 andFigure 3 , and\nshow its experimental performance in Section 5.1 . To construct\nChainedFilter, in step 1â—‹, we first encode all the positive items into\nağ¶ğ‘›log(ğœ†ln2)-bit approximate Bloomier Filter with false positive\nrateğœ–=1/(ğœ†ln2)(Line 3). In step 2â—‹, we query all negative and\ncollect the false positive ones into a set Sâ€²(Line 4). In step 3â—‹, we\n9We assume1\nğœ†ln 2<1, otherwise it degenerates to the exact Bloomier Filter. For\nconvenience, we donâ€™t round numbers here, but weâ€™ll do it in practice.encode all the positive as well as all the false positive items (i.e.\nitems inSâ€²) into ağ¶ğ‘›log2ğ‘’-bit Exact Bloomier Filter (Line 5). In\nthis way, the overall space cost ğ‘›ğ‘“ğ¶ğ¹(0,ğœ†)is minimized. To query\nan item, we query both of the two filters and report their ANDvalue\nas the result (Line 6).\nğ’®ğ’®andğ’°ğ’°\\ğ’®ğ’®xconstruction begin\ninput ğ’®ğ’®andğ’°ğ’°\\ğ’®ğ’®\nconstruct stage 1 (â„±1)\nquery stage 1\nconstruct stage 2 (â„± 2)\noutputâ„±=â„±1&â„±2\nendğ’®ğ’®andğ’®ğ’®â€™(ğ’®ğ’®â€™:false positive items)input item ğ‘’ğ‘’\nâ„±1&â„±2ğ‘’ğ‘’=1?\noutput false\nendyes\noutput truenopositive and negative items\nquery beginx\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±=â„±0\nelementary filtersâ‘ \nâ‘¡\nâ‘¢\nâ‘ â‘¡â‘¢\nstep num .insert\nquerypositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\nFigure 3: ChainedFilter shown in Section 4.1.\n4.2 Generalization and Analysis\nIn this part, we (1) extend the exact ( ğœ–=0) ChainedFilter to a\ngeneral (ğœ–â‰ 0) ChainedFilter and show that the two-stage structure\nis space-optimal, (2) extend Bloomier Filters to an arbitrary number\nof elementary filters and reveal ChainedFilterâ€™s limitation. Since\nthis part is only technically complex, skipping it does not\naffect the comprehension of this paper .\n4.2.1 ChainedFilter for general membership query .Since\nthe trivial theoretical bound\nğ‘“ğ¶ğ¹(ğœ–,ğœ†)â©½minn\nğ‘“ğ¶ğ¹(0,(1âˆ’ğœ–)ğœ†),ğ‘¡ğ‘“ğ¶ğ¹(ğœ–,ğœ†/ğ‘¡)o\n(âˆ€ğ‘¡>1)\nis too loose, we introduce additional inequalities to reduce error.\nThe key observation is that an ğ¶(ğ›½+1)ğ‘›(ğ›½>0)-bit Bloomier Filter\ncan also filter out some negative items that are not encoded in\nthe perfect hash table. Recall that in Section 3 , we say a Bloomier\nFilter encodes a one-bit fingerprint ğ‘“1(ğ‘’)=â„1(ğ‘’)âˆˆ{ 0,1}(resp.\nâˆ¼â„1(ğ‘’)) for a positive (resp. negative) item. Now letâ€™s consider two\nstrategies for generating â„1(ğ‘’). (a) The first strategy is P[â„ğ›¼(Â·)=\n1]=1/2, which means we flip a fair coin and record the face up\nside (resp. face down side) as the fingerprint of a positive (resp.\nnegative) item. In this way, only 1/2 not-encoded negative items\nare false positive items. (b) The second strategy is P[â„ğ›¼(Â·)=1]=1,\nwhich means we directly record 1 (resp. 0) as the fingerprint of\na positive (resp. negative) item. In this way, only 1/(ğ›½+1)not-\nencoded negative items are false positive items. These strategies\ngive rise to two additional inequalities (BF represents ChainedFilter.\nWhen the equation â€œ=â€ holds, the algorithm degenerates to one\n5\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\nsingle Bloomier Filter)\n(\nğ‘“ğ¶ğ¹(ğœ–,ğœ†)/ğ¶â©½ğœ†+1âˆ’2ğœ–ğœ†(ğœ–â©½2ğœ†/(ğœ†+1)) (ğ‘);\nğ‘“ğ¶ğ¹(ğœ–,ğœ†)/ğ¶â©½(ğœ†+1)/(ğœ–ğœ†+1) (ğœ–â©½1/2) (ğ‘).\nSimilar to the exact ChainedFilter ( Algorithm 1 ), the generalized\nalgorithm also consists of one approximate Bloomier Filter and\none exact Bloomier Filter. The only difference is, the approximate\nBloomier Filter requires ğ¶ğ‘›ğ›¼=ğ¶ğ‘›(ğ‘“ğ¶ğ¹(ğœ–,ğœ†)âˆ’ğ›½âˆ’1)bits and has a\nfalse positive rate of 1/2ğ›¼, while the Exact Bloomier Filter requires\nğ¶ğ‘›(ğ›½+1)bits and has a false positive rate of min{1/2,1/(ğ›½+1)}.\nUsing the two inequalities and the chain rule, we can determine\nthe optimal parameter settings of ğ›¼,ğ›½and thusğ‘“ğ¶ğ¹(ğœ–,ğœ†). Because\nthe calculation process is a bit dry, we present the results directly\ninCorollary 4.1 andFigure 4 .\nCorollary 4.1. if we only combine two Bloomier Filters, the opti-\nmal space cost and the corresponding parameters are\nğ‘“ğ¶ğ¹(ğœ–,ğœ†):=minn\nğ‘“(ğ‘)(ğœ–,ğœ†),ğ‘“(ğ‘)(ğœ–,ğœ†)o\n,\nwhereğ‘“(ğ‘)(ğœ–,ğœ†),ğ‘“(ğ‘)(ğœ–,ğœ†)are defined as follows:\n(a) Ifğœ†>1\nln 2andğœ†<1\n2ğœ–ln 2, thenP[â„ğ›¼(Â·)=1]=1/2,\nğ›½(ğ‘)=1\nln 2âˆ’2ğœ†ğœ–andğ‘“(ğ‘)(ğœ–,ğœ†)/ğ¶=log(2ğ‘’ğœ†ln 2)âˆ’2ğœ†ğœ–.\nOtherwiseğ‘“(ğ‘)(ğœ–,ğœ†)degenerates to the space of approximate\n(ğ›½=0)or exact(ğ›¼=0)Bloomier Filters.\n(b) Ifğœ†>1\nln 2âˆ’ğœ–>0, thenP[â„ğ›¼(Â·)=1]=1,\nğ›½(ğ‘)=1\nln 2âˆ’ğœ–ğœ†\nğœ–ğœ†+1,andğ‘“(ğ‘)(ğœ–,ğœ†)/ğ¶=log2ğ‘’ğœ†ln 2\nğœ–ğœ†+1âˆ’ğœ–ğœ†\nğœ–ğœ†+1.\nOtherwiseğ‘“(ğ‘)(ğœ–,ğœ†)degenerates to the space of approximate\n(ğ›½=0)or exact(ğ›¼=0)Bloomier Filters.\n4.2.2 Two filters can be optimal .It seems that only two stages is\ntoo trivial. But interestingly, we prove that combining two Bloomier\nFilters using operator â€œ&â€ is space-optimal.\nTheorem 4.1. (Optimality ) Suppose we have a combined filter\nF:=&ğ‘š\nğ‘–=1Fğ‘–, whereFğ‘–are Bloomier Filters. Then we can prove that\n(CF represents ChainedFilter)\nğ‘“F(ğœ–,ğœ†)â©¾ğ‘“ğ¶ğ¹(ğœ–,ğœ†).\nProof. We only consider inequality (ğ‘), i.e.ğ‘“ğµğ¹(ğœ–,ğœ†)/ğ¶=ğœ†+\n1âˆ’2ğœ–ğœ†(ğœ–â©½2ğœ†/(ğœ†+1)), where BF represents Bloomier Filter,\nbecause the case for inequality (ğ‘)is similar.\nLetğœ–:=ğœ–1ğœ–2...ğœ–ğ‘š, according to the chain rule\nğ‘“(ğœ–,ğœ†)=ğ‘“(ğœ–1,ğœ†)+ğ‘“(ğœ–\nğœ–1,ğœ–1ğœ†)\n=ğ‘“(ğœ–1,ğœ†)+ğ‘“(ğœ–2,ğœ–1ğœ†)+ğ‘“(ğœ–\nğœ–1ğœ–2,ğœ–1ğœ–2ğœ†)\n=ğ‘“(ğœ–1,ğœ†)+ğ‘“(ğœ–2,ğœ–1ğœ†)+ğ‘“(ğœ–3,ğœ–1ğœ–2ğœ†)+ğ‘“(ğœ–\nğœ–1ğœ–2ğœ–3,ğœ–1ğœ–2ğœ–3ğœ†)\n=...\n=ğ‘“(ğœ–1,ğœ†)+ğ‘“(ğœ–2,ğœ–1ğœ†)+...+ğ‘“(ğœ–ğ‘š,ğœ–1ğœ–2...ğœ–ğ‘šâˆ’1ğœ†),\nFigure 4: Space cost when ğ¶â†’1. The multicolored sur-\nface is the minimum space cost of a single Bloomier Filter.\nWhenğœ–=0andğœ†=16, it is 210% higher than the theoretical\nlower bound, while the space overhead of ChainedFilter\n(the blue surface) is only 8%.\nwe have\nmin\nFğ‘“F(ğœ–,ğœ†)/ğ¶=ğœ–1ğœ–2...ğœ–ğ‘š=ğœ–\nmin\nğœ–1,ğœ–2,...,ğœ–ğ‘šâˆˆ[0,1/2]ğ‘šâˆ‘ï¸\nğ‘–=1ğ‘“ğµğ¹(ğœ–ğ‘–,ğœ–1ğœ–2...ğœ–ğ‘–âˆ’1ğœ†)/ğ¶\n=ğ‘š+(1âˆ’2ğœ–)ğœ†âˆ’ max\nğœ–1,ğœ–2,...,ğœ–ğ‘šâˆ’1âˆˆ[0,1/2]Â©Â­\nÂ«ğ‘šâˆ’1âˆ‘ï¸\nğ‘–=1ğ‘–Ã–\nğ‘—=1ğœ–ğ‘—ÂªÂ®\nÂ¬ğœ†\n=ğ‘š+(1âˆ’2ğœ–)ğœ†âˆ’\u0012\n1âˆ’1\n2ğ‘šâˆ’1\u0013\nğœ†=\u0012\nğ‘š+ğœ†\n2ğ‘šâˆ’1\u0013\nâˆ’2ğœ–ğœ†.\nWhenï£±ï£´ï£´ï£´ ï£²\nï£´ï£´ï£´ï£³ğ‘š=âŒŠlogğœ†âŒ‹+1;\nğœ–1=...=ğœ–ğ‘šâˆ’1=1/2;\nğœ–ğ‘š=2ğ‘šâˆ’1ğœ–,\nThe formula achieves the minimum value\nğ‘“F(ğœ–,ğœ†)=âŒŠlogğœ†âŒ‹+1+ğœ†\n2âŒŠlogğœ†âŒ‹âˆ’2ğœ–ğœ†=ğ‘“ğ¶ğ¹(ğœ–,ğœ†).\nSo ChainedFilter is space-optimal. â–¡\nRemark. Whenğœ–=0, the rounded space cost of ChainedFilter is\nğ‘“ğ¶ğ¹(0,ğœ†)=ğ¶(âŒŠlogğœ†âŒ‹+1+ğœ†\n2âŒŠlogğœ†âŒ‹)<1.11ğ¶ğ‘“(0,ğœ†).\nWe will recap this result in Section 5.1 and 5.2 .\n4.2.3 Limitation of the operator â€œ&â€ .When the elementary\nfilters are not limited to Bloomier Filters, the optimal combined\nfilter can be very complex. In fact, we may not even know how\nmany elementary filters we should use. However, we find that if we\ncontinue to use the â€œ&â€ operator to combine filters, we can derive\nthe tight space lower bound of the combined filter.\nTheorem 4.2. (Limitation ) Given arbitrary elementary filters\n(EF)Fğ‘–with a restriction of ğ‘“ğ¸ğ¹(ğœ–,ğœ†)and an arbitrary combined\n6\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\nfilterF:=&ğ‘š\nğ‘–=1Fğ‘–. We defineğ›¹ğ¸ğ¹(ğœ–,ğœ†):[0,1]Ã—R+â†¦â†’Ras any\nfunction satisfying\n(\nğ‘“(ğœ–,ğœ†)â©½ğ›¹ğ¸ğ¹(ğœ–,ğœ†)â©½ğ‘“ğ¸ğ¹(ğœ–,ğœ†) âˆ€ ğœ–âˆˆ[0,1],\nğ›¹ğ¸ğ¹(ğœ–1ğœ–2,ğœ†)â©½ğ›¹ğ¸ğ¹(ğœ–1,ğœ†)+ğ›¹ğ¸ğ¹(ğœ–2,ğœ–1ğœ†) âˆ€ğœ–1,ğœ–2âˆˆ[0,1].\nThen we have\ninfğ‘“F(ğœ–,ğœ†)=supğ›¹ğ¸ğ¹(ğœ–,ğœ†).\nProof. First, we assert that (1) infğ‘“F(ğœ–,ğœ†)exists. This is be-\ncauseğ‘“F(ğœ–,ğœ†)exists (ğ‘“F(ğœ–,ğœ†)â©½ğ‘“ğ¸ğ¹(ğœ–,ğœ†)) and has an lower\nboundğ‘“(ğœ–,ğœ†). (2) supğ›¹ğ¸ğ¹(ğœ–,ğœ†)exists. This is because ğ›¹ğ¸ğ¹(ğœ–,ğœ†)\nexists (ğ›¹ğ¸ğ¹(ğœ–,ğœ†)â©¾ğ‘“(ğœ–,ğœ†)) and has an upper bound ğ‘“ğ¸ğ¹(ğœ–,ğœ†).\nSecond, we prove that ğ‘“F(ğœ–,ğœ†)â©¾ğ›¹ğ¸ğ¹(ğœ–,ğœ†)by mathematical\ninduction. When ğ‘š=1(note thatğ‘šis the number of elementary\nfilters), we observe ğ‘“F(ğœ–,ğœ†)=ğ‘“ğ¸ğ¹(ğœ–,ğœ†)â©¾ğ›¹ğ¸ğ¹(ğœ–,ğœ†).Assume that\nwhenğ‘š=ğ‘š0âˆ’1we haveğ‘“F(ğœ–,ğœ†)â©¾ğ›¹ğ¸ğ¹(ğœ–,ğœ†). Then, when\nğ‘š=ğ‘š0,we can rewriteFas(&ğ‘š0âˆ’1\nğ‘–=1Fğ‘–)&Fğ‘š0.W.l.o.g., we can\nassume that &ğ‘š0âˆ’1\nğ‘–=1Fğ‘–encodesğœ†ğ‘›negative items with false positive\nrateğœ–â€², andFğ‘š0encodesğœ†â€²ğ‘›(ğœ†â€²â©¾ğœ–â€²ğœ†)negative items with false\npositive rate ğœ–â€²â€²(ğœ–â€²ğœ–â€²â€²â©½ğœ–). Thus\nğ‘“F(ğœ–,ğœ†)â©¾ğ›¹ğ¸ğ¹(ğœ–â€²,ğœ†)+ğ›¹ğ¸ğ¹(ğœ–â€²â€²,ğœ†â€²)\nâ©¾ğ›¹ğ¸ğ¹(ğœ–â€²,ğœ†)+ğ›¹ğ¸ğ¹(ğœ–â€²â€²,ğœ–ğœ†)\nâ©¾ğ›¹ğ¸ğ¹(ğœ–â€²ğœ–â€²â€²,ğœ†)â©¾ğ›¹ğ¸ğ¹(ğœ–,ğœ†).\nTherefore,âˆ€ğ‘šâˆˆN+we have\nğ‘“F(ğœ–,ğœ†)â©¾ğ›¹ğ¸ğ¹(ğœ–,ğœ†)â‡’ infğ‘“F(ğœ–,ğœ†)â©¾supğ›¹ğ¸ğ¹(ğœ–,ğœ†).\nFinally, we assert that\ninfğ‘“F(ğœ–1ğœ–2,ğœ†)â©½infğ‘“F(ğœ–1,ğœ†)+infğ‘“F(ğœ–2,ğœ–1ğœ†)\nâ‡’infğ‘“F(ğœ–,ğœ†)â©½supğ›¹ğ¸ğ¹(ğœ–,ğœ†).\nTherefore, we conclude that infğ‘“F(ğœ–,ğœ†)=supğ›¹ğ¸ğ¹(ğœ–,ğœ†).â–¡\nRemark. Theorem 4.2 shows the limitation of the operator â€œ&â€:\nif we solely use the â€œ&â€ operator, the space cost of a combined filter\ncannot be less than supğ›¹ğ¸ğ¹\nğœ–,ğœ†. However, if we utilize the chain rule with\nother operators such as â€œ &âˆ¼â€, then the situation may be different\n(Section 4.3.2 ).\n4.3 ChainedFilter is a Framework\nInSection 4.1 , we combine Bloomier Filters with operator â€œ&â€\nto construct ChainedFilter. However, this design has two limita-\ntions. First, Bloomier Filter only supports static membership query,\nwhich means that any new item added may require a reconstruction\nof the entire data structure. Second, although the Bloomier Filter\nitself only requires ğ‘‚(ğ‘›)space, its construction process requires an\nadditionalğ›º(ğ‘›logğ‘›)space (as the peeling process relies on a good\nordering). In this part, we present some extensions to ChainedFilter\nthat overcomes these shortcomings to some extent.\n4.3.1 Replace elementary filters.\nFor the first limitation, we can replace the Bloomier Filter(s) with\nother dynamic elementary filter(s) to support online updates. For\ninstance, we can replace the static second stage (exact) BloomierFilter with a dynamic filter such as Othello Hashing [ 26] or Col-\noring Embedder [ 27], at the expense of additional space10. With\nthe help of the dynamic â€œwhitelistâ€, the new version of ChainedFil-\nter supports the exclusion of new negative items without causing\nany false negative. Similarly, we can further replace the static first\nstage (approximate) Bloomier Filter, which requires ğ¶log1/ğœ–bits\nper item, with a dynamic filter such as a Bloom Filter [ 28], which\nrequires(log1/ğœ–)/ln2bits per item, or a Cuckoo Filter [ 14], which\nrequires 1.05(2+log1/ğœ–)bits per item. In this way, the new version\nof ChainedFilter supports not only the exclusion of new negative\nitems but also the inclusion (insertion) of new positive items with\na small false positive rate. These enhancements enable Chained-\nFilter to be used in more dynamic scenarios where new items are\nfrequently added.\nWhile we present some compensations, it is important to note\nthat ChainedFilter does not perfectly align with dynamic scenarios.\nThis is because we need to determine all false positive items before\nwe construct the second stage filter. At the theoretical level, we can\neven prove that the chain rule does not hold for general dynamic\nmemberships. This is supported by prior work [ 29], which shows\nthat a dynamic exact membership problem only requires ğ‘›ğ‘“â€²(0,ğœ†)=\n(1+ğ‘œ(1))ğ‘›ğ‘“(0,ğœ†)bits, and [ 30], which demonstrates that a dy-\nnamic approximate membership problem costs ğ‘›ğ‘“â€²(ğœ–,+âˆ)=ğ‘›ğ¶(ğœ–)\nğ‘“(ğœ–,+âˆ) bits, whereğ¶(ğœ–)>1depends solely on ğœ–(This implies that\nthere exists a ğœ†>0for whichğ‘“â€²(ğœ–,ğœ†)>ğ‘“(ğœ–,ğœ†)). So the inequality\nğ‘“â€²(0,ğœ†)=ğ‘“(0,ğœ†)=ğ‘“(ğœ–,ğœ†)+ğ‘“(0,ğœ–ğœ†)<ğ‘“â€²(ğœ–,ğœ†)+ğ‘“â€²(0,ğœ–ğœ†)\nserves as a counterexample to the chain rule ( Theorem 2.2 ).\n4.3.2 Replace the combining operator â€œ&â€.\nFor the second limitation, we can design a space-efficient (i.e.\nğ‘‚(ğ‘›ğ‘“(0,ğœ†))) exact filter with no additional construction space based\non the chain rule.\nOverview. Our key idea is to replace the combining operator\nâ€œ&â€ (i.e. &ğ‘š\nğ‘–=1Fğ‘–) with â€œ &âˆ¼â€ and recursively define\n(\nF(Â·) :=F0(Â·);\nFğ‘–(Â·):=Fğ‘–+1(Â·)&âˆ¼Fğ‘–+1(Â·),âˆ€ğ‘–âˆˆN(âˆ¼means NOT).\nIn this formula, every elementary filter Fğ‘–(Â·)is a approximate filter\nlike Bloom Filter or Cuckoo Filter, and Fğ‘–+1is the whitelist ofFğ‘–\n(Figure 5 ). To construct the filter, in step 1â—‹, we insert all positive\nitems intoF1; in step 2â—‹, we insert all false positive items of F1\nintoF2; in step 3â—‹, we insert all false positive items of F2intoF3,\nand so on. If we need an exact filter, this process iterates until no\nfalse positive items are left. Itâ€™s easy to find that ChainedFilter has\nno additional construction space, as all items can be placed on the\ninput tape of the Turing Machine model.\nAnalysis. Here we analysis the space cost of the new design\n(denoted as ğ‘›ğ‘“ğ¶ğ¹(0,ğœ†)bits) and derive related parameter settings.\nTheorem 4.3. (Space Cost ) Suppose an approximate filter costs\nğ¶â€²log 1/ğœ–bits per item ( ğ¶â€²=logğ‘’=1.44for Bloom Filter), then\ninfğ‘“ğ¶ğ¹(0,ğœ†)=ğ¶â€²log 4ğ‘’ğœ†.\n10These two algorithms map each item to an edge in a random hypergraph and then\ncolor the nodes the same for positive items and different for negative items. Othello\nHashing / Coloring Embedder requires 2.33/2.2 bits per item (compared to ğ¶<1.13\nbits per item cost of Bloomier Filter) but support online updates.\n7\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\nğ’®ğ’®andğ’°ğ’°\\ğ’®ğ’®xconstruction begin\ninput ğ’®ğ’®andğ’°ğ’°\\ğ’®ğ’®\nconstruct stage 1 (â„±1)\nquery stage 1\nconstruct stage 2 (â„± 2)\noutputâ„±=â„±1&â„±2\nendğ’®ğ’®andğ’®ğ’®â€™(ğ’®ğ’®â€™:false positive items)input item ğ‘’ğ‘’\nâ„±1&â„±2ğ‘’ğ‘’=1?\noutput false\nendyes\noutput truenopositive and negative items\nquery beginx\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±=â„±0\nelementary filtersâ‘ \nâ‘¡\nâ‘¢\nâ‘ â‘¡â‘¢\nstep num .insert\nquerypositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\nFigure 5: The â€œ &âˆ¼â€ version shown in Section 4.3.2.\nProof. Our proof is based on a simple observation: Exactly\nclassifyingğ‘›positive items and ğœ†ğ‘›negative items is equivalent to\nexactly classifying ğœ†Ã—ğ‘›positive items and ğœ†Ã—(1/ğœ†)ğ‘›negative\nitems. Formally speaking, we have ğ‘“(0,ğœ†)=ğœ†ğ‘“(0,1/ğœ†). We use\nthe above formula to determine the parameter settings, and the\nfollowing proof is only technically complicated.\nW.l.o.g. we let ğœ†â©¾1. According to the chain rule\nğ‘“(0,ğœ†)=ğ‘“(ğœ–,ğœ†)+ğ‘“(0,ğœ–ğœ†)=ğ‘“(ğœ–,ğœ†)+ğœ–ğœ†ğ‘“(0,1/(ğœ–ğœ†)),\nwe have\ninfğ‘“ğ¶ğ¹(0,ğœ†)/ğ¶â€²=inf\nğœ–<1\u001a\nlog1\nğœ–+ğœ–ğœ†ğ‘“ğ¶ğ¹(0,ğœ–ğœ†)/ğ¶â€²\u001b\n=logğœ†+inf\nğœ–<1\u001a\nlog1\nğœ–ğœ†+ğœ–ğœ†ğ‘“ğ¶ğ¹(0,ğœ–ğœ†)/ğ¶â€²\u001b\n=logğœ†+inf\nğ‘¥<ğœ†\u001a\nlog1\nğ‘¥+ğ‘¥infğ‘“ğ¶ğ¹(0,ğœ–ğœ†)/ğ¶â€²\u001b\n=logğœ†+Constant.\nSince infğ‘“ğ¶ğ¹(0,ğœ–ğœ†)is derivable, so the right hand side achieves\nthe minimum value when\nd\ndğ‘¥(log1\nğ‘¥+ğ‘¥infğ‘“ğ¶ğ¹(0,ğœ–ğœ†)/ğ¶â€²)=0\nTherefore(\nğœ–ğœ†=ğ‘¥=1;\ninfğ‘“ğ¶ğ¹(0,ğœ–ğœ†)=ğ¶â€²log 4ğ‘’ğœ†.\nActually, according to Lâ€™HÃ´pitalâ€™s rule, if\nğ‘“ğ¶ğ¹(0,ğœ–ğœ†)â‰¡ğ¶â€²\u0012\nlogğœ†+log1\nğ›¿+ğ›¿ğ‘“ğ¶ğ¹(0,ğœ–ğœ†)\u0013\n(ğ›¿<1),we have\nğ‘“ğ¶ğ¹(0,ğœ–ğœ†)=ğ¶â€²\u0012\nlogğœ†+1+ğ›¿\n1âˆ’ğ›¿log1\nğ›¿\u0013\nâ†’ğ¶â€²log 4ğ‘’ğœ†(ğ›¿â†’1).\nWe show our algorithm in Algorithm 2 . â–¡\nRemark. In practice, we can set ğ›¿=1/2, round up the space cost\nofF1toğ¶â€²ğ‘›âŒˆlogğœ†/ğ›¿âŒ‰bits, and round up the space cost of Fğ‘–(ğ‘–â©¾2)\ntoğ¶â€²ğ‘›2ğ›¿ğ‘–âˆ’1log1/ğ›¿=ğ¶â€²ğ‘›22âˆ’ğ‘–bits. The total space cost is no more\nthanğ¶â€²ğ‘›log16ğœ†bits and the expected query time is ğ‘‚(1). To take a\nstep further, we can replace the last ğ‘‚(logğ‘›âˆ’log logğ‘›)approximate\nfilters with one exact filter whose construction space is ğ‘‚(ğ‘›), so that\nwe can reduce the number of filters from ğ‘‚(logğ‘›)toğ‘‚(log logğ‘›). We\nsummarize the properties of the exact ChainedFilter using operatorAlgorithm 2: Exact ChainedFilter (using operator â€œ &âˆ¼â€)\nInput: UniverseUand subsetS,|U|/|S| =ğœ†>1.\nOutput: A filterF:Uâ†¦â†’{ 0,1}s.t.F(ğ‘’)=1iffğ‘’âˆˆğ‘†.\n1Function Construct (U,S):\n2Setğœ…=ğœ†,ğ›¿âˆˆ(0,1),Sğ‘‡=S,Sğ¹=U\\S,ğ‘–=1.\n3WhileSğ¹â‰ âˆ…:\n4 Construct an approximate filter Fğ‘–s.t.\n\u001aFğ‘–(ğ‘’)=1,âˆ€ğ‘’âˆˆSğ‘‡;\nP[Fğ‘–(ğ‘’)=0]â©½ğ›¿/ğœ…,âˆ€ğ‘’âˆˆSğ¹.\n5ğœ…â†1/ğ›¿,Sğ‘‡â†Sğ¹,Sğ¹â†{ğ‘’âˆˆSğ¹:Fğ‘–(ğ‘’)=0}.\n6ğ‘–â†ğ‘–+1.\n7returnF(Â·) :=F0(Â·), where\nFğ‘—(Â·):=Fğ‘—+1(Â·)&âˆ¼Fğ‘—+1(Â·),âˆ€ğ‘—âˆˆ[0..ğ‘–âˆ’2].\nâ€œ&â€ and â€œ &âˆ¼â€ inTable 2 (â€œ/â€ means the additional space complexity\nis no more than the filter space complexity).\n5 APPLICATIONS AND EVALUATION\nâ€¢Experimental Setup : In this section, we implement Chained-\nFilter and its variants in C++ and Python and equip them with\nMurmur Hashing [ 31] to compute mapped addresses. We evaluate\ntheir performance in terms of space usage, speed and accuracy in\nseveral applications, including data compressing ( Section 5.1, 5.2 ),\nclassifying ( Section 5.3, 5.5 ), and filtering ( Section 5.4 ). Note that\nthe universeUmay not be the absolute universe. Instead, it can be\nthe set of frequently queried items ( Section 5.4 ). Unless otherwise\nstated, all item keys are 64-bit pre-generated random integers. All\nexperiments are conducted on a machine with 36 IntelÂ®Core â„¢\ni9-10980XE CPU @ 3.00GHz (576KiB L1 d-cache, 576KiB L1 i-cache,\n18MiB L2 cache, 24.8MiB L3 cache) and 128GB DRAM.\nâ€¢Our evaluation metrics (with units) are:\n(a)Filter space (Mb) : The size of the filter measured in million\nbits (Mb). Additional construction space is not included.\n(b)Average construct and query throughput (Mops) : The\naverage number of operations per time, measured in million opera-\ntions per second (Mops). Each experiment was repeated 10 times,\nand the mean value was recorded to reduce error.\n(c)Error rate : The ratio of the number of misclassified (both\nfalse positive and false negative) items to the number of all items.\nWe use this metric in Section 5.3 .\n(d)Tail latency ( ğœ‡ğ‘ ): The high percentile latency measured in ğœ‡ğ‘ .\nFor example, a P99 latency represents the time cost of an operation\nwhich is longer than 99% time costs of all operations. We use this\nmetric in Section 5.4 .\n(e)False Positive Rate : The ratio of the false positive items to\nthe number of negative items. We use this metric in Section 5.5 .\n5.1 Static Dictionary\nAs a warmup, in this part, we use ChainedFilter (\"&\" version, Al-\ngorithm 1 ) to compactly encode Boolean function ğœ‘:{0,1,...,|U|}\nâ†¦â†’{0,1}with static support.\n5.1.1 Modeling .We regard all ğ‘›inputs which satisfy ğœ‘(Â®ğ‘‹)=1as\npositive items, and the other ğœ†ğ‘›inputs as negative items. According\n8\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\nProperties â€œ&â€ version â€œ &âˆ¼â€ version Approximate ExactLower bound\n(ğœ–=0) (Algorithm 1 ) ( Algorithm 2 ) Bloomier Bloomier\nConstruction time ğ‘‚(|U|) ğ‘‚(|U| log logğ‘›) ğ‘‚(ğ‘›) ğ‘‚(|U|) Linear\nFilter space (bits) â‰ˆğ¶ğ‘›log(2ğ‘’ğœ†ln 2) â‰ˆğ¶â€²ğ‘›log 4ğ‘’ğœ† ğ‘‚(ğ‘›logğœ†ğ‘›) â‰ˆğ¶|U|ğ‘›(logğœ†+(ğœ†+1)log(1+1/ğœ†))\nAdditional space ğ›º(ğ‘›logğ‘›) / /ğ›º(|U| log|U|) /\nTable 2: Summary of ChainedFilter variants\nto the Remark ofTheorem 4.1 , the exact ChainedFilter requires\nğ¶\n1+ğœ†\u0012\nâŒŠlogğœ†âŒ‹+1+ğœ†\n2âŒŠlogğœ†âŒ‹\u0013\n|U|â©½4ğ¶\n5 log 5âˆ’8ğ»(1\nğœ†+1)|U| bits,\nwhereğ¶<1.13according to the Remark ofSection 3 . So we have\nCorollary 5.1. Whenğ¶<1.13, ChainedFilter takes at most\n4ğ¶/(5log5âˆ’8)=26% space overhead to encode static dictionaries\nwith high probability 1âˆ’ğ‘œ(1).\n81420Filter Space (Mb)2 4 6 8 10 12 14 16\n246\nBloomier Filter\nChainedFilterLower Bound\nConstruction Fail\nFigure 6: Filter space of the exact Bloomier Filter, Chained-\nFilter, and the theoretical lower bound. The dotted lines\nand the dashes represent theoretical and experimental re-\nsults, respectively. We run each data point for 10 times with\ndifferent hash seeds. A colored dash indicates a successful\nconstruction, while a grey dash indicates the construction\nfails (you may want to enlarge this figure).\n5.1.2 Experiments .We fixğ‘›=1million and vary the parameter\nğœ†from 2 to 16 to compare the filter space, construction throughput\nand query throughput between ChainedFilter and exact Bloomier\nFilter11. InFigure 6 , we find that the experimental space costs\ncorrespond well with our theory. Once the allocated space cost is\nlarger than a certain threshold, the filter build processes will succeed\nwith high probability. Specifically, when ğœ†=16, ChainedFilter\ncosts 64% less space than exact Bloomier Filter. In Figure 7 (a) , we\ndiscover that the construction throughput of exact Bloomier Filter\ndecreases as ğœ†increases, whereas that of ChainedFilter increases\nasğœ†increases. This is because although a larger ğœ†leads to a worse\nlocality, the throughput bottle neck of ChainedFilter is from the\nspace cost of exact Bloomier Filter, which fluctuates between 2ğ¶ğ‘›\n(whenğœ†=2,4,8,16) and 3ğ¶ğ‘›. Therefore, the amortized throughput\nof each item of ChainedFilter increases, and it even surges from the\ncase ofğœ†=2ğ‘–âˆ’1to the case of ğœ†=2ğ‘–(ğ‘–=2,3,4,...). Specifically,\nwhenğœ†=16, the construction throughput of ChainedFilter is\n407% higher than that of Exact Bloomier Filter. In Figure 7 (b) ,\nwe observe that the query throughput of ChainedFilter shows the\n11Whenğœ†=1, ChainedFilter exactly degenerates to exact Bloomier Filter.same phenomenon. This is because only the positive items and the\nfalse positive items require the lookup of the second stage filter.\nSpecifically, when ğœ†=16, the query throughput of ChainedFilter is\n103% higher than that of Exact Bloomier Filter.\n246810121416\n02468 Throughput (Mops)\n(a) ConstructionChainedFilter\nBloomier Filter\n246810121416\n048121620\n(b) QueryChainedFilter\nBloomier Filter\nFigure 7: Average construction and query throughput.\n5.2 Random Access Huffman Coding\nIn this part, we apply ChainedFilter to lossless data compression.\n5.2.1 Background .In information theory, Huffman Coding [ 32]\nis an optimal prefix coding technique for lossless data compression.\nGiven the possibility of occurrence of all kinds of symbols Â®ğ‘:=\n(ğ‘1,ğ‘2,...), the Huffmanâ€™s algorithm generates a variable-length\ncode table, namely Huffman Tree, which assigns an ğ‘™ğ‘–âˆ’bit prefix\ncode for the ğ‘–-th symbol. The literature shows that the average code\nlengthğ¿Huff :=Ãğ‘™ğ‘–ğ‘ğ‘–satisfies\nğ»(Â®ğ‘)â©½ğ¿Huff<ğ»(Â®ğ‘)+1,whereğ»(Â®ğ‘):=âˆ’âˆ‘ï¸\nğ‘–ğ‘ğ‘–logğ‘ğ‘–.\nAlthough Huffmanâ€™s algorithm is optimal for separate symbols, it\nhas certain limitations: (1) Compression ratio . Unlike arithmetic\ncoding or ANS [ 33],ğ¿Huffmay not approach the entropy ğ»(Â®ğ‘)arbi-\ntrarily. For example, if we have a string consisting of one character\nâ€˜aâ€™ and 1023 character â€˜bâ€™. The Huffmanâ€™s algorithm will cost 1024\nbits to encode them, but the least space cost is only 10 bits since\nwe can simply record the address of â€˜aâ€™. (2) Decoding order . The\nHuffmanâ€™s algorithm does not support random memory access of\ndata. (3) Confidentiality . Attackers with prior knowledge of the\ncharacterâ€™s frequency Â®ğ‘can decipher the unencrypted Huffman\nTree. (4) Robustness . In Huffman Code, small interference (bit\nflip or loss) may cause it to fail to recognize the starting position\nof characters, resulting in decoding failure. Some alternative ap-\nproaches can partially address these problems. For example, (1)\nblocking some symbols can increase the compression ratio at the\nexpense of the Huffman Treeâ€™s complexity; (2) Encoding the Huff-\nman Code into a perfect hash table can support random access at\nthe expense of space overhead [ 34];(3) Encryption and(4) error\n9\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\ncorrecting code may increase the confidentiality and robustness\nat the expense of time and space overhead.\n5.2.2 Modeling .ChainedFilter (\"&\" version, Algorithm 1 ) can\novercome the four limitations simultaneously. Given the Huffman\nTree based on the probability vector Â®ğ‘, we encode every char-\nacterâ€™s address paired with its Huffman Code into ChainedFilter.\nSpecifically, for the ğ‘–-th character in the data with Huffman Code\nÂ®ğ‘£=(ğ‘£1,ğ‘£2...,ğ‘£ğ‘˜)âˆˆ{ 0,1}ğ‘˜, we encode(key=(ğ‘–,ğ‘—),value =ğ‘£ğ‘—),ğ‘—âˆˆ\n[1..ğ‘˜]into ChainedFilter. To query the ğ‘–-th character, we can query\nkey=(ğ‘–,1),(ğ‘–,2)...until the leaf node of the Huffman Tree.\nFor example, to compress a string \" ab\\0\" with its Huffman Tree\n(â€˜aâ€™â†’00, â€˜bâ€™â†’01, â€˜\\0â€™â†’1), we can encode the negative items (1,1),\n(1,2),(2,1)and the positive items (2,2),(3,1)into ChainedFilter.\nTo query, say, the second character, we first query key =(2,1)and\nfind that it is negative, and then query key =(2,2)and find that it\nis positive. Therefore, we know that the second character whose\nHuffman Code is â€œ 01â€ is â€˜bâ€™.\nOur algorithm has random access property, high confidentiality\n(as long as the hash seed is secure), and high robustness. In The-\norem 5.1 , we prove that ChainedFilter optimizes the worst-case\ncompression ratio performance as well.\nTheorem 5.1. The average code length of our algorithm, denoted\nasğ¿ours, satisfiesğ»(Â®ğ‘)<ğ¿ours<ğ»(Â®ğ‘)+0.22with high probability\n1âˆ’ğ‘œ(1).\nProof. We only prove the right inequality by mathematical\ninduction. For convenience, we define constant ğ¶0:=0.22. First, if\nthe Huffman Tree has only two leaf nodes, according to the Remark\nofTheorem 4.1 , we have\nğ¿oursâ©½ğ¶\n1+ğœ†\u0012\nâŒŠlogğœ†âŒ‹+1+ğœ†\n2âŒŠlogğœ†âŒ‹\u0013\nâ©½ğ»(ğ‘)+ğ¶+2\n3âˆ’log 3 <ğ»(ğ‘)+ğ¶0.\nConsider there are two Huffman Trees that satisfy the above in-\nequality. We combine them into a larger Huffman Tree with weights\nğ‘and ( 1âˆ’ğ‘), respectively. Since the number of layers is increased\nby one, we have\nğ¿ours=âˆ‘ï¸\nğ‘–ğ‘ğ‘1ğ‘–(ğ‘™1ğ‘–+1)+âˆ‘ï¸\nğ‘–(1âˆ’ğ‘)ğ‘2ğ‘–(ğ‘™2ğ‘–+1)\nâ©½ğ‘ğ»(Â®ğ‘1)+(1âˆ’ğ‘)ğ»(Â®ğ‘2)+1+ğ¶0\n=âˆ’âˆ‘ï¸\nğ‘–ğ‘ğ‘1ğ‘–logğ‘ğ‘1ğ‘–âˆ’âˆ‘ï¸\nğ‘–(1âˆ’ğ‘)ğ‘2ğ‘–log(1âˆ’ğ‘)ğ‘2ğ‘–\n+ğ‘âˆ‘ï¸\nğ‘–logğ‘+(1âˆ’ğ‘)âˆ‘ï¸\nğ‘–log(1âˆ’ğ‘)+1+ğ¶0\n=ğ»(Â®ğ‘)âˆ’(ğ»(ğ‘)âˆ’1)+ğ¶0<ğ»(Â®ğ‘)+ğ¶0.\nSoğ¿ours<ğ»(Â®ğ‘)+ğ¶0holds for all Huffman Trees. â–¡\nRemark. Theorem 5.1 demonstrates that our algorithm has a\ntighter upper bound (0.22 bit per item) on space overhead than the\nstandard Huffmanâ€™s algorithm (1 bit per item). This is particularly\nadvantageous when the data is highly skewed or sparse. However, one\ndrawback of ChainedFilter is its poor spacial locality, which limits\nits throughput in hierarchical memory systems. To compensate this\ndrawback, we can enable the first and the second stage filters to sharethe same mapped addresses, as suggested in [ 35]. The optimized ver-\nsion uses ağ¶ğ‘›âŒˆlogğœ†âŒ‰-bit approximate Bloomier Filter (with less than\nğ‘›false positive items) and a 2ğ¶ğ‘›-bit exact Bloomier Filter, and every\n(âŒˆlogğœ†âŒ‰+2)bits are organized as a block. With this optimization,\neach item has ğ‘—=3common mapped blocks shared by both of the first\nand the second stages, making it possible to access its value within ğ‘—\nmemory accesses.\n4 6 8 10357911 Filter Space (Mb)\n(a)ChainedFilter-basic\nChainedFilter-optimized\nStrawman Solution\nOriginal Huffman Code\n4 6 8 10\n010203040 Query Throughput (Mops)\n (b)ChainedFilter-basic\nChainedFilter-optimized\nStrawman Solution\nOriginal Huffman Code\nFigure 8: Filter space and query throughput of random\naccess Huffman coding algorithms.\n5.2.3 Experiments .We synthesize eight datasets of strings whose\ncharactersâ€™ occurrence obeys an exponential distribution with pa-\nrameterğœ”=3,4,...,10,respectively12. We fix the number of positive\nitems to 1 million, generate the Huffman Code for each string, and\nencoding the Huffman Code using ChainedFilter and its optimized\nversion ( Remark ofTheorem 5.1 ). To provide a strawman solu-\ntion, we encode the Huffman Code into an exact Bloomier Filter\nand record its filter space and query throughput. For reference, we\nalso evaluate the performance of raw Huffman Coding, but present\nits sequential decoding throughput rather than random decoding\nthroughput (because it does not support random access). The exper-\nimental results are shown in Figure 8 , we find that ChainedFilter\nperforms better as ğœ”grows. When ğœ”=10, the basic and the op-\ntimized versions of ChainedFilter saves 48.3% and 39.2% of the\nfilter space compared to the strawman solution, while their query\nthroughput is only 15.5% and 1.17% slower.\n5.3 Self-Adaptive Hashing\nIn this part, we use ChainedFilter to reduce the number of mem-\nory accesses required for Cuckoo Hashing [36].\n5.3.1 Background .Serving as a hash predictor, ChainedFilter\nreduces unnecessary memory accesses for multiple-choice hashing,\nwhich take around 100ğ‘›ğ‘ for DRAM andâ‰ˆ150ğœ‡ğ‘ for NAND SSD.\nInstead, it requires only a few fast (around 10ns) in-cache lookups.\nBased on \"the power of two random choices\" [ 37], Cuckoo Hash-\ning consists of two hash tables ğ‘‡1[1..ğ‘€]andğ‘‡2[1..ğ‘€], allowing\nan itemğ‘’to have two potential mapping locations ğ‘‡1[h1(ğ‘’)]and\nğ‘‡2[h2(ğ‘’)]. Each item can only occupy one location at a time, but\ncan swap between the two if its prior location is taken. To insert\nan itemğ‘’, we first attempt to place it into ğ‘‡1[h1(ğ‘’)]. Ifğ‘‡1[h1(ğ‘’)]is\nalready occupied by another item ğ‘’â€², we evictğ‘’â€²and reinsert it into\nğ‘‡2[h2(ğ‘’â€²)]. We repeat this process until all items stabilize. If this is\nimpossible, we reconstruct the cuckoo hash table with a new hash\n12For example, when ğœ”=3, the dataset may have (expected) 1 character â€˜ aâ€™, 3 character\nâ€˜bâ€™, 9 characterâ€˜ câ€™, and 27 character â€˜ dâ€™, etc.\n10\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\nseed. The literature shows that the insertion failure probability is\nğ‘‚(1/ğ‘€)when the occupancy (load factor ğ‘Ÿ) is less than 1/2âˆ’ğœ€.\nHowever, to query an item, we often check both of the two hash\ntables, which can result in significant latency penalties.\nA well known solution to reduce the number of memory accesses\nfor Cuckoo Hashing is to use a pre-filter, such as a Bloom Filter [ 28]\nor Counting Bloom Filter13[39], to predict the mapped locations\nof each item. However, false predictions by the pre-filter can cause\nadditional memory accesses. To address this problem, EMOMA\n[40] adds a 1(block):1(bucket) pre-Counting Block Bloom Filter\nthat corresponds to the first hash table, and locks certain items in\nthe second hash table to prevent movements that may cause false\npositives. This creates an always-exact hash predictor that supports\nline-rate processing (e.g. in programmable switches or FPGAs) at\nthe expense of complex insertion process and space overhead.\ntrue items (ğ’®ğ’® ) false items (ğ’°ğ’° \\ğ’®ğ’®)\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±0\nfirst scheme filtersâ‘ \nâ‘¡\nâ‘¢\nstep numâ‘ â‘¡â‘¢insert\nquery\nx\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±=â„±0\nfirst scheme filtersâ‘ \nâ‘¡\nâ‘¢\nâ‘ â‘¡â‘¢\nstep num .insert\nquerypositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\npredict mapped locations\ntrainthe hash predictorHash \nPredictorHash \nTables\nNew SSTable keysChainedFilters\nInsert positive items\nexclude negative items\nkey to be queried\n...\nğ‘—ğ‘—1 ğ‘—ğ‘—ğ‘™ğ‘™ ğ‘—ğ‘—ğ‘™ğ‘™âˆ’1... ... ...\nğ‘—ğ‘—ğ‘˜ğ‘˜ ğ‘—ğ‘—ğ‘™ğ‘™+1\nkey exists false positives(a)\n(b)    (1â‰¤ğ‘—ğ‘—1<â‹¯<ğ‘—ğ‘—ğ‘˜ğ‘˜â‰¤ğ‘ğ‘)1 2 3 4\n|ğ’³ğ’³â„±|=3,ğ’®ğ’®=2â„± |ğ‘“ğ‘“âˆ’1â„±|=3ğ’°ğ’°=8pos\nnegfalse pos\n{1,3}{2,3}} {1,2}\nğ’³ğ’³â„±\\ğ’®ğ’®={3} {2} {1}ğ‘“ğ‘“âˆ’1â„±âŠ‚{ , ,\nâ„±=\nâ„±âˆˆFğ’®ğ’®âˆˆS12 million items\n16million itemspositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\nfirst scheme       (â„± 1)\nsecond scheme (â„±2)false positive items ( ğ’®ğ’®ğ’®\\ğ’®ğ’®)â‘ \nâ‘¡â‘¢\nstep num.â‘ â‘¡â‘¢insert\nquery â‘¢\nFigure 9: The concept of the self-adaptive hashing.\n5.3.2 Modeling .Instead of supporting absolute exact matches,\nwe use ChainedFilter (\" &âˆ¼\" version, Algorithm 2 ) as a pre-filter\nto predict the mapped locations with best effort. Our key idea is to\nlet false predictions train the predictor to reduce errors ( Figure\n9). Specifically, we regard items in the first hash table as negative\nand those in the second hash table as positive. To query an item ğ‘’,\nwe ask ChainedFilter for the predicted location. If the prediction\nis incorrect, we adjust ChainedFilter by flipping the mapped bits\ninF1,F2,F3,...to 1 until ChainedFilter can accurately predict the\nlocations of ğ‘’. In the Remark ofTheorem 4.3 , we have proved\nthat the error rate will ultimately converge to zero as long as the\nspace cost of is greater than ğ¶â€²ğ‘›(logğœ†âˆ’((1+ğ›¿)/(1âˆ’ğ›¿))logğ›¿).\nNext we show how to choose the negative-positive ratio ğœ†.\nTheorem 5.2. Given the expected number of items |U|and the\nnumber of buckets in the Cuckoo hash table, 2ğ‘€, we defineğ‘Ÿ:=\n|U|/ 2ğ‘€<1/2âˆ’ğœ€is the load factor. Then we have\nğœ†=\u00122ğ‘Ÿ\n1âˆ’ğ‘’âˆ’2ğ‘Ÿâˆ’1\u0013âˆ’1\n+ğ‘œ(1).\nProof. Letğœ‚be the number of negative items (items in the first\nhash table). A new item can either insert into an empty location in\nthe first hash table, increasing ğœ‚by one, or evict an old item with\nprobabilityğœ‚/ğ‘€(assuming no insertion failures). This problem can\nbe reformulated as the well-known coupon collectorâ€™s problem,\nwhereğ‘€is the number of coupons and ğœ‚is the number of draws.\nTherefore, we have\n2ğ‘Ÿ=ğ‘€âˆ‘ï¸\nğ‘™=ğ‘€âˆ’ğœ‚1\nğ‘™+ğ‘œ(1)=1âˆ«\n1âˆ’ğœ‚/ğ‘€1\nğ‘¥dğ‘¥+ğ‘œ(1)=ln\u0010\n1âˆ’ğœ‚\nğ‘€\u0011\n+ğ‘œ(1)\nâ‡’ğœ†:=ğœ‚\n2ğ‘Ÿğ‘€âˆ’ğœ‚=\u00122ğ‘Ÿ\n1âˆ’ğ‘’âˆ’2ğ‘Ÿâˆ’1\u0013âˆ’1\n+ğ‘œ(1).\n13The Counting Bloom Filter replaces every bit to a counter to support deletion of\nexisting items. It is called Counting Block Bloom Filter [ 38] if we further restrict all\nmapped bits in the same block.â–¡\nRemark. According to Theorem 5.2 and the Remark ofSection\n4.3.2 , whenğ›¿=1/2, ChainedFilter incurs a space cost of no more than\nğ¶â€²ğ‘›log16ğœ†=2ğ¶â€²ğ‘Ÿ/(ğœ†+1)log16ğœ†Â·ğ‘€bits. In contrast, the Counting\nBlock Bloom Filter of EMOMA [ 40] costs 8ğ‘€bits if every block has two\n4-bit counters. In the following experiments, we fix the Cuckoo hash\ntable size 2ğ‘€to 1 million. Table 3 shows the space cost (measured in\nMb) of ChainedFilter ( ğ›¿=1/2) and EMOMA when ğ‘Ÿâˆˆ[0.1,0.4](for\nreasonable comparison, the space cost of Bloom Filter equals to that of\nEMOMA). We observe that ChainedFilter is much more space-efficient:\nit saves 76.7%(r=0.4)âˆ¼99.75% (r=0.1) space of EMOMA to predict\nexact locations.\nSpaceğ‘Ÿ0.10 0.15 0.20 0.25 0.30 0.35 0.40\nEMOMA 4.00 4.00 4.00 4.00 4.00 4.00 4.00\nChainedFilter 0.10 0.20 0.32 0.45 0.60 0.76 0.93\nTable 3: Filter space of EMOMA and ChainedFilter.\n5.3.3 Experiments .In the first experiment, we show that al-\nthough ChainedFilter may not initially predict the mapped locations\nabsolutely exactly, its error rate decreases exponentially and can\nquickly converge to zero. To verify this, we set ğ‘Ÿ=0.4and query\nall items in order for ğ‘…rounds to train the ChainedFilter and show\nthe change in error rate in Figure 13 (a) . We find that only 0.34%\nitems are wrongly predicted after three rounds of training, and all\nitems are exactly predicted after seven rounds of training, resulting\nin a reduction of(ğœ†+1)âˆ’1|ğ‘Ÿ=0.4=31%external memory access for\nCuckoo Hashing. To further accelerate the training process, we in-\nsert all items of the âŒŠlog logğ‘›âŒ‹=4-th layerF4into an Othello hash\ntable [ 26] according to the Remark ofSection 4.3.2 , so that the\ntraining process can be completed in four rounds (â€œChainedFilter-\noptimizedâ€ in Figure 13 ). In the second experiment, we use keys\nof length 36 bytes and values of length 64 bytes and compare the\nthroughput of raw Cuckoo Hashing, Cuckoo Hashing with Chained-\nFilter, with EMOMA, and with Bloom Filter ( Figure 13 (b) ). We find\nthat although ChainedFilter uses only 23.3%of the filter space of\nEMOMA, its average construction and query throughput is 17% and\n41% faster, respectively. It is interesting to note that both Cuckoo\nHashing with EMOMA and Cuckoo Hashing with Bloom Filter ex-\nhibit slower query throughput compared to raw Cuckoo Hashing,\npossibly due to their higher hash computation overhead.\n5.4 Point Query for LSM-Tree\nIn the final application, we utilize ChainedFilter to reduce the\ntail point query latency of LSM-Tree.\n5.4.1 Background .LSM-Tree (short for log-structured merge-\ntree) is a storage system for high write-throughput of key-value\npairs. It uses an in-memory data structure called memtable to buffer\nall updates until it is full, and then flushes the contents into the\npersistent storage as a sorted run through a process called minor\ncompaction. However, since the sorted runs may have overlapping\nkey ranges, LSM-Tree has to check all of them for a point query,\n11\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\n0 2 4 6 8\n/glyph1197umber of Rounds-\n-16-12-8-4log(Error Rate)\n(a)Raw Cuckoo\nChainedFilter-basic\nChainedFilter-optimized\nEMOMA\nBloom Filter\nRaw\n Cuckoo\nChainedFilter-basicChainedFilter    -optimizedEMOMA\nBloom Filter123 Throughput (Mops)\n(b)Construction\nQuery\nFigure 10: Error rate and throughput of raw Cuckoo Hash-\ning, Cuckoo Hashing with ChainedFilter (0.93Mb), with\nEMOMA (4Mb), and with Bloom Filter (4Mb).\nwhich can result in poor query performance. To address this prob-\nlem, LSM-Tree uses a hierarchical merging process called major\ncompaction to merge sorted runs14. In tiered major compaction,\nthe LSM-Tree is organized as a sequence of levels, and the number\nof runs in each level is bounded by a threshold ğ‘‡. If the number\nachieves the threshold, the compaction process is triggered to merge\nallğ‘‡sorted runs a new sorted run (SSTable) in the next level. To\nfurther speed up point queries, each SSTable typically has an ap-\nproximate filter, such as a Bloom Filter, to skip most non-existing\nitems. However, since the approximate filter has false positives,\nin the worst case, a point query still needs to check all SSTables,\nresulting in poor tail point query latency.\ntrue items (ğ’®ğ’® ) false items (ğ’°ğ’° \\ğ’®ğ’®)\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±0\nfirst scheme filtersâ‘ \nâ‘¡\nâ‘¢\nstep numâ‘ â‘¡â‘¢insert\nquery\nx\n...â„±1\nâ„±2\nâ„±3\nâ„±2â„±1â„±=â„±0\nfirst scheme filtersâ‘ \nâ‘¡\nâ‘¢\nâ‘ â‘¡â‘¢\nstep num .insert\nquerypositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\npredict mapped locations\nadjust the hash predictorHash \nPredictorHash \nTables\nNew SSTable keysChainedFilters\nInsert positive items\nexclude negative items\nkey to be queried\n...\nğ‘—ğ‘—1 ğ‘—ğ‘—ğ‘™ğ‘™ ğ‘—ğ‘—ğ‘™ğ‘™âˆ’1... ... ...\nğ‘—ğ‘—ğ‘˜ğ‘˜ ğ‘—ğ‘—ğ‘™ğ‘™+1\nkey exists false positives(a)\n(b)    (1â‰¤ğ‘—ğ‘—1<â‹¯<ğ‘—ğ‘—ğ‘˜ğ‘˜â‰¤ğ‘ğ‘)1 2 3 4\n|ğ’³ğ’³â„±|=3,ğ’®ğ’®=2â„± |ğ‘“ğ‘“âˆ’1â„±|=3ğ’°ğ’°=8pos\nnegfalse pos\n{1,3}{2,3}} {1,2}\nğ’³ğ’³â„±\\ğ’®ğ’®={3} {2} {1}ğ‘“ğ‘“âˆ’1â„±âŠ‚{ , ,\nâ„±=\nâ„±âˆˆFğ’®ğ’®âˆˆS12 million items\n16million itemspositive items ( ğ’®ğ’®) negative items ( ğ’°ğ’°\\ğ’®ğ’®)\nfirst scheme       (â„± 1)\nsecond scheme (â„±2)false positive items ( ğ’®ğ’®ğ’®\\ğ’®ğ’®)â‘ \nâ‘¡â‘¢\nstep num.â‘ â‘¡â‘¢insert\nquery â‘¢\nFigure 11: ChainedFilter (â€œ& versionâ€) for LSM-Tree. Note\nthat the second stage part must be a dynamic filter.\n5.4.2 Modeling .To reduce the latency, we replace every approx-\nimate filter with a dynamic exact ChainedFilter (â€œ&â€ version, Al-\ngorithm 1 andSection 4.3.1 ). Suppose there are ğ‘SSTables in\none level, our goal is to reduce the worst case additional SSTable\nsearch time from ğ‘to 1 (whether or not there are repeating items).\nOur key idea is, for ChainedFilter of the ğ‘–-th SSTable in this level,\nwe regard all keys in the ğ‘–-th SSTable as positive items, and regard\nall other keys in the (ğ‘–+1),(ğ‘–+2),...,ğ‘ -th SSTables (but not in\ntheğ‘–-th SSTable) as negative items ( Figure 11 (a) ). In this way,\nan exact ChainedFilter says â€œyesâ€ only when (1) the queried key\nis in its corresponding SSTable, (2) the queried key is not in the\n14The most commonly used compaction strategies are leveled compaction and tiered\ncompaction. The leveled compaction minimizes space amplification at the expense of\nread and write amplification, while the tiered compaction minimizes write amplification\nat the cost of read and space amplification. Here we only focus on the tiered compaction.subsequent(ğ‘–+1),(ğ‘–+2),...,ğ‘ -th SSTables in the same level (other-\nwise the key must be excluded when the later SSTables are formed).\nConsider the case where the ğ‘—1<ğ‘—2<...<ğ‘—ğ‘˜-th ChainedFilters\nreport â€œyesâ€. Our strategy is to check the corresponding SSTables\nin order until we find a false positive SSTable (note that the item\nkeys are repeatable). Once we detect that the ğ‘—ğ‘™-th ChainedFilterâ€™s\nresult is a false positive, we can assert that all the ğ‘—ğ‘™+1,ğ‘—ğ‘™+2,...,ğ‘—ğ‘˜-th\nChainedFilterâ€™s results are false positives as well ( Figure 11 (b) ).\nTherefore, the number of additional SSTable searches in this level\nis no more than one.\n5.4.3 Experiments .We measure the tail point query latency of\nour approach in RocksDB database [ 15] by replacing the built-in\nBloom Filter with the ChainedFilter. To simplify the implementa-\ntion, we let all SSTables stay in the first level ( L0) and use the default\n64MB write buffer size15. We reuse the built-in Bloom Filter as the\nfirst stage of ChainedFilter, but additionally implement an Othello\nhash table as the dynamic second stage filter. When creating a new\nSSTable after a compaction, we generate the Bloom Filter as what\nRocksDB does, but additionally query its keys in prior SSTables in\nthe same level and update the false positive SSTablesâ€™ ChainedFil-\nters by including the false positive items into the second stage filter\n(Figure 11 (a) ). When querying an item, we check the positive\nSSTables (whose Bloom Filter reports â€œyesâ€) in order. Once we find\na false positive one, we can assert that all later possible SSTables\nare false positives ( Figure 11 (b) ).\nChainedFilter Bloom Filter\nn|U|=4 mill. |U|=8 mill.\n(a) Query Existing Items\n(b) Query Non-Existing Items\nLatency (Î¼s)\n|U|=12 mill. |U|=16 mill.P70 P99 P70 P99 P70 P99 P70 P9912 15 17 920 24 26 1528 33 35 21128 180 252 72Latency (Î¼s)\n|U|=12 mill. |U|=16 mill.P70 P99 P70 P99 P70 P99 P70 P995 8 10 314 17 20 1123 26 30 19144 180 260 64\nn|U|=4 mill. |U|=8 mill.No Filter Bloom Filter (2Ã—)\nFigure 12: Tail point query latency in RocksDB.\nFigure 12 demonstrates that ChainedFilter can significantly re-\nduce the tail point query latency of LSM-Tree. We generate items\nwith distinct 36-Byte random keys and 64-Byte values and vary\nthe number of items |U|from 4 million (400MB data, 7 SSTables\nin total) to 16 million (1.6GB data, 30 SSTables in total). The filter\nspace of ChainedFilter just allows it to exactly classify positive\nand negative items. We use RocksDB with only Bloom Filters with\nthe0Ã—,1Ã—,and2Ã—filter space as the comparison algorithm (â€œ 0Ã—â€\n15RocksDB stores temporal write operations in memtable and flushes it to disk to\ngenerate an SSTable file in L0when its size reaches the write buffer size.\n12\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\nmeans no filter). In Figure 12 (a) , we show the tail latency of query-\ning existing items16. Let us consider the â€œ |U|=16 mill. â€ sub-figure\nas an example. The green area in the figure shows the tail point\nquery latency using only built-in Bloom Filter which costs the same\nspace as ChainedFilter. The P0-P77 ,P77-P95 , and P95-P99 tail la-\ntency approximately represents the query latency with zero, one,\nand more than one false positive SSTable reads. In the worst case,\nwith many false positive SSTable reads, the P99tail point query la-\ntency is about 31ğœ‡ğ‘ . In contrast, as shown in the blue area, the query\nprocess using ChainedFilter has no false positive when querying\nexisting items, so the tail latency remains under 20ğœ‡ğ‘ , which is 36%\nlower. In Figure 12 (b) , we show the tail latency of querying non-\nexisting items. We find that when |U|is 16 million, the latency with\nChainedFilter gradually increases. This is because the latency is not\nonly determined by the number of false positive SSTables, but is\nalso influenced by the index of the false positive ChainedFilter. For\nexample, if the first SSTable reports a false positive, the algorithm\ncan quickly return, and thus the overall latency may be even lower\nthan 12ğœ‡ğ‘ . However, if the 30-th SSTable is the first one to report\nfalse positive, the overall latency will be more than 18ğœ‡ğ‘ .\n5.5 Learned Filter\nIn this part, we use ChainedFilter to reduce the false positive\nrate of Learned Filters.\n5.5.1 Background .Although our space lower bound ( Section\n2.2) assumes that the positive items are randomly drawn from the\nuniverse, further compression can be achieved when the items fol-\nlow a specific data distribution. Learned Filters [ 16â€“19] incorporate\na continuous function, such as an RNN model, in front of the fil-\nter structure to capture the data distribution. When querying an\nitem, if the continuous function outputs â€œyesâ€, the Learned Filter\nimmediately reports true. However, when the continuous function\noutputs â€œnoâ€, the item is sent to a backup Bloom Filter to eliminate\nfalse negatives. In the learned filter structure, both the learning\nmodel and the backup filter may introduce false positives, but in\nsome cases, the overall false positive rate even decreases.\n5.5.2 Experiments .Extending the chain rule ( Theorem 2.2 ) to\ngeneral membership problems with different data distributions is\nan intriguing problem17. Since we havenâ€™t derive an elegant theory\nat this moment, we empirically replace the backup Bloom Filter\n/ Bloomier Filter with our ChainedFilter (â€œ&â€ version) to show\nthe experimental improvements. We refer to the open-source code\nof the learned Bloom Filter and the dataset on GitHub [ 42]. The\ndataset has 30,000 positive (good) and 30,000 negative (bad) websites\nevaluated by users. In this experiment, we randomly select different\nproportions (ranging from 0%to100% ) of data to train the RNN\nmodel. Generally, the modelâ€™s generalization ability improves as\nthe amount of training data increases. Experimental results show\nthat when we fix the overall false positive rate at 0.0118, the filter\n16Since all existing keys are different, we end the query process once we find an item.\n17An analogy is, some machine learning algorithms like Boosting [ 41] combine multi-\nstage elementary classifiers to work together, which seem similar to ChainedFilter.\n18For Learned ChainedFilter and Learned Bloomier Filter, we set the false positive rate\nof the RNN model to 0.01, and the false positive rate of the backup filter to zero. For\nLearned Bloom Filer, we set the false positive rate of both the RNN model and the\nbackup filter to 0.005.space of Learned ChainedFilter can be up to 99.1% lower than that\nof Learned Bloom Filter and 96.2% lower than ğ‘›ğ‘“(ğœ–,ğœ†)(the space\nlower bound without considering data distribution).\n0 25 50 75 100\nTraining Set (%)12141618log(Filter Space) (Mb)\nLearned Bloom Filter\nLearned Bloomier Filter\nLearned ChainedFilter\nnf(,)=30,000f(0.01,1)\nFigure 13: Filter space in bits ( logscale) of Learned Bloom\nFilter, Learned Bloomier Filter and Learned ChainedFilter.\n6 RELATED WORK\nFilter algorithms are the foundation of many important problems\n[43â€“53] and have been well studied. In this section, we introduce\nmore membership filters that may work as our elementary filters.\n6.1 Approximate Membership Filters\nApproximate filters originated with Bloom Filter [ 28] in 1970. A\nBloom Filter is a bitmap of size ğ‘šwhere every one of ğ‘›positive\nitems is mapped using ğ‘˜independent hash functions. To insert an\nitem, we set all mapped positions to one; To query an item, we\ncheck whether all mapped positions are one, and report positive iff\nthey are. A Bloom Filter satisfies one-sided error: a query is either\nâ€œdefinitely notâ€ (no false negative) or â€œprobably yesâ€ (small false\npositive). The false positive rate depends on the space cost\nğœ–= \n1âˆ’\u0012\n1âˆ’1\nğ‘š\u0013ğ‘›ğ‘˜!ğ‘˜\nâ‰ˆ\u0010\n1âˆ’ğ‘’âˆ’ğ‘›ğ‘˜\nğ‘š\u0011ğ‘˜\nâ‡’ğ‘šâ©¾ğ‘›log 1/ğœ–\nln 2.\nIn 1978, [ 13] gave the tight space lower bound ( log1/ğœ–+ğ‘œ(1)bits per\nitem) for approximate filters, which means the Bloom Filter wastes\nno more than 1/ln2âˆ’1=44%space. In 2010, [ 30] gave the space\nlower bound ğ¶(ğœ–)log1/ğœ–bits per item for dynamic approximate\ndata structures, where ğ¶(ğœ–)>1depends only on ğœ–. Many later\nworks have emerged to reduce the space overhead of Bloom Filter.\nCuckoo Filter (2014) [ 14] borrows the concept from Cuckoo Hashing\n(Background ofSection 5.3 ) and uses fingerprints for approximate\nclassification. It maps an item ğ‘’to two buckets â„(ğ‘’)and(â„(ğ‘’)âŠ•\nğ‘“(ğ‘’))in one hash table, and shows that the load factor can be up to\n95% if the buckets have four slots. Therefore, the space cost drops\nto1.05(2+log1/ğœ–)bits per item. Inspired by Bloomier filter and\nthe peeling theory, XOR Filter (2019) [ 23] and Binary Fuse Filter\n(2022) [ 24] achieves a space cost of ğ¶log1/ğœ–bits per item for static\nmembership query ( Remark ofSection 3 ). In fact, a more compact\nspace cost ((1+ğ‘œ(1))log1/ğœ–bits per item) is given by [ 54] (2008)\nand [ 55] (2009) for static membership query if we allow a more\ncomplex implementation.\n13\n\nSIGMODâ€™24, June 11-16, 2024, Santiago, Chile Haoyu Li, Liuhui Wang, Qizhi Chen, Jianan Ji, Yuhan Wu, Yikai Zhao, Tong Yang, and Aditya Akella\n6.2 Exact Membership Filters\nOne type of exact filters builds upon perfect hashing [ 56]. The\nBloomier Filter [ 21,22] (2004) is a milestone which requires 1.23\nbits per item (the theoretical result is excerpted from IBLT (2011)\n[10]). According to [ 25] (2021), this constant can be optimized to\nclose to 1 ( Remark ofSection 3 ). In fact, a more compact space\ncost of(1+ğ‘œ(1))bits per item is achievable if a more complex\nimplementation is allowed [ 54,55]. Othello Hashing [ 26] (2016) and\nColoring Embedder [ 27] (2021) provide dynamic perfect hashing\ndesigns with ğ‘‚(1)bits per item. However, they both need additional\nstructures with ğ›º(ğ‘›logğ‘›)space for construction and update.\nAnother one type of exact filters is called â€œdictionariesâ€. In 1984,\n[57] described a general constant-time hashing scheme (FKS dic-\ntionary) with a space complexity of ğ‘‚(ğ‘›)words (not bits). In 1994,\nresearchers designed an static exact filter with a space complexity of\nğ‘‚(ğµ)[58] (they later improved to ğµ(1+ğ‘‚(1/log log log|U|)) [59]\nin 1999) for static dictionary, where ğµ:=âŒˆlog\u0000|U|\nğ‘›\u0001âŒ‰is the lower\nbound for static membership problems [ 13]. In 2001, the space com-\nplexity is optimized to nearly optimal ( ğµ+ğ‘‚(log log(|U|))+ğ‘œ(ğ‘›)\nbits) [ 60]. In 2010, [ 29] proofs the lower bound (1+ğ‘œ(1))ğµalso holds\nfor dynamic exact membership filters. Nowadays, the research on\nexact membership problems is still on going [61].\nIn the end, we list some other membership filters satisfying\nspecial properties. In 2005, [ 62] started considers dynamic general\nmembership problems and designed a membership filter with a\nspace complexity of ((1+ğ‘œ(1))ğ‘›log1/ğœ–+ğ‘‚(ğ‘›+log|U|) bits for\narbitraryğœ–andğœ†. Since 2018, researchers have creatively introduced\nmachine learning methodology to construct Learned Bloom Filters\n[16â€“19], or add pre-filters to construct membership algorithms [ 35],\nwhich are more accurate than the original Bloom Filter.\n7 CONCLUSION\nIn this paper, we present a lossless factorization theorem, namely\nchain rule, for solving general membership query problems. Based\non this theorem, we propose a simple yet space-efficient filter frame-\nwork called ChainedFilter and apply it to various applications. Both\ntheoretical and experimental results show that the ChainedFilter\noutperforms its elementary filters. We believe our chain rule can\ninspire more innovative works, and our ChainedFilter can be used\nin more practical applications.\nACKNOWLEDGEMENT\nWe thank to Maria Apostolaki (Princeton University) and Jiarui\nGuo (Peking University) for valuable comments of this work.\nREFERENCES\n[1]Sasu Tarkoma, Christian Esteve Rothenberg, and Eemil Lagerspetz. Theory and\npractice of bloom filters for distributed systems. IEEE Communications Surveys &\nTutorials , 14(1):131â€“155, 2011.\n[2]Andrei Broder and Michael Mitzenmacher. Network applications of bloom filters:\nA survey. Internet mathematics , 1(4):485â€“509, 2004.\n[3]Shahabeddin Geravand and Mahmood Ahmadi. Bloom filter applications in\nnetwork security: A state-of-the-art survey. Computer Networks , 57(18):4047â€“\n4064, 2013.\n[4]Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C Hsieh, Deborah A Wallach,\nMike Burrows, Tushar Chandra, Andrew Fikes, and Robert E Gruber. Bigtable: A\ndistributed storage system for structured data. ACM Transactions on Computer\nSystems (TOCS) , 26(2):1â€“26, 2008.\n[5]Niv Dayan, Manos Athanassoulis, and Stratos Idreos. Optimal bloom filters and\nadaptive merging for lsm-trees. ACM Transactions on Database Systems (TODS) ,43(4):1â€“48, 2018.\n[6]Yoshinori Matsunobu, Siying Dong, and Herman Lee. Myrocks: Lsm-tree data-\nbase storage engine serving facebookâ€™s social graph. Proceedings of the VLDB\nEndowment , 13(12):3217â€“3230, 2020.\n[7]Sarang Dharmapurikar, Haoyu Song, Jonathan Turner, and John Lockwood. Fast\npacket classification using bloom filters. In Proceedings of the 2006 ACM/IEEE\nsymposium on Architecture for networking and communications systems , pages\n61â€“70, 2006.\n[8]Dan Li, Henggang Cui, Yan Hu, Yong Xia, and Xin Wang. Scalable data center\nmulticast using multi-class bloom filter. In 2011 19th IEEE international conference\non network protocols , pages 266â€“275. IEEE, 2011.\n[9]Pedro Reviriego, Jorge MartÃ­nez, David Larrabeiti, and Salvatore Pontarelli.\nCuckoo filters and bloom filters: Comparison and application to packet classifi-\ncation. IEEE Transactions on Network and Service Management , 17(4):2690â€“2701,\n2020.\n[10] Michael T Goodrich and Michael Mitzenmacher. Invertible bloom lookup ta-\nbles. In 2011 49th Annual Allerton Conference on Communication, Control, and\nComputing (Allerton) , pages 792â€“799. IEEE, 2011.\n[11] A Pinar Ozisik, Gavin Andresen, Brian N Levine, Darren Tapp, George Bissias,\nand Sunny Katkuri. Graphene: efficient interactive set reconciliation applied to\nblockchain propagation. In Proceedings of the ACM Special Interest Group on Data\nCommunication , pages 303â€“317. 2019.\n[12] Muhammad Anas Imtiaz, David Starobinski, Ari Trachtenberg, and Nabeel You-\nnis. Churn in the bitcoin network: Characterization and impact. In 2019 IEEE\nInternational Conference on Blockchain and Cryptocurrency (ICBC) , pages 431â€“439.\nIEEE, 2019.\n[13] Larry Carter, Robert Floyd, John Gill, George Markowsky, and Mark Wegman.\nExact and approximate membership testers. In Proceedings of the tenth annual\nACM symposium on Theory of computing , pages 59â€“65, 1978.\n[14] Bin Fan, Dave G Andersen, Michael Kaminsky, and Michael D Mitzenmacher.\nCuckoo filter: Practically better than bloom. In Proceedings of the 10th ACM\nInternational on Conference on emerging Networking Experiments and Technologies ,\npages 75â€“88, 2014.\n[15] Siying Dong, Andrew Kryczka, Yanqin Jin, and Michael Stumm. Rocksdb: Evolu-\ntion of development priorities in a key-value store serving large-scale applications.\nACM Transactions on Storage (TOS) , 17(4):1â€“32, 2021.\n[16] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case\nfor learned index structures. In Proceedings of the 2018 international conference\non management of data , pages 489â€“504, 2018.\n[17] Michael Mitzenmacher. A model for learned bloom filters and optimizing by\nsandwiching. Advances in Neural Information Processing Systems , 31, 2018.\n[18] Qiyu Liu, Libin Zheng, Yanyan Shen, and Lei Chen. Stable learned bloom filters\nfor data streams. Proceedings of the VLDB Endowment , 13(12):2355â€“2367, 2020.\n[19] Zhenwei Dai and Anshumali Shrivastava. Adaptive learned bloom filter (ada-bf):\nefficient utilization of the classifier with application to real-time information\nfiltering on the web. Advances in Neural Information Processing Systems , 33:11700â€“\n11710, 2020.\n[20] The open source code of chainedfilter. https://github.com/ChainedFilter.\n[21] Bernard Chazelle, Joe Kilian, Ronitt Rubinfeld, and Ayellet Tal. The bloomier\nfilter: an efficient data structure for static support lookup tables. In Proceedings of\nthe fifteenth annual ACM-SIAM symposium on Discrete algorithms , pages 30â€“39.\nCiteseer, 2004.\n[22] Denis Charles and Kumar Chellapilla. Bloomier filters: A second look. In\nAlgorithms-ESA 2008: 16th Annual European Symposium, Karlsruhe, Germany,\nSeptember 15-17, 2008. Proceedings 16 , pages 259â€“270. Springer, 2008.\n[23] Thomas Mueller Graf and Daniel Lemire. Xor filters: Faster and smaller than\nbloom and cuckoo filters. Journal of Experimental Algorithmics (JEA) , 25:1â€“16,\n2020.\n[24] Thomas Mueller Graf and Daniel Lemire. Binary fuse filters: Fast and smaller\nthan xor filters. Journal of Experimental Algorithmics (JEA) , 27(1):1â€“15, 2022.\n[25] Stefan Walzer. Peeling close to the orientability thresholdâ€“spatial coupling in\nhashing-based data structures. In Proceedings of the 2021 ACM-SIAM Symposium\non Discrete Algorithms (SODA) , pages 2194â€“2211. SIAM, 2021.\n[26] Ye Yu, Djamal Belazzougui, Chen Qian, and Qin Zhang. Memory-efficient and\nultra-fast network lookup and forwarding using othello hashing. IEEE/ACM\nTransactions on Networking , 26(3):1151â€“1164, 2018.\n[27] Yang Tong, Dongsheng Yang, Jie Jiang, Siang Gao, Bin Cui, Lei Shi, and Xiaoming\nLi. Coloring embedder: A memory efficient data structure for answering multi-set\nquery. In 2019 IEEE 35th International Conference on Data Engineering (ICDE) ,\npages 1142â€“1153. IEEE, 2019.\n[28] Burton H Bloom. Space/time trade-offs in hash coding with allowable errors.\nCommunications of the ACM , 13(7):422â€“426, 1970.\n[29] Yuriy Arbitman, Moni Naor, and Gil Segev. Backyard cuckoo hashing: Constant\nworst-case operations with a succinct representation. In 2010 IEEE 51st Annual\nsymposium on foundations of computer science , pages 787â€“796. IEEE, 2010.\n[30] Shachar Lovett and Ely Porat. A space lower bound for dynamic approximate\nmembership data structures. SIAM Journal on Computing , 42(6):2182â€“2196, 2013.\n14\n\nChainedFilter: Combining Membership Filters by Chain Rule SIGMODâ€™24, June 11-16, 2024, Santiago, Chile\n[31] Murmur hashing source code. https://github.com/aappleby/smhasher/blob/\nmaster/src/MurmurHash3.cpp.\n[32] David A Huffman. A method for the construction of minimum-redundancy codes.\nProceedings of the IRE , 40(9):1098â€“1101, 1952.\n[33] Jarek Duda. Asymmetric numeral systems: entropy coding combining speed\nof huffman coding with compression rate of arithmetic coding. arXiv preprint\narXiv:1311.2540 , 2013.\n[34] JÃ³hannes B Hreinsson, Morten KrÃ¸yer, and Rasmus Pagh. Storing a compressed\nfunction with constant time access. In Algorithms-ESA 2009: 17th Annual European\nSymposium, Copenhagen, Denmark, September 7-9, 2009. Proceedings 17 , pages\n730â€“741. Springer, 2009.\n[35] Pedro Reviriego, Alfonso SÃ¡nchez-MaciÃ¡n, Stefan Walzer, and Peter C Dillinger.\nApproximate membership query filters with a false positive free set. arXiv\npreprint arXiv:2111.06856 , 2021.\n[36] Rasmus Pagh and Flemming Friche Rodler. Cuckoo hashing. Journal of Algorithms ,\n51(2):122â€“144, 2004.\n[37] Michael Mitzenmacher. The power of two choices in randomized load balancing.\nIEEE Transactions on Parallel and Distributed Systems , 12(10):1094â€“1104, 2001.\n[38] Udi Manber and Sun Wu. An algorithm for approximate membership checking\nwith application to password security. Information Processing Letters , 50(4):191â€“\n197, 1994.\n[39] Li Fan, Pei Cao, Jussara Almeida, and Andrei Z Broder. Summary cache: a scalable\nwide-area web cache sharing protocol. IEEE/ACM transactions on networking ,\n8(3):281â€“293, 2000.\n[40] Salvatore Pontarelli, Pedro Reviriego, and Michael Mitzenmacher. Emoma: Ex-\nact match in one memory access. IEEE Transactions on Knowledge and Data\nEngineering , 30(11):2120â€“2133, 2018.\n[41] Yoav Freund, Robert Schapire, and Naoki Abe. A short introduction to boosting.\nJournal-Japanese Society For Artificial Intelligence , 14(771-780):1612, 1999.\n[42] The open source code of learned filter. https://github.com/karthikeya20/Learned-\nBloom-Filters.\n[43] Yuhan Wu, Jintao He, Shen Yan, Jianyu Wu, Tong Yang, Olivier Ruas, Gong\nZhang, and Bin Cui. Elastic bloom filter: deletable and expandable filter using\nelastic fingerprints. IEEE Transactions on Computers , 71(4):984â€“991, 2021.\n[44] Zhuochen Fan, Yubo Zhang, Siyuan Dong, Yi Zhou, Fangyi Liu, Tong Yang, Steve\nUhlig, and Bin Cui. Hoppingsketch: More accurate temporal membership query\nand frequency query. IEEE Transactions on Knowledge and Data Engineering ,\n35(9):9067â€“9072, 2023.\n[45] Haoyu Li, Qizhi Chen, Yixin Zhang, Tong Yang, and Bin Cui. Stingy sketch: A\nsketch framework for accurate and fast frequency estimation. Proc. VLDB Endow. ,\n15(7):1426â€“1438, mar 2022.\n[46] Yuanpeng Li, Feiyu Wang, Xiang Yu, Yilong Yang, Kaicheng Yang, Tong Yang,\nZhuo Ma, Bin Cui, and Steve Uhlig. Ladderfilter: Filtering infrequent items with\nsmall memory and time overhead. Proceedings of the ACM on Management of\nData , 1(1):1â€“21, 2023.\n[47] Jiarui Guo, Yisen Hong, Yuhan Wu, Yunfei Liu, Tong Yang, and Bin Cui. Sketch-\npolymer: Estimate per-item tail quantile using one sketch. In Proceedings of the\n29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , pages590â€“601, 2023.\n[48] Ziwei Wang, Zheng Zhong, Jiarui Guo, Yuhan Wu, Haoyu Li, Tong Yang, Yaofeng\nTu, Huanchen Zhang, and Bin Cui. Rencoder: A space-time efficient range filter\nwith local encoder. In 2023 IEEE 39th International Conference on Data Engineering\n(ICDE) , pages 2036â€“2049, 2023.\n[49] Hun Namkung, Zaoxing Liu, Daehyeok Kim, Vyas Sekar, and Peter Steenkiste.\n{SketchLib}: Enabling efficient sketch-based monitoring on programmable\nswitches. In 19th USENIX Symposium on Networked Systems Design and Im-\nplementation (NSDI 22) , pages 743â€“759, 2022.\n[50] Xiaodong Li, Zhuochen Fan, Haoyu Li, Zheng Zhong, Jiarui Guo, Sheng Long,\nTong Yang, and Bin Cui. Steadysketch: Finding steady flows in data streams.\nIn2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS) ,\npages 01â€“09. IEEE, 2023.\n[51] Zhuochen Fan, Gang Wen, Zhipeng Huang, Yang Zhou, Qiaobin Fu, Tong Yang,\nAlex X Liu, and Bin Cui. On the evolutionary of bloom filter false positives-an\ninformation theoretical approach to optimizing bloom filter parameters. IEEE\nTransactions on Knowledge and Data Engineering , 2022.\n[52] Hun Namkung, Zaoxing Liu, Daehyeok Kim, Vyas Sekar, and Peter Steenkiste.\nSketchovsky: Enabling ensembles of sketches on programmable switches. In\n20th USENIX Symposium on Networked Systems Design and Implementation (NSDI\n23), pages 1273â€“1292, 2023.\n[53] Zirui Liu, Chaozhe Kong, Kaicheng Yang, Tong Yang, Ruijie Miao, Qizhi Chen,\nYikai Zhao, Yaofeng Tu, and Bin Cui. Hypercalm sketch: One-pass mining\nperiodic batches in data streams.\n[54] Martin Dietzfelbinger and Rasmus Pagh. Succinct data structures for retrieval and\napproximate membership. In Automata, Languages and Programming: 35th Inter-\nnational Colloquium, ICALP 2008, Reykjavik, Iceland, July 7-11, 2008, Proceedings,\nPart I 35 , pages 385â€“396. Springer, 2008.\n[55] Ely Porat. An optimal bloom filter replacement based on matrix solving. In\nComputer Science-Theory and Applications: Fourth International Computer Science\nSymposium in Russia, CSR 2009, Novosibirsk, Russia, August 18-23, 2009. Proceedings\n4, pages 263â€“273. Springer, 2009.\n[56] Bohdan S Majewski, Nicholas C Wormald, George Havas, and Zbigniew J Czech.\nA family of perfect hashing methods. The Computer Journal , 39(6):547â€“554, 1996.\n[57] Michael L Fredman, JÃ¡nos KomlÃ³s, and Endre SzemerÃ©di. Storing a sparse table\nwith 0 (1) worst case access time. Journal of the ACM (JACM) , 31(3):538â€“544,\n1984.\n[58] Andrej Brodnik and J Ian Munro. Membership in constant time and minimum\nspace. In Algorithmsâ€”ESAâ€™94: Second Annual European Symposium Utrecht, The\nNetherlands, September 26â€“28, 1994 Proceedings 2 , pages 72â€“81. Springer, 1994.\n[59] Andrej Brodnik and J Ian Munro. Membership in constant time and almost-\nminimum space. SIAM Journal on computing , 28(5):1627â€“1640, 1999.\n[60] Rasmus Pagh. Low redundancy in static dictionaries with constant query time.\nSIAM Journal on Computing , 31(2):353â€“363, 2001.\n[61] Ioana Oriana Bercea and Guy Even. A space-efficient dynamic dictionary for\nmultisets with constant time operations. arXiv preprint arXiv:2005.02143 , 2020.\n[62] Anna Pagh, Rasmus Pagh, and S Srinivasa Rao. An optimal bloom filter replace-\nment. In Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete\nalgorithms , pages 823â€“829, 2005.\n15",
  "textLength": 84450
}