{
  "paperId": "281edeed7e6dee5473c4f8d0dbf600cdf4b822cb",
  "title": "Learned Monotone Minimal Perfect Hashing",
  "pdfPath": "281edeed7e6dee5473c4f8d0dbf600cdf4b822cb.pdf",
  "text": "Learned Monotone Minimal Perfect Hashing\nPaolo Ferragina /envel⌢pe\nUniversity of Pisa, Italy\nHans-Peter Lehmann /envel⌢pe\nKarlsruhe Institute of Technology, Germany\nPeter Sanders /envel⌢pe\nKarlsruhe Institute of Technology, Germany\nGiorgio Vinciguerra /envel⌢pe\nUniversity of Pisa, Italy\nAbstract\nA Monotone Minimal Perfect Hash Function (MMPHF) constructed on a set Sof keys is a function\nthat maps each key in Sto its rank. On keys not in S, the function returns an arbitrary value.\nApplications range from databases, search engines, data encryption, to pattern-matching algorithms.\nIn this paper, we describe\n LeMonHash, a new technique for constructing MMPHFs for integers.\nThe core idea of LeMonHash is surprisingly simple and effective: we learn a monotone mapping\nfrom keys to their rank via an error-bounded piecewise linear model (the PGM-index), and then we\nsolve the collisions that might arise among keys mapping to the same rank estimate by associating\nsmall integers with them in a retrieval data structure (BuRR). On synthetic random datasets,\nLeMonHash needs 34% less space than the next larger competitor, while achieving about 16 times\nfaster queries. On real-world datasets, the space usage is very close to or much better than the\nbest competitors, while achieving up to 19 times faster queries than the next largercompetitor. As\nfar as the construction of LeMonHash is concerned, we get an improvement by a factor of up to 2,\ncompared to the competitor with the next best space usage.\nWe also investigate the case of keys being variable-length strings, introducing the so-called\nLeMonHash-VL: it needs space within 13% of the best competitors while achieving up to 3 times\nfaster queries than the next larger competitor.\n2012 ACM Subject Classification Theory of computation →Data compression; Information systems\n→Point lookups\nKeywords and phrases compressed data structure, monotone minimal perfect hashing, retrieval\nRelated Version An extended abstract of this paper appears in the Proceedings of the 31st Annual\nEuropean Symposium on Algorithms (ESA 2023) :https://doi.org/10.4230/LIPIcs.ESA.2023.46\nSupplementary Material Software (Source Code) :https://github.com/ByteHamster/LeMonHash\nFunding This project has received funding from the European Research Council (ERC) under the\nEuropean Union’s Horizon 2020 research and innovation programme (grant agreement No. 882500).\nPF and GV have been supported by the European Union – Horizon 2020 Program under the scheme\n“INFRAIA-01-2018-2019 – Integrating Activities for Advanced Communities”, Grant Agreement n.\n871042, “SoBigData++: European Integrated Infrastructure for Social Mining and Big Data Analyt-\nics” (http://www.sobigdata.eu), by the NextGenerationEU – National Recovery and Resilience Plan\n(Piano Nazionale di Ripresa e Resilienza, PNRR) – Project: “SoBigData.it – Strengthening the Italian\nRI for Social Mining and Big Data Analytics” – Prot. IR0000013 – Avviso n. 3264 del 28/12/2021, by\nthe spoke “FutureHPC & BigData” of the ICSC – Centro Nazionale di Ricerca in High-Performance\nComputing, Big Data and Quantum Computing funded by European Union – NextGenerationEU –\nPNRR, by the Italian Ministry of University and Research “Progetti di Rilevante Interesse Nazionale”\nproject: “Multicriteria data structures and algorithms” (grant n. 2017WR7SHH).\nAcknowledgements We thank Stefan Walzer for early discussions leading to this paper.arXiv:2304.11012v3  [cs.DS]  30 Aug 2023\n\n2 Learned Monotone Minimal Perfect Hashing\n1 Introduction\nGiven a set Sofnkeys drawn from a universe [u] ={0,...,u−1}, aMonotone Minimal\nPerfect Hash Function (MMPHF) is a hash function that maps keys from Sto their rank,\nand returns an arbitrary value for keys not in S. As the name suggests, such a function\nis both perfectbecause it has no collisions on S, and minimal because its output range is\n[n]. Differently from a Minimal Perfect Hash Function (MPHF) [4,13,18,27,41,43,45,51],\nwhich maps keys from Sbijectively to [n]in any order, and from an Order-Preserving MPHF\n(OPMPHF) [26], which retains a given (arbitrary) order on the keys, an MMPHF takes\nadvantage of the natural order of the universe to rank the keys in Sin small space, i.e. without\nencoding them. Indeed, encoding Sneeds log/parenleftbigu\nn/parenrightbig\n/n= Ω( logu\nn)bits per key, and encoding\nthe ranks via an OPMPHF needs log(n!)/n= Ω( logn)bits per key, whilst an MMPHF may\nuse as few asO(log log logu)bits per key [2], which was recently proven to be optimal [1].\nThroughout this paper, logxstands for log2x, and we use the w-bit word RAM model.\nMMPHFs have numerous applications [1]. They enable efficient queries both in encrypted\ndata [12] and databases [40,42]. Further applications can be found in information retrieval,\nwhere MMPHFs can be used to index the lexicon [55] or to compute term frequencies [7,47],\nand in pattern matching [5,28,33], where MMPHFs are applied mostly to integer sequences\nrepresenting the occurrences of certain characters in a text.\nDespite the widespread use of MMPHFs and recent advancements on their asymptotic\nbounds [1], the practical implementations have not made significant progress in terms of\nnew designs and improved space-time performance since their introduction more than a\ndecade ago [3], with only some exceptions targeting query time [34]. As a matter of fact, the\nsolutions in [3] are very sophisticated and well-optimised, and they offer a vast number of\nefficient space-time trade-offs that were hard to beat.\nIn this paper, we offer a fresh new perspective on MMPHFs that departs from existing\napproaches, which are mostly based on a trie-like data structure on the keys. We build upon\nrecent advances in (learning-based) indexing data structures, namely the PGM-index [21,25],\nand in retrieval data structures (or static functions), namely BuRR [15]. The former learns a\npiecewise linear approximation mapping keys in Sto their rank estimate. The latter allows\nassociating a small fixed-width integer to each key in S, without storing S. We combine these\ntwo seemingly unrelated data structures in a surprisingly simple and effective way. First, we\nuse the PGM to monotonically map keys to buckets according to their rank estimate, and we\nstore the global rank of each bucket’s first key in a compressed data structure. Second, since\nthe rank estimate of some keys might coincide, we solve such bucket collisions by storing the\nlocal ranks of these keys using BuRR. We call our proposal LeMonHash , because it learnsand\nleverages the smoothness of the input data to build a space-time efficient monotone MPHF.\nOn the theoretical side, this achieves O(1)bits per key for inputs which are sufficiently\nrandom within buckets—breaking the superlinear lower bound. Practically, on various\ninteger datasets tried, it needs about one-third less space than previous approaches and is an\norder of magnitude faster. We also extend LeMonHash to support variable-length string keys.\nThis approach needs space within 13% of the best competitors while being up to 3 ×faster.\nOutline. We first describe the basic building blocks of LeMonHash in Section 2 and discuss\nrelated work in Section 3. In Section 4, we describe LeMonHash for integers and then extend\nit to variable-length strings in Section 5. In Section 6, we discuss variants and refinements,\nbefore proving the space-time guarantees of LeMonHash in Section 7. In Section 8, we present\nour experiments. In Section 9, we summarise the paper and give an outlook for future work.\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 3\n2 Preliminaries\nIn this section, we describe the basic building blocks of LeMonHash.\nBit Vectors. Given a bit vector of size nandb∈{0,1}, the rankb(x)operation returns the\nnumber ofb-bits before position x, and the selectb(i)operation returns the position of the ith\nb-bit. These operations can be executed in constant time using as little as o(n)bits on top\nof the bit vector [14,35], and they have very space-time efficient implementations [31,39,53].\nElias-Fano. Elias-Fano Coding [17,19] is a way to efficiently store a non-decreasing sequence\nofnintegers over a universe of size u. An integer at position iis split into two parts. The\nlognupper bitsxare stored in a bit vector Has a 1-bit in H[i+x]. The remaining lower\nbits are directly stored in an array L. Integers can be accessed in constant time by finding\ntheith1-bit inHusing a select 1data structure and by looking up the lower bits in L.\nPredecessor queries are possible by determining the range of integers that share the same\nupper bits of the query key using two select 0queries, and then performing a binary search\non that range. If there are no duplicates, this binary search takes O/parenleftbig\nmin{logn,logu\nn}/parenrightbig\ntime.\nThe space usage of an Elias-Fano coded sequence is n⌈logu\nn⌉+ 2n+o(n)bits (see [48, §4.4]).\nPartitioned Elias-Fano [50] is an extension that uses dynamic programming to partition the\ninput into multiple independent Elias-Fano sequences to minimise the overall space usage.\nPGM-index. The PGM-index [25] is a space-efficient data structure for predecessor and\nrank queries on a sorted set of nkeys from an integer universe [u]. Given a query q∈[u],\nit computes a rank estimate that is guaranteed to be close to the correct rank by a given\ninteger parameter ε. If one stores the input keys, then the correct rank can be recovered\nvia anO(logε)-time binary search on 2ε+ 1keys around the rank estimate. The PGM\nis constructed in O(n)time by first mapping the sorted integers x1,...,xninSto points\n(x1,1),..., (xn,n)in a key-position Cartesian plane, and then learning a piecewise linear\nε-approximation of these points, i.e. a sequence of mlinear models each approximating the\nrank of the keys in a certain sub-range of [u]with a maximum absolute error ε. The value m,\nwhich impacts on the space of the PGM, can range between 1 and m≤n/(2ε)[25, Lemma 2]\ndepending on the “approximate linearity” of the points. In practice, it is very low and can\nbe proven to be m=O/parenleftbig\nn/ε2/parenrightbig\nwhen the gaps between keys are random variables from a\nproper distribution [21]. The time complexity to compute the rank estimate with a PGM\nis given by the time to search for the linear model that contains the searched key q, which\nboils down to a predecessor search on mintegers from a universe of size u. For this, there\nexist many trade-offs in various models of computations [25,49].\nRetrieval Data Structures. Aretrieval data structure orstatic function on a setSofnkeys\ndenotes a function f:S→{0,1}rthat returns a specific r-bit value for each key. Applying\nthe function on a key not in Sreturns an arbitrary value. Retrieval data structures take\n(1 +η)rnbits, where η≥0is the space overhead over the space lower bound of rnbits.\nMWHC [44] is a retrieval data structure based on hypergraph peeling, has an overhead\nη= 0.23and can be evaluated in constant time. 2-step MWHC [3] can have a smaller\noverhead than MWHC by using two MWHC functions of different widths.\nThe morerecently proposed Bumped Ribbon Retrieval (BuRR) data structure [15] basically\nconsists of a matrix. The output value for a key can be obtained by multiplying the hash\nof the key with that matrix. The matrix can be calculated by solving a linear equation\n\n4 Learned Monotone Minimal Perfect Hashing\nsystem. Because BuRR uses hash functions with spacial coupling [54], the equation system\nis almost a diagonal matrix, which makes it very efficient to solve. When some rows of\nthe equation system would prevent successful solving, BuRR bumpsthese rows (and the\ncorresponding keys) to the next layer of the same data structure. BuRR has an overhead\nη=O/parenleftbig\nlogW/(rW2)/parenrightbig\nand can be evaluated in O(1 +rW/ logn)time, where W=O(logn)\nis a parameter called ribbon width. In practice, BuRR achieves space overheads well below\nη= 1%while being faster than widely used data structures with much larger overhead [15].\n3 Related Work\nNon-monotone perfect hash functions are a related and very active area of research [4,8,13,\n18,27,41,43,45,51]. Due to space constraints, we do not review them in detail. For a more\ndetailed list, refer to Ref. [41]. We also do not describe order-preserving minimal perfect\nhash functions [26] because their theoretical lower bound can trivially be reached by using a\nretrieval data structure taking lognbits per key (plus a small overhead). Another loosely\nrelated result is using learned models as a replacement for hash functions in traditional hash\ntables [38,52], but it generally has a negative impact on the probe/insert throughput (and\nmost likely on the space too, due to the storage of the models’ parameters, which these\nstudies do not evaluate). We now look at monotone minimal perfect hash functions, first\ndescribing the idea of bucketing before then continuing with specific MMPHF constructions.\nBucketing. Bucketing [3] is a general technique to break down MMPHF construction into\nsmaller sub-problems. The idea is to store a simple monotone, but not necessarily minimal or\nperfect distributor function that maps input keys to buckets. Each bucket receives a smaller\nnumber of keys that can then be handled using some (smaller) MMPHF data structure.\nTo determine the global rank of a key, we need the prefix sum of the bucket sizes. For\nequally-sized buckets, this is trivial. Otherwise, this sequence can be stored with Elias-Fano\ncoding. In the paper by Belazzougui et al. [3], where many of the following techniques are\ndescribed, the authors use MWHC [44] to explicitly store the ranks within each bucket.\nLeMonHash uses a learned distributor and buckets of expected size 1 (see Section 4).\nLongest Common Prefix. Bucketing with Longest Common Prefixes (LCP) [2] maps keys\nto equally sized buckets. A first retrieval data structure maps all keys to the lengthof the\nLCP among all keys in its bucket. A second one then maps the valueof the LCP to the\nbucket index. Overall, it uses O(log logu)bits per key and query time O((logu)/w), and in\npractice it has been shown to be the fastest but the most space-inefficient MMPHF [3].\nPartial Compacted Trie. First map the keys to equally sized buckets and consider the last\nkey of each bucket as a routerindexed by a compacted trie , e.g., a binary tree where every\nnode contains a bit string denoting the common prefix of its descending keys. During queries,\nthe trie is traversed by comparing the bit string of the traversed nodes with the key to decide\nwhether to stop the search operation at some node (if the prefix does not match), or descend\ninto the left or right subtree based on the next bit of the key. A Partial Compacted Trie\n(PaCo Trie) [3] compresses the compacted trie above by 30–50% by exploiting the fact that,\nin an MMPHF, the trie needs to correctly rank only the keys from the input set. Therefore,\neach node can store a shorter bit string just long enough to correctly route all input keys.\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 5\nHollow Trie. AHollow Trie [3] only stores the position of the next bit to look at. Hollow\ntries can be represented succinctly using balanced parentheses [46]. To use hollow tries for\nbucketing, and thus allow the routing of not-indexed keys, we need a modification to the\ndata structure. The Hollow Trie Distributor [3] uses a retrieval data structure that maps the\ncompacted substrings of each key in each tree node to the behaviour of that key in the node\n(stopping at the left or right of the node, or following the trie using the next bit of the key).\nOverall, it usesO(log log logu)bits per key and query time O(logu).\nZFast Trie. To construct a ZFast Trie [2], we first generate a path-compacted trie. Then,\nfor prefixes of a specific length ( 2-fattest number ) of all input keys, a dictionary stores the trie\nnode that represents that prefix. A query can then perform a binary search over the length\nof the queried key. If there is no node in the dictionary for a given prefix, the search can\ncontinue with the pivot as its upper bound. If there is a node, the lower bound of the search\ncan be set to the length of the longest common prefix of all keys represented by that node.\nThe ZFast trie uses O(log log logu)bits per key and query time O((logu)/w+ log logu).\nPath Decomposed Trie. In the previous paragraphs, we described binary tries with a rather\nhigh height. However, those tries are inefficient to query because of the pointer chasing to\nnon-local memory areas. The main idea behind Path Decomposed Tries [20], which can be\nused as an MMPHF [34], is to reduce the height of the tries. We first select one path all\nthe way from the root node to a leaf. This path is now contracted to a single node, which\nbecomes the root node in our new path decomposed trie. The remaining nodes in the original\ntrie form subtries branching from every node in that path. We take all of these subtries,\nmake them children of the root node, and annotate them by their branching character with\nrespect to the selected path. The subtries are then converted to path decomposed tries\nrecursively. In centroid path decomposition, the path to be contracted is always the one that\ndescends to the node with the most leaves in its subtree.\n4 LeMonHash\nWe now introduce the main contribution of this paper—the MMPHF LeMonHash. The\ncore idea of LeMonHash is surprisingly simple. We take all the ninput integers and map\nthem tonbuckets using some monotone mapping function, that we will describe later. We\nstore an Elias-Fano coded sequence with the global ranks of the first key in each bucket using\n2n+o(n)bits. Given a bucket of size b, we use a⌈logb⌉-bit retrieval data structure (see\nSection 2) to store the local ranks of all its keys. Note that we do not need to store local\nranks if the bucket has only 0or1keys. For squeezing space, instead of storing one retrieval\ndata structure per bucket, we store a collection of retrieval data structures so that the ith\none stores the local ranks of all keys mapped to buckets whose size bis such that i=⌈logb⌉.\nAn illustration of the overall data structure is given in Figure 1a.\nBucket Mapping Function. The space efficiency of LeMonHash is directly related to the\nquality of the monotone mapping function. For uniform random integers, a linear mapping\nfrom input keys to nbuckets, i.e. a mapping from a key xto the bucket number ⌊xn/u⌋,\nleads to an MMPHF with a space usage of just 2.915bits per key (see Theorem 1). Intuitively,\nsuch a linear mapping returns a rank estimate in [n]for a given key. However, for skewed\ndistributions, the rank estimate can be far away which can create large buckets whose local\nranks are expensive to store. For example, if the majority of the keys are such that x<u/n,\n\n6 Learned Monotone Minimal Perfect Hashing\n0\n1\n1\n3\n4\n4\n5\n6\n6\n9\n10\n11\n0\n1\n00\n01\n10\nninput keys\nnbuckets\nRetrieval\nu\nMapper\nGlobal ranks ∈[n]\n(a)LeMonHash. Keys are mapped to buckets.\nRanks within buckets are stored in (a collection\nof) retrieval data structures.\n0\n3\n7\n20\n23\n23\n25\n35\n35\nFirst chunks of all ninput keys\nFew keys\nwith these\nchunks,\nstore local\nranks\nNext chunks\nNext chunks\n3\n11\n11\n20\n23\n29\n29\n35\n2w\ncbuckets\nGlobal ranks ∈[n]\nMapper(b)LeMonHash-VL. Global ranks in each level are\nstored together. Buckets that are not handled re-\ncursively use retrieval data structures like before.\nFigure 1 Illustration of the LeMonHash and LeMonHash-VL data structures.\nthen the first bucket will be large enough to require Θ(logn)bits per key, i.e. our MMPHF\ndegenerates to a trivial OPMPHF. To tackle this problem, we implement the mapping\nfunction with a PGM-index [25]. As we observed in Section 2, the PGM was originally\ndesigned as a predecessor-search data structure. Here, we use the PGM as a rank estimator\nthat, for a given key, returns an ε-bounded estimate of its rank. To achieve this result\nin LeMonHash, we do not store the list of indexed keys and simply use the PGM’s rank\nestimate as the bucket index. The PGM internally adapts to the input data by learning the\nsmoothness in the distribution via a piecewise linear ε-approximation model, thus it can be\nthought of as a “local” approximation of the linear mapping above. Real-world data sets can\noften be approximated using piecewise linear models, as discussed in the literature [21] and\nalso demonstrated by the good space efficiency of our experiments (see Section 8). There\nis a trade-off between the amount of space needed to represent the PGM and the quality\nof the mapping, which depends on both the input data distribution and the given integer\nparameter ε. In Section 8, we test both a version with a constant εvalue and a version\nthat auto-tunes its value by constructing multiple PGMs and then selecting the optimal ε.\nFinally, we observe that with the PGM mapper, unlike for the linear mapping and other non\nerror-bounded learning-based approaches [24,37], the number of retrieval data structures we\nneed to keep is bounded by O(logε)regardless of the input key distribution (see Theorem 2).\nQueries. Given a key q, we obtain its bucket iusing the mapping function. The global rank\nof the (first key in the) bucket is the ith integer in the Elias-Fano coded sequence of global\nranks, which can be accessed in constant time, and the bucket size is computed by subtraction\nfrom the next integer in that sequence. The bucket size bdirectly tells us which retrieval data\nstructure to query, i.e. the ⌈logb⌉th one. Evaluating the retrieval data structure with qgives\nus its local rank in the bucket. Adding this to the global rank of the bucket gives us the rank\nofq. As we show in Section 7, for uniform data, the linear bucket mapper gives constant time\nqueries, while for other inputs we use the PGM mapper and the query time is O(log logu).\nComparison to Known Solutions. Known MMPHFs in the literature typically divide\nthe keys into equal-size buckets and build a compact trie-based distributor. Unlike them,\nLeMonHash learns the data linearities and leverages them to distribute keys to buckets close\nto their rank. Whenever some keys collide into a bucket, LeMonHash handles these keys via\na (small) collection of succinct retrieval structures. In contrast to known solutions, whenever\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 7\na key is the only one mapped to its bucket, no information needs to be stored in (and no\nquery is issued on) a retrieval data structure. These features allow LeMonHash to possibly\nachieve reduced space occupancy compared to classic MMPHFs, which are oblivious to data\nlinearities. Also, LeMonHash can reduce the query time by replacing the cache-inefficient\ntraversal of a trie with the PGM mapper, which in practice is fast to evaluate.\n5 LeMonHash-VL\nOf course, the idea of LeMonHash can be immediately applied to keys whose maximum\nlongest common prefix (LCP) is less than wbits. In this case, each string prefix and the\nfollowing bit (which are sufficient to distinguish every string from each other) fit into one\nmachine word and thus can be handled efficiently in time and in space by the PGM mapper.\nFor strings with longer LCPs, we introduce a tree data structure that we call LeMonHash-VL\n(since it handles Variable-Length strings). The main idea is to simply compute the bucket\nmapping on a length- wsubstring of each string, which we call a chunk. Buckets that receive\nmany keys using this procedure are then handled recursively. Details follow.\nOverview. We start with a root node representing all the string keys in Sand consider the\nset of chunks extracted from each key starting from position |p|(which we store), where pis\nthe LCP among the keys in S. Given these cdistinct chunks, we construct a PGM mapper\nto distribute the keys to buckets in [c], and we store an Elias-Fano coded sequence with the\nglobal ranks of the first key in each bucket. Clearly, different keys can be mapped to the\nsame bucket because the PGM mapper is not perfect (as in the integer case) and because\nthey share the same chunk value (unlike in the integer case). For example, for the strings\nS={cherry,cocoa,coconut}withp=cand chunks composed of 3 characters, the keys\ncocoaandcoconut share the chunk value ocoand will be mapped to the same bucket.\nIf a bucket of size bcontains fewer input strings than a specific threshold t, we store the\nlocal ranks of the strings in the bucket in a ⌈logb⌉-bit retrieval data structure. Once again,\nwe do not need to store local ranks if the bucket has only 0 or 1 keys. If instead the bucket is\nlarge (i.e.b≥t), we create a child node in the tree data structure by applying the same idea\nrecursively on the strings S′of that bucket. This means that we compute a PGM mapper on\nthe chunks extracted from each string in S′starting from position |p′|, wherep′is the LCP\namong the bucket strings S′. Notice that|p′|≥|p|but we always guarantee that S′⊊S, so\nthe recursion is bounded. In practice, we set the threshold t= 128(see Section 8.1).\nAt query time, we can use the sequence of global ranks to calculate the bucket size b,\nwhich allows determining whether we need to continue recursively on a child (because b≥t)\nor directly return the global rank of the bucket plus the local rank stored in the ⌈logb⌉-bit\nretrieval data structure. Figure 1b gives an overview of the data structure.\nWe observe that the global ranks of each node increase monotonically from left to right\nin each level of the overall tree. Therefore, we merge all these global ranks in a level into one\nElias-Fano sequence, thereby avoiding the space overhead of storing many small sequences.\nOf course, each inner node of the tree needs some extra metadata, like the encoding of its\nbucket mapper, the value of |p|, and an offset to its first global rank in the per-level Elias-Fano\nsequence. We associate a node to its metadata via a minimal perfect hash function, where\nthe identifier of a node is given by the path of the buckets’ indices leading to it.\nGiven the overall idea, there is a wide range of optimisations that we use. In the\nfollowing, we outline the main algorithmic ones and refer the interested reader to our\nimplementation [29] and Appendix C for the many other small-and-tricky optimisations,\n\n8 Learned Monotone Minimal Perfect Hashing\nsuch as the use of specialised instructions like popcount andbextr, or lookup tables.\nAlphabet Reduction. The number of nodes and the depth of LeMonHash-VL depend on\nboth the length and distribution of the input strings, and on how well the PGM mapper\nat each node can map strings to distinct buckets given their w-bit chunks. Therefore, we\nshould aim to fit as much information as possible in the w-bit chunks. We do so by exploiting\nthe fact that, in real-world data sets, often only a very small alphabet Σof branching\ncharacters distinguish the strings in each bucket, and that we do not care about the other\ncharacters. We extract chunks from the suffix of each string starting from the position\nfollowing the LCP p, as before, but interpret the suffix as a number in radix σ=|Σ|where\neach character is replaced by its 0-based index in Σif present, or by 0 if not present. For\nexample, for a node on the strings {shoppers,shopping,shops}whose LCP is p=shop,\nwe would store the alphabet Σ ={e,i,p,s}and map the suffix “ pers” of “ shoppers ” to\nindex (p)σ3+index (e)σ2+index (r)σ1+index (s)σ0= 2σ3+ 0σ2+ 0σ1+ 3σ0. Observe that\nthe chunks computed in this way still preserve the lexicographic order of the strings. The\nnumber of characters we extract is computed to fit as many characters as possible in a w-bit\nword, i.e.⌊w/logσ⌋characters. In our implementation over bytes, we store Σvia a bitmap\nof size 128 or 256, depending on whether its characters are a subset of ASCII or not. Finally,\nwe mention that a mapping from strings to numbers in radix σhas also been used to build\ncompressed string dictionaries [9], but the twist here is that we are considering only the\nalphabet of the branching characters since we do not need to store the keys.\nElias-Fano Sequences. The large per-level Elias-Fano sequences of global ranks have a very\nirregular structure. For example, if many of the strings in a node share the same chunks,\nthere is a large gap between two of the stored ranks. We can deal with these irregularities and\nreduce the overall space usage by using partitioned Elias-Fano [50]. Furthermore, the PGM\nmappers do not always provide a very uniform mapping, which thus results in empty buckets.\nAn empty bucket corresponds to a duplicate offset value being stored in the Elias-Fano\nsequences (see e.g. the duplicate offset 23 in Figure 1b). To optimise the space usage of\nsuch duplicates, we filter them out before constructing the partitioned Elias-Fano sequence.\nWe do this by grouping the stored numbers in groups of 3 numbers. If all 3 numbers are\nduplicates of the number before that group, we do not need to store the group. A bit vector\nwith rank support indicates which groups were removed.\nPerfect Chunk Mapping. In many datasets, there might be only a small number of different\nchunks, even if the number of strings they represent is large. For instance, chunks computed\non the first bytes of a set of URLs might be a few due to the scarcity of hostnames, but\neach host may contain many distinct pages. In these cases, instead of a PGM, it might be\nmore space-efficient to build a (perfect) map from chunks to buckets in [c]via a retrieval\ndata structure taking c⌈logc⌉bits overall (plus a small overhead), where cis the number of\ndistinct chunks. In practice, we apply this optimisation whenever c<128(see Section 8.1).\nComparison to Known Solutions. In essence, LeMonHash-VL applies the idea of LeM-\nonHash recursively to handle variable-length strings. Therefore, unlike known solutions, it\ncan leverage data linearities to distribute w-bit chunks from the input strings to buckets\nusing small space, and use additional child nodes only whenever a bucket contains many\nstrings that thus require inspecting the following chunks to be distinguished. Additionally, it\nperforms an adaptive alphabet reduction within the buckets to fit more information in the\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 9\nw-bit chunks, thus leveraging the presence of more regularities in the input data. Overall,\nthese features result in a data structure that has a small height and is efficient to be traversed.\n6 Variants and Refinements\nLeMonHash can be refined in numerous ways, which we only mention briefly due to space\nconstraints. Looking at a possible external memory implementation, LeMonHash can be\nconstructed trivially by a linear sweep and queries are possible using a suitable representation\nof the predecessor and bucket-size data structures. LeMonHash can also be constructed in\nparallel without affecting the queries, in contrast to the trivial parallelisation by partitioning\nthe input. In LeMonHash-VL, extracting chunks from non-contiguous bytes reduces the\nheight of the trees but has worse trade-offs in practice. Finally, we present an alternative\nto storing the local ranks explicitly. The idea is to recursively split the universe size of that\nbucket and record the number of keys smaller than that midpoint. Despite its query overhead,\nthis technique might be of general interest for MMPHFs. Refer to Appendix A for details.\n7 Analysis\nWe now prove some properties of our LeMonHash data structure for integers. In our analysis,\nwe use succinct retrieval data structures taking rn+o(n)bits per stored value and answering\nqueries in constant time (see Section 2 and [15]). Furthermore, since our bucket mappers\nneed multiplications and divisions, we make the simplifying assumption u= 2wto avoid\ndealing with the increased complexity of these arithmetic operations over large integers.\n▶Theorem 1. A LeMonHash data structure with a bucket mapper that simply performs a\nlinear interpolation of the universe on a list of nuniform random keys needs ≈n(2.91536 +\no(1))bits on average1and answers queries in constant time.\nProof.We approximate the number of keys per bucket using a Poisson distribution which\nresults in 0.91536n+o(n)bits of space for the retrieval data structures. On top of that, an\nElias-Fano coding of the global bucket ranks gives 2n+o(n)bits. Refer to Appendix B for\nthe full proof. ◀\nWhile this result is formally only valid for a global uniform distribution, for use in\nLeMonHash it suffices if each segment computed by the PGM-index is sufficiently smooth. It\nneed not even be uniformly random as long as each local bucket has a constant average size.\nAs long as the space for encoding the segments is in O(n)bits, we retain the linear space\nbound of Theorem 1. Moreover, the following worst-case analysis gives us a fallback position\nthat holds regardless of any assumptions.\n▶Theorem 2. A LeMonHash data structure with the PGM mapper takes n(⌈log(2ε+1)⌉+2+\no(1))+O/parenleftbig\nmlogu\nm/parenrightbig\nbits of space in the worst case and answers queries in O/parenleftbig\nlog logwu\nm/parenrightbig\ntime,\nwheremis the number of linear models in a PGM with an integer parameter ε≥0constructed\non theninput keys.\n1Numerically, we find that a better space usage of ≈2.902nbits can be achieved by mapping the nkeys to\nonly≈0.909nbuckets, but this difference is irrelevant in practice. It is also interesting to note that this is\nclose to the space requirements of most of the practical non-monotone MPHFs [4,8,13,18,27,41,43,45,51].\nUsing an MMPHF can be useful when indexing an array through an MPHF, because sorting the hash\nvalues can be more cache efficient than a large number of random accesses to the array.\n\n10 Learned Monotone Minimal Perfect Hashing\nProof.The basic idea is that the rank estimate returned by the PGM is guaranteed to be\nfar from the correct rank by ε, which limits the space of the retrieval data structures. The\nO/parenleftbig\nmlogu\nm/parenrightbig\n-term in the space bound is given by a compressed encoding of the linear models\nin the PGM, and the query time is given by a predecessor search structure on the linear\nmodels’ keys. Refer to Appendix B for the full proof. ◀\nThe worst-case bounds obtained in Theorem 2 are hard to compare with the ones of classic\nMMPHF (see Section 3) due to the presence of m(andε), which depends on (and must be\ntuned according to) the approximate linearity of the input data, which classic MMPHFs are\noblivious to.2Refer to Section 2 for bounds on m. Our experiments show that we obtain\nbetter space or space close to the best classic MMPHFs, while being much faster (we use\na weaker but practical predecessor search structure than the one in Theorem 2). Refer to\nSection 8 for details.\n8 Experiments\nIn the following section, we first compare different configurations of LeMonHash and\nLeMonHash-VL before comparing them with competitors from the literature.\nExperimental Setup. We perform our experiments on an Intel Xeon E5-2670 v3 with a\nbase clock speed of 2.3 GHz running Ubuntu 20.04 with Linux 5.10.0. We use the GNU C++\ncompiler version 11.1.0 with optimisation flags -O3 -march=native . As a retrieval data\nstructure, we use BuRR [15] with 64-bit ribbon width and 2-bit bumping info. To store the\nbucket sizes, we use the select data structure by Kurpicz [39] in LeMonHash and Partitioned\nElias-Fano [50] in LeMonHash-VL. To map tree paths to the node metadata, we use the\nMPHF PTHash [51]. For the PGM implementation in LeMonHash, we use the encoding\nfrom Theorem 2 and use a predecessor search on the Elias-Fano sequence (Section 2). In\nLeMonHash-VL, since the number of linear models in a node is typically small, we encode\nthem explicitly as fixed-width triples (key,slope,intercept )and find the predecessor via a\nbinary search on the keys. All our experiments are executed on a single thread. Because the\nvariation is very small, we run each experiment only twice and report the average. We run\nthe Java competitors on OpenJDK 17.0.4 and perform one warm-up run for the just-in-time\ncompiler that is not measured. With this, the Java performance is expected to be close to\nC++ [3]. Because Java does not have an unsigned 64-bit integer type, we subtract 263from\neach input key to keep their relative order.\nThe code and scripts needed to reproduce our experiments are available on GitHub under\nthe General Public License [29,30].\nDatasets. Our datasets, as in previous evaluations [3,34], are a textdataset that contains\nterms appearing in the text of web pages [3] and urlscrawled from .uk domains in 2007 [11].\nAdditionally, we also test with dnasequences consisting of 32-mers [23]. Regarding real-world\ninteger datasets, 5gramcontains positions of the most frequent letter in the BWT of a text\nfile containing 5-grams found in books indexed by Google [10,32]. The fbdataset contains\nFacebook user IDs [36] and osmcontains OpenStreetMap locations [36]. As synthetic integer\ndatasets, we use 64-bit uniform,normal, and exponential distributions. Refer to Table 1 for\ndetails.\n2This happens also in other problems in which data is encoded with linear models [10,22].\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 11\nTable 1Datasets used for the experiments, together with their length or average (ø) length. Top:\nreal-world string datasets. Middle: real-world integer datasets. Bottom: synthetic integer datasets.\nDataset nLength Description\ntext 35M ø 11 bytes Terms appearing in the text of web pages, GOV2 corpus [3]\ndna 367M 32 bytes 32-mer from a DNA sequence, Pizza&Chili corpus [23]\nurls 106M ø 105 bytes Web URLs crawled from .uk domains in 2007 [11]\n5gram 145M 32 bits Positions of the most frequent letter in the BWT of a text file\ncontaining 5-grams found in books indexed by Google [10,32]\nfb 200M 64 bits Facebook user IDs [36]\nosm 800M 64 bits OpenStreetMap locations [36]\nuniform 100M 64 bits Uniform random\nnormal 100M 64 bits Normal distribution ( µ= 1015,σ2= 1010)\nexponential 100M 64 bits Exponential distribution ( λ= 1, scaled with 1015)\n8.1 Tuning Parameters\nIn the following section, we compare several configuration parameters of LeMonHash and\nshow how they provide a trade-off between space usage and performance.\nLeMonHash. Different ways of mapping the keys to buckets have their own advantages and\ndisadvantages. Table 2 gives measurements of the construction and query throughput, as well\nas the space consumption of different bucket mappers. Our implementation of LeMonHash\nwith a linear bucket mapper achieves a space usage of 2.94nbits, which is remarkably close\nto the theoretical space usage of 2.91nbits (see Theorem 1). Of course, a global, linear\nmapping does not work for all datasets. A bucket mapper that creates equal-width segments\nby interpolating between sampled keys (denoted as “Segmented” in the table) is fast to\nconstruct and query, and it achieves good space usage. But, as for the global linear mapping,\nthis approach is not robust enough to manage arbitrary input distributions. In particular,\nfor this heuristic mapper, it is easy to come up with a worst-case input that degenerates the\nspace usage. Conversely, with the PGM mapper, LeMonHash still achieves 2.96nand2.98n\nbits on uniform random integers but it is more performant and robust on other datasets\n(except on osm, where the heuristic mapper obtains a good enough mapping with only its\nequal-width segments, which are inexpensive to store). In fact, we explicitly avoided heuristic\ndesign choices in our PGM mapper (such as sampling input keys, removing outliers, or using\nlinear regression) to not inflate our performance on the tested datasets at the expense of\nrobustness on unknown ones (see Ref. [37]). Finally, on most input distributions, auto-tuning\nthe value of ε∈{15,31,63}does not have a large effect on the space usage.\nLeMonHash-VL. Table 3 lists the effect of alphabet reduction on the query and construction\nperformance. In general, alphabet reduction enables noticeable space improvements with\nonly a small impact on the construction time. For the dna dataset, which uses only 15\ndifferent characters, the alphabet reduction has the largest effect, saving 1.3 bits per key and\nsimultaneously making the queries 40% faster. The faster queries can be explained by the\nreduced tree height. Note that alphabet reduction makes the queries slightly slower for the\nother datasets. The reason is that instead of one single bswapinstruction for chunk extraction,\nit needs multiple arithmetic operations (including popcount ) for each input character. The\n\n12 Learned Monotone Minimal Perfect Hashing\nTable 2Comparison of different bucket mappers. The space usage is given in bits per key, the\nquery throughput in kQueries/second, and the construction throughput (c.t.) in MKeys/second.\nDataset Linear mapper PGM ε=auto PGM ε= 31 Segmented\nbpk kq/s c.t. bpk kq/s c.t. bpk kq/s c.t. bpk kq/s c.t.\n5gram 5.60 1833.5 6.2 2.62 1747.0 3.8 2.63 1779.4 8.5 2.64 2145.9 14.5\nfb 34.35 0.8 5.1 4.91 1156.1 2.8 4.91 1150.7 5.1 4.93 1441.3 7.2\nosm 12.92 1525.3 5.5 4.42 999.6 2.8 4.42 998.6 5.0 4.33 1272.9 6.8\nuniform 2.94 3244.6 8.7 2.96 1903.3 3.5 2.98 1850.5 6.5 3.03 2192.0 8.7\nnormal 34.27 105.3 4.8 2.95 1935.0 3.6 2.97 1858.0 6.6 3.00 1727.7 8.7\nexponential 5.42 2715.9 6.0 2.95 1876.9 3.6 2.98 1791.5 6.6 3.01 2085.1 8.8\nTable 3Comparison of different variants of LeMonHash-VL. The space usage is given in bits\nper key, the query throughput in kQueries/second, and the construction throughput (c.t.) in\nMKeys/second. Variants with and without alphabet reduction (AR), a special indexed variant (Idx,\nsee Appendix A), and a variant with fixed instead of auto-tuned parameter εfor the bucket mapper.\nDatasetε=auto, no AR ε=auto, AR ε= 63, AR Idx, ε=auto, AR\nbpk kq/s c.t. bpk kq/s c.t. bpk kq/s c.t. bpk kq/s c.t.\ntext 6.52 1062.9 1.7 6.03 1005.8 1.6 6.08 1001.8 2.5 6.10 933.2 2.3\ndna 7.66 452.8 2.0 6.32 631.3 1.7 6.25 644.8 2.7 6.27 601.1 2.4\nurls 7.14 282.7 2.3 6.37 298.8 1.8 6.46 295.1 2.3 6.63 298.1 1.6\nindexed variant that builds chunks from the distinguishing bytes instead of a contiguous\nbyte range (see Appendix A) is slower to construct but does not show clear space savings,\nwhich can be explained by larger per-node metadata. We also experimented with different\nthresholds for when to stop recursion, as well as the perfect chunk mapping (see Section 5).\nGiven that the space overhead from each bucket mapper is the same for all data sets, it is not\nsurprising that the same threshold (128 keys) works well for all datasets (see Appendix D).\nFinally, making the εvalue of the PGM mapper constant instead of auto-tuned, we naturally\nget faster construction. As in the integer case, one would expect a fixed εvalue to always\nproduce results that are the same or worse than the auto-tuned version. This is not the case\nbecause, in the recursive setting, it is hard to estimate the effect of a mapper on the overall\nspace usage. Therefore, an εvalue that needs more space locally can lead to a mapping that\nproves useful on a later level of the tree. This is why ε= 63can achieve better space usage\nthan the auto-tuned version on the dna dataset.\n8.2 Comparison with Competitors\nIn this section, we compare the performance of LeMonHash and LeMonHash-VL with\ncompetitors from the literature. Competitors include the C++ implementation by Grossi and\nOttaviano [34] of the Centroid Hollow Trie, Hollow Trie, and Path Decomposed Trie. Because\nthat implementation only supports string inputs, we convert the integers to a list of fixed-\nlength strings. We point out that the Path Decomposed Trie crashes at an internal assertion\nwhen being run on integer datasets. For the Hollow Trie, we encode the skips with either\nGamma or Elias-Fano coding, whatever is better on the dataset. We also include the Java\nimplementations by Belazzougui et al. [3] of a range of techniques (see Section 3). We use\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 13\n00.51\nQuery MKeys/stext\n dna\n urls\n012\nQuery MKeys/s5gram\n fb\n osm\n5 10012\n≥\nBits/keyQuery MKeys/suniform\n5 10≥\nBits/keynormal\n5 10≥\nBits/keyexponential\nFigure 2 Query throughput for string, integer, and synthetic integer datasets vs space usage.\nThe top-left corner of every plot shows the top-performing solutions in terms of space-time efficiency.\n0123\nConstr. MKeys/stext\n dna\n urls\n02468\nConstr. MKeys/s5gram\n fb\n osm\n5 1002468\n≥\nBits/keyConstr. MKeys/suniform\n5 10≥\nBits/keynormal\n5 10≥\nBits/keyexponential\nCentroid HT [34] HTDist\n [3] Hollow [34] Hollow\n [3]ZFast\n[3]\nLCP 2-step\n [3]LCP\n[3] VLLCP\n [3]PaCo\n[3]VLPaCo\n [3]\nPath Decomp. [34]\n LeMonHash-VL\n LeMonHash\nFigure 3 Construction throughput for string, integer, and synthetic integer datasets. Competitors\nwith the\n symbol in the legend are implemented in Java.\n\n14 Learned Monotone Minimal Perfect Hashing\neither the FixedLong or PrefixFreeUtf16 transformation, depending on the data type of the\ninput. For LeMonHash, we use the PGM mapper with ε= 31. For LeMonHash-VL, we use\nthe PGM mapper with ε= 63, alphabet reduction and a recursion threshold t= 128.\nQueries. Figure 2 plots the query throughput against the achieved storage space. In\nTable A.1 in the Appendix, we additionally detail the numbers in tabular format. The\nLCP-based methods (see Section 3) have very fast queries but also need the most space (in\nfact, they appear to the top-right of the plots). At the same time, LeMonHash matches or\neven outperforms the query throughput of LCP-based methods, while being significantly more\nspace efficient (in fact, it appears towards the top-left of the plots). Compared to competitors\nwith similar space usage, LeMonHash offers significantly higher query throughput.\nConstruction. Figure 3 plots the construction throughput against the space needed. On\nmost synthetic integer datasets, LeMonHash provides a significant improvement to the\nstate-of-the-art approaches, whereas it matches or outperforms the competitors on real-world\ndatasets. LeMonHash improves the construction throughput by up to a factor of 2, compared\nto the competitor with the next best space usage (typically, variants of the Hollow Trie).\nWhile LeMonHash-VL does not achieve the same space usage as the Hollow Trie Distributor,\nits construction is significantly faster, and still it is the second best in space usage.\n9 Conclusion and Future Work\nIn this paper, we have introduced the monotone minimal perfect hash function LeMonHash.\nLeMonHash, unlike previous solutions, learns and leverages data smoothness to obtain a\nsmall space usage and significantly faster queries. On most synthetic and real-world datasets,\nLeMonHash dominates all competitors—simultaneously—on space usage, construction and\nquery throughput. Our extension to variable-length strings, LeMonHash-VL, consists of\ntrees that are significantly more flat and efficient to traverse than competitors. This enables\nextremely fast queries with space consumption similar to competitors.\nFuture Work. Many MMPHF construction algorithms are based on the idea of explicitly\nstoring ranks of keys within a small bucket. The idea to split small buckets recursively that\nwe mention in Section 6 can help to reduce the space usage. It remains an open problem\nwhether the idea works in practice, especially when the distribution of keys inside the bucket\nis skewed. It is also worth investigating a different construction of the piecewise linear\napproximation in the PGM that minimises the overall space given by the segments and\nthe local ranks stored in retrieval data structures, rather than the current approach that\nmaximises the length of the segment (thus minimising just the segments space). Applying\nnon-linear transformations like low-degree polynomials within each segment would also be\ninteresting future work. Finally, it would be interesting to apply smoothed analysis to\nformally show that many real-world distributions locally behave as if they were uniform\nrandom, therefore leading to tighter space bounds.\nReferences\n1Sepehr Assadi, Martin Farach-Colton, and William Kuszmaul. Tight bounds for monotone\nminimal perfect hashing. In Proc. 34th Annual ACM-SIAM Symposium on Discrete Algorithms\n(SODA), pages 456–476, 2023. doi:10.1137/1.9781611977554.CH20 .\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 15\n2Djamal Belazzougui, Paolo Boldi, Rasmus Pagh, and Sebastiano Vigna. Monotone minimal\nperfect hashing: searching a sorted table with O(1) accesses. In Proc. 20th Annual ACM-\nSIAM Symposium on Discrete Algorithms (SODA) , pages 785–794, 2009. doi:10.1137/1.\n9781611973068.86 .\n3Djamal Belazzougui, Paolo Boldi, Rasmus Pagh, and Sebastiano Vigna. Theory and practice\nof monotone minimal perfect hashing. ACM J. Exp. Algorithmics , 16, 2011. doi:10.1145/\n1963190.2025378 .\n4Djamal Belazzougui, Fabiano C. Botelho, and Martin Dietzfelbinger. Hash, displace, and\ncompress. In Proc. 17th Annual European Symposium on Algorithms (ESA) , pages 682–693,\n2009. doi:10.1007/978-3-642-04128-0_61 .\n5Djamal Belazzougui, Fabio Cunial, Juha Kärkkäinen, and Veli Mäkinen. Linear-time string\nindexing and analysis in small space. ACM Trans. Algorithms , 16(2):17:1–17:54, 2020. doi:\n10.1145/3381417 .\n6Djamal Belazzougui and Gonzalo Navarro. Optimal lower and upper bounds for representing\nsequences. ACM Trans. Algorithms , 11(4):31:1–31:21, 2015. doi:10.1145/2629339 .\n7Djamal Belazzougui, Gonzalo Navarro, and Daniel Valenzuela. Improved compressed indexes\nfor full-text document retrieval. J. Discrete Algorithms , 18:3–13, 2013. doi:10.1016/j.jda.\n2012.07.005 .\n8Dominik Bez, Florian Kurpicz, Hans-Peter Lehmann, and Peter Sanders. High performance\nconstruction of RecSplit based minimal perfect hash functions. In Proc. 31st Annual European\nSymposium on Algorithms (ESA) , pages 19:1–19:16, 2023. doi:10.4230/LIPIcs.ESA.2023.19 .\n9Antonio Boffa, Paolo Ferragina, Francesco Tosoni, and Giorgio Vinciguerra. Compressed string\ndictionaries via data-aware subtrie compaction. In Proc. 29th International Symposium on\nString Processing and Information Retrieval (SPIRE) , pages 233–249, 2022. doi:10.1007/\n978-3-031-20643-6_17 .\n10Antonio Boffa, Paolo Ferragina, and Giorgio Vinciguerra. A learned approach to design\ncompressed rank/select data structures. ACM Trans. Algorithms , 18(3):24:1–24:28, 2022.\ndoi:10.1145/3524060 .\n11Paolo Boldi, Massimo Santini, and Sebastiano Vigna. A large time-aware web graph. SIGIR\nForum, 42(2):33–38, 2008. doi:10.1145/1480506.1480511 .\n12Alexandra Boldyreva, Nathan Chenette, and Adam O’Neill. Order-preserving encryption revis-\nited: Improved security analysis and alternative solutions. In Proc. 31st Annual International\nCryptology Conference (CRYPTO) , pages 578–595, 2011. doi:10.1007/978-3-642-22792-9_\n33.\n13Jarrod A. Chapman, Isaac Ho, Sirisha Sunkara, Shujun Luo, Gary P. Schroth, and Daniel S.\nRokhsar. Meraculous: De novo genome assembly with short paired-end reads. PLOS ONE ,\n6(8):1–13, 08 2011. doi:10.1371/journal.pone.0023501 .\n14David Richard Clark. Compact Pat Trees . PhD thesis, University of Waterloo, Canada, 1996.\n15Peter C. Dillinger, Lorenz Hübschle-Schneider, Peter Sanders, and Stefan Walzer. Fast succinct\nretrieval and approximate membership using ribbon. In Proc. 20th International Symposium\non Experimental Algorithms (SEA) , pages 4:1–4:20, 2022. doi:10.4230/LIPICS.SEA.2022.4 .\n16Patrick Dinklage, Johannes Fischer, Alexander Herlez, Tomasz Kociumaka, and Florian\nKurpicz. Practical performance of space efficient data structures for longest common extensions.\nInProc. 28th Annual European Symposium on Algorithms (ESA) , pages 39:1–39:20, 2020.\ndoi:10.4230/LIPIcs.ESA.2020.39 .\n17Peter Elias. Efficient storage and retrieval by content and address of static files. J. ACM,\n21(2):246–260, 1974. doi:10.1145/321812.321820 .\n18Emmanuel Esposito, Thomas Mueller Graf, and Sebastiano Vigna. RecSplit: Minimal perfect\nhashing via recursive splitting. In Proc. 22nd Symposium on Algorithm Engineering and\nExperiments (ALENEX) , pages 175–185, 2020. doi:10.1137/1.9781611976007.14 .\n19Robert Mario Fano. On the number of bits required to implement an associative memory.\nTechnical report, MIT, Computer Structures Group, 1971. Project MAC, Memorandum 61\".\n\n16 Learned Monotone Minimal Perfect Hashing\n20Paolo Ferragina, Roberto Grossi, Ankur Gupta, Rahul Shah, and Jeffrey Scott Vitter. On\nsearching compressed string collections cache-obliviously. In Proc. 27th ACM Symposium on\nPrinciples of Database Systems (PODS) , pages 181–190, 2008. doi:10.1145/1376916.1376943 .\n21Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. On the performance of learned data\nstructures. Theor. Comput. Sci. , 871:107–120, 2021. doi:10.1016/J.TCS.2021.04.015 .\n22Paolo Ferragina, Giovanni Manzini, and Giorgio Vinciguerra. Compressing and querying\ninteger dictionaries under linearities and repetitions. IEEE Access , 10:118831–118848, 2022.\ndoi:10.1109/ACCESS.2022.3221520 .\n23Paolo Ferragina and Gonzalo Navarro. Pizza&Chili corpus. Accessed: February 2023. URL:\nhttp://pizzachili.dcc.uchile.cl/texts.html .\n24Paolo Ferragina and Giorgio Vinciguerra. Learned data structures. In Luca Oneto, Nicolò\nNavarin, Alessandro Sperduti, and Davide Anguita, editors, Recent Trends in Learning From\nData, pages 5–41. Springer International Publishing, 2020. doi:10.1007/978-3-030-43883-8_\n2.\n25Paolo Ferragina and Giorgio Vinciguerra. The PGM-index: a fully-dynamic compressed\nlearned index with provable worst-case bounds. PVLDB, 13(8):1162–1175, 2020. doi:10.\n14778/3389133.3389135 .\n26Edward A. Fox, Qi Fan Chen, Amjad M. Daoud, and Lenwood S. Heath. Order-preserving\nminimal perfect hash functions and information retrieval. ACM Trans. Inf. Syst. , 9(3):281–308,\n1991. doi:10.1145/125187.125200 .\n27Edward A. Fox, Qi Fan Chen, and Lenwood S. Heath. A faster algorithm for constructing\nminimal perfect hash functions. In Proc. 15th Annual International ACM Conference on\nResearch and Development in Information Retrieval (SIGIR) , pages 266–273, 1992. doi:\n10.1145/133160.133209 .\n28TravisGagie, GonzaloNavarro, andNicolaPrezza. Fullyfunctionalsuffixtreesandoptimaltext\nsearching in BWT-runs bounded space. J. ACM, 67(1):2:1–2:54, 2020. doi:10.1145/3375890 .\n29LeMonHash - GitHub. https://github.com/ByteHamster/LeMonHash , 2023.\n30MMPHF-Experiments - GitHub. https://github.com/ByteHamster/MMPHF-Experiments ,\n2023.\n31Simon Gog, Timo Beller, Alistair Moffat, and Matthias Petri. From theory to practice: Plug\nand play with succinct data structures. In Proc. 13th International Symposium on Experimental\nAlgorithms (SEA) , pages 326–337, 2014. doi:10.1007/978-3-319-07959-2_28 .\n32Google. Google ngram exports. Accessed: March 2023. URL: https://storage.googleapis.\ncom/books/ngrams/books/datasetsv3.html .\n33Roberto Grossi, Alessio Orlandi, and Rajeev Raman. Optimal trade-offs for succinct string\nindexes. In Proc. 37th International Colloquium on Automata, Languages and Programming\n(ICALP) , pages 678–689, 2010. doi:10.1007/978-3-642-14165-2_57 .\n34Roberto Grossi and Giuseppe Ottaviano. Fast compressed tries through path decompositions.\nACM J. Exp. Algorithmics , 19(1), 2014. doi:10.1145/2656332 .\n35Guy Jacobson. Space-efficient static trees and graphs. In Proc. 30th IEEE Symposium on\nFoundations of Computer Science (FOCS) , pages 549–554, 1989. doi:10.1109/SFCS.1989.\n63533.\n36Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska,\nand Thomas Neumann. SOSD: A benchmark for learned indexes. CoRR, abs/1911.13014,\n2019.\n37Evgenios M. Kornaropoulos, Silei Ren, and Roberto Tamassia. The price of tailoring the\nindex to your data: Poisoning attacks on learned index structures. In Proc. 48th International\nConference on Management of Data (SIGMOD) , pages 1331–1344, 2022. doi:10.1145/\n3514221.3517867 .\n38Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proc. 44th International Conference on Management of Data (SIGMOD) ,\npages 489–504, 2018. doi:10.1145/3183713.3196909 .\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 17\n39Florian Kurpicz. Engineering compact data structures for rank and select queries on bit\nvectors. In Proc. 29th International Symposium on String Processing and Information Retrieval\n(SPIRE) , pages 257–272, 2022. doi:10.1007/978-3-031-20643-6\\_19 .\n40Florian Kurpicz, Hans-Peter Lehmann, and Peter Sanders. PaCHash: Packed and compressed\nhash tables. In Proc. 25th Symposium on Algorithm Engineering and Experiments (ALENEX) ,\npages 162–175, 2023. doi:10.1137/1.9781611977561.ch14 .\n41Hans-Peter Lehmann, Peter Sanders, and Stefan Walzer. SicHash - small irregular cuckoo\ntables for perfect hashing. In Proc. 25th Symposium on Algorithm Engineering and Experiments\n(ALENEX) , pages 176–189, 2022. doi:10.1137/1.9781611977561.ch15 .\n42Hyeontaek Lim, Bin Fan, David G. Andersen, and Michael Kaminsky. SILT: a memory-\nefficient, high-performance key-value store. In Proc. 23rd ACM Symposium on Operating\nSystems Principles (SOSP) , pages 1–13, 2011. doi:10.1145/2043556.2043558 .\n43Antoine Limasset, Guillaume Rizk, Rayan Chikhi, and Pierre Peterlongo. Fast and scalable\nminimal perfect hashing for massive key sets. In Proc. 16th International Symposium on\nExperimental Algorithms (SEA) , pages 25:1–25:16, 2017. doi:10.4230/LIPICS.SEA.2017.25 .\n44Bohdan S. Majewski, Nicholas C. Wormald, George Havas, and Zbigniew J. Czech. A family of\nperfect hashing methods. Comput. J. , 39(6):547–554, 1996. doi:10.1093/COMJNL/39.6.547 .\n45Ingo Müller, Peter Sanders, Robert Schulze, and Wei Zhou. Retrieval and perfect hashing\nusing fingerprinting. In Proc. 13th International Symposium on Experimental Algorithms\n(SEA), pages 138–149, 2014. doi:10.1007/978-3-319-07959-2_12 .\n46J. Ian Munro and Venkatesh Raman. Succinct representation of balanced parentheses and\nstatic trees. SIAM J. Comput. , 31(3):762–776, 2001. doi:10.1137/S0097539799364092 .\n47Gonzalo Navarro. Spaces, trees, and colors: The algorithmic landscape of document retrieval\non sequences. ACM Comput. Surv. , 46(4):1–47, 2014. doi:10.1145/2535933 .\n48Gonzalo Navarro. Compact data structures: a practical approach . Cambridge University Press,\n2016.\n49Gonzalo Navarro and Javiel Rojas-Ledesma. Predecessor search. ACM Comput. Surv. , 53(5),\n2020. doi:10.1145/3409371 .\n50Giuseppe Ottaviano and Rossano Venturini. Partitioned Elias-Fano indexes. In Proc. 37th\nInternational ACM Conference on Research and Development in Information Retrieval (SIGIR) ,\npages 273–282, 2014. doi:10.1145/2600428.2609615 .\n51Giulio E. Pibiri and Roberto Trani. PTHash: Revisiting FCH minimal perfect hashing. In Proc.\n44th International ACM Conference on Research and Development in Information Retrieval\n(SIGIR), pages 1339–1348, 2021. doi:10.1145/3404835.3462849 .\n52Ibrahim Sabek, Kapil Vaidya, Dominik Horn, Andreas Kipf, Michael Mitzenmacher, and\nTim Kraska. Can learned models replace hash functions? PVLDB, 16(3):532–545, 2022.\ndoi:10.14778/3570690.3570702 .\n53Sebastiano Vigna. Broadword implementation of rank/select queries. In Proc. 7th International\nWorkshop on Experimental Algorithms (WEA) , pages 154–168. Springer, 2008. doi:10.1007/\n978-3-540-68552-4_12 .\n54Stefan Walzer. Peeling close to the orientability threshold - spatial coupling in hashing-based\ndata structures. In Proc. 32nd ACM-SIAM Symposium on Discrete Algorithms (SODA) , pages\n2194–2211, 2021. doi:10.1137/1.9781611976465.131 .\n55Ian H. Witten, Alistair Moffat, and Timothy C. Bell. Managing Gigabytes: Compressing and\nIndexing Documents and Images . Morgan Kaufmann, 2nd edition, 1999.\n\n18 Learned Monotone Minimal Perfect Hashing\nA Variants and Refinements\nThe following section explains in detail our proposed variants and refinements inside the\nLeMonHash framework.\nExternal Memory Construction. To construct the PGM-index with a specific εvalue, a\nsingle scan over the input data is sufficient. As soon as one of the segments is constructed, the\ncorresponding keys can be mapped to buckets and the input for the retrieval data structures\ncan be generated. The retrieval data structures can be constructed in external memory as\nwell [15]. The construction of LeMonHash can therefore be performed entirely in external\nmemory. External memory queries are possible by selecting a suitable data structure for\npredecessor queries inside the PGM-index (such as the recursive structure in [25]), as well\nas an external-memory encoding of the bucket sizes. LeMonHash-VL can be constructed\nand queried in external memory using similar considerations. While the recursion needs\nadditional passes over the input data, note that the construction is performed in depth-first\norder, so it can profit from the locality between different levels.\nParallel Construction. As described in [3], it is easy to divide any MMPHF into multiple\nbuckets (see Section 3). The buckets can then be constructed independently in parallel,\nbut this naive construction introduces some query overhead due to adding another layer\non top of the data structure. Instead, the LeMonHash construction can be parallelised\ntransparently to the queries. We can divide the input data into ranges and construct\nindependent PGM-indexes on each range. When concatenating the linear models of all\nranges, we get a PGM-index for the whole input set. An advantage of this approach is that it\nis transparent to the queries. With the naive division, this index stores a negligible number\nof additional segments linear in the number of processors, but these cut-points can likely\nbe “repaired” locally, so that we do not get a space overhead for most inputs. Mapping\nall keys to buckets by evaluating the PGM and therefore determining the input for the\nretrieval data structures is possible in parallel as well. Finally, the retrieval data structures\ncan be constructed in parallel. This is again transparent to the queries and introduces only a\nnegligible space overhead linear in the number of processors [15]. For variable-length strings,\neach node of the LeMonHash-VL construction can be parallelised just like described above.\nOn top of that, different child nodes can be constructed independently in parallel.\nRecursive Bucket Splitting. Inside a bucket, our implementation explicitly stores the ranks\nof all keys. Let us call this strategy Direct Rank Storing (DRS). An alternative method to\ndetermine the ranks within a bucket is Recursive Bucket Splitting (RBS). Take a bucket of\nsizebthat can contain keys from the range (L,R). We can now split this bucket in half by\nstoring how many of the keys are smaller than M= (L+R)/2. This takes⌈log2(b+ 1)⌉bits\nand splits the bucket into two sub-buckets of average size b/2. The two sub-buckets can be\nhandled recursively. For uniform random inputs with an average bucket size of b≥3, RBS\nneeds less space than DRS. This reduction in space usage comes at the cost of more expensive\nquery operations. In particular, we need to query the retrieval data structures for every level\nin that bucket-internal tree. An additional problem with this variant is that it depends on the\ndistribution of keys. In the worst case, when all key values are very close to L, the approach\nrepeatedly needs to store the fact that bkeys are smaller than the midpoint. This can lead\nto a space usage close to log(b)log(R−L), which can be arbitrarily large depending on the\nuniverse size. We therefore did not implement this construction for LeMonHash.Whether the\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 19\nRBS technique still works well with real-world data sets remains an open question. Given\nthat many MMPHF construction algorithms use the bucketing technique (see Section 3), the\nRBS technique might still be of general interest for MMPHFs.\nIndexed Chunk Extraction. As described in Section 5, the chunks in LeMonHash-VL\nare generated from consecutive characters. Now consider an input where the positions of\nbranching characters of the keys are very far. Then the chunks encode a lot of data that is not\nnecessary to differentiate the keys. Instead, it is possible to determine the distinct minima of\nthe LCP values of strings in the corresponding node. Then chunks can be generated from\nthe positions at these minima, which reduces the height of the tree. In practice, however, we\nfind that the plain version is faster and more space efficient (see Section 8.1).\nB Full Proofs\nFull proof of Theorem 1. Fornuniform random integers mapped to nbuckets, the number\nof keys per bucket follows a binomial distribution with p= 1/n. For large n, we can\napproximate this by the Poisson distribution with λ=n·1/n= 1. Therefore, the probability\nthat a bucket has size kisλke−λ\nk!=1\nk!e. Storing a bucket of size krequireskentries in the\ncorresponding retrieval data structure, and each needs ⌈logk⌉bits. Note that buckets of size\n0and1do not need to store ranks. Using the linearity of expectation, the average total\nnumber of bits to store in retrieval data structures is:\nE(space ) =n·E(space per bucket ) =n·∞/summationdisplay\nk=2k⌈logk⌉·1\nk!e≈0.91536n.\nA succinct retrieval data structure can then store this using ≈0.91536n+o(n)bits of\nspace. The Elias-Fano coded sequence of global ranks takes 2n+o(n)bits. Overall, we get a\nspace usage of≈n(2.91536 +o(1))bits.\nFor queries, the evaluation of the linear function and rounding can be executed in constant\ntime. Now that we have the bucket index, we retrieve its offset and size from that binary\nsequence using two constant time select 1queries. From that, we know which retrieval data\nstructure to query, and the actual query works in constant time [15]. ◀\nFull proof of Theorem 2. The rank estimate returned by the PGM is guaranteed to be far\nfrom the correct rank by ε. In other words, given a bucket number i∈[n], any of the input\nkeys with rank between max{1,i−ε}andmin{i+ε,n}can be mapped to it, thus yielding\na bucket of size at most b= 2ε+ 1. In the worst case, there are n/(2ε+ 1)of such size- b\nbuckets, which overall require storing nlocal ranks in a⌈logb⌉-bit retrieval data structure.\nAdditional 2n+o(n)bits are needed for the Elias-Fano coded sequence of global ranks.\nThe remaining term of the space bound is given by the PGM, that we encode with an Elias-\nFano representation of linear models’ (x,y)-endpoints in m(logu\nm+logn\nm+ 2log(2ε+ 1)) +\nO(m)bits [22]. This can be bounded by O/parenleftbig\nmlogu\nm/parenrightbig\nbits, since from [25, Lemma 2] it holds\n2ε≤n/m≤u/m. Finally, webuildthepredecessorstructureof[6,TheoremA.1]onthelinear\nmodels’ keys, which takes O/parenleftbig\nmlogu\nm/parenrightbig\nbits and yields a query time of O/parenleftbig\nlog logwu\nm/parenrightbig\n.◀\nC Low-Level Optimizations\nIn addition to the main algorithmic optimizations described in the main part, we here detail\nsome more low-level optimizations of our implementation.\n\n20 Learned Monotone Minimal Perfect Hashing\n64 128 256 51266.57\nRecursion thresholdBits/keytext\n64 128 256 512\nRecursion thresholddna\n64 128 256 512\nRecursion thresholdurls\nPerfect Chunk Mapping threshold: 32 64 128 256\nFigure A.1 Different thresholds for when to store ranks (of keys and chunks) explicitly.\nWe encode the alphabet reduction as a bitmap and use the popcount instruction to\ndetermine a character’s index. For determining how many characters fit into a chunk with\na given alphabet, we use a lookup table of size 256 because that is more efficient than a\n(floating point) logarithm and division. Depending on the dataset, multiple nodes of the\ntree might use alphabet reduction with a similar alphabet. When constructing a node, we\ntherefore look if another node stores a superset of the alphabet that still leads to the same\nnumber of characters fitting into a chunk, and possibly re-use the alphabet. If no alphabet\nreduction is used, we use the bswapinstruction to immediately convert the next 8 characters\nto a chunk.\nTo speed up access in Elias-Fano coded sequences, we use the clzinstruction, which\ncounts the number of leading zeroes in a word. When calculating the LCP of strings, we\ndo so for multiple bytes at once using 64-bit comparisons. This general idea was already\nevaluated in Ref. [16]. To avoid accessing the strings during alphabet map creation (which\nwould lead to cache faults), we annotate the LCP array with the branching characters.\nTo decode the PGM metadata, which is stored as integers of small width, we use the\nbextrinstruction to extract specific bits from a word. To evaluate the PGM, we use a 64-bit\ndivision with overflow detection instead of a 128-bit division because in practice, 64 bits are\noften enough to store the operands. For the PGM that auto-tunes its εvalue, we abort early\nwhen we detect that the PGM itself is already larger than the optimal cost. This way, very\nsmallεvalues can often be ruled out earlier.\nD Additional Experimental Data\nTable A.1 repeats the measurements of Figures 2 and 3, so that exact values can be compared.\nThresholds. Figure A.1 compares different thresholds for when to stop recursion (see\nSection 5), as well as when to store ranks of chunks explicitly (see Section 5) in LeMonHash-\nVL. The behaviour of the different datasets is very similar, which is (as mentioned in\nSection 8.1) not surprising since the space overhead of a single-segment PGM bucket mapper\nis constant. While we have not plotted the query performance here, note that queries get\nslightly faster when increasing the recursion threshold because that reduces the height of the\ntree.\n\nP. Ferragina, H.-P. Lehmann, P. Sanders, G. Vinciguerra 21\nTable A.1 Comparison of string data sets. Query throughput is given in kQueries/s and space usage is given in bit/key (bpk).\nMethod text dna urls 5gram fb osm uniform normal exponential\nkq/s bpk kq/s bpk kq/s bpk kq/s bpk kq/s bpk kq/s bpk kq/s bpk kq/s bpk kq/s bpk\nCentroid HT [34] 560 6.78 294 9.05 399 8.36 398 5.09 363 5.47 295 5.95 413 5.55 400 5.54 375 5.55\nHTDist\n [3] 92 5.40 80 5.67 52 5.70 115 4.67 97 4.84 73 4.81 133 4.69 122 4.69 127 4.69\nHollow [34] 345 5.84 252 7.87 153 7.42 300 4.15 276 4.53 187 5.01 351 4.61 339 4.60 356 4.61\nHollow\n [3] 148 6.90 124 9.26 73 8.41 162 4.07 150 4.50 110 4.96 179 4.54 169 4.53 188 4.54\nLCP 2-step\n [3] 1176 13.12 834 11.62 394 17.81 926 9.98 938 10.79 903 11.00 1193 9.46 1096 9.87 1093 9.97\nLCP\n[3] 1291 21.61 1161 16.23 430 22.74 1429 12.90 1269 12.90 1364 12.97 1535 11.77 1711 12.87 1660 12.87\nPaCo\n[3] 339 7.88 350 8.77 181 11.09 429 6.13 397 6.44 340 6.69 522 6.50 463 6.30 471 6.42\nPath Decomp. [34] 579 54.44 185 148.27 224 228.88 crashes on integers\nVLLCP\n [3] 816 18.43 611 20.13 315 22.59 723 16.30 690 17.56 692 16.86 823 16.26 780 16.27 868 16.27\nVLPaCo\n [3] 337 8.19 360 9.86 177 11.06 423 7.25 404 7.56 320 7.81 500 7.61 449 7.41 465 7.53\nZFast\n[3] 530 8.88 269 8.71 198 8.77 487 7.59 441 7.73 345 7.87 591 7.63 581 7.64 611 7.78\nLeMonHash-VL 1278 6.08 790 6.25 338 6.46 1458 2.98 1111 4.91 857 4.39 1572 3.33 1647 3.32 1635 3.33\nLeMonHash only supports integers 2421 2.63 1463 4.91 1338 4.42 2718 2.98 2657 2.97 2493 2.98",
  "textLength": 70939
}