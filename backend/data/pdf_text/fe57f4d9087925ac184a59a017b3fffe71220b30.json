{
  "paperId": "fe57f4d9087925ac184a59a017b3fffe71220b30",
  "title": "GLIN: A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries",
  "pdfPath": "fe57f4d9087925ac184a59a017b3fffe71220b30.pdf",
  "text": "GLIN : A (G)eneric (L)earned (In)dexing Mechanism for Complex\nGeometries\nCongying Wangâˆ—\nUniversity at Buffalo\ncwang39@buffalo.eduJia Yu\nWSU, Wherobots Inc.\njia.yu1@wsu.eduZhuoyue Zhao\nUniversity at Buffalo\nzzhao35@buffalo.edu\nABSTRACT\nAlthough spatial indexes shorten the query response time, they\nrely on complex tree structures to narrow down the search space.\nSuch structures in turn yield additional storage overhead and take\na toll on index maintenance. Recently, there have been a flurry of\nefforts attempting to leverage Machine-Learning (ML) models to\nsimplify the index structures. However, existing geospatial indexes\ncan only index point data rather than complex geometries such as\npolygons and trajectories that are widely available in geospatial\ndata. As a result, they cannot efficiently and correctly answer geom-\netry relationship queries. This paper introduces GLIN , an indexing\nmechanism for spatial relationship queries on complex geometries.\nTo achieve that, GLIN transforms geometries to Z-address intervals,\nand then harnesses an existing order-preserving learned index to\nmodel the cumulative distribution function between these intervals\nand the record positions. The lightweight learned index greatly re-\nduces indexing overhead and provides faster or comparable query\nlatency. Most importantly, GLIN augments spatial query windows\nto support queries exactly for common spatial relationships. Our\nexperiments on real-world and synthetic datasets show that GLIN\nhas 80%-90% lower storage overhead than Quad-Tree and 60% -\n80% than R-tree and 30% - 70% faster query on medium selectivity.\nMoreover, GLIN â€™s maintenance throughput is 1.5 times higher on\ninsertion and 3 - 5 times higher on deletion.\nKEYWORDS\ngeospatial data, database indexing, machine learning\nACM Reference Format:\nCongying Wang, Jia Yu, and Zhuoyue Zhao. 2018. GLIN : A (G)eneric (L)earned\n(In)dexing Mechanism for Complex Geometries. In Woodstock â€™18: ACM Sym-\nposium on Neural Gaze Detection, June 03â€“05, 2018, Woodstock, NY. ACM,\nNew York, NY, USA, 12 pages. https://doi.org/10.1145/1122445.1122456\n1 INTRODUCTION\nDatabase Management Systems (DBMSs) often create spatial in-\ndexes such as R-Tree [ 10], JED-Tree [ 2], and Quad-Tree [ 23] to accel-\nerate queries on geospatial data. Although spatial index structures\nshorten query response time, they rely on complex tree structures\nâˆ—Part of this work was conducted while the author was affiliated with WSU.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nÂ©2018 Association for Computing Machinery.\nACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00\nhttps://doi.org/10.1145/1122445.1122456to narrow down the search space. Such structures in turn yield ad-\nditional storage overhead and take a toll on index maintenance [ 30].\nRecent works on spatial indices [ 19,26] mostly focus on acceler-\nating query speed at the cost of even higher storage overhead. As\ndepicted in Table 1a, R-Tree and Quad-Tree usually cost 10% - 20%\nadditional storage overhead. This leads to significant dollar cost es-\npecially now that most enterprises move their data to cloud storage\nfor better security and stability. Table 1b shows the cloud storage\ncost we collect from Amazon Web Services (AWS) EC2, the most\npopular cloud vendor. Such storage services are typically charged\non a monthly or even an hourly basis, with additional fees for data\ntransfer, which can result in unexpected bills for the users.\nTable 1: Index storage overhead and storage dollar cost\n(a) Index storage overhead on geospatial data (described in Table 4)\nBoost R-Tree GEOS Quad-Tree\nROADS (8.3GB) 1.57GB 1.98GB\nLinearWater (6.4GB) 461.1 MB 685 MB\nParks (8.5GB) 783 MB 1.01GB\n(b) Cloud storage cost on Amazon Web Services EC2 instances\nRAM (no. CPU) SSD storage Data transfer\n32GB (2): $0.16/hour L1: $0.08/GB/month Internal 1: $0.01/GB\n64GB (4): $0.33/hour L2: $0.10/GB/month Internal 2: $0.02/GB\n128GB (8): $0.66/hour L3: $0.12/GB/month External: $0.09/GB\nOn the other hand, as open data lake formats such as Apache Par-\nquet [ 21] and GeoParquet [ 9], become widely adopted, and as the\ntrend to separate storage and computation layers in the cloud con-\ntinues, researchers and practitioners are increasingly focusing their\nefforts on leveraging lightweight index structures. This strategy is\naimed at enhancing data skipping efficiency at the storage level.\nSeveral works leverage data synopses such as min-max, bounding\nbox, and histograms [ 11,24,29,30] from the indexed data to navi-\ngate queries. They adopt much simpler data structure, which bring\ndown the cost of storing and maintaining the index. However, they\ncompromise on query response time and cannot be easily tailored\nto geospatial data (e.g., polygons, trajectories, etc.).\nRecently, there have been a flurry of works [ 6,14,28] attempting\nto leverage Machine-Learning (ML) models to simplify the index\nstructures. An index, denoted as ğ‘¦=ğ‘“(ğ‘¥), can be viewed as an ML\nmodel, where x is the lookup key and y is the physical position of the\ncomplete record in an array. Theoretically, this ML model learns\nthe Cumulative Distribution Function (CDF) between keys and\ntheir positions in a sorted array. Although learned index structures\ndemonstrate promising results on space saving and query speedup\nas opposed to the traditional B+ Tree index, these approaches only\nwork for 1-dimensional (1-D) sortable values\nTo remedy that, follow-up works extend the idea to support\ngeospatial points. These approaches [ 16,18,27] partition the mul-\ntidimensional space to cells and assign IDs to these cells usingarXiv:2207.07745v2  [cs.DB]  14 Sep 2023\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Congying Wang, Jia Yu, and Zhuoyue Zhao\nspace-filling curve (e.g., Z-order curve [ 27]) or mathematical equa-\ntions [ 16]. They can reduce data dimension to 1-D and thus can be\nindexed by learned indexes. They work well for geospatial points\nbut are incapable of handling complex geometries such as polygons\nand trajectories which are widely available in geospatial data. One\nreason is that complex geometries can intersect multiple cells and\nthus have more than one IDs. This leads to duplicates in the final re-\nsult [ 31] and introduces additional challenges in index maintenance.\nIn addition, the user must hand-tune the partitioning resolution\nto find an appropriate cell size that is small enough but also does\nnot introduce too many duplicates. Finding such a sweet spot can\nbe prohibitively expensive especially when indexed geometries go\nacross large regions by nature (e.g., trajectories).\nDesigning a learned index structure for complex geometries\npresents several major challenges, stated as follows: (1) Shapes.\nGeometries are collections of various complex shapes including\npolygons and trajectories, which have been standardized to 7 cat-\negories [ 8]. Geometries are not 1-D or 2-D point values. Thus we\ncannot establish a CDF from such data to their positions for an exist-\ning learned indexes. (2) Spatial distribution. Geometries often show\nskewed spatial distributions in the space. For example, most land-\nmarks, such as parks, hospitals, and government buildings, cluster\nat major metropolitan regions. The index structures should adapt to\nsuch distributions for better prediction performance. (3) Spatial rela-\ntionship. Geometries may have various spatial relationships such as\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  ,ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  ,ğ‘‡ğ‘œğ‘¢ğ‘â„ğ‘’ğ‘  , andğ·ğ‘–ğ‘ ğ‘—ğ‘œğ‘–ğ‘›ğ‘¡ . Given a spatial query,\nthe learned index structures must return all geometries that satisfy\nthe spatial relationship to the query geometry.\nThis paper proposes GLIN1, a lightweight learned indexing\nmechanism for spatial range queries on complex geometries such\nas points, polygons, and trajectories. GLIN by design produces low\nstorage and maintenance overhead while achieving competitive\nquery performance in common cases, as opposed to Quad-Tree\nand R-Tree. Moreover, GLIN can work in conjunction with existing\nregular learned indexes to enable geospatial data support. Our\ncontributions in this paper are summarized as follows:\nâ€¢GLIN transforms geometries to 1-D sortable values using Z-\norder curve. We prove that GLIN can always deliver correct results\nfor bothğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  andğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  spatial relationships.\nâ€¢For any existing order-preserving learned indexes (Section 4),\nGLIN can extend it to index Z-address values and further improves\nthe search performance by introducing additional information in\nleaf models. To the best of our knowledge, it is the first indexing\nmechanism that enables learned indexes on non-point data.\nâ€¢GLIN equips efficient algorithms to update its structure for data\ninsertion and deletion while offering the query accuracy guarantees.\nâ€¢Our experimental analysis on real-world dataset shows that\nGLIN has 80% - 90% lower storage overhead than Quad-Tree and 60%\n- 80% than R-tree. Meanwhile, GLIN has faster query response time\non medium selectivity. Its update throughput is 1.5 times higher on\ninsertion and 3 5 times higher on deletion.\n2 BACKGROUND\nSpatial range query. Given a query window ğ‘„, a spatial dataset ğ‘…\nand a predefined spatial relationship ğ‘†ğ‘…, a range query denoted as\n1GLIN GitHub repository: https://github.com/DataOceanLab/GLINğ‘Ÿğ‘ğ‘›ğ‘”ğ‘’(ğ‘„,ğ‘…,ğ‘†ğ‘…)finds the geometries in ğ‘…such that each geometry\n(denoted as ğºğ‘€) hasğ‘†ğ‘…relationship with ğ‘„.ğºğ‘€andğ‘„can have\nany shapes including polygons and lines.\nSpatial relationship. SQL/MM3 standard [ 8] lists a number of\npossible spatial relationships between two geometries. This includes\nbut is not limited to: Contains, Intersects, Touches, and Disjoint. In\nthis paper, we focus on the two most common spatial relationships:\n(1)ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  (Figure 2 Case 1): given two geometries ğ‘„andğºğ‘€,\n\"Q contains GM\" is true if and only if no points of GM lie in the\nexterior of Q, and at least one point of the interior of GM lies in\nthe interior of Q. (2) ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  (Figure 2 Case 1, 2, 3): given two\ngeometriesğ‘„andğºğ‘€, \"Q intersects GM\" is true if Q and GM share\nany portion of space. ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  is a special case of ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  . If \"Q\ncontains GM\" is true, then \"Q intersects GM\" must be true as well.\nMinimum Bounding Rectangle (MBR). An MBR describes\nthe maximum extents of a 2-dimensional geometry in an (ğ‘¥,ğ‘¦)co-\nordinate system. An MBR consists of four values, the minimum and\nmaximum values of ğ‘¥andğ‘¦coordinates of a geometry, and are rep-\nresented as two points, ğ‘ğ‘šğ‘–ğ‘›(ğ‘¥ğ‘šğ‘–ğ‘›,ğ‘¦ğ‘šğ‘–ğ‘›)andğ‘ğ‘šğ‘ğ‘¥(ğ‘¥ğ‘šğ‘ğ‘¥,ğ‘¦ğ‘šğ‘ğ‘¥)\n(see Figure 2 Case 1). The coordinates of the MBR can be easily\nobtained by iterating every coordinate of a geometry. MBR is often\nused to approximate geometries since it is a much simpler shape.\nProbing and Refinement steps of spatial index search. Most\nexisting spatial indexing mechanisms, such as R-Tree, Quad-Tree,\nand KD-Tree, approximate complex geometries to their MBR and\nthen build index structures on MBRs. A spatial range query is pro-\ncessed mostly in two steps. (1) ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ‘ğ‘Ÿğ‘œğ‘ğ‘–ğ‘›ğ‘” : the MBR of the query\nwindow is processed against the spatial index. It returns a set of\ncandidate geometries whose MBRs possibly ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ the query\nwindow MBR. This set of candidates is not the exact answer of\nthis query but is a super set of the answer. (2) ğ‘…ğ‘’ğ‘“ğ‘–ğ‘›ğ‘’ğ‘šğ‘’ğ‘›ğ‘¡ : the\ncandidate geometries are checked against the query window using\ntheir actual shapes with a spatial relationship such as ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  or\nğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  . The refinement step is computationally expensive due\nto the complexity of shapes and usually takes more time than the\nprobing step [ 3].GLIN also follows this two-step process which\ncan significantly reduce computation cost and index storage over-\nhead. Existing learned spatial indexes [ 16,18,27] only perform the\nprobing step and their results might only be a subset of the exact\nanswer if the underlying data is not points.\n3 OVERVIEW\nThe index structure of GLIN is depicted in Figure 1.\nZ-address interval. To establish this CDF and enable the model\ntraining process, GLIN assigns each geometry a Z-address interval,\nan one-dimensional sortable interval (serve as keys), by using a\nwell-known space-filling curve called Z-order curve. In this paper,\nwe also study that how ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  andğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationships are\nreflected on Z-address intervals and prove that GLIN can guarantee\nthe query accuracy in both cases.\nIndex structure. Once the CDF is made available between Z-\naddress intervals and record positions, GLIN can harness an existing\norder-preserving learned indexes, called the base index, such as\nALEX [ 6] and RadixSpline [ 13] to model the CDF. Since Z-address\nintervals cannot 100% preserve the original shape information and\nspatial proximity, the index probing will return some false positive\n\nGLIN : A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\n[ ],\n[ ],[ ],\n[ ],\n[ ],[ ],[ ],[ ],\n[ ],\n[ ],0 1\n12 22 3\n63\n39 58\n1012\n14Z-add ress interval\n[2, 11]\nRefinement sta rts Refinement sta rts\n(Augmented)Refinement endsmodel\n......\n4\n75model .........model model\nmodelmodel\nmodel model model ... ...(0,1)\n(1, 3)Query window\n(2, 0)\n(3, 1)(0, 1)\n(1, 2)(0, 0)\n(2, 2)(0, 2)\n(2, 3)\n9\n12\nFigure 1: GLIN index structure. White nodes are internal\nnodes and colored nodes are leaves. Index search: (1) ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  :\nfollow the red paths and return red records. The gray node is\nskipped as its MBR does not intersect the query. (2) ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  :\nfollow the yellow path and the second red path. Red and\nyellow records will be returned.\nTable 2: Notations used in this paper\nTerm Definition\nQ, GM Q - a spatial range query window. GM - an indexed geometry. Both\ncan be in any shapes.\nMBR Minimum Bounding Rectangle of a geometry, represented as two\npointsğ‘ğ‘šğ‘–ğ‘›(ğ‘¥ğ‘šğ‘–ğ‘›,ğ‘¦ğ‘šğ‘–ğ‘›)andğ‘ğ‘šğ‘ğ‘¥(ğ‘¥ğ‘šğ‘ğ‘¥,ğ‘¦ğ‘šğ‘ğ‘¥)\nğ‘€ğµğ‘…ğ‘„- MBR of Q.ğ‘€ğµğ‘…ğºğ‘€- MBR of GM.\nZmin Z-address for ğ‘ğ‘šğ‘–ğ‘› of a MBR\nğ‘ğ‘šğ‘–ğ‘›ğ‘„- Zmin of Q, ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€- Zmin of GM.\nZmax Z-address for ğ‘ğ‘šğ‘ğ‘¥ of a MBR\nğ‘ğ‘šğ‘ğ‘¥ğ‘„- Zmax of Q, ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€- Zmax of GM.\nZitvl Z-address interval described by Jğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥ K\nğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„- Zitvl of Q,ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğºğ‘€- Zitvl of GM.\nresults. In response, GLIN introduces a refinement phase to prune\nout all false positives. In addition, it creates a MBR on each leaf\nnode of the hierarchical model to accelerate the refinement phase.\nQuery augmentation. The basic indexing mechanism in GLIN\nis designed to handle ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  relationship and may produce true\nnegatives for ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship. To remedy that, GLIN employs\na piecewise function with outlier handling to augment the query\nwindow. More precisely, GLIN will enlarge the Z-address interval\nof the query window to make sure that it covers all correct results\nat the cost of additional pruning time.\n4 Z-ADDRESS INTERVALS AND ORDER\nPRESERVING INDEXES\nNotations used in this section are summarized in Table 2.\nZ-address. Z-order curve is a Z-shape curve (see Figure 2) that\nconnects all 2-dimensional positive integer coordinates in the space.\nEach coordinate(ğ‘¥,ğ‘¦)will then have a Z-address. The Z-addresses\nof two nearby coordinates will likely be close to each other. For\nexample,ğ‘ğ‘šğ‘–ğ‘›(0,1)in Figure 2 will have a Z-address 2. GLIN\nrounds down geospatial coordinates to their nearest integers: x\n0 1 2 3 4 5 6 7\n0 0 1 4 5 16172021\n1 2 3 6 7 18192223\n2 8 9 121324252829\n3 1011141526273031\n4 3233363748495253\n5 3435383950515455\n6 4041444556576061\n7 4243464758596263X\nY\nCase 1\nGMpmin\npmaxQCase 2\nCase 3Figure 2: Spatial relationship. Case 1: Q ğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  GM; Case 1,\n2, 3: Qğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  GM. Z-address( ğ‘ğ‘šğ‘–ğ‘›) = 2, Z-address( ğ‘ğ‘šğ‘ğ‘¥) =\n11, Z-address interval of Q in Case 1 = J2,11K.\n=ğ‘™ğ‘œğ‘›ğ‘”ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’âˆ’(âˆ’180â—¦)\nğ‘ğ‘’ğ‘™ğ‘™ ğ‘ ğ‘–ğ‘§ğ‘’and y =ğ‘™ğ‘ğ‘¡ğ‘–ğ‘¡ğ‘¢ğ‘‘ğ‘’âˆ’(âˆ’90â—¦)\nğ‘ğ‘’ğ‘™ğ‘™ ğ‘ ğ‘–ğ‘§ğ‘’. Then it calculates the\nZ-address using libmorton [ 17] which interleaves the binary rep-\nresentation of x and y coordinates [ 15]. GLIN sets the cell size\nas5Ã—10âˆ’7to represent centimeter-level precision [ 5]. Detailed\ndiscussion can be found in Section A.3.\nZ-address interval. GLIN assigns a Z-address interval, Zitvl\nJğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥ K, for every geometry including the indexed geome-\ntries and the range query window. It is computed in two steps:\n(1) find the MBR of a geometry, represented as ğ‘ğ‘šğ‘–ğ‘›(ğ‘¥ğ‘šğ‘–ğ‘›,ğ‘¦ğ‘šğ‘–ğ‘›)\nandğ‘ğ‘šğ‘ğ‘¥(ğ‘¥ğ‘šğ‘ğ‘¥,ğ‘¦ğ‘šğ‘ğ‘¥); (2) compute the minimum and maximum\nZ-addresses ğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥ fromğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥ respectively. In Figure 2\nCase 1, Q has ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„J2,11K.\nNotes. (1) When calculating ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ ,GLIN must useğ‘ğ‘šğ‘–ğ‘›and\nğ‘ğ‘šğ‘ğ‘¥ rather than vertices of the geometry because ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ from the\nlatter might not cover all Z-addresses touched by the geometry. For\nexample, vertices of Q in Figure 2 Case 1 indicate ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ =J3,11K,\nwhich misses Z-address 2. (2) We choose Z-order curve due to\nits monotonic ordering property [15] which guarantees that ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™\nfromğ‘ğ‘šğ‘–ğ‘›andğ‘ğ‘šğ‘ğ‘¥ covers the Z-address of any point that falls\ninside this geometry [ 27]. In Hilbert curve (or other space filling\ncurves), the ğ»ğ‘šğ‘–ğ‘› andğ»ğ‘šğ‘ğ‘¥ of the desired ğ»ğ‘–ğ‘¡ğ‘£ğ‘™ are actually on\nthe boundary of the MBR (details omitted due to page limit). To\nobtain such ğ»ğ‘–ğ‘¡ğ‘£ğ‘™ , we have to calculate every H-address touched by\nthe MBR. This will significantly slow down the queries and require\nto tune the cell size which cannot be too large or too small.\nSpatial relationship between intervals. Since GLIN is built\non Z-address intervals, when we examine the spatial relationship\nbetween Q and GM, we also need to understand how this relation-\nship translates to Z-address intervals of ğ‘„andğºğ‘€, denoted as\nğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„andğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğºğ‘€, respectively. We show two important lemmas\nbelow which allow us to prune the search space for ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  and\nğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship using range scans. The proofs are given in\nAppendix A in the interest of space.\nlemma 1. Z-address interval Contains .If Qğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  GM, then\nğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„ğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘ ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ ğºğ‘€\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Congying Wang, Jia Yu, and Zhuoyue Zhao\nwhereğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„ğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ ğºğ‘€â‡â‡’ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€â‰¤\nğ‘ğ‘šğ‘ğ‘¥ğ‘„âˆ§ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€â‰¤ğ‘ğ‘šğ‘ğ‘¥ğ‘„.\nlemma 2. Z-address interval Intersects .If Qğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  GM,\nthenğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘ ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ ğºğ‘€\nwhereğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘ ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ ğºğ‘€â‡â‡’ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€âˆ§\nğ‘ğ‘šğ‘ğ‘¥ğ‘„â‰¥ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€. In other words, ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„andğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğºğ‘€share\nsome portion of the intervals\nOrder-preserving learned index. GLIN is designed as a gen-\neral framework to adapt 1-D learned indexes as spatial indexes\nfor polygon relationship queries. One important property that the\nunderlying index must satisfy is order-preserving . To explain why,\nwe first define the order-preserving property.\nDefinition 4.1. Letğ¼be a 1-D range index where the leaves store\nitem keys. The keys in the leaves can be conceptually concatenated\ninto a list in the pre-order traversal of the index. We say a 1-D range\nindex is order-preserving if the list is in sorted order.\nOrder-preserving is crucial for us to correctly prune the search\nsearch space in tree probing. Suppose we index the geometries with\nan order-preserving range index using ğ‘ğ‘šğ‘–ğ‘› of the geometries. As\nwe will show later, Lemma 1 and 2 allow us to search for geometrices\nwith respect to a query geometry ğ‘„using a sufficiently large ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ .\nTakingğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  as an example, the range can be Jğ‘ğ‘šğ‘–ğ‘›ğ‘„,ğ‘ğ‘šğ‘ğ‘¥ğ‘„K.\nSince the index is order preserving, we can simply probe the index\nfor the first geometry with ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€â‰¥ğ‘ğ‘šğ‘–ğ‘›ğ‘„and scan the leaf\nlevels until ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€>ğ‘ğ‘šğ‘ğ‘¥ğ‘„. However, we cannot do so if an\nindex is not order preserving as there might be some ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€>\nğ‘ğ‘šğ‘–ğ‘›ğ‘„that appears before the first ğ‘ğ‘šğ‘–ğ‘›ğ‘„(if it exists) in the index.\nIn traditional range indexes such as B-tree (which technically\ncan also be used in GLIN), the list consists of all keys in the leaf level\nfrom left to right. It is order-preserving because the tree strictly\ndivides sub-trees into disjoint and increasing key ranges from left to\nright. Many learned indexes are also order-preserving. For instance,\nALEX [ 6] also divides its key into disjoint and increasing key ranges\nbased on linear regression models, and thus it can be used in GLIN.\nRMI [ 14] is an example of non-order-preserving index because an\nimplementation can choose not to enforce the monotonicity of\nassignment of keys in the internal models when they are complex\nneural networks. Consequently, we cannot use RMI (or adapt any\nRMI based spatial indexes such as RSMI [ 22] to support exact spatial\nrelationship queries).\n5 INDEX INITIALIZATION\nTo create an index, GLIN reads a set of geometry records and initial-\nizes the index structure based on the geometries. The mechanism\ndepicted in this section only handles the spatial range query with\ntheğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  spatial relationship, which is \"the query window con-\ntains geometries\".\nSort geometries by Z-address intervals. To establish the CDF\nbetween keys and record positions, the first step is to put the ge-\nometries in a sequential order. GLIN sorts geometries based on\ntheir Z-address intervals (see Section 4). The reason is two-fold:\n(1) Z-addresses can partially preserve the spatial proximity of ge-\nometries. This is critical because a spatial range query looks for\ngeometries that lie in the same region. This query will inevitably\nscan a large portion of the table if the trained ML model does not\nMinKey MaxKey0.00.20.40.60.81.0PositionZmin\nZmax(a) LW\nMinKey MaxKey0.00.20.40.60.81.0Position\nZmin\nZmax (b) PARKS\nMinKey MaxKey0.00.20.40.60.81.0PositionZmin\nZmax (c) ROADS\nFigure 3: CDFs of different datasets based on ğ‘ğ‘šğ‘–ğ‘› andğ‘ğ‘šğ‘ğ‘¥\nrespect any spatial proximity. (2) A Z-address interval can partially\npreserve the shapes of geometries. This will make it possible for\nGLIN to employ different strategies for ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  andğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘ \nrelationships for the sake of query performance.\nGLIN iterates through every geometry and calculates the Z-\naddress interval (i.e., ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ =Jğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥ K) for this geometry.\nGLIN then sorts these geometries by the ğ‘ğ‘šğ‘–ğ‘› of their intervals.\nIn the rest of the index initialization phase, ğ‘ğ‘šğ‘ğ‘¥ of intervals will\nbe completely discarded. In other words, GLIN actually indexes\n<ğ‘ğ‘šğ‘–ğ‘›,ğ‘”ğ‘’ğ‘œğ‘šğ‘’ğ‘¡ğ‘Ÿğ‘¦ ğ‘˜ğ‘’ğ‘¦ >pairs while traditional spatial indices\nindex <ğ‘€ğµğ‘…,ğ‘”ğ‘’ğ‘œğ‘šğ‘’ğ‘¡ğ‘Ÿğ‘¦ğ‘˜ğ‘’ğ‘¦ >pairs. Later, in the index probing\nphase of the index search, GLIN only checks if the Z-address interval\nof the query window contains ğ‘ğ‘šğ‘–ğ‘› of geometries (i.e., ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤\nğ‘ğ‘šğ‘–ğ‘›ğºğ‘€â‰¤ğ‘ğ‘šğ‘ğ‘¥ğ‘„). According to Lemma 1, this introduces some\nfalse positive results but does not have true-negatives. ğ‘ğ‘šğ‘ğ‘¥ will\nbe used in Section 7 for query augmentation. It is worth noting\nthatGLIN could also sort geometries by the ğ‘ğ‘šğ‘ğ‘¥ instead ofğ‘ğ‘šğ‘–ğ‘› .\nHowever, this will not make much difference in the learned CDF\nmodels since ğ‘ğ‘šğ‘ğ‘¥ will follow the same data distribution of ğ‘ğ‘šğ‘–ğ‘›\n(see Figure 3). In Section 7, both ğ‘ğ‘šğ‘–ğ‘› andğ‘ğ‘šğ‘ğ‘¥ will be needed in\norder to handle ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship.\nBuild the base learned index. Once geometries are sorted by\ntheğ‘ğ‘šğ‘–ğ‘› of their intervals, GLIN will train a base index to learn the\nCDF between these ğ‘ğ‘šğ‘–ğ‘› addresses and the record positions. GLIN\nworks in conjunction with any order-preserving learned index and\nextend it to uphold geometries. These indexes usually possess a\nhierarchical structure to build models for different regions. In this\npaper, we adopt the method in ALEX [ 6] because it supports index\nupdates by design.\nCreate MBRs in leaf nodes. Since GLIN trains and queries\nmodels based on Z-addresses of geometries, the model prediction\nmay introduce more false positives that need to be pruned during\nthe refinement step.\nTo mitigate this, GLIN employs a simple yet efficient method to\nreduce the computation cost. When constructing each leaf node of\nthe hierarchical model, GLIN also creates a MBR of all geometries\nin this node. This can be done by traversing all geometries and\nfinding the overall ğ‘ğ‘šğ‘–ğ‘›(ğ‘¥ğ‘šğ‘–ğ‘›,ğ‘¦ğ‘šğ‘–ğ‘›)andğ‘ğ‘šğ‘ğ‘¥(ğ‘¥ğ‘šğ‘ğ‘¥,ğ‘¦ğ‘šğ‘ğ‘¥). When\nrefining the query results, GLIN will directly skip a leaf node unless\nthe MBR of this node intersects the query windowâ€™s MBR.\nIndex maintenance. For insertion, GLIN takes as input a geom-\netry key and inserts it to the index. To insert a new record, GLIN\nfirst obtains the ğ‘ğ‘šğ‘–ğ‘› address for the geometry key in this record\nusing the approach described in Section 4, then inserts the record\n\nGLIN : A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nto the base index. Once GLIN puts the new record in a leaf node, it\nexpands the MBR of the leaf node to include the new geometry.\nFor deletion, the input is a geometry key and GLIN deletes\nrecords that have the same key. Similar to the insertion, the first\nstep to delete a geometry key is to get the ğ‘ğ‘šğ‘–ğ‘› address of this\ngeometry. It is possible that several different geometries share the\nsameğ‘ğ‘šğ‘–ğ‘› addresses. In that case, GLIN only erases records that\nhave the same geometry key. The MBR of the involved leaf node\nwill not be shrunk after the deletion because it requires a scan of\nall records in this leaf node to get the latest MBR. However, this\ndoes not affect the correctness of GLIN as the out-of-date MBR\nonly introduces more false positives instead of true negatives.\n6 INDEX SEARCH\nAlgorithm 1: GLIN Index Search\nInput : A query window ğ‘„, a spatial relationship ğ‘†ğ‘…\nOutput: A set of records ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ that satisfyğ‘†ğ‘…withğ‘„\n1/* Step 1: index probing */\n2ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„Jğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥ K= calculate_zitvl( ğ‘„);\n3ifSR is \"ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  \" relationship then\n4 // Augment the query window\n5ğ‘ğ‘šğ‘–ğ‘› = augment(ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„, piecewise function). ğ‘ğ‘šğ‘–ğ‘› ;\n6start_position = ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ _ğ‘¡ğ‘Ÿğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘ğ‘™(GLIN.ğ‘Ÿğ‘œğ‘œğ‘¡,ğ‘ğ‘šğ‘–ğ‘›);\n7/* Step 2: refinement */\n8ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ = new List();\n9iterator = start_position;\n10while iterator.keyâ‰¤ğ‘ğ‘šğ‘ğ‘¥ do\n11ğ‘”ğ‘’ğ‘œğ‘š = Get_Record(iterator);\n12 ifğ‘„hasğ‘†ğ‘…withğ‘”ğ‘’ğ‘œğ‘š then\n13ğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ .add(ğ‘”ğ‘’ğ‘œğ‘š );\n14 node = iterator.node();\n15 ifiteratorâ‰¥node.last_position() then\n16 whileğ‘€ğµğ‘…ğ‘„does not intersect ğ‘›ğ‘œğ‘‘ğ‘’.ğ‘€ğµğ‘… do\n17 node = node.next_node(); // Skip this node\n18 iterator = node.first_position();\n19 else\n20 iterator++;\n21Returnğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ ;\n6.1 Probe the base index\nGLIN leverages an existing learned index to build the hierarchical\nmodel based on the ğ‘ğ‘šğ‘–ğ‘› addresses of geometries. Therefore, to\nsearch the index, this algorithm must first obtain the Z-address\ninterval of the query window (see Section 4). The Z-address interval\nJZmin,Zmax Kof the query window will then serve as the actual\ninput for the index probing which finds geometries whose ğ‘ğ‘šğ‘–ğ‘›\nis within the interval. According to Lemma 1, geometries whose\nğ‘ğ‘šğ‘–ğ‘› is not within this interval are guaranteed not to be contained\nby the query window.\nThe process of searching the hierarchy model is identical to\nthe base learned index on which GLIN is built. As described in\nAlgorithm 1, the index probing step requires a tree-like traversal of\nthe hierarchical model (i.e., ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ _ğ‘¡ğ‘Ÿğ‘ğ‘£ğ‘’ğ‘Ÿğ‘ ğ‘ğ‘™ ). It usesğ‘ğ‘šğ‘–ğ‘› address\nof the query window as the lookup key (see the first red pathin\nFigure 1). This traversal runs in a top-down fashion starting from\nthe root. The model inside the root node will predict a position\nin the pointer array using the lookup key. Once the algorithmTable 3: Number of records checked during the refinement\nQuery selectivity W/o leaf MBR W/ leaf MBR\nROADS1% 3339990 369184\n0.1% 1173710 67474\n0.01% 632839 18244\nPARKS1% 1126520 154685\n0.1% 291197 21700\n0.01% 105076 4180\nreaches the leaf node, it will first perform the model prediction to\nfind an approximate position in the record array and then run an\nexponential search from this position to locate the correct result.\n6.2 Refine the results\nThe records returned by the index probing have some false positives\ndue to the following reasons: (1) GLIN uses the MBR of each geome-\ntry to produce the Z-addresses rather than the actual shape. (2) The\nZ address interval includes additional Z-addresses. For example,\nin Case 1 of Figure 2, the ğ‘€ğµğ‘…ğ‘„only contains 6 addresses (2, 3,\n8, 9, 10, 11) but all records whose ğ‘ğ‘šğ‘–ğ‘› values are in J2,11K(the\nZitvl of Q, 10 Z-addresses in total) will be returned by the index\nprobing step. (3) the hierarchical model is built upon the ğ‘ğ‘šğ‘–ğ‘› of\ngeometries without considering ğ‘ğ‘šğ‘ğ‘¥ at all.\nAs given in Algorithm 1, GLIN conducts a refinement step to filter\nout these false positive results and hence offer accuracy guarantee.\nAs illustrated in Figure 1, this refinement starts from the position\nreturned by the ğ‘ğ‘šğ‘–ğ‘› -based model traversal and keeps checking\nif every geometry satisfies the spatial relationship with the query\nwindow using their exact shapes, until it arrives at the position\nwhose key is no larger than the query windowâ€™s ğ‘ğ‘šğ‘ğ‘¥ . The MBRs\nin leaf nodes will help GLIN skip non-intersecting nodes directly.\n7 QUERY AUGMENTATION FOR INTERSECTS\n7.1 The lowest intersecting Z-address\nGiven a query window ğ‘„, Algorithm 1 in Section 6 finds all geome-\ntriesğºğ‘€such thatğ‘ğ‘šğ‘–ğ‘›ğºğ‘€â‰¥ğ‘ğ‘šğ‘–ğ‘›ğ‘„. However, an intersecting ge-\nometryğºğ‘€ may haveğ‘ğ‘šğ‘–ğ‘›ğºğ‘€<ğ‘ğ‘šğ‘–ğ‘›ğ‘„andğ‘ğ‘šğ‘ğ‘¥ğºğ‘€â‰¥ğ‘ğ‘šğ‘–ğ‘›ğ‘„\n(Lemma 2). Therefore, the algorithm does not return a superset\nof all the intersecting geometries. For example, Case 2 in Figure 2\nshows two intersecting polygons whose Z-address intervals are\nJ7,27Kand J13,49K. Let the first one be an indexed geometry ğºğ‘€\nand the second one be the query window ğ‘„.J7,27Kwill be missing\nfrom the final results returned by Algorithm 1.\nA simple solution is, for all geometries that have ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€â‰¥\nğ‘ğ‘šğ‘–ğ‘›ğ‘„, we find the smallest ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€, namely the lowest inter-\nsecting Z-address . Then we augment the query window by tak-\ningğ‘šğ‘–ğ‘›(ğ‘ğ‘šğ‘–ğ‘›ğ‘„,ğ‘™ğ‘œğ‘¤ğ‘’ğ‘ ğ‘¡ ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘›ğ‘”ğ‘ âˆ’ğ‘ğ‘‘ğ‘‘ğ‘Ÿğ‘’ğ‘ ğ‘ ). Unfortunately,\nsince the underlying records are sorted by their ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€instead\nofğ‘ğ‘šğ‘ğ‘¥ğºğ‘€, finding such value for each query requires a full scan,\nwhich is prohibitively expensive. Hence, we need a data structure\nto help GLIN quickly find ğ‘™ğ‘œğ‘¤ğ‘’ğ‘ ğ‘¡ğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘›ğ‘”ğ‘ âˆ’ğ‘ğ‘‘ğ‘‘ğ‘Ÿğ‘’ğ‘ ğ‘  .\n7.2 The piecewise function\nThe intuition is that we divide the domain range of ğ‘ğ‘šğ‘ğ‘¥ to a few\nsub-domains, and precompute the lowest intersecting Z-address\nfor each sub-domain. Consider a set of ğ‘Z-address intervals, let\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Congying Wang, Jia Yu, and Zhuoyue Zhao\n10510910131017\nlength of Zintvl0.00.20.40.60.81.0CDF\nFigure 4: CDF base on ğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™ length\nğ‘be the maximum ğ‘ğ‘šğ‘ğ‘¥ among all intervals. Note that all Z-\naddresses are non-negative and thus the ğ‘ğ‘šğ‘ğ‘¥ of all intervalsâˆˆ\nJ0,ğ‘K. If we divide the range [0,ğ‘]intoğ‘˜disjoint domains: J0,ğ‘1K,\nLğ‘1,ğ‘2K,... Lğ‘ğ‘˜âˆ’1,ğ‘K, we can define a piecewise-constant function\nwith theseğ‘˜pieces and compute the lowest intersecting Z-address\nfor each. To simplify notation, we denote ğ‘0=âˆ’1andğ‘ğ‘˜=ğ‘,\nand thus the ğ‘–ğ‘¡â„piece can be denoted as Lğ‘ğ‘–,ğ‘ğ‘–+1Kfor0â‰¤ğ‘–<ğ‘˜.\nGiven a query window ğ‘„, ifğ‘ğ‘šğ‘–ğ‘›ğ‘„âˆˆLğ‘ğ‘–,ğ‘ğ‘–+1K, we can find such\nvalue on the fly by binary searching the piecewise function, and\nthen augment the query window. It is worth noting that the lowest\nintersecting Z-address monotonically increases over ğ‘–. A proof\nsketch is shown in Appendix A.\nBelow is a possible piecewise function for Z-intervals listed in\nFigure 5. If we want to search for geometries that intersect a query\nwindowğ‘„, whose z-address interval is J2,5K, then we can use\nğ‘“(2)=1as the newğ‘ğ‘šğ‘–ğ‘›ğ‘„to search the base index. Without this\nfunction, we will miss a potentially intersecting geometry J1,2K\nduring the index probing phase.\nğ‘“(ğ‘ğ‘šğ‘–ğ‘›ğ‘„)=ï£±ï£´ï£´ ï£²\nï£´ï£´ï£³1âˆ’1<ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤3\n3 3<ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤6\n5 6<ğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤14\nIssues with long intervals. Long Z-address intervals could\njeopardize the effectiveness of the piecewise function. If we insert\ninterval J0,14Kin the dataset, then the piecewise function becomes\na contant function with value 0everywhere. The reason is that the\nnew interval has to be considered in each lower bound of the lowest\nintersecting z-address because ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€=14is greater than the\nlower ends of all intervals. Fortunately, we observe that such long\nintervals rarely appear in real-world datasets (Figure 4). If we treat\nthem as outliers and separately index them in a different structure,\nthe piecewise function will still produce close lower bounds. In\nGLIN, we first find out the 99% percentile (an adjustable threshold)\nof the lengths of the Z-address intervals as the outlier length thresh-\nold. We treat all intervals with length longer than that as outliers.\nThey are separately maintained in a smaller outlier index using\nthe base index. For any intersects query, we additionally probe and\nsearch the index from ğ‘ğ‘šğ‘–ğ‘›ğ‘„=0using Algorithm 1.\nGreedy construction of the piece-wise function. There is a\ntrade-off of how many intervals we partition the range J0,ğ‘Kinto.\nOn one hand, we can create one interval per distinct ğ‘ğ‘šğ‘ğ‘¥ value in\nthe dataset, which provides the exact lowest intersecting z-address\nfor any query window. However, it takes ğ‘‚(logğ‘)time to augment\nthe query window. On the other hand, we can create one single\nFigure 5: A piecewise funtion with piece granularity ğ‘š=2.\ninterval J0,ğ‘K, which maps to the smallest Zmin for all possible\nquery windows. Augmenting the query is quick with ğ‘‚(1)time,\nbut the number of geometries to go through the refinement step\nwill be very large. Hence, we balance the trade-off by constructing\nthe piecewise function using the following greedy algorithm (Algo-\nrithm 2): we sort all geometriesâ€™ intervals by ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€(which can\nbe done using a leaf level traversal in GLIN without an additional\nsorting operation), and combine every ğ‘šintervals (called piece\ngranularity ) into a single combined interval that exactly covers the\nğ‘šintervals. We treat all combined intervals as the input dataset,\ndenoted as Jğ‘ğ‘šğ‘–ğ‘›â€²\n1,ğ‘ğ‘šğ‘ğ‘¥â€²\n1K,... Jğ‘ğ‘šğ‘–ğ‘›â€²\nâŒˆğ‘/ğ‘šâŒ‰,ğ‘ğ‘šğ‘ğ‘¥â€²\nâŒˆğ‘/ğ‘šâŒ‰K}. Then\nwe scan these intervals and create a new piece if the ğ‘ğ‘šğ‘ğ‘¥ of an\ninterval is greater than that of the previous one. The higher ğ‘šis,\nthe less accurate the lower bounds are. A less accurate lower bound\nleads to more records to refine.\nFigure 5 shows a concrete example of how to build the piece-\nwise function using Algorithm 2 with piece granularity of 2. The\ninputğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™ is first sorted by ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€(and ties are broken using\nğ‘ğ‘šğ‘ğ‘¥ğºğ‘€) and we combine every two intervals into a larger inter-\nval. For example, the first two J1,2Kand J2,3Kare combined into\nJ1,3K. Then we construct a new piece starting from the previous\nğ‘ğ‘šğ‘ğ‘¥ =âˆ’1(exclusive) until the ğ‘ğ‘šğ‘ğ‘¥ =3(inclusive) of the com-\nbined interval, and record the function value ğ‘“=ğ‘ğ‘šğ‘–ğ‘› =1. Note\nthat, if theğ‘ğ‘šğ‘ğ‘¥ of the combined interval is not larger than the\npreviousğ‘ğ‘šğ‘ğ‘¥ value (e.g, the last combined interval J9,13K), it\nshould be absorbed by the previous pieces without any update due\nto the monotonicity of the piecewise function.\nUpdating piecewise function. To handle an update, we may\nalso need to update the piecewise functions. For insertion, suppose\nthe inserted geometry is ğºğ‘€. We first check its z-address interval\nlength against the outlier length threshold. If the length is greater\nthan the threshold, we do not need to update the piecewise function.\nOtherwise, we use binary search to find the first interval (ğ‘ğ‘–,ğ‘ğ‘–+1]\nsuch thatğ‘ğ‘šğ‘–ğ‘›ğºğ‘€is in that interval. For all intervals ğ‘—â‰¥ğ‘–, we\nupdate the function value of range ğ‘—toğ‘ğ‘šğ‘–ğ‘›ğºğ‘€ifğ‘ğ‘šğ‘ğ‘¥ğºğ‘€>\nğ‘ğ‘šğ‘–ğ‘›ğ‘—with min{ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€,ğ‘“(ğ‘ğ‘šğ‘ğ‘¥ğ‘—)}. For example, if we insert a\nnon-outlier geometry with its z-addres interval being J6,8K, we first\nfind the first piece that contains its ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€= 6 and scan forward\nuntil it no longer overlaps with the piece. In this case, both the\nL3,6Kand L6,14Kneed to be updated. However, since ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€=6\nis already larger than the recorded function values 3and5, we will\nkeep the original function values. A subsequent Intersects query\nwill start from either ğ‘ğ‘šğ‘–ğ‘› =3orğ‘ğ‘šğ‘–ğ‘› =5, which will be able\nto find the inserted geometry J6,8K. If an inserted geometry has\n\nGLIN : A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nAlgorithm 2: Initialize the piecewise Function\nInput :ğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™ğ‘  sorted byğ‘ğ‘šğ‘–ğ‘›ğ¼ ,ğ‘ƒğ‘–ğ‘’ğ‘ğ‘’ _ğ‘”ğ‘Ÿğ‘ğ‘›ğ‘¢ğ‘™ğ‘ğ‘Ÿğ‘–ğ‘¡ğ‘¦ğ‘š\nOutput: piecewise function ğ‘ƒğ‘Š\n1c = 0;\n2prev_zmax = -1;\n3foreachğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™ inğ¼do\n4 ifc == 0 then\n5 current_zmin = ğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™.ğ‘ğ‘šğ‘–ğ‘› ;\n6 current_zmax = ğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™.ğ‘ğ‘šğ‘ğ‘¥ ;\n7 else\n8 current_zmax =max( ğ‘ğ‘–ğ‘›ğ‘¡ğ‘£ğ‘™.ğ‘ğ‘šğ‘ğ‘¥ , current_zmax) ;\n9 c ++ ;\n10 ifc ==ğ‘šthen\n11 ifcurrent_zmax > prev_zmax then\n12 ğ‘ƒğ‘Š.pushback(current_zmax, current_zmin);\n13 prev_zmax = current_zmax;\n14 counter = 0 ;\n15ifc> 0then\n16 ifcurrent_zmax > prev_zmax then\n17ğ‘ƒğ‘Š.pushback(current_zmax, current_zmin);\n18Returnğ‘ƒğ‘Š ;\nTable 4: Dataset description\nName Size Cardinality Type Description\nLINEARWATER (LW) [ 25]6.44GB 5.8M LineString Paths of rivers in the USA\nRoads [25] 8.29GB 19M LineString Paths of roads in the USA\nParks [20] 8.53GB 9.8M Polygon Boundaries of parks and green areas\non the planet\nz-value larger than the maximum value in the piecewise function,\nwe will append a new piece at the end of the function.\nFor deletion, we do not perform any update because the piece-\nwise function would still provide lower bounds of the lowest in-\ntersecting Z-addresses. However, we can end up with unnecessary\nrefinements if there are many deletions. Hence, we periodically re-\nbuild the piecewise function using GLIN if the lower bounds are too\nloose and the number of refinements on average becomes too large.\nSince deletion is less frequent than insertion in a typical workload,\nit is not unreasonable to amortize the rebuild cost across a large\nnumber of deletions.\n8 EXPERIMENTS\nThis section presents the result of an experimental analysis on\nGLIN on query-only workloads, maintenance-only workloads and\nhybrid workloads (depicted in Section A.4 in the interest of space).\nAll experiments are done in the main memory of a machine with\n12th Gen Intel Core i9 CPU, 128GB memory, 1TB SSD storage.\n8.1 Experiment setup\nImplementation details. We implement GLIN on top of ALEX\nusing C++ since ALEX is open-source and supports data updates.\nOur implementation re-uses the hierarchical model and gapped\narrays from ALEX and keeps the corresponding ALEX parameters\nunchanged. With that being said, GLIN can be easily migrated to\nother learned indexes too. Furthermore, our idea is also compatible\nwith other one-dimensional index structures, such as B-trees.We\nillustrate this by effortlessly implementing GLIN on top of a B-tree,\nwhich incurs a minimal overhead with promising performance.\nCompared approaches. (1) Boost-Rtree: from Boost C++ v1.73.0,\nwith default settings. (2) Quad-Tree: from GEOS v3.9.0. Quad-Tree.(3)GLIN -ALEX: This is the approach proposed in this paper. When\nquerying for the ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  relationship, no query augmentation\nis needed. However, for the ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘–ğ‘œğ‘› relationship, query aug-\nmentation comes into play.(4) GLIN -BTREE: This uses the same\napproach as GLIN -ALEX but with TLX-BTree as the base index,\ndemonstrating the adaptability of GLIN and the benefits derived\nfrom a one-dimensional index structure. Datasets. We test our\napproaches on 3 real-world datasets(see Table 4), including polygon\nand line string data. Real-world datasets are obtained from the US\nCensus Bureau TIGER project [ 25] . These datasets are cleaned by\nSpatialHadoop [7].\nQuery selectivity. We test GLIN on 3 range query selectivities:\n1%, 0.1%, 0.01%. To generate a range query with the required se-\nlectivity, we randomly take a geometry from the dataset and do a\nK Nearest Neighbor query around this geometry (K = selectivity\n* dataset cardinality) using JTS STR-Tree The MBR of the KNN\nquery results then becomes the query window at this selectivity.\nWe generate 100 such query windows per selectivity per dataset.\nQuery response time. The measured query response time con-\nsists of two parts: (1) index prob time. For all compared approaches,\nthis is the time spent on searching the index structure. For GLIN -\nALEX and GLIN -BTREE, this also includes the query augmentation\ntime when check ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  . (2) Refinement time. For all compared\napproaches, this is the time spent on refining the query results\nusing the exact shapes of query windows and geometries. For the\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  relationship, the results are refined using the ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘ \ncheck in GEOS while for the ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship, the refinement\nuses theğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  check.\n8.2 Query response time\nQuery response time for ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  .As shown in Figure 6, on 1% -\n0.01% selectivity, the index probing time of GLIN -ALEX and GLIN -\nBTREE is nearly 30% - 80%shorter than Quad-Tree and R-Tree. On\n0.01% selectivity, GLIN -ALEX and GLIN -BTREE are still 1 times to 3\ntimes faster than R-Tree and Quad-Tree. This makes sense because\nGLIN -ALEX uses the model prediction-based traversal and GLIN -\nBTREE uses pointer to traverse while Quad-Tree and R-Tree do the\ncomparison-based tree traversal. When check ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  , there is no\nneed to perform the query augmentation.\nQuery response time for ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  .Figure 7 demonstrates the\nquery performance of both GLIN -ALEX and GLIN -BTREE when\nthey incorporate query augmentation to perform query with the\nğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship. Performing query augmentation in GLIN\nintroduces additional overheads during index construction and\nquerying. These overheads include: an additional traversal of the\nleaf level to construct the piecewise function, the piecewise func-\ntion to augment the query window, a small auxiliary index (either\nALEX or BTREE) to handle outliers, and an extra search on the\npiecewise function when augmenting the query window. Despite\nthese overheads, as evidenced by Figure 7, they do not significantly\nimpact the query performance. Both GLIN -ALEX and GLIN -BTREE\ncan achieve a query performance comparable to that of GLIN when\nit does not utilize query augmentation.\nFalse positives. Figure 10 illustrates the number of records\nchecked during the refinement. A lower value indicates less false\npositives which eventually leads to less refinement time and overall\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Congying Wang, Jia Yu, and Zhuoyue Zhao\nLINEWATER ROADS PARKS20406080Time (millisecond)GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE\n(a) 1% Selectivity\nLINEWATER ROADS PARKS25710Time (millisecond)GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE (b) 0.1% Selectivity\nLINEWATER ROADS PARKS123Time (millisecond)GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE (c) 0.01% Selectivity\nFigure 6: Query response time on different query selectivities with ğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  relationship\nLINEWATER ROADS PARKS20406080Time (millisecond)GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE\n(a) 1% Selectivity\nLINEWATER ROADS PARKS510Time (millisecond)GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE (b) 0.1% Selectivity\nLINEWATER ROADS PARKS123Time (millisecond)GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE(c) 0.01% Selectivity\nFigure 7: Query response time on different query selectivities with ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship\nLINEWATER ROADS PARKS2505007501KIndex size (MB)X too large, actual size 1892MBGLIN ALEX\nGLIN BTREEQUADTREE\nRTREE\nFigure 8: Index size with the piecewise function\nLINEWATER ROADS PARKS05101520Time (second)GLIN ALEX\nPIECEWISECONSTRUCTIONGLIN BTREE\nRTREEQUADTREE\nFigure 9: Index initialization time\nquery response time. GLIN has 10% - 50% more false positives than\nR-Tree on 1% to 0.1% selectivity. But the fast index probing of GLIN\nmakes up the difference so its query response time still outstanding\nto others. As expected, GLIN with query augmentation introduces\nmore false positives. the larger the selectivity, the more number of\nrecord to check during the refinement.8.3 Indexing overhead\nIndex size. We measure the sizes by combining the size of internal\nnodes and the size of leaf node metadata. As demonstrated in Fig-\nure 8, the index size of GLIN is 80% - 90% smaller than that of the\nQuad-Tree, and 60% - 80%times smaller than the R-Tree when tested\non real-world datasets. This is reasonable considering that GLIN\nhas far fewer nodes, and each internal node employs a simple linear\nregression model comprised only of two parameters. Additionally,\nwe calculated the sizes of GLIN -ALEX and GLIN -BTREE, including\nthe piecewise function, and found that this part is very small, so it\ndoes not alter our conclusion.\nIndex initialization time. As depicted in Figure 9, GLIN re-\nquires 10% - 50% more initialization time compared to Quad-Tree\nand R-Tree on real-world datasets. This is understandable as, during\nindex initialization, GLIN needs to sort geometries by their ğ‘ğ‘šğ‘–ğ‘›\nvalues and train models. GLIN with query augmentation takes ap-\nproximately 10% more time than GLIN because it needs to generate\nthe piecewise function and handle outliers. The top part of GLIN -\nALEX and GLIN -BTREE, depicted in a deeper color, represents the\nconstruction time of the piecewise function and additional auxiliary\nindex for query augmentation, which is not significantly more than\nthe original construction time of GLIN .\n8.4 Tuning GLIN parameters\nThis section studies the impact of the piece_ granularity (m) param-\neter. This parameter defines the number of records summarized by\neach piece of the piecewise function.\nIndex probing time. As shown in Figure 11, piece_granularity\nhas a significant impact on the index probing time. The probing\ntime for piece_granularity = 9 million is up to twice as high as that\n\nGLIN : A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nLINEWATER ROADS PARKS300700Reï¬nement input x 103GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE\n(a) 1% selectivity\nLINEWATER ROADS PARKS70150Reï¬nement input x 103GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE (b) 0.1% selectivity\nLINEWATER ROADS PARKS2050Reï¬nement input x 103GLIN ALEX\nGLIN BTREEQUADTREE\nRTREE (c) 0.01% selectivity\nFigure 10: Number of records checked during the refinement\n1 100 10k 1m 9m\nPiece granularity2468Query Time (millisecond)LW PARK ROAD\nFigure 11: GLIN query time on piece granularity ( ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  )\nfor piece_granularity = 10000. A larger piece_granularity results\nin higher index probing time because it can augment every query\nwindow to a small ğ‘ğ‘šğ‘–ğ‘› . This may potentially cause every query\nto start from the beginning of the leaf level, resulting in a time-\nconsuming leaf level scan and more false positive refinement. The\ncondition for piece_granularity = 9 million illustrates this scenario.\nConversely, a smaller piece_granularity doesnâ€™t significantly reduce\nthe query response time. Even though the query window might\nnot be augmented to a small ğ‘ğ‘šğ‘–ğ‘› , leading to more refinement,\nthe search within the piecewise function will take longer for each\naugmented query window. As a result, the query response time for\npiece_granularity = 1 is not significantly smaller than the time for\nlarger granularities, such as 10000.\nIndex size. Compared to the index size of GLIN (see Figure 8),\nthe storage overhead of the piecewise function is negligible. Each\npiece contains a ğ‘ğ‘šğ‘ğ‘¥ , indicating where the current piece ends,\nand ağ‘ğ‘šğ‘–ğ‘› , used to augment a query window if it falls within this\npiece. As such, the storage overhead of the piecewise function is\ninsubstantial. Moreover, Figure 8 also incorporates the auxiliary\nindex, yet the overall size remains significantly smaller than those\nof QUADTREE and RTREE. Therefore, we can conclude that the\nstorage overhead of GLIN is indeed negligible.\nTherefore, we use piece_granularity = 10000 as the default pa-\nrameter as it shows the good performance in Figure 11 and its\npiecewise function size is very small compared to GLIN index size.\n8.5 Maintenance Overhead\nInsertion. For each dataset, we first bulk-load a random 50% of\nthe data into all indexes and then insert the remaining 50% into\nthe indexes record by record. As shown in Figure 12(a), on larger\n10 20 30 40 50\nNumber of inserted records (%)02M4M6M8MThroughput (records/s)GLIN BTREE\nGLIN ALEXQUADTREE\nRTREE\n10 20 30 40 50\nNumber of deleted records (%)02M4M6MThroughput(records/s)GLIN BTREE\nGLIN ALEXQUADTREE\nRTREEFigure 12: Index maintenance performance on ROADS\ndatasets, the throughput of GLIN is around 1.5 times higher than R-\nTree and 1.2 times higher than Quad-Tree. This makes sense because\nGLIN â€™s index probing is orders of magnitude faster than others and\nno refinement is needed for insertion. GLIN occasionally show\nperformance downgrade because of node expansion or splitting.\nDeletion. For each dataset, we first bulk-load the entire dataset\nand then randomly delete 50% of the data record by record. As\nshown in Figure 12(b), the throughput of GLIN is around 3 - 5\ntimes higher than R-Tree and Quad-Tree as GLIN â€™s index probing is\norders of magnitude faster than others. The throughput of GLIN oc-\ncasionally show performance downgrade because of node merging.\n9 RELATED WORK\nLearned indexes. Recursive model index(RMI) [ 14], a tree-like hi-\nerarchical model, to learn the cumulative distribution function(CDF)\nbetween keys and their position. RMI takes as input a lookup key\nand predicts the corresponding position by using the models level\nby level. Compared to B+ Tree, RMI possesses low storage over-\nhead with an outperforming lookup performance but only supports\nread-only workload. Hermit [ 28] is a learned secondary index that\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Congying Wang, Jia Yu, and Zhuoyue Zhao\nleverages a hierarchical machine learning model to learn the cor-\nrelation between two columns. ALEX [ 6] is an updatable learned\nindex which adopts RMIâ€™s hierarchy structure but adds gapped\narrays and node splitting to absorb data updates.\nLearned spatial indexes. Researchers have been working on\nextending learned indexes to uphold spatial and multi-dimentional\npoint data. ZM-index[ 27] leverages the Z-order space-filling curve\nto sort the data and then builds RMI on them. Given a spatial range\nquery, it first maps a range query to two Z addresses, then uses the\nprebuilt machine learning model to find an approximate range for\nfurther investigation. Although both GLIN and ZM-Index make use\nof Z order curve, ZM-index cannot handle non-point data and only\nworks with read-only workload. Flood [ 18] also employs the RMI\nto support multidimensional data. It proposes an in-memory read\noptimized index that partitions a d-dimensional space with a d-1\ndimensional grid. The model will predict the grid cell that contains\nthe lookup key. The ML-Index[ 4] utilizes the iDistance [ 12] to map\ndata points to the one-dimensional value and also employs the RMI\nto index the values further. Qi et al. [ 22] come up with a recursive\nspatial model index called RSMI to improve the ZM-index. Their\nwork mitigates the uneven gap problem by using a rank space-based\ntransformation. However, this work provides approximate answers.\nLi et al. propose LISA [ 16], a disk-based learned spatial index that\ncan reach a low storage consumption and I/O cost. LISA partitions\nthe space to grids and assigned each grid an ID by applying the\npartially monotonic function. All of the works mentioned above\nfocus on making learned indexes work for 2 or multi-dimensional\npoint data. Unfortunately, in the real world, geospatial data is more\nthan just points. GLIN handles all types of geometries and hence is\na practical alternative to R-Tree or Quad-Tree.\nLightweight index structures. Some other studies focus on\nsuccinct index structures which take advantage of data synopses\nfrom the indexed data and quickly skip irrelevant data. Column\nimprints [ 24] utilizes the idea of cache conscious bitmap indexing\nto create a bit map for each zone. Block Range Indexes (BRIN)\nin Postgres stores min/max values for each range of disk blocks.\nHippo [ 29] extends BRINâ€™s idea but implements partial histograms\nin each range to decrease the query response time. Hentschel et al.\npropose Column Sketch[ 11] that makes use of lossy compression to\ngenerate data synopses and hence accelerates table scan. BF-tree[ 1]\napplies bloom filter in the leaf node of a B-Tree and hence reduces\nthe storage overhead. However, these succinct index structures\nreduce the index storage overhead at the cost of additional query\nresponse time and cannot be easily tailored to complex geometries.\n10 CONCLUSION\nThis paper introduces GLIN , a lightweight learned index for spatial\nrange queries on complex geometries. In terms of storage overhead,\nGLIN is 80% - 90% less than Quad-Tree and 60% - 80% times less\nthan R-Tree. Moreover, GLIN â€™s maintenance speed is around 1.5\ntimes higher on insertion and 3 -5 times higher on deletion as\nopposed to R-Tree and Quad-Tree. If the application only needs the\nğ¶ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  relationship, the user can opt to use GLIN without query\naugmentation the query response time is 30% - 80% shorter than\nQuad-Tree and R-Tree on medium selectivity. GLIN with query\naugmentation deals with both spatial relationships still showing a30%-70% faster than Quad-Tree and R-Tree query response time on\nmedium selectivity. In a nutshell, GLIN is a lightweight indexing\nmechanism for medium selectivity queries which are commonly\nused in spatial analytic applications.\nREFERENCES\n[1]Manos Athanassoulis and Anastasia Ailamaki. 2014. BF-Tree: Approximate Tree\nIndexing. PVLDB 7, 14 (2014), 1881â€“1892.\n[2]Jon Louis Bentley. 1975. Multidimensional Binary Search Trees Used for Associa-\ntive Searching. CACM 18, 9 (1975), 509â€“517.\n[3]Panagiotis Bouros and Nikos Mamoulis. 2019. Spatial joins: whatâ€™s next? ACM\nSIGSPATIAL Special 11, 1 (2019), 13â€“21.\n[4]Angjela Davitkova, Evica Milchevski, and Sebastian Michel. 2020. The ML-Index:\nA Multidimensional, Learned Index for Point, Range, and Nearest-Neighbor\nQueries. In EDBT . 407â€“410.\n[5]degree-precision [n. d.]. Accuracy versus decimal places. http://wiki.gis.com/\nwiki/index.php/Decimal_degrees.\n[6]Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\nDavid B. Lomet, and Tim Kraska. 2020. ALEX: An Updatable Adaptive Learned\nIndex. In SIGMOD . 969â€“984.\n[7]Ahmed Eldawy and Mohamed F. Mokbel. 2015. SpatialHadoop: A MapReduce\nFramework for Spatial Data. In ICDE . 1352â€“1363.\n[8]geometries [n. d.]. ISO/IEC 13249-3:2016 Information technology â€” Database\nlanguages â€” SQL multimedia and application packages â€” Part 3: Spatial. https:\n//www.iso.org/standard/60343.html.\n[9]geoparquet [n. d.]. GeoParquet. https://github.com/opengeospatial/geoparquet.\n[10] Antonin Guttman. 1984. R-Trees: A Dynamic Index Structure for Spatial Search-\ning. In SIGMOD . 47â€“57.\n[11] Brian Hentschel, Michael S. Kester, and Stratos Idreos. 2018. Column Sketches: A\nScan Accelerator for Rapid and Robust Predicate Evaluation. In SIGMOD . 857â€“\n872.\n[12] H. V. Jagadish, Beng Chin Ooi, and Kian-Lee Tan. 2005. iDistance: An adaptive\nB+-tree based indexing method for nearest neighbor search. TODS 30, 2 (2005),\n364â€“397.\n[13] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. In SIGMOD . 5:1â€“5:5.\n[14] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe Case for Learned Index Structures. In SIGMOD . 489â€“504.\n[15] Ken C. K. Lee, Baihua Zheng, Huajing Li, and Wang-Chien Lee. 2007. Approaching\nthe Skyline in Z Order. In VLDB . 279â€“290.\n[16] Pengfei Li, Hua Lu, Qian Zheng, Long Yang, and Gang Pan. 2020. LISA: A Learned\nIndex Structure for Spatial Data. In SIGMOD . 2119â€“2133.\n[17] libmorton [n. d.]. Libmorton Library. https://github.com/Forceflow/libmorton.\n[18] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learn-\ning Multi-Dimensional Indexes. In SIGMOD . 985â€“1000.\n[19] Matthaios Olma, Farhan Tauheed, Thomas Heinis, and Anastasia Ailamaki. 2017.\nBLOCK: Efficient Execution of Spatial Range Queries in Main-Memory. In SSDBM .\n15:1â€“15:12.\n[20] OSM [n. d.]. OpenStreetMap. http://www.openstreetmap.org/.\n[21] parquet [n. d.]. Apache Parquet. https://parquet.apache.org/.\n[22] Jianzhong Qi, Guanli Liu, Christian S. Jensen, and Lars Kulik. 2020. Effectively\nLearning Spatial Indices. PVLDB 13, 11 (2020), 2341â€“2354.\n[23] Hanan Samet. 1984. The Quadtree and Related Hierarchical Data Structures.\nCSUR 16, 2 (1984), 187â€“260.\n[24] Lefteris Sidirourgos and Martin L. Kersten. 2013. Column imprints: a secondary\nindex structure. In SIGMOD . 893â€“904.\n[25] tiger [n. d.]. TIGER/Line files. http://www.census.gov/geo/www/tiger/.\n[26] Dimitrios Tsitsigkos, Konstantinos Lampropoulos, Panagiotis Bouros, Nikos\nMamoulis, and Manolis Terrovitis. 2021. A Two-layer Partitioning for Non-point\nSpatial Data. In ICDE . 1787â€“1798.\n[27] Haixin Wang, Xiaoyi Fu, Jianliang Xu, and Hua Lu. 2019. Learned Index for\nSpatial Queries. In MDM . 569â€“574.\n[28] Yingjun Wu, Jia Yu, Yuanyuan Tian, Richard Sidle, and Ronald Barber. 2019.\nDesigning Succinct Secondary Indexing Mechanism by Exploiting Column Cor-\nrelations. In SIGMOD . 1223â€“1240.\n[29] Jia Yu and Mohamed Sarwat. 2016. Two Birds, One Stone: A Fast, yet Lightweight,\nIndexing Scheme for Modern Database Systems. PVLDB 10, 4 (2016), 385â€“396.\n[30] Jia Yu and Mohamed Sarwat. 2017. Indexing the Pickup and Drop-Off Locations\nof NYC Taxi Trips in PostgreSQL - Lessons from the Road. In SSTD (Lecture Notes\nin Computer Science, Vol. 10411) . 145â€“162.\n[31] Jia Yu, Zongsi Zhang, and Mohamed Sarwat. 2019. Spatial data management in\napache spark: the GeoSpark perspective and beyond. GeoInformatica 23, 1 (2019),\n37â€“78.\n\nGLIN : A (G)eneric (L)earned (In)dexing Mechanism for Complex Geometries Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nA APPENDIX\nA.1 Proofs of Lemma 1 and Lemma 2\nTo prove the lemmas, we first show a well-known result in Theo-\nrem 1 and additionally prove Theorem 2.\ntheorem 1. Monotonic ordering [15]: Data points ordered by\nnon-descending Z-addresses are monotonic in a way that a dominating\npoint is placed before its dominated points.\nwhere dominance is defined as: given two points ğ‘andğ‘â€², ifğ‘is\nno larger than ğ‘â€²in any dimension, then we say ğ‘dominatesğ‘â€².\ntheorem 2. If Q contains GM, then MBR ğ‘„contains MBR ğºğ‘€\nwhere MBR ğ‘„contains MBR ğºğ‘€â‡â‡’ Qâ€™sğ‘ğ‘šğ‘–ğ‘›dominates GMâ€™s\nğ‘ğ‘šğ‘–ğ‘›and GMâ€™sğ‘ğ‘šğ‘ğ‘¥ dominates Qâ€™s ğ‘ğ‘šğ‘ğ‘¥.\nProof. Since Qğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  GM, in a 2D space, if there is a line, it\nis obvious that the geometrical projection of Q on this line must\ncontain the geometrical projection of GM on this line. In other\nwords, when Q ğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  GM, then if a person stands somewhere\noutside Q, he or she should never see GM because GM is completely\ninside Q assuming Q is a closed geometry. The projection of a\ngeometry on X axis and Y axis are [ğ‘¥ğ‘šğ‘–ğ‘›,ğ‘¥ğ‘šğ‘ğ‘¥]and[ğ‘¦ğ‘šğ‘–ğ‘›,ğ‘¦ğ‘šğ‘ğ‘¥],\nrespectively. We have (1) Qâ€™s ğ‘¥ğ‘šğ‘–ğ‘›â‰¤GMâ€™sğ‘¥ğ‘šğ‘–ğ‘›& Qâ€™sğ‘¦ğ‘šğ‘–ğ‘›â‰¤GMâ€™s\nğ‘¦ğ‘šğ‘–ğ‘›, so Qâ€™sğ‘ğ‘šğ‘–ğ‘›dominates GMâ€™s ğ‘ğ‘šğ‘–ğ‘›(2) GMâ€™sğ‘¥ğ‘šğ‘ğ‘¥â‰¤Qâ€™sğ‘¥ğ‘šğ‘ğ‘¥\n& GMâ€™sğ‘¦ğ‘šğ‘ğ‘¥â‰¤Qâ€™sğ‘¦ğ‘šğ‘ğ‘¥, so GMâ€™sğ‘ğ‘šğ‘ğ‘¥ dominates Qâ€™s ğ‘ğ‘šğ‘ğ‘¥.â–¡\nProof of Lemma 1:\nProof.ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€â‰¤ğ‘ğ‘šğ‘ğ‘¥ğºğ‘€is known. Since Q ğ‘ğ‘œğ‘›ğ‘¡ğ‘ğ‘–ğ‘›ğ‘  GM,\nwe have (1)ğ‘ğ‘šğ‘–ğ‘›of Q dominates ğ‘ğ‘šğ‘–ğ‘›of GM, soğ‘ğ‘šğ‘–ğ‘›ğ‘„â‰¤ğ‘ğ‘šğ‘–ğ‘›ğºğ‘€\n(2)ğ‘ğ‘šğ‘ğ‘¥ of GM dominates ğ‘ğ‘šğ‘ğ‘¥ of Q, soğ‘ğ‘šğ‘ğ‘¥ğºğ‘€â‰¤ğ‘ğ‘šğ‘ğ‘¥ğ‘„.â–¡\nProof of Lemma 2:\nProof. Since Qğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  GM, Q and GM must share some por-\ntion of the space. On the other hand, Q and GMâ€™s ğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ guarantee to\ncover any point that falls inside Q and GM, respectively. Therefore,\nğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğ‘„andğ‘ğ‘–ğ‘¡ğ‘£ğ‘™ğºğ‘€share some portion of the intervals. â–¡\nA.2 Monotonicity of piecewise functions\nLemma A.1. The piecewise function for query augmentation is a\nnon-strict monotonically increasing function.\nProof. To show that by contradition, suppose there are two\nğ‘ğ‘šğ‘ğ‘¥ valuesğ‘ğ‘šğ‘ğ‘¥ 1<ğ‘ğ‘šğ‘ğ‘¥ 2but the lowest intersecting Z-addresses\nğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 1)>ğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 2). Let the pieces containing ğ‘ğ‘šğ‘ğ‘¥ 1and\nğ‘ğ‘šğ‘ğ‘¥ 2be theğ‘–1andğ‘–2. Since the computed ğ‘“values are differ-\nent andğ‘ğ‘šğ‘ğ‘¥ 1<ğ‘ğ‘šğ‘ğ‘¥ 2, we must have ğ‘–1<ğ‘–2. For the second\npiece, there must be a z-address interval Jğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 2),ğ‘ğ‘šğ‘ğ‘¥â€²\n2Ksuch\nthatğ‘ğ‘šğ‘ğ‘¥â€²\n2âˆˆJğ‘ğ‘–2,ğ‘ğ‘–2+1K. Then we can show that the z-address\ninterval Jğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 2),ğ‘ğ‘šğ‘ğ‘¥â€²\n2Kintersects with the first piece:\nğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 2)<ğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 1) ( assumption)\nâ‰¤ğ‘ğ‘–1+1(definition of ğ‘“)\nâ‰¤ğ‘ğ‘–2(sinceğ‘–1<ğ‘–2)\nâ‰¤ğ‘ğ‘šğ‘ğ‘¥â€²\n2(definition of ğ‘“)\nTherefore,ğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 1)should have been smaller than or equal to\nğ‘“(ğ‘ğ‘šğ‘ğ‘¥ 2), which is a contradition. â–¡\n5e-05 5e-06 5e-07 5e-08\nZ-Address Cell Size012Time(Millisec)\nPARKS ROADSFigure 13: Query response time per cell size\n10 20 30 40 50\nNumber of processed records (%)020406080Throughput(transaction/s)GLIN BTREE\nGLIN ALEXQUADTREE\nRTREE\n(a) Read-intensive on Roads\n10 20 30 40 50\nNumber of processed records (%)02040Throughput(transaction/s)GLIN BTREE\nGLIN ALEXQUADTREE\nRTREE\n(b) Write-intensive on Roads\nFigure 14: Index performance on hybrid workloads\nA.3 Z-address cell size\nThe cell size can be any small number with 7 to 8 decimal places\n(see Figure 13). This way, we can prevent too many geospatial co-\nordinates from having the same Z-address, which would otherwise\nmake indexe unable to prune the refinement candidates.\nA.4 GLIN â€™s performance on hybrid workload\nWe define a transaction as (1) query: a spatial range query with\nğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘ ğ‘’ğ‘ğ‘¡ğ‘  relationship at 1% selectivity, or (2) insertion: insert 1%\nnew records into the indexes. We have two hybrid workloads: (1)\nread-intensive: 90% of the transactions are queries and the other\n10% are insertion. (2) Write-intensive: 50% of the transactions are\nqueries and the rest are insertion. For each dataset, we first bulk-\nload 50% of the entire dataset, and then start the workloads. We\nstop when the remaining 50% data are inserted.\nRead-intensive workload. As depicted in Figure 14a, the through-\nput of GLIN -ALEX and GLIN -BTREE initially surpasses that of\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Congying Wang, Jia Yu, and Zhuoyue Zhao\nQuad-Tree and R-Tree, but eventually aligns with the throughput\nof R-Tree and Quad-Tree towards the end. This behavior is expected,\nasGLIN -BTREE requires more rebalancing as more data is inserted\ninto the tree. Meanwhile, GLIN -ALEX is able to consistently main-\ntain higher throughput due to its learned index structure.Write-intensive workload. As shown in Figure 14b, GLIN out-\nperforms Quad-Tree and R-Tree almost all the time. This matches\nour expectation because the insertion speed of GLIN is much higher\nthan that of Quad-Tree and R-Tree (see Figure 12). When we have\na write-intensive workload, the overall performance of GLIN is\nproven to be better.",
  "textLength": 61780
}