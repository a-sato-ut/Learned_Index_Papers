{
  "paperId": "68652b5fa371394cc32b5ab2fcd797e03903d26c",
  "title": "BFTBrain: Adaptive BFT Consensus with Reinforcement Learning",
  "pdfPath": "68652b5fa371394cc32b5ab2fcd797e03903d26c.pdf",
  "text": "BFTBrain: Adaptive BFT Consensus with Reinforcement Learning\nChenyuan Wu\nUniversity of PennsylvaniaHaoyun Qin\nUniversity of PennsylvaniaMohammad Javad Amiri\nStony Brook University\nBoon Thau Loo\nUniversity of PennsylvaniaDahlia Malkhi\nUC Santa BarbaraRyan Marcus\nUniversity of Pennsylvania\nAbstract\nThis paper presents BFTBrain, a reinforcement learning (RL)\nbased Byzantine fault-tolerant (BFT) system that provides\nsignificant operational benefits: a plug-and-play system suit-\nable for a broad set of hardware and network configurations,\nand adjusts effectively in real-time to changing fault scenar-\nios and workloads. BFTBrain adapts to system conditions\nand application needs by switching between a set of BFT\nprotocols in real-time. Two main advances contribute to BFT-\nBrain’s agility and performance. First, BFTBrain is based on\na systematic, thorough modeling of metrics that correlate the\nperformance of the studied BFT protocols with varying fault\nscenarios and workloads. These metrics are fed as features to\nBFTBrain’s RL engine in order to choose the best-performing\nBFT protocols in real-time. Second, BFTBrain coordinates\nRL in a decentralized manner which is resilient to adversarial\ndata pollution, where nodes share local metering values and\nreach the same learning output by consensus. As a result, in\naddition to providing significant operational benefits, BFT-\nBrain improves throughput over fixed protocols by 18% to\n119% under dynamic conditions and outperforms state-of-the-\nart learning based approaches by 44% to 154%.\n1 Introduction\nByzantine fault-tolerant (BFT) consensus protocols are the\ncore engines powering the state machine replication (SMR)\nparadigm, ensuring that non-faulty replicas execute client re-\nquests in the same order, despite the existence of fByzantine\nreplicas. The ability to tolerate up to farbitrary failures makes\nBFT protocols a key component in various distributed sys-\ntems, including permissioned blockchains [6, 48], distributed\nfile systems [19, 22], locking services [23], firewalls [33, 34],\nkey-value stores [27, 35], and SCADA systems [9, 45].\nWhile various BFT protocols have been proposed (e.g.,\nPBFT [18, 19], Zyzzyva [46], CheapBFT [43], Prime [4],\nSBFT [40] and HotStuff-2 [52]), there is no one-size-fits-all\nsolution. The performance ranking of BFT protocols varies\nsignificantly depending on client workloads, network con-\nfigurations, and application needs. For example, protocolsthat reduce message complexity by increasing communica-\ntion phases exhibit better throughput but worse latency. In\naddition, adversarial behaviors in the system also affect the\nbest-performing protocol choice. The lack of a clear “winner”\namong BFT protocols makes it difficult for application devel-\nopers to choose one and may invalidate their choice if work-\nloads or attacks change. This is exacerbated in blockchain\nsystems where application workloads and potential attacks\nare diverse and dynamic [37].\nTo address this challenge, two prior systems, Abstract\n[8, 38] and ADAPT [10] have been proposed. Both systems\ncombine multiple protocols under a single framework and\nswitch between protocols adaptively in real-time. Specifically,\nAbstract creates an adaptive framework whereby there is a\npredefined switching order of BFT protocols. If one protocol\ndoes not make sufficient progress, it is aborted and the next\nprotocol in the predefined order is selected. Such an approach\nlacks flexibility and is unlikely to work in all scenarios.\nADAPT enhances protocol selection using supervised learn-\ning, but it faces operational limitations. First, it relies on a sin-\ngle replica to collect data, train the machine learning model,\nand then distribute the decision to all other replicas. In a\nByzantine environment, such centralized control is not real-\nistic and runs counter to the entire BFT approach. Second,\nits requirement for prolonged upfront data collection and su-\npervised learning hinders its ability to adapt to unforeseen\nconditions and workloads. Lastly, as our experiments will\ndemonstrate, ADAPT ’s incomplete feature space design ren-\nders it ineffective under diverse fault scenarios.\nTo embrace the idea of a multi-protocol BFT engine while\nconsiderably enhancing its practicality, we propose BFTBrain ,\na reinforcement learning (RL) based BFT system. At a high\nlevel, given a performance metric to optimize, BFTBrain\nsmartly switches between a set of BFT protocols at run-time\nunder dynamic workloads. BFTBrain is practical in two as-\npects — it not only maintains adaptivity under various ad-\nversarial behaviors, but also provides significant operational\nbenefits when deployed on different hardware and system con-\nfigurations: instead of manually choosing from multiple alter-\n1arXiv:2408.06432v1  [cs.DC]  12 Aug 2024\n\nnative systems for deployment, or running a prolonged data\ncollection process prior to the deployment, BFTBrain only\nrequires running one system that automatically re-configures\nitself to implement a top-performing protocol in real-time.\nTo leverage RL, BFTBrain measures in real-time perfor-\nmance metrics obtained locally by replicas. Beyond stan-\ndard metrics like commit throughput, BFTBrain employs fine-\ngrained metrics that offer deeper performance insights, such\nas the ratio of requests that are committed in the fast path of\ndual-path protocols, the number of received messages per slot,\nand the interval between consecutive leader proposals. These\nnew metrics are measured in a distributed manner and serve as\nfeatures for BFTBrain’s RL engine. By modeling the selection\nof a BFT protocol as a contextual multi-armed bandit prob-\nlem, the RL engine strategically tests different protocols at\nrun-time to learn which ones are well-suited to the current sys-\ntem conditions. BFTBrain coordinates RL in a decentralized\nmanner, where nodes share local features/rewards by consen-\nsus and reach the same learning output, achieving resilience\nto adversarial data pollution. Our extensive evaluation shows\nthat BFTBrain significantly outperforms fixed protocols and\nexisting adaptive systems in dynamic workloads and faults.\nSpecifically, this paper makes the following contributions.\nBFT based on reinforcement learning. To our best knowl-\nedge, BFTBrain is the first BFT system that utilizes reinforce-\nment learning to achieve run-time adaptability. It does not rely\non a lengthy data collection process prior to every deployment\nand effectively adapts to unforeseen system conditions.\nAdaptivity to fault scenarios. BFTBrain is the first BFT con-\nsensus system that not only automatically adapts to dynamic\nuser workloads under a broad set of hardware and system\nconfigurations, but also adapts to various fault scenarios.\nDissecting BFT performance. Through a suite of workload\nand fault parameters, we conducted a large-scale study exam-\nining the relationship between protocol algorithmic design\nand performance, encompassing a wide range of well-known\nBFT protocols, including PBFT, Zyzzyva, CheapBFT, Prime,\nSBFT, and HotStuff-2. Our experiments highlight the vast\nstate space, rendering existing solutions impractical.\nPrototype and experimental evaluation. We developed a\nprototype of BFTBrain and integrated it with the six BFT\nprotocols listed above. Our CloudLab evaluation demonstrates\nthat BFTBrain improves throughput by 18%-119% over fixed\nprotocols under dynamic conditions and outperforms the state-\nof-the-art learning-based approach by 44%-154% depending\non how many data are polluted by adversaries.\n2 Landscape of BFT Performance\nTo motivate BFTBrain, we first conduct an in-depth perfor-\nmance study to examine how various BFT protocols perform\nunder different conditions. The key takeaway is that no sin-\ngle BFT protocol is always “better” or “worse” than others,\nbut rather that different protocols perform better/worse than\nothers under different circumstances.Table 1: Our observed best-performing BFT protocols un-\nder different conditions. The advantage over the second-best\nprotocol is shown in the last column.\nf # of absentees request size proposal slowness best protocol\n1 0 4KB 0ms Zyzzyva (15.6%)\n4 0 4KB 0ms Zyzzyva (34.3%)\n4 0 100KB 0ms CheapBFT (8.5%)\n4 4 4KB 0ms CheapBFT (13.1%)\n4 0 0KB 20ms HotStuff-2 (45.4%)\n4 0 1KB 20ms HotStuff-2 (44.8%)\n4 0 0KB 100ms Prime (16.9%)\n1 0 0KB 20ms Prime (71.5%)\n2.1 Comparing Representative BFT Protocols\nWe picked six representative BFT protocols as our explo-\nration targets: PBFT [18], Zyzzyva [46], CheapBFT [43],\nPrime [4], SBFT [40], and HotStuff-2 [52]. All six protocols\nareleader-based , working in the partial synchrony settings\nwith networks of n=3f+1nodes1. Detailed background\non these protocols is provided in Appendix A. These proto-\ncols and the benchmarking tools were implemented under a\ncommon software framework Bedrock [5]; hence, our eval-\nuation below focuses on the impact of algorithmic logic of\nthese protocols on performance, rather than the effect of the\nimplementation details of a specific system.\nOur experiments were conducted on CloudLab [28] where\neach replica is an xl170 bare metal server. We ran these six\nprotocols under diverse workloads and fault scenarios, and\ncompared their average throughput during 120second runs\nthat were stably reproduced 10times. For a fair comparison,\nthe common internal parameters (e.g., batch size and view-\nchange timer) of all six protocols were configured with the\nsame values. For simplicity and facilitating protocol switch-\ning, as described in later sections, we added fextra replicas\nto the original CheapBFT acting as active replicas (see [43]).\nThis approach affects the hardware resource consumption and\nscalability of the original CheapBFT, but does not change its\nperformance under our setups. We also emulated the overhead\nof the trusted subsystem CASH by injecting 60µsdelay for\ncreating and verifying message certificates.\nTable 1 summarizes our evaluation results. Importantly, it\ndemonstrates that no single protocol dominates in all con-\nditions . The first four columns indicate the workloads and\nfault scenarios: system size, number of non-responsive nodes,\nclient request size, and slowness of leader proposals; a more\ndetailed description is provided in Section 4.2. The last col-\numn shows the best-performing protocol under each condition\nas well as its relative percentage advantage in throughput over\nthe second-best protocol; the throughput of all six protocols\nunder each condition is provided in Appendix D.1.\nIt is worth underscoring that a “slowness-attack”, capturing\nthe interval between two consecutive leader proposals, ap-\n1CheapBFT requires only 2f+1with the help of trusted hardware, but\nwas evaluated with 3 f+1 for simplicity. Correctness is still guaranteed.\n2\n\npears in many studies [4, 8,23]. It captures a Byzantine attack\nwhere a malicious leader deliberately postpones its proposal\nbefore the view-change timer expires. In addition, it could\nalso happen naturally in a heterogeneous deployment, where\na leader has weaker compute or network resources compared\nto other replicas. Below, we navigate through the table and\nexplain the insights behind the results.\nRow 1-3. The first three rows are in an ideal world where\nevery replica is benign and responsive, with no obvious slow-\nness in leader proposals, while varying the network and re-\nquest sizes. When n=4(f=1) and the request size is 4KB,\nZyzzyva outperforms the next best protocol CheapBFT by\n15.6%. When increasing the network size to n=13(f=4),\nZyzzyva outperforms CheapBFT by 34.3%. However, when\nthe request size increases to 100KB, a flip of ranking occurs:\nCheapBFT becomes the best-performing protocol and outper-\nforms the second best protocol HotStuff-2 by 8.5%, which\nthen slightly outperforms Zyzzyva. The comparison of rows\n2and3suggests that different protocols have different “sweet\nspots” depending on the request size and quorum size. When\nrequests are small, optimistically waiting for 3f+1votes is\nreasonable, but when requests become larger, waiting for the\nslowest fnodes to vote on a leader proposal takes a long time,\nespecially when fis large. In the latter scenario, protocols\nthat only need 2f+1replicas to vote on the leader proposal\nperform better, even at the cost of an extra phase of exchang-\ning small hashes and extra computation. Note that due to the\nseparation of transaction dissemination from consensus logic,\nonly the leader proposals contain the actual requests.\nTwo of the protocols we studied require a 3f+1quorum\nin their fast paths: Zyzzyva and SBFT. Across rows 1 to 3 in\nTable 1, Zyzzyva’s performance leads or almost equals SBFT\nsince it has fewer phases of communication. However, we\nfound that with weaker clients, SBFT outperforms Zyzzyva in\nsome cases. More specifically, we reran row 1on a different\nhardware setup, where the client machine (which hosts mul-\ntiple client threads) is configured with fewer CPU cores and\nhigher network latency: this is done by limiting the available\nCPU cores on a 10-core machine to 6 using taskset and\ninjecting an extra 20ms RTT. In this new setup, SBFT outper-\nforms Zyzzyva by 8.5%. These two protocols demonstrate a\ndesign trade-off between the number of phases and the choice\nof commit collector. Since SBFT moves the collector role\nfrom clients to certain replicas, it is beneficial when clients\nhave weak network connectivity and compute power.\nRow 4. Row 4 demonstrates the effect of non-responsive repli-\ncas, referred to as absentees in the table. When certain replicas\nare non-responsive, the performance of dual-path protocols is\nadversely impacted, since a slow path is activated only after\na timer expiration when failing to gather 3f+1votes on the\nfast path. Conversely, single-path protocols are less impacted\nand even have better performance due to fewer message vali-\ndations and less bookkeeping. In this setting, CheapBFT is\nthe best-performing protocol in our evaluation, which outper-forms the next best protocol HotStuff-2 by 13.1%since it\nhas fewer phases of communication. Due to their slow paths,\nZyzzyva and SBFT become the bottom-performing protocols.\nIt is worth mentioning that in our evaluation, HotStuff-2 is\nequipped with a reputation-based leader rotation mechanism,\nCarousel [24], which tracks active replica participation via\ntheir signed votes during the committed chain prefix in order\nto select the next leaders. For a HotStuff-2 implementation\nwithout leader reputation mechanisms, CheapBFT will out-\nperform it by an even larger margin, since it suffers from a\nnon-responsive leader periodically.\nRow 5-8. Row 5-8 evaluate different degrees of proposal slow-\nness, representing a Byzantine world where malicious leaders\nmight deliberately slow down the system. When the slowness\nis as low as 20ms and fis large, HotStuff-2 outperforms all\nother protocols by up to 45.4%. This is due to HotStuff-2’s\nroutine leader rotation, which is made possible with low cost\nby its linear responsive view-change and alleviates the impact\nof slow nodes elected as leaders. Although Prime also re-\nplaces slow leaders proactively, it has more phases and higher\ncommunication complexity than HotStuff-2 (i.e., 6phases\nand quadratic complexity compared to 2phases and linear\ncomplexity), resulting in worse performance. However, when\nthe slowness further increases to 100ms, or when the net-\nwork size reduces from 13to4(f=4tof=1), the ranking\nflips: Prime outperforms HotStuff-2 by 16.9%-71.5%. This\nhappens since Prime replaces any deliberately slow leader\nwith a stable benign leader. In Prime, each node measures\nthe actual turnaround time to the leader, which is indepen-\ndent of the system load, and compares it with the acceptable\nturnaround time, which is a function of the RTT between\ncorrect servers. In HotStuff-2, when the network is small or\nslowness is high, slow nodes are being rotated in as leaders\nroutinely, causing considerable slowness. This outweighs the\nbenefits of HotStuff-2’s simpler and linear communication\npattern, resulting in sub-optimal performance.\nThese experiments demonstrate a complex trade-off be-\ntween design principles of different BFT protocols. Thus,\nwhen conditions change dynamically, no single protocol out-\nperforms others in all scenarios.\n2.2 The Case for Reinforcement Learning\nSince no single BFT protocol is dominant in all scenarios,\none could imagine building heuristics or supervised learning\nmodels that map conditions to the best-performing protocol,\nand switching protocols at run-time according to the current\nperceived conditions. However, such approaches suffer from\nseveral drawbacks.\nCondition space size. The condition space is too large to\nsearch. Table 1 only presents a sample of the space. The\ncomplete condition space we monitor consists of 6 dimensions\n(State 1 and 2 in Section 4.2), where each dimension is either\na continuous or discrete variable. Further, each point in the\ncondition space has multiple protocols to experiment with.\n3\n\nEven with coarse-grained sampling and an automated toolkit,\nit took us more than a week to experimentally explore just a\nsmall subset of the condition space. Unfortunately, building\ngood heuristics and supervised models requires complete data,\nwhich are hard to obtain.\nHardware and time dependence. The mapping from condi-\ntions to the best-performing protocol depends on the underly-\ning hardware and system configuration: when changing from\nxl170 tom510 instances on CloudLab, or changing from a\n13-node network to a 4-node network, the mapping changes.\nAdditionally, we observe that even with the same hardware\ninstance type but across different launches on shared facilities\nlike CloudLab, the sweet spots (in terms of request size) of\nZyzzyva and CheapBFT change due to subtle differences in\nphysical machines and network resource availability. Worse\nyet, network conditions can change over time, rendering any\npre-computed mapping on a specific network less useful.\nGrowing protocol space. When new BFT protocols emerge\n(e.g., HotStuff-2) or changes are introduced to existing imple-\nmentations (e.g., DiemBFT-v1 to v4 [1]), any precomputed\nmapping would need to be recomputed. In other words, one\nwould need to re-collect data and re-craft the heuristics, or re-\ncollect data and retrain the supervised model virtually every\ntime a new BFT consensus protocol is proposed.\nReinforcement learning addresses this daunting and com-\nplex task, and has shown superior performance in other\nlearned systems [20, 53, 54, 61]. Unlike supervised learning,\nwhich assumes training data is complete and requires a sepa-\nrate lengthy data collection process prior to deployment, one\ncan simply plug and play an RL-based system — it learns\nfrom its mistakes and optimizes long-term rewards through\ntrials in an online fashion. With reinforcement learning, BFT-\nBrain can optimize itself to whatever client workloads, faults,\nhardware, system configurations and BFT protocols present,\nproviding adaptivity and significant operational benefits.\n3 BFTBrain Overview\nWe provide an overview of BFTBrain, first outlining its sys-\ntem model followed by its overall reinforcement learning\nbased design.\n3.1 System Model\nIn BFTBrain, we assume a system consists of a fixed set of\nn=3f+1nodes and a finite population of clients , where\nup to fnodes and any number of clients might experience\nByzantine faults. Each node serves two roles simultaneously,\nvalidator andlearning agent . A validator is responsible for\ntotally ordering the blocks, while a learning agent coordinates\nonline data collection, trains machine learning models, and\nperiodically instructs the companion validator at run-time to\nreplace the current BFT protocol.\nWhen a node is faulty, it can behave arbitrarily in any of its\nroles. The faulty validators may exhibit standard malicious\nbehavior such as double voting and message suppression orequivocation. We assume a strong adversary that can coordi-\nnate the faulty validators to compromise the replicated service.\nHowever, we do assume the adversary cannot break the crypto-\ngraphic techniques. Given our use of machine learning, faulty\nlearning agents could exhibit additional malicious behaviors\nrelated to learning, such as being non-responsive (e.g., refuse\nto exchange its locally measured data with other learning\nagents), as well as presenting arbitrarily manipulated local\ndata points (i.e., local features and rewards) in order to disrupt\nthe machine learning models on other agents.\nNetwork communication is point-to-point and authenti-\ncated. BFTBrain adopts the partial synchrony model [29],\nwhere there is a known bound ∆and an unknown Global\nStabilization Time (GST), such that after GST, all transmis-\nsions between two correct nodes arrive within time ∆. For\ntwo different roles on the same node, we assume their com-\nmunication in-between is always synchronous.\n3.2 Design Overview\nAt a high level, BFTBrain contains three key components:\n(1) a reinforcement learning algorithm (i.e., the core of the\nlearning agent) that guides the choice of BFT protocols ac-\ncording to the perceived underlying dynamic environment, (2)\na coordination protocol that collects data distributedly at run-\ntime, and (3) a switching mechanism that allows BFTBrain to\nseamlessly transition from one BFT protocol to another while\nensuring safety and liveness.\nBFTBrain operates in epochs , where each epoch is marked\nby the completion of kblocks. Here, kis a predefined constant\nhyper-parameter. Within one epoch, the protocol remains un-\nchanged. When the learning agent finds a protocol candidate,\nit instructs the validator to use that protocol for the next epoch.\nWe next introduce BFTBrain’s key components and workflow.\nLearning agent. BFTBrain’s learning agent models the prob-\nlem of selecting a BFT protocol as a contextual multi-armed\nbandit (CMAB) problem [66]: periodically, BFTBrain exam-\nines the most recent state of the workload and faults in the\nsystem ( context ), and then selects one of many BFT proto-\ncols ( arms ) in our protocol pool. After making the selection,\nit observes the performance of the newly selected protocol\n(reward ). To be successful, BFTBrain must balance the explo-\nration of new, untested protocols with exploiting past expe-\nrience to maximize performance. That is, without a careful\nbalance of exploration and exploitation, BFTBrain risks fail-\ning to discover an optimal protocol (too much exploitation),\nor performing no better than random (too much exploration).\nWe select this CMAB formulation (as opposed to full rein-\nforcement learning) because CMABs are exceptionally well-\nstudied, enable faster convergence, and many asymptotically-\noptimal algorithms exist to solve them [2, 21]. Details about\nthe learning algorithms are provided in Section 4.\nSince BFTBrain operates in a Byzantine environment, a\ncentralized learning agent cannot be trusted. In BFTBrain,\neach validator process has a companion learning agent run-\n4\n\nFigure 1: Overview of BFTBrain. For readability, we only\npresent the internals of one node i.\nning on the same node, and accepts instructions only from its\ncompanion learning agent. The learning agents themselves\nalso form a state machine replication. Specifically, they start\nwith the same initial state , i.e., the same random seed of ma-\nchine learning models. For the same epoch t, as we will show\nlater, different learning agents agree on the same sequence\nof operations , i.e., training data points where each data point\nconsists of context and reward. With deterministic training,\nbenign learning agents host the same parameters for their ma-\nchine learning models. As a result, if different learning agents\nperceive the same context for epoch t+1, they will render the\nsame decision (i.e., choice of protocol) for epoch t+1.\nDistributed online data collection. In a Byzantine environ-\nment, no centralized entity could be trusted to collect training\ndata. Therefore, the learning agents in BFTBrain also partici-\npate in a protocol that coordinates distributed data collection\nin an online fashion. At a high level, for every epoch, each\nlearning agent monitors its local context and reward at run-\ntime, then exchanges them with other agents via a separate\ninstance of BFT consensus independent of the consensus that\nvalidators are running. For each epoch, agents form agreement\nover an aggregation of contexts and rewards that include input\nfrom at least a quorum of two-thirds of agents. The consensus\nalgorithm used for forming this agreement is left open for the\nsystem designer (note that it is invoked only once per epoch,\nhence does not need to have high throughput). Once an agreed\nquorum of local contexts and rewards is obtained, each learn-\ning agent can apply the same robustness filter to the quorum\nin order to get a global context and reward, constituting a\ntraining data point. Details about this learning-coordination\nprotocol are provided in Section 5.\nSwitching BFT protocols. After a BFT protocol is selected\nby the learning agent, the switching mechanism allows each\nvalidator to make use of this protocol for the next epoch. Our\nswitching mechanism is an improvement over Abstract [8],\nwhich aborts a BFT instance if a certain progress condition\nis not met. An epoch in BFTBrain is equivalent to a Backup\ninstance in Abstract . Due to space limits, details on how we\nswitch BFT protocols are provided in Appendix B.\nBFTBrain workflow overview. Figure 1 presents an\noverview of BFTBrain, where each node in the system fol-lows the same workflow as depicted. In the middle of epoch\nt, when the number of executed blocks reaches a certain wa-\ntermark, the validator on node inotifies its local learning\nagent. The learning agent featurizes its current local state\n(i.e., context) observed in epoch t, and uses it to approxi-\nmate the next local state statet+1\nifor epoch t+1. Each agent\nexchanges statet+1\niand its locally measured reward of pre-\nvious epoch rewardt−1\niwith other agents via the learning-\ncoordination protocol. Therefore, each agent obtains the same\nglobal state statet+1and reward rewardt−1. Subsequently,\neach agent adds the (statet−1,protocolt−1,rewardt−1)triplet\nto its experience buffer, and retrains its predictive model Mθ\nbased on its experience buffer as well as the chosen algo-\nrithm to solve CMAB. Once retrained, the predictive model\nMθinferences the performance of each protocol candidate\nunder statet+1, and selects protocolt+1that is predicted to\nhave the best performance. The learning agent then informs\nthe validator to switch to protocolt+1for epoch t+1, the re-\nward of which is then measured locally upon reaching the end\nof epoch t+1. The validator only starts epoch t+1once it\nreceives a decision for that epoch from the companion agent.\nThe learning agent is designed in a way such that the BFT\nsystem is not delayed due to learning. First, within one epoch,\nwhen the model undergoes retraining and inference, the par-\nallel validator process still commits blocks simultaneously.\nSecond, with a lightweight model design and limiting the size\nof the experience buffer, model training and inference can\nbe viewed as a synchronous process. In other words, with a\nreasonable epoch length, the learning agent can complete pro-\ntocol selection before the validator finishes its current epoch,\nwithout impeding the start of the next epoch.\n4 Learning Algorithms\nThis section delves into BFTBrain’s learning algorithms. We\nfirst formalize the learning problem and explain the use of\nThompson sampling. The state and action space design is\nthen outlined, followed by the predictive model description.\n4.1 Problem Formulation\nBFTBrain formulates the learning problem as a contextual\nmulti-armed bandit (CMAB) problem, where an agent peri-\nodically makes decisions in a sequence of epochs. In epoch t,\nthe agent selects an action atin its protocol pool based on a\nprovided state st, and then receives a reward rt. The agent’s\ngoal is to select actions in a way that minimizes regret , i.e., the\ndifference between the reward sum associated with an opti-\nmal selection strategy and the reward sum associated with the\nchosen actions. CMABs assume that epochs are independent\nfrom each other, and that the optimal action depends only on\nthe state st. BFTBrain fits this assumption, since the current\nchoice of protocol does not affect the pattern of workloads and\nfaults in future epochs. Using this CMAB formulation, BFT-\nBrain allows users to specify any performance metric (e.g.,\nthroughput or latency) as the reward function to optimize.\n5\n\nThompson sampling. Amongst different CMAB algorithms,\nwe select Thompson sampling [2, 21] for its simplicity: at\nthe start of each epoch, the learning agent trains a model\nbased on current experience, and then selects the best action\nas predicted by the model. In Thompson sampling, instead\nof selecting the model parameters that are most likely given\nthe training data as used by supervised learning, it samples\nmodel parameters proportionally to their likelihood given\nthe training data . More formally, we can define maximum\nlikelihood estimation as finding the model parameters θthat\nmaximize likelihood given experience E:argmaxθP(θ|E)\n(assuming a uniform prior). Instead of maximizing likelihood,\nThompson sampling simply samples from the distribution\nP(θ|E). As a result, if we have a lot of data suggesting that\nour model weights should be in a certain part of the parameter\nspace, our sampled parameters are likely to be in that part of\nthe space. Conversely, if we have only a small amount of data\nsuggesting that our model weights should be in a certain part\nof the parameter space, we may or may not sample parameters\nin that part of the space during any given epoch.\n4.2 State and Action Space\nWe next list factors that affect the performance of BFT pro-\ntocols, broadly grouped into workloads, faults, and hard-\nware/system configurations categories, jointly constituting\nthe state space. Within each epoch, each learning agent lever-\nages a window of the last wexecuted requests to featurize\nsuch factors, where wis a constant hyper-parameter.\nState 1: Workloads (W). The first category consists of factors\nthat are influenced by application and client dynamics.\nW1: Request size. The request size is dependent on the ap-\nplication workload, where some requests contain little data\nwhile others are more involved and require updating files with\nlarge chunks of data. Although all our candidate protocols\nseparate request dissemination from sequencing (i.e., only the\nleader proposals contain the actual requests while the remain-\ning messages contain the hash of requests), as described in\nSection 2, request size is still an important factor impacting\nthe performance of different protocols in different ways. We\nuse the average request size to represent this feature.\nW2: Reply size. Depending on the application, request and re-\nply size can be asymmetric. Reply size also impacts different\nprotocols in different ways, but with a distinct boundary from\nthat of request size. For instance, in our experiments, when\nall other factors remain the same, CheapBFT performs best\nfor either 0KB/4KB (request size/reply size) or 40KB/0KB,\nwhile Zyzzyva is best with 4KB/0KB. Furthermore, different\nprotocols have different sensitivity to an increase in reply size.\nFor instance, SBFT reduces the per-client linear reply cost to\njust one message by adding an execution aggregation phase.\nWe use the average reply size to represent this feature.\nW3: Load on system. The load on the BFT system is depen-\ndent on the number of clients and the rate at which clients\nsend new requests. Specifically, each honest client allows aquota of outstanding unacknowledged requests before issuing\nnew ones, controlling the rate at which requests are generated\nrelative to the system’s capacity to process them.\nIn our experiments, we observed that lowering the load af-\nfects different protocols in the same direction, but to different\nextents: for example, there is a sharper drop in the throughput\nof Zyzzyva and SBFT compared with other protocols. The\nreason is that lower load increases batching delay, which has\na larger impact in terms of both latency and throughput on\nprotocols with fewer phases (i.e., Zyzzyva and SBFT in our\nprotocol pool). BFTBrain derives the per-client sending rate\naccording to the request timestamps, and uses the aggregated\nclient sending rate to represent this feature.\nW4: Execution overhead. Execution overhead captures the\ncomputational cost of request execution, which impacts the\nsystem in two ways. First, it directly affects the execution la-\ntency in state machine replication. Second, it indirectly affects\nother components of the BFT protocol that are also compute-\nintensive. For instance, requests with high execution overhead\ncompete for CPU resources that are otherwise used to sign\nand verify messages, especially when machines have limited\ncompute capacity or a small number of cores. Higher compute\nload results in excessive context switching, and potentially\npushes the system towards being compute-bound instead of\nnetwork-bound. We use the CPU cycles consumed by the\nexecutor thread to represent this feature.\nState 2: Faults (F). The next category of factors is tied to\nfaulty behaviors. BFT protocols make different assumptions\nabout “steady state” and “common faults”, and hence, each\nprotocol is often optimized for specific fault scenarios. The\nfeatures below enable BFTBrain to tell what type of fault\nscenarios the system is experiencing and choose the most\npromising protocol accordingly.\nNote that BFTBrain does not aim to defend against tran-\nsient orbroad-spectrum faults. The reason is, transient faults\nare already handled timely at the protocol level and require no\nprotocol switching. An example would be a crashed leader or\na malicious leader which equivocates, such that no progress\nis made and a view-change will be triggered to replace the\nleader. For broad-spectrum faults, effective and orthogonal\nsolutions already exist. Examples of broad-spectrum faults\ninclude network flooding which can be resolved via resource\nisolation [8], and malformed client requests which can be han-\ndled by enforcing client signatures (instead of MACs) [23].\nF1: Absence from participation. In BFT consensus, valida-\ntors can be absent from participation for various reasons: a\n(benignly) crashed validator is absent from all protocol phases\nafter crashing, while an alive malicious validator could be ab-\nsent from any arbitrary phases.\nMeasuring absence is tricky in a Byzantine environment,\nespecially considering that a collusion of fmalicious partici-\npants could taint validator participation simply by excluding\nsome alive benign validators (up to f) and progressing with-\nout them. For example, a malicious leader could deliberately\n6\n\navoid sending leader proposals to them, while the fmalicious\nvalidators work together with the remaining f+1benign\nones to make sure all requests are committed successfully on\nthese 2f+1validators. We refer to such excluded, non-faulty\nvalidators as being placed in-dark . In-dark validators could\nfurther be excluded in other protocol phases, in addition to\nleader proposals, by fmalicious validators. Since no state\ntransition is ever triggered on in-dark validators, they remain\nin the initial state and are thus absent from participation. Al-\nthough they will timeout and complain, since fewer than f+1\nvalidators complain, view-change is not triggered to replace\nthe malicious leader and they are in-dark continuously.\nAll protocols tolerate the absence of up to fvalidators by\ndesign, but the performance of different protocols is impacted\ndifferently. As illustrated in Section 2, dual-path protocols\n(i.e., Zyzzyva, SBFT) are adversely impacted since the more\nexpensive slow paths are initiated, while single-path protocols\n(i.e., PBFT, CheapBFT, Prime, HotStuff-2) could be positively\nimpacted due to less resource consumption.\nThe learning agents in BFTBrain featurize absence by uti-\nlizing information that is already collected locally during\nprotocol execution. First, fast path ratio captures the percent-\nage of slots committed in the fast path over the total number of\ncommitted slots. For single-path protocols, all slots are com-\nmitted in the slow path. Second, for each slot, the agent sums\nthe number of (valid) distinct messages from each sender, de-\nriving the number of received messages per slot . Note that this\nfeature does not incur more messages to be sent or received;\nit simply counts messages as they arrive and pass preliminary\nprocessing (de-serializing and sender verification) before they\ncan be excluded from protocol steps like voting.\nF2: Slowness of proposal. In leader-based BFT protocols, ev-\nery slot is initiated by a leader proposal, which significantly\naffects the system’s end-to-end performance. In the case of\na faulty leader, validators use a timer to trigger view-change,\nwhich will replace the leader, hence guaranteeing liveness.\nHowever, a malicious leader can deliberately slow down its\nproposals without being replaced, resulting in poor latency\nand throughput. Slowness may not necessarily be a deliberate\nact by a malicious leader, it could result simply from a weak\nor overloaded leader, albeit to a lighter extent.\nSection 2 illustrates the effect of this factor. Protocols\nwith routine or proactive leader replacement (i.e., HotStuff-2,\nPrime) maintain good performance under such slowness, but\nperform sub-optimally in other normal cases. To featurize\nthis factor, each node in BFTBrain timestamps every leader\nproposal received, and measures the average time interval\nbetween receiving two consecutive proposals.\nState 3: Hardware and system configurations. The last\ncategory comprises hardware and system configurations.\nHardware-level factors include standard data-center infras-\ntructure network settings that affect network latency and band-\nwidth, and also machine-level configurations such as CPU\nfrequency and the number of cores. System-level configura-tions include the number of nodes in the consensus system\nand the geo-distribution of the nodes. Compared to State 1\nand 2, both hardware and system configurations are fairly\nstatic and do not change rapidly at the timescale of a consen-\nsus deployment. Thus, BFTBrain does not explicitly featurize\nthese factors because (1) the impact of these factors is implic-\nitly encoded in the predictive model trained online, and (2)\nCMABs will converge even without any explicit features [12],\nthe purpose of which is to accelerate convergence so that the\noptimal action is reached before the world changes.\nActions. BFTBrain’s action space consists of the same set of\nleader-based protocols that are studied in Section 2, namely,\nPBFT, Zyzzyva, CheapBFT, Prime, SBFT, and HotStuff-2. As\nwe will show later, since BFTBrain builds a separate model\nfor each candidate protocol, features of the protocol design\nare encoded in the model itself. Thus, BFTBrain does not\nrequire protocol-specific feature engineering for encoding the\naction space, making it easy to incorporate new protocols into\nthe BFTBrain framework. Although BFTBrain focuses on\nchoosing the best-performing protocol, configuring protocol\ninternal parameters (e.g., values of different timers and the\ninterval for rotating leaders) intelligently at run-time can be\nan interesting future extension.\n4.3 Predictive Model\nEach learning agent hosts some predictive models, which\nfollow the value based RL approach: given the featurized\ncurrent state, predict the performance (i.e., reward) of each\naction (i.e., protocol). The simplest implementation would\nbe to build a single predictive model for all protocols, but\nthis has a major drawback. While features W1-W4 in the\nworkloads category are completely independent from the pre-\nvious action, the featurized absence-from-participation F1\nand slowness-of-proposal F2have a “one-step dependency”:\nthe current observed statet+1\nF1,F2is dependent on the previous\nprotocolt. When the workload and fault scenario shift, such\none-step dependency might prevent convergence to the new\noptimal protocol. For instance, if BFTBrain has converged\nto protocols whose leader has lower parallelism (e.g., Prime\ndue to message aggregation in global ordering), the measured\nslowness of proposals will be higher than other protocols,\nregardless of whether a fault is actually happening or not. In\nother words, the interpretation of the slowness-of-proposal\nfeature changes based on the previous action. If the model\nlearns that a high slowness-of-proposal is bad for Zyzzyva,\nthen once Prime is chosen, slowness-of-proposal will always\nseem high, and Zyzzyva may not ever be selected again.\nLuckily, unlike in the general case of Markov decision pro-\ncesses, the dependency observed here is limited to a single\ntime step. That is, the prediction of the next best action is\nindependent given the immediately prior action . To solve\nthis issue rooted in one-step dependency, the learning agent\ntrains a separate model for each possible (previous protocol,\nprotocol) pair, and divides the experience buffer into several\n7\n\nsmaller buckets according to the (previous protocol, protocol)\npair as well. In terms of bandit theory, assuming there are K\nprotocols in our action space, BFTBrain’s approach is equiva-\nlent to playing Kbandit games where each game has Karms.\nIn each game, the current observed statet+1\nF1,F2is independent\nfrom the previous action protocolt.\nIt is worth mentioning that this transformation does not\ncompletely remove the one-step dependency. The action made\nat epoch twill determine which of the Kbandit games is being\nplayed at epoch t+1. A multi-armed bandit algorithm will\nnot be able to take advantage of the fact that some of the\nKbandits may have significantly better reward distributions\nthan others. Thus, the convergence bound on regret of bandit\nalgorithms will not apply to our scenario. However, since\neach of the Kbandits will be played an unbounded number\nof times eventually (assuming the probability of any action\nnever fully reaches 0), regret is still bounded in the limit.\nSpecifically, for each possible (protocolt,protocolt+1)\npair, BFTBrain uses a lightweight random forest [15] as the\npredictive model, which is trained exclusively on the cor-\nresponding experience bucket. The model takes the featur-\nized state as input, and outputs the predicted performance\nfor the corresponding candidate action protocolt+1. Thus, at\ninference time, given a known previous protocol and the cur-\nrent state, the learning agent enumerates Kmodels to get the\npredicted performance for each candidate protocol, and then\nchooses the candidate with the best predicted performance to\nbe carried out. Once there is a tie on the best predicted per-\nformance, we break the tie randomly to avoid local maxima.\nWhen an experience bucket is empty, BFTBrain prioritizes ex-\nploring this bucket by choosing the corresponding candidate\nprotocol to be carried out.\nIntegration with Thompson sampling. Integrating a pre-\ndictive model with Thompson sampling requires the ability\nto sample model parameters from P(θ|E)— the distribu-\ntion of model parameters given the current experience. The\nsimplest technique (which has been shown to work well in\npractice [55]) is to train the model as usual, but only on a boot-\nstrap [14] of the training data. In other words, the predictive\nmodel is trained using |E|random samples drawn with re-\nplacement from experience E, inducing the desired sampling\nproperties. BFTBrain uses this bootstrapping technique on\neach experience bucket and predictive model for its simplicity.\nOverhead of learning. First, BFTBrain’s training overhead\nis not larger than the strawman of building a single predictive\nmodel, since in every epoch, only one model which corre-\nsponds to the updated bucket needs to be retrained. For such\na bucket, the time complexity for training a single random\nforest is O(nlogn), where nis the number of data points.\nThus, given the same total population of data, it even incurs\nless training overhead than the strawman solution, since the\nbucket contains fewer data points than the single unified ex-\nperience buffer. Second, BFTBrain’s inference overhead isO(K), where Kis the number of candidate protocols. Lastly,\nBFTBrain has the same memory overhead as the strawman\nfor storing training data. However, it incurs O(K2)memory\noverhead for storing the models. Since random forest is a very\nlightweight model as compared to deep neural networks, such\nmodel storage overhead is negligible.\n5 Learning Coordination\nThe goal of the learning-coordination mechanism is to form\nan agreement at each epoch on a report quorum that includes\nlocal metrics collected from 2 f+1 nodes.\nSpecifically, learning coordination is performed in every\nepoch t. After executing wrequests (a hyper-parameter) in\nepoch t, each node igathers local performance indicators\npt−1\nimeasured during epoch t−1, featurizes the next state\nft+1\ni, and broadcasts both metrics inside a report message. To\nensure that at least f+1metrics in the report quorum are\nhonest measurements, it is important that the metrics reported\nby honest nodes are measured by themselves . That is, if a\nnode jhas been placed in-dark (defined in Section 4.2) or\ntemporarily slows down during epoch t, it may not have exe-\ncuted wrequests by itself. Rather, node jwill have recovered\nthe consensus state through a state-transfer from other nodes.\nIn this case, jshould avoid reporting the state features it has\ncopied from others, and likewise, avoid reporting performance\nindicators collected from partial or no execution. Therefore,\nnode jwill not report any metrics for epoch t. Note that in\naddition to the fbenign nodes being placed in-dark, in the\nmeantime, the fByzantine nodes that contributed to commit-\nting requests can refuse to report their metrics. Hence, there\nmay not be enough 2 f+1 nodes reporting for the epoch.\nIn order for nodes to agree on a quorum of (valid) reports\nto be used as input for the learning engine, any “blackbox”\nvalidated Byzantine consensus primitive (VBC) seeded with\na leader collecting reports from 2f+1nodes can be utilized.\nSpecifically, for each epoch t, the leader of VBC initiates\nVBC-PROPOSE ((t,reportQCt),P) once it receives valid report\nmessages ( pt−1\ni,ft+1\ni) where both fields are non-null from\n2f+1nodes, or when a timer expires. Here, Pis an external\nvalidity predicate that checks if reportQCtincludes at least\nf+1 distinct reports.\nEach node participating in VBC gates voting for a leader\nproposal it receives by applying the validity predicate Pto it.\nOnce a quorum of reports reportQCtis decided by VBC, if it\nincludes sufficient 2f+1reports, each node takes the median\nvalue of each field in order to obtain a robust global per-\nformance measurement pt−1and state feature ft+1, thereby\ntriggering the retraining and inference process. Taking the\nmedian value from an aggregated set of metrics guarantees\nthat despite farbitrarily manipulated values from Byzantine\nnodes, the global value taken is between two honest mea-\nsurement values. Otherwise, if reportQCtdoes not include\nsufficient reports, each node retains the decision from the\nprevious epoch instead of deriving any new learning deci-\n8\n\nsion, and complains about the leader in VBC as well as the\nleader in the current protocol used by the node for committing\nclient requests. Note that since VBC is a separate consensus\ninstance, the leader of VBC can be different from the leader\nof the current protocol in BFTBrain. Either of them acting\nmaliciously can result in insufficient reports being collected.\nFor completeness, Appendix C.1 presents in Algorithm 1\na detailed learning coordination protocol where VBC is im-\nplemented using PBFT. Due to space limitations, the safety,\nliveness, and robustness guarantees of BFTBrain’s learning\nagents are discussed and proved in Appendix C.2.\n6 Implementation\nWe implemented BFTBrain in Java using Bedrock [5], a uni-\nfied platform for BFT protocol implementation and experi-\nmentation. The Bedrock platform consists of four main com-\nponents: the core unit, the state machine manager, the plugin\nmanager, and the coordination unit. The core unit defines en-\ntities (e.g., clients and validators), maintains the application\nlogic, enables users to specify different workloads and bench-\nmarks, and track the execution of requests via sequence num-\nbers and views. The state machine manager parses Bedrock’s\ndomain-specific language (DSL) for rapidly prototyping BFT\nprotocols, and defines the states and transitions of the specific\nBFT protocol for each entity. The plugin manager enables\nimplementing protocol-specific behaviors that cannot be cap-\ntured by Bedrock’s DSL, while the coordination unit manages\nthe run-time execution of Bedrock.\nAll protocol candidates in BFTBrain’s action space utilize\nBedrock. On top of it, we implemented a workload and fault\ngenerator, which allows users to specify time-varying dynam-\nics inside a YAML configuration file, enabling parameterized\nrandom sampling and scheduling of predefined sequences of\nevents. To enable switching among BFT protocols, we imple-\nmented a new state machine manager which loads all plugins\nrequired by BFTBrain when the system boots, and uniquely\ntags each protocol state and transition such that different pro-\ntocols do not interfere. This approach has negligible overhead\nsince such loading and tagging only happens when the system\nboots, and lookup for states and transitions at run-time takes\na (small) constant time. We implemented the learning agent\nseparately in Python using scikit-learn , which communi-\ncates with the companion validator process in Bedrock via\ngRPC. Our implementation is publicly available2.\n7 Evaluation\nOur evaluation aims to answer the following questions:\n1.How fast can BFTBrain converge to the best-performing\nprotocol under static conditions without pre-training?\n2.How does BFTBrain compare to fixed protocols and exist-\ning learning-based approaches in dynamic environments?\n3.How does the hardware setup affect the performance of\nfixed protocols? How does BFTBrain compare to existing\n2https://github.com/JeffersonQin/BFTBrainlearning approaches under different hardware setups?\n4.How robust is BFTBrain and how does it compare to ex-\nisting learning approaches under adversarial data pollution?\n5. What learning overhead does BFTBrain introduce?\nIn the rest of this section, we present the experimental setup\nand then answer each of the above questions.\n7.1 Experimental Setup\nTestbed. Unless otherwise specified, our testbed consists of\nseveral bare-metal xl170 machines on CloudLab, each with a\n10-core Intel E5-2640v4 processor at 2.4 GHz, 64GB ECC\nMemory, and two dual-port Mellanox ConnectX-4 25 GB\nNIC. Each server is connected via a 10Gbps control link and\na 25Gbps experimental link to Mellanox 2410 switches in\ngroups of 40 servers. Our experiments are conducted using\nthe experimental link.\nSystem configuration. Our experiments are carried over net-\nworks of two sizes: n=4andn=13. In all experiments, we\nrun multiple client threads on a separate xl170 server, where\neach client follows the standard closed-loop buffer design,\ni.e., allows at most 100 outstanding unacknowledged requests\nbefore issuing new ones. The number of clients is a parameter\nin our workload space. We use batch sizes of 10 requests\nthroughout the experiments. Every experiment of BFTBrain\nstarts with PBFT as its initial protocol. We use throughput as\nthe reward function for BFTBrain to optimize.\n7.2 Convergence under Static Conditions\nOur first set of experiments evaluates how quickly can BFT-\nBrain converge to the best-performing protocol under static\nconditions. We picked three representative settings from Ta-\nble 1 where the size of the network is small: row 1, a variant\nof row 4 where f=1, and row 8. Under each setting, we\nran all six fixed protocols and BFTBrain for 10minutes on a\nLAN. We note that the other rows in Table 1 yielded similar\nconclusions and are omitted for brevity.\nTable 2 summarizes our results, listing for each static con-\ndition the average throughput (tps) of each protocol in the last\n20epochs. The last column reports the convergence time of\nBFTBrain, defined as the time BFTBrain spent to reach the\nstable peak throughput. Although each setting has a different\nbest-performing protocol, BFTBrain always learns to select it\nwithin 0.81-5.39minutes3. As we will show soon, the conver-\ngence is significantly accelerated the second time BFTBrain\nencounters the same conditions.\nObviously, in this experiment, BFTBrain is not able to\nsurpass the best-performing protocol in any given setting. Ad-\nditionally, as shown in the table, it experiences a marginal\nincrease in switching overhead when compared to the leading\nprotocol in each specific setting. Nevertheless, owing to its\nadaptability, BFTBrain does deliver the best average and best\nworst-case performance across all settings in the table. In con-\ntrast, fixed protocols exhibit subpar average and worst-case\n3Most RL systems quantify convergence time in minutes.\n9\n\nTable 2: Throughput of protocols and the convergence time of BFTBrain under various static conditions. The highest throughput\nin each row is highlighted in blue.\nConditionAverage Throughput (tps)Conv. Time (minutes)PBFT Zyzzyva CheapBFT Prime SBFT HotStuff-2 BFTBrain\nRow 1 (LAN) 9133 13664 11822 4601 11067 6882 13100 0.81\nRow 4 (LAN)* 10303 1025 12297 3749 2920 5156 11803 2.08\nRow 8 (LAN) 989 988 989 4527 989 2640 4329 5.39\nRow 1 (WAN) 5325 9503 12201 1639 8261 2882 11101 1.58\nAverage 6438 6295 9327 3629 5809 4390 10083 2.47\nWorst 989 988 989 1639 989 2640 4329 5.39\nZyzzyvaZyzzyvaZyzzyva\nZyzzyva\nCheapBFTCheapBFT\nCheapBFT\nCheapBFTHotstuff-2\nHotstuff-2Hotstuff-2Hotstuff-2Hotstuff-2Prime\nFigure 2: Adaptivity of BFTBrain under changing conditions.\nThe vertical dashed lines indicate when conditions change.\nLabels indicate the dominant protocol that BFTBrain and\nADAPT choose under each condition.\nFigure 3: BFTBrain’s throughput (a) during minutes 0-30, and\n(b) during minutes 180-210. In both periods, it encounters the\nsystem conditions captured in row 2 of Table 1.\nthroughput, underscoring our initial premise that no single\nfixed protocol excels under all circumstances.\n7.3 Adaptivity under Changing Conditions\nOur next set of experiments evaluate BFTBrain under dy-\nnamic conditions, demonstrating clear performance benefits.\nCycle back conditions. In the initial series of experiments,\nwe selected rows 2-7 from Table 1, each characterized by an\nidentical network size ( f=4). We ran the settings of each\nrow for 30 minutes each, employing a round-robin approach\nto switch to the next row and repeating the cycle from the be-\nginning after reaching row 7. We compared BFTBrain against\nfive baselines: the fixed protocols with the best and worst\nperformance (based on the number of committed requeststhroughout the entire experiment), ADAPT ,ADAPT #, and an\nexpert heuristic. Details on the last three are explained below.\nTo be faithful to ADAPT ’s design [10], we excluded all\nfeatures capturing faults (i.e., State 2 in Section 4.2), and\npre-trained ADAPT with complete data that we collected in\nthese changing conditions when running BFTBrain for hours\nspanning multiple protocols. To study the effect of unseen\nconditions in supervised learning, we implemented another\nbaseline named ADAPT #. In ADAPT #, we used the same\nset of complete features as BFTBrain, but pre-trained it on\npartial data that we collected in these changing conditions,\ni.e., excluding data corresponding to the settings of rows 5-7.\nIn both ADAPT andADAPT #, for fair comparison, we used the\nsame set of BFT protocols as BFTBrain in their action space.\nThe expert heuristic we used is designed based on insights\ngleaned from Table 1, namely: if proposal slowness is greater\nthan 20ms, use Prime; otherwise, use Zyzzyva.\nFigure 2 shows the cumulative number of committed re-\nquests over time, where the slope of each line indicates its\ncurrent throughput. Throughout the 4-hour experiment, BFT-\nBrain successfully converges to the best-performing protocols\nwhenever the conditions change. In terms of the number of\nrequests committed, BFTBrain demonstrates 18% improve-\nment over the best fixed protocol (i.e., HotStuff-2), 119% over\nthe worst fixed protocol (i.e., PBFT), 14% over ADAPT ,19%\nover A DAPT #, and 43% over heuristic.\nAs expected, both ADAPT andADAPT # exhibit similar\nperformance to BFTBrain for the first 60minutes, as the sys-\ntem is operating without faults and their features and training\ndata encompass these conditions. However, both methods\nencounter challenges when the conditions shift to rows 4-7.\nADAPT struggles since it fails to recognize the changes in con-\nditions, as faults are not captured in its feature space. While\nADAPT # does detect the changes due to its expanded feature\nset, these conditions were absent during its pre-training phase.\nTwo things are worthy of noting. First, BFTBrain not only\noutperforms both supervised learning based approaches, but\nalso completely removes the cumbersome data collection and\npre-training process prior to deployment. Second, in com-\nmon stable conditions corresponding to row 2, BFTBrain\noutperforms HotStuff-2 by 57% while being able to switch to\nHotStuff-2 when conditions become advantageous for it.\n10\n\nFigure 3 further demonstrates how BFTBrain’s throughput\nchanges over time: (a) during minutes 0-30, and (b) during\nminutes 180-210. In both periods, it encounters the conditions\ncaptured in row 2of Table 1. Obviously, when the system\ncondition cycles back to what it has seen before, BFTBrain\nconverges to the best-performing protocol much faster than\nthe first time ( 2s vs. 70s). The blips in both throughput plots\nindicate that certain sub-optimal protocols have been chosen\nfor a few epochs. These are the explorations made by the\nThompson sampling algorithm when it samples the less likely\nmodel parameters. When conditions are dynamic, such sam-\npling is crucial to avoid being stuck at a local sub-optimal\ndecision, since the predictive model can gain insights on the\nperformance of unexplored protocols in the current condition.\nRandomized sampling. Our next experiment evaluates BFT-\nBrain’s adaptivity when there are more variations in the state\nspace and when the variations are more frequent . Specifically,\neach dimension in the state space follows a certain normal\ndistribution. We varied each dimension every 1s by randomly\nsampling from its distribution, and shifted the mean and vari-\nance of such distribution every 20minutes. Appendix D.2\npresents the detailed experiment setup and results. In a nut-\nshell, during the entire 2-hour deployment, BFTBrain com-\nmits 44% more requests than ADAPT . This is a much larger\nimprovement than the 14% improvement demonstrated in the\ncycle back experiment and can be explained as follows. Cer-\ntain input factors in the cycle back experiment are correlated,\ne.g., a request size near zero is correlated with high proposal\nslowness. Thus, although ADAPT suffers from incomplete\nfeatures, it indirectly learns the best-performing protocol un-\nder high proposal slowness using other features, as shown in\nFigure 2 between 90-150minutes. However, randomized sam-\npling breaks such correlations, and as a result, ADAPT does\nnot have enough information to know how the surrounding\nenvironment changes which leads to poor performance.\n7.4 Adaptivity to Changing Hardware\nThe next set of experiments evaluate BFTBrain under dif-\nferent hardware setups from our initial protocol evaluation,\nand compare with the adaptivity of ADAPT to these new se-\ntups. Specifically, we reran the settings of row 1from Table 1\non a WAN (RTT= 38.7ms, bandwidth= 559Mbps) instead of\non a LAN, where we placed two nodes in Cloudlab’s Utah\ndata center on xl170 machines and the other two nodes in the\nWisconsin data center on c220g5 machines. We compared\nBFTBrain with fixed protocols and with ADAPT in this setup.\nThe results are summarized under “Row 1 (WAN)” in Ta-\nble 2; the detailed performance plot of BFTBrain and ADAPT\nis provided in Appendix D.3. Interestingly, compared to “Row\n1 (LAN)” where Zyzzyva is the best protocol and leads by\n15.6%, running the same workload and fault conditions on\nWAN with different instance types renders CheapBFT the\nbest protocol, which outperforms Zyzzyva by 28.4%. The\nreason is that Zyzzyva commits via the fast path and requires\nZyzzyva\nZyzzyvaZyzzyvaZyzzyvaZyzzyvaCheapBFTZyzzyvaHotstuff-2Hotstuff-2Hotstuff-2ZyzzyvaCheapBFT\nSBFTCheapBFTSBFTHotstuff-2\nPrime\nPrimePrimePrimeHotstuff-2Hotstuff-2SBFTCheapBFTFigure 4: Robustness of BFTBrain against data pollution. The\nvertical dashed lines indicate when conditions change. Labels\nindicate the dominant protocol that ADAPT (before and after\npollution) chooses under each setting.\nvotes from all nodes, resulting in high end-to-end latency,\ngiven the high RTT between some nodes. CheapBFT, on\nthe other hand, requires a smaller quorum of voters, which\ncould be co-located inside a single data center, thus achieving\nlower latency. With a moderate number of clients (i.e., 50\nin our workload), this results in CheapBFT also achieving\nhigher throughput than Zyzzyva due to finite parallelism. Un-\nder this unseen hardware setup, BFTBrain converges to the\nbest-performing protocol within 1.58minutes without requir-\ning data recollection prior to deployment. On the contrary,\nADAPT cannot transfer the knowledge it learned on different\nhardware setups. As a result, when ADAPT is pre-trained with\ncomplete data we collected on “Row 1 (LAN)”, it remains\nstuck at the sub-optimal decision Zyzzyva.\nThis experiment demonstrates the operational benefits of\nBFTBrain when hardware configurations may differ across\ndeployments. BFTBrain can rapidly converge to the best-\nperforming protocol for new hardware settings without any\nhuman intervention. As discussed before, it may not be practi-\ncal to recollect data and pre-train a supervised approach such\nas A DAPT on every new hardware setup.\n7.5 Robustness of BFTBrain\nIn a Byzantine environment, malicious nodes might arbitrarily\nmanipulate (i.e., pollute) their collected metrics in order to\nmisguide the machine learning models. Our next experiment\ncompares the resilience of BFTBrain and ADAPT under data\npollution. We ran the same dynamic benchmark as the “cycle\nback conditions” experiment in Section 7.3, and compared\nBFTBrain with ADAPT ’s performance under two types of data\npollution: slight and severe. In the slight pollution scenario,\nonly the reward (i.e., throughput) of SBFT was increased to\n2.5x of its true value. In the severe pollution, regardless of\nthe protocol, for every single data point, both its state and re-\nward were polluted by replacing the true values with random\nvalues. The random value was chosen uniformly between 0\n11\n\nand 5x the maximal true value for the polluted dimension.\nNote that when polluting BFTBrain, flearning agents were\nmalicious and hence reported polluted values as their local\nmeasurements; when polluting ADAPT , the malicious cen-\ntralized entity polluted training data and distributed the same\ndata to all nodes in the system.\nFigure 4 shows the number of committed requests with\nrespect to time, under different types of pollution. Compared\nto non-polluted scenarios, under slight pollution, BFTBrain\nincurs only a 0.7% performance drop, while ADAPT suffers\nfrom a 12% drop. Thus, after such slight pollution where\nonly less than 0.01% of the data population is polluted, BFT-\nBrain outperforms ADAPT by 28%. Under severe pollution,\nalthough the fmalicious learning agents cause a distribution\nshift in BFTBrain’s global state and reward, BFTBrain only\nincurs a 0.5% performance drop. The reason is, as proved in\nSection C.2, the learning-coordination protocol guarantees\nthat the global feature and reward always fall into the range\nbetween two honest local observations. On the contrary, when\nall features and rewards can be arbitrarily manipulated by the\ncentralized entity in ADAPT , it performs no better than ran-\ndomly choosing protocols. In the worst case, a smart pollution\nstrategy misguides ADAPT to pick the worst protocol for each\ncondition (as shown by the A DAPT (severe pollution) line in\nFigure 4), resulting in a 55% performance drop. In such a\nscenario, BFTBrain outperforms A DAPT by 154%.\n7.6 Overhead of BFTBrain\nOur last experiment evaluates the overhead incurred by BFT-\nBrain’s learning framework. We repeated the “cycle back\nconditions” experiment in Section 7.3, and plot BFTBrain’s\ntraining and inference overhead in each epoch in Figure 15\n(provided in Appendix D.4). Labels indicate the dominant\nprotocol that BFTBrain chooses in each segment of the figure.\nThe training overhead increases quasi-linearly in each seg-\nment, but zigzags across different segments. The reason is that\nBFTBrain’s training overhead increases with the number of\ndata points in the experience bucket, and the bucket used for\ntraining (i.e., one out of K2) depends on the previous and cur-\nrent protocol. Within one segment, since BFTBrain chooses\nthe best-performing protocol dominantly after convergence, a\ncertain bucket is selected dominantly and accumulates train-\ning data. The drops of overhead in the figure is caused by\nBFTBrain’s exploration of other protocol, resulting in other\nsmaller buckets being retrained. On the contrary, the inference\noverhead is always constant with the number of epochs.\nWe also measured the duration of epochs in this experi-\nment: 0.88s in minimum and 1.31s in average. During the\nentire 4-hour deployment, compared to the duration of epochs,\neven the maximum training and inference overhead is negli-\ngible, due to the lightweight nature of random forests. More\nimportantly, the learning agent and validator are two parallel\nprocesses. Thus, the overhead of learning does not adversely\naffect the node’s throughput, as long as there are some spareCPU cycles devoted to the learning agent. When BFTBrain\nis deployed for a longer run, techniques such as periodic re-\nsampling and limiting the size of the experience bucket can\nbe utilized [54] to control the overhead of learning.\n8 Related Work\nThe BFT consensus problem has been studied extensively,\nand surveying it is beyond the scope of this work; readers may\nfind introductory material in textbooks, various surveys, and\nmeasurement studies, e.g., [7, 17, 25, 26, 51, 56, 57, 60, 65]. As\nan example, BFTSim [57] provides a simulation environment\nfor BFT protocols, which has been used to evaluate a set of\nprotocols under multiple scenarios. The specific set of BFT\nprotocols which are incorporated in BFTBrain [4, 19, 40, 43,\n46, 52] belong to a category of solutions for a setting called\npartial synchrony which has been introduced in [29].\nBFTBrain employs a mechanism similar to reconfiguration\nwhich allows the system to switch the parameters of a BFT\nalgorithm by agreement at certain positions within a sequence\nof decisions. The reconfiguration problem has been formal-\nized in several works, both in the benign fault settings and the\nByzantine setting, e.g., [8, 13, 16, 38, 42, 49, 50].\nTo our knowledge, the first work to propose switching be-\ntween a set of BFT protocols in real-time to adapt to dynamic\nconditions is Abstract [8]. It was followed by ADAPT [10],\nwhich further enhanced the approach by training a supervised\nlearning model to govern switching. BFTBrain embraces\nthe idea of a multi-protocol BFT engine while considerably\nenhancing its practicality via a decentralized reinforcement\nlearning engine that provides significant operational bene-\nfits and by introducing deep performance metrics, capturing\nfaults, and being hardware agnostic.\nAt the core of BFTBrain, learning in untrusted distributed\nsettings is made resilient against intentional data pollution\nvia robust aggregation and agreement. Similar techniques\nhave been explored in robust distributed learning studies\n[3, 11, 32, 39, 44, 63]. More generally, harnessing learning\nto enhance performance has been done successfully in many\nsystems under the umbrella of machine programming [36]:\nindexing [47], query optimization [54, 62, 67], database tun-\ning [58], software analysis [41], scheduling [53], concurrency\ncontrol [59], and transaction management in blockchains [61].\n9 Conclusion\nExisting BFT protocols lack flexibility and adaptability, lead-\ning to suboptimal performance in various scenarios. In this\npaper, we propose a practical reinforcement learning-based\nBFT system called BFTBrain, which dynamically selects the\ntop-performing BFT protocols in real-time. Our extensive\nevaluation demonstrates that BFTBrain significantly outper-\nforms existing solutions under various conditions, including\ndynamic environments and adversarial attacks.\n12\n\nReferences\n[1]The diem team. https://developers.diem.com/papers/diem-\nconsensus-state-machine-replication-in-the-diem-\nblockchain/2021-08-17.pdf, 2021.\n[2]Shipra Agrawal and Navin Goyal. Further optimal regret\nbounds for thompson sampling. In The International\nConference on Artificial Intelligence and Statistics , AIS-\nTATS ’13.\n[3]Youssef Allouah, Rachid Guerraoui, Nirupam Gupta,\nRafael Pinot, and Geovani Rizk. Robust distributed\nlearning: Tight error bounds and breakdown point under\ndata heterogeneity. In Conf. on Neural Information\nProcessing Systems (NeurIPS) , 2023.\n[4]Yair Amir, Brian Coan, Jonathan Kirsch, and John Lane.\nPrime: Byzantine replication under attack. Transactions\non Dependable and Secure Computing , 8(4):564–577,\n2011.\n[5]Mohammad Javad Amiri, Chenyuan Wu, Divyakant\nAgrawal, Amr El Abbadi, Boon Thau Loo, and Moham-\nmad Sadoghi. The bedrock of byzantine fault tolerance:\nA unified platform for {BFT}protocols analysis, im-\nplementation, and experimentation. In 21st USENIX\nSymposium on Networked Systems Design and Imple-\nmentation (NSDI 24) , pages 371–400, 2024.\n[6]Elli Androulaki, Artem Barger, Vita Bortnikov, Chris-\ntian Cachin, Konstantinos Christidis, Angelo De Caro,\nDavid Enyeart, Christopher Ferris, Gennady Laventman,\nand Yacov Manevich. Hyperledger fabric: a distributed\noperating system for permissioned blockchains. In Eu-\nropean Conf. on Computer Systems (EuroSys) , pages\n30:1–30:15. ACM, 2018.\n[7]Hagit Attiya and Jennifer Welch. Distributed comput-\ning: fundamentals, simulations, and advanced topics ,\nvolume 19. John Wiley & Sons, 2004.\n[8]Pierre-Louis Aublin, Rachid Guerraoui, Nikola Kneže-\nvi´c, Vivien Quéma, and Marko Vukoli ´c. The next 700 bft\nprotocols. Transactions on Computer Systems (TOCS) ,\n32(4):12, 2015.\n[9]Amy Babay, John Schultz, Thomas Tantillo, Samuel\nBeckley, Eamon Jordan, Kevin Ruddell, Kevin Jordan,\nand Yair Amir. Deploying intrusion-tolerant scada for\nthe power grid. In Int. Conf. on Dependable Systems\nand Networks (DSN) , pages 328–335. IEEE, 2019.\n[10] Jean-Paul Bahsoun, Rachid Guerraoui, and Ali Shoker.\nMaking bft protocols really adaptive. In Int. Parallel\nand Distributed Processing Symposium , pages 904–913.\nIEEE, 2015.\n[11] Gilad Baruch, Moran Baruch, and Yoav Goldberg. A\nlittle is enough: Circumventing defenses for distributedlearning. Advances in Neural Information Processing\nSystems , 32, 2019.\n[12] Omar Besbes, Yonatan Gur, and Assaf Zeevi. Stochas-\ntic multi-armed-bandit problem with non-stationary re-\nwards. In Advances in neural information processing\nsystems , NIPS ’14, pages 199–207.\n[13] Alysson Bessani, Joao Sousa, and Eduardo EP Alchieri.\nState machine replication for the masses with bft-smart.\nInInt. Conf. on Dependable Systems and Networks\n(DSN) , pages 355–362. IEEE, 2014.\n[14] Leo Breiman. Bagging predictors. In Machine Learning ,\nMaching Learning ’96.\n[15] Leo Breiman. Random forests. 45(1):5–32.\n[16] Mike Burrows. The chubby lock service for loosely-\ncoupled distributed systems. In Symposium on Operat-\ning Systems Design and Implementation (OSDI) , pages\n335–350. USENIX Association, 2006.\n[17] Christian Cachin and Marko Vukoli ´c. Blockchain con-\nsensus protocols in the wild. In Int. Symposium on\nDistributed Computing (DISC) , pages 1–16, 2017.\n[18] Miguel Castro and Barbara Liskov. Practical byzantine\nfault tolerance. In Symposium on Operating Systems\nDesign and Implementation (OSDI) , pages 173–186.\nUSENIX Association, 1999.\n[19] Miguel Castro and Barbara Liskov. Practical byzantine\nfault tolerance and proactive recovery. Transactions on\nComputer Systems (TOCS) , 20(4):398–461, 2002.\n[20] Lujing Cen, Ryan Marcus, Hongzi Mao, Justin\nGottschlich, Mohammad Alizadeh, and Tim Kraska.\nLearned garbage collection. In Proceedings of the 4th\nACM SIGPLAN International Workshop on Machine\nLearning and Programming Languages , MAPL @ PLDI\n’20. ACM.\n[21] Olivier Chapelle and Lihong Li. An empirical evalu-\nation of thompson sampling. In Advances in neural\ninformation processing systems , NIPS’11.\n[22] Allen Clement, Manos Kapritsos, Sangmin Lee, Yang\nWang, Lorenzo Alvisi, Mike Dahlin, and Taylor Riche.\nUpright cluster services. In Symposium on Operating\nSystems Principles (SOSP) , pages 277–290. ACM, 2009.\n[23] Allen Clement, Edmund L Wong, Lorenzo Alvisi,\nMichael Dahlin, and Mirco Marchetti. Making byzan-\ntine fault tolerant systems tolerate byzantine faults. In\nSymposium on Networked Systems Design and Imple-\nmentation (NSDI) , volume 9, pages 153–168. USENIX\nAssociation, 2009.\n13\n\n[24] Shir Cohen, Rati Gelashvili, Lefteris Kokoris Kogias,\nZekun Li, Dahlia Malkhi, Alberto Sonnino, and Alexan-\nder Spiegelman. Be aware of your leaders. In Int. Conf.\non Financial Cryptography and Data Security , pages\n279–295. Springer, 2022.\n[25] Miguel Correia, Giuliana Santos Veronese, Nuno Fer-\nreira Neves, and Paulo Verissimo. Byzantine consensus\nin asynchronous message-passing systems: a survey. Int.\nJournal of Critical Computer-Based Systems , 2(2):141–\n161, 2011.\n[26] Tobias Distler. Byzantine fault-tolerant state-machine\nreplication from a systems perspective. ACM Computing\nSurveys (CSUR) , 54(1):1–38, 2021.\n[27] Dan Dobre, Ghassan Karame, Wenting Li, Matthias Ma-\njuntke, Neeraj Suri, and Marko Vukoli ´c. Powerstore:\nProofs of writing for efficient and robust storage. In\nConf. on Computer and communications security (CCS) ,\npages 285–298. ACM, 2013.\n[28] Dmitry Duplyakin, Robert Ricci, Aleksander Maricq,\nGary Wong, Jonathon Duerig, Eric Eide, Leigh Stoller,\nMike Hibler, David Johnson, Kirk Webb, et al. The de-\nsign and operation of {CloudLab }. InAnnual Technical\nConf. (ATC) , pages 1–14. USENIX Association, 2019.\n[29] Cynthia Dwork, Nancy Lynch, and Larry Stockmeyer.\nConsensus in the presence of partial synchrony. Journal\nof the ACM (JACM) , 35(2):288–323, 1988.\n[30] Amr El Abbadi, Dale Skeen, and Flaviu Cristian. An\nefficient, fault-tolerant protocol for replicated data man-\nagement. In SIGACT-SIGMOD symposium on Princi-\nples of database systems , pages 215–229. ACM, 1985.\n[31] Amr El Abbadi and Sam Toueg. Availability in parti-\ntioned replicated databases. In SIGACT-SIGMOD sym-\nposium on Principles of database systems , pages 240–\n251. ACM, 1986.\n[32] Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta,\nRafael Pinot, and John Stephan. Byzantine machine\nlearning made easy by resilient averaging of momen-\ntums. In Int. Conf. on Machine Learning (ICML) , pages\n6246–6283. PMLR, 2022.\n[33] Miguel Garcia, Nuno Neves, and Alysson Bessani. An\nintrusion-tolerant firewall design for protecting siem\nsystems. In Conf. on Dependable Systems and Networks\nWorkshop (DSN-W) , pages 1–7. IEEE, 2013.\n[34] Miguel Garcia, Nuno Neves, and Alysson Bessani.\nSieveq: A layered bft protection system for critical ser-\nvices. IEEE Transactions on Dependable and Secure\nComputing , 15(3):511–525, 2016.[35] Garth R Goodson, Jay J Wylie, Gregory R Ganger, and\nMichael K Reiter. Efficient byzantine-tolerant erasure-\ncoded storage. In Int. Conf. on Dependable Systems and\nNetworks (DSN) , pages 135–144. IEEE, 2004.\n[36] Justin Gottschlich, Armando Solar-Lezama, Nesime Tat-\nbul, Michael Carbin, Martin Rinard, Regina Barzilay,\nSaman Amarasinghe, Joshua B. Tenenbaum, and Tim\nMattson. The three pillars of machine programming. In\nProceedings of the 2nd ACM SIGPLAN International\nWorkshop on Machine Learning and Programming Lan-\nguages , MAPL 2018, pages 69–80. Association for\nComputing Machinery.\n[37] Vincent Gramoli, Rachid Guerraoui, Andrei Lebedev,\nChris Natoli, and Gauthier V oron. Diablo: A benchmark\nsuite for blockchains. In European Conf. on Computer\nSystems (EuroSys) . ACM, 2023.\n[38] Rachid Guerraoui, Nikola Kneževi ´c, Vivien Quéma, and\nMarko Vukoli ´c. The next 700 bft protocols. In European\nconf. on Computer systems (EuroSys) , pages 363–376.\nACM, 2010.\n[39] Rachid Guerraoui, Sébastien Rouault, et al. The hidden\nvulnerability of distributed learning in byzantium. In Int.\nConf. on Machine Learning (ICML) , pages 3521–3530.\nPMLR, 2018.\n[40] Guy Golan Gueta, Ittai Abraham, Shelly Grossman,\nDahlia Malkhi, Benny Pinkas, Michael K Reiter, Dragos-\nAdrian Seredinschi, Orr Tamir, and Alin Tomescu.\nSbft: a scalable decentralized trust infrastructure for\nblockchains. In Int. Conf. on Dependable Systems and\nNetworks (DSN) , pages 568–580. IEEE/IFIP, 2019.\n[41] Niranjan Hasabnis and Justin Gottschlich. ControlFlag:\na self-supervised idiosyncratic pattern detection system\nfor software control structures. In Proceedings of the 5th\nACM SIGPLAN International Symposium on Machine\nProgramming , MAPS ’21, pages 32–42. Association for\nComputing Machinery.\n[42] Patrick Hunt, Mahadev Konar, Flavio P Junqueira, and\nBenjamin Reed. {ZooKeeper }: Wait-free coordination\nfor internet-scale systems. In Annual Technical Conf.\n(ATC) . USENIX Association, 2010.\n[43] Rüdiger Kapitza, Johannes Behl, Christian Cachin,\nTobias Distler, Simon Kuhnle, Seyed Vahid Moham-\nmadi, Wolfgang Schröder-Preikschat, and Klaus Stengel.\nCheapbft: resource-efficient byzantine fault tolerance.\nInEuropean Conf. on Computer Systems (EuroSys) ,\npages 295–308. ACM, 2012.\n[44] Sai Praneeth Karimireddy, Lie He, and Martin Jaggi.\nLearning from history for byzantine robust optimization.\nInInt. Conf. on Machine Learning (ICML) , pages 5311–\n5319. PMLR, 2021.\n14\n\n[45] Jonathan Kirsch, Stuart Goose, Yair Amir, Dong Wei,\nand Paul Skare. Survivable scada via intrusion-tolerant\nreplication. IEEE Transactions on Smart Grid , 5(1):60–\n70, 2013.\n[46] Ramakrishna Kotla, Lorenzo Alvisi, Mike Dahlin, Allen\nClement, and Edmund Wong. Zyzzyva: speculative\nbyzantine fault tolerance. Operating Systems Review\n(OSR) , 41(6):45–58, 2007.\n[47] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and\nNeoklis Polyzotis. The case for learned index structures.\nInProceedings of the 2018 International Conference on\nManagement of Data , SIGMOD ’18. ACM.\n[48] Jae Kwon. Tendermint: Consensus without mining.\n2014.\n[49] Leslie Lamport. Paxos made simple. ACM Sigact News ,\n32(4):18–25, 2001.\n[50] Leslie Lamport, Dahlia Malkhi, and Lidong Zhou. Verti-\ncal paxos and primary-backup replication. In symposium\non Principles of distributed computing (PODC) , pages\n312–313. ACM, 2009.\n[51] Dahlia Malkhi. Concurrency: the works of Leslie Lam-\nport. ACM, 2019.\n[52] Dahlia Malkhi and Kartik Nayak. Hotstuff-2: Optimal\ntwo-phase responsive bft. Cryptology ePrint Archive ,\n2023.\n[53] Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja\nVenkatakrishnan, Zili Meng, and Mohammad Alizadeh.\nLearning scheduling algorithms for data processing clus-\nters.\n[54] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime\nTatbul, Mohammad Alizadeh, and Tim Kraska. Bao:\nMaking learned query optimization practical. In Pro-\nceedings of the 2021 International Conference on Man-\nagement of Data , SIGMOD ’21. Award: ’best paper\naward’.\n[55] Ian Osband and Benjamin Van Roy. Bootstrapped\nthompson sampling and deep exploration.\n[56] Marco Platania, Daniel Obenshain, Thomas Tantillo,\nYair Amir, and Neeraj Suri. On choosing server-or client-\nside solutions for bft. ACM Computing Surveys (CSUR) ,\n48(4):1–30, 2016.\n[57] Atul Singh, Tathagata Das, Petros Maniatis, Peter Dr-\nuschel, and Timothy Roscoe. Bft protocols under fire.InSymposium on Networked Systems Design and Imple-\nmentation (NSDI) , volume 8, pages 189–204. USENIX\nAssociation, 2008.\n[58] Dana Van Aken, Andrew Pavlo, Geoffrey J. Gordon,\nand Bohan Zhang. Automatic database management\nsystem tuning through large-scale machine learning. In\nProceedings of the 2017 ACM International Conference\non Management of Data , SIGMOD ’17, pages 1009–\n1024. ACM.\n[59] Jiachen Wang, Ding Ding, Huan Wang, Conrad Chris-\ntensen, Zhaoguo Wang, Haibo Chen, and Jinyang Li.\nPolyjuice: {High-Performance} transactions via learned\nconcurrency control. OSDI ’21, pages 198–216.\n[60] Xin Wang, Sisi Duan, James Clavin, and Haibin Zhang.\nBft in blockchains: From protocols to use cases. ACM\nComputing Surveys (CSUR) , 54(10s):1–37, 2022.\n[61] Chenyuan Wu, Bhavana Mehta, Mohammad Javad\nAmiri, Ryan Marcus, and Boon Thau Loo. AdaChain:\nA learned adaptive blockchain. Proc. of the VLDB En-\ndowment , 16(8):2033–2046, 2023.\n[62] Zongheng Yang, Wei-Lin Chiang, Sifei Luan, Gautam\nMittal, Michael Luo, and Ion Stoica. Balsa: Learning\na query optimizer without expert demonstrations. In\nProceedings of the 2022 International Conference on\nManagement of Data , SIGMOD ’22, pages 931–944.\nAssociation for Computing Machinery.\n[63] Dong Yin, Yudong Chen, Ramchandran Kannan, and\nPeter Bartlett. Byzantine-robust distributed learning: To-\nwards optimal statistical rates. In Int. Conf. on Machine\nLearning (ICML) , pages 5650–5659. PMLR, 2018.\n[64] Maofan Yin, Dahlia Malkhi, Michael K Reiter,\nGuy Golan Gueta, and Ittai Abraham. Hotstuff: Bft\nconsensus with linearity and responsiveness. In Sympo-\nsium on Principles of Distributed Computing (PODC) ,\npages 347–356. ACM, 2019.\n[65] Gengrui Zhang, Fei Pan, Michael Dang’ana, Yunhao\nMao, Shashank Motepalli, Shiquan Zhang, and Hans-\nArno Jacobsen. Reaching consensus in the byzantine\nempire: A comprehensive review of bft consensus algo-\nrithms. arXiv preprint arXiv:2204.03181 , 2022.\n[66] Li Zhou. A survey on contextual multi-armed bandits.\n[67] Rong Zhu, Wei Chen, Bolin Ding, Xingguang Chen,\nAndreas Pfadler, Ziniu Wu, and Jingren Zhou. Lero: A\nlearning-to-rank query optimizer. 16(6):1466–1479.\n15\n\nFigure 5: PBFT protocol\nFigure 6: HotStuff-2 protocol\nA Background on Selected BFT Protocols\nIn this section, we provide background on BFT protocols that\nare experimentally studied in Section 2.\nPBFT [18, 19]. PBFT (Figure 5) is a leader-based protocol\nthat operates in a succession of configurations called views\n[30,31]. Each view is coordinated by a stable leader (primary).\nPBFT consists of pre-prepare ,prepare , and commit phases.\nThe pre-prepare phase assigns an order to the request, the\nprepare phase guarantees the uniqueness of the assigned order,\nand the commit phase guarantees that the next leader after\nview-change can safely assign the order.\nDuring a normal case execution of PBFT, clients send their\nsigned request messages to the leader. In the pre-prepare\nphase, the leader assigns a sequence number to the request to\ndetermine the execution order of the request and multicasts a\npre-prepare message to all backups. Upon receiving a valid\npre-prepare message from the leader, each backup node mul-\nticasts a prepare message to all nodes and waits for prepare\nmessages from 2fdifferent nodes (including the node itself)\nthat match the pre-prepare message. The goal of the prepare\nphase is to guarantee safety within the view, i.e., 2fnodes\nreceived matching pre-prepare messages from the leader node\nand agree with the order of the request.\nEach node then multicasts a commit message to all nodes.\nOnce a node receives 2f+1valid commit messages from\ndifferent nodes, including itself, that match the pre-prepare\nmessage, it commits the request. The goal of the commit\nphase is to ensure safety across views, i.e., the request has\nbeen voted on a majority of non-faulty nodes and can be\nrecovered after (leader) failures. The second and third phases\nof PBFT follow the clique topology, i.e., have O(n2)message\nFigure 7: Zyzzyva protocol (fast path)\nFigure 8: Zyzzyva protocol (slow path)\ncomplexity. If the node has executed all requests with lower\nsequence numbers, it executes the request and sends a reply\nto the client. The client waits for f+1matching results from\ndifferent nodes.\nHotStuff-2 [52]. HotStuff-2 (Figure 6) HotStuff-2 is a leader-\nbased BFT protocol with two main properties. First, it pro-\nvides linear communication complexity (rather than quadratic\nas in PBFT). Specifically, each all-to-all communication phase\nof PBFT is replaced with two linear phases in HotStuff; one\nfrom the replicas to the leader and one from the leader to\nthe replicas. Second, HotStuff-2 uses the leader rotation tech-\nnique, where the leader is replaced after every single proposal\nin a predetermined manner (round-robin). This is in contrast\nto most existing protocols that rely on a stable leader, and\nthe leader is changed only when it is suspected to be faulty.\nCompared to the original HotStuff [64], HotStuff-2 reduces\none phase of communication, improving the overall perfor-\nmance of the protocol. Chaining (also proposed in [64]) is\nan optimization technique that is applicable to both HotStuff\nand HotStuff-2. The chaining optimization involves execut-\ning some phases which are deemed identical in a pipelined\nmanner in order to reduce the latency of request processing.\nZyzzyva [46]. Zyzzyva (Figure 7) optimistically assumes\nthat the leader and all backups are non-faulty. Hence, upon\nreceiving an order message from the primary node which\nincludes the request, nodes speculatively execute requests\nwithout running any agreement and send reply messages to\nthe client. The client waits for 3f+1matching replies to\naccept the results. If the client timer is expired and the client\nhas received matching replies from between 2f+1and3f\nnodes, as presented in Figure 8, two more linear rounds of\ncommunication are needed to ensure that at least 2f+1nodes\n16\n\nFigure 9: SBFT protocol (fast path)\nFigure 10: SBFT protocol (slow path)\nhave committed the request.\nSBFT [40]. SBFT4presents a linear optimistic fast path (Fig-\nure 9), assuming all nodes are non-faulty. In SBFT, upon\nreceiving a pre-prepare message from the primary node, all\nnodes send sign-share messages to the commit collector (i.e.,\nthe primary in our figure). If the commit collector is able to\ncollect 3f+1sign-share messages, it puts them together to\ngenerate a commit message and broadcasts it to the backups.\nOtherwise (the commit collector does not receive messages\nfrom allbackups in the sign-share phase and its timer is\nexpired), SBFT switches to its slow path (Figure 10) and re-\nquires two more linear rounds of communication ( prepare\nphase). The dual-path nature of SBFT requires nodes to sign\neach message with two schemes (i.e., 2f+1and3f+1). To\nsend replies to the client, a single (execution collector) node\nreceives replies from all nodes and sends a single (threshold)\nsigned reply message.\nCheapBFT [43]. CheapBFT (Figure 11) differs from PBFT\nin two major ways. First, it puts fnodes as passive nodes\nby optimistically assuming all nodes participating in the quo-\nrum (i.e., called active nodes) are honest. Second, it relies on\ntrusted hardware to prevent equivocation. CheapBFT reduces\nthe required quorum of active nodes to f+1(the total number\nof nodes becomes 2f+1) in its normal case execution, and\nreduces the number of phases from three to two as compared\nwith PBFT (i.e., no pre-prepare phase). If an active node\nbecomes faulty, it is replaced with a passive node.\nPrime [4]. Prime (Figure 12) is a robust protocol by incorpo-\nrating a pre-ordering stage. In the pre-ordering stage, nodes\nexchange the requests they receive from clients and period-\n4SBFT tolerates both crash and Byzantine failure ( n=3f+2c+1where c\nis the number of crashed nodes). Since the focus of this paper is on Byzantine\nfailures, we consider a variation of SBFT where c=0.\nFigure 11: CheapBFT protocol\nFigure 12: Prime protocol\nically share a vector of all received requests, expecting the\nleader to globally order requests following those vectors. In\nthis way, nodes can also monitor the leader to order requests\nin a fair manner. Prime also uses timers to periodically check\nperformance of the protocol and replace the primary node if\nit does not provide acceptable performance (e.g., under slow-\nness attack) corresponding to the current network condition.\nB Switching BFT Protocols\nIn this section, we describe how BFTBrain performs the actual\nswitching from BFT protocol ttot+1.\nSimilar to Abstract , BFTBrain operates in epochs. Each\nepoch in BFTBrain can be considered as a Backup instance\ninAbstract , which is marked by the completion of krequests,\nwhere kis a predefined constant hyper-parameter. For each\nepoch, an existing BFT protocol in our action space (i.e.,\nPBFT, Zyzzyva, CheapBFT, Prime, SBFT, and HotStuff-2)\nis selected by the learning agent and remains unchanged\nthroughout the epoch.\nTheBackup instance in Abstract is a thin wrapper that can\nbe put around an existing BFT protocol. Backup works as fol-\nlows: it is inactive until it receives a request containing a valid\ninit history , which is an unforgeable history generated by the\npreceding BFT instance. At this point, Backup sets its state by\nexecuting the requests in the init history it received. Then, it\nsimply executes the first krequests committed by the underly-\ning BFT protocol, aborts all subsequent requests, and returns\nthe signed sequence of executed requests as the init history\nfor the next BFT instance. A client can switch from a Backup\ninstance tto instance t+1as soon as it receives f+1signed\nmessages from different replicas, containing an identical init\nhistory . The client uses the init history to invoke instance t+1.\nOnce instance taborts some requests and switches to t+1, it\ncannot commit any subsequently invoked requests.\n17\n\nOptimizations of Abstract. Abstract also implements the\nfollowing optimization for the switching procedure above:\nalign switching from a Backup instance with a checkpoint in\norder to minimize the size of init history , which is transferred\nthrough clients. In Abstract , BFT instances tandt+1might\nbe run on two different clusters, and not every instance is a\nBackup instance whose progress condition is kcommitted\nrequests. For example, an instance could be Quorum whose\nprogress condition is 3f+1matching history, or Chain whose\nprogress condition is one correct reply, both of which require\nan honest client to validate the progress condition and ini-\ntiate the switching. On the contrary, in BFTBrain, all BFT\ninstances are run on the same cluster of machines, and every\nBFT instance is a Backup instance. Thus, the optimization\ncan be taken one step further inside BFTBrain. First, instead\nof relying on the client, each replica has enough information\nto decide whether to switch or not. Once executing krequests,\neach replica multicasts an init history (i.e., checkpoint) to all\nother replicas. Second, an honest replica does not need to be\nblocked and wait for f+1signed matching init history and\nexecute it before starting the new epoch, since the init history\nis already reflected in its local service state. Once krequests\nare committed in epoch tand the BFT protocol for t+1is\nderived by the learning agent, epoch t+1is invoked. In other\nwords, the switching can be performed asynchronously inside\nBFTBrain with low overhead.\nSpeculative Backup instances. Backup can be easily imple-\nmented over an existing BFT protocol, except for specula-\ntive protocols where clients are the commit collectors, e.g.,\nZyzzyva. This is because such protocols rely on clients to de-\ncide if a request has been committed, while the replicas might\nnot have enough information to tell. Specifically, in Zyzzyva,\nif a request commits in the slow path where the client only re-\nceives 2f+1replies with matching history (instead of 3f+1\nreplies in its fast path) and multicasts a commit certificate\nto all replicas, the replicas can deterministically commit the\nrequest as well. However, if a request commits in the fast path,\nthe client directly completes the request without notifying the\nreplicas. Thus, the replicas can not decide whether the current\nepoch is finished.\nTo address this issue, when running speculative protocols\nin epoch t, BFTBrain enforces the k-th request (i.e., the last\nrequest in t) to be a special NOOP request and to be committed\nin the slow path. On each replica, the view-change timer for\nthis request is only removed when it can be considered as\ncommitted. Specifically, for the k-th request, the leader acts\nas a dummy client and multicasts a commit certificate even\nif3f+1replies with matching history are received. Upon\nreceiving the commit certificate or f+1signed matching\ninit history for epoch t+1, replicas can safely consider the\nk-th request of epoch tas completed. Note that a malicious\ndummy client might refuse to multicast the commit certificate.\nIn this case, view-change is triggered and a new leader will be\nelected, which will act as a new dummy client for this request.Then, in the NEW-VIEW message, for this k-th request, the new\nleader always inserts a ORDER-REQ message where the original\nNOOP request is replaced by the NOOP request proposed by\nits own dummy client. For this special request, no safety\nissues exist since its content is not part of the service state.\nThe mechanisms above guarantee that each honest replica\nwill successfully commit this request (i.e., liveness), and thus\nconcluding the current epoch.\nCorrectness of switching. Below, we discuss the safety and\nliveness of switching between epochs.\nSafety. Abstract ’s idempotency theorem [8] specifies that if\nindividual BFT instances are correct, irrespectively of each\nother, then the system composed through switching is also\ncorrect. Since each BFT instance in BFTBrain is an existing\nprotocol whose safety has been previously proven (instead of\nour newly invented protocol), the composed system is safe.\nLiveness. Abstract guarantees liveness if a request is not\naborted by all instances, which can be made simple by reusing\nan existing BFT protocol as one of the instances. Apparently,\nBFTBrain satisfies this requirement too.\nMoreover, to ensure liveness, Abstract exponentially in-\ncreases the parameter kwith every new instance of Backup by\ndefault. This is to prevent a corner case with very slow clients:\nkrequests committed by a single Backup instance imight all\nbe invoked by the same, fast client, while a slow client can\nthen get its requests aborted by i. The same can happen with\na subsequent Backup instance, and so forth. By exponentially\nincreasing k, this liveness issue is resolved since no realis-\ntic load increases faster than exponentially. Alternatively, by\nhaving the replicas across different Backup instances share\na client input buffer, such an issue can also be prevented\nwithout exponentially increasing k. BFTBrain takes the latter\napproach, since all epochs run on the same cluster, so the\nclient input buffer is naturally shared across epochs.\nC Learning Coordination\nIn this section, we present BFTBrain’s learning coordination\nprotocol and discuss the correctness of BFTBrain.\nC.1 Detailed Description of The Protocol\nAlgorithm 1 presents the detailed learning coordination pro-\ntocol, where VBC (i.e., any “blackbox” validated Byzantine\nconsensus primitive) is implemented using PBFT. As shown\nin lines 1-7, after executing wrequests (a hyper-parameter)\nin epoch t, each node icollects local performance indica-\ntors pt−1\nimeasured during epoch t−1, featurizes the next\nstate ft+1\ni, and broadcasts both metrics inside a report mes-\nsage. Each agent icollects the received valid report messages\nwhere pt−1\njandft+1\njare non-null, into a local set reportQCt\ni.\nUpon collecting f+1report messages from different agents,\nthe agent triggers the coordination protocol for epoch tand\nstarts a view-change timer τc,1to track the progress (lines\n8-11).\nEach time an agent lbecomes the leader, as shown in lines\n12-15 (the view-change leader is omitted), it starts an addi-\n18\n\nTable 3: The throughput of each studied protocol under different conditions. Each row characterizes a different condition, where\nthe best throughput is highlighted in blue.\nCondition Parameters Throughput (tps)\nf # of clients # of absentees request size proposal slowness PBFT Zyzzyva CheapBFT Prime SBFT HotStuff-2\n1 50 0 4KB 0ms 9133 13664 11822 4601 11067 6882\n4 100 0 4KB 0ms 4316 10699 7966 4239 6414 7124\n4 100 0 100KB 0ms 4261 6513 7353 4177 6518 6779\n4 100 4 4KB 0ms 5386 1929 10011 4440 5347 8848\n4 100 0 0KB 20ms 2435 2424 2433 4265 2432 6201\n4 100 0 1KB 20ms 2435 2424 2432 4211 2433 6099\n4 100 0 0KB 100ms 497 498 497 4257 497 3641\n1 50 0 0KB 20ms 989 988 989 4527 989 2640\ntional timer τc,2for collecting 2f+1reports. Once the size\nofreportQCt\nlreaches 2f+1orτc,2expires, the leader mul-\nticasts ⟨C-PROPOSE ,vc,nc,t,d⟩σl,reportQCt\nl⟩message to all\nagents, where vcis the view in the coordination protocol, nc\nis the sequence number in the coordination protocol, tis the\nepoch id, and dis the digest of reportQCt\nl.\nOnce a coordinator agent ireceives a valid c-propose with\ncoordination sequence ncthat it has not voted for, it accepts\nthat proposal and multicasts a c-prepare message if: (1) the\nsize of corresponding reportQCt\nlis at least f+1, (2) tis not\ncommitted and (3) nc−1 is committed (lines 16-18).\nThen, similar to PBFT, after the c-prepare andc-commit\nphases, the predicate c-committed (vc,nc,t,reportQCt\nl)be-\ncomes true if 2f+1matching c-commit messages from dif-\nferent agents have been received. Once committed, agent\nichecks the size of reportQCt\nl. If smaller than 2f+1, the\nlearning algorithm (i.e., retraining and inference based on pre-\ndictive models) is not invoked, and the agent utilizes the same\nprotocol for epoch t+1as in the current epoch t. It also initi-\nates a view-change on the current BFT protocol used by its\nvalidator and multicasts a c-view-change message to all other\nagents. Here, scstands for the last stable checkpoint known\ntoiin the coordination protocol, Ccis a set of c-checkpoint\nmessages proving the correctness of sc, and Pcis a set contain-\ning a set PreportQC for each reportQC that prepared at iwith a\ncoordination sequence number higher than sc. Each PreportQC\ncontains the c-propose andc-prepare messages (lines 23-26).\nOtherwise, if the size is 2f+1, for reward and each state di-\nmension, the median value is taken as the global reward pt−1\nand state ft+1. The state-action-reward triplet for epoch t−1\nis then added to the experience buffer, the predictive mod-\nels are re-trained, and a promising BFT protocol is inferred\nfor epoch t+1based on state ft+1(lines 27-31). Finally, re-\ngardless of the size of reportQCt\nl, ac-checkpoint message is\nmulticast to all coordination agents.\nUpon timer τc,1expires, each coordination agent multicasts\nac-view-change message to all agents. Once receiving 2f+\n1c-view-change messages from different agents, the new\nleader l′begins the c-new-view phase similar to PBFT. At\nthe end of this phase, l′checks all PreportQC ofPccomponents\ncollected in the view-change quorum. If none of them includesareportQC for epoch t,l′will multicast a c-propose message\nto all agents which carries the reportQCt\nl′it has collected.\nWe argue that the leader agent could also deliberately delay\nc-propose messages. However, unlike the active BFT instance\nin each epoch that has tens of thousands of requests to com-\nmit, this coordination protocol runs only once every epoch.\nThus, the performance impact of such malicious behavior is\nnegligible.\nC.2 Proof Sketch\nBelow, we formalize the safety, liveness, and robustness guar-\nantees of BFTBrain, followed by the proof sketch.\nSafety. For each epoch t, each honest learning agent will\nagree on the same feature and the same reward if its learning\nalgorithm is invoked.\nProof: We prove by contradiction that only one reportQC\ncan be committed for the same epoch t. First, by reduction to\nPBFT, c-propose ,c-prepare ,c-commit phases guarantee that\nfor each coordination sequence nc, only one reportQC can\nbe committed. Then, assume two different reportQC for the\nsame epoch tare committed at different nc:reportQCt\njcom-\nmitted at nc,1, and reportQCt\nkatnc,2, where nc,1<nc,2and\nD(reportQCt\nj)̸=D(reportQCt\nk). At least one honest agent i\nneeds to accept the c-propose for both reportQC . Since the\nnetwork is asynchronous, we consider two cases. If nc,1is\ncommitted before nc,2oni,ineeds to accept c-propose with\nreportQCt\nkwhen tis already committed. Otherwise if nc,1\nis committed at the same time with or after nc,2,ineeds to\naccept reportQCt\nkwhose coordination sequence is nc,2, be-\nforenc,2−1is committed. Both cases contradict with line 17\nof Algorithm 1. Thus, only one reportQC can be committed\nfor the same epoch t. Finally, since an honest learning agent\ntakes the median value of the same committed reportQC , they\nagree on the same feature and reward if reportQC includes\n2f+1 reports.\nFollowing this safety property, through deterministic train-\ning (i.e., using the same random seed on each learning agent),\neach honest learning agent in BFTBrain derives the same\naction (i.e., BFT protocol) for the same epoch t.\nLiveness. BFTBrain guarantees that every honest agent even-\ntually invokes its learning algorithm in the same epoch.\nProof: If fewer than 2f+1reports are collected, the learning\n19\n\nAlgorithm 1 Learning coordination\n▷On each agent i\n1:Upon execution of wrequests in epoch t\n2: ifno state transfer happens during epoch t−1then\n3: Record performance pt−1\ni\n4: ifno state transfer happens during epoch tthen\n5: Extract features ft+1\nifrom executed requests in window w\n6: ifpt−1\ni̸=null∧ft+1\ni̸=null then\n7: Multicast ⟨REPORT ,t,i,pt−1\ni,ft+1\ni⟩σito all agents\n8:Upon receiving valid REPORT message m\n9: Add mtoreportQCt\ni\n10: ifreportQCt\ni.size =f+1then\n11: Start timer τc,1\n▷On the leader agent l\n12:Upon reportQCt\nl.sizereaching f+1\n13: Start timer τc,2 ▷τc,2<τc,1\n14:Upon timer τc,2timeouts ∨reportQCt\nl.size =2f+1\n15: Multicast ⟨C-PROPOSE ,vc,nc,t,d⟩σl,reportQCt\nl⟩to all agents\n▷On each agent i\n16:Upon receiving a valid C-PROPOSE from the leader\n17: ifreportQCt\nl.size≥f+1∧tis not committed ∧nc−1is committed\nthen\n18: Multicast ⟨C-PREPARE ,vc,nc,t,d,i⟩σito all agents\n19:Upon receiving valid matching C-PREPARE from 2f+1different\nagents\n20: Multicast ⟨C-COMMIT ,vc,nc,t,d,i⟩σito all agents\n21:Upon receiving valid matching C-COMMIT from 2f+1different agents\n22: Commit ( vc,nc,t,reportQCt\nl)\n23: ifreportQCt\nl.size<2f+1then\n24: protocolt+1←protocolt\n25: Initiate view change on validator iinprotocolt\n26: Multicast ⟨C-VIEW-CHANGE ,vc+1,sc,Cc,Pc,i⟩σito all agents\n27: else\n28: pt−1←median {m.pt−1\nj|m∈reportQCt\nl}\n29: ft+1←median {m.ft+1\nj|m∈reportQCt\nl}\n30: Add ( ft−1,protocolt−1,pt−1) to experience buffer\n31: protocolt+1←BESTPREDICTED PROTOCOL (ft+1)\n32: Multicast ⟨C-CHECKPOINT ,nc,t,i,reportQCn\nl⟩σito all agents\n33:Upon timer τc,1timeouts\n34: Multicast ⟨C-VIEW-CHANGE ,vc+1,sc,Cc,Pc,i⟩σito all agents\n▷On the leader agent l′of view vc+1\n35:ifno set in the Pccomponents has reportQCt\nlthen\n36: Multicast ⟨C-PROPOSE ,vc+1,nc,t,d⟩σl′,reportQCt\nl′⟩to all agents\n▷The remaing view change routine are omitted here\nalgorithm will be ineffective (i.e. not invoked) for one epoch,\nand the BFT protocol chosen for the next epoch will be the\nsame as the current one. We first show agents are able to com-\nmit a reportQC of2f+1reports within fconsecutive epochs\n(Part 1). We then show if such reportQC is committed for\nepoch t, every honest agent will invoke its learning algorithm\nin epoch t(Part 2).\nPart 1: In the active BFT protocol of any certain epoch, there\ncan be at most fhonest validators placed in-dark by the mali-\ncious leader, since otherwise, f+1validators will trigger a\nview-change to replace the leader in the epoch. The agents on\nthese in-dark validators will not send report messages accord-\ning to our protocol. In addition, at most fmalicious agents\ncan deliberately refuse to send report messages. Thus, each\nagent is guaranteed to receive at least f+1reports for epoch\nt, which starts a timer τc,2on leader agent lfor collecting\n2f+1reports in reportQCt\nland a timer τc,1on each agent for\ntracking the progress of coordination protocol. If reportQCt\nlis committed, a view-change in the active BFT protocol used\nby validators will be initiated if it contains less than 2f+1\nreports. Since such coordination is run once every epoch, an\nhonest leader validator will be found within at most fconsec-\nutive epochs. Otherwise, if reportQCt\nlis not committed, the\nleader agent will be replaced while the current epoch waits\nfor a report quorum to be committed.\nPart 2: If areportQC of size 2f+1is committed on an agent,\nit is committed on at least 2f+1agents, otherwise c-view-\nchange is triggered and it will be committed in view vc+1\nor above. Thus, at least f+1honest agents will multicast a\nc-checkpoint message containing the reportQC as the service\nstate of the coordination protocol. Every honest agent, even if\nit is placed in dark by the malicious leader agent, will receive\nthis stable checkpoint and thus invoke its learning algorithm.\nRobustness. If honest feature/reward values form a range\n[rl,rh], the global feature/reward taken by the learning agent\nalways falls into this range.\nProof: According to our protocol, honest nodes never report\ninvalid (e.g., zero or null) values to others, even when they\nare placed in-dark and recover their service state from others.\nThe learning agent only takes the median value of\nreportQC of size 2f+1, where at most fcan be arbitrary\nvalues reported by malicious replicas, and the remaining f+1\nis guaranteed to be honest. Now we prove by contradiction:\nw.l.o.g., assume the median value of reportQC isrm, where\nrm>rh. Since there are at least f+1honest values smaller\nthan rm, to make rmthe median, at least f+1dishonest values\nlarger than rmneed to be reported. This contradicts the fact\nthat, at most fcan be arbitrary values in reportQC .\nD Additional Experiment Results\nD.1 Comprehensive Performance Comparison\nTable 3 presents the comprehensive performance comparison\nresults, which were previously summarized by Table 1 in Sec-\ntion 2. Under each different condition (i.e., row), we list the\nthroughput of each protocol in terms of transactions per sec-\nond. For a fair comparison, the common internal parameters\nof all six protocols are configured with the same value: we set\nthe batch size to be 10and the view-change timer to be 100ms.\nThe protocol-specific internal parameters (e.g., leader rotation\ninterval of HotStuff-2, the aggregation delay for global order-\ning in Prime, the timer that distinguishes fast path vs. slow\npath in Zyzzyva) are configured with a reasonable value such\nthat the protocol has good performance on all conditions.\nD.2 Randomized Sampling\nCompared to the “cycle back conditions” experiment in Sec-\ntion 7.3, we created a benchmark that has more variations in\nthe state space and introduced the variations more frequently.\nSpecifically, each dimension in category State 1 and 2 (except\nF1) follows a certain normal distribution independently. We\nvary each dimension every 1s by randomly sampling from its\ndistribution, and shift the mean and variance of such distribu-\n20\n\nFigure 13: Adaptivity of BFTBrain compared to ADAPT under\nrandomly sampled conditions.\nFigure 14: Adaptivity of BFTBrain compared to ADAPT under\ndifferent hardware (WAN).\ntion every 20 minutes. During the first hour of the experiment,\nall validators ( n=13) are responsive, whereas during the\nsecond hour, fvalidators are non-responsive. The entire ex-\nperiment lasts 2 hours. Compared to other dimensions, we\nvaried F1at a lower frequency, since in real deployment sce-\nnarios, client workloads vary more frequently than faults in\nthe system. The exact distribution we used and their shifting\npattern can be found here5.\nWe compare BFTBrain with state-of-the-art learning based\napproach ADAPT , which is pre-trained with complete data that\nwe collected in this setup when running BFTBrain. Figure 13\nshows the number of committed requests with respect to time.\nDuring the first 40 minutes, ADAPT performs even slightly\nbetter than BFTBrain. This is because BFTBrain incurs a\nfew explorations (i.e., chooses sub-optimal protocols) when\nstarting the system from scratch and the experience buckets\nare all empty, while ADAPT exploits its prior knowledge and\nthus avoids all such explorations. However, starting from 40\n5https://github.com/JeffersonQin/BFTBrain/tree/master/\nexp/randomize\nZyzzyvaCheapBFT\nHotstuffPrimeFigure 15: Learning overhead of BFTBrain in each epoch.\nminutes, when the condition varies towards a more Byzan-\ntine setup (i.e., with persistent in-dark attacks and leaders\nthat appear randomly slow), BFTBrain gradually outperforms\nADAPT since the latter does not featurize faults in the system.\nThus, although pre-trained with complete data, ADAPT consis-\ntently picks sub-optimal protocols since its predictive model\ndoes not have enough information to tell how the condition\nchanged. As a result, during the entire 2-hour deployment,\nBFTBrain commits 44% more requests than A DAPT .\nCompared to the 14% improvement in the “cycle back” ex-\nperiment, BFTBrain improves ADAPT by a larger margin in\nthis experiment. The reason is that some input factors in the\ncycle back experiment are correlated, e.g., a request size near\nzero is correlated with high proposal slowness. Thus, although\nADAPT suffers from incomplete features, it indirectly learns\nthe optimal protocol under high proposal slowness using other\nfeatures, as shown in Figure 2 between 90-150 minutes. How-\never, the randomized sampling in this experiment breaks such\na correlation.\nD.3 Adaptivity under WAN\nFigure 14 plots BFTBrain and ADAPT ’s throughput with re-\nspect to time on the “Row 1 (WAN)” setup described in Sec-\ntion 7.4. Here, ADAPT is pre-trained with complete data we\ncollected on “Row 1 (LAN)”, while BFTBrain is started from\nscratch. BFTBrain converges to the optimal protocol Cheap-\nBFT after a few explorations. On the contrary, ADAPT does\nnot perform any explorations and performs relatively well\nfrom the very beginning, but is stuck at the sub-optimal deci-\nsion Zyzzyva. This is because the supervised model ADAPT\ntrained is dependent on the hardware. Therefore, ADAPT can-\nnot transfer what it learned on a LAN setup to a WAN setup,\nunless running a prolonged data re-collection process and\nre-training the supervised model before this new deployment.\nD.4 Overhead of BFTBrain\nFigure 15 plots BFTBrain’s training and inference overhead\nin each epoch. Labels indicate the dominant protocol that\nBFTBrain chooses in each segment of the figure.\n21",
  "textLength": 110974
}