{
  "paperId": "eb11ed9b8208d3f8fe6e5fc9e5ede4c4ec7ac2d4",
  "title": "Learning to Optimize LSM-trees: Towards A Reinforcement Learning based Key-Value Store for Dynamic Workloads",
  "pdfPath": "eb11ed9b8208d3f8fe6e5fc9e5ede4c4ec7ac2d4.pdf",
  "text": "213Learning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads\nDINGHENG MO, Nanyang Technological University, Singapore\nFANCHAO CHENâˆ—,Fudan University, China\nSIQIANG LUOâ€ ,Nanyang Technological University, Singapore\nCAIHUA SHAN, Microsoft Research Asia, China\nLSM-trees are widely adopted as the storage backends of key-value stores. However, optimizing the system\nperformance under dynamic workloads has not been sufficiently studied in previous work. To fill the gap, we\npresent RusKey , a key-value store with the following new features: (1) RusKey is a first attempt to design\nLSM-tree structures online to enable robust performance under the context of dynamic workloads; (2) RusKey\nis the first study to use Reinforcement Learning (RL) to guide LSM-tree transformations; (3) RusKey includes\na new LSM-tree design, named FLSM-tree , that facilitates efficient transitions between different compaction\npolicies, which addresses the key bottleneck for dynamic key-value stores. We justify the superiority of the new\ndesign with theoretical analysis; (4) RusKey requires no prior workload knowledge for system adjustment, in\ncontrast to state-of-the-art techniques. Experiments show that RusKey exhibits strong performance robustness\nacross diverse workloads, achieving up to 4x better end-to-end performance than the RocksDB system under\nvarious settings.\nCCS Concepts: â€¢Information systems â†’Data management systems ;â€¢Theory of computation â†’\nData structures design and analysis .\nAdditional Key Words and Phrases: LSM-tree, key-value stores, compaction policy, system design, reinforce-\nment learning\nACM Reference Format:\nDingheng Mo, Fanchao Chen, Siqiang Luo, and Caihua Shan. 2023. Learning to Optimize LSM-trees: Towards\nA Reinforcement Learning based Key-Value Store for Dynamic Workloads. Proc. ACM Manag. Data 1, 3\n(SIGMOD), Article 213 (September 2023), 25 pages. https://doi.org/10.1145/3617333\n1 INTRODUCTION\nLog-structured-merge-trees (LSM-trees) are widely adopted as the backbones of mainstream key-\nvalue stores, such as LevelDB [ 24] at Google, RocksDB [ 21] at Facebook, Cassandra [ 31] at Apache,\nVoldemort [ 35] at LinkedIn, and WiredTiger [ 13] at MongoDB. An LSM-tree stores data as key-value\nentries, offering efficient entry updates and key lookups. It organizes the data into multiple levels\nwith exponentially increasing capacities. The data in each level is organized into sorted runs. An\nLSM-tree appends the new key-value entry into the main memory buffer, whose filled-up will\nâˆ—Work done when the author was working as a research assistant under the supervision of Siqiang Luo.\nâ€ Siqiang Luo is the corresponding author.\nAuthorsâ€™ addresses: Dingheng Mo, Nanyang Technological University, , Singapore, ; Fanchao Chen, Fudan University,\nShanghai, China, ; Siqiang Luo, Nanyang Technological University, , Singapore, ; Caihua Shan, Microsoft Research Asia,\nBeijing, China, .\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the\nfull citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\nÂ©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\n2836-6573/2023/9-ART213\nhttps://doi.org/10.1145/3617333\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:2 Dingheng Mo et al.\nsort the buffered entries and compact them as a larger sorted run merged into the next level. The\nprocess can cascade down whenever the affected level reaches its capacity. The compaction policy\nin a level determines how frequently the level compacts its data.\nIn LSM-tree based key-value stores, one important topic is to handle dynamically changing\nworkloads. As demonstrated by prior studies (e.g., [ 6,14,22,40]), workloads for real-world applica-\ntions are dynamically changing with daily patterns and shifts, which underscores the necessity\nof processing various portions of key lookups and entry updates. For example, Cao et al. [10]\ncollected a trace of 14-day operations processed by UDB [ 5], which is a database storing Facebookâ€™s\nsocial graph data. They concluded that the numbers and portions of queries and updates vary\nsignificantly over time. This is not surprising as modern databases have billions of users who are\nactively accessing or updating database applications in different time spans. Therefore, in this paper\nwe focus on designing an LSM-tree key-value store that can process dynamic workloads with high\nperformance.\n1.1 Prior Work\nThere has been fast development on LSM-tree optimizations. Behind the ingenuity of an optimized\nLSM-tree often we see an elaborate design of its key components. Examples include optimizing\ncompaction policies [ 12,17,18,26,27,48], developing update-friendly compaction schemes [ 3,20,\n47,49,59,61,62], enhancing Bloom filters [ 16,19,33,44,67,68], enhancing range filters [ 29,39,63],\nadopting unconventional hardwares [ 2,25,54,57,58,66], narrowing the gap between LSM-trees and\nupdate-in-place designs [ 53], separating keys and values [ 11,36], keeping hot entries in the buffer\nand selective flushing [ 7], improving concurrency [ 23,50], reducing tail latency [ 8,37,49], improving\nmemory management mechanisms [ 9,28,38], and exploiting data characteristics [ 1,46,60]. These\nworks offer promising improvement in various aspects.\nMost of the works [ 1â€“4,7â€“9,11,16,19,20,23,25,28,29,36â€“39,46,47,49,50,54,57â€“60,63,66â€“68],\nunfortunately, are not from the angle of optimizations under dynamic workloads, because their\ndesigns are not workload-aware. Recent studies working towards workload-aware LSM-trees lie in\ntuning the compaction policy [12,17,18,26,27]. Compaction improves the read efficiency in an\nLSM-tree because it reduces the sorted runs to be probed in each query and cuts down space by\neliminating redundant entries. However, compaction itself is a costly process that affects write\nefficiency. The more aggressive in compaction, the lower read amplification and the higher write\namplification. Based on these observations, Dayan and Idreos [ 17] further point out that a more\nfrequent compaction optimizes the lookup cost but increases the update cost, and hence, various\ncustomized compaction policies based on workload characteristics are proposed to improve the\noverall performance of the LSM-tree.\nThere are still several deficiencies in these closest works when applied to dynamic workloads.\nMost of them [ 12,17,27] compute an optimized system setting when given a specific application\nworkload. For example, Cosine [ 12] and Dostoevisky [ 17] require users to input a workload with a\nspecific ratio between lookups and updates, so that they can model the expected performance of\nvarious possible compaction policies, and choose the best one. While these models are very promis-\ning in analyzing a workload-aware system, it remains open regarding how to design reasonable\nkey-value stores when the workload is not known a priori. One possibility is to combine them with\nworkload forecasters such as those designed by Ma et al. [40], but this incurs an additional forecaster\ntraining cost. More importantly, even though the additional workload forecaster may be integrated,\nthe obstacle is in efficient adaptation of the underlying LSM-tree from one state to another in\nresponse to workload changes â€“ the main bottleneck of designing dynamic LSM-trees. For example,\nchanging a compaction policy at a level usually requires resizing the runs and remapping each\ndata block to the runs, which incurs a high cost. This issue has been largely overlooked in the\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:3\nliterature and the only known strategy is a greedy transition mentioned by Dayan and Idreos [ 17]\nas an extended discussion. Nonetheless, this strategy is sub-optimal as we discuss in Section 4.3.\n1.2 The Problem and Our Solution\nWe aim to design an LSM-tree based key-value store that can automatically adapt itself in an online\nmanner to continuously changing workloads while keeping a robust end-to-end performance\n(i.e., close to the performance of the optimal setting in the hindsight). In contrast to prior works\non autonomous DBMS, our focus on NoSQL key-value stores (particularly, LSM-trees) brings in\ndrastically different technical challenges. We thus explore new ways of modeling key-value stores\nso as to achieve our goal. Below we give a preview of our new ideas.\nModeling Key-Value Stores Using Reinforcement Learning. We model (See Section 3 and\nSection 5) the LSM-tree based key-value store as a reinforcement learning process [ 51,52], which\nis a machine learning approach that trains a model with an action-reward series in an online\nmanner. We remark that most existing methods for tuning compaction policy [ 12,17,18,26,27]\nuse a different way in modeling, which captures the relationship between compaction policy and\nLSM-tree performance via a sophisticated formula, referred to as a white-box cost model. While\nthese models show promising results in many aspects, there are limitations in modeling the end-\nto-end system performance. First, white-box models often focus on I/O complexity analysis to\npredict the I/Os incurred by each lookup or update, neglecting the CPU overheads that can be\nsignificant. For example, Zhu et al. [68] reported that the hashing of Bloom filters in LSM-trees\nmay incur high CPU overhead that even exceeds I/O overhead with modern storage hardware.\nNeglecting the CPU overhead is therefore a source of inaccuracy. Second, modern systems are\nextremely sophisticated in design, and are often cumbersome, if not unpromising, to be unfolded for\ndetailed complexity analysis of internal components. For example, memory cache can significantly\naffect the performance, but white-box formulas are often unable to model such bottom-level details.\nIn contrast to white-box formula based models, models based on RL for tuning treat the system\nas a black-box, where action modifies the LSM-tree compaction policies and reward traces system\nperformance. The tuning is automatic in a machine-learning style. Modeling the process with RL is\nnot trivial, as discussed in Section 5.\nIt is also important to note that we do not aim to completely replace classic white-box models\nwhich are still helpful in many aspects. Instead, our main purpose is to explore the potential of\napplying RL in tuning LSM-tree based systems, which complements the existing classic methods\nand, possibly, opens the new research direction for machine-learning-based LSM-tree tuning.\nDesigning Transition-Friendly LSM-trees for Reinforcement Learning. When dynamically\ntuning LSM-trees, one critical issue is maintaining an efficient transformation of LSM-trees, as\na slow transformation may outweigh the benefit of a compaction policy adjustment. This issue\nmotivates us to design FLSM-tree (See Section 4), a flexible LSM-tree that allows various-sized\nruns in a level. When the compaction policy changes, FLSM-tree avoids the modification of most\nof the data in the affected level. We also provide a theoretical analysis showing that FLSM-tree\npromises zero delay, free immediate transition costs, as well as less implicit additional costs.\nIntegrating White-box Models in Reinforcement Learning. Unlike RL in other typical machine\nlearning scenarios, it is unpromising to gather a large amount of training samples in a key-value store\nbecause the samples are obtained by running costly lookup and update operations. To circumvent\nthe problem, we propose a new level-based training strategy, where the compaction policies of\nsmaller levels are learned by RL while those of large levels are extended by the lower-level policies\nthrough a careful complexity analysis (i.e., a white-box model). This technique largely reduces the\nnumber of samples needed to train the model, empowering the tuning ability of RL.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:4 Dingheng Mo et al.\nPutting together, we develop the RusKey system, a flexible LSM-tree-based key-value storage\nsystem that is self-adaptive to dynamic workloads. We summarize our contributions as follows.\nâ€¢We make the first attempt at designing RL models to optimize the performance of LSM-tree\nbased key-value systems. We design and implement RusKey which is a key-value system that\ndemonstrates strong robustness in end-to-end performance via an RL-based tuning model. RusKey\ncan efficiently adapt itself to various workloads, based on the instructions of the learning model.\nâ€¢We address an open problem in dynamic key-value systems â€“ the efficient and transient policy\ntransformation in LSM-tree under dynamic workloads. We present FLSM-tree , a novel LSM-\ntree structure that incorporates a flexible compaction policy transition scheme, which swiftly\ntransforms the compaction policy of an LSM-tree with minor additional overhead.\nâ€¢We present a new level-based RL model which is embedded with a policy propagation formula to\nreduce the number of samples required, shrink the action space and improve the convergence\nspeed in our RusKey system.\nâ€¢We conduct extensive experimental evaluations of RusKey in real system environments. We\ndemonstrate that RusKey achieves high performance in all the tested workloads. RusKey achieves\nup to 4x throughput compared with the baselines.\n2 BACKGROUND\nLSM-tree. The log-structured merge tree (LSM-tree) [ 42] is a persistent multi-level index structure\nthat stores key-value entries. When a key-value entry is inserted, an LSM-tree buffers it in the\nmain memory. Once the buffer is filled up, it sorts the entries by keys and flushes them into a\ndisk-resident sorted run in Level 1. When the size of the disk runs in a level exceeds a certain\nthreshold, the LSM-tree sort-merges them into a larger run and puts it into the next level. This\nprocess of sort-merging multiple smaller sorted runs in Level ğ‘–to a larger sorted run in Level ğ‘–+1\nis called compaction . As such, the capacity of Level ğ‘–+1isğ‘‡times larger than that of Level ğ‘–, where\nğ‘‡is the capacity ratio.\nLookup (Query) in LSM-tree. In modern key-value systems, LSM-tree is coupled with Bloom\nfilters and fence pointers to improve the key lookup performance. The Bloom filter and fence\npointer are built for each sorted run and will be loaded into the main memory when the system\nstarts. To check whether a key exists in a run, the Bloom filter associated with the run is first\nprobed. If it returns false, then the run does not contain the key and no I/O cost will be incurred.\nOtherwise, accessing the run in the disk is necessary, which incurs ğ‘‚(1)I/Os guaranteed by fence\npointers. In general, the Bloom filter largely prevents unnecessary disk reads. The I/O-cost reduced\nNotation Description\nğ‘‡ Capacity ratio between adjacent levels\nğ¾ğ‘– Compaction policy of the ğ‘–-th level\nğ¸ Size of a key-value entry (in bytes)\nğµ Size of a disk page (in bytes)\nğ¶ğ‘– Capacity of the ğ‘–-th level (in bytes)\nğ‘“ğ‘– False positive rate of Bloom filters at the ğ‘–-th level\nğ·ğ‘– Total data size in the ğ‘–-th level (in bytes)\nTable 1. Frequently used notations.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:5\nby the Bloom filter depends on its FPR (False-Positive Rate). In particular, if the run does not\ncontain the queried key, its Bloom filter may still mistakenly return true for the key, incurring a\nfalse positive. While mainstream designs uniformly set the FPRs for Bloom filters at all LSM-tree\nlevels, state-of-the-art techniques [ 12,16â€“18,26] employ the Monkey allocation scheme [ 16], which\narranges exponentially higher FPRs to Bloom filters in larger levels.\nCompaction Policy. The compaction policy ğ¾ğ‘–at each Level ğ‘–can be independent, as presented\nin Dostoevsky [ 17]. The policy ğ¾ğ‘–means that there are at most ğ¾ğ‘–sorted runs in the level. Level ğ‘–\nhas an active run that admits the merged run from Level ğ‘–âˆ’1. The capacity for each active run is\n1/ğ¾ğ‘–of the level capacity. All entries in a level are eventually merged and flushed down to the next\nlevel when the level reaches its capacity. Dostoevsky proposes Lazy-Leveling which applies an\naggressive compaction policy of at most 1 sorted run in the largest level while all other levels use a\nlazy compaction policy in common. They give a way of applying different compaction policies at\ndifferent levels, but within the same level the compaction policy is always the same. Our framework\ngive a significant extension by allowing various run sizes in a level.\nAmplification. Read amplification and write amplification are commonly used to measure the\nperformance of an LSM-tree. Read amplification refers to the average number of disk pages read\nduring a lookup, since a query may probe multiple sorted runs in an LSM-tree to search for the\nqueried key. Write amplification refers to the average number of physical rewrites that an entry\nincurs, because each data entry is constantly rewritten to storage as a result of the LSM-treeâ€™s\ncompaction.\n3RUSKEY OVERVIEW\nThis section presents RusKey , a key-value system empowered with deep reinforcement learning.\nThe purpose of RusKey is to tune the compaction policy in each LSM-tree level to best process\nthe workload. There is no doubt that a fixed policy is still possible to be applied under dynamic\nworkloads, but as we have mentioned, changing policies can bring in benefits as long as the LSM-\ntree structure transformation cost is small. RusKey includes two major designs: (1) A level-based\ndeep reinforcement learning tuning model, named Lerp and (2) A new flexible LSM-tree with new\ncompaction transition method, named FLSM-tree . As we will explain shortly, Lerp incorporates\nthe cost analysis across levels for fast convergence and less sample-demanding training. FLSM-\ntree embeds flexible transition to avoid high transition cost, hence being more cost-friendly to\na compaction policy tuner like Lerp . We will first describe the general workload of RusKey in\nthis section, and then discuss the detailed mechanism of FLSM-tree andLerp in Section 4 and\nSection 5. Table 1 lists the frequently used notations.\n3.1 System Workflow\nInRusKey , the application workload is a series of lookups orentry updates operations input to the\ndatabase. A lookup finds the corresponding value for a given key, and an update inserts or deletes a\nkey-value entry. RusKey allows for arbitrary arrivals of operations, which means that knowledge of\nthe query/update ratio is not known in advance. A mission inRusKey is a collection of operations\n(e.g., lookups or updates) in the workload. Conceptually, the workload is divided into missions.\nAfter processing each mission, RusKey may adjust its internal LSM-tree structure for the coming\nmissions. RusKey also maintains a statistics collector that keeps track of necessary statistics of\nRusKey and application workload over time. Besides overall statistics of the FLSM-tree , it tracks\nstatistics separately for each FLSM-tree level to support the level-based training scheme in Lerp .\nIt also collects the operation composition in each mission for detecting changes in the application\nworkload.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:6 Dingheng Mo et al.\nGet State & RewardStore\nApplication Workload\nMissions\nMissions\nMissionsMissionFLSM-tree Based Database LERP Model \nProcess\nâ€¦ Level213LFLSM-TreeStats CollectorComposition\nLevel stats\nCriticActorEnd-to-end statsCurrent state\nTuning strategyReplayBuffer\nFlexibleTransitionKKKâ€™KKK\nCurrent stateTuning strategyNext StateRewardEnd-to-end latencyLevel latency\nSample &Update\nUpdateLookupsUpdates\nFig. 1. The components and workflow of RusKey .\nFLSM-tree Write-heavy Workload \n90% updates, 10% lookups \nBy default \nK = 1, T = 10 FLSM-tree Write-heavy Workload \n90% updates, 10% lookups \nSelf-tuned to K = 10, \nwhich is write-optimized RusKey RusKey \nFLSM-tree Balanced Workload \n50% updates, 50% lookups \nSelf-tuned to K = 3, \ngood on both read&write RusKey \nFLSM-tree Read-heavy Workload \n10% updates, 90% lookups \nSelf-tuned to K = 1, \nwhich is read-optimized RusKey Workload shift Workload shift Initial State \nK = 1 K = 10 K = 3 K = 1 \nFig. 2. Running example of RusKey . This is a simplified example where we assume that each level has the\nsame compaction policy. In fact, RusKey allows the FLSM-tree to set various compaction policies across\ndifferent levels.\nFigure 1 illustrates the workflow of RusKey . Suppose a real-world application employs RusKey\nas its data storage backend. RusKey processes operations from the application workload with the\nFLSM-tree and uses the tuning model Lerp to adjust the compaction policy. Lerp andFLSM-tree\ninteract after each mission. At the end of a mission, Lerp gives tuning suggestions to the FLSM-tree\nand updates the actor-critic network. Meanwhile, the statistics collector sends statistics of FLSM-\ntree in this mission to Lerp , which extracts experience samples from the statistics and stores them\nin the replay buffer. The replay buffer stores some quadruples (called experience samples), each\nof which contains the essential information for reinforcement training. The information includes\nthe action of policy change, the FLSM-tree state before the action, the FLSM-tree state after the\naction, and the subsequent mission, as well as the reward of the action. Through learning from\nthese samples, Lerp effectively updates its internal actor-critic network [ 34]. Then Lerp selects a\nsuitable tuning strategy for the compaction policy of the FLSM-tree in the next mission according\nto the current state of the FLSM-tree .RusKey then updates the FLSM-tree based on the suggested\ncompaction policy with the flexible transition. Under a stable application workload, the actor-critic\nnetwork converges in a number of missions, shifting FLSM-tree towards the optimal compaction\npolicy. Once the application workload changes, the actor-critic network is no longer in convergence,\nandLerp will restart to exploit compaction policies under the new workload.\nRunning Example. Figure 2 shows a running example of RusKey , which is simplified by assuming\neach level has the same compaction policy. Initially, the compaction policy is set as 1, and the\ncapacity ratio is 10. The dynamic workload is write-heavy at first with 90% of updates and 10% of\nlookups. It then shifts into a read-write-balanced workload (50% of updates and 50% of lookups),\nfollowed by a read-heavy workload (10% of updates and 90% of lookups). At the beginning, RusKey\ntunes the compaction policy of the FLSM-tree fromğ¾=1toğ¾=10to achieve the best write\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:7\nperformance under write-heavy workloads, and we note that during the tuning the system is\nnot fed with the workload statistics. With the benefit of flexible transition, the FLSM-tree could\ntransform its policy ğ¾=1toğ¾=10without a transition cost and delay. Once the workload shifts\nto the balanced one, RusKey will re-tune the compaction policy of the FLSM-tree fromğ¾=10\ntoğ¾=3, which is more effective in a balanced workload. Similarly, when the workload shifts to\nread-heavy, RusKey will adjust its compaction policy from ğ¾=3toğ¾=1to achieve an optimized\nread efficiency.\n4FLSM-TREE INRUSKEY\nThis section discusses two baseline transition methods (Section 4.1), followed by presenting our\ndesign of FLSM-tree (Section 4.2) and its desired properties (Section 4.3).\n4.1 Greedy and Lazy Transitions\nRusKey changes the underlying LSM-tree based on the suggested compaction policy by the tuning\nmodel. However, in the classic LSM-tree, continuously changing the compaction policy demands\nthe reallocation of memory and potentially reorganizes the data in the LSM-tree. Enforcing a change\nof compaction policy at a level can have two straightforward solutions, namely, greedy transition\nandlazy transition . However, these solutions are not ideal.\nGreedy Transition [ 17].Once a level receives a tuning strategy, it merges and flushes all its\ndata into its next level. The current level then needs to be rebuilt based on the new compaction\npolicy, as shown in Figure 3 (top). We note that such a greedy transition is not effective due to its\ndreadful cost and the write stall incurred during data flush, and hence significantly degrades the\nperformance. Moreover, if an unfilled level is merged with the next level, it incurs a larger write\namplification than an LSM-tree without transitions.\nLazy Transition. The other extreme is the lazy transition that an LSM-tree level changes its\ncompaction policy only after it is merged to the next level, as shown in Figure 3 (bottom). Although\nsuch a lazy transition will not bring an immediate compaction cost, it affects the timeliness of the\ninformation fed into the RL model. To explain, a given (policy change) action may have no effect\non the LSM-tree level until the level eventually becomes full and gets merged, and the delay can be\nlong at a large level, ultimately reducing the effectiveness of the model.\n4.2 Main Design of FLSM-tree\nWe design a Flexible LSM -tree, abbreviated as FLSM-tree , to accommodate a flexible transition\nbetween compaction policies. A novel design in FLSM-tree is that it allows different-sized runs\nto exist at the same level. This extends the classic LSM-tree structure, allowing more room for an\nLSM-tree to morph the structure gradually. At each level, there is an active run that can admit\nFig. 3. Greedy and lazy transitions of compaction policy.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:8 Dingheng Mo et al.\n(A) Original LSM-tree \n1 Level \n2\n36000  Policy: 2 Runs  \nPolicy: 1 Run  \nPolicy: 6 Runs  â€¦ â€¦ (B) Transform Policy at Level 3 to 10 \n6000  Policy: 2 Runs  \nPolicy: 1 Run  \nNew Policy: 10 Runs  â€¦ â€¦ (C) Transform Policy at Level 3 to 3 \n6000  Policy: 2 Runs  \nPolicy: 1 Run  \nNew Policy: 3 Runs  â€¦ â€¦ 1000 1000 1000 600 2000 2000 \nFig. 4. Flexible compaction policy transition in a FLSM-tree.\nTransition Alg. Greedy Lazy FLSM-tree (ours)\nTransition Costğ¶\n2ğµ0 0\nDelay (secs) 0ğ¶\n2ğ‘ğ‘¢ğ¸0\nAdditional\nCostğ¾<ğ¾â€²ğ‘‡ğ¶(1âˆ’ğ‘¥)\n2ğµğ¾ğ‘‡ğ¶(1âˆ’ğ‘¥)(ğ¾â€²âˆ’ğ¾)\n2ğµğ¾ğ¾â€² 0\nğ¾>ğ¾â€²ğ‘‡ğ¶(1âˆ’ğ‘¥)\n2ğµğ¾ğ‘“ğ¶(1âˆ’ğ‘¥2)(ğ¾âˆ’ğ¾â€²)ğ›¾\n2ğ¸(1âˆ’ğ›¾)ğ‘“ğ¶(ğ‘¥âˆ’ğ‘¥2)(ğ¾âˆ’ğ¾â€²)ğ›¾\nğ¸(1âˆ’ğ›¾)\nCase Study 125I/Os 3.75I/Os 2.5I/Os\nTable 2. Transition costs and delays.\nLevel read amplification \nD / C 1K\nxSlope = fÂ·KLazy transition \nFlexible transition Transform \nfrom K to Kâ€™ \nSlope = fÂ·Kâ€™\nBefore transition After transition Area 2 Area 1 Fig. 5. Flexible transition incurs an additional cost =\nArea 2; lazy transition incurs an additional cost = Area\n1 + Area 2.\nmore key-value entries. When the active run in the level reaches its capacity, it is sealed, and a new\nactive run is created. When a new policy is applied on a level, it never affects the runs that have\nbeen sealed, and only changes the capacity of the active run and the runs to be formed later. In this\nway, the change of the policy is immediate and the Lerp model gets the correct reward by applying\nthe policy changes without incurring any immediate transition costs.\nLet the capacity of Level ğ‘–beğ¶ğ‘–, the new compaction policy be ğ¾â€²\nğ‘–, and the original compaction\npolicy of Level ğ‘–isğ¾ğ‘–. The discussion is divided into two cases.\nIfğ‘²â€²\nğ’Š<ğ‘²ğ’Š,FLSM-tree will increase the capacity of the active run, keeping the other runs intact.\nIfğ‘²â€²\nğ’Š>ğ‘²ğ’Š,FLSM-tree will decrease the capacity of the active run. One may have a concern\nthat when the new policy is known, the active run size can already be larger than the expected\nsizeğ¶ğ‘–/ğ¾â€²\nğ‘–. In this case, we immediately seal the active run and create a new active run. The runs,\nwhen sealed, remain untouched until the level holding them reaches its capacity and triggers a\ncompaction during which all runs will be merged to the next level.\nExample. Figure 4 presents examples of transforming compaction policy in FLSM-tree . A grey\nsquare represents a sorted run filled with data, and the dashed line denotes logical capacity of a\nlevel or an incoming run. In Figure 4 (A), the compaction policy of Level 1 is 2. Level 1 includes\ntwo runs, each having a size that is half of the level capacity. The compaction policy of Level 2 is 1,\nrendering a single run in the level. For Level 3, initially the compaction policy is 6 and the level\ncapacity is 6000, giving an expected run size 6000/6=1000. If we transform the policy of Level 3 to\n10, it will turn to the state of Figure 4 (B), such that the expected run size under the new compaction\npolicy would not affect existing sealed runs, but the expected size of an incoming run decreases to\n600 (=6000/10). If we transform the policy to 3, it will turn to the state of Figure 4 (C). The expected\nsize of an incoming run becomes 6000/3=2000, and the current active run size also increases to\n2000.\n4.3 Desired Properties of FLSM-tree\nTo check the advantages of our FLSM-tree design, we focus on the following measures: (1) Transition\nCost, which is the immediate compaction cost incurred by a transition. We aim at small immediate\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:9\ntransition cost to avoid serious performance glitches; (2) Delay , which is the time span between the\nnew policyâ€™s arriving at the system and the time at which the transition actually takes effect on\nthe LSM-tree; (3) Additional Cost , which is the total additional I/O cost incurred by a transition, as\ncompared to an ideal LSM-tree born with the new compaction policy.\nWe illustrate the concept of additional cost incurred by transition using Figure 4 (C) as an\nexample. After transforming the policy in Level 3 from 6 to 3, the incoming runs will follow the\nnew compaction policy 3, while the existing sealed runs stay with the previous compaction policy\n6. In this instance, there will be at most 4 runs in Level 3 after the flexible transition, whereas the\nnew compaction policy indicates 3 runs in the level, such that accessing the level would incur more\nI/Os than expected. Here we only discuss the additional cost, and hence the cost is lower bounded\nby0. We note that sometimes additional benefits may be involved, for which we will have a further\ndiscussion in the overall comparison paragraph at the end of this section.\nNotations. To facilitate our discussion, we first introduce the necessary notations for the analysis\nin this sub-section. We fix an LSM-tree level whose capacity (in bytes) is ğ¶. Letğ·be the total data\namount (in bytes) of key-value entries currently stored in the level. Let ğµbe the size (in bytes) of a\ndisk page. Let ğ¸be the size (in bytes) of a key-value entry. Let ğ‘ğ‘¢be the number of updates arriving\nper second. Let ğ‘¥be the percentage of the stored data in the current level when a compaction policy\ntransition is applied. Let ğ‘“be the FPR of the Bloom filter in the level. Let ğ›¾denote the percentage\nof lookups in the workload.\nFLSM-tree incurs zero transition cost and delay. OurFLSM-tree has the minimum transition\ncost and delay cost. The greedy transition merges all data in that level to the next level. This process\nincursğ·\nğµI/Os. When a transition occurs, ğ·may be any random value between 0andğ¶, leading to\nan amortized I/O costğ¶\n2ğµfor a greedy transition. In contrast, the transition cost of a lazy transition\nis always zero. As for the delay, in the lazy transition, the new compaction policy takes effect only\nafter the level is full and a whole-level compaction is triggered. The delay can be estimated by\nğ¶âˆ’ğ·\nğ‘ğ‘¢ğ¸seconds. The amortized delay of the lazy transition isğ¶\n2ğ‘ğ‘¢ğ¸considering ğ·ranges from 0toğ¶.\nRegarding the transition mechanism in a FLSM-tree , the transition cost is always zero, since it only\nchanges the metadata of the active run and does not incur any disk reads. Meanwhile, the flexible\ntransition in a FLSM-tree comes into effect immediately with zero delay1. Table 2 summarizes the\ntransition cost and delay of the three transition methods.\nFLSM-tree incurs less additional cost. FLSM-tree also incurs the minimum additional costs\ncompared with baselines. We first examine the additional cost of each transition method.\nAdditional cost of the greedy transition. A greedy transition compacts the level right after the pol-\nicy transition, giving zero additional read cost. However, this compaction suffers a larger write\namplification because it merges fewer data into the next level than a normal full-level compaction.\nWe now analyze the additional write amplification incurred by a greedy transition. Let us first\nconsider a normal compaction without policy changes. Without loss of generality, we assume that\nthe subsequent levelâ€™s compaction policy is ğ¾. In expectation, the size of the active run in the\nsubsequent level isğ‘‡ğ¶\n2ğ¾. A compaction reads expectedğ‘‡ğ¶\n2ğ¾bytes of data and rewrites them into the\ndisk in order to merge ğ¶bytes of data (i.e., the full current level) into the subsequent level. Hence,\nthe active run sizeğ‘‡ğ¶\n2ğ¾divided byğ¶, which isğ‘‡\n2ğ¾, is the write amplification of the current level. The\nadditional cost caused by the greedy transition isğ‘‡\n2ğ¾Â·ğ‘¥because it only merges data that is ğ‘¥times\nthe level capacity, which leads toğ‘‡\n2ğ¾Â·ğ‘¥âˆ’ğ‘‡\n2ğ¾additional write amplifications.\n1Zero-delay means the LSM-tree immediately reacts when policy changes, marking that upcoming updates will follow the\nnew policy. We note that the policy changes will not have any effect for the extreme case where the workload only contains\nreads. In this case, flexible transition simply degenerates into lazy transition and will not bring additional negative impact.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:10 Dingheng Mo et al.\nThe expected additional I/O cost is computed by multiplying the additional write amplification\nwith the number of pages merged by the greedy transition into the subsequent level:\nğ¶ğ‘œğ‘ ğ‘¡ğ‘”ğ‘Ÿğ‘’ğ‘’ğ‘‘ğ‘¦ =\u0012ğ‘‡\n2ğ¾Â·ğ‘¥âˆ’ğ‘‡\n2ğ¾\u0013\nÂ·ğ¶Â·ğ‘¥\nğµ=ğ‘‡ğ¶(1âˆ’ğ‘¥)\n2ğµğ¾(1)\nAdditional cost of lazy transition. Ifğ¾>ğ¾â€², lazy transition avoids the immediate transition cost\nand the additional cost from write amplification, at the expense of incurring additional read cost.\nWe illustrate this expense in Figure 5, where the horizontal-axis refers to the levelâ€™s filling ratio,\nwhich is the percentage of data stored at the level among the capacity of the level, i.e., ğ·/ğ¶. The\nvertical-axis refers to the read amplification of the level, which is the expected number of disk\npages a lookup needs to probe in the level. In a process of inserting data from an empty level to a\nfull level, the filling ratio increases from 0to1. In expectation, the read amplification of a level is\nthe product of three values â€“ its false positive rate ğ‘“, its compaction policy ğ¾, and its filling ratio.\nTo explain, when the level is full, there are ğ¾runs in the level to be probed during each query and\neach run probe requires a disk I/O only when its Bloom filter returns positive. Therefore, the read\namplification can be expressed by ğ‘“Â·ğ¾Â·ğ·\nğ¶.\nAs shown in Figure 5, after the transition, the read amplification of the level is higher than it\nshould be under the more aggressive compaction policy ğ¾â€²(which is represented by the dotted line).\nThis is because the level still adheres to the foregoing ğ¾compaction policy with lazy transition. This\nlasts until the level is full, at which point all data is merged into the following level via compaction.\nTherefore, the sum of Area 1 and Area 2 in Figure 5 represents the overall additional read cost of a\nlazy transition. A lazy transitionâ€™s additional cost in I/Os can be expressed by Equation 2.\nğ¶ğ‘œğ‘ ğ‘¡ğ‘™ğ‘ğ‘§ğ‘¦=ğ‘“ğ¶(1âˆ’ğ‘¥2)(ğ¾âˆ’ğ¾â€²)ğ›¾\n2ğ¸(1âˆ’ğ›¾)(2)\nIfğ¾<ğ¾â€², a lazy transition incurs an additional write cost. Upon changing the policy, the expected\nwrite amplification for this level becomesğ‘‡\n2ğ¾â€². However, until the level becomes full and triggers\ncompaction, the actual write amplification of the lazy transition remainsğ‘‡\n2ğ¾. Throughout this\nperiod, this level will merge a total of(1âˆ’ğ‘¥)ğ¶\nğµblocks, incurring an additional cost ofğ‘‡ğ¶(1âˆ’ğ‘¥)(ğ¾â€²âˆ’ğ¾)\n2ğµğ¾ğ¾â€² .\nAdditional cost of a flexible transition. The additional cost of a flexible transition can be derived\nin a similar way to a lazy transition. Before changing a compaction policy, the growth rate of\nread amplification equals the current compaction policy ğ¾. When a new compaction policy ğ¾â€²is\napplied, different transition methods bring in distinctions. With a lazy transition, the growth rate\nof read amplification stays the same after the change of the policy. With a flexible transition, the\ngrowth rate reduces from ğ‘“Â·ğ¾toğ‘“Â·ğ¾â€². Similar to a lazy transition, a flexible transition also incurs\nadditional read amplification when the level is full. This is because part of the data in this level is\ninserted before the transition, where the inserted data adheres to the foregoing compaction policy\nğ¾. Therefore, Area 2 in Figure 5 represents the overall additional cost of flexible transition, which is\nğ¶ğ‘œğ‘ ğ‘¡ğ‘“ğ‘™ğ‘’ğ‘¥ğ‘–ğ‘ğ‘™ğ‘’ =ğ‘“ğ¶(1âˆ’ğ‘¥)(ğ¾âˆ’ğ¾â€²)ğ›¾\nğ¸(1âˆ’ğ›¾)(3)\nOverall Comparison. Table 2 summarizes the additional cost of different transition methods. It is\nobvious that the additional cost of lazy transition is always larger than flexible transition. For\ncomparison between flexible transition and greedy transition, it is obvious that greedy transition is\nalways more costly when ğ¾<ğ¾â€²because the additional cost of a flexible transition is zero in this\ncase. When ğ¾>ğ¾â€², by removing the constant coefficients in cost functions (Equations 2, 3), the\nadditional costs of a flexible transition and a greedy transition are ğ‘‚(ğ‘“ğ¶\nğ¸)andğ‘‚(ğ¶\nğµ), respectively.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:11\nNote that the FPR ğ‘“in an LSM-tree is often less than 1%, and the entry size ğ¸is usually in the\nsame magnitude as the disk page size ğµ. Therefore, the cost of a flexible transition can be up to two\norders of magnitude smaller than that of a greedy transition.\nWe give an example in real scenarios for ease of comparison. We let ğ‘¥=1/2andğ›¾=1/2sinceğ‘¥\nandğ›¾are both distributed between 0and 1. We follow the common settings in key-value stores and\nsetğ‘‡=10,ğµ=4096,ğ¸=1024,ğ¶=1024000 , andğ‘“=0.01. Finally, setting ğ¾=5andğ¾â€²=4gives\nusğ‘‡ğ¶(1âˆ’ğ‘¥)\n2ğµğ¾=125,ğ‘“ğ¶(1âˆ’ğ‘¥2)(ğ¾âˆ’ğ¾â€²)ğ›¾\n2ğ¸(1âˆ’ğ›¾)=3.75, andğ‘“ğ¶(ğ‘¥âˆ’ğ‘¥2)(ğ¾âˆ’ğ¾â€²)ğ›¾\nğ¸(1âˆ’ğ›¾)=2.5. Hence, a flexible transition\nincurs a much smaller additional cost under this scenario.\nFurthermore, if we consider the overall benefit that takes into account both additional costs\nand additional benefits, flexible transition in general still has a greater benefit than that of lazy\ntransition, assuming that a newly learned policy outperforms the previous one in terms of current\nworkload and has lower latency. Since flexible transition does not involve any delay compared to\nlazy transition, it allows for a prompt transformation to the new and improved policy, leading to\nearlier benefits.\n5LERP : THE TUNING MODEL IN RUSKEY\nReinforcement learning (RL) is a machine learning paradigm that trains an agent to cognize and\ndecipher its environment. The agent gets reward or penalty for each action it takes, and decides\nthe next action based on previous experience. The goal of RL is to improve an agentâ€™s performance\nby learning the optimal policy that maximizes the expected cumulative reward.\nIt is not a trivial task to design a suitable RL model for tuning an LSM-tree-based key-value\nsystem. First, it remains unexplored how to relate the key-value system properties such as LSM-tree\ncompaction policy, the running time cost, the level properties, and the workload characteristics to\nthe fundamental RL elements such as states, actions, and rewards. The model should also avoid\nover-amplifying the action space and state space. Second, to make RusKey work in an online manner\nunder dynamic workloads, the model should converge fast. Unfortunately, the high data volume in\nkey-value systems makes the deeper LSM-tree levels experience much longer time to be affected.\nAs a result, the corresponding feedback to the RL model is significantly delayed. Considering that\nRL requires sufficient feedback from the actual environment to adjust its policy, efficiently and\neffectively learning the policy for larger levels is notorious challenging. To address the challenge,\nwe design a novel Level-based Reinforcement learning model with policy Propagation, abbreviated\nasLerp . Next, we introduce the level-based model of Lerp in Section 5.1, and policy propagation\ntechniques in Section 5.2.\n5.1 The Level-based Model\nWe model the reward ,state,environment , and action to capture the system process, and then apply\na RL procedure.\n5.1.1 State and Environment. The state captures the parameters related to the FLSM-tree and the\nworkload within a mission. Our model state consists of internal statistics of the LSM-tree, such\nas the number of read and write I/Os, the level capacities, and the current compaction policies at\neach level. It also includes workload statistics such as the read/write ratio in the previous mission.\nThese statistics effectively capture the system state which is related to the system performance. We\nmodel the environment by the compaction policy of a level. For Level ğ‘–, its compaction policy ğ¾ğ‘–is\ndefined as the maximum number of sorted runs in the level, and obviously ğ¾ğ‘–needs to be in[1,ğ‘‡].\nA smallerğ¾ğ‘–means a more aggressive compaction policy. Particularly, ğ¾ğ‘–=1implies a leveling\ncompaction policy, and ğ¾ğ‘–=ğ‘‡implies a tiering compaction policy.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:12 Dingheng Mo et al.\n5.1.2 Action Space: From ğ‘‚(2ğ¿)toğ‘‚(ğ¿).The Action changes the compaction policy of an FLSM-\ntree . A compaction policy setting of an ğ¿-level FLSM-tree is a list(ğ¾1,ğ¾2,...,ğ¾ğ¿), whereğ¾ğ‘–refers\nto the policy of Level ğ‘–. Intuitively, an action can change a policy setting V=(ğ¾1,ğ¾2,...,ğ¾ğ¿)to\nanother Vâ€²=(ğ¾â€²\n1,ğ¾â€²\n2,...,ğ¾â€²\nğ¿), giving a massive action space of size ğ‘‚(ğ‘‡ğ¿), whereğ‘‡indicates the\nnumber of policies in a level. To reduce the action space, our main idea is two-fold. First, the\ncompaction policy is independent among levels, and hence the training can be done separately for\neach level. Second, the characteristics of real-world workloads often change gradually over time.\nThis hints that the policy should also be roughly continuous , and a drastic change of the policy may\nnot be preferred.\nTherefore, we design a level-based model that trains an independent RL model for each level,\nwhere the reward, state, and action are only tailored to the corresponding level. Such level-decoupled\nmodels have drastically smaller action and state space, and hence easier to train. To explain, the\naction space in the model at each level (or level model) is only ğ‘‚(ğ‘‡), and the total action space is\nğ‘‚(ğ‘‡ğ¿). Furthermore, we only allow continuous change of the policy in level models, i.e., the next\naction for policy ğ¾ğ‘–can only be one of ğ¾ğ‘–âˆ’1,ğ¾ğ‘–, orğ¾ğ‘–+1. This further reduces the action space to\nğ‘‚(ğ¿).\n5.1.3 Reward. In RL, the reward function provides feedback from the environment indicating the\ncorrectness of the actions that have been taken. In RusKey , the reward function is obliged to reflect\nthe performance of an FLSM-tree level. Our reward function combines both the end-to-end system\nlatency and a specific level-based latency. The former reflects the global impact while the latter\nreflects the local impact. Let ğ‘¡ğ‘–denote the level-based latency of the ğ‘–-th level and ğ‘¡â€²denote the\nend-to-end latency of FLSM-tree .Lerp â€™s reward function on Level ğ‘–isğ›¼Â·ğ‘¡ğ‘–+(1âˆ’ğ›¼)Â·ğ‘¡â€². Whereğ›¼\nis a parameter between 0 and 1, which controls the weight of ğ‘¡ğ‘–andğ‘¡â€². We do not deliberately set\ndifferent weights to read latency and write latency, because the relative speed of reads and writes\nis reflected in the reward (end-to-end latency), and automatically learnt in RL.\n5.1.4 Incorporating Actor-Critic Network. With the fundamental mapping between the major RL\nelements and FLSM-tree , we now discuss the specific design of the RL model. Note that our\nlevel-based design can be applied with different RL models, and we select the Deep Deterministic\nPolicy Gradient (DDPG) model [ 34], which has been shown to be more effective compared with\nthe classic models such as DQN [41].\nDDPG integrates DQN with the actor-critic network from DPG (Deterministic Policy Gradient).\nThe actor-critic network can be regarded as a temporal difference variation of the policy gradient.\nIt parameterizes a critic function and an actor function with neural networks. The critic function\nmaps the current state and action taken into a Q-Value, which is an estimation of the expected\nreward. The actor function maps the state into a probabilistic distribution of available actions along\nthe direction suggested by the critic function. The policy gradient technique is the foundation for\nthe actorâ€™s learning. Comparatively, critics assess the actorâ€™s performance by computing the value\nfunction. We refer interested readers to the original paper [34] for more details of the model.\nUnder the Lerp model, actors are in charge of selecting the best compaction strategy, and critics\nassist in assessing the effectiveness of a compaction strategy. In addition, each level has its own\nactor and critic functions with the level-based setting. Based on this idea, it is natural to have\nDDPG-based training steps for each level, while we take the level state of the previous round as\ninput.\n5.2 Optimize Training with Policy Propagation\nThe training data of the RL model comes from system runtime metrics. For larger levels in the\nFLSM-tree , training data is sparse because the compaction in a deeper level is exponentially less\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:13\nfrequent than at a shallower level. Nonetheless, the size of a deeper level is exponentially larger than\na shallower level and hence needs more training data. This gives rise to a crucial question: how to\neffectively learn the compaction policy at a large level while keeping a fast learning convergence?\nTo address this issue, we present a policy propagation method based on a cost analysis. As the\nquery cost analysis is related to the bits-per-key at Bloom filters in each level, discussions are\ndivided divided into two cases:\nâ€¢Case 1: Uniform Bits-Per-Key: Every level assigns the same bits-per-key to the Bloom filter.\nThis is the default setting in many key-value stores such as RocksDB [21].\nâ€¢Case 2: Monkey Allocation: Levelğ‘–assigns exponentially lower bits-per-key than Level ğ‘–+1.\nIt is shown in [ 16] that this scheme achieves better amortized read performance, and has been\nadopted in other advanced systems such as Dostoevisky [17] and Cosine [12].\n5.2.1 Propagation for Case 1. In this case, the read/write cost ratio is very similar across different\nlevels, for the reason that each level has the same read amplification and write amplification.\nTherefore, we can use the RL model to learn the policy of Level 1and propagate the policy to the\nother levels. Specifically, we employ the per-level model to obtain the optimal policy at Level 1. The\ncompaction policies of other levels remain unchanged throughout this process so as not to interfere\nwith the end-to-end latency which contributes to the reward. Then, we transform the compaction\npolicies at all other levels into the policy we learned at Level 1 with the flexible transition. It should\nbe noted that our previous comments about the potential for independent policy settings at each\nlevel still stand. Our earlier mention of independence referred specifically to the design space of the\nLSM-tree and did not necessarily contradict the possibility of level correlation within an optimal\nscheme.\n5.2.2 Propagation for Case 2. In this case, the read/write cost ratio can be drastically different, and\nhence the policy at each level can vary. Under the Monkey scheme, if we intend to optimize the\nexpected cost of an operation (lookup or update), there is an optimal policy. We mainly focus on\nanalyzing the zero-result case following Dostoevsky [ 17]. We apply the following lemma to guide\nus in making appropriate inferences on compaction policies.\nLemma 5.1. Consider that the three consecutive levels ( ğ‘–âˆ’1,ğ‘–,ğ‘–+1) in a FLSM-tree employ the\nMonkey scheme. Let ğ¾âˆ—\nğ‘–be the optimal merge policy that minimizes the expected cost per operation at\nLevelğ‘–. We have the following equation:\n1\nğ¾âˆ—\nğ‘–+1=âˆšï¸„\n1\nğ¾âˆ—2\nğ‘–+ğ‘‡Â·\u00121\nğ¾âˆ—2\nğ‘–âˆ’1\nğ¾âˆ—2\nğ‘–âˆ’1\u0013\n(4)\nProof. We follow the notations in Section 4.3 (e.g., ğ¾ğ‘–,ğµ,ğ¸,ğ›¾) unless otherwise specified.\n(1)Lookup cost. Letğ‘“ğ‘–denote the FPR of the Bloom filters in Level ğ‘–. In expectation, the lookup\nwill incurğ‘“ğ‘–Â·ğ¾ğ‘–false positives in Level ğ‘–in the zero-result case. As each false positive causes one\ndisk page read, the time cost that a lookup causes in Level ğ‘–isğ‘“ğ‘–Â·ğ¼ğ‘ŸÂ·ğ¾ğ‘–, whereğ¼ğ‘Ÿis the average\ntime of a read I/O. Let ğ‘ğ‘Ÿbe the cost of probing the metadata of a sorted run in the main memory.\nThen, the total lookup cost in Level ğ‘–isğ‘“ğ‘–Â·ğ¼ğ‘ŸÂ·ğ¾ğ‘–+ğ‘ğ‘ŸÂ·ğ¾ğ‘–.\n(2)Update cost. Letğ¼ğ‘¤denote the average time cost of a write I/O. According to [ 27], the write\namplification of Level ğ‘–isğ‘‡/ğ¾ğ‘–, signaling that on average the key-value entry of the update will\ntake part in ğ‘‡/ğ¾ğ‘–compactions in Level ğ‘–. This entry is read into memory and written into the disk\nonce at each compaction. Therefore, the update incurs an overhead ofğ‘‡Â·ğ¸\nğµÂ·ğ¾ğ‘–Â·(ğ¼ğ‘Ÿ+ğ¼ğ‘¤)+ğ‘‡\nğ¾ğ‘–Â·ğ‘ğ‘¤,\nwhereğ‘ğ‘¤is the CPU cost a key incurs in compaction (such as merge sorting and space allocation).\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:14 Dingheng Mo et al.\nThen, the expected time overhead per operation in Level ğ‘–is\nğ‘“ğ‘–Â·ğ¼ğ‘ŸÂ·ğ¾ğ‘–Â·ğ›¾\n|          {z          }\nQuery I/O cost+ğ‘ğ‘ŸÂ·ğ¾ğ‘–Â·ğ›¾\n|      {z      }\nQuery CPU cost+ğ‘‡Â·ğ¸\nğµÂ·ğ¾ğ‘–Â·(ğ¼ğ‘Ÿ+ğ¼ğ‘¤)Â·( 1âˆ’ğ›¾)\n|                              {z                              }\nUpdate I/O cost+ğ‘‡\nğ¾ğ‘–Â·ğ‘ğ‘¤Â·(1âˆ’ğ›¾)\n|                 {z                 }\nUpdate CPU cost(5)\nMonkey requires ğ‘“ğ‘–=ğ‘‡ğ‘–âˆ’1ğ‘“1, whereğ‘“1is the FPR of the Bloom filters at the first level. Applying\nthe method of Lagrange multipliers, the time overhead is minimized when\nğ¾âˆ—2\nğ‘–=ğ‘‡Â·ğ¸Â·(ğ¼ğ‘Ÿ+ğ¼ğ‘¤)Â·(1âˆ’ğ›¾)+ğµÂ·ğ‘‡Â·ğ‘ğ‘¤Â·(1âˆ’ğ›¾)\nğµÂ·ğ‘“1Â·ğ¼ğ‘ŸÂ·ğ‘‡ğ‘–âˆ’1Â·ğ›¾+ğµÂ·ğ‘ğ‘ŸÂ·ğ›¾\nOr equivalently,\nğ¾âˆ—2\nğ‘–=ğ‘‹\nğ‘ŒÂ·ğ‘‡ğ‘–âˆ’1+ğ‘\nwhereğ‘‹=ğ‘‡Â·ğ¸Â·(ğ¼ğ‘Ÿ+ğ¼ğ‘¤)Â·(1âˆ’ğ›¾)+ğ‘‡Â·ğµÂ·ğ‘ğ‘¤Â·(1âˆ’ğ›¾),ğ‘Œ=ğµÂ·ğ‘“1Â·ğ¼ğ‘ŸÂ·ğ›¾, andğ‘=ğµÂ·ğ‘ğ‘ŸÂ·ğ›¾. This\nfurther gives\n1\nğ¾âˆ—2\nğ‘–+1âˆ’1\nğ¾âˆ—2\nğ‘–=ğ‘ŒÂ·(ğ‘‡ğ‘–âˆ’ğ‘‡ğ‘–âˆ’1)\nğ‘‹=ğ‘‡Â·ğ‘ŒÂ·(ğ‘‡ğ‘–âˆ’1âˆ’ğ‘‡ğ‘–âˆ’2)\nğ‘‹=ğ‘‡Â· \n1\nğ¾âˆ—2\nğ‘–âˆ’1\nğ¾âˆ—2\nğ‘–âˆ’1!\n,\nNote that under the Monkey scheme, the optimal policies always satisfy that ğ¾âˆ—\nğ‘–â‰¤ğ¾âˆ—\nğ‘–âˆ’1, and hence\n1\nğ¾âˆ—\nğ‘–+1=âˆšï¸„\n1\nğ¾âˆ—2\nğ‘–+ğ‘‡Â·\u00121\nğ¾âˆ—2\nğ‘–âˆ’1\nğ¾âˆ—2\nğ‘–âˆ’1\u0013\nâ–¡\nLemma 5.1 shows that the optimal policy of two consecutive levels can help us infer the optimal\ncompaction policy of larger levels even if we are unaware of the specific values of the system\nrelated parameters ğ‘‹,ğ‘Œ, andğ‘. Therefore, we let the tuning model only tune the compaction policy\nof Level 1 and Level 2, and infer the compaction policy for all subsequent levels by Lemma 5.1.\nWhen the inferred policy may not be integers, we round it to the closest valid policy.\nExample. We assume that the tuning result of Level 1 and Level 2 are 9 and 7, respectively. Then\nfollowing Equation 4, we set the compaction policy of Level 3 as ğ¾âˆ—\n3=âˆšï¸‚\n1\n1\n72+10Â·\u0010\n1\n72âˆ’1\n92\u0011â‰ˆ3. Similarly,\nLevel 4 hasğ¾âˆ—\n4=âˆšï¸‚\n1\n1\n32+10Â·\u0010\n1\n32âˆ’1\n72\u0011â‰ˆ1.\nAdditional discussion with non-zero-result lookups. The policy propagation still largely\nremains viable in the presence of non-zero-result lookups. Firstly, according to previous works [ 12,\n26], the hit rate of non-zero-result lookups for each level is in general proportional to the level\ncapacity, which increases exponentially by a factor of ğ‘‡from the smallest to the largest levels.\nConsequently, the hit rates for all levels, except the largest level, are relatively insignificant, resulting\nin a negligible impact on Bloom filters and the trade-off between reads and writes in these levels.\nHence, our policy propagation remains applicable in these levels. Secondly, under the Monkey\nscheme, the FPR of the Bloom filter increases exponentially by a factor of ğ‘‡for each level. As\na result, the largest level has an immense FPR, which necessitates an aggressive optimal policy\n(ğ¾=1) to remedy excessive read overhead. For instance, in our case study presented in Figure 9,\nthe optimal policy for the largest layer is ğ¾=1. Even if non-zero-result lookups may partially\nmitigate the influence of the Bloom filter in the largest level, the need for an aggressive optimal\npolicy very likely remains unchanged.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:15\n6 RELATED WORK\nMachine Learning for Database Storage Systems. There are extensive studies on tuning storage\nsystems via machine learning. Pavlo et al. [43] and Aken et al. [56] propose the concept of a self-\ndriving database that makes decisions automatically with machine learning models. Ottertune [ 55]\nincludes the techniques that analyze and flit database knobs with machine learning techniques\nand further recommend parameter settings by learning from collected metrics. Qtune [ 32], CDB-\nTune [ 64], and CDBTune+ [ 65] are RL-based database tuning methods, which adopt DDPG to\nimprove their learning effectiveness in large configuration space. Bourbon [ 15] also incorporates\nmachine learning into the LSM-tree, however, in a different way from our paper. It proposes to\naugment the fence pointers in the LSM-tree with the learned index structures [ 30]. We note that\nmost of the studies are concentrated on tuning SQL databases. To the best of our knowledge, we\nhave the first attempt on applying machine learning to NoSQL key-value database tuning.\nLSM-tree Optimization There are numerous studies on LSM-tree optimizations [ 1â€“3,7â€“9,11,12,\n16â€“20,23,25â€“29,36â€“39,45â€“50,53,54,57â€“60,63,66â€“68], as we summarized in Section 1. Among\nthese studies, some studies [ 12,16â€“18,26,27] are more related to RusKey , since they focus on\ntuning compaction policies as well as RusKey . Monkey [ 16] includes a theoretical cost model for\nan LSM-tree by estimating the expected I/O cost. Based on the model, Monkey co-tunes the merge\npolicy, the buffer size, and the Bloom filtersâ€™ bits-per-key to locate an optimal LSM-tree design with\nthe minimal I/O cost for a given workload. Dayan and Idreos [ 17] show that existing merge policies\n(tiering and leveling) are not able to fully trade between read costs and write costs, therefore they\npropose Fluid LSM-tree that enables hybrid compaction policies. In addition, Dostoevsky further\ngeneralizes its theoretical model on hybrid compaction policies. Chatterjee et al. [12] propose a\nsynthetic model named Cosine for key-value stores on the cloud. Moreover, they present an I/O\ncost model that is aware of workload distribution. Huynh et al. [26] provide a model-based analysis\non workloads with uncertainty. Dayan and Idreos [ 18] devise a more scalable merge policy for\nLSM-tree by adjusting the size ratio between adjacency levels. Compared with these works, our\nstudy is the first one that employs machine learning techniques and is a pioneer work that considers\nreal-time transition costs between different tuning settings.\n7 EVALUATION\nThis section presents experimental studies of RusKey on various workloads. The result shows that\nRusKey exhibits strong robustness in performance across different workloads.\nSetup. We process our experiments on a server with an Intel(R) Xeon(R) Gold 6326 CPU @ 2.90GHz\nprocessor, 256GB DDR4 main memory, and 1TB NVMe SSD, running 64-bit Ubuntu 20.04.4 LTS on\nan ext4 partition.\nImplementation. We implement RusKey â€™sFLSM-tree on top of Facebookâ€™s RocksDB [ 21], a\nwidely used LSM tree-based key-value storage system. Similar to previous works [ 12,17,18], we\nextend the compactor API which RocksDB provides to allow hybrid compaction policies across\nlevels. We also implement Monkey [ 16] by enabling RocksDB to assign different bits-per-keys of\nthe Bloom filters across all levels. Following previous works [ 17,26], we enable direct I/Os for\nread and write. We set the memory buffer size to 2MB, the size ratio to 10, and the default Bloom\nfilter bits-per-key to 8. For RocksDB with Monkey scheme, we lower bits-per-key to 4 since in\nthis case Monkey exploits Bloom filters more effectively. We use the internal counters of RocksDB\nto acquire necessary statistics for states and measure the level-based latency. We implement the\nLerp model with PyTorch. In our experiments, we employ a three-layer fully-connected neural\nnetwork with 128 neurons per layer using ReLU activation functions for both critic and actor. We\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:16 Dingheng Mo et al.\nlet the end-to-end latency and by-level latency to be equally contributed to the reward by setting\nparameterğ›¼to1/2.\nOur previous discussions are based on the assumption that the compaction is conducted per\nlevel at a time, in line with many previous works [ 16â€“18,26]. In RocksDB, however, compaction is\nperformed at the granularity of files. A sorted run in these systems is composed of a few disk files.\nDuring compaction, a small set of files with overlapping key ranges in each level are merged. File\ncompaction may reduce the actual size of a sealed run, which will be reactivated, and ultimately\nleads to multiple active runs in one level. Although the compaction granularity is different, a similar\ntransition method can still be applied. To increase the compaction policy ğ¾ğ‘–of Levelğ‘–by one, we\nreduce the capacity of all existing runs in the level fromğ¶ğ‘–\nğ¾ğ‘–toğ¶ğ‘–\nğ¾ğ‘–+1, whereğ¶ğ‘–is the level capacity\nof Levelğ‘–, and initialize an empty run as the active run with the same capacity. To decrease ğ¾ğ‘–by\none, we seal one of the runs in the level and increase the capacity of other sequences fromğ¶ğ‘–\nğ¾ğ‘–to\nğ¶ğ‘–\nğ¾ğ‘–âˆ’1. To avoid an additional cost and a performance slump, the sealed run does not trigger any\ncompaction. When other runs in the level trigger a file compaction, overlapping files in the sealed\nrun will also be involved in this compaction. Therefore, the sealed run would gradually get merged\nthrough compactions triggered by other runs in the level. In this way, a FLSM-tree transition still\ntakes effect immediately and incurs zero immediate transition cost.\nBaselines. We compare RusKey with three typical compaction policy settings in Fluid LSM-\ntree [ 17], including aggressive compaction ( ğ¾=1), lazy compaction ( ğ¾=10), and moderate setting\n(ğ¾=5). We name them as Aggressive ,Lazy andModerate , respectively. We also compare RusKey\nwith the state-of-the-art hybrid compaction policy Lazy-Leveling . For fairness, we only compare\nLazy-Leveling under Monkey scheme, following the setting of Dostoevisky [17]. In addition, we\nalso include heuristic-based baselines on top of our FLSM-tree , which greedily selects a more read\nor write friendly compaction policy for each level if the workload in the level moves towards the\nrespective direction.\nExperiment Design. By default, we initially bulk load the empty database with 100 million random\nsampled key-value entries. Each key-value entry consists of a key of 128 bytes and a value of 896\nbytes. The mission size is set to 50000 operations. The setting is determined to ensure a reasonably\nconsistent workload throughout a mission, while also involving sufficient operations in a mission\nto gather the necessary information for reinforcement learning. We measure the performance\nof the database with workloads of 100 million operations, which are divided into 2000 missions.\nEach operation can be lookup orupdate , which consists of uniformly and randomly distributed\nkeys and values. Our evaluations are performed with various ratios between lookups and updates.\nForRusKey , we initiate the FLSM-tree with leveling, which is the default compaction policy in\nRocksDB.\nWe evaluate RusKey under both the uniform Bloom filter scheme and the Monkey Bloom filter\nscheme. In virtue of policy propagation, we only need to tune the compaction policy Level 1 under\nthe uniform scheme and propagate it to other larger levels. Under the Monkey scheme, we tune\nLevel 1 and Level 2 successively with the Lerp . When the compaction policies of Level 1 and Level\n2 stay stable and the RL model converges, we finish the tuning and transfer the policy to larger\nlevels with Equation 4.\nRusKey self-navigates to optimal design on static workloads. In Figure 6, we compare the\nperformance of RusKey with the baselines under various workloads, which include read-heavy\nworkload with 90% lookups, write-heavy workload with 10% lookups, and read-write-balanced\nworkload with 50% lookups. Each of these workloads includes 100 million operations which are\ndivided into 2000 missions.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:17\n 0 2 4 6 8 10 Compaction policy of Ruskey\n 0 0.02 0.04 0.06 0.08 0.1 0.12\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions\n(a) Read-heavy\n 0 2 4 6 8 10\nCompaction policy of Ruskey\n 0 0.05 0.1 0.15 0.2\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions (b) Write-heavy\n 0 2 4 6 8 10 Compaction policy of Ruskey\n 0.05 0.06 0.07 0.08 0.09 0.1 0.11\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions (c) Balanced\nFig. 6. RusKey self-navigates to the optimal design on static workloads.\nThe result shows that RusKey achieves near-optimal performance across all workloads. In\ncontrast, the baselines perform sub-optimally on at least one workload. For example, in the read-\nheavy workload (Figure 6 (a)), Aggressive is the most effective because it maintains a low read\ncost by merging sorted runs aggressively that promises low read amplification. However, its\nperformance degrades with the write-heavy workload (Figure 6 (b)) because the aggressive merging\nincurs significant additional write amplification. Moderate achieves moderate performance on\neach of the workloads. It performs worse than aggressive policy on the read-heavy workload and\nworse than lazy policy on the write-heavy workload. Meanwhile, its performance is relatively better\nthan the other two baselines on the balanced workload. To explain, the balanced workload contains\nan equal quantity of lookups and updates. Aggressive andLazy are respectively much slower on\nupdate and lookup operations. In contrast, Moderate processes both lookups and updates with\nreasonable efficiency. Nevertheless, the end-to-end performance of moderate policy is still lower\nthan RusKey on the balanced workload when RusKey finishes the tuning and reaches a sweet\ntrade-off between lookups and updates.\nOverall, RusKey has robust performance across different workloads as it can adjust its compaction\npolicies to accommodate different workload compositions. The sub-figures at the top of Figure 6\nshow the compaction policy of RusKey tuned by the RL model Lerp during workload processing.\nThrough tracking the tuning strategy of Lerp , we find that Lerp selects an aggressive compaction\npolicy with a read-heavy workload and a lazy compaction policy with a write-heavy workload.\nIn addition, as shown in Figure 6 (c), Lerp selects an intermediate policy ğ¾=4on the balanced\nworkload, which dominates all baselines after around 600 missions. This is because the baselines\nare sub-optimal on the balanced workload while RusKey self-drives to the optimal compaction\npolicy through the Lerp model. This wise strategy is enabled by integrating the FLSM-tree with\nthe deep RL model Lerp . Note that there are still minor gaps between RusKey and the respective\noptimal baselines on read-heavy and write-heavy workloads because RusKey requires a small\nnumber of missions to conduct the online training in order to find the optimal compaction policy.\nAs shown in the upper sub-figures of Figure 6, it takes Lerp around 300 missions to explore and\nnavigate to the optimal setting with the read-heavy and write-heavy workloads. Tuning on the\nbalanced workload takes longer, which is around 600 missions.\nRusKey performs better on dynamic workloads. In this experiment, we evaluate RusKey and\nthe baselines with a comprehensive dynamic workload. The workload is divided into five sessions\nwith different proportions of lookups and updates. They are in the order of read-heavy (10% update),\nbalanced (50% update), write-heavy (90% update), write-inclined (70% update), and read-inclined\n(30% update). Each section includes 50 million operations which are divided into 1000 missions\nwith 50000 operations for each.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:18 Dingheng Mo et al.\nRead-heavy Balanced Write-heavy Write-inclined Read-inclined \nThe Number of Missions \nFig. 7. RusKey outperforms other baselines on dynamic workloads through self-tuning and transforming its\ncompaction policy according to the change of workload.\nMethodPerformance RankingAvg. RankingRead-H Balanced Write-H Write-I Read-I\nK=1 1 4 4 4 1 2.8\nK=5 3 2 3 1 3 2.4\nK=10 4 3 1 3 4 3\nRusKey 1 1 1 1 2 1.2\nTable 3. RusKey ranks higher in performance on average. â€œHâ€ stands for â€œheavyâ€ and â€œIâ€ stands for â€œinclinedâ€.\nFigure 7 presents the latency of RusKey and the baselines as well as the compaction policy that\nRusKey chooses. All baselines perform sub-optimally on at least one of the sessions. In the meantime,\nthe latency of RusKey is close-to-optimal across all sessions, benefiting from a successful tuning\nthrough Lerp andFLSM-tree â€™s ability to flexibly transform the compaction policy. Specifically,\nRusKey adopts compaction policy settings of ğ¾=1,ğ¾=5,ğ¾=10,ğ¾=6,ğ¾=2on the read-heavy,\nbalanced, write-heavy, write-incline and read-inclined sessions, respectively.\nAcross all workload sessions, RusKey achieves up to 4 times better performance than Aggressive\n(on the write-heavy session), up to 2.4 times better performance than Moderate (on the read-heavy\nsession), and up to 3.5 times better performance than Lazy (on the read-heavy session). Note that\nin Figure 7, the latency of RusKey rises slightly at the beginning of each workload session and\nthen drops rapidly. The reason behind this is that Lerp requires a short retraining under a new\nworkload setting.\nTo further show the robustness of RusKey , we compute the performance ranking of all methods\nacross all five workload sessions after tuning RusKey , which is summarized in Table 3. The\nperformance is compared by the average time cost per operation after the RL model is converged in\neach session. The result demonstrates that RusKey ranks first for four workloads and ranks second\nfor the remaining one. Overall, it achieves a high average ranking of 1.2, demonstrating the strong\nrobustness of RusKey .\nRusKey is effective under the Monkey scheme. In Figure 8, we compare RusKey with the\nbaselines under the Monkey scheme, with the same workload setting as Figure 6. In addition to the\nthree basic baselines, we also compare with Lazy-Leveling [17], which is one of the state-of-the-art\ncompaction policies designed for the Monkey scheme. The result is similar to Figure 6, showing\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:19\n 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions\n(a) Read-heavy\n 0 0.05 0.1 0.15 0.2 0.25\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions (b) Write-heavy\n 0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions (c) Balanced\nFig. 8. RusKey is effective under the Monkey scheme.\nFig. 9. RusKey adopts novel policy settings compared with previous designs.\nthat RusKey achieves near-optimal performance across various workloads under the Monkey\nscheme as well. Moreover, Lazy-Leveling also reaches near-optimal across all workloads, whereas\nRusKey performs better than Lazy-Leveling on every workload. Specifically, RusKey performs\nsignificantly better than Lazy-Leveling and other baselines on the balanced workload. The reason\nis that RusKey is able to adopt novel policy settings through policy propagation. We will explain\nthis in detail with a subsequent experiment.\nRusKey adopts novel policy settings compared with previous designs. We compare the\ncompaction policy setting of RusKey and the state-of-the-art design Lazy-Leveling under the\nread-write-balanced workload. The experiment is conducted on a workload of 25 million operations\nunder the Monkey scheme after RusKey finishes self-tuning. We report the end-to-end latency\n(i.e., the running time of processing all the operations) in Figure 9 Left and the per-level latency\nin Figure 9 Right. Under this case, RusKey adopts different compaction policies at each level. It\nsets an aggressive policy at the first level. As the level goes deeper, the policy becomes lazier. This\nmatches the intuition of Lazy-Leveling , that is, compactions in smaller levels are less needed than\nin smaller levels with the Monkey scheme, because the read cost is lower in smaller levels. The\nsuperiority of RusKey is that RusKey self-tunes its compaction policy in a more elaborate way\nthan Lazy-Leveling and gains more benefits from this intuition.\nRusKey remains effective when for YCSB workloads. We evaluate RusKey under the YCSB\nstandard benchmarks and report the results in Figure 11. We use the default Zipfian distribution,\nin which the update frequency and access frequency of keys follow the power law. As shown in\nFigure 11 (a), (b), and (c), the results on YCSB are quite similar in trends to the results on uniform\nworkloads, if we set the composition of workloads the same as the previous experiments. These\nresults further verify that RusKey delivers near-optimal performance across diverse workloads on\nthe YCSB benchmark. Furthermore, we evaluate YCSB benchmark with a workload that contains\n50% range lookups and 50% updates, and the results are shown in Figure 11 (d). Among all baselines,\nAggressive achieves the lowest latency, and the performance of RusKey is on par with that of\nAggressive . This demonstrates that RusKey remains high effectiveness even with range lookups.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:20 Dingheng Mo et al.\n 0 1 2 3 4 5 6\n 0  20  40  60  80  100K=1 K=10Transition\nK=1 K=10TransitionMission Write Latency (s)\nThe Number of Missions\n(a) Write latency\n 0.2 0.4 0.6 0.8 1 1.2\n 0  20  40  60  80  100K=1 K=10TransitionMission Read Latency (s)\nThe Number of Missions (b) Read latency\nFig. 10. Flexible transition incurs no immediate transition cost and delay.\n 0.06 0.07 0.08 0.09 0.1 0.11 0.12 0.13 0.14 0.15\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions\n(a) Read-heavy\n 0 0.05 0.1 0.15 0.2\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions (b) Write-heavy\n 0.06 0.07 0.08 0.09 0.1 0.11 0.12\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions\n(c) Balanced\n 0 0.2 0.4 0.6 0.8 1 1.2 1.4\n 0  500  1000  1500  2000Latency per Query (ms)\nThe Number of Missions (d) Range\nFig. 11. RusKey is robust on YCSB benchmarks and can self-tune to a near-optimal policy.\nFlexible transition performs better than other transition methods. In Figure 10, we evaluate\nthe greedy, lazy, and flexible transitions using a micro-benchmark with compaction granularity of\nlevels. We employ a read-write-balanced workload (50% lookups and 50% updates) of 120 missions,\nwhile each mission contains 1 million operations. Each levelâ€™s initial compaction policy in the\nFLSM-tree is 1. The compaction policy is transformed from 1 to 10 midway through the workload.\nSpecifically, the compaction policy transition happens at the 60th mission, which is represented by\nthe dotted lines in Figure 10. In Figures 10 (a) and 10 (b), the write latency and read latency for each\nmission using various transition methods are depicted, respectively. The spikes of write latency\nin Figures 10 (a) are caused by compactions with the level granularity. Figure 10 (a) demonstrates\nthat when a greedy transition occurs, it results in a very high write latency spike since changing\nthe compaction policies at every level necessitates compacting all data in each level to the next\nlevel. With a greedy transition and a flexible transition, the write latency spikes brought on\nby compactions are significantly lower after the policy is changed. The reason is that the new\ncompaction policy of ğ¾=10incurs less write amplification, so the cost of each compaction, i.e. the\nspikes, would be lower. However, with a lazy transition, the height of spikes stays the same before\nand after the transition, which means that the compaction policies in larger levels still remain\nunchanged, because the transition is delayed until the level is completely filled. Moreover, we can\nfind similar results in Figures 10 (b). The read latencies of the greedy and flexible transition are\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:21\nRead-heavy Balanced Write-heavy Write-inclined Read-inclined \nMethod Rank\nRusKey 1.2\nSymmetric\nThresholdsGreedy, 50%, 50% 1.8\nGreedy, 33%, 67% 1.8\nGreedy, 25%, 75% 2.4\nGreedy, 10%, 90% 3.2\nBiased\nThresholdsGreedy, 25%, 50% 1.8\nGreedy, 50%, 75% 2.4\nFig. 12. RusKey is more robust than greedy approaches with various thresholds.\n 0.01 0.1 1 10\nRead-heavy-U Write-heavy-U Balanced-U Read-heavy-M Write-heavy-M Balanced-MLatency per Mission (s)LSM-tree RL-model\nFig. 13. RusKey â€™s model update time is relatively insignificant.\nhigher than that of the lazy transition after the transition happens, which also reflects the delay\nof the lazy transition. In terms of the end-to-end latency, the greedy transition, lazy transition\nand flexible transition use 51s, 44s, and 40s, respectively. In general, Figure 10 indicates that the\nflexible transition incurs almost-free immediate transition cost and has no delay, demonstrating its\nsuperiority.\nComparison with greedy approaches. An interesting question is whether a simple greedy policy\ncan effectively address our problem. To explore this possibility, we implemented a series of greedy\nstrategies for comparison. We utilized a per-level detector to detect the workload within a level and\nset two thresholds, â„ğ‘ğ‘œğ‘¡ğ‘¡ğ‘œğ‘š andâ„ğ‘¡ğ‘œğ‘. If the percentage of lookups in the level is less than â„ğ‘ğ‘œğ‘¡ğ‘¡ğ‘œğ‘š ,\nthe greedy algorithm identifies the workload as write-heavy and increases the compaction policy\nof the level by one. Conversely, if the percentage of lookups in the level exceeds â„ğ‘¡ğ‘œğ‘, the greedy\nalgorithm recognizes the workload as read-heavy and decreases the compaction policy by one. We\nconsider a wide range of thresholds, including the symmetric thresholds and biased thresholds\nshown in the right table of Figure 12, and present four settings in the left figure of Figure 12\nfor better visualization. The results indicate that some greedy methods can achieve the desired\nperformance for read-heavy or write-heavy workloads. However, for other workloads such as\nbalanced, read-inclined, and write-inclined workloads, they fail to reach the optimal performance. In\ncontrast, RusKey can self-tune to a near-optimal performance across all workloads, thus providing a\nrelatively more robust performance. The robustness of RusKey is attributed to its ability to capture\nthe intricate mapping from workload ratio to the optimal policy through a reward mechanism,\nwhich is absent in the greedy approaches.\nThe right table in Figure 12 summarizes the average performance ranking of all methods, similar\nto the setting of Table 3. Overall, RusKey achieves the highest average ranking, surpassing the best\nsetting of a greedy approach we tested. Our findings suggest that while greedy policies may be\neffective in some scenarios, the use of reinforcement learning methods like RusKey may provide\nmore robust and comprehensive optimization for LSM-trees.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:22 Dingheng Mo et al.\nThe model updating time is insignificant. In Figure 13, we compare the RL model update cost\nand LSM-tree operation cost per mission on various workloads. â€œUâ€ and â€œMâ€ refer to the uniform\nBloom filter scheme and the Monkey scheme, respectively. The Y-axis is in logarithmic scale. Our\nresults show that the model update cost is insignificant compared with the total cost of processing\nthe workload by the LSM-tree. For most workloads, the time spent on updating the model is at most\n1% of the time for processing LSM-tree operations. For example, on the balanced workload with\nthe uniform Bloom filter scheme, the average query processing cost per mission is 3.36 seconds,\nwhile the average model update cost is only 0.019 seconds. The small update cost of the RL model\nofRusKey is mainly attributed to the reduction of the action space.\nBrute-force learning approaches can be impractical. We evaluated two brute-force training\napproaches: (1) without a level-based model that reduces the action space , and (2) without the policy\npropagation and train all levels. We limit the maximum experiment time to 24 hours and use the\nsetting of Figure 6 (c). Our results show that the first approach cannot finish learning within the\ngiven time frame while the second approach fails to achieve the optimum policy starting from\nLevel 3 due to insufficient samples. This demonstrates the importance of our optimization strategy.\nLimitations. Our work represents a first attempt at using reinforcement learning to optimize LSM-\ntrees, and as such, we have only explored one feasible solution for using machine learning to tune\nLSM-trees. However, there are opportunities for further improvement of RusKey by incorporating\nadditional design parameters. For instance, we could learn to adjust the memory allocation for\nBloom filters by considering a more refined analysis with non-zero result workloads or adapt\nsize ratios based on a given workload. The challenge here is to maintain a practical action space\nand a reasonable LSM-tree transition cost. Another limitation of our approach is that the flexible\ntransition degenerates into lazy transition in an extreme read-only case since flexible transition\nonly takes effect when there are updates. It is unclear whether there are better transition methods\nfor this scenario, and this remains an open question for future research. In summary, there is still\nmuch to be explored regarding the optimization of LSM-trees using reinforcement learning, and\nthese aspects deserve further study in future works.\n8 CONCLUSION\nWe present RusKey , which is an RL-enhanced key-value store that supports dynamic workloads in\nan online manner. We integrate into RusKey a novel FLSM-tree to perform an efficient compaction\npolicy transformation, where a FLSM-tree improves an original LSM-tree in terms of transition\ncosts and delays. Further, we model the system by a level-based RL model Lerp , which applies\nDDPG to each level of the FLSM-tree for effective tuning of RusKey under dynamic workloads.\nMoreover, we propose a policy propagation method across levels, reducing the demand for training\nsamples.\n9 ACKNOWLEDGEMENT\nThis research is supported by NTU SUG-NAP and the Ministry of Education, Singapore, under its\nAcRF Tier-2 (MOE-T2EP20122-0003). Any opinions, findings and conclusions or recommendations\nexpressed in this paper are those of the author(s) and do not reflect the views of the Ministry of\nEducation, Singapore. We thank Andrew Lim and Weiping Yu for the disucssions during the initial\nphase of the research.\nREFERENCES\n[1]Ildar Absalyamov, Michael J Carey, and Vassilis J Tsotras. 2018. Lightweight cardinality estimation in LSM-based\nsystems. In Proceedings of the 2018 International Conference on Management of Data . 841â€“855.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:23\n[2] Muhammad Yousuf Ahmad and Bettina Kemme. 2015. Compaction management in distributed key-value datastores.\nProceedings of the VLDB Endowment 8, 8 (2015), 850â€“861.\n[3]Wail Y Alkowaileet, Sattam Alsubaiee, and Michael J Carey. 2019. An LSM-based Tuple Compaction Framework for\nApache AsterixDB (Extended Version). arXiv preprint arXiv:1910.08185 (2019).\n[4]Sattam Alsubaiee, Yasser Altowim, Hotham Altwaijry, Alexander Behm, Vinayak Borkar, Yingyi Bu, Michael Carey,\nInci Cetindil, Madhusudan Cheelangi, Khurram Faraaz, et al .2014. AsterixDB: A scalable, open source BDMS. arXiv\npreprint arXiv:1407.0454 (2014).\n[5]Timothy G Armstrong, Vamsi Ponnekanti, Dhruba Borthakur, and Mark Callaghan. 2013. Linkbench: a database\nbenchmark based on the facebook social graph. In Proceedings of the 2013 ACM SIGMOD International Conference on\nManagement of Data . 1185â€“1196.\n[6]Berk Atikoglu, Yuehai Xu, Eitan Frachtenberg, Song Jiang, and Mike Paleczny. 2012. Workload analysis of a large-\nscale key-value store. In Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on\nMeasurement and Modeling of Computer Systems . 53â€“64.\n[7]Oana Balmau, Diego Didona, Rachid Guerraoui, Willy Zwaenepoel, Huapeng Yuan, Aashray Arora, Karan Gupta, and\nPavan Konka. 2017. TRIAD: Creating Synergies Between Memory, Disk and Log in Log Structured Key-Value Stores.\nIn2017 USENIX Annual Technical Conference (USENIX ATC 17) . 363â€“375.\n[8]Oana Balmau, Florin Dinu, Willy Zwaenepoel, Karan Gupta, Ravishankar Chandhiramoorthi, and Diego Didona.\n2019. SILK: Preventing Latency Spikes in Log-Structured Merge Key-Value Stores. In 2019 USENIX Annual Technical\nConference (USENIX ATC 19) . 753â€“766.\n[9]Edward Bortnikov, Anastasia Braginsky, Eshcar Hillel, Idit Keidar, and Gali Sheffi. 2018. Accordion: Better memory\norganization for LSM key-value stores. Proceedings of the VLDB Endowment 11, 12 (2018), 1863â€“1875.\n[10] Zhichao Cao, Siying Dong, Sagar Vemuri, and David HC Du. 2020. Characterizing, Modeling, and Benchmarking\nRocksDB Key-Value Workloads at Facebook. In 18th USENIX Conference on File and Storage Technologies (FAST 20) .\n209â€“223.\n[11] Helen HW Chan, Chieh-Jan Mike Liang, Yongkun Li, Wenjia He, Patrick PC Lee, Lianjie Zhu, Yaozu Dong, Yinlong Xu,\nYu Xu, Jin Jiang, et al. 2018. HashKV: Enabling Efficient Updates in KV Storage via Hashing. In 2018 USENIX Annual\nTechnical Conference (USENIX ATC 18) . 1007â€“1019.\n[12] Subarna Chatterjee, Meena Jagadeesan, Wilson Qin, and Stratos Idreos. 2021. Cosine: a cloud-cost optimized self-\ndesigning key-value storage engine. Proceedings of the VLDB Endowment 15, 1 (2021), 112â€“126.\n[13] Source Code. 2022. WiredTiger. https://github.com/wiredtiger/wiredtiger.\n[14] Carlo Curino, Evan PC Jones, Samuel Madden, and Hari Balakrishnan. 2011. Workload-aware database monitoring\nand consolidation. In Proceedings of the 2011 ACM SIGMOD International Conference on Management of data . 313â€“324.\n[15] Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth, Andrea Arpaci-Dusseau, and Remzi\nArpaci-Dusseau. 2020. From WiscKey to Bourbon: A Learned Index for Log-Structured Merge Trees. In 14th USENIX\nSymposium on Operating Systems Design and Implementation (OSDI 20) . 155â€“171.\n[16] Niv Dayan, Manos Athanassoulis, and Stratos Idreos. 2017. Monkey: Optimal navigable key-value store. In Proceedings\nof the 2017 ACM International Conference on Management of Data . 79â€“94.\n[17] Niv Dayan and Stratos Idreos. 2018. Dostoevsky: Better Space-Time Trade-Offs for LSM-Tree Based Key-Value Stores\nvia Adaptive Removal of Superfluous Merging. In Proceedings of the 2018 International Conference on Management\nof Data (Houston, TX, USA) (SIGMOD â€™18) . Association for Computing Machinery, New York, NY, USA, 505â€“520.\nhttps://doi.org/10.1145/3183713.3196927\n[18] Niv Dayan and Stratos Idreos. 2019. The log-structured merge-bush & the wacky continuum. In Proceedings of the 2019\nInternational Conference on Management of Data . 449â€“466.\n[19] Niv Dayan and Moshe Twitto. 2021. Chucky: A Succinct Cuckoo Filter for LSM-Tree. In Proceedings of the 2021\nInternational Conference on Management of Data . 365â€“378.\n[20] Niv Dayan, Tamar Weiss, Shmuel Dashevsky, Michael Pan, Edward Bortnikov, and Moshe Twitto. 2022. Spooky:\ngranulating LSM-tree compactions correctly. Proceedings of the VLDB Endowment 15, 11 (2022), 3071â€“3084.\n[21] Facebook. 2022. RocksDB. https://github.com/facebook/rocksdb.\n[22] Daniel Gmach, Jerry Rolia, Ludmila Cherkasova, and Alfons Kemper. 2007. Workload analysis and demand prediction\nof enterprise data center applications. In 2007 IEEE 10th International Symposium on Workload Characterization . IEEE,\n171â€“180.\n[23] Guy Golan-Gueta, Edward Bortnikov, Eshcar Hillel, and Idit Keidar. 2015. Scaling concurrent log-structured data\nstores. In Proceedings of the Tenth European Conference on Computer Systems . 1â€“14.\n[24] Google. 2022. LevelDB. https://github.com/google/leveldb/.\n[25] Gui Huang, Xuntao Cheng, Jianying Wang, Yujie Wang, Dengcheng He, Tieying Zhang, Feifei Li, Sheng Wang, Wei\nCao, and Qiang Li. 2019. X-Engine: An optimized storage engine for large-scale E-commerce transaction processing.\nInProceedings of the 2019 International Conference on Management of Data . 651â€“665.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\n213:24 Dingheng Mo et al.\n[26] Andy Huynh, Harshal Chaudhari, Evimaria Terzi, and Manos Athanassoulis. 2021. Endure: A Robust Tuning Paradigm\nfor LSM Trees Under Workload Uncertainty. arXiv preprint arXiv:2110.13801 (2021).\n[27] Stratos Idreos, Niv Dayan, Wilson Qin, Mali Akmanalp, Sophie Hilgard, Andrew Slavin Ross, James Lennon, Varun Jain,\nHarshita Gupta, David Li, and Zichen Zhu. 2019. Design Continuums and the Path Toward Self-Designing Key-Value\nStores that Know and Learn. In Proceedings of the Biennial Conference on Innovative Data Systems Research (CIDR) .\n[28] Taewoo Kim, Alexander Behm, Michael Blow, Vinayak Borkar, Yingyi Bu, Michael J Carey, Murtadha Hubail, Shiva\nJahangiri, Jianfeng Jia, Chen Li, et al .2020. Robust and efficient memory management in Apache AsterixDB. Software:\nPractice and Experience 50, 7 (2020), 1114â€“1151.\n[29] Eric R Knorr, Baptiste Lemaire, Andrew Lim, Siqiang Luo, Huanchen Zhang, Stratos Idreos, and Michael Mitzenmacher.\n2022. Proteus: A Self-Designing Range Filter. In Proceedings of the 2022 International Conference on Management of\nData . 1670â€“1684.\n[30] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The case for learned index structures. In\nProceedings of the 2018 international conference on management of data . 489â€“504.\n[31] Avinash Lakshman and Prashant Malik. 2010. Cassandra: a decentralized structured storage system. ACM SIGOPS\nOperating Systems Review 44, 2 (2010), 35â€“40.\n[32] Guoliang Li, Xuanhe Zhou, Shifu Li, and Bo Gao. 2019. QTune: A Query-Aware Database Tuning System with Deep\nReinforcement Learning. 12, 12 (Aug. 2019), 2118â€“2130. https://doi.org/10.14778/3352063.3352129\n[33] Meng Li, Deyi Chen, Haipeng Dai, Rongbiao Xie, Siqiang Luo, Rong Gu, Tong Yang, and Guihai Chen. 2022. Seesaw\nCounting Filter: An Efficient Guardian for Vulnerable Negative Keys During Dynamic Filtering. In Proceedings of the\nACM Web Conference 2022 . 2759â€“2767.\n[34] Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan\nWierstra. 2015. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971 (2015).\n[35] LinkedIn. 2022. Voldemort. http://www.project-voldemort.com.\n[36] Lanyue Lu, Thanumalayan Sankaranarayana Pillai, Hariharan Gopalakrishnan, Andrea C Arpaci-Dusseau, and Remzi H\nArpaci-Dusseau. 2017. Wisckey: Separating keys from values in ssd-conscious storage. ACM Transactions on Storage\n(TOS) 13, 1 (2017), 1â€“28.\n[37] Chen Luo and Michael J Carey. 2019. On performance stability in LSM-based storage systems (extended version).\narXiv preprint arXiv:1906.09667 (2019).\n[38] Chen Luo and Michael J Carey. 2020. Breaking down memory walls: adaptive memory management in LSM-based\nstorage systems. Proceedings of the VLDB Endowment 14, 3 (2020), 241â€“254.\n[39] Siqiang Luo, Subarna Chatterjee, Rafael Ketsetsidis, Niv Dayan, Wilson Qin, and Stratos Idreos. 2020. Rosetta: A robust\nspace-time optimized range filter for key-value stores. In Proceedings of the 2020 ACM SIGMOD International Conference\non Management of Data . 2071â€“2086.\n[40] Lin Ma, Dana Van Aken, Ahmed Hefny, Gustavo Mezerhane, Andrew Pavlo, and Geoffrey J Gordon. 2018. Query-based\nworkload forecasting for self-driving database management systems. In Proceedings of the 2018 International Conference\non Management of Data . 631â€“645.\n[41] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin\nRiedmiller. 2013. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602 (2013).\n[42] Patrick Oâ€™Neil, Edward Cheng, Dieter Gawlick, and Elizabeth Oâ€™Neil. 1996. The log-structured merge-tree (LSM-tree).\nActa Informatica 33, 4 (1996), 351â€“385.\n[43] Andrew Pavlo, Gustavo Angulo, Joy Arulraj, Haibin Lin, Jiexi Lin, Lin Ma, Prashanth Menon, Todd C Mowry, Matthew\nPerron, Ian Quah, et al .2017. Self-Driving Database Management Systems.. In Proceedings of the Biennial Conference\non Innovative Data Systems Research (CIDR) , Vol. 4. 1.\n[44] Mohiuddin Abdul Qader, Shiwen Cheng, and Vagelis Hristidis. 2018. A comparative study of secondary indexing\ntechniques in LSM-based NoSQL databases. In Proceedings of the 2018 International Conference on Management of Data .\n551â€“566.\n[45] Pandian Raju, Rohan Kadekodi, Vijay Chidambaram, and Ittai Abraham. 2017. Pebblesdb: Building key-value stores\nusing fragmented log-structured merge trees. In Proceedings of the 26th Symposium on Operating Systems Principles .\n497â€“514.\n[46] Kai Ren, Qing Zheng, Joy Arulraj, and Garth Gibson. 2017. SlimDB: A space-efficient key-value storage engine for\nsemi-sorted data. Proceedings of the VLDB Endowment 10, 13 (2017), 2037â€“2048.\n[47] Subhadeep Sarkar, Tarikul Islam Papon, Dimitris Staratzis, and Manos Athanassoulis. 2020. Lethe: A tunable delete-\naware LSM engine. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data . 893â€“908.\n[48] Subhadeep Sarkar, Dimitris Staratzis, Zichen Zhu, and Manos Athanassoulis. 2022. Constructing and analyzing the\nLSM compaction design space. arXiv preprint arXiv:2202.04522 (2022).\n[49] Russell Sears and Raghu Ramakrishnan. 2012. bLSM: a general purpose log structured merge tree. In Proceedings of the\n2012 ACM SIGMOD International Conference on Management of Data . 217â€“228.\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.\n\nLearning to Optimize LSM-trees: Towards A Reinforcement\nLearning based Key-Value Store for Dynamic Workloads 213:25\n[50] Pradeep J Shetty, Richard P Spillane, Ravikant R Malpani, Binesh Andrews, Justin Seyster, and Erez Zadok. 2013.\nBuilding Workload-Independent Storage with VT-Trees. In 11th USENIX Conference on File and Storage Technologies\n(FAST 13) . 17â€“30.\n[51] Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An introduction . MIT press.\n[52] Richard S Sutton, Andrew G Barto, et al. 1998. Introduction to reinforcement learning. (1998).\n[53] Yu, Geoffrey X and Markakis, Markos and Kipf, Andreas and Larson, Per-Ã…ke and Minhas, Umar Farooq and Kraska,\nTim. 2022. TreeLine: an update-in-place key-value store for modern storage. Proceedings of the VLDB Endowment 16, 1\n(2022), 99â€“112.\n[54] Risi Thonangi and Jun Yang. 2017. On log-structured merge for solid-state drives. In 2017 IEEE 33rd International\nConference on Data Engineering (ICDE) . IEEE, 683â€“694.\n[55] Dana Van Aken, Andrew Pavlo, Geoffrey J Gordon, and Bohan Zhang. 2017. Automatic database management system\ntuning through large-scale machine learning. In Proceedings of the 2017 ACM international conference on management\nof data . 1009â€“1024.\n[56] Dana Van Aken, Dongsheng Yang, Sebastien Brillard, Ari Fiorino, Bohan Zhang, Christian Bilien, and Andrew Pavlo.\n2021. An inquiry into machine learning-based automatic configuration tuning services on real-world database\nmanagement systems. Proceedings of the VLDB Endowment 14, 7 (2021), 1241â€“1253.\n[57] Tobias VinÃ§on, Sergej Hardock, Christian Riegger, Julian Oppermann, Andreas Koch, and Ilia Petrov. 2018. Noftl-kv:\nTackling write-amplification on kv-stores with native storage management. In Advances in database technology-EDBT\n2018: 21st International Conference on Extending Database Technology, Vienna, Austria, March 26-29, 2018. proceedings .\nUniversity of Konstanz, University Library, 457â€“460.\n[58] Peng Wang, Guangyu Sun, Song Jiang, Jian Ouyang, Shiding Lin, Chen Zhang, and Jason Cong. 2014. An efficient\ndesign and implementation of LSM-tree based key-value store on open-channel SSD. In Proceedings of the Ninth\nEuropean Conference on Computer Systems . 1â€“14.\n[59] Xingbo Wu, Yuehai Xu, Zili Shao, and Song Jiang. 2015. LSM-trie: An LSM-tree-based Ultra-Large Key-Value Store for\nSmall Data Items. In 2015 USENIX Annual Technical Conference (USENIX ATC 15) . 71â€“82.\n[60] Lei Yang, Hong Wu, Tieying Zhang, Xuntao Cheng, Feifei Li, Lei Zou, Yujie Wang, Rongyao Chen, Jianying Wang, and\nGui Huang. 2020. Leaper: A learned prefetcher for cache invalidation in LSM-tree based storage engines. Proceedings\nof the VLDB Endowment 13, 12 (2020), 1976â€“1989.\n[61] Ting Yao, Jiguang Wan, Ping Huang, Xubin He, Qingxin Gui, Fei Wu, and Changsheng Xie. 2017. A light-weight\ncompaction tree to reduce I/O amplification toward efficient key-value stores. In Proc. 33rd Int. Conf. Massive Storage\nSyst. Technol.(MSST) . 1â€“13.\n[62] Ting Yao, Jiguang Wan, Ping Huang, Xubin He, Fei Wu, and Changsheng Xie. 2017. Building efficient key-value stores\nvia a lightweight compaction tree. ACM Transactions on Storage (TOS) 13, 4 (2017), 1â€“28.\n[63] Huanchen Zhang, Hyeontaek Lim, Viktor Leis, David G Andersen, Michael Kaminsky, Kimberly Keeton, and Andrew\nPavlo. 2018. SuRF: Practical range query filtering with fast succinct tries. In Proceedings of the 2018 International\nConference on Management of Data . 323â€“336.\n[64] Ji Zhang, Yu Liu, Ke Zhou, Guoliang Li, Zhili Xiao, Bin Cheng, Jiashu Xing, Yangtao Wang, Tianheng Cheng, Li Liu,\net al.2019. An end-to-end automatic cloud database tuning system using deep reinforcement learning. In Proceedings\nof the 2019 International Conference on Management of Data . 415â€“432.\n[65] Ji Zhang, Ke Zhou, Guoliang Li, Yu Liu, Ming Xie, Bin Cheng, and Jiashu Xing. 2021. CDBTune+: An efficient deep\nreinforcement learning-based automatic cloud database tuning system. The VLDB Journal 30, 6 (2021), 959â€“987.\n[66] Teng Zhang, Jianying Wang, Xuntao Cheng, Hao Xu, Nanlong Yu, Gui Huang, Tieying Zhang, Dengcheng He, Feifei\nLi, Wei Cao, et al .2020. FPGA-Accelerated Compactions for LSM-based Key-Value Store. In 18th USENIX Conference on\nFile and Storage Technologies (FAST 20) . 225â€“237.\n[67] Yueming Zhang, Yongkun Li, Fan Guo, Cheng Li, and Yinlong Xu. 2018. ElasticBF: Fine-grained and Elastic Bloom\nFilter Towards Efficient Read for LSM-tree-based KV Stores. In 10th USENIX Workshop on Hot Topics in Storage and File\nSystems (HotStorage 18) .\n[68] Zichen Zhu, Ju Hyoung Mun, Aneesh Raman, and Manos Athanassoulis. 2021. Reducing bloom filter cpu overhead in\nlsm-trees on modern storage devices. In Proceedings of the 17th International Workshop on Data Management on New\nHardware (DaMoN 2021) . 1â€“10.\nReceived January 2023; revised April 2023; accepted May 2023\nProc. ACM Manag. Data, Vol. 1, No. 3 (SIGMOD), Article 213. Publication date: September 2023.",
  "textLength": 97311
}