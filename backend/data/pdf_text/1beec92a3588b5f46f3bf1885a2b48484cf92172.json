{
  "paperId": "1beec92a3588b5f46f3bf1885a2b48484cf92172",
  "title": "HyperBlocker: Accelerating Rule-based Blocking in Entity Resolution using GPUs",
  "pdfPath": "1beec92a3588b5f46f3bf1885a2b48484cf92172.pdf",
  "text": "HyperBlocker: Accelerating Rule-based Blocking in Entity\nResolution using GPUs\nXiaoke Zhu\nBeihang University, China\nShenzhen Institute of\nComputing Sciences ,China\nzhuxk@buaa.edu.cnMin Xieâˆ—\nShenzhen Institute of\nComputing Sciences ,China\nxiemin@sics.ac.cnTing Deng\nBeihang University, China\ndengting@act.buaa.edu.cnQi Zhang\nMeta Platforms, USA\nqizhang@meta.com\nABSTRACT\nThis paper studies rule-based blocking in Entity Resolution (ER).\nWe propose HyperBlocker , a GPU-accelerated system for blocking\nin ER. As opposed to previous blocking algorithms and parallel\nblocking solvers, HyperBlocker employs a pipelined architecture\nto overlap data transfer and GPU operations. It generates a data-\naware and rule-aware execution plan on CPUs, for specifying how\nrules are evaluated, and develops a number of hardware-aware\noptimizations to achieve massive parallelism on GPUs.\nUsing real-life datasets, we show that HyperBlocker is at least\n6.8Ã—and 9.1Ã—faster than prior CPU-powered distributed systems\nand GPU-based ER solvers, respectively. Better still, by combining\nHyperBlocker with the state-of-the-art ER matcher, we can speed\nup the overall ER process by at least 30% with comparable accuracy.\nPVLDB Reference Format:\nXiaoke Zhu, Min Xie, Ting Deng, Qi Zhang. HyperBlocker: Accelerating\nRule-based Blocking in Entity Resolution using GPUs. PVLDB, 18(2): 308 -\n321, 2024.\ndoi:10.14778/3705829.3705847\nPVLDB Artifact Availability:\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/SICS-Fundamental-Research-Center/HyperBlocker.\n1 INTRODUCTION\nEntity resolution (ER), also known as record linkage, data dedupli-\ncation, merge/purge and record matching, is to identify tuples that\nrefer to the same real-world entity. It is a routine operation in many\ndata cleaning and integration tasks, such as detecting duplicate\ncommodities [34] and finding duplicate customers [22].\nRecently, with the rising popularity of deep learning (DL) mod-\nels, research efforts have been made to apply DL techniques to\nER. Although these DL-based approaches have shown impressive\naccuracy, they also come with high training/inference costs, due\nto the large number of parameters. Despite the effort to reduce\nparameters, the growth in the size of DL models is still an inevitable\ntrend, leading to the increasing time for making matching decisions.\nIn the worst case, ER solutions have to spend quadratic time ex-\nâˆ—Corresponding author\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 18, No. 2 ISSN 2150-8097.\ndoi:10.14778/3705829.3705847\n(a) Execution time\n (b) Memory cost\nFigure 1: DL-based blocking vs. rule-based blocking\namining all pairs of tuples. As reported by Thomson Reuters, an ER\nproject can take 3-6 months, mainly due to the scale of data [ 20]. To\naccelerate, most ER solutions divide ER into two phases: (a) a block-\ning phase, where a blocker discards unqualified pairs that are guar-\nanteed to refer to distinct entities, and (b) a matching phase, where\na matcher compares the remaining pairs to finally decide whether\nthey are matched ,i.e.,refer to the same entity. The blocking phase is\nparticularly useful when dealing with large data and â€œis the crucial\npart of ER with respect to time efficiency and scalabilityâ€ [65].\nTo cope with the volume of big data, considerable research has\nbeen conducted on blocking techniques. As surveyed in [ 50,65], we\ncan divide blocking methods into rule-based [20,35,39,44,64] or\nDL-based [24,40,77,79], both have their strengths and limitations.\nDL-based blocking methods typically utilize pre-trained DL mod-\nels to generate embeddings for tuples and discard tuple pairs with\nlow similarity scores. While DL-based blocking can enhance ER by\nparallelizing computation and leveraging GPU acceleration [ 42], it\noften comes with long runtime and high memory costs. To justify\nthis, we conducted a detailed analysis on DeepBlocker [77], the\nstate-of-the-art (SOTA) DL-based blocker in Figure 1. We picked a\nrule-based blocker (a prototype of our method) with comparable ac-\ncuracy with DeepBlocker and compared their runtime and memory.\nThe evaluation was conducted on a machine equipped with V100\nGPUs using the Songs dataset [ 59], varying the number of tuples.\nWhen running on one GPU, the runtime of DeepBlocker increases\nsubstantially when the number of tuples exceeds 40k. Worse still,\nit consumes excessive memory due to the large embeddings and\nintermediate results during similarity computation. Although the\nruntime of DeepBlocker can be reduced by using more GPUs, the\nissue remains, e.g.,even with four GPUs in Figure 1(a), DeepBlocker\nis still slower than the rule-based blocker that runs on one GPU.\nIn contrast, rule-based blocking methods demonstrate potential\nfor achieving scalability by leveraging multiple blocking rules . Each\nrule employs various comparisons with logical operators such as\nAND, OR, and NOT to discard unqualified tuple pairs. For instance,\na blocking rule for books may state â€œIf titles match and the number\nof pages match, then the two books matchâ€ [ 46]. We refer to the\ncomparisons in this rule as equality comparisons , as they requirearXiv:2410.04349v2  [cs.DB]  13 Dec 2024\n\n(b) Shared Memory(c) Shared nothingusedunused\nStp. 1 visitStp 2 visitentity 1entity 2(a) Workï¬‚ow for blocking\nStp. 5 visitStp.4 visit\nStp. 1visitStp. 2 data transferBlockingInput\nOutputtuple setpairwise-comparisoncandidate matchesRemote data buï¬€erStp. 3 buï¬€eringFigure 2: Shared memory vs shared nothing architectures\nexact equality. Another example, referred to as similarity compar-\nisons , is presented in [ 64], which adopts the Jaccard similarity to\ndetermine whether a pair of tuples requires further matching. Rule-\nbased approaches complement DL-based approaches by providing\nflexibility, explainability, and scalability in the blocking process [ 19].\nMoreover, by incorporating domain knowledge into blocking rules,\nthese approaches can readily adapt to different domains.\nExample 1: As a critical step for data consistency, an e-commerce\ncompany ( e.g.,Amazon [ 5]) conducts ER for products, to enhance\noperations for e.g.,product listings and inventory management.\nTo identify duplicate products, the blocking rule ğœ‘1may fit.\nğœ‘1: Two products are potentially matched if (a) they have same color\nand price, (b) they are sold at same store, (c) their names are similar.\nHereğœ‘1is a conjunction of attribute-wise comparisons, where\nboth equality (parts (a) and (b)) and similarity comparisons (part\n(c)) are involved. In Section 2, we will formally define ğœ‘1. â–¡\nRule-based blocking in ER has attracted a lot of attention (sur-\nveyed in [ 50,65]). However, most existing rule-based blockers are\ndesigned for CPU-based (shared nothing) architectures, leading to\nunsatisfactory performance. Typically, a blocker conducts pairwise\ncomparisons on all pairs of tuples to obtain candidate matches (Fig-\nure 2(a)). In a shared-nothing architecture, data is partitioned and\nspread across a set of processing units. Each unit independently\nblocks data using its local memory, which may lead to skewed\npartitions/computations and rising communication costs, e.g.,in\nFigure 2(c), the first unit is assigned more tuples than the second one\nand worse still, two tuples that both refer to entity 1 are distributed\nto different partitions. To avoid missing this match, the second unit\nhas to visit its local memory (Stp. 1) and transfer its data to the first\nunit (Stp. 2). Then the first unit buffers the data (Stp. 3) and finally,\nconducts comparison locally (Stp. 4 & 5). The shared memory archi-\ntecture (Figure 2(b)) is the opposite: all data is accessible from all pro-\ncessing units, allowing for efficient data sharing, collaboration be-\ntween processing units and dynamic workload scheduling, e.g.,the\ntwo tuples referred to entity 1 can be directly accessed by both units\nin Figure 2(b) (Stp. 1 & 2). GPUs are typically based on shared mem-\nory architectures, offering promising opportunities to achieve block-\ning parallelism. However, unlike DL-based approaches, few rule-\nbased methods support the massive parallelism offered by GPUs,\ndespite their greater potential in parallel scalability (see Figure 1).\nTo make practical use of rule-based blocking, several questions\nhave to be answered. Can we parallelize it under a share memory\narchitecture, utilizing massive parallelism of a GPU? Can we explore\ncharacteristics of GPUs and CPUs, to effectively collaborate them?\nHyperBlocker . To answer these, we develop HyperBlocker , a GPU-\naccelerated system for rule-based blocking in Entity Resolution. Asproof of concept, we adopt matching dependencies ( MDs ) [27] for\nrule-based blocking. As a class of rules developed for record match-\ning, MDs are defined as a conjunction of (similarity) predicates\nand support both equality and similarity comparisons. Compared\nwith prior works, HyperBlocker has the following unique features.\n(1) A pipelined architecture .HyperBlocker adopts an architecture\nthat pipelines the memory access from/to CPUs for data transfer,\nand operations on GPUs for rule-based blocking. In this way, the\ndata transfer and the computation on GPUs can be overlapped.\n(2) Execution plan on CPUs . To effectively filter unqualified pairs,\nblocking must be optimized for the underlying data (resp. blocking\nrules) for both equality and similarity comparisons; in this case, we\nsay that the blocking is data-aware (resp. rule-aware ). To our knowl-\nedge, prior methods either fail to consider data/rule-awareness or\ncannot handle arbitrary comparisons well. HyperBlocker designs an\nexecution plan generator to warrant efficient rule-based blocking.\n(3) Hardware-aware parallelism on GPUs . Due to different charac-\nteristics of CPUs and GPUs, a naive approach that applies existing\nCPU-based blocking on GPUs makes substantial processing ca-\npacity untapped. We develop a variety of GPU-based parallelism\nstrategies, designated for rule-based blocking, by exploiting the\nhardware characteristics of GPUs, to achieve massive parallelism.\n(4) Multi-GPUs collaboration . It is already hard to offload tasks on\nCPUs. This problem is even exacerbated under multi-GPUs, due to\nthe complexities of task decomposition, (inter-GPU) resource man-\nagement, and workload balancing. HyperBlocker provides effective\npartitioning and scheduling strategies to scale with multiple GPUs.\nContribution & organization. After reviewing background in Sec-\ntion 2, we present HyperBlocker as follows: (1) its unique architec-\nture and system overview (Section 3); (2) the rule/data-aware execu-\ntion plan generator (Section 4); (3) the hardware-aware parallelism\nand the task scheduling strategy across GPUs (Section 5); and (4)\nan experimental study (Section 6). Section 7 presents related work.\nUsing real-life datasets, we find the following: (a) HyperBlocker\nspeedups prior distributed blocking systems and GPU baselines by\nat least 6.8Ã—and 9.1Ã—, respectively. (b) Combining HyperBlocker\nwith the SOTA ER matcher saves at least 30% time with comprable\naccuracy. (c) HyperBlocker is scalable, e.g.,it can process 36M tuples\nin 1604s. (d) While promising, DL-based blocking methods are not\nalways the best. By carefully optimizing rule-based blocking on\nGPUs, we share valuable lessons/insights about when rule-based\napproaches can beat the DL-based ones and vice versa.\n2 PRELIMINARIES\nWe first review the notations for ER, blocking, and the GPU.\nRelations. Consider a schema ğ‘…=(eid,ğ´1,...,ğ´ğ‘›), whereğ´ğ‘–is an\nattribute (ğ‘–âˆˆ[1,ğ‘›]), and eidis an entity id, such that each tuple of ğ‘…\nrepresents an entity. A relation ğ·ofğ‘…is a set of tuples of schema ğ‘….\nEntity resolution (ER). Given a relation ğ·, ER is to identify all\ntuple pairs in ğ·that refer to the same real-life entity. It returns a\nset of tuple pairs(ğ‘¡1,ğ‘¡2)ofğ·that are identified as matches . Ifğ‘¡1\ndoes not match ğ‘¡2,(ğ‘¡1,ğ‘¡2)is referred to as a mismatch .\nMost existing methods typically conduct ER in three steps:\n\nTable 1: A relation ğ·of schema Products , where the dash (â€œ-â€) denotes a missing value.\neidpno pname price sname description color saddress\nğ‘’1ğ‘¡1Apple Mac Air $909 Comp. World Apple MacBook Air (13-inch, 8GB RAM, 256GB SSD) Gray 9 Barton Grove, McCulloughmouth\nğ‘’2ğ‘¡2 ThinkPad -Smithâ€™s Tech ThinkPad E15, 15.6-inch full HD IPS display, Intel Core i5-1235U processor, (16GB) RAM | 512GB PCIe SSD) Gray Seg Plaza, Hua qiang North Road\nğ‘’2ğ‘¡3 ThinkPad $849 Smithâ€™s Tech Lenovo E15 Business ThinkPad, 15.6-inch full HD IPS display, 12 generation Intel Core i5, 16GB RAM, 512GB SSD Gray Seg Plaza, Hua qiang North Road\nğ‘’1ğ‘¡4MacBook Air $909 Comp. World Apple 2022 MacBook Air M2 chip 13-inch,8 GB RAM,256 GB SSD storage gray Gray -\nğ‘’1ğ‘¡5MacBook Air $909 Comp. World - Gray Barton Grove, McCulloughmouth\n(1) Data partitioning. The tuples in relation ğ·are divided into mul-\ntiple data partitions, namely ğ‘ƒ1,ğ‘ƒ2,...,ğ‘ƒğ‘š, so that tuples of similar\nentities tend to be put into the same data partition.\n(2) Blocking. Each tuple pair(ğ‘¡1,ğ‘¡2)from a partition ğ‘ƒis a potential\nmatch that requires further verification. To reduce cost, a blocking\nmethodAblock (i.e.,blocker) is often adopted to filter out those pairs\nthat are definitely mismatches efficiently , instead of directly verify-\ning every tuple pair. Denote the set of remaining pairs obtained from\nğ‘ƒbyCa(ğ‘ƒ)={(ğ‘¡1,ğ‘¡2)âˆˆğ‘ƒÃ—ğ‘ƒ|(ğ‘¡1,ğ‘¡2)is not filtered byAblock}.\n(3) Matching. For each pair in Ca(ğ‘ƒ), an accurate (but expensive)\nmatcher is applied, to make final decisions of matches/mismatches.\nOur scope: blocking. Note that in some works, both steps (1) and\n(2) are called blocking. To avoid ambiguity, we follow [ 77] and distin-\nguish partitioning from blocking. We mainly focus on blocking ,i.e.,\nâ—¦Input : A relation ğ·of the tuples of schema ğ‘…, where the tuples\ninğ·are divided into ğ‘špartitionsğ‘ƒ1,...,ğ‘ƒğ‘š.\nâ—¦Output : The set Ca(ğ‘ƒğ‘–)of candidate tuple pairs on each ğ‘ƒğ‘–.\nAlthough our work can be applied on data partitions generated\nbyanyexisting method, we optimize over multiple data partitions,\nby exploiting designated GPU acceleration techniques (Section 5.3).\nWhile blocking focuses more on efficiency and matching focuses\nmore on accuracy, they can be used without each other, e.g.,one can\ndirectly employ rules [ 27] for ER or apply an ER matcher [ 51] on\nthe Cartesian product of the entire partition. When blocking is used\nalone on a given partition ğ‘ƒ, all tuple pairs in Ca(ğ‘ƒ)are identified as\nmatches. In Section 6, we will test HyperBlocker with or without a\nmatcher, to elaborate the trade-off between efficiency and accuracy.\nRule-based blocking. We study rule-based blocking in this paper,\ndue to its efficiency and explainability remarked earlier. We review a\nclass of matching dependencies ( MDs ), originally proposed in [ 27].\nPredicates. Predicates over schema ğ‘…are defined as follows:\nğ‘::=ğ‘¡.ğ´=ğ‘|ğ‘¡.ğ´=ğ‘ .ğµ|ğ‘¡.ğ´â‰ˆğ‘ .ğµ\nwhereğ‘¡andğ‘ are tuple variables denoting tuples of ğ‘…,ğ´andğµare\nattributes of ğ‘…andğ‘is a constant; ğ‘¡.ğ´=ğ‘ .ğµandğ‘¡.ğ´=ğ‘compare\nthe equality on compatible values, e.g.,ğ‘¡.eid=ğ‘ .eidsays that(ğ‘¡,ğ‘ )is\na potential match; ğ‘¡.ğ´â‰ˆğ‘ .ğµcompares the similarity ofğ‘¡.ğ´andğ‘ .ğµ.\nHere any similarity measure, symmetric or asymmetric, can be used\nasâ‰ˆ,e.g.,edit distance or KL divergence, such that ğ‘¡.ğ´â‰ˆğ‘ .ğµis true\nifğ‘¡.ğ´andğ‘ .ğµare â€œsimilarâ€ enough w.r.t. a threshold. Sophisticated\nsimilarity measures like ML models can also be used as in [ 18,28].\nRules. A (bi-variable) matching dependency (MD) overğ‘…is:\nğœ‘=ğ‘‹â†’ğ‘™,\nwhereğ‘‹is a conjunction of predicates over ğ‘…with two tuple vari-\nablesğ‘¡andğ‘ , andğ‘™isğ‘¡.eid=ğ‘ .eid. We refer to ğ‘‹as the precondition\nofğœ‘, andğ‘™as the consequence ofğœ‘, respectively.\nExample 2: Consider a (simplified) e-commence database with self-explained schema Products (eid,pno,pname ,price ,sname (store\nname), description ,color ,saddress (store address)). Below are some\nexamples MDs , where the rule in Example 1 is written as ğœ‘1.\n(1)ğœ‘1:ğ‘¡.color =ğ‘ .colorâˆ§ğ‘¡.price =ğ‘ .priceâˆ§ğ‘¡.sname =ğ‘ .sname\nâˆ§ğ‘¡.pnameâ‰ˆEDğ‘ .pnameâ†’ğ‘¡.eid=ğ‘ .eid, whereâ‰ˆEDmeasures\nthe edit distance. As stated before, ğœ‘1identifies two products, by\ntheir colors, prices, product names and the stores sold.\n(2)ğœ‘2:ğ‘¡.sname =ğ‘ .snameâˆ§ğ‘¡.descriptionâ‰ˆJDğ‘ .descriptionâ†’\nğ‘¡.eid=ğ‘ .eid, whereâ‰ˆJDmeasures the Jaccard distance. The MD\nsays that if two products are sold in the store and have a similar\ndescription, then they are identified as a potential match.\n(3)ğœ‘3:ğ‘¡.saddressâ‰ˆEDğ‘ .saddressâˆ§ğ‘¡.descriptionâ‰ˆJDğ‘ .description\nâ†’ğ‘¡.eid=ğ‘ .eid. It gives another condition for identifying two\nproducts, i.e.,the two products with similar descriptions sold from\nstores with similar addresses are potentially matched. â–¡\nSemantics . Avaluation of tuple variables of an MDğœ‘inğ·, or simply\na valuation of ğœ‘, is a mapping â„that instantiates the two variables\nğ‘¡andğ‘ with tuples in ğ·. A valuation â„satisfies a predicateğ‘over\nğ‘…, written as â„|=ğ‘, if the following is satisfied: (1) if ğ‘isğ‘¡.ğ´=ğ‘\norğ‘¡.ğ´=ğ‘ .ğµ, then it is interpreted as in tuple relational calculus\nfollowing the standard semantics of first-order logic [ 15]; and (2) ifğ‘\nisğ‘¡.ğ´â‰ˆğ‘ .ğµ, thenâ„(ğ‘¡).ğ´â‰ˆâ„(ğ‘ ).ğµreturns true. Given a conjunction\nğ‘‹of predicates, we say â„|=ğ‘‹if for allpredicatesğ‘inğ‘‹,â„|=ğ‘.\nBlocking. Rule-based blocking employs a set Î”ofMDs . Given a par-\ntitionğ‘ƒ, a pair(ğ‘¡1,ğ‘¡2)âˆˆğ‘ƒÃ—ğ‘ƒis in Ca(ğ‘ƒ)iffthere exists an MDğœ‘\ninÎ”such that the valuation â„(ğ‘¡1,ğ‘¡2)ofğœ‘that instantiates variables\nğ‘¡andğ‘ with tuplesğ‘¡1andğ‘¡2satisfies the precondition of ğœ‘; we call\nsuchğœ‘as awitness at(ğ‘¡1,ğ‘¡2), since it indicates that (ğ‘¡1,ğ‘¡2)is a poten-\ntial match. Otherwise, (ğ‘¡1,ğ‘¡2)will be filtered. Since a precondition is\na conjunction of predicates, rule-based blocking is in Disjunctive nor-\nmal form (DNF), i.e.,it is to evaluate a disjunction of conjunctions.\nExample 3: Continuing with Example 2, consider ğ·in Table 1 and\nâ„(ğ‘¡1,ğ‘¡4)that instantiates variables ğ‘¡andğ‘ with tuples ğ‘¡1andğ‘¡4in\nğ·. Sinceâ„(ğ‘¡1,ğ‘¡4)satisfies the precondition of ğœ‘1,ğœ‘1is a witness at\n(ğ‘¡1,ğ‘¡4). Similarly, one can verify that ğœ‘1is not a witness at(ğ‘¡2,ğ‘¡3).â–¡\nDiscovery of MDs .MDs can be considered as a special case of entity\nenhancing rules ( REEs ) [28,29]. We can readily apply the discovery\nalgorithms for REEs ,e.g.,[28,29], to discover MDs (details omitted).\nGPU hardware. As general processors for high-performance com-\nputation, GPUs offer the following benefits compared with CPUs.\nFirst, GPUs provide massive parallelism by programming with\nCUDA (Compute Unified Device Architecture) [ 54]. A GPU has\nmultiple SMs (Streaming Multiprocessors), where each SM accom-\nmodates multiple processing units. e.g.,V100 has 80 SMs, each with\n64 CUDA cores. SMs handle the parallel execution of CUDA cores. In\nCUDA programming, CUDA cores are conceptually organized into\n\nTBs (Thread Blocks) and physically grouped into thread warps, each\ncomprising subgroups of 32 threads. This hierarchical organization\nallows thousands of threads running simultaneously on GPUs.\nSecond, GPUs utilize the DMA (Direct Memory Access) tech-\nnology, which enables direct data transfer between GPU memory\nand system memory. This not only reduces CPU overhead but also\nallows the GPU to handle multiple data streams simultaneously.\nHowever, the number of PCIe lanes determines the maximum num-\nber of streams that can transfer data simultaneously ( e.g.,16 PCIe\nlanes for V100). When multiple partitions perform data transfers\nover a PCIe lane, only one can utilize the lane at a time.\nThird, GPUs adopt SIMT (Single Instruction, Multiple Threads)\nexecution, where each SIMT lane is an individual unit that is re-\nsponsible for executing a thread under a single instruction. Thread\ndivergence can adversely affect the performance and it typically oc-\ncurs in conditional statements ( e.g., if-else ), where some lanes take\none execution path while the others take a different path. However,\nGPUs must execute different execution paths sequentially, rather\nthan in parallel, resulting in underutilization of GPU resources.\n3 HYPERBLOCKER: SYSTEM OVERVIEW\nIn this section, we present the overview of HyperBlocker , a GPU-\naccelerated system for rule-based blocking that optimizes the effi-\nciency by considering rules, underlying data, and hardware simul-\ntaneously. In the literature, GPUs and CPUs are usually referred to\nas devices and hosts, respectively. We also follow this terminology.\nChallenges. Existing parallel blocking methods typically rely on\nmultiple CPU-powered machines under the shared nothing archi-\ntecture, to achieve data partition-based parallelism. They reduce the\nruntime by using more machines, which, however, is not always fea-\nsible due to, e.g.,the increasing communication cost (see Section 1).\nIn light of these, HyperBlocker focuses on parallel blocking un-\nder a shared memory architecture; this introduces new challenges.\n(1) Execution plan for efficient blocking. The efficiency of blocking\ndepends heavily on how much/fast we can filter mismatches. There-\nfore, a good execution plan that specifies how rules are evaluated is\ncrucial. However, most existing blocking optimizers fail to consider\nthe properties of rules/data for blocking and even the optimizers\nof popular DBMS ( e.g.,PostgreSQL [ 11]) may not work well when\nhandling similarity comparisons and evaluating queries in DNF (see\nSection 4). This motivates us to design a different plan generator.\n(2) Hardware-aware parallelism. When GPUs are involved, those\nCPU-based techniques adopted in existing solvers no longer suffice,\nsince GPUs have radically different characteristics (Section 2). Novel\nGPU-based parallelism for blocking is required to improve GPU uti-\nlization, e.g.,by reducing thread wait stalls and thread divergence.\n(3) Multi-GPUs collaboration. Existing parallel blocking solvers fo-\ncus on minimizing the communication cost across all workers [ 20,\n22]. However, this objective no longer applies in multi-GPUs sce-\nnarios, where unique challenges such as task decomposition, (inter-\nGPU) resource management and task scheduling arise.\nNovelty. The ultimate goal of HyperBlocker is to generate the set\nCa(ğ‘ƒ)of potential matches on each data partition ğ‘ƒ. To achieve\nthis, we implement three novel components as follows:\n(1) Execution plan generator (EPG) (Section 4). We develop a gener-\nThreadTB\nâ€¦Data partitionDevice MemoryHost MemoryHost ProducerResult\nâ€¦Host ReceiverEPGRulesSchedulerDataset\nâ€¦\nTupleParallelism optimizerDataPartitionningPartitionerPCIeNVLink\nInputFigure 3: The pipelined architecture of HyperBlocker\nator to generate data-aware and rule-aware execution plans, which\nsupport arbitrary comparisons and work well with DNF evaluation.\nHere we say an execution plan is data-aware, since it considers the\ndistribution of data to decide which predicates are evaluated first;\nsimilarly, it is rule-aware, since it is optimized for underlying rules.\n(2) Parallelism optimizer (Section 5). We implement a specialized op-\ntimizer that exploits the hierarchical structure of GPUs, to optimize\nthe power of GPUs by utilizing thread blocks (TBs) and warps. With\nthis optimizer, blocking can be effectively parallelized on GPUs.\n(3) Resource scheduler (Section 5). To achieve optimal performance\nover multiple GPUs, a partitioning strategy and a resource scheduler\nare developed to manage the resources, and balance the workload\nacross multiple GPUs, minimizing idle time and resource waste.\nArchitecture. The architecture of HyperBlocker is shown in\nFigure 3. Taken a relation ğ·of tuples and a set Î”ofMDs discovered\noffline as input, HyperBlocker divides the tuples in ğ·intoğ‘šdisjoint\npartitions and asynchronously processes partitions in a pipelined\nmanner, so that the execution at devices and the data transfer can\nbe overlapped, mitigating the excessive data transfer costs.\nWorkflow. More specifically, HyperBlocker works in five steps:\n(1)Data partitioning. HyperBlocker divides the tuples in ğ·intoğ‘š\npartitions, to allow parallel processing asynchronously.\n(2)Execution plan generation. Given the set Î”ofMDs discovered\noffline, an execution plan that specifies in what order the rules (and\nthe predicates in rules) should be evaluated is generated at the host.\n(3)Host scheduling. The blocking on each partition forms a computa-\ntional task and the host dynamically assigns tasks to the queue(s) of\navailable devices without interrupting their ongoing execution, min-\nimizing the idle time of devices and improving resource utilization.\n(4)Device execution. When a device receives the task assigned, it con-\nducts the rule-based blocking on the corresponding data partition,\nfollowing the execution plan generated in Step (2).\n(5)Result retrieval. Once a task is completed on a device, the host\nwill pull/collect the result (i.e., Ca(ğ‘ƒ)) from the device.\nTo facilitate processing, HyperBlocker has two additional compo-\nnents: HostProducer andHostReceiver , where the former manages\nSteps (1), (2), and (3) and the latter handles Step (5). Steps (3) (4) (5)\ninHyperBlocker work asynchronously in a pipeline manner.\n4 EPG: EXECUTION PLAN GENERATOR\nGiven the set Î”ofMDs and a partition ğ‘ƒofğ·, a naive approach to\ncompute Ca(ğ‘ƒ)is to evaluate each MDinÎ”for all pairs in ğ‘ƒ. That\n\nis, to decide whether (ğ‘¡1,ğ‘¡2)is in Ca(ğ‘ƒ), we perform ğ‘‚(âˆ‘ï¸\nğœ‘âˆˆÎ”|ğœ‘|)\npredicate evaluation, where |ğœ‘|is the number of predicates in ğœ‘.\nWorse still, there are ğ‘‚(|Î”|!|ğœ‘|!)possible ways to evaluate all MDs\ninÎ”, since both MDs inÎ”and predicates in each ğœ‘can be evaluated\nin arbitrary orders. However, not all orders are equally efficient.\nExample 4: In Example 3, ğœ‘1is a witness at(ğ‘¡1,ğ‘¡4)whileğœ‘3is not.\nIf we first evaluate ğœ‘1for(ğ‘¡1,ğ‘¡4),(ğ‘¡1,ğ‘¡4)is identified as a potential\nmatch and there is no need to evaluate ğœ‘3. Moreover, when eval-\nuatingğœ‘1for another pair(ğ‘¡2,ğ‘¡3), we can conclude that ğœ‘1is not a\nwitness at(ğ‘¡2,ğ‘¡3), as soon as we find â„(ğ‘¡2,ğ‘¡3)Ì¸|=ğ‘¡.price =ğ‘ .price .â–¡\nChallenges. Given the huge number of possible evaluation orders,\nit is non-trivial to define a good one, for three reasons:\n(1) Rule priority. Recall that rule-based blocking is in DNF, i.e.,as\nlong as there exists a witness at (ğ‘¡1,ğ‘¡2),(ğ‘¡1,ğ‘¡2)will be considered\nas a potential match. This motivates us to prioritize the rules in\nÎ”so that promising ones can be evaluated early; once a witness\nis found, the evaluation of the remaining rules can be skipped.\n(2) Reusing computation. MDs may have common predicates. To\navoid evaluating a predicate repeatedly, we reuse previous results\nwhenever possible, e.g.,given(ğ‘¡1,ğ‘¡2),ğœ‘1:ğ‘âˆ§ğ‘‹1â†’ğ‘™andğœ‘2:ğ‘âˆ§ğ‘‹2\nâ†’ğ‘™, ifğœ‘1is not a witness at(ğ‘¡1,ğ‘¡2)sinceâ„(ğ‘¡1,ğ‘¡2)Ì¸|=ğ‘, neither isğœ‘2.\n(3) Predicate ordering. Given(ğ‘¡1,ğ‘¡2)andğœ‘:ğ‘‹â†’ğ‘™,ğœ‘is not a\nwitness at(ğ‘¡1,ğ‘¡2)if we find the first ğ‘inğ‘‹such thatâ„(ğ‘¡1,ğ‘¡2)Ì¸|=ğ‘.\nHowever, to decide which predicate is evaluated first, we have to\nconsider both its evaluation cost and its effectiveness/selectivity.\nAs remarked in [ 18,30], blocking with a set of MDs can be im-\nplemented in a single DNF SQL query ( i.e.,anORofANDs ), where\nsimilarity predicates in MDs are re-written as user-defined func-\ntions (UFDs). In light of this, one may want to adopt the optimizers\nof existing DBMS to tackle rule-based blocking, which, however,\nmay not work well, for several reasons. (a) The mixture of relational\noperators and UDFs poses serious challenges to an optimizer [ 67].\nIt may lack â€œthe information needed to decide whether they can be\nreordered with relational operators and other UDFsâ€ [ 37] and worse\nstill, it is hard to accurately estimate the runtime performance of\nUDFs [ 67]. (b) Using ORoperators in WHERE clauses can be ineffi-\ncient, since it can force the database to perform a full table scan to\nfind matching tuples [ 6]. (c) Similar to [ 52], if a tuple pair fails to\nsatisfy prior predicates in a blocking rule, the remaining evalua-\ntion of this rule can be bypassed directly. While this is undeniably\nobvious, â€œmany approaches have not leveraged it effectivelyâ€ [ 52].\nNovelty. In light of these, EPG in HyperBlocker gives a lightweight\nsolution, by generating an execution plan to make the overall eval-\nuation cost of Î”as small as possible. Its novelty includes (a) a new\nnotion of execution tree that works no matter what types of com-\nparisons are used, (b) a rule-aware scoring strategy, to decide which\nMDs inÎ”are evaluated first, and (c) a data-aware predicate ordering\nscheme, to strike for a balance between cost and effectiveness.\nBelow we first give the formal definition of execution plans and\nthen show how EPG generates a good execution plan.\n4.1 Execution plan\nAn execution plan specifies how rules and predicates in Î”are eval-\nuated. Although an execution plan can be represented in differentways, we represent it as an execution tree , denoted byTin this paper\nfor its conciseness and simplicity (an example is given in Figure 4,\nto be explained in more detail later). (1) A node in Tis denoted by\nğ‘, where the root is denoted by ğ‘0. (2) A pathğœŒfrom the root is\na listğœŒ=(ğ‘0,ğ‘1,...,ğ‘ğ¿)such that(ğ‘ğ‘–âˆ’1,ğ‘ğ‘–)is an edge ofTfor\nğ‘–âˆˆ[1,ğ¿]; the length of ğœŒisğ¿,i.e.,the number of edges on ğœŒ. (3) We\nrefer toğ‘2as achild node ofğ‘1if(ğ‘1,ğ‘2)is an edge inT, and as a\ndescendant ofğ‘1if there exists a path from ğ‘1toğ‘2; conversely, we\nrefer toğ‘1as aparent node (resp. predecessor) of ğ‘2. (4) Each edge\nğ‘’represents a predicate ğ‘and is associated with a score, denoted by\nscore(ğ‘’), indicating the priority of ğ‘’. (5) A node is called a leaf if it\nhas no children and Thas|Î”|leaves, where each leaf is associated\nwith a ruleğœ‘:ğ‘‹â†’ğ‘™inÎ”; the length of the path from the root to the\nleaf is|ğ‘‹|(i.e.,the number of predicates in ğ‘‹) and for each predicate\ninğ‘‹, it appears exactly once in an edge on the path. (6) The leaves of\ntwoMDs may have common predecessors, in addition to the root;\nintuitively, this means that the MDs have common predicates. With\na slight abuse of notation, we also denote an execution plan by T.\nEvaluating an execution plan. For each pair(ğ‘¡1,ğ‘¡2), it is eval-\nuated by exploring Tvia depth-first search (DFS), starting at the\nroot. At each internal node ğ‘ofT, we pick a child ğ‘ğ‘such that the\nedge(ğ‘,ğ‘ğ‘), whose associated predicate is ğ‘, has the highest score\namong all children of ğ‘. Then we check whether â„(ğ‘¡1,ğ‘¡2)|=ğ‘. If it\nis the case, we move to ğ‘ğ‘and process ğ‘ğ‘similarly. Otherwise, we\ncheck whether ğ‘still has other unexplored children and we process\nthem similarly, according to the decreasing order of scores. If all\nchildren of ğ‘are explored, we return to the parent ğ‘ğ‘ofğ‘and\nrepeat the process. The evaluation completes if we reach the first\nleaf ofT. Suppose the rule associated with this leaf is ğœ‘:ğ‘‹â†’ğ‘™.\nThis means â„(ğ‘¡1,ğ‘¡2)satisfies all predicates in ğ‘‹, along the path\nfrom the root to that leaf, and thus â„(ğ‘¡1,ğ‘¡2) |=ğ‘‹,i.e.,we find a\nwitness at(ğ‘¡1,ğ‘¡2), and the remaining tree traversal can be skipped.\nExample 5: Consider an execution tree Tin Figure 4(b), which\ndepicts MDs in Example 2. For simplicity, we denote a predicate\nğ‘¡.ğ´=ğ‘ .ğ´(resp.ğ‘¡.ğ´â‰ˆğ‘ .ğ´) byğ‘=\nğ´(resp.ğ‘â‰ˆ\nğ´) and the score associated\nwith each edge is labeled. DFS starts at the root, which has two chil-\ndren. It first explores the edge labeled ğ‘=sname since its score is higher.\nWhen DFS completes, MDsğœ‘2,ğœ‘1andğœ‘3are checked in order. â–¡\n4.2 Execution plan generation\nTaking the set Î”ofMDs as input, EPG in HyperBlocker returns an\nexecution planTin the following two major steps:\n(1) We order all predicates appeared in Î”, by estimating their evalu-\nation costs via a shallow model and quantifying their probabilities\nof being satisfied, by investigating the underlying data distribution.\n(2) Based on the predicate ordering, we build an execution tree\nTby iterating MDs inÎ”. Moreover, we compute a score for each\nedge inT, by considering the probability of finding a witness, i.e.,\nreaching a leaf, if we explore Tfollowing this edge.\nNote that plan generation in EPG can be regarded as a (quick)\npre-processing step for blocking, i.e.,once an execution plan is gen-\nerated, it is applied in allpartitions of ğ·. Below we present these two\nsteps. For simplicity, we assume w.l.o.g. thatğ·is itself a partition.\nPredicate ordering. Denote byPthe set of all predicates appeared\ninÎ”. Intuitively, not all predicates in Pare equally potent for evalu-\n\nation, e.g.,although texts ( e.g.,description ) are often more informa-\ntive than categorical attributes ( e.g.,color ), the former comparison is\nmore expensive. A simple idea is to order predicates by only consid-\nering attribute types and operators ( e.g.,prioritize equality like tra-\nditional optimizers). However, the time/effect of evaluating a predi-\ncate for distinct tuples can be different. Without taking the underly-\ning data into account, it can lead to poor ordering. Motivated by this,\nwe order the predicates in Pby their â€œcost-effectivenessâ€ on ğ·.\nFor simplicity, below we consider a predicate ğ‘that compares\nğ´-values of two tuples, i.e.,ğ‘¡.ğ´=ğ‘ .ğ´orğ‘¡.ğ´â‰ˆğ‘ .ğ´(simplyğ‘=\nğ´or\nğ‘â‰ˆ\nğ´). All discussion extends to other predicate types, e.g.,ğ‘¡.ğ´=ğ‘ .ğµ.\nEvaluation cost. We measure the evaluation cost of a predicate ğ‘by\nthe time for evaluating ğ‘; a predicate that can be evaluated quickly\nshould be checked first. Given a predicate ğ‘inPand a relation ğ·,\nthe evaluation cost of ğ‘onğ·, denoted by cost(ğ‘,ğ·), is:\ncost(ğ‘,ğ·)=âˆ‘ï¸‚\n(ğ‘¡1,ğ‘¡2)âˆˆğ·Ã—ğ·ğ‘‡ğ‘(ğ‘¡1,ğ‘¡2).\nwhereğ‘‡ğ‘(ğ‘¡1,ğ‘¡2)denotes the actual time for checking â„(ğ‘¡1,ğ‘¡2)|=ğ‘.\nNote that it can be costly to iterate all tuple pairs in ğ·to compute\nthe exact evaluation cost of ğ‘onğ·. Thus, below we train a shallow\nNNs, denoted byN, (i.e.,a small feed-forward neural network [ 47])\nto estimate the exact ğ‘‡ğ‘(ğ‘¡1,ğ‘¡2), since it has been proven effective\nin approximating a continuous function on a closed interval [75].\nShallow NNs. The inputs ofNare two tuples ğ‘¡1andğ‘¡2, and a pred-\nicateğ‘, that compares the ğ´-values ofğ‘¡1andğ‘¡2. It first encodes the\nattribute type and the ğ´-value ofğ‘¡1into an embedding ğ‘¡1âƒ—; similarly\nforğ‘¡2âƒ—. The embeddings are then fed to a feed-forward neural net-\nwork, which outputs the estimated time for evaluating ğ‘on(ğ‘¡1,ğ‘¡2).\nWe trainNoffline with training data sampled from historical logs,\nso that the training data follows the same distribution as ğ·.\nEstimated cost. Based onN, the estimated cost of ğ‘onğ·is\ncostË†(ğ‘,ğ·)=norm(ï¸âˆ‘ï¸‚\n(ğ‘¡1,ğ‘¡2)âˆˆğ·Ã—ğ·N(ğ‘,ğ‘¡1,ğ‘¡2))ï¸,\nwhere norm(Â·)normalizes the estimated cost in the range (0,1]. In\npractice, we can also use a sampled set from ğ·for estimating costs.\nEffectiveness. We measure the effectiveness of predicate ğ‘by its\nselectivity, i.e.,the probability of being satisfied. Given the attribute\nğ´compared in ğ‘, we quantify how likely ğ‘¡1andğ‘¡2have distinc-\nt/dissimilar values on ğ´. Ifğ‘¡1andğ‘¡2do so with a high probability, ğ‘\nis less likely to be satisfied; such predicate should be evaluated first\nsince it concludes that an MDinvolvingğ‘is not a witness early.\nTo achieve this, we investigate the data distribution in ğ·. Specif-\nically, we use LSH [ 17] to hash the ğ´-values of all tuples into ğ‘˜\nbuckets, so that similar/same values are hashed into the same bucket\nwith a high probability, where ğ‘˜is a predefined parameter.\nDenote the number of tuples hashed to the ğ‘–-th bucket by ğ‘ğ‘–.\nIntuitively, the evenness of hashing results reflects the probability\nofğ‘being satisfied. If all tuples are hashed into the same bucket,\nit means that the ğ´-values of all tuples are similar and thus ğ‘\n(which compares the ğ´-values) is likely to be satisfied by many\npairs(ğ‘¡1,ğ‘¡2); such predicates should be evaluated with low-priority.\nMotivated by this, the probability of ğ‘being satisfied on ğ·, denoted\nbysp(ğ‘,ğ·), is estimated by measuring the evenness of hashing, i.e.,\n(b) Execution Tree(c) Sequential execution pathAttribute indexFunction pointert.sname=s.snamet.price=s.pricet.pname<latexit sha1_base64=\"dFpIVFMVUdWc7e0zJyAIhk9J788=\">AAAB+nicbVDLSsNAFJ20Pmp9pYorN4Ot4Kokgo9lQQWXFewDmhAm00k7dJIJMxNrif0UNy4UcesP+AsuBFd+ik4fC209cOFwzr3ce48fMyqVZX0amezC4tJybiW/ura+sWkWtuqSJwKTGuaMi6aPJGE0IjVFFSPNWBAU+ow0/N7ZyG/cECEpj67VICZuiDoRDShGSkueWSg5KI4Fv/WcXj+9OB+WPLNola0x4Dyxp6RYyX58v+18kapnvjttjpOQRAozJGXLtmLlpkgoihkZ5p1EkhjhHuqQlqYRCol00/HpQ7ivlTYMuNAVKThWf0+kKJRyEPq6M0SqK2e9kfif10pUcOqmNIoTRSI8WRQkDCoORznANhUEKzbQBGFB9a0Qd5FAWOm08joEe/bleVI/LNvH5aMru1ixwAQ5sAv2wAGwwQmogEtQBTWAQR/cg0fwZNwZD8az8TJpzRjTmW3wB8brD3Apl9g=</latexit>â‡¡ED\n<latexit sha1_base64=\"dFpIVFMVUdWc7e0zJyAIhk9J788=\">AAAB+nicbVDLSsNAFJ20Pmp9pYorN4Ot4Kokgo9lQQWXFewDmhAm00k7dJIJMxNrif0UNy4UcesP+AsuBFd+ik4fC209cOFwzr3ce48fMyqVZX0amezC4tJybiW/ura+sWkWtuqSJwKTGuaMi6aPJGE0IjVFFSPNWBAU+ow0/N7ZyG/cECEpj67VICZuiDoRDShGSkueWSg5KI4Fv/WcXj+9OB+WPLNola0x4Dyxp6RYyX58v+18kapnvjttjpOQRAozJGXLtmLlpkgoihkZ5p1EkhjhHuqQlqYRCol00/HpQ7ivlTYMuNAVKThWf0+kKJRyEPq6M0SqK2e9kfif10pUcOqmNIoTRSI8WRQkDCoORznANhUEKzbQBGFB9a0Qd5FAWOm08joEe/bleVI/LNvH5aMru1ixwAQ5sAv2wAGwwQmogEtQBTWAQR/cg0fwZNwZD8az8TJpzRjTmW3wB8brD3Apl9g=</latexit>â‡¡EDs.pnamet.color=s.colorTraversal order==CP <latexit sha1_base64=\"UGAMpfNupGmPbolKWIF2ZI/Shx4=\">AAAB9XicbVDLSgMxFM20Pmp9VcWVm2AruCozgo9lQRfiqoJ9QDuWTJppQzNJSDJqGfofblwo4tZv8BdcCK78FE0fC209cOFwzr3ce08gGdXGdT+dVHpufmExs5RdXlldW89tbFa1iBUmFSyYUPUAacIoJxVDDSN1qQiKAkZqQe906NduiNJU8CvTl8SPUIfTkGJkrHRdaCIplbhrJRdng0Irl3eL7ghwlngTki+lP77ftr9IuZV7b7YFjiPCDWZI64bnSuMnSBmKGRlkm7EmEuEe6pCGpRxFRPvJ6OoB3LNKG4ZC2eIGjtTfEwmKtO5Hge2MkOnqaW8o/uc1YhOe+AnlMjaE4/GiMGbQCDiMALapItiwviUIK2pvhbiLFMLGBpW1IXjTL8+S6kHROyoeXnr5kgvGyIAdsAv2gQeOQQmcgzKoAAwUuAeP4Mm5dR6cZ+dl3JpyJjNb4A+c1x+c8JZQ</latexit>â‡¡JD\n<latexit sha1_base64=\"UGAMpfNupGmPbolKWIF2ZI/Shx4=\">AAAB9XicbVDLSgMxFM20Pmp9VcWVm2AruCozgo9lQRfiqoJ9QDuWTJppQzNJSDJqGfofblwo4tZv8BdcCK78FE0fC209cOFwzr3ce08gGdXGdT+dVHpufmExs5RdXlldW89tbFa1iBUmFSyYUPUAacIoJxVDDSN1qQiKAkZqQe906NduiNJU8CvTl8SPUIfTkGJkrHRdaCIplbhrJRdng0Irl3eL7ghwlngTki+lP77ftr9IuZV7b7YFjiPCDWZI64bnSuMnSBmKGRlkm7EmEuEe6pCGpRxFRPvJ6OoB3LNKG4ZC2eIGjtTfEwmKtO5Hge2MkOnqaW8o/uc1YhOe+AnlMjaE4/GiMGbQCDiMALapItiwviUIK2pvhbiLFMLGBpW1IXjTL8+S6kHROyoeXnr5kgvGyIAdsAv2gQeOQQmcgzKoAAwUuAeP4Mm5dR6cZ+dl3JpyJjNb4A+c1x+c8JZQ</latexit>â‡¡JDCP <latexit sha1_base64=\"dFpIVFMVUdWc7e0zJyAIhk9J788=\">AAAB+nicbVDLSsNAFJ20Pmp9pYorN4Ot4Kokgo9lQQWXFewDmhAm00k7dJIJMxNrif0UNy4UcesP+AsuBFd+ik4fC209cOFwzr3ce48fMyqVZX0amezC4tJybiW/ura+sWkWtuqSJwKTGuaMi6aPJGE0IjVFFSPNWBAU+ow0/N7ZyG/cECEpj67VICZuiDoRDShGSkueWSg5KI4Fv/WcXj+9OB+WPLNola0x4Dyxp6RYyX58v+18kapnvjttjpOQRAozJGXLtmLlpkgoihkZ5p1EkhjhHuqQlqYRCol00/HpQ7ivlTYMuNAVKThWf0+kKJRyEPq6M0SqK2e9kfif10pUcOqmNIoTRSI8WRQkDCoORznANhUEKzbQBGFB9a0Qd5FAWOm08joEe/bleVI/LNvH5aMru1ixwAQ5sAv2wAGwwQmogEtQBTWAQR/cg0fwZNwZD8az8TJpzRjTmW3wB8brD3Apl9g=</latexit>â‡¡ED\n<latexit sha1_base64=\"dFpIVFMVUdWc7e0zJyAIhk9J788=\">AAAB+nicbVDLSsNAFJ20Pmp9pYorN4Ot4Kokgo9lQQWXFewDmhAm00k7dJIJMxNrif0UNy4UcesP+AsuBFd+ik4fC209cOFwzr3ce48fMyqVZX0amezC4tJybiW/ura+sWkWtuqSJwKTGuaMi6aPJGE0IjVFFSPNWBAU+ow0/N7ZyG/cECEpj67VICZuiDoRDShGSkueWSg5KI4Fv/WcXj+9OB+WPLNola0x4Dyxp6RYyX58v+18kapnvjttjpOQRAozJGXLtmLlpkgoihkZ5p1EkhjhHuqQlqYRCol00/HpQ7ivlTYMuNAVKThWf0+kKJRyEPq6M0SqK2e9kfif10pUcOqmNIoTRSI8WRQkDCoORznANhUEKzbQBGFB9a0Qd5FAWOm08joEe/bleVI/LNvH5aMru1ixwAQ5sAv2wAGwwQmogEtQBTWAQR/cg0fwZNwZD8az8TJpzRjTmW3wB8brD3Apl9g=</latexit>â‡¡ED <latexit sha1_base64=\"UGAMpfNupGmPbolKWIF2ZI/Shx4=\">AAAB9XicbVDLSgMxFM20Pmp9VcWVm2AruCozgo9lQRfiqoJ9QDuWTJppQzNJSDJqGfofblwo4tZv8BdcCK78FE0fC209cOFwzr3ce08gGdXGdT+dVHpufmExs5RdXlldW89tbFa1iBUmFSyYUPUAacIoJxVDDSN1qQiKAkZqQe906NduiNJU8CvTl8SPUIfTkGJkrHRdaCIplbhrJRdng0Irl3eL7ghwlngTki+lP77ftr9IuZV7b7YFjiPCDWZI64bnSuMnSBmKGRlkm7EmEuEe6pCGpRxFRPvJ6OoB3LNKG4ZC2eIGjtTfEwmKtO5Hge2MkOnqaW8o/uc1YhOe+AnlMjaE4/GiMGbQCDiMALapItiwviUIK2pvhbiLFMLGBpW1IXjTL8+S6kHROyoeXnr5kgvGyIAdsAv2gQeOQQmcgzKoAAwUuAeP4Mm5dR6cZ+dl3JpyJjNb4A+c1x+c8JZQ</latexit>â‡¡JD\n<latexit sha1_base64=\"UGAMpfNupGmPbolKWIF2ZI/Shx4=\">AAAB9XicbVDLSgMxFM20Pmp9VcWVm2AruCozgo9lQRfiqoJ9QDuWTJppQzNJSDJqGfofblwo4tZv8BdcCK78FE0fC209cOFwzr3ce08gGdXGdT+dVHpufmExs5RdXlldW89tbFa1iBUmFSyYUPUAacIoJxVDDSN1qQiKAkZqQe906NduiNJU8CvTl8SPUIfTkGJkrHRdaCIplbhrJRdng0Irl3eL7ghwlngTki+lP77ftr9IuZV7b7YFjiPCDWZI64bnSuMnSBmKGRlkm7EmEuEe6pCGpRxFRPvJ6OoB3LNKG4ZC2eIGjtTfEwmKtO5Hge2MkOnqaW8o/uc1YhOe+AnlMjaE4/GiMGbQCDiMALapItiwviUIK2pvhbiLFMLGBpW1IXjTL8+S6kHROyoeXnr5kgvGyIAdsAv2gQeOQQmcgzKoAAwUuAeP4Mm5dR6cZ+dl3JpyJjNb4A+c1x+c8JZQ</latexit>â‡¡JDCP3215CP4CP64CP <latexit sha1_base64=\"dFpIVFMVUdWc7e0zJyAIhk9J788=\">AAAB+nicbVDLSsNAFJ20Pmp9pYorN4Ot4Kokgo9lQQWXFewDmhAm00k7dJIJMxNrif0UNy4UcesP+AsuBFd+ik4fC209cOFwzr3ce48fMyqVZX0amezC4tJybiW/ura+sWkWtuqSJwKTGuaMi6aPJGE0IjVFFSPNWBAU+ow0/N7ZyG/cECEpj67VICZuiDoRDShGSkueWSg5KI4Fv/WcXj+9OB+WPLNola0x4Dyxp6RYyX58v+18kapnvjttjpOQRAozJGXLtmLlpkgoihkZ5p1EkhjhHuqQlqYRCol00/HpQ7ivlTYMuNAVKThWf0+kKJRyEPq6M0SqK2e9kfif10pUcOqmNIoTRSI8WRQkDCoORznANhUEKzbQBGFB9a0Qd5FAWOm08joEe/bleVI/LNvH5aMru1ixwAQ5sAv2wAGwwQmogEtQBTWAQR/cg0fwZNwZD8az8TJpzRjTmW3wB8brD3Apl9g=</latexit>â‡¡ED\n<latexit sha1_base64=\"dFpIVFMVUdWc7e0zJyAIhk9J788=\">AAAB+nicbVDLSsNAFJ20Pmp9pYorN4Ot4Kokgo9lQQWXFewDmhAm00k7dJIJMxNrif0UNy4UcesP+AsuBFd+ik4fC209cOFwzr3ce48fMyqVZX0amezC4tJybiW/ura+sWkWtuqSJwKTGuaMi6aPJGE0IjVFFSPNWBAU+ow0/N7ZyG/cECEpj67VICZuiDoRDShGSkueWSg5KI4Fv/WcXj+9OB+WPLNola0x4Dyxp6RYyX58v+18kapnvjttjpOQRAozJGXLtmLlpkgoihkZ5p1EkhjhHuqQlqYRCol00/HpQ7ivlTYMuNAVKThWf0+kKJRyEPq6M0SqK2e9kfif10pUcOqmNIoTRSI8WRQkDCoORznANhUEKzbQBGFB9a0Qd5FAWOm08joEe/bleVI/LNvH5aMru1ixwAQ5sAv2wAGwwQmogEtQBTWAQR/cg0fwZNwZD8az8TJpzRjTmW3wB8brD3Apl9g=</latexit>â‡¡ED=CPt.desc<latexit sha1_base64=\"l30SwooEmjZM4fGG1X7w2KxOGtk=\">AAACDXicbVC7SgNBFL2b+IjxtUasbBYTwSrsCj7KgBZiFcE8IFnC7GSSDJndWWZm1bDkB2z8FRsLRQQrewvByj8xTh6FJp5h4Mw593LnHi9kVCrb/jQSybn5hcXUUnp5ZXVt3dzIlCWPBCYlzBkXVQ9JwmhASooqRqqhIMj3GKl43ZOhX7kiQlIeXKpeSFwftQPaohgpLXEzAzmoA4JQHwEcbqCh3124hhjO4RT63wPINcysnbdHsGaJMyHZQvJj8Lr1RYoN873e5DjySaAwQ1LWHDtUboyEopiRfroeSRIi3EVtUtM0QD6Rbjzapm/taqVptbjQN1DWSP3dESNfyp7v6UofqY6c9obif14tUq1jN6ZBGCkS4PGgVsQsxa1hNFaTCoIV62mCsKD6rxbuIIGw0gGmdQjO9MqzpLyfdw7zBxdOtmDDGCnYhh3YAweOoABnUIQSYLiFe3iEJ+POeDCejZdxacKY9GzCHxhvP4BBmpY=</latexit>â‡¡JD\n<latexit sha1_base64=\"l30SwooEmjZM4fGG1X7w2KxOGtk=\">AAACDXicbVC7SgNBFL2b+IjxtUasbBYTwSrsCj7KgBZiFcE8IFnC7GSSDJndWWZm1bDkB2z8FRsLRQQrewvByj8xTh6FJp5h4Mw593LnHi9kVCrb/jQSybn5hcXUUnp5ZXVt3dzIlCWPBCYlzBkXVQ9JwmhASooqRqqhIMj3GKl43ZOhX7kiQlIeXKpeSFwftQPaohgpLXEzAzmoA4JQHwEcbqCh3124hhjO4RT63wPINcysnbdHsGaJMyHZQvJj8Lr1RYoN873e5DjySaAwQ1LWHDtUboyEopiRfroeSRIi3EVtUtM0QD6Rbjzapm/taqVptbjQN1DWSP3dESNfyp7v6UofqY6c9obif14tUq1jN6ZBGCkS4PGgVsQsxa1hNFaTCoIV62mCsKD6rxbuIIGw0gGmdQjO9MqzpLyfdw7zBxdOtmDDGCnYhh3YAweOoABnUIQSYLiFe3iEJ+POeDCejZdxacKY9GzCHxhvP4BBmpY=</latexit>â‡¡JDs.descCPt.desc<latexit sha1_base64=\"l30SwooEmjZM4fGG1X7w2KxOGtk=\">AAACDXicbVC7SgNBFL2b+IjxtUasbBYTwSrsCj7KgBZiFcE8IFnC7GSSDJndWWZm1bDkB2z8FRsLRQQrewvByj8xTh6FJp5h4Mw593LnHi9kVCrb/jQSybn5hcXUUnp5ZXVt3dzIlCWPBCYlzBkXVQ9JwmhASooqRqqhIMj3GKl43ZOhX7kiQlIeXKpeSFwftQPaohgpLXEzAzmoA4JQHwEcbqCh3124hhjO4RT63wPINcysnbdHsGaJMyHZQvJj8Lr1RYoN873e5DjySaAwQ1LWHDtUboyEopiRfroeSRIi3EVtUtM0QD6Rbjzapm/taqVptbjQN1DWSP3dESNfyp7v6UofqY6c9obif14tUq1jN6ZBGCkS4PGgVsQsxa1hNFaTCoIV62mCsKD6rxbuIIGw0gGmdQjO9MqzpLyfdw7zBxdOtmDDGCnYhh3YAweOoABnUIQSYLiFe3iEJ+POeDCejZdxacKY9GzCHxhvP4BBmpY=</latexit>â‡¡JD\n<latexit sha1_base64=\"l30SwooEmjZM4fGG1X7w2KxOGtk=\">AAACDXicbVC7SgNBFL2b+IjxtUasbBYTwSrsCj7KgBZiFcE8IFnC7GSSDJndWWZm1bDkB2z8FRsLRQQrewvByj8xTh6FJp5h4Mw593LnHi9kVCrb/jQSybn5hcXUUnp5ZXVt3dzIlCWPBCYlzBkXVQ9JwmhASooqRqqhIMj3GKl43ZOhX7kiQlIeXKpeSFwftQPaohgpLXEzAzmoA4JQHwEcbqCh3124hhjO4RT63wPINcysnbdHsGaJMyHZQvJj8Lr1RYoN873e5DjySaAwQ1LWHDtUboyEopiRfroeSRIi3EVtUtM0QD6Rbjzapm/taqVptbjQN1DWSP3dESNfyp7v6UofqY6c9obif14tUq1jN6ZBGCkS4PGgVsQsxa1hNFaTCoIV62mCsKD6rxbuIIGw0gGmdQjO9MqzpLyfdw7zBxdOtmDDGCnYhh3YAweOoABnUIQSYLiFe3iEJ+POeDCejZdxacKY9GzCHxhvP4BBmpY=</latexit>â‡¡JDs.desct.saddress<latexit sha1_base64=\"XbOjGFwrnUWiwS8qyNGIv7qzJSI=\">AAAB9XicbVDLSgMxFM20Pmp9VcWVm2AruCozgo9lQQWXFewD2rFk0kwbmklCklHL0P9w40IRt36Dv+BCcOWnaPpYaOuBC4dz7uXeewLJqDau++mk0nPzC4uZpezyyuraem5js6pFrDCpYMGEqgdIE0Y5qRhqGKlLRVAUMFILeqdDv3ZDlKaCX5m+JH6EOpyGFCNjpetCE0mpxF0rOT8bFFq5vFt0R4CzxJuQfCn98f22/UXKrdx7sy1wHBFuMENaNzxXGj9BylDMyCDbjDWRCPdQhzQs5Sgi2k9GVw/gnlXaMBTKFjdwpP6eSFCkdT8KbGeETFdPe0PxP68Rm/DETyiXsSEcjxeFMYNGwGEEsE0VwYb1LUFYUXsrxF2kEDY2qKwNwZt+eZZUD4reUfHw0suXXDBGBuyAXbAPPHAMSuAClEEFYKDAPXgET86t8+A8Oy/j1pQzmdkCf+C8/gCVTZZL</latexit>â‡¡ED\n<latexit sha1_base64=\"XbOjGFwrnUWiwS8qyNGIv7qzJSI=\">AAAB9XicbVDLSgMxFM20Pmp9VcWVm2AruCozgo9lQQWXFewD2rFk0kwbmklCklHL0P9w40IRt36Dv+BCcOWnaPpYaOuBC4dz7uXeewLJqDau++mk0nPzC4uZpezyyuraem5js6pFrDCpYMGEqgdIE0Y5qRhqGKlLRVAUMFILeqdDv3ZDlKaCX5m+JH6EOpyGFCNjpetCE0mpxF0rOT8bFFq5vFt0R4CzxJuQfCn98f22/UXKrdx7sy1wHBFuMENaNzxXGj9BylDMyCDbjDWRCPdQhzQs5Sgi2k9GVw/gnlXaMBTKFjdwpP6eSFCkdT8KbGeETFdPe0PxP68Rm/DETyiXsSEcjxeFMYNGwGEEsE0VwYb1LUFYUXsrxF2kEDY2qKwNwZt+eZZUD4reUfHw0suXXDBGBuyAXbAPPHAMSuAClEEFYKDAPXgET86t8+A8Oy/j1pQzmdkCf+C8/gCVTZZL</latexit>â‡¡EDs.saddressCP(a) order of predicates[ <latexit sha1_base64=\"TF/mViAogp3JwTtlkKPI4zJeqaQ=\">AAACcnicbVFdSxtBFJ1dtWrqR6r4oqBTY8GHEHZLq74IQQ1In1JoTCCJy+zsTRwyuzvMzKph2R/QP9Mf07f+Cl/03dlsKPHjwsC559zD/RhfcKa04/yz7Ln5hQ+LS8uljyura+vlTxtXKk4khRaNeSw7PlHAWQQtzTSHjpBAQp9D2x+d53r7FqRicfRLjwX0QzKM2IBRog3llX8fCK83uktVRELIrk+ruMiFZHQ2VyQIJCiVXac9IoSM7720cZFl/+sL//tiAIrWZsUfuVhokxVMowOvXHFqziTwW+BOQaWO17pnjac/Ta/8txfENAkh0pQTpbquI3Q/JVIzyiEr9RIFgtARGULXwHxA1Z/2w18ME+BBLM2LNJ6ws46UhEqNQ99UhkTfqNdaTr6ndRM9OOmnLBKJhogWjQYJxzrG+f1xwCRQzccGECqZmRXTGyIJ1eaXSuYI7uuV34KrrzX3qPb9p1upf0NFLKEdtI8OkYuOUR1doiZqIYoerC1r19qzHu1t+7NdKUpta+rZRC/Crj4DDI/DkQ==</latexit>p=sname,p=price,pâ‡¡EDsaddress,pâ‡¡EDpname,pâ‡¡JDdesc.,p=color\n<latexit sha1_base64=\"TF/mViAogp3JwTtlkKPI4zJeqaQ=\">AAACcnicbVFdSxtBFJ1dtWrqR6r4oqBTY8GHEHZLq74IQQ1In1JoTCCJy+zsTRwyuzvMzKph2R/QP9Mf07f+Cl/03dlsKPHjwsC559zD/RhfcKa04/yz7Ln5hQ+LS8uljyura+vlTxtXKk4khRaNeSw7PlHAWQQtzTSHjpBAQp9D2x+d53r7FqRicfRLjwX0QzKM2IBRog3llX8fCK83uktVRELIrk+ruMiFZHQ2VyQIJCiVXac9IoSM7720cZFl/+sL//tiAIrWZsUfuVhokxVMowOvXHFqziTwW+BOQaWO17pnjac/Ta/8txfENAkh0pQTpbquI3Q/JVIzyiEr9RIFgtARGULXwHxA1Z/2w18ME+BBLM2LNJ6ws46UhEqNQ99UhkTfqNdaTr6ndRM9OOmnLBKJhogWjQYJxzrG+f1xwCRQzccGECqZmRXTGyIJ1eaXSuYI7uuV34KrrzX3qPb9p1upf0NFLKEdtI8OkYuOUR1doiZqIYoerC1r19qzHu1t+7NdKUpta+rZRC/Crj4DDI/DkQ==</latexit>p=sname,p=price,pâ‡¡EDsaddress,pâ‡¡EDpname,pâ‡¡JDdesc.,p=color ]N1N0N2N3N4N5N6N7 <latexit sha1_base64=\"5g1JvHngDaC4fswNnexQGi4BvEw=\">AAAB+XicbVDLSsNAFL3xWavVWJdugq3QVUkKPjZCwY3LCvYBbQyT6bQdOpnEmUmlhH6Bv+DGhSLizj9xJ/6Mk7YLbT1w4XDOvdx7jx8xKpVtfxkrq2vrG5uZrez2Tm53z9zPN2QYC0zqOGShaPlIEkY5qSuqGGlFgqDAZ6TpDy9TvzkiQtKQ36hxRNwA9TntUYyUljzTLEZeZ3ifSI4CMrm9KHpmwS7bU1jLxJmTQjVf+n54v8vVPPOz0w1xHBCuMENSth07Um6ChKKYkUm2E0sSITxEfdLWNN0j3WR6+cQ61krX6oVCF1fWVP09kaBAynHg684AqYFc9FLxP68dq965m1AexYpwPFvUi5mlQiuNwepSQbBiY00QFlTfauEBEggrHVZWh+AsvrxMGpWyc1o+uXYK1QrMkIFDOIISOHAGVbiCGtQBwwge4RlejMR4Ml6Nt1nrijGfOYA/MD5+ACbNlkg=</latexit>p=sname\n<latexit sha1_base64=\"5g1JvHngDaC4fswNnexQGi4BvEw=\">AAAB+XicbVDLSsNAFL3xWavVWJdugq3QVUkKPjZCwY3LCvYBbQyT6bQdOpnEmUmlhH6Bv+DGhSLizj9xJ/6Mk7YLbT1w4XDOvdx7jx8xKpVtfxkrq2vrG5uZrez2Tm53z9zPN2QYC0zqOGShaPlIEkY5qSuqGGlFgqDAZ6TpDy9TvzkiQtKQ36hxRNwA9TntUYyUljzTLEZeZ3ifSI4CMrm9KHpmwS7bU1jLxJmTQjVf+n54v8vVPPOz0w1xHBCuMENSth07Um6ChKKYkUm2E0sSITxEfdLWNN0j3WR6+cQ61krX6oVCF1fWVP09kaBAynHg684AqYFc9FLxP68dq965m1AexYpwPFvUi5mlQiuNwepSQbBiY00QFlTfauEBEggrHVZWh+AsvrxMGpWyc1o+uXYK1QrMkIFDOIISOHAGVbiCGtQBwwge4RlejMR4Ml6Nt1nrijGfOYA/MD5+ACbNlkg=</latexit>p=sname <latexit sha1_base64=\"Iv9jd7FUi1GBWgJAmOoYm2zoPBY=\">AAACCHicbVDLSsNAFJ3UV1tf8YEbFwZbwVVJCj6WBV2Iqwr2AU0Mk8m0Dp0kw8xELSFLEfwVNy4UcesnuPNnxGnahbYeuHA4517uvcdjlAhpml9abmZ2bn4hXyguLi2vrOpr600RxRzhBopoxNseFJiSEDckkRS3Gccw8Chuef2Tod+6wVyQKLyUA4adAPZC0iUISiW5+k6ZuXb/NvGxQOlVYkPGeHSXSeenaVp29ZJZMTMY08Qak1Jta7NZKXw/1F390/YjFAc4lIhCITqWyaSTQC4Jojgt2rHADKI+7OGOoiEMsHCS7JHU2FOKb3QjriqURqb+nkhgIMQg8FRnAOW1mPSG4n9eJ5bdYychIYslDtFoUTemhoyMYSqGTzhGkg4UgYgTdauBriGHSKrsiioEa/LladKsVqzDysGFVapVwQh5sA12wT6wwBGogTNQBw2AwD14Ai/gVXvUnrU37X3UmtPGMxvgD7SPH8eXnK8=</latexit>pâ‡¡JDdesc\n<latexit sha1_base64=\"Iv9jd7FUi1GBWgJAmOoYm2zoPBY=\">AAACCHicbVDLSsNAFJ3UV1tf8YEbFwZbwVVJCj6WBV2Iqwr2AU0Mk8m0Dp0kw8xELSFLEfwVNy4UcesnuPNnxGnahbYeuHA4517uvcdjlAhpml9abmZ2bn4hXyguLi2vrOpr600RxRzhBopoxNseFJiSEDckkRS3Gccw8Chuef2Tod+6wVyQKLyUA4adAPZC0iUISiW5+k6ZuXb/NvGxQOlVYkPGeHSXSeenaVp29ZJZMTMY08Qak1Jta7NZKXw/1F390/YjFAc4lIhCITqWyaSTQC4Jojgt2rHADKI+7OGOoiEMsHCS7JHU2FOKb3QjriqURqb+nkhgIMQg8FRnAOW1mPSG4n9eJ5bdYychIYslDtFoUTemhoyMYSqGTzhGkg4UgYgTdauBriGHSKrsiioEa/LladKsVqzDysGFVapVwQh5sA12wT6wwBGogTNQBw2AwD14Ai/gVXvUnrU37X3UmtPGMxvgD7SPH8eXnK8=</latexit>pâ‡¡JDdesc <latexit sha1_base64=\"PeHupyS2eIydQEyXtcUv0ySz9Oo=\">AAACCXicbVDLSsNAFJ3UV1tf8YEbN4Ot4KokBR/LggouK9gHtDFMJtN26CQZZiZqCdnqwl9x40IRt/6BO39GnD4W2nrgwuGce7n3Ho8zKpVlfRmZufmFxaVsLr+8srq2bm5s1mUUC0xqOGKRaHpIEkZDUlNUMdLkgqDAY6Th9U+HfuOGCEmj8EoNOHEC1A1ph2KktOSasMjdRCLfF0TK9DppI85FdOe2+7fJ+VmaFl2zYJWsEeAssSekUNnZrpdy3w9V1/xs+xGOAxIqzJCULdviykmQUBQzkubbsSQc4T7qkpamIQqIdJLRJync14oPO5HQFSo4Un9PJCiQchB4ujNAqienvaH4n9eKVefESWjIY0VCPF7UiRlUERzGAn0qCFZsoAnCgupbIe4hgbDS4eV1CPb0y7OkXi7ZR6XDS7tQKYMxsmAX7IEDYINjUAEXoApqAIN78ARewKvxaDwbb8b7uDVjTGa2wB8YHz+vfJ0w</latexit>pâ‡¡EDsaddress\n<latexit sha1_base64=\"PeHupyS2eIydQEyXtcUv0ySz9Oo=\">AAACCXicbVDLSsNAFJ3UV1tf8YEbN4Ot4KokBR/LggouK9gHtDFMJtN26CQZZiZqCdnqwl9x40IRt/6BO39GnD4W2nrgwuGce7n3Ho8zKpVlfRmZufmFxaVsLr+8srq2bm5s1mUUC0xqOGKRaHpIEkZDUlNUMdLkgqDAY6Th9U+HfuOGCEmj8EoNOHEC1A1ph2KktOSasMjdRCLfF0TK9DppI85FdOe2+7fJ+VmaFl2zYJWsEeAssSekUNnZrpdy3w9V1/xs+xGOAxIqzJCULdviykmQUBQzkubbsSQc4T7qkpamIQqIdJLRJync14oPO5HQFSo4Un9PJCiQchB4ujNAqienvaH4n9eKVefESWjIY0VCPF7UiRlUERzGAn0qCFZsoAnCgupbIe4hgbDS4eV1CPb0y7OkXi7ZR6XDS7tQKYMxsmAX7IEDYINjUAEXoApqAIN78ARewKvxaDwbb8b7uDVjTGa2wB8YHz+vfJ0w</latexit>pâ‡¡EDsaddress <latexit sha1_base64=\"Iv9jd7FUi1GBWgJAmOoYm2zoPBY=\">AAACCHicbVDLSsNAFJ3UV1tf8YEbFwZbwVVJCj6WBV2Iqwr2AU0Mk8m0Dp0kw8xELSFLEfwVNy4UcesnuPNnxGnahbYeuHA4517uvcdjlAhpml9abmZ2bn4hXyguLi2vrOpr600RxRzhBopoxNseFJiSEDckkRS3Gccw8Chuef2Tod+6wVyQKLyUA4adAPZC0iUISiW5+k6ZuXb/NvGxQOlVYkPGeHSXSeenaVp29ZJZMTMY08Qak1Jta7NZKXw/1F390/YjFAc4lIhCITqWyaSTQC4Jojgt2rHADKI+7OGOoiEMsHCS7JHU2FOKb3QjriqURqb+nkhgIMQg8FRnAOW1mPSG4n9eJ5bdYychIYslDtFoUTemhoyMYSqGTzhGkg4UgYgTdauBriGHSKrsiioEa/LladKsVqzDysGFVapVwQh5sA12wT6wwBGogTNQBw2AwD14Ai/gVXvUnrU37X3UmtPGMxvgD7SPH8eXnK8=</latexit>pâ‡¡JDdesc\n<latexit sha1_base64=\"Iv9jd7FUi1GBWgJAmOoYm2zoPBY=\">AAACCHicbVDLSsNAFJ3UV1tf8YEbFwZbwVVJCj6WBV2Iqwr2AU0Mk8m0Dp0kw8xELSFLEfwVNy4UcesnuPNnxGnahbYeuHA4517uvcdjlAhpml9abmZ2bn4hXyguLi2vrOpr600RxRzhBopoxNseFJiSEDckkRS3Gccw8Chuef2Tod+6wVyQKLyUA4adAPZC0iUISiW5+k6ZuXb/NvGxQOlVYkPGeHSXSeenaVp29ZJZMTMY08Qak1Jta7NZKXw/1F390/YjFAc4lIhCITqWyaSTQC4Jojgt2rHADKI+7OGOoiEMsHCS7JHU2FOKb3QjriqURqb+nkhgIMQg8FRnAOW1mPSG4n9eJ5bdYychIYslDtFoUTemhoyMYSqGTzhGkg4UgYgTdauBriGHSKrsiioEa/LladKsVqzDysGFVapVwQh5sA12wT6wwBGogTNQBw2AwD14Ai/gVXvUnrU37X3UmtPGMxvgD7SPH8eXnK8=</latexit>pâ‡¡JDdesc <latexit sha1_base64=\"qpPxk5lQ7nCRBNUUxb21xYBuMtE=\">AAAB+XicbVDJSgNBEK1xjXEbl5uXxkTIKcwEXC5CQA9ehAhmgWQcejo9SZOehe6eSBjyJ148KOLVH/AbvHn2NzzYWQ6a+KDg8V5VV9fzYs6ksqxPY2FxaXllNbOWXd/Y3No2d3ZrMkoEoVUS8Ug0PCwpZyGtKqY4bcSC4sDjtO71LkZ+vU+FZFF4qwYxdQLcCZnPCFZack0zH7ut3n06fml4d553zZxVtMZA88Seklx5//2ycP39VXHNj1Y7IklAQ0U4lrJpW7FyUiwUI5wOs61E0hiTHu7QpqYhDqh0pvvQkVbayI+ErlChsfp7IsWBlIPA050BVl05643E/7xmovwzJ2VhnCgakskiP+FIRWgUA2ozQYniA00wEUz/FZEuFpgoHVZWh2DPnjxPaqWifVI8vrFz5RJMkIEDOIQC2HAKZbiCClSBQB8e4AmejdR4NF6M10nrgjGd2YM/MN5+AA6llvU=</latexit>p=color\n<latexit sha1_base64=\"qpPxk5lQ7nCRBNUUxb21xYBuMtE=\">AAAB+XicbVDJSgNBEK1xjXEbl5uXxkTIKcwEXC5CQA9ehAhmgWQcejo9SZOehe6eSBjyJ148KOLVH/AbvHn2NzzYWQ6a+KDg8V5VV9fzYs6ksqxPY2FxaXllNbOWXd/Y3No2d3ZrMkoEoVUS8Ug0PCwpZyGtKqY4bcSC4sDjtO71LkZ+vU+FZFF4qwYxdQLcCZnPCFZack0zH7ut3n06fml4d553zZxVtMZA88Seklx5//2ycP39VXHNj1Y7IklAQ0U4lrJpW7FyUiwUI5wOs61E0hiTHu7QpqYhDqh0pvvQkVbayI+ErlChsfp7IsWBlIPA050BVl05643E/7xmovwzJ2VhnCgakskiP+FIRWgUA2ozQYniA00wEUz/FZEuFpgoHVZWh2DPnjxPaqWifVI8vrFz5RJMkIEDOIQC2HAKZbiCClSBQB8e4AmejdR4NF6M10nrgjGd2YM/MN5+AA6llvU=</latexit>p=color <latexit sha1_base64=\"d9be49L7dcsJyNQg4HAyVu1bE8c=\">AAACCXicbVC7SgNBFJ31GeMraplmMBGswm7ARxlQwTKCeUA2LrOTSTJkdnaYmVXDsq2N/oadjYWigpV/YOeH2Dt5FJp44MLhnHu59x5fMKq0bX9ZM7Nz8wuLqaX08srq2npmY7OqwkhiUsEhC2XdR4owyklFU81IXUiCAp+Rmt87Gvi1SyIVDfm57gvSDFCH0zbFSBvJy8C88NzeVSw4CkhyEbtICBleD7WT4yTJe5mcXbCHgNPEGZNcKft9/+rfvZe9zKfbCnEUEK4xQ0o1HFvoZoykppiRJO1GigiEe6hDGoYO9qpmPPwkgTtGacF2KE1xDYfq74kYBUr1A990Bkh31aQ3EP/zGpFuHzZjykWkCcejRe2IQR3CQSywRSXBmvUNQVhScyvEXSQR1ia8tAnBmXx5mlSLBWe/sHfm5EpFMEIKZME22AUOOAAlcArKoAIwuAEP4Ak8W7fWo/VivY1aZ6zxzBb4A+vjByKXnwM=</latexit>pâ‡¡EDpname\n<latexit sha1_base64=\"d9be49L7dcsJyNQg4HAyVu1bE8c=\">AAACCXicbVC7SgNBFJ31GeMraplmMBGswm7ARxlQwTKCeUA2LrOTSTJkdnaYmVXDsq2N/oadjYWigpV/YOeH2Dt5FJp44MLhnHu59x5fMKq0bX9ZM7Nz8wuLqaX08srq2npmY7OqwkhiUsEhC2XdR4owyklFU81IXUiCAp+Rmt87Gvi1SyIVDfm57gvSDFCH0zbFSBvJy8C88NzeVSw4CkhyEbtICBleD7WT4yTJe5mcXbCHgNPEGZNcKft9/+rfvZe9zKfbCnEUEK4xQ0o1HFvoZoykppiRJO1GigiEe6hDGoYO9qpmPPwkgTtGacF2KE1xDYfq74kYBUr1A990Bkh31aQ3EP/zGpFuHzZjykWkCcejRe2IQR3CQSywRSXBmvUNQVhScyvEXSQR1ia8tAnBmXx5mlSLBWe/sHfm5EpFMEIKZME22AUOOAAlcArKoAIwuAEP4Ak8W7fWo/VivY1aZ6zxzBb4A+vjByKXnwM=</latexit>pâ‡¡EDpname <latexit sha1_base64=\"JkedI8B6/EvZulkXw1DQlrijjoU=\">AAAB+XicbVDLSsNAFL2pr1pfUZduBlvBVUkKPjZCwY3LCvYBbQyT6aQdOpmEmUmlhP6JGxeKuPVP3Pk3TtsstPXAhcM593LvPUHCmdKO820V1tY3NreK26Wd3b39A/vwqKXiVBLaJDGPZSfAinImaFMzzWknkRRHAaftYHQ789tjKhWLxYOeJNSL8ECwkBGsjeTbdiXxe6OnLJGM0OnjTcW3y07VmQOtEjcnZcjR8O2vXj8maUSFJhwr1XWdRHsZlpoRTqelXqpogskID2jXUIEjqrxsfvkUnRmlj8JYmhIazdXfExmOlJpEgemMsB6qZW8m/ud1Ux1eexkTSaqpIItFYcqRjtEsBtRnkhLNJ4ZgIpm5FZEhlphoE1bJhOAuv7xKWrWqe1m9uK+V67U8jiKcwCmcgwtXUIc7aEATCIzhGV7hzcqsF+vd+li0Fqx85hj+wPr8AQ9Dkz4=</latexit>p=price\n<latexit sha1_base64=\"JkedI8B6/EvZulkXw1DQlrijjoU=\">AAAB+XicbVDLSsNAFL2pr1pfUZduBlvBVUkKPjZCwY3LCvYBbQyT6aQdOpmEmUmlhP6JGxeKuPVP3Pk3TtsstPXAhcM593LvPUHCmdKO820V1tY3NreK26Wd3b39A/vwqKXiVBLaJDGPZSfAinImaFMzzWknkRRHAaftYHQ789tjKhWLxYOeJNSL8ECwkBGsjeTbdiXxe6OnLJGM0OnjTcW3y07VmQOtEjcnZcjR8O2vXj8maUSFJhwr1XWdRHsZlpoRTqelXqpogskID2jXUIEjqrxsfvkUnRmlj8JYmhIazdXfExmOlJpEgemMsB6qZW8m/ud1Ux1eexkTSaqpIItFYcqRjtEsBtRnkhLNJ4ZgIpm5FZEhlphoE1bJhOAuv7xKWrWqe1m9uK+V67U8jiKcwCmcgwtXUIc7aEATCIzhGV7hzcqsF+vd+li0Fqx85hj+wPr8AQ9Dkz4=</latexit>p=price <latexit sha1_base64=\"Ji8kvhlHuXxsXnxOoDYpyo11oPM=\">AAAB8nicbZDLSgMxFIYz9VZr1apLQQZbwVWZKXhZFty4bMFeYDqUTJppQzPJkJwplKFLH8GNC0Xc+gB9Dnc+gy9hello6w+Bj/8/h5xzgpgzDY7zZWU2Nre2d7K7ub38/sFh4ei4qWWiCG0QyaVqB1hTzgRtAANO27GiOAo4bQXDu1neGlGlmRQPMI6pH+G+YCEjGIzllTojrOIB67qlbqHolJ257HVwl1Cs5qf178ezaa1b+Oz0JEkiKoBwrLXnOjH4KVbACKeTXCfRNMZkiPvUMyhwRLWfzkee2BfG6dmhVOYJsOfu744UR1qPo8BURhgGejWbmf9lXgLhrZ8yESdABVl8FCbcBmnP9rd7TFECfGwAE8XMrDYZYIUJmCvlzBHc1ZXXoVkpu9flq7pbrFbQQll0is7RJXLRDaqie1RDDUSQRE/oBb1aYD1bb9b7ojRjLXtO0B9ZHz83rJQ4</latexit>'1\n<latexit sha1_base64=\"Ji8kvhlHuXxsXnxOoDYpyo11oPM=\">AAAB8nicbZDLSgMxFIYz9VZr1apLQQZbwVWZKXhZFty4bMFeYDqUTJppQzPJkJwplKFLH8GNC0Xc+gB9Dnc+gy9hello6w+Bj/8/h5xzgpgzDY7zZWU2Nre2d7K7ub38/sFh4ei4qWWiCG0QyaVqB1hTzgRtAANO27GiOAo4bQXDu1neGlGlmRQPMI6pH+G+YCEjGIzllTojrOIB67qlbqHolJ257HVwl1Cs5qf178ezaa1b+Oz0JEkiKoBwrLXnOjH4KVbACKeTXCfRNMZkiPvUMyhwRLWfzkee2BfG6dmhVOYJsOfu744UR1qPo8BURhgGejWbmf9lXgLhrZ8yESdABVl8FCbcBmnP9rd7TFECfGwAE8XMrDYZYIUJmCvlzBHc1ZXXoVkpu9flq7pbrFbQQll0is7RJXLRDaqie1RDDUSQRE/oBb1aYD1bb9b7ojRjLXtO0B9ZHz83rJQ4</latexit>'1 <latexit sha1_base64=\"zFODwHohs9ZtkxN17aKfuNUMfvo=\">AAAB8nicbZDLSgMxFIbP1FutVasuBRlsBVdlpuBlWXDjsgV7gelQMmmmDc0kQ5IplKFLH8GNC0Xc+gB9Dnc+gy9hello6w+Bj/8/h5xzgphRpR3ny8psbG5t72R3c3v5/YPDwtFxU4lEYtLAggnZDpAijHLS0FQz0o4lQVHASCsY3s3y1ohIRQV/0OOY+BHqcxpSjLSxvFJnhGQ8oN1KqVsoOmVnLnsd3CUUq/lp/fvxbFrrFj47PYGTiHCNGVLKc51Y+ymSmmJGJrlOokiM8BD1iWeQo4goP52PPLEvjNOzQyHN49qeu787UhQpNY4CUxkhPVCr2cz8L/MSHd76KeVxognHi4/ChNla2LP97R6VBGs2NoCwpGZWGw+QRFibK+XMEdzVldehWSm71+WrulusVmChLJzCOVyCCzdQhXuoQQMwCHiCF3i1tPVsvVnvi9KMtew5gT+yPn4AOTGUOQ==</latexit>'2\n<latexit sha1_base64=\"zFODwHohs9ZtkxN17aKfuNUMfvo=\">AAAB8nicbZDLSgMxFIbP1FutVasuBRlsBVdlpuBlWXDjsgV7gelQMmmmDc0kQ5IplKFLH8GNC0Xc+gB9Dnc+gy9hello6w+Bj/8/h5xzgphRpR3ny8psbG5t72R3c3v5/YPDwtFxU4lEYtLAggnZDpAijHLS0FQz0o4lQVHASCsY3s3y1ohIRQV/0OOY+BHqcxpSjLSxvFJnhGQ8oN1KqVsoOmVnLnsd3CUUq/lp/fvxbFrrFj47PYGTiHCNGVLKc51Y+ymSmmJGJrlOokiM8BD1iWeQo4goP52PPLEvjNOzQyHN49qeu787UhQpNY4CUxkhPVCr2cz8L/MSHd76KeVxognHi4/ChNla2LP97R6VBGs2NoCwpGZWGw+QRFibK+XMEdzVldehWSm71+WrulusVmChLJzCOVyCCzdQhXuoQQMwCHiCF3i1tPVsvVnvi9KMtew5gT+yPn4AOTGUOQ==</latexit>'2 <latexit sha1_base64=\"CIpYGtWyEP4aTAxxgBAHxKIljD8=\">AAAB8nicbZDLSgMxFIYzXmutWnUpSLAVXJWZipdlwY3LFuwFpkPJpJk2NJMZkjOFMnTpI7hxoYhbH6DP4c5n8CVMLwtt/SHw8f/nkHOOHwuuwba/rLX1jc2t7cxOdje3t3+QPzxq6ChRlNVpJCLV8olmgktWBw6CtWLFSOgL1vQHd9O8OWRK80g+wChmXkh6kgecEjCWW2wPiYr7vHNZ7OQLdsmeCa+Cs4BCJTepfT+eTqqd/Ge7G9EkZBKoIFq7jh2DlxIFnAo2zrYTzWJCB6THXIOShEx76WzkMT43ThcHkTJPAp65vztSEmo9Cn1TGRLo6+Vsav6XuQkEt17KZZwAk3T+UZAIDBGe7o+7XDEKYmSAUMXNrJj2iSIUzJWy5gjO8sqr0CiXnOvSVc0pVMporgw6QWfoAjnoBlXQPaqiOqIoQk/oBb1aYD1bb9b7vHTNWvQcoz+yPn4AOraUOg==</latexit>'3\n<latexit sha1_base64=\"CIpYGtWyEP4aTAxxgBAHxKIljD8=\">AAAB8nicbZDLSgMxFIYzXmutWnUpSLAVXJWZipdlwY3LFuwFpkPJpJk2NJMZkjOFMnTpI7hxoYhbH6DP4c5n8CVMLwtt/SHw8f/nkHOOHwuuwba/rLX1jc2t7cxOdje3t3+QPzxq6ChRlNVpJCLV8olmgktWBw6CtWLFSOgL1vQHd9O8OWRK80g+wChmXkh6kgecEjCWW2wPiYr7vHNZ7OQLdsmeCa+Cs4BCJTepfT+eTqqd/Ge7G9EkZBKoIFq7jh2DlxIFnAo2zrYTzWJCB6THXIOShEx76WzkMT43ThcHkTJPAp65vztSEmo9Cn1TGRLo6+Vsav6XuQkEt17KZZwAk3T+UZAIDBGe7o+7XDEKYmSAUMXNrJj2iSIUzJWy5gjO8sqr0CiXnOvSVc0pVMporgw6QWfoAjnoBlXQPaqiOqIoQk/oBb1aYD1bb9b7vHTNWvQcoz+yPn4AOraUOg==</latexit>'30.040.040.080.0480.0480.0480.08Figure 4: Execution tree\nsp(ğ‘,ğ·)=norm(ï¸âŒœâƒ“â·\n1\nğ‘˜ğ‘˜âˆ‘ï¸‚\nğ‘–=1(ğ‘ğ‘–âˆ’|ğ·|\nğ‘˜)2)ï¸\nOrdering scheme. Putting these together, we can order all the\npredicatesğ‘inPby the cost-effectiveness, defined to be1âˆ’sp(ğ‘,ğ·)\ncostË†(ğ‘,ğ·).\nIntuitively, hard-to-satisfied predicates will be evaluated first, since\nthey are more likely to fail a rule, while costly predicates will be\npenalized, to strike a balance between the cost and the effectiveness.\nExample 6: Consider two predicates ğ‘=\ncolorandğ‘â‰ˆEDpname inğœ‘1. On\nthe one hand, since ğ‘=\ncoloris an equality comparison while ğ‘â‰ˆEDpname\ncomputes the edit distance, ğ‘â‰ˆEDpname is more costly to evaluate, e.g.,\ncostË†(ğ‘=\ncolor,ğ·)=0.1<costË†(ğ‘â‰ˆEDpname,ğ·)=0.6. On the other hand,\nsince all tuples in ğ·have the same color (and satisfy ğ‘=\ncolor), we\nhave sp(ğ‘=\ncolor,ğ·)=1; similarly, let sp(ğ‘â‰ˆEDpname,ğ·)=0.4. Then the\ncost-effectiveness of ğ‘=\ncolorandğ‘â‰ˆEDpname are1âˆ’1\n0.1=0and1âˆ’0.2\n1=0.8,\nrespectively, and ğ‘â‰ˆEDpname is ordered before ğ‘=\ncolor(see Figure 4(a)). â–¡\nConstructing an execution tree. We initialize the execution tree\nTwith a single root node ğ‘0. Then based on the predicate ordering,\nwe progressively construct Tby processing the MDs inÎ”one by\none. For each MDğœ‘:ğ‘‹â†’ğ‘™âˆˆÎ”, we assume the predicates in\nğ‘‹are sorted in the descending order of their cost-effectiveness,\ni.e.,ifğ‘‹isğ‘1âˆ§ğ‘2âˆ§...âˆ§ğ‘|ğ‘‹|, then1âˆ’sp(ğ‘ğ‘–,ğ·)\ncostË†(ğ‘ğ‘–,ğ·)>1âˆ’sp(ğ‘ğ‘—,ğ·)\ncostË†(ğ‘ğ‘—,ğ·)for\n1â‰¤ğ‘–<ğ‘—â‰¤|ğ‘‹|. We traverseT, starting from the root, and process\nthe predicates in ğ‘‹, starting from ğ‘1. Suppose that the traversal is\nat a nodeğ‘and the predicate we are processing is ğ‘ğ‘–. We check\nthe children of ğ‘. If there exists a child node ğ‘ğ‘ofğ‘such that the\nedge(ğ‘,ğ‘ğ‘)representsğ‘ğ‘–, we move to this child and process the\nnext predicate ğ‘ğ‘–+1inğ‘‹. Otherwise, we create a new child node\nğ‘ğ‘forğ‘such that the edge (ğ‘,ğ‘ğ‘)representsğ‘ğ‘–, move to this\nnew child and process the next predicate ğ‘ğ‘–+1inğ‘‹. The traversal\nprocess continues until all predicates in ğ‘‹are processed and we set\nthe current node we reach as a leaf node, whose associated rule is ğœ‘.\nExample 7: The predicate ordering is shown in Figure 4(a). Assume\nthat we have processed ğœ‘1and created path(ğ‘0,ğ‘1,ğ‘2,ğ‘3,ğ‘4)in\nTin Figure 4(b). Then we show how ğœ‘2:ğ‘=snameâˆ§ğ‘â‰ˆJD\ndescriptionâ†’ğ‘™\nis processed. We start from the root and process ğ‘=sname . Since there\nis a childğ‘1of root labeled ğ‘=sname , we move to ğ‘1and process\nğ‘â‰ˆJD\ndescription. Since there is no child of ğ‘1labeledğ‘â‰ˆJD\ndescription, we cre-\nate a newğ‘5and label(ğ‘1,ğ‘5)asğ‘â‰ˆJD\ndescription. Since all predicates\ninğœ‘2are processed, ğ‘5is a leaf node, whose associated rule is ğœ‘2.â–¡\n\nIntuitively, given(ğ‘¡1,ğ‘¡2)andğœ‘âˆˆÎ”, ifğœ‘is more likely to be a\nwitness at(ğ‘¡1,ğ‘¡2), it should be evaluated earlier. Motivated by this,\nwe compute the probability for ğœ‘:ğ‘‹â†’ğ‘™to be a witness on ğ·as:\nwp(ğœ‘,ğ·)=âˆï¸‚\nğ‘âˆˆğ‘‹sp(ğ‘,ğ·)\nif we assume the satisfaction of predicates as independent events;\nintuitively, if all predicates in ğ‘‹are satisfied, ğœ‘is a witness. If this\ndoes not hold, we can reuse historical logs and estimate wp(ğœ‘,ğ·),\nto be the proportion of historical pairs such that ğœ‘is a witness. Since\nthe evaluation of MDs inÎ”is guided by edge scores during DFS on\nT, below we define the score of a given edge ğ‘’based on wp(ğœ‘,ğ·).\nEdge score. For each MDğœ‘, we denote by ğœŒğœ‘the path ofTfrom root\nto the leaf whose associated MDisğœ‘. We compute the set of MDs\nğœ‘inÎ”such that the given edge ğ‘’is part ofğœŒğœ‘and denote it by Î¨ğ‘’,\ni.e.,Î¨ğ‘’={ğœ‘âˆˆÎ”|ğ‘’is part ofğœŒğœ‘}. The score of edge ğ‘’isscore(ğ‘’)=\nmaxğœŒğœ‘âˆˆÎ¨ğ‘’wp(ğœ‘,ğ·). This said, edges leading to promising MDs\nwill have high scores and thus, will be explored early via DFS on T.\nExample 8: Letsp(ğ‘=sname,ğ·)=0.4andsp(ğ‘â‰ˆJD\ndescription,ğ·)=0.2.\nThen wp(ğœ‘2,ğ·)=0.4Ã—0.2=0.08. Assume that we also compute\nwp(ğœ‘1,ğ·)=0.048. Then the score of edge ğ‘’=(ğ‘0,ğ‘1)ismax{\nwp(ğœ‘1,ğ·),wp(ğœ‘2,ğ·)}= 0.08, since ğ‘’is part of both ğœŒğœ‘1andğœŒğœ‘2.â–¡\nComplexity. It takes EPG ğ‘‚(ğ‘unit|P|+|P| log(|P|)+|ğœ‘||Î”|)time\nto generate the execution plan, where ğ‘unitis the unit time for com-\nputing the cost-effectiveness of a predicate. This is because the pred-\nicate ordering can be obtained in ğ‘‚(ğ‘unit|P|+|P| log(|P|)) time\nand the tree can be constructed in (|ğœ‘||Î”|)time, by scanning Î”once.\nRemark. As a by-product of ensuring the predicate ordering and\nDFS tree traversal, we can reuse the evaluation results of common\nâ€œprefixâ€ predicates ( i.e.,common predecessors in T). Moreover, if a\ntuple pair fails to satisfy the predicate associated with edge (ğ‘,ğ‘ğ‘)\ninT, the evaluation of all descendants of ğ‘ğ‘is bypassed directly.\nExample 9: We evaluateTin Figure 4(b) for(ğ‘¡1,ğ‘¡5)inğ·. After\nevaluatingğ‘=sname , we find that â„(ğ‘¡1,ğ‘¡5)Ì¸|=ğ‘â‰ˆJD\ndescriptionand thus we\ncannot move to ğ‘5. Then DFS will return back to ğ‘1and continue to\ncheck unexplored children of ğ‘1(i.e.,ğ‘2). In this way, the common\nâ€œprefixâ€ predicate ğ‘=sname ofğœ‘1andğœ‘2is only evaluated once. â–¡\n5 OPTIMIZATIONS AND SCHEDULING\nAs remarked earlier, GPUs adopt SIMT execution, where a thread is\nidle if other threads take longer ( i.e.,thread divergence). Below are\nsources of divergence (some are specific to rule-based blocking).\nâ—¦Conditional statements. GPUs may execute different paths in con-\nditional statements (Section 2), e.g.,one pair may be quickly iden-\ntified as a potential match if the first MDchecked is its witness,\nwhile another is found as a mismatch until all MDs are iterated.\nâ—¦Data-dependent execution. The execution depends on the data\nbeing processed, e.g.,even for the same predicate, the evaluation\ntime on different tuples is different ( e.g.,long vs. short text).\nâ—¦Imbalanced workloads. If the workload assigned to each thread\nis not evenly distributed, some may complete faster than others.\nWhile thread divergence is a general issue in GPU-programming,\nrule-based blocking offers some unique opportunities to mitigateit,e.g.,the evaluations of distinct pairs are often independent tasks,\nmaking it possible to (a) assign approximately equal tasks to threads,\nto enable workload balancing , and (b) â€œstealâ€ tasks from other\nthreads, to cope with different execution paths anddata-dependent\nexecution . Below we present the hardware-aware optimization\nand scheduling techniques that exploit GPU characteristics for\nmassive parallelism, including: (a) efficient device execution of an\nexecution plan (Section 5.1), (b) strategies to mitigate divergence\n(Section 5.2), (c) collaboration of multiple GPUs (Section 5.3).\n5.1 Execution plan on GPUs\nThe execution plan T, initially generated on CPUs, will undergo the\nevaluation on GPUs in a DFS manner. However, DFS tree traversal is\ntypically recursively implemented, which is not efficient on GPUs. It\nmay exacerbate divergence since each call adds a recursive function\nto the stack and incurs message payloads (see Section 6). Moreover,\nalthough we can reuse â€œprefixâ€ predicates via DFS, some predicates\nmay still be evaluated repeatedly, e.g.,ğ‘â‰ˆJD\ndescriptioninğœ‘2andğœ‘3.\nOptimized structures are required to harness the power of GPUs.\nTree traversal on GPUs. Note that upon completion of the tree\nconstruction, the evaluation order is fixed. Thus the DFS traversal\nof the tree on CPUs can be translated to a sequential execution path ,\nwhich is an ordered list of predicates, on GPUs (see Figure 4(c) for\nthe sequential execution path of the tree in Example 5).\nWe maintain two structures for each predicate ğ‘in the execution\npath: an index buffer and a function pointer buffer, which store the\nindices of attributes compared in ğ‘, and the function pointer of the\ncomparison operator in ğ‘, respectively, e.g.,for predicate ğ‘=sname :\nğ‘¡.sname =ğ‘ .sname , its comparison operator is â€œ=â€ and its attribute\nindex is 3 since sname is the 3rd attribute in schema Products . In\naddition, at the end of each rule, we set a checkpoint ( CP). When\na GPU thread encounters a CP, it knows that the undergoing tuple\npair satisfies a rule and it can skip the subsequent computation.\nReusing computation. To avoid repeated evaluation, we addi-\ntionally maintain a bitmap for all predicates on GPUs. The bit of a\npredicateğ‘is set to true if ğ‘has been evaluated. If this is the case,\nwe can directly reuse previous results. This bitmap can also be used\nfor symmetric predicates ( i.e.,â„(ğ‘¡1,ğ‘¡2)|=ğ‘iffâ„(ğ‘¡2,ğ‘¡1)|=ğ‘).\nNote that to be general, we do not make the assumption that a\nwitnessğœ‘at(ğ‘¡1,ğ‘¡2)is also a witness at (ğ‘¡2,ğ‘¡1), due to, e.g.,asym-\nmetric similarity comparison (Section 2). However, we can extend\nHyperBlocker if such assumption holds, by maintaining a bitmap to\navoid repeated evaluation for (ğ‘¡2,ğ‘¡1)if(ğ‘¡1,ğ‘¡2)is already evaluated.\n5.2 Divergence mitigation strategies\nTo further mitigate divergence, we propose two GPU-oriented\nstrategies, namely parallel sliding windows (PSW) andtask-stealing .\nParallel sliding windows (PSW). Given a partition ğ‘ƒ, PSW pro-\ncesses it with only a few index jumps; it also helps GPUs evenly\ndistribute workloads across SMs. Specifically, PSW works in 3 steps:\n(1) We divide ğ‘ƒinto|ğ‘ƒ|\nğ‘›ğ‘¡intervals, where each interval consists of\nğ‘›ğ‘¡tuples. These intervals are processed with a fixed-size window,\nwhich slides the intervals from left to right. Within each window, we\nassign an interval to a Thread Block (TB) with warps of 32 threads;\neach thread in the TB is responsible for a tuple ğ‘¡ğ‘–in the interval.\n\nInterval 2TB 1TB 21|P|1Interval 1Interval 3TB 3Interval 5TB 1TB 2Interval 4Interval 6TB 3Interval 8TB 1TB 2Interval 7Interval 9TB 3Sliding window 1Sliding window 2Sliding window 3|P|Figure 5: Parallel sliding windows\n(2) Assume that a thread is responsible for tuple ğ‘¡ğ‘–. Then this thread\ncomparesğ‘¡ğ‘–with all the other tuples, say ğ‘¡ğ‘—, inğ‘ƒaccording to the\nexecution planTand decides whether (ğ‘¡ğ‘–,ğ‘¡ğ‘—)is a potential match.\n(3) When all threads of a TB finish, this TB writes the results back\nto the host memory and it will move on to process the next interval\nin the next sliding window until the window reaches the end.\nNote that in total, it requires|ğ‘ƒ|\nğ‘›ğ‘¡ğ‘›ğ‘¤sequential index jumps for\neach TB, where ğ‘›ğ‘¤is the size of the sliding window.\nExample 10: As shown in Figure 5, a data partition ğ‘ƒis divided\n9 intervals and the size of the sliding window is 3 ( i.e.,ğ‘›ğ‘¤=3).\nInterval 1 is assigned to TB1, where each thread in TB1 will compare\na tuple in Interval 1 with all other tuples in ğ‘ƒ. When all threads of\nTB1 finish evaluation, TB1 moves on to process Interval 4. â–¡\nTask-stealing. Although each TB will process roughly equal inter-\nvals, the execution time of different intervals is not the same, due\nto conditional statements and data-dependent execution remarked\nearlier. This said, the workloads of all TBs can still be imbalanced.\nExample 11: Continuing Example 10, three TBs process 9 intervals\nin Figure 6(a). Even though each TB is assigned 3 intervals, the exe-\ncution times can still skew, e.g.,the total time units required by TB1\nand TB3 are 10 and 3, respectively, i.e.,TB3 is idle for 7 time units. â–¡\nBelow we introduce both the inter-interval and intra-interval\ntask-stealing strategies to further balance the workloads.\nInter-interval task-stealing . It is commonly observed that the exe-\ncution times of some TBs are longer than the others. In this case, a\nlarge number of TBs are idle, waiting for the slowest TB.\nIn light of this, we employ an inter-interval task-stealing strategy.\nSpecifically, we maintain a bitmap in global memory, where each\nbit indicates the status of an interval, so that TBs can steal not-yet-\nprocessed intervals from each other. Each TB processes intervals\nin two stages: (a) It first processes its assigned intervals one by one.\nWhenever a TB starts to process an interval, the bitmap is checked. If\nthe bit of the interval is false ( i.e.,not yet processed), it processes this\ninterval and sets the bit true. (b) If this TB is idle after finishing all as-\nsigned intervals, it traverses the bitmap to steal a not-yet-processed\ninterval, by setting the corresponding bit true and processing that\ninterval. Other TBs will skip an interval if it has been stolen.\nExample 12: In Example 11, TB3 finishes its assigned intervals\nafter 3 time units. Then it checks the bitmap and steals Interval 4;\nsimilarly for TB2. Compared with the time in Figure 6(a), the total\ntime units are reduced from 10 to 7 after stealing in Figure 6(b). â–¡\nIntra-interval task-stealing. Recall that a thread for ğ‘¡ğ‘–will compare\nğ‘¡ğ‘–with other tuples in ğ‘ƒ. Since the evaluation of distinct pairs is inde-\npendent, we can even steal tasks from executing intervals. To facili-\ntate this, we maintain two integers start andend, initialized to 1 and\n|ğ‘ƒ|, respectively, indicating the remaining range of tuples to be com-\nTime unitTB 1TB 2TB 3IDLEIDLEIDLEIDLEIDLEIDLEIDLEIDLEIDLEIDLEIDLETB 1TB 2TB 3123456789123456Time unit\nIDLEIDLE710TB 1TB 2TB 3123456Time unit(a) Intuitive approach(b) Iter-interval task stealing(c) Intra-interval task stealingEvaluate the cartesian  product between IntervalX and P  IDLEIDLEIDLEIDLEIDLEInterval 2Interval 3Interval 6Interval 9Interval 1Interval 7Interval 4Interval XInterval 8Interval 5Interval 2Interval 8Interval 5Interval 3Interval 6Interval 9Interval 1Interval 7Interval 4Interval 3Interval 6Interval 9Interval 4Interval 1Interval 2Interval 8Interval 5Interval 7Interval 7Figure 6: Task-stealing\npared withğ‘¡ğ‘–. Then this thread starts to evaluate (ğ‘¡ğ‘–,ğ‘¡start). Upon\ncompletion, it sets start=start+1and moves on to the next pair (ğ‘¡ğ‘–,\nğ‘¡start). When start=end, this thread finishes all evaluation for ğ‘¡ğ‘–.\nBased on this, the intra-interval task-stealing works as follows.\nIf TBğ‘finishes all assigned intervals and there are no not-yet-\nprocessed intervals, it finds an executing TB ğ‘and iterates all threads\nin TBğ‘, so that the ğ‘–-th thread in TB ğ‘steals half workload ( i.e.,half\npairs to be compared) from the ğ‘–-th thread in TB ğ‘. Assume the inte-\ngers maintained for the ğ‘–-th thread in TB ğ‘(resp. TBğ‘) are startğ‘and\nendğ‘(resp. startğ‘andendğ‘). We set startğ‘=startğ‘+start ğ‘+endğ‘\n2,\nendğ‘=endğ‘, and endğ‘=startğ‘+start ğ‘+endğ‘\n2âˆ’1,i.e.,the latter half\nof tuples remained to be compared is stolen from each thread in TB ğ‘.\nExample 13: Continuing Example 12, when TB3 finishes Interval\n4 stolen from TB1 in Figure 6(b), it finds no not-yet-processed inter-\nvals. However, since TB2 is still evaluating Interval 7, TB3 steals half\nremaining workload from it, saving 1 more time unit (Figure 6(c)). â–¡\n5.3 GPU collaboration\nA GPU server nowadays usually has multiple GPUs connected via\nNVLink [ 49] or PCIe. Scaling blocking to multiple GPUs is beneficial\nfor jointly utilizing the computation and storage powers of GPUs.\nIn pursuit of this, one can split data evenly so that each GPU\nhandles exactly one [ 63], or assign multiple partitions to each GPU\nin a round-robin manner [ 68]. These, however, do not work well\nsince (a) workload can be imbalanced due to skewed execution\ntimes of partitions, (b) pending partitions may wait when multiple\npartitions compete for limited PCIe bandwidth or CUDA cores (see\nSection 2) and (c) they independently conduct blocking on partitions\nand do not effectively handle scenarios where ğ‘¡ğ‘–andğ‘¡ğ‘—reside on\ndifferent partitions, resulting in elevated false-negative rates. To\naddress these, one can duplicate tuples in multiple partitions [ 20,\n22], but it incurs both memory and data transfer costs.\nIn light of these, we present a collaborative approach integrating\npartitioning and scheduling strategies, where the former aims at\nminimizing data redundancy while reducing false negatives and the\nlatter prioritizes load balancing and minimizes resource contention.\nData partitioning. A typical method for data partitioning com-\nputes a hash key for each tuple based on some attributes and tuples\nwith same hash key are grouped together. Instead of sacrificing\nthe accuracy ( e.g.,using only one hash function) or unnecessarily\nduplicating tuples, HyperBlocker appliesğ‘ hash functions to obtain\nğ‘ partition-keys, where ğ‘ is the number of children ğ‘ğ‘of the root\nnodeğ‘0in the execution tree T; each hash function is constructed\nfrom the predicate ğ‘associated with an edge (ğ‘0,ğ‘ğ‘). In this way,\n\nTable 2: Datasets\nDataset Domain #Tuples Max #Pairs #GT Pairs #Attrs #Rules #Partitions\nFodors -Zagat restaurant 866 1.8Ã—104112 6 1 1\nDBLP -ACM citation 4591 6.0Ã—1062294 4 10 8\nDBLP -Scholar citation 66881 1.7Ã—1085348 4 10 8\nIMDB movie 1.5M 8.1Ã—10100.2M+ 6 10 128\nSongs music 0.5M 2.7Ã—10111.2M 8 10 128\nNCV vote 2M 1.0Ã—10120.5M+ 5 10 512\nTFACC traffic 10M 1.0Ã—1014# 16 50 1024\nTFACC large traffic 36M 1.3Ã—1015# 16 50 1024\nthe predicates that we adopt for data partitioning are those priori-\ntized byT,e.g.,givenğ‘=sname associated with ( ğ‘0,ğ‘1) in Figure 4(b),\nwe hash tuples in ğ·based on their values in sname . The benefits are\ntwo-fold: (1) According to the construction of T, these hash func-\ntions are selective and might be shared by rules, i.e.,we can achieve\ngood hashing with a few hashing functions. (2) We can assign each\ntuple a branch ID, indicating the hash function used. Only tuples\nthat share the same hash function are compared, thereby reducing\nredundant computations incurred by multiple hash functions.\nScheduling. HyperBlocker adopts a two-step scheduling strategy.\nInitially, data partitions and GPUs are hashed to random locations\non a unit circle [ 57]. If a partition ğ‘ƒğ‘–is assigned to an ineligible\nGPU (where there is no idle core or available PCIe bandwidth), it is\nrerouted to the nearest available GPU in a clockwise direction.\nRemark. If data partitioning is done by a hashing function from a\nsimilarity predicate ğ‘, it is possible that â„(ğ‘¡1,ğ‘¡2)|=ğ‘butğ‘¡1andğ‘¡2\nreside on different partitions, leading to potential false negatives\nin blocking. In this case, a CUDA kernel [7] with local data ğ‘ƒğ‘–can\noptionally â€œpullâ€ partition ğ‘ƒğ‘—from another kernel and evaluate T\nacrossğ‘ƒğ‘–andğ‘ƒğ‘—. The pull operation retrieves data from locations\noutsideğ‘ƒğ‘–, depending on whether ğ‘ƒğ‘–andğ‘ƒğ‘—reside on the same GPU.\nIfğ‘ƒğ‘–andğ‘ƒğ‘—reside on the same GPU, the pull operation is executed\ndirectly without any data transfer. Otherwise, the pull operation\nforğ‘ƒğ‘—can be carried out using cudaMemcpyPeer() to take the\nadvantages of high bandwidth and low latency provided by NVLink.\n6 EXPERIMENTAL STUDY\nWe evaluated HyperBlocker for its accuracy-efficiency and scala-\nbility. We also conducted sensitivity tests and ablation studies.\nExperimental setup. We start with the experimental setting.\nDatasets. We used eight real-world public datasets in Table 2, which\nare widely adopted ER benchmarks and real-life datasets [ 3,4,9].\nMost datasets (except TFACC andTFACC large) have labeled matches\nor mismatches as the ground truths (GT). For datasets without\nground truths, we assume the original datasets were correct, and\nrandomly duplicated tuples as noises [ 30]. The training data con-\nsists of 50% of ground truths and 50% of randomly selected noise.\nBaselines. As remarked in Section 2, although HyperBlocker is de-\nsigned as a blocker, it can be used with or without a matcher. Thus,\nbelow we not only compared HyperBlocker against widely used\nblockers but also integrated ER solutions ( i.e.,blocker + matcher).\nWe compared three distributed ER systems: (1) Dedoop [1,44],\n(2)SparkER [13,33], (3) DisDedup [8,20], where DisDedup is the\nSOTA CPU-based parallel ER system, designed to minimize commu-\nnication and computation costs; Dedoop focuses on optimizing com-\nputation cost; SparkER integrates Blast blocking [ 71] on Spark [ 12].Table 3: Comparison with the SOTA DL-based blocker\nMethod MetricDataset\nFodors-Zagat DBLP-Scholar DBLP-ACM\nDeepBlockerRec(%) 100 (+0) 98 (+5) 98 (+4)\nCSSR (â€±) 15.1 (+14.5) 2.3 (+1.1) 2.2 (+1.8)\nTime (s) 6.1 (122 Ã—) 72.8 (11.0 Ã—) 8.0 (10.0Ã—)\nHost Mem. cost (GB) 9.9 (49.5Ã—) 14.0 (23.3 Ã—) 10.3 (34.3Ã—)\nDevice Mem. cost (GB) 0.9 (1.8Ã—) 1.1 (1.6Ã—) 0.9 (1.5Ã—)\nHyperBlockerRec(%) 100 93 94\nCSSR (â€±) 0.6 1.2 0.4\nTime (s) 0.05 6.6 0.8\nHost Mem. cost (GB) 0.2 0.6 0.3\nDevice Mem. cost (GB) 0.5 0.7 0.6\nWe also compared four GPU-based baselines: (4) DeepBlocker\n[77], (5) GPUDet [31], (6) Ditto [2,51], (7) DeepBlockerDitto, where\nDeepBlocker is the SOTA DL-based blocker, GPUDet implements\nwell-known similarity algorithms for tuple pair comparison, Ditto is\nthe SOTA matcher, and DeepBlockerDitto uses DeepBlocker as the\nblocker and Ditto as the matcher, respectively. Note that Ditto takes\ntuple pairs as input, instead of relations/partitions as other methods.\nDue to the high cost of Ditto , it is infeasible to feed the Cartesian\nproduct of data to Ditto . Thus, for each tuple in GT, we adopted a\nsimilarity-join method [ 42] to get the top-2 nearest neighbors, as\nits preprocessing step. Denote the resulting baseline by Ditto top2.\nBesides, we also implemented several variants: (1) HyperBlocker ,\nthe basic blocker with all optimizations. (2) HyperBlockerDitto, an\nimproved version that uses HyperBlocker as the blocker and Ditto\nas the matcher, respectively. Note that HyperBlockerDitto is particu-\nlarly compared against Ditto top2to show how we speed up the over-\nall ER. (3) HyperBlockernoEPG , a variant without EPG (Section 4). (4)\nHyperBlockernoHO that disables all hardware optimizations (Sec-\ntion 5). We also compared more designated variants in Exp 3-5.\nRules. We mined MDs using [ 73] and the number of MDs is shown\nin Table 2. We checked the MDs manually to ensure correctness.\nMeasurements . Following typical ER settings, we measured the\nperformance of each method (blocker, matcher, or the combination\nof the two) in terms of the runtime and the F1-score, defined as\nF1-score =2Ã—PrecÃ—Rec\nPrec+Rec. Here Prec is the ratio of correctly identified\ntuple pairs to all identified pairs and Recis the ratio of correctly\nidentified tuple pairs to all pairs that refer to the same real-world\nentity. All methods aim to achieve high Rec,Prec and F1-scores.\nFollowing [ 77], we also report the candidate set size ratio (CSSR), de-\nfined as|Ca(ğ‘ƒ)|\n|ğ‘ƒ|Ã—|ğ‘ƒ|, when comparing HyperBlocker with DeepBlocker ,\nto show the portion of tuple pairs that require further comparison\nby the matcher, i.e.,the smaller the CSSR, the better the blocker.\nEnvironment. We run experiments on a Ubuntu 20.04.1 LTS ma-\nchine powered with 2 Intel Xeon Gold 6148 CPU @ 2.40GHz, 4TB\nIntel P4600 PCIe NVMe SSD, 128GB memory, and 8 Nvidia Tesla\nV100 GPUs with the widely adopted hybrid cube-mesh topology\n(see more in [62]). The programs were compiled with CUDA-11.0\nand GCC 7.3.0 with -O3 compiler. DisDedup ,SparkER , and Dedoop\nwere run on a cluster of 30 HPC servers, powered with 2.40GHz\nIntel Xeon Gold CPU, 4TB Intel P4600 SSD, 128GB memory.\nDefault parameters. Unless stated explicitly, we used the following\nparameters, best-tuned on each dataset via gird search [41]. The\nmaximum number of predicates in an MDis 10. The number ğ‘šof\ndata partitions is given in Table 2. The sizes of intervals and sliding\nwindows, namely ğ‘›ğ‘¡andğ‘›ğ‘¤, are 256 and 1024, respectively. We\nadopted a regression model as N, with 3 hidden layers, with 2, 6, and\n\nTable 4: Accuracy & runtime on benchmarks where â€œ*â€ denotes that integrating HyperBlocker with Ditto does not improve the\nF1-score and thus we report the result of HyperBlocker , and â€œ/â€ denotes that the F1-score cannot be computed within 3 hours.\nMethod Backend CategoryDBLP-ACM IMDB Songs NCV\nF1-score Time (s) F1-score Time (s) F1-score Time (s) F1-score Time (s)\nSparkER CPU Blocker 0.77 (-0.17) 11.0 (13.8 Ã—) 0.31 (-0.65) 242.9 (6.8 Ã—) 0.08 (-0.72) 203.4 (15.2 Ã—) 0.26 (-0.66) 229.3 (49.8 Ã—)\nGPUDet GPU Blocker 0.92 (-0.02) 20.1 (25.1 Ã—) 0.94 (-0.02) 323.8 (9.1 Ã—) 0.80 (+0) 404.8 (30.2 Ã—) 0.90 (-0.02) 1252.6 (272.3 Ã—)\nDeepBlocker GPU Blocker 0.98 (+0.04) 8.3 (10.4 Ã—) / >3h / >3h / >3h\nHyperBlockernoEPG GPU Blocker 0.94 (+0) 9.9 (12.4 Ã—) / >3h 0.80 (+0) 1904.1 (142 Ã—) 0.92 (+0) 2408.6 (523.6 Ã—)\nHyperBlockernoHO GPU Blocker 0.94 (+0) 9.5 (11.9 Ã—) 0.96 (+0) 472.6 (13.2 Ã—) 0.80 (+0) 45.0 (3.4 Ã—) 0.92 (+0) 35.9 (7.8 Ã—)\nHyperBlocker GPU Blocker 0.94 0.8 0.96 35.7 0.80 13.4 0.92 4.6\nDedoop CPU Blocker+Matcher 0.90 (-0.08) 59.4 (9.4 Ã—) 0.67 (-0.29) 534.0 (15.0 Ã—) 0.80 (-0.08) 7643.4 (6.5 Ã—) / >3h\nDisDedup CPU Blocker+Matcher 0.45 (-0.53) 94.0 (14.9 Ã—) 0.67 (-0.29) 644.0 (18.0 Ã—) 0.06 (-0.82) 917.0 (0.8 Ã—) / >3h\nDitto top2 GPU Blocker+Matcher 0.98 (+0) 9.0 (1.4 Ã—) 0.79 (-0.17) 6741.2 (188.8 Ã—) 0.88 (+0) 2308.6 (2.0 Ã—) 0.97 (+0.03) 381.8 (2.1 Ã—)\nDeepBlockerDitto GPU Blocker+Matcher 0.99 (+0.01) 12.4 (2.0 Ã—) / >3h / >3h / >3h\nHyperBlockerDitto GPU Blocker+Matcher 0.98 6.3 *0.96 *35.7 0.88 1179.0 0.94 180.6\n1 neurons, respectively. We used ReLU [60] as the activation func-\ntion and Adam [ 43] as the optimizer. We used one GPU by default.\nExperimental results. For lack of space, we report our findings\non some datasets as follows; consistent on other datasets.\nExp-1: Motivation study. We motivate our study by comparing\nHyperBlocker , our rule-based blocker, with the SOTA DL-based\nblocker DeepBlocker (Table 3), where the bracket next to a metric\nofDeepBlocker gives its difference or deterioration factor to ours.\nDL-based blocking vs. rule-based blocking. We report recall, CSSR,\nruntime, and (host and device) memory for both methods. Consis-\ntent with [ 77], for DeepBlocker , each tuple was paired with top- ğ¾\nsimilar tuples as initial candidate pairs, where ğ¾=5on all datasets\n(except DBLP -Scholar whereğ¾=150). As remarked in Section 1,\nboth methods have strengths. (1) HyperBlocker effectively reduces\nthe number of pairs to further compare while maintaining high\nRec(>93%), e.g.,its average CSSR is 5.8â€±less than DeepBlocker .\n(2)HyperBlocker is at least 10Ã—faster. (3) HyperBlocker consumes\nless memory than DeepBlocker ,e.g.,the host memory it consumes\nis at least 23.3Ã—less than DeepBlocker . (4) Note that the Recof\nHyperBlocker is slightly lower than DeepBlocker , which is accept-\nable given its convincing speedup and memory saving, since the\nprimary goal of a blocker is to improve the efficiency and scalability\nof ER, not to improve the accuracy of ER (the goal of a matcher).\nExp-2: Accuracy-efficiency. We report the F1-scores and runtime\nof all blockers and integrated ER solutions ( i.e.,blocker + matcher)\nin Table 4. Here DeepBlocker pairs each tuple with its top-2 tuples\nas initial candidate pairs. For all blockers, the bracket next to\neach F1-score (resp. time) gives the difference (resp. slowdown)\nin F1-score (resp. time) to HyperBlocker (marked yellow). For a\nfair comparison, the brackets of each integrated ER solution give\nthe difference compared with HyperBlockerDitto (marked yellow).\nAccuracy. We mainly analyze the F1-scores of HyperBlocker , which\nare consistently above 0.8 over all datasets. Besides, we find:\n(1)HyperBlocker outperforms CPU-based distributed solutions, e.g.,\nit achieves up to 0.29, 0.74, and 0.72 improvement in F1-score against\nDedoop ,DisDedup , and SparkER , respectively, even though the for-\nmer two are integrated with matchers. This is because these solu-\ntions exploit data partition-based parallelism only, which may lead\nto false negatives if matched tuples are put into different partitions.(2) Compared with the four GPU-based baselines, HyperBlocker has\ncomparable accuracy. In particular, it even beats Ditto top2, the SOTA\nmatcher, by 0.17 F1-score in IMDB . This shows that even without\na matcher, HyperBlocker alone is already accurate in certain cases.\nMoreover, DeepBlocker andDeepBlockerDitto struggle to handle\nlarge datasets. When facing million-scale data, they cannot finish in\n3 hours. This again motivates the need for rule-based alternatives.\n(3) Combing HyperBlocker with Ditto ,HyperBlockerDitto further\nboosts the accuracy, achieving the best F1-score in Songs . Neverthe-\nless, DL-based solutions still have the best F1 scores in other cases,\njustifying that none of them can dominate the other in all cases.\n(4)HyperBlockernoEPG andHyperBlockernoHO are as accurate as\nHyperBlocker , since they only differ in the optimizations.\nRuntime. We next report the runtime. (1) HyperBlocker runs sub-\nstantially faster than all baselines, e.g., it is at least 6.8Ã—, 9.1Ã—,\n10.4Ã—, 15.0Ã—, 18.0Ã—, 11.3Ã—and 15.5Ã—faster than SparkER ,GPUDet ,\nDeepBlocker ,Dedoop ,DisDedup ,Ditto , and DeepBlockerDitto re-\nspectively. (2) HyperBlockerDitto is slower than HyperBlocker\nas expected since it performs additional matching. Nonetheless,\nHyperBlockerDitto is at least 1.4Ã—(resp. 2.0Ã—) faster than Ditto top2\n(resp. DeepBlockerDitto). Given its comparable F1-score, we substan-\ntiate our claim (Section 1) that blocking is a crucial part of the overall\nER process. (3) HyperBlocker is at least 12.4Ã—and 3.4Ã—faster than\nHyperBlockernoEPG and HyperBlockernoHO , respectively, verify-\ning the usefulness of execution plans and hardware optimizations.\nImpact ofğ‘š.Figure 7 (a) reports how the number ğ‘šof data parti-\ntions affects the recall (the right y-axis) and the runtime (the left\ny-axis) on NVC . As shown there, both metrics of HyperBlocker\ndecreases with increasing ğ‘š. This is because when there are more\npartitions, both the number of pairwise comparisons and the candi-\ndate matches that can be identified in each partition are reduced.\nExp-3: Scalability. We tested our scalability under multi-GPUs sce-\nnarios. The default number of GPUs is 4 in this set of experiments.\nVarying|ğ·|/#GPUs. We varied the scale factor of ğ·inTFACC large\nand tested HyperBlocker with different numbers of GPUs in Fig-\nure 7(b). HyperBlocker scales well with data sizes, e.g.,with 8 GPUs,\nit takes 1604s to process 36M tuples; this is not feasible for both CPU-\nand GPU-based baselines. When the number of GPUs changes from\n1 to 8, HyperBlocker is 2.6Ã—faster, since HyperBlocker mainly accel-\n\n(a)NVC: Impact ofğ‘š\n (b)TFACC -Large : Varying #GPUs\n (c)IMDB : Impact of schedulers\n (d)TFACC : Varying|ğœ‘|\n(e)TFACC : Varying|Î”|\n (f)DBLP -ACM : Varying noise%\n (g) More ordering strategies\n (h) Ablation study\nFigure 7: Efficiency, scalability, and effectiveness of HyperBlocker\nerates the operations on GPUs, while other parts of the system ( e.g.,\nI/O and data partitioning) may also limit the overall performance.\nImpact of task schedulers. We tested the impact of task schedulers,\nby comparing HyperBlocker with two variants, that uses EvenSplit\nandRoundRobin for scheduling (Section 5.3), respectively, by vary-\ning|ğ·|in Figure 7(c). HyperBlocker works better than the two, e.g.,\nwhen the scale factor is 100%, HyperBlocker is 1.3Ã—and 2.2Ã—faster\nthan RoundRobin andEvenSplit , respectively, since both variants\nmay limit CUDAâ€™s ability to dynamically schedule tasks.\nExp-4: Tests on EPG (Section 4). We evaluated EPG (and its offline\nmodelN) and justified the need of effective evaluation orders.\nVarying|ğœ‘|.We tested the number |ğœ‘|of predicates in each MDğœ‘\nagainst HyperBlockernoPO that evaluates predicates in a random\norder in TFACC (Figure 7(d)). (1) HyperBlocker takes longer with\nlarger|ğœ‘|, as expected. (2) HyperBlocker is feasible in practice, e.g.,\nwhen|ğœ‘|=10, it only takes 135.2s. (3) On average, HyperBlocker\nshows 32.5Ã—speedup to HyperBlockernoPO . This justifies the im-\nportance of predicate ordering in efficient rule-based blocking.\nVarying|Î”|.We evaluated the impact of the number |Î”|ofMDs\ninÎ”in Figure 7(e), where HyperBlocker takes longer with more\nrules, e.g.,it takes 523.2s when |Î”|=50, and consistently beats\nHyperBlockernoRO , a variant that evaluates rules in a random order.\nShallow modelN.We evaluated the performance of Nin EPG by\n(1) its sensitivity to noises, (1) the resulting predicate ordering,\ncompared with the â€œground truthâ€ ordering derived from actual\ncosts, and (3) the speedup of estimating the actual costs using N.\n(1) Given a noise ratio ğ›½%, we injected ğ›½%noises to training data of\nN, to disturb its distribution, and report RMSE (Root Mean Squared\nError), a widely used metric for regression, in Figure 7(f) (the left\ny-axis). The RMSE of Ndoes not degrade much when ğ›½%= 20%.\nHowever, when ğ›½%continues to increase, Nbecomes inaccurate.\n(2) We compared the predicate ordering estimated via Nwith the\nground truth one using NDCG (Normalized Discounted Cumula-\ntive Gain [ 78]), a widely used metric for evaluating ranking, in\nFigure 7(f) (the right y-axis). The result shows that the two order-\nings are close ( i.e.,NDCG is high), even when the noise ratio is 40%.\n(3) The average time for computing the actual cost of a predicateis 0.8s on DBLP -ACM , as opposed to 0.007s for the estimated cost.\nMore ordering strategies. To justify the need for both cost and effec-\ntiveness, we compared two more strategies using designated MDs :\n(1)COrder , that prioritizes cheap predicates ( e.g.,always evaluate\nequality first, a common strategy in existing DBMS, as remarked in\nSection 4) and (2) SOrder , that prioritizes selective predicates. For\nall orders, we applied the same partitioning strategy (Section 5.3). To\nbetter visualize the effects on different datasets, we report the slow-\ndown percentages in Figure 7(g). SOrder (resp. COrder ) is on av-\nerage slowed by 733.6% (resp. 38.2%) compared with HyperBlocker .\nThis said, we strike a balance between the two strategies.\nExp-5: Tests on hardware optimizations (Section 5). Finally, we\nconducted an ablation study on hardware optimizations and report\nthe runtime statistics. We compared three baselines: (1) noSeq , that\nrecursively implements DFS without sequential execution paths, (2)\nnoPSW that assigns continuous intervals to each TB without paral-\nlel sliding windows, and (3) noStealing , where GPUs automatically\nschedule a new TB whenever one is done, without task stealing. To\nbetter visualize the effect, below we used ğ·as a single partition.\nAblation study. We show the slowdown percentages compared to\nHyperBlocker in Figure 7(h). We find: (1) noSeq is much slower\nthan HyperBlocker , since recursive DFS is not efficient on GPUs. (2)\nnoStealing andnoPSW are on average 43.1% and 28.8% slower than\nHyperBlocker , respectively, justifying the use of both optimizations.\nRuntime statistic. We adopted NSight [ 10], a profiling tool provided\nby NVIDIA, and report wait stalls (i.e.,the number of clock cycles\nthat the kernel spent on waiting), branch efficiency (i.e.,the ratio of\ncorrectly predicted branch instructions), and the average number\nactive threads per warp inTFACC (Table 5). HyperBlocker performs\nthe best in all metrics. The reasons are twofold: (1) while divergence\nis sometimes unavoidable, a recursive DFS exacerbates it ( e.g.,due\nto stacking), leading to more idle threads; and (2) the workloads\ncan be imbalanced, e.g.,without parallel sliding windows, noPSW\nincurs a larger number of wait stalls compared with HyperBlocker .\nSummary. We find the following. (1) HyperBlocker outperforms\nprior blockers and integrated ER solutions. It is at least 6.8 Ã—, 9.1Ã—,\n10.4Ã—, 15.0Ã—, 18.0Ã—, 11.3Ã—and 15.5Ã—faster than SparkER ,GPUDet ,\nDeepBlocker ,Dedoop ,DisDedup ,Ditto , and DeepBlockerDitto\n\nTable 5: Runtime info ( â†‘: higher is better vs. â†“: lower is better)\nMethodâ†“Wait stalls (in\nterms of clock cycles)â†‘Branch\nefficiencyâ†‘Average number of\nactive threads per warp\nnoSeq 4.25 89.9% 14.45\nnoPSW 13.79 96.3% 25.59\nnoStealing 4.11 96.2% 27.62\nHyperBlocker 4.07 96.4% 28.21\nrespectively. (2) By combining HyperBlocker with Ditto , we save at\nleast 30% of time with comparable accuracy. (3) HyperBlocker beats\nall its variants (except HyperBlockerDitto) in both runtime and\naccuracy, justifying the usefulness of various optimizations: (a) EPG\nspecifies an effective evaluation order, improving the runtime by at\nleast 12.4Ã—and (b) the hardware optimizations on GPUs speedup\nblocking by at least 3.4 Ã—. (4)HyperBlocker scales well with various\nparameters, e.g.,it completes blocking in 1604s on 36M tuples.\n7 RELATED WORK\nWe categorize the related work in the literature as follows.\nBlocking algorithms. There has been a host of work on the block-\ning algorithms, classified as follows: (1) Rule-based [ 20,35,39,44,\n64],e.g.,[35] creates data partitions and then refines candidate pairs\nin every partition, by removing mismatches with similarity mea-\nsures or length/count filtering [ 55]. (2) DL-based [ 24,40,77,79],\nwhich cast the generation of candidate matches into a binary classi-\nfication problem, where each tuple pair is labeled â€œlikely matchâ€ or\nâ€œunlikely matchâ€, e.g.,[77] adopts similarity search to generate can-\ndidate matches for each tuple based on its top- ğ¾probable matches\nin an embedding space. DL-based blocking and rule-based blocking\nshare the same goal, but are different in their approaches, where\nthe former focuses on learning the distributed representations of\ntuples, while the latter emphasizes explicit logical reasoning.\nAlthough we study rule-based blocking, we are not to develop\nanother blocking algorithm. Instead, we provide a GPU-accelerated\nblocking solution. As a testbed, we use MDs as our blocking rules,\nwhich subsume many existing rules [46, 64] as special cases.\nParallel blocking solvers. Several parallel blocking systems have\nbeen proposed, e.g.,[16,20,21,26,30,33,44,45,66,76], mostly un-\nder MapReduce [ 20,33,44] or MPC [ 22,30,76], which aim at scaling\nto large data with a cluster of machines. DisDedup [20] uses a tri-\nangle distribution strategy to minimize both comparisons and com-\nmunication over Spark[ 12].Minoan [26] runs on top of Spark and\napplies parallel meta blocking [ 25] to minimize its overall runtime.\nThis work differs as follows. Unlike MapReduce-based systems,\nwhich split data at the coordinator and execute tasks on workers,\nHyperBlocker focuses on collaborating GPUs and CPUs, to promote\nbetter resource utilization and massive parallelism. HyperBlocker\nis designed for the shared memory architecture of GPUs and is fine-\ntuned to exploit GPU hardware for rule-based blocking. To the best\nof our knowledge, incorporating both GPU and CPU characteristics\nhas not been considered in prior parallel blocking solutions.\nGPU-accelerated techniques. GPUs have been used extensively\nto speed up the training of DL tasks. Recent works exploit GPUs\nto accelerate data processing, e.g., GPU-based query answering\n[23,36,72] and similarity join [ 42,53,61]. Closer to this work\nare [42,53] which leverage GPUs for similarity join, since blocking\ncan be regarded as a similarity join problem under the assumptionthat two tuples refer to the same entity if their similarity is high.\nSimilarity join is often served as a preprocessing step of ER.\nIn contrast, HyperBlocker aims at expediting rule-based block-\ning, addressing challenges in rule-based optimization that are not\nincurred in similarity join. The closest work is GPUDet [31], which\nemploys GPUs to expedite similarity measures. HyperBlocker dif-\nfers from GPUDet , in its data/rule-aware execution plan designated\nfor rule evaluation, beyond similarity measures. It also incorporates\nhardware-aware optimizations for improving GPU utilization.\nQuery optimizations. Also related to EPG is query optimization\nin DBMS [ 48,56,58,67,69,70], which uses sampling, statistics, or\nprofiling to get execution plans via cost and cardinality estimation.\nSince rule-based blocking is in DNF, with arbitrary similarity com-\nparisons and multiple rules, EPG is particularly related to the opti-\nmizations on DNF SQLs with UDFs [ 32,38,70,74],e.g.,[74] analyzes\nPython UDFs to reorder operators based on data/operation types.\nEPG differs from existing query optimizations: (1) EPG optimizes\nthe execution, no matter what comparisons ( e.g.,equality or sim-\nilarity) are adopted, while many DBMS optimizers struggle when\nsimilarity comparisons are encoded as UDFs, e.g.,SQL Server [ 14]\nrestricts UDFs to a single thread, and PostgreSQL [ 11] treats UDFs\nas black boxes. This said, EPG solves a more specialized problem, be-\nyond general query optimization, for arbitrary comparisons. (2) It is\nhard for most optimizers to accurately estimate the runtime perfor-\nmance of UDFs [ 67], which may depend on specific measures/data,\nwhile we consider the time/selectivity of predicates, using learned\nand LSH-based models for accurate estimation. (3) EPG employs\ntree structures and bitmaps, to effectively handle the disjunction\nlogic behind blocking and to reuse computation, while traditional\nDBMS may be forced to perform full scan when evaluating ORop-\nerations. (4) EPG produces a data partitioning scheme based on the\nexecution tree as a by-product, to coordinate across multiple GPUs.\n8 CONCLUSION\nThe novelty of HyperBlocker consists of (1) a pipelined architecture\nthat overlaps the data transfer from/to CPUs and the operations on\nGPUs; (2) a data-aware and rule-aware execution plan generator\non CPUs, that specifies how rules are evaluated; (3) a variety of\nhardware-aware optimization strategies that achieve massive paral-\nlelism, by exploiting GPU characteristics; and (4) partitioning and\nscheduling strategies to achieve workload balancing across multiple\nGPUs. Our experimental study has verified that HyperBlocker is\nmuch faster than existing CPU-powered distributed systems and\nGPU-based ER solvers, while maintaining comparable accuracy.\nThere are some future topics: (a) give a different plan on each\npartition; (b) explore the materialization of partial evaluation results\nto avoid divergence and (c) investigate whether EPG and traditional\noptimizers can complement/enhance each other.\nACKNOWLEDGMENTS\nWe sincerely thank Wenfei Fan, Shuhao Liu, Yaoshu Wang, and\nWeijie Ou for their comments and helpful discussions.\n\nREFERENCES\n[1] 2021. Dedoop Source Code. https://dbs.uni-leipzig.de/dedoop.\n[2] 2021. Ditto Source Code. https://github.com/megagonlabs/ditto.\n[3] 2021. ER Benchmark Dataset. https://dbs.uni-leipzig.de/de/research/projects/\nobject_matching/benchmark_datasets_for_entity_resolution.\n[4] 2021. Magellan Dataset. https://sites.google.com/site/anhaidgroup/projects/data.\n[5] 2023. Amazon Duplicate Product Listings. https://www.amazowl.com/amazon-\nfrustration-free-packaging-2-2-2/.\n[6]2024. 7 Bad Practices to Avoid When Writing SQL Queries for Better Per-\nformance. https://dev.to/abdelrahmanallam/7-bad-practices-to-avoid-when-\nwriting-sql-queries-for-better-performance-c87.\n[7]2024. CUDA C Programming Guide. https://docs.nvidia.com/cuda/cuda-c-\nprogramming-guide/.\n[8] 2024. DisDedup Source Code. https://github.com/david-siqi-liu/sparklyclean.\n[9] 2024. MOT Tests and Results. https://ckan.publishing.service.gov.uk/dataset.\n[10] 2024. NSight Compute. https://docs.nvidia.com/nsight-compute/.\n[11] 2024. PostgreSql. https://www.postgresql.org.\n[12] 2024. Spark. https://spark.apache.org.\n[13] 2024. Sparker Source Code. https://github.com/Gaglia88/sparker.\n[14] 2024. SQL Server user-defined functions. https://learn.microsoft.com/en-us/sql/\nrelational-databases/user-defined-functions/user-defined-functions?view=sql-\nserver-ver16.\n[15] Serge Abiteboul, Richard Hull, and Victor Vianu. 1995. Foundations of Databases .\nAddison-Wesley.\n[16] Yasser Altowim and Sharad Mehrotra. 2017. Parallel Progressive Approach to\nEntity Resolution Using MapReduce. In ICDE .\n[17] Alexandr Andoni and Piotr Indyk. 2008. Near-optimal hashing algorithms for\napproximate nearest neighbor in high dimensions. Commun. ACM 51, 1 (2008).\n[18] Xianchun Bao, Zian Bao, Bie Binbin, QingSong Duan, Wenfei Fan, Hui Lei, Daji\nLi, Wei Lin, Peng Liu, Zhicong Lv, et al .2024. Rock: Cleaning Data by Embedding\nML in Logic Rules. In SIGMOD . 106â€“119.\n[19] Nils Barlaug. 2023. ShallowBlocker: Improving Set Similarity Joins for Blocking.\narXiv preprint arXiv:2312.15835 (2023).\n[20] Xu Chu, Ihab F Ilyas, and Paraschos Koutris. 2016. Distributed data deduplication.\nPVLDB 9, 11 (2016), 864â€“875.\n[21] Sanjib Das, Paul Suganthan GC, AnHai Doan, Jeffrey F Naughton, Ganesh Krish-\nnan, Rohit Deep, Esteban Arcaute, Vijay Raghavendra, and Youngchoon Park.\n2017. Falcon: Scaling up hands-off crowdsourced entity matching to build cloud\nservices. In SIGMOD . 1431â€“1446.\n[22] Ting Deng, Wenfei Fan, Ping Lu, Xiaomeng Luo, Xiaoke Zhu, and Wanhe An.\n2022. Deep and collective entity resolution in parallel. In ICDE . 2060â€“2072.\n[23] Gregory Frederick Diamos, Haicheng Wu, Jin Wang, Ashwin Sanjay Lele, and\nSudhakar Yalamanchili. 2013. In PPoPP . 301â€“302.\n[24] Muhammad Ebraheem, Saravanan Thirumuruganathan, Shafiq R. Joty, Mourad\nOuzzani, and Nan Tang. 2018. Distributed Representations of Tuples for Entity\nResolution. PVLDB 11, 11 (2018), 1454â€“1467.\n[25] Vasilis Efthymiou, George Papadakis, George Papastefanatos, Kostas Stefanidis,\nand Themis Palpanas. 2015. Parallel meta-blocking: Realizing scalable entity\nresolution over large, heterogeneous data. In IEEE Big Data . 411â€“420.\n[26] Vasilis Efthymiou, George Papadakis, Kostas Stefanidis, and Vassilis\nChristophides. 2019. MinoanER: Schema-Agnostic, Non-Iterative, Mas-\nsively Parallel Resolution of Web Entities. In EDBT .\n[27] Wenfei Fan, Hong Gao, Xibei Jia, Jianzhong Li, and Shuai Ma. 2011. Dynamic\nconstraints for record matching. The VLDB Journal 20 (2011), 495â€“520.\n[28] Wenfei Fan, Ziyan Han, Yaoshu Wang, and Min Xie. 2022. Parallel Rule Discovery\nfrom Large Datasets by Sampling. In SIGMOD . 384â€“398.\n[29] Wenfei Fan, Ziyan Han, Yaoshu Wang, and Min Xie. 2023. Discovering Top-k\nRules using Subjective and Objective Criteria. In SIGMOD .\n[30] Wenfei Fan, Chao Tian, Yanghao Wang, and Qiang Yin. 2021. Parallel discrepancy\ndetection and incremental detection. PVLDB 14, 8 (2021), 1351â€“1364.\n[31] Benedikt Forchhammer, Thorsten Papenbrock, Thomas Stening, Sven Viehmeier,\nUwe Draisbach, and Felix Naumann. 2013. Duplicate detection on GPUs. HPI\nFuture SOC Lab 70, 3 (2013).\n[32] Yannis Foufoulas and Alkis Simitsis. 2023. Efficient execution of user-defined\nfunctions in SQL queries. PVLDB 16, 12 (2023), 3874â€“3877.\n[33] Luca Gagliardelli, Giovanni Simonini, Domenico Beneventano, and Sonia Berga-\nmaschi. 2019. SparkER: Scaling Entity Resolution in Spark. In EDBT .\n[34] Lei Gao, Pengpeng Zhao, Victor S. Sheng, Zhixu Li, An Liu, Jian Wu, and Zhiming\nCui. 2015. EPEMS: An Entity Matching System for E-Commerce Products. In Web\nTechnologies and Applications , Reynold Cheng, Bin Cui, Zhenjie Zhang, Ruichu\nCai, and Jia Xu (Eds.). Springer International Publishing, Cham, 871â€“874.\n[35] Lifang Gu and Rohan Baxter. 2004. Adaptive filtering for efficient record linkage.\nInSDM . 477â€“481.\n[36] Bingsheng He, Mian Lu, Ke Yang, Rui Fang, Naga K Govindaraju, Qiong Luo,\nand Pedro V Sander. 2009. Relational query coprocessing on graphics processors.\nACM Transactions on Database Systems (TODS) 34, 4 (2009), 1â€“39.\n[37] Fabian Hueske, Mathias Peters, Aljoscha Krettek, Matthias Ringwald, Kostas\nTzoumas, Volker Markl, and Johann-Christoph Freytag. 2013. Peeking into theoptimization of data flow programs with mapreduce-style udfs. In ICDE .\n[38] Fabian Hueske, Mathias Peters, Matthias J Sax, Astrid RheinlÃ¤nder, Rico\nBergmann, Aljoscha Krettek, and Kostas Tzoumas. 2012. Opening the black\nboxes in data flow optimization. PVLDB 5, 11 (2012), 1256â€“1267.\n[39] Robert Isele, Anja Jentzsch, and Christian Bizer. 2011. Efficient multidimensional\nblocking for link discovery without losing recall.. In WebDB . 1â€“6.\n[40] Delaram Javdani, Hossein Rahmani, Milad Allahgholi, and Fatemeh Karimkhani.\n2019. Deepblock: A novel blocking approach for entity resolution using deep\nlearning. In ICWR . 41â€“44.\n[41] Ãlvaro Barbero JimÃ©nez, Jorge LÃ³pez LÃ¡zaro, and JosÃ© R Dorronsoro. 2008. Find-\ning optimal model parameters by discrete grid search. In Innovations in hybrid\nintelligent systems . Springer, 120â€“127.\n[42] Jeff Johnson, Matthijs Douze, and HervÃ© JÃ©gou. 2021. Billion-Scale Similarity\nSearch with GPUs. IEEE Transactions on Big Data (TBD) 7, 3 (2021), 535â€“547.\n[43] Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Opti-\nmization. In ICLR .\n[44] Lars Kolb, Andreas Thor, and Erhard Rahm. 2012. Dedoop: Efficient Deduplication\nwith Hadoop. PVLDB 5, 12 (2012), 1878â€“1881.\n[45] Lars Kolb, Andreas Thor, and Erhard Rahm. 2012. Load balancing for MapReduce-\nbased entity resolution. In ICDE .\n[46] Pradap Konda, Sanjib Das, AnHai Doan, Adel Ardalan, Jeffrey R Ballard, Han\nLi, Fatemah Panahi, Haojun Zhang, Jeff Naughton, Shishir Prasad, et al .2016.\nMagellan: toward building entity matching management systems over data\nscience stacks. PVLDB 9, 13 (2016), 1581â€“1584.\n[47] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In SIGMOD . 489â€“504.\n[48] Per-Ake Larson, Wolfgang Lehner, Jingren Zhou, and Peter Zabback. 2007. Car-\ndinality estimation using sample views with quality assurance. In SIGMOD .\n[49] Ang Li, Shuaiwen Leon Song, Jieyang Chen, Jiajia Li, Xu Liu, Nathan R Tallent,\nand Kevin J Barker. 2019. Evaluating modern gpu interconnect: Pcie, nvlink,\nnv-sli, nvswitch and gpudirect. IEEE Transactions on Parallel and Distributed\nSystems (TPDS) 31, 1 (2019), 94â€“110.\n[50] Bo-Han Li, Yi Liu, An-Man Zhang, Wen-Huan Wang, and Shuo Wan. 2020. A\nsurvey on blocking technology of entity resolution. Journal of Computer Science\nand Technology 35 (2020), 769â€“793.\n[51] Yuliang Li, Jinfeng Li, Yoshihiko Suhara, AnHai Doan, and Wang-Chiew Tan.\n2020. Deep Entity Matching with Pre-Trained Language Models. PVLDB 14, 1\n(2020), 50â€“60.\n[52] Yinan Li, Jianan Lu, and Badrish Chandramouli. 2023. Selection Pushdown in\nColumn Stores Using Bit Manipulation Instructions. SIGMOD (2023).\n[53] Michael D. Lieberman, Jagan Sankaranarayanan, and Hanan Samet. 2008. A Fast\nSimilarity Join Algorithm Using Graphics Processing Units. In ICDE , Gustavo\nAlonso, JosÃ© A. Blakeley, and Arbee L. P. Chen (Eds.). 1111â€“1120.\n[54] Jonas Lippuner. 2019. NVIDIA CUDA . Technical Report. Los Alamos National\nLab.(LANL), Los Alamos, NM (United States).\n[55] Willi Mann and Nikolaus Augsten. 2014. PEL: Position-Enhanced Length Filter\nfor Set Similarity Joins. In Grundlagen von Datenbanken .\n[56] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul23. 2019. Neo: A Learned\nQuery Optimizer. PVLDB 12, 11 (2019).\n[57] Vahab S. Mirrokni, Mikkel Thorup, and Morteza Zadimoghaddam. 2018. Consis-\ntent Hashing with Bounded Loads. In SODA . 587â€“604.\n[58] Guido Moerkotte. [n.d.]. Building query compilers. ([n. d.]).\n[59] Sidharth Mudgal, Han Li, Theodoros Rekatsinas, AnHai Doan, Youngchoon Park,\nGanesh Krishnan, Rohit Deep, Esteban Arcaute, and Vijay Raghavendra. 2018.\nDeep Learning for Entity Matching: A Design Space Exploration. In SIGMOD ,\nGautam Das, Christopher M. Jermaine, and Philip A. Bernstein (Eds.).\n[60] Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted\nboltzmann machines. In ICML . 807â€“814.\n[61] Negin Nematollahi, Mohammad Sadrosadati, Hajar Falahati, Marzieh Barkhordar,\nMario Paulo Drumond, Hamid Sarbazi-Azad, and Babak Falsafi. 2020. Efficient\nnearest-neighbor data sharing in GPUs. ACM Transactions on Architecture and\nCode Optimization (TACO) 18, 1 (2020), 1â€“26.\n[62] NVIDIA. 2024. NVIDIA V100 TENSOR CORE GPU. https://www.nvidia.com/en-\nus/data-center/v100/.\n[63] Santosh Pandey, Xiaoye Sherry Li, Aydin Buluc, Jiejun Xu, and Hang Liu. 2019.\nH-INDEX: Hash-Indexing for Parallel Triangle Counting on GPUs. In HPEC .\n[64] George Papadakis, Ekaterini Ioannou, Claudia NiederÃ©e, Themis Palpanas, and\nWolfgang Nejdl. 2011. To compare or not to compare: making entity resolution\nmore efficient. In Proceedings of the international workshop on semantic web\ninformation management . 1â€“7.\n[65] George Papadakis, Dimitrios Skoutas, Emmanouil Thanos, and Themis Palpanas.\n2020. Blocking and filtering techniques for entity resolution: A survey. ACM\nComputing Surveys (CSUR) 53, 2 (2020), 1â€“42.\n[66] Vibhor Rastogi, Nilesh Dalvi, and Minos Garofalakis. 2011. Large-Scale Collective\nEntity Matching. PVLDB 4, 4 (2011).\n[67] Astrid RheinlÃ¤nder, Ulf Leser, and Goetz Graefe. 2017. Optimization of complex\ndataflows with user-defined functions. ACM Computing Surveys (CSUR) 50, 3\n\n(2017), 1â€“39.\n[68] Ryan A Rossi and Rong Zhou. 2016. Leveraging multiple gpus and cpus for\ngraphlet counting in large networks. In CIKM . 1783â€“1792.\n[69] Prasan Roy, Srinivasan Seshadri, S Sudarshan, and Siddhesh Bhobe. 2000. Efficient\nand extensible algorithms for multi query optimization. In SIGMOD . 249â€“260.\n[70] Yasin N Silva, Walid G Aref, and Mohamed H Ali. 2010. The similarity join\ndatabase operator. In ICDE .\n[71] Giovanni Simonini, Sonia Bergamaschi, and HV Jagadish. 2016. BLAST: a loosely\nschema-aware meta-blocking approach for entity resolution. PVLDB 9, 12 (2016),\n1173â€“1184.\n[72] Panagiotis Sioulas, Periklis Chrysogelos, Manos Karpathiotakis, Raja Ap-\npuswamy, and Anastasia Ailamaki. 2019. Hardware-Conscious Hash-Joins on\nGPUs. In ICDE . 698â€“709.\n[73] Shaoxu Song and Lei Chen. 2013. Efficient discovery of similarity constraints for\nmatching dependencies. Data & Knowledge Engineering 87 (2013), 146â€“166.\n[74] Leonhard Spiegelberg, Rahul Yesantharao, Malte Schwarzkopf, and Tim Kraska.2021. Tuplex: Data science in python at native code speed. In Proceedings of the\n2021 International Conference on Management of Data . 1718â€“1731.\n[75] Marshall Harvey Stone. 1937. Applications of the theory of Boolean rings to\ngeneral topology. Trans. Amer. Math. Soc. 41, 3 (1937), 375â€“481.\n[76] Yufei Tao. 2018. Massively Parallel Entity Matching with Linear Classification in\nLow Dimensional Space. In ICDT .\n[77] Saravanan Thirumuruganathan, Han Li, Nan Tang, Mourad Ouzzani, Yash\nGovind, Derek Paulsen, Glenn Fung, and AnHai Doan. 2021. Deep learning\nfor blocking in entity matching: a design space exploration. PVLDB 14, 11 (2021),\n2459â€“2472.\n[78] Yining Wang, Liwei Wang, Yuanzhi Li, Di He, and Tie-Yan Liu. 2013. A theoretical\nanalysis of NDCG type ranking measures. In Conference on learning theory .\nPMLR.\n[79] Wei Zhang, Hao Wei, Bunyamin Sisman, Xin Luna Dong, Christos Faloutsos,\nand Davd Page. 2020. Autoblock: A hands-off blocking framework for entity\nmatching. In WSDM .",
  "textLength": 110683
}