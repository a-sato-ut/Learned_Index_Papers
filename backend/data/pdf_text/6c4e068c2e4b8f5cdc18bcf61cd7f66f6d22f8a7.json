{
  "paperId": "6c4e068c2e4b8f5cdc18bcf61cd7f66f6d22f8a7",
  "title": "Competitive caching with machine learned advice",
  "pdfPath": "6c4e068c2e4b8f5cdc18bcf61cd7f66f6d22f8a7.pdf",
  "text": "Competitive caching with machine learned advice\nThodoris Lykouris\u0003Sergei Vassilvitskiiy\nFirst version: February 2018\nCurrent version: August 2020z\nAbstract\nTraditional online algorithms encapsulate decision making under uncertainty and give ways\nto hedge against all possible future events, while guaranteeing a nearly optimal solution, as\ncompared to an oﬄine optimum. On the other hand, machine learning algorithms are in the\nbusiness of extrapolating patterns found in the data to predict the future, and usually come with\nstrong guarantees on the expected generalization error.\nIn this work we develop a framework for augmenting online algorithms with a machine learned\noracle to achieve competitive ratios that provably improve upon unconditional worst case lower\nbounds when the oracle has low error. Our approach treats the oracle as a complete black box,\nand is not dependent on its inner workings, or the exact distribution of its errors.\nWe apply this framework to the traditional caching problem—creating an eviction strategy\nfor a cache of size k. We demonstrate that naively following the oracle’s recommendations may\nlead to very poor performance, even when the average error is quite low. Instead we show how\nto modify the Marker algorithm to take into account the oracle’s predictions, and prove that\nthis combined approach achieves a competitive ratio that both decreases as the oracle’s error\ndecreases, and is always capped by O(logk), which can be achieved without any oracle input.\nWe complement our results with an empirical evaluation of our algorithm on real world datasets,\nand show that it performs well empirically even when using simple oﬀ-the-shelf predictions.\n\u0003Microsoft Research, thlykour@microsoft.com . Work supported under NSF grant CCF-1563714. This work was\ndone while the author was a Ph.D. student at Cornell University and started while the author was interning at Google.\nyGoogle Research, sergeiv@google.com .\nzPreliminary version of the paper appeared at the 35th International Conference on Machine Learning (ICML\n2018). The current version improves the presentation of the suggested framework (Section 2.2), provides a more clear\ndiscussion on how it can be more broadly applied, and ﬁxes some more minor presentation issues in other sections.arXiv:1802.05399v4  [cs.DS]  21 Aug 2020\n\n1 Introduction\nDespitethesuccessandprevalenceofmachinelearnedsystemsacross manyapplicationdomains, there\nare still a lot of hurdles that one needs to overcome to deploy an ML system in practice [ SHG+15].\nAs these systems are rarely perfect, a key challenge is dealing with errors that inevitably arise.\nThere are many reasons that learned systems may exhibit errors when deployed. First, most of them\nare trained to be good on average , minimizing some expected loss. In doing so, the system may\ninvest its eﬀorts in reducing the error on the majority of inputs, at the expense of increased error on\na handful of outliers. Another problem is that generalization error guarantees only apply when the\ntrain and test examples are drawn from the same distribution. If this assumption is violated, either\ndue to distribution drift or adversarial examples [ SZS+14], the machine learned predictions may be\nvery far from the truth. In all cases, any system backed by machine learning needs to be robust\nenough to handle occasional errors.\nWhile machine learning is in the business of predicting the unknown, online algorithms provide\nguidance on how to act without anyknowledge of future inputs. These powerful methods show\nhow to hedge decisions so that, regardless of what the future holds, the online algorithm performs\nnearly as well as the optimal oﬄine algorithm. However these guarantees come at a cost: since they\nprotect against the worst case, online algorithms may be overly cautious, which translates to high\ncompetitive ratios even for seemingly simple problems.\nIn this work we ask:\nWhat if the online algorithm is equipped with a machine learned oracle? How can one use this oracle\nto combine the predictive power of machine learning with the robustness of online algorithms?\nWe focus on a prototypical example of this area: the online paging, or cachingproblem. In this\nsetting, a series of requests arrives one at a time to a server equipped with a small amount of memory.\nUpon processing a request, the server places the answer in the memory (in case an identical request\ncomes in the future). Since the local memory has limited size, the server must decide which of\nthe current elements to evict. It is well known that if the local memory or cachehas sizek, then\nany deterministic algorithm incurs competitive ratio \n(k). However, an O(k)bound can be also\nachieved by almost any reasonable strategy, thus this metric fails to distinguish between algorithms\nthat perform well in practice and those that perform poorly. The competitive ratio of the best\nrandomized algorithm is \u0002(logk)which, despite its elegant analysis, is much higher than what is\nobserved on real inputs.\nIn contrast, we show how to use machine learned predictions to achieve a competitive ratio of\n2 +O(min(p\n\u0011=Opt;logk), when using a predictor with total prediction error of \u0011, where Optis the\nvalue of the oﬄine optimal solution — see Section 3.2 for a precise statement of results. Thus when\nthe predictions are accurate (small \u0011), our approach circumvents the worst case lower bounds. On\nthe other hand, even when the oracle is inaccurate (large \u0011), the performance degrades gracefully to\nalmost match the worst case bound.\n1.1 Our contribution\nThe conceptual contribution of the paper lies in formalizing the interplay between machine learning\nand competitive analysis by introducing a general framework (Section 2), and a set of desiderata for\nonline algorithms that use a machine learned oracle.\n1\n\nWe look for approaches that:\n\u000fMakeminimal assumptions on the machine learned oracle. Speciﬁcally, since most machine\nlearning guarantees are on the expected performance, our results are parametric as a function\nof the error of the oracle, \u0011, and not the distribution of the error.\n\u000fArerobust: a better oracle (one with lower \u0011) results in a smaller competitive ratio\n\u000fAre worst-case competitive : no matter the performance of the oracle on the particular instance,\nthe algorithm behaves comparably to the best online algorithm for the problem.\nWe instantiate the general framework to the online caching problem, specifying the prediction made\nby the oracle, and presenting an algorithm that uses that prediction eﬀectively (Section 3.2). Along\nthe way we show that algorithmic innovation is necessary: simply following the recommendations\nof the predictor may lead to poor performance, even when the average error is small (Section 3.1).\nInstead, we adapt the Marker algorithm [ FKL+91] to carefully incorporate the feedback of the\npredictor. The resulting approach, which we call Predictive Marker has guarantees that capture the\nbest of both worlds: the algorithm performs better as the error of the oracle decreases, but performs\nnearly as well as the best online algorithm in the worst case.\nOur analysis generalizes to multiple loss functions (such as absolute loss and squared loss). This\nfreedom in the loss function with the black-box access to the oracle allows our results to be\nstrengthened with future progress in machine learning and reduces the task of designing better\nalgorithms to the task of ﬁnding better predictors.\nWe complement our theoretical ﬁndings with empirical results (Section 5). We test the performance\nof our algorithm on public data using oﬀ-the-shelf machine learning models. We compare the\nperformance to the Least Recently Used (LRU) algorithm, which serves as the gold standard, the\noriginal Marker algorithm, as well as directly using the predictor. In all cases, the Predictive Marker\nalgorithm outperforms known approaches.\nBefore moving to the main technical content, we provide a simple example that highlights the main\nconcepts of this work.\n1.2 Example: Faster Binary Search\nConsider the classical binary search problem. Given a sorted array Aonnelements and a query\nelementq, the goal is to either ﬁnd the index of qin the array, or state that it is not in the set. The\ntextbook method is binary search: compare the value of qto that of the middle element of A, and\nrecurse on the correct half of the array. After O(logn)probes, the method either ﬁnds qor returns.\nInstead of applying binary search, one can train a classiﬁer, h, to predict the position of qin the array.\n(Although this may appear to be overly complex, Kraska et.al [ KBC+17] empirically demonstrate\nthe advantages of such a method.) How to use such a classiﬁer? A simple approach is to ﬁrst probe\nthe location at h(q); ifqis not found there, we immediately know whether it is smaller or larger.\nSupposeqis larger than the element in A[h(q)]and the array is sorted in increasing order. We probe\nelements at h(q) + 2;h(q) + 4;h(q) + 8, and so on, until we ﬁnd an element larger than q(or we\nhit the end of the array). Then we simply apply binary search on the interval that’s guaranteed to\ncontainq.\nWhat is the cost of such an approach? Let t(q)be the true position of qin the array (or the position\n2\n\nof the largest element smaller than qif it is not in the set). The absolute loss of the classiﬁer on qis\nthen\u000fq=jh(q)\u0000t(q)j. On the other hand, the cost of running the above algorithm starting at h(q)\nis at most 2(logjh(q)\u0000t(q)j) = 2 log\u000fq.\nIf the queries qcome from a distribution, then the expected cost of the algorithm is:\n2Eqh\nlog (jh(q)\u0000t(q)j)i\n\u00142 logEqh\njh(q)\u0000t(q)ji\n= 2 log Eq[\u000fq];\nwhere the inequality follows by Jensen’s inequality. This gives a trade-oﬀ between the performance\nof the algorithm and the absolute loss of the predictor. Moreover, since \u000fqis trivially bounded by n,\nthis shows that even relatively weak classiﬁers (those with average error ofpn) this can lead to an\nimprovement in asymptotic performance.\n1.3 Related work\nOur work builds upon the foundational work on competitive analysis and online algorithms; for\na great introduction see the book by Borodin and El-Yaniv [ BEY98]. Speciﬁcally, we look at the\nstandard caching problem, see, for example, [ MR95]. While many variants of caching have been\nstudied over the years, our main starting point will be the Marker algorithm by Fiat et al. [ FKL+91].\nAs we mentioned earlier, competitive analysis fails to distinguish between algorithms that perform\nwell in practice, and those that perform well only in theory. Several ﬁxes have been proposed to\naddress these concerns, ranging from resource augmentation, where the online algorithm has a larger\ncache than the oﬄine optimum [ ST85], to models of real-world inputs that restrict the inputs\nanalyzed by the algorithm, for example, insisting on locality of reference [ AFG02], or the more\ngeneral Working Set model [Den68].\nThe idea of making assumptions on the nature of the input to prove better bounds is common in the\nliterature. The most popular of these is that the data arrive in a random order. This is a critical\nassumption in the secretary problem, and, more generally, in other streaming algorithms, see for\ninstance the survey by McGregor [ McG14]. While the assumption leads to algorithms with useful\ninsight into the structure of the problem, it rarely holds true, and is often hard to verify.\nAnothercommonassumptiononthestructureoftheinputgivesrisetoSmoothedAnalysis, introduced\nin a pioneering work by Spielman and Teng [ ST04] explaining the practical eﬃciency of the Simplex\nmethod. This approach assumes that any worst case instance is perturbed slightly before being\npassed to the algorithm; the idea is that this perturbation may be due to measurement error, or\nsome other noise inherent in the data. The goal then is to show that the worst case inputs are\nbrittle, and do not survive addition of random noise. Since its introduction this method has been\nused to explain the unusual eﬀectiveness of many practical algorithms such as ICP [ AV06], Lloyd’s\nmethod [AMR11], and local search [ERV16], in the face of exponential worst case bounds.\nThe prior work that is closest in spirit to ours looks for algorithms that optimistically assume\nthat the input has a certain structure, but also have worst case guarantees when that fails to be\nthe case. One such assumption is that the data are coming from a stochastic distribution and\nwas studied in the context of online matching [ MGZ12] and bandit learning [ BS12]; both of these\nworks provide improved guarantees if the input is stochastic but retain the worst-case guarantees\notherwise. Subsequent work has provided a graceful decay in performance when the input is mostly\nstochastic (analogous to our robustness property) both in the context online matching [ EKM15]\n3\n\nand bandit learning [ LMPL18 ]. In a related note, Ailon et al. [ ACC+11] consider “self-improving”\nalgorithms that eﬀectively learn the input distribution, and adapt to be nearly optimal in that\ndomain. Contrasting to these works, our approach utilizes a diﬀerent structure in the data: the fact\nthat the sequence can be predicted.\nOur work is not the ﬁrst to use predictions to enhance guarantees in online decision-making. The\nability to predict something about the input has also used been used in online learning by Rakhlin\nand Sridharan [ RS13] where losses of next round are predicted and the guarantees scale with how\nerroneous these precitions are. Our focus is on competitive analysis approaches where requests\naﬀect the state of the system; as a result, a single misprediction can have long-lasting eﬀect on the\nsystem. With respect to using predictions in competitive analysis, another approach was suggested\nby Mahdian et al. [ MNS12], who assume the existence of an optimistic, highly competitive, algorithm,\nand then provide a meta algorithm with a competitive ratio that interpolates between that of the\nworst-case algorithm and that of the optimistic one. This work is most similar to our approach, but\nit ignores two key challenges that we face: (i) identifying predictions that can lead to (near) oﬄine\noptimality, and (ii) developing algorithms that use these predictions eﬀectively in a robust way. The\nwork of Mahdian et al. [ MNS12] starts directly from the point where such an “optimistic” algorithm\nis available, and combines it with a “good in the worst-case” algorithm in a black-box manner. This\nhas similarities to the approaches we discuss in Section 4.3 and Remark 4.4 but does not answer\nhow to develop the optimistic algorithm. As we show in the paper, developing such algorithms may\nbe non-trivial even when the predictions are relatively good.\nIn other words, we do not assume anything about the data, or the availability of good algorithms\nthat work in restricted settings. Rather, we use the predictor to implicitly classify instances into\n“easy” and “hard” depending on their predictability. The “easy” instances are those on which the\nlatest machine learning technology, be it perceptrons, decision trees, SVMs, Deep Neural Networks,\nGANs, LSTMs, or whatever else may come in the future, has small error. On these instances our\ngoal is to take advantage of the predictions, and obtain low competitive ratios. (Importantly, our\napproach is completely agnostic to the inner workings of the predictor and treats it as a black box.)\nThe “hard” instances, are those where the prediction quality is poor, and we have to rely more on\nclassical competitive analysis to obtain good results.\nA previous line of work has also considered the beneﬁt of enhancing online algorithms with oracle\nadvice (see [ BFK+16] for a recent survey). This setting assumes access to an infallible oracle and\nstudies the amount of information that is needed to achieve desired competitive ratio guarantees.\nOur work diﬀers in two major regards. First, we do not assume that the oracle is perfect, as that is\nrarely the case in machine learning scenarios. Second, we study the trade-oﬀ between oracle error\nand the competitive ratio, rather than focusing on the number of perfect predictions necessary.\nAnother avenue of research close to our setting asks what happens if the algorithm cannot view the\nwhole input, but must rely on a sample of the input to make its choices. Introduced in the seminal\nwork of Cole and Roughgarden [ CR14], this notion of Learning from Samples, can be viewed as ﬁrst\ndesigning a good prediction function, h, and then using it in the algorithms. Indeed, some of the\nfollow up work [ MR16,BRS17] proves tight bounds on precisely how many samples are necessary to\nachieve good approximation guarantees. In contrast, we assume that the online algorithm is given\naccess to a machine learned predictor, but does not know any details of its inner workings—we know\nneither the average performance of the predictor, nor the distribution of the errors.\nVery recently, two papers explored domains similar to ours. Medina and Vassilvitskii [ MV17] showed\nhow to use a machine learned oracle to optimize revenue in repeated posted price auctions. Their\n4\n\nwork has a mix of oﬄine calculations and online predictions and focuses on the speciﬁc problem of\nrevenue optimization. Kraska et al. [ KBC+17] demonstrated empirically that introducing machine\nlearned components to classical algorithms (in their case index lookups) can result in signiﬁcant\nspeed and storage gains. Unlike this work, their results are experimental, and they do not provide\ntrade-oﬀs on the performance of their approach vis-à-vis the error of the machine learned predictor.\nFinally, since the publication of the original paper, learning augmented algorithms has emerged\nas a rich area. Subsequently to our work, researchers have studied how to incorporate machine\nlearned predictions in other settings such as ski rental [ PSK18,GP19], scheduling [ PSK18,ADJ+19,\nLLMV20 ], bin packing [ ADJ+19], bloom ﬁlters [ Mit18,VKKM20 ], queueing [ Mit20], streaming\nalgorithms [ HIKV19], weighted paging [ JPS20], and page migration [ IMTMR20 ]. While many of\nthese focus on improving competitive ratios, some of them explore other performance metrics, such\nas space complexity [ HIKV19,Mit18,VKKM20 ]. With respect to the unweighted caching problem\nwe consider, subsequent work has also provided reﬁned guarantees under our prediction model\n[Roh20, Wei20] or alternate prediction models [ACE+20].\n2 Online Algorithms with Machine Learned Advice\nIn this section, we introduce a general framework for combining online algorithms with machine\nlearning predictions, which we term Online with Machine Learned Advice framework (OMLA).\nBefore introducing the framework, we review some basic notions from machine learning and online\nalgorithms.\n2.1 Preliminaries\nMachine learning basics. We are given a feature space X, describing the salient characteristics\nof each item and a set of labels Y. An example is a pair (x;y), wherex2Xdescribes the speciﬁc\nfeatures of the example, and y2Ygives the corresponding label. In the binary search example, x\ncan be thought as the query element qsearched and yas its true position t(x).\nA hypothesis is a mapping h:X!Yand can be probabilistic in which case the output on x2Xis\nsome probabilistically chosen y2Y. In binary search, h(x)corresponds to the predicted position of\nthe query.\nTo measure the performance of a hypothesis, we ﬁrst deﬁne a loss function `:Y\u0002Y ! R\u00150.\nWhen the labels lie in a metric space, we deﬁne absolute loss `1(y;^y) =jy\u0000^yj, squared loss\n`2(y;^y) = (y\u0000^y)2, and, more generally, classiﬁcation loss `c(y;^y) =1y6=^y.\nCompetitive analysis. To obtain worst-case guarantees for an online algorithm (that must make\ndecisions as each element arrives), we compare its performance to that of an oﬄine optimum (that\nhas the beneﬁt of hindsight). Let \u001bbe the input sequence of elements for a particular online\ndecision-making problem, costA(\u001b)be the cost incurred by an online algorithm Aon this input, and\nOpt(\u001b)be the cost incurred by the optimal oﬄine algorithm. Then algorithm Ahas competitive\nratiocrif for all sequences \u001b,\ncostA(\u001b)\u0014cr\u0001Opt(\u001b):\n5\n\nIf the algorithmAis randomized then costA(\u001b)corresponds to the expected cost of the algorithm\nin input\u001bwhere the expectation is taken over the randomness of the algorithm.\nThe Caching Problem. The caching (or online paging) problem considers a system with two\nlevels of memory: a slow memory of size mand a fast memory of size k. A caching algorithm is\nfaced with a sequence of requests for elements. If the requested element is in the fast memory, a\ncache hit occurs and the algorithm can satisfy the request at no cost. If the requested element is not\nin the fast memory, a cache miss occurs, the algorithm fetches the element from the slow memory,\nand places it in the fast memory before satisfying the request. If the fast memory is full, then one of\nthe elements must be evicted. The eviction strategy forms the core of the problem. The goal is to\nﬁnd an eviction policy that results in the fewest number of cache misses.\nIt is well known that the optimal oﬄine algorithm at time tevicts the element from the cache that\nwill arrive the furthest in the future; this is typically referred to in the literature as Bélády’s optimal\nreplacement paging algorithm [ Bel66]. On the other hand, without the beneﬁt of foresight, any\ndeterministic caching algorithm achieves a competitive ratio of \n(k), and any randomized caching\nalgorithm achieves a competitive ratio of \n(logk)[MR95].\n2.2 OMLA Deﬁnition.\nTo deﬁne our framework in generality, we consider a general problem setting associated with a\ngeneral prediction model and then explain how both can be instantiated in the context of caching.\nIn traditional online algorithms, there is an universe Zand elements zi2Zarrive one at a time\nfor roundsi= 1;2;:::. The problem \u0005speciﬁes the optimization problem at hand, along with the\nrequired constraints and any necessary parameters. For example, in the problem of caching studied\nin this paper, \u0005caching =Caching (n;k), is parametrized by the number of requests nand the cache\nsizek.\nAugmenting online algorithms with machine learned predictors. In our framework, we\nassume that the requested elements are augmented with a feature space X(discussed below). We\nrefer to the resulting feature-augmented elements as itemsand denote the item of the i-th request\nby\u001bi. An input \u001b2\u0005corresponds to a sequence of items: \u001b= (\u001b1;\u001b2;:::). For the problem of\ncaching \u0005caching =Caching (n;k), the item sequence \u001bhas lengthn.\nEach item is associated with a particular element by z(\u001bi)2Zas well as a feature x(\u001bi)2X. The\nfeatures capture any information that may be available to the machine learning algorithm to help\nprovide meaningful predictions. In caching, these may include information about the sequence prior\nto the request, time patterns associated to the particular request, or any other information. We note\nthat even for caching, items are more general than their associated element: two items with the\nsame element are notnecessarily the same as their corresponding features may diﬀer.\nPrediction model. The prediction model Hprescribes a label space Y; thei-th item has label\ny(\u001bi)2Y. This label space can be viewed as the information needed to solve the task (approximately)\noptimally. As we discuss in the end of Section 2.2, deciding on a particular label space is far from\ntrivial and it often involves trade-oﬀs between learnability and accuracy.\n6\n\nGiven a prediction model Hdetermining a label space Y, a machine learned predictor h2Hmaps\nfeaturesx2Xto predicted labels h(x)2Y. In particular, for item \u001bi, the predictor hreturns\na predicted label h(x(\u001bi)). To ease notation we denote this by h(\u001bi). Here we assume that this\nmapping from features to labels is deterministic; our results extend to randomized mappings by\napplications of Jensen’s inequality (see Section 3.5).\nLoss functions and error of predictors. To evaluate the performance of a predictor on a\nparticular input, we consider a loss function `. Similar to the prediction model, selecting a loss\nfunction involves trade-oﬀs between learnability of the predictor and resulting performance guarantees;\nwe elaborate on these trade-oﬀs in the end of Section 2.2. For a given loss function `, problem \u0005,\nand prediction model H, the performance of the predictor h2Hon input\u001b2\u0005is evaluated by its\nerror\u0011`(h;\u001b). In full generality, this error can depend on the whole input in complicated ways.\nFor the caching problem, the prediction model we consider predicts the subsequent time that a\nrequested element will get requested again. In this case, a natural loss function such as absolute or\nsquared loss decomposes the error across items. In later sections, we focus on such loss functions\nthroughout this paper and therefore can express the error as:\n\u0011`(h;\u001b) =X\ni`(y(\u001bi);h(\u001bi)):\nInstantiated with the absolute loss function, the error of the predictor is \u0011`1(h;\u001b) =P\nijy(\u001bi)\u0000h(\u001bi)j.\nWe will use \u00111(h;\u001b)as a shorthand for this absolute loss.\nWe note that this decomposition across items may not be possible. For example, edit distance\ndoes not decompose across items but needs to be evaluated with respect to the whole instance.\nThe general framework we deﬁne extends to such non-decomposable loss functions but the above\nrestriction lets us better describe our results and draws more direct connection with classical machine\nlearning notions.\nWe now summarize the general concepts of our framework in the following deﬁnition.\nDeﬁnition 1. TheOnline with Machine Learned Advice (OMLA) framework is deﬁned with respect\nto a) a problem \u0005, b) a prediction model Hdetermining a feature space Xand a label space Y, and\nc) a loss function `. An instance consists of:\n\u000fAn input\u001b2\u0005consisting of items \u001biarriving online, each with features x(\u001bi)2Xand label\ny(\u001bi)2Y.\n\u000fA predictor h:X!Ythat predicts a label h(\u001bi)for eachx(\u001bi)2X.\n\u000fThe error of predictor hat sequence \u001bw.r.t. loss`,\u0011`(h;\u001b).\nOur goal is to create online algorithms that, when augmented with a predictor h, can use its advice\nto achieve an improved competitive ratio. To evaluate how well an algorithm Aperforms with\nrespect to this task, we extend the deﬁnition of competitive ratio to be a function of the predictor’s\nerror. We ﬁrst deﬁne the set of predictors that are suﬃciently accurate.\nDeﬁnition 2. For a ﬁxed optimization problem \u0005, letOpt \u0005(\u001b)denote the value of the optimal\nsolution on the input \u001b. Consider a prediction model H. A predictor h2His\u000f-accurate with respect\nto a loss function `for\u0005if for any\u001b2\u0005:\n\u0011`;H;\u0005(h;\u001b)\u0014\u000f\u0001Opt \u0005(\u001b):\n7\n\nWe will useH`;H;\u0005(\u000f)to denote the class of \u000f-accurate predictors.\nAt ﬁrst glance, it may appear unnatural to tie the error of the prediction to the value of the optimal\nsolution. However, our goal is to have a deﬁnition that is invariant to simple padding arguments.\nFor instance, consider a sequence \u001b0=\u001b\u001b, which concatenates two copies of an input \u001b.1It is clear\nthat the prediction error of any predictor doubles, but this is not due to the predictor suddenly\nbeing worse. One could instead normalize the prediction error by the length of the sequence, but in\nmany problems, including caching, one can artiﬁcially increase the length of the sequence without\nimpacting the value of the optimum solution, or the impact of predictions. Normalizing by the value\nof the optimum addresses both of these problems.\nCall an algorithm A\u000f-assisted if it has access to an \u000f-accurate predictor. The competitive ratio of\nan\u000f-assisted algorithm is itself a function of \u000fand may also depend on parameters speciﬁed by \u0005\nsuch as the cache size kor the number of elements n.\nDeﬁnition 3. For a ﬁxed optimization problem \u0005and a prediction model H, letinputCRA;H;\u0005(h;\u001b)\nbe the competitive ratio of algorithm Athat uses a predictor h2Hwhen applied on an input \u001b2\u0005.\nThecompetitive ratio of an\u000f-assisted algorithm Afor problem \u0005with respect to loss function `and\nprediction modelHis:\ncrA;`;H;\u0005(\u000f) = max\n\u001b2\u0005;h2H`;H;\u0005(\u000f)inputCRA;H;\u0005(h;\u001b):\nWe now deﬁne the desiderata that we wish our algorithm to satisfy. We would like our algorithm to\nperform as well as the oﬄine optimum when the predictor is perfect, degrade gracefully with the\nerror of the predictor, and perform as well as the best online algorithm regardless of the error of the\npredictor. We deﬁne these properties formally for the performance of an algorithm Aa particular\nloss function `, prediction model H, and problem \u0005.\nDeﬁnition 4.Ais\f-consistent ifcrA;`;H;\u0005(0) =\f.\nDeﬁnition 5.Ais\u000b-robustfor a function \u000b(\u0001), ifcrA;`;H;\u0005(\u000f) =O(\u000b(\u000f)).\nDeﬁnition 6.Ais\r-competitive ifcrA;`;H;\u0005(\u000f)\u0014\rfor all values of \u000f.\nOur goal is to ﬁnd algorithms that simultaneously optimize the aforementioned three properties.\nFirst, they are ideally 1-consistent: recovering the optimal solution when the predictor is perfect.\nThis is not necessarily feasible for multiple reasons. From a computational side, the underlying\nproblem may be NP-hard. Moreover, achieving any notion of robustness may inevitably be at odds\nwith exact consistency. As a result, we are satisﬁed with \f-consistency for some small constant\n\f. Second, they are \u000b(\u0001)-robust for a slow growing function \u000b: seamlessly handling errors in the\npredictor. This function depends on the exact prediction model and the way that the loss is deﬁned\nwith respect to it. As discussed below, diﬀerent prediction models and loss functions may well lead\nto diﬀerent robustness guarantees while also achieve diﬀerent levels of learnability. Finally, they are\nworst-case competitive: they perform as well as the best online algorithms even when the predictor’s\nerror is high. As hinted before, all competitive ratios can be functions of the problem dimensions\ninherent in \u0005; for example, in caching, the worst-case performance \rneeds to depend on the cache\nsizek. Ideally, the consistency and robustness quantities \fand\u000b(\u000f)(for small\u000f>0) do not display\nsuch dependence on these problem dimensions.\n1In order for both instances to be equally sized and therefore be inputs of the same problem \u0005, we can think of\npadding the end of the ﬁrst instance with the same dummy request.\n8\n\nDiscussion on the OMLA framework. For the caching problems predictions and loss functions\nas decomposable per element, but one can also deﬁne predictions with respect to diﬀerent parts of\nthe instance. For example, subsequent works used strong lookahead for weighted paging [ JPS20]\nand learned weights for scheduling [ LLMV20 ] – both of these prediction models are not per-element.\nSimilarly, loss functions can be computed with respect to the complete instance. Per-item predictions,\nhowever, have a stronger connection to classical machine learning terminology.\nNext, thus far we have disregarded the question of where the predictor comes from and how learnable\nit is. This is an important question and has been elegantly discussed in multiple contexts such as\nrevenue maximization [ CR14]. In general, the decision on both the prediction model Hand the\nloss function `needs to take into account the learnability question and better understanding of the\nexact trade-oﬀs is a major open direction of our work. Subsequent work sheds further light on the\nlearnability question in the context of our framework [AGP20].\nFinally, although we deﬁne our framework with respect to competitive analysis, predictions can\nbe useful to augment online algorithm design with respect to other metrics such as space com-\nplexity [HIKV19,Mit18,VKKM20 ] and our framework can be easily extended to capture such\nperformance gains.\n2.3 Caching with ML Advice\nIn order to instantiate the framework to the caching problem, we need to specify the items of the\ninput sequence \u001b, the prediction model H(and thereby the label space Y), as well as the loss function\n`. Each item corresponds to one request \u001bi; the latter is associated with an element z(\u001bi)2Zand\nfeaturesx(\u001bi)2Xthat encapsulate any information available to the machine learning algorithm.\nThe element space Zconsists of the melements of the caching problem deﬁned in Section 2.1. The\nexact choice of the feature space Xis orthogonal to our setting, though of course richer features\ntypically lead to smaller errors. The input sequence \u001b= (\u001b1;\u001b2;:::)of the requested items is\nassumed to be ﬁxed in advance and is oblivious to the realized randomness of the algorithm but\nunknown to the algorithm.\nThe main design choice of the prediction model is the question of what to predict which is captured\nin our framework by the choice of the label space. For caching problems, a natural candidate is\npredicting the next time a particular element is going to appear. It is well known [ Bel66] that when\nsuch predictions are perfect, the online algorithm can recover the best oﬄine optimum. Formally,\nthe label spaceYwe consider is a set of positions in the sequence, Y=N+. Given a sequence \u001b, the\nlabel of the i-th element is y(\u001bi) =mint>ift:x(\u001bt) =x(\u001bi)g. If the element is never seen again, we\nsety(\u001bi) =n+ 1. Note that y(\u001bi)is completely determined by the sequence \u001b. We useh(\u001bi)to\ndenote the outcome of the prediction on an element with features x(\u001bi). Note that the feature is\nnot only a function of the element identity z(\u001bi); when an element reappears, its features may be\ndrastically diﬀerent.\nIn what follows, we ﬁx the problem \u0005 =Caching (n;k)to a caching problem with nrequests and\ncache sizekand the prediction model Hto be about the next appearance of a requested element.\nWe consider a variety of loss functions (discussed in detail in Section 3.3) that capture for example\nabsolute and squared loss functions. To ease notation, we therefore drop any notational dependence\non the prediction model Hand the problem \u0005as both are ﬁxed throughout the rest of the paper,\nbut keep the dependence on the loss function `.\n9\n\n3 Main result: Predictive Marker\nIn this section, we describe the main result: an algorithm that satisﬁes the three desiderata of the\nprevious section. Before describing our algorithm, we show that combining the predictions with\nideas from competitive analysis is to a large extent essential; blindly evicting the element that is\npredicted the furthest in the future by the predictor (or simple modiﬁcations of this idea) can result\nin poor performance both with respect to robustness and competitiveness.\n3.1 Blindly following the predictor is not suﬃcient\nEvicting element predicted the furthest in the future. An immediate way to use the\npredictor is to treat its output as truth and optimize based on the whole predicted sequence. This\ncorresponds to Bélády rule that evicts the element predicted to appear the furthest in the future.\nWe refer to this algorithm as algorithm B(as it follows the Bélády rule). Since this rule achieves\noﬄine optimality, this approach is consistent, i.e. if the predictor is perfect, this algorithm is ex-post\noptimal. Unfortunately this approach does not have similarly nice performance with respect to the\nother two desiderata. With respect to robustness, the degradation with the average error of the\npredictor is far from the best possible, while a completely unreliable predictor leads to unbounded\ncompetitive ratios, far from the ones of the best online algorithm.\nProposition 3.1. Consider the caching problem \u0005withnrequests and cache size k, the prediction\nmodelHthat predicts the next arrival of a requested element and the absolute loss function `1. The\ncompetitive ratio of \u000f-assisted algorithm BiscrB;`1(\u000f) = \n(\u000f).\nThe implication is that when the error of the predictor is much worse than the oﬄine optimum, the\ncompetitive ratio becomes unbounded. With respect to robustness, the rate of decay is far from\noptimal as we will see in Section 3.3.\nProof of Proposition 3.1. We will show that for every \u000f, there exist a sequence \u001band a predictor h\nsuch that the absolute error \u00111(h;\u001b)\u0014\u000f\u0001Optwhile the competitive ratio of algorithm Bis\u000f\u00001\n2. For\nease of presentation, assume that \u000f>3. Consider a cache of size k= 2and three elements a;b;c; the\ninitial conﬁguration of cache is a;c. The sequence consists of repetitions of the following sequence\nwith\u000frequests per repetition. The actual sequence is abcbc:::bc|{z}\n\u000f\u00001abcbc:::bc|{z}\n\u000f\u00001:::(aappears once\nand thenbcappears (\u000f\u00001)=2times).\nIn any repetition, the predictor accurately predicts the arrival time of all elements apart from two: i)\nwhen element aarrives, it predicts that it will arrive again two steps after the current time (instead\nof in the ﬁrst step of the next repetition) and ii) when barrives for the last time in one repetition, it\npredicts it to arrive again in the fourth position of the next repetition (instead of the second). As a\nresult, the absolute error of the predictor is \u000f(\u000f\u00002error in the a-misprediction and 2error in the\nb-misprediction). The optimal solution has two evictions per repetition (one to bring ain the cache\nand one to directly evict it afterwards). Instead, the algorithm never evicts aas it is predicted to\narrive much earlier than all other elements, and therefore has \u000f\u00001cache misses. This means that\nthe competitive ratio of this algorithm is \n(\u00111(h;\u001b)=Opt(\u001b))which completes the proof.\nEvicting elements with proven wrong predictions. The problem in the above algorithm is\nthat algorithmBkeeps too much faith in predictions that have been already proven to be wrong\n10\n\n(as the corresponding elements are predicted to arrive in the past). It is tempting to “ﬁx” the issue\nby evicting any element whose predicted time has passed, and evict again the element predicted\nthe furthest in the future if no such element exists. We call this algorithm Was it takes care of\nwrong predictions. Formally, let h(j;t)denote the last prediction about zjat or prior to time t.\nAt timetalgorithmWevicts an arbitrary element from the set St=fj:h(j;t)<tgifSt6=;\nandarg maxzi2Cache(t)h(i;t)otherwise. We show that algorithm Whas similarly bad performance\nguarantees.\nProposition 3.2. Consider the caching problem \u0005withnrequests and cache size k, the prediction\nmodelHthat predicts the next arrival of a requested element and the absolute loss function `1. The\ncompetitive ratio of \u000f-assisted algorithm WiscrW;`1(\u000f) = \n(\u000f).\nProof.Consider a cache of size k= 3and four elements a;b;c;d; the initial conﬁguration of cache is\na;b;cand thendarrives. The actual sequence consists of repetitions of the following sequence with\n(\u000f=2) + 1requests per repetition (for ease of presentation, assume that \u000f>6). The actual sequence\n\u001bisdabcabc:::abc|{z}\n\u000f=2dabcabc:::abc|{z}\n\u000f=2:::.\nIn any repetition, the predictor haccurately predicts the arrival time of element dbut always makes\nmistake in elements a;b;cby predicting them to arrive two time steps earlier. As a result, the\nabsolute error of the predictor is \u000f(error of 2for any of the appearances of a;b;c). The optimal\nsolution has two evictions per repetition (one to bring element dand one to evict it afterwards).\nInstead the algorithm always evicts elements a;b;cbecause they are predicted earlier than their\nactual arrival and are therefore evicted as “wrong” predictions. This means that the competitive\nratio of this algorithm is also \n(\u00111(h;\u001b)=Opt(\u001b))which completes the proof.\nThe latter issue can be again ﬁxed by further modiﬁcations of the algorithm but these simple examples\ndemonstrate that, unless taken into account, mispredictions can cause signiﬁcant ineﬃciency in the\nperformance of the algorithms.\nBeyond blindly trusting the predictor. The common problem in both examples is that there\nis an element that should be removed but the algorithm is tricked into keeping it in the cache. To\ndeal with this in practice, most popular heuristics such as LRU (Least Recently Used) and FIFO\n(First In First Out) avoid evicting recent elements when some elements have been dormant for a\nlong time. This tends to utilize nice locality properties leading to strong empirical performance\n(especially for LRU). However, such heuristics impose a strict eviction policy which leads to weak\nperformance guarantees. Moreover, incorporating additional information provided by the predictor\nbecomes complicated.\nCompetitive analysis has also built on the idea of evicting dormant elements via developing algorithms\nwith stronger theoretical guarantees such as Marker. In the next subsection, we show how we can\nincorporate predictions in the Marker algorithm to enhance its performance when the predictions\nare good while retaining the worst-case guarantees. Interestingly, via our framework, we can provide\nimproved guarantees for the aforementioned heuristics such as LRU, improving their worst-case\nguarantees while retaining their practical performance (see Section 4.2).\n11\n\n3.2 Predictive Marker Algorithm\nWe now present our main technical contribution, a prediction-based adaptation of the Marker\nalgorithm [ FKL+91]. This\u000f-assisted algorithm gets a competitive ratio of 2\u0001min(1 +p\n5\u000f;2Hk)\nwhereHk= 1 + 1=2+\u0001\u0001\u0001+1=kdenotes the k-th Harmonic number.\nClassic Marker algorithm. We begin by recalling the Marker algorithm and the analysis of\nits performance. The algorithm runs in phases. At the beginning of each phase, all elements are\nunmarked. When an element arrives and is already in the cache, the element is marked. If it is not\nin the cache, a random unmarked element is evicted, the newly arrived element is placed in the cache\nand is marked. Once all elements are marked and a new cache miss occurs, the phase ends and we\nunmark all of the elements.\nFor the purposes of analysis, an element is called cleanin phaserif it appears during phase r,\nbut does not appear during phase r\u00001. In contrast, elements that also appeared in the previous\nphase are called stale. The marker algorithm has a competitive ratio of 2Hk\u00001and the analysis is\ntight [ACN00]. We use a slightly simpler analysis that achieves competitive ratio of 2Hkbelow.\nThe crux of the upper bound lies in two claims. The ﬁrst relates the performance of the optimal\noﬄine algorithm to the total number of clean elements Qacross all phases.\nClaim 1 ([FKL+91]).LetQbe the number of clean elements. Then the optimal algorithm suﬀers\nat leastQ=2cache misses.\nThe second comes from bounding the performance of the algorithm as a function of the number of\nclean elements.\nClaim 2 ([FKL+91]).LetQbe the number of clean elements. Then the expected number of cache\nmisses of the marker algorithm is Q\u0001Hk.\nPredictive Marker. The algorithm of [ FKL+91] is part of a larger family of marking algorithms;\ninformally, these algorithms never evict marked elements when there are unmarked elements present.\nAny algorithm in this family has a worst-case competitive ratio of k. Therefore pairing predictions\nwith a marking algorithm would avoid the pathological examples we saw previously.\nA natural approach is to use predictions for tie-breaking, speciﬁcally evicting the element whose\npredicted next appearance time is furthest in the future. When the predictor is perfect (and has\nzero error), the stale elements never result in cache misses, and therefore, by Claim 1, the algorithm\nhas a competitive ratio of 2. On the other hand, by using the Marker algorithm and not blindly\ntrusting the oracle, we can guarantee a worst-case competitive ratio of k.\nWe extend this direction to further reduce the worst-case competitive ratio to O(Hk). To achieve\nthis, we combine the prediction-based tie-breaking rule with the random tie-breaking rule. Suppose\nan element eis evicted during the phase. We construct a blame graph to understand the reason why\neis evicted; this may happen for two distinct reasons. First, emay have been evicted when a clean\nelementcarrived; in this case, we create a new node cwhich can be thought as the start of a distinct\nchain of nodes. Alternatively, it may have been evicted because a stale element sarrived (swas\npreviously evicted in the same phase); in this case, we add a directed edge from etos. Note that the\ngraph is always a set of chains (paths). The total length of the chains represents the total number\nof evictions incurred by the algorithm during the phase, whereas the number of distinct chains\n12\n\nrepresents the number of clean elements. We call the lead element in every chain representative and\ndenote it by !(r;c), whereris the index of the phase and cthe index of the chain in the phase.\nOur modiﬁcation is simple – when a stale element arrives, it evicts a new element in a prediction-based\nmanner if the chain containing it has length less than Hk. Otherwise it evicts a random unmarked\nelement. Looking ahead to the analysis, this switch to uniform evictions results in at most Hk\nadditional elements added to any chain during the course of the phase. This guarantees that the\ncompetitive ratio is at most O(Hk)in expectation; we make the argument formal in Theorem 3.3.\nThe key to the analysis is the fact that the chains are disjoint, thus the interactions between evictions\ncan be decomposed cleanly. We give a formal description of the algorithm in Algorithm 1. For\nsimplicity, we drop dependence on \u001bfrom the notation.\nAlgorithm 1 Predictive Marker\nRequire: CacheCof sizekinitially empty (C ;).\n1:Initialize phase counter r 1, unmark all elements ( M ;), and set round i 1.\n2:Initialize clean element counter qr 0and tracking setS ;.\n3:Elementziarrives, and the predictor gives a prediction hi. Save prediction p(zi) hi.\n4:ifziresults in cache hit or the cache is not full ( zi2CorjCj<k)then\n5:Add to cache C C[fzigwithout evicting any element and go to step 26\n6:end if\n7:ifthe cache is full and all cache elements are marked ( jMj=k)then\n8:Increase phase ( r r+ 1), initialize clean counter ( qr 0), save current cache ( C!S) as\nthe set of elements that are possibly stale in the new phase, and unmark elements ( M ;).\n9:end if\n10:ifziis a clean element ( zi=2S)then\n11:Increase number of clean elements: qr qr+ 1.\n12:Initialize size of new clean chain: n(r;qr) 1.\n13:Select to evict unmarked element with highest predicted time: e= arg maxz2C\u0000Mp(z).\n14:end if\n15:ifziis a stale element ( zi2S)then\n16:It is the representative of some clean chain. Let cbe this clean chain: zi=!(r;c).\n17:Increase length of the clean chain n(r;c) n(r;c) + 1.\n18:ifn(r;c)\u0014Hkthen\n19:Select to evict unmarked element with highest predicted time: e= arg maxz2C\u0000Mp(z).\n20:else\n21:Select to evict a random unmarked element e2C\u0000M .\n22:end if\n23:Update cache by evicting e:C C[fzig\u0000feg.\n24:Seteas representative for the chain: !(r;c) e.\n25:end if\n26:Mark incoming element ( M M[f zig), increase round ( i i+ 1), and go to step 3.\n3.3 Analysis\nIn order to analyze the performance of the proposed algorithm, we begin with a technical deﬁnition\nthat captures how slowly a loss function `can grow.\n13\n\nDeﬁnition 7. LetATbe the set of all the sequences AT=a1;a2;:::;aTof increasing integers of\nlengthT, that isa1< a 2< ::: < a T, andBTbe the set of all sequences BT=b1;b2;:::;bTof\nnon-increasing reals of length T,b1\u0015b2\u0015:::\u0015bT. For a ﬁxed loss function `, we deﬁne its spread\nS`:N+!R+as:\nS`(m) = minfT:8AT2AT;BT2BT:`(AT;BT)\u0015mg\nThe spread captures the length of a subsequence that can be predicted in completely reverse order\nas a function of the error of the predictor with respect to loss function `. We note that the sequence\nBTis assumed to be over reals instead of integers as it corresponds to the outcome of the machine\nlearned predictor and we do not want to unnecessarily restrict the output of this predictor.\nThe following Lemma instantiates the spread for loss metrics we consider and is proved in the\nAppendix A.\nLemma 3.1. For absolute loss, `1(A;B) =P\nijai\u0000bij, the spread of `1isS`1(m)\u0014p\n5m.\nFor squared loss, `2(A;B) =P\ni(ai\u0000bi)2, the spread of `2isS`2(m)\u00143p\n14m:\nWe now prove the main theorem of the paper.\nTheorem 3.3. Consider the caching problem \u0005withnrequests and cache size k, the prediction\nmodelHthat predicts the next arrival of a requested element and any loss function `with spread\nbounded by S`for some function S`that is concave in its argument. Then the competitive ratio of\n\u000f-assisted Predictive Marker PMis bounded by:\ncrPM;`(\u000f)\u00142\u0001min (1 + 2S`(\u000f);2Hk):\nTo prove this theorem, we ﬁrst introduce an analogue of Claim 2, which decomposes the total cost\ninto that incurred by each of the chains individually.\nTo aid in our analysis, we consider the following marking algorithm, which we call SM(Special\nMarking). Initially we simply evict an arbitrary unmarked element. At some point, the adversary\ndesignates an arbitrary element not in the cache as special. For the rest of the phase, upon a\ncache miss, if the arriving element is special, the algorithm evicts a randomunmarked element\nand designates the evicted element as special. If the arriving element is not special, the algorithm\nproceeds as before, evicting an arbitrary unmarked element.\nLemma 3.2. Using algorithm SM, in expectation at most Hkspecial elements cause cache misses\nper phase.\nProof.Since we use a marking algorithm, the set of elements that are in the cache at the end of\neach phase is determined by the element sequence (z1;z2;:::)and is independent of the particular\neviction rule among unmarked elements. Fix a phase that begins at time \u001c. LetEbe the set of k\ndistinct elements that arrive in this phase. Note that the arrival of the k+ 1st distinct elements\nstarts a new phase.\nConsider the time \u001c?that an element is designated special and assume that, at this time, there are\ni?special elements. At this point, we deﬁne A\u0012Eto be the subset of the initial elements that are\nunmarked and in the cache; we refer to this set as the candidate special set as they are the only\nones that can subsequently get designated as special; the set’s initial cardinality is i?. This set is\nshrinking over time as elements are getting marked or evicted from the cache. Order the elements\nby the time of their ﬁrst requst in this phase.\n14\n\nWe now bound the probability of the event Eithat an element becomes special when it is the i-th\nlast element in A(based on the ordering by ﬁrst arrival). By principle of deferred decisions, we\nconsider the ﬁrst time that, upon request of a special element, it evicts one of the last ielements in\nthe active set. If this never happens then the event Einever occurs. Otherwise, observe that we\nselect the element to evict uniformly at random, and there exists at least one element in the cache\nthat never appears before the end of the phase. Second, if at any point an element jamong the\ni\u00001elements in the active set becomes special, the i-th element can no longer become special as, at\nthe time that jis requested, iis already marked. The above imply that the probability of the event\nEiis at most:\nPr[Ei]\u00141\ni+ 1: (1)\nTherefore, given Equation (1), we can bound the expected number of misses caused by special\nelements as:\n1 +k\u00001X\ni=11\ni+ 1=Hk;\nwhere the ﬁrst term is due to the ﬁrst special element and the second term is due to events E1\nthroughEk\u00001.\nWe now provide the lemma that lies in the heart of our robustness property.\nLemma 3.3. For any loss metric `, any phase r, the expected length of any chain is at most\n1 +S`(\u0011r;c)where\u0011r;cis the cumulative error of the predictor on the elements in the chain and S`is\nthe spread of the loss metric.\nProof.The clean element that initiates the clean chain evicts one of the unmarked elements upon\narrival. Since it does so based on the Bélády rule, it evicts the element s1that is predicted to\nreappear the latest in the future. If the predictor is perfect, this element will never appear in this\nphase. If, on the other hand, s1comes back (is a stale element) let s2be the element it evicts, which\nis predicted to arrive the furthest among the current unmarked elements.\nSuppose there are msuch evictions: s1;s2;:::;sm. The elements were predicted to arrive in reverse\norder of their evictions. This is because elements sjforj >iwere unmarked and in the cache when\nelementsigot evicted; therefore siwas predicted to arrive later. However, the actual arrival order\nis the reverse. If \u0011r;cis the total error of these elements, setting the actual arriving times as the\nsequenceATand the predicted ones as the sequence BTin the deﬁnition of spread (Deﬁnition 7), it\nmeans that m\u0014S`(\u0011r;c).\nCombining the two above lemmas, we can obtain a bound on the expected length of any chain.\nLemma 3.4. For any loss metric `, any phase r, the expected length of any chain is at most\nmin(1 + 2S`(\u0011r;c);2 logk)where\u0011r;cis the cumulative error of the predictor on the elements in the\nchain andS`is the spread of the loss metric.\nProof.The proof follows from combining the two above lemmas. By Lemma 3.2, if the chain switches\nto random evictions, it incurs another Hkcache misses in expectation after the switch point (and its\nlength increases by the same amount), capping in expectation the total length by 2Hk\u00142logk. If\nthe chain does not switch to random evictions, it has Bélády evictions and, by Lemma 3.3, it incurs\nat mostS`(\u0011r;c)misses from stale elements. To ensure that the 2logkterm dominates the bound\nwhenS`(\u0011r;c)\u0015logk, we multiply S`(\u0011r;c)by a factor of 2in the ﬁrst term.\n15\n\nProof of Theorem 3.3. Consider an input \u001b2\u0005determining the request sequence. Let Qbe the\nnumber of clean elements (and therefore also chains). Any cache miss corresponds to a particular\neviction in one clean chain; there are no cache misses not charged to a chain by construction. By\nLemma 3.4, we can bound the evictions from the clean chain cof ther-th phase in expectation by\nmin(1 + 2\u0001S`(\u0011r;c);2logk). Since both S`and the minimum operator are concave functions, the\nway to maximize the length of chains is to apportion the total error, \u0011, equally across all of the\nchains. Thus for a given error \u0011and number Qof clean chains, the competitive ratio is maximized\nwhen the error in each chain is \u0011r;c=\u0011=Qeach. The total number of stale elements is therefore in\nexpectation at most: Q\u0001min(2\u0001S`(\u0011=Q);2Hk). By Claim 1, it holds that Q=2\u0014Opt(\u001b), implying\nthe result since Opt(\u001b)\u0014Q.\nWe now specialize the results for the absolute and squared losses.\nCorollary 1. The competitive ratio of \u000f-assisted Predictive Marker with respect to the absolute\nloss metric `1is bounded by crPM;`1(\u000f)\u0014min\u0000\n2 + 2\u0001p\n5\u000f;4Hk\u0001\n.\nCorollary 2. The competitive ratio of \u000f-assisted Predictive Marker with respect to the absolute\nloss metric `2is bounded by crPM;`1(\u000f)\u0014min\u0000\n2 + 2\u00013p\n14\u000f;4Hk\u0001\n.\n3.4 Tightness of analysis\nRobustness rate of Predictive Marker. We show that our analysis is tight: any marking\nalgorithm that uses the predictor in a deterministic way cannot achieve an improved guarantee with\nrespect to robustness.\nTheorem 3.4. Any deterministic \u000f-assisted marking algorithm A, that only uses the predictor\nin tie-breaking among unmarked elements in a deterministic fashion, has a competitive ratio of\ncrA;`(\u000f) = \n(min(S`(\u000f);k)).\nProof.Consider a cache of size kwithk+ 1elements and any \u000fsuch thatS`(\u000f)< k. We will\nconstruct an instance that exhibits the above lower bound. Since Auses marking, we can decompose\nits analysis into phases. Let \u001bbe the request sequence, and assume that we do not have any\nrepetition of an element inside the phase; as a result the i-th element of phase rcorresponds to\nelement\u001b(r\u00001)k+i.\nSuppose the predictor is always accurate on elements 2 through k\u0000S`(\u000f) + 1in each phase.\nFor the last S`(\u000f)\u00001elements of phase ras well as the ﬁrst element of the of the next phase, the\nelements are predicted to come again at the beginning of the subsequent phase, at time t=rk+ 1.\nSince the algorithm is deterministic, we order the elements so that their evictions are in reverse\norder of their arriving time. By the deﬁnition of spread, the error of the predictor in these elements\nis exactly\u000fand the algorithm incurs a cache miss in each of them. On the other hand, the oﬄine\noptimum has only 1miss per phase, which concludes the proof.\nOn the rate of robustness in caching. Theorem 3.4 establishes that the analysis of Predictive\nMarker is tight with respect to the rate of robustness, and suggests that algorithms that use the\npredictor in a deterministic manner may suﬀer from similar rates. However, a natural question\nthat comes up is whether a better rate can be achieved using the predictor in a randomized way.\nWe conjecture that a rate of log(1 +p\u000f)with respect to the absolute loss is possible, similar to\n16\n\nthe exponential improvement randomized schemes obtain over the deterministic guarantees of k\nwith respect to worst-case competitiveness. In subsequent work, Rohatgi [ Roh20] made signiﬁcant\nprogress towards identifying the correct rate by proving reﬁned upper and lower bounds.\n3.5 Randomized predictors\nWe now remove the assumption that the predictor his deterministic and extend the deﬁnition of\n\u000f-accurate predictors (Deﬁnition 2) to hold in expectation. The randomness may either come in how\nthe inputs are generated or in the predictions of h.\nDeﬁnition 8. For a ﬁxed optimization problem \u0005, letOpt \u0005(\u001b)denote the value of the optimal\nsolution on input \u001b. Assume that the predictor is probabilistic and therefore the error of the predictor\nat\u001bis a random variable \u0011`(h;\u001b). Taking expectation over the randomness of the precictor, we say\nthat a predictor his\u000f-accurate in expectation for \u0005if:\nE[\u0011`(h;\u001b)]\u0014\u000f\u0001Opt \u0005(\u001b):\nSimilarly an algorithm is \u000f-assisted if it has access to an \u000f-accurate predictor in expectation.\nAnalogously to the previous part, we can show:\nTheorem 3.5. Consider any loss function `with spread bounded by S`for some function S`that is\nconcave in its argument. Then the competitive ratio of \u000f-assisted in expectation Predictive Marker\nPMis bounded by:\ncrPM;`(\u000f)\u00142\u0001min (1 + 2S`(\u000f);2Hk):\nProof.For ease of notation assume that the outcomes of the predictors are ﬁnite. For each of these\npotential realizations, we can bound the performance of the algorithm by Theorem 3.3. The proof\nthen follows by applying an additional Jensen’s inequality on all the possible realizations due to the\nconcavity of the spread and the min operator.\n4 Discussion and extensions\nThus far we have shown how to use an \u000f-accurate predictor to get a caching algorithm with an\nO(p\u000f)competitive ratio for the absolute loss metric. We now provide a deeper discussion of the\nmain results. In Section 4.1, we give a ﬁner trade-oﬀ of competitiveness and robustness. We then\ndiscuss some traits that limit the impact of the errors of the predictors in Section 4.2.Subsequently,\nwe show that common heuristic approaches, such as LRU, can be expressed as predictors in our\nframework. This allows us to combine their predictive power with robust guarantees when they fail.\nFinally, in Section 4.3, we provide a black-box way to combine robust and competitive approaches.\n4.1 Robustness vs competitiveness trade-oﬀs.\nOne of the free parameters in Algorithm 1 is the length of the chain when the algorithm switches\nfrom following the predictor to random evictions. If the switch occurs after chains grow to \rHkin\nlength, this provides a trade-oﬀ between competitiveness and robustness.\n17\n\nTheorem 4.1. Suppose that, for \r > 0, the algorithm uses \rHkas switching point (line 18 in\nAlgorithm 1); denote this algorithm by PM(\r). Let a loss function `with spread bounded by S`for\nsome function S`that is concave in its argument. Then the competitive ratio of \u000f-assistedPM(\r)is\nbounded by:\ncrPM(\r);`(\u000f)\u00142\u0001min\u0012\n1 +1 +\r\n\rS`(\u000f);\rHk;k\u0013\n:\nProof.The proof follows the proof of Theorem 3.3 but slightly changes the Lemma 3.2 to account\nfor the new switching point. In particular, with respect to the second term, the expected length of\neach clean chain is at most Hkafter the switching point, and, at most \rHkbefore the switching\npoint by construction.\nWith respect to the robustness term, the length of each clean chain before the switch is bounded\nby the spread of the metric on this subsequence. Since the total length is in expectation at most\n(1 +\r)=\rhigher, we need to adjust the ﬁrst term accordingly.\nFinally, the length of its clean chain is at most kregardless of the tie-breaking since we are using\nmarking which provides the last term.\nLet us reﬂect on the above guarantee. When \r!0then the algorithm is more conservative\n(switching to random evictions earlier); this reduces the worst-case competitive ratio but at the cost\nof abandoning the predictor unless it is extremely accurate. On the other hand, setting \rvery high\nmakes the algorithm trust the predictor more, reducing the competitive ratio when the predictor is\naccurate at the expense of a worst guarantee when the predictor is unreliable.\n4.2 Practical traits of Predictive Marker\nLocality. The guarantee in Theorem 3.3 bounds the competitive ratio as a function of the quality\nof the prediction. One potential concern is that if the predictions have of a small number of very\nlarge errors, then the applicability of Predictive Marker may be quite limited.\nHere we show that this is not the case. Due to the phase-based nature of the analysis, the algorithm\nessentially “resets” at the end of every phase, and therefore the errors incurred one phase do not\ncarry over to the next. Moreover, the competitive ratio in every phase is bounded by O(Hk).\nFormally, for any sequence \u001b, we can deﬁne phases that consist of exactly kdistinct elements. Let\ncl(r;\u001b)be the number of clean elements in phase rof sequence \u001b, and let\u0011`;r(h;\u001b)denote the error\nof predictor hrestricted only to elements occurring in phase r.\nTheorem 4.2. Consider a loss function `with spread S`. IfS`is concave, the competitive ratio of\nPredictive Marker PMat sequence \u001bwhen assisted by a predictor his at most:\ncrPM;`\u0014P\nrcl(r;\u001b)\u0001min(1 + 2S`(\u0011`;r(h;\u001b);2Hk)P\nrcl(r;\u001b)\nProof.The proof follows directly from Lemma 3.4 and applying Jensen’s inequality only within the\nchains of the phase (instead of also across phases as we did in Theorem 3.3).\nThis theorem illustrates a nice property of our algorithm. If the predictor his really bad for a period\nof time (i.e. its errors are localized) then the clean chains of the corresponding phases will contribute\n18\n\nthe second term (the logarithmic worst-case guarantee) but the other phases will provide enhanced\nperformance utilizing the predictor’s advice. In this way, the algorithm adapts to the quality of\nthe predictions, and bad errors do not propagate beyond the end of a phase. This quality is very\nuseful in caching where most patterns are generally well predicted but there may be some unforeseen\nsequences.\nRobustifying LRU. Another practical property of our algorithm is that it can seamlessly in-\ncorporate heuristics that are known to perform well in practice. In particular, the popular Least\nRecently Used (LRU) algorithm can be expressed within the Predictive Marker framework. Consider\nthe following predictor, h: when an element \u001biarrives at time i, the LRU predictor predicts next\narrival time h(\u001bi) =\u0000i.\nNote that, by doing so, at any point of time, among the elements that are in the cache, the element\nthat is predicted the furthest in the future is exactly the one that has appeared the least recently.\nAlso note that any marked element needs to have arrived later than any unmarked element. As a\nresult, if we never switched to random evictions (or had kin the RHS of line 18 in Algorithm 1), the\nPredictive Marker algorithm assisted with the LRU predictor is exactly the LRU algorithm.\nThe nice thing that comes from this observation is that we can robustify the analysis of LRU. LRU,\nand its variants like LRU(2), tend to have very good empirical performance as using the recency of\nrequests is a good predictor about how future requests will arise. However, the worst-case guarantee\nof LRU is unfortunately \u0002(k)since it is a deterministic algorithm. By expressing LRU as a predictor\nin the Predictive Marker framework and using a switching point of Hkfor each clean chain, we\nexploit most of this predictive power while also guaranteeing a logarithmic worst-case bound on it.\n4.3 Combining robustness and competitiveness in a black-box manner\nIn the previous section, we showed how we can slightly modify a classical competitive algorithm\nto ensure that it satisﬁes nice consistency and robustness properties when given access to a good\npredictor, while retaining the worst-case competitiveness guarantees otherwise. In this part, we\nshow that, in fact, achieving the requirements individually is enough. In particular, we show a\nblack-box way to combine an algorithm that is robust and one that is worst-case competitive. This\nreduction leads to a slightly worse bound, but shows that proving the robustness property (i.e. a\ngraceful degradation with the error of the predictor) is theoretically suﬃcient to augment an existing\nworst-case competitive algorithm.\nTheorem 4.3. For the caching problem, let Abe an\u000b-robust algorithm and Ba\r-competitive\nalgorithm. We can then create a black-box algorithm ALGthat is both 9\u000b-robust and 9\r-competitive.\nProof.We proceed by simulating AandBin parallel on the dataset, and maintaining the cache state\nand the number of misses incurred by each. Our algorithm switches between following the strategy\nofAand the strategy of B. Letct(A)andct(B)denote the cost (number of misses) of AandBup\nto timet. Without loss of generality, let ALGbegin by following strategy of A; it will do so until a\ntimetwherect(A) = 2\u0001ct(B). At this point ALGswitches to following the eviction strategy of B,\ndoing so until the simulated cost of Bis double that of A: a timet0withct0(B) = 2\u0001ct0(A). At this\npoint it switches back to following eviction strategy of A, and so on. When ALGswitches from A\ntoB, the elements that Ahas in cache may not be the same as those that Bhas in the cache. In\nthis case, it needs to reconcile the two. However, this can be done lazily (at the cost of an extra\n19\n\ncache miss for every element that needs to be reconciled). To prove the bound on the performance of\nthe algorithm, we next show that ct(ALG )\u00149\u0001min(ct(A);ct(B))for allt. We decompose the cost\nincurred by ALGinto that due to following the diﬀerent algorithms, which we denote by ft(ALG ),\nand that due to reconciling caches, rt(ALG ).\nWe prove a bound on the following cost ftby induction on the number of switches. Without loss of\ngenerality, suppose that at time t,ALGswitched from AtoB, and at time t0it switches from B\nback toA. By induction, suppose that ft(ALG )\u00143min(ct(A);ct(B)) = 3ct(B), where the equality\nfollows since ALGswitched from AtoBat timet. In both cases, assume that caches are instantly\nreconciled. Then:\nft0(ALG ) =ft(ALG ) + (ct0(B)\u0000ct(B))\n=ft(ALG ) + 2ct0(A)\u00001=2ct(A)\n\u00143ct(B) + 2(ct0(A)\u0000ct(A)) + 3=2\u0001ct(A)\n= 3ct(A) + 2(ct0(A)\u0000ct(A))\n\u00143ct0(A)\n= 3 min(ct0(A);ct0(B))\nWhat is left is to bound the following cost for the time since the last switch. Let sdenote the\ntime of the last switch and, assume without loss of generality that it was done from AtoB. Let\ns0denote the last time step. By the previous set of inequalities (changing the second equation\nto inequality) and the fact that the algorithm never switched back to Aafters, it holds that\nfs0(ALG )\u00143cs0(A)\u00146 min(cs0(A);cs0(B)).\nTo bound the reconciliation cost, assume the switch at time tis fromAtoB. We charge the\nreconciliation of each element in BnAto the cache miss when the element was last evicted by A.\nTherefore the overall reconciliation cost is bounded by rt(ALG )\u0014ct(A)+ct(B)\u00143min(ct(A);ct(B).\nObserve that the above construction can extend beyond caching and applies to any setting where we\ncan bound the cost that the algorithm needs to incur to reconcile the states of the robust and the\nworst-case competitive algorithm. In particular, this occurs in the more general k-server problem.\nRemark 4.4. The above construction is similar to that of Fiat et al. [ FRR94] who showed how to\ncombine multiple competitive algorithms. In subsequent work, Antoniadis et al. [ ACE+20] relied on a\nsimilar construction to provide results for metrical task systems under a diﬀerent prediction model.\n5 Experiments\nIn this section we evaluate our approach on real world datasets, empirically demonstrate its depen-\ndence on the errors in the oracle, and compare it to standard baselines.\nDatasets and Metrics We consider two datasets taken from diﬀerent domains to demonstrate\nthe wide applicability of our approach.\n\u000fBKis data extracted from BrightKite, a now defunct social network. We consider sequences of\ncheckins, and extract the top 100users with the longest non-trivial check in sequences—those\n20\n\nDataset Num Sequences Sequence Length Unique Elements\nBK 100 2,101 67– 800\nCiti 24 25,000 593 – 719\nTable 1: Number of sequences; sequence length; min and max number of elements for each dataset.\nwhere the optimum policy would have at least 50misses. This dataset is publicly available at\n[CML11, Bri]. Each of the user sequences represents an instance of the caching problem.\n\u000fCitiis data extracted from CitiBike, a popular bike sharing platform operating in New York\nCity. We consider citi bike trip histories, and extract stations corresponding to starting points\nof each trip. We create 12 sequences, one for each month of 2017 for the New York City dataset.\nWe consider only the ﬁrst 25,000 events in each ﬁle. This data is publicly available at [Cit].\nWe give some additional statistics about each datasets in Table 1.\nOur main metric for evaluation will be the competitive ratio of the algorithm, deﬁned as the number\nof misses incurred by the particular strategy divided by the optimum number of misses.\nPredictions We run experiments with both synthetic predictions to showcase the sensitivity\nof our methods to learning errors, and with preditions using an oﬀ the shelf classiﬁer, published\npreviously [AKTV14].\n\u000fSynthetic Predictions. For each element, we ﬁrst compute the true next arrival time, y(t),\nsetting it to n+ 1if it does not appear in the future. To simulate the performance of an ML\nsystem, we set h(t) =y(t) +\u000f, where\u000fis drawn i.i.d. from a lognormal distribution with\nmean parameter 0and standard deviation \u001b. We chose the lognormal distribution of errors to\nshowcase the eﬀect of rare but large failures of the learning algorithm. Finally, observe that\nsince we only compare the relative predicted times for each method, adding a bias term to the\npredictor would not change the results.\n\u000fPLECO Predictions. In their work Anderson et al. [ AKTV14 ] developed a simple framework\nto model repeat consumption, and published the parameters of their PLECO (Power Law with\nExponential Cut Oﬀ) model for the BrightKite dataset. While their work focused on predicting\nthe relative probabilities of each element (re)appearing in the subsequent time step, we modify\nit to predict the next time an element will appear. Speciﬁcally, we set h(t) =t+ 1=p(t), where\np(t)represents the probability that element that appeared at time twill re-appear at time\nt+ 1.\nAlgorithms We consider multiple algorithms for evaluation.\n\u000fLRUis the Least Recently Used policy that is wildly successful in practice.\n\u000fMarker is the classical Marker algorithm due to Fiat et al. [FKL+91].\n\u000fPredictiveMarker is the algorithm we develop in this work. We set the switching cost to k,\nand therefore never switch to random evictions.\n\u000fBlind Oracle is the algorithmBdescribed in Section 3.1, which evicts the element predicted\nto appear furthest in the future.\n21\n\nFigure 1: Ratio of average number of evictions as compared to optimum for varying levels of oracle\nerror.\nAlgorithm Competitive Ratio on BK Competitive Ratio on Citi\nBlind Oracle 2.049 2.023\nLRU 1.280 1.859\nMarker 1.310 1.869\nPredictive Marker 1.266 1.810\nTable 2: Competitive Ratio using PLECO model.\n5.1 Results\nWe setk= 10, and summarize the synthetic results on the BKdataset in Figure 1. Observe that\nthe performance of Predictive Marker is consistently better than LRU and standard Marker, and\ndegrades slowly as the average error increases, as captured by the theoretical analysis. Second, we\nempirically verify that blindly following the oracle works well when the error is very low, but quickly\nbecomes incredibly costly.\nThe results using the PLECO predictor are shown in Table 2, where we keep k= 10for the BK\ndataset and set k= 100forCiti; we note that the ranking of the methods is not sensitive to the\ncache size,k. We can again see that the Predictive Marker algorithm outperforms all others, and is\n2.5% better than the next best method, LRU. While the gains appear modest, we note they are\nstatistically signiﬁcant at p<0:001. Moreover, the oﬀ-the-shelf PLECO model was not tuned or\noptimized for predicting the nextappearance of each element.\nIn that regard, the large diﬀerence in performance between using the predictor directly (Blind Oracle)\nand using it in combination with Marker (Predictive Marker) speaks to the power of the algorithmic\nmethod. By considering only the straightforward use of the predictor in the Blind Oracle setting,\none may deem the ML approach not powerful enough for this application; what we show is that a\nmore judicious use of the same model can result in tangible and statistically signiﬁcant gains.\n6 Conclusion\nIn this work, we introduce the study of online algorithms with the aid of machine learned predictors.\nThis combines the empirical success of machine learning with the rigorous guarantees of online\nalgorithms. We model the setting for the classical caching problem and give an oracle-based algorithm\nwhose competitive ratio is directly tied to the accuracy of the machine learned oracle.\n22\n\nOur work opens up two avenues for future work. On the theoretical side, it would be interesting to\nsee similar predictor -based algorithms for other online settings such as the k-server problem; this\nhas already led to a fruitful line of current research as we discussed in Section 1.3. On the practical\nside, our caching algorithm shows how we can use machine learning in a safe way, avoiding problems\ncaused by rare wildly inaccurate predictions. At the same time, our experimental results show that\neven with simple predictors, our algorithm provides an improvement compared to LRU. In essence,\nwe have reduced the worst case performance of the caching problem to that of ﬁnding a good (on\naverage) predictor. This opens up the door for practical algorithms that need not be tailored towards\nthe worst-case or speciﬁc distributional assumptions, but still yield provably good performance.\nAcknowledgements\nThe authors would like to thank Andrés Muñoz-Medina and Éva Tardos for valuable discussions on\nthe presentation of the paper, Shuchi Chawla and Seﬃ Naor for useful feedback regarding Section 3.4,\nOla Svensson for suggesting the locality extension (Theorem 4.2) as well as an anonymous reviewer\nfor pointing towards the direction of Theorem 4.3.\nReferences\n[ACC+11]Nir Ailon, Bernard Chazelle, Kenneth L. Clarkson, Ding Liu, Wolfgang Mulzer, and\nC. Seshadhri. Self-improving algorithms. SIAM J. Comput. , 40(2):350–375, 2011.\n[ACE+20]Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, and Simon Betrand.\nOnline metric algorithms with untrusted predictions. In Proceedings of the 37th\nInternational Conference on Machine Learning (ICML) , 2020.\n[ACN00] Dimitris Achlioptas, Marek Chrobak, and John Noga. Competitive analysis of random-\nized paging algorithms. Theor. Comput. Sci. , 234(1-2):203–218, 2000.\n[ADJ+19]Spyros Angelopoulos, Christoph Dürr, Shendan Jin, Shahin Kamali, and Marc Renault.\nOnline computation with untrusted advice. arXiv preprint arXiv:1905.05655 , 2019.\n[AFG02] Susanne Albers, Lene M. Favrholdt, and Oliver Giel. On paging with locality of\nreference. In Proceedings of the Thiry-fourth Annual ACM Symposium on Theory of\nComputing , STOC ’02, pages 258–267, New York, NY, USA, 2002. ACM.\n[AGP20] Keerti Anand, Rong Ge, and Debmalya Panigrahi. Customizing ml predictions for\nonline algorithms. In Proceedings of the 37th International Conference on Machine\nLearning (ICML) , 2020.\n[AKTV14] AshtonAnderson, RaviKumar, AndrewTomkins, andSergeiVassilvitskii. Thedynamics\nof repeat consumption. In Proceedings of the 23rd International Conference on World\nWide Web , WWW ’14, pages 419–430, New York, NY, USA, 2014. ACM.\n[AMR11] David Arthur, Bodo Manthey, and Heiko Röglin. Smoothed analysis of the k-means\nmethod. J. ACM, 58(5):19:1–19:31, 2011.\n[AV06] David Arthur and Sergei Vassilvitskii. Worst-case and smoothed analysis of the ICP\nalgorithm, with an application to the k-means method. In 47th Annual IEEE Symposium\n23\n\non Foundations of Computer Science (FOCS 2006), 21-24 October 2006, Berkeley,\nCalifornia, USA, Proceedings , pages 153–164, 2006.\n[Bel66] L. A. Belady. A study of replacement algorithms for a virtual-storage computer. IBM\nSyst. J., 5(2):78–101, June 1966.\n[BEY98] Allan Borodin and Ran El-Yaniv. Online Computation and Competitive Analysis .\nCambridge University Press, New York, NY, USA, 1998.\n[BFK+16]Joan Boyar, Lene M. Favrholdt, Christian Kudahl, Kim S. Larsen, and Jesper W.\nMikkelsen. Online algorithms with advice: A survey. SIGACT News , 47(3):93–129,\nAugust 2016.\n[Bri] Brightkite data. http://snap.stanford.edu/data/loc-brightkite.html .\n[BRS17] Eric Balkanski, Aviad Rubinstein, and Yaron Singer. The limitations of optimization\nfrom samples. In STOC, 2017.\n[BS12] Sébastien Bubeck and Aleksandrs Slivkins. The best of both worlds: Stochastic and\nadversarial bandits. In COLT 2012 - The 25th Annual Conference on Learning Theory,\nJune 25-27, 2012, Edinburgh, Scotland , pages 42.1–42.23, 2012.\n[Cit] Citibike system data. http://https://www.citibikenyc.com/system-data .\n[CML11] Eunjoon Cho, Seth A. Myers, and Jure Leskovec. Friendship and mobility: User\nmovement in location-based social networks. In Proceedings of the 17th ACM SIGKDD\nInternational Conference on Knowledge Discovery and Data Mining , KDD ’11, pages\n1082–1090, New York, NY, USA, 2011. ACM.\n[CR14] Richard Cole and Tim Roughgarden. The sample complexity of revenue maximization.\nInSymposium on Theory of Computing, STOC 2014, New York, NY, USA, May 31 -\nJune 03, 2014 , pages 243–252, 2014.\n[Den68] Peter J. Denning. The working set model for program behavior. Commun. ACM ,\n11(5):323–333, May 1968.\n[EKM15] Hossein Esfandiari, Nitish Korula, and Vahab Mirrokni. Online allocation with traﬃc\nspikes: Mixing adversarial and stochastic models. In Proceedings of the Sixteenth ACM\nConference on Economics and Computation , pages 169–186. ACM, 2015.\n[ERV16] Matthias Englert, Heiko Röglin, and Berthold Vöcking. Smoothed analysis of the 2-opt\nalgorithm for the general TSP. ACM Trans. Algorithms , 13(1):10:1–10:15, 2016.\n[FKL+91]Amos Fiat, Richard M. Karp, Michael Luby, Lyle A. McGeoch, Daniel D. Sleator,\nand Neal E. Young. Competitive paging algorithms. J. Algorithms , 12(4):685–699,\nDecember 1991.\n[FRR94] Amos Fiat, Yuval Rabani, and Yiftach Ravid. Competitive k-server algorithms. Journal\nof Computer and System Sciences , 48(3):410 – 428, 1994.\n[GP19] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with\nexpert advice. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings\nof the 36th International Conference on Machine Learning , volume 97 of Proceedings of\nMachine Learning Research , pages 2319–2327, Long Beach, California, USA, 09–15 Jun\n2019. PMLR.\n24\n\n[HIKV19] Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency\nestimationalgorithms. In International Conference on Learning Representations (ICLR) ,\n2019.\n[IMTMR20] Piotr Indyk, Frederik Mallmann-Trenn, Slobodan Mitrović, and Ronitt Rubinfeld.\nOnline page migration with ml advice, 2020.\n[JPS20] Zhihao Jiang, Debmalya Panigrahi, and Kevin Sun. Online algorithms for weighted\npaging with predictions. In Proceedings of the 47th International Colloquium on\nAutomata, Languages and Programming (ICALP) , 2020.\n[KBC+17]Tim Kraska, Alex Beutel, Ed H. Chi, Jeﬀ Dean, and Neoklis Polyzotis. The case for\nlearned index structures. 2017.\n[LLMV20] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online\nscheduling via learned weights. In Proceedings of the Twenty-Third Annual Symposium\non Discrete Algorithms (SODA) , 2020.\n[LMPL18] Thodoris Lykouris, Vahab Mirrokni, and Renato Paes Leme. Stochastic bandits robust\nto adversarial corruptions. In Proceedings of the 50th ACM Annual Symposium on\nTheory of Computing (STOC) , 2018.\n[McG14] Andrew McGregor. Graph stream algorithms: A survey. SIGMOD Rec. , 43(1):9–20,\nMay 2014.\n[MGZ12] Vahab S. Mirrokni, Shayan Oveis Gharan, and Morteza Zadimoghaddam. Simultaneous\napproximations for adversarial and stochastic online budgeted allocation. In Proceedings\nof the Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms, SODA\n2012, Kyoto, Japan, January 17-19, 2012 , pages 1690–1701, 2012.\n[Mit18] MichaelMitzenmacher. Amodel forlearnedbloom ﬁltersand optimizing by sandwiching.\nInAdvances in Neural Information Processing Systems (NeurIPS) . 2018.\n[Mit20] Michael Mitzenmacher. Queues with small advice. CoRR, abs/2006.15463, 2020.\n[MNS12] Mohammad Mahdian, Hamid Nazerzadeh, and Amin Saberi. Online optimization with\nuncertain information. ACM Trans. Algorithms , 8(1):2:1–2:29, 2012.\n[MR95] Rajeev Motwani and Prabhakar Raghavan. Randomized Algorithms . Cambridge\nUniversity Press, New York, NY, USA, 1995.\n[MR16] Jamie Morgenstern and Tim Roughgarden. Learning simple auctions. In Proceedings\nof the 29th Conference on Learning Theory, COLT 2016, New York, USA, June 23-26,\n2016, pages 1298–1318, 2016.\n[MV17] Andres Muñoz Medina and Sergei Vassilvitskii. Revenue optimization with approximate\nbid predictions. In Advances in Neural Information Processing Systems 30: Annual\nConference on Neural Information Processing Systems 2017, 4-9 December 2017, Long\nBeach, CA, USA , pages 1856–1864, 2017.\n[PSK18] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml\npredictions. In Advances in Neural Information Processing Systems , pages 9661–9670,\n2018.\n25\n\n[Roh20] Dhruv Rohatgi. Near-optimal bounds for online caching with machine learned advice.\nIn Shuchi Chawla, editor, Proceedings of the 2020 ACM-SIAM Symposium on Discrete\nAlgorithms, SODA 2020, Salt Lake City, UT, USA, January 5-8, 2020 , pages 1834–1845.\nSIAM, 2020.\n[RS13] Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences.\nInProceedings of the 26th Annual Conference on Learning Theory (COLT) , 2013.\n[SHG+15]D. Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner,\nVinay Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. Hidden\ntechnical debt in machine learning systems. In Proceedings of the 28th International\nConference on Neural Information Processing Systems , NIPS’15, pages 2503–2511,\nCambridge, MA, USA, 2015. MIT Press.\n[ST85] Daniel D. Sleator and Robert E. Tarjan. Amortized eﬃciency of list update and paging\nrules.Commun. ACM , 28(2):202–208, February 1985.\n[ST04] Daniel A. Spielman and Shang-Hua Teng. Smoothed analysis of algorithms: Why the\nsimplex algorithm usually takes polynomial time. J. ACM, 51(3):385–463, 2004.\n[SZS+14]Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian\nGoodfellow, and Rob Fergus. Intriguing properties of neural networks. In International\nConference on Learning Representations , 2014.\n[VKKM20] Kapil Vaidya, Eric Knorr, Tim Kraska, and Michael Mitzenmacher. Partitioned learned\nbloom ﬁlter. CoRR, abs/2006.03176, 2020.\n[Wei20] Alexander Wei. Better and simpler learning-augmented online caching. In International\nConference on Approximation Algorithms for Combinatorial Optimization Problems\n(APPROX) , 2020.\nA Proof of Lemma 3.1\nIn this section, we provide the proof of the lemma connecting spread to absolute and squared loss.\nBefore doing so, we provide a useful auxiliary lemma.\nLemma A.1. For oddT= 2n+ 1, one pair (AT;BT)minimizing either absolute or squared loss\nsubject to the constraints of the spread deﬁnition is A2n+1= (0:::2n)andBT= (n:::n ).\nProof.First we show that there exists a BTminimizing the loss with bi=bjfor alli;j. Assume\notherwise; then there exist two subsequent i;jwithb0\ni>b0\nj. Sinceai<aj+ 1by the assumption on\nspread, minx2bi;bjf`(ai;b) +`(aj;b)g\u0014`(ai;bi) +`(aj;bj). Applying this recursively, we conclude\nthat such a BTexists.\nSecond, we show that there exist an ATthat consists of elements ai+1=ai+ 1. Since the elements\nofBTare all equal to b, the sequenceP2n\ni=0`(ai;b)is minimized for both absolute and squared loss\nwhenai=b+i\u0000n.\nLast, the exact value of bdoes not make a diﬀerence and therefore we can set it to be b=n\nconcluding the lemma.\n26\n\nLemma 3.1 restated: For absolute loss, `1(A;B) =P\nijai\u0000bij, the spread of `1isS`1(m)\u0014p\n5m.\nFor squared loss, `2(A;B) =P(ai\u0000bi)2, the spread of `2isS`2(m)\u00143p\n14m:\nProof.It will be easier to restrict ourselves to odd T= 2n+ 1and also assume that T\u00153. This\nwill give an upper bound on the spread (which is tight up to small constant factors). By Lemma\nA.1, a pair of sequence minimizing absolute/squared loss is AT= (0;:::; 2n)andBT= (n;:::;n ).\nWe now provide bounds on the spread based on this sequence, that is we ﬁnd a T= 2n+ 1that\nsatisﬁes the inequality `(AT;BT)\u0014m.\nAbsolute loss: The absolute loss of the above sequence is:\n`(AT;BT) = 2\u0001nX\nj=1j= 2\u0001n(n+ 1)\n2=n(n+ 1) =T\u00001\n2\u0001T+ 1\n2=T2\u00001\n4:\nATthat makes `(AT;BT)\u0015misT=p4m+ 1. Therefore, for absolute loss S`(m)\u0014p\n5m, since\nm\u00151\nSquared loss: The squared loss of the above sequence is:\n`(AT;BT) = 2\u0001nX\nj=1j2= 2\u0001n(n+ 1)(2n+ 1)\n6=(T2\u00001)\u0001T\n12=T3\u0000T\n12\u00158T3\n9\u000112=2T3\n27\nwhere the inequality holds because T\u00153.\nATthat makes `(AT;BT)\u0015misT=3p\n14m. Therefore, for squared loss S`(m)\u00143p\n14m.\n27",
  "textLength": 85426
}