{
  "paperId": "96f01ee6cce4aef838a93fc541e446a4d6049df2",
  "title": "MANAGEMENT OF LARGE INDOOR POINT CLOUDS: AN INITIAL EXPLORATION",
  "pdfPath": "96f01ee6cce4aef838a93fc541e446a4d6049df2.pdf",
  "text": "Management of large indoor point clouds: an initial exploration  \n \n \nH. Liu, P. Van Oosterom , M. Meijers , E. Verbree  \n \nOTB, Faculty of Architecture and the Built Environment , Delft University of Technology , the Netherlands  – (H.Liu -6, \nP.J.M.vanOosterom , B.M.Meijers , E.Verbree)@tudelft.nl  \n  \nCommission IV, WG IV/7 \n \n \nKEY WORDS: Point Cloud, Indoor, Level of Detail, Oracle, Data Management, Benchmark, Morton Curve  \n \n \nABSTRACT:  \n \nIndoor navigation and visualization become increasingly important nowadays. Meanwhile, the proliferation of new sensors as well as \nthe advancement of data processing provide massive point clouds to model the indoor environment in high accuracy. However, \ncurrent state -of-the-art solutions fail to manage such large datasets efficiently. File b ased solutions often require substantial \ndevelopment work while database solutions are still faced with issues such as inefficient data loading and indexing. In this research, \nthrough a case study which aims to solve the problem of intermittent rendering o f massive points in the context of indoor navigation, \nwe devised and implemented an algorithm to compute the continuous Level of Detail (cLoD) where geometric and classification \ninformation are considered. Benchmarks are developed and different approaches in Oracle are tested to learn the pros and cons. \nSurprisingly, the flat table approach could be very efficient compared with other schemes. The crucial point lies in how to a ddress \npriority of different dimensions including cLoD, classification and spatial  dimensions, and avoid unnecessary scanning of the table.  \nWriting results either to the memory or the disk constitutes major part of the time cost when large output is concerned. Conv entional \nsolutions based on spatial data objects present poor performanc e due to cumbersome indexing structure, inaccurate selection and \nadditional decoding process. Besides, approximate selection in the unit of physical object is proposed and the performance is  \nsatisfactory when large amount of data is requested. The knowledg e acquired could prompt the development of a novel data \nmanagement of high dimensional point clouds where the classification information is involved.  \n \n1. INTRODUCTION  \nA paradigm shift from outdoor to indoor spatial services has \ntaken pl ace in recent years, as the complexity of buildings \nincreases and people spend most of the time indoors. Due to \nhigh accuracy and efficiency of data collection techniques, point \nclouds are utilized more frequently for indoor 3D modelling \nprocesses. In Janu ary 2018, the National Institute of Standards \nand Technology (NIST) of US initialized a public safety \nresearch program of which the topic was the collection of \nindoor point clouds. The intention was to build a standard \nprototype for indoor point cloud mode ls as point clouds may \nbecome the basis for indoor applications for the next generation. \nSuch agendas would definitely result in the harvesting of \nmassive point data.  \n \nUnlike most conventional point cloud with only X/Y/Z \nattributes, indoor point clouds pr ovide more abundant \ninformation including colour, and also semantics, e.g. \nclassification which plays an important role in visibility \ndetection and navigation. These attributes could also be named \nas dimensions because conceptually, there is no difference \nbetween these two terms (Liu et al., 2018b). Every type of \ninformation such as sound and temperature could be perceived \nas one dimension for us to comprehend the world. However, in \nterms of storage, two types of dimensions are identified. One \ntype is calle d organizing dimension which could be utilized to \ncluster and index the data, e.g. X/Y/Z. The other is the property \ndimension such as color, intensity and classification which is \nnot frequently queried.  Depending on applications, these two \ntypes of dimensi on are interchangeable. All dimensions together \nform the nD point clouds. However, practical experience \nindicates that current database management systems (DBMS) \npresent critical problems to manage massive nD point clouds \nsuch as inefficient loading/indexi ng, lack of support of \ncontinuous Level of Detail (cLoD) and limited functionalities.  Flat table -based approaches mostly suffer from full table scans \nfor simple queries, while block based solutions cost enormous \ntime for construction of data blocks as wel l as decoding them \nfor data extraction. Besides, the concept of LoD which serves as \na general way for processing big data is either missing in state -\nof-the-art solutions or implemented using traditional Octree \nstructure which presents side effects such as visual artefacts \nduring rendering (Liu et al., 2018a). Basically, blocks of points \nin various densities are shown in the same scene.   \n \nThe research aims at exploring a model of data management for \nlarge indoor point clouds. This will be constructed for sp ecific \napplications, i.e. visualization of the indoor environment \nconsidering navigation needs. The whole paper is divide into 6 \nsections. The first two sections introduce the background \ninformation. This is then followed by a description of \nbenchmark appl ied in Section 3. LoD in the indoor environment \nis specifically discussed in Section 4. Then by implementing \ndifferent data schemas and testing in Oracle, results are \npresented and analysed in Section 5. The lessons learnt as well \nas research directions in  the future are concluded in the end.  \n \n2. RELATED  WORK  \nA data management solution normally starts from a conceptual \nmodel which guides the organization of various information. \nHagedorn et al. (2009) proposed an indoor LoD  model taking \naccount of geometry, semantics and appearance of indoor \nobjects for the purpose of indoor route visualization. The LoD \nmodel put forward includes 4 levels. The first two levels are \nbased on 2D floor plans with different geometric accuracy and  \ndetails of topology. The last two levels utilize a 3D vector \nmodel. The level LoD -3 only presents doors and windows in \naddition to the floor plans while LoD -4 cover all objects in the \n3D model with highest accuracy.  \n \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n365\n\nAs regard to point cloud management, lots of approaches exist. \nMost of them are file -based solutions such as LAS/LAZ (ISPRS, \n2011), HDF (Folk et al., 2011), while other vendors adopt their \nown formats. Additional sorting and indexing to create block \ndata structures for efficient querying have  to be manually \nperformed. Yet the scalability with large data cannot be \nguaranteed.  \n \nIn contrast, the DBMS does not have such problems. State -of-\nthe-art solutions are split into two types according to the storage \nmodel. Take Oracle as an example. One is the flat table \napproach where all dimensions are stored equally in each record \nfor a point. Psomadaki (2016) developed an approach based on \nOracle Index -Organized Tables (IOT) for the management of \nlarge dynamic point data. The index node was a Morton key \n(Figure 1) by encoding X/Y/Z or X/Y/T together, whereas other \ndimensions were stored as normal attributes in the database. By \nperforming a benchmark, the best approach in the research \nconcerns an equal treatment of the spatial and temporal \ndimensions in th e Morton key. The other advanced solution is \nutilization of the SDO_PC data type which groups points into \nblocks which could be indexed by organizing dimensions. Van \nOosterom et al. (2015) implemented this approach for managing \nand querying the AHN2 datase t consists of only xyz \ninformation. Results indicated that the block approach did not \nhave noticeable scaling effects when increasing the data size. \nThe query accuracy is at point level, so that a significant \noverhead would be incurred due to the need to u npack the \nblocks for checking whether individual points were within the \nquery regions and also when dumping the selected points in the \nresults table. What was kept in the cache were the points instead \nof the blocks. When the query was repeated, the blocks had to \nbe read again, which confined the scalability.  \n \n \nFigure 1. The first and second order of the Morton curve. In \neach cell, the corresponding key is shown.  \n \nA comprehensive benchmark test as the last step is needed to \nassess the performance of differ ent solutions as well as to \nprompt further optimization. Van Oosterom et al. (2015) \ndesigned and implemented a benchmark for large point clouds \nmanagement, after collecting user requirements (Suijker et al., \n2014). The testing dataset AHN2 elaborates total ly 640 billion \npoints with 12 TB size in LAS files. Various platforms and data \norganizing approaches were tested including PostgreSQL flat \ntable, PostgreSQL block, Oracle flat table, Oracle block, Oracle \nExadata, MonetDB and LAStools. To exploit the scalab ility, the \nbenchmark was decomposed into several stages with different \ndata size, i.e. mini (20 million points), medium (20 billion \npoints), and full benchmark (640 billion points). Besides, two \nparallel query processing algorithms were presented and partl y \ntested to learn the improvement of performance.  \n \n3. BENCHMARK  \nAs is mentioned, the large nD point cloud data is the focus, and \nan open dataset is utilized. From the query list provided by van Oosterom et al. (2015), relevant processes of indoor \napplications  as well as the maintenance of data are selected for \nthe benchmark testing.  \n \n3.1 Data  \nThe Stanford Large -Scale 3D Indoor Spaces Dataset (S3DIS) \n(Armeni  et al., 2016), containing totally 273,608,340 points, is \ncollected by a 3D camera (Figure 2). The dataset is split into 6 \nareas, corresponding to 6 folders. Each area (folder) is further \ndivided into separate rooms (subfolder) such as conference \nroom, hal lway, office, etc. Inside a folder, different objects are \nstored individually using text files, with desk_1 and floor_1 for \nexample, as the file name. Each text file contains 6 fields and \nthey are x, y, z, R, G and B. The spatial range is ( -37.928, -\n26.078 , -2.645, 29.927, 46.056, 6.576) in (lower left corner, \nupper right corner).  \n \n \nFigure 2. The S3DIS model  \n \nAs the semantic information like classification of objects, \nidentifier of objects and room types is encoded into file names \nin the original dataset,  to manage all the information into a \nDBMS, more dimensions should be added to each point record \nexplicitly. They are:  \n1. Classification  such as floor, door and stairs  \n2. RoomType  such as hallway and office  \n3. RoomID, a numeric identifier for each room  \n4. ObjectID , a numeric identifier for each object  \n5. LoD, a numeric value for each point indicating the \nimportance and it is a continuous field.  \n \n3.2 Queries  \n1. Multi -resolution/LoD selections. For example, select top 1% \nof the points, i.e. the first 1% most important points . \n2. Simple 2D range/rectangle filters of various sizes.  \n3. Selection on other dimensions such as the colour and the \nclassification.  \n4. The K nearest neighbours’ search.  \n5. Attribute statistics including minimum, maximum, average, \nmedian, and count.  \n6. Update of point geometries, e.g. some small changes to \nmany points.  \n7. Computations of areas of implied surface by point clouds.  \n8. Computations of volumes below surfaces.  \n9. Deletion of portions of points (0.1%, 1%, 5%, 10%, 25%).  \n \n4. LOD  COMPUTATION  \nConventional LoD is comprised of  discrete layers, for instance, \nthe 4 -layer LoD model mentioned in Section 2. For indoor point \nclouds, this entails visualizing the indoor environment with \nseveral distinct densities. The sudden change between different \nlayers does not keep in line with hu man’s visual perception. \nHence the cLoD concept is developed to gradually visualize \npoints at different scales, which can make the rendering process \nmore smoothly and naturally. In the cLoD structure, every point \nis assigned an importance value indicating its ranking among \nthe whole dataset. So there is no discrete data layers as before.  \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n366\n\n \nUnlike the 3D indoor models represented by vectors, the indoor \npoint cloud model does not address too much on topology. In \nthis research, when visualizing the point cloud s for the \nnavigation purpose, the computation of LoD only takes account \nof geometric and semantic information.  \n \n4.1 Geometric LoD  \nThe method is to first construct a Btree, Quadtree or Octree \nstructure for each object, and then within each level of the tree, \nthe ranking of points is randomized. Afterwards, all levels are \ncombined sequentially. So the final result is the same as the \noriginal data but with a different ranking of points. Specifically, \nmore important points which are located at geometric centres \nare at the head of the list. In this method, the tree structure is \nimplicitly embedded. Every point represents a level.  \n \nTo determine whether Btree, Quadtree or Octree for organizing \nthe points of an object, a dimapprox function is built. The basic \nidea is to first grasp the range of x, y and z of the object where \n90% of points fall respectively. Then the ranges are compared. \nIf the largest range is 10 times larger than the second, which \nimplies a linear feature, then the object is regarded as a 1D \nobject an d Btree will be applied. If the second largest range is \n10 times larger than the third, which indicates a surface, then \nthe object will be simulated in 2D and Quadtree will be \nemployed. Otherwise, the Octree will be adopted. In this way, \ncomputing efficien cy can be improved and geometric features \ncan be captured more accurately. As an illustration, a 2D wall is \npresented in Figure 3.  \n \n \n \n \nFigure 3. Representation of a wall in a small scale and large \nscale by controlling number of points to render after th e cLoD \nsorting.  \n \nAs the objective is the visualization, a purely random ranking \ncould also be applicable to compute the cLoD. That is, by \nassigning a random number between 0 to 1 to each point, sort \nthe points using the number. Unless the number of points to \nvisualize is too small, the object could be recognized. The \ncomputational load becomes less than that of the tree -based \napproach.  \n \n4.2 Semantic LoD  \nThe geometric LoD cannot express the importance of objects \nfor navigation. Large objects like wall and floor  would be \nrepresented by much more points than small objects like \nwindow and door by choosing a same range of cLoD values. \nHence, three classes are established to represent the importance \nlevel. The first class (most important) includes 'stairs', 'floor', \n'window' and 'door'. They are essential for navigation. The \nsecond class contains objects like 'wall', 'ceiling', 'clutter', etc. The third class refers to 'sofa', 'bookcase', 'board', 'table' and \n'chair'. They are movable objects which are less significan t for \nrouting.  \n \nThe semantic LoD  method is then to assign a unique importance \nvalue to each point. Basically, after the geometric sorting, a \nrandom series based on the uniform distribution between 0 and \n1 will be generated. Then the random numbers are sorted and \neach of them is attached to the end of a point record as the \ninitial LoD value. However, the LoD values belonging to \nobjects in the second class will be multiplied by 0.9, while for \nthe third class a factor 0.8 is applied. In the end, all points from \ndifferent objects are mixed an d sorted according to the LoD \nvalue. The head of the final point list would be occupied by \npoints in the first class and at the geometric centres. Figure 4 \nshows a demonstration of a conference room by utilizing the \ngeometric and semantic LoD method. It cl early presents that \nwhen a small amount of points are selected, only the first class \nobjects are rendered.  \n \n \n \n \n \nFigure 4. Visualization of a conference room using the indoor \ncLoD  model. The scenes contain first 50 000, 100 000 points \nrespectively sorted by the cLoD value.  \n \n5. TEST  RESULTS  AND  DISCUSSION  \nTo get more understanding for managing and querying the \nindoor point cloud data, possible approaches have been \nimplemented in Oracl e. Data are stored in a normal flat table, a \nnested table, a table with a spatial index, SDO_PC blocks and \nan IOT respectively (schemas are provided in the Appendix). \nQueries executed only include spatial selection, LoD selection \nand classification selecti on. Each query is executed several \ntimes with cache flushed until the response time converges to a \nstable value. The time measurement starts from sending the \nSQL command, while ends with storing the results into a \nPython variable, i.e. an in -memory object.  The SDO_PC \nsolution is an exception as it writes results into another table. \nThe aim of the testing is to examine the possible direction to \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n367\n\nrealize an efficient data management. The test platform is a HP \nDL380p Gen8 server with 2 ×  8 -core Intel Xeon proce ssors, E5 -\n2690 at 2.9 GHz, 128 GB of main memory, a RHEL6 operating \nsystem. The disk storage is a 41 TB SATA 7200 rpm in RAID5 \nconfiguration. Advanced disks such as SSD is also available but \nthey are not utilized.  \n  \n5.1 Flat table  \nAs every dimension might be q ueried, so no index is created. \nThe table contains following fields:  \nX, Y, Z, R, G, B, RoomType, RoomID, Classification, ObjectID, \nLoD \n \nAll field use the same data type, NUMBER. With SQL loader, \nthe data can be directly imported into a flat table (Table 1) . Its \nstorage space is 17,141 MB and utilizes 548,495 Oracle logical \nblocks.  \n \nDue to the structure, whatever the selection is, a full table scan \nwill be executed. All queries tested are listed in Table 1. These \nqueries are applied for testing other soluti ons as well. The first \nCOUNT query is executed to learn the speed of a full table scan. \nThe second query is concerned with LoD selection, and 4 levels \nare set to assess the scalability (Figure 5) which is linear. \nSimilarly, spatial selections are executed.  The tendency also \nshows a linear scalability and time cost can be modelled by 9 x \n10-6 n + 6.54 where n is the number of points returned.  \n \nFrom the execution plan, all these queries experience the full \ntable scan.  The time cost therefore includes table s canning, if -\nstatements for filtering and writing into the memory. The linear \ntendency of the real measurements verifies this assertion. With \na constant representing full table scan and if -statements, the \nmain component of time cost lies in the writing part .  \n \nQuery  Number of \nrecords returned  Time \ncost (s)  \n1. select COUNT(*) from s3disflat  1 15.2 \n2. select * from s3disflat where \nlod>0.99/0.95/0.8/0.5  657,295/  \n3,287,515/  \n31,730,001/  \n122,433,484  17.72/  \n39.57/  \n277.92/  \n1042.3  \n \n3. select * from s3disflat where  x>12.075 \nand x<20.13 and y>15.267 and y<19.3 and \nz>0 and z<2 / ( -9.072, 17.307, 1, 3.208, \n23.557, 2.8) / (4.7, 10.9, -1, 19.2, 31.6, 3.8) / \n(-20.32, -5.9, -2, 21.2, 27.5, 2)  1,126,508/  \n6,117,966/  \n13,914,061/  \n98,991,886  16.5/ \n59.8/ \n125.93/  \n861.3  \nTable 1. Query performance on S3DISFLAT  \n \n \nFigure 5. LoD selection (Query 2) at different levels. The \ntendency shows a linear scalability and Time = 8 x 10-6 n + \n11.73, where n is the output size.  \n 5.2 Nested table  \nOracle supports the nested table, i.e. the data type of a field in a \ntable can be another table. By observing the data, we find that \nthe fields including RoomType, RoomID, Classification, \nObjectID  cause much redundancy. So, a solution is to store \nthese fie lds into a base table and by adding a Point_tab field of \nwhich the data type is a table, other information of points could \nbe stored (Figure 6). Geom_extent  is the spatial bounding box of \neach object where a 3D R -tree index is created. Spatial queries \nwill be formulated into an intersection operation with the \nbounding boxes. What is returned is a set of points of whole \nobjects, i.e. an approximate answer. This is reasonable as for \nvisualization, it is vague to show only part of an object. As LoD \nis another dimension frequently queried, a B -tree index is \ncreated on the sub tables. After population, the base table \ncontains 9,833 records. The total storage space is 21,366 MB, \nout of which 5,246 MB is used to store the B -tree index.  \n \nRoomType  RoomID  Class  ObjectID  Geom_extent  Point_tab  \nNum  Num  Num  Num  SDO_GEOMETRY  POINTER  \n \nLoD X Y Z R G B \nNum Num Num Num Num Num Num \nFigure 6. Schema of the S3DIS nested table, S3OBJ_NEST, \ncontaining a base table and many sub tables.  \n \nQuery  Number of \nrecords \nreturned  Time  \ncost (s)  \n1. select COUNT(*) from (select u.* from \nS3OBJ_NEST,  \ntable(S3OBJ_NEST.point_tab) u)  1 25.3 \n2. select u.* from S3OBJ_NEST,table \n(S3OBJ_NEST.point_tab) u where \nu.lod>0.99/0.95/0.8/0.5  657,295/  \n3,287,515/  \n31,730,001/  \n122,433,484  5/ \n33.27/  \n207.14/  \n767.4  \n3. select roomtype, roomid, class, objected, \nu.* from S3OBJ_NEST,table \n(S3OBJ_NEST.point_tab) u where \nu.lod>0.99/0.95/0.8/0.5  657,295/  \n3,287,515/  \n31,730,001/  \n122,433,484  74.66/  \n114.86/  \n342.6/  \n1092.48  \n4. select u.* from S3OBJ_NEST,table \n(S3OBJ_NEST. point_tab) u where \nu.R=223/142/  \nRoomtype = 2006  188,704/  \n2,117,209/  \n1,161,301/  14/ \n26.7/ \n7.54 \n5. SELECT u.* FROM s3obj_nest s, \ntable(s.point_tab) u WHERE \nSDO_ANYINTERACT (s.geom_extent, \nSDO_GEOMETRY(3008,NULL, \nNULL,SDO_ELEM_INFO_ARRAY(1,1007\n,3), \nSDO_ORDINATE_ARRAY(12.075,15.267,\n0, 20.13,19.3,2))) = 'TRUE' / ( -9.072, 17.307, \n1, 3.208, 23.557, 2.8) / (4.7, 10.9, -1, 19.2, \n31.6, 3.8) / ( -20.32, -5.9, -2, 21.2, 27.5, 2)  4,036,284/  \n14,195,028/  \n22,893,270/  \n129,250,908  27.6/ \n92.96/  \n149/ \n836.6  \nTable 2. Q uery performance on S3OBJ_NEST  \n \nSimilar to the flat table approach, the second query, LoD \nselection presents a linear tendency with the formula: Time = 6 \nx 10-6 n + 7.71. The execution plan shows that only indexed \nrange scan is performed. The slope is smaller as there are only 7 \ndimensions written out. However, when the RoomType  and the \nother attributes in the base table are added (i.e. the 3rd query), \nthe execution plan incorporates nested loops to join dimensions \nand the time cost becomes larger.  \n \nWithout index, the selection on the R (color) dimension of \nQuery 4 incurs the full table scan which indeed takes longer \nthan the selection on the in dexed LoD dimension. However, the \nincrease of the output scale could make the writing process \ndominant. Hence, the time cost does not vary much from that of \nLoD when more points are selected. Besides, if the dimension \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n368\n\nselected resides in the base table, th e process, in contrast, can be \nvery fast. Only full table scan of the base table (which nearly \nhas no cost) and the writing phase take up the time.  \n \nWith regard to the spatial selection, i.e. Query 5, the original \nfull table scan for three dimensions turn s into a spatial selection \nusing a spatial index. Yet the number of records for searching \ndecrease as well, i.e. from full records into records in the base \ntable. On the whole, the approximate spatial selection on the \nS3OBJ_NEST table is faster than full t able scan selections on \nthe S3SDISFLAT table (Figure 7). However, in all cases, the \napproximate selections contain more points (Figure 8). On the \none hand, this is a result from selections of complete objects; on \nthe other hand, since the bounding box is u tilized for \nintersection, more objects might get involved. Sometimes the \noutliers are even more than the accurate result itself. \nNonetheless, the ratios of outliers (the extra number of points \nreturend divided by the number of points from approximate \nselec tion) are: 0.72, 0.57, 0.39 and 0.23, which presents a \ndecreasing trend as the output size grows.  Consequently, in the \ntail of the curve of time cost (Figure 8), we observe that the \napproximate selection surpasses the accurate selection. It \nimplies that t he time spent on full table scan becomes more \nsignificant than the additional time to write extra records into \nthe memory.  \n \n \nFigure 7. Comparison between the accurate spatial selections on \nthe S3SDISFLAT table and the approximate selections on the \nS3OBJ_ NEST table.  \n \n \nFigure 8. Comparison of the number of points returned from \nspatial selections on the S3SDISFLAT table presented as bars \nand the S3OBJ_NEST table, together with the query execution \ncost expressed using curves.  \n \nIn summary, the nested table s tructure complexes the query \nprocess to some extent, selections to join the dimensions in the \nbase table and sub tables for instance. The advancement from \nthe B -tree index on LoD is insignificant although it facilitates queries with small output. It could be an alternative to order the \ndata according to the cLoD value and then use ROWNUM to \nonly scan parts of the sub tables to reduce the time cost. The \naccess pattern of the LoD dimension is always to select certain \ncontinuous portion of the points. The appr oximate method \npresents its advantage when the time cost on the full table scan \nbecomes inevitably significant with large output. Besides, it is \ncrucial to notice that the importance of each dimension is well \naddressed by such a data structure, i.e. CLASS > SPATIAL > \nLoD > Normal.  \n \n5.3 Table with a spatial index  \nCompared to the S3DISFLAT, the xyz information is stored in a \nSDO_GEOMETRY object, i.e. SDO_GEOMETRY(3001, null, \nMDSYS.SDO_POINT_TYPE( X, Y, Z ), null, null) in the \nS3DISGEOM table. After it, a 3D R -tree is created on the \ngeometry column, while the index creation cost 3 hours and 9 \nminutes to finish. The other dimensions are normal attributes. \nThe table size is 19,175 MB, occupying 611,142 Oracle logic \nblocks, while the spatial index size is 22,011 MB.  \n \nFor the LoD selection and the spatial selection, initial tests \npresent high time cost. Hence, to reduce the workload for \nwriting, only XYZ are selected (Table 3). The linear model of \nthe LoD selection is: Time = 4 x 10-5 n + 17.6, which entails the \nquery e xecution is much slower than that of S3DISFLAT. The \nmain reason is that in the writing part, additional cost is spent \non converting binary geometry objects into plain coordinates.  \n \nIt could be observed that the spatial selections based on \nSDO_INSIDE fail to fetch the correct number of points. In \naddition, the process takes huge amount of time to execute. As \nis indicated in the table, the inefficient spatial computation \ncomprises the body. Besides, previous developers also proposed \nthat an index may not wor k out if the query was not selective \nenough (e.g. query data distributed across the whole storage). It \ncould be much slower than a full table scan. The R -tree index \ncreated in this solution is very large. With such a cumbersome \nindex, searching the pointer s and then extracting the data are \nless efficient than a direct full table scan.  \n \nQuery  Number of \nrecords \nreturned  Time cost \n(s) \nselect COUNT(*) from s3disgeom  1 17.3 \nselect t.x,t.y,t.z from s3disgeom c, \ntable(SDO_UTIL.GETVERTICES(c.point\n_geom )) t where lod>0.99/0.95/0.8/  657,295/  \n3,287,515/  \n31,730,001  41.54/  \n136.3/  \n1165 \nselect t.x, t.y, t.z from s3disgeom c, table \n(MDSYS.SDO_UTIL.getvertices(c.point_\ngeom)) t where SDO_INSIDE \n(c.point_geom, SDO_GEOMETRY(3008, \nNULL, NULL, \nSDO_ELEM_INFO_ARRAY(1, 1007,3), \nSDO_ORDINATE_ARRAY(12.075,15.26\n7,0,20.13,19.3,2))) / ( -9.072, 17.307, 1, \n3.208, 23.557, 2.8) / (4.7, 10.9, -1, 19.2, \n31.6, 3.8)  911,090/  \n5,541,547/  \n13,163,720  549.87 \n(538.92)/  \n2917.9 \n(2761)/  \n6659.6 \n(6239.4)  \nTable 3. Query performance on S3DISGEOM. Time \nmeasurements in brackets are roughly the time to perform the \nSDO_INSIDE computation.  \n \n5.4 SDO_PC blocks  \n \nThe schema is analogous to the nested table (Figure 9). In this \nsolution, the whole dataset is divided into blocks/BLOBs of \n10,000 points. So each object might be stored into several \nblocks. In the block table S3DISBLKTAB, the column  \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n369\n\nBLK_EXTENT  stores the bounding box of each block. On top of \nit, a 3D R -tree index is created. The solution costs 32.5 hours to \nfinish, which includes the creatio n and population from a stage \ntable like S3DISFLAT. 32,525 blocks are created in the end. \nThe total storage size is 21,417 MB, which is 1/4 more than that \nof the nested table. This is mainly because normally in the last \nblock of each object, only a part is  used to store the points.  \n \nRoomType  RoomID  Class ObjectID  PC \nNum Num Num Num SDO_PC  \nS3DISBASE  \n \nOBJ_ID  BLK_ID  BLK_EXTENT  NUM_POINTS  POINTS  \nNum Num SDO_GEOMETRY  Num BLOB  \nS3DISBLKTAB  \n \nX, Y, Z, R, \nG, B, LOD  \nBLOB  \nFigure 9. Schema of the SDO_PC solution. It includes the base \ntable S3DISBASE, the block table S3DISBLKTAB, and the \nBLOBs for real storage of points.  \n \nQueries are implemented in SQL scripts (Appendix) with \nSDO_PC tools which is the standard operation in t his solution. \nThe output is an Oracle flat table and it is difficult to store \nresults as an in -memory object.  \n \nFrom Table 4, the LoD selections take enormous amount of \ntime to execute, which is mainly caused by unpacking each \nblock for filtering, as was i ndicated by van Oosterom et al. \n(2015). Additional queries are tested to learn the output writing \nrate, and it turns out that in this case, the writing part is \nnegligible compared to the unpacking process.  \n \nType Range  Number of \nrecords \nreturned  Time cost \n(s) \nLoD \nquery  >0.99  \n>0.95  - \n- >10,000  \n>10,000  \nSpatial \nquery  (12.075,15.267,0,20.13,19.3,2)  \n(-9.072, 17.307, 1, 3.208, \n23.557, 2.8)  \n(4.7, 10.9, -1, 19.2, 31.6, 3.8)  \n(-20.32, -5.9, -2, 21.2, 27.5, 2)  1,155,519/  \n6,140,715/  \n13,916,132/  \n99,028,009  112.5/  \n485.4/  \n808.2/  \n9,380  \n \nTable 4. Query performance of the SDO_PC solution.  \n \nThe spatial query is more efficient thanks to the spatial index. \nHowever, still considerable time is spent on decoding the blocks \nand the successive scanning to return the precise re sults. The \nperformance deteriorates severely in the last query. It should be \nnoted that the spatial operators utilized causes inaccurate \nselections once again.  \n \nThe schema of this solution is similar to the nested table, but \nunpacking blocks is needed. It is not preferred considering the \nLoD selection where each BLOB has to be unpacked for \nfiltering. But this is inevitable as no operators is available for \ncreating  a 4D geometry (i.e. BLK_ENTENT ) used for indexing. \nA substitute is to utilize X/Y/LoD  as the bounding box to index. \nHowever, Z dimension plays a more important role in the \nindoor environment than outdoor. Additionally, the solution \nalso has the problem of  long loading process.  \n \n5.5 Index -Organized Table (IOT)  \n \nThe Oracle IOT is an index integrated data structure. The \nprimary key and non -key column data stored within the same B -tree structure in leaf nodes. The logical model is however, still a \ntable. Changes t o the table, for example, adding new rows, or \nupdating or deleting existing rows, result only in updating the \nindex. It is the fact that most of the time, X/Y/Z/LoD would be \nselected together. Using pySFC (Meijers, 2017), we encode \nX/Y/Z/LoD into a Morton key which is the primary key of the \nIOT. Specifically, X, Y and Z values are multiplied by 1,000 to \nbecome integers. The cLoD value are expressed as the ranking \nnumber. Then by interleaving the bits of the four dimensions \n(Psomadaki, 2016), the Morton key could be derived. As the \nlength of bits after encoding could exceed the limit of the \nNUMBER type, so VARCHAR is used to store the key. Other \ndimensions keep the same as that of the S3DISFLAT. The total \nstorage size is 21,179 MB.  \n \nType Range  Search \ndepth/ Number \nof ranges  Number of \nrecords \nreturned  Time cost (s)  \nLoD \nquery >0.99 \n>0.95 \n>0.8 \n>0.5 57/105  \n56/51 \n53/61 \n51/59 688,127/  \n3,342,335/  \n31,981,567/  \n123,731,967  8.8 + 36.36/  \n22.69 + 193/  \n217.2 + \n2,019/ 775.6 \n+ 7,848.5  \nSpatial \nquery (12.075,15.267,0,2\n0.13,19.3,2)  \n(-20.32, -5.9, -2, \n21.2, 27.5, 2)  52/261  \n52/261  273,608,340/  \n273,608,340  3001.7 + \n(>10,000)/  \n2950.5 + \n(>1,0000)  \nTable 5. Query performance of the IOT solution. The first part \nof time cost is query time including writing into  the memory, \nwhile the second part is the decoding cost.  \n \nThe searching process is based on the key, so the original \ndimension spans have to be translated into the ranges in the one -\ndimensional key. Due to the LoD structure embedded in the \nMorton code (in this case, every four bits represent a level), it is \npossible to control the computational depth (Table 5) to \ngenerate the ranges. It implies that a larger depth corresponds \nmore ranges, i.e. the result selected would be more accurate. In \nthe end, these ra nges are inserted into the WHERE clause in a \nSQL command to execute. Initial tests indicate too many ranges \nin the WHERE clause would be very inefficient.  For all queries, \nthe computation of ranges takes less than 1 second.  \n \nIn the tests, the writing resu lts contain all dimensions except \nLoD. As Table 5 shows, the querying process takes less time \nthan that of the S3DISFLAT thanks to the index although more \npoints are returned. This is more obvious when the output is \nsmall where writing is not the body. How ever, more time is \nspent on decoding. In fact, the decoding process constitutes \nanother linear factor in the performance in addition to writing \nresults. The current implementation of decoding is of \ncomplexity O(n) where n is the output size. If we intend t o \nachieve the O(logN) (N refers to the input data size) \nperformance of the B -tree, the n should be below of level of 106 \nif N does not exceed 1030. Otherwise, the decoding process \nwould become dominant. It implies that for large point clouds \nmanagement, th e additional encoding/decoding is not a \nrationale choice unless a new computational framework would \nbe directly built on the encoded data.  \n \nWith respect to the spatial queries, due to large time cost, the \nsmallest spatial query and the largest spatial que ry are used for \ntesting. As can be seen from the table, both queries return the \nwhole dataset as the result. In real experiments, larger search \ndepth is tried, but the query execution takes too much time to \nreturn the result. The inefficient spatial queryi ng is radically \ncaused by the value distribution of different dimensions \nencoded in the Morton key. Basically, the LoD dimension is a \nlong series with distinct values for each point, which makes it \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n370\n\nsuperior in the Morton key. The query then becomes extract ing \na thin slice from a large 4D cube, which is bound to be \ninefficient. The continuous LoD dimension may thus be \nremoved from the Morton key encoding, but LoD selection then \nbecomes a problem. Hence, employing the appropriate unit \nwhich controls the resol ution and range of the data \nrepresentation in the Morton code is a critical issue in which a \nproper balance has to be determined.   \n \nThere are two major advantages in applying an IOT approach. \nFirst, it utilized  the B tree to organize the whole storage bas ed \non a combined column SFC key where several dimensions are \ninvolved. Second , SFC is leveraged to group points together so \nthat relationships such as spatial neighbouring could be \nsustained. So the selection could be more consecutive instead of \ntoo many  intermittent retravel from the memory. Besides, the \nstructure is more compact compared with the separate table and \nindex approach with less pointers stored. This has direct \ninfluence on querying process where the “join” between index \nand table is more effic ient.  \n \n6. CONCLUSIONS  AND  FUTURE  WORK  \nThis research is an exploration of a state -of-the art solution to \nmanage large indoor point clouds for visualization in the \nnavigating mode. First the cLoD  which could help improve the \nperformance of large data visualization is introduced into data \nmanagement. Then by establishing a benchmark and utilize \nvarious Oracle solutions to test, we gained essential insights \nwhich indicate possible directions to furt her develop a nD \nPointCloud structure (Liu et al., 2018a):  \n \n1. Flat table with B -tree index and plain scanning could be \nefficient enough for management of large point clouds. A trick \nis how to realize the priority of different dimensions. Current \nunsatisfa ctory performance is mainly caused by the long writing \nprocess. In case of visualization, a possible solution is to \ntransfer the data retrieved directly to GPU for rendering. Then \nsmart caching strategies might  be applied to buffer a part of the \nquery resu lts into memory in parallel. Besides, the superfluous \ntable scanning could also be improved. An intuitive approach is \nto avoid unnecessary scanning by harnessing the cLoD \ndimension of which the access pattern is normally extraction of \na continuous portion of the storage. Another option is to \ndevelop an approximate accessing scheme.  \n \n2. The approximate querying shows its superiority when the \noutput size is large. The nested table approach is based on \nobjects, i.e. semantic information, while the IOT approac h \ncontrols the accuracy of query through the search depth. In \ngeneral, the probability density function (Kraska et al.,2017) \ncould be utilized to locate the targets roughly in the storage, for \nexample, development of a nD histogram based on the \ndistributio n of points to refine the ranges.  \n \n3. Use of spatial data types is not recommended. In the \nexperiments, none of the spatial computation could return \naccurate results. This might be related to the tolerance settings \nin the metadata table used for executing  queries. Also such an \napproach relies on spatial indexes which turn out to be very \ncumbersome. The index size is even larger than original data \nand it works inefficiently. Lastly, additional encoding/decoding \nprocesses are required. The decoding is a line ar factor in the \ntime cost, which undermines any gain of time from smart \nsearching of the data. This point is not only confined in spatial \ndata types, but also applies to the Morton coding. In the \nresearch,  a physical bound of 106 for the IOT approach is derived. If the output size exceeds it, the decoding process \nwould become dominant. However, such a threshold could be \nimproved by developing best practices, e.g. implementation \ninside the DBMS. Then the approach can be acceptable for \nexample, in virtual r ealize equipment where the memory size is \nlimited. Accordingly, research focus could shift to the LoD \ncomputation to determine the most representative points.  \n \nWith knowledge acquired, the research could be extended to \nintegrate point cloud models of citi es where classification \ninformation is also involved. As the object is the minimum unit, \na semantic index structure could be established, e.g. name of \ntown and then the city’s name. A high dimensional point cloud \nmanagement could then be developed as a cas e study.  \n \nApart from novel data management, more aspects could be \nimproved. Current implementation including Python query and \nencoding/decoding scheme, the SDO_PC and IOT structure is \nnot optimal. Benchmarks applied are simple and are not verified \nand dis cussed with industrial professionals. Scalability is not \nfully incorporated. The computation of LoD still originates from \nan engineer thinking, instead, visual perception/computer vision \nshould also be taken into account. The argument on whether \nutilize a cLoD or discrete LoD reserve to be solved.  \n \nACKNOWLEDGEMENTS  \nThe funding of this research comes from the Chinese \nScholarship Council (CSC) and Fugro. Thus, their support is \ngreatly acknowledged.  \n \nREFERENCES  \nArmeni, I., Sener, O., Zamir, A.R., Jiang, H., B rilakis, I., \nFischer, M. and Savarese, S., 2016. 3D semantic parsing of \nlarge -scale indoor spaces. In Proceedings of the IEEE \nConference on Computer Vision and Pattern Recognition, pp. \n1534 -1543.  \n \nFolk, M., Heber, G., Koziol, Q., Pourmal , E. and Robinson, D., \n2011, March. An overview of the HDF5 technology suite and \nits applications. In Proceedings of the EDBT/ICDT 2011 \nWorkshop on Array Databases  (pp. 36 -47). ACM.  \n \nHagedorn, B., Trapp, M., Glander, T. and Dö llner , J., 2009, \nMay. Towards an indoor level -of-detail model for route \nvisualization. In Mobile Data Management: Systems, Services \nand Middleware, 2009. MDM'09. Tenth International \nConference on (pp. 692 -697). IEEE.  \n \nISPRS, 2011. Las 1.4 format specification. Technical report, \nThe American Society for Photogrammetry And Remote \nSensing https://www.asprs.org/wp -\ncontent/uploads/2010/12/LAS_1_4_r13.pdf (13 May 2018).  \n \nKraska, T., Beutel, A., Chi, E. H., Dean, J., & Polyzotis, N. \n2017. The Case for Learned Index Str uctures. arXiv preprint \narXiv:1712.01208.  \n \nLiu, H., van Oosterom, P., Meijers, M. and Verbree, E., 2018a.  \nTowards 1015-level point clouds management - a nD PointCloud \nstructure. In Proceedings 21th AGILE Conference on \nGeographic Information Science, Lund, Sweden . \n \nLiu, H., van Oosterom, P., Tijssen, T., Commandeur, T. and \nWang, W., 2018b. Managing large multidimensional hydrologic \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n371\n\ndatasets: A case study comparing NetCDF and SciDB.  Journal \nof Hydroinformatics , https://doi.org/10.2166/hydro.2018.136.  \n \nMeijers , M., 2017. Functionality to use Space Filling Curves \ninside PostgreSQL for clustering and indexing. \nhttps://bitbucket.org/bmmeijers/pysfc   \n \nNIST. 2018. Notice of funding opportunity NIST public safe ty \ninnovation accelerator program (PSIAP) – point cloud city. \nTechnical report, National Institute of Standards and \nTechnology \nhttps://www.nist.go v/sites/default/files/documents/2018/01/05/2\n018-nist-psiap -pc2_nofo.pdf  (13 May 2018)  \n \nPsomadaki, S. 2016. Using a space filling curve for the \nmanagement of dynamic point cloud data in a relational DBMS . \nMaster’s thesis, Delft University of Technology, the  \nNetherlands.  \n \nSuijker, P.M., Alkemade, I., Kodde, M.P. and Nonhebel, A.E., \n2014. User requirements massive point clouds for eSciences \n(WP1). \nhttp://www.pointclouds.nl/docs/User _Requirements%20_MPC.\npdf (13 May 2018)  \n \nVan Oosterom, P., Martinez -Rubi, O., Ivanova, M., Horhammer, \nM., Geringer, D., Ravada, S., Tijssen, T., Kodde , M., and \nGoncalves, R. 2015. Massive point cloud data management: \nDesign, implementation and execution of a point cloud \nbenchmark. Computers & Graphics , 49:92 –125. \n \nAPPENDIX  \nSQL for table creation  \nFlat table : \nCREATE TABLE S3DISFLAT (X number, Y number, \nZ number, R number, G number, B number, \nRoomType number, RoomID number, Class \nnumber, ObjectID number, LoD number);  \n \nNested table : \nCREATE TYPE Point_type as object (X number, \nY number, Z number, R number, G numbe r, B \nnumber, LoD number);  \n \nCREATE TYPE Point_table IS TABLE OF \npoint_type;  \n \nCREATE TABLE S3OBJ_NEST (RoomType number, \nRoomID number, Class number, ObjectID \nnumber, Geom_extent SDO_GEOMETRY, Point_tab \nPoint_table)  NESTED TABLE Point_tab STORE \nAS Points ; \n \nCREATE INDEX bb_idx ON S3OBJ_NEST \n(Geom_extent) INDEXTYPE IS \nMDSYS.SPATIAL_INDEX PARAMETERS \n('sdo_indx_dims=3');  \n \nCREATE INDEX nested_tab_idx ON Points (LoD); \n \nTable with a spatial index : \nCREATE TABLE S3DISGEOM (Point_geom \nSDO_GEOMETRY, R number, G number, B  number, \nRoomType number, RoomID number, Class \nnumber, ObjectID number, LoD number);  \n CREATE INDEX point_idx ON S3DISGEOM \n(Point_geom) INDEXTYPE IS \nMDSYS.SPATIAL_INDEX PARAMETERS \n('sdo_indx_dims=3');  \n \nSDO_PC blocks : \nCREATE TABLE S3DISBASE (RoomType  number, \nRoomID number, Class number, ObjectID \nnumber, PC SDO_PC);  \n \nCREATE TABLE S3DISBLKTAB AS select * from \nmdsys.sdo_pc_blk_table;  \n \nCREATE TABLE tmp_heap as (select X as \nVAL_D1, Y as VAL_D2, Z as VAL_D3, R as \nVAL_D4, G as VAL_D5, B as VAL_D6, LoD as \nVAL_D7 from S3DISFLAT;  \n \nPC := SDO_PC_PKG.init('S3DISBASE ', 'PC', \n'S3DISBLKTAB', 'blk_capacity=10000', \nmdsys.sdo_geometry(3008, null, null, \nmdsys.sdo_elem_info_array(1,1007,3),mdsys.s\ndo_ordinate_array( -37.928, -26.078, -2.645, \n29.927, 46.056, 6.576)), 0.0001,  7, null);  \n \nSDO_PC_PKG.create_pc(PC, 'tmp_heap',  null);  \n \nIOT: \nCREATE TABLE S3DISIOT (SFC varchar2(200), R \nnumber, G number, B number, RoomType number, \nRoomID number, Class number, ObjectID \nnumber, CONSTRAINT SFC4D_PK PRIMARY KEY \n(SFC)) ORGANIZATION INDEX;  \n \nSDO_PC query script  \nLoD: \nINSERT into PC_RES SELECT query_points.X, \nquery_points.Y, query_points.Z from  \ntable(SDO_PC_PKG.CLIP_PC(each.pc, \nSDO_GEOMETRY(3008, null, null,  \nSDO_ELEM_INFO_ARRAY(1,1007,3), \nSDO_ORDINATE_ARRAY( -37.928, -26.078, -2.645, \n29.927, \n46.056,6.576)),SDO_MBR(SDO_VPOINT_TYPE(0,0,\n0,LoDmin), SDO_VPOINT_TYPE \n(256,256,256,1)),null,null))  \nquery_blocks,table(SDO_UTIL.GETVERTICES(SDO\n_PC_PKG.TO_GEOMETRY(query_blocks.points,  \nquery_blocks.num_points,3,null))) \nquery_points; (LoDmin equals \n0.99/0.95/ 0.8/0.5)  \n \nSpatial : \nINSERT into PC_RES SELECT query_points.X, \nquery_points.Y, query_points.Z from \ntable(SDO_PC_PKG.CLIP_PC (PC, SDO_GEOMETRY \n(3008, null, null, SDO_ELEM_INFO_ARRAY (1, \n1007, 3),  \nSDO_ORDINATE_ARRAY (Xmin, Ymin, Zmin, Xmax, \nYmax, Zmax)),null ,null,null)) query_blocks, \ntable(SDO_UTIL.GETVERTICES(SDO_PC_PKG.TO_GE\nOMETRY (query_blocks.points, \nquery_blocks.num_points,3,null))) \nquery_points; (Spatial range are \n(12.075,15.267,0,20.13,19.3,2) / ( -\n9.072,17.307, 1, 3.208, 23.557, 2.8) / (4.7, \n10.9, -1, 19.2, 31.6, 3.8)) / ( -20.32, -5.9, \n-2, 21.2, 27.5, 2)  \nThe International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Volume XLII-4, 2018 \nISPRS TC IV Mid-term Symposium “3D Spatial Information Science – The Engine of Change”, 1–5 October 2018, Delft, The Netherlands\nThis contribution has been peer-reviewed. \nhttps://doi.org/10.5194/isprs-archives-XLII-4-365-2018 | © Authors 2018. CC BY 4.0 License.\n \n372",
  "textLength": 48656
}