{
  "paperId": "e69a88df64d3906e9f8e5c9652b48f662410ef8a",
  "title": "LIMAO: A Framework for Lifelong Modular Learned Query Optimization",
  "pdfPath": "e69a88df64d3906e9f8e5c9652b48f662410ef8a.pdf",
  "text": "arXiv:2507.00188v1  [cs.DB]  30 Jun 2025LIMAO: A Framework for Lifelong Modular Learned Query\nOptimization\nQihan Zhang\nqihanzha@usc.edu\nUniversity of Southern California\nLos Angeles, California, USAShaolin Xie\nshaolinx@usc.edu\nUniversity of Southern California\nLos Angeles, California, USAIbrahim Sabek\nsabek@usc.edu\nUniversity of Southern California\nLos Angeles, California, USA\nABSTRACT\nQuery optimizers are crucial for the performance of database sys-\ntems. Recently, many learned query optimizers (LQOs) have demon-\nstrated significant performance improvements over traditional opti-\nmizers. However, most of them operate under a limited assumption:\na static query environment. This limitation prevents them from\neffectively handling complex, dynamic query environments in real-\nworld scenarios. Extensive retraining can lead to the well-known\ncatastrophic forgetting problem which reduces the LQO general-\nizability over time. In this paper, we address this limitation and\nintroduce LIMAO (Lifelong M odula r Learned Query O ptimizer), a\nframework for lifelong learning of plan cost prediction that can\nbe seamlessly integrated into existing LQOs. LIMAO leverages a\nmodular lifelong learning technique, an attention-based neural net-\nwork composition architecture, and an efficient training paradigm\ndesigned to retain prior knowledge while continuously adapting to\nnew environments. We implement LIMAO in two LQOs, showing\nthat our approach is agnostic to underlying engines. Experimental\nresults show that LIMAO significantly enhances the performance of\nLQOs, achieving up to a 40% improvement in query execution time\nand reducing the variance of execution time by up to 60% under\ndynamic workloads. By leveraging a precise and self-consistent de-\nsign, LIMAO effectively mitigates catastrophic forgetting, ensuring\nstable and reliable plan quality over time. Compared to Postgres,\nLIMAO achieves up to a 4 Ã—speedup on selected benchmarks, high-\nlighting its practical advantages in real-world query optimization.\nPVLDB Artifact Availability:\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/Tsihan/LIMAOLifeLongRLDB.\n1 INTRODUCTION\nQuery optimizers are crucial components of database systems, re-\nsponsible for selecting efficient execution plans for queries. Tradi-\ntional query optimizers have been the backbone of database systems\nfor decades (e.g., [ 21,58]). However, their inherent limitations and\nchallenges, such as reliance on heuristics (e.g., attribute indepen-\ndence [ 33,62]) and inaccurate cost models especially with complex\nworkloads and diverse data distributions, have spurred the develop-\nment of learned query optimizers (LQOs) (e.g., [ 15,38,40,68,73]),\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.\ndoi:XX.XX/XXX.XXwhere machine learning (ML) models have been used to replace\nor improve different components of the query optimizer including\ncardinality estimation [ 29,60,70], cost prediction [ 42,59], and plan\nsearch [38, 40, 68, 73].\nWhile effective in certain scenarios, existing LQOs struggle in\ndynamic environments with shifting data distributions and query\nworkloads. Recent efforts (e.g.,[ 11,51]) have primarily focused on\nmanaging controlled and infrequent shifts. However, addressing\nsignificant and frequent changes remains a challenge, as the pre-\ndominant solution still relies on complete retraining from scratch .\nThis approach is computationally expensive and susceptible to per-\nformance degradation due to catastrophic forgetting [27], where pre-\nviously learned knowledge is lost when adapting to new workloads,\nparticularly in cases of temporary changes or workload reversions.\nIn this paper, we address this limitation by introducing LIMAO ,\na framework for Lifelong Modular Learned Query Optimization.\nLIMAO focuses on the learned cost prediction (LCP) problem, where\nML models (e.g., tree convolution networks [ 49] and transform-\ners [ 47]) are employed to predict (sub-)plan costs. In particular,\nLIMAO aims at promoting existing LCPs (e.g., [ 38,40,68,73]) in\nLQOs to be lifelong learners; capable of continuously learning and\nadapting over time while retaining and leveraging previously ac-\nquired knowledge to ensure stable performance. LIMAO is based\non the idea of learning reusable knowledge in a modular man-\nner [ 36,44]. The core intuition is that, to develop a versatile LCP\ncapable of accurately predicting the costs of unseen queries, it is es-\nsential to learn reusable knowledge of queriesâ€™ sub-plans, i.e., tasks,\nthat can be recombined for new queries, rather than tailoring LCPs\nto specific query types or workloads. This approach draws inspira-\ntion from advancements in robotics and mirrors human problem\nsolving, where accumulated, reused, and recombined skills enable\nefficient handling of novel challenges over time.\nRealizing the idea of learned reusable knowledge in the query\noptimization context requires addressing three key challenges:\n(1) identifying a modular decomposition approach suited to the tree\nstructure of query plans, (2) ensuring the LCP effectively reuses\nexisting knowledge about tasks (i.e., sub-plans) before incorpo-\nrating new knowledge to prevent redundant learning, and (3) de-\nveloping a learning strategy that preserves previously acquired\nknowledge when integrating new knowledge from tasks in new\nqueries. To address these challenges, LIMAO introduces several\ncore components. To tackle the first challenge, LIMAO employs an\nefficient plan decomposer that splits query plans into sub-plans (i.e.,\ntasks) using a new notion of \"break\" operators that defines modular\npoints in the plan tree. For the second challenge, LIMAO builds and\nmaintains Module Hubs , a shared repository of specialized neural\nnetwork modules corresponding to specific task types, using an\n\nTraining Queries, \ntheir Plans, and latenciesUser\nQuery\nQT\n1 QT\n2\nQLearned Cost Prediction\nQuery Execution EngineQuery\nOutput Cost\nPrediction\nFinal PlanQuery, its plan, \nand latency\nExperience Manager\nQCandidate\n(or Partial) \nPlan\nReplay Buffer \nfor (Re-)training(Learned) Plan SearchFigure 1: A typical learned query optimizer architecture.\nefficient variation of the ğ¾-prototype algorithm [ 26].LIMAO fur-\nther introduces a new attention-based neural network composition\narchitecture that dynamically integrates the selected modules from\nthe hub and assigns appropriate weights to their contributions to\nthe final plan cost estimation. To overcome the third challenge,\nLIMAO proposes a novel two-phase training approach grounded\nin the lifelong learning paradigm that avoids overriding previous\nknowledge. This approach leverages experience replay buffers along\nwith a lightweight episodic updates mechanism to facilitate fre-\nquent, low-overhead model updates during the online phase while\neliminating the need for full retraining in the offline phase.\nLIMAO is a generic framework designed to seamlessly integrate\nwith almost all existing LQOs. In this paper, we showcase its po-\ntential by integrating it with Balsa [ 68], a state-of-the-art reinforce-\nment learning-based query optimizer, and Bao, a state-of-the-art\nhint-based query optimizer, as system prototypes. We tested on\nIMDB [ 33] and TPC-H [ 6] databases using Postgres and designed\nchallenging dynamic situations for them. Our experimental eval-\nuation across various dynamic workloads and data distribution\nshifts demonstrates that LIMAO not only shows better results on\nexecution time but also outperforms the prototype by orders of\nmagnitude in query stability (variance of plan quality over the\nsame query). For IMDB queries, LIMAO improves plan execution\ntime up to 40%and query stability by 60%, effectively addressing\ncatastrophic forgetting. LIMAO also achieves up to 400% gains in ex-\necution time compared to Postgres. For TPC-H queries, 2Ã—speedup\nis achieved, and the query stability gain is more than 100Ã—, demon-\nstrating significant performance improvements and resilience under\ndynamic situations. LIMAO can reduce the number of bad plans to\n0, while Balsa has a few hundred. We also test LIMAO â€™s resilience\nto overcome the fluctuation in different dynamic levels on different\nworkloads for IMDB, the result shows that LIMAO can achieve up\nto6Ã—speedup than Balsa.\n2 LCP AS A LIFELONG LEARNING PROBLEM\n2.1 LCP in Learned Query Optimizers\nPlan cost prediction is a critical operation in query optimization\nthat determines the efficiency of an execution plan. Traditional\ncost models rely on formulas that take cardinality estimates of sub-\nqueries as inputs and use manually-tuned constants and heuristics\nrefined over years to align estimated costs with actual performance\n(e.g., [ 20,21,58]). While effective, these traditional models often\nstruggle to capture the complexity of varying data distributions\nand query workloads [42, 59].Many LQOs (e.g., [ 38,40,68,73]) adopt learned cost prediction\n(LCP) techniques, where ML models, such as tree convolution net-\nworks [ 49] and attention mechanisms [ 63], are used to predict\nthe cost of (sub-)plans based on execution statistics from diverse\ndatasets and workloads1. LCPs play a central role in these LQOs\nto guide the plan search algorithms to find the best execution\nplan. For instance, the plan search process can be modeled as a\ndeep reinforcement learning problem, with LCP as value networks\nto guide searches that complete partial plans into full execution\nplans [ 68]. Alternatively, other plan search algorithms learn how to\nselect among candidate plans generated by traditional optimizers\nwhile leveraging LCPs to estimate the cost of these candidate plans\n(e.g., [ 38]) or their relative rankings (e.g., [ 73]). Figure 1 shows a\ntypical architecture of an LQO employing LCP with its plan search.\n2.2 LCP with Lifelong Learning\nPerformance Degradation in Dynamic Environments. While\nexisting LCP approaches (e.g., [ 38,40,42,59,68]) have shown\npromise, they face significant challenges in dynamic environments\nof data and query workloads. Some LQOs have attempted to ad-\ndress the dynamic environment challenges by emulating the data\nand workload drift scenarios during training, such as randomly\nremoving [ 11] or partially masking query information [ 51] to force\nML models to make predictions with missing information. How-\never, these approaches are only effective for slight and infrequent\nchanges in query or data distributions. Most LCP approaches still re-\nquire complete (re-)training from scratch (i.e., ML model parameters\nare completely re-learned) when faced with significant andfrequent\nchanges in the environment. For example, an LCP trained on a\nworkload dominated by JOB queries [ 33] will generate suboptimal\nplans if the workload is frequently altered with CEB queries [ 51],\nwhich involve more complex join patterns than JOB. While robust\nlearned cardinality estimators (e.g., [ 35,51]) might adapt to such\nchanges, the LCP still needs to be retrained to reflect this change in\nthe plan cost prediction. Extensive retraining of LCPs in response\nto frequent changes in dynamic environments can lead to the cata-\nstrophic forgetting problem [ 27], where the learned model fails to\nretain prior knowledge when retrained on new ones, especially in\ncases of temporary changes orworkload reversions . To better un-\nderstand this failure behavior, we conducted a simple experiment\nthat simulates frequent workload drift using a TPC-H query work-\nload [ 6] (scale factor of 10). We divided the workload into two sets,\nnamely set1 and set2, based on query templates, and alternated\ntheir execution every 5 iterations over a total of 100 iterations. In\neach iteration, all queries from the active set were executed (e.g.,\nset1 ran during iterations 1â€“5, set2 during iterations 6â€“10, and so\non, with each set running for a total of 50 iterations). We evaluated\ntwo variations of Balsa [ 68], a typical RL-based LQO: vanilla Balsa,\nwhich suffers catastrophic forgetting, and our LIMAO -based Balsa,\nwhich addresses this issue based on our proposed LIMAO frame-\nwork. Both variations incrementally retrained their LCPs at the end\nof each iteration. This means that for iterations 2 to 4 within any\n5-iteration period, queries used an LCP that had been (re)-trained\non their current query set, while in iteration 1, they relied on an\n1Unlike approaches that focus solely on learning cardinality estimation [ 18,28,50,65,\n70, 71, 74], our focus is on learned end-to-end cost prediction techniques.\n2\n\n0 10 20 30 40 50\nIteration255075Time (s)\nTPC-H sf=10 Q10e\nLIMAO-based Balsa\nVanilla BalsaFigure 2: Catastrophic forgetting on the LQOs performance.\nLCP trained on the other query set from the previous period. Fig-\nure 2 shows the execution time of one query in set1 across its 50\niterations. After iteration 20, the performance of both variations\nstarted to stabilize, where vanilla Balsa encounters latency jumps\nat the beginning of the 5-iterations period due to the catastrophic\nforgetting of its LCP that was re-trained on the other query set\nin the previous 5-iterations period. In contrast, the LIMAO -based\nvariation was more stable despite frequent workload changes.\nOur Goal. Our ultimate goal is to develop a lifelong LCP that can\nbe useful for long stretches of time. The LCP can continuously\nlearn and adapt over time, integrating new knowledge from chang-\ning queries and data while retaining and leveraging the previously\nacquired knowledge to ensure that performance in prior tasks does\nnot degrade. While single-task learning approaches incorporating\ntechniques like transfer learning [ 7] and mechanisms to avoid cat-\nastrophic forgetting [ 30] seem to be a natural fit for our problem,\nthey are inherently task-specific and struggle to generalize to signif-\nicantly different tasks. Multi-task learning (e.g., [ 56]) offers another\ndirection, where a single model can be learned to share knowledge\nacross diverse types of queries and data scenarios, but this approach\nis impractical since future queries and data patterns cannot be fully\nanticipated. Following the same direction, large-scale pre-training\non diverse query workloads and data distributions (e.g., [ 23,24])\ncan provide a foundation, yet assumes stationary distributions and\nfails to adapt to the dynamic nature of real-world database environ-\nments. Furthermore, pre-trained models are inherently imperfect\nand require continual feedback from the execution environment to\ncorrect unexpected behaviors and maintain effectiveness over time.\n3LIMAO OVERVIEW\nMain Observation and Challenges. We observe a key limitation\nhindering existing LCPs from being suitable for a lifelong setup:\nthey treat each query as a standalone task, which is inadequate for\nknowledge retention. Queries often comprise fine-grained patterns\nthat are hard to learn with a single ML model. Moreover, these pat-\nterns can be shared across queries to help in predicting their costs.\nFor example, in a multi-table join query, it is typical to combine\ndifferent types of join operators (e.g., nested-loop join, hash join,\nsort-merge join) to run the query, and such combinations often\nrecur in other queries. Thus, it is valuable to learn these patterns\nas independent ML modules . Learning compositional modules en-\nables the recombination of these modules for unseen queries and\nthe addition of new patterns (i.e., new modules) without requiring\na complete update of the LCPâ€™s model. However, achieving this\npresents three main challenges. First, we need to identify a modular\ndecomposition approach that is suitable for the plan tree structure(Challenge 1 ). Second, we need a strategy that ensures that the LCP\nreally reuses knowledge from existing modules to predict the cost\nof new queries before incorporating any specific new knowledge\nto these new queries ( Challenge 2 ). Third, when incorporating\nsuch new knowledge, we must devise a learning strategy that si-\nmultaneously prevents the forgetting of knowledge already stored\nin existing modules ( Challenge 3 ).\nFramework Overview. Here, we propose LIMAO , a framework\n(shown in Figure 3) that tackles the above-mentioned challenges\nand allows existing LCPs to be efficient lifelong learners. Inspired by\nrecent advances in robotics and human learning processes [ 36,43â€“\n45] that focus on learning reusable knowledge, LIMAO formulates\nthe learning process of LCP as a functional compositional learn-\ning problem [ 44]. The core idea is to decompose query plans into\nsmaller â€œtasksâ€ (i.e., sub-plans), each handled by specialized neural\nnetwork â€œmodulesâ€ (e.g., Tree-CNN [ 49], Transformer [ 63]), which\nare then composed into a higher-level network to predict the over-\nall cost (similar to programming, where functions are combined to\nsolve complex problems). For example, a query plan with nested-\nloop joins and hash joins can reuse pre-trained modules for these\noperators, recombining them to handle unseen queries efficiently.\nTo address Challenge 1, LIMAO introduces a Plan Decomposer\n(Section 4) that divides the plan into sub-plans (i.e., tasks) based\non a new notion of \"break\" operators. These operators efficiently\ndefine points in the plan tree where modular composition can occur.\nTo tackle Challenge 2, LIMAO maintains a shared compositional\nknowledge base called Module Hubs . Each hub contains a set of spe-\ncialized neural network modules that correspond to a specific task\ntype, allowing the model to dynamically select the most relevant\nmodules for a given task. LIMAO further employs a composable\nneural network (Section 7) designed to predict the cost of any plan\nbased on the modules chosen for the tasks inside it, dynamically\nweighting their contributions to refine the final estimate. To over-\ncome Challenge 3, and inspired by prior works [ 44],LIMAO adopts\nan efficient two-phase training paradigm (Section 8) that encour-\nages knowledge reuse rather than redundantly learning patterns.\nThe training process of LCP is divided into online andoffline phases.\nDuring the online phase, LIMAO attempts to form a cost prediction\nmodel for the LCP and train it using only existing close enough\nmodules from the Module hubs. To ensure that LCP wisely reuses\npreviously acquired knowledge without overriding it ,LIMAO modi-\nfies only a copy of the selected modules using a lightweight training\nmechanism. In this approach, each training iteration is divided into\nsmaller sections called episodes , which allow for prompt model\nupdates and avoid disastrous plans. The original module parame-\nters remain unchanged, and any newly discovered knowledge is\nstored in a buffer for later use in the offline phase. During the offline\nphase, the LCP incorporates any new knowledge from the buffer\nby updating the original parameters of existing modules.\nFigure 3 shows the components and workflow of LIMAO . First,\na candidate or a final plan is obtained from an LQO. For example,\nan LQO like Bao [ 38] would rely on complete candidate execution\nplans generated by a traditional optimizer to select from, whereas\nNeo [ 40] and Balsa [ 68] use a step-by-step plan searcher that builds\non partial plans at each iteration. Then, the Plan Decomposer breaks\nthe plan into sub-plans (i.e., tasks) (Section 4). Next, the Tasks En-\ncoder obtains efficient embeddings for each task using plan-level\n3\n\nTraining Queries, \ntheir Plans, and latenciesUser\nQuery\nQT\n1QT\n2QTasks EncoderPlan DecomposerLQO (e.g., Balsa)\nLearned Modular \nCost Prediction\nTask Modules \nSelector\nQuery Execution Engine Experience ManagerQuery\nOutput\nTask Modules Maintainer Cost\nPredictionCandidate\n(or Partial) \nPlanTasks\nTasks' \nEmbeddings\nSelected Tasks' \nModules\nFinal Plan Replay Buffer \nfor (Re-)trainingModules\nfor\nModules\nfor\nModules\nfor\nQuery, its plan, \nand latencyShared \nTasks' \nModulesQ(Learned) Plan Search\nExperience for Updating\nTasks's ModulesModule HubsFigure 3: LIMAO framework overview.\nand operator-level features (Section 5), which are used by the Task\nModules Selector andModular Plan Cost Predictor components. The\nTask Modules Selector (Section 6) retrieves the most relevant mod-\nules from the Module Hubs based on embeddings, adopting a ğ¾-\nprototype clustering algorithm [ 26]. These hubs are created and\nfrequently updated by the Task Modules Maintainer (Section 6). The\nModular Plan Cost Predictor assembles the selected modules into a\ncompositional neural network. Their output query representations\nare weighted and merged using the attention mechanism [ 8,12,22]\nto generate a final cost estimate for the plan. When the LQO pro-\nvides a final plan based on the cost estimates, the plan is executed\nin the query execution engine and feedback is sent to Experience\nManager for (re-)training the Modular Plan Cost Predictor and the\nselected modules using our two-phase training approach.\n4 PLAN DECOMPOSITION INTO TASKS\nIn this section, we illustrate the process of decomposing a query\nplan into a set of tasks to address Challenge 1 . This process is an\nimportant step in enabling the functional composition of LIMAO .\nHowever, it is very challenging because decomposing a plan into\na set of combinable tasks is inherently complex. This complexity\narises from the variable structure of the query plans, where the\nnumber, types, sequence of operators, and tree depth are not fixed.\nApproach. A straightforward idea for decomposing a query plan is\nto divide it into pipelines based on \"blocking\" operators [ 46]. How-\never, this often results in suboptimal tasks from the functional com-\nposition perspective, as blocking operators may create pipelines\nthat are too coarse-grained, resulting in large, monolithic tasks\nwhere diverse execution patterns (e.g., various join types or scan\nmethods) are grouped together. Such coarse decomposition makes\nit challenging to construct reusable modules for other queries. De-\ntermining appropriate breakpoints in the plan tree for task decom-\nposition is, in general, a non-trivial problem. Sub-trees that are\ntoo deep result in ineffective decomposition, as they closely re-\nsemble the original query plan, while overly frequent breakpoints\ncreate shallow sub-trees that fail to capture plan complexity and\nadd computational overhead due to the proliferation of sub-trees.\nTo address this, we introduce the concept of \"break\" operators\nto guide the plan decomposition process. A break operator is an\noperator that splits the plan tree at its first occurrence during a\n \nDecomposeTree 1 Tree 3\nTree 4\nTree 2Finalized Aggregate\nGather\nPartial Aggregate\nNL\nHJ HJ\nISNL IS\nSSIS SSFinalized Aggregate\nGather\nPartial Aggregate\nNL\nHJ HJ\nISNL IS\nSSIS SSHJ\nIS SSHJ\nISNL IS\nSSNL=Nested Loop\nSS=Seq ScanHJ=Hash Join\nIS=Index ScanNotationsFigure 4: Example on plan decomposition into tasks. Grey\noperators are those break operators that are ignored because\ntheir ancestral nodes already include at least one instance of\nthe same break operator type.\ntop-down traversal. Specifically, we identify the first occurrence of\na break operator in both the leftandright sub-trees of the root, and\nextract the corresponding sub-trees rooted at these operators. We\nstop the traversal upon encountering the first instance of each break\noperator type to avoid creating structurally overlapping sub-trees\nrooted at the same operator type. Continuing the decomposition\nbeyond the first occurrence would lead to multiple sub-trees that\nshare the same break operator type at their rootsâ€”i.e., they would\nbefunctionally overlapping â€”resulting in unnecessary tasks.\nJoins as Break Operators. In principle, break operators can be\nany type of query plan operator (e.g., scan, join, aggregate, sort).\nHowever, for break operators to be effective, they should satisfy two\nkey criteria: 1) Performance-critical : the break operator should sig-\nnificantly influence the query execution time, and 2) Decomposition-\neffective : splitting around this operator should produce sub-plans\nthat are neither too fine-grained nor too coarse, enabling meaning-\nful modular learning. We chose the join operators as break oper-\nators because they best satisfy both criteria. First, join operators\nare typically the most computationally expensive components in\nquery plans. Second, decomposing around join operators results in\nsub-plans that are rich in structure and execution variability.\nExample. Figure 4 shows an example of our plan decomposition\napproach using two example break operators: hash join (HJ) and\nnested-loop join (NL). The left side shows the original plan tree,\nwhile the right side shows the resulting four sub-trees (i.e., tasks):\nthree sub-trees that are generated by the break operators and one\nsub-tree that spans the remaining operators (i.e., aggregations,\n4\n\nscans, non-break join operators) from the root to the first encoun-\ntered break operator or leaf nodes for completeness. The plan tree\nis traversed independently for each break operator type to generate\ntheir corresponding tasks. For the NL operator, only one sub-tree\n(Tree 2) is generated as the first encountered NL node has no sibling\nand already covers its grandchild NL node, which is colored in grey.\nConversely, for the HJ operator, two HJ-rooted sub-trees (Trees\n3 and 4) are produced, as the traversal continues through the left\nand right sub-trees of the NL node, marked in purple. Note that,\nsince Tree 2 is NL-rooted and Tree 3 (or Tree 4) is HJ-rooted (i.e.,\nfunctionally non-overlapping), they can overlap structurally.\n5 TASK ENCODING\nEfficient encoding of decomposed tasks is crucial to capture their\ncharacteristics during the module selection and cost prediction\nsteps. Below, we provide the details of encoding a single task:\nTable Selectivity (Feature ğ´).This captures the selectivity of\ntables involved in the task. Following the approach in [ 51], we\nuse traditional cardinality estimators to compute these selectivities.\nThese estimators add minimal overhead to the inference time of the\nlearned model while providing valuable information. If there are ğ‘›\ntables in a workload, then we represent this feature with a numerical\nvector of length ğ‘›, where each entry contains a normalized value\nbetween 0 and 1 (i.e., table selectivity divided by table size) if the\ntask involves the corresponding table, and 0 otherwise.\nOperator Mapping (Feature ğµ).This encodes the join and scan\nproperties associated with the task. To generate it, we perform a\nbottom-up traversal of the sub-tree corresponding to the task and\nrecord the count of each type of join operator (hash join (HJ), merge\njoin (MJ), and nested-loop (NL) join) and scan operator (sequential\nscan (SS) and index scan (IS)) encountered. If there are ğ‘›tables in a\nworkload, then we represent this feature with a numerical vector of\nlength 3+2ğ‘›, where the first three entries correspond to the counts\nof the join types, and the remaining entries represent the counts of\nscan types for each table.\nPreorder Index (Feature ğ¶).This encodes the tree structure of\nthe sub-tree associated with the task in a numerical vector. Similar\nto [40,68], we generate this vector using a pre-order traversal of\nthe sub-tree, where each entry represents the index of a node in the\noriginal query plan to which the task belongs. For nodes with no\nchildren, the corresponding child entries in the vector are set to 0.\nQuery Feature (Feature ğ·).This captures whether the SQL query\nassociated with the task possesses any of the following four proper-\nties: (1) contains a sub-query, (2) includes an aggregation function,\n(3) contains a GROUP BY clause, or (4) contains an ORDER BY\nclause. It is represented as a binary 0-1 vector of length 4.\nExample. Figure 5 depicts the encoding of the three break-operator-\nbased tasks in Figure 4 (we omitted the encoding details of Tree 1\nto avoid cluttered visualization). The upper left part shows the SQL\nquery corresponding to the decomposed plan. Features ğ´andğ·are\ndefined at the query-level and then used with all tasks. In contrast,\nfeaturesğµandğ¶are task-specific, with ğµğ‘–andğ¶ğ‘–representing the\nfeatures for the task associated with Tree ğ‘–(ğ‘–âˆˆ{2,3,4}). Addi-\ntionally, we detail the process of generating Feature ğµfor Tree 3,\ndemonstrating a bottom-up traversal that incrementally counts the\njoin and scan operators encountered.\nA. Table Selectivity\nB. Operator Mapping\nC. Preorder IndexNLHJ\nIS (T2)IS (T3)\nSS (T1)\n0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 00 1 0 1 0 0 1 0 0 0 0 0 01 1 0 1 0 0 1 0 1 0 0 0 0\n0 0 0 0 0 0 0 0 1 0 0 0 0\nT1 T2 T3 T4 T51\n2 3\n4 5\nUseHJ UseNL UseMJ T1SS T1IS T2SS T2IS T3SS T3IS T4IS T4SS T5IS T5SS\n[  2,      2,     0 ,    1 ,  0,    0,   1,    0,   1,   0,    1,   1,   0 ]B2\nD. Query Featuresub-query? aggregation? GROUP BY? ORDER BY?[  1,      1,     0 ,    1 ,  0,    0,   1,    0,   1,   0,    0,   0,   0 ] \n[  1,      0,     0 ,    0 ,  0,    0,   0,    0,   0,   0,    1,   1,   0 ]B3\nB4Tree 3SELECT  COUNT(T1.name) \nFROM  T1, T2, T3, T4,T5\nWHERE  \n T1.id = T2.id AND\n T1.id = T3.id AND \n T2.id = T4.id AND \n T4.id = T5.id\nGROUP BY  T1.name\nSQL Query\nFigure 5: Encoding for the tasks represented with trees 2, 3,\nand 4 in Figure 4.\n6MODULES MAINTENANCE AND SELECTION\nIdentifying the appropriate neural network modules for the decom-\nposed tasks is a critical step in constructing an accurate LCP. A\nstraightforward approach is to treat each unique combination or\nsequence of operators in a query plan as an independent task and\nassign a dedicated neural network module to it in the module hub.\nFor example, a task that involves SS followed by NL would require\na different module from a task that involves SS followed by \"in-\ndexed\" NL. Similarly, a task executing HJ before NL would require\na distinct module from the one executing them in reverse order.\nHowever, this approach is impractical, as it would lead to an explo-\nsion in the number of modules, significantly increasing storage and\nsearch overhead while limiting the benefits of modularization by\nover-specializing each module to a highly specific task. To address\nthis, our idea is to maintain a representative module for each group\nofsimilar enough tasks using a clustering algorithm. These repre-\nsentative modules serve as a carrier of knowledge, which is the\nprerequisite for solving Challenge 2 . All representative modules\nbuilt for an LQO integrated with LIMAO share the same neural\nnetwork architecture, inherited from the base LCP model used by\nthis LQO (e.g., the Tree-CNN architecture in Balsa [ 68]). However,\nthey differ in their parameters, which are specialized through train-\ning on their respective tasks (i.e., sub-plans). These parameters are\nthen dynamically adapted as tasks evolve over time, resulting in a\nbalance between accuracy and efficiency.\nBuilding Each Module Hub as a Cluster. We adopt a variation of\ntheğ¾-prototype algorithm [ 26] to maintain ğ¾representative neural\nnetwork modules for each type of task decomposed using a specific\nbreak operator type (i.e., a set of ğ¾representatives for NL-rooted\ntasks, and another set of ğ¾representatives for HJ-rooted tasks, etc).\nWe choose the ğ¾-prototype algorithm for two key reasons. First, it\nis an extension of ğ¾-means designed to handle mixed data types\n(numerical and categorical features), which is compatible with our\nnumerical and categorical task encodings (Section 5). Second, it is\ncomputationally efficient, making it practical for maintaining and\nupdating module clusters dynamically over time. Our algorithm for\nconstructing clusters for each module hub operates in four steps\nduring the training phase of any LQO. First, initialize ğ¾module\nrepresentatives (i.e., centroids) with random values for Feature ğ´\n5\n\nas the numerical feature, and Features ğµ,ğ¶,ğ·as categorical ones,\nbased on the training set queries. Second, for each task ğ‘¥ğ‘–decom-\nposed from the training examples, assign it to the cluster with the\nsmallest dissimilarity value, calculated according to this formula:\nğ‘‘=âˆ‘ï¸\nğ‘—âˆˆ{A}disnum(ğ‘¥ğ‘– ğ‘—,ğ‘ğ‘˜ ğ‘—)+ğ›¾âˆ‘ï¸\nğ‘—âˆˆ{B, C, D}discat(ğ‘¥ğ‘– ğ‘—,ğ‘ğ‘˜ ğ‘—)(1)\nwhereğ‘¥ğ‘– ğ‘—is a feature vector (numerical or categorical), and\nğ‘ğ‘˜is the representative for cluster ğ‘˜âˆˆ{1,...,ğ¾},ğ›¾is a weight-\ning factor to balance the influence of numerical and categorical\nfeatures, and disnumanddiscatarevector-wise numerical (e.g., Eu-\nclidean distance) and categorical (e.g., mismatch count) dissimilarity\nfunctions, respectively. Third, for each cluster representative ğ‘ğ‘˜,\nupdate its numerical ğ‘num\nğ‘˜ ğ‘—and categorical ğ‘cat\nğ‘˜ ğ‘—features using the\nnumerical mean ğ‘num\nğ‘˜ ğ‘—=1\n|ğ‘†ğ‘˜|Ã\nğ‘¥ğ‘–âˆˆğ‘†ğ‘˜ğ‘¥ğ‘– ğ‘—and most frequent value\nğ‘cat\nğ‘˜ ğ‘—=arg max ğ‘£Ã\nğ‘¥ğ‘–âˆˆğ‘†ğ‘˜1(ğ‘¥ğ‘– ğ‘—=ğ‘£)functions, respectively, where ğ‘†ğ‘˜\nis the set of tasks assigned to the cluster. Fourth, repeat the second\nand third steps until convergence; either no change in task assign-\nments occurs or the maximum number of iterations is reached.\nSelecting Modules and Updating Hubs. During the testing phase,\nwe simply use Equation 1 to determine the appropriate representa-\ntive cluster for any incoming task that minimizes the dissimilarity\nvalue and then retrieve its corresponding neural network module. If\nthe dissimilarity of a task to all clusters exceeds a predefined thresh-\nold, the Task Modules Maintainer creates a new cluster with that\ntask as its representative. Moreover, the modules maintainer peri-\nodically checks cluster sizes and removes any clusters that contain\nfewer tasks than a specified minimum.\n7 MODULAR PLAN COST PREDICTION\nOur primary objective in LIMAO is to enable LQOs to construct a\ncustomized LCP neural network policy for each query by selecting\nand combining modules from several shared module hubs, thereby\npromoting knowledge reuse to address Challenge 2 . To achieve\nthis, we propose to use neural composition techniques (e.g.,[ 2,19])\nto assemble a complete LCP neural network from the selected\nmodules to handle the query. Neural composition has been exten-\nsively applied to build modular architectures in supervised learning\n(e.g.,[ 2,55]) and reinforcement learning (e.g.,[ 19,67]) and has re-\ncently been adapted for functional compositional problems [ 13,44].\nAttention-based Neural Composition. A large class of existing\nneural composition methods assumes a linear dependency struc-\nture between decomposed tasks (i.e., a chaining or graph structure),\nwhich is common in robotic tasks [ 4,44] (e.g., a pick-and-place\nrobotic task is decomposed into sequential steps such as \"grasp,\"\nfollowed by \"lift,\" and then \"place\"). This chaining structure, how-\never, creates brittle dependencies among modules, where changes\nto one module can have cascading effects on others. Moreover, this\nassumption does not align well with our break-operator-based de-\ncomposition, which can produce non-temporally related tasks. For\ninstance, a multi-table join query may be decomposed into two\nparallel HJ tasks, as shown in Figure 4. Although parallel neural\ncomposition approaches [ 3,54] seem well-suited for such scenarios,\nthey often fail to capture the inherent inter-dependencies between\nquery tasks, particularly as the outputs of these tasks must becombined to produce a unified cost prediction for the entire query\nplan. Additionally, not all tasks contribute equally to the final cost\nprediction, which these methods typically overlook.\nTo address these limitations, we propose an attention-based vari-\nation of parallel neural composition. This variation facilitates the\ncomposition of cost prediction tasks by leveraging attention mech-\nanisms [ 8,12,22] to capture task relationships and adjust their\ncontributions accordingly. The core idea is to assign importance\nto the outputs of different modules using attention weights, dy-\nnamically adjusting their contributions based on their potential\nimpact on the final predicted cost. Attention mechanisms have\nalready demonstrated their effectiveness in other database appli-\ncations [ 35,57], and we extend their utility to our cost prediction\nframework. Formally, assume that there are ğ‘˜modules with impor-\ntanceğ‘¤1,Â·Â·Â·,ğ‘¤ğ‘˜, then the assigned weight ğ‘¤â€²\nğ‘–forğ‘¤ğ‘–,ğ‘–âˆˆ[1,ğ‘˜]is\nin a softmax weighting form: ğ‘¤â€²\nğ‘–=exp(ğ‘¤ğ‘–)/Ãğ‘˜\nğ‘—=1exp(ğ‘¤ğ‘—).\nFurthermore, we train the combination of modules correspond-\ning to one query plan as a whole unit. In this way, the modules are\nnot only trained on their tasks but also learn to collaborate with\nother modules under different combinatorial setups.\nNetwork Architecture. Figure 6 shows the neural network ar-\nchitecture of our LCP. After a plan is decomposed into ğ¾tasks\nand their corresponding modules are retrieved (see Section 6), the\ntable selectivity encoding (i.e., Feature ğ´) is passed through a se-\nries of fully-connected layers, each progressively reducing in size.\nThe output of the third fully connected layer is then concatenated\nwith the operator mapping encoding (Feature ğµ) of each decom-\nposed task, resulting in a new vector representation ğ‘ƒfor each\ntask. Next, using the pre-order index encoding (Feature ğ¶), the tree\nrepresentation of encodings is reconstructed for each task. Each\nnode in this tree corresponds to the previously concatenated vec-\ntors from Features ğ´andğµ, resulting in 1Ã—ğ‘“â€²dimension. This\ntree representation is then processed by its corresponding mod-\nule to generate a module-specific plan representation ğ‘¤ğ‘–for each\ntask (e.g., Tree-CNN-based [ 39,51,73] or Tree-LSTM-based [ 9,72]\nplan representation). Afterward, the attention merger is applied to\nthese module-specific plan representations. It dynamically assigns\nweights to each representation and combines them to send to the\noutput MLP layers, producing the final cost estimation of the plan.\n8LIMAO TRAINING\nLIMAO introduces a novel training mechanism that follows the\nlifelong learning paradigm, incorporating experience buffers and\nepisodic updates to improve the quality of LCP and reduce training\ncosts. The training mechanism effectively addresses Challenge 3\nby: 1) taking advantage of reusable modules to eliminate the time\nneeded for retraining from scratch when query or data pattern\ndrifts; 2) using experience replay to quickly reclaim previous knowl-\nedge; and 3) dividing training queries within each iteration into\nsubsets of episodes and performing rapid lightweight model train-\ning after each episode2In such a way, LIMAO generates better\nplans in shorter learning periods while effectively avoiding bad\nplans and stabilizing plan quality. We have two main phases: an\n2Note that, in LIMAO , training iterations and their corresponding episodes use different\nsets of queries, unlike existing LQOs (e.g.,[ 39,68]), which fix the same set of queries\nacross all training iterations.\n6\n\nCkModules\nOutput MLP Layers\nInput MLP Layers1 x n1 x 1281 x 641 x 321 x 1Module 1\nModule kP1 concat.Attention Merger\nP2\nPkC1\nC2 B2Atrans1 x f'\n1 x f'1 x f'\n1 x f'1 x f'\n1 x f'\n1 x f'1 x f'\n1 x f'1 x f'1 x f'\n1 x f'1 x f'\n1 x f'1 x f'1 x f'\n1 x f'\n1 x f'1 x f'\n1 x f'\n1 x f'1 x f'\n1 x f'1 x f'\n1 x 1281 x 641 x 32Tree Representation\nFeature A\nconcat.\nconcat.\nFeature C Feature B1 x f'\n1 x f'1 x f'\n1 x f'1 x f'1 x f'w1\nw2\nwkCost EstimationTask 1\nTask 2\nTask kAtrans\nAtransBkB1\nModule 2Figure 6: Neural network architecture of modular LCP.\nAlgorithm 1 Training Mechanism in LIMAO\n1:ğ‘‡â†0;Bğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’â†[];Bğ‘ğ‘™ğ‘™â†[] âŠ²Initialization\n2:Mâ† Init(input & output MLP, Module Hubs )\n3:while ğ‘‡<iterations do\n4: ifğ‘‡>0then\n5:Mâ† DeepCopy(Mâ€²) âŠ²Offline updates\n6: ifDrift Detected then\n7:M.CompletelyTrainWith (Bğ‘ğ‘™ğ‘™)\n8: else\n9:M.CompletelyTrainWith (Bğ‘™ğ‘ğ‘ ğ‘¡)\n10:Mâ€²â†DeepCopy(M) ,Bğ‘™ğ‘ğ‘ ğ‘¡â†[]\n11: ğ‘’1. . . ğ‘’ ğ‘›â†iteration queries âŠ²Split queries into episodes\n12: foreach episode ğ‘’ğ‘–do âŠ²Online exploration phase\n13: foreach query ğ‘ğ‘—âˆˆğ‘’ğ‘–do\n14: modulesIdsâ†ModuleSelector(ğ‘ğ‘—)\n15: feedbackâ†PredictAndExecute(Mâ€², ğ‘ğ‘—,modulesIds)\n16:Bğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’ .Add(feedback ,modulesIds)\n17:Mâ€².LightlyTrainWith(E)\n18:Bğ‘™ğ‘ğ‘ ğ‘¡.Add(Bğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’)and ResetBğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’\n19:Bğ‘ğ‘™ğ‘™.Add(Bğ‘™ğ‘ğ‘ ğ‘¡)\n20: Evaluate(M,testSet) âŠ²Evaluation\n21: ğ‘‡â†ğ‘‡+1\nonline phase where we episodically update a copy of the LCP model\nand populate the experience buffer, and an offline phase where we\nupdate the original LCP model and perform experience replay. The\ndetails of our method (Algorithm 1) are as follows:\nInitialization. TheExperience Manager maintains an episode buffer\nBğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’ that is refreshed per training episode, and an experience\nbufferBğ‘ğ‘™ğ‘™that contains experience from every iteration (line 1).\nThe experience from the previous iteration is defined as Bğ‘™ğ‘ğ‘ ğ‘¡. We\ncreate the LCP model Mby initializing the neural networkâ€™s MLP\ninput and output layers with random parameters, as well as all\nthe modules in Module Hubs and Attention Merger (line 2). To\navoid catastrophic damage to the model Mwhile (re-)training it,\nwe maintain a copy Mâ€²that is updated frequently in our episodic\nsetup, whereasMis updated once per iteration (Details are below).\nOnline Phase. An under-trained LCP model, particularly in early\niterations, could lead to a sequence of inefficient plans due to infre-\nquent model updates. To avoid this, we introduce an episode-based\nparadigm that updates the LCP model more frequently to stabilize\nperformance. In each episode, the current LCP model is used to pre-\ndict query plans for the episodeâ€™s queries, which are then executed.\nThe resulting runtime feedback, along with the corresponding mod-\nule combinations, is stored in the episode buffer Bepisode (lines\n14â€“16). At the end of the episode, Mâ€²is quickly trained based on\nthe buffer, with only a few epochs of neural network updates (line17). This lightweight training process introduces minimal latency to\nthe online exploration phase, typically completes in a few seconds,\nwhile avoiding damage to the model M.\nOffline Phase. In this phase, we perform comprehensive training\non the modelMto ensure it remains up-to-date in dynamic en-\nvironments (lines 5-9). We start by replacing Mwith the model\ncopyMâ€²which was episodically trained in the previous iteration.\nFollowing this,Mis retrained using an experience replay buffer,\ndetermined by whether a drift is detected or not. If a drift in query\npatterns or data distribution is identified [ 1,5,17,25,34,37], then\nMis retrained using the experience buffer Bğ‘ğ‘™ğ‘™, which contains\nexperiences from all prior iterations, allowing the model to retain\nhistorical knowledge while integrating new patterns. If no drift is\ndetected, thenMonly requires light adaptation. In this case, we\nlimit the retraining of Mto the most recent experiences stored in\nBğ‘™ğ‘ğ‘ ğ‘¡(lines 6-9) only to reduce overhead and prevent overfitting.\nNote that, regardless of whether retraining uses Bğ‘ğ‘™ğ‘™orBğ‘™ğ‘ğ‘ ğ‘¡,M\nconverges quickly, as it is initialized from Mâ€², which has already\nbeen lightly exposed to recent workload and data shifts.\n9 EXPERIMENTAL EVALUATION\nHere, we conduct experiments to answer some key questions: Can\nLIMAO help generate better plans in dynamic environments (Sec-\ntion 9.2.1)? How does LIMAO training paradigm prevent cata-\nstrophic forgetting (Section 9.2.2)? How do the design components\nofLIMAO contribute to its performance (Section 9.3.3)? How effec-\ntively can LIMAO avoid bad plans (Section 9.3.4)?\n9.1 Experiment Setup\nBenchmarks. We perform our evaluation using TPC-H [ 6] and\nIMDB-based [ 33] benchmarks. For IMDB, we evaluate on the JOB [ 33]\nand CEB [ 51] query sets, as well as a set of queries from [ 39], which\nwe refer to as BaoQs. We construct six benchmarks for IMDB and\nthree benchmarks for TPC-H, where we randomly split each bench-\nmark into training and test sets, as shown in Table 1. The first three\nIMDB workloads consist of distinct query templates, while the last\nthree reuse the same templates as the first three but apply different\nfiltering conditions to create different queries.\n7\n\nTable 1: Evaluation workloads and their templates.\nWorkload training test Template\nIMDB_set1 94 18 Most from JOB, 2 from BaoQs\nIMDB_set2 71 14 Most from BaoQs, 3 from JOB\nIMDB_set3 30 5 Most from CEB, 3 from JOB\nIMDB_set4 94 18 Most from JOB, 2 from BaoQs\nIMDB_set5 14 5 Most from CEB, 3 from JOB\nIMDB_set6 14 5 Most from CEB, 3 from JOB\nTPC-H_set1 34 6 TPC-H template 3, 8, 10, 13\nTPC-H_set2 34 6 TPC-H template 5, 7, 12, 14\nTPC-H_set3 40 12 Other TPC-H template except 15\nStatic and Dynamic Environments. We conducted experiments\nunder four different environments: Static ,Workload Switch ,Vol-\nume Switch , and Both Switch . For Workload Switch , the experi-\nment iteratively switches between multiple query sets. We refer to\nthe collection of these query sets as a combined workload . For Volume\nSwitch , the experiment iteratively switches between two databases\nwith different data volumes. For the IMDB dataset, this involves\nswitching between the full database and a subset containing only\ndata from the year 2000 onward. For TPC-H, we switch between\ndatabases with scale factors of 10 and 1. The Both Switch scenario\ncombines changes in both query patterns and data volume simul-\ntaneously. Unless otherwise specified, dynamic scenarios involve\nperiodic switching every 5 iterations over a total of 100 iterations,\nresulting in 50 combined iterations to evaluate for each switch side.\nFor example, in Workload Switch , IMDB_set1 is used for iterations\n1â€“5, IMDB_set2 for iterations 6â€“10, then back to IMDB_set1 for\niterations 11â€“15, and so on. We analyze the performance of LIMAO\nunder non-periodic switching in Section 9.2.3 and 9.2.4.\nWe compare LIMAO to the following LQOs and Postgres:\nBaselines: We evaluate the performance of LIMAO against three\nbaselines: Balsa [69], an LQO that uses deep reinforcement learning\nto construct query plans step-by-step from scratch; Bao[39], an LQO\nthat employs a multi-armed bandit model to steer the traditional\noptimizer toward more efficient plans via ranked hint sets, without\nfully replacing it; and Postgres [52], the traditional rule-based and\ncost-based optimizer (Version 12.5). We integrated LIMAO with\nboth Balsa and Bao, denoted as LIMAO-Balsa andLIMAO-Bao ,\nrespectively. We also extended Balsaâ€™s source code to support non-\nequality joins and multiple join conditions between two tables,\nand applied these improvements to both Balsa and LIMAO-Balsa .\nOur experimental evaluation primarily uses LIMAO-Balsa to assess\nLIMAO , while LIMAO-Bao is used to explore the performance under\nnon-periodic and cross-schema switching situations in Section 9.2.3\nand Section 9.2.4, respectively.\nPerformance Metrics. We evaluate performance using several key\nmetrics, including query execution time , the number of bad query\nplans , and execution stability . Execution stability is used to quantify\nthe degree of catastrophic forgetting and is measured using two\nindicators: the variance and the derivative of the total workload\nexecution time across iterations. Variance captures fluctuations in\nexecution time, while the derivative is computed from a smoothed\ncurve of execution time to reflect the rate of change over time.\nBetter stability implies better handling of catastrophic forgetting.Default Settings. Unless otherwise specified, we adopt the follow-\ning default configurations. To construct the Module Hubs inLIMAO ,\nwe select HJ and NL as break operators for the IMDB benchmark,\nwith module hub sizes (i.e., ğ¾representative modules) of 2 and 3\nrespectively. For the TPC-H benchmark, we use HJ and MJ as break\noperators, each with a module hub size of 1. The sizes of Module\nHubs are determined by the complexity of the workload and the\noccurrence frequency of the corresponding operator types. In both\nbenchmarks, we include an additional module hub, referred to as\nOTH, which stores modules corresponding to sub-plans not rooted\nat a break operator (e.g., Tree 1 in Figure 4). For training LIMAO ,\nwe divide the queries in each training iteration into episodes of 10\nqueries. In both the Bao and LIMAO-Bao implementations, we use\n49 hint sets and train using the most recent 500 execution records.\nMachine Settings. Unless otherwise specified, experiments are\nconducted on CloudLab [ 53], using c240g5 which is equipped with\ndual Intel Xeon Silver 4114 CPUs (2.20 GHz, 20 cores total), 192 GB\nDDR4 RAM, a 480 GB SATA SSD, and NVIDIA P100 GPU.\n9.2 End-to-End Experimental Results\nIn this section, we evaluate the performance of LIMAO across\nfour dynamic scenarios. Section 9.2.1 presents the performance\nofLIMAO-Balsa under a basic Workload Switch scenario, where\ntwo workloads are alternated periodically. In this setting, LIMAO-\nBalsa performs comparably to Balsa and shows advantages in cer-\ntain cases only. Therefore, in Section 9.2.2 and Section 9.2.3, we\ndevise more complex Workload Switch scenarios which involve\nperiodic switching among three workloads and the other using a\nnon-periodic switch pattern. In Section 9.2.4, we shift to LIMAO-\nBaoto evaluate performance under a non-periodic, cross-schema\nswitching scenario involving five different workloads. Given the\nstronger performance of LIMAO-Balsa , we further evaluate its be-\nhavior in Sections 9.2.5 to provide a deeper analysis of the benefits\nintroduced by integrating LIMAO into Balsa.\n9.2.1 Comparison with Balsa under a simple Workload Switch. In\na simple Workload Switch scenario, we evaluate the performance\nofLIMAO-Balsa and Balsa by alternating between IMDB_set1 and\nIMDB_set2 every 5 iterations over a total of 100 iterations. Table 2\nshows the speedup ratios of the best query plans generated by\nLIMAO-Balsa and Balsa in this setup. Both systems outperform\nPostgres by up to 2.4Ã—on IMDB queries. The performance gain in\nIMDB workloads is largely due to the ability of LQOs like Balsa\nandLIMAO-Balsa , which generate plans from scratch, to better\nhandle complex join conditions commonly found in these queries.\nIn IMDB_set1, LIMAO further enhances performance by decom-\nposing complex queries into simpler sub-queries and effectively\npreserving historical knowledge from the workload, giving it an\nedge over Balsa. In IMDB_set2, the BaoQs workload is more com-\nplex than JOB, featuring more join operations and longer average\nquery execution time. Under such conditions, the limited number of\ntraining iterations and queries may not provide enough examples\nper module combination to train a fully effective model in LIMAO-\nBalsa , resulting in a slight performance degradation in IMDB_set2\ncompared to IMDB_set1.\n8\n\nIMDB_10a_ceb IMDB_13a_job IMDB_29c_job IMDB_14c_ceb IMDB_3c_ceb IMDB_26a_cebTPCH_3g TPCH_8e TPCH_10a TPCH_10d\nQueries05101520Execution Time (s)Performance Comparison Across Different Optimizers\nPostgres\nLIMAO-Balsa\nBalsaFigure 7: Sample execution time in simple Workload Switch .\nFor TPC-H, the performance advantage of LIMAO-Balsa and\nBalsa over Postgres is less obvious, particularly due to the rela-\ntively simple join conditions. This observation aligns with prior\nfindings [ 16,69,73], which show that LQOs typically offer limited\nimprovements over traditional query optimizers for the TPC-H\nbenchmark. Despite this, LIMAO-Balsa still achieves improved per-\nformance under the TPC-H_set1 and TPC-H_Combined workloads.\nThe lack of performance gains in TPC-H_set2 for both Balsa and\nLIMAO-Balsa can be attributed to operator selection behavior. In\nTPC-H_set1, using only HJ is generally sufficient to generate opti-\nmal plans. However, in TPC-H_set2 which includes templates such\nas 5, 7, 12, and 14, the use of NL would be more optimal. However,\nwhen Balsa becomes biased toward always selecting HJ during\ntraining, it fails to consider NL, which may be critical for optimal\nperformance in certain queries. This bias can result in performance\nthat is even worse than Postgres. Increasing the number of training\niterations could help mitigate this issue by enabling the model to\nlearn when using NL is beneficial.\nIn Figure 7, we provide further insights by analyzing several slow\nqueries: those with execution times exceeding a few seconds, drawn\nfrom different workloads to highlight where performance advan-\ntages emerge. Consistent with the results in Table 2, LIMAO-Balsa\ngenerally outperforms Balsa on IMDB queries. TPC-H templates 3,\n8, and 10 do not involve complex aggregation functions or nested\nstructures and contain complex join orders. In such cases, a build-\nfrom-scratch LQO like Balsa performs well. However, for TPC-H\nqueries with relatively simple join structures, the benefits of using\nBalsa or LIMAO-Balsa over Postgres are minimal.\nTable 2: Execution speedup ratio of LIMAO-Balsa vs Balsa in\nsimple Workload Switch .\nWorkload LIMAO-Balsa Balsa Postgres\nIMDB_set1 2.44 1.96 1.00\nIMDB_set2 2.66 2.68 1.00\nIMDB_Combined 2.59 2.40 1.00\nTPC-H_set1 1.31 1.30 1.00\nTPC-H_set2 0.76 0.75 1.00\nTPC-H_Combined 1.11 1.10 1.00\n9.2.2 Challenging Periodic Workload Switch. Here, we move to a\nmore complex scenario, where we alternate between IMDB_set1,\n0 20 40 60 80 100 120\nIteration05000100001500020000Execution Time (seconds)Execution Time per Iteration\nIMDB_set1 - Balsa\nIMDB_set2 - Balsa\nIMDB_set3 - Balsa\nIMDB_set1 - LIMAO-Balsa\nIMDB_set2 - LIMAO-Balsa\nIMDB_set3 - LIMAO-BalsaFigure 8: Execution time throughout 120 iterations in the\nchallenging Workload Switch .\nIMDB_set2, and IMDB_set3 every 5 iterations, over a total of 120\niterations, and evaluate LIMAO-Balsa against Balsa. Table 3 shows\nthe overall speedup and the variance of plan execution times across\niterations. LIMAO-Balsa consistently outperforms Balsa in both\nmetrics, indicating that it produces faster and more stable query\nplans. Specifically, LIMAO-Balsa requires as little as 30% of Post-\ngresâ€™s execution time and 60% of Balsaâ€™s, while achieving up to 8.8 Ã—\ngreater stability compared to Balsa. As the environment becomes\nincreasingly dynamic, the stability of LIMAO-Balsa becomes more\nprominent, thanks to its episode-based training mechanism, which\npromptly trains the model to prevent generations of bad plans.\nTable 3: Speedup ratio and variance of execution time of\nLIMAO-Balsa vs Balsa in challenging Workload Switch .\nMetric LIMAO-Balsa Balsa Postgres\nIMDB_set1 Speedup 2.49 1.53 1.00\nIMDB_set2 Speedup 4.08 2.92 1.00\nIMDB_set3 Speedup 1.53 1.31 1.00\nCombined Speedup 2.90 2.07 1.00\nIMDB_set1 Variance 4.73Ã—1054.20Ã—106NA\nIMDB_set2 Variance 1.18Ã—1061.05Ã—107NA\nIMDB_set3 Variance 5.21Ã—1052.29Ã—106NA\nFigure 8 visually depicts the execution time of Balsa and LIMAO-\nBalsa , summed across all training and testing queries within each it-\neration, with different line segments indicating the active workload\nat each point. LIMAO-Balsa exhibits significantly greater stability\nand shows steady performance improvements over time. In contrast,\nBalsaâ€™s performance curve is highly erratic, with frequent spikes\nthat correspond to instances of catastrophic forgetting, where the\nmodel generates poor plans upon switching back to a previously\nseen workload. This figure highlights LIMAO-Balsa â€™s ability to effec-\ntively mitigate catastrophic forgetting, demonstrating its robustness\nand practical viability for real-world dynamic environments.\n9.2.3 Challenging Non-periodic Workload Switch. In this experi-\nment, we use all six IMDB workloads, with workloads switching\nrandomly: each executed for 2 to 8 consecutive iterations. To ensure\nreproducibility, we use fixed random seeds. The total number of iter-\nations is set to 100. As shown in Figure 9, Balsa requires 405 seconds\nto complete all workloads optimally, while LIMAO-Balsa achieves\nthe same in just 307 seconds. Balsa encounters 464 timeouts (de-\nfined as queries exceeding 60 seconds in execution time), compared\n9\n\nto only 219 timeouts with LIMAO-Balsa . These results demonstrate\nthatLIMAO significantly improves Balsaâ€™s performance in highly\nunpredictable, non-periodic environments.\nTable 4: Speedup ratio of LIMAO-Bao vs Bao in non-periodic\nWorkload Switch forLIMAO-Bao experiment.\nWorkload LIMAO-Bao Bao Postgres\nIMDB_set1 1.17 1.17 1.00\nIMDB_set2 1.48 1.25 1.00\nIMDB_Combined 1.34 1.22 1.00\nTPC-H_set1 1.98 2.04 1.00\nTPC-H_set2 3.20 3.20 1.00\nTPC-H_set3 1.97 1.58 1.00\nTPC-H_Combined 2.15 1.91 1.00\nAll 5 Workloads 1.85 1.66 1.00\n0 100 200 300 400 500 600\nTime (s)PostgresBalsaLIMAO-BalsaT otal Workload Runtimes\nWorkloads\nIMDB_set1\nIMDB_set2\nIMDB_set3\nIMDB_set4\nIMDB_set5\nIMDB_set6\nFigure 9: Total optimal execution time of different workloads\nin non-periodic cross-schema Workload Switch .\n9.2.4 Non-periodic Workload Switch with Schema Changes. In this\nsection, we evaluate LIMAO-Bao under a non-periodic Workload\nSwitch scenario involving schema changes. We randomly switch\nbetween five workloads: IMDB_set1, IMDB_set2, TPC-H_set1, TPC-\nH_set2, and TPC-H_set3, where each workload is executed consecu-\ntively for 2 to 10 iterations. Table 4 reports the speedup ratios of Bao\nandLIMAO-Bao under this dynamic setting. Overall, LIMAO-Bao\nshows either promising improvements or performance comparable\nto Bao across most workloads. LIMAO-Bao achieves an average\nspeedup of 1.85 Ã—over Postgres, compared to 1.66 Ã—achieved by Bao.\nBoth Bao and LIMAO-Bao perform particularly well on the TPC-H\nbenchmarks, which can be attributed to Baoâ€™s hint-based design\nthat is especially effective for handling simpler, join-naive queries.\n9.2.5 Performance of LIMAO-Balsa and Balsa in All Situations. Fig-\nure 10 presents the execution time of static workloads and three\ntypes of dynamic switching scenarios across iterations, highlight-\ning the overall performance stability of LIMAO-Balsa and Balsa.\nWhile both achieve comparable overall performance, LIMAO-Balsa\ndemonstrates a significantly more stable execution pattern, whereas\nBalsa suffers from noticeable fluctuations.\nIn the Static setting (Figures 10a and 10b), LIMAO-Balsa performs\ncomparably to Balsa, but with consistently lower execution time in\nmost iterations. Notably, in the TPC-H Static scenario, LIMAO-Balsa\nexhibits much lower execution time at the beginning, whereas Balsaproduces a continuous segment of poorly performing plans. This\ntrend indicates that LIMAO-Balsa â€™s episodic training mechanism\nhelps prevent the repeated generation of suboptimal plans, even\nin static environments. In the Both Switch scenarios (Figures 10g\nand 10h), Balsaâ€™s performance is highly unstable, especially in the\nIMDB environment, where performance even deteriorates over time.\nIn contrast, LIMAO-Balsa maintains low execution latency and\nstable performance across all iterations. These results demonstrate\nthat LIMAO-Balsa is more robust than Balsa across both static\nand dynamic scenarios. This improvement can be attributed to the\nlifelong LCP, which stabilizes the training process and reduces the\noccurrence of performance spikesâ€”an issue commonly observed in\nconventional reinforcement learning approaches.\n9.3 Micro Benchmarks\n9.3.1 Performance Stability. During training iterations, LIMAO-\nBalsa demonstrates notable performance stability. In this experi-\nment, we collect the total execution time at each iteration, smooth\nthe resulting time series into a continuous curve, and compute its\nderivative to assess stability. Figure 11 shows the derivatives of the\nfitted curves for both Balsa and LIMAO-Balsa . In dynamic envi-\nronments, Balsa exhibits substantial instability, as reflected by its\nlarge and highly variable derivative values. Such instability often\nresults in severe performance degradation, as discussed in detail\nin Section 9.3.4. Moreover, consistently lower derivative values\nsuggest that a model is converging, as the differences in execution\ntime between consecutive iterations become minimal. For instance,\nin the IMDB Workload Switch scenario, LIMAO-Balsa â€™s derivative\nvalues remain below 1500 after 30 iterations, compared to 11,000\nfor Balsa. Similarly, in the TPC-H Both Switch scenario, LIMAO-\nBalsa â€™s values stay below 1000 after 20 iterations, whereas Balsaâ€™s\nrise to 4400. These observations indicate that LIMAO-Balsa likely\nconverges significantly faster, potentially requiring only slightly\nmore than half the number of iterations compared to Balsa. Table 5\nfurther supports this observation by presenting the variance in exe-\ncution time across different scenarios. In every case, LIMAO-Balsa\nexhibits lower variance than Balsa, often by orders of magnitude.\nNotably, in the IMDB Both Switch scenario, LIMAO-Balsa achieves\n22Ã—greater stability than Balsa. These results highlight that LIMAO\nsubstantially improves Balsaâ€™s robustness particularly when both\nquery workloads and data distributions shift.\nTable 5: Variances for Balsa and LIMAO-Balsa . The results\nare based on each iterationâ€™s combined execution time.\nWorkload pattern LIMAO-Balsa Balsa\nIMDB Both Switch 1.77Ã—1064.00Ã—107\nIMDB Workload Switch 2.23Ã—1066.96Ã—106\nIMDB Volume Switch 9.43Ã—1044.32Ã—105\nTPC-H Both Switch 1.10Ã—1068.30Ã—106\nTPC-H Workload Switch 3.93Ã—1067.70Ã—106\nTPC-H Volume Switch 1.44Ã—1051.88Ã—107\n9.3.2 Choice of Module Hubâ€™s Length. To evaluate the impact of\ndifferent Module Hub sizes, we test three settings on the IMDB\nworkload by varying the number of modules assigned to the HJ, NL,\n10\n\n0 20 40 60 80 100\nIteration5001000150020002500Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa(a) IMDB Static Workload .\n0 20 40 60 80 100\nIteration10002000300040005000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa (b) TPC-H Static Workload .\n0 20 40 60 80 100\nIteration1000200030004000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa (c) IMDB Volume Switch .\n0 20 40 60 80 100\nIteration0250050007500100001250015000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa (d) TPC-H Volume Switch .\n0 10 20 30 40 50\nIteration400060008000100001200014000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa\n(e) IMDB Workload Switch .\n0 10 20 30 40 50\nIteration2000400060008000100001200014000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa (f) TPC-H Workload Switch .\n0 10 20 30 40 50\nIteration50001000015000200002500030000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa (g) IMDB Both Switch .\n0 10 20 30 40 50\nIteration20004000600080001000012000Execution Time (seconds)\nExecution Time per Iteration for Balsa and LIMAO-Balsa\nLIMAO-Balsa\nBalsa (h) TPC-H Both Switch .\nFigure 10: Performance of Balsa and LIMAO-Balsa throughout iterations in all 8 types of dynamic environments.\n0 10 20 30 40 50\nIterationâˆ’5000âˆ’2500025005000750010000ValueDerivatives of Fitted Curves\nDerivative of Fitted LIMAO-Balsa\nDerivative of Fitted Balsa\n(a) IMDB Workload Switch .\n0 10 20 30 40 50\nIterationâˆ’5000âˆ’2500025005000750010000ValueDerivatives of Fitted Curves\nDerivative of Fitted LIMAO-Balsa\nDerivative of Fitted Balsa (b) TPC-H Workload Switch .\n0 10 20 30 40 50\nIterationâˆ’10000âˆ’50000500010000ValueDerivatives of Fitted Curves\nDerivative of Fitted LIMAO-Balsa\nDerivative of Fitted Balsa\n(c) IMDB Both Switch .\n0 10 20 30 40 50\nIterationâˆ’5000050001000015000ValueDerivatives of Fitted Curves\nDerivative of Fitted LIMAO-Balsa\nDerivative of Fitted Balsa (d) TPC-H Both Switch .\nFigure 11: Derivatives of execution time from each iteration.\nand OTH hubs. In setting S1, we assign 1 module each to HJ, NL,\nand OTH. In setting S2, we use 2 modules for HJ, 3 for NL, and 1 for\nOTH. In setting S3, we assign 3 modules to each of HJ, NL, and OTH.\nThese three settings are evaluated over 20 iterations in the IMDB\nWorkload Switch scenario to compare their minimum execution\ntime per iteration. The results for S1, S2, and S3 are 4067ğ‘ ,3652ğ‘ ,\nand4826ğ‘ , respectively (S2 has the best performance). This result\nhighlights how the choice of Module Hub size can significantly\ninfluence the performance of LIMAO . In the IMDB workload, NL\njoins tend to exhibit more complex behavior than HJ and OTH\noperators, so allocating more modules to NL tasks improves model\nperformance. However, assigning too many modules can lead to\nunderfitting, as the number of training tasks per module becomes\ninsufficient, ultimately degrading overall performance.\n9.3.3 Ablation Study. To evaluate the impact of different compo-\nnents in LIMAO , we conduct ablation studies in the IMDB Volume\nSwitch and TPC-H Workload Switch environments. For the IMDBworkload, we compare the following variations: (1) Balsa, (2) Balsa\n+ decomposition , (3)Balsa + decomposition + Module Hub , (4)Balsa\n+ decomposition + Modular RL training , and (5) the full LIMAO-\nBalsa . As described in Section 9.1, each Module Hub in the TPC-H\nworkload is limited to one module due to the simpler join patterns\ncharacteristic of TPC-H. Accordingly, we evaluate only three con-\nfigurations for TPC-H: Balsa, Balsa + decomposition , and Balsa +\ndecomposition + Modular RL training (i.e.,LIMAO-Balsa without the\nModule Hub component). Figure 12 shows the performance of Balsa\nand the various LIMAO-Balsa variants. As shown in Figures 12a\nand 12b, LIMAO-Balsa achieves the lowest cumulative execution\ntime in both IMDB and TPC-H workloads, demonstrating its ro-\nbustness and effectiveness in dynamic environments. In Figures 12c\nand 12d, we observe that while some variants occasionally dis-\ncover better individual query plans than Balsa and LIMAO-Balsa ,\nthey suffer from higher average execution times overall. This is\nprimarily because, without the use of a replay buffer, these variants\ntend to overfit to a narrow subset of queries. A specific module\ncombination may be trained on only a limited set of queries and\nthus fail to generalize when presented with new ones, resulting\nin performance collapse. Similarly, using decomposition alone can\nlead to overfitting and poor generalization. This issue is particularly\nevident in the variant combining tree decomposition with Mod-\nule Hubs. In contrast, LIMAO-Balsa achieves an optimal balance\nbetween short-term peak performance and long-term stability.\n9.3.4 Bad Performance Plans. A query plan is considered bad if\nits execution time exceeds 512 seconds. Table 6 reports the num-\nber of such timeouts across different scenarios for both Balsa and\nLIMAO-Balsa . Balsa experiences significantly more timeouts dur-\ning model training, while LIMAO-Balsa effectively avoids them.\nWhen LIMAO-Balsa encounters a bad plan, it is less likely to gen-\nerate a similar one in subsequent iterations, due to its episodic\ntraining mechanism that enables prompt model tuning. This en-\nhanced stability stems from the lifelong LCP training paradigm,\nwhich allows LIMAO-Balsa to quickly recognize the characteristics\nof poor-performing plans and adapt accordingly in future episodes.\n11\n\n0 20 40 60 80 100\nIteration020000400006000080000100000120000Accumulative Time (s)Time vs Combined Iteration for All the Queries\nBalsa + decomposition\nBalsa + decomposition + Modular RL train\nBalsa + decomposition + module hub\nLIMAO-Balsa\nBalsa(a) IMDB Volume Switch .\n0 10 20 30 40 50\nIteration050000100000150000200000Accumulative Time (s)Time vs Iteration for Workload1 and Workload2\nLIMAO_workload1\nBalsa + decomposition_workload1\nBalsa_workload1\nLIMAO_workload2\nBalsa + decomposition_workload2\nBalsa_workload2 (b) TPC-H Workload Switch .\nOriginal Avg Original Min After 2000 Avg After 2000 Min02004006008001000120014001600Time (s)\n762.84\n401.22\n554.58\n270.581570.54\n410.31\n912.09\n233.371282.32\n290.05\n834.38\n200.871391.10\n342.23\n751.79\n245.001086.05\n451.53\n539.12\n273.49Comparison of Original and Shrinked Database Values\nLIMAO-Balsa\nBalsa + decomposition\nBalsa + decomposition + module hub\nBalsa + decomposition + ModularRL\nBalsa\n(c) IMDB Average and MIN\nRunning Time.\nWorkload1 Avg Workload1 Min Workload2 Avg Workload2 Min05001000150020002500300035004000Time (s)\n1066.61\n663.46\n1969.23\n450.592192.63\n710.52\n3989.68\n479.062257.17\n1040.10\n4126.79\n933.97Comparison of Different Variants on Switching Workloads\nLIMAO-Balsa\nBalsa + decomposition\nBalsa(d) TPC-H Average and MIN\nRunning Time.\nFigure 12: Accumulated, average, and minimum execution\nperformance of LIMAO-Balsa variations.\nThis highlights the importance of training the model to identify\nand avoid bad plans as early as possible.\nTable 6: Number of time-outs in different situations.\nDatabase Environment Balsa LIMAO-Balsa\nIMDB Static Workload 54 5\nTPC-H Static Workload 127 0\nIMDB Workload Switch 1128 120\nTPC-H Workload Switch 230 26\nIMDB Volume Switch 67 2\nTPC-H Volume Switch 949 0\nIMDB Both Switch 605 120\nTPC-H Both Switch 322 98\n9.3.5 Extra Training Overhead. As discussed in Section 8, LIMAO\nintroduces additional training overhead due to experience buffer\nreplay and episodic updates. Although this adds cost per iteration,\nthe overall training time remains competitive due to faster conver-\ngence. With access to high-performance GPUs such as the NVIDIA\n4090 or A100, this additional overhead is further mitigated and\ndoes not hinder practical deployment. In our IMDB experiments,\nepisodic training in LIMAO-Balsa takes approximately 3 seconds\nper episode, with up to 10 episodes per iteration. The post-iteration\ntraining phase in both Balsa and LIMAO-Balsa (including buffer\nreplay) ranges between 4 and 9 seconds per iteration, depending\non the workload (e.g., JOB, CEB, BaoQs). While LIMAO-Balsa in-\ncurs slightly higher per-iteration training costs, it converges sig-\nnificantly faster, typically within 30 iterations (as shown in Fig-\nure 11)â€”resulting in a total training overhead of 160â€“310 seconds.\nIn contrast, Balsa often requires at least 50 iterations, leading to\na total overhead of 200â€“450 seconds. Thus, despite the added per-\niteration cost, LIMAO-Balsa achieves lower overall training time.\nFor simpler workloads like TPC-H, the training overhead becomes\nminimal for both systems.\n10 RELATED WORK\nLearned Query Optimizers (LQOs). Existing LQOs like Bao [ 39],\nLEON [ 10], and Lero [ 73], leverage neural networks to refine andenhance query plans generated by traditional optimizers. It mini-\nmally interferes with the underlying optimizer logic, reducing the\nrisk of generating bad plans. However, these LQOs remain capped\nwith the recommendations of traditional optimizers. On the other\nhand, LQOs like Balsa [ 69], Neo [ 41], and Lemo [ 48] control the\nplan generation process, allowing them to explore a broader range\nof execution strategies. While this leads to the discovery of superior\nplans, it also introduces greater variability and potential instability\nin performance. LIMAO can be integrated with both categories of\nLQOs and allow their LCPs to operate in a lifelong setup, improving\ntheir training stability, and ensuring more consistent performance\nacross varying workloads and data distributions.\nQuery Execution in Dynamic Environments. Bao [ 39] and\nHybridQO [ 72] evaluate their performance under dynamic work-\nloads, data, and schema by periodically introducing new query tem-\nplates, data updates, and schema normalization. Similarly, Lero [ 73],\nLEON [ 10], and ERASER [ 64] test their models by incrementally\nadding new data to the database. However, they provide limited\ninsights into the LQOsâ€™ performance stability, as the updates are\nneither extensive nor frequent enough to fully capture the complex-\nities of real-world, fluctuating environments. In contrast, LIMAO\nintroduces a comprehensive benchmarking framework for dynamic\nscenarios, simulating more intricate changes and showing how\nit can enhance performance stability. Meanwhile, recent research\nin learned cardinality estimation has addressed challenges related\nto workload drifts during query execution by partially masking\nquery information to promote generalization [ 51], utilizing rapid\nre-training with replay buffers [ 66], and applying attention mecha-\nnisms to capture relationships between queries and dynamic under-\nlying data [ 35]. Conversely, LIMAO takes a more holistic approach,\nfocusing on learned cost prediction for entire query plans.\n11 CONCLUSION AND FUTURE WORK\nIn this paper, we introduce LIMAO , the first modular lifelong learn-\ning framework for query optimization designed to handle signifi-\ncant and frequent shifts in workloads and data distributions. LIMAO\nprovides a lifelong learned plan cost predictor that can adapt over\ntime while retaining and leveraging previously acquired knowledge\nto ensure stable performance. LIMAO has several contributions,\nincluding a modular plan decomposition, an attention-based neural\ncomposition, and an efficient two-phase training approach. We inte-\ngrated LIMAO with two LQOs, and evaluated them with IMDB and\nTPC-H queries under dynamic situations. Our evaluation shows\nthatLIMAO can improve query speed up to 40%and the variance\nin running times of the same query by 60%for IMDB. For TPC-H,\nLIMAO achieves more than 2Ã—speedup and 100Ã—query stability\ngain. For future work, we plan to 1) integrate LIMAO with addi-\ntional LQOs, 2) automatically identify workload-customized break\noperators for query decomposition and sizes for module hubs, and\n3) explore knowledge transfer across different databases. In this\nstudy, we only focused on query optimization, a task with inherent\nmodularity that aligns well with the principles of lifelong modu-\nlar learning. However, we believe that our proposed framework\ncan be extended to other learned database tasks, such as knob\ntuning [ 32,61] and learned indexes [ 14,31], where modular repre-\nsentations and continual adaptation are also essential.\n12\n\nREFERENCES\n[1]Ahmad Abbasi, Abdul Rehman Javed, Chinmay Chakraborty, Jamel Nebhen,\nWisha Zehra, and Zunera Jalil. 2021. ElStream: An ensemble learning approach\nfor concept drift detection in dynamic social big data stream learning. IEEE\nAccess 9 (2021), 66408â€“66419.\n[2] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. 2016. Neural\nModule Networks. In 2016 IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR) . 39â€“48. https://doi.org/10.1109/CVPR.2016.12\n[3] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. 2016. Neural\nModule Networks. In 2016 IEEE Conference on Computer Vision and Pattern\nRecognition (CVPR) . 39â€“48. https://doi.org/10.1109/CVPR.2016.12\n[4] Pierre-Luc Bacon, Jean Harb, and Doina Precup. 2017. The option-critic architec-\nture. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence\n(San Francisco, California, USA) (AAAIâ€™17) . AAAI Press, 1726â€“1734.\n[5]Ishwar Baidari and Nagaraj Honnikoll. 2021. Bhattacharyya distance based\nconcept drift detection method for evolving data stream. Expert Systems with\nApplications 183 (2021), 115303.\n[6] TPC-H Benchmark. [n. d.]. http://www.tpc.org/tpch/.\n[7] Yoshua Bengio. 2012. Deep Learning of Representations for Unsupervised and\nTransfer Learning. In Proceedings of ICML Workshop on Unsupervised and Transfer\nLearning .\n[8]Gianni Brauwers and Flavius Frasincar. 2021. A general survey on attention\nmechanisms in deep learning. IEEE Transactions on Knowledge and Data Engi-\nneering 35, 4 (2021), 3279â€“3298.\n[9] Tianyi Chen, Jun Gao, Hedui Chen, and Yaofeng Tu. 2023. LOGER: A Learned\nOptimizer Towards Generating Efficient and Robust Query Execution Plans. Proc.\nVLDB Endow. 16, 7 (March 2023), 1777â€“1789. https://doi.org/10.14778/3587136.\n3587150\n[10] Xu Chen, Haitian Chen, Zibo Liang, Shuncheng Liu, Jinghong Wang, Kai Zeng,\nHan Su, and Kai Zheng. 2023. Leon: A new framework for ml-aided query\noptimization. Proceedings of the VLDB Endowment 16, 9 (2023), 2261â€“2273.\n[11] Xue Chen, Rui Xi, Yiheng Tang, and Mengshu Hou. 2023. Robust Listwise\nLearning-to-Rank Approach for Database Query Optimizer. In 2023 IEEE 29th\nInternational Conference on Parallel and Distributed Systems (ICPADS) . 1165â€“1172.\nhttps://doi.org/10.1109/ICPADS60453.2023.00170\n[12] Alana de Santana Correia and Esther Luna Colombini. 2022. Attention, please! A\nsurvey of neural attention models in deep learning. Artificial Intelligence Review\n55, 8 (2022), 6037â€“6124.\n[13] Coline Devin, Abhishek Gupta, Trevor Darrell, Pieter Abbeel, and Sergey Levine.\n2017. Learning modular neural network policies for multi-task and multi-robot\ntransfer. In 2017 IEEE International Conference on Robotics and Automation (ICRA) .\n2169â€“2176. https://doi.org/10.1109/ICRA.2017.7989250\n[14] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\net al.2020. ALEX: an updatable adaptive learned index. In Proceedings of the 2020\nACM SIGMOD international conference on management of data . 969â€“984.\n[15] L. Doshi et al .2023. Kepler: Robust Learning for Parametric Query Optimization.\nInSIGMOD .\n[16] Lyric Doshi, Vincent Zhuang, Gaurav Jain, Ryan Marcus, Haoyu Huang, Deniz\nAltinbÃ¼ken, Eugene Brevdo, and Campbell Fraser. 2023. Kepler: Robust Learning\nfor Parametric Query Optimization. Proc. ACM Manag. Data 1, 1, Article 109\n(May 2023), 25 pages. https://doi.org/10.1145/3588963\n[17] Quang-Huy Duong, Heri Ramampiaro, Kjetil NÃ¸rvÃ¥g, Philippe Fournier-Viger,\nand Thu-Lan Dam. 2018. High utility drift detection in quantitative data streams.\nKnowledge-Based Systems 157 (2018), 34â€“51.\n[18] Anshuman Dutt, Chi Wang, Vivek Narasayya, and Surajit Chaudhuri. 2020.\nEfficiently approximating selectivity functions using low overhead regression\nmodels. Proc. VLDB Endow. 13, 12 (July 2020), 2215â€“2228. https://doi.org/10.\n14778/3407790.3407820\n[19] Anirudh Goyal, Alex Lamb, Jordan Hoffmann, Shagun Sodhani, Sergey Levine,\nYoshua Bengio, and Bernhard SchÃ¶lkopf. 2021. Recurrent Independent Mech-\nanisms. In International Conference on Learning Representations . https://\nopenreview.net/forum?id=mLcmdlEUxy-\n[20] Goetz Graefe. 1995. The Cascades Framework for Query Optimization. IEEE\nData Eng. Bull. 18, 3 (1995), 19â€“29.\n[21] G. Graefe and W.J. McKenna. 1993. The Volcano optimizer generator: extensibility\nand efficient search. In Proceedings of IEEE 9th International Conference on Data\nEngineering . 209â€“218.\n[22] Meng-Hao Guo, Tian-Xing Xu, Jiang-Jiang Liu, Zheng-Ning Liu, Peng-Tao Jiang,\nTai-Jiang Mu, Song-Hai Zhang, Ralph R Martin, Ming-Ming Cheng, and Shi-Min\nHu. 2022. Attention mechanisms in computer vision: A survey. Computational\nvisual media 8, 3 (2022), 331â€“368.\n[23] Benjamin Hilprecht and Carsten Binnig. 2021. One model to rule them all:\ntowards zero-shot learning for databases. arXiv preprint arXiv:2105.00642 (2021).\n[24] Benjamin Hilprecht and Carsten Binnig. 2022. Zero-shot cost models for out-of-\nthe-box learned cost prediction. Proc. VLDB Endow. 15, 11 (July 2022), 2361â€“2374.\nhttps://doi.org/10.14778/3551793.3551799[25] Songqiao Hu, Zeyi Liu, and Xiao He. 2022. CADM: Confusion model-based\ndetection method for real-drift in chunk data stream. In International Conference\non Sensor Systems and Software . Springer, 191â€“201.\n[26] Z Huang. 1997. Clustering Large Data Sets With Mixed Numeric And Categorical\nValues,\" Proceedings Of 1st Pacific-Asia Conference on Knowledge Discouvery\nAnd Data Mining.\n[27] Ronald Kemker, Marc McClure, Angelina Abitino, Tyler L. Hayes, and Christo-\npher Kanan. 2018. Measuring catastrophic forgetting in neural networks. In\nProceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and\nThirtieth Innovative Applications of Artificial Intelligence Conference and Eighth\nAAAI Symposium on Educational Advances in Artificial Intelligence (New Orleans,\nLouisiana, USA) (AAAIâ€™18/IAAIâ€™18/EAAIâ€™18) . AAAI Press, Article 415, 9 pages.\n[28] Kyoungmin Kim, Jisung Jung, In Seo, Wook-Shin Han, Kangwoo Choi, and\nJaehyok Chong. 2022. Learned Cardinality Estimation: An In-depth Study. In\nProceedings of the 2022 International Conference on Management of Data (Philadel-\nphia, PA, USA) (SIGMOD â€™22) . Association for Computing Machinery, New York,\nNY, USA, 1214â€“1227. https://doi.org/10.1145/3514221.3526154\n[29] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and Alfons\nKemper. 2019. Learned Cardinalities: Estimating Correlated Joins with Deep\nLearning. In 9th Biennial Conference on Innovative Data Systems Research (CIDR\nâ€™19).\n[30] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume\nDesjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka\nGrabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and\nRaia Hadsell. 2017. Overcoming catastrophic forgetting in neural networks.\nProceedings of the National Academy of Sciences 114, 13 (2017), 3521â€“3526. https:\n//doi.org/10.1073/pnas.1611835114\n[31] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In Proceedings of the 2018 international\nconference on management of data . 489â€“504.\n[32] Jiale Lao, Yibo Wang, Yufei Li, Jianping Wang, Yunjia Zhang, Zhiyuan Cheng,\nWanghu Chen, Mingjie Tang, and Jianguo Wang. 2023. Gptuner: A manual-\nreading database tuning system via gpt-guided bayesian optimization. arXiv\npreprint arXiv:2311.03157 (2023).\n[33] Viktor Leis, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, and\nThomas Neumann. 2015. How good are query optimizers, really? Proceedings of\nthe VLDB Endowment 9, 3 (2015), 204â€“215.\n[34] Beibin Li, Yao Lu, and Srikanth Kandula. 2022. Warper: Efficiently adapting\nlearned cardinality estimators to data and workload drifts. In Proceedings of the\n2022 International Conference on Management of Data . 1920â€“1933.\n[35] Pengfei Li, Wenqing Wei, Rong Zhu, Bolin Ding, Jingren Zhou, and Hua Lu.\n2023. ALECE: An Attention-based Learned Cardinality Estimator for SPJ Queries\non Dynamic Workloads. Proceedings of the VLDB Endowment 17, 2 (Oct. 2023),\n197â€“210. https://doi.org/10.14778/3626292.3626302\n[36] Jorge Mendez Mendez: Embodied lifelong learning for decision making: Oppor-\ntunities brought on by modularity. [n. d.]. https://lis.csail.mit.edu/embodied-\nlifelong-learning-for-decision-making/.\n[37] Ankur Mallick, Kevin Hsieh, Behnaz Arzani, and Gauri Joshi. 2022. Matchmaker:\nData drift mitigation in machine learning for large-scale systems. Proceedings of\nMachine Learning and Systems 4 (2022), 77â€“94.\n[38] R. Marcus et al .2021. Bao: Making Learned Query Optimization Practical. In\nSIGMOD .\n[39] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Al-\nizadeh, and Tim Kraska. 2021. Bao: Making learned query optimization practical.\nInProceedings of the 2021 International Conference on Management of Data . 1275â€“\n1288.\n[40] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A Learned\nQuery Optimizer. Proc. VLDB Endow. 12, 11 (jul 2019), 1705â€“1718. https://doi.\norg/10.14778/3342263.3342644\n[41] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A learned\nquery optimizer. arXiv preprint arXiv:1904.03711 (2019).\n[42] Ryan Marcus and Olga Papaemmanouil. 2019. Plan-structured deep neural\nnetwork models for query performance prediction. Proc. VLDB Endow. 12, 11\n(July 2019), 1733â€“1746. https://doi.org/10.14778/3342263.3342646\n[43] Jorge A Mendez and ERIC EATON. 2023. How to Reuse and Compose Knowl-\nedge for a Lifetime of Tasks: A Survey on Continual Learning and Func-\ntional Composition. Transactions on Machine Learning Research (2023). https:\n//openreview.net/forum?id=VynY6Bk03b Survey Certification.\n[44] Jorge A Mendez, Harm van Seijen, and Eric Eaton. 2022. Modular lifelong\nreinforcement learning via neural composition. arXiv preprint arXiv:2207.00429\n(2022).\n[45] Jorge Mendez-Mendez, Leslie Pack Kaelbling, and TomÃ¡s Lozano-PÃ©rez. 2023.\nEmbodied Lifelong Learning for Task and Motion Planning. In Proceedings of\nThe 7th Conference on Robot Learning (Proceedings of Machine Learning Research,\nVol. 229) , Jie Tan, Marc Toussaint, and Kourosh Darvish (Eds.). PMLR, 2134â€“2150.\nhttps://proceedings.mlr.press/v229/mendez-mendez23a.html\n13\n\n[46] Yabin Meng, Paul Bird, Pat Martin, and Wendy Powley. 2007. An approach to\nmanaging the execution of large SQL queries. In Proceedings of the 2007 conference\nof the center for advanced studies on Collaborative research . 268â€“271.\n[47] Artem Mikhaylov, Nina S Mazyavkina, Mikhail Salnikov, Ilya Trofimov, Fu\nQiang, and Evgeny Burnaev. 2022. Learned Query Optimizers: Evaluation and\nImprovement. IEEE Access 10 (2022), 75205â€“75218.\n[48] Songsong Mo, Yile Chen, Hao Wang, Gao Cong, and Zhifeng Bao. 2023. Lemo:\nA Cache-Enhanced Learned Optimizer for Concurrent Queries. Proceedings of\nthe ACM on Management of Data 1, 4 (2023), 1â€“26.\n[49] Lili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. 2016. Convolutional neural\nnetworks over tree structures for programming language processing. In Proceed-\nings of the Thirtieth AAAI Conference on Artificial Intelligence (Phoenix, Arizona)\n(AAAIâ€™16) . AAAI Press, 1287â€“1293.\n[50] Parimarjan Negi, Ryan Marcus, Andreas Kipf, Hongzi Mao, Nesime Tatbul,\nTim Kraska, and Mohammad Alizadeh. 2021. Flow-Loss: Learning Cardinal-\nity Estimates That Matter. Proc. VLDB Endow. 14, 11 (jul 2021), 2019â€“2032.\nhttps://doi.org/10.14778/3476249.3476259\n[51] Parimarjan Negi, Ziniu Wu, Andreas Kipf, Nesime Tatbul, Ryan Marcus, Sam\nMadden, Tim Kraska, and Mohammad Alizadeh. 2023. Robust query driven\ncardinality estimation under changing workloads. Proceedings of the VLDB\nEndowment 16, 6 (2023), 1520â€“1533.\n[52] PostgreSQL Global Development Group. [n. d.]. https://www.postgresql.org/.\n[53] Robert Ricci, Eric Eide, and CloudLab Team. 2014. Introducing CloudLab: Scien-\ntific infrastructure for advancing cloud architectures and applications. ; login::\nthe magazine of USENIX & SAGE 39, 6 (2014), 36â€“38.\n[54] Clemens Rosenbaum, Tim Klinger, and Matthew Riemer. 2017. Routing Net-\nworks: Adaptive Selection of Non-linear Functions for Multi-Task Learning. ICLR\nabs/1711.01239 (2017). https://api.semanticscholar.org/CorpusID:22014305\n[55] Clemens Rosenbaum, Tim Klinger, and Matthew Riemer. 2018. Routing Net-\nworks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning. In\nInternational Conference on Learning Representations . https://openreview.net/\nforum?id=ry8dvM-R-\n[56] Paul Ruvolo and Eric Eaton. 2013. ELLA: an efficient lifelong learning algo-\nrithm. In Proceedings of the 30th International Conference on International Confer-\nence on Machine Learning - Volume 28 (Atlanta, GA, USA) (ICMLâ€™13) . JMLR.org,\nIâ€“507â€“Iâ€“515.\n[57] I. Sabek et al .2022. LSched: A Workload-Aware Learned Query Scheduler for\nAnalytical Database Systems. In SIGMOD .\n[58] P Griffiths Selinger, Morton M Astrahan, Donald D Chamberlin, Raymond A\nLorie, and Thomas G Price. 1979. Access path selection in a relational database\nmanagement system. In Proceedings of the 1979 ACM SIGMOD international\nconference on Management of data . 23â€“34.\n[59] Ji Sun and Guoliang Li. 2019. An end-to-end learning-based cost estimator.\nProc. VLDB Endow. 13, 3 (Nov. 2019), 307â€“319. https://doi.org/10.14778/3368289.\n3368296\n[60] Ji Sun, Jintao Zhang, Zhaoyan Sun, Guoliang Li, and Nan Tang. 2021. Learned\nCardinality Estimation: A Design Space Exploration and a Comparative Eval-\nuation. Proc. VLDB Endow. 15, 1 (sep 2021), 85â€“97. https://doi.org/10.14778/\n3485450.3485459[61] Immanuel Trummer. 2022. DB-BERT: a Database Tuning Tool that\" Reads the\nManual\". In Proceedings of the 2022 international conference on management of\ndata. 190â€“203.\n[62] Kostas Tzoumas, Amol Deshpande, and Christian S. Jensen. 2011. Lightweight\ngraphical models for selectivity estimation without independence assumptions.\nProc. VLDB Endow. 4, 11 (Aug. 2011), 852â€“863. https://doi.org/10.14778/3402707.\n3402724\n[63] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N. Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you\nneed. In Proceedings of the 31st International Conference on Neural Information\nProcessing Systems (Long Beach, California, USA) (NIPSâ€™17) . Curran Associates\nInc., Red Hook, NY, USA, 6000â€“6010.\n[64] Lianggui Weng, Rong Zhu, Di Wu, Bolin Ding, Bolong Zheng, and Jingren Zhou.\n2024. Eraser: Eliminating performance regression on learned query optimizer.\nProceedings of the VLDB Endowment 17, 5 (2024), 926â€“938.\n[65] Peizhi Wu and Gao Cong. 2021. A Unified Deep Model of Learning from both\nData and Queries for Cardinality Estimation. In Proceedings of the 2021 Inter-\nnational Conference on Management of Data (Virtual Event, China) (SIGMOD\nâ€™21). Association for Computing Machinery, New York, NY, USA, 2009â€“2022.\nhttps://doi.org/10.1145/3448016.3452830\n[66] Peizhi Wu and Zachary G. Ives. 2024. Modeling Shifting Workloads for Learned\nDatabase Systems. Proc. ACM Manag. Data 2, 1, Article 38 (March 2024), 27 pages.\nhttps://doi.org/10.1145/3639293\n[67] Ruihan Yang, Huazhe Xu, Yi Wu, and Xiaolong Wang. 2020. Multi-task reinforce-\nment learning with soft modularization. In Proceedings of the 34th International\nConference on Neural Information Processing Systems (Vancouver, BC, Canada)\n(NIPS â€™20) . Curran Associates Inc., Red Hook, NY, USA, Article 400, 11 pages.\n[68] Z. Yang et al .2022. Balsa: Learning a Query Optimizer Without Expert Demon-\nstrations. In SIGMOD .\n[69] Zongheng Yang, Wei-Lin Chiang, Sifei Luan, Gautam Mittal, Michael Luo, and Ion\nStoica. 2022. Balsa: Learning a query optimizer without expert demonstrations. In\nProceedings of the 2022 International Conference on Management of Data . 931â€“944.\n[70] Zongheng Yang, Amog Kamsetty, Sifei Luan, Eric Liang, Yan Duan, Xi Chen,\nand Ion Stoica. 2020. NeuroCard: One Cardinality Estimator for All Tables.\narXiv:2006.08109 [cs] (June 2020). arXiv:2006.08109 [cs]\n[71] Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan Duan, Xi\nChen, Pieter Abbeel, Joseph M. Hellerstein, Sanjay Krishnan, and Ion Stoica.\n2019. Deep Unsupervised Cardinality Estimation. Proc. VLDB Endow. 13, 3 (nov\n2019), 279â€“292. https://doi.org/10.14778/3368289.3368294\n[72] Xiang Yu, Chengliang Chai, Guoliang Li, and Jiabin Liu. 2022. Cost-Based or\nLearning-Based? A Hybrid Query Optimizer for Query Plan Selection. Proc. VLDB\nEndow. 15, 13 (Sept. 2022), 3924â€“3936. https://doi.org/10.14778/3565838.3565846\n[73] Rong Zhu, Wei Chen, Bolin Ding, Xingguang Chen, Andreas Pfadler, Ziniu Wu,\nand Jingren Zhou. 2023. Lero: A learning-to-rank query optimizer. Proceedings\nof the VLDB Endowment 16, 6 (2023), 1466â€“1479.\n[74] Rong Zhu, Ziniu Wu, Yuxing Han, Kai Zeng, Andreas Pfadler, Zhengping Qian,\nJingren Zhou, and Bin Cui. 2021. FLAT: fast, lightweight and accurate method\nfor cardinality estimation. Proc. VLDB Endow. 14, 9 (May 2021), 1489â€“1502.\nhttps://doi.org/10.14778/3461535.3461539\n14",
  "textLength": 90564
}