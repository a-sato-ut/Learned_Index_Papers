{
  "paperId": "bba32a7e7f5147dd5beb7f51f358a2edfcda6cf0",
  "title": "A Unified Transferable Model for ML-Enhanced DBMS",
  "pdfPath": "bba32a7e7f5147dd5beb7f51f358a2edfcda6cf0.pdf",
  "text": "A Unified Transferable Model for ML-Enhanced DBMS\nZiniu Wu2, Pei Yu#,1,4, Peilun Yang#,1,3, Rong Zhu1, Yuxing Han1, Yaliang Li1, Defu Lian4, Kai\nZeng1, Jingren Zhou1\n1Alibaba Group,2Massachusetts Institute of Technology,3University of Technology Sydney,4University of Science and\nTechnology of China\n1{yangpeilun.ypl, yupei.yu, red.zr, yuxing.hyx, yaliang.li, zengkai.zk, jingren.zhou }@alibaba-inc.com ,\n2ziniuw@mit.edu ,4liandefu@ustc.edu.cn\nABSTRACT\nRecently, the database management system (DBMS) community\nhas witnessed the power of machine learning (ML) solutions for\nDBMS tasks. Despite their promising performance, these existing\nsolutions can hardly be considered satisfactory. First, these ML-\nbased methods in DBMS are not effective enough because they are\noptimized on each specific task, and cannot explore or understand\nthe intrinsic connections between tasks. Second, the training pro-\ncess has serious limitations that hinder their practicality, because\nthey need to retrain the entire model from scratch for a new DB.\nMoreover, for each retraining, they require an excessive amount\nof training data, which is very expensive to acquire and unavail-\nable for a new DB. We propose to explore the transferabilities of\nthe ML methods both across tasks and across DBs to tackle these\nfundamental drawbacks.\nIn this paper, we propose a unified model MTMLF that uses a\nmulti-task training procedure to capture the transferable knowl-\nedge across tasks and a pre-train fine-tune procedure to distill the\ntransferable meta knowledge across DBs. We believe this para-\ndigm is more suitable for cloud DB service, and has the potential\nto revolutionize the way how ML is used in DBMS. Furthermore,\nto demonstrate the predicting power and viability of MTMLF, we\nprovide a concrete and very promising case study on query op-\ntimization tasks. Last but not least, we discuss several concrete\nresearch opportunities along this line of work.\n1 INTRODUCTION\nDatabase management system (DBMS) is the cornerstone of a broad\nrange of applications such as big data platforms, cloud computing,\ninternet of things, and artificial intelligence. Designing and tuning\nDBMS involves a series of complicated tasks ranging from physical\ndesign, configuration tuning, to query optimization and execution\nscheduling, which all require intensive expertise. With the growth\nof data volume and complexity, it becomes increasingly difficult to\nmaintain DBMS purely using human efforts.\nRecently, the prosperity of machine learning (ML), especially\ndeep learning, helps to resolve a large number of DBMS challenges.\nML techniques enable automatic, fine-grained, and more accurate\ncharacterization of the problem space and benefit a variety of tasks\nin DBMS. Specifically, unsupervised ML techniques can model the\ndata distribution for cardinality estimation (CardEst) [ 13,37â€“39,43]\nand indexing [ 6,7,17,25]; supervised ML models can replace the\ncost estimator (CostEst) [ 24,31,32] and execution scheduler [ 22,\n29]; and reinforcement learning methods solve decision making\nproblems such as configuration tuning [ 1,19,41] and join order\nselection (JoinSel) [10, 21, 23, 27, 40].Motivation: Despite these ML methodsâ€™ promising results on each\nindividual task, the existing ML techniques in DBMS do not explore\nthe following transferabilities and can lead to impractical solutions\nand/or ineffective models.\n(1)Transferability across databases : Existing ML methods for\nDBMS only focus on learning the database-specific knowledge and\nignore the database-agnostic meta knowledge that can be transferred\nto new DBs. Therefore, they need to retrain the entire model from\nscratch for a new DB, and generally require an excessive and im-\npractical amount of data, such as executed queries and logs, for\neach retraining, which is very expensive to acquire especially for\na new DB [ 20] (referred to as the notorious â€œcold-startâ€ problem).\nFortunately, some meta knowledge can be distilled and shared across\nDBs to mitigate this problem. This knowledge (such as expert expe-\nrience and heuristics in the physical join implementation and access\npath selection) is independent of each specific DB. For example, the\nquery optimizer usually chooses an index scan for high-selectivity\npredicates and a sequential scan for low-selectivity ones; and the\nhash join is usually more memory-intensive than nest loop join\nand merge join. This knowledge should be distilled and shared\nacross various databases to avoid the redundant learning process\nand mitigate the â€œcold-startâ€ problem.\n(2)Transferability across tasks : Existing ML approaches are only\noptimized on individual DBMS tasks and neglect the task-shared\nknowledge , leading to inefficient use of data and ineffective model.\nSince all these approaches are fundamentally based on understand-\ning the data distributions and query workload representation, the\nshared knowledge can be used to reduce model redundancy and im-\nprove data efficiency across tasks. More importantly, it can enhance\nthe model effectiveness because these tasks are inter-dependent\nand this knowledge can capture the inherent interactions. For exam-\nple, the purpose of CardEst model is to help generate better query\nplans. However, different estimations have different impacts on the\nquality of the generated plan, which is also determined by the plan\nenumeration method and the cost model. Sometimes a series of bad\nestimations will not lead to a worse plan, but a small estimation\nerror of a critical sub-query can have catastrophic outcomes. Thus,\na CardEst model trained without considering other tasks can not\neffectively generate better query plans [26].\nInspired by the recent success of the pre-trained models (e.g.,\nBERT [ 5] and GPT-3 [ 3]) in NLP domain, we advocate for the next\ngeneration of ML-based methods for DBMS to explore and exploit\nthe aforementioned transferabilities in a unified framework. Within\nthis framework, the knowledge can be distilled and shared across\ntasks to mutually benefit all, and the meta knowledge can be reused\nfor new DBs. Specifically, we propose a meta-learning paradigmarXiv:2105.02418v3  [cs.DB]  25 Nov 2021\n\nZiniu Wu2, Pei Yu#,1,4, Peilun Yang#,1,3, Rong Zhu1, Yuxing Han1, Yaliang Li1, Defu Lian4, Kai Zeng1, Jingren Zhou1\nthat pre-trains a model on various DBs to condense the database-\nagnostic meta knowledge and fine-tunes this model to fit a new DB\nwith a small number of training examples. Moreover, we propose a\nmulti-task training procedure that simultaneously trains the model\non all DBMS tasks to extract the task-shared knowledge .\nContribution: We identify the transferable andnon-transferable\nknowledge that ML models try to understand and use to solve the\nDBMS tasks. Based on the transferability across DBs, we classify the\nknowledge into database-agnostic meta knowledge anddatabase-\nspecific knowledge . Based on the transferability across tasks, we\nclassify the knowledge into task-shared knowledge andtask-specific\nknowledge .\nThereafter, we propose the multi-task meta-learning framework\n(MTMLF) with three modules: (1) a featurization and encoding\nmodule to characterize the database-specific knowledge such as the\ndata distributions in each DB, (2) a shared representation module\nto extract task-shared knowledge that would benefit all DBMS tasks,\nand (3) a task-specific module to tackle each task (such as CardEst,\nCostEst, JoinSel, indexing, and configuration tuning) and learn the\ntask-specific knowledge . Furthermore, the architecture of MTMLF\nnaturally enables a pre-train fine-tune meta learning paradigm to\ndistill the database-agnostic meta knowledge .\nIn order to demonstrate the viability of the envisioned MTMLF,\nwe provide a case study MTMLF-QO for query optimization tasks,\nincluding CardEst, CostEst, and JoinSel. Thanks to the multi-task\njoint learning, the MTMLF-QO on a single DB outperforms the\nprevious state-of-the-art (SOTA) method on CardEst/CostEst tasks,\nand yields near-optimal results in JoinSel task. When trained on\nmultiple DBs with the proposed meta-learning algorithms, MTMLF-\nQOhas ability to distill the meta knowledge that can be transferred\non new DBs.\nThe contributions of this paper are summarized as follows:\nâ€¢We identify and classify the knowledge that ML models in\nDBMS essentially trying to comprehend (Section 2).\nâ€¢We propose the MTMLF, a unified transferable model for all\nDBs and all tasks in DBMS (Section 2).\nâ€¢We design a concrete model MTMLF-QO to showcase that\nMTMLFâ€™s viability for query optimization (Section 3).\nâ€¢We conduct experiments to demonstrate MTMLF-QOâ€™s su-\nperior performance and effectiveness of multi-task learning and\nmulti-DB meta-learning (Section 4).\nâ€¢We point out several concrete future research directions along\nthis line of work (Section 5).\n2 MULTI-TASKING META-LEARNING\nFRAMEWORK\nIn this section, we classify the knowledge that ML methods in\nDBMS trying to comprehend, from the data and task dimensions in\nSection 2.1. Based on this classification, we design the multi-tasking\nmeta-learning framework (MTMLF) to explicitly learn each type of\nknowledge in Section 2.2. At last, we provide the workflow about\nthe MTMLF with the potential to revolutionize the way how ML\nmethods are used for DBMS in Section 2.3.\nShared Representation ModuleCardEst modelCostEst modelSchedulingmodelâ€¦\nData(TablesinDB)Queries(SQL, plan tree)â€¦â€¦Featurization and encodingOther inputs(e.g. machine property)JoinSelmodelQuery optimization tasksTask-specificModule(Multi-task Learning)Cross-DB Meta-LearningDatabase-agnosticMeta knowledgeDatabase-specificknowledgeDataAspectTask-specificknowledgeTask-sharedknowledgeTaskAspectFigure 1: Framework and knowledge overview\n2.1 Knowledge classification\nThe ML solutions for DBMS are fundamentally based on extracting\nknowledge from the DB and apply it to various tasks. We can classify\nthis knowledge from two aspects as shown in Figure 1.\nFrom data aspect based on whether the knowledge is transferable\nacross DBs, it can be classified into database-specific anddatabase-\nagnostic meta knowledge:\nDatabase-specific knowledge refers to the knowledge that is\nunique and can hardly benefit other DBs. Specifically, it includes\nthe data distributions, the join schema (i.e. the fact/dimension tables\nand their join relationship), and the query workload in a DB.\nDatabase-agnostic meta knowledge refers to the knowledge\nthat should be distilled and shared across various DBs. In a high\nlevel, this knowledge is independent of the data distributions and\nquery workloads in specific DBs, such as the expert experience and\nheuristics about the physical join implementation and access path\nselection. E.g., to implement a hash join for foreign key join, the\ndimension table is usually the build side and the fact table is the\nprobe side. Furthermore, in a distributed setting, the hash join is\nusually implemented using broadcast join where the dimension\ntable is broadcasted. This type of meta knowledge should be shared\nacross DBs to avoid redundant learning process for each new DB.\nFrom task aspect based on the knowledgeâ€™s transferability across\ntasks, it can be classified as task-shared andtask-specific knowledge:\nTask-shared knowledge refers to the data and query representa-\ntion that can benefit all tasks in DBMS. The existing ML approaches\nto all DBMS tasks are fundamentally based on understanding the\nunderlying data distributions and query workload representation.\nTherefore, these tasks are inter-dependent and the shared knowl-\nedge can capture their inherent interactions to enhance the model\neffectiveness. For instance, the index recommender analyzes the\ndata and query workload to recommend an index that can improve\na large portion of join and scan cases encountered by the query op-\ntimizer. Conversely, the query optimizer, which plans the execution\nessentially based on understanding the distributions, can generate\nmore efficient query plans by considering the learned index.\nTask-specific knowledge will be used to tackle each specific task\nbased on the shared data and query workload representation. For ex-\nample, having access to the shared representation, a JoinSel model\nstill needs to explicitly solve an NP-hard problem [ 18]. Specifically,\nafter deriving estimated cardinalities and the cost of different oper-\nations from the shared knowledge, the JoinSel model will design\nspecific features to solve an NP-hard combinatorial optimization\nproblem and plan an optimal join order. This step is hardly benefi-\ncial to other tasks and too complex to be shared with.\n\nA Unified Transferable Model for ML-Enhanced DBMS\nExisting ML approaches in DBMS are not effective or practical\nmainly because they did not explore or learn the database-agnostic\nmeta knowledge andtask-specific knowledge . Therefore, we propose\nthe MTMLF to explicitly learn these two types of knowledge.\n2.2 Framework overview\nWe design the MTMLF with the following architecture to explicitly\ncapture the aforementioned four types of knowledge (shown in\nFigure 1). First, the MTMLF uses a featurization and encoding mod-\nulefor each DB to process the non-transferable database-specific\nknowledge . Second, it constructs a shared representation module to\nlearn the data distributions and query workload representation that\ncan benefit all DBMS tasks. This module will be trained jointly on\nall tasks in order to extract the task-shared knowledge and improve\nmodel effectiveness on each task. Third, it creates a task-specific\nmodule with each sub-module corresponding to one DBMS task and\nunderstands the task-specific knowledge . Fourth, the architecture\ndesign of MTMLF enables an effective meta-learning procedure to\ndistill the database-agnostic meta knowledge . All database-specific\ninformation is pushed to the featurization and encoding module .\nThe remaining modules are devoted to understanding the database-\nagnostic knowledge . Therefore, we hypothesize that the task-specific\nandshared representation modules can benefit significantly from pre-\ntrain fine-tune paradigm. I.e. we can pre-train these two modules\nof MTMLF using data from various DBs; thereafter, when deployed\non a new DB, the pre-trained model only needs a small number of\ntraining examples to fine-tune for the best accuracy.\nFeaturization and encoding module adaptively applies feature\nengineering to three types of input: the data tables, the executed\nquery workload, and additional information such as join schema\nand physical machine properties. (1) This module will take each\ndata table in the DB as input and output its encoded distribution.\n(2) This module can directly apply the existing procedures [ 21,32]\nto featurize each query in the workload. (3) Some tasks may take\nadditional information into consideration. For example, a resource\nallocation and execution scheduling model might need to know the\nmemory size, buffer size, CPU usages, etc. This module can also\nfeaturize these inputs accordingly.\nShared representation module takes the featurized and encoded\ninputs, models their interactions, and outputs a shared represen-\ntation that could benefit all tasks/DBs. For example, many tasks\n(e.g. CardEst, JoinSel) must understand the data distribution of the\njoin on multiple tables. This module can learn such distribution by\nanalyzing the cardinality of executed join queries and combining\nthe single table distributions. Inspired by recent advance using pre-\ntrain models for NLP [ 3,5], data cleaning [ 33] and relational table\nunderstanding [ 4,12], we advocate for implementing the shared rep-\nresentation module with transformer [35], which is demonstrated\nto be very powerful in modeling interactions, extracting effective\nrepresentations, and easy for pre-train fine-tune procedure.\nTask-specific module contains a series of models corresponding\nto all DBMS tasks, some of which may contain many sub-tasks (for\nexample, the query optimization task consists of CardEst, CostEst,\nJoinSel sub-tasks). Each model takes the shared representation fromthe previous module and returns the desired outputs for its corre-\nsponding DBMS task. This module learns the task-specific knowl-\nedge, which can also benefit various DBs through meta-learning.\n2.3 Workflow overview\nThe MTMLF has the potential to revolutionize the way how ML is\nused in DBMS. It is more suitable in the form of cloud service, which\ncan significantly reduce the time and complexity of adopting ML-\npowered DBMS components (such as DB auto-tuner and learned\nquery optimizer) on usersâ€™ DBs, and boost the wide applications\nof these ML components. We provide the details from the service\nprovider and the users sides.\nService provider side: The cloud service provider will train the\nMTMLF on multiple usersâ€™ DBs and provide the shared represen-\ntation andtask-specific modules as part of the DB service to the\nusers. In this way, the provider can leverage its advantages: 1) it\nhas access to various usersâ€™ DBs either through anonymous access\nor federated learning [ 16] to protect the data privacy; 2) it has pow-\nerful computation resources to train large models; and 3) it has\nabundant time because the training process is offline. Thus, the\npre-trained MTMLF can fully exploit these advanatges to distill the\ndatabase-agnostic meta knowledge beneficial to all usersâ€™ DBs.\nFurthermore, the service provider can periodically collect useful\ninformation from the users side in the form of anonymous training\ndata or gradients of model parameters (in federated learning). This\ninformation will be used continuously and asynchronously to up-\ndate and optimize the pre-trained MTMLF. The new model will be\npublished as service upgrades to benefit all users.\nUsers side: The DB users will locally adjust the received pre-trained\nMTMLF to best fit their DBs. This fast local training process only\nrequires the users to (1) analyze the data tables in the userâ€™s DB to\nsummarize the data distributions, similar to an â€œANALYZEâ€ oper-\nation in traditional DBMS [ 9], and (2) execute a small number of\nrepresentative queries to fine-tune the pre-trained MTMLF. This\ntraining procedure only needs to be conducted once and all tasks\nare tuned to the best performance.\nThe MTMLF model is very effective in inference. Since all tasks\nare trained jointly to learn the task inherent interactions, the in-\nference of each task can effectively take others into consideration,\nguaranteed to make consistent decisions. For example, the physical\ndesign wizard will only recommend indices that the query optimizer\nfinds useful for a large portion of query workloads.\nThis pre-train fine-tune paradigm can significantly reduce the\nmanagement complexity. First, the MTMLF can swiftly evolve itself\nas the DB changes. When the data or query workload distribution\nin this DB shifts, only the featurization and encoding module of\nMTMLF needs to be updated without affecting the other two mod-\nules. Second, despite the diverse set of DBMS tasks, only a single\nmodel needs to be maintained, monitored, and regularly updated.\n3 CASE STUDY QUERY OPTIMIZATION\nIn this section, we describe the MTMLF in a concrete scenario,\nquery optimization (QO), a key component in DBMS. In Section 3.1,\nwe first review the relevant learning tasks in QO: CardEst, CostEst,\nand JoinSel tasks. Then in Section 3.2, we present the case study\nmodel, MTMLF-QO for a single DB, which can be jointly trained on\n\nZiniu Wu2, Pei Yu#,1,4, Peilun Yang#,1,3, Rong Zhu1, Yuxing Han1, Yaliang Li1, Defu Lian4, Kai Zeng1, Jingren Zhou1\nLoss CriteriaEst. CardEst. CostEst. Scheduleâ€¦True CardTrue CostOptimal Scheduleâ€¦lossInputsMTMLFSeqScan T1 on f(T1)IndexScan T2on f(T2)Index Scan T3on f(T3)Seq Scan Tnon f(Tn)Merge join on j(T1, T2)Loopjoin on j(T3, Tn)Hashjoin on j(T1, T3)(I) InputsTable T1Table T2Table Tnâ€¦I.i) Data TablesI.ii) Query QInitial plan !:SELECT COUNT(*) FROM T1, T2, T3, Tn WHERE (joins) AND f(T1) AND â€¦ AND f(Tn)\nNode: N1Node: N2Node: N3(F) Featurizationand encodingF.i) Featurization   FEAt/f(T)/j(Ti,Tj)xEnc1â€¦F.ii) Encoding   E(f(T1))E(f(Tn))F.iii) Tree structure embedding.SerializerE(N1)E(N2)E(N3)â€¦(S) SharedRepresentationTrans_Share(T) Task-specificModuleT.i) CardEst Model   M_CardEst\nS1S2â€¦T.ii) CostEst Model  M_CostEst\"#$%&\"#'()T.iii) Join order Model   Trans_JO*+1!\"i: Pred position of ith table*+2*+nâ€¦(L) Loss Criteriaand trainingL.i) CardEst lossQerror(#$%&', Card)L.ii) CostEst lossQerror(#$()*, Cost)L.iii) JO lossCrossEntropy(!\"i, Pi)\nL.iv) Gradient backpropogationEncnLabel\nLoss Criterion\nFigure 2: MTMLF-QO Model for a single DB\nthese three tasks to mutually benefit all. At last in Section 3.3, we\nexplain the meta-learning algorithm of MTMLF-QO for multiple\nDBs, which helps distill the meta-knowledge beneficial to all DBs.\n3.1 Learning tasks in query optimization\nThe query optimizer, which takes as input a SQL query and outputs\nits physical execution plan, directly determines the performance of\nDBMS. Tuning the query optimizer is a challenging task, requiring\nthousands of expert-engineering hours [ 18,21]. Thus, numerous ef-\nforts have been devoted to optimizing QO using ML techniques [ 42].\nEach candidate plan of a query ğ‘„can be regarded as a tree,\nwhere each leaf node is a (sequential or index) scan operation\non some tables and each inner node is a (merge, nested loop, or\nhash) join operation between multiple tables. Following previous\nwork [ 21], as we focus on JoinSel, we omit other physical operations\n(e.g. aggregate or hash). The QO process would enumerate several\ncandidate plans, estimate their cardinality and cost, and select the\noptimal one. Next, we list the core learning tasks of QO:\nâ€¢Cardinality estimation (CardEst) refers to estimating the num-\nber of tuples satisfying a query before its execution. ML-based\nCardEst techniques try to build either unsupervised models charac-\nterizing the data distribution [ 13] or supervised models mapping\nfeaturized queries to the cardinality [ 15]. Recent evaluation re-\nsults [ 43] have exhibited their superiority over traditional methods.\nâ€¢Cost estimation (CostEst) refers to estimating the latency of a\n(sub-)query execution plan. ML-based CostEst methods use tree-\nbased models (such as tree convolution [ 24] and tree-LSTM [ 32])\nto encode a plan and map the encoding to its estimated costs.\nâ€¢Join order selection (JoinSel) decides the order with minimal\ncost to join multiple tables in the query. It is an NP-hard problem\nwith a large search space [ 18]. Existing ML-based solutions attempt\nto effectively solve JoinSel using deep reinforcement learning tech-\nniques [10, 21, 23, 40].\nThese core tasks in QO are interdependent. Specifically, CostEst\nis fundamentally based on CardEst; JoinSel requires CardEst and\nCostEst to evaluate the quality of the join order. It has been shown\nempirically that the CardEst model learned without considering the\njoin order and cost model will not generate effective prediction [ 26].\nThus, these tasks will be learned jointly in MTMLF-QO.3.2 Architecture\nAs a concrete case study of the aforementioned MTMLF, the MTMLF-\nQO model also consists of inputs (I), featurization and encoding\nmodule (F), shared representation module (S), task-specific module\n(T), and loss criteria and training (L), as shown in Figure 2.\n(I) Inputs: The MTMLF-QO model takes two types of inputs: (I.i)\nthe data tables ğ‘‡={ğ‘‡1,ğ‘‡2,...,ğ‘‡ğ‘›}in the DB and (I.ii) the query ğ‘„=\n(ğ‘‡ğ‘„,ğ‘—ğ‘„,ğ‘“ğ‘„)whereğ‘‡ğ‘„âŠ†ğ‘‡denotes the tables touched by ğ‘„,ğ‘—ğ‘„=\n{ğ‘—(ğ‘‡1,ğ‘‡2),...}denotes the join predicates, and ğ‘“ğ‘„={ğ‘“(ğ‘‡1),ğ‘“(ğ‘‡2),\n...,ğ‘“(ğ‘‡ğ‘›)}denotes the filter predicates. We also provide ğ‘„â€™s initial\nplanPwith each node corresponding to a join or scan operation.\nWe modify the CardEst and CostEst tasks to let MTMLF-QO take\nthe queryPand estimate the cardinality and cost of the sub-plan\nrooted at each node of P. All three tasks will be trained jointly.\n(F) Featurization and encoding module: We extract the useful\ninformation from each data tuple and input queries, and embed\nthem into vectors [ 21,32] (shown in F.i). Specifically, we provide a\nvalue embedding for each unique column domain value in the DB\nto embed the tuples and the predicates ğ‘—(ğ‘„),ğ‘“(ğ‘„). We use a one-\nhot vector to represent each distinct table, column, and physical\noperation of a DB.\nAfter the featurization, (F.ii) of this module will encode the data\ndistribution of each table. For each single table ğ‘‡ğ‘–, this module\ndeploys a transformer encoder [ 35] (ğ¸ğ‘›ğ‘ğ‘–), which takes the filter\npredicate on this table ğ‘“(ğ‘‡ğ‘–)and outputs ğ¸(ğ‘“(ğ‘‡ğ‘–))representing the\ndistribution of ğ‘‡ğ‘–after applying ğ‘“(ğ‘‡ğ‘–).\nThus far, we can embed each node ğ‘ğ‘–of the query planPas a\nconcatenation of the one-hot vector embedding of tables touched\nbyğ‘ğ‘–, the one-hot vector of operation type, and the embedding\nfor predicate ğ‘—(ğ‘ğ‘–)or encoded ğ¸(ğ‘“(ğ‘ğ‘–)). We denote the embed-\nding ofğ‘ğ‘–asğ¸(ğ‘ğ‘–). At last, a serializer (F.iii) will convert the\ntree-structured plan into a vector ğ¸(P)=(ğ¸(ğ‘1),ğ¸(ğ‘2),...)using\nthe transformersâ€™ tree positional embedding techniques [30].\n(S) Shared representation module: After the previous module\nproduces a sequence of embeddings ğ¸(P)for the query, MTMLF-\nQO will model the interactions among elements ğ¸(ğ‘ğ‘–)ofğ¸(P)and\ngenerate a shared representation for the subsequent tasks. We use\na transformer encoder Trans_Share to learn such interactions.\n\nA Unified Transferable Model for ML-Enhanced DBMS\nThe inputğ¸(P)toTrans_Share contains the information of single\ntable distributions and join predicates. Trans_Share will construct\nthe multi-table join distributions and understand the cost of dif-\nferent physical operations on specific single and join tables. The\noutput(ğ‘†1,ğ‘†2,...)ofTrans_Share has the same length as the input,\nwith one-to-one correspondence. For example, the ğ‘†ğ‘–corresponding\ntoğ¸(ğ‘ğ‘–)will represent the query Pâ€™s sub-plan rooted at node ğ‘ğ‘–.\n(T) Task-specific module: Two multiple-layer perceptrons\n(MLPs), namely M_CardEst andM_CostEst can directly extract the\nestimated cardinality Âšğ¶ğ‘ğ‘Ÿğ‘‘ and cost dğ¶ğ‘œğ‘ ğ‘¡ from the shared represen-\ntation (T.i and T.ii, respectively). However, extracting the optimal\njoin order from this representation is much more complicated, be-\ncause there exists an exponential number of possible join orders\nand a large amount of them might not be executable (e.g. there does\nnot exist a join predicate between two tables).\nAs demonstrated in (T.iii), we formulate the JoinSel task into a\nsequence to sequence learning task (seq2seq) and use a transformer\ndecoder [ 35]Trans_JO to generate the join order. For clarity of\ndiscussion, we focus on generating the left-deep join orders [ 18],\nwhich can be directly flattened into an ordered sequence of tables.\nSpecifically, the Trans_JO takes as input the shared representation\n(ğ‘†1,ğ‘†2,...), with each ğ‘†ğ‘–representing a single or join table. At\neach timestamp ğ‘¡,Trans_JO will output a value Ë†ğ‘ƒğ‘¡representing the\nprobability of which table should be joined at the current timestamp.\nFor a DB with ğ‘›tables, Ë†ğ‘ƒğ‘¡will be a multinoulli distribution vector\nof lengthğ‘›with the i-th entree corresponding to the probability\nthat the table ğ‘‡ğ‘–is the next table to join with. Then, we design a\nnovel decoding algorithm to decode a sequence of tables from the\ntime sequence of Ë†ğ‘ƒğ‘¡as the predicted join order, which is guaranteed\nto be legal and executable.\nPlease note that the Trans_JO can also generate bushy plans with\nour novel decoding algorithm based on novel beam-search [ 2,8].\nWe delay the discussion on the details of Trans_JO for bushy plans\nand the decoding algorithm to Section 4.\n(L) Loss criteria and training: In order to train the models for\nCardEst and CostEst, we use the conventional Q-error loss [ 15,32],\ni.e., the factor between the predicted and true cardinality or cost\n(L.i and L.ii): ğ¿ğ‘ğ‘ğ‘Ÿğ‘‘=ğ‘šğ‘ğ‘¥(dğ‘ğ‘ğ‘Ÿğ‘‘/ğ‘ğ‘ğ‘Ÿğ‘‘,ğ‘ğ‘ğ‘Ÿğ‘‘/dğ‘ğ‘ğ‘Ÿğ‘‘).\nFor the JoinSel, which can be modeled as the seq2seq task, we use\nthe cross-entropy loss function. Specifically, given a ground truth\noptimal left-deep join order ğ‘‡â€²\n1,ğ‘‡â€²\n2,...,ğ‘‡â€²ğ‘šfor a query ğ‘„touching\nğ‘štables out of the total ğ‘›tables, we can embed each ğ‘‡â€²\nğ‘¡intoğ‘ƒğ‘¡, a\none-hot vector of length ğ‘›. At each time stamp ğ‘¡, the MTMLF-QO\noutputs a probability vector Ë†ğ‘ƒğ‘¡and we can compute a cross entropy\nloss between Ë†ğ‘ƒğ‘¡andğ‘ƒğ‘¡. We average the loss across all ğ‘štimestamps\nand derive the loss of join order ğ¿ğ‘—ğ‘œ=âˆ’(Ãğ‘š\nğ‘¡=1ğ‘ƒğ‘¡Â·ğ‘™ğ‘œğ‘”(Ë†ğ‘ƒğ‘¡))/ğ‘š. This\nrefers to the token-level loss function in NLP context []. To further\nenhance the effectiveness of the model training, we design a novel\nsequence-level loss function to train the Trans_JO . We will explain\nthe details in Section 5.\nDuring the offline training phase of MTMLF-QO, all three tasks\nare trained jointly. The overall loss criterion is defined as the weighted\ncombination of three loss functions for three tasks as defined in\nequation 1. The weights are hyper-parameters of the MTMLF-QO.\nğ¿ğ‘„ğ‘‚=ğ‘¤ğ‘ğ‘ğ‘Ÿğ‘‘âˆ—ğ¿ğ‘ğ‘ğ‘Ÿğ‘‘+ğ‘¤ğ‘ğ‘œğ‘ ğ‘¡âˆ—ğ¿ğ‘ğ‘œğ‘ ğ‘¡+ğ‘¤ğ‘—ğ‘œâˆ—ğ¿ğ‘—ğ‘œ (1)Algorithm 1: Meta-learning Algorithm for MTMLF-QO\n1:Input :ğ‘›database((ğ·1,ğ‘„1),(ğ·2,ğ‘„2),...,(ğ·ğ‘,ğ‘„ğ‘))\n2:Initialize empty set ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘› _ğ·ğ‘ğ‘¡ğ‘\n3:forğ‘–âˆˆ{1,...,ğ‘›}do\n4: For each table ğ‘‡ğ‘—inğ·ğ‘–, trainğ¸ğ‘›ğ‘ğ‘—(F.i and F.ii in Figure 2)\n5: (F) module featurizes each query in ğ‘„ğ‘–, and deriveğ¸(P)\n6: Add(ğ¸(P),ğ¶ğ‘ğ‘Ÿğ‘‘,ğ¶ğ‘œğ‘ ğ‘¡,ğ‘ƒ ğ‘¡)toğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘› _ğ·ğ‘ğ‘¡ğ‘\n7:Shuffleğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘› _ğ·ğ‘ğ‘¡ğ‘\n8:Train (S) and (T) modules with ğ‘‡ğ‘Ÿğ‘ğ‘–ğ‘› _ğ·ğ‘ğ‘¡ğ‘\nThe gradient of this loss function will be backpropagated to update\nthe parameters of the (S) and (T) modules only.\nFor the (F) module, each single table encoder ğ¸ğ‘›ğ‘ğ‘–(F.ii) is trained\nseparately with a CardEst task on a single table ğ‘‡ğ‘–. I.e.ğ¸ğ‘›ğ‘ğ‘–learns\nthe data distribution of ğ‘‡ğ‘–through predicting the cardinality of filter\npredicateğ‘“(ğ‘‡ğ‘–). The details are put in the supplementary material.\nResearch opportunities: The optimal join order for a query with\na large number of tables is very expensive to obtain, limiting the\nMTF-QOâ€™s ability to extrapolate to very complex queries. A two-\nphase training can potentially alleviate this problem. I.e, an existing\nDBMS can be used to generate sub-optimal join orders to train a\nbaseline MTF-QO, and then the precious data of the optimal join\norders will be used to optimize this model.\n3.3 Cross-DB meta learning for MTMLF-QO\nIn this section, we first propose a meta-learning algorithm (MLA)\nfor MTMLF-QO and then conceptually reason about its feasibility.\nMeta-learning algorithm: The details of MLA are shown in Al-\ngorithm 1. Assume that MTMLF-QO has access to ğ‘›DBs, each with\ndata tables ğ·ğ‘–and executed query workload ğ‘„ğ‘–. The MLA aims\nat enabling MTMLF-QO to predict the cardinality, cost, and join\norder for all ğ‘›DBs using a single model, and learning the database-\nagnostic meta knowledge . Thus, MLA empowers MTF-QO with the\nability to transfer its learned knowledge to new DBs.\nFirst, the data tables and queries in each DB will go through\nthe featurization module of MTF-QO. Then, following the training\nprocedure described earlier, we train the single table encoder ğ¸ğ‘›ğ‘ğ‘—\nfor each table ğ‘‡ğ‘—of each DB (line 4). Thus, the (F) module can embed\neach queryğ‘âˆˆğ‘„ğ‘–with initial planP(line 5) and add the embedding\nğ¸(P)and its corresponding cardinality, cost, and optimal join order\nto the training dataset (line 6). After all queries in all DBs have been\nadded, MLA will shuffle the training dataset (line 7) and train the\nshare representation (S) and task-specific modules (T) using the\naforementioned loss criteria (line 8).\nThe returned MTMLF-QO trained by MLA would extrapolate to\nvarious DBs and produce accurate predictions on all of them. Thus,\nfor each new DB, we can train the single table encoders ( ğ¸ğ‘›ğ‘ğ‘—in\nF.ii) and the â€œmetaâ€ MTMLF-QO model only needs to be fine-tuned\non a small number of example queries. The encoders in (F.ii) only\nrequire query cardinalities on single tables and are efficient to train.\nConceptual reasoning of MLA: MLA pushes all data-specific in-\nformation to the (F) module, which can be efficiently trained for a\nnew BD. By shuffling the training dataset across different DBs, the\nMLA enforce subsequent modules of MTMLF-QO to learn the data-\nagnostic information, such as how the (S) module can derive the\ndistribution on the join of multiple tables, and how the (T) module\ncan use the shared representation to predict the cardinality, cost\n\nZiniu Wu2, Pei Yu#,1,4, Peilun Yang#,1,3, Rong Zhu1, Yuxing Han1, Yaliang Li1, Defu Lian4, Kai Zeng1, Jingren Zhou1\nğ‘‡!ğ‘‡\"ğ‘—(ğ‘‡!,ğ‘‡\")ğ‘‡#ğ‘—(ğ‘‡!,ğ‘‡#)ğ‘—(ğ‘‡\",ğ‘‡$)ğ‘‡$ğ‘‡!ğ‘‡\"ğ‘—(ğ‘‡!,ğ‘‡\")ğ‘‡#ğ‘‡$ğ‘—(ğ‘‡#,ğ‘‡$)ğ‘—(ğ‘‡!,ğ‘‡#)\n(a)Left-deepplantree(b)Bushyplantree\nFigure 3: Tree-structured Logic query plans\nand join order. Without this training procedure, the (S) and (T) will\nlikely map the embedded query to the target by brute force without\ntruly understanding the semantics of the encoded data distribution.\nWe also provide a detailed example in the supplementary material\non how the (S) and (T) modules can learn to construct the proba-\nbility distribution on the join of multiple tables from single table\ndistributions provided by the (F) module.\nFor example, for the shared representation module, the most\ncritical and challenging part will be understanding the probabil-\nity distribution on the join of multiple tables. Without MLA, the\n(S) module would require thousands of executed multi-table join\nqueries to forcedly capture this information. Alternatively, the join\ntables probability distribution can be reconstructed from the single\ntable distributions. For example, consider two tables ğ´,ğµ, and their\njoin tableğ‘‚=ğ´âŠ²âŠ³ğµon join predicate ğ´.ğ‘–ğ‘‘=ğµ.ğ‘–ğ‘‘. The probability\nof any filter predicate on ğ‘‚can be derived from the distributions\nonğ´andğµonly, as shown in Equation 2. By shuffling the training\ndataset across different DBs, MLA will compel the (S) module to\nlearn this reconstruction process because otherwise a single (S)\nmodule can not extrapolate on different DBs.\nğ‘ƒğ‘‚(ğ‘“(ğ´)âˆ§ğ‘“(ğµ))\n=âˆ‘ï¸\nğ‘–ğ‘‘âˆˆğ·(ğ´.ğ‘–ğ‘‘)ğ‘ƒğ´(ğ‘“(ğ´)âˆ§ğ´.ğ‘–ğ‘‘=ğ‘–ğ‘‘)âˆ—ğ‘ƒğµ(ğ‘“(ğµ)âˆ§ğµ.ğ‘–ğ‘‘=ğ‘–ğ‘‘) (2)\n4 JOIN ORDER PREDICTION: TRANS_JO\nIn this section, we present the details of the Trans_JO model, which\ntakes the table representation as inputs and outputs an executable\njoin order. Specifically, we first explain the encoding and decoding\ntechniques for join order trees in Section 4.1. Next, we thoroughly\nexplain the workflow of Trans_JO in Section 4.2. At last, we present\nour novel beam search algorithm which guarantees to output an\nexecutable join order in Section 4.3.\n4.1 Tree-to-seq and seq-to-tree conversion of\nquery plan\nAs described in the previous section, we formulate the join order\nselection task into a seq2seq learning task. Thus, it is crucial to\nflatten a tree-structured logical query plan into a sequence and\nconversely, revert a sequence into a logical query plan. We introduce\nour novel techniques for this tree-to-seq and seq-to-tree conversion.\nThis method can be applied to both left-deep plans and bushy plans.\nSince the plan tree is essentially a binary tree, we transform\nthe plan tree into a complete binary tree. Given a complete plan\ntree, we employ an embedding to record the position of each single\nğ‘‡!ğ‘‡\"ğ‘—(ğ‘‡!,ğ‘‡\")ğ‘‡#ğ‘—(ğ‘‡!,ğ‘‡#)ğ‘—(ğ‘‡\",ğ‘‡$)ğ‘‡$\n(a)Binaryplantree(b)Completebinaryplantreeğ‘‡!ğ‘—(ğ‘‡!,ğ‘‡\")ğ‘‡#ğ‘—(ğ‘‡!,ğ‘‡#)ğ‘—(ğ‘‡\",ğ‘‡$)ğ‘‡$ğ‘‡\"ğ‘‡#ğ‘‡#ğ‘‡$ğ‘‡$ğ‘‡$ğ‘‡$ğ‘‡$ğ‘‡$Figure 4: Decoding techniques\ntable in the tree. As shown in Figure 4, the left-deep plan tree is\ntransformed into a complete binary tree. Leaves are noted the same\nas their ancestors in the tree, thus all the leaves of the sub-tree\nwhich roots at ğ‘‡3, are marked as ğ‘‡3. And the leaves of ğ‘‡4are all\nlabeled with ğ‘‡4. Then, because the number of leaves of a 4-plan-tree\nis at most 8, we employ an 8-dimension vector as the decoding\nembedding to preserve the single tableâ€™s position in the tree. For\neach single tableâ€™s embedding, the leaves which are labeled as the\nsame single table will be set 1 and the others are all zeros. For\ninstance, for the left-deep plan tree (a) in the Figure 3, the decoding\nembeddings of ğ‘‡1,ğ‘‡2,ğ‘‡3,ğ‘‡4are[1,0,0,0,0,0,0,0],[0,1,0,0,0,0,0,0],\n[0,0,1,1,0,0,0,0],\n[0,0,0,0,1,1,1,1], respectively. For bushy plan tree (b), the corre-\nsponding decoding embeddings are [1,0,0,0,0,0,0,0],\n[0,1,0,0,0,0,0,0],[0,0,1,0,0,0,0,0],[0,0,0,1,0,0,0,0].\nThese two different plan trees can be derived from their embeddings.\nSince our Tran_JO generates a distribution Ë†ğ‘ƒğ‘¡at each timestamp\nğ‘¡, we can compute the KL divergence between the distribution\nË†ğ‘ƒğ‘¡and the decoding embeddings. This loss will penalize Tran_JO\nif the prediction Ë†ğ‘ƒğ‘¡is not the same as the ground truth position\nembeddings.\nThis method is also convenient to revert a tree. Given all the\ndecoding embeddings of single tables, we can note the leaves of the\ncomplete binary plan tree with the embeddings. The leaf will be\nnoted with the table name where this tableâ€™s position embedding is\n1. For example, given an embedding [1,0,0,0,0,0,0,0]ofğ‘‡1, the first\nleaf will be noted ğ‘‡1since only the first position in this embedding\nis 1. Then, if two siblings are noted the same, their parents will\nbe denoted the same as their label. While if two siblings are noted\ndifferently, their parent should be a join operation ğ‘—(ğ‘‡1,ğ‘‡2). With\nthis novel decoding method, we can not only decode left-deep\nplan trees and bushy plan trees but revert a unique tree from the\ndecoding embeddings.\n4.2 Detailed workflow of Trans_JO\nAt a high level, the Trans_JO model formulates the join order se-\nlection into a seq2seq task and uses the powerful transformer de-\ncoder [ 35] to predict the join order sequentially. We provide its\ndetailed workflow as follows.\nAssume that we have a database with ğ‘›tables (21 for IMDB\ndataset) and would like to predict the join order for a query ğ‘„cov-\nering m tables ğ‘‡1,ğ‘‡2,...,ğ‘‡ğ‘š. At each timestamp ğ‘¡,Trans_JO will\noutput a probability distribution Ë†ğ‘ƒğ‘¡corresponding to the position of\ntableğ‘‡ğ‘¡in the join order. Similar to seq2seq task in NLP, Trans_JO\ntakes two inputs at each timestamp: 1) the outputs from the encoder\nlayer, which are the single table representations (ğ‘†1,ğ‘†2,...,ğ‘†ğ‘š)\n\nA Unified Transferable Model for ML-Enhanced DBMS\nfrom the previously shared representation layer; 2) the output of\nTrans_JO from previous timestamp Ë†ğ‘ƒğ‘¡âˆ’1.\nAs described in Section 3.2, given the input data tables, SQL\nquery, and query plan, the Trans_Share can learn the interactions be-\ntween all tables and nodes in the query plan. Then, the Trans_Share\noutputs a sequence of (ğ‘†1,ğ‘†2,...,ğ‘†ğ‘š), each corresponding to a rep-\nresentation of single table distribution and all these distributions\ncontaining the interactions with other tables and nodes in the query\nplan. Analogous to the transformer for seq2seq tasks in the NLP\ndomain, the Trans_Share can be considered as an encoder, which\nmodels the interactions between tables (source language in NLP)\nand provides an encoding for them. The Trans_JO can be consid-\nered as a decoder, which decodes the information and provides a\nsequence of join order for these tables (target language in NLP).\nDuring training, the optimal join order ğ‘ƒ1,ğ‘ƒ2,...,ğ‘ƒğ‘šwill be pro-\nvided as the ground truth. A cross-entropy loss will be calculated\nbetween each pair of ğ‘ƒğ‘–and Ë†ğ‘ƒğ‘–and the gradient will be backpropa-\ngated to update the parameters of Trans_Share andTrans_JO . We\nalso use the â€œteacher forcingâ€ strategy [] to help our model avoid\nexposure bias in the seq2seq learning procedure and effectively\nlearn the join order selection task. Assume that there are ğ‘›tables in\nthe DB, the output distribution Ë†ğ‘ƒğ‘¡is formulated as an n-dimension\nvector. Each dimension of Ë†ğ‘ƒğ‘¡corresponds to a specific table. And\neach value on the corresponding dimension is the probability that\nthis table should be selected. At each timestamp, we choose the\ntable whose value is the largest as the predicted table to be joined\nwith previous tables. After decoding, we can obtain the predicted\njoin order. Note that our predicted join order is guaranteed to be\nlegal and executable by using our novel beam-search algorithm\nwhich will be introduced in the following section 3.\n4.3 Join order beam search algorithm\nIn this section, we will introduce the application of the Beam Search\nalgorithm on Trans_JO and the method which can ensure the legal-\nity of output.\nAs described above, because we only consider the left-deep plan,\nTrans_JO can be thought of as a seq2seq task which means that\nthe process of generating join order is equivalent to generating a\nsequence, i.e. the table in Trans_JO can be analogous to the word\nin machine translation. On the one hand, choosing the table with\nthe maximum conditional probability at each generation step is\neasier to fall into local optimum. On the other hand, the only result\ngenerated by our model may not be legal which can be defined\nthat plan with this join order can not be executed in DB, i.e. there\ndoes not exist join keys between two tables. Thus we design a\npruning strategy based on beam search which not only expands the\nexploration space but also ensures the legitimacy of the generated\nresult. So that the certain legal output we generate is more likely\nto approach the optimum.\nTo be specific, we usually take the top ğ‘˜, which is generally\ncalled beam width, tables as candidates for further expansion in\nthe conditional probability distribution of the next table at each\ntime step, and each exploration branch stops until all tables have\nbeen traversed. We finally choose the join order with the maximum\nprobability among candidates as result. Mathematically, the number\nof candidates will be ğ‘˜ğ‘›âˆ’ğ‘˜âˆ—ğ‘˜!if table number is ğ‘›and beamwidthis set toğ‘˜and assuming ğ‘›>ğ‘˜, and we typically set the upper\nlimit due to the excessive number. Note that a SQL query with join\ncondition offers the information of relationship among involved\ntables, i.e. movie_info.movie_id = title.id suggests that there is a join\nkey between movie_info andtitle. Thus we utilize this relationship\nto construct a corresponding adjacency matrix for each query. And\nin the process of beam search, we only choose candidates from\ntables having join key with current joined table in accordance with\nthis matrix at each time step. After selection, we perform AND\noperation on the adjacency vector of the selected table and current\njoined table. Until all legal tables have been selected, we will acquire\na legal candidate set to choose the best one. In that way, we ensure\nthe final join order is executable.\n5 NOVEL SEQUENTIAL LOSS CRITERIA FOR\nJOIN ORDER\nIn this section, we propose a novel loss function for the join order\nselection task, which is inspired by the works in NLP domain on\nsequential loss functions [28].\nWe observe that the model Trans_JO is trained by a token-level\nloss function described in Section 3.2 but later decoded using a\nsequence-level beam search algorithm as described in Section 4.3.\nThe token-level join order loss function is less effective because\nit only maximizes the conditional probability of one table in the\njoin order but does not optimize the quality of the entire join order\nsequence. Therefore, we need to design a new sequence-level loss\ncriterion to evaluate the overall join order quality as a sequence,\nupdate the model parameter accordingly, and force the model to\noutput a more effective join order.\nJoin order evaluation understudy: Inspired by the well-recognized\nevaluation criterion for a sequence of natural language: bilingual\nevaluation understudy (BLEU) ??, we first design an evaluation cri-\nterion to measure the difference between the generated join order\nsequence and the optimal sequence, namely Join order evaluation\nunderstudy (JOEU).\nJOEU is motivated by the observation that if the partial join order\nof tables up to the current timestamp ğ‘¡is not optimal, the overall\njoin order can not be optimal regardless of the table orders after ğ‘¡.\nTherefore, we define ğ½ğ‘‚ğ¸ğ‘ˆ(ğ‘¢,ğ‘¢âˆ—)as the length of the same prefix\nof the two join order sequences ğ‘¢andğ‘¢âˆ—divided by the sequence\nlength. The larger JOEU of generated join order, the closer it is to\nthe optimal join order and more likely to produce better run-time\nperformance.\nSequence-level join order loss criterion: Based on beam search\nand JOEU, we design a novel sequence-level loss function, as shown\nin Equation 3, where ğ‘¥is the input,U(ğ‘¥)is the candidate set of\nlegal join order generated by beam search, U(ğ‘¥)is the set of illegal\njoin orders generated by beam search and ğ‘¢âˆ—is the optimal join\norder (i.e. training label).\nThe loss function consists of three parts. The first part measures\nthe negative log-likelihood of the optimal join order, which we\nwould like to minimize so that the model is more likely to produce\noptimal join order. The second part is a weighted summation of\nall legal join order sequences. Recall that ğ½ğ‘‚ğ¸ğ‘ˆ(ğ‘¢,ğ‘¢âˆ—)is a value\nbetween 0and1, with 1indicating the optimal join order sequence.\nTherefore, we want to minimize the likelihood of all join order\n\nZiniu Wu2, Pei Yu#,1,4, Peilun Yang#,1,3, Rong Zhu1, Yuxing Han1, Yaliang Li1, Defu Lian4, Kai Zeng1, Jingren Zhou1\nTable 1: Q-errors on the JOB workload.\nMethodCardinality Cost\nmedian max mean median max mean\nPostgreSQL 184.00 670,000 10,416 4.90 4920 105.00\nTree-LSTM 8.78 696.29 36.83 4.00 290.35 15.01\nMTMLF-QO 4.48 614.45 28.69 2.10 37.54 4.20\nMTMLF-CardEst 5.12 804.48 36.66\\ \\ \\\nMTMLF-CostEst \\ \\ \\ 2.06 61.41 4.69\nTable 2: Execution time with different join orders.\nJoinOrder Total Time Overall Improvement Ratio\nPostgreSQL 1143.2 min \\\nOptimal 209.1 min 81.7%\nMTMLF-QO 318.3 min 72.2%\nMTMLF-JoinSel 450.4 min 60.6%\nsequences with small ğ½ğ‘‚ğ¸ğ‘ˆ(ğ‘¢,ğ‘¢âˆ—). The third part penalizes illegal\njoin orders. The penalty ğœ†is usually set to a large value to ensure the\nmodel would be less likely to output illegal join order. Intuitively,\nminimizing theLğ½ğ‘‚can maximize the occurrence probability of\nthe optimal join order and minimize the likelihood of both not\noptimal but legal join order and illegal join order.\nLğ½ğ‘‚=âˆ’ğ‘™ğ‘œğ‘”(ğ‘(ğ‘¢âˆ—|ğ‘¥))+âˆ‘ï¸\nğ‘¢âˆˆU(ğ‘¥)(1âˆ’ğ½ğ‘‚ğ¸ğ‘ˆ(ğ‘¢,ğ‘¢âˆ—))âˆ—ğ‘™ğ‘œğ‘”(ğ‘(ğ‘¢|ğ‘¥))\n+ğœ†âˆ—ğ‘™ğ‘œğ‘”âˆ‘ï¸\nğ‘¢âˆˆU(ğ‘¥)ğ‘(ğ‘¢|ğ‘¥) (3)\n6 EXPERIMENTAL RESULTS\nWe first evaluate the performance of MTMLF-QO for a single DB on\nCardEst, CostEst, and JoinSel tasks and the effectiveness of multi-\ntask joint training (Section 6.1). Then, we provide a data generation\npipeline to generate artificial DBs (Section 6.2). These DBs will\nbe used to evaluate the cross-DB â€œtransferabilityâ€ of MTMLF-QO\ntrained via MLA (Section 6.3).\n6.1 Experiments on single DB\nWe use the JOB benchmark of 113queries joining dozens of tables\nand having the complex â€œLIKEâ€ predicates on the IMDB dataset\ncontaining 21tables with skewed distribution and strong attribute\ncorrelation [ 18]. Following the prior work [ 32], we generate 150K\nSQL queries similar to the JOB queries as the training data. Then,\nwe execute these queries in PostgreSQL [ 9] to derive the query\nplans and their true cardinalities and costs. For the JoinSel task,\nwe generate the optimal join order using the ECQO program [ 34].\nSince deriving optimal join order has exponential time complexity,\nwe can only afford to execute this program for 20K queries out of\nthe150K, which touches no more than 8tables.\nHyperparameters of MTMLF-QO: We use a transformer with\n3 blocks and 4 headers for each ğ¸ğ‘›ğ‘ğ‘–, the Trans_Share and the\nTrans_JO . We use two-layer MLPs for M_CardEst andM_CostEst .\nThe weights ğ‘¤ğ‘ğ‘ğ‘Ÿğ‘‘,ğ‘¤ğ‘ğ‘œğ‘ ğ‘¡, andğ‘¤ğ‘—ğ‘œare all set to 1. The Adam opti-\nmizer [ 14] with 10âˆ’4learning rate is used to optimize the model. All\nexperiments are conducted on a CentOS Server with an Intel XeonPlatinum 8163 2.50GHz 64-core CPU, 376GB DDR4 main memory,\nand 1TB SSD and GeForce RTX 2080 Ti GPU.\nPerformance on CardEst and CostEst: In order to show the ef-\nfectiveness of our MTMLF-QO model on CardEst and CostEst tasks,\nwe compare it with a traditional DBMS PostgreSQL [ 9], and the\nprevious SOTA method Tree-LSTM [ 32] on the JOB benchmark.\nPlease note that we can not compare MTMLF-QO with other unsu-\npervised SOTA methods [ 13,37,43] because they can not support\nâ€œLikeâ€ predicates on strings [11].\nWe take 90% of generated 150K queries as the training dataset,\n10% as the validation set for hyper-parameter tuning, and JOB\nqueries as the test set. We use q-error as the metric to evaluate car-\ndinality and cost estimation. As shown in Table 1, our MTMLF-QO\nsignificantly outperforms the traditional DBMS and the previous\nSOTA Tree-LSTM on both CardEst and CostEst tasks.\nPerformance on JoinSel: To evaluate the quality of the join order\ngenerated by MTMLF-QO, we use 85%of the 20K queries to train,\n10%of the queries to find the hyper-parameter, and the rest 5%as\nthe test set to predict the optimal join orders. Note that, we refrain\nfrom testing on the original JOB queries because MTMLF-QO only\nhas access to queries joining no more than 8tables.\nWe compare the quality of the join order generated by MTMLF-\nQO against two baselines: the original PostgreSQLâ€™s query opti-\nmizer and the optimal join order produced by ECQO. Table 2 shows\nthe results of query execution time using different join orders,\nwhere â€œtotal timeâ€ is the total running time of all 1,000testing\nqueries, and â€œoverall improvement ratioâ€ refers to the improvement\nover the PostgreSQL divided by the PostgreSQL total time.\nBased on this table, we can see that the learned join order of\nMTMLF-QO can significantly outperform the PostgreSQL baseline.\nIn addition, for more than 70% of the 1,000testing queries, MTMLF-\nQO can output the optimal join order. These results indicate that\nMTMLF-QO can be a very effective learned query optimizer of\nPostgreSQL. We left the comparison of MTMLF-QO with other\nSOTA join order selection methods [10, 21, 23, 40] as future work.\nBenefits of multi-task joint training: In order to demonstrate\nthe benefits of multi-task joint training of MTMLF-QO, we con-\nduct an ablation experiment to separately train the MTMLF-QO\nmodel for CardEst (MTMLF-CardEst), CostEst (MTMLF-CostEst),\nand JoinSel (MTMLF-JoinSel). According to Table 1 and Table 2, the\nperformance of MTMLF-JoinSel is much worse than the original\nMTMLF-QO, and MTMLF-CardEst and MTMLF-CostEst are slightly\nworse than MTMLF-QO. This suggests that the joint training of\nCardEst, CostEst, and JoinSel tasks is indeed more effective than\nthe separate training.\n6.2 Data generation pipeline\nSince there exists a very limited number of real-world DBs open\nto the research community, we have to generate artificial DBs to\nverify the cross-DB transferability of MTMLF-QO. Specifically, we\ndesign a data generation pipeline that can automatically generate\nDBs containing 6âˆ’11tables with varied numbers of attributes\nand very different distributions. We provide the details of how this\npipeline generates one DB step by step as follows.\n\nA Unified Transferable Model for ML-Enhanced DBMS\nTable 3: Execution time with different join orders.\nJoinOrder Total Time Overall Improvement Ratio\nPostgreSQL 393.9 min \\\nMTMLF-QO (MLA) 234.1 min 40.6%\nMTMLF-QO (single) 219.5 min 44.3%\nS1: Generate a valid join schema J.The first step of generating\na DBDwill be deciding how many tables should this DB contain\nand what is the join relationship between these tables. We first\nuniformly sample a number ğ‘›ranging from 6 to 11 and create ğ‘›\nempty tables{ğ‘‡1,Â·Â·Â·,ğ‘‡ğ‘›}. Then, we pick 2âˆ’3tables as the fact\ntables and the rest tables as dimension tables. W.L.O.G assume that\nğ‘‡1,ğ‘‡2are the fact tables and ğ‘‡3,Â·Â·Â·,ğ‘‡ğ‘›are the dimension tables.\nWe create the first join relation between ğ‘‡1â€™s primary key and ğ‘‡2â€™s\nforeign key. For each of the dimension table ğ‘‡ğ‘–, we create a join\nrelation between ğ‘‡ğ‘–andğ‘‡1,ğ‘‡2or both. At last, each dimension table\nwill connect with one or two fact tables, i.e., primary key/foreign key\njoin relation (PK-FK). There does not exist any PK-FK join relation\nbetween the dimension tables but they can be joined through a\ntransitive FK-FK join. For example, if both foreign keys ğ¹ğ¾3ğ‘‡1of\nğ‘‡3andğ¹ğ¾4ğ‘‡1ofğ‘‡4can join with the primary key ğ‘ƒğ¾1ofğ‘‡1, then\nğ¹ğ¾3ğ‘‡1andğ¹ğ¾4ğ‘‡1can form a FK-FK join relation. Next, we discuss\nhow to fill in the content of each table ğ‘‡ğ‘–.\nS2: Generate attribute columns for ğ‘‡ğ‘–.We first randomly gen-\nerate two numbers ğ‘Ÿandğ‘to be the total number of rows (between\n50ğ¾to10ğ‘€) and attribute columns (between 2to20) inğ‘‡ğ‘–. Then,\nwe generate the attribute columns of ğ‘‡ğ‘–using two approaches. The\nfirst approach is completely artificially-generated with varied data\ndistribution skewness, attributes correlation, and domain size. This\napproach is similar to recent works [ 36,37]. The second approach\nbootstraps from an existing real-world data table. By controlling the\ndistribution of the number of bootstrapping rows and columns, we\ncan create data distribution with varied skewness and correlation\nbut the domain remains the same as the original table. In this way,\nthe generated data mimics the real-world one.\nS3: Generate join keys for ğ‘‡ğ‘–.We first create a column of pri-\nmary key (PK) for ğ‘‡ğ‘–(unique value from 1 to ğ‘Ÿ). Creating the\ncolumns of foreign keys (FK) is much more complicated. First, we\nneed to identify from the join schema Jall the fact tables that can\njoin withğ‘‡ğ‘–. Then,ğ‘‡ğ‘–creates a column ğ¹ğ¾ğ‘–ğ‘—of FK for each fact\ntableğ‘‡ğ‘—with a domain equal to the PK domain of ğ‘‡ğ‘—. Since the join\nkeys are correlated with the attribute columns [ 18], we will make\nthe values of ğ¹ğ¾ğ‘–ğ‘—correlate with attributes in ğ‘‡ğ‘–.\n6.3 Experiments on cross-DB transferrability\nExperiment procedures: We use the aforementioned pipeline to\ngenerate 11 DBs{D1,...,D11}. For each DBDğ‘–, we create a work-\nloadğ‘Šğ‘–of20ğ¾join queries and execute the ECQO program [ 34] to\nderive its optimal join order.\nThe hyper-parameters of MTMLF are the same as described in\nSection 4.1 of the main paper. The training of the MTMLF follows\nthe MLA procedure. Specifically, we first generate some single-table\nqueries for each table within each DB Dğ‘–. Then, we learn a featur-\nization module ğ¹ğ‘–for every DB to capture all the dataset-specific\nknowledge such as the single table distributions. The procedureof training each ğ¹ğ‘–is very efficient since the single table query\ncan be efficiently executed in parallel or using AQP techniques.\nW.L.O.G., we use the first 10 DBs {D1,...,D10}as the training\ndata and learns the (S) shared representation and (T) task-specific\nmodules for the MTMLF via MLA. These two modules can output\neffective join orders for all 10DBs. Thus, it must have captured the\ndataset-agnostic knowledge that can be transferred to a new DB.\nWe useD11as testing data to verify the transferability of MTMLF.\nSpecifically, we connect the learned ğ¹11module containing all\ndataset-specific information of D11with the pre-trained (S) and\n(T) modules. Then, we use this MTMLF model to generate the join\norder of queries in ğ‘Š11and execute these join orders in PostgreSQL.\nEffectiveness of MTMLF-QOâ€™s meta-learning: From Table 3, we\nobserve that the MTMLF-QO trained via MLA can generate join\norders that are 40%faster than the ones produced by PostgreSQL\nbaseline on a brand new DB. As a controlled study, we directly\ntrain an MTMLF-QO on this test DB Dfrom scratch (MTMLF-QO\nsingle), which is only slightly better than MTMLF-QO trained via\nMLA. These results suggest that MTMLF-QO can distill cross-DB\nmeta-knowledge that is transferrable to new DBs.\n7 CONCLUSIONS\nIn this paper, we present the MTMLF, which can condense an ef-\nfective shared representation to mutually benefit various tasks in\nDBMS and distill the â€œmeta-knowledgeâ€ beneficial to all DBs. We\nalso demonstrate with a very promising case study on query opti-\nmization that future research along this direction can be fruitful.\nNext, we list two concrete future research opportunities. First,\ninspired by MTMLF-QO, other DBMS tasks can also be incorporated\ninto the MTMLF framework. Second, a cloud DB service can greatly\nfacilitate the pre-train fine-tune paradigm of MTMLF. This setting\nmotivates the research community to design a federated learning\nalgorithm to protect the DB usersâ€™ data privacy and simultaneously\nensure effective training of MTMLF.\nREFERENCES\n[1] Debabrota Basu, Qian Lin, Weidong Chen, Hoang Tam Vo, Zihong Yuan, Pierre\nSenellart, and StÃ©phane Bressan. 2016. Regularized cost-model oblivious database\ntuning with reinforcement learning. In Transactions on Large-Scale Data-and\nKnowledge-Centered Systems XXVIII . Springer, 96â€“132.\n[2]Nicolas Boulanger-Lewandowski, Yoshua Bengio, and Pascal Vincent. 2013. Audio\nChord Recognition with Recurrent Neural Networks. In ISMIR . Citeseer, 335â€“340.\n[3]Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\nPrafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, et al .2020. Language models are few-shot learners. arXiv preprint\narXiv:2005.14165 (2020).\n[4]Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020. Turl: Table\nunderstanding through representation learning. arXiv preprint arXiv:2006.14806\n(2020).\n[5]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:\nPre-training of deep bidirectional transformers for language understanding. arXiv\npreprint arXiv:1810.04805 (2018).\n[6]Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\net al.2020. ALEX: an updatable adaptive learned index. In Proceedings of the 2020\nACM SIGMOD International Conference on Management of Data . 969â€“984.\n[7]Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. 2020.\nTsunami: A learned multi-dimensional index for correlated data and skewed\nworkloads. arXiv preprint arXiv:2006.13282 (2020).\n[8]Alex Graves. 2012. Sequence transduction with recurrent neural networks. arXiv\npreprint arXiv:1211.3711 (2012).\n[9]The PostgreSQL Global Development Group. 2018. Documentation PostgreSQL\n10.3.\n\nZiniu Wu2, Pei Yu#,1,4, Peilun Yang#,1,3, Rong Zhu1, Yuxing Han1, Yaliang Li1, Defu Lian4, Kai Zeng1, Jingren Zhou1\n[10] Runsheng Benson Guo and Khuzaima Daudjee. 2020. Research challenges in\ndeep reinforcement learning-based join query optimization. In Proceedings of the\nThird International Workshop on Exploiting Artificial Intelligence Techniques for\nData Management . 1â€“6.\n[11] Yuxing Han, Ziniu Wu, Peizhi Wu, Rong Zhu, Jingyi Yang, Liang Wei Tan, Kai\nZeng, Gao Cong, Yanzhao Qin, Andreas Pfadler, et al .2021. Cardinality Es-\ntimation in DBMS: A Comprehensive Benchmark Evaluation. arXiv preprint\narXiv:2109.05877 (2021).\n[12] Jonathan Herzig, PaweÅ‚ Krzysztof Nowak, Thomas MÃ¼ller, Francesco Piccinno,\nand Julian Martin Eisenschlos. 2020. Tapas: Weakly supervised table parsing via\npre-training. arXiv preprint arXiv:2004.02349 (2020).\n[13] Benjamin Hilprecht, Andreas Schmidt, Moritz Kulessa, Alejandro Molina, Ker-\nsting Kristian, and Carsten Binnig. 2020. DeepDB: Learn from Data, not from\nQueries! PVLDB (2020).\n[14] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-\nmization. arXiv preprint arXiv:1412.6980 (2014).\n[15] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and\nAlfons Kemper. 2019. Learned Cardinalities: Estimating correlated joins with\ndeep learning. CIDR (2019).\n[16] Jakub KoneÄn `y, Brendan McMahan, and Daniel Ramage. 2015. Federated op-\ntimization: Distributed optimization beyond the datacenter. arXiv preprint\narXiv:1511.03575 (2015).\n[17] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In Proceedings of the 2018 International\nConference on Management of Data . 489â€“504.\n[18] Viktor Leis, Andrey Gubichev, Atanas Mirchev, Peter Boncz, Alfons Kemper, and\nThomas Neumann. 2015. How Good Are Query Optimizers, Really? Proc. VLDB\nEndow 9 (2015), 204â€“215.\n[19] Guoliang Li, Xuanhe Zhou, Shifu Li, and Bo Gao. 2019. Qtune: A query-aware\ndatabase tuning system with deep reinforcement learning. Proceedings of the\nVLDB Endowment 12, 12 (2019), 2118â€“2130.\n[20] Lin Ma, Bailu Ding, Sudipto Das, and Adith Swaminathan. 2020. Active learning\nfor ML enhanced database systems. In Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data . 175â€“191.\n[21] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A learned\nquery optimizer. PVLDB (2019).\n[22] Ryan Marcus and Olga Papaemmanouil. [n.d.]. Wisedb: A learning-based work-\nload management advisor for cloud databases. PVLDB ([n. d.]), 780â€“791.\n[23] Ryan Marcus and Olga Papaemmanouil. 2018. Deep reinforcement learning for\njoin order enumeration. In Proceedings of the First International Workshop on\nExploiting Artificial Intelligence Techniques for Data Management . 1â€“4.\n[24] Ryan Marcus and Olga Papaemmanouil. 2019. Plan-structured deep neural net-\nwork models for query performance prediction. arXiv preprint arXiv:1902.00132\n(2019).\n[25] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learn-\ning multi-dimensional indexes. In Proceedings of the 2020 ACM SIGMOD Interna-\ntional Conference on Management of Data . 985â€“1000.\n[26] Parimarjan Negi, Ryan Marcus, Andreas Kipf, Hongzi Mao, Nesime Tatbul, Tim\nKraska, and Mohammad Alizadeh. 2021. Flow-Loss: Learning Cardinality Esti-\nmates That Matter. arXiv preprint arXiv:2101.04964 (2021).\n[27] Jennifer Ortiz, Magdalena Balazinska, Johannes Gehrke, and S Sathiya Keerthi.\n2018. Learning state representations for query optimization with deep reinforce-\nment learning. In Proceedings of the Second Workshop on Data Management for\nEnd-To-End Machine Learning . 1â€“4.\n[28] Marcâ€™Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba.\n2015. Sequence level training with recurrent neural networks. arXiv preprint\narXiv:1511.06732 (2015).\n[29] Yangjun Sheng, Anthony Tomasic, Tieying Zhang, and Andrew Pavlo. 2019.\nScheduling OLTP transactions via learned abort prediction. In Proceedings of the\nSecond International Workshop on Exploiting Artificial Intelligence Techniques for\nData Management . 1â€“8.\n[30] Vighnesh Shiv and Chris Quirk. 2019. Novel positional encodings to enable\ntree-based transformers. Advances in Neural Information Processing Systems 32\n(2019), 12081â€“12091.\n[31] Tarique Siddiqui, Alekh Jindal, Shi Qiao, Hiren Patel, and Wangchao Le. 2020.\nCost models for big data query processing: Learning, retrofitting, and our findings.\nInProceedings of the 2020 ACM SIGMOD International Conference on Management\nof Data . 99â€“113.\n[32] Ji Sun and Guoliang Li. 2019. An end-to-end learning-based cost estimator. arXiv\npreprint arXiv:1906.02560 (2019).\n[33] Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam\nMadden, and Mourad Ouzzani. 2020. Relational Pretrained Transformers towards\nDemocratizing Data Preparation [Vision]. arXiv preprint arXiv:2012.02469 (2020).\n[34] Immanuel Trummer. 2019. Exact cardinality query optimization with bounded\nexecution cost. In Proceedings of the 2019 International Conference on Management\nof Data . 2â€“17.[35] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\nAidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all\nyou need. In Advances in neural information processing systems (2017).\n[36] Xiaoying Wang, Changbo Qu, Weiyuan Wu, Jiannan Wang, and Qingqing\nZhou. 2020. Are We Ready For Learned Cardinality Estimation?\narXiv:2012.06743 [cs.DB]\n[37] Ziniu Wu and Amir Shaikhha. 2020. BayesCard: A Unified Bayesian Framework\nfor Cardinality Estimation. arXiv preprint arXiv:2012.14743 (2020).\n[38] Zongheng Yang, Amog Kamsetty, Sifei Luan, Eric Liang, Yan Duan, Xi Chen, and\nIon Stoica. 2020. NeuroCard: One Cardinality Estimator for All Tables. arxiv\n(2020).\n[39] Zongheng Yang, Eric Liang, Amog Kamsetty, Chenggang Wu, Yan Duan, Xi Chen,\nPieter Abbeel, Joseph M. Hellerstein, Sanjay Krishnan, and Ion Stoica. 2019. Deep\nunsupervised cardinality estimation. Proceedings of the VLDB Endowment (2019).\n[40] Xiang Yu, Guoliang Li, Chengliang Chai, and Nan Tang. 2020. Reinforcement\nlearning with tree-lstm for join order selection. In 2020 IEEE 36th International\nConference on Data Engineering (ICDE) . IEEE, 1297â€“1308.\n[41] Ji Zhang, Yu Liu, Ke Zhou, Guoliang Li, Zhili Xiao, Bin Cheng, Jiashu Xing,\nYangtao Wang, Tianheng Cheng, Li Liu, et al .2019. An end-to-end automatic\ncloud database tuning system using deep reinforcement learning. In Proceedings\nof the 2019 International Conference on Management of Data . 415â€“432.\n[42] Xuanhe Zhou, Chengliang Chai, Guoliang Li, and Ji Sun. 2020. Database meets\nartificial intelligence: A survey. IEEE Transactions on Knowledge and Data Engi-\nneering (2020).\n[43] Rong Zhu, Ziniu Wu, Yuxing Han, Kai Zeng, Andreas Pfadler, Zhengping Qian,\nJingren Zhou, and Bin Cui. 2021. FLAT: Fast, Lightweight and Accurate Method\nfor Cardinality Estimation. VLDB (2021).",
  "textLength": 64328
}