{
  "paperId": "c7b15ef0019af2df5f11bb5d906657f65727a4af",
  "title": "ML-AQP: Query-Driven Approximate Query Processing based on Machine Learning",
  "pdfPath": "c7b15ef0019af2df5f11bb5d906657f65727a4af.pdf",
  "text": "ML-AQP: Query-Driven Approximate Query\nProcessing based on Machine Learning\nFotis Savva\nUniversity of Glasgow\nGlasgow, UK\nf.savva.1@research.gla.ac.ukChristos\nAnagnostopoulos\nUniversity of Glasgow\nGlasgow, UK\nchristos.anagnostopoulos@glasgow.ac.ukPeter Triantafillou\nUniversity of Warwick\nWarwick, UK\np.triantafillou@rwarwick.ac.uk\nABSTRACT\nAs more and more organizations rely on data-driven decision\nmaking, large-scale analytics become increasingly important.\nHowever, an analyst is often stuck waiting for an exact re-\nsult. As such, organizations turn to Cloud providers that\nhave infrastructure for efficiently analyzing large quantities\nof data. But, with increasing costs, organizations have to op-\ntimize their usage. Having a cheap alternative that provides\nspeed and efficiency will go a long way. Concretely, we offer\na solution that can provide approximate answers to aggre-\ngate queries, relying on Machine Learning (ML), which is\nable to work alongside Cloud systems. Our developed light-\nweight ML-led system can be stored on an analystâ€™s local\nmachine or deployed as a service to instantly answer analytic\nqueries, having low response times and monetary/compu-\ntational costs and energy footprint. To accomplish this we\nleverage the knowledge obtained by previously answered\nqueries and build ML models that can estimate the result\nof new queries in an efficient and inexpensive manner. The\ncapabilities of our system are demonstrated using extensive\nevaluation with both real and synthetic datasets/workloads\nand well known benchmarks.\nACM Reference Format:\nFotis Savva, Christos Anagnostopoulos, and Peter Triantafillou.\n2018. ML-AQP: Query-Driven Approximate Query Processing based\non Machine Learning. In Woodstock â€™18: ACM Symposium on Neural\nGaze Detection, June 03â€“05, 2018, Woodstock, NY. ACM, New York,\nNY, USA, 18 pages. https://doi.org/10.1145/1122445.1122456\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are not\nmade or distributed for profit or commercial advantage and that copies bear\nthis notice and the full citation on the first page. Copyrights for components\nof this work owned by others than ACM must be honored. Abstracting with\ncredit is permitted. To copy otherwise, or republish, to post on servers or to\nredistribute to lists, requires prior specific permission and/or a fee. Request\npermissions from permissions@acm.org.\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nÂ©2018 Association for Computing Machinery.\nACM ISBN 978-1-4503-9999-9/18/06. . . $15.00\nhttps://doi.org/10.1145/1122445.1122456\n1 5 10 20 50\nSize/uni00A0(TB)0500010000150002000025000Cost/uni00A0($)Queries\n10\n40\n80\n100Figure 1: Costs associated with using cloud-managed\ndatabases (BigQuery). The x-axis is the amount of data\nused per query and the y-axis is the associated costs\nwith the average number of queries daily.\n1 INTRODUCTION\nWith the rapid explosion of data volume and the adoption of\ndata-driven decision making, organizations are struggling\nto analyze data efficiently and inexpensively. Hence, a lot\nof companies turn to Cloud providers that maintain large-\nscale data warehouses [ 25,52] able to store and process large\nquantities of data. But, the problem still remains: as mul-\ntiple queries are issued by multiple analysts, clusters are\noften overburdened and costs rise significantly. For instance,\nlooking at Figure 1, we can observe the exponential costs\nassociated with an increasing data size. The associated cost\n(in y-axis) is obtained after multiplying the cost of scan-\nning an amount of data (in x-axis) with varying number of\nqueries shown as colored bars1. Most importantly, during\ndata analysis, it is of high importance to be able to extract\ninformation without significant delays so as to not break the\ninteractivity constraint , which is set around 500ms [ 40]. This\nconstraint supports that any answers returned over that limit\ncan have negative effects on an analystâ€™s experience and pro-\nductivity. Concretely, analysts often engage in what is called\nexploratory analysis [29] in order to better understand the\ndata. Such analyses are an invariable step in the process of\nfurther constructing hypotheses or constructing and training\n1Data For this graph are obtained from https://cloud.google.com/bigquery/\npricingarXiv:2003.06613v1  [cs.DB]  14 Mar 2020\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\npredictive and inferential models to answer business ques-\ntions. A key to these analyses is that an approximate answer\nto any query is often enough to move forward. As such, over\nthe last few decades research has focused into systems that\nallow Approximate Query Processing (AQP)[ 9,24,31,48]\nto facilitate the process of data analysis with this in mind.\nBy trading off some of the accuracy they allow for order of\nmagnitude speed-ups in execution.\nAlthough AQP systems offer a straight-forward and effi-\ncient solution to the problem of efficiently processing queries,\nthey come at a cost. They require large samples and would\nhave to reside in the same Cloud system which makes them\ncostly to maintain as every operation carries a cost. In addi-\ntion, in cases where multiple analysts are using the Cloud\nsystem or AQP engine to process queries, they might be\nstuck waiting for their job to execute as multiple operations\ncould be in the queue. Hence, what we propose is a comple-\nmentary system to that of AQP engines addressing some of\ntheir shortcomings and better highlighting their strengths.\nWe envision a system that is computationally lightweight\nand can be stored in an analystâ€™s machine or in a central\nserver, away from the main backend analytic system of\nchoice. This allows for the exploratory process to be exe-\ncuted locally at the analystâ€™s machine, without overburden-\ning the cloud system, thus, saving up resources (and money)\nto be used in cases where accurate answers are needed. From\nthe cloud providerâ€™s standpoint, our solution could act as a\npseudo -caching mechanism to reduce load when it is neces-\nsary thus allowing for other operations to run.\nWhat makes such a system possible, and the salient feature\nof our approach, is the availability of a number of previously\nexecuted queries (in log files). Leveraging previously exe-\ncuted queries allow for the creation of Machine Learning\n(ML) models that can estimate the results of new unseen\nqueries. As exploratory analysis is often made up of opera-\ntions that filter the data and then return descriptive statistics\n(aggregates) on the resulting subsets, we can construct ML\nmodels that predict such statistics. An ML model can effec-\ntively learn to associate the input parameter values of a query\nwith the obtained result. Subsequent predictions can then be\nmade in milliseconds, thus, fulfilling the interactivity con-\nstraint. In addition, most ML models are orders of magnitude\nlighter and can be stored on any device.\nThe desiderata are: Derived models are lightweight (in\nterms of memory footprint), easy to configure and fast to\ntrain, supporting error guarantees for their predictions, able\nto deal with updates to both query patterns and DB updates,\nable to handle all types of aggregate functions (AFs), and en-\nsure high accuracy. Lastly, such mechanism does not require\naccess to any of the data neither at training time, as is the case\nwith current sampling-based and ML-based AQP approaches,\nnor at prediction time as what is being queried is the actualtrained model. Concretely, our technical contributions are\nas follows:\nâ€¢A flexible vectorized representation for (SQL) queries,\nto be used by ML models;\nâ€¢The first AQP engine (ML-AQP) that mines query logs\n(query-driven) and develops ML models meeting all\nabove desiderata;\nâ€¢Up to 5 orders of magnitude greater efficiency than\nthe state of the art sampling-based techniques;\nâ€¢A new method for providing probabilistic error guar-\nantees, based on Quantile Regression to complement\napproximate answers;\nâ€¢Support for all AFs (including MIN/MAX which cannot\nbe supported by current approaches);\nâ€¢A comprehensive performance evaluation using syn-\nthetic and several real-world data sets and workloads\nwhich substantiate performance claims.\n2 PRELIMINARIES AND SUPPORTED\nQUERIES\nWe abstract every (back-end) Cloud analytics system (both\nrelational and non-relational) as a black box. Thus, essen-\ntially, queries are regarded as executing over sets of multi-\ndimensional points2to which a number of operations are\nperformed to return a result. Both non-relational andrela-\ntional databases can be considered as large collections of\nattributes either grouped in a collection of normalized tables\nor being part of a single de-normalized data set. We can store\nour data in either of the two settings and the result of a query\nwill still be the same. It is just the way of performing data\nmanipulation and aggregation that differs. In the remainder\nof this section, we demonstrate how common operations in\na relational schema can be performed using our proposed\nrepresentation. This is without loss of generality to any kind\nof data-storage system and it is merely used as the abstrac-\ntion should be familiar to the reader. Given the above, our\nfirst concern is to develop an appropriate representation for\nqueries so that an ML model can associate the query repre-\nsentation with the query results and learn to predict answers\nfor â€™similarâ€™ queries.\nDefinition 1. (Data & Attributes) As we are unaware of\nthe underlying data storage format, we adopt a generic as-\nsumption of all data being collections of attributes, where a\ndatasetBis a collection of real-valued d-dimensional vectors\na=(a1, . . . , ad), such thatB={a}n\ni=1. The avector holds\nvalues for dattributes.\nDefinition 2. (Aggregate Functions) Aggregate Functions\n(AF) are applied to the returned result-set and mapping a set of\nreturned values to a scalar result yâˆˆR. An AF can be applied\n2A single row in a table can be considered as a multi-dimensional point\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nto a specific attribute; AFs commonly include functions such\nasCOUNT ,AVG,SUM. They are typically used in an SQL-style\nquery along with various predicates and joins.\nDefinition 3. (Predicates) Predicates are used to restrict the\nnumber of rows (data vectors) returned by a query. Predicates\ncan be considered as a sequence of negations, conjunctions,\nand disjunctions (Â¬,âˆ¨,âˆ§) over attributes with equality and/or\ninequality constraints ( â‰¤,â‰¥,=). A well known predicate is\nthe range-predicate. A range-predicate effectively restricts an\nattribute aito be within a given range [ lb,ub] with aiâ‰¥\nlbâˆ§aiâ‰¤ub. To effectively model a sequence of predicates, we\nassign two meta-attributes for each attribute aiand consider\nevery predicate as a range-predicate. The two meta-attributes\nare equal to the [ lb,ub] of a range-predicate. For instance,\nwithout loss of generality, assume the three following predicates\napplied on a dataset with a single attribute a1: (1)a1â‰¥lb, (2)\na1=c, where cis a numerical value, and (3) a1â‰¥lbâˆ§a1â‰¤ub.\nWe construct two meta-attributes for each case as follows: (1)\n(a1,lb,âˆ’), whereâˆ’could be set to NULL anda1,lbis the supplied\nlbvalue, (2)(a1,c,a1,c), where a1,c=c, and (3)(a1,lb,a1,ub).\n2.1 Transforming Aggregate Queries to\nVectors\n2.1.1 SPA Queries. We first consider Selection-Projection-\nAggregate (SPA) queries, in which a single aggregate is the\nresult of a query; that is made up of a single relation and mul-\ntiple predicates. Given our definition of predicates, we obtain\na meta-vector which is made up of all the constraints m=\n(a1,lb,a1,ub, . . . , ad,lb,ad,ub)across all attributes. Hence, each\nSPA query can be represented by a meta-vector mâˆˆR2d.\nFor all attributes that are part of the data set but not part\nof the query we leave the values of their associated meta-\nattributes as NULL . For instance, a simple SPA aggregate\nquery is the following applied over a data set Bwith at-\ntributes a=(a1,a2,a3):\nSELECT AF( ai)\nFROMB\nWHERE a1â‰¥x1âˆ§a2â‰¤x2\nThe meta-vector is m=(x1,NULL ,NULL ,x2,NULL ,NULL).\n2.1.2 SPJA Queries. To effectively model SPJA (Selection-\nProjection-Join-Aggregate) queries we first redefine what\nit means to join two or more tables together from a query\nrepresentation perspective. We assume an architecture in\nschema design where, if multiple tables exist, then these ta-\nbles are made up of a large facttable along with much smaller\ndimension tables. This is widely accepted in the literature\n[9,26,48]. Specifically, in a designed AQP system by Google\n[26] it is mentioned that all queried relations are pre-joinedso that JOINs are not performed at query runtime. As a re-\nsult, a data analyst simply queries the large fact table using\nequi-joins whenever they wish to project more attributes\nto the result set. Therefore, the dimensionality of the initial\nrow (data vector) obtained from the facttable is simply in-\ncreased. However, it is evident that the result set is still only\naffected by the predicates in the selection. Assuming these\nkind of JOINs and that the number of rows is not affected by\nthe resulting JOIN our initial representation is appropriate\nwithout any changes.\n2.1.3 GROUP-BY Queries. Supporting GROUP-BY queries is\ncrucial for data analytics, as analysts often issue queries to ex-\nplore differences between cohorts via grouping. A GROUP-BY\nquery is an application of the same AF onto different sub-\ngroups defined by an attribute. Hence, for an attribute ai, we\nuse a DISTINCT operator to identify the different groups and\nsubsequently use the vectorization process of an SPA query\non the individual groups. The result of the operator would be\na set of group values G=(G1, . . . , Gk), which can be used\nas an equality predicate to construct kdifferent queries. An\nexample of this is shown at Figure 2. An SQL query with a\nGROUP-BY clause is issued and the colored parts of this query\nare extracted. Suppose that the group-by attribute used is\na3,a3=Ð´1. The predicate values (x1,x2,x3,x4)and the ex-\ntracted group values (G1, . . . , Gk)are used to construct k\nmeta-vectors in which the values for (a1,lb,a1,ub,a2,lb,a2,ub\ncontain the same values for all rows as the filter-predicates\nare applied for each group value G1,i. The last two columns\na3,lb,a3,ubare used to store the group values. Each one of\nthose meta-vectors will become associated with the output\nof the corresponding AF. This is similar to the formulation\nSELECT  g1, AF1(Î±3)\nFROM B \nWHERE Î±1>= x1AND Î±1<=x2\nAND Î±2>=x3AND Î±2<=x4\nGROUP BY g1\nÎ±1,lbÎ±1,lbÎ±2,lbÎ±2,ubÎ±3,lbÎ±3,ub\nx1 x2 x3 x4 g1,1 g1,1\nx1 x2 x3 x4 g1,1 g1,1\nâ€¦. â€¦. â€¦. â€¦. â€¦. â€¦.\nx1 x2 x3 x4 g1,k g1,kAF1(Î±3)\ny1\ny2\nâ€¦.\nyk\nFigure 2: How to vectorize GROUP-BY queries.\nof Database Learning [ 48]. However, we do not limit the\nnumber of generated queries to 1000 as suggested by the\nformulation of [ 48]. Hence, an arbitrarily large number of\ngroups can be supported by our formulation.\n2.1.4 Handling Categorical Attributes. Some attributes might\nhold categorical values instead of numerical. An accepted\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\napproach is to restrict the length of the categorical attributes\nto the currently longest of each categorical attribute [ 36].\nAnother option is to construct various dummy columns each\none denoting a value included in the categorical attribute\nai[37]. Suppose Ndistinct values for a1=(A1, . . . , AN), then\nNdummy columns are created, with its rows having a value\nof{0,1}, that being a mapping Aiâ†’{0,1}. However, the\ninherent problem with this option is the explosion in dimen-\nsionality of the query vector mas its dimensionalty now\nbecomes 2d+N. To this end, an effective encoding scheme\ncan be an injective function, such as various hash functions,\nthat provide an effective mapping from a categorical attribute\nto a real number, i.e., A7â†’ R. In our implementation for\nML-AQP we use a combination of both. The first technique\nis used for attributes with low cardinality <1000. For tree-\nbased ML algorithms, this has been shown to work best\n[37]. The latter technique is used for attributes with high\ncardinality >1000.\n2.2 Overall Support for Queries &\nLimitations\nOverall, with this representation we are able to support a\nlarge fraction of the aggregate queries commonly in an OLAP\nsetting, from simple multi-predicate aggregation queries to\nqueries that include JOINs and GROUP-BYs. We can provide\nsupport for foreign-key joins as this is the case for multiple\nAQP engines [ 48]. Specifically our setting does not make\nany assumptions as to what type of aggregate functions are\nused. To ML-AQP the response variable is a scalar y, associ-\nated with a meta-vector m. Subsequently it tries to identify\npatterns in mthat would allow it to predict a future ynew\nwhen given an mnew. Therefore it is agnostic to the AFs used.\nThis is in contrast to most sampling based AQP engines [ 9]\nwhich restrict the number of aggregates supported. In ad-\ndition, in the presence of textual filters ( LIKE â€™%productâ€™ )\nthe same approach to other categorical attributes can be ap-\nplied. Meaning that the pattern is considered as a string and\nencoded following the approach described at Section 2.1.4.\nFor JOINs which do not simply extend the dimensionality\nbut instead introduce less/more tuples in the result we do\nnot explicitly represent them in the current meta-vector. As\nwe described, usually such schema designs are avoided when\nconducting analyses over large amounts of data [ 26]. In addi-\ntion, derived attributes for GROUP-BYs cannot be supported\nwith our current formulation and instead such queries have\nto be partially executed to obtain the derived attributes.\n3 SYSTEM ARCHITECTURE\nFigure 3 shows holistically how ML-AQP complements the\ndata analytics stack. Our system sits between cloud-based\nSampling\n-AQPData Warehouseð‘€ð¿âˆ’ð´ð‘„ð‘ƒAccuracy\nSpeedFigure 3: The ML-AQP within the complete data an-\nalytics stack. Starting from ML-AQP, analysts can\nchoose a system going from left to right, if they re-\nquire more accuracy. If speed is essential, they can\nchoose from right to left.\ndata warehouses and/or Sampling -based AQP engines. Us-\ning all three components (ML-AQP, sampling-based AQP\nengines, data warehouses), the analyst can choose which\none to use based on their needs of efficiency and accuracy. A\nsystem could also make this choice based on the resources\navailable. Hence, if a cloud system is experiencing heavy\nloads, it could direct queries to either the sampling-based\nAQP (S-AQP) engine or ML-AQP. A useful analogy is to think\nof each of the three components as the cache ,RAM andDisk\ncomponents of a computer. Caches and RAMs can often not\nhold the data required (hence the lack of accuracy), but the\ndisk will always hold the true answer. However, this comes\nat a cost in efficiency. Therefore in our case, ML-AQP can\nact as the cache of the data analytics stack, sampling-based\nAQP engines as the RAM and finally cloud-based engines as\nthe disk.\nTo better explain the overall architecture followed in ML-\nAQP, we explain each component as part of two distinct\nmodes: (a) Training mode and (b) Prediction or Production\nmode. During Training mode, queries are either executed\nat the Data Warehouse or the S-AQP and become associ-\nated with their results. We can also utilise pre-computed\nqueries stored at log files. ML-AQP leverages those queries\nto build training sets of query-result pairs for the ML mod-\nels. Training these ML models transitions ML-AQP to the\nPrediction/Production mode to which queries are now being\ntransformed into the described vectorial representation m\nand their results are estimated by ML models.\nThe complete flow and interaction of the components, is\nshown at Figure 4. Initially, at Training mode, each query\nis parsed, through the Parser, and the projected AFs are ex-\ntracted f1, . . . , fn, along with the included predicates p1, . . . , pm\nand any GROUP-BY attributes Ð´1, . . . ,Ð´k. In the example at\nFigure 4, the extracted AF is f1=AF1(a3), the resulting\npredicates are p1=(a1â‰¥x1)andp2=(a1â‰¤x2)and the\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nParserSELECT  g1, AF1(Î±3)\nFROM B \nWHERE Î±1>= x1\nAND Î±1<=x2\nGROUP BY g1\nÎ±1,lbÎ±1,lbÎ±3,lbÎ±3,u\nbAF1(Î±3)\nx1 x2 g1,1 g1,1 y1\nx1 x2 g1,1 g1,1 y2\nâ€¦. â€¦. â€¦. â€¦. â€¦.\nx1 x2 g1,k g1,k ykAF1(Î±3)\ny1\ny2\nâ€¦.\nykData Warehouse\nð‘¸âˆˆâ„(ð‘˜,4)Model \nGenerator\nð´ð¹1(ð‘Ž3)â†’â„³1\nModel \nCatalogueAnswer\nFigure 4: ML-AQP during Training\nGROUP-BY attribute is Ð´1. For the predicates, we construct\nanmâˆˆR2dmeta-vector, where dis total number of at-\ntributes in a data set. Each meta-vector is associated with\na number of results y1, . . . ,yn, obtained from the executed\nAFs. If no GROUP-BY attributes are included then we call\nthis a single query q=(m,y),qâˆˆR2d+n. For any, GROUP-\nBY attribute Ð´iaSELECT-DISTINCT query is executed and\nits result is cached in GROUP-BY catalogue D. The cata-\nlogue Dis a mapping from the GROUP-BY attributeÐ´ito its\nset of distinct values D:Ð´iâ†’GÐ´i. Caching its result al-\nlows their reuse during Prediction/Production mode. For any\nGROUP-BY attributes that are frequently used together such\nas(Ð´i,Ð´j)we also cache their set of distinct values. Given the\nvalues returned for Ð´i,GÐ´(i)={GÐ´i,1, . . . , GÐ´i,|GÐ´i|}, we con-\nstruct multiple single-queries which have different results\nfory1, . . . ,ykas they correspond to different groups. Hence,\nin the case of GROUP-BY queries, a single query has a matrix\nrepresentation for its meta-vectors and their associated re-\nsults Q=(M,Y),QâˆˆR(|GÐ´(i)|)Ã—(2d+n), this result is shown\nat Figure 4. The same procedure occurs for each executed\nquery, which results in the collection of possibly sparse vec-\ntors (as not each attribute is often included in the predicates\nor the GROUP-BY clause). Because of this, we store all of\nthe processed queries in a sparse matrix to save space. Once\nwe finish parsing and constructing the representation for\neach query in our training set, we use the Model Generator\nto construct/train models Mi,Mnfor each AF encountered\nand an association is created AF1(a3)â†’M 1. The models are\nthen serialized and stored in a Model Catalogue .\nA similar process occurs during the Prediction/Production\nmode when a new (SQL) query is issued at the ML-AQP. The\ncomplete flow of interactions between sub-components is\nshown at Figure 5. During initialization of the ML-AQP, both\nthe GROUP-BY catalogue and Model Catalogue are loaded\nin memory. Consider the same query used as an example at\nFigure 4, but this time the query is not sent for execution\nbut instead ML-AQP is asked to predict its answer. Again\nthe Parser is used to extract the same elements (predicates,\nSELECT  g1, AF1(Î±3)\nFROM B \nWHERE Î±1>= x1\nAND Î±1<=x2\nGROUP BY g1Parser\nModel \nCatalogueQuery Meta -Vector\nModel WrapperGROUP -BY \nCatalogue\nAF1(Î±3)\nà·žð‘¦1\nà·žð‘¦2\nâ€¦.\nà·žð‘¦ð‘˜Figure 5: ML-AQP during Production/Prediction\nAFs, GROUP-BY attributes). A vectorized representation of\nthe query is constructed at Query Meta-Vector . If a GROUP-BY\nstatement exists, the resulting meta-vector is a matrix M\nand the values for Ð´i, . . . ,Ð´kare obtained from the GROUP-BY\ncatalogue storing different GÐ´i. If the group-by attributes\nhave been cached together then that result is fetched from the\ncatalogue. The necessary AFs to be estimated are identified\nand their models are fetched from Model Catalogue. The\nModel Wrapper is used to query the model and estimate\nthe results given the meta-vector m. The result(s) are then\nreturned to the user in an efficient manner as no data are\naccessed and the only overhead is the inference time of a\nmodel.\n4 MACHINE LEARNING SPECIFICS\nEach query result yfrom the training pair (m,y)derives from\nan unknown true function f(Â·). Such function produces an-\nswers w.r.t an unknown conditional distribution p(y|m). Our\naim is to approximate the truefunctions ffor each aggregate\nfunction e.g., COUNT ,AVG,MIN,MAX,SUM, etc. Supervised ML\nalgorithms are adopted to minimize the expected prediction\nloss between the actual answer y=f(m)from the true func-\ntion f(Â·)and the predicted Ë†yfrom an approximated function\nË†f(Â·)generated by the ML model:\nmin\nfE[L(f(m),Ë†f(m))] (1)\nThe lossL(Â·,Â·)can be usually measured using absolute or\nsquared loss functions:L=|f(m)âˆ’Ë†f(m)|orL=(f(m)âˆ’\nË†f(m))2.Supervised learning algorithms minimize the ex-\npected prediction loss using training examples, which they\nuse to learn the true function f. Such training examples are\nthe query-answer pairs in C, which are drawn from P(y|m)\nand are thus a sample of this distribution. Hence, by mini-\nmizing the sample error we expect to obtain good estimation\nover any unseen query. Our objective over the sample shown\natEq.2 is to minimize the Mean Squared Error (MSE) as it is\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\ncommonly used in regression algorithms [22]:\n1\nNNÃ•\ni(yiâˆ’Ë†f(mi))2. (2)\nNote, various supervised learning algorithms minimize a\nvariant of the objective in (2) including regularization pa-\nrameters as a technique to avoid overfitting [22].\nGoing back to our use case, we obtain a set of queries and\ntheir responsesC={(m,y)},mâˆˆR2d,yâˆˆRn. We treat\nqueries that have a matrix representation Qas collections of\nsingle queries. This makes sense as essentially each row in\nQcorresponds to a single query if instead of the GROUP-BY\nattribute a single predicate existed restricting Ð´ito a single\nvalue. The task is to train ML models Mi, . . . ,Mnthat would\nproduce regression functions Ë†fi, . . . , Ë†fnthat minimize MSE.\nMultiple such regression algorithms exist and to make the\nright choice we have to consider some of the properties of\nthe problem at hand.\n4.1 Choice of Machine Learning Models\nA primary concern is that the produced training set Cis\ninherently sparse as both the parameter vector mand re-\nsponse vector ycontain NULLs (which can be represented\nas zeroes in linear algebra) for (a) attributes that do not have\nany predicates set on them and, hence, ai,lb,ai,ubwould be\nNULL or zero3, (b) queries that do not include an AF produc-\ning a response variable yiwould also have NULL values for\nyi. For instance, in a dense matrix representation consider\ntwo queries calling different AFs; AF1andAF2, to represent\nas a matrix we have to set up two columns AF1andAF2with\nthe first row (for the first query) having a NULL value for\nAF2and the second row having NULL for AF1. To alleviate\nthe NULL response problem we partition the dataset per\nresponse/AF such that queries that refer to the same AF are\ngrouped together. However, the input is still sparse. Hence\nwe need algorithms that are able to handle such problems\neffectively.\nLinear models can often be trained in an online manner\nusing SGD [ 15], which makes them very efficient. However,\nthey result in simple models which cannot adequately model\nnon-linear relationships without introducing more polyno-\nmial terms. Models such as Ridge and Lasso [ 22] regression\nare interesting variants that include regularization to han-\ndle the increased dimensionality of our input. However, we\nhave found that these algorithms do not perform well for our\nproblem. We have also considered the use of Deep Learning,\nhowever the models become unnecessarily complex, hard\nto interpret, expensive to train, difficult to tune and have\nhigh inference times [ 36] which could increase the latency\n3A special construct nanis placed instead of 0 as 0â€™s are perfectly acceptable\nvalues.of estimating the response of an issued query. hence, they\nviolate the desiderata set earlier.\nIn light of the above arguments, we have made the choice\nof using Gradient Boosting Machines [ 23] (GBM) using efficient-\nparallel implementations called XGBoost [17] and LightGBM [32].\nA GBM iteratively fits decision trees, at first trying to ap-\nproximate the response variable and then making this ap-\nproximation more fine-grained by combining decision trees\ntrained on the negative gradient of the response variable and\nthe produced predictions by the last decision tree. In addi-\ntion, the highly scalable implementation of GBM by XGBoost\nand LightGBM allows handling large, high dimensional and\nsparse input.\n4.2 Error Guarantees\nA highly desirable feature of any AQP engine is its ability to\noffer error guarantees to the user, regarding its approximated\nanswers. For sampling-based AQP engines, providing such\nguarantees is relatively straightforward: Using subsampling/-\nbootstraping methods, confidence intervals ( [low,hiÐ´h]) can\nbe derived, associated with certain confidence levels ( l%), in-\ndicating that the sampled-population statistic of interest (say,\nthe mean) will fall within the [low,hiÐ´h]range with proba-\nbility l%[9,31,44,47]. However, this is not appropriate for\nAQP engines which, instead of inferring population statis-\ntics of a sampled population, employ predictive-ML-based\nmodels for predicting answers to future questions.\nTherefore, as ML-AQP relies on predictive/regression ML\nmodels, the produced Ë†yis not an estimator of a population\nparameter, but a prediction of the answer for a future query\n(vector m). Hence, we start off our discussion with a naive so-\nlution of offering some kind of error estimation for aggregate\nanswers. All ML models are assessed and minimize what is\nknown as the Expected Prediction Error (EPE). This is mea-\nsured by the loss stated at (2). During training mode, this is\nan over-optimistic estimate of the generalizability error that\nthe specific ML model is associated with. The generalizability\nerror is an estimate of the error associated with any future\nestimations. However, because ML models are trained on the\nset used for measuring EPE, they tend to produce inaccurate\nestimates. Hence, we use cross-validation [ 22] that measures\nthe EPE on out-of-sample examples that the model did not\nuse during training. Although, techniques such as Leave-\nOne-Out (LOO) and K-Fold [ 22] produce good estimates for\nthe EPE, this is not probabilistically guaranteed. In addition,\nthe EPE is static across the input space. This means that,\neven though an ML model might have learned to predict the\nanswers of certain queries with error Ïµ1and some others\nwith errorÏµ2, andÏµ1â‰ªÏµ2, both sets of queries will have the\nsame EPE associated with them. We find this assumption of\na static EPE as undesirable.\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nInstead of the estimate for EPE, we can use Prediction\nIntervals : Unlike confidence intervals, which are used to\nprovide an interval for a population parameter, prediction\nintervals are used to provide intervals that contain the true\n(not predicted ) value of an aggregate result yn+1of a future\nquery (vector mn+1)). If we knew that the distribution of yis\nNormal and that any yis independent, prediction intervals\ncould be produced similarly to confidence intervals. Using\nthe sample of ygiven from the training examples (y1, . . . ,yn),\nwe compute the interval: yÂ±tasnq\n1+1\nn, where tais the\n100(1âˆ’a\n2)thpercentile of the t-distribution, with Î±âˆˆ(0,1)\nand commonly set to Î±=0.01orÎ±=0.05,snis the sample\nvariance of the response variable yand1âˆ’Î±is the coverage of\nthe prediction interval. However, we do not wish to make any\nparametric assumption about the distribution of y. Hence,\nwe resort to other methods outlined below.\nAs mentioned, bootstrap [ 20], is a prominent method\nwhich makes no parametric assumptions about the distribu-\ntion ofy. This is used among sampling based AQP engines as\nwell [ 8,65]. In a sampling-based AQP engine, the bootstrap\nmethod is adopted to re-sample the underlying data set b\ntimes (where bis usually over >100) and produce a distribu-\ntion of estimates for y,Ë†yi,1, . . . , Ë†yi,b. Letyi,0be the original es-\ntimate, with the estimates provided by the bootstrap samples,\nwe then compute the residuals yi,0âˆ’Ë†yi,1, . . . ,yi,0âˆ’Ë†yi,b. Us-\ning the empirical distribution of residuals, we then compute\nquantiles, which can be used to produce a confidence interval\n[Ë†yi,0âˆ’t1âˆ’a/2,Ë†yi,0+ta/2]. Theoretically, ML-AQP could also\nuse the bootstrap method, re-sampling the training dataset b\ntimes and constructing bML models Mi, . . . , Mb. This would\nyield bestimates for y,{Ë†y}b\ni=1={Ë†fi(m)}b\ni=1and can similarly\nproduce confidence intervals. However, this methodology\nwould incur the costs of training, maintaining, and predict-\ning the estimates from b+1(if we count the initial model\nproviding the prediction) different ML models. Multiply that\nby the number of different AFs that need to be learned and\nthe overhead cost of this approach quickly becomes huge.\nMore recent developments in ML literature focus on build-\ning predictive intervals by making use of conformal infer-\nence [39,46,53]. This technique relies on building a non-\nconformity measure which estimates the difference of two\nexamples i.e., miandmj. This could be defined as the Lp\nnorm (i.e p=2) of the examplesâˆ¥miâˆ’mjâˆ¥2\n2. But finding the\nright non-conformity measure in our case is non-trivial as\nthe input vectors are high-dimensional and sparse. Distance\nin this case becomes meaningless [ 10] and the choice of a\nvalid p-norm is beyond the scope of this work. In addition,\nthese techniques scan the complete set of previous training\nexamples to find similar and dissimilar examples. Thus, all\nprevious queries have to remain stored. This is undesirable,as we would like to discard all of the queries and only deploy\nmodels for ML-AQP.\nTherefore, our choice is to employ Quantile Regression\n(QR) [ 35]. While typical regression models minimize the EPE\nand focus on estimating the conditional expectation E[y|m],\nQR tries to estimate the tthconditional quantile Qy|m(t). Mul-\ntiple ML algorithms have been proposed to estimate condi-\ntional quantiles [ 43,54,56]. Formally, given a conditional\ndistribution function for y,\nFy|m=P{Yâ‰¤y|m}, (3)\nwe define the tthconditional quantile function as:\nqt(m)=inf{yâˆˆR:Fy|m>t} (4)\nWhere infis the infimum , which points to ythat is less\nthan or equal to all the elements in the defined set. Given the\nconditional quantile function defined in (4), we construct pre-\ndiction intervals using [qt/2,q1âˆ’t/2]. This defines the lower\nand upper bounds of the estimated value for ywith cover-\nage probability of 100(1âˆ’t)%. As stated, earlier regression\nalgorithms estimate the conditional expectation of y,E[y|m]\nby minimizing EPE. In the same manner, quantile regression\nalgorithms estimate the conditional tthquantile Qy|m(t)by\nminimizing what is known as \" pinball loss \"[35] :\nÏt(y,Ë†y)=(\nt(yâˆ’Ë†y),ifyâˆ’Ë†y>0\n(1âˆ’t)(Ë†yâˆ’y),otherwise(5)\nSuppose we have trained two different quantile regression\nfunctions Ë†qt/2:mâˆˆR2dâ†’Qy|m(t/2)âˆˆRand Ë†q1âˆ’t/2:mâˆˆ\nR2dâ†’Qy|m(1âˆ’t/2)âˆˆR. Then, a prediction interval for\neach new query is estimated as: [Ë†qt/2(mnew),Ë†q1âˆ’t/2(mnew)]\nwith coverage probability 100(1âˆ’t)%.\nTherefore, ML-AQP provides error guarantees using QR\nand the statistical tools of prediction intervals and cover-\nage. Specifically, ML-AQP produces a prediction interval\n[low,hiÐ´h]and a coverage level l%and guarantees that the\ntrue answer to a future query will fall within [low,hiÐ´h]\nwith probability l%. LightGBM [ 32] offers support for QR\nand we are also looking into incorporating [ 50] to support\nstricter guarantees.\n5 UPDATES\nAs ML-AQP is deployed, over the course of time there might\nbesignificant data updates or drastic workload shifts that in-\nvalidate the patterns learned by the models so far. In general\nnew query patterns or new data might not cause the accu-\nracy of ML-AQP to deteriorate as it is still able to generalize.\nFormally, we require workload/data updates to be significant\nso that the distributions at times tandt+1are no longer\nthe same, meaning that the condition, pt(y),pt+1(y), holds\nfor data updates and pt(m),pt+1(m)for workload shifts.\nAlthough insertions/updates/deletions could be expected to\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\nbe frequent, p(y)might not change. Therefore, the key ob-\nservation is that we do not need to track changes in the data\nspace but instead need to monitor for changes in p(y). To\ntackle both workload/data shifts we could naively retrain\nthe models at fixed time intervals to be sure that the most\nupdated queries and data are used. Over, 1M+ queries are\nexecuted daily in large deployments [ 31]; thus, it is easy/fast\nto find new queries executed on fresh data. However, we\nprovide two alternative methods and in the next paragraphs\nwe first address data updates and then workload shifts.\nAs shown previously, our solution is query-driven and\ndoes not access data at any time. Therefore, to detect changes\nin the data/workload, we monitor queries that are succes-\nsively executed by the data warehouse (qt, . . .). To detect\nchanges to the aggregates distribution p(y)we employ the\ntwo-sample Kolmogorov-Smirnov (KS) test. The KS test out-\nput statistic is D=supy|F1(y)âˆ’F2(y)|, where F1is the em-\npirical CDF (ECDF) at time tof answersY1:t4of all queries\nthat were used to train a model and F2is the ECDF ofYt+1:\nfrom monitored queries executed against the data warehouse.\nThe KS test, evaluates the hypothesis that the two sets of\nanswers come from the same distribution. The hypothesis\nis rejected at a significance level Î±ifD>c(a)q\nn+m\nnm, where\nc(a)=q\nâˆ’1\n2+lnÎ±\n2andn=|Y1:t|,m=|Yt+1:|. If the hy-\npothesis is rejected then the distribution has shifted and the\nmodel associated with the aggregate needs to be retrained.\nRetraining a model because of a distribution shift does not\nimpose a large overhead as the cost of training the models is\nminimal, (as shown in Section 6.4). We are also considering\nother solutions such as data augmentation [ 57] to augment\nthe existing set of queries and allow our models to generalize\nto possible data updates without retraining.\nWe also need to address the case of a workload shift and\nemploy a similar detection test. The workload is charac-\nterised by the query vectors mâˆˆR2dand the KS test cannot\nbe applied as their distribution p(m)is multivariate. In this\ncase we can apply Chebyshevâ€™s inequality which states that;\ngiven a random variable Xand its expected value Âµthen the\nprobability of obtaining a sample point greater than kstan-\ndard deviations from the mean is â‰¤1\nk2, formally Pr(|Xâˆ’Âµ|â‰¥\nkÏƒ)â‰¤1\nk2. This is clearly defined for a scalar value Xand\nwe need the multivariate version of this as we have vectors\nmâˆˆR2d. For the multivariate case we can express the above\nasPr(p\n(mâˆ’Âµ)TÎ£âˆ’1(mâˆ’Âµ)â‰¥k)â‰¤N\nk2, where Î£is the co-\nvariance matrix and N=Tr[Î£âˆ’1Î£]. Hence, as queries are\nbeing monitored we can examine the inequality and trigger\nan alarm to retrain the models if the inequality is violated,\n4The notation 1 :tdenotes the answers of queries at time-steps 1totand\nt+1 :denotes answers of queries from t+1onwards.meaning that if Pr(p\n(mâˆ’Âµ)TÎ£âˆ’1(mâˆ’Âµ)â‰¥k)â‰¥N\nk2then\nwe need to retrain the models because of a workload shift.\n6 EVALUATION\n6.1 Experimental Setup\nDatasets & Workloads. For our experiments we used the\nfollowing data sets and workloads:\n(1)TPC-H [4]: This is the standard TPC-H benchmark.\n(2)Instacart [2]: This is a data set of an online store. A\ndatabase was created using the csv files which follows\nthe setup of VerdictDB. [47].\n(3)Crimes [5]: This is a real data set of crimes reported in\nthe city of Chicago. A workload for this data set was\nobtained from [ 1] which models a number of range-\nqueries with multiple AFs. Their predicates are sam-\npled from a number of random distributions to sim-\nulate various analysts executing queries at different\nsubspaces of the data set.\n(4)Sensors [6]: Is a data set comprised of a number of sen-\nsor readings including voltage, humidity temperature\netc with a temporal dimension. A synthetic workload\nwas created restricting the temporal dimension and ex-\ntracting the MIN(temperature) andMAX(humidity) .\nTraining ML-AQP. ML-AQP has a Training phase, much\nlike sampling based AQP engines that need to create samples\nbefore being able to operate. For all workloads, we gener-\nate queries and train the models on 70% of the complete\nworkload. We then conduct the experiments and take mea-\nsurements on the rest 30%. This is standard practise in the ML\nliterature. For Instacart , we use a similar format of queries\nas VerdictDB [ 3]. However, to facilitate learning we vary the\npredicate values. For all queries containing predicate values,\nwe generate queries from the same template with values\nsampled from a normal distribution N(Âµ,Ïƒ), where(Âµ,Ïƒ)\nis the average and standard deviation of the corresponding\nattribute, respectively. If the attribute contains a categor-\nical value, the generated queries contain a value selected\nuniformly at random. The total number of training queries\ngenerated were 104and3.3Â·103for testing. Some queries\ncontained no predicates, in these cases no additional queries\nwere generated. The number of queries obtained is not large\nas typically there are millions of queries being executed on\na daily basis in production environments [31].\nForTPC-H , we use a subset of the queries contained in the\nbenchmark as we are still making progress on our Parser . We\ngenerate 100queries for each of the queries used. A model is\ntrained for each distinct AF. For Instacart , three different\nmodels are generated as three distinct AFs are used in this\nworkload. For TPC-H ,12different models were generated. For\nCrimes andSensors . we generate a model per AF tested.\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\n6.2 Performance\nWe first examine the performance of ML-AQP and demon-\nstrate the speedup gains over a popular database PostgreSQL.\nWe compare the results using a sampling based AQP engine,\nVerdictDB [ 47]. Let tbbe the response time for PostgreSQL\nandtm,tvthe response times for ML-AQP and VerdictDB\nthen speedup is measured bytb\ntmandtb\ntv, respectively. For this\nexperiment, we use TPC-H with 1GB and Instacart with its\nmain fact tables ( order_products ,orders ) containing 3M\nand 30M rows. For TPC-H , we use a subset of all the tem-\nplate queries and for Instacart , we use the same format of\nqueries as used in the evaluation of VerdictDB[ 3]. For Ver-\ndictDB, uniform samples were created for large fact tables at\n1%/10%ratio. This experiment ran on a single machine with\nan Intel(R) Core(TM) i7-6700 CPU @3.40GHz, 16GB RAM\nand 1TB HDD.\n1-ic2-ic3-ic4-ic5-ic6-ic7-ic8-ic9-ic10-ic11-ic12-ic13-ic14-ic1-tpch3-tpch4-tpch5-tpch6-tpch\nQuery101103Speedup (log)VerdictDB (10%)\nML-AQPVerdictDB (1%)\nFigure 6: Speedups offered by ML-AQP compared to\nVerdictDB\nThe results are shown at Figure 6. We can instantly notice\nthat the speedup differences are huge (notice the log-scale on\ny-axis)5. Even though we are using relatively small datasets,\nVerdictDB, understandably, cannot offer the same speedup\nas ML-AQP. The minimum/maximum speedup gained by\nML-AQP is at 7Ã—/7200Ã—,for VerdictDB 1% 0 .59Ã—/43Ã—(as we\nsuspect that some of the computation is offloaded to the\nmain engine) and for VerdictDB 10% 3Ã—/11Ã—. This stems\nfrom the fact that ML-AQP is only performing inferences at\nPrediction mode using trained models. It does not need to\nscan any of the data at any time. To be more specific, Table\n1 shows the mean response time along with the standard\ndeviation and 95thpercentile for all queries across the four\ndifferent systems. As it is evident, even at the 95thpercentile\nthe response times for ML-AQP are no greater than 120\nmilliseconds, satisfying the interactivity constraint set at\n500ms [40].\nEven for queries with relatively large GROUP-BY s the speedup\nis at20x. By default GROUP-BYs are a bottleneck in our case as\nmultiple queries have to be executed for each distinct value\n5For4-tpch we could not get VerdictDB to execute this query.System Time (sec) 95thpercentile (sec)\nPostgreSQL 1.62Â±1.21 4 .01\nVerdictDB (10%) 0.28Â±0.41 0 .79\nVerdictDB (1%) 0.14Â±0.3 0 .43\nML-AQP 0.05Â±0.16 0 .12\nTable 1: Performance over all queries across systems\nof the attribute used in the GROUP-BY clause. For instance,\nquery 14-ic has approximately 50K distinct values. In this\nexperiment its values were cached as this would have been\nthe default behavior. This is due to similar queries with the\nsame GROUP-BY attributes being executed during Training\nmode. When caching the values, query 14âˆ’ictakes 0.67sec-\nonds to execute and 0.7seconds when it does not cache the\nGROUP-BY values. We can see minor impact, with an over-\nhead attributed to the execution of the SELECT DISTINCT\nquery at 0.3seconds. We can still get 7xbetter response\ntimes than PostgreSQL, where as VerdictDB ( 1%/10%) is at\n24x/3xfor this particular query. Although a larger speed-up\nis observed, for VerdictDB( 1%) we will notice that accuracy\nusing 1%sampling ratio deteriorates with large errors in the\nindividual groups.\n0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\nSampling Ratio101102103Speedup (log)ML-AQP mean speedup\nFigure 7: VerdictDB speedup for an increasing sam-\npling ratio.\nAt Figure 7 we examine how the speed-up offered by sam-\npling based and in general data-driven AQP solutions di-\nminishes as the sampling ratio is increased. For point of\nreference we also provide the average speedup offered by\nML-AQP which is not constrained by a sampling ratio as it\nuses no data.\n6.3 Performance at the Cloud\nOur solution is designed to alleviate the monetary, compu-\ntational, storage costs in large deployments usually in the\ncloud. We first examine how the computational cost can be\nmediated using our solution. For this experiment, we use\nAWS Redshift , with 2 dc2.large compute nodes and 1master\nnode each at 16GB memory with 160GB SSD. We use a 100x\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\nscaled version of the Instacart dataset. The total storage\nfootprint of this data set is 100GB with the main fact tables\n(order_products ,orders ) containing 4.2billion and 0.5\nbillion rows respectively. We execute the same Instacart\nqueries [ 3] and we set a timeout value at 5(mins). After\nthis, we abort the execution of the query. For VerdictDB we\nuniformly sample the same fact tables at 10%ratio. In this ex-\nperiment, we expect the results for VerdictDB to deteriorate.\nOn the other hand ML-AQP is constant in its performance\nas it is unaffected by data size. It is important to recall that\nthe deployment of ML-AQP can happen in two ways: (i)\nAll the models and required modules for ML-AQP can be\ndistributed to all the analystsâ€™ machines and be loaded in\nmemory during analysis (later experiments will showcase\nthat the small storage footprint of ML-AQP permits this solu-\ntion); (ii) All models can be deployed at a server and be used\nas a service. This would have significantly lower costs than\nexecuting queries using Redshift. However, it might have\nmore overhead as the predictions have to be transferred to\nthe analysts machine over the network. We further examine\nthe performance benefits of both solutions.\nThe results of this experiment are shown at Figure 8. There\nare two different deployments for ML-AQP: (a) ML-AQP (net-\nwork) , (b) ML-AQP (local) . For ML-AQP (network) deploy-\nment, we set up a small server serving predictions over the\nnetwork. It accepts HTTP POST requests with the extracted\nparameter values of the SQL query and returns a prediction\nof its answer. The results shown in Figure 8 are in log-scale .\nAs expected, the benefits of a local deployment are far greater,\nalthough we would have to consider problems in maintain-\ning the models as in this case ML-AQP are in each analysts\nmachine. In addition, for some queries VerdictDB offers no\nspeedups as Redshift is able to process those queries in an\nefficient manner.\n1-iq10-iq 11-iq 12-iq 13-iq 14-iq2-iq 3-iq 4-iq 5-iq 6-iq 7-iq 8-iq 9-iq\nQuery100102104Speedup (log)VerdictDB\nML-AQP (network)ML-AQP (local)\nFigure 8: Speedups in large deployments\nTo be more concise, the min/max speedup benefits of the\ncompared systems are shown at Table 2. As evident, the local\ndeployment is orders of magnitude faster than both Ver-\ndictDB and an over the network deployment. We also report\non average response times and the response times at the 95thML-AQP ( local ) ML-AQP ( network ) VerdictDB\n443-10524-195 0 .16-28\nTable 2: Minimum-Maximum speedups at the Cloud\nSystem Time (sec) 95thpercentile (sec)\nRedshift 55Â±75 142\nVerdictDB 49Â±120 300\nML-AQP ( network )0.78Â±1.82 2 .68\nML-AQP ( local ) 0.02Â±0.08 0 .25\nTable 3: Performance at the Cloud\npercentile for all systems. The results are shown in Table 3.\nThe first thing we notice, is that although VerdictDB has less\nmean response time than Redshift, at the 95thpercentile it\nis slower, possibly due to overheads of VerdictDB in decid-\ning which samples to process. In addition, both the network\nandlocal deployments for ML-AQP offer mean sub-second\nlatencies and only 2.68seconds at the 95thfornetwork .\n6.4 Training Overhead\nAs stated earlier, ML-AQP has to go through Training mode\ninitially. At this stage, previously executed queries are used to\ntrain a variety of models and learn to predict the answers of\nfuture aggregate queries. Ideally training the models would\nhappen locally at Data Scientistâ€™s machines so as not to in-\ncur additional costs of repeatedly training and fine tuning\nthe models in the Cloud. Therefore, in this experiment we\nmeasure the Training Time required to build a model with\nvarying number of queries. We run this experiment locally\non a single machine with an Intel(R) Core(TM) i7-6700 CPU\n@3.40GHz, 16GB RAM and 1TB HDD to demonstrate this\ncapability. We compare this to the sample building time of\nVerdictDB with an increasing sample ratio. We use the TPC-H\ndata set at 1GB. At each iteration 3samples are built on the\nmain fact tables. Figure 9 shows the result of this experiment.\nThe sample preparation time for VerdictDB, Figure 9(right),\nincreases linearly and even for 0.1ratio at 1GB, takes longer\nthan training ML-AQP on 4million queries. At 6+million\nqueries, this overhead is still lessthan the sample prepara-\ntion time for VerdictDB at 0.6ratio. To put this in context,\nfor ML-AQP to train on queries generated for Instacart ,\non4,000forAVGqueries took 1.1seconds and for SUM3.3\nseconds. For TPC-H it took, less than a second to train each\nmodel. The only exception was for COUNT as its associated\nqueries included a large number of groups (>50,000)and\ntook 326seconds to train on around 5million training exam-\nples in total. It is also important to note that sampling based\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\n104105106\n# Queries (log)101102103Overhead (s)\n0.10.20.30.40.50.60.70.80.9\nRatio\nFigure 9: (Left) Training overhead for an increasing\nnumber of queries (x-axis) (Right) Sample preparation\ntime for VerdictDB\nAQP engines are susceptible to the size of the data set. In\nthis experiment, we are only using 1GB of data, as the size\nincreases, sample preparation time is expected to increase,\ntoo. This would not be a problem for ML-AQP as it is only\naffected by the number of queries and it is not, at any point,\naffected by the size of the underlying data set. In conclusion,\nboth approaches, sampling-based AQPs and Query-Driven\nML-based AQPs will have \" training \" overheads. Their over-\nheads are largely determined by different dimensions and as\nthese solutions are designed to expedite query processing in\npetabyte scale storage engines we expect ML-AQPs overhead\nto be much less.\n6.5 Accuracy\n6.5.1 Accuracy on TPC-H & Instacart. To assess the accu-\nracy of ML-AQP we measure the Relative Error [9,31,47,48]\nacross all the query templates of both Instacart andTPC-H .\nML-AQP was trained on past queries generated as described\nin Section 6.1. Three models were trained using LightGBM\nto answer Instacart queries, one for each AF involved.\nForTPC-H , 11 models were trained using XGBoost as the\nqueries were largely referring to AFs on different attributes.\nThe number of rounds were set to 104with early stopping\nwhen no more improvement was shown. Objective was set\ntosquared_error . We compare our results with VerdictDB,\nwhich created samples over the large fact tables at ratios of\n1%/10%. An initial set of results is shown at Figure 10. A first\nimpression is that both systems perform really well over a\nlarge range of queries. Please note that the results show the\naverage relative error over each query template. Where for\neach query template multiple, >50, queries were executed\nwith random predicate values as described in (6.1). ML-AQP\nis able to accurately answer 80%of queries for Instacart\nand100% of the selected TPC-H queries with relative error\nbelow 10%. We can also visually discern that ML-AQP out-\nperforms VerdictDB for many queries. VerdictDB at 1%was\n11-ic8-ic13-ic1-ic4-ic6-ic14-ic3-ic9-ic5-ic10-ic7-ic12-ic2-ic3-tpch1-tpch5-tpch6-tpch4-tpch\nQuery10âˆ’1101103Relative Error (%)VerdictDB (10%) VerdictDB (1%) ML-AQPFigure 10: Relative Errors for each query in TPC-H &\nInstacart\nnot able to answer accurately queries that have a large num-\nber of groups, such as 14-ic and in some cases the groups\nreturned by VerdictDB did not match the ones returned by\nthe engine ( 3-tpch, 5-tpch)6. For ML-AQP, queries 1-icand\n5-icproduce large relative errors. This is understandable as\nthese queries include no predicates and are simply the results\nover a full scan of the table (ie are simple SELECT AF FROM\nT). The results of such queries can easily be cached. ML-AQP\nis not expected to answer such queries as the meta-vector m\nis filled with nanvalues, to which the model simply ignores\nas there are no patterns to be learned.\n100101102103104105\nPer Group Error (%)0.00.20.40.60.81.0CDF\nML-AQP\nVerdictDB (10%)\nVerdictDB (1%)\n0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9\nSampling Ratio100101102Relative Error (%)\nFigure 11: (Left) CDFs of relative error per group in a\nGROUP-BY query (right) Relative error for an increasing\nsampling ratio with the mean relative error for ML-\nAQP as a horizontal line.\nWe also measure the relative error on a per-group basis. Es-\npecially, for query 14-ic where a large number of groups are\npresent we notice high relative error. Figure 11(left), shows\nthe CDF of the relative error across groups for all three\nsystems. ML-AQP outperforms VerdictDB at both sampling\nratios ( 1%,10%), which shows that it can accurately estimate\nthe aggregates across groups. Given the prior discussion we\ndo not mean to say that sampling based engines have less\naccuracy. Instead, at a small sampling ratio the benefits are\nnot great and the large trade-off between accuracy and speed\n6We were not able to run query 4-tpch as an uknown error was thrown at\nruntime.\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\nmakes their use inappropriate. Hence, sampling based en-\ngines can be used in parallel to ML-AQP, when the analyst\nneeds more accurate answers and they are willing to sacrifice\nsome of the efficiency for it, as also suggested by Figure 3. So,\nthe systems can co-exist if we use sampling based engines\nwith a higher sampling ratio as the expected error over all\nqueries decreases as is shown at Figure 11(right).\n24Normalized Error (%)\nSensors\nMIN\nMAX\n510Relative Error (%)\nCrimes\nCOUNT\nSUM\nMEAN\n25005000750010000125001500017500200002250025000\n# Training Queries0510Median Absolute Error\nMIN\nMAX\n25005000750010000125001500017500200002250025000\n# Training Queries024Median Absolute Error\nCOUNT\nSUM\nMEAN\nFigure 12: Accuracy over Sensors and Crimes for an in-\ncreasing number of training queries and over differ-\nent AFs. (Top) Relative/Normalized Error (Bottom) Me-\ndian Absolute Error. (Right Column) For Crimes the\naccuracy of VerdictDB is plotted as horizontal lines.\n6.5.2 Accuracy on range queries over spatio-temporal data.\nWe have also measured the accuracy of ML-AQP in predict-\ning the responses of range-queries over spatio-temporal data\nsets. Specifically, multiple synthetic queries are executed\nover Crimes restricting its spatial dimensions and return-\ning a response COUNT ,MEAN orSUMover other attributes in-\ncluded in the data set. Namely COUNT returns the number\nof recorded incidents within the defined area, MEAN is the\naverage Beat number which is a police defined number de-\nscribing the area, and SUMof the arrests over the specified\narea. For Sensors we restricted the temporal dimensions\nand extract the MIN(temperature) and MAX(humidity). All of\nthe results at Figure 12(top) show that the relative error is\nbelow the targeted 10%for this kind of data sets and con-\nntinues dropping as more queries are being used for training\nthe models. We also plot the accuracy for VerdictDB ( 1%) as\nhorizontal lines only for the Crimes data set as VerdictDB\ndoes not support MIN/MAXaggregates. Note that for Sensors ,\nwe report on the Normalized Error |yâˆ’Ë†y\ny|, which computes\nthe absolute difference divided by the mean response. The\nreason is that for this workload, the values are really small\n(Âµ=9) and the measured relative error is not robust as itmight report a 50%error even if y=2and Ë†y=1. This is also\nencountered in [ 30] and similar technique is employed. To\nprovide more context as to how close the predictions are in\nrelation to the true response, we also provide results on the\nMedian Absolute Error (MAE) at Figure 12(bottom). It is a\nwell known metric in the ML community that is robust to\noutliers indicating the median of the absolute error between\nyand Ë†y. As evidenced, the absolute difference is small for\nall aggregates and data sets and continues to drop as more\nqueries are used for training. The accuracy obtained is simi-\nlar to VerdictDBâ€™s with ML-AQP having lower relative error\nforCOUNT . In addition, we stress the fact that we are able to\npredict the responses for MINandMAXthat to our knowledge\nare not supported by most AQP systems. In addition, as the\nnumber of queries increase, we see a drop in relative error\nsuggesting that more accurate predictions can be obtained.\nOverall, the results of this experiment show that ML-AQP is\nable to support a wide variety of aggregates over a diverse\nset of data sets.\n6.5.3 Accuracy on error estimation. We study the effective-\nness of the prediction intervals constructed using QR. For\nthis experiment we train two LightGBM models on quantile\nloss , with parameters n_estimators =1500 andl_rate =\n0.001. We set t=0.95and train the two models using\nalpha =1âˆ’tandalpha =t. This effectively creates a predic-\ntion interval that would ideally provide a coverage rate of\n90%. Coverage rate is used in other work to assess prediction\nintervals [ 21,39] and is essentially an empirical estimate of\nthe predictions that will fall within the proposed interval.\nIt is computed using a held-out set of queries. Specifically,\nthe two models generate responses for Ë†y5thand Ë†y95th. We test\neach truevalueyonË†y5thâ‰¤yâ‰¤Ë†y95thand report the ratio of\nqueries where the condition is true. We used the queries of\nInstacart and conduct this experiment on three different\nAFsCOUNT ,SUM,AVG.\nCOUNT AVG SUM0.00.20.40.60.81.0Coverage\nFigure 13: Coverage Ratio for different AFs. Horizon-\ntal line drawn at 90%\nThe results at Figure 13 confirm, that empirically a value\nlies within the interval, provided by QR estimates, by an\nestimated probability >0.9. In short, using QR, ML-AQP\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nis able to provide good probabilistic intervals for the true\nanswer. Using this interval the user can choose whether\nthey trust the prediction or they wish to get a more accurate\nestimate using an S-AQP or the data warehouse engine.\n6.6 Storage\nFor this experiment, we measure the Storage overhead of\nML-AQP. At the end of the Training phase we deploy ML\nmodels at analysts devices or a central device. Measuring\nthe storage overhead and ensuring that this is adequately\nsmall is of great importance. We expect orders of magnitude\nsmaller storage footprint than sampling based AQP engines\nas we neither store any of the data nor any of the queries\nused for training. We initially examine how much memory\nis required by a model with increased complexity. The main\nfactor contributing to the size of the selected ML models\n(GBMs) is the number of trees and their depth.\n5000 10000 15000 20000\nComplexity (Trees Number)0200004000060000Size (KB)\nFigure 14: Increasing number of trees (x-axis) and size\nin kilobytes\nFigure 14 shows an increase in the total storage required\nby an increasing number of trees. For conducting the ex-\nperiments over Instacart andTPC-H the number of trees\nnever exceeded 1700 with some AFs requiring as little as 100\ntrees. ML-AQP requires additional storage for encoding cate-\ngorical values and for caching values obtained from queries\nwith GROUP-BY clauses. For instance for Instacart , there\nare50,000categorical values and ML-AQP requires an extra\n4MB (on top of the storage required by the models). This\ncost increases linearly as the number of labels increase. Ac-\ncounting for all of this and even any required modules by the\nimplementation of ML-AQP still does not match the storage\noverhead required by sampling based AQP. To put this in\ncontext, Instacart requires 2.4GB of storage for its tables.\nTo sample its main fact tables orders andorder_products\nat0.1, VerdictDB required 1.8GB in total. On the other hand,\nML-AQP requires a mere 15.5MB to cover the aggregate\nqueries issued against Instacart , this includes all models\nand catalogues. Given this information, we can safely assert\nthat ML-AQP is extremely light-weight and can easily reside\nin main memory during analysis.6.7 Updates Adaptation\nWe conduct an experiment to assess ML-AQPâ€™s detection\nmechanisms for updates in data and workload. As we have\nelaborated we need to identify cases where p(y)andp(m)\nchange by observing queries executed at the data warehouse\nwithout accessing any data. Monitoring actual insertion-\ns/updates/deletions could prove futile as the distribution of\nymight not be changing. For this experiment we use two\ndistributions p1(m,y)andp2(m,y). The distributions for pa-\nrameters mare multivariate Normal distributions initialized\nrandomly at the data space of Crimes data set and the an-\nswersyare the actual answers for COUNT over the same data\nset. We first test for data shift detection. In this experiment\nwe obtain the empirical distribution function of p1(y)and\nconduct the KS test at regular intervals. At a specific point in\ntime we change to p2(y)which we then expect that KS statis-\ntic will go over the threshold. The results at Figure 15(left)\nshow that as the distribution shifts the KS statistic increases\nand becomes larger than c(a)q\nn+m\nnmas soon as the data shift\nhappens (vertical dotted line). In addition, Figure 15(right)\nshows when the KS statistic fires relative to the impact of\nupdates on p(y)indicating that the model would be updated\nbefore relative error increases dramatically.\n0 50 100\n# Queries0.20.40.6Statisticc(a)/radicalBig\nn+m\nnm\nD- KS\nData Shift\n0 2 4\nUpdates Magnitude406080100120Relative Error (%) KS-test triggered\nFigure 15: (Left) x-axis; Number of queries processed\ninitially from p1and then from p2; y-axis; measured\nstatistic (Right) Updates Magnitude and firing of the\nKS statistic before relative error increases.\nWe perform a similar experiment to assess the detection of\na workload shift. Again,we have two different distributions,\nwhere initially queries are observed from the first distribu-\ntion and at a specific point in time queries are sampled from\nthe other distribution. We monitor Cheybyshevâ€™s inequal-\nity and detect whether the inequality has been violated to\ntrigger a workload shift. The results shown at Figure 16 de-\nnote that as the workload changes (indicated by the vertical\ndotted line) the threshold (horizontal dotted line) provided\nby the inequality is exceeded and we can successfully detect\nwhether the patterns have shifted and adapt accordingly. In\ngeneral, in the face of data or workload updates ML-AQP is\nable to appropriately detect and adapt to such changes.\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\n0 20 40 60 80 100\n# Queries0.00.20.40.6Pr(/radicalbig\n(mâˆ’Âµ)TÎ£âˆ’1(mâˆ’Âµ)â‰¥k)\nN\nk2\nWorkload Shift\nFigure 16: Number of monitored queries and proba-\nbility of exceeding kstandard deviations along with\nChebyshevâ€™s inequality threshold.\n7 RELATED WORK\nTo meet the needs of interactive query processing in large\nanalytic environments various big data engines [ 13,18,63]\nand columnar databases [ 25] have been developed. However,\nthe goal of truly interactive analysis still remains elusive, as\nsuch engines produce exact results. Their results have to be\ncomputed over large quantities of data. Therefore, research\nin AQP has been pretty strong the last decades [ 7,9,14,16,24,\n27,30,31,41,44,47â€“49,64] and still the list is not exhaustive.\nWe can categorize most AQP engines to sampling based AQP\nengines [ 9,44,47] and online aggregation engines [ 27,64].\nSampling based AQP engines create samples over some (or\nall) of the columns in tables and produce answers with error\nguarantees based on samples. On the other hand, online\naggregation engines produce a result as quickly as possible\nand then keep on refining it as more and more data are\nprocessed until the user stops the query execution. However,\nAQP is struggling to find its way through the industry. A\nnotable approach is QuickR developed from Microsoft [ 30,\n31] but there is more work to be done.\nMore recently we see the deployment of ML models to a\nwide variety of data management problems: selectivity esti-\nmation [ 11,12,19,33,34,45,55,61,62], query optimization\n[42], in which ML is used to decide on a query plan, or to\ncreate indexes [ 36], for expediting visualisation [ 59] and to\nAQP [ 28,38,41,58]. We believe that this approach can be\nfruitful if used with care. This is why we are not aiming\nto replace already existing AQP engines or data analytic\nsystems and instead provide an addition to the stack. We\nbelieve the user needs to have a choice considering the trade-\noffs between speed and accuracy. As such our approach is\nsimilar to the recent trend of applying ML over data man-\nagement problems, in that we employ ML models for AQP.\nApproaches such as [ 33,34,45,55,61,62] make use of ML\nto estimate cardinalities for their use in a query optimiza-\ntion setting. Similar methodologies are adopted in that first\nfeatures are extracted either from data or from queries andsubsequently used for training models. This is to be expected\nas any relevant work that makes use of ML needs to follow\nthis process. However, all of the aforementioned works focus\non cardinality estimation and not on AQP. In addition they\nfollow different modelling/vectorization for the queries, use\ndifferent ML models and none of the works explicitly ad-\ndress data/workload updates and error guarantees. Perhaps\nthe most similar work to ours is NeuralCubes (NC) [ 59] in\nwhich the authors describe a query-driven ML-based sys-\ntem to be used as a visualisation backend engine using AQP\n(COUNT/AVERAGE) answers. Compared to NC, ML-AQP\n(i) provides error guarantees, (ii) support updates in both\ndata and workload, (iii) support more AFs, (iv) explicitly\nprovide information on training/storage/prediction-serving\noverheads, and (v) provide all that with inherently simple,\neasy to understand ML models. We have conducted exper-\niments based on two data sets that were used in NC and\nreport on Relative Absolute Error (RAE) which is the metric\nused in NC. ML-AQPâ€™s RAE for BK-Austin was3.9%(where\nNC is at 3.88%) and for BK-NYC , RAE was 3.6%(where NC is\nat4.25%). The results suggest better or similar accuracy over\nNC with a much smaller training overheadâ€“ML-AQP trains\nits models >10Xfaster than NC on weaker hardware.\nCompared to other approaches focusing on ML for AQP\nsuch as [ 28,38,41,58] ML-AQP neither learns from data nor\nuses data to construct samples or models. ML-AQP employs\na novel query-driven method, based on vectorized repre-\nsentations of previously executed queries and their results\nand is oblivious to the underlying data distribution. In ad-\ndition, ML-AQPâ€™s focus is not solely in COUNT/SUM/AVG\nas most works [ 28,38,58] but offers support for any kind\nof AF through its AF agnostic methodology. Nevertheless,\ndata-driven approaches are surely a promising avenue and\nwe believe all of these approaches could complement each\nother. In cases where;i) data sets are massive, ii) no models or\nsamples can be built and stored efficiently, and iii) there is a\nlow cost requirement, ML-AQP appears to be more favorable.\n8 CONCLUSIONS\nIn this paper we described ML-AQP, whose salient feature is\nthat it develops ML models over (small numbers of) previ-\nously executed queries and their answers, instead of develop-\ning models or samples over massive base tables. The models\nare extremely compact and simple, avoiding using complex\ndeep learning networks. Despite this, ML-AQP can provide\nanswers efficiently, offering up to 5orders of magnitude\nspeedups in large deployments with small relative errors.\nSpecifically, queries and their answers are transformed into\na custom vectorized representation. This representation, al-\nlows training ML models that learn patterns to predict future\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nquery answers. Also, ML-AQP can bound errors of its an-\nswers by employing prediction intervals constructed using\nQuantile Regression models. In addition, updates to data and\nchanges in query workloads can be handled effectively. More-\nover, it can support any aggregate queries, including MIN,MAX\n(which most AQP systems struggle to address), along with\nGROUP-BYs . Experiments substantiate that ML-AQP can en-\nsure low errors while introducing dramatic efficiency gains\nwith small memory/storage footprints, and supporting all ag-\ngregate functions. ML-AQP, thus, shows a promising method\ninto how ML models can be incorporated for AQP, avoiding\nthe pitfalls of dealing with massive data sets.\nREFERENCES\n[1]Crimes workload. URL :https://archive.ics.uci.edu/ml/datasets/Query+Analytics\n+Workloads+Dataset. Accessed: 2019-06-28.\n[2]Instacart. URL :https://www.instacart.com/datasets/grocery-shopping-\n2017. Accessed: 2019-06-28.\n[3]Instacart queries. https://github.com/verdictdb/verdict/wiki/Instacart-\nQueries.\n[4] Tpc-h. http://www.tpc.org/tpch/.\n[5]Crimes - 2001 to present. URL: https://data.cityofchicago.org/Public-\nSafety/Crimes-2001-to-present/ijzp-q8t2, 2018. Accessed: 2018-08-10.\n[6]Intel lab data. URL: http://db.csail.mit.edu/labdata/labdata.html, 2019.\nAccessed: 2019-04-10.\n[7]S. Acharya, P. B. Gibbons, V. Poosala, and S. Ramaswamy. The aqua ap-\nproximate query answering system. In ACM Sigmod Record , volume 28,\npages 574â€“576. ACM, 1999.\n[8]S. Agarwal, H. Milner, A. Kleiner, A. Talwalkar, M. Jordan, S. Madden,\nB. Mozafari, and I. Stoica. Knowing when youâ€™re wrong: building fast\nand reliable approximate query processing systems. In Proceedings\nof the 2014 ACM SIGMOD international conference on Management of\ndata, pages 481â€“492. ACM, 2014.\n[9]S. Agarwal, B. Mozafari, A. Panda, H. Milner, S. Madden, and I. Stoica.\nBlinkdb: queries with bounded errors and bounded response times on\nvery large data. In Proceedings of the 8th ACM European Conference on\nComputer Systems , pages 29â€“42. ACM, 2013.\n[10] C. C. Aggarwal, A. Hinneburg, and D. A. Keim. On the surprising\nbehavior of distance metrics in high dimensional space. In International\nconference on database theory , pages 420â€“434. Springer, 2001.\n[11] C. Anagnostopoulos and P. Triantafillou. Learning set cardinality in\ndistance nearest neighbours. In 2015 IEEE international conference on\ndata mining , pages 691â€“696. IEEE, 2015.\n[12] C. Anagnostopoulos and P. Triantafillou. Query-driven learning for\npredictive analytics of data subspace cardinality. ACM Transactions on\nKnowledge Discovery from Data (TKDD) , 11(4):47, 2017.\n[13] M. Armbrust, R. S. Xin, C. Lian, Y. Huai, D. Liu, J. K. Bradley, X. Meng,\nT. Kaftan, M. J. Franklin, A. Ghodsi, et al. Spark sql: Relational data\nprocessing in spark. In Proceedings of the 2015 ACM SIGMOD inter-\nnational conference on management of data , pages 1383â€“1394. ACM,\n2015.\n[14] B. Babcock, S. Chaudhuri, and G. Das. Dynamic sample selection for\napproximate query processing. In Proceedings of the 2003 ACM SIGMOD\ninternational conference on Management of data , pages 539â€“550. ACM,\n2003.\n[15] L. Bottou. Stochastic gradient descent tricks. In Neural networks: Tricks\nof the trade , pages 421â€“436. Springer, 2012.\n[16] S. Chaudhuri, B. Ding, and S. Kandula. Approximate query processing:\nNo silver bullet. In Proceedings of the 2017 ACM International Conferenceon Management of Data , pages 511â€“519. ACM, 2017.\n[17] T. Chen and C. Guestrin. Xgboost: A scalable tree boosting system. In\nProceedings of the 22nd acm sigkdd international conference on knowl-\nedge discovery and data mining , pages 785â€“794. ACM, 2016.\n[18] J. Dean and S. Ghemawat. Mapreduce: simplified data processing on\nlarge clusters. Communications of the ACM , 51(1):107â€“113, 2008.\n[19] A. Dutt, C. Wang, A. Nazi, S. Kandula, V. Narasayya, and S. Chaudhuri.\nSelectivity estimation for range predicates using lightweight models.\nProceedings of the VLDB Endowment , 12(9):1044â€“1057, 2019.\n[20] B. Efron and R. J. Tibshirani. An introduction to the bootstrap . CRC\npress, 1994.\n[21] R. Foygel Barber, E. J. Candes, A. Ramdas, and R. J. Tibshirani. Pre-\ndictive inference with the jackknife+. arXiv preprint arXiv:1905.02928 ,\n2019.\n[22] J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical\nlearning , volume 1. Springer series in statistics New York, NY, USA:,\n2001.\n[23] J. H. Friedman. Greedy function approximation: a gradient boosting\nmachine. Annals of statistics , pages 1189â€“1232, 2001.\n[24] M. N. Garofalakis and P. B. Gibbons. Approximate query processing:\nTaming the terabytes. In VLDB , pages 343â€“352, 2001.\n[25] A. Gupta, D. Agarwal, D. Tan, J. Kulesza, R. Pathak, S. Stefani, and\nV. Srinivasan. Amazon redshift and the case for simpler data ware-\nhouses. In Proceedings of the 2015 ACM SIGMOD international confer-\nence on management of data , pages 1917â€“1923. ACM, 2015.\n[26] A. Hall, A. Tudorica, F. Buruiana, R. Hofmann, S.-I. Ganceanu, and\nT. Hofmann. Trading off accuracy for speed in powerdrill. 2016.\n[27] J. M. Hellerstein, P. J. Haas, and H. J. Wang. Online aggregation. In\nAcm Sigmod Record , volume 26, pages 171â€“182. ACM, 1997.\n[28] B. Hilprecht, A. Schmidt, M. Kulessa, A. Molina, K. Kersting, and\nC. Binnig. Deepdb: Learn from data, not from queries! arXiv preprint\narXiv:1909.00607 , 2019.\n[29] S. Idreos, O. Papaemmanouil, and S. Chaudhuri. Overview of data\nexploration techniques. In Proceedings of the 2015 ACM SIGMOD\nInternational Conference on Management of Data , pages 277â€“281. ACM,\n2015.\n[30] S. Kandula, K. Lee, S. Chaudhuri, and M. Friedman. Experiences with\napproximating queries in microsoftâ€™s production big-data clusters.\nProceedings of the VLDB Endowment , 12(12):2131â€“2142, 2019.\n[31] S. Kandula, A. Shanbhag, A. Vitorovic, M. Olma, R. Grandl, S. Chaud-\nhuri, and B. Ding. Quickr: Lazily approximating complex adhoc queries\nin bigdata clusters. In Proceedings of the 2016 International Conference\non Management of Data , pages 631â€“646. ACM, 2016.\n[32] G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T.-Y.\nLiu. Lightgbm: A highly efficient gradient boosting decision tree. In\nAdvances in Neural Information Processing Systems , pages 3146â€“3154,\n2017.\n[33] A. Kipf, T. Kipf, B. Radke, V. Leis, P. Boncz, and A. Kemper. Learned\ncardinalities: Estimating correlated joins with deep learning. arXiv\npreprint arXiv:1809.00677 , 2018.\n[34] A. Kipf, D. Vorona, J. MÃ¼ller, T. Kipf, B. Radke, V. Leis, P. Boncz, T. Neu-\nmann, and A. Kemper. Estimating cardinalities with deep sketches.\nInProceedings of the 2019 International Conference on Management of\nData , SIGMOD â€™19, pages 1937â€“1940, New York, NY, USA, 2019. ACM.\n[35] R. Koenker and K. F. Hallock. Quantile regression. Journal of economic\nperspectives , 15(4):143â€“156, 2001.\n[36] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The case\nfor learned index structures. In Proceedings of the 2018 International\nConference on Management of Data , pages 489â€“504. ACM, 2018.\n[37] M. Kuhn and K. Johnson. Applied predictive modeling , volume 26.\nSpringer, 2013.\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\n[38] M. Kulessa, A. Molina, C. Binnig, B. Hilprecht, and K. Kersting. Model-\nbased approximate query processing. arXiv preprint arXiv:1811.06224 ,\n2018.\n[39] J. Lei, M. GÅšell, A. Rinaldo, R. J. Tibshirani, and L. Wasserman.\nDistribution-free predictive inference for regression. Journal of the\nAmerican Statistical Association , 113(523):1094â€“1111, 2018.\n[40] Z. Liu and J. Heer. The effects of interactive latency on exploratory vi-\nsual analysis. IEEE Transactions on Visualization & Computer Graphics ,\npages 1â€“1, 2014.\n[41] Q. Ma and P. Triantafillou. Dbest: Revisiting approximate query pro-\ncessing engines with machine learning models. In Proceedings of the\n2019 International Conference on Management of Data , pages 1553â€“1570.\nACM, 2019.\n[42] R. Marcus, P. Negi, H. Mao, C. Zhang, M. Alizadeh, T. Kraska, O. Pa-\npaemmanouil, and N. Tatbul. Neo: A learned query optimizer. Proc.\nVLDB Endow. , 12(11):1705â€“1718, July 2019.\n[43] N. Meinshausen. Quantile regression forests. Journal of Machine\nLearning Research , 7(Jun):983â€“999, 2006.\n[44] M. Olma, O. Papapetrou, R. Appuswamy, and A. Ailamaki. Taster:\nSelf-tuning, elastic and online approximate query processing. In 2019\nIEEE 35th International Conference on Data Engineering (ICDE) , pages\n482â€“493. IEEE, 2019.\n[45] J. Ortiz, M. Balazinska, J. Gehrke, and S. S. Keerthi. An empirical\nanalysis of deep learning for cardinality estimation. arXiv preprint\narXiv:1905.06425 , 2019.\n[46] H. Papadopoulos, V. Vovk, and A. Gammerman. Regression conformal\nprediction with nearest neighbours. Journal of Artificial Intelligence\nResearch , 40:815â€“840, 2011.\n[47] Y. Park, B. Mozafari, J. Sorenson, and J. Wang. Verdictdb: universalizing\napproximate query processing. In Proceedings of the 2018 International\nConference on Management of Data , pages 1461â€“1476. ACM, 2018.\n[48] Y. Park, A. S. Tajik, M. Cafarella, and B. Mozafari. Database learning:\nToward a database that becomes smarter every time. In Proceedings of\nthe 2017 ACM International Conference on Management of Data , pages\n587â€“602. ACM, 2017.\n[49] N. Potti and J. M. Patel. Daq: a new paradigm for approximate query\nprocessing. Proceedings of the VLDB Endowment , 8(9):898â€“909, 2015.\n[50] Y. Romano, E. Patterson, and E. J. CandÃ¨s. Conformalized quantile\nregression. arXiv preprint arXiv:1905.03222 , 2019.\n[51] S. T. Roweis and L. K. Saul. Nonlinear dimensionality reduction by\nlocally linear embedding. science , 290(5500):2323â€“2326, 2000.\n[52] K. Sato. An inside look at google bigquery. White paper, URL:\nhttps://cloud. google. com/files/BigQueryTechnicalWP. pdf , 2012.\n[53] G. Shafer and V. Vovk. A tutorial on conformal prediction. Journal of\nMachine Learning Research , 9(Mar):371â€“421, 2008.\n[54] I. Steinwart, A. Christmann, et al. Estimating conditional quantiles\nwith the help of the pinball loss. Bernoulli , 17(1):211â€“225, 2011.\n[55] J. Sun and G. Li. An end-to-end learning-based cost estimator. Pro-\nceedings of the VLDB Endowment , 13(3):307â€“319, 2019.\n[56] I. Takeuchi, Q. V. Le, T. D. Sears, and A. J. Smola. Nonparametric\nquantile estimation. Journal of machine learning research , 7(Jul):1231â€“\n1264, 2006.\n[57] M. A. Tanner and W. H. Wong. The calculation of posterior distri-\nbutions by data augmentation. Journal of the American statistical\nAssociation , 82(398):528â€“540, 1987.\n[58] S. Thirumuruganathan, S. Hasan, N. Koudas, and G. Das. Approxi-\nmate query processing using deep generative models. arXiv preprint\narXiv:1903.10000 , 2019.\n[59] Z. Wang, D. Cashman, M. Li, J. Li, M. Berger, J. A. Levine, R. Chang,\nand C. Scheidegger. Neuralcubes: Deep representations for visual data\nexploration. arXiv preprint arXiv:1808.08983 , 2018.[60] A. Wasay, X. Wei, N. Dayan, and S. Idreos. Data canopy: Accelerat-\ning exploratory statistical analysis. In Proceedings of the 2017 ACM\nInternational Conference on Management of Data , pages 557â€“572. ACM,\n2017.\n[61] L. Woltmann, C. Hartmann, M. Thiele, D. Habich, and W. Lehner.\nCardinality estimation with local deep learning models. In Proceedings\nof the Second International Workshop on Exploiting Artificial Intelligence\nTechniques for Data Management , pages 1â€“8, 2019.\n[62] Z. Yang, E. Liang, A. Kamsetty, C. Wu, Y. Duan, X. Chen, P. Abbeel,\nJ. M. Hellerstein, S. Krishnan, and I. Stoica. Selectivity estimation with\ndeep likelihood models. arXiv preprint arXiv:1905.04278 , 2019.\n[63] M. Zaharia, R. S. Xin, P. Wendell, T. Das, M. Armbrust, A. Dave,\nX. Meng, J. Rosen, S. Venkataraman, M. J. Franklin, et al. Apache\nspark: a unified engine for big data processing. Communications of the\nACM , 59(11):56â€“65, 2016.\n[64] K. Zeng, S. Agarwal, A. Dave, M. Armbrust, and I. Stoica. G-ola:\nGeneralized on-line aggregation for interactive analysis on big data.\nInProceedings of the 2015 ACM SIGMOD International Conference on\nManagement of Data , pages 913â€“918. ACM, 2015.\n[65] K. Zeng, S. Gao, B. Mozafari, and C. Zaniolo. The analytical bootstrap: a\nnew method for fast error estimation in approximate query processing.\nInProceedings of the 2014 ACM SIGMOD international conference on\nManagement of data , pages 277â€“288. ACM, 2014.\n\nML-AQP: Query-Driven Approximate Query Processing based on Machine Learning Woodstock â€™18, June 03â€“05, 2018, Woodstock, NY\nA APPENDIX\nA.1 Restricting Dimensionality of the\nQuery Representation\nAs the number of columns (attributes, dimensions) gets larger,\nour representation will be moving towards a high-dimensional\nspace causing problems to our underlying ML models. One\nway to tackle this is to use unsupervised dimensionality\nreduction techniques [ 51], which will reduce the dimension-\nality of our given query vectors. Another, more straightfor-\nward way to tackle this is to restrict the number of columns\nwe built our ML models over. As examined queries focus on\na subset of the original column set [ 9,60], allowing us to use\na heuristic to build ML models only over the most frequently\nused columns or the columns of the highest importance to\nthe analysts. Especially, in the case of spatio-temporal data\nsets the focus is usually on the spatial and temporal dimen-\nsions to which an analyst applies filters and then examines\ndescriptive statistics over other columns.\nA.2 Sensitivity Analysis\n0123Relative Error (%)\nAggregate: count\n2 5 10 20\nAggregate: sum\n10 20 50100\nColumns0123Relative Error (%)\nAggregate: mean\n10 20 50100\nColumns\nAggregate: max\nFigure 17: Relative Error (y-axis) measured across\ndifferent aggregates with an increasing number of\ncolumns/attributes (x-axis) and a varying number of\npredicates set randomly.\nIn this section of our experimental analysis, we study a va-\nriety of variables contributing to the accuracy of our solution.\nFor these experiments, we use the synthetic dataset to con-\ntrol the number of attributes and predicates set. Queries with\nmeta-vectors up to 200,mâˆˆR200, are executed over uniform\nspaces with the number of set predicates up to 507. All predi-\ncates are numerical and each query vector is associated with\na response. The predicates essentially define range queries\n7Note to reviewers: A public Github repository with instructions on how to\ngenerate the synthetic datasets as well as automated scripts will be made\navailable. It is merely omitted to adhere to the double-blind constraint.over the respective columns. To put this in perspective, real\nworkloads expect a median number of columns selected in a\nquery around 8[31] with a more recent estimate reporting\nthat 90% of queries use around 1âˆ’6[30] columns with a\nmaximum reaching 12. We increase the number of predicates\nand columns to study the effects on accuracy. We initially\ntrain the models on a constant number of queries 10,000and\nvary the number of predicates and columns/attributes. In\naddition, we test different aggregates, COUNT ,SUM,MEAN /AVG\nandMAX, to examine their predictability. In essence, ML-AQP\nis agnostic to what kind of aggregate is being predicted, to\nML-AQP an AF applied over an attribute is a response vari-\nable to which it tries to identify patterns that can help it\nminimize the loss L(y,Ë†y).\nAs can be seen at Figure 17, the relative error increases\nw.r.t. the number of columns and predicates. Although there\nis not a notable increase ( 2%), we can attribute this to the\nfact that more queries might be needed to learn a more com-\nplex space. As the dimensionality of the space (number of\ncolumns) increases, the number of predicates increasingly\nrestricts the sub-spaces defined by the queries. In addition,\nForMEAN andMAX, we do not observe large differences in\nrelative error. Closely, examining the workloads we notice\nthat the Coefficient of Variation (CoV), defined by the stan-\ndard deviation to the mean ration:Ïƒ\nÂµis0.08for the response\nyofMEAN and 0.01for the response MAX. Where the CoV\nshows the extent of the variability in relation to the mean. A\nCoV value closer to 1indicates high variability. Therefore,\nML-AQP might be able to learn their distributions with less\nqueries.\n2.55.07.510.012.515.0Relative Error (%)\nAggregate: count\n2 5 10 20\n2.55.07.510.012.515.017.5\nAggregate: sum\n1002003004005006007008009001000\nQueries2.55.07.510.012.515.017.5Relative Error (%)\nAggregate: mean\n1002003004005006007008009001000\nQueries0.02.55.07.510.012.515.0\nAggregate: max\nFigure 18: Relative Error (y-axis) measured across\ndifferent aggregates with an increasing number of\nqueries (x-axis) used for training.\nFigure 18 shows how relative error decreases as the num-\nber of queries that a model is trained on increases. For all\naggregates, we notice that the effect the number of queries\nhas started to diminish and nothing more can be learned.\n\nWoodstock â€™18, June 03â€“05, 2018, Woodstock, NY Fotis Savva, Christos Anagnostopoulos, and Peter Triantafillou\nThis provides an approximation to the number of queries\nneeded to model the specific aggregates under this work-\nload. It also denotes that after exceeding a certain number\nof queries, we should then focus on the complexity of our\nmodel to further decrease the relative error. In addition, for\nMEAN andMAX, we see high standard deviation for relativeerror across settings, especially when the number of queries\nis small. This advises us that as the number of queries is\nsmall, relative error is largely determined by the complexity\nof the workload (dimensionality, sparsity). However, as more\nand more queries are being used to train the models this\neffect fades away.",
  "textLength": 87488
}