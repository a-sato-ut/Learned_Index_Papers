{
  "paperId": "0fe6fcfbb5f090e0b8a5c5e8fce6d991bef0159e",
  "title": "A Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks",
  "pdfPath": "0fe6fcfbb5f090e0b8a5c5e8fce6d991bef0159e.pdf",
  "text": "A Robust Optimisation Perspective on\nCounterexample-Guided Repair of Neural Networks\nDavid Boetius1Stefan Leue1Tobias Sutter1\nAbstract\nCounterexample-guided repair aims at creat-\ning neural networks with mathematical safety\nguarantees, facilitating the application of neu-\nral networks in safety-critical domains. How-\never, whether counterexample-guided repair is\nguaranteed to terminate remains an open ques-\ntion. We approach this question by showing that\ncounterexample-guided repair can be viewed as a\nrobust optimisation algorithm. While termination\nguarantees for neural network repair itself remain\nbeyond our reach, we prove termination for more\nrestrained machine learning models and disprove\ntermination in a general setting. We empirically\nstudy the practical implications of our theoretical\nresults, demonstrating the suitability of common\nverifiers and falsifiers for repair despite a disad-\nvantageous theoretical result. Additionally, we\nuse our theoretical insights to devise a novel algo-\nrithm for repairing linear regression models based\non quadratic programming, surpassing existing\napproaches.\n1. Introduction\nThe success of artificial neural networks in such diverse\ndomains as image recognition (LeCun et al., 1998), natu-\nral language processing (Brown et al., 2020), predicting\nprotein folding (Senior et al., 2020), and designing novel\nalgorithms (Fawzi et al., 2022) sparks interest in applying\nthem to more demanding tasks, including applications in\nsafety-critical domains. Neural networks are proposed to\nbe used for medical diagnosis (Amato et al., 2013), au-\ntonomous aircraft control (Jorgensen, 1997; Julian et al.,\n2018), and self-driving cars (Bojarski et al., 2016). Since a\nmalfunctioning of such systems can threaten lives or cause\n1Department of Computer and Information Science, University\nof Konstanz, Konstanz, Baden-W ¨urttemberg, Germany. Corre-\nspondence to: David Boetius <david.boetius@uni-konstanz.de >.\nAccepted at the 40thInternational Conference on Machine Learn-\ning, Copyright 2023 by the authors. This work is licensed under a\nCreative Commons Attribution 4.0 International License cbenvironmental disaster, we require mathematical guarantees\non the correct functioning of the neural networks involved.\nFormal methods, including verification and repair, allow\nobtaining such guarantees (Pulina & Tacchella, 2010). As\nthe inner workings of neural networks are opaque to human\nengineers, automated repair is a vital component for creating\nsafe neural networks.\nAlternating search for violations and removal of violations\nis a popular approach for repairing neural networks (Pulina\n& Tacchella, 2010; Goodfellow et al., 2015; Guidotti et al.,\n2019a; Dong et al., 2021; Goldberger et al., 2020; Sivaraman\net al., 2020; Tan et al., 2021; Bauer-Marquart et al., 2022).\nWe study this approach under the name counterexample-\nguided repair . Counterexample-guided repair uses inputs\nfor which a neural network violates the specification (coun-\nterexamples) to iteratively refine the network until the net-\nwork satisfies the specification. While empirical results\ndemonstrate the ability of counterexample-guided repair to\nsuccessfully repair neural networks (Bauer-Marquart et al.,\n2022), a theoretical analysis of counterexample-guided re-\npair is lacking.\nIn this paper, we study counterexample-guided repair\nfrom the perspective of robust optimisation. Viewing\ncounterexample-guided repair as an algorithm for solving\nrobust optimisation problems allows us to encircle neural\nnetwork repair from two sides. On the one hand side, we are\nable to show termination and optimality for counterexample-\nguided repair of linear regression models and linear clas-\nsifiers, as well as single ReLU neurons. Coming from the\nother side, we disprove termination for repairing ReLU net-\nworks to satisfy a specification with an unbounded input set.\nAdditionally, we disprove termination of counterexample-\nguided repair when using generic counterexamples without\nfurther qualifications, such as being most-violating. While\nwe could not address termination for the precise robust pro-\ngram of neural network repair with specifications having\nbounded input sets, such as L∞adversarial robustness or\nthe ACAS Xu safety properties (Katz et al., 2017), our ro-\nbust optimisation framework provides, for the first time to\nthe best of our knowledge, fundamental insights into the\ntheoretical properties of counterexample-guided repair.\nOur analysis establishes a theoretical limitation of repair\n1arXiv:2301.11342v2  [cs.LG]  5 Jun 2023\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nwith otherwise unqualified counterexamples and suggests\nmost-violating counterexamples as a replacement. We em-\npirically investigate the practical consequences of these find-\nings by comparing early-exit verifiers — verifiers that stop\nsearch on the first counterexample they encounter — and\noptimal verifiers that produce most-violating counterexam-\nples. We complement this experiment by investigating the\nadvantages of using falsifiers during repair (Bauer-Marquart\net al., 2022), which is another approach that leverages sub-\noptimal counterexamples. These experiments do not reveal\nany practical limitations for repair using early-exit verifiers.\nIn fact, using an early-exit verifier consistently yields faster\nrepair for ACAS Xu networks (Katz et al., 2017) and an\nMNIST (LeCun et al., 1998) network, compared to using\nan optimal verifier. While the optimal verifier often allows\nperforming fewer iterations, this advantage is offset by its\nadditional runtime cost most of the time. Our experiments\nwith falsifiers demonstrate that they can provide a significant\nruntime advantage for neural network repair.\nFor repairing linear regression models, we use our theoreti-\ncal insights to design an improved repair algorithm based\non quadratic programming. We compare this new algo-\nrithm with the Ouroboros (Tan et al., 2021) and SpecRe-\npair (Bauer-Marquart et al., 2022) repair algorithms. The\nnew quadratic programming repair algorithm surpasses\nOuroboros and SpecRepair, illustrating the practical rel-\nevance of our theoretical results.\nWe highlight the following main contributions of this paper:\n1.We formalise neural network repair as a robust optimi-\nsation problem and, therefore, view counterexample-\nguided repair as a robust optimisation algorithm.\n2.Using this theoretical framework, we prove termination\nof counterexample-guided repair for more restrained\nproblems than neural network repair and disprove ter-\nmination in a more general setting.\n3.We empirically investigate the merits of using falsifiers\nand early-exit verifiers during repair.\n4.Our theoretical insights into repairing linear regression\nmodels allow us to surpass existing approaches for\nrepairing linear regression models using a new repair\nalgorithm.\n2. Related Work\nThis paper is concerned with viewing neural network repair\nthrough the lens of robust optimisation. Neural network\nrepair relies on neural network verification and can make\nuse of neural network falsification. Counterexample-guided\nrepair is related to other counterexample-guided algorithms.\nWe introduce related work from these fields in this section.Neural Network Verification We can verify neural net-\nworks, for example, using Satisfiability Modulo Theo-\nries (SMT) solving (Katz et al., 2017; Ehlers, 2017) or\nMixed Integer Linear Programming (MILP) (Tjeng et al.,\n2019). Verification benefits from bounds computed using\nlinear relaxations (Ehlers, 2017; Singh et al., 2018; Zhang\net al., 2018; Xu et al., 2021). A particularly fruitful tech-\nnique from MILP is branch and bound (Bunel et al., 2018;\nPalma et al., 2021; Wang et al., 2021). Approaches that\ncombine branch and bound with multi-neuron linear relax-\nations (Ferrari et al., 2022) or extend branch and bound\nusing cutting planes (Zhang et al., 2022b) form the current\nstate-of-the-art (M ¨uller et al., 2022).\nFalsifiers are designed to discover counterexamples fast at\nthe cost of completeness — they can not prove specification\nsatisfaction. We view adversarial attacks as falsifiers for\nadversarial robustness specifications. Falsifiers use generic\nlocal optimisation algorithms (Szegedy et al., 2014; Good-\nfellow et al., 2015; Kurakin et al., 2017; Madry et al., 2018),\nglobal optimisation algorithms (Uesato et al., 2018; Bauer-\nMarquart et al., 2022), or specifically tailored search and\noptimisation techniques (Papernot et al., 2015; Chen et al.,\n2020).\nNeural Network Repair Neural network repair is con-\ncerned with modifying a neural network such that it satisfies\na formal specification. Many approaches make use of the\ncounterexample-guided repair algorithm while utilising dif-\nferent counterexample-removal algorithms. The approaches\nrange from augmenting the training set (Pulina & Tacchella,\n2010; Goodfellow et al., 2015; Tan et al., 2021), over spe-\ncialised neural network architectures (Guidotti et al., 2019a;\nDong et al., 2021), and neural network training with con-\nstraints (Bauer-Marquart et al., 2022), to using a verifier\nfor computing network weights (Goldberger et al., 2020).\nCounterexample-guided repair is also applied to support vec-\ntor machines (SVMs) and linear regression models (Guidotti\net al., 2019b; Tan et al., 2021). Using decoupled neural\nnetworks (Sotoudeh & Thakur, 2021) provides optimality\nand termination guarantees for repair but is limited to two-\ndimensional input spaces.\nWhen considering only adversarial robustness, an alternative\nto counterexample-guided repair is provably robust train-\ning. Here, the applied techniques include interval arith-\nmetic (Gowal et al., 2018), semi-definite relaxations (Raghu-\nnathan et al., 2018), linear relaxations (Mirman et al., 2018),\nand duality (Wong & Kolter, 2018). Also specialised neural\nnetwork architectures can increase the adversarial robust-\nness of neural networks (Ciss ´e et al., 2017; Zhang et al.,\n2022a).\nRobust and Scenario Optimisation Robust optimisa-\ntion is, originally, a technique for dealing with data uncer-\ntainty (Ben-Tal et al., 2009). Although robust optimisation\n2\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nproblems are, in general, NP-hard (Ben-Tal & Nemirovski,\n1998), polynomial-time methods exist in many —typically\nconvex — settings (Ben-Tal et al., 2009). Scenario problems\nand chance-constrained problems relax robust problems.\nFeasibility for a scenario problem can be linked to feasi-\nbility for a chance-constrained problem (Campi & Garatti,\n2008) and even to a perturbed robust problem (Esfahani\net al., 2015). In this paper, we consider the worst-case per-\nspective on robust optimisation (Mutapcic & Boyd, 2009).\nLoss functions based on robust optimisation can be used to\ntrain for adversarial robustness and beyond (Madry et al.,\n2018; Wong & Kolter, 2018; Fischer et al., 2019). We\nstudy a different robust optimisation formulation, where the\nspecification is modelled as constraints.\nCounterexample-Guided Algorithms Besides neural\nnetwork repair, counterexample-guided approaches are also\nused in model checking (Clarke et al., 2000), program syn-\nthesis (Solar-Lezama et al., 2006), and beyond (Henzinger\net al., 2003; Reynolds et al., 2015; Nguyen et al., 2017).\nThe notion of minimal counterexamples in program syn-\nthesis (Jha & Seshia, 2014), which is based on an ordering\nof the counterexamples, encompasses our notion of most-\nviolating counterexamples. While related, the termination\nresults for counterexample-guided program synthesis (Solar-\nLezama et al., 2006) do not transfer to repairing neural net-\nworks, as they only apply for finite input domains. We study\ninfinite input domains in this paper.\n3. Preliminaries and Problem Statement\nIn this section, we introduce preliminaries on robust optimi-\nsation, neural networks, and neural network verification be-\nfore progressing to neural network repair, counterexample-\nguided repair, and the problem statement of our theoretical\nanalysis.\n3.1. Robust Optimisation\nWe consider general robust optimisation problems of the\nform\nP:\n\nminimise\nvf(v)\nsubject to g(v,d)≥0∀d∈ D\nv∈ V,(1)\nwhere V ⊆Rv,D ⊆Rdandf:V →R,g:V × D → R.\nBothVandDcontain infinitely many elements. There-\nfore, a robust optimisation problem has infinitely many con-\nstraints. The variable domain Vdefines eligible values for\ntheoptimisation variable v. The set Dmay contain, for\nexample, all inputs for which a specification needs to hold.\nIn this example, gcaptures whether the specification is sat-\nisfied for a concrete input. Elaborating this example leads\nto neural network repair, which we introduce in Section 3.4.Ascenario optimisation problem relaxes a robust opti-\nmisation problem by replacing the infinitely many con-\nstraints of Pwith a finite selection. For d(i)∈ D ,i∈\n{1, . . . , N },N∈N, the scenario optimisation problem is\nSP:\n\nminimise\nvf(v)\nsubject to g\u0000\nv,d(i)\u0001\n≥0∀i∈ {1, . . . , N }\nv∈ V.(2)\nThe counterexample-guided repair algorithm that we study\nin this paper uses a sequence of scenario optimisation prob-\nlems to solve a robust optimisation problem.\n3.2. Neural Networks\nA neural network netθ:Rn→Rm, with parameters θ∈\nRpis a function composition of affine transformations and\nnon-linear activations. For our theoretical analysis, it suf-\nfices to consider fully-connected neural networks (FCNN).\nOur experiments in Section 5 also use convolutional neural\nnetworks (CNN). We refer to Goodfellow et al. (2016) for\nan introduction to CNNs. An FCNN with Lhidden layers\nis a chain of affine functions and activation functions\nnetθ=h(L+1)◦σ(L)◦h(L)◦ ··· ◦ σ(1)◦h(1),(3)\nwhere h(i):Rni−1→Rniandσ(i):Rni→Rni\nwithni∈Nfori∈ {0, . . . , L +1}and, specifically, n0=n\nandnL+1=m. Each h(i)is an affine function, called an\naffine layer . It computes h(i)(z) =W(i)z+b(i)with\nweight matrix W(i)∈Rni×ni−1andbias vector b(i)∈\nRni. Stacked into one large vector, the weights and biases\nof all affine layers are the parameters θof the FCNN. An\nactivation layer σ(i)applies a non-linear function, such as\nReLU [z]+= max(0 , z)or the sigmoid function σ(z) =\n1\n1+e−zin an element-wise fashion.\n3.3. Neural Network Verification\nNeural network verification is concerned with automatically\nproving that a neural network satisfies a formal specification.\nDefinition 3.1 (Specification) .Aspecification Φ =\n{φ1, . . . , φ S}is a set of properties φi. A property φ=\n(Xφ,Yφ)is a tuple of an input set Xφ⊆Rnand an output\nsetYφ⊆Rm.\nWe write netθ⊨Φwhen a neural network netθ:Rn→\nRmsatisfies a specification Φ. Specifically,\nnetθ⊨Φ⇔ ∀φ∈Φ : net θ⊨φ (4a)\nnetθ⊨φ⇔ ∀x∈ Xφ: net θ(x)∈ Yφ. (4b)\nExample specifications, such as L∞adversarial robustness\nor an ACAS Xu safety specification (Katz et al., 2017) are\ndefined in Appendix C.\n3\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nCounterexamples are at the core of the counterexample-\nguided repair algorithm that we study in this paper.\nDefinition 3.2 (Counterexample) .An input x∈ X φfor\nwhich a neural network netθviolates a property φis called\nacounterexample .\nTo define verification as an optimisation problem, we intro-\nduce satisfaction functions . A satisfaction function quan-\ntifies the satisfaction or violation of a property regarding\nthe output set. Definition 3.4 introduces the verification\nproblem, also taking the input set of a property into account.\nDefinition 3.3 (Satisfaction Function) .A function fSat:\nRm→Ris a satisfaction function of a property φ=\n(Xφ,Yφ)ify∈ Yφ⇔fSat(y)≥0.\nDefinition 3.4 (Verification Problem) .Theverification prob-\nlemfor a property φ= (Xφ,Yφ)and a neural network netθ\nis\nV:f∗\nSat=(\nminimise\nxfSat(net θ(x))\nsubject to x∈ Xφ.(5)\nWe call a specification a linear specification when its prop-\nerties have a closed convex polytope as an input set and an\naffine satisfaction function. Appendix C contains several\nexamples of satisfaction functions from SpecRepair (Bauer-\nMarquart et al., 2022). The following Proposition follows\ndirectly from the definition of a satisfaction function.\nProposition 3.5. A neural network netθsatisfies the prop-\nertyφif and only if the minimum of the verification prob-\nlemV(f∗\nSat) is non-negative.\nWe now consider counterexample searchers that evaluate\nthe satisfaction function for concrete inputs to compute an\nupper bound on the minimum of the verification problem V.\nSuch tools can disprove specification satisfaction by discov-\nering a counterexample. They can also prove specification\nsatisfaction when they are sound andcomplete .\nDefinition 3.6 (Soundness and Completeness) .We call a\ncounterexample searcher sound if it computes valid upper\nbounds and complete if it is guaranteed to find a counterex-\nample whenever a counterexample exists.\nDefinition 3.7 (Verifiers and Falsifiers) .We call a sound\nand complete counterexample searcher a verifier . A sound\nbut incomplete counterexample searcher is a falsifier .\nDefinition 3.8 (Optimal and Early-Exit Verifiers) .Anop-\ntimal verifier is a verifier that always produces a global\nminimiser of the verification problem — a most-violating\ncounterexample . An early-exit verifier aborts on the first\ncounterexample it encounters. It provides any counterexam-\nple, without further qualifications.\nWe can perform verification through global minimisation of\nthe verification problem from Equation (5). For ReLU-activated neural networks, global minimisation is possi-\nble, for example, using Mixed Integer Linear Program-\nming (MILP) (Cheng et al., 2017; Lomuscio & Maganti,\n2017). Falsifiers may perform local optimisation using pro-\njected gradient descent (PGD) (Kurakin et al., 2017; Madry\net al., 2018) to become sound but not complete. We name\nthe approach of using PGD for falsification BIM, abbreviat-\ning the name Basic Iterative Method used by Kurakin et al.\n(2017).\n3.4. Neural Network Repair\nNeural network repair means modifying a trained neural\nnetwork so that it satisfies a specification it would otherwise\nviolate. While the primary goal of repair is satisfying the\nspecification, the key secondary goal is that the repaired\nneural network still performs well on the intended task.\nThis secondary goal can be captured using a performance\nmeasure, such as the training loss function (Bauer-Marquart\net al., 2022) or the distance between the modified and the\noriginal network parameters (Goldberger et al., 2020).\nDefinition 3.9 (Repair Problem) .Given a neural net-\nwork netθ, a property φ= (Xφ,Yφ)and a performance\nmeasure J:Rp→R, repair translates to solving the repair\nproblem\nR:(\nminimise\nθ∈RpJ(θ)\nsubject to fSat(net θ(x))≥0∀x∈ Xφ.(6)\nThe repair problem Ris an instance of a robust optimisation\nproblem as defined in Equation (1). Checking whether a\nparameter θis feasible for Rcorresponds to verification.\nIn particular, we can equivalently reformulate Rusing the\nverification problem’s minimum f∗\nSatfrom Equation (5) as\nR′:(\nminimise\nθ∈RpJ(θ)\nsubject to f∗\nSat≥0.(7)\nWe stress several characteristics of the repair problem that\nwe relax or strengthen in Section 4. First of all, netθis a\nneural network and we repair all parameters θof the network\njointly. Practically, netθis a ReLU-activated FCNN or\nCNN, as these are the models most verifiers support. For\ntypical specifications, such as L∞adversarial robustness or\nthe ACAS Xu safety specifications (Katz et al., 2017), the\nproperty input set Xφis a hyper-rectangle. Hyper-rectangles\nare closed convex polytopes and, therefore, bounded.\n3.5. Counterexample-Guided Repair\nIn the previous section, we have seen that the repair problem\nincludes the verification problem as a sub-problem. Using\nthis insight, a natural approach to tackle the repair problem\n4\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nAlgorithm 1 Counterexample-Guided Repair\nN←0\nrepeat\n// counterexample-removal (8)\nθ(N)←local minimiser of CRN\nN←N+ 1\n// verification (9)\nx(N)←global minimiser of VN\nuntil fSat\u0000\nnetθ(N−1)\u0000\nx(N)\u0001\u0001\n≥0\nis to iterate running a verifier and removing the counterex-\namples it finds. This yields the counterexample-guided\nrepair algorithm, that was first introduced by Goldberger\net al. (2020), in a similar form. Removing counterexamples\ncorresponds to a scenario optimisation problem CRNof the\nrobust optimisation problem Rfrom Equation (6), where\nCRN:\n\nminimise\nθ∈RpJ(θ)\nsubject to fSat\u0000\nnetθ\u0000\nx(i)\u0001\u0001\n≥0\n∀i∈ {1, . . . , N }.(8)\nAlgorithm 1 defines the counterexample-guided repair al-\ngorithm using CRNandVfrom Equation (5). In analogy\ntoCRN, we use VNto denote the verification problem in\niteration N. Concretely,\nVN:(\nminimise\nxfSat(netθ(N−1)(x))\nsubject to x∈ Xφ.(9)\nWe call the iterations of Algorithm 1 repair steps .\nAlgorithm 1 is concerned with repairing a single property.\nHowever, the algorithm extends to repairing multiple proper-\nties by adding one constraint for each property to CRNand\nverifying the properties separately. While Algorithm 1 is\nformulated for the repair problem R, it is easy to generalise\nit to any robust program Pas defined in Equation (1). Then,\nsolving CRNcorresponds to solving SPfrom Equation (2)\nand solving VNcorresponds to finding maximal constraint\nviolations of P.\nThe question we are concerned with in this paper is\nwhether Algorithm 1 is guaranteed to terminate after finitely\nmany repair steps. We investigate this question in the fol-\nlowing section by studying robust programs that are similar\nto the repair problem for neural networks and typical speci-\nfications, but either more restrained or more general.\n4. Termination Results for Algorithm 1\nThe counterexample-guided repair algorithm (Algorithm 1)\nrepairs neural networks by iteratively searching and remov-\ning counterexamples. In this section, we study whether\nAlgorithm 1 is guaranteed to terminate and whether it pro-\nduces optimally repaired networks. Our primary focus isTable 1: Symbol Overview\nSymbol Meaning\nR Repair Problem (6)\nCRN Counterexample Removal Problem (8)\nVN Verification Problem for netθ(N−1)(9)\nθ†(Local) minimiser of R\nθ(N)(Local) minimiser of CRN\nx(N)Global minimiser of VN\non studying robust optimisation problems that are more re-\nstrained or more general than the repair problem Rfrom\nEquation (6). We apply Algorithm 1 to such problems and\nstudy termination of the algorithm for these problems. On\nour way, we also address the related questions of optimality\non termination and termination when using an early-exit\nverifier as introduced in Definition 3.8.\nTable 1 summarises the central problem and variable names\nthat we use throughout this paper. The iterations of Algo-\nrithm 1 are called repair steps . We count the repair steps\nstarting from one but index the counterexample-removal\nproblems starting from zero, reflecting the number of con-\nstraints. Hence, the minimiser of the counterexample-\nremoval problem CRN−1from Equation (8)in repair\nstepNisθ(N−1). The verification problem in repair step N\nisVNwith a global minimiser x(N).\n4.1. Optimality on Termination\nWe prove that when applied to any robust program Pas\ndefined in Equation (1), counterexample-guided repair pro-\nduces a minimiser of Pwhenever it terminates. While\nAlgorithm 1 is formulated for the repair problem R, it is\neasy to generalise it to P, as described in Section 3.5. The\nfollowing proposition holds regardless of whether we search\nfor a local minimiser or a global minimiser of R.\nProposition 4.1 (Optimality on Termination) .When-\never Algorithm 1 terminates after Niterations, it holds\nthatθ(N−1)=θ†.\nWe defer the proof of Proposition 4.1 to Appendix A.1.\n4.2. Non-Termination for General Robust Programs\nIn this section, we demonstrate non-termination and diver-\ngence of Algorithm 1 when we relax the assumptions on\nthe repair problem Rthat we outline in Section 3.4. In\nparticular, we drop the assumption that the property’s input\nsetXφis bounded. We disprove termination by example\nwhenXφis unbounded. To simplify the proof, we use a\nnon-standard neural network architecture. We also present a\nfully-connected neural network (FCNN) that similarly leads\nto non-termination. However, for this FCNN we also have\n5\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nto relax the assumption that we repair all parameters of a\nneural network jointly. Instead, we repair an individual\nparameter of the FCNN in isolation.\nProposition 4.2 (General Non-Termination) .Algorithm 1\nis not guaranteed to terminate for J:R2→R,fSat:\nR2→R, and netθ:R→R2, where J(θ) =\nnetθ(0)1,fSat(y) =y2+y1−1,Xφ=R, and\nnetθ(x) =\u0014\u0012θ1θ2\nθ1x+θ2\u0013\u0015+\n, (10)\nwhere [x]+= max(0 , x)denotes the ReLU.\nProof Idea. The network in Proposition 4.2 is constructed\nsuch that it allows for an execution of Algorithm 1 where\nthe counterexamples x(N)and the parameter iterates θ(N)\ndiverge, such that Algorithm 1 does not terminate. The\ndetailed proof and a visualisation of this phenomenon are\ncontained in Appendix A.2.\nExample 1 (Non-Termination for an FCNN) .The network\nin Proposition 4.2 fits our definition of a neural network\nbut does not have a standard neural network architecture.\nHowever, Algorithm 1 also does not terminate for repairing\nonly the parameter θof the FCNN\nnetθ(x) =\"\u0012−1 0\n1−1\u0013\u0014\u00120\n1\u0013\nx+\u0012θ\n2\u0013\u0015+\n+\u00122\n0\u0013#+\n,(11)\nwhen fSatandJ(θ)are as in Proposition 4.2. The proof\nof non-termination for this FCNN is discussed in Ap-\npendix A.2.1.\n4.3. Robust Programs with Linear Constraints\nIn the previous section, we relax assumptions on neural\nnetwork repair and show non-termination for the resulting\nmore general problem. In this section, we look at a more\nrestricted class of problems instead: robust problems with\nlinear constraints. For this class, we can prove termination\nregardless of the objective J. Therefore, this class encom-\npasses such cases as training a linear regression model, a\nlinear support vector machine (SVM), or a deep linear net-\nwork (Saxe et al., 2014) to conform to a linear specification.\nLinear specifications, as defined in Section 3.3, only con-\nsist of properties with an affine satisfaction function and a\nclosed convex polytope as an input set.\nTheorem 4.3 (Termination for Linear Constraints) .\nLetg(θ,x) =fSat(net θ(x))be linear in xand let Xφbe a\nclosed convex polytope. Algorithm 1 computes a minimiser\nof\nR:(\nminimise\nθ∈RpJ(θ)\nsubject to g(θ,x)≥0∀x∈ Xφ,(12)\nin a finite number of repair steps.Proof Idea. ForRas in Equation (12), all verification\nproblems VNare linear programs sharing the same fea-\nsible set Xφ. Due to this, all most-violating counterexam-\nplesx(N)are vertices of Xφ, of which there are only finitely\nmany. This forces Algorithm 1 to terminate. The detailed\nproof is contained in Appendix A.3.\nThe insights from our proof enable a new repair algorithm\nfor linear regression models based on quadratic program-\nming. We discuss and evaluate this algorithm in Section 5.3.\n4.4. Element-Wise Monotone Constraints\nNext, we study a different restricted class of repair problems\nthat contains repairing single ReLU and sigmoid neurons\nto conform to linear specifications. This includes repairing\nlinear classifiers, which are single sigmoid neurons. In\nthis class of problems, the constraint function g(θ,x) =\nfSat(net θ(x))iselement-wise monotone and continuous\nandXφis a hyper-rectangle. We show termination for this\nclass.\nElement-wise monotone functions are monotone in each\nargument, all other arguments being fixed at some value.\nThey can be monotonically increasing and decreasing in the\nsame element but only for different values of the remaining\nelements. We formally define element-wise monotonicity\nin Appendix A.4. The definition includes single ReLU and\nsigmoid neurons.\nTheorem 4.4 (Termination for Element-Wise Monotone\nConstraints) .Letg(θ,x) =fSat(net θ(x))be element-wise\nmonotone and continuous. Let Xφbe a hyper-rectangle.\nAlgorithm 1 computes a minimiser of\nR:(\nminimise\nθ∈RpJ(θ)\nsubject to g(θ,x)≥0∀x∈ Xφ(13)\nin a finite number of repair steps under the assumption\nthat the algorithm prefers global minimisers of VNthat are\nvertices of Xφ.\nThe assumption in this theorem is weak, as we show in\nAppendix A.4. In particular, it is easy to construct a global\nminimiser of VNthat is a vertex of Xφgiven any global\nminimiser of VN. Given that all x(N)are vertices of Xφ\nunder this assumption, Theorem 4.4 follows analogously to\nTheorem 4.3. Appendix A.4 contains a detailed proof.\n4.5. Neural Network Repair with Bounded Input Sets\nTable 2 summarises our results regarding the termination\nof Algorithm 1. On the one hand, Theorem 4.4 provides us\nwith a termination guarantee for repairing single neurons.\nOn the other hand, Proposition 4.2 shows that Algorithm 1\nis not, in general, guaranteed to terminate when applied\n6\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nTable 2: Summary of Termination Results for Algorithm 1\nProblem Class Model Specification Termination\nfSat(net θ(x))linear in x,\nXφclosed convex polytopeLinear Regression Model, Linear\nSVM, Deep Linear NetworkLinear ✓(Theorem 4.3)\nfSat(net θ(x))elem.-wise mon.\nand cont., Xφhyper-rectangleLinear Classifier, ReLU Neuron Linear ✓(Theorem 4.4)\nXφbounded Neural Network Bounded Input Set ?\nXφunbounded Neural Network Unbounded Input Set ×(Proposition 4.2)\nUsing an early-exit verifier Any Any ×(Proposition 4.5)\nto neural networks. However, both results do not readily\ntransfer to our primary target — neural network repair with\nbounded input sets. When looking at neural network repair,\nthe verification problem can have a minimiser anywhere\ninside the feasible region. Furthermore, this minimiser may\nmove when the network parameters are modified. Therefore,\nthe reasoning we use for proving Theorems 4.3 and 4.4 is not\ndirectly applicable when repairing neural networks. Coming\nfrom the other side, Proposition 4.2 relies on constructing\na diverging sequence of counterexamples. However, when\ncounterexamples need to lie in a bounded set, as it is the\ncase with common neural network specifications, it becomes\nintricate to construct a diverging sequence originating from\na repair problem.\nIn summary, although we can not answer at this point\nwhether Algorithm 1 terminates when applied to neural\nnetwork repair for bounded property input sets, our method-\nology is useful for studying related questions. In the follow-\ning section, we continue our theoretical analysis, showing\nthat early-exit verifiers are insufficient for guaranteeing ter-\nmination of Algorithm 1.\n4.6. Early-Exit Verifiers\nFrom a verification perspective, verifiers are not required to\nfind most-violating counterexamples. Instead, it suffices to\nfind any counterexample if one exists. In this section, we\nshow that using just any counterexample is not sufficient for\nAlgorithm 1 to terminate, even for linear regression models.\nConsider a modification of Algorithm 1, where we only\nsearch for a feasible point of VNwith a negative objective\nvalue instead of the global minimum. This corresponds to\nusing an early-exit verifier during repair. The following\nproposition demonstrates that this modification can lead to\nnon-termination.\nProposition 4.5 (Non-Termination for Early-Exit Veri-\nfiers) .Algorithm 1 modified to use an early-exit verifier\nis not guaranteed to terminate for J, fSat,netθ:R→R,\nwhere J(θ) =|θ|,fSat(y) = y,netθ(x) = θ−x,\nandXφ= [0,1].Proof Idea. Assume that the early-exit verifier generates the\nsequence x(N)=1\n2−1\nN+2. This leads to non-termination\nof Algorithm 1. The detailed proof of Proposition 4.5 is\ncontained in Appendix A.5.\nThis result concludes our theoretical investigation. In the\nfollowing section, we research empirical aspects of Algo-\nrithm 1, including the practical implications of the above\nresult on using early-exit verifiers during repair.\n5. Experiments\nOptimal verifiers that compute most-violating counterex-\namples are theoretically advantageous but not widely avail-\nable (Strong et al., 2021). Conversely, early-exit verifiers\nthat produce plain counterexamples without further quali-\nfications are readily available (Katz et al., 2019; Bak et al.,\n2020; Tran et al., 2020; Zhang et al., 2022b; Ferrari et al.,\n2022), but are theoretically disadvantageous, as apparent\nfrom Section 4.6. In this section, we empirically compare\nthe effects of using most-violating counterexamples and\nsub-optimal counterexamples — as produced by early-exit\nverifiers and falsifiers — for repair. Additionally, we apply\nour insights from Section 4.3 for repairing linear regres-\nsion models. Appendix D contains additional experimental\nresults. Our experiments address the following questions\nregarding counterexample-guided repair:\n1.How does repair using an early-exit verifier compare\nquantitatively to repair using an optimal verifier?\n2.What quantitative advantages does it provide to use\nfalsifiers during repair?\n3.Can we surpass existing repair algorithms for linear\nregression models using our theoretical insights?\nIn our experiments, we repair an MNIST (LeCun et al.,\n1998) image classification network, ACAS Xu aircraft con-\ntrol networks (Julian et al., 2018; Katz et al., 2017), a Col-\nlisionDetection (Ehlers, 2017) particle dynamics network,\n7\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nCD RMI MNIST ACAS Xu9%0%6%0%10%0%86%97%\n74%92%\n8%3%\n(a) Which is faster in terms of runtime?\nCD RMI MNIST ACAS Xu56%\n0%56%79%\n28%\n0%20% 18%9%92%\n24%\n3% (b) Which is faster in terms of repair steps?\nFigure 1: Optimal vs. Early-Exit Verifier. We plot how frequently repair using the optimal verifier\n or the early-exit\nverifier\n is faster in terms of (a) runtime and (b) repair steps. Grey bars\n depict how frequently both approaches are\nequally fast. We consider two runtimes equal when they deviate by at most 30seconds. We use four different datasets:\nCollisionDetection (CD), integer datasets (RMI), MNIST and ACAS Xu. Gaps to 100 % are due to failing repairs.\nand integer dataset Recursive Model Indices (RMIs) (Tan\net al., 2021) for database indexing. RMIs contain two stages:\na first-stage neural network and several second-stage lin-\near regression models. We collect 50repair instances for\nMNIST, 34for ACAS Xu, 100for CollisionDetection, 50\nfor RMI first-stage networks and 100for RMI second-stage\nmodels. A detailed description of all datasets, networks and\nspecifications is contained in Appendix B.\nFor repair, we make use of an early-exit verifier, an opti-\nmal verifier, and the BIM falsifier (Kurakin et al., 2017;\nMadry et al., 2018). To obtain an optimal verifier, we\nmodify the ERAN verifier (Singh et al., 2022) to compute\nmost-violating counterexamples. This is described in Ap-\npendix B.1. We use the modified ERAN verifier both as the\nearly-exit and as the optimal verifier. We use the SpecRepair\ncounterexample-removal algorithm (Bauer-Marquart et al.,\n2022) unless otherwise noted. Our implementation and hard-\nware are documented in Appendix B.4. Our source code\nis available at https://github.com/sen-uni-kn/\nspecrepair .\n5.1. Optimal vs. Early Exit Verifier\nTo evaluate how repair using an early-exit verifier compares\nto repair using an optimal verifier, we run repair using both\nverifiers for CollisionDetection, MNIST, ACAS Xu, and the\nRMI first-stage networks.\nFigure 1 depicts which verifier leads to repair fastest. The\nfigure shows this both for the absolute runtime of repair and\nthe number of repair steps. For the larger MNIST and ACAS\nXu networks, we observe that repair using the early-exit\nverifier requires less runtime in most cases. Regarding the\nnumber of repair steps, we observe the opposite trend. Here,\nthe optimal verifier yields repair in fewer repair steps more\noften than not. The additional runtime cost of computing\nmost-violating counterexamples offsets the advantage in\nrepair steps. For the smaller CollisionDetection network\nand the RMI first stage networks, we primarily observe\n0 10 20 30 40 50102103104\nOptimal\nEarly-Exit\nBIM\n#Repaired InstancesRuntime ( s)Figure 2: Repair using Falsifiers. We plot the number of\nrepaired MNIST instances that individually require less than\na certain runtime. We plot this for repair using BIM\n , only\nthe optimal verifier\n and only the early-exit verifier\n .\nthat only infrequently repair using one verifier outperforms\nusing the other by more than 30seconds. While there is\nno variation regarding the number of repair steps for the\nInteger Dataset RMIs, Figure 1b shows the same trend for\nCollisionDetection as for ACAS Xu and MNIST.\n5.2. Using Falsifiers for Repair\nFalsifiers are sound but incomplete counterexample\nsearchers that specialise in finding violations fast. In this\nsection, we study how falsifiers can speed up repair. For this\npurpose, we repair an MNIST network using the BIM (Ku-\nrakin et al., 2017; Madry et al., 2018) falsifier that we de-\nscribe in Section 3.3. We start repair by searching coun-\nterexamples using BIM. Only when BIM fails to produce\nfurther counterexamples we turn to the early-exit verifier.\nIdeally, we would want that the verifier is invoked only once\nto prove specification satisfaction. Practically, often sev-\neral additional repair steps have to be performed using the\nverifier.\nFigure 2 summarises the results of our experiment. We\n8\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nTable 3: Repairing Linear Regression Models. We report\nthe success rates of repairing RMI second-stage linear re-\ngression models for two specifications with different error\nbounds ε. The success rates include models that already\nsatisfy their specification.\nSuccess Rate\nAlgorithm ε= 100 ε= 150\nOuroboros∗30 % 77 %\nSpecRepair⋆58 % 94 %\nQuadratic Programming 72% 97%\n∗Tan et al. (2021)⋆Bauer-Marquart et al. (2022)\nsee that using BIM can significantly accelerate repair of the\nMNIST network, demonstrating the potential of falsifiers for\nrepair. BIM is an order of magnitude faster than the early-\nexit verifier, yet it can find counterexamples with a larger\nviolation. Thus, BIM can sometimes provide the repair\nstep advantage of the optimal verifier at a much smaller\ncost. Appendix D.1 contains further experiments on using\nfalsifiers for repair.\n5.3. Repairing Linear Regression Models\nOur theoretical investigation into the repair of linear regres-\nsion models in Section 4.3 provides interesting insights that\ncan be used to create a repair algorithm for linear regression\nmodels based on quadratic programming. In this section, we\ndescribe this algorithm and compare it to the Ouroboros (Tan\net al., 2021) and SpecRepair (Bauer-Marquart et al., 2022)\nrepair algorithms. Both Ouroboros and SpecRepair are\ncounterexample-guided repair algorithms. The linear re-\ngression models we repair are the second-stage models of\nseveral integer dataset RMIs.\nInsights into Repairing Linear Regression Models We\nrecall from Section 4.3 that for repairing a linear regres-\nsion model to conform to a linear specification, the most-\nviolating counterexample for a property is always located at\none of the vertices of the property’s input set. This implies\ntwo conclusions for repairing the second-stage RMI models:\na)To verify a linear regression model, it suffices to eval-\nuate it on the vertices of the input set. This provides\nus with an analytical solution of the verification prob-\nlemV. As the input of the RMI second-stage models\nis one-dimensional, we only have to check property\nviolation for two points per property.\nb)Since we can analytically solve V, we can rewrite R′\nfrom Equation (7)using, for RMI second-stage mod-\nels, two constraints per property. The two constraints\ncorrespond to evaluating the satisfaction function for\nthe two vertices of the property input set. We obtain anequivalent formulation of the repair problem Rfrom\nEquation (6) with a finite number of constraints.\nRepair using Quadratic Programming Conclusion b)\nprovides an equivalent formulation of the repair problem R\nwith finitely many linear constraints. We train and repair the\nsecond-stage models using MSE. Since MSE is a convex\nquadratic function and all constraints are linear, it follows\nthat the repair problem is a quadratic program (Boyd &\nVandenberghe, 2014). This allows for applying a quadratic\nprogramming solver to repair the linear regression models\ndirectly. We use Gurobi (Gurobi Optimization, LLC, 2021)\nand report the results for repairing linear regression models\nusing this method under the name Quadratic Programming .\nTable 3 summarises the results of repairing the second-stage\nRMI linear regression models. Our new Quadratic Program-\nming repair algorithm achieves the highest success rate,\noutperforming Ouroboros and SpecRepair. In fact, due to\nsolving the repair problem directly, Quadratic Programming\nis guaranteed to produce the optimal repaired model when-\never repair is possible. Our implementation of the different\nalgorithms does not allow for a fair runtime comparison, but\nwe remark that the runtime of Quadratic Programming is\ncompetitive in our experiments.\n6. Conclusion\nIn this paper, we prove termination of counterexample-\nguided repair for linear regression models, linear classifiers\nand single ReLU neurons, assuming linear specifications.\nWe disprove termination for repairing neural networks when\nthe specification has an unbounded input set. As our re-\nsults show, our methodology of viewing repair as robust\noptimisation is useful for studying the theoretical proper-\nties of counterexample-guided repair. Empirically, we find\nthat both early-exit verifiers and falsifiers allow achieving\nrepair and can give speed advantages. For repairing lin-\near regression models, we surpass existing approaches by\ndesigning a novel repair algorithm using our theoretical in-\nsights. Overall, we believe that robust optimisation provides\na rich arsenal of useful tools for studying and advancing\nrepair, both theoretically and practically.\nFuture Work Theorems 4.3 and 4.4 provide sufficient\nconditions for termination of Algorithm 1. Deriving suf-\nficient conditions that are closer to neural network repair\nis an interesting direction for future work, as is deriving\nnecessary conditions for termination. Another direction for\nfuture work is studying different classes of verifiers beyond\noptimal and early-exit verifiers. Further sufficient condi-\ntions, necessary conditions, and a more refined taxonomy\nof verifiers could provide insights into why, practically, Al-\ngorithm 1 terminates even when using early-exit verifiers.\n9\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nReferences\nAmato, F., L ´opez, A., Pe ˜na-M ´endez, E. M., Va ˇnhara, P.,\nHampl, A., and Havel, J. Artificial neural networks in\nmedical diagnosis. J. Appl. Biomed. , 11(2):47–58, 2013.\nURL https://doi .org/10 .2478/v10136-012-\n0031-x .\nBak, S., Tran, H., Hobbs, K., and Johnson, T. T. Im-\nproved Geometric Path Enumeration for Verifying ReLU\nNeural Networks. In CAV (1) , volume 12224 of Lec-\nture Notes in Computer Science , pp. 66–96. Springer,\n2020. URL https://doi .org/10 .1007/978-3-\n030-53288-8 4.\nBauer-Marquart, F., Boetius, D., Leue, S., and Schilling,\nC. SpecRepair: Counter-Example Guided Safety Repair\nof Deep Neural Networks. In SPIN , volume 13255 of\nLecture Notes in Computer Science , pp. 79–96. Springer,\n2022. URL https://doi .org/10 .1007/978-3-\n031-15077-7 5.\nBen-Tal, A. and Nemirovski, A. Robust Convex Optimiza-\ntion. Math. Oper. Res. , 23(4):769–805, 1998. URL\nhttps://doi .org/10 .1287/moor .23.4.769.\nBen-Tal, A., Ghaoui, L. E., and Nemirovski, A. Robust\nOptimization , volume 28 of Princeton Series in Applied\nMathematics . Princeton University Press, 2009. URL\nhttps://doi .org/10 .1515/9781400831050 .\nBojarski, M., Testa, D. D., Dworakowski, D., Firner,\nB., Flepp, B., Goyal, P., Jackel, L. D., Monfort, M.,\nMuller, U., Zhang, J., Zhang, X., Zhao, J., and Zieba,\nK. End to End Learning for Self-Driving Cars. CoRR ,\nabs/1604.07316, 2016. URL http://arxiv .org/\nabs/1604 .07316 .\nBoyd, S. P. and Vandenberghe, L. Convex Optimization .\nCambridge University Press, 2014. URL https://\ndoi.org/10 .1017/CBO9780511804441 .\nBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan,\nJ., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\nAskell, A., Agarwal, S., Herbert-V oss, A., Krueger, G.,\nHenighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu,\nJ., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,\nGray, S., Chess, B., Clark, J., Berner, C., McCandlish, S.,\nRadford, A., Sutskever, I., and Amodei, D. Language\nModels are Few-Shot Learners. In NeurIPS , 2020.\nURL https://proceedings .neurips .cc/\npaper/2020/hash/\n1457c0d6bfcb4967418bfb8ac142f64a-\nAbstract .html .\nBunel, R., Turkaslan, I., Torr, P. H. S., Kohli, P., and\nMudigonda, P. K. A Unified View of Piecewise LinearNeural Network Verification. In NeurIPS , pp. 4795–4804,\n2018. URL https://proceedings .neurips .cc/\npaper/2018/hash/\nbe53d253d6bc3258a8160556dda3e9b2-\nAbstract .html .\nCampi, M. C. and Garatti, S. The Exact Feasibility of\nRandomized Solutions of Uncertain Convex Programs.\nSIAM J. Optim. , 19(3):1211–1230, 2008. URL https:\n//doi .org/10 .1137/07069821X .\nCarlini, N. and Wagner, D. A. Towards Evaluating the\nRobustness of Neural Networks. In IEEE Symposium\non Security and Privacy , pp. 39–57. IEEE Computer\nSociety, 2017. URL https://doi .org/10 .1109/\nSP.2017 .49.\nChen, J., Jordan, M. I., and Wainwright, M. J. Hop-\nSkipJumpAttack: A Query-Efficient Decision-Based At-\ntack. In IEEE Symposium on Security and Privacy , pp.\n1277–1294. IEEE, 2020. URL https://doi .org/\n10.1109/SP40000 .2020 .00045 .\nCheng, C., N ¨uhrenberg, G., and Ruess, H. Maximum Re-\nsilience of Artificial Neural Networks. In ATVA , vol-\nume 10482 of Lecture Notes in Computer Science , pp.\n251–268. Springer, 2017. URL https://doi .org/\n10.1007/978-3-319-68167-2 18.\nCiss´e, M., Bojanowski, P., Grave, E., Dauphin, Y . N., and\nUsunier, N. Parseval Networks: Improving Robustness to\nAdversarial Examples. In ICML , volume 70 of Proceed-\nings of Machine Learning Research , pp. 854–863. PMLR,\n2017. URL http://proceedings .mlr.press/\nv70/cisse17a .html .\nClarke, E. M., Grumberg, O., Jha, S., Lu, Y ., and Veith, H.\nCounterexample-guided abstraction refinement. In CAV,\nvolume 1855 of Lecture Notes in Computer Science , pp.\n154–169. Springer, 2000. URL https://doi .org/\n10.1007/10722167 15.\nDong, G., Sun, J., Wang, J., Wang, X., and Dai, T. To-\nwards Repairing Neural Networks Correctly. In QRS,\npp. 714–725. IEEE, 2021. URL https://doi .org/\n10.1109/QRS54544 .2021 .00081 .\nEhlers, R. Formal Verification of Piece-Wise Linear Feed-\nForward Neural Networks. In ATVA , volume 10482\nofLecture Notes in Computer Science , pp. 269–286.\nSpringer, 2017. URL https://doi .org/10 .1007/\n978-3-319-68167-2 19.\nEsfahani, P. M., Sutter, T., and Lygeros, J. Performance\nBounds for the Scenario Approach and an Extension to a\nClass of Non-Convex Programs. IEEE Trans. Autom. Con-\ntrol., 60(1):46–58, 2015. URL https://doi .org/\n10.1109/TAC .2014 .2330702 .\n10\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nFawzi, A., Balog, M., Huang, A., Hubert, T., Romera-\nParedes, B., Barekatain, M., Novikov, A., R. Ruiz, F. J.,\nSchrittwieser, J., Swirszcz, G., Silver, D., Hassabis, D.,\nand Kohli, P. Discovering faster matrix multiplication\nalgorithms with reinforcement learning. Nat., 610(7930):\n47–53, 2022. URL https://doi .org/10 .1038/\ns41586-022-05172-4 .\nFerrari, C., Mueller, M. N., Jovanovi ´c, N., and\nVechev, M. Complete Verification via Multi-\nNeuron Relaxation Guided Branch-and-Bound. In\nICLR , 2022. URL https://openreview .net/\nforum?id=l amHf1oaK .\nFischer, M., Balunovic, M., Drachsler-Cohen, D., Gehr,\nT., Zhang, C., and Vechev, M. T. DL2: Train-\ning and Querying Neural Networks with Logic.\nInICML , volume 97 of Proceedings of Machine\nLearning Research , pp. 1931–1941. PMLR, 2019.\nURL http://proceedings .mlr.press/v97/\nfischer19a .html .\nGoldberger, B., Katz, G., Adi, Y ., and Keshet, J. Minimal\nModifications of Deep Neural Networks using Verifica-\ntion. In LPAR , volume 73 of EPiC Series in Comput-\ning, pp. 260–278. EasyChair, 2020. URL https://\neasychair .org/publications/paper/CWhF .\nGoodfellow, I. J., Shlens, J., and Szegedy, C. Explaining\nand Harnessing Adversarial Examples. In ICLR (Poster) ,\n2015. URL http://arxiv .org/abs/1412 .6572 .\nGoodfellow, I. J., Bengio, Y ., and Courville, A. C.\nDeep Learning . Adaptive computation and ma-\nchine learning. MIT Press, 2016. URL http://\nwww.deeplearningbook .org/ .\nGowal, S., Dvijotham, K., Stanforth, R., Bunel, R., Qin, C.,\nUesato, J., Arandjelovic, R., Mann, T. A., and Kohli,\nP. On the Effectiveness of Interval Bound Propaga-\ntion for Training Verifiably Robust Models. CoRR ,\nabs/1810.12715, 2018. URL http://arxiv .org/\nabs/1810 .12715 .\nGuidotti, D., Leofante, F., Pulina, L., and Tacchella, A. Ver-\nification and Repair of Neural Networks: A Progress Re-\nport on Convolutional Models. In AI*IA , volume 11946\nofLecture Notes in Computer Science , pp. 405–417.\nSpringer, 2019a. URL https://doi .org/10 .1007/\n978-3-030-35166-3 29.\nGuidotti, D., Leofante, F., Tacchella, A., and Castellini, C.\nImproving reliability of myocontrol using formal verifi-\ncation. IEEE Trans. Neural Syst. Rehabilitation Eng. ,\n27(4):564–571, 2019b. URL https://doi .org/\n10.1109/TNSRE .2019 .2893152 .Gurobi Optimization, LLC. Gurobi Optimizer Reference\nManual, 2021. URL https://www .gurobi .com.\nHenzinger, T. A., Jhala, R., and Majumdar, R.\nCounterexample-guided control. In ICALP , volume 2719\nofLecture Notes in Computer Science , pp. 886–902.\nSpringer, 2003. URL https://doi .org/10 .1007/\n3-540-45061-0 69.\nJha, S. and Seshia, S. A. Are there good mistakes? A\ntheoretical analysis of CEGIS. In SYNT , volume 157 of\nEPTCS , pp. 84–99, 2014. URL https://doi .org/\n10.4204/EPTCS .157.10.\nJorgensen, C. C. Direct Adaptive Aircraft Control Using\nDynamic Cell Structure Neural Networks. Technical\nreport, NASA Ames Research Center, 1997.\nJulian, K. D. and Kochenderfer, M. J. Guaranteeing Safety\nfor Neural Network-Based Aircraft Collision Avoidance\nSystems. CoRR , abs/1912.07084, 2019. URL http:\n//arxiv .org/abs/1912 .07084 .\nJulian, K. D., Kochenderfer, M. J., and Owen, M. P.\nDeep Neural Network Compression for Aircraft Colli-\nsion Avoidance Systems. CoRR , abs/1810.04240, 2018.\nURL http://arxiv .org/abs/1810 .04240 .\nKatz, G., Barrett, C. W., Dill, D. L., Julian, K. D., and\nKochenderfer, M. J. Reluplex: An Efficient SMT Solver\nfor Verifying Deep Neural Networks. In CAV (1) , volume\n10426 of Lecture Notes in Computer Science , pp. 97–117.\nSpringer, 2017. URL https://doi .org/10 .1007/\n978-3-319-63387-9 5.\nKatz, G., Huang, D. A., Ibeling, D., Julian, K., Lazarus,\nC., Lim, R., Shah, P., Thakoor, S., Wu, H., Zeljic, A.,\nDill, D. L., Kochenderfer, M. J., and Barrett, C. W. The\nMarabou Framework for Verification and Analysis of\nDeep Neural Networks. In CAV (1) , volume 11561 of Lec-\nture Notes in Computer Science , pp. 443–452. Springer,\n2019. URL https://doi .org/10 .1007/978-3-\n030-25540-4 26.\nKingma, D. P. and Ba, J. Adam: A Method for Stochas-\ntic Optimization. In ICLR , 2015. URL http://\narxiv .org/abs/1412 .6980 .\nKraska, T., Beutel, A., Chi, E. H., Dean, J., and Polyzotis,\nN. The Case for Learned Index Structures. In SIGMOD\nConference , pp. 489–504. ACM, 2018. URL https:\n//doi .org/10 .1145/3183713 .3196909 .\nKurakin, A., Goodfellow, I. J., and Bengio, S. Adversar-\nial examples in the physical world. In ICLR . OpenRe-\nview.net, 2017. URL https://openreview .net/\nforum?id=HJGU3Rodl .\n11\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nLeCun, Y ., Bottou, L., Bengio, Y ., and Haffner, P. Gradient-\nbased learning applied to document recognition. Proc.\nIEEE , 86(11):2278–2324, 1998. URL https://\ndoi.org/10 .1109/5 .726791 .\nLomuscio, A. and Maganti, L. An approach to reachability\nanalysis for feed-forward ReLU neural networks. CoRR ,\nabs/1706.07351, 2017. URL http://arxiv .org/\nabs/1706 .07351 .\nMadry, A., Makelov, A., Schmidt, L., Tsipras, D., and\nVladu, A. Towards Deep Learning Models Resistant\nto Adversarial Attacks. In ICLR (Poster) . OpenRe-\nview.net, 2018. URL https://openreview .net/\nforum?id=rJzIBfZAb .\nMirman, M., Gehr, T., and Vechev, M. T. Differen-\ntiable Abstract Interpretation for Provably Robust Neu-\nral Networks. In ICML , volume 80 of Proceedings of\nMachine Learning Research , pp. 3575–3583. PMLR,\n2018. URL http://proceedings .mlr.press/\nv80/mirman18b .html .\nM¨uller, M. N., Brix, C., Bak, S., Liu, C., and Johnson,\nT. T. The Third International Verification of Neural Net-\nworks Competition (VNN-COMP 2022): Summary and\nResults. CoRR , abs/2212.10376, 2022. URL https:\n//doi .org/10 .48550/arXiv .2212 .10376 .\nMutapcic, A. and Boyd, S. P. Cutting-set methods for robust\nconvex optimization with pessimizing oracles. Optim.\nMethods Softw. , 24(3):381–406, 2009. URL https:\n//doi .org/10 .1080/10556780802712889 .\nNguyen, T., Antonopoulos, T., Ruef, A., and Hicks,\nM. Counterexample-guided approach to finding nu-\nmerical invariants. In ESEC/FSE , pp. 605–615.\nACM, 2017. URL https://doi .org/10 .1145/\n3106237 .3106281 .\nNocedal, J. and Wright, S. J. Numerical Optimization .\nSpringer, 2 edition, 2006. URL https://doi .org/\n10.1007/b98874 .\nPalma, A. D., Bunel, R., Desmaison, A., Dvijotham,\nK., Kohli, P., Torr, P. H. S., and Kumar, M. P.\nImproved Branch and Bound for Neural Network\nVerification via Lagrangian Decomposition. CoRR ,\nabs/2104.06718, 2021. URL https://arxiv .org/\nabs/2104 .06718 .\nPapernot, N., McDaniel, P. D., Jha, S., Fredrikson, M., Celik,\nZ. B., and Swami, A. The Limitations of Deep Learning\nin Adversarial Settings. CoRR , abs/1511.07528, 2015.\nURL http://arxiv .org/abs/1511 .07528 .Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury,\nJ., Chanan, G., Killeen, T., Lin, Z., Gimelshein,\nN., Antiga, L., Desmaison, A., K ¨opf, A., Yang, E.,\nDeVito, Z., Raison, M., Tejani, A., Chilamkurthy,\nS., Steiner, B., Fang, L., Bai, J., and Chintala, S.\nPyTorch: An Imperative Style, High-Performance Deep\nLearning Library. In NeurIPS , pp. 8024–8035, 2019.\nURL https://proceedings .neurips .cc/\npaper/2019/hash/\nbdbca288fee7f92f2bfa9f7012727740-\nAbstract .html .\nPulina, L. and Tacchella, A. An Abstraction-Refinement\nApproach to Verification of Artificial Neural Networks.\nInCAV, volume 6174 of Lecture Notes in Computer\nScience , pp. 243–257. Springer, 2010. URL https:\n//doi .org/10 .1007/978-3-642-14295-6 24.\nRaghunathan, A., Steinhardt, J., and Liang, P. Certi-\nfied Defenses against Adversarial Examples. In ICLR\n(Poster) . OpenReview.net, 2018. URL https://\nopenreview .net/forum?id=Bys4ob-Rb .\nReynolds, A., Deters, M., Kuncak, V ., Tinelli, C., and\nBarrett, C. W. Counterexample-guided quantifier in-\nstantiation for synthesis in SMT. In CAV (2) , volume\n9207 of Lecture Notes in Computer Science , pp. 198–216.\nSpringer, 2015. URL https://doi .org/10 .1007/\n978-3-319-21668-3 12.\nSaxe, A. M., McClelland, J. L., and Ganguli, S. Exact\nsolutions to the nonlinear dynamics of learning in deep\nlinear neural networks. In ICLR , 2014. URL http:\n//arxiv .org/abs/1312 .6120 .\nSenior, A. W., Evans, R., Jumper, J., Kirkpatrick, J., Sifre,\nL., Green, T., Qin, C., Z ´ıdek, A., Nelson, A. W. R.,\nBridgland, A., Penedones, H., Petersen, S., Simonyan,\nK., Crossan, S., Kohli, P., Jones, D. T., Silver, D.,\nKavukcuoglu, K., and Hassabis, D. Improved protein\nstructure prediction using potentials from deep learn-\ning. Nat., 577(7792):706–710, 2020. URL https:\n//doi .org/10 .1038/s41586-019-1923-7 .\nSingh, G., Gehr, T., Mirman, M., P ¨uschel, M., and\nVechev, M. T. Fast and Effective Robustness Cer-\ntification. In NeurIPS , pp. 10825–10836, 2018.\nURL https://proceedings .neurips .cc/\npaper/2018/hash/\nf2f446980d8e971ef3da97af089481c3-\nAbstract .html .\nSingh, G., Gehr, T., P ¨uschel, M., and Vechev, M. T. An\nAbstract Domain for Certifying Neural Networks. Proc.\nACM Program. Lang. , 3(POPL):41:1–41:30, 2019. URL\nhttps://doi .org/10 .1145/3290354 .\n12\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nSingh, G., M ¨uller, M. N., Balunovic, M., Makarchuk, G.,\nRuoss, A., Serre, F., Baader, M., Cohen, D. D., Gehr,\nT., Hoffmann, A., Maurer, J., Mirman, M., M ¨uller, C.,\nP¨uschel, M., Tsankov, P., and Vechev, M. ETH Ro-\nbustness Analyzer for Neural Networks (ERAN) Reposi-\ntory, 2022. URL https://github .com/eth-sri/\neran . Accessed 2023-05-17.\nSivaraman, A., Farnadi, G., Millstein, T. D., and den\nBroeck, G. V . Counterexample-Guided Learning\nof Monotonic Neural Networks. In NeurIPS , 2020.\nURL https://proceedings .neurips .cc/\npaper/2020/hash/\n8ab70731b1553f17c11a3bbc87e0b605-\nAbstract .html .\nSolar-Lezama, A., Tancau, L., Bod ´ık, R., Seshia,\nS. A., and Saraswat, V . A. Combinatorial sketch-\ning for finite programs. In ASPLOS , pp. 404–415.\nACM, 2006. URL https://doi .org/10 .1145/\n1168857 .1168907 .\nSotoudeh, M. and Thakur, A. V . Provable repair\nof deep neural networks. In PLDI , pp. 588–603.\nACM, 2021. URL https://doi .org/10 .1145/\n3453483 .3454064 .\nStrong, C. A., Wu, H., Zelji ´c, A., Julian, K. D., Katz, G., Bar-\nrett, C., and Kochenderfer, M. J. Global optimization of\nobjective functions represented by ReLU networks. Mach.\nLearn. , 2021. URL https://doi .org/10 .1007/\ns10994-021-06050-2 .\nSzegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,\nD., Goodfellow, I. J., and Fergus, R. Intriguing properties\nof neural networks. In ICLR (Poster) , 2014. URL http:\n//arxiv .org/abs/1312 .6199 .\nTan, C., Zhu, Y ., and Guo, C. Building verified neural net-\nworks with specifications for systems. In APSys , pp. 42–\n47. ACM, 2021. URL https://doi .org/10 .1145/\n3476886 .3477508 .\nTjeng, V ., Xiao, K. Y ., and Tedrake, R. Evaluat-\ning Robustness of Neural Networks with Mixed In-\nteger Programming. In ICLR (Poster) . OpenRe-\nview.net, 2019. URL https://openreview .net/\nforum?id=HyGIdiRqtm .\nTran, H., Yang, X., Lopez, D. M., Musau, P., Nguyen, L. V .,\nXiang, W., Bak, S., and Johnson, T. T. NNV: The Neural\nNetwork Verification Tool for Deep Neural Networks\nand Learning-Enabled Cyber-Physical Systems. In CAV\n(1), volume 12224 of Lecture Notes in Computer Science ,\npp. 3–17. Springer, 2020. URL https://doi .org/\n10.1007/978-3-030-53288-8 1.Uesato, J., O’Donoghue, B., Kohli, P., and van den Oord, A.\nAdversarial Risk and the Dangers of Evaluating Against\nWeak Attacks. In ICML , volume 80 of Proceedings\nof Machine Learning Research , pp. 5032–5041. PMLR,\n2018. URL http://proceedings .mlr.press/\nv80/uesato18a .html .\nWang, S., Pei, K., Whitehouse, J., Yang, J., and Jana,\nS. Formal Security Analysis of Neural Networks\nusing Symbolic Intervals. In USENIX Security Sym-\nposium , pp. 1599–1614. USENIX Association, 2018.\nURL https://www .usenix .org/conference/\nusenixsecurity18/presentation/wang-\nshiqi .\nWang, S., Zhang, H., Xu, K., Lin, X., Jana, S., Hsieh, C., and\nKolter, J. Z. Beta-CROWN: Efficient Bound Propagation\nwith Per-neuron Split Constraints for Neural Network\nRobustness Verification. In NeurIPS , pp. 29909–29921,\n2021. URL https://proceedings .neurips .cc/\npaper/2021/hash/\nfac7fead96dafceaf80c1daffeae82a4-\nAbstract .html .\nWong, E. and Kolter, J. Z. Provable Defenses against\nAdversarial Examples via the Convex Outer Adversar-\nial Polytope. In ICML , volume 80 of Proceedings of\nMachine Learning Research , pp. 5283–5292. PMLR,\n2018. URL http://proceedings .mlr.press/\nv80/wong18a .html .\nXu, K., Zhang, H., Wang, S., Wang, Y ., Jana, S., Lin,\nX., and Hsieh, C. Fast and Complete: Enabling Com-\nplete Neural Network Verification with Rapid and Mas-\nsively Parallel Incomplete Verifiers. In ICLR . OpenRe-\nview.net, 2021. URL https://openreview .net/\nforum?id=nVZtXBI6LNn .\nZhang, B., Jiang, D., He, D., and Wang, L. Boosting\nthe Certified Robustness of L-infinity Distance Nets.\nInICLR . OpenReview.net, 2022a. URL https://\nopenreview .net/forum?id=Q76Y7wkiji .\nZhang, H., Weng, T., Chen, P., Hsieh, C., and Daniel, L. Effi-\ncient Neural Network Robustness Certification with Gen-\neral Activation Functions. In NeurIPS , pp. 4944–4953,\n2018. URL https://proceedings .neurips .cc/\npaper/2018/hash/\nd04863f100d59b3eb688a11f95b0ae60-\nAbstract .html .\nZhang, H., Wang, S., Xu, K., Li, L., Li, B., Jana, S., Hsieh,\nC., and Kolter, J. Z. General Cutting Planes for Bound-\nPropagation-Based Neural Network Verification. In\nNeurIPS , 2022b. URL https://openreview .net/\nforum?id=5haAJAcofjc .\n13\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\n−5\n0\n5−4−2 0 2 40510\nx\nθfSat(net θ(x))\n(a) Setting of Proposition 4.2\n−5\n0\n5−2 0 2 4 60510\nx\nθfSat(net θ(x)) (b) FCNN Variant from Example 1\nFigure 3: Constraint Visualisations for Non-Termination Proofs. We visualise the function fSat(net θ(x))from Proposi-\ntion 4.2 and for the FCNN variant from Example 1. In both cases, the parameter iterates θ(N)and the counterexamples x(N)\ndiverge to ∞along the dark-red flat surface where the fSatvalue is negative. This divergence implies non-termination of\nAlgorithm 1. The black line\n represents an example sequence of diverging parameter and counterexample iterates.\nA. Proofs\nThis section contains the full proofs of all our propositions and theorems.\nA.1. Proposition 4.1\nProof of Proposition 4.1. Assume Algorithm 1 has terminated after Niterations for some robust program R. Since\nAlgorithm 1 has terminated, we know that minVN≥0. Hence, θ(N−1)is feasible for R. Asθ(N−1)also minimises CRN−1,\nwhich is a relaxation of R, it follows that θ(N−1)minimises R.\nThis proof is independent of whether we search for a local minimiser or a global minimiser of R. Therefore, Proposition 4.1\nholds regardless of the type of minimiser of Rthat we are interested in.\nA.2. Proposition 4.2\nFor proving Proposition 4.2, we first prove non-termination for a simplified version of the network in Proposition 4.2. This\nsimplified version serves as a lemma for proving Proposition 4.2.\nLemma A.1. Algorithm 1 does not terminate for J:R→R,fSat:R2→Randnetθ:R→R2where J(θ) =\nnetθ(0)1,fSat(y) =y2+y1−1,Xφ=R, and\nnetθ(x) =\u0014\u0012\n−θ\nθ−x\u0013\u0015+\n, (14)\nwhere [x]+= max(0 , x)denotes the ReLU.\nThe network netθin Lemma A.1 corresponds to the network from Proposition 4.2 with θ1=−1. This leads to a one-\ndimensional input and a one-dimensional parameter space. Because of this, we can visualise the optimisation landscape\nthat underlies repairing netθ. This visualisation is insightful for the proof of non-termination. Therefore, before we begin\nthe proof of Lemma A.1, we first give an intuition for the proof using Figure 3a. The core of the proof is that Algorithm 1\ngenerates parameter iterates θ(N)and counterexamples x(N)that lie on the dark-red flat surface of Figure 3a, where fSat\nis negative. The combination of fSatand the objective function Jthat prefers non-negative θ(N)leads to θ(N)≥0for\nevery N∈N. As there is always a new counterexample x(N)for every θ(N−1)≥0, Algorithm 1 does not terminate.\n14\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nProof of Lemma A.1. LetJ,fSat,netθandXφbe as in Lemma A.1. Assembled into a repair problem, they yield\nR:(\nminimise\nθ∈R[−θ]+\nsubject to [θ−x]++ [−θ]+−1≥0∀x∈R.(15)\nWe now show that Algorithm 1 does not terminate when applied to R. The problem CR0is minimising J(θ) = [−θ]+\nwithout constraints. The minimiser of Jis not unique, but all minimisers satisfy θ(0)≥0. Letθ(0)≥0be such a minimiser.\nSearching for the global minimiser x(1)ofV1, we find that this minimiser is non-unique as well. However, all minimisers\nsatisfy x(1)≥θ(0). This follows since any minimiser of\ng\u0010\nx,θ(0)\u0011\n=h\nθ(0)−xi+\n+h\n−θ(0)i+\n−1 (16)\nminimises\u0002\nθ(0)−x\u0003+as the remaining terms of Equation (16) are constant regarding x. The observation x(1)≥θ(0)\napplies analogously for later repair steps. Therefore, x(N)≥θ(N−1).\nFor any further repair step, we find that all non-negative feasible points θofCRNsatisfy\nθ≥max\u0010\nx(1), . . . ,x(N)\u0011\n+ 1. (17)\nThis follows because g\u0000\nx(i),θ\u0001\n≥0has to hold for all i∈ {1, . . . , N }forθto be feasible for CRN. Now, if θ≥0, we\nhave\ng\u0010\nx(i),θ\u0011\n=h\nθ−x(i)i+\n+ [−θ]+−1 =h\nθ−x(i)i+\n−1≥0, (18)\nfor all i∈ {1, . . . , N }. We see that Equation (18) is satisfied for all i∈ {1, . . . , N }only if θis larger than the largest x(i)\nby at least one. This yields equivalence of Equations (18) and (17).\nAs Equation (17) always has a solution, there always exists a positive feasible point for CRN. Now, due to J, any\nminimiser θ(N)ofCRNis positive and hence satisfies Equation (17). Putting these results together, we obtain\nθ(0)≥0 (19a)\nx(N)≥θ(N−1)(19b)\nθ(N)≥x(N)+ 1. (19c)\nInspecting Equation (15) closely reveals that no positive value θis feasible for Ras there always exists an x≥θ. However,\nit follows from Equations (19) that the iterate θ(N)of Algorithm 1 is always positive and thus never feasible for R. Since\nfeasibility for Ris the criterion for Algorithm 1 to terminate, it follows that Algorithm 1 does not terminate for this repair\nproblem.\nRemark A.2.We might be willing to accept non-termination for problems without a minimiser. However, Rfrom\nEquation (15) has a minimiser. We have already seen in the proof of Lemma A.1 that all positive θare infeasible for R.\nSimilarly, all θ∈(−1,0]are infeasible. However, all θ≤ −1are feasible as\n[θ−x]++ [−θ]+−1≥[−θ]+−1≥0, (20)\nfor any x∈R. For negative θ,Jprefers larger values. Because of this, the only minimiser of Risθ†=−1. Indeed,\nAlgorithm 1 not only fails to terminate but also moves further and further away from the optimal solution.\nWe now prove Proposition 4.2 using Lemma A.1. As will become clear during the proof, the divergence for Lemma A.1\ntransfers to Proposition 4.2.\nProof of Proposition 4.2. LetJ,fSat,netθandXφbe as in Proposition 4.2. The repair problem is\nR:(\nminimise\nθ∈R[θ1θ2]+\nsubject to [θ1x+θ2]++ [θ1θ2]+−1≥0∀x∈R.(21)\n15\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nTo show that Algorithm 1 is not guaranteed to terminate for R, we now construct an execution of Algorithm 1 that does not\nterminate. We first consider CR0, which is minimising Jwithout constraints. Choosing θ1=−1andθ2≥0yields a local\nminimiser of J, since J(θ) = 0 , which is the global minimum of J. Assuming θ(0)\n2≥0andθ(0)\n1=−1, we now show that\nthere is an execution of Algorithm 1, such that\n∀N∈N0:θ(N)\n1=−1∧θ(N)\n2≥0 (22)\nAsθ1=−1recreates the neural network from Lemma A.1, Proposition 4.2 follows from Lemma A.1 when Equation (22)\nholds for some execution. In the proof of Lemma A.1, we have already shown that there exists a θ(N)satisfying Equation (22)\nthat is feasible for CRN. Since J\u0000\nθ(N)\u0001\n= 0for any θ(N)satisfying Equation (22), there exist such parameters that are a\nlocal (in fact global) minimiser of CRN. Therefore, Algorithm 1 is not guaranteed to terminate when repairing the neural\nnetwork in Proposition 4.2, as there exists an execution of Algorithm 1 that does not terminate.\nRemark A.3.While the proof of Proposition 4.2 constructs an execution that does not terminate, the example in Proposi-\ntion 4.2 also permits executions that terminate. In the following, we discuss different executions of Algorithm 1, including\nthe executions that terminate. Beyond the execution constructed in the proof of Proposition 4.2, all executions with\n∀N∈N0:θ1<0∧θ2≥0 (23)\nfail to terminate. Such executions may, however, converge to a solution θ1= 0,θ2≥1. While still failing to terminate,\nthey do not diverge. Values of θ1>0lead to non-termination, analogously to the case where θ1<0. Also in this case,\nAlgorithm 1 may converge to a solution with θ1= 0. There also exist executions where Algorithm 1 terminates, namely\nwhen it chooses θ1= 0at some point during its execution. Choosing θ1= 0is a valid choice, as it yields local minimisers\nofJand allows removing any set of counterexamples. Therefore, for the example in Proposition 4.2, it is possible that\nAlgorithm 1 terminates, but there is no guarantee.\nRegarding the plausibility of non-terminating executions, we first remark that it is reasonable to obtain θ(0)\n1̸= 0, as neural\nnetwork training is unlikely to reach θ(0)\n1= 0exactly. Regarding the plausibility of the choice of local minimisers of CRN,\nwe consider different concrete counterexample-removal algorithms.\n•Gradient-based techniques (Pulina & Tacchella, 2010; Goodfellow et al., 2015; Dong et al., 2021; Tan et al., 2021;\nBauer-Marquart et al., 2022) are unable to remove counterexamples for Proposition 4.2, as fSatdoes not provide\ninformation on improving property violation through its gradient. This is because the region where the most violating\ncounterexamples are located is flat. Therefore, these techniques fail to remove counterexamples, which makes it\nimpossible to study the termination of Algorithm 1.\n•For SMT-based techniques (Goldberger et al., 2020), the choice of the local minimum θ(N)depends on the heuristics\napplied by the SMT solver. The SMT solver may choose to increase only one parameter, leading to a non-terminating\nexecution, such as the one constructed in the proof of Proposition 4.2.\nA.2.1. E XAMPLE 1\nFigure 4 visualises the FCNN from Example 1 The proof of non-termination for this FCNN is analogous to the proof of\nLemma A.1. Figure 3b visualises fSat(net θ(x))for the FCNN from Equation (11). Comparison with Figure 3a reveals that\nthe key aspects of fSat(net θ(x))for the FCNN are identical to Lemma A.1, except for being shifted. Most notably, there\nalso exists a flat surface with a negative fSatvalue. As Jalso prefers non-negative θin this example, Algorithm 1 diverges\nhere as well.\nA.3. Theorem 4.3\nProof of Theorem 4.3. We prove termination of Algorithm 1 for Rfrom Theorem 4.3. Optimality then follows from\nProposition 4.1. Let g:Rp×Rn→Rbe linear in the second argument. Let Xφbe a closed convex polytope. Given this,\nevery VNis a linear program and all VNshare the same feasible set Xφ. Because VNis a linear program, its minimiser\ncoincides with one of the vertices of the feasible set Xφ.\nIt follows that ∀N∈N:x(N)∈vert(Xφ), where vert(Xφ)are the vertices of Xφ. Because vert(Xφ)is finite, at some\nrepair step Nof Algorithm 1, we obtain a minimiser that we already encountered in a previous repair step. Let ˜Nbe this\n16\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nθ\n20\n12\n0−1\n1\n−10\n01\n1xy1\ny2\nFigure 4: Fully-Connected Neural Network Variant of Proposition 4.2. This Figure visualises Equation (11). Empty nodes\nrepresent single ReLU neurons. Edge labels between nodes contain the network weights. Where edges are omitted, the\ncorresponding weights are zero. Biases are written next to the incoming edge above the ReLU neurons.\nprevious repair step, such that x(˜N)=x(N). Since θ(N−1)is feasible for CRN−1, it satisfies\n0≤g\u0010\nθ(N−1),x(˜N)\u0011\n=g\u0010\nθ(N−1),x(N)\u0011\n=fSat\u0010\nnetθ(N−1)\u0010\nx(N)\u0011\u0011\n. (24)\nAs this is the termination criterion of Algorithm 1, the algorithm terminates in repair step N.\nA.4. Theorem 4.4\nWe first formally introduce element-wise monotonous functions. Informally, element-wise monotone functions are monotone\nin each argument, all other arguments being fixed at some value.\nDefinition A.4 (Element-Wise Monotone) .A function f:X →R,X ⊆Rn, iselement-wise monotone if\n∀i∈ {1, . . . , n }:∀x∈ X:f|X∩({x1}×···×{ xi−1}×R×{xi+1}×···×{ xn})is monotone . (25)\nRemark A.5.Affine transformations of element-wise monotone functions maintain element-wise monotonicity. This directly\nfollows from affine transformations maintaining monotonicity.\nElement-wise monotone functions can be monotonically increasing and decreasing in the same element but only for different\nvalues of the remaining elements. Examples of element-wise monotone functions include the single neurons\u0002\nwTx+b\u0003+\nandσ\u0000\nwTx+b\u0001\n, where [x]+= max(0 , x)is the ReLU function and σ(x) =1\n1+e−xis the sigmoid function. These\nfunctions are also continuous.\nIn Theorem 4.4, we make an assumption on the global minimisers that Algorithm 1 prefers when there are multiple global\nminimisers. In the proof of Lemma A.6, we show that the assumption in Theorem 4.4 is a weak assumption. In particular,\nwe show that it is easy to construct a global minimiser of VNthat is a vertex of Xφgiven any global minimiser of VN.\nLemma A.6 is a preliminary result for proving Theorem 4.4.\nLemma A.6 (Optimal Vertices) .LetR,gandXφbe as in Theorem 4.4. Then, for every N∈Nthere is ˜x(N)∈vert(Xφ)\nthat globally minimises VN, where vert(Xφ)denotes the set of vertices of Xφ.\nProof. LetR,g,Xφbe as in Lemma A.6. Let N∈N. To prove the lemma we show that a) VNhas a minimiser and b)\nwhen there is a minimiser of VN, some vertex of Xφalso minimises VNand has the same fSatvalue.\na)As the feasible set of VNis closed and bounded due to being a hyper-rectangle and the objective function is continu-\nous,VNhas a minimiser.\nb)Letx(N)∈Rnbe a global minimiser of VN. We show that there is a ˜x(N)∈vert(Xφ)such that ˜x(N)also\nminimises VNsince\ng\u0010\nθ(N−1),x(N)\u0011\n≥g\u0010\nθ(N−1),˜x(N)\u0011\n. (26)\nPick any dimension i∈ {1, . . . , n }. Asgis element-wise monotone, it is non-increasing in one of the two directions\nalong dimension istarting from x(N). When x(N)does not already lie on a face of Xφthat bounds expansion\n17\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nalong the i-axis, we walk along the non-increasing direction along dimension iuntil we reach such a face of Xφ.\nAsXφis a hyper-rectangle and, therefore, bounded, it is guaranteed that we reach such a face. We pick the point\non the face of Xφas the new x(N). While keeping dimension ifixed, we repeat the above procedure for a different\ndimension j∈ {1, . . . , n }, i̸=j. We iterate the procedure over all dimensions always keeping the value of x(N)in\nalready visited dimensions fixed.\nIn every step of this procedure, we restrict ourselves to a lower-dimensional face of Xφas we fix the value in one\ndimension. Thus, when we have visited every dimension, we have reached a 0-dimensional face of Xφ, that is, a\nvertex. Since we only walked along directions in which gis non-increasing and since gis element-wise monotone, the\nvertex ˜x(N)that we obtain satisfies Equation (26). Since x(N)is a global minimiser, Equation (26) needs to hold with\nequality.\nTogether, a) and b) yield that there is always a vertex ˜x(N)∈vert(Xφ)that globally minimises VN.\nProof of Theorem 4.4. We prove termination with optimality following from Proposition 4.1. Let R,g,Xφbe as in\nTheorem 4.4. Also, assume that Algorithm 1 prefers vertices of Xφas global minimisers of VN. From Lemma A.6 we know\nthat there is always a vertex of Xφthat minimises VN. From the proof of Lemma A.6 we also know that it is easy to find\nsuch a vertex given any global minimiser of VN. As Algorithm 1 always chooses vertices of Xφunder our assumption, there\nis only a finite set of minimisers x(N), as a hyper-rectangle has only finitely many vertices. Given this, termination follows\nanalogously to the proof of Theorem 4.3.\nA.5. Proposition 4.5\nProof of Proposition 4.5. LetJ,fSat,netθandXφbe as in Proposition 4.5. When inserting these into Equation (6), we\nobtain the repair problem\nR:(\nminimise\nθ∈R|θ|\nsubject to θ−x≥0∀x∈[0,1].(27)\nAssume the early-exit verifier generates the sequence x(N)=1\n2−1\nN+2as long as these points are counterexamples\nfornetθ(N−1). Otherwise, let it produce x(N)= 1, the global minimum of all VN.\nMinimising Jwithout constraints yields θ(0)= 0. The point x(1)=1\n2−1\n3is a valid result of the early-exit verifier for V1,\nas it is a counterexample. We observe that the constraint\nfSat(net θ(x)) =θ−x≥0 (28)\nis tight when θ=x. Smaller θviolate the constraint. Since Jprefers values of θcloser to zero, it always holds for any\nminimiser of CRNthat\nθ(N)= max\u0010\nx(1), . . . ,x(N)\u0011\n=x(N). (29)\nThe last equality is due to the construction of the points returned by the early-exit verifier. However, for these values\nofθ(N),1\n2−1\nN+2always remains a valid product of the early-exit verifier for VN. Thus we obtain,\nθ(N)=x(N)=1\n2−1\nN+ 2. (30)\nThe minimiser of Risθ†= 1. However, θ(N)does not converge to this point but to the infeasible limN→∞θ(N)=1\n2.\nSince the iterates θ(N)always remain infeasible for R, the modified Algorithm 1 never terminates.\nB. Experiment Design\nIn our experiments, we repair an MNIST (LeCun et al., 1998) network, ACAS Xu networks (Katz et al., 2017), a\nCollisionDetection (Ehlers, 2017) network, and integer dataset Recursive Model Indices (RMIs) (Tan et al., 2021). For repair,\nwe make use of an early-exit verifier, an optimal verifier, the SpecAttack falsifier (Bauer-Marquart et al., 2022), and the BIM\nfalsifier (Madry et al., 2018; Kurakin et al., 2017). To obtain an optimal verifier, we modify the ERAN verifier (Singh et al.,\n18\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nTable 4: Network Architectures. In(•) gives the dimension of the network input. Convolutional layers are denoted\nConv(out=•, kernel=•, stride=•, pad=•) , where out is the number of filters and kernel ,stride , and\npad are the kernel size, stride, and padding for all spatial dimensions of the layer input. Fully-connected layers are denoted\nFC(out=•) , where out is the number of neurons. [ •]×ndenotes the n-fold repetition of the block in square brackets.\nRMI stands for the Integer Dataset RMIs.\nDataset Network Architecture\nMNISTIn(1×28×28) ,Conv(out=8, kernel=3, stride=3, pad=1) ,ReLU ,\nFC(out=80) ,ReLU ,FC(out=10)\nACAS Xu In(5) , [FC(out=50) ,ReLU ] × 6, FC(out=5)\nCollision-Detection In(6) , [FC(out=10) ,ReLU ] × 2, FC(out=2)\nRMI, First Stage In(1) , [FC(out=16) ,ReLU ] × 2, FC(out=1)\nRMI, Second Stage In(1) ,FC(out=1)\n2022) to compute most-violating counterexamples. We use the modified ERAN verifier both as the early-exit and as the\noptimal verifier in our experiments, as it supports both exit modes.\nIn all experiments, we use the SpecRepair counterexample-removal algorithm (Bauer-Marquart et al., 2022) unless otherwise\nnoted. We set up all verifiers and falsifiers to return a single counterexample. For SpecAttack, which produces multiple\ncounterexamples, we select the counterexample with the largest violation. We make this modification to eliminate differences\ndue to some tools returning more counterexamples than others, as we are interested in studying the effects of counterexample\nquality, not counterexample quantity.\nWe make our source code available under the Apache 2.0 license1athttps://github .com/sen-uni-kn/\nspecrepair . Our experimental data is available at https://doi .org/10 .5281/zenodo .7938547 .\nB.1. Modifying ERAN to Compute Most-Violating Counterexamples\nThe ETH Robustness Verifier for Neural Networks (ERAN) (Singh et al., 2022) combines abstract interpretation with\nMixed Integer Linear Programming (MILP) to verify neural networks. For our experiments, we use the DeepPoly abstract\ninterpretation (Singh et al., 2019). ERAN leverages Gurobi (Gurobi Optimization, LLC, 2021) for MILP. To verify properties\nwith low-dimensional input sets having a large diameter, ERAN implements the ReluVal input splitting branch and bound\nprocedure (Wang et al., 2018). We employ this branch and bound procedure only for ACAS Xu.\nThe Gurobi MILP solver can be configured to stop optimisation when encountering the first point with a negative satis-\nfaction function value below a small threshold. We use this feature for the early-exit mode. To compute most-violating\ncounterexamples, we instead run the MILP solver until achieving optimality.\nThe input-splitting branch and bound procedure evaluates branches in parallel. In the early-exit mode, the procedure\nterminates when it finds a counterexample on any branch. As other branches may contain more-violating counterexamples,\nwe search the entire branch and bound tree in the optimal mode.\nB.2. Datasets, Networks, and Specifications\nWe perform experiments with four different datasets. In this section, we introduce the datasets, as well as what networks we\nrepair to conform to which specifications. The network architectures for each dataset are contained in Table 4.\nB.2.1. MNIST\nThe MNIST dataset (LeCun et al., 1998) consists of 70 000 labelled images of hand-written Arabic digits. Each image\nconsists of 28×28pixels. The dataset is split into a training set of 60 000 images and a test set of 10 000 images. The task\nis to predict the digit in an image from the image pixel data. We train a small convolutional neural network achieving 97 %\ntest set accuracy ( 98% training set accuracy). Table 4 contains the concrete architecture.\nWe repair the L∞adversarial robustness of this convolutional neural network for groups of 25input images. These images\n1https://www.apache.org/licenses/LICENSE-2.0.html\n19\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nare randomly sampled from the images in the training set for which the network is not robust. Each robustness property has\na radius of 0.03. Overall, we form 50non-overlapping groups of input images. Thus, each repaired network is guaranteed to\nbe locally robust for a different group of 25training set images. While specifications of this size are not practically relevant,\nthey make it feasible to perform several ( 50) experiments for each verifier variant. We formally define L∞adversarial\nrobustness in Appendix C.1.\nWe train the MNIST network using Stochastic Gradient Descent (SGD) with a mini-batch size of 32, a learning rate of 0.01\nand a momentum coefficient of 0.9, training for two epochs. Counterexample-removal uses the same setup, except for using\na decreased learning rate of 0.001and iterating only for a tenth of an epoch.\nB.2.2. ACAS X U\nThe ACAS Xu networks (Katz et al., 2017) form a collision avoidance system for aircraft without onboard personnel.\nEach network receives five sensor measurements that characterise an encounter with another aircraft. Based on these\nmeasurements, an ACAS Xu network computes scores for five possible steering directions: Clear of Conflict (maintain\ncourse), weak left/right, and strong left/right. The steering direction advised to the aircraft is the output with the minimal\nscore. Each of the 45ACAS Xu networks is responsible for another class of encounter scenarios. More details on the system\nare provided by Julian et al. (2018). Each ACAS Xu network is a fully-connected ReLU network with six hidden layers\nof50neurons each.\nKatz et al. (2017) provide safety specifications for the ACAS Xu networks. Of these specifications, the property ϕ2is\nviolated by the largest number of networks. We repair ϕ2for all networks violating it, yielding 34repair cases. The\nproperty ϕ2specifies that the score for the Clear of Conflict action is never maximal (least-advised) when the intruder is far\naway and slow. The precise formal definition of ϕ2is given in Appendix C.2.\nWe repair the ACAS Xu networks following Bauer-Marquart et al. (2022). To replace the unavailable ACAS Xu training\ndata, we randomly sample a training and a validation set and compare with the scores produced by the original network. As\na loss function, we use the asymmetric mean square error loss of Julian & Kochenderfer (2019). We repair using the Adam\ntraining algorithm (Kingma & Ba, 2015) with a learning rate of 10−4. We terminate training on convergence, when the loss\non the validation set starts to increase, or after at most 500iterations.\nFor assessing the performance of repaired networks, we compare the accuracy and the Mean Absolute Error (MAE) between\nthe predictions of the repaired network and the predictions of the original network on a large grid of inputs, filtering out\ncounterexamples. For all networks, the filtered grid contains more than 24million points.\nB.2.3. C OLLISION DETECTION\nThe CollisionDetection dataset (Ehlers, 2017) is introduced for evaluating neural network verifiers. The task is to predict\nwhether two particles collide based on their relative position, speed, and turning angles. The training set of 7000 instances\nand the test set of 3000 instances are obtained from simulating particle dynamics for randomly sampled initial configurations.\nWe train a small fully-connected neural network with 20neurons on this dataset. The full architecture is given in Table 4.\nSimilarly to MNIST, we repair the adversarial robustness of this network for 100 non-overlapping groups of ten randomly\nsampled inputs from the training set. Here we also include inputs that do not violate the specification to gather a sufficient\nnumber of groups. Each robustness property has a radius of 0.05.\nThe CollisionDetection network is trained for 1000 iterations using Adam (Kingma & Ba, 2015) with a learning rate of 0.01.\nRepair uses Adam with a learning rate of 0.001, terminating training on convergence or when reaching 5000 iterations.\nB.2.4. I NTEGER DATASET RMI S\nLearned index structures replace index structures, such as B-trees, with machine learning models (Kraska et al., 2018).\nTan et al. (2021) identify these models as prime candidates for neural network verification and repair due to the strict\nrequirements of their domain and the small size of the models. We use Recursive Model Indices (RMIs) (Kraska et al., 2018)\nin our experiments. The task of an RMI is to resolve a key to a position in a sorted sequence.\nWe build datasets, RMIs and specifications following Tan et al. (2021), with the exception that we create models of two\nsizes. While Tan et al. (2021) build one RMI with a second-stage size of ten, we build ten RMIs with a second-stage size of\nten and 50RMIs with a second-stage size of 304. Each RMI is constructed for a different dataset. We create models of\n20\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\ntwo second-stage sizes because the smaller size does not yield unsafe first-stage models, while the larger second-stage size\ndoes not yield unsafe second-stage models. However, we want to repair models of both stages. Therefore, when repairing\nfirst-stage models in Section 5.2, we repair the first-stage models of the RMIs with second-stage size 304. In Section 5.3, we\nrepair the second-stage models of the RMIs with second-stage size ten.\nEach dataset is a randomly generated integer dataset consisting of a sorted sequence of 190 000 integers. The integers are\nrandomly sampled from a uniform distribution with the range\u0002\n0,106\u0003\n. The task is to predict the index of an integer (key) in\nthe sorted sequence.\nWe build an RMI for each dataset. Each RMI consists of two stages. The first stage contains one neural network. The second\nstage contains several linear regression models. In our case, the second stage contains either ten or 304models. Each dataset\nis first split into several disjoint blocks, one for each second-stage model. Now, the first-stage network is trained to predict\nthe block an integer key belongs to. The purpose of this model is to select a model from the second stage. Each model\nof the second stage is responsible for resolving the keys in a block to the position of the key in the sorted sequence. The\narchitectures of the models are given in Table 4.\nWe train the first-stage model to minimise the Mean Square Error (MSE) between the model predictions and the true blocks.\nTraining uses Adam (Kingma & Ba, 2015) with a learning rate of 0.01and a mini-batch size of 512. For an RMI with a\nsecond-stage size of ten, we train for one epoch. For the larger second-stage size of 304, we train for six epochs.\nMinimising the MSE between the positions a second-stage model predicts and the true positions can be solved analytically.\nWe use the analytic solution for training the second-stage models. In Section 5.3, we compare with Ouroboros (Tan et al.,\n2021) that also uses the analytic solution. SpecRepair (Bauer-Marquart et al., 2022) can not make use of the analytic solution.\nInstead, it repairs second-stage models using gradient descent with a learning rate of 10−13, running for 150iterations.\nThe specifications for the RMIs are error bounds on the predictions of each model. For a first-stage neural network, the\nspecification is that it may not deviate by more than one valid block from the true block. The specification for a second-stage\nmodel consists of one property for each key in the target block and one for all other keys that the first stage assigns to the\nsecond-stage model. The property for a key kispecifies that the prediction for all keys between the previous key ki−1and\nthe next key ki+1in the dataset may not deviate by more than εfrom the position for ki. We use two sets of specifications,\none with ε= 100 and one with ε= 150 . According to Tan et al. (2021), the specifications express a guaranteed error bound\nfor looking up both existing and non-existing keys. The formal definitions of the specifications are given in Appendix C.3.\nAs the original Ouroboros implementation is not publicly available, we reimplement Ouroboros, including creating integer\ndataset RMIs. To roughly estimate whether our reimplementation is faithful, we can examine the average size of the\nspecifications for the second-stage models for the RMIs with second-stage size ten. As these specifications include keys that\nare wrongly assigned to a second-stage model, they can serve for quantifying the accuracy of the first-stage models. The\nspecifications that we obtain for these models have a similar average size as reported by Tan et al. (2021) ( 19 426 properties).\nThis indicates that our reimplementation is faithful.\nB.3. Repair Algorithms\nExcept for Section 5.3, we exclusively use the SpecRepair counterexample-removal algorithm (Bauer-Marquart et al., 2022)\nin our experiments. In Section 5.3, we also use the Ouroboros (Tan et al., 2021) repair algorithm and the novel Quadratic\nProgramming repair algorithm. Additionally, we leverage different falsifiers for repair. This section introduces these tools.\nBoth Ouroboros and SpecRepair are counterexample-guided repair algorithms. Ouroboros performs repair by augmenting\nthe training set with counterexamples and retraining the linear regression models using an analytic solution. SpecRepair\nuses the L1penalty function method (Nocedal & Wright, 2006). We use SpecRepair with a decreased initial penalty weight\nof2−4and a satisfaction constant of 10−4. We do not limit the number of repair steps a repair algorithm may perform,\nexcept for Section 5.3. Here, we perform at most two repair steps for SpecRepair. For Ouroboros, we perform up to five\nrepair steps following Tan et al. (2021).\nThe Quadratic Programming repair algorithm from Section 5.3 is exact. That is, we obtain an infeasible problem if and only\nif the linear regression model can not satisfy the specification and otherwise obtain the optimal repaired regression model.\nTo mitigate floating point issues, we require the satisfaction function to be at least 10−2in Equation (6)instead of requiring\nit to be just non-negative. That corresponds to applying a satisfaction constant as in SpecRepair (Bauer-Marquart et al.,\n2022).\n21\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nWe run SpecAttack Bauer-Marquart et al. (2022) using Sequential Least SQuares Programming (SLSQP) as network\ngradients are available. Following Carlini & Wagner (2017), we run BIM (Kurakin et al., 2017; Madry et al., 2018) with\nAdam (Kingma & Ba, 2015) as optimiser. BIM performs local optimisation ten times from different random starting points.\nB.4. Implementation and Hardware\nWe build upon SpecRepair (Bauer-Marquart et al., 2022) for our experiments, leveraging the modified ERAN. SpecRepair\nand ERAN are implemented in Python. SpecRepair is based on PyTorch (Paszke et al., 2019). For repairing linear regression\nmodels, we also use an ERAN-based Python reimplementation of Ouroboros (Tan et al., 2021). The original Ouroboros\nimplementation is not publicly available. The quadratic programming repair algorithm for linear regression models is\nimplemented in Python and leverages Gurobi (Gurobi Optimization, LLC, 2021).\nAll experiments were conducted on Ubuntu 2022.04.1 LTS machines using Python 3.8. The ACAS Xu, CollisionDetection\nand Integer Dataset RMI experiments were run on a compute server with an Intel Xeon E5–2580 v4 2.4GHz CPU (28 cores)\nand 1008GB of memory. The MNIST experiments were run on a GPU compute server with an AMD Ryzen Threadripper\n3960X 24-Core Processor and 252GB of memory, utilising an NVIDIA RTX A6000 GPU with 48GB of memory.\nWe limit the execution time for repairing each ACAS Xu network and each MNIST specification to three hours. For\nCollisionDetection and the Integer Dataset RMIs, we use a shorter timeout of one hour. Except for ACAS Xu, whenever\nwe report runtimes, we repeat all experiments ten times and report the median runtime from these runs. This way, we\nobtain more accurate runtime measurements that are necessary for interpreting runtime differences below one minute. For\nACAS Xu, the runtime differences are sufficiently large for all but one network, so that we can faithfully compare different\ncounterexample searchers without repeating the experiments.\nC. Specifications\nIn this section, we formally define the specifications used throughout this paper.\nC.1.L∞Adversarial Robustness\nAdversarial robustness is a specification for classifiers capturing that small perturbations of an input may not change the\nclassification. For L∞adversarial robustness, the input set is an L∞ball (a hyper-rectangle).\nAssume the input space has ndimensions and there are mclasses. Furthermore, assume the classifier produces a score\nfor each class so that the classifier has moutputs. Also, assume the classification is the class with the largest score.\nLetD ⊂Rn× {1, . . . , m }be the set of labelled inputs for which we want to specify adversarial robustness. Then, the L∞\nadversarial robustness specification with radius εis\nΦ ={φ(x, c)|(x, c)∈ D} (31a)\nφ(x, c) = \n{x′|x′∈Rn,∥x′−x∥∞≤ε},(\ny\f\f\f\f\fy∈Rm,m^\ni=1yi≤yc)!\n. (31b)\nThe SpecRepair satisfaction function (Bauer-Marquart et al., 2022) for a property φ(x, c)is\nfSat(y) =m\nmin\ni=1yc−yi. (32)\nEquivalently, we can split up each property into several properties with just one linear constraint, yielding a linear\nspecification. We describe this in Section C.3.\nC.2. ACAS Xu ϕ2\nThis safety specification consists of a single property. The property ϕ2of Katz et al. (2017) is\nϕ2= \n[55947 .691,∞]×R2×[1145 ,∞]×[−∞,60],(\ny\f\f\f\f\fy∈R5,5_\ni=1y1≤yi)!\n. (33)\n22\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nThe output set expresses that Clear-of-Conflict is not the maximal score, or, in other words, is not least advised. The input\nset of this property is unbounded, but each ACAS Xu network has a bounded input domain. Intersected with one of the\ninput domains, we obtain a closed input set for the property. The SpecRepair satisfaction function for ϕ2is\nfSat(y) =mmax\ni=1yi−y1. (34)\nC.3. Integer Dataset RMI Error Bounds\nFor an RMI, the specification of a first-stage model is that it may not deviate by more than one valid block from the true\nblock a key resides in. Let [l1, u1],[l2, u2], . . . , [lK, uK]be the blocks of the RMI, where K∈ {10,304}is the number of\nblocks. Then, the specification of the first-stage model is\nΦ ={φi}K\ni=1(35a)\nφi= ([li, ui],[max(1 , i−1),min(i+ 1, K)])∀i∈ {1, . . . , K }. (35b)\nThe specification of a second-stage model contains one property for each key kithat is in the model’s target block or is\nassigned to the model by the first-stage model. Let K ⊂Nbe the indices of keys that are in the model’s block or assigned to\nit. Each property expresses that the predictions for all keys between the previous key ki−1and the next key ki+1deviate by\nat most ε∈ {100,150}from the true position piofki. When there is no previous or next key in the dataset, we use the key\nitself as bound. Therefore, k0=k1andk190 001 =k190 000 . Now, the second-stage specification is\nΦ ={φi}i∈K(36a)\nφi= ([min( ki−1+ 1, ki),max( ki+1−1, ki)],[pi−ε, pi+ε]). (36b)\nThe output sets of these properties are hyper-rectangles. In the SpecRepair property format, one-dimensional hyper-\nrectangles correspond to a conjunction of two linear constraints. A conjunction of multiple linear constraints does not yield\nan affine satisfaction function, as SpecRepair uses a minimum to encode conjunctions. This is illustrated by Equation (32).\nTo obtain a linear specification, we can split each property into two properties, such that each property only has one linear\nconstraint. Using this alternative formulation, the specification of a second-stage model is\nΦ ={φi}i∈K∪ {ψi}i∈K(37a)\nφi= ([min( ki−1+ 1, ki),max( ki+1−1, ki)],{y|y∈R,y≥pi−ε}) (37b)\nψi= ([min( ki−1+ 1, ki),max( ki+1−1, ki)],{y|y∈R,y≤pi+ε}). (37c)\nThis formulation yields the affine SpecRepair satisfaction functions fSat(y) =y−pi−εfor the property φiandfSat(y) =\npi+ε−yforψi. As the input set of each property is a hyper-rectangle, Φfrom Equation (37) is a linear specification.\nD. Additional Experimental Results\nIn this section, we report additional experimental results. This includes additional results on using falsifiers for repair and an\noverview of the success rates and repaired network performance when using different verifiers and falsifiers for repair. For\ncomparison with earlier work, we report our full ACAS Xu results in Section D.3.\nA Note on Failing Repairs We witness several failing repairs in our experiments. These are either due to timeout or due\nto failing counterexample-removal. There are no indications of non-termination regarding Algorithm 1 itself in these failing\nrepairs. In other words, we do not observe exceedingly high repair step counts. This holds true both for the optimal verifier,\nfor which termination remains an open question, and the early-exit verifier, for which we disprove termination in Section 4.6.\nD.1. Using Falsifiers for Repair\nIn this section, we report additional results on repair using falsifiers. To study the advantages of falsifiers for repair, we repair\nan MNIST network and the ACAS Xu networks using the SpecAttack (Bauer-Marquart et al., 2022) and BIM (Kurakin\net al., 2017; Madry et al., 2018) falsifiers. We outline the approach of the BIM falsifier in Section 3.3. We start repair by\nsearching counterexamples using one of the falsifiers. Only when the falsifier fails to produce further counterexamples we\n23\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\n0 10 20 30 40 50103104\nOptimal\nEarly-ExitSpecAttack\n#Repaired InstancesRuntime ( s)\n(a) MNIST\n0 5 10 15 20 25 30 35102103104\nOptimal\nEarly-Exit\nSpecAttack\n#Repaired InstancesRuntime ( s) (b) ACAS Xu\nFigure 5: Repair using Falsifiers. We plot the number of repaired instances that individually require less than a certain\nruntime. We plot this for repair using SpecAttack\n , only the optimal verifier\n and only the early-exit verifier\n . Both\nexperiments use a timeout of three hours. Runtimes are given on a logarithmic scale.\nturn to the early-exit verifier. Ideally, we would want that the verifier is invoked only once to prove specification satisfaction.\nPractically, often several additional repair steps have to be performed using the verifier.\nFor ACAS Xu, we observe that BIM generally fails to find counterexamples. Therefore, we only report using SpecAttack for\nACAS Xu. For the small CollisionDetection and Integer Dataset networks, the verifier is already comparably fast, so neither\nBIM nor SpecAttack can provide a runtime advantage. We also evaluated combining falsifiers with the optimal verifier, but\nthis does not improve upon using the early-exit verifier.\nSpecAttack Figure 5 summarises our results for repairing the MNIST network and the ACAS Xu networks using\nSpecAttack. For the MNIST network, using SpecAttack is inferior to using only the early-exit verifier. In our experiments,\nSpecAttack provides no significant runtime advantage for generating counterexamples over the early-exit verifier and\ntends to compute counterexamples with a smaller violation. SpecAttack’s runtime scales well with the network size but\nexponentially in the input dimension. Thus, it is not surprising that it provides no advantage for our MNIST network, which\nis tiny compared to state-of-the-art image classification networks.\nFor ACAS Xu, we would expect that SpecAttack outperforms using only the early-exit verifier more clearly than apparent\nfrom Figure 5. Here, SpecAttack’s runtime is an order of magnitude faster than the runtime of the early-exit verifier.\nSpecAttack can also provide an advantage in repair steps in many cases. However, at times using SpecAttack also increases\nthe number of repair steps. Additionally, SpecAttack sometimes makes the final invocations of the early-exit verifier more\ncostly than when only the verifier is used.\nAdditional Results on BIM The results of our experiments using BIM on MNIST are summarised in Figure 2. We already\ndiscussed that BIM can significantly accelerate repair. For MNIST, repair using BIM is the fastest method in 70 % of the\nrepair cases, compared to 26 % for only the early-exit verifier, 2 %for SpecAttack and 0 %for only the optimal verifier.\nIn2 %of the cases, the runtime of the two best variants is within 30seconds. The breakdown of which method is the fastest\nfor each repair case shows that the picture is not as clear as we may wish it to be — BIM provides a significant runtime\nadvantage in 70 % of the cases, but in 26 % of the cases using only the early-exit verifier is faster.\nOur experiments using falsifiers demonstrate that they can give a substantial runtime advantage to repair, but they also show\nthat speeding up repair traces back to more intricate properties beyond just falsifier speed. Understanding these properties\nbetter is a promising future research direction for designing better falsifiers for repair.\nD.2. Success Rates and Repaired Network Performance\nTable 5 summarises the success rates of repairing MNIST, ACAS Xu, and CollisionDetection networks and Integer Dataset\nRMI first-stage models using different verifiers and falsifiers. For the large MNIST and ACAS Xu networks, the early-exit\nverifier enables repair in some cases where repair using the optimal verifier fails due to timeout. Regarding the use of\nfalsifiers, there are minor variations for the Integer Dataset RMIs and CollisionDetection. These differences are due to\nfailing repairs. Here, the counterexample removal procedure is unable to remove all counterexamples provided by, for\n24\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nTable 5: Experiments: Success Rates. The success rates when repairing the ACAS Xu, MNIST, and CollisionDetection\nnetworks and integer dataset RMI first-stage models using the different verifiers and falsifiers. For ACAS Xu, BIM is not\nincluded as it is unable to discover counterexamples for these networks.\nSuccess Rate\nDataset Optimal Early-Exit BIM SpecAttack\nACAS Xu 82.5 % 100 .0 % – 100.0 %\nMNIST 96.0 % 100 .0 % 100 .0 % 100 .0 %\nInteger Datasets 92.0 % 92 .0 % 94 .0 % 90 .0 %\nCollisionDetection 90.0 % 90 .0 % 89 .0 % 88 .0 %\nTable 6: Experiments: Median Accuracy. The median repaired network accuracy when repairing the ACAS Xu, MNIST,\nand CollisionDetection networks and integer dataset RMI first-stage models using the different verifiers and falsifiers. We\nreport the test set accuracy for MNIST and CollisionDetection and the training set accuracy for the integer dataset RMIs.\nFor ACAS Xu, we report the accuracy for recreating the predictions of the original network for a large grid of inputs, as\ndescribed in Appendix B.2. We report the median accuracy among the cases where repair is successful for all verifiers and\nfalsifiers. For ACAS Xu, BIM is not included as it is unable to discover counterexamples for these networks.\nMedian Accuracy\nDataset Optimal Early-Exit BIM SpecAttack\nACAS Xu 99.6 % 99 .6 % – 99.6 %\nMNIST 97.4 % 97 .5 % 97 .4 % 97 .5 %\nInteger Datasets 90.9 % 90 .9 % 90 .0 % 91 .0 %\nCollisionDetection 89.8 % 90 .2 % 90 .0 % 89 .9 %\nexample, the optimal verifier, while it succeeds for another set of counterexamples.\nTable 6 summarises the performance of the repaired networks. We only observe minimal variations regarding the performance.\nUsing the early-exit verifier slightly outperforms the optimal verifiers on MNIST and CollisionDetection. The impact of BIM\nand SpecAttack is inconsistent across datasets. We recommend fine-tuning the initial penalty weight to the counterexample\nviolation magnitude instead of using a different counterexample searcher to increase repaired network performance.\nD.3. ACAS Xu\nFor comparison with the earlier work of Bauer-Marquart et al. (2022), we report our detailed ACAS Xu results in Table 7.\nDue to improvements in the interaction with the verifier, we are successful more frequently than any method evaluated\nby Bauer-Marquart et al. (2022). At the same time, we maintain the level of repaired network performance.\n25\n\nA Robust Optimisation Perspective on Counterexample-Guided Repair of Neural Networks\nTable 7: Detailed ACAS Xu Results. Opt. and E.E denote repair using the optimal and the early-exit verifier, respectively.\nSp.A. denotes repair using SpecAttack and the early-exit verifier. The symbol ✓denotes successful repair, while \ndenotes timeout. Both accuracy and Mean Absolute Error (MAE) compare the predictions of the repaired network with the\npredictions of the initial faulty network for a large grid of inputs. More details on this are provided in Appendix B.2.\nStatus Accuracy MAE\nSpec. Model Opt. E.E. Sp.A. Opt. E.E. Sp.A. Opt. E.E. Sp.A.\nϕ2 N2,1✓✓✓ 99.6 % 99 .4 % 99 .6 % 0 .10 0 .15 0 .11\nϕ2 N2,2 \n✓✓ – 99.2 % 99 .1 % – 0.18 0 .22\nϕ2 N2,3✓✓✓ 99.7 % 99 .7 % 99 .7 % 0 .09 0 .10 0 .11\nϕ2 N2,4✓✓✓ 99.7 % 99 .5 % 99 .8 % 0 .08 0 .11 0 .08\nϕ2 N2,5 \n✓✓ – 99.4 % 99 .3 % – 0.11 0 .11\nϕ2 N2,6✓✓✓ 99.6 % 99 .5 % 99 .5 % 0 .12 0 .11 0 .10\nϕ2 N2,7 \n✓✓ – 99.5 % 14 .5 % – 0.17 0 .16\nϕ2 N2,8✓✓✓ 99.6 % 99 .6 % 99 .7 % 0 .12 0 .15 0 .13\nϕ2 N2,9✓✓✓ 99.9 % 99 .8 % 99 .8 % 0 .17 0 .14 0 .14\nϕ2 N3,1✓✓✓ 99.0 % 99 .3 % 99 .4 % 0 .22 0 .14 0 .17\nϕ2 N3,2✓✓✓ 99.9 % 99 .8 % 99 .8 % 0 .08 0 .09 0 .13\nϕ2 N3,4✓✓✓ 99.6 % 99 .6 % 99 .6 % 0 .11 0 .13 0 .08\nϕ2 N3,5✓✓✓ 99.5 % 99 .5 % 99 .5 % 0 .08 0 .10 0 .08\nϕ2 N3,6✓✓✓ 99.8 % 99 .8 % 99 .7 % 0 .05 0 .06 0 .06\nϕ2 N3,7✓✓✓ 99.6 % 99 .6 % 99 .7 % 0 .09 0 .08 0 .08\nϕ2 N3,8✓✓✓ 99.6 % 99 .6 % 99 .7 % 0 .13 0 .10 0 .11\nϕ2 N3,9 \n✓✓ – 97.5 % 97 .5 % – 0.19 0 .18\nϕ2 N4,1✓✓✓ 99.8 % 99 .8 % 99 .8 % 0 .10 0 .07 0 .10\nϕ2 N4,3✓✓✓ 99.6 % 99 .6 % 99 .5 % 0 .09 0 .08 0 .13\nϕ2 N4,4✓✓✓ 99.7 % 99 .6 % 99 .7 % 0 .11 0 .15 0 .09\nϕ2 N4,5✓✓✓ 99.6 % 99 .5 % 99 .5 % 0 .09 0 .07 0 .12\nϕ2 N4,6 \n✓✓ – 99.5 % 99 .6 % – 0.13 0 .11\nϕ2 N4,7 \n✓✓ – 99.2 % 99 .2 % – 0.17 0 .18\nϕ2 N4,8✓✓✓ 99.4 % 99 .3 % 99 .5 % 0 .08 0 .08 0 .09\nϕ2 N4,9✓✓✓ 96.5 % 96 .4 % 96 .5 % 0 .16 0 .14 0 .13\nϕ2 N5,1✓✓✓ 99.7 % 99 .5 % 99 .6 % 0 .12 0 .13 0 .09\nϕ2 N5,2✓✓✓ 99.7 % 99 .7 % 99 .7 % 0 .08 0 .07 0 .08\nϕ2 N5,3✓✓✓ 99.9 % 99 .9 % 99 .9 % 0 .04 0 .04 0 .04\nϕ2 N5,4✓✓✓ 99.7 % 99 .7 % 99 .7 % 0 .10 0 .07 0 .10\nϕ2 N5,5✓✓✓ 99.8 % 99 .7 % 99 .8 % 0 .10 0 .13 0 .11\nϕ2 N5,6✓✓✓ 99.6 % 99 .5 % 99 .5 % 0 .13 0 .11 0 .11\nϕ2 N5,7✓✓✓ 99.3 % 99 .3 % 99 .5 % 0 .17 0 .14 0 .11\nϕ2 N5,8✓✓✓ 99.6 % 99 .4 % 99 .5 % 0 .13 0 .12 0 .13\nϕ2 N5,9✓✓✓ 99.0 % 98 .9 % 99 .1 % 0 .14 0 .13 0 .09\n28 34 34 99.6 % 99 .5 % 99 .6 % 0 .10 0 .11 0 .11\nsuccess frequency median median\n26",
  "textLength": 107467
}