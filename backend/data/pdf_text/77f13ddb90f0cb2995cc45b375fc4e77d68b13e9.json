{
  "paperId": "77f13ddb90f0cb2995cc45b375fc4e77d68b13e9",
  "title": "SPECIAL: Synopsis Assisted Secure Collaborative Analytics",
  "pdfPath": "77f13ddb90f0cb2995cc45b375fc4e77d68b13e9.pdf",
  "text": "SPECIAL: SynoPsis AssistEd Secure CollaboratIve AnaLytics\nChenghong Wang\nIndiana University\ncw166@iu.eduLina Qiu\nBoston University\nqlina@bu.eduJohes Bater\nTufts University\njohes.bater@tufts.eduYukui Luo\nUmass Dartmouth\nyluo2@umassd.edu\nABSTRACT\nSecure collaborative analytics (SCA) enables the processing of ana-\nlytical SQL queries across data from multiple owners, even when\ndirect data sharing is not possible. While traditional SCA provides\nstrong privacy through data-oblivious methods, the significant over-\nhead has limited its practical use. Recent SCA variants that allow\ncontrolled leakages under differential privacy (DP) strike balance\nbetween privacy and efficiency but still face challenges like un-\nbounded privacy loss, costly execution plan, and lossy processing.\nTo address these challenges, we introduceSPECIAL, the first\nSCA system that simultaneously ensures bounded privacy loss, ad-\nvanced query planning, and lossless processing.SPECIALemploys\na novelsynopsis-assisted secure processing model, where a one-time\nprivacy cost is used to generate private synopses from owner data.\nThese synopses enableSPECIALto estimate compaction sizes for\nsecure operations (e.g., filter, join) and index encrypted data with-\nout additional privacy loss. These estimates and indexes can be\nprepared before runtime, enabling efficient query planning and\naccurate cost estimations. By leveraging one-sided noise mecha-\nnisms and private upper bound techniques,SPECIALguarantees\nlossless processing for complex queries (e.g., multi-join). Our com-\nprehensive benchmarks demonstrate thatSPECIALoutperforms\nstate-of-the-art SCAs, with up to80 Ã—faster query times,900 Ã—\nsmaller memory usage for complex queries, and up to89 Ã—reduced\nprivacy loss in continual processing.\nPVLDB Reference Format:\nChenghong Wang, Lina Qiu, Johes Bater, and Yukui Luo.SPECIAL:\nSynoPsis AssistEd Secure CollaboratIve AnaLytics. PVLDB, 18(4): 1035 -\n1048, 2024.\ndoi:10.14778/3717755.3717764\nPVLDB Artifact Availability:\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/lovingmage/caplan.\n1 INTRODUCTION\nOrganizations, such as hospitals, frequently hold sensitive data\nin separate silos to comply with privacy laws, despite the valu-\nable insights that could be gained from sharing this information.\nRecent advancement of Secure Collaborative Analytics (SCA) [ 7â€“\n9,25,33,44,54,55,57,70,71] provides an exciting solution to tackle\nthis dilemma. These systems leverage advanced multi-party secure\ncomputation (MPC) [ 76] primitives to empower multiple data own-\ners, who previously could not directly share data, to collaboratively\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 18, No. 4 ISSN 2150-8097.\ndoi:10.14778/3717755.3717764process analytical queries over their combined data while ensuring\nthe privacy of each individualâ€™s data.\nWhile MPC can effectively conceal data values [ 76], its security\nguarantees do not immediately extend to the protection of execu-\ntion transcripts. Consequently, data-dependent processing patterns\nsuch as memory traces and read/write volumes can still reveal crit-\nical information, risking privacy breaches [ 11,15,29,38,50,60,78]\neven when the core data remains encrypted. To ensure strong pri-\nvacy, modern SCA systems utilizedata-obliviousprimitives that\nexhaustively pad query processing complexities to a worst-case and\ndata-independent upper bound [ 7,44,54]. However, such stringent\nprotections can largely reduce system efficiency and hinder the\ngeneralization of conventional optimization techniques to SCA,\nwhich are typically data-dependent [ 44]. To address this, recent\nefforts [ 8,55,70,71] have introduced Differentially Private SCA\n(DPSCA). This approach allows controlled information leakage un-\nder DP [ 23] to mitigate constant worst-case overhead. For instance,\nsystems under this model can dynamically compact an intermediate\nquery size to a noisy estimate close to the actual size, avoiding ex-\nhaustive padding. As such, queries under DPSCA experience largely\nboosted efficiencies (e.g., up to105Ã—faster [ 71]) compared to their\nâ€œno leakageâ€ counterparts. Despite these substantial performance\ngains, existing DPSCAs still face critical limitations that impede\ntheir practical uses, as elaborated below:\nâ€¢L-1. Unbounded privacy loss.Most DPSCA systems utilize a per-\noperator privacy expenditure model [ 8,16,19,55,70,71], meaning\neach query operator (e.g., join, filter) independently consumes a\nportion of the privacy budget. This approach can lead to either\nunbounded privacy loss or the forced cessation of query responses\nupon budget exhaustion. To mitigate this, some studies [ 13,56,\n77] propose private, locality-sensitive grouping, incurring a one-\ntime privacy cost to pre-group data based on specific attributes.\nSubsequent queries on those attributes can be directly applied to\na smaller subset and need no additional privacy budget. However,\nthis method only supports simple queries (e.g., point and range);\ncomplex queries like joins still suffer from unbounded privacy loss.\nâ€¢L-2. Unoptimized execution plan.Conventional query planners can\npre-estimate sizes for equivalent plans of a given query and select\nthe most efficient plan with minimized intermediate sizes before\nexecution [ 12,61]. In contrast, SCA systems lack this capability,\nand even DPSCA designs [ 8,9,55,69,71,77] can only reactively\ndetermine plan sizes during runtime. This inherent limitation often\nforces existing systems to settle for less efficient query plans, such as\ncostly join orders, which lead to significantly inflated intermediate\nsizes (Â§ 7.2) and substantially hinder performance.\nâ€¢L-3. Lossy processing.Noise from randomized mechanisms in\nDPSCA also introduces a unique accuracy issue (e.g., conventional\nDP mechanisms may generate negative noise, applying which to\nobfuscate the sizes of intermediate query results can cause losingarXiv:2404.18388v2  [cs.CR]  17 Sep 2025\n\nqualified real tuples), and unfortunately, no existing DPSCA can\nmitigate such loss for complex queries [ 28,69â€“71,77]. Furthermore,\nstronger DP settings can further increase noise variance, which\namplifies errors, significantly impacting the utility of SCA systems.\n1.1 Overview ofSPECIAL\nIn this work, we introduceSPECIAL, an innovative SCA system\nthat resolves the aforementioned limitations all at once through a\nnew paradigm calledsynopsis-assisted secure processing. At its core,\nSPECIALincurs a one-time privacy cost to gather DP synopses\n(statistics of base tables) from ownersâ€™ data. These synopses are\nthen used to accelerate complex query processing, and enhance SCA\nquery planning. Notably,SPECIALis the first system to provide all\nof the following benefits: (1)Bounded privacyâ€”the privacy loss in\nSPECIALis strictly limited to the one-time synopses release stage,\nwith absotely no additional privacy cost during complex query\nprocessing and planning; (2)Advanced query planningâ€”it builds an\nadvanced SCA planner that can exploit plan sizes before runtime;\nand (3)Lossless processingâ€”it ensures exact results with no data\nomissions. An overview ofSPECIALis shown in Figure 1.\nFigure 1: Overview ofSPECIALworkflow.\nSPECIALoperates under a standard server-aided MPC model [ 37]\nwith three key participants: data owners, at least twoSPECIAL\nservers, and a vetted analyst. The process begins with data own-\ners securely outsourcing their data, typically through secret shar-\ning [ 37,70,71,77], and privately releasing corresponding DP syn-\nopses (Â§ 4) to the servers.SPECIALintroduces a set of novel prim-\nitives (Â§ 5) that can leverage these synopses to accelerate secure\nquery operations. Once the data and synopses are in place, analysts\ncan submit Select-Project-Join-Aggregation (SPJA) queries [ 61] for\nanalytics. To process queries, a private planner (Â§ 6), running on\nSPECIALservers, strategically orchestratesSPECIALprimitives to\nprocess the query and optimize performance. Finally, the results\nare securely returned to the analyst.\n1.2 Unique challenges and key contributions\nLeveraging DP synopses in SCA holds significant promise for achiev-\ning our desired objectives. However, this also introduces unique\nchallenges. Below, we highlight the key challenges and summarize\nour non-trivial contributions to address them:\nâ€¢C-1. How to select proper synopses?Even for a single relation, one\ncan find numerous attribute combinations for generating synopses.\nImproper selection can lead to large errors (e.g. using too many syn-\nopses or high-dimensional attributes [ 79]), or reduced functionali-\nties (e.g., using only simple attributes [ 77]). Hence, a key challenge\nis selecting a limited set of DP synopses to optimize the privacy\nbudget for complex query processing. Our approach is informed bytwo observations: (i) secure joins are resource-intensive and need\nprioritized acceleration, and (ii) synopses for common filtering pred-\nicates are vital as they allow pre-built indexes on base relations for\nfast access. Consequently, we propose a focused strategy (Â§ 4) that\ntargets low-dimensional (1D and 2D) attributes frequently involved\nin joins and filters within a representative workload.\nâ€¢C-2. How to enforce lossless processing?Private synopses do not\nimmediately implies lossless guarantees. Thus, a second challenge\nis designing practical approaches to achieve lossless results without\nviolating privacy goals. To address this, we employ one-sided DP\nnoise (either strictly positive or negative, Â§ 4) in generating syn-\nopses, and design novel primitives (Â§ 5) based on them to pessimisti-\ncally estimate filter cardinalities and intervals of index structures.\nTo ensure lossless processing of complex joins, we extend upon\ncutting-edge join upper bound techniques [ 34] to privately estimate\nlossless join sizes using DP synopses. To our knowledge, this is the\nfirst study to support private join upper bound estimation.\nâ€¢C-3. How DP synopses can empower efficient query processing?\nThe use of DP synopses in SCA is largely underexplored, leav-\ning a knowledge gap regarding their potential to enhance query\nefficiency. To navigate this potential, we explore various use of\nsynopses in accelerating secure processing including private in-\ndexesSPEidx(Â§ 5.2), and compacted oblivious operationsSPEop\n(Â§ 5.3). We also design a novel private query planner (Â§ 6) that\nefficiently orchestrate the execution ofSPECIALprimitives (e.g.,\nSPEidx,SPEop) to process SPJA queries. The planner uses avail-\nable synopses to privately estimate intermediate result sizes and\noperation costs for a set of equivalent execution plans of a given\nquery. It then executes the one with the lowest estimated cost.\nâ€¢C-4. How to systematically evaluateSPECIAL?A major is the\nabsence of open benchmarks. We address this by initiating an open-\nsource evaluation set, accessible to the public. Specifically, we use\npublic financial data [ 1] and design eight test queries, ranging from\nsimple linear queries to complex 5-way joins. We also re-produce\nan open version of the HealthLNK benchmark. We evaluate our\nprototype,SPECIAL, against the state-of-the-art (SOTA) DPSCA\nsystem, Shrinkwrap [ 8], and the conventional SCA system, SM-\nCQL [ 7]. Results indicate thatSPECIALoutperforms Shrinkwrap,\nreducing query latency by up to80 .3Ã—, and SMCQL, with at least a\n114Ã—reduction in query latency. Additionally,SPECIALimproves\nmemory efficiency in complex join processing by more than900Ã—\ncompared to both systems. Moreover, scaling experiments show\nthatSPECIALcan effectively scale up to 8.8M rows dataset and up\nto 9-way complex joins. All benchmarks, including our prototype\nimplementation, are open-sourced and available at [45].\n2 BACKGROUND\nGeneral notations.We consider the logical database Dto contain\nmultiple private (base) relations {ğ·1,ğ·2,...}, where each relation\nğ·ğ‘–is owned by a specific party ğ‘ƒğ‘–. A base relation ğ·(we omit sub-\nscript for simplicity) has a set of attributes ğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·) . The domain of\nan attribute ğ´âˆˆğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·) is denoted by ğ‘‘ğ‘œğ‘š(ğ´) , and the combined\ndomain of a collection of attributesA ={ğ´ 1,ğ´2,...}âŠ†ğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·)\nis denoted by ğ‘‘ğ‘œğ‘š( A)=Ã\nğ´âˆˆAğ‘‘ğ‘œğ‘š(ğ´) . For a tuple ğ‘¡âˆˆğ· , and\nAâŠ†ğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·) , we useğ‘¡.Ato denote the attribute value ofAin ğ‘¡. A\nlogical query, represented by ğ‘(D) , applies transformations and\n\ncomputations onD. In this work, we focus on SPJA [61] queries.\nFrequency (count). Givenğ·,AâŠ†ğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·) , and a set of values\nvâˆˆğ‘‘ğ‘œğ‘š( A), the frequency (count) ofvin ğ·is the total number of\ntuplesğ‘¡âˆˆğ· withğ‘¡.A=v. In addition, the max frequency moments\n(MF) ofAis defined as mf(A,ğ·)=max vâˆˆğ‘‘ğ‘œğ‘š(A)|{ğ‘¡âˆˆğ·|ğ‘¡. A=v}|.\nHistograms. Givenğ·, andAâŠ†ğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·) , the (equal-width) his-\ntogramh(A,ğ·)=(ğ‘ 1,ğ‘2,...,ğ‘ğ‘š)is a list of counts for the attribute\nvalues inA. Specifically,hpartitions ğ‘‘ğ‘œğ‘š( A)intoğ‘šâ€œequal-sizedâ€\ndomain intervals(ğµ1,...,ğµğ‘š), and a count ğ‘ğ‘–âˆˆhis the number of\ntuplesğ‘¡âˆˆğ·withğ‘¡.Ain the interval ofğµ ğ‘–.\nQuery planning.Modern databases parse queries into physical\nplans [ 61] that can be executed by the underlying query engine.\nThese plans specify the operations like scans, joins, and sorts, and\nthe order in which theyâ€™re performed. The same query can have\nmultiple equivalent execution plans, but their performance can\nvary greatly depending on resource usage and data access patterns.\nQuery planning [ 12], done before runtime, involves selecting cost-\nefficient plans from these options. A key part of this process is\naccurately estimating intermediate result sizes, known as cardi-\nnality estimation (CE) [ 31], which relies heavily on table statistics.\nTwo crucial statistics in modern cardinality estimation methods are:\n(i)histograms,which are vital for estimating selectivities in filters,\nand (ii)max frequency,which is crucial for estimating join sizes.\nMulti-party secure computation (MPC).MPC [ 10,26,46,76]\nis a cryptographic technique that allows multiple parties ğ‘ƒ1,ğ‘ƒ2,...\nto jointly compute a function ğ‘“(ğ‘¥ 1,ğ‘¥2,...)over their own private\ninputğ‘¥ğ‘–. MPC ensures no unauthorized information is revealed to\nany party, except the desired output of ğ‘“, emulating a computation\nas if performed by a trusted third party. Traditional MPC required\nall parties to actively participate in intensive computations. How-\never, recent server-aided MPC [ 37,48,59] schemes allow offloading\ncomputations to powerful servers, without sacrificing security. In\nthis model, parties secretly share their inputs with servers, which\njointly evaluate an MPC protocol to reconstruct the secrets and\ncompute the function.\nDifferential privacy [ 23].DP ensures that modifying a single\ninput tuple to a mechanism produces only a negligible change in its\noutput. To elaborate, consider ğ·andğ·â€²as two relations differing\nby just one tuple, then DP defines the following.\nDefinition 2.1 ((ğœ–,ğ›¿) -DP). Given ğœ–>0, andğ›¿âˆˆ( 0,1). A random-\nized mechanismMis said to be(ğœ–,ğ›¿) -DP if for all ğ·âˆ¼ğ·â€²pairs, and\nany possible outputğ‘œâŠ‚ğ‘…ğ‘ğ‘›ğ‘”ğ‘’(M), the following holds:\nPr[M(ğ·)âˆˆğ‘œ]â‰¤ğ‘’ğœ–Pr[M(ğ·â€²)âˆˆğ‘œ]+ğ›¿\nSecret sharing and secure array.SPECIALuses the2-out-of-2\nboolean secret share [ 4] over ring Z232for securely outsourcing\nownersâ€™ data and storing query execution results. Specifically, each\ndata,ğ‘¥, is divided into two shares: ğ‘¥1,ğ‘¥2that are uniformly dis-\ntributed over the ring Z232such thatğ‘¥=ğ‘¥ 1âŠ•ğ‘¥2. Each server ğ‘†ğ‘–\nreceives one secret shares, ğ‘ ğ‘–, whereğ‘–âˆˆ{ 0,1}. By retrieving shares\nfrom any two servers, an authorized party can successfully recon-\nstruct the value of ğ‘¥. However, a single server alone learns nothing\naboutğ‘¥. For clarity and to abstract out the lower-level details, we\nleverage a logically unified data structure, namely the secure ar-\nray [ 8,71], denoted asâŸ¨xâŸ©=(âŸ¨ğ‘¥1âŸ©,âŸ¨ğ‘¥ 2âŸ©,...), which is a collection\nof secret-shared relational tuples.Oblivious (relational) operators.Oblivious operators are data-\nindependent MPC protocols that implement the same functional-\nities as their plaintext database counterparts (e.g., filter and join).\nData-independent execution requires that the control flow and\nmemory access patterns of a function are indistinguishable given\ndifferent inputs of the same size, and typically requires costly com-\nputation. For example, a linear scan is required to fulfill oblivious\nfiltering [ 80], and join requires nested-loop over the two inputs [ 25].\nThe output sizes of such operators are usually padded with dummy\ntuples to the worst case: ğ‘rows for filters and ğ‘2for joins, given\nsizeğ‘inputs. The dummy tuples will not affect the query result\nbut can significantly impact the performance [25, 80]. To enhance\nefficiency while maintaining strong privacy, DPSCAs introduce a\nnew type of oblivious operators [ 8,55,56,71]. These operators\ntypically involve two steps:ComputeandCompact. TheCompute\nstep is fully oblivious, while theCompactresizes the output, often\nby obliviously sorting valid tuples to the front and trimming the\noutput to a noisy DP size (the true size plus DP noise). While this\napproach can significantly reduce the computation cost and query\nsizes, it may lead to lossy query processing if the DP size is smaller\nthan the true size (e.g., negative DP noise), asvalid tuples could\nbe excluded during the compaction[ 70,71,77]. We emphasize that\nwhen DP sizes exceed true sizes, there is no accuracy loss as it only\nincludes extra dummy data that do not impact accuracy [25, 80].\nPrivate indexes.In conventional databases, indexes are powerful\ndata structures that map attribute values to positions in a sorted ar-\nray, allowing a predicate selection to quickly access the desired data\nvia index lookup without the need for full table scan. However, tra-\nditional indexes are unsuitable in SCAs due to their data-dependent\nnature, which can easily lead to privacy breaches. To address this,\nrecent research has proposed DP indexes [ 57], where the mapping\nof attribute values to their positions is intentionally distorted with\nDP noise. To process queries, the system first pre-fetch a small\nset of data using DP indexes, followed by oblivious selection. This\neffectively avoids full table oblivious scan and sorting-based re-\nsult compaction. However, the uncertainty inherent in DP indexes\ncan lead to the loss of valid tuples. For example, in the DP index\nof [57], a true index range of positions [10,20]might be distorted\ninto positions[12,17], causing data at position10 ,11,18,19and\n20to be missed. Nevertheless,if DP indexes overestimate the range,\nsubsequent oblivious selection can losslessly identify all valid tuples.\n3 SYSTEM AND PRIVACY MODEL\nIn general,SPECIALfollows a standard server-aided MPC [ 37]\nmodel, involving (i) a set of mutually distrustful data owners ğ‘ƒ1,...,ğ‘ƒğ‘›,\n(ii) two non-colluding serversğ‘† 0andğ‘† 1, and (iii) a trusted analyst.\nWe assume anadmissible adversary[ 48]A, capable of corrupting\nğ‘›âˆ’1out ofğ‘›clients and at most one of the two servers. An in-\nstance of such adversary can be a malicious server that creates Sybil\nowners to form a malicious collation, attempting to steal sensitive\ninformation from an honest owner. Additionally, Ais considered\nhonest-but-curious, meaning it follows the protocol without de-\nviation but may try to infer information from observed protocol\ntranscripts, such as randomness, memory access patterns, and com-\nmunication messages. The combination of these information is\nreferred to as the view of A. We also assumeAis computationally\n\nbounded as a probabilistic polynomial time (p.p.t.) adversary, which\nis a standard requirement in MPC protocols to ensure that adver-\nsaries cannot break cryptographic primitives. This threat model\nis consistent with prior SCA designs [ 7,8,48,70,71]. Given this\nsetup, we designSPECIALto satisfy the following:\nDefinition 3.1 (MPC protocol with DP leakage). Given a set of\nparties (owners) ğ‘ƒğ‘–with private data ğ·ğ‘–and a secure query proto-\ncolÎ that applies overD={ğ· 1,ğ·2,Â·Â·Â·} . We define a randomized\nmechanism Lkg(D)={Lkg(ğ· 1),Lkg(ğ· 2),Â·Â·Â·} as the leakage pro-\nfile, consisting of the control flow and access patterns of running Î \noverD. The protocol Î is said to be secure with DP leakage if, for\nthe subset of uncorrupted parties with dataD âŠ†D , leakage profile\nLkg(D)âŠ†Lkg(D), and any p.p.t. adversaryA:\nâ€¢Lkg(D)satisfies(ğœ–,ğ›¿)-DP (definition 2.1).\nâ€¢There exists a p.p.t. simulator Swith only access to public param-\netersppandLkg(D)that satisfies:\nPrh\nA\u0010\nVIEWÎ (D,pp)=1\u0011i\nâ‰¤Prh\nA\u0010\nVIEWS(Lkg(D),pp)\u0011\n=1i\n+negl(ğœ…)(1)\nwhere VIEWÎ isAâ€™s view in Î â€™s execution and VIEWSis a simulated\nview produced bySusing Lkg;ppdenotes all public parameters, and\nnegl(ğœ…)is a negligible function related to a security parameterğœ….\nSimply put, Definition 3.1 requires that the knowledge any p.p.t.\nadversary adversary can gain about each individual tuple of an\nhonest owner, by observing the protocol execution, is bounded to\nwhat can be inferred from the outputs of the (ğœ–,ğ›¿) -DP mechanism\nLkg. We stress that this notion focuses on DP at the event (tuple)\nlevel without loss of generality. Due to the group-privacy properties\nof DP [ 22,40,66,75], event-level DP can be extended to user-level\nDP. For instance, in a logical database Dwhere any single user\nowns at most ğ‘™tuples, if a protocol satisfies (ğœ–,ğ›¿) event-level DP,\nit also satisfies(ğ‘™ğœ–,ğ‘™ğ‘’(ğ‘™âˆ’1)ğœ–ğ›¿)user-level DP. Moreover, we say that\nSPECIALcan be relaxed to employ a weaker corruption model,\nsuch as requiring a supermajority of owners and servers to remain\nuncorrupted, to enhance efficiency [ 44,64]. This adjustment does\nnot change the privacy guarantee outlined in Definition 3.1, but it\ndoes affect the security assumptions. Under the relaxed corruption\nmodel, Definition 3.1 is only satisfied when at least two-thirds of\nthe parties remain uncorrupted. Due to space concerns, we defer\nthe complete privacy proof ofSPECIALto our full version [18].\n4SPECIALSYNOPSES\nWe now discuss the details of private synopses used inSPECIAL,\nwhile in later sections we will show how they accelerate query\nprocessing (Â§ 5) and aid in query planning (Â§ 6).\nChallenges.We reiterate the main challenges in generating private\nsynopses for a relation include: (C-1) selecting a set of attribute\ncombinations that enable functional and efficient query processing;\n(C-2) ensuring that the subsequent query processing based on the\nprivate synopses is lossless.\nKey ideas.Given a SPJA query, join operations typically need\nprioritized acceleration, as they are more resource-intensive than\nother operations. A ğ‘˜-way join can have ğ‘‚(ğ‘›ğ‘˜)complexity without\noptimizations [ 7,8,25,71,80]. Additionally, synopses for frequentlyqueried filter attributes play an important role in efficient query\nprocessing, as they enable fast indexing (Â§ 5.2) and effective filtering\nof unnecessary data before heavy joins. As such, our first key idea\nis to focus on histograms-based synopses that cover frequently\nqueried join and filter attributes. To minimize noise, we focus on\nlow-dimensional synopses: only 1D or 2D histograms.\nTo address the second challenge, our approach combines two\nstrategies. First, to support accurate indexing and filtering, we use\none-sided DP noise to generate DP histograms that consistently\noverestimate or underestimate attribute distributions. We will show\nlater that such special histograms allow lossless filtering and index-\ning that reliably overestimate true filter sizes and indexing ranges\n(Â§ 5.2). Second, for lossless join output compaction, we incorpo-\nrate noisy max frequency moments (MF) into the synopses. MF\nallows us to build on advanced join upper bound techniques [ 34]\nto privately estimate join sizes without data loss (Â§ 5.2).\n4.1 Synopses generation\nWe now elaborate on the details of synopsis generation, which\nmainly contains two phases: (i) Attributes selection, where theSPE-\nCIALservers select appropriate attributes for the generation, which\nare then distributed to owners; (ii) Local synopses release, where\nthe owners create corresponding synopses using a DP mechanism\nand upload them toSPECIALservers.\nAttributes selection (servers).The first step is to identify a set of\nattributes for deriving synopses. In general, we consider the exis-\ntence of a representative workload, ğ‘„R[42], which can be sourced\nfrom a warm-up run or annotated by the administrator. Note that\nthe representative workload does not involve any private data and\nthus is leakage-free. The servers first identify representative at-\ntribute pairs, pair={pairğ‘˜}ğ‘˜â‰¥1, for each private relation ğ·âˆˆD\nviağ‘„R. The designated pairs include: (i) 2-way attribute pairs, which\ncorrespond to frequently queriedfilter-join keycombinations; (ii)\nfrequently queried individual attributes not covered by these pairs.\nBy default, each pairğ‘˜=(ğ´ ft,ğ´j)contains two valid attributes (case\ni), but eitherğ´ ftorğ´ jmay be empty (case ii).\nSynopses release (owners).Next, servers pushes the identified\npairs to owners, and subsequently, the owners independently dis-\npatche private synopses and return them to servers. We now focus\non the DP synopses generation mechanism run by each owner,\nAlgorithm 1 illustrates the workflow.\nIn general, we expect owners to set a desired privacy budget\nfor their data (using parameters ğœ–andğ›¿). Algorithm 1 produces\nsynopses formalized as :\nDefinition 4.1 (SPECIALsynopses). Given ğ‘„R, we consider for\neach relation ğ·, its corresponding synopsis synop is the collection of\n{(pairğ‘˜,H(pairğ‘˜,ğ·),MFğ‘˜)}ğ‘˜â‰¥1, such that\nâ€¢pairğ‘˜=(ğ´ ft,ğ´j)âˆˆğ‘„ Ris a frequently queried attribute pair.\nâ€¢H(pairğ‘˜,ğ·)={ h+,hâˆ’}is the DP bounding histogram for pairğ‘˜,\nwhereh+(resp.hâˆ’) is a DP histogram that overestimate (resp.\nunderestimate) the true histogram ofpairğ‘˜.\nâ€¢MFğ‘˜represents a collection of privately overestimated join key MFs\ncategorized bypairğ‘˜.ğ´ft.\nWe now present a detailed explanation of generating these synop-\nsis structures, starting with the private bounding histograms (Alg 1,\n\nAlgorithm 1DP synopsis genM synop (in the view ofğ‘ƒ)\nInput:pair={pairğ‘˜}ğ‘˜â‰¥1from servers; private datağ·.\n1:ğ‘ƒ self-determines privacy parameters ğœ–,ğ›¿, and init synopâ†âˆ…\n2:foreachpairğ‘˜do\n3:h(pairğ‘˜,ğ·)â†HistGen(pairğ‘˜,ğ·)\nDP histograms:\n4:h+(pairğ‘˜,ğ·)â†h+Lap+(ğœ–,ğ›¿,h.shape)\n5:hâˆ’(pairğ‘˜,ğ·)â†h+Lapâˆ’(ğœ–,ğ›¿,h.shape)\nâŠ²adding independently sampled noise to every bin ofh+,hâˆ’\nDP max frequencies:\n6:ifğ´ jâˆˆpairğ‘˜=âˆ…orğ´ jis unique valuedthenMF ğ‘˜=âˆ…\n7:else ifğ´ ftâˆˆpairğ‘˜â‰ âˆ…then\nâŠ²assuminghpartitionsğ‘‘ğ‘œğ‘š(ğ´ ft)into{ğµ 1,...,ğµğ‘š}\n8:ğ·â„“â†ğœğ´ftâˆˆğµâ„“(ğ·)forâ„“=1,2,...,ğ‘š\n9:compute noisy MF table,MF ğ‘˜={cmf(ğ´ j,ğ·â„“)}1â‰¤â„“â‰¤ğ‘š\n10:elseMF ğ‘˜=cmf(ğ´ j,ğ·)\n11:synopâ†synopâˆª(pairğ‘˜,{h+,hâˆ’},MFğ‘˜)\n12:releasesynop,ğœ–,ğ›¿to servers\nlines 2:5). Specifically, for each pairğ‘˜, each owner first constructs\na histogramh(pairğ‘˜,ğ·). By default, we assume there exists global\nparameters (e.g., bin sizes) for each attribute, that ensure consistent\ndata partitioning among all owners. Next, the owner derives two\nnoisy histograms,h+(pairğ‘˜,ğ·)andhâˆ’(pairğ‘˜,ğ·), by adding inde-\npendently sampled one-sided Laplace noise (Definition 4.2) to every\nbin ofh(pairğ‘˜,ğ·). This guarantees that h+always overestimates\nthe true histogram, whilehâˆ’consistently underestimates it.\nDefinition 4.2 (One-sided Laplace variable). Lap+(ğœ–,ğ›¿)=max( 0,ğ‘§)\n(resp. Lapâˆ’(ğœ–,ğ›¿)=min( 0,ğ‘§)) is a one-sided Laplace random variable\nin the range of[0,âˆ) (resp.(âˆ’âˆ, 0]) ifğ‘§is drawn from a distribution\nwith the following density function\nPr[ğ‘§=ğ‘¥]=ğ‘’ğœ–âˆ’1\nğ‘’ğœ–+1ğ‘’âˆ’ğœ–|ğ‘¥âˆ’ğœ‡|(2)\nwhereğœ‡=1âˆ’1\nğœ–ln(ğ›¿(ğ‘’ğœ–+1))(resp.ğœ‡=1\nğœ–ln(ğ›¿(ğ‘’ğœ–+1))âˆ’1).\nNext, we detail the generation of (noisy) join key MFs (Alg 1\nlines 6:10). We assume that both ğ´ftandğ´jare non-empty and that\nh(pairğ‘˜,ğ·)partitionsğ‘‘ğ‘œğ‘š(ğ´ ft)into bins{ğµ1,...,ğµğ‘š}. Each owner\nthen generates a table of noisy MFs, {cmf(ğ´ j,ğ·â„“)}1â‰¤â„“â‰¤ğ‘š , where each\nentrycmf(ğ´ j,ğ·â„“)represents an independently generated MF statistic\nfor the join key attribute ğ´j, calculated over a specific subset of\ndata filtered by the attributeğ´ ft, such that\ncmf(ğ´ j,ğ·â„“)â†dmaxğœ–\u0010\nGcount(ğ´ j)\u0000ğœğ´ftâˆˆğµâ„“(ğ·)\u0001\u0011\n(3)\nhereGcount(ğ´ j)is a group-by-count operation over ğ´j, anddmaxğœ–is\nareport noisy maxmechanism [ 23]. It first adds i.i.d. noise from\nthe exponential distribution Exp(2\nğœ–)to each grouped count, then\noutputs the largest noisy count. We stress that Msynop will not\ngenerate noisy MFs for non-join key attributes, and when ğ´ftis\nempty, a global MF will be generated instead of MF tables (Alg 1:10).\nMoreover, sinceSPECIALenables owners to label attributes as\nunique-valued, if ğ´jis known to be unique-valued, then cmf(ğ´ j,Â·)\nis always 1. Nevertheless, as exponential noises are non-negative,\nthuscmfâ‰¥mfholds for all cases.Theorem 4.3.Given |pair|=ğ‘ ,ğœ–,ğ›¿> 0, the synopsis generation\n(Algorithm 1) is(Ë†ğœ–,Ë†ğ›¿)-DP where Ë†ğœ–â‰¤6ğœ–âˆšï¸\nğ‘ln(1/ğ›¿) , and Ë†ğ›¿=(ğ‘+ 1)ğ›¿\nFor space concern, we move complete proofs to the full ver-\nsion [ 18]. In a sketch, adding Lap+(orLapâˆ’) to a single bin is\n(ğœ–,ğ›¿) -DP. By parallel and sequential composition, generatingHis\n(2ğœ–,2ğ›¿)-DP. Moreover, each noisy max is (ğœ–,0)-DP, and by parallel\ncomposition, the generation of the entire MF table is also (ğœ–,0)-DP.\nIn this way, we know that the generation of each (pairğ‘˜,H,MFğ‘˜)is\nat most(3ğœ–,2ğ›¿)-DP. Given there are in total ğ‘such pairs, and thus\nthe total privacy loss is subject to ğ‘-fold advanced composition [ 23].\nSynopsis transformations.We say that one can perform trans-\nformations on released synopses without incurring extra privacy\nloss, per the post-processing theorem of DP [ 23]. Now, we out-\nline the key synopsis transformation relevant toSPECIALâ€™s design.\nFirst, given any (2d) bounding histogramH (pair,ğ·) with both\nğ´ft,ğ´jâˆˆpair are non-empty, one can derive the (1d) bounding\nhistograms, i.e.H(ğ´j,ğ·)andH(ğ´ft,ğ·), for any single attribute ğ´ft\norğ´jby marginal sumsh+,hâˆ’âˆˆH(pair,ğ·) overğ´jorğ´ft, respec-\ntively. This enables the creation of statistics on individual attributes,\neven when ğ´ftandğ´jare not included as a standalone synopsis\nattribute. Moreover, itâ€™s possible to derive relevant join key statis-\ntics following a selection on the base relation. For example, given\nğ´ft,ğ´jâˆˆpairâ‰ âˆ… , and letğ·â€²â†ğœğ´ftâˆˆğ‘£ğ‘ğ‘™ğ‘ (ğ·), one can obtain the\n(1d) bounding histogramH (ğ´j,ğ·â€²)by conducting a selective mar-\nginal sum ofh+,hâˆ’âˆˆH(pair,ğ·) over bins of ğ´ftthat intersect with\nğ‘£ğ‘ğ‘™ğ‘ . Beyond bounding histograms, join key MFs over pre-filtered\ndata can also be computed by\ncmf(ğ´ j,ğ·â€²)=min\u0010Ã\nğµâ„“âˆ©ğ‘£ğ‘ğ‘™ğ‘ â‰ âˆ…cmf(ğ´ j,ğ·â„“),cmf(ğ´ j,ğ·)\u0011\n(4)\nNote that cmf(ğ´ j,ğ·)exists ifğ´jis also included as a standalone\nsynopsis attribute; otherwise, Eq 4 yields only the first term.\n5SPECIALPRIMITIVES\nWe next introduce the secure primitives inSPECIAL. One major\nchallenge in designing these primitives is the knowledge gap on\nhow private synopses can accelerate oblivious query processing, i.e.,\nC-3. To address this, we explore various usage of synopses, includ-\ning creating private indexes (SPEidxÂ§ 5.2) and designing compacted\noblivious operations (SPEopÂ§ 5.3). Given that joins are the most\nresource-intensive operations, we optimize join algorithms by com-\nbining private indexing and compaction techniques to develop a\nnovel, parallel-friendly oblivious join (Â§ 5.3). Another challenge\nis ensuring lossless processing, which we tackle by integrating\nmechanisms that pessimistically estimate selection cardinalities,\nindexing ranges, and join sizes using synopses (Â§ 4) and advanced\nupper bound techniques [ 34]. For simplicity, we assume all input\nrelations are of sizeğ‘›and all 1D histograms containğ‘šbins.\n5.1 Basic Operations\nSPECIALsupports conventional fully-oblivious operators [ 7], which\nlogically the same as non-private ones but with data-independent\nexecution and worst-case padding for results. We briefly introduce\nthese operations: (i)Default data access ( SeqACC ).By default,\nquery execution begins with loading all data into a secure array via\nsequential scan. Each loaded tuple gets a secret bit ret(initially â€˜0â€™),\n\nmarking its validity; (ii) SELECT .This secure filter ğœğ‘(ğ‘…)performs\na linear scan over the secure array âŸ¨ğ‘…âŸ©, updating the retbit to â€˜1â€™\nfor tuples satisfying predicate ğ‘and â€˜0â€™ for others; (iii) PROJECT .\nRemoves irrelevant attributes from relation âŸ¨ğ‘…âŸ©, but retains the ret\nbit; (iv) JOIN.Implements a secure ğœƒ-joinğ‘…0Zğœƒğ‘…1by computing\nthe cartesian product âŸ¨ğ‘…0Ã—ğ‘… 1âŸ©and marking joined tuples with\nSELECT . The output is padded to the worst-case maximum size; (v)\nCOUNT ,SUM,MIN/MAX .These aggregation operators scan the secure\narray and update a secret-shared aggregation value for each tuple;\n(vi)ORDER-BY ,DISTINCT ,GROUP-BY(AGG) .Built on the oblivious\nsort primitive [ 6].ORDER-BY sorts the array by a given attribute.\nDISTINCT sorts and then identifies unique tuples, marking only the\nlast in a sequence of identical tuples with ret=â€˜1â€™ .GROUP-BY(AGG)\nfirst uses DISTINCT to find unique tuples. For each distinct tuple\n(retset to â€˜1â€™), it appends an aggregation value derived from the\ntuple and a dummy attribute (e.g., â€˜-1â€™) for non-distinct tuples.\n5.2SPECIALIndexSPEidx\nExisting index techniques in SCA have several drawbacks: loss\nof qualified data [ 57], reliance on intricate data structures with\nlarge overhead [ 13,56,77], and restricted query support [ 13,77].\nFurthermore, all these techniques only support indexing the base\nrelations.SPEidxoffers a breakthrough by enabling the creation\nof lossless indexes directly on outsourced data and the query of\nintermediate results, eliminating the need for extra structures or\nstoring dummy data.\nIn general,SPEidxbuilds upon the typical indexing model that\nutilizes cumulative frequencies (CF) [ 43]. Specifically, given ğ·sorted\nbyğ´âˆˆğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ·) , all records ğ‘¡âˆˆğ· whereğ‘¡.ğ´=ğ‘¥ can be indexed\nby the interval[ğ‘”(ğ‘¥âˆ’ 1),ğ‘”(ğ‘¥)] , whereğ‘”(ğ‘¥)=|{ğ‘¡|ğ‘¡.ğ´â‰¤ğ‘¥}| is\nthe CF function. For better illustration, we show an example index\nlookup in Figure 2: to get all records with an attribute value of\n24, one may compute [ğ‘”(23),ğ‘”(24)]=[ 217,248]and access the\nrelevant data from the subset ğ·[217 : 248]. To make this indexing\nmethod private and lossless, the key idea ofSPEidxis to derive\ntwo noisy CF curves from synopses (i.e., bounding histograms).\nOne curve,ğ‘”+(ğ‘¥), consistently overestimates ğ‘”(ğ‘¥), while the other,\nğ‘”âˆ’(ğ‘¥), consistently underestimates it. Then for any attribute value\nğ‘¥, we can now derive a private interval [ğ‘”âˆ’(ğ‘¥âˆ’ 1),ğ‘”+(ğ‘¥)] that\nlosslessly indexes all the desired records. As illustrated in Figure 2,\ntheSPECIALindex might estimate the index range for attribute\nvalue 24 as[ğ‘”âˆ’(23),ğ‘”+(24)]=[198,267].\nFigure 2: True (left) vs.SPECIAL(right) index forğ‘¥=24\nIn what follows, we provide the formal explanations on how\nSPEidxderives indexes from DP synopses. Specifically,SPEidx\nfirst determines the bounding histogramsH (ğ´,ğ·) , which may be\neither transformed from an available 2D histogramH (pair,ğ·) withğ´âˆˆpair , or sourced directly ifH (ğ´,ğ·) is already included in the\nsynopses. It then constructs the noisy mapping as follows:\nDefinition 5.1 (SPECIALindex). Given ğ·sorted byğ´, the bounding\nhistogramH(ğ´,ğ·)={ h+,hâˆ’}, and assumeh+=(ğ‘+\n1,...,ğ‘+\nğ‘š),hâˆ’=\n(ğ‘âˆ’\n1,...,ğ‘âˆ’\nğ‘š)partitionsğ‘‘ğ‘œğ‘š(ğ´) into{ğµ1,...,ğµğ‘š}. We say SPEidx(ğ´,ğ·)=\n{idxğ‘–=[loğ‘–,hiğ‘–]}1â‰¤ğ‘–â‰¤ğ‘š is theSPECIALindex ofğ·overğ´with:\nâ€¢ âˆ€ğ‘–â‰¥1,hi ğ‘–=min(|ğ·|,Ãğ‘–\nğ‘˜=1ğ‘+\nğ‘˜).\nâ€¢lo 1=0, andâˆ€ğ‘–â‰¥2,lo ğ‘–=Ãğ‘–âˆ’1\nğ‘˜=1max(0,ğ‘âˆ’\nğ‘˜).\nBy this construction, all tuples ğ‘¡âˆˆğ· such thatğ‘¡.ğ´âˆˆğµğ‘–will\nbe organized into the subset ğ·[idxğ‘–] âŠ†ğ· . This subset can be\nquickly accessed if ğ·is already sorted, without the need for special\ndata structures or inclusion of dummy tuples. Depending on how\nbounding histograms are constructed, SPEidx(ğ´,ğ·) can support\nindexing lookups with varying granularity. This can range from\nindexing individual attribute values (where each ğµğ‘–corresponds\nto a single domain value) to indexing a range of of values. The\nbounding histogramâ€™s pessimistic estimation ensures that all tuples\nwhereğ‘¡.ğ´âˆˆğµğ‘–are accurately contained within ğ·[idxğ‘–], thereby\nachieving lossless indexing. In contrast to existing methods that are\nlimited to indexing base relations [ 13,57,77],SPEidxextends its\ncapabilities to create private indexes on query intermediate results.\nFor instance, consider ğ·â€²â†ğœğ´âˆ—âˆˆğ‘£ğ‘ğ‘™ğ‘ (ğ·)where the attribute pair\n(ğ´âˆ—,ğ´)is included in synop . Here,SPEidxcan deriveH (ğ´,ğ·â€²)from\nH(ğ´âˆ—,ğ·)and subsequently build indexes on ğ·â€². Importantly, since\nindex creation is a post-processing procedure using available DP\nsynopses, it incurs no additional privacy loss.\nIndexed store and fast data access IdxAcc .SPEidxenables a\nnew storage layout for outsourced data, namely indexed datastore.\nSpecifically, by analyzing a representative workload ğ‘„R, one may\nidentify the â€œhottestâ€ attribute per base relation, sort them according\nto the â€œhottestâ€ attribute, and then build indexes over the sorted data.\nThis storage layout enables fast indexed access ( IdxAcc ) to retrieve\na compact subset of data from the outsourced relations, thereby\neliminating the need for a full table sequential scan ( SeqAcc ) and\ncan directly produce a compact input. We emphasize that theSPE-\nCIALdesign does not require replicating the outsourced datastore\nto accommodate multiple query types [ 13,77]. However, creating\ncompact replicas (e.g., column replicas [ 35] over frequently queried\nattributes) can be optionally employed to enhance query process-\ning speed. Moreover, the generation of all aforementioned objects\n(indexed store and column replicas) requires only three primitives:\nprojection, oblivious sorting, andSPEidx. In other words, this im-\nplies that one can selectively adjust these objects to align with\ndynamic query workloads, without incurring extra privacy loss.\n5.3SPECIALOperatorsSPEop\nWe introduceSPEop, a set of novel synopsis-assisted operators that\nmaintain full obliviousness, while enabling lossless compaction. To\nour knowledge,SPEopis the first primitive of its kind in any SCA.\nOblivious compaction: OPAC . is a fundamental operation critical\nto otherSPEopprimitives. Given input âŸ¨ğ‘…âŸ©,OPAC sorts it based\non the secret bit ret, moving tuples with ret= â€˜1â€™ to the front.\nThen, OPAC retains only the first ğ‘˜tuples from the sorted array. The\ncompaction islosslessif ğ‘˜is greater than or equal to the number of\ntuples withret=â€˜1â€™; otherwise, it islossy.\n\nSPECIALselections: (OP)SELECT ,(SP)SELECT ,(DC)SELECT .Let\nğ‘…to be a relation and ğ´âˆˆğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ‘…) , we now introduce three ad-\nvanced selections that implementsğœ ğ´âˆˆğ‘£ğ‘ğ‘™ğ‘ (ğ‘…).\n(OP)SELECT. is mainly implemented based on the oblivious com-\npaction ( OPAC ) operation. Specifically, the operation first conducts\na standard SELECT on the input secure array âŸ¨ğ‘…âŸ©to label selected\ntuples, followed by an OPAC to to eliminate a large portion of non-\nmatching tuples. To determine the compaction size ğ‘ğ‘ ,(OP)SELECT\nexamines the synopsis of ğ‘…and pessimistically estimates the car-\ndinality ofğœğ´âˆˆğ‘£ğ‘ğ‘™ğ‘ (ğ‘…)as shown in Algorithm 2. Since ğ‘ğ‘ never\nunderestimates the actual cardinality, and thus, the compaction is\nlossless with no missing tuples. Moreover, as OPAC is fully oblivi-\nous andğ‘ğ‘ is determined completely from post-processing over DP\nsynopsis, thus,(OP)SELECTcauses no privacy loss.\nAlgorithm 2CardEst(ğœ ğ´âˆˆğ‘£ğ‘ğ‘™ğ‘ (ğ‘…),synop)\n1:h=âˆ…,ğ‘=0\n2:ifH(ğ´,ğ‘…)âˆˆsynopthenhâ†h+âˆˆH(ğ´,ğ‘…)\n3:else ifâˆƒpairâˆˆsynop, s.t.ğ´âˆˆpairthen\n4:hâ†marginal sumh+âˆˆH(ğ´,ğ‘…)over(pair\\ğ´).\n5:else returnğ‘ğ‘ =|ğ‘…|\n6:returnğ‘ğ‘ =min(|ğ‘…|,Ãğ‘š\nğ‘–=1ğ‘ğ‘–âˆˆh:(ğµğ‘šâˆ©ğ‘£ğ‘ğ‘™ğ‘ â‰ âˆ…))\n(SP)SELECT. The running complexity of (OP)SELECT depends on\nOPAC , which is typically linearithmic (see Â§ 6.1 or [ 58]). However,\nwhen CardEst(ğœ ğ´âˆˆğ‘£ğ‘ğ‘™ğ‘ (ğ‘…),synop) is relatively small, oblivious se-\nlection can be achieved without necessarily incurring linearithmic\ncost. Specifically, we consider (SP)SELECT , which first creates an\nempty output array âŸ¨ğ‘…ğ‘œâŸ©with size equals to ğ‘ğ‘ before any compu-\ntations. Next, it evaluates two linear scans over âŸ¨ğ‘…âŸ©, where the first\nscan obliviously marks all selected tuples, and in the second scan,\nit privately writes all marked tuples into âŸ¨ğ‘…ğ‘œâŸ©. Specifically, in the\nsecond scan, (SP)SELECT internally maintains the lastactual write\nposition idxinâŸ¨ğ‘…ğ‘œâŸ©. Then for every newly accessed tuple âŸ¨ğ‘¡âŸ©in\nâŸ¨ğ‘…âŸ©, a write action occurs on all tuples in âŸ¨ğ‘…ğ‘œâŸ©. IfâŸ¨ğ‘¡âŸ©is selected,\nthen anactual writeis made that writes âŸ¨ğ‘¡âŸ©toâŸ¨ğ‘…ğ‘œ[idx+ 1]âŸ©and a\ndummy writeis made to elsewhere. If not, dummy writes are made\nthroughoutâŸ¨ğ‘…ğ‘œâŸ©. We say that, in the context of the secret-shared\nsecure arrayâŸ¨aâŸ©, a dummy write to âŸ¨a[ğ‘–]âŸ©is simply a re-sharing of\na[ğ‘–]through secure protocols without changing its value.\n(DC)SELECT. Finally, if the underlying data is already indexable\nonğ´, a direct pre-fetch can be applied to avoid full table scan\nand compaction. The operator simply looks up SPEidx(ğ´,ğ‘…) , and\naccessesğ‘…[ğ‘,ğ‘] , whereğ‘=minğ‘–(idxğ‘–.lo),ğ‘=max ğ‘–(idxğ‘–.hi), and\nidxğ‘–dentoes the index in SPEidx(ğ´,ğ‘…) with binğµğ‘–âˆ©[ğ‘,ğ‘]â‰ âˆ… . A\nstandardSELECTis then applied toğ‘…[ğ‘,ğ‘].\nSPECIALjoin: (MX)JOIN .We now introduce a novel MF-Index\nbased oblivious join operation. The advancements of (MX)JOIN\nstand out in three aspects. First, compared to the standard JOIN ,\n(MX)JOIN stands out for its ability to significantly compact the\noutput size, coupled with a highly parallelizable fast processing\nmode. Second, existing DP oblivious joins typically require spending\nprivacy budget [ 21] to learn join sensitivity [ 21] or necessitate\ntruncation on joined tuples [ 8,71].(MX)JOIN eliminates this need.\nMoreover, (MX)JOIN is unique as the first oblivious join that enableslossless output compaction without extra privacy loss. We illustrate\nthe construction details in Algorithm 3.\nAlgorithm 3(MX)JOIN(base and pre-filtered relations)\nInput: relations ğ‘…0,ğ‘…1; join attribute ğ´j; we consider synopses\n(histograms) ofğ´ jare partitioned into binsğµ 1,...ğµğ‘š.\n1:ifMXReady(ğ‘… 0,ğ‘…1)==TruethenBucketJoin(ğ‘… 0,ğ‘…1,ğ´j)\n2:else ifğ‘… 0,ğ‘…1are either base or pre-filtered relationthen\n3:forğ‘âˆˆ{0,1}do\n4:derive cmf(ğ´ j,ğ‘…ğ‘)fromsynop ğ‘(Â§ 4)\n5:build indexSPEidx(ğ´ j,ğ‘…ğ‘)={idxğ‘–}ğ‘–=1,..,ğ‘š (Â§ 5.2)\n6:ifâˆ€ğ‘, cmf(ğ´ j,ğ‘…ğ‘), andSPEidx(ğ´ j,ğ‘…ğ‘)â‰ nullthen\n7:oblivious sortğ‘… 0,ğ‘…1onğ´ j,BucketJoin(ğ‘… 0,ğ‘…1,ğ´j)\n8:else assertâ€œnot applicable for(MX)JOINâ€\nBucketJoin(ğ‘… 0,ğ‘…1,ğ´j):\n9:forğ‘–=1,2,...,ğ‘šdo\n10:ğ‘…(ğ‘–)\n0,1â†ğœğ´ğ‘—âˆˆğµğ‘–(ğ‘…0,1)using(DC)SELECT/SPEidx(ğ´ j,ğ‘…0,1)\n11:computeğ‘‚ ğ‘–â†(ğ‘…(ğ‘–)\n0Zğ´jğ‘…(ğ‘–)\n1)via standardJOIN\n12:ğ‘ğ‘ ğ‘–â†min\u0012\n|ğ‘…(ğ‘–)\n0|\ncmf(ğ´ j,ğ‘…0),|ğ‘…(ğ‘–)\n1|\ncmf(ğ´ j,ğ‘…1)\u0013\nÃ—cmf(ğ´ j,ğ‘…0)Â·cmf(ğ´ j,ğ‘…1)\n13:ğ‘… outâ†ğ‘… outâˆªOPAC(ğ‘‚ ğ‘–,ğ‘ğ‘ ğ‘–)\n14:returnğ‘… out\nIn general, (MX)JOIN can be applied to two types of data: the\nbase and pre-filtered relations where the join key attribute is in-\ncluded in synop . Specifically, (MX)JOIN starts with computing the\njoin key MFs (Alg 3:4) and constructing private indexes (Alg 3:5)\nfor both inputs. All these operations are conducted through â€œpri-\nvacy cost-freeâ€ transformations using available DP synopses. Once\nthese objects are obtained, the algorithm employs oblivious sort to\nrearrange both inputs (Alg 3:6,7), rendering them indexable with\ntuples logically distributed into independent buckets by join key\nvalues. Next, (MX)JOIN simply adopts standard JOIN to join tuples\nexclusively within the same buckets (Alg 3:10). Finally, (MX)JOIN\nperforms per-bucket output compaction, where it first determines\ntheMF join bound[ 34] for each bucket join and invokes OPAC to\ncompact the output according to the learned size (Alg 3:11,12). As\nbucket-wise operations are independent, the aforementioned steps\nlend themselves well to parallelized processing. As (MX)JOIN de-\nrives join compaction sizes completely from post-processing of DP\nsynopses, it thus incurs no extra privacy loss. Additionally, the\nnoisy MF bounds guarantee that compaction sizes are consistently\noverestimated, ensuring lossless compaction of join results.\n6SPECIALPLANNER\nCurrent DPSCA designs struggle with costly execution plans be-\ncause they cannot pre-estimate query intermediate sizes, and thus\nunable to identify effective execution plans with minimized cost.\nSPECIALovercomes this challenge by introducing a novel query\nplanner that uses synopses for size estimation, and thus enabling\nboth private and efficient SCA query planning.\nAt a high level, our planner is modeled after the Selinger-style op-\ntimizer [ 12]. It uses a bottom-up, dynamic programming approach\nto enumerate all equivalent plans for a given query, estimates their\ncosts (heavily influenced by intermediate sizes) using available\n\nTable 1: Asymptotic costs for secure operators\nOperator Input I/O (ğ¶ in) Eval. (ğ¶ eval) Output I/O (ğ¶ out)\nPROJECTğ‘‚(ğ‘›)N/Ağ‘‚(ğ‘›)\nAgg.ğ‘‚(ğ‘›)ğ‘‚(ğ‘›)ğ‘‚(1)\nGroup & Orderğ‘‚(ğ‘›)ğ‘‚(ğ‘›log2ğ‘›)ğ‘‚(ğ‘›)\nSELECTğ‘‚(ğ‘›)ğ‘‚(ğ‘›)ğ‘‚(ğ‘›)\n(OP)SELECTğ‘‚(ğ‘›)ğ‘‚(ğ‘›logğ‘›)hist_bound\n(SP)SELECTğ‘‚(ğ‘›)ğ‘‚(ğ‘›)ğ‘‚(1)\n(DC)SELECTidx_boundN/A N/A\nJOINğ‘‚(ğ‘›)ğ‘‚(ğ‘›2)ğ‘‚(ğ‘›2)\n(MX)JOINğ‘‚(ğ‘›)ğ‘‚(ğ‘›2)âˆ—mf_boundâˆ—Assuming\nthe max size of the indexed buckets is bounded byğ‘‚(ğ‘›\nlogğ‘›).\nsynopses, and selects the plan with minimal cost. The introduc-\ntion ofSPECIALprimitives significantly impacts cost modeling for\noblivious operations, rendering existing models [ 8,44] inadequate.\nFurthermore, the design-space challenge of query planning per-\nsists, and the extensive equivalent plan search space necessitates\nstrategies to simplify the search process. To address these, we first\nsystematically analyze the complexities ofSPECIALprimitives and\ndevelop a new cost model (Â§ 6.1). We then design protocol-specific\nheuristics (Â§ 6.2) tailored to our planner to narrow the search space.\n6.1 Cost Model\nWe adopt the standard SCA cost framework [ 8] to developSPE-\nCIALâ€™s cost model, viewing the cost of a secure execution plan as the\nsum of each operatorâ€™s I/O and secure evaluation costs. Specifically,\ngiven a plan with â„“operators, op1,...,opâ„“, and letI ={ğ¼ 1,...,ğ¼â„“},\nO={ğ‘‚ 1,...,ğ‘‚â„“}, to be the input and output sizes of each operators.\nThe plan cost is:\nCost=Ãâ„“\nğ‘–=1ğ¶opğ‘–\nin(ğ¼ğ‘–)+ğ¶opğ‘–\neval(ğ¼ğ‘–)+ğ¶opğ‘–\nout(ğ‘‚ğ‘–)(5)\nHere,ğ¶inrepresents the data access cost (input I/O), primarily cap-\nturing the expenses when moving data from persistent storage\nto an in-memory secure array. ğ¶outdenotes the output I/O cost,\nmodeling the expenses when writing operator results into output\narrays.ğ¶evalaccounts for the secure computing cost for evaluating\nan operator, typically constituting the dominant cost. Note that, in\npractice, the exact formulas for ğ¶in,ğ¶out, andğ¶evalcan vary depend-\ning on the specific secure protocol employed (garbled circuits [ 76],\nsecret sharing [ 46], etc.) as well as the particular hardware configu-\nrations in use. Nonetheless, the understanding of the asymptotic\ncosts is adequate for comprehending the principles of SCA query\nplanning and optimization strategies [ 8,44]. In what follows, we\nprovide detailed analysis on the asymptotic costs for eachSPECIAL\noperator. Similarly, we assume that all input data sizes mentioned\nhenceforth in this section are of size ğ‘›, and all 1D histograms have\nğ‘šbins. Table 1 summarizes the operator costs.\nOblivious sorting and compaction.While oblivious sorting al-\ngorithms with optimal ğ‘‚(ğ‘›logğ‘›) complexity exist, they often ne-\ncessitate either impractically large constants [ 3,27] or client-side\nmemory [ 5], both do not fit with SCA scenario. Consequently, we\nwill consider the well-established bitonic sorting based implemen-\ntation for oblivious sort, which come with ğ‘‚(ğ‘›log2ğ‘›)complexity.\nNonetheless, efficient OPAC implementations with ğ‘‚(ğ‘›logğ‘›) com-\nplexity remain achievable [58].\nProjection, grouping and aggregation.The PROJECT accesses\nprivate relations and discards unnecessary columns independentlyon each server, which is naturally oblivious. Thus, I/O costs domi-\nnate this operation, with both input and output costs bounded by\nğ‘‚(ğ‘›) . The costs of ORDER-BY ,DISTINCT , and GROUP-BY are domi-\nnated by oblivious sorting, resulting in a complexity of ğ‘‚(ğ‘›log2ğ‘›).\nAdditionally, as these operators do not reduce output sizes, both\nğ¶inandğ¶outare bounded by ğ‘‚(ğ‘›) . Finally, the cost of aggregations,\ni.e.COUNT ,SUM, and MIN/MAX subjects to a oblivious linear scan,\ntypically outputting a single secret-shared value. Hence, its ğ¶evalis\nbounded byğ‘‚(ğ‘›), withğ¶ inatğ‘‚(ğ‘›)andğ¶ outatğ‘‚(1).\nSelections.The primary cost of SELECT stems from an oblivious lin-\near scan, making ğ¶evalwithinğ‘‚(ğ‘›) . Since SELECT does not shrink\nthe output size, both ğ¶inandğ¶outare withinğ‘‚(ğ‘›) .(OP)SELECT\nrequires an oblivious compaction ( OPAC ) before writing outputs,\nwhere OPAC usually yields an ğ‘‚(ğ‘›logğ‘›) complexity [ 58]. Con-\nsequently, its ğ¶evalis bounded by ğ‘‚(ğ‘›logğ‘›) with input I/O cost\nsame as SELECT . However, as (OP)SELECT compacts output size,\nğ¶outis reduced to hist_bound=ğ‘‚\u0000Ã\nğµğ‘–âˆ©ğ‘£ğ‘ğ‘™ğ‘ â‰ âˆ…|ğµğ‘–|\u0001, whereğµğ‘–âˆ©\nğ‘£ğ‘ğ‘™ğ‘ â‰ âˆ… are bins in the synopsis histogram intersecting with se-\nlection conditions. IfÃ\nğµğ‘–âˆ©ğ‘£ğ‘ğ‘™ğ‘ â‰ âˆ…|ğµğ‘–|âˆ¼ğ‘‚( 1),(SP)SELECT becomes\npreferable, with its running cost dominated by a two-phase lin-\near scan, and thus ğ¶evalis nowğ‘‚(ğ‘›) , and the output cost is ğ‘‚(1).\n(DC)SELECT is the most efficient selection, though it requires in-\ndexable input data. All costs are directly related to the size of the\nindexed data, so ğ¶in,ğ¶evalsandğ¶outare all bounded by idx_bound=\nğ‘‚(maxğ‘–(idxğ‘–.hi)âˆ’min ğ‘–(idxğ‘–.lo)). Here, idxğ‘–are indexed regions\nthat intersect with selection conditions.\nJoins.Both JOIN and(MX)JOIN haveğ‘‚(ğ‘›) data access costs, but\ndiffer inğ¶evalandğ¶out.JOIN , conducting a Cartesian product for two\ninput tables, has ğ¶evalandğ¶outboth bounded by ğ‘‚(ğ‘›2). Compared to\nJOIN , in the worst-case scenario where the join keys follow a highly\nbiased distribution, i.e. max bucket size reaches ğ‘‚(ğ‘›) ,(MX)JOIN â€™s\nasymptotic cost is at most ğ‘‚(ğ‘›2logğ‘›) . However, when join keys are\ndistributed more uniformly, the cost can be asymptotically better.\nFor instance, with ğ‘š=logğ‘› and assuming a max bucket size of\nğ‘‚(ğ‘›\nlogğ‘›), each bucket join costs ğ‘‚(ğ‘›2\nlogğ‘›), leading to a total cost of\nğ‘‚(ğ‘›2), equivalent to JOIN . Recall that bucket joins in (MX)JOIN can\nbe executed concurrently, hence, the processing latency is indeed\ndominated by the bucket-wise cost, i.e. ğ‘‚(ğ‘›2\nlogğ‘›). Additionally, the\noutput cost is lowered from ğ‘‚(ğ‘›2)to the sum of per-bucket MF\nupper bounds (Alg 3:11), which can be substantially less if the join\nkey MFs are low.\n6.2 Heuristics\nH-1. Filter push down.is a common query planning optimiza-\ntion, moves selection operations to the earliest possible stage to\nreduce data processed by subsequent operations. In conventional\nSCAs, data obliviousness often requires padding selection sizes,\nmaking filter pushdown ineffective [ 25,44,54,80]. However,SPE-\nCIALâ€™s innovative selection methods enable compacting selections\nto approximate true cardinalities without compromising privacy,\nrestoring the effectiveness of filter pushdown. Hence, we include\nfilter push down as one of the optimization heuristic forSPEplan.\nH-2. Predicates fusion.Let ğ‘…to be any relation, ğ´1,ğ´2,...,ğ´ğ‘˜âŠ†\nğ‘ğ‘¡ğ‘¡ğ‘Ÿ(ğ‘…) , andv ={ğ‘£ 1,ğ‘£2,...,ğ‘£ğ‘˜}. We say that for multiple selection\noverğ‘…such thatğœğ´1âˆˆğ‘£1(...ğœğ´ğ‘˜âˆˆğ‘£ğ‘˜(ğ‘…)), one can always fuse them\ninto one selection ğœAâŠ‚v(ğ‘…). This can reduce the number of secure\n\ncomputation invocations from ğ‘˜rounds to just one. Additionally,\nthe selection size can be estimated as minğ´ğ‘–\u0000CardEst(ğœ ğ´ğ‘–âˆˆğ‘£ğ‘–(ğ‘…))\u0001.\nH-3. Join statistics propagation.A key property ofSPECIAL\njoin, (MX)JOIN , is that the output is already indexed and bucketized\nby the join key. Therefore, for any output ğ‘…of(MX)JOIN comput-\ningğ‘…0Zğ´jğ‘…1, a new index SPEidx(ğ´ j,ğ‘…)acrossğ‘…can be easily\nderived. Moreover, as per [ 34], one can also update the MF for ğ‘…\nby computing cmf(ğ´ j,ğ‘…)=cmf(ğ´ j,ğ‘…0)Ã—cmf(ğ´ j,ğ‘…1). As a result, we\nsay that the output of (MX)JOIN asMF-and-index-ready, enabling\ndirect application of another(MX)JOINon the same join attribute.\n7 EVALUATION\nIn this section, we present evaluation results of our proposed frame-\nwork. Specifically, we address the following questions:Question-1:\nDoesSPECIALoffer efficiency and privacy advantages over exist-\ning SCAs?Question-2: ForSPECIALdesign, is there a trade-off\nbetween privacy guarantees and system efficiency? How different\nsynopses scenarios affect system performance?Question-3: Can\nSPECIALscale complex analytical (e.g. multi-way join) queries to\nlarge-scale (multi-million rows) datasets?\n7.1 Experimental setups\nBaseline systems andSPECIALprototype.We compareSPE-\nCIALwith two baseline systems: Shrinkwrap [ 8], the SOTA DPSCA,\nand SMCQL [ 7] (also used as a baseline for Shrinkwrap). For con-\nsistency, we consider the same circuit-model implementations for\nboth baseline systems and theSPECIALprototype. While some\nworks [ 44,54] similar to SMCQL use exhaustive padding but im-\nprove efficiency through protocol-level optimizations, we exclude\nthem from our benchmarks for fair comparison concerns. We re-\nimplemented key query features for the two baseline systems and\nbuiltSPECIALusing the same MPC package ( EMPtoolkit-0.2.5 ).\nAll implementations are open-sourced [45].\nDatasets and workloads.We developed two open benchmarks.\nThe first reproduces the HealthLNK benchmark used by Shrinkwrap\nand SMCQL which simulates a real-world scenario where medical\nresearchers want to perform secure analytics across multiple co-\nhortsâ€™ sensitive data. We use an open schema [ 62] to generate a\nscalable synthetic dataset with 4 tables, 222K rows and 24 columns.\nThe benchmark involves four multi-cohort medical study queries,\nidentical to those used in Shrinkwrap and SMCQL. Our second\nbenchmark simulates secure collaborative analytics within the fi-\nnancial sector. Imagine multiple banks needing to analyze their\ncombined, private data to study loan and financial statisticsâ€”all\nwithout compromising sensitive customer information. We use the\nanonymizedCzech Financial Dataset[ 1] for this, assuming each\nentry represents data owned by a different bank or financial organi-\nzation unable to directly share information. This dataset comprises\n8 relational tables with a total of 55 columns and 1.1 million rows.\nFor testing workloads, we design eight query workloads, ranging\nfrom simple linear queries to complex multi-way join-aggregation\nqueries. A brief summary of the workloads is provided in Table 2.\nDefault configurations.ForSPECIAL, we employ a per-table\nprivacy budget allocation strategy. Each table is allocated a one-time\nprivacy budget of ğœ–=1.5andğ›¿=0.00005for synopses generation,Table 2: Query workloads\nBench. Query Type Description\nHealthLNKDosage Study Binary Join Expanding binary join.\nComorbidity Binary Join Non-expanding binary join.\nAspirin count Multi Join 3 way mixed join\n3 Join Aspirin Multi Join 4 way mixed join\nFinancialFQ1 Linear Point query.\nFQ2 Linear Range query.\nFQ3 Binary Join Non-expanding binary join.\nFQ4 Binary Join Expanding binary join.\nFQ5 Multi Join 3-way mixed joins.\nFQ6 Multi Join 3-way all expanding joins.\nFQ7 Multi Join 4-way mixed joins.\nFQ8 Multi Join 5-way mixed joins.\nand is evenly distributed across all DP synopses. For Shrinkwrap, we\nadopt their default per-query privacy allocation, assigning a privacy\nbudget ofğœ–=1.5andğ›¿=0.00005to each query, as outlined in [ 8]. It\nis important to note that this configuration means Shrinkwrap will\nnot offer guarantees on the bounded privacy loss across multiple\nqueries. For the HealthLNK benchmark, we useDosageandAspirin\nas representative workloads, and for the Financial benchmark, we\nuseFQ2, FQ4, and FQ8.Unless further elaborated, these workloads\nwill also serve as default testing queries for our evaluation. For all\nequal-width histograms generated inSPECIAL, we configure them\nto have at most 8 bins. Moreover, for baseline systems, as they do\nnot have join ordering optimizations, thus we will assume a random\njoin order for them. We conduct all experiments on bare-metal Mac\nmachines with M2 Max CPUs and 96GB unified memory.\n7.2 End-to-end comparisons\nTo addressQuestion-1, we first conduct an end-to-end perfor-\nmance comparison ofSPECIAL, Shrinkwrap, and SMCQL across all\nbenchmark workloads. The results are summarized in Figure 4, 5.\nWe cannot complete full benchmark for SMCQL due to high mem-\nory cost, so we project evaluations for FQ4 (using 10% data) and\nomit results for other complex workloads.\nFigure 4: End-to-end comparison: query latency\nFigure 5: End-to-end comparison: memory usage\nObservation 1.SPECIALoutperforms Shrinkwrap and SM-\nCQL in query latency across all benchmarks, reaching up to\n3618.3Ã—for linear queries,114 Ã—for binary joins, and80 .3Ã—\nfor multi-joins.Figure 4 shows the comparison results in query\n\nFigure 3: In-depth comparisons in execution plans: (i) The exhaustive padding in SMCQL can lead to significant memory blowup;\n(ii) Both SMCQL and Shrinkwrap suffer from unoptimized join ordering; (iii) Although Shrinkwrap reduces intermediate sizes,\nit still requires substantial memory to materialize join outputs; (iv)SPECIALcan identify efficient join execution orders to\nreduce intermediate sizes; (v)IdxAcccan significantly reduce input I/O costs.\ntime. First,SPECIALshows significant speedups for linear queries,\nreaching up to3618 .3Ã—(FQ2). This large performance gain is mainly\nattributed to its index-based fast data access. By directly fetching\nprivate data through DP indexes,SPECIALeliminate substantial\nI/O costs (e.g., sequential reads) and bypass the need for secure com-\nputations (e.g., oblivious filter). Second, we observe that in binary\njoins,SPECIALhas a less pronounced advantage over Shrinkwrap.\nThis is because binary joins have a single join order, eliminating the\npotential for join ordering problems (where different join orders\nlead to significantly different performance). Consequently, even\nthough Shrinkwrap does not optimize join orders, it doesnâ€™t experi-\nence efficiency losses in this scenario. However, for more complex\nmulti-way joins,SPECIALâ€™s advantage becomes more pronounced\nagain. For instance, more than80 Ã—speedup in FQ7. This is because\nSPECIALcan pre-select efficient join orders before runtime.\nObservation 2.SPECIALshows profound improvement in\nmemory usage (Figure 5) against baseline systems, especially\nin complex multi-way joins.This is primarily due to two factors:\nFirst, the (MX)JOIN used bySPECIALis more memory-efficient\ncompared to the joins implemented by Shrinkwrap and SMCQL.\nSecond,SPECIALâ€™s capability to identify optimal execution plans\nsignificantly reduces total intermediate sizes, which is particularly\nbeneficial for complex joins that suffer from sub-optimal or exhaus-\ntive padding in other systems. To better understand the substantial\nimprovementsSPECIALachievesâ€”for instance, up to928 .2Ã—over\nShrinkwrap and more than105Ã—over SMCQLâ€”we will zoom into\na specific query, FQ6, and compare the detailed execution plans of\nthe three systems. The choice of FQ6 is strategic because its com-\nplexity sufficiently highlights the differences in execution plans,\nyet it remains simple enough for clear visual representation. Our\ncomparison features four execution plans: a plaintext optimal plan,\nillustrating the ground truth optimal execution; a hypothetical SM-\nCQL plan (with projected cardinalities); and two actual execution\nplans from our experiments with Shrinkwrap andSPECIAL. The\ndetailed comparisons and observations are summarized in Figure 3.To continue addressQuestion-1, we now compare the privacy\nguarantees ofSPECIALwith the baseline systems (Figure 6). Specif-\nically, we focus on comparing cumulative privacy loss in multiple\nquery answering, w.r.t. two composition models: advanced compo-\nsition (Adv.)[23] and concentrated composition (CDP.)[14].\nFigure 6: End-to-end comparison privacy loss.\nObservation 3. Under continual query answering,SPECIAL\ndemonstrates significantly lower privacy loss compared to\nShrinkwrap, achieving up to89 .01Ã—and38.91Ã—improvements\nin the Adv. and CDP modes, respectively.The privacy loss\nofSPECIALis bounded to the initial synopsis release stage, so\ncontinual query answering does not incur additional privacy loss.\nIn contrast, Shrinkwrapâ€™s privacy loss accumulates over time as\neach new query allocates a fresh privacy budget. Consequently, its\nprivacy loss exhibits a logarithmic growth, as shown in Figure 6.\nThis accumulation can result in significant privacy degradation\nwhen processing a large number of queries. For example, answering\n100 queries in Shrinkwrap could result in a privacy loss of ğœ–>\n100in Adv. and ğœ–â‰ˆ60in CDP., respecitvely, even if each query\nonly uses a small privacy budget of ğœ–= 1.5. As such,SPECIAL\ndemonstrate significant improve in privacy guarantees towards\nSOTA DPSCA. Even when compared to standard SCA (e.g., SMCQL)\nwith no privacy loss due to exhaustive padding, our system incurs\nonly a small and fixed privacy cost (e.g. ğœ–=1.5per table) while\ndelivering substantial performance gains.\n\n7.3 Privacy efficiency tradeoffs\nWe addressQuestion-2by evaluatingSPECIALat various privacy\nlevels. Specifically, we maintain ğ›¿constant while varying ğœ–from\n0.1to10and assess the performance across default testing queries.\nThe results are shown in Figure 7.\nFigure 7: Privacy vs. Performance trade-offs\nObservation 4. The privacy-efficiency tradeoff generally ex-\nists but exhibits varying trends at different privacy levels.\nFor instance,SPECIALshows a clear tradeoff at higher pri-\nvacy levels ( ğœ–<1), while at lower privacy levels ( ğœ–>1), the\ntradeoff becomes less pronounced.When ğœ–increases from0 .1\nto1, both memory usage and query latency for all test queries\nsignificantly decrease. However, increasing ğœ–from1to10shows\nno significant performance gains. This may indicate that once ğœ–\nexceeds1, the impact of noises on cardinality estimation or index\nbuilding is alredy minimal, and further reductions in ğœ–do not lead\nto notable improvements. Therefore, if high privacy protection is\nrequired, practitioners should carefully fine-tune privacy param-\neters to optimize performance. Conversely, if performance is the\npriority, settingğœ–near 1 is typically sufficient.\n7.4 Synopses impacts micro benchmarks\nWe continue to addressQuestion-2to explore how synopses sce-\nnarios may affectSPECIALâ€™s performance. Specifically, we study\ntwo key settings: (i) How different bin numbers (BinNum) in syn-\nopses can impact the efficiency of (IDX)JOIN , and (ii) how synopsis\ncoverage levels for a single query can affect its overall execution. We\nwill conduct micro-benchmarks for a thorough investigation. Note\nthat simulate different synopses scenario on both HealthLNK and\nFinancial benchmarks can be challenging (e.g., joins typically occur\non the same key, so it is hard to simulate partial coverage), hence, to\nbetter control experimental variables and accurately assess impacts,\nwe will now use synthetic data and workloads.\nFigure 8: BinNum experiments.Table 3: Synopses coverage experiments.\nSynopses Coverage Time (ms) Improv. Mem. (bytes) Improv.\nNo coveragee 1831703 baseline 129048576 baseline\nJoin Key\n(JK)2 way (1 JK) 276340 6.6Ã— 28481424 4.5Ã—\n3 way (2 JKs) 29200 62.7Ã— 905808 142.5Ã—\nAll way (3 JKs) 6097 300.4Ã— 65088 1982.7Ã—\nFilterâˆ—1 input 444463 4.1Ã— 40327680 3.2Ã—\n2 inputs 108205 16.9Ã— 12602400 10.2Ã—\n3 inputs 24486 74.8Ã— 3943200 32.72Ã—\nAll inputs 6847 267.5Ã— 1303200 99Ã—\n* We synthesize a random selectivity between (0, 0.33) for each filter operation.\nWe first study how the BinNums impact the performance of\n(IDX)JOIN . To study this, we synthesize two join queries on fixed\ninput data, generate join key synopses with varying bin numbers (2\nto 64), and measure the performance of (IDX)JOIN in processing\nthe queries. The results are shown in Figure 8.\nObservation 6. The running time of (IDX)JOIN initially de-\ncreases but then increases as the BinNum grows. The memory\nusage consistently increases.(IDX)JOINpartitions larger joins\ninto smaller sub-joins, but since we rely on DP indexes for parti-\ntioning, each sub-join inevitably includes additional dummy data.\nThis increased plan size directly translates to higher memory usage\nand will grow when BinNum increases (more noises in DP indexes).\nOn the other hand, partitioning large joins into smaller ones can en-\nhance join efficiency, which is why we initially observe a decrease\nin execution time as BinNums increase (e.g., 2 to 8). However, the\ntrade-off arises when the number of bins becomes excessive (e.g.,\n>8). The overhead of handling the increased dummy data starts to\noutweigh the benefits gained from partitioning. At this point, the\nperformance improvement plateaus and starts to degrade as the\nsystem struggles with the inflated plan sizes.\nWe now study how synopses coverage impacts query perfor-\nmance. We synthesize and test a 4-way join query under two con-\ntrolled scenarios: (i)JK coverage:We focus on varying the level of\nJK coverage, starting from 1 out of 3 JKs to full coverage, while\nensuring no filter synopses are present. We then measure how this\nimpacts query performance; and (ii)Filter coverage: We maintain\nfull JK coverage and change the coverage of filter synopses on the\nqueryâ€™s input tables, ranging from 1 out of 4 inputs to full cover-\nage. This allows us to examine the isolated effect of filter synopsis\ncoverage on performance. Results are in Table 3.\nObservation 7. For both groups, query efficiency significantly\nimproves as synopses coverage grows. Nevertheless, even at\nthe lowest coverage level, queries can still achieve notable\nspeedups.Even with minimal synopsis coverageâ€”like boosting\nonly one join or applying synopses to just one input tableâ€”we\nobserve significant speedups of6 .6Ã—and4.1Ã—, respectively. This\ndemonstrates the potential for substantial performance gains even\nwith limited synopsis availability. Moreover, real-world workloads\noften involve joins on the same keys and similar filtered inputs (e.g.,\nHealthLNK workloads), suggesting that high synopsis coverage is\nachievable even with a small set of representative workloads. As\ndemonstrated by Table 3, adding even a single additional synop-\nsis, whether for join keys or table filters, can yield a substantial\nperformance boost (up to 10Ã—) in query execution efficiency.\n\nTable 4: Scaling query complexity experiments\nJoin scale Query time (ms) Improv. Memory (bytes) Improv.\nShrinkwrap Q6 58342782 baseline 3354165360 baseline\n7 (FQ8ZFQ3) 1330602 43.8Ã— 5334360 628Ã—\n8 (FQ8ZFQ5) 11789800 4.9Ã— 7901016 424Ã—\n9 (FQ8ZFQ3ZFQ4) 13306150 4.4Ã— 8999352 328Ã—\n7.5 Scaling experiments\nTo addressQuestion-3, we stressSPECIALwith two types of scaled\nworkloads: (i)scaled data:we duplicate the raw dataset to sizes of\n2Ã—,4Ã—, and8Ã—and evaluate default testing queries;(ii) scaled query\ncomplexity:We use standard inputs, but simulate complex multi\njoins (up to 9-way) by chaining together multiple join workloads.\nThe results are shown in Figure 9 and Table 4.\nFigure 9: Scaling data experiments.\nObservation 8.SPECIALshows large potential to scale up to\nmulti-million data, even for complex 5-way joins.Figure 9\nshowsSPECIALâ€™s effective scaling: up to8 Ã—data for linear queries\nand binary joins, and up to4 Ã—data for complex 5-way joins like\nQ8. For instance, Q2 can be completed within 290ms under8 Ã—, and\nin fact, since selection is bypassed (due to index access), thus the\ncost is mainly on I/O costs. Q4 finishes in 289 minutes at the same\nscale8Ã—, while the more complex 5-way join Q8 takes less than\n280 minutes for4Ã—data. As a reference, Shrinkwrap would require\nover 1035 minutes to complete Q8 even with unscaled data.\nObservation 9.SPECIALcan effectively process very large\njoins (e.g., 9-ways).Table 4 shows that the query processing time\nofSPECIALat 9-way scale can still be4 .4Ã—faster than Shrinkwrap\nat 3-way join scale (Q6), and the memory improvement is even more\nevident that is 328Ã—smaller. We stress that these significant memory\nsavings can become even more crucial when processing massive\ndatasets. Techniques like Shrinkwrap or SMCQL, might be forced\nto rely on much slower persistent storage to handle intermediate\nresults that exceed memory capacity. In contrast,SPECIALcan still\nmaintain a fully in-memory query mode, potentially leading to even\nmore pronounced efficiency gains in such scenarios.\n8 RELATED WORK\nSCA systems.Two main approaches exist for designing MPC-\nbased SCA systems. The first ispeer-to-peer (P2P) paradigm[ 2,49,54,\n67,74], where the goal is to improve efficiency by decomposing ana-\nlytical queries and pushing them to data owners, so that they can ei-\nther directly process in clear or running MPCs across a small group\nof parties. Unfortunately, this approach imposes large overhead on\ndata owners, especially for complex operations like joins. Given that\nreal-world data owners often lack robust computing resources andservice capabilities, the P2P paradigm is hard to scale and support\nreliable SCA services to external analysts. The other paradigm is the\nserver-aided-MPC model[ 8,9,37,41,44,48,57,64,70,71,77]. This\nmodel allows data owners to outsource both expensive MPC com-\nputations and secure data storage to a set of capable servers, which\ncan then jointly evaluate MPC to provide reliable SCA services.\nSPECIALis built upon the server-aided-MPC model and under a\nstrong â€œall but oneâ€corruption assumption. Moreover,SPECIALâ€™s\ncore design is protocol-agnostic, which allows interoperability with\nvarious MPC models, including the P2P or a weaker corruption\nwhere a supermajority of servers need to be honest [41, 44, 64].\nDP leakages.Leakage-abuse attacks [ 11,15,29,38,50,60,78], ex-\nploit data-dependent processing patterns, are persistent threats to\nSCA systems. To mitigate these risks, oblivious computation [ 5,17,\n20,36,39,47,52,53,58,63,65,72,73] have become thede facto\nsolution. While this technique ensures the strongest privacy guaran-\ntees by eliminating any data-dependent leakages, it also introduces\na fundamental contention with modern database optimizations,\nwhich often rely heavily on data-dependent operations [ 8,69â€“71].\nTo this end, many recent efforts seek a practical balance in the\nprivacy-performance trade-off by allowing controlled leakage un-\nder DP [ 8,16,19,28,32,51,55,56,68â€“71,77]. However, a common\nissue of these approaches is unbounded privacy loss. While some\nworks propose to address this [ 13,56,77], their approaches are re-\nstricted to only simple linear queries.SPECIALaddresses all these\nlimitations together, and to our knowledge, is the first SCA system\nthat can simultaneously ensure both bounded privacy and lossless\nresults for complex SPJA queries.\nSCA query planning.Query planning [ 61] is crucial in conven-\ntional databases. Conventional planners can exploit size disparities\nacross different query plans to choose efficient ones with smaller\nsizes [ 24,30,31]. However, such techniques use data-dependent\ninformation and are typically prohibited in SCA. A handful of stud-\nies [7,44,54,67] that explore query planning within SCA frame-\nworks primarily rely on data-independent metrics for planning,\nwhich usually lead to only moderate optimizations. Shrinkwrap [ 8]\nintroduced a private planning method that optimally compacts\nintermediate sizes by efficiently allocating privacy budgets to mini-\nmize dummy data. However, it cannot pre-determine an optimal\njoin order.SPECIALoffers an advanced query planner capable of\npre-estimating intermediate sizes and comparing execution costs\namong different plan structures before runtime.\n9 CONCLUSION\nWe introduceSPECIAL, the first SCA system that simultaneously\nsupports: (i) handling complex queries with bounded privacy loss;\n(ii) advanced query planning that effectively exploit plan interme-\ndiate sizes before runtime; and (iii) delivering exact query results\nwithout missing tuples. This is achieved through a novel synopses-\nassisted SCA design, where a set of private table statistics are re-\nleased with one-time privacy cost to guide subsequent secure SCA\nplanning and processing.\nACKNOWLEDGMENTS\nThis work was supported by the NSF grant OAC-2419821, IUIAS\nCollaborative Award, and IU Faculty Startup Grant.\n\nREFERENCES\n[1] [n.d.]. Financial Dataset. https://relational-data.org/dataset/Financial. Accessed:\n2024-03-30.\n[2]Gagan Aggarwal, Mayank Bawa, Prasanna Ganesan, Hector Garcia-Molina,\nKrishnaram Kenthapadi, Rajeev Motwani, Utkarsh Srivastava, Dilys Thomas,\nand Ying Xu. 2005. Two Can Keep A Secret: A Distributed Architecture for\nSecure Database Services.. InCIDR, Vol. 2005. 186â€“199.\n[3] MiklÃ³s Ajtai, JÃ¡nos KomlÃ³s, and Endre SzemerÃ©di. 1983. An 0 (n log n) sorting\nnetwork. InProceedings of the fifteenth annual ACM symposium on Theory of\ncomputing. 1â€“9.\n[4] Toshinori Araki, Jun Furukawa, Yehuda Lindell, Ariel Nof, and Kazuma Ohara.\n2016. High-throughput semi-honest secure three-party computation with an\nhonest majority. InProceedings of the 2016 ACM SIGSAC Conference on Computer\nand Communications Security. 805â€“817.\n[5]Gilad Asharov, TH Hubert Chan, Kartik Nayak, Rafael Pass, Ling Ren, and\nElaine Shi. 2020. Bucket oblivious sort: An extremely simple oblivious sort. In\nSymposium on Simplicity in Algorithms. SIAM, 8â€“14.\n[6] Kenneth E Batcher. 1968. Sorting networks and their applications. InProceedings\nof the April 30â€“May 2, 1968, spring joint computer conference. 307â€“314.\n[7] Johes Bater, Gregory Elliott, Craig Eggen, Satyender Goel, Abel N Kho, and Jennie\nRogers. 2017. SMCQL: Secure Query Processing for Private Data Networks.Proc.\nVLDB Endow.10, 6 (2017), 673â€“684.\n[8] Johes Bater, Xi He, William Ehrich, Ashwin Machanavajjhala, and Jennie Rogers.\n2018. Shrinkwrap: efficient sql query processing in differentially private data\nfederations.Proceedings of the VLDB Endowment12, 3 (2018).\n[9]Johes Bater, Yongjoo Park, Xi He, Xiao Wang, and Jennie Rogers. 2020. Saqe:\npractical privacy-preserving approximate query processing for data federations.\nProceedings of the VLDB Endowment13, 12 (2020), 2691â€“2705.\n[10] Michael Ben-Or, Shafi Goldwasser, and Avi Wigderson. 2019. Completeness theo-\nrems for non-cryptographic fault-tolerant distributed computation. InProviding\nsound foundations for cryptography: on the work of Shafi Goldwasser and Silvio\nMicali. 351â€“371.\n[11] Laura Blackstone, Seny Kamara, and Tarik Moataz. 2019. Revisiting leakage\nabuse attacks.Cryptology ePrint Archive(2019).\n[12] Mike W Blasgen, Morton M Astrahan, Donald D Chamberlin, JN Gray, WF King,\nBruce G Lindsay, Raymond A Lorie, James W Mehl, Thomas G Price, Gianfranco R\nPutzolu, et al .1981. System R: An architectural overview.IBM systems journal\n20, 1 (1981), 41â€“62.\n[13] Dmytro Bogatov, Georgios Kellaris, George Kollios, Kobbi Nissim, and Adam\nOâ€™Neill. 2021. Epsolute: E iciently erying Databases While Providing Differential\nPrivacy. (2021).\n[14] Mark Bun and Thomas Steinke. 2016. Concentrated differential privacy: Simpli-\nfications, extensions, and lower bounds. InTheory of Cryptography Conference.\nSpringer, 635â€“658.\n[15] David Cash, Paul Grubbs, Jason Perry, and Thomas Ristenpart. 2015. Leakage-\nabuse attacks against searchable encryption. InProceedings of the 22nd ACM\nSIGSAC conference on computer and communications security. 668â€“679.\n[16] T-H Hubert Chan, Kai-Min Chung, Bruce Maggs, and Elaine Shi. 2022. Founda-\ntions of differentially oblivious algorithms.ACM Journal of the ACM (JACM)69,\n4 (2022), 1â€“49.\n[17] Zhao Chang, Dong Xie, Sheng Wang, and Feifei Li. 2022. Towards Practical\nOblivious Join. InProceedings of the 2022 International Conference on Management\nof Data. 803â€“817.\n[18] Johes Bater Yukui Luo Chenghong Wang, Lina Qiu. 2024. SPECIAL: Synopsis\nAssisted Secure Collaborative Analytics. https://arxiv.org/abs/2404.18388.\n[19] Shumo Chu, Danyang Zhuo, Elaine Shi, and TH Hubert Chan. 2021. Differentially\noblivious database joins: Overcoming the worst-case curse of fully oblivious\nalgorithms.Cryptology ePrint Archive(2021).\n[20] Natacha Crooks, Matthew Burke, Ethan Cecchetti, Sitar Harel, Rachit Agarwal,\nand Lorenzo Alvisi. 2018. Obladi: Oblivious serializable transactions in the cloud.\nIn13th USENIX Symposium on Operating Systems Design and Implementation\n(OSDI 18). 727â€“743.\n[21] Wei Dong, Juanru Fang, Ke Yi, Yuchao Tao, and Ashwin Machanavajjhala. 2022.\nR2t: Instance-optimal truncation for differentially private query evaluation with\nforeign keys. InProceedings of the 2022 International Conference on Management\nof Data. 759â€“772.\n[22] Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N Rothblum. 2010. Dif-\nferential privacy under continual observation. InProceedings of the forty-second\nACM symposium on Theory of computing. 715â€“724.\n[23] Cynthia Dwork, Aaron Roth, et al .2014. The algorithmic foundations of differ-\nential privacy.Found. Trends Theor. Comput. Sci.9, 3-4 (2014), 211â€“407.\n[24] R Elmasri, SB Navathe, R Elmasri, and SB Navathe. 2020. Fundamentals of\nDatabase Systems</Title. InAdvances in Databases and Information Systems: 24th\nEuropean Conference, ADBIS 2020, Lyon, France, August 25â€“27, 2020, Proceedings,\nVol. 12245. Springer Nature, 139.\n[25] Saba Eskandarian and Matei Zaharia. 2017. Oblidb: Oblivious query processing\nfor secure databases.arXiv preprint arXiv:1710.00458(2017).[26] Oded Goldreich. 2009.Foundations of cryptography: volume 2, basic applications.\nCambridge university press.\n[27] Michael T Goodrich. 2014. Zig-zag sort: A simple deterministic data-oblivious\nsorting algorithm running in o (n log n) time. InProceedings of the forty-sixth\nannual ACM symposium on Theory of computing. 684â€“693.\n[28] Adam Groce, Peter Rindal, and Mike Rosulek. 2019. Cheaper private set in-\ntersection via differentially private leakage.Proceedings on Privacy Enhancing\nTechnologies2019, 3 (2019).\n[29] Paul Grubbs, Marie-Sarah LacharitÃ©, Brice Minaud, and Kenneth G Paterson.\n2018. Pump up the volume: Practical database reconstruction from volume\nleakage on range queries. InProceedings of the 2018 ACM SIGSAC Conference on\nComputer and Communications Security. 315â€“331.\n[30] Yuxing Han, Ziniu Wu, Peizhi Wu, Rong Zhu, Jingyi Yang, Liang Wei Tan,\nKai Zeng, Gao Cong, Yanzhao Qin, Andreas Pfadler, et al .2021. Cardinality\nestimation in DBMS: A comprehensive benchmark evaluation.arXiv preprint\narXiv:2109.05877(2021).\n[31] Hazar Harmouch and Felix Naumann. 2017. Cardinality estimation: An experi-\nmental survey.Proceedings of the VLDB Endowment11, 4 (2017), 499â€“512.\n[32] Xi He, Ashwin Machanavajjhala, Cheryl Flynn, and Divesh Srivastava. 2017.\nComposing differential privacy and secure computation: A case study on scaling\nprivate record linkage. InProceedings of the 2017 ACM SIGSAC Conference on\nComputer and Communications Security. 1389â€“1406.\n[33] Zhian He, Wai Kit Wong, Ben Kao, David Wai Lok Cheung, Rongbin Li, Siu Ming\nYiu, and Eric Lo. 2015. Sdb: A secure query processing system with data interop-\nerability.Proceedings of the VLDB Endowment8, 12 (2015), 1876â€“1879.\n[34] Axel Hertzschuch, Claudio Hartmann, Dirk Habich, and Wolfgang Lehner. 2021.\nSimplicity Done Right for Join Ordering.. InCIDR.\n[35] Dongxu Huang, Qi Liu, Qiu Cui, Zhuhe Fang, Xiaoyu Ma, Fei Xu, Li Shen, Liu\nTang, Yuxing Zhou, Menglong Huang, et al .2020. TiDB: a Raft-based HTAP\ndatabase.Proceedings of the VLDB Endowment13, 12 (2020), 3072â€“3084.\n[36] KristjÃ¤n Valur JÃ¶nsson, Gunnar Kreitz, and Misbah Uddin. 2011. Secure multi-\nparty sorting and applications.Cryptology ePrint Archive(2011).\n[37] Seny Kamara, Payman Mohassel, and Mariana Raykova. 2011. Outsourcing\nmulti-party computation.Cryptology ePrint Archive(2011).\n[38] Georgios Kellaris, George Kollios, Kobbi Nissim, and Adam Oâ€™neill. 2016. Generic\nattacks on secure outsourced databases. InProceedings of the 2016 ACM SIGSAC\nConference on Computer and Communications Security. 1329â€“1340.\n[39] Marcel Keller and Peter Scholl. 2014. Efficient, oblivious data structures for MPC.\nInAdvances in Cryptologyâ€“ASIACRYPT 2014: 20th International Conference on\nthe Theory and Application of Cryptology and Information Security, Kaoshiung,\nTaiwan, ROC, December 7-11, 2014, Proceedings, Part II 20. Springer, 506â€“525.\n[40] Daniel Kifer and Ashwin Machanavajjhala. 2011. No free lunch in data privacy.\nInProceedings of the 2011 ACM SIGMOD International Conference on Management\nof data. 193â€“204.\n[41] Brian Knott, Shobha Venkataraman, Awni Hannun, Shubho Sengupta, Mark\nIbrahim, and Laurens van der Maaten. 2021. Crypten: Secure multi-party com-\nputation meets machine learning.Advances in Neural Information Processing\nSystems34 (2021), 4961â€“4973.\n[42] Ios Kotsogiannis, Yuchao Tao, Xi He, Maryam Fanaeepour, Ashwin Machanava-\njjhala, Michael Hay, and Gerome Miklau. 2019. Privatesql: a differentially private\nsql query engine.Proceedings of the VLDB Endowment12, 11 (2019), 1371â€“1384.\n[43] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. InProceedings of the 2018 international\nconference on management of data. 489â€“504.\n[44] John Liagouris, Vasiliki Kalavri, Muhammad Faisal, and Mayank Varia. 2023.\n{SECRECY}: Secure collaborative analytics in untrusted clouds. In20th USENIX\nSymposium on Networked Systems Design and Implementation (NSDI 23). 1031â€“\n1056.\n[45] Lovingmage. 2024. Synopsis Assisted Secure Collaborative Analytics. https:\n//github.com/lovingmage/SPECIAL/.\n[46] Silvio Micali, Oded Goldreich, and Avi Wigderson. 1987. How to play any mental\ngame. InProceedings of the Nineteenth ACM Symp. on Theory of Computing, STOC.\nACM New York, NY, USA, 218â€“229.\n[47] Pratyush Mishra, Rishabh Poddar, Jerry Chen, Alessandro Chiesa, and Raluca Ada\nPopa. 2018. Oblix: An efficient oblivious search index. In2018 IEEE symposium\non security and privacy (SP). IEEE, 279â€“296.\n[48] Payman Mohassel and Yupeng Zhang. 2017. Secureml: A system for scalable\nprivacy-preserving machine learning. In2017 IEEE symposium on security and\nprivacy (SP). IEEE, 19â€“38.\n[49] Dimitris Mouris, Daniel Masny, Ni Trieu, Shubho Sengupta, Prasad Bud-\ndhavarapu, and Benjamin Case. 2024. Delegated Private Matching for Compute.\nProceedings on Privacy Enhancing Technologies(2024).\n[50] Simon Oya and Florian Kerschbaum. 2021. Hiding the access pattern is not\nenough: Exploiting search pattern leakage in searchable encryption. In30th\nUSENIX security symposium (USENIX Security 21). 127â€“142.\n[51] Sarvar Patel, Giuseppe Persiano, Kevin Yeo, and Moti Yung. 2019. Mitigating\nleakage in secure cloud-hosted data structures: Volume-hiding for multi-maps\nvia hashing. InProceedings of the 2019 ACM SIGSAC conference on computer and\ncommunications security. 79â€“93.\n\n[52] Martin Pettai and Peeter Laud. 2015. Combining differential privacy and secure\nmultiparty computation. InProceedings of the 31st annual computer security\napplications conference. 421â€“430.\n[53] Benny Pinkas and Tzachy Reinman. 2010. Oblivious RAM revisited. InAdvances\nin Cryptologyâ€“CRYPTO 2010: 30th Annual Cryptology Conference, Santa Barbara,\nCA, USA, August 15-19, 2010. Proceedings 30. Springer, 502â€“519.\n[54] Rishabh Poddar, Sukrit Kalra, Avishay Yanai, Ryan Deng, Raluca Ada Popa, and\nJoseph M Hellerstein. 2021. Senate: a {Maliciously-Secure}{MPC}platform for\ncollaborative analytics. In30th USENIX Security Symposium (USENIX Security\n21). 2129â€“2146.\n[55] Lianke Qin, Rajesh Jayaram, Elaine Shi, Zhao Song, Danyang Zhuo, and Shumo\nChu. 2022. Adore: Differentially oblivious relational database operators.arXiv\npreprint arXiv:2212.05176(2022).\n[56] Lina Qiu, Georgios Kellaris, Nikos Mamoulis, Kobbi Nissim, and George Kollios.\n2023. Doquet: Differentially Oblivious Range and Join Queries with Private Data\nStructures.Proceedings of the VLDB Endowment16, 13 (2023), 4160â€“4173.\n[57] Amrita Roy Chowdhury, Chenghong Wang, Xi He, Ashwin Machanavajjhala,\nand Somesh Jha. 2020. Crypte: Crypto-assisted differential privacy on untrusted\nservers. InProceedings of the 2020 ACM SIGMOD International Conference on\nManagement of Data. 603â€“619.\n[58] Sajin Sasy, Aaron Johnson, and Ian Goldberg. 2022. Fast Fully Oblivious Com-\npaction and Shuffling. InProceedings of the 2022 ACM SIGSAC Conference on\nComputer and Communications Security. 2565â€“2579.\n[59] Peter Scholl, Nigel P Smart, and Tim Wood. 2017. When itâ€™s all just too much:\noutsourcing MPC-preprocessing. InCryptography and Coding: 16th IMA Interna-\ntional Conference, IMACC 2017, Oxford, UK, December 12-14, 2017, Proceedings 16.\nSpringer, 77â€“99.\n[60] Zhiwei Shang, Simon Oya, Andreas Peter, and Florian Kerschbaum. 2021. Ob-\nfuscated access and search patterns in searchable encryption.arXiv preprint\narXiv:2102.09651(2021).\n[61] Abraham Silberschatz, Henry F Korth, and Shashank Sudarshan. 2011. Database\nsystem concepts. (2011).\n[62] SMCQL. [n.d.]. SMCQL: Secure Multi-party Computation Query Language.\nhttps://github.com/smcql/smcql/tree/master/conf/workload. Accessed: 2024-08-\n12.\n[63] Emil Stefanov, Elaine Shi, and Dawn Song. 2011. Towards practical oblivious\nRAM.arXiv preprint arXiv:1106.3652(2011).\n[64] Sijun Tan, Brian Knott, Yuan Tian, and David J Wu. 2021. CryptGPU: Fast\nprivacy-preserving machine learning on the GPU. In2021 IEEE Symposium on\nSecurity and Privacy (SP). IEEE, 1021â€“1038.\n[65] Afonso Tinoco, Sixiang Gao, and Elaine Shi. 2023. {EnigMap}:{External-\nMemory}Oblivious Map for Secure Enclaves. In32nd USENIX Security Sympo-\nsium (USENIX Security 23). 4033â€“4050.\n[66] Salil Vadhan. 2017. The complexity of differential privacy.Tutorials on the\nFoundations of Cryptography: Dedicated to Oded Goldreich(2017), 347â€“450.[67] Nikolaj Volgushev, Malte Schwarzkopf, Ben Getchell, Mayank Varia, Andrei\nLapets, and Azer Bestavros. 2019. Conclave: secure multi-party computation on\nbig data. InProceedings of the Fourteenth EuroSys Conference 2019. 1â€“18.\n[68] Sameer Wagh, Paul Cuff, and Prateek Mittal. 2016. Differentially private oblivious\nram.arXiv preprint arXiv:1601.03378(2016).\n[69] Sameer Wagh, Xi He, Ashwin Machanavajjhala, and Prateek Mittal. 2021. DP-\ncryptography: marrying differential privacy and cryptography in emerging\napplications.Commun. ACM64, 2 (2021), 84â€“93.\n[70] Chenghong Wang, Johes Bater, Kartik Nayak, and Ashwin Machanavajjhala. 2021.\nDP-Sync: Hiding update patterns in secure outsourced databases with differential\nprivacy. InProceedings of the 2021 International Conference on Management of\nData. 1892â€“1905.\n[71] Chenghong Wang, Johes Bater, Kartik Nayak, and Ashwin Machanavajjhala.\n2022. IncShrink: Architecting Efficient Outsourced Databases using Incremental\nMPC and Differential Privacy.arXiv preprint arXiv:2203.05084(2022).\n[72] Chenghong Wang, David Pujo, Kartik Nayak, and Ashwin Machanavajjhala. 2023.\nPrivate Proof-of-Stake Blockchains using Differentially-private Stake Distortion.\nCryptology ePrint Archive(2023).\n[73] Xiao Shaun Wang, Kartik Nayak, Chang Liu, TH Hubert Chan, Elaine Shi, Emil\nStefanov, and Yan Huang. 2014. Oblivious data structures. InProceedings of\nthe 2014 ACM SIGSAC Conference on Computer and Communications Security.\n215â€“226.\n[74] Yilei Wang and Ke Yi. 2021. Secure yannakakis: Join-aggregate queries over\nprivate data. InProceedings of the 2021 International Conference on Management\nof Data. 1969â€“1981.\n[75] Yonghui Xiao and Li Xiong. 2015. Protecting locations with differential privacy\nunder temporal correlations. InProceedings of the 22nd ACM SIGSAC Conference\non Computer and Communications Security. 1298â€“1309.\n[76] Andrew Chi-Chih Yao. 1986. How to generate and exchange secrets. In27th\nannual symposium on foundations of computer science (Sfcs 1986). IEEE, 162â€“167.\n[77] Yanping Zhang, Johes Bater, Kartik Nayak, and Ashwin Machanavajjhala. 2023.\nLongshot: Indexing Growing Databases Using MPC and Differential Privacy.\nProceedings of the VLDB Endowment16, 8 (2023), 2005â€“2018.\n[78] Yupeng Zhang, Jonathan Katz, and Charalampos Papamanthou. 2016. All your\nqueries are belong to us: the power of {File-Injection}attacks on searchable\nencryption. In25th USENIX Security Symposium (USENIX Security 16). 707â€“720.\n[79] Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes, Shibo\nHe, Jiming Chen, and Yang Zhang. 2021. {PrivSyn}: Differentially Private Data\nSynthesis. In30th USENIX Security Symposium (USENIX Security 21). 929â€“946.\n[80] Wenting Zheng, Ankur Dave, Jethro G Beekman, Raluca Ada Popa, Joseph E\nGonzalez, and Ion Stoica. 2017. Opaque: An oblivious and encrypted distributed\nanalytics platform. In14th USENIX Symposium on Networked Systems Design and\nImplementation (NSDI 17). 283â€“298.",
  "textLength": 87690
}