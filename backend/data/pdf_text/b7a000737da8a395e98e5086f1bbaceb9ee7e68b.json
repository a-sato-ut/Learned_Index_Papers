{
  "paperId": "b7a000737da8a395e98e5086f1bbaceb9ee7e68b",
  "title": "Connectivity Oracles for Predictable Vertex Failures",
  "pdfPath": "b7a000737da8a395e98e5086f1bbaceb9ee7e68b.pdf",
  "text": "arXiv:2312.08489v4  [cs.DS]  20 Sep 2024Connectivity Oracles for Predictable Vertex Failures∗\nBingbing Hu\nUC San DiegoEvangelos Kosinas\nISTAAdam Polak\nBocconi University\nAbstract\nThe problem of designing connectivity oracles supporting vertex fa ilures is one of the\nbasic data structures problems for undirected graphs. It is alrea dy well understood: previous\nworks [Duan–Pettie STOC’10; Long–Saranurak FOCS’22] achieve qu ery time linear in the\nnumber of failed vertices, and it is conditionally optimal as long as we re quire preprocessing\ntime polynomial in the size of the graph and update time polynomial in th e number of failed\nvertices.\nWerevisitthisproblemintheparadigmofalgorithmswith predictions:w easkifthe query\ntime can be improved if the set of failed vertices can be predicted bef orehand up to a small\nnumber of errors.More speciﬁcally, we design a data structure th at, givena graph G= (V,E)\nand a set of vertices predicted to fail /hatwideD⊆Vof sized=|/hatwideD|, preprocesses it in time ˜O(d|E|)\nand then can receive an update given as the symmetric diﬀerence be tween the predicted and\nthe actualset offailedvertices /hatwideD△D= (/hatwideD\\D)∪(D\\/hatwideD)ofsizeη=|/hatwideD△D|,processit intime\n˜O(η4), and after that answerconnectivity queries in G\\Din timeO(η). Viewed from another\nperspective, our data structure provides an improvement over t he state of the art for the\nfully dynamic subgraph connectivity problem in thesensitivity setting [Henzinger–Neumann\nESA’16].\nWe argue that the preprocessing time and query time of our data st ructure are condition-\nally optimal under standard ﬁne-grained complexity assumptions.\n1 Introduction\nConnectivity is a fundamental problem in undirected graphs . For a static input graph, one can\ncompute its connected components in linear time; after such preprocessing it is easy to answer,\nin constant time, queries asking whether two given vertices uandvare connected.\nThe problem becomes much more challenging when the graph may change over time – for\ninstance, when certain vertices may fail and have to be remov ed from the graph. Duan and\nPettie [DP10] were the ﬁrst to propose a data structure that, after constr ucting it for graph\nG= (V,E), can receive an updateconsisting of a set of failedverticesD⊆V, and then can\nanswer connectivity queriesinG\\D(i.e., in the subgraph of Ginduced on V\\D). For a graph\nwithnvertices and medges, the data structure can be constructed in ˜O(nm) time1, the update\ntakes time ˜O(d6), where d=|D|, and each query runs in O(d) time.2Under the Online Matrix-\nVector Multiplication (OMv) Hypothesis, this linear query time is optimal (up to subpolynomial\nfactors) if werequirethat preprocessingrunsintimepolyn omial in thegraphsize andtheupdate\ntime is polynomial in the number of failed vertices [ HKNS15 ].\nWe study the problem of designing such connectivity oracles through the new lens of al-\ngorithms with predictions . More speciﬁcally, we ask whether the query time can be impro ved,\nbeyond the ﬁne-grained lower bound, if some quite-accurate -but-not-perfect prediction of the\nset of failed vertices is available already during the prepr ocessing.\n∗Part of this work was done when Bingbing Hu and Adam Polak were at Max Planck Institute of Informatics,\nand Evangelos Kosinas was at University of Ioannina.\n1We use the ˜Onotation to hide polylogarithmic (log n)O(1)factors.\n2Their data structure allows also for a certain trade-oﬀ betw een the preprocessing and update times.\n1\n\n1.1 Our results\nWe deﬁne the problem of designing a connectivity oracle for p redictable vertex failures as follows.\nWe ask for a data structure that:\n•in thepreprocessing phase , receives an undirected graph G= (V,E), an upper bound\non the number of failed vertices d∈Z+, and a set /hatwideD⊆Vof vertices predicted to fail\n(|/hatwideD|/lessorequalslantd);\n•in theupdate phase , receives a set D⊂Vof vertices that actually fail ( |D|/lessorequalslantd);\n•in thequery phase , receives two vertices u,v∈V\\D, and answers whether uandvare\nconnected in G\\D:=G[V\\D].\nWe measure the prediction error as the size of the diﬀerence be tween the predicted and the\nactual set of failed vertices η:=|/hatwideD△D|=|/hatwideD\\D|+|D\\/hatwideD|. Our goal is to design a data\nstructure that improves upon the running time of classic (pr ediction-less) data structures when\nη≪d. To allow for update time sublinear in d, we let the set Dbe given not explicitly but as\nthe symmetric diﬀerence /hatwideD△D:= (/hatwideD\\D)∪(D\\/hatwideD) instead.\nOur main result is such data structure with the following gua rantees:\nTheorem 1. There is a (deterministic) connectivity oracle for predicta ble vertex failures with\n˜O(dm)preprocessing time and space, ˜O(η4)update time, and O(η)query time.\nOur result can also be interpreted outside of the realm of alg orithms with predictions. One\ncan think of /hatwideDas of the set of vertices that are initially inactive. Then, in the update phase, a\nsmall number ηof vertices change their state – some inactive vertices beco me active and some\nactive come to be inactive. With this perspective, our resul t can be interpreted as extending the\ntype of the data structure of Duan and Pettie [ DP10] with vertex insertions . Since we want to\nkeep the update and query times depending only on the number o f aﬀected vertices we cannot\neven aﬀord to read all the edges of an inserted vertex, which ca n potentially have a high degree;\nhence, we need to know candidates for insertion already in th e preprocessing phase, and the\ninitially inactive vertices are precisely these candidate s.\nThe above perspective – of adding insertions to a Duan–Petti e-style oracle – actually gives\na good intuition of how our data structure works internally: we create a (prediction-less) vertex-\nfailure connectivity oracle for G\\/hatwideD, we use it to further remove D\\/hatwideD, and we extend it so that\nit is capable of reinserting /hatwideD\\D. We found that the original connectivity oracle of Duan and\nPettie[DP10],withitscomplex high-degree hierarchy tree , isnotbestsuitedforsuchanextension.\nInstead, we base our data structure on a recent DFS-tree deco mposition scheme proposed by\nKosinas [ Kos23].\nComparison to prior work. Henzinger and Neumann [ HN16] studied already the problem\nof designing a data structure like ours, under the name of fully dynamic subgraph connectivity\nin thesensitivity setting . Their proposed solution is a reduction to a Duan–Pettie-st yle (i.e.,\nany deletion-only) connectivity oracle. Plugging in the cu rrent best oracle of Long and Sara-\nnurak [LS22], the reduction gives ˆO(d3m) preprocessing time3,ˆO(η4) update time, and O(η2)\nquery time. Because the oracle of [ LS22] is (near-)optimal under plausible ﬁne-grained complex-\nity assumptions, these running times turn out to be (nearly) the best we can hope to get from\nthat reduction.\nUsing algebraic techniques, van den Brand and Saranurak [ vdBS19] tackle a more general\nproblem of answering reachability queries in directed graphs in the presence of edge insertions\nand deletions. Note that in directed graphs edge updates can be used to simulate both vertex\nfailures and activating (initially inactive) vertices. Th is is done by splitting each vertex into two\n3TheˆOnotation hides subpolynomial no(1)factors.\n2\n\n– one only for incoming edges, one only for outgoing – and havi ng a special edge from the former\nto the later whenever the original vertex is meant to be activ e. Therefore, the data structure\nthat they provide also solves the problem that we study; it ac hievesˆO(nω) preprocessing time,\nˆO(ηω) update time, and O(η2) query time, with high probability, where ω/lessorequalslant2.372 denotes the\nmatrix multiplication constant.\nOur result oﬀers a considerable improvement over the preproc essing and query times of\nboth [HN16] and [vdBS19].\nLower bounds. We argue that the preprocessing and update times of our data s tructure are\noptimal under standard ﬁne-grained complexity assumption s. For the query time, notice that a\nclassic (prediction-less) vertex-failure connectivity o racle can be simulated by setting /hatwideD=∅in\nthe preprocessing; then η=d, and hence the lower bound of Henzinger et al. [ HKNS15 ] implies\nthat the query time O(η1−ε) is impossible, for any ε >0 (assuming the OMv Hypothesis and\nrequiring that the preprocessing time is polynomial in the g raph size and the update time is\npolynomial in d).\nRegarding the preprocessing time, in Section 4we give a lower bound based on the Exact\nTriangle Hypothesis4, which is implied by both the 3SUM Hypothesis and the APSP Hyp othesis,\nsoitisaweaker assumptionthaneitherofthosepopularﬁne- grainedcomplexity hypotheses.Our\nlower bound shows that the ˜O(dm) complexity is conditionally optimal, up to subpolynomial\nfactors, as long as the update and query times depend polynom ially only on η, and not on the\ngraph size nor on d.\nTheorem 2. Unless the Exact Triangle Hypothesis fails, there is no conn ectivity oracle for\npredictable vertex failures with preprocessing time O(d1−εm)orO(dm1−ε)and update and query\ntimes of the form f(η)·no(1), for any ε >0.\nWe note that Long and Saranurak [ LS22] give a similar lower bound for connectivity ora-\ncles for vertex failures (without predictions), which is ho wever based on the Boolean Matrix\nMultiplication Hypothesis, and hence it holds only against “combinatorial” algorithms.\n1.2 Related work\nVertex-failure connectivity oracles. Duan and Pettie [ DP10] were the ﬁrst to study con-\nnectivity oracles supporting vertex failures, and they alr eady achieved query time that turns out\nto be (conditionally) optimal [ HKNS15 ]. Their preprocessing time and update time were sub-\nsequently improved [ DP17,DP20,LS22] to˜O(dm) and˜O(d2), respectively, which are optimal\nunder standard ﬁne-grained complexity assumptions [ LS22]. Recently, Kosinas [ Kos23] gave a\ndata structure with a slightly worse ˜O(d4) update time, but much simpler than all the previous\nconstructions.\nOn the other hand, Pilipczuk et al. [ PSS+22] proposed a data structure that handles update\nand query together, in time doubly exponential in dbut with no dependence (even logarithmic)\non the graph size. Their approach is thus beneﬁcial, for inst ance, when dis a constant.\nEdge-failure connectivity oracles. Edge failures are much easier to handle than vertex\nfailures. In particular, there exist edge-failure connect ivity oracles using ˜O(m) space with ˜O(d)\nupdate time and ˜O(1) query time [ PT07,KKM13,DP20], which is unconditionally optimal\n(up to polylogarithmic factors). This diﬀerence can be expla ined by the fact that a single edge\ndeletion can only split the graph into two parts while deleti ng a high-degree vertex can create\nmultiple new connected components.\n4The Exact Triangle Hypothesis says that there is O(n3−ε) time algorithm for ﬁnding in an n-node edge-\nweighted graph a triangle whose edge weights sum up to 0, for a nyε >0.\n3\n\nFully dynamic subgraph connectivity. In the fully dynamic subgraph connectivity prob-\nlem every update consists in the activation or deactivation of a vertex, and there is no bound\non the number of vertices that may be active or inactive at any given point. In the meantime,\nthere are queries that ask whether two active vertices are co nnected through a path that visits\nonly active vertices. This model was introduced by Frigioni and Italiano [ FI00] in the context\nof planar graphs, where they show that one can achieve polylo garithmic time per operation.\nFor general undirected graphs, there are several solutions , deterministic and randomized, that\nprovide a trade-oﬀ between the update and query time [ CPR11,Dua10,DZ17,BCCK19 ]. In\nall those cases, both the update and the query time are Ω( mδ), for some δ >0, which is in\naccordance with known conditional lower bounds [ AW14,HKNS15 ,JX22]. Thus, there is a clear\ndistinction between the complexity in this unrestricted mo del, against that in the fault-tolerant\n(sensitivity) setting. In other words, we can achieve bette r performance if there is a bound on\nthe number of vertices at any given time whose state may be diﬀe rent from their original one.\nFault-tolerant labelling schemes. There is a recent line of work that provides eﬃcient\nlabelling schemes for connectivity queries in the fault-to lerant setting [ DP21,PP22,IEWM23 ,\nPPP24]. Theproblem here is to attach labels to the vertices, so tha t one can answer connectivity\nqueries in the presence of failures given the labels of the qu ery vertices and those of the failed\nvertices. The most signiﬁcant complexity measures are the s ize of the labels (ideally, the number\nof bits per label should be polylogarithmic on the number of v ertices), and the time to retrieve\nthe answer from the labels. There are many problems that admi t eﬃcient labelling schemes (see,\ne.g., [Pel05]). Such labellings have applications in the distributed se tting, because they allow to\ncompute the answer without having to access a centralized da ta structure. All else being equal,\nit is obviously a much harder problem to provide labels whose total size matches that of the\nbest centralized data structures.\nAlgorithms with predictions. The ﬁeld of algorithms with predictions, also known as\nlearning-augmented algorithms, blossoms in the recent yea rs, see surveys [ MV20,MV22] and\nan updated list of papers [ LM22]. While the majority of those works concern online algorith ms,\ndata structures are also being studied in this paradigm, see , e.g., [KBC+18,FV19,LLW22].\nThese are however mostly index data structures, BSTs, etc., and not graph data structures.\nProbably the closest to our work are three recent papers abou t dynamic graph algorithms\nwith predictions [ LS24,vdBFNP24 ,HSSY24]. We note that [ vdBFNP24 ] also manage to usepre-\ndictions to go beyond OMv-based conditional lower bounds, b ut they achieve it using algebraic\nalgorithms for fast matrix multiplication, while we only us e simple combinatorial methods and\nbeneﬁt from the fact that the predicted information is avail able already duringthe preprocessing\ntime.\nRecent follow-up work. Following the initial submission of our manuscript and post ing a\npreprint on arXiv, Long and Wang [ LW24] improved over our update time, from ˜O(η4) down\nto˜O(η2), which is conditionally optimal. Their data structure bui lds on the work of Long and\nSaranurak [ LS22], and is arguably much more complex than ours. In particular , our bounds\ninvolve less logarithmic factors hidden in the ˜Onotation.\n2 Preliminaries\nLetGdenote the input graph with nvertices and medges. Let /hatwideDbe the set of vertices predicted\nto fail, and let Dbe the set of vertices that actually fail. Moreover, we let th e size of both D\nand/hatwideDto be at most d, and we let the prediction error η:=|D\\/hatwideD|+|/hatwideD\\D|.\nWithout loss of generality, we may assume that G\\/hatwideDis connected. Indeed, we may add\na new auxiliary vertex ztoG, that is connected with an edge with every vertex of the graph .\n4\n\nThen,G\\/hatwideDis deﬁnitely connected, and in order to perform the updates, we always include z\nin the set Dof failed vertices. Notice that this does not aﬀect the asympt otic complexity of any\nof our measures of eﬃciency.\nWe build on the DFS-based tree decomposition scheme from [ Kos23]. Given the inputs G\nand/hatwideD, we grow an arbitrary DFS tree TofG\\/hatwideDrooted at some vertex r. LetT(v) denote the\nsubtree of Trooted at v. LetND(v) denote the number of descendants of v, which is equal to\nthe size of T(v). LetpT(v) denote the parent of vinT.\nSupposewe further remove some set of failed vertices D\\/hatwideDfromT. ThenTgets decomposed\nintomultipleconnectedcomponents,whichcanbehowever co nnectedtoeachotherthrough back-\nedgesin (G\\/hatwideD)\\(D\\/hatwideD). We use rCto denote the root of each connected component C. The\npresence of back-edges is important in that they establish c onnectivity between the otherwise\nloose connected components of T\\(D\\/hatwideD), so connectivity queries between two vertices can be\nreduced to queries between the connected component(s) that they reside in. Let low(v) denote\nthe lowest proper ancestor of vthat is connected to T(v) through a back-edge. It is useful to\nextend the deﬁnition of low(v) tolowk(v), as is introduced in [ Kos23, Section 2.1]. We identify\nlow1(v) withlow(v). Then for every k >1, we deﬁne lowk(v) to be the next lowest ancestor of\nvconnected to T(v) through a back-edge that is higher than lowk−1(v).\nIt is important to distinguish between two types of connecte d components: hanging subtree\nandinternal component , whichareintroducedin[ Kos23].Aconnectedcomponent CofT\\(D\\/hatwideD)\niscalled a hanging subtree ifnoneofthefailed vertices from D\\/hatwideDisadescendantof it. Otherwise,\nCis called an internal component . (See [Kos23, Section 3.3] for more properties of these two\ntypes of components.) For a visual illustration of the decom position, see the left hand side of\nFigure1. After the black vertices are removed, the white arrows repr esent internal components,\nand the grey triangles represent hanging subtrees. The reas on for this distinction is that while\nthe number of hanging subtrees can be close to n, the numberof internal components is bounded\nby the number of failed vertices, which is a convenient fact t hat we leverage in the update phase.\nIfCis an internal component and f∈D\\/hatwideDis a failed vertex whose parent lies in C, then\nwe callfaboundary vertex of C. The set of all boundary vertices of Cis denoted ∂(C). For\ninstance, in Figure 1,C1has two boundary vertices and C3has only one boundary vertex.\nWe also add structure to the vertices in D\\/hatwideDby putting them in a failed vertex forest F\n(see [Kos23, Section 3.3]). Basically each failed vertex f∈D\\/hatwideDhas a parent pointer parent F(f)\nto the largest (w.r.t. the DFS numbering) failed vertex that is an ancestor of f. Eachfalso has\na pointer to the list of its children in the forest. This fores t can be built in O(η2) time. To check\nwhether a failed vertex fis a boundary vertex of some internal component C, we can check\nwhether parent F(f)/\\e}atio\\slash=pT(f) [Kos23, Lemma 5].\n3 Our data structure\nOur oracle operates in three phases: preprocessing, update , and query.\nPreprocessing. We begin with a DFS tree Tfor the graph G\\/hatwideD, and prepare relevant data\nstructures, which are detailed in Section 3.1.\nUpdate. In this phase, we are concerned with further removing the set of vertices D\\/hatwideDfrom\nG\\/hatwideD, and adding back the vertices /hatwideD\\Dthat were deleted in the previous phase because\nof prediction errors. We build an auxiliary connectivity graph M, which captures connectivity\nrelations among so called internal components ofT\\(D\\/hatwideD) and the reinserted vertices /hatwideD\\D.\nQuery. Given two vertices s,t∈G\\D, we ﬁnd a representative connected component for each\nofsandt, and answer the connectivity query based on M.\n5\n\n3.1 The preprocessing phase\nIn the preprocessing phase, we build a number of data structu res around G\\/hatwideD. It takes ˜O(dm)\ntime. Our preprocessing data structures expand on the data s tructures introduced in [ Kos23]\n(the ﬁrst six in the list below). See Section 3.1 in [ Kos23] for more explanation and ways to\nconstruct them.\n1. A DFS-tree TforG\\/hatwideDrooted at some vertex r. For each vertex vinG\\/hatwideD, we compute its\ndepth in Tand number of descendants ND(v). We store the DFS numbering and identify\nthe vertices with the order in which they are visited.\n2. A level-ancestor data structure on T[BF04]. For any vertex v∈Tand any depth ℓ∈Z+,\nthis data structure can return in constant time the ancestor ofvat depth ℓin the tree.\n3. A 2D-range-emptiness data structure [ CLP11,CT17] that can answer, in ˜O(1) time,\nwhether there is a back-edge with one end in some segment5[X1,X2] ofTand the other\nend in some segment [ Y1,Y2] ofT.\n4. Thelowipoints of all vertices in T, fori∈{1,...,d}.\n5. For every i∈{1,...,d}, we ﬁrst sort the children of each vertex vinTin increasing\norder with respect to their lowipoints. Then we compute a new DFS numbering, which\nwe denote Ti, corresponding to the DFS traversal in which children of eve ry vertex are\nvisited in that sorted order. Note that the ancestor-descen dant relation in Tiis the same\nas that in T.\n6. For every Ti, a separate 2D-range-emptiness data structure described i n item3.\n7. For every u∈/hatwideD, we traverse the vertices in Tin a bottom-up fashion and mark vertices\nthat have in their subtrees a neighbor of u. Then we create a tree Tuas follows: for\nevery vertex vinT, rearrange the children of vby putting unmarked vertices before\nmarked vertices, and do a DFS traversal under this rearrange ment to get Tu. Note that\nthe ancestor–descendant relation in Tuis the same as that in T.\n8. For every u∈/hatwideD, a 2D-range-emptiness data structure on Tuas described in item 3.\n9. For every u,v∈/hatwideD,u/\\e}atio\\slash=v, we sort the adjacent vertices of vinG\\/hatwideDin increasing order\nwith respect to their numbering in Tuand store them as neighbors u(v). Moreover, in\nneighbors (v) we store the adjacent vertices of vinG\\/hatwideDin increasing order w.r.t. their\noriginal DFS numbering in T.\nRemark. The purpose of items 1–9 will become clear when we describe ho w to add edges to the\nauxiliary connectivity graph Min the update phase. Items 1–6 allow us to eﬃciently establis h\nconnectivity within ( G\\/hatwideD)\\(D\\/hatwideD). Items 7–9 allow us to eﬃciently establish connectivity\nbetween /hatwideD\\Dand (G\\/hatwideD)\\(D\\/hatwideD).\nThe total time for initializing items 1–6 is ˜O(dm). See [Kos23, Section 3.1] for more explana-\ntion. Items 7, 8, and 9 take ˜O(dm) time because for every u∈/hatwideD, we create a new tree by taking\nthe old tree Tand rearranging its children lists in ˜O(m) time. Hence, the total preprocessing\ntime is˜O(dm), and the created data structures take ˜O(dm) space.\n3.2 The update phase\nIn the update phase, we receive the real set of failed vertice sD. Since/hatwideDhas already been\nremoved from Gbefore computing our DFS tree T, we just need to further remove D\\/hatwideDfrom\n5When we talk about segments of a DFS tree T, we mean that we identify vertices w.r.t. their DFS numberin g,\nand a segment [ X,Y] ofTis the set of vertices {X,X+1,...,Y}.\n6\n\nC1\nC2\nC3C4\nC5r\nf1 f2\nf3\nf4 f5f6f7\nf8\nT\\(D\\ˆD) ˆD\\Du1\nu2\nu3\nu4\nu5\nFigure 1: The decomposition graph after we further remove D\\/hatwideDfromTand add back /hatwideD\\D.\nOn the left hand side we have T\\(D\\/hatwideD). The black vertices f1,...,f8are failed vertices\ninD\\/hatwideD. The white pentagonal arrows represent internal component s. The light grey triangles\nrepresent hanging subtrees. The blue edges represent back- edges between connected components\nofT\\(D\\/hatwideD). On the right hand side we have /hatwideD\\D. The edges with an end in /hatwideD\\Dare\ncolored green.\nrC1\nrC3 rC2\nrC5rC4u1\nu2\nu3\nu4\nu51\n26\n64\n5\n3\nFigure 2: The connectivity graph Mfor the example shown in Figure 2. Edges are labeled\nwith their types. The left hand side of the dotted line are ver tices representing the internal\ncomponents of T\\(D\\/hatwideD); the right hand side of the dotted line are vertices in /hatwideD\\D. Edge\n(rC1,rC3) is due to a back-edge between C1andC3. Edges ( rC2,rC5),(rC2,u5),(rC5,u5),(u1,u2)\nare all due to mutual connections to a hanging subtree. Edges (rC4,u1),(u3,u4) are both due to\ndirect edges. Vertices in the same connected component are ﬁ lled with the same color.\n7\n\nT, and then add back /hatwideD\\D, which we needlessly removed (because of prediction errors ) in the\npreprocessing phase. See Figure 1for the decomposition of Gafter these operations have been\nperformed.\nAn issue with the full decomposition graph is that the number of hanging subtrees can be as\nlarge as order of n. We want to “shrink” the decomposition graph by getting rid o f the hanging\nsubtrees while still preserving connectivity. For this pur pose, we deﬁne an auxiliary connectivity\ngraph, which builds on and extends a similar construction already introduced in [ Kos23].\nDeﬁnition 3. LetMbe a graph with the vertex set\nV(M):= (/hatwideD\\D)∪{rC:Cis an internal component of T\\(D\\/hatwideD)}.\nThe edge set E(M) consists of edges of the following six types (the ﬁrst two ty pes are the same\nas in [Kos23]).\n1. If there is a back-edge connecting two internal component sC1,C2ofT\\(D\\/hatwideD), then we\nadd an edge between rC1andrC2inM.\n2. If there is a hanging subtree HofT\\(D\\/hatwideD) which is connected to internal components\nC1,...,C kthrough back-edges, with Ckbeing an ancestor of all C1,...,C k−1, then we add\nedges (rCk,rC1),...,(rCk,rCk−1) inM.\n3. If there is an edge connecting two vertices u1,u2∈/hatwideD\\DinG, then we also add an edge\nbetween u1andu2inM.\n4. Ifthereisanedgeconnectinganinternal component CofT\\(D\\/hatwideD)andavertex u∈/hatwideD\\D,\nthen we add an edge between rCanduinM.\n5. If there are two vertices u1,u2∈/hatwideD\\Dand a hanging subtree HofT\\(D\\/hatwideD) such that\nbothu1andu2are connected to H, then we add an edge between u1andu2inM.\n6. If there are an internal component CofT\\(D\\/hatwideD), a vertex u∈/hatwideD\\D, and a hanging\nsubtreeHofT\\(D\\/hatwideD) such that there is a back-edge connecting CandH, and there is\nan edge connecting uandH, then we add an edge between rCanduinM.\nAs an illustration, in Figure 2we show the connectivity graph for the graph in Figure 1.\nThe validity of type-2 edges comes from the following proper ty of back-edges: If eis a back-\nedge ofT\\(D\\/hatwideD), then we have that either (i) the two ends of eare in two internal components\nthat are related as ancestor and descendant, or (ii) one end o feis in a hanging subtree Hand\nthe other end lies in an internal component that is an ancesto r ofH(see Lemma 6 and Corollary\n7 in [Kos23] for a full proof). Hence, the internal components C1,...,C kin the characterization\nof type-2 edges are all ancestors of H, so it suﬃces to pick the most ancestral internal component\nCkand connect it by type-2 edges with the remaining components C1,...,C k−1.\nIn the next lemma we show that Mcorrectly captures the connectivity between internal\ncomponents of T\\(D\\/hatwideD) and/hatwideD\\DinG\\D.\nLemma 4. LetSandS′each be an internal component of T\\(D\\/hatwideD)or a vertex in /hatwideD\\D.\nThenSandS′are connected in G\\Dif and only if the vertices representing them in M,SM\nandS′\nM, are connected in M.\nProof.First, let us show the “only if” direction. Let S=P0−P1−P2−···−Pk−1−Pk=S′\ndenote a path from StoS′inG\\D, where each Piis either an internal component of T\\(D\\/hatwideD),\na hanging subtree of T\\(D\\/hatwideD), or a vertex in /hatwideD\\D. Note that by the property of back-edges\nabove, we cannot have two consecutive hanging subtrees in th e path.\n8\n\nLet us consider a segment ( Pi−Pi+1) of this path. If neither PinorPi+1is a hanging\nsubtree, then we automatically have that their representat ives inMare connected, by one of\nthe constructions of type-1, type-3, or type-4 edges.\nHowever, if one of PiandPi+1is a hanging subtree, and without loss of generality we assum e\nit isPi, then it follows that Pi−1exists and it is not a hanging subtree. If Pi−1andPi+1are\nboth internal components, then their representatives in Mare (perhaps indirectly) connected\nby type-2 edges. If Pi−1andPi+1are both vertices in /hatwideD\\D, then their representatives are\nconnected inMby a type-5 edge. If one of them is an internal component and th e other is a\nvertex in /hatwideD\\D, then their representatives are connected in Mby a type-6 edge. Therefore, by\napplying the connectivity to all segments of the path, we get that the representatives of Sand\nS′inMare connected, as desired.\nNow, let us showthe morestraightforward “if” direction. Su pposeSMandS′\nMareconnected\ninM. ThenSandS′are either directly connected with an edge in G\\D, or indirectly connected\nthrough a hanging subtree in G\\D. In either case, we have that SandS′are connected.\nNote that only vertices from /hatwideD\\Dand the roots of internal components of T\\(D\\/hatwideD) are\npresent in V(M). Hence, the number of vertices in MisO(η). We argue that we can add in\ntype-1 to type-6 edges in ˜O(η4) time. Proposition 11 and Proposition 12 in [ Kos23] describe how\nwe can compute type-1 edges in ˜O(η2) time and type-2 edges in ˜O(η4) time. Computing type-3\nedges is also straightforward. Hence, we focus on computing type-4, type-5, and type-6 edges\nin the following sections. We ﬁnish the update phase by compu ting connected components of\nM, in time O(|V(M)|+|E(M)|) =O(η2), so that in the query phase we are able to decide in\nconstant time whether two vertices in V(M) are connected.\n3.2.1 Computing type-4 edges\nIn this section we describe our algorithm for adding type-4 e dges toM, see Algorithm 1. Recall\nthat type-4 edges connect vertices from /hatwideD\\Dwith internal components in which they have\nneighbors.\nAlgorithm 1: For each internal component CofT\\(D\\/hatwideD) andu∈/hatwideD\\D, adds a\ntype-4 edge between rCanduinMif there is an edge in Gconnecting utoC.\n1foreach u∈/hatwideD\\Ddo\n2foreach internal component CofT\\(D\\/hatwideD)do\n3 f1,f2,...,fk←boundary vertices of Csorted in increasing order;\n4 fori= 0,...,kdo\n5 ifi >0thenL←fi+ND(fi)elseL←rC;\n6 ifi < kthenR←fi+1−1elseR←rC+ND(rC)−1;\n// Check the condition below in O(log n) time using binary sea rch.\n7 ifneighbors (u)∩[L,R]/\\e}atio\\slash=∅then\n8 add an edge between rCanduinM;\nFor each vertex u∈/hatwideD\\Dand each internal component CofT\\(D\\/hatwideD) we want to\neﬃciently establish if there is an edge between them. Let f1,f2,...,fkbe the boundary vertices\nofC. By Lemma 4(3) of [ Kos23],Ccan be written as the union of the following segments:\n[rC,f1−1],[f1+ND(f1),f2−1],...,[fk−1+ND(fk−1),fk−1],[fk+ND(fk),rC+ND(rC)−1].\nFor each of these segments we check whether neighbors (u) contains a vertex with the DFS\nnumber in that segment and if it does we add an edge between uandrCinM. Each such check\ncan be performed eﬃciently, in time O(log(|neighbors (u)|)) =O(logn), by using binary search.\n9\n\nIndeed, for a segment [ L,R], we ﬁrst binary search in neighbors (u) the smallest number greater\nthan or equal to L, and then just check if it is less than or equal to R.\nFor each internal component C, the number of binary searches we make is O(|∂(C)|). Since\nthe total number of boundary vertices is O(η), we have that the total number of binary searches\nin Algorithm 1isO(η2), and hence its running time is O(η2logn).\n3.2.2 Computing type-5 edges\nIn this section we describe our algorithm for adding type-5 e dges toM, see Algorithm 2. Recall\nthat type-5 edges join pairs of vertices in /hatwideD\\Dthat are connected in G\\Dvia a hanging\nsubtree.\nFor every u,v∈/hatwideD\\D, we want to know whether they are connected to the same hangin g\nsubtreeH. If we checked this separately for every tuple ( u,v,H), then it would be ineﬃcient\nbecause the number of hanging subtrees can be as large as orde r ofn. However, if we group\ntogether vertices that have edges to uin their subtrees, which is exactly what we do in Tu, then\nwecan processthehangingsubtreesinbatches. Let fbeafailed vertex in D\\/hatwideD, andletLu(f) be\nthe sequence of children of fthat are marked by u, sorted by their DFS numbering in Tu. Since\nwe only care about hanging subtrees, we disregard vertices i nLu(f) which are roots of internal\ncomponents. This breaks Lu(f) intoO(η)slicesconsisting of roots of hanging subtrees. Each\nsuch slice s= (L,...,R)∈Su(f) corresponds to (potentially) multiple hanging subtrees – each\nsubtree containing a neighbor of u– which form a contiguous set of vertices [ L,R+ND(R)−1]\nin the DFS numbering for Tu. We can eﬃciently check if vhas a neighbor with the DFS number\nin that range. Indeed, we binary search in neighbors u(v) the smallest number greater than or\nequal to L, and check if it is less than or equal to R+ND(R)−1. If this is the case, then uand\nvboth have edges to a common hanging subtree, so we add a type-5 edge between them.\nAlgorithm 2: Adds a type-5 edge in Mbetween every u,v∈/hatwideD\\Dthat are connected\nto the same hanging subtree.\n1foreach u∈/hatwideD\\Ddo\n// Consider the DFS tree Tuand the respective DFS numbering.\n2foreach v∈/hatwideD\\Ddo\n3 foreach failed vertex f∈D\\/hatwideDdo\n4 Su(f)←the collection of contiguous slices of the sorted list of chi ldren off\nthat are marked by uconsisting only of roots of hanging subtrees;\n5 foreach slices∈Su(f)do\n6 L←min(s);\n7 R←max(s);\n// Check the condition below in O(log n) time using binary sea rch.\n8 ifneighbors u(v)∩[L,R+ND(R)−1]/\\e}atio\\slash=∅then\n9 add an edge between uandvinM;\nWe claim that the number of binary searches we make in line 8of Algorithm 2isO(η3).\nEach of them corresponds to a tuple ( u,v,f,s). We leverage the fact that the number of internal\ncomponents in T\\(D\\/hatwideD) isO(η). Suppose f1,...,fkare all the failed vertices in D\\/hatwideD. Then\n|Su(f1)|+|Su(f2)|+···+|Su(fk)|=O(η) for every u∈/hatwideD\\D. It follows that Algorithm 2runs\nin timeO(η3logn).\n10\n\n3.2.3 Computing type-6 edges\nIn this section we describe our algorithm for adding type-6 e dges toM, see Algorithm 3. Recall\nthat type-6 edges join vertices from /hatwideD\\Dwith internal components that are connected to them\nindirectly via a hanging subtree.\nAlgorithm 3: Adds a type-6 edge in Mbetween every u∈/hatwideD\\Dand every internal\ncomponent CofT\\(D\\/hatwideD) that are connected to the same hanging subtree H.\n1foreach u∈/hatwideD\\Ddo\n// Consider the DFS tree Tuand the respective DFS numbering.\n2foreach failed vertex f∈D\\/hatwideDdo\n3 Su(f)←the collection of contiguous slices of the sorted list of chi ldren offthat\nare marked by uconsisting only of roots of hanging subtrees;\n4 f′←f;\n5 whilef′/\\e}atio\\slash=nulldo\n6 ifpT(f′)/\\e}atio\\slash=parent F(f′)then\n// Vertex f′is a boundary vertex of some internal component.\n7 C←the internal component of T\\(D\\/hatwideD) such that f′∈∂(C);\n8 foreach slices∈Su(f)do\n9 L←min(s);\n10 R←max(s);\n11 if2Drangequeryu([L,R+ND(R)−1]×[rC,pT(f′)])/\\e}atio\\slash=∅then\n12 add an edge between uandrCinM;\n13 f′←parent F(f′);\nConceptually, we want to query each ( C,u,H)-tuple (where Cis an internal component, u\nis a vertex from /hatwideD\\D, andHis a hanging subtree) whether Hcontains a neighbor of uand\na back-edge to C. Similarly to how we compute type-5 edges, for each u∈/hatwideD\\Dwe group\ntogether relevant hanging subtrees in order to bound the num ber of queries we make on them\n(line3). Note that if Cis an internal component connected to Hthrough a back-edge, then C\nis an ancestor of H(see Lemma 6 and Corollary 7 in [ Kos23]). Therefore, once we have ﬁxed\na vertex u∈/hatwideD\\Dand a failed vertex f∈D\\/hatwideD, we only need to traverse Tuup from fand\nperform queries on each encountered internal component (th e while-loop in line 5). During that\ntraversal, whenever we encounter an internal component C, we want to check whether there\nexists a back-edge between Cand a hanging subtree Hwhose root is a child of fand which\ncontains a neighbor of u. We do it in line 11by sending a query to the 2D-range-emptiness data\nstructure (created in item 8of the preprocessing phase) indexed by the DFS numbering of t ree\nTu. The validity of line 11comes from two lemmas in [ Kos23], which we reprint here:\nLemma 5 ([Kos23] Lemma 4(2)) .LetCbe an internal component of T\\X, whereXis any\nset of failed vertices. For every vertex vthat is a descendant of C, there is a unique boundary\nvertex of Cthat is an ancestor of v.\nLemma 6 ([Kos23] Lemma 8) .LetC,C′be two connected components of T\\X, whereXis\nany set of failed vertices, such that C′is an internal component that is an ancestor of C. Letb\nbe the boundary vertex of C′that is an ancestor of C. Then there is a back-edge from CtoC′if\nand only if there is a back-edge from Cwhose lower end lies in [rC′,pT(b)].\nNow let us show the correctness of Algorithm 3. Suppose that a vertex ufrom/hatwideD\\Dand\nan internal component Care both connected in G\\Dto a hanging subtree H, and denote by\n11\n\nf∈D\\/hatwideDthe parent of the root of H. We claim that Algorithm 3eventually ﬁnds CinTu\nby traversing up from f. Indeed, by Lemma 5, letf′be the boundary vertex of Cthat is an\nancestor of f. Then, by Lemma 6, we know that the 2D range query in line 11returns true.\nConversely, if the 2D range query in line 11returns true for some Candf′, then we can also\nconclude that uis connected with Cthrough the mediation of a hanging subtree whose root is\na child of f.\nBy the same reasoning as for Algorithm 2, each query corresponds to a tuple ( u,f,f′,s). For\nﬁxeduandf′the total number of segments sinTu\\(D\\/hatwideD), over all choices of f, isO(η).\nHence the number of 2D range queries Algorithm 3makes is O(η3). Since each such query takes\nO(logn) time [CLP11], the total running time is O(η3logn).\n3.3 The query phase\nFinally, we describe our algorithm for the query phase, see A lgorithm 4. GivensandtinG\\D,\nwe ﬁrst determine where they lie in. If they lie in some intern al component(s) of T\\(D\\/hatwideD) or in\nthe extra set of vertices /hatwideD\\D, we can check whether these components/vertices are connec ted in\nM. However, if s(ort) lies in a hanging subtree, we try to ﬁnd a surrogate for s(respectively t),\nnamely a vertex in /hatwideD\\Dor an internal component of T\\(D\\/hatwideD) that is connected by an edge\nto the hanging subtree of s(respectively t).6If we can ﬁnd such a surrogate, we can replace s\n(respectively t) with it, and refer to Mas in the previous case. However, if no such surrogate\nexists, either for sor fort, thensandtare connected if and only if they reside in the same\nhanging subtree.\nAlgorithm 4: Given two vertices s,t∈V\\D, answers if they are connected in G\\D.\n1function ﬁndrepresentative( u)\n2ifu∈/hatwideD\\Dthen return u;\n3ifulies in an internal component CofT\\(D\\/hatwideD)then return rC;\n4H←the hanging subtree of T\\(D\\/hatwideD) whereulies in;\n// Try to find an internal component as a surrogate.\n5fori∈{1,...,η}do\n6 iflowi(rH)/\\e}atio\\slash=nullandlowi(rH)/∈Dthen\n7 C←the internal component of T\\(D\\/hatwideD) wherelowi(rH) lies in;\n8 returnrC;\n// Try to find a vertex in /hatwideD\\Das a surrogate.\n9foreach v∈/hatwideD\\Ddo\n10 ifrHis marked in Tvthen return v;\n// No surrogate found, return the hanging tree’s root as the r epresentative.\n11returnrH;\n12s←ﬁndrepresentative( s);\n13t←ﬁndrepresentative( t);\n14ifs∈V(M)andt∈V(M)then\n15returnwhether sandtare connected in M;\n16else/* At least one vertex lies in an isolated hanging subtree, re presented by\nits root. */\n17returnwhether s=t;\nNow let us justify the running time for Algorithm 4. Given that we have computed the\n6Note that in order to ﬁnd a surrogate internal component it is suﬃcient to check the low1,...,low ηpoints of\nthe root of the hanging subtree.\n12\n\nconnected components of Mat the end of the update phase, we can decide in O(1) time the\nconnectivity amonginternal components andvertices from /hatwideD\\D. Locating thecorrect connected\ncomponent in T\\(D\\/hatwideD) and deciding whether it is an internal component or a hangin g subtree\ntakesO(η) time (see Proposition 13 in [ Kos23] for more detail). The for-loops on lines 5and9,\nwhich are looking for a surrogate, both take O(η) time. Summing up, Algorithm 4answers a\nquery in O(η) time.\n4 Lower bound for preprocessing time\nIn this section, we show that the ˜O(dm) preprocessing time of our oracle cannot be improved\nby a polynomial factor assuming the Exact Triangle Hypothes is, which is implied by both the\n3SUM Hypothesis and the APSP Hypothesis.\nTo show this, we give a ﬁne-grained reduction from the oﬄine S etDisjointness problem. This\nproblem was introduced by Kopelowitz, Pettie, and Porat [ KPP16], who showed it is hard under\nthe3SUM Hypothesis. Vassilevska Williams andXuextended t heir hardnessresultto holdunder\na weaker assumption, namely the Exact Triangle Hypothesis; as a consequence the problem is\nalso hard under the APSP Hypothesis. The input to the SetDisj ointness problem is a universe\nof elements U, a family of subsets F⊆2U, and a collection of query pairs ( Si,Sj)∈F×F,\nwhose number is denoted by q. For each query, one has to answer whether Si∩Sjis empty or\nnot. We use the following lower bound for SetDisjointness fr om [WX20, Corollary 3.11].\nTheorem 7 (Vassilevska Williams and Xu [ WX20, Corollary 3.11]) .For any constant γ∈(0,1),\nletAbe an algorithm for oﬄine SetDisjointness where |U|= Θ(n2−2γ),|F|= Θ(n), each set\ninFhas at most O(n1−γ)elements from U, andq= Θ(n1+γ). Assuming the Exact Triangle\nHypothesis,Acannot run in O(n2−ε)time, for any ε >0.\nProof of Theorem 2.We reduce solving the oﬄine SetDisjointness problem, in the parameter\nregime speciﬁed in Theorem 7(later, we set γ= 1−ε/2), to creating a connectivity oracle for\npredictable vertex failures on an undirected graph with O(n+n2−2γ) vertices and O(n2−γ) edges,\nwithd=O(n), and then running the update and query phases qtimes each, with η=O(1).\nHere is how we construct the undirected graph G. LetV(G) consist of two disjoint sets A\nandB. The vertices in A={a1,a2,...,a |F|}represent the sets in F={S1,S2,...,S |F|}, and\nthe vertices in B={bu|u∈U}represent the elements in U. We put edges between AandBso\nthatai∈Ais connected to bu∈Bif and only if u∈Si. Note that, for i/\\e}atio\\slash=j,Si∩Sj/\\e}atio\\slash=∅if and\nonly ifaiandajare connected in the subgraph of Ginduced on B∪{ai,aj}. The constructed\ngraph has|A|+|B|=|F|+|U|=O(n+n2−2γ) vertices and O(|F|·maxi|Si|) =O(n2−γ) edges.\nIn the preprocessing phase we set /hatwideD=A. Then, for each input query pair ( Si,Sj), we set\nD=/hatwideD\\{ai,aj}, do the update, and then query connectivity between aiandaj.\nLett1denote the preprocessing time; t2denote the update time; and t3denote the query\ntime. Then, the total time to solve SetDisjointness is t1+q·(t2+t3). By Theorem 7, we get\nthatt1+q·(t2+t3)/greaterorequalslantn2−o(1), unless the Exact Triangle Hypothesis fails. Since η= 2 is a\nconstant, we know that t2=no(1)andt3=no(1), and hence q·(t2+t3) =n1+γ+o(1). This forces\nt1/greaterorequalslantn2−o(1). Recall that d=|/hatwideD|=|A|=|F|=O(n), andm=O(n2−γ). Ift1=O(d1−εm) (or\nO(dm1−ε)), then by setting γ= 1−ε/2 we would get that t1=O(n2−ε/2) and hence the Exact\nTriangle Hypothesis would fail.\nReferences\n[AW14] AmirAbboudandVirginiaVassilevska Williams. Popu larconjectures implystrong\nlower bounds for dynamic problems. In 55th IEEE Annual Symposium on Founda-\ntions of Computer Science, FOCS , pages 434–443. IEEE Computer Society, 2014.\ndoi:10.1109/FOCS.2014.53 .\n13\n\n[BCCK19] Surender Baswana, Shreejit Ray Chaudhury, Keerti Choudhary, and Shahbaz\nKhan. Dynamic DFS in undirected graphs: Breaking the o(m) ba rrier.SIAM\nJ. Comput. , 48(4):1335–1363, 2019. doi:10.1137/17M114306X .\n[BF04] Michael A. Bender and Martin Farach-Colton. The leve l ancestor problem simpli-\nﬁed.Theor. Comput. Sci. , 321(1):5–12, 2004. doi:10.1016/j.tcs.2003.05.002 .\n[CLP11] Timothy M. Chan,KasperGreen Larsen,andMihai Puat racscu. Orthogonal range\nsearching on the RAM, revisited. In Proceedings of the 27th ACM Symposium on\nComputational Geometry, Paris, France, June 13-15, 2011 , pages1–10. ACM,2011.\ndoi:10.1145/1998196.1998198 .\n[CPR11] Timothy M. Chan, Mihai Puatracscu, and Liam Roditty . Dynamic connectivity:\nConnecting to networks and geometry. SIAM J. Comput. , 40(2):333–349, 2011.\ndoi:10.1137/090751670 .\n[CT17] Timothy M. Chan and Konstantinos Tsakalidis. Dynami c orthogonal range search-\ning on the RAM, revisited. In 33rd International Symposium on Computational\nGeometry, SoCG 2017 , volume 77 of LIPIcs, pages 28:1–28:13. Schloss Dagstuhl -\nLeibniz-Zentrum f¨ ur Informatik, 2017. doi:10.4230/LIPIcs.SoCG.2017.28 .\n[DP10] Ran Duan and Seth Pettie. Connectivity oracles for fa ilure prone graphs. In\nProceedings of the 42nd ACM Symposium on Theory of Computing, STO C 2010,\npages 465–474. ACM, 2010. doi:10.1145/1806689.1806754 .\n[DP17] Ran Duan and Seth Pettie. Connectivity oracles for gr aphs subject to ver-\ntex failures. In Proceedings of the Twenty-Eighth Annual ACM-SIAM Sym-\nposium on Discrete Algorithms, SODA 2017 , pages 490–509. SIAM, 2017.\ndoi:10.1137/1.9781611974782.31 .\n[DP20] Ran Duan and Seth Pettie. Connectivity oracles for gr aphs subject to vertex\nfailures. SIAM J. Comput. , 49(6):1363–1396, 2020. doi:10.1137/17M1146610 .\n[DP21] Michal Dory and Merav Parter. Fault-tolerant labeli ng and compact routing\nschemes. In PODC ’21: ACM Symposium on Principles of Distributed Computin g,\npages 445–455. ACM, 2021. doi:10.1145/3465084.3467929 .\n[Dua10] Ran Duan. New data structures for subgraph connecti vity. In Automata,\nLanguages and Programming, 37th International Colloquium, ICA LP, volume\n6198 of Lecture Notes in Computer Science , pages 201–212. Springer, 2010.\ndoi:10.1007/978-3-642-14165-2\\_18 .\n[DZ17] Ran Duan and Le Zhang. Faster randomized worst-case u pdate time for dynamic\nsubgraph connectivity. In Algorithms and Data Structures - 15th International\nSymposium, WADS , volume 10389 of Lecture Notes in Computer Science , pages\n337–348. Springer, 2017. doi:10.1007/978-3-319-62127-2\\_29 .\n[FI00] DanieleFrigioni andGiuseppeF.Italiano. Dynamica lly switchingverticesinplanar\ngraphs.Algorithmica , 28(1):76–103, 2000. doi:10.1007/S004530010032 .\n[FV19] Paolo Ferragina and Giorgio Vinciguerra. Learned da ta structures. In Recent\nTrends in Learning From Data - Tutorials from the INNS Big Data and Deep\nLearning Conference (INNSBDDL 2019) , volume 896 of Studies in Computational\nIntelligence , pages 5–41. Springer, 2019. doi:10.1007/978-3-030-43883-8\\_2 .\n14\n\n[HKNS15] Monika Henzinger, Sebastian Krinninger, Danupon Nanongkai, and Thatchaphol\nSaranurak. Unifying and strengthening hardness for dynami c problems via the\nonline matrix-vector multiplication conjecture. In Proceedings of the Forty-Seventh\nAnnual ACM on Symposium on Theory of Computing, STOC 2015 , pages 21–30.\nACM, 2015. doi:10.1145/2746539.2746609 .\n[HN16] Monika Henzinger and Stefan Neumann. Incremental an d fully dynamic subgraph\nconnectivity for emergency planning. In 24th Annual European Symposium on\nAlgorithms, ESA 2016 , volume 57 of LIPIcs, pages 48:1–48:11. Schloss Dagstuhl -\nLeibniz-Zentrum f¨ ur Informatik, 2016. doi:10.4230/LIPICS.ESA.2016.48 .\n[HSSY24] Monika Henzinger, Barna Saha, Martin P. Seybold, a nd Christopher Ye. On the\ncomplexity of algorithms with predictions for dynamic grap h problems. In 15th\nInnovations in Theoretical Computer Science Conference, ITCS 2024 , volume 287\nofLIPIcs, pages 62:1–62:25. Schloss Dagstuhl - Leibniz-Zentrum f¨ u r Informatik,\n2024.doi:10.4230/LIPICS.ITCS.2024.62 .\n[IEWM23] Taisuke Izumi, Yuval Emek, Tadashi Wadayama, and T oshimitsu Masuzawa. De-\nterministic fault-tolerant connectivity labeling scheme . InProceedings of the 2023\nACM Symposium on Principles of Distributed Computing, PODC , pages 190–199.\nACM, 2023. doi:10.1145/3583668.3594584 .\n[JX22] Ce Jin and Yinzhan Xu. Tight dynamic problem lower bou nds from generalized\nBMM and omv. In STOC ’22: 54th Annual ACM SIGACT Symposium on Theory\nof Computing , pages 1515–1528. ACM, 2022. doi:10.1145/3519935.3520036 .\n[KBC+18] TimKraska, Alex Beutel, Ed H. Chi,Jeﬀrey Dean, and Neokli s Polyzotis. Thecase\nfor learned index structures. In Proceedings of the 2018 International Conference\non Management of Data, SIGMOD Conference 2018 , pages 489–504. ACM, 2018.\ndoi:10.1145/3183713.3196909 .\n[KKM13] Bruce M. Kapron, Valerie King, and Ben Mountjoy. Dyn amic graph connectivity\nin polylogarithmic worst case time. In Proceedings of the Twenty-Fourth Annual\nACM-SIAM Symposium on Discrete Algorithms, SODA 2013 , pages 1131–1142.\nSIAM, 2013. doi:10.1137/1.9781611973105.81 .\n[Kos23] Evangelos Kosinas. Connectivity queries under ver tex failures: Not optimal, but\npractical. In 31st Annual European Symposium on Algorithms, ESA 2023 , volume\n274ofLIPIcs,pages75:1–75:13. SchlossDagstuhl-Leibniz-Zentrumf¨ u rInformatik,\n2023.doi:10.4230/LIPIcs.ESA.2023.75 .\n[KPP16] Tsvi Kopelowitz, Seth Pettie, and Ely Porat. Higher lower bounds from the\n3SUM conjecture. In Proceedings of the Twenty-Seventh Annual ACM-SIAM\nSymposium on Discrete Algorithms , SODA 2016, page 1272–1287. SIAM, 2016.\ndoi:10.1137/1.9781611974331.ch89 .\n[LLW22] Honghao Lin, Tian Luo, and David P. Woodruﬀ. Learning augmented binary\nsearch trees. In International Conference on Machine Learning, ICML 2022 , vol-\nume 162 of Proceedings of Machine Learning Research , pages 13431–13440. PMLR,\n2022. URL: https://proceedings.mlr.press/v162/lin22f.html .\n[LM22] Alexander Lindermayr and Nicole Megow. Algorithms w ith predictions.\nhttps://algorithms-with-predictions.github.io , 2022. Accessed 8 Septem-\nber 2023.\n15\n\n[LS22] Yaowei Long and Thatchaphol Saranurak. Near-optima l deterministic vertex-\nfailure connectivity oracles. In 63rd IEEE Annual Symposium on Foun-\ndations of Computer Science, FOCS 2022 , pages 1002–1010. IEEE, 2022.\ndoi:10.1109/FOCS54457.2022.00098 .\n[LS24] Quanquan C. Liu and Vaidehi Srinivas. The predicted- updates dynamic model:\nOﬄine, incremental, and decremental to fully dynamic trans formations. In The\nThirty Seventh Annual Conference on Learning Theory, COLT 2024 , Proceedings\nof Machine Learning Research. PMLR, 2024.\n[LW24] Yaowei Long and Yunfan Wang. Better decremental and f ully dynamic sensitivity\noracles for subgraph connectivity. In 51st International Colloquium on Automata,\nLanguages, and Programming, ICALP 2024 , LIPIcs. Schloss Dagstuhl - Leibniz-\nZentrum f¨ ur Informatik, 2024.\n[MV20] Michael Mitzenmacher and Sergei Vassilvitskii. Alg orithms with predictions. In\nTim Roughgarden, editor, Beyond the Worst-Case Analysis of Algorithms , pages\n646–662. Cambridge University Press, 2020. doi:10.1017/9781108637435.037 .\n[MV22] Michael Mitzenmacher and Sergei Vassilvitskii. Alg orithms with predictions. Com-\nmun. ACM , 65(7):33–35, 2022. doi:10.1145/3528087 .\n[Pel05] David Peleg. Informative labeling schemes for grap hs.Theor. Comput. Sci. ,\n340(3):577–593, 2005. doi:10.1016/J.TCS.2005.03.015 .\n[PP22] Merav Parter and Asaf Petruschka. ˜Optimal dual vertex failure connectivity labels.\nIn36th International Symposium on Distributed Computing, DISC , volume 246 of\nLIPIcs, pages 32:1–32:19. Schloss Dagstuhl - Leibniz-Zentrum f¨ u r Informatik, 2022.\ndoi:10.4230/LIPICS.DISC.2022.32 .\n[PPP24] Merav Parter, Asaf Petruschka, and Seth Pettie. Con nectivity labeling and\nrouting with multiple vertex failures. In Proceedings of the 56th Annual ACM\nSymposium on Theory of Computing, STOC 2024 , pages 823–834. ACM, 2024.\ndoi:10.1145/3618260.3649729 .\n[PSS+22] Michal Pilipczuk, Nicole Schirrmacher, Sebastian Sieb ertz, Szymon Torunczyk,\nand Alexandre Vigny. Algorithms and data structures for ﬁrs t-order logic\nwith connectivity under vertex failures. In 49th International Colloquium on\nAutomata, Languages, and Programming, ICALP 2022 , volume 229 of LIPIcs,\npages 102:1–102:18. Schloss Dagstuhl - Leibniz-Zentrum f¨ ur Informatik, 2022.\ndoi:10.4230/LIPIcs.ICALP.2022.102 .\n[PT07] Mihai P˘ atra¸ scu and Mikkel Thorup. Planning for fas t connectivity updates. In\n48th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2007) ,\npages 263–271. IEEE Computer Society, 2007. doi:10.1109/FOCS.2007.54 .\n[vdBFNP24] Jan van den Brand, Sebastian Forster, Yasamin Na zari, and Adam Polak. On\ndynamic graph algorithms with predictions. In Proceedings of the 2024 ACM-\nSIAM Symposium on Discrete Algorithms (SODA) , pages 3534–3557. SIAM, 2024.\ndoi:10.1137/1.9781611977912.126 .\n[vdBS19] Jan van den Brand and Thatchaphol Saranurak. Sensi tive distance and reachabil-\nity oracles for large batch updates. In 60th IEEE Annual Symposium on Founda-\ntions of Computer Science, FOCS , pages 424–435. IEEE Computer Society, 2019.\ndoi:10.1109/FOCS.2019.00034 .\n16\n\n[WX20] Virginia Vassilevska Williams and Yinzhan Xu. Monoc hromatic triangles,\ntriangle listing and APSP. In 61st IEEE Annual Symposium on Foun-\ndations of Computer Science, FOCS 2020 , pages 786–797. IEEE, 2020.\ndoi:10.1109/FOCS46700.2020.00078 .\n17",
  "textLength": 51907
}