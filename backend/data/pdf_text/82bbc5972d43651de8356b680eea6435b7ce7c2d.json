{
  "paperId": "82bbc5972d43651de8356b680eea6435b7ce7c2d",
  "title": "AirIndex: Versatile Index Tuning Through Data and Storage",
  "pdfPath": "82bbc5972d43651de8356b680eea6435b7ce7c2d.pdf",
  "text": "AirIndex : Versatile Index Tuning Through Data and Storage\nSupawit Chockchowwat, Wenjie Liu, Yongjoo Park\n{supawit2,wenjie3,yongjoo}@illinois.edu\nCreateLab, University of Illinois at Urbana-Champaign\nABSTRACT\nThe end-to-end lookup latency of a hierarchical indexâ€”such as a\nB-tree or a learned indexâ€”is determined by its structure such as the\nnumber of layers, the kinds of branching functions appearing in\neach layer, the amount of data we must fetch from layers, etc. Our\nprimary observation is that by optimizing those structural parame-\nters (or designs ) specifically to a target systemâ€™s I/O characteristics\n(e.g., latency, bandwidth), we can offer a faster lookup compared\nto the ones that are not optimized. Can we develop a systematic\nmethod for finding those optimal design parameters? Ideally, the\nmethod must have the potential to generate almost any existing\nindex or a novel combination of them for the fastest possible lookup.\nIn this work, we present a new data-and-I/O-aware index builder\n(called AirIndex ) that can find high-speed hierarchical index de-\nsigns in a principled way. Specifically, AirIndex minimizes an\nobjective expressing the end-to-end latency in terms of various\ndesigns â€”the number of layers, types of layers, and moreâ€”for given\ndata and a storage profile , using a graph-based optimization method\npurpose-built to address the computational challenges rising from\nthe inter-dependencies among index layers and the exponentially\nmany candidate parameters in a large search space. Our evaluations\nconfirm that AirIndex can find optimal index designs, build them\nwithin the times comparable to existing methods, and deliver up to\n4.1Ã—faster lookup than a lightweight B-tree library ( LMDB ),3.3Ã—â€“\n46.3Ã—faster than state-of-the-art learned indexes ( RMI/CDFShop ,\nPGM-index ,ALEX/APEX ,PLEX ), and 2.0Ã—faster than Data Cal-\nculator â€™s suggestion on various dataset and storage settings.\nACM Reference Format:\nSupawit Chockchowwat, Wenjie Liu, Yongjoo Park. 2024. AirIndex : Versa-\ntile Index Tuning Through Data and Storage. In Proceedings of ACM SIG-\nMOD/PODS International Conference on Management of Data (SIGMOD â€™24).\nACM, New York, NY, USA, 18 pages. https://doi.org/XXXXXXX.XXXXXXX\n1 INTRODUCTION\nHierarchical indexes (e.g., binary search tree, B-tree) allow us to\nquickly locate a relevant item by fetching (only) a small fraction of\ndata inside each index layer. The B-tree [ 17,19,25,72] has been a\nconventional choice for many data systems such as PostgreSQL [ 56],\nMySQL [ 8], ZLog [ 7], BTRFS [ 58], etc. More recently, it has been\nshown that by using learned models (i.e., regression functions of-\nfering approximate pointers) in place of the (exact) child pointers\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\nÂ©2024 Association for Computing Machinery.\nACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00\nhttps://doi.org/XXXXXXX.XXXXXXXFast SlowSmallLarge\nTall &\nNarrowShallow\n& Wide\nLocal SSD\nCloud Storage\nLatency (RTT)Bandwidth\nFigure 1: Expected optimal structures by I/O characteristics.\nAirIndex finds the optimal structure in a large design space.\ninside a B-treeâ€™s internal nodes, we can reduce the amount of data\nwe need to fetch for each layer, lowering the overall lookup la-\ntency [ 31,33,41,43,50]. In general, the amount of data indicated\nby those exact/approximate branching pointersâ€”along with the\nnumber of layersâ€”determine the overall lookup latency of an index.\nDespite their effectiveness, (most) existing indexes have a com-\nmon limitation, making them often suboptimal for novel system\nenvironments with different I/O characteristics. That is, due to their\nnearly fixed index structures (e.g., the number of layers, the types of\nlayers), existing indexes cannot deliver as fast performance as the ones\nspecifically designed in consideration of the data access cost of a target\nsystem environment. For instance, in Figure 1, if an index is main-\ntained directly on remote storage with relatively high I/O latency\n(e.g., in cloud systems like Amazon Aurora [ 67] and Delos [ 16]),\nwe might be able to achieve faster lookup speeds by creating a\nwider/shallower index (e.g., larger fanout in B-trees, more accu-\nrate models in learned indexes), mitigating the impact of high I/O\nlatency with fewer data fetches required for index traversal. In con-\ntrast, if an index is maintained on a local SSD (e.g., SQLite [ 63]) with\nfast I/O latency (or relatively smaller bandwidth), we can create\na narrower/taller index (e.g., smaller fanout in B-trees, less accu-\nrate models in learned indexes) for faster lookup. In other words,\ndepending on a different system environment, an optimal index\nstructure may vary, causing significant performance gaps between\nfixed index structures and the ones adapting to target environments\n(Â§2). This observation closely resembles the one made by Gray and\nGraefe [ 36] for determining an optimal B-tree page size in relation\nto page access cost. However, its utility-based approach is specific to\nconventional indexes with exact child pointers, meaning it cannot\nbe generalized to a wider class of indexes with learned models.\nIn this work, we tackle this limitation with AirIndex , a general\nindex-building framework that can efficiently find an (optimal) low-\nlatency index structure in consideration of profiled I/O characteristics\nas well as data distribution. The core difference of AirIndex is that\nit can balance the properties of all the layers simultaneously (in-\ncluding their total count) to optimize the expected (cache-aware)\nend-to-end latency by solving a mathematical optimization problem.\nDuring the optimization, AirIndex considers many different de-\nsign choices (e.g., the number of layers, fanout, model types, modelarXiv:2306.14395v3  [cs.DB]  1 Sep 2023\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\nTable 1: Summary of existing work. â–²/âœ—indicates limited/no support.\nMethod Approx. Pointer? I/O Aware? Novelty Weakness/Difference\nB-trees [17, 25] âœ— âœ— First B-tree proposal No search for optimal fanout\nRMI [45] âœ” âœ— First approximate branching No hyperparameter tuning, fixed two-layer structure\nALEX/APEX [30] âœ” âœ— Updatable with learned models No optimization for end-to-end latency\n5minRules [36] âœ— âœ” Heuristic for B-tree page size Restricted tuning, fixed branching across layers\nCDFShop [53] âœ” âœ— Searches Pareto efficient RMIs Inconclusive tuning, not optimize for latency\nData Calculator [38] â–² âœ” Evaluates end-to-end performance Inefficient tuning, restricted branching functions\nOurs ( AirIndex ) âœ” âœ” I/O-aware exact/approx. layers Optimization focuses on lookup than updates\nsize/accuracy), often producing a heterogeneous index consisting\nof different types of layers: an index may have a B-tree-like design\nfor one layer and a model-based design for another layer. While\nthe primary contribution of AirIndex is demonstrating significant\nimprovements in lookup speeds enabled by its principled search\ntechnique, its approach can easily integrate with existing orthogo-\nnal work (e.g., ALEX [ 31]) to allow insert/delete without complete\nreconstruction. To our knowledge, no previous work has formally\nstudied an efficient search technique for optimizing the entire index\nstructure in consideration of I/O performance and has evaluated its\npractical performance benefits with comprehensive experiments.\nChallenge. The core challenge in finding an optimal index struc-\nture is the lack of an efficient mechanism that can compare the\nquality of exponentially many candidate structures. For example,\nwe need to consider indexes with different heights (i.e., 1, 2, ...); for\nan index of height ğ¿, there areğ¿layers to build; and for each layer,\nwe need to compare various branching functions (e.g., B-tree-like\nchild pointers, regression-based learned models). Moreover, the\ndesign decision we make for layers are dependent on one another;\nthat is, if we alter the design of a layer, it affects the other compo-\nnents that depend on this layer (i.e., all the other layers on top of it)\ndue to the inherent nature of hierarchical indexes, complicating the\nsearch process. Finally, we must be able to evaluate the goodness of\neach index for (arbitrary) target storage media.\nOur Approach. AirIndex can be understood as a search pro-\ncess ( AirTune ) inside a high-dimensional design space consist-\ning of exponentially many feasible candidate structures. Each\n(entire) candidate structure is a model: We mathematically rep-\nresent each candidate structure using a unified index model (called\nAirIndex-Model ), a high-level abstraction that expresses diverse\nhierarchical indexes parametrically L(ğš¯), where ğš¯=(Î˜1,...,Î˜ğ¿)\nare layer-specific design parameters (such as fanout, model accu-\nracy/size), andL(ğš¯)is the (cache-aware) end-to-end lookup la-\ntency (i.e., cumulative time for traversing the index). That is, given\na parameter set ğš¯, there exists an associated physical index; and\nthe index takesL(ğš¯)time for finding a relevant item via traver-\nsal (thus, the lower the better). Search: Our key contribution\nis an efficient search algorithm for finding an optimal design ğš¯âˆ—\nat whichL(ğš¯)has the smallest value. Since the design includes\nboth numeric and categorical values, gradient-descent-like opti-\nmization algorithms are inapplicable. We devise a novel algorithm\nby translating our problem into a graph traversal; that is, each de-\nsign represents a vertex (or state) in the search space and an edge is\ndrawn from ğš¯ğ´toğš¯ğµifğš¯ğµis immediately reachable from ğš¯ğ´bystacking another layer on top. While our algorithm involves actual\nindex constructionâ€”because for some types of layers, their quality\ndepends on data distribution requiring actual constructionâ€”our\nalgorithm can quickly find ğš¯âˆ—with bounded time by avoiding visits\nto the (low-quality) states unlikely to reach an optimal one.\nOrthogonal Work. Database research has a long history in index\ndesign such as (1) leveraging the properties of emerging hardware,\n(2) employing machine learning for compact layers, and (3) target-\nting for different data layouts. We summarize more closely related\nwork in Table 1 while providing comprehensive discussions in Â§8.\nOur work is largely orthogonal to those existing work because we\ndo not propose a new type of index per se; instead, we study how\nto combine existing techniques under a unified framework to build\nan index specifically tuned for target I/O characteristics.\nContribution. In this work, we make the following contributions:\n(1)We illustrate the significance of optimizing indexes with both\ndata and storage (Â§2).\n(2)We formulate the index optimization as a search for the optimal\ndesign parameters of a unified index model (Â§4).\n(3) We design an efficient graph-based search method (Â§5).\n(4)We empirically study AirIndex with various datasets and stor-\nage and show that AirIndex can offer up to 2.0Ã—â€“46.3Ã—faster\nlookup speed compared to state-of-the-art methods (Â§7).\nFinally, Â§8 discusses related work, and Â§9 concludes this work.\n2 MOTIVATION\nWe present why we need a new index builder that considers the\nend-to-end lookup latency (Â§Â§ 2.1 to 2.3).\n2.1 Need for I/O-Aware Optimization\nIn this section, we motivate the need for environment-specific index\noptimization with concrete examples showing there is no single\ndominant index structure (e.g., B-trees with fixed fanout) that can\noffer superior performance for all system environments.\nExample. We have two candidate B-tree structures: B200 and\nB5000 (Note: special cases of AirIndex-Model ).B200 consists of 4\nKB nodes, each with 200 fanout. B5000 consists of 100 KB nodes,\neach node with 5,000 fanout. Both B200 andB5000 index the same\ndataset with one million distinct keys, stored in 4 KB pages.\nTo index the dataset, B200 needs three layers (because the third\nlayer can hold up to 2003=8ğ‘€pointers). Likewise, B5000 needs\ntwo layers (because the second layer can hold up to 50002=25ğ‘€\npointers). Note that while B5000 is shallower than B200 , fetching\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\nÂ·Â·Â·\nÂ·Â·Â·Â·Â·Â·\nData Layer (1M records)\n(a)B200: B-tree with 200 child pointersÂ·Â·Â·\nData Layer (1M records)\n(b)B5000 : B-tree with 5,000 child pointersSSD CloudStorage0.511.52Relative LatencyB200 B5000\n(c) Lookup Speed Comparison\nFigure 2: Need for I/O-aware Optimization. Depending on system environments ( SSDand CloudStorage ), employing different\nB-tree designs ( B200 and B5000 ) achieve higher expected performance in end-to-end lookup latency.\nStep\nStep\nData16KB\n16KB16KB\n(a) Tuned B-treePWL\nPWL\nData8KB\n10KB96B\n(b) Tuned PWL IndexStep\nPWL\nData4KB\n2KB3KB\n(c)AirIndex(a) (b) (c)05001,0001,500Latency (ğœ‡s)Data Layer 1 Root\n(d) Lookup Speed Comparison\nFigure 3: Indexes built for gmmdataset stored on SSD (250 ğœ‡s latency, 175MB/s bandwidth) and their estimated latency. Bold\nnumbers show the average read sizes of components in a query: root layer, partial first index layer, and partial data layer.\neach node of B5000 takes longer because its page size is 25 Ã—larger.\nFigures 2a and 2b depict these structures.\nInterestingly, neither of these two indexes (i.e., B200 andB5000 )\nis superior to the other, if we compare their lookup latencies based\non a widely used formula: (data transfer time) =(latency) + (data\nsize) / (bandwidth); that is, (1) B200 offers higher performance than\nB5000 if we store data on SSD having 100 ğœ‡s latency and 1 GB/s\nbandwidth, and that (2) B5000 offers higher performance than B200\nif we store data on CloudStorage having 100 ms latency and 100\nMB/s bandwidth. Specifically, inSSD,B5000 is 21% slower than\nB200 because B200 needs to retrieve 3 nodes and 1 data page, taking\n416ğœ‡s (= 3Ã—(100ğœ‡s + 4KB / (1GB/s)) + (100 ğœ‡s + 4KB / (1GB/s)) )\nwhile B5000 needs to retrieve 2 nodes and 1 data page, taking 504\nğœ‡s (= 2Ã—(100ğœ‡s + 100KB / (1GB/s)) + (100 ğœ‡s + 4KB / (1GB/s)) ). In\ncontrast, inCloudStorage ,B200 is 32% slower than B5000 with B200\ntaking 400.16 ms and B5000 taking 302.04 ms. Figure 2c summarizes\nthis relative performance strength. For each environment, the figure\nreports the relative difference in end-to-end lookup time. This shows\nthat different index structures offer higher lookup performance,\ndepending on the storage device.\n2.2 Need for Layer-Wise Optimization\nIn this section, we explain why we need to consider different types\nof branching functions for different layers. That is, a homogeneous\nindexâ€”consisting of the same type of layersâ€”may offer poorer\nperformance even with careful tuning in comparison to a tuned\nheterogeneous indexâ€”consisting of different types of layers.\nGeneral Lookup Process. In general, we can consider a lookup\nprocess with a hierarchical index as a series of data fetch operations\nthat proceed as follows: the root (or the ğ‘–-th) layer is fetched, based\non which we determine what data we need to fetch in the next\n(or the(ğ‘–âˆ’1)-th) layer. This iteration repeats until we reach the\ndata layer. This means that in each layer, we can use any type of\nmonotonically increasing function (with respect to search keys)that can tell us what data we need to fetch in the subsequent layer.\nFor example, a B-tree layer has a property such that for all the keys\nbetween two adjacent separators, we get the same child pointer (or\nthe same range of data we need to fetch), which can be expressed\nas a step function that jumps at separators. This gives rise to our\nunified index model ,AirIndex-Model , allowing different types of\nbranching functions in different layers (Â§4).\nFormally, we express such a design space with Î˜ğ‘™forğ‘™-th layer,\nandğš¯=(Î˜1,...,Î˜ğ¿)describes an entire index design. The follow-\ning examples demonstrate that by allowing Î˜ğ‘–â‰ Î˜ğ‘—forğ‘–â‰ ğ‘—, we\ncan construct an index with lower end-to-end latency.\nConcrete Example. Suppose two types of branching functionsâ€”\nstep functions (Step) appearing in B-trees and piece-wise linear\nfunctions (PWL) employed in RMI [ 45]. Formally, a step function\nis ağ‘-piece constant function that Ë†ğ‘¦step(ğ‘¥)=[ğ‘ğ‘–,ğ‘ğ‘–+1), while a\nPWL is ağ‘-piece band function (widen linear functions) Ë†ğ‘¦PWL(ğ‘¥)=\n[ğ‘šğ‘–ğ‘¥+ğ‘ğ‘–âˆ’ğ›¿ğ‘–,ğ‘šğ‘–ğ‘¥+ğ‘ğ‘–+ğ›¿ğ‘–)forğ‘¥âˆˆ[ğ‘ğ‘–,ğ‘ğ‘–+1). We present a case where\nby combining Step and PWL, we can build a higher-performing\nindex than the ones solely comprising Step or PWL, respectively.\nFirst, we construct an optimal B-tree index (Figure 3a) by com-\nparing the latencies of multiple B-trees with different node sizes\n(100 bytesâ€“10 MB): for the dataset we use, 16KB nodes offer the\nfastest lookup. In Figure 3d, we show the costs of index traversal\nto fetch each layer from the root to the data layer to find the rele-\nvant key-value; For the tuned B-tree, the end-to-end latency takes\nslightly longer than 1,000 ğœ‡s. Likewise, we construct an optimal\nindex solely consisting of PWL layers (Figure 3b). The dataset we\nconsider has its keys distributed favorably for PWL; thus, we need\nsmaller layers than the optimal B-tree, needing to fetch 96B for the\nroot, 8KB for Layer 1, and 10KB for the data layer. Accordingly, the\noverall latency shown in Figure 3d is also lower than the B-tree.\nIn contrast, by combing Step and PWL, we can discover an in-\ndex (denoted by AirIndex ) with significantly more compact layers\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\nLookup (Â§4.2)Storage\nLayer\nInterfaceAirTune (Â§5)Storage\nLayer\n(e.g., SSD,\nNFS)AirIndexclient\nFigure 4: AirIndex Architecture. AirIndex manages indexes\non Storage Layer (e.g., SSD, NFS, cloud storage APIs) via its\nStorage Layer Interface that abstracts read/write operations.\noverall (Figure 3c). Specifically, while AirIndex â€™s root layer is big-\nger in size compared to the tuned PWL index, it allows fetching\nsignificantly smaller amounts of data for the other layers (i.e., Layer\n1 and the data layer), lowering the end-to-end latency. In theory, an\noptimal index with heterogeneous layers is guaranteed to deliver\nperformance not worse than the optimal index with homogeneous\nlayers. Nevertheless, the amount of improvement we can offer with\nlayer-wise optimization well compensates for the increase in search\neffort, as we demonstrate with more empirical results in Â§7.\n2.3 Need for Novel Index Tuning\nNew Search Space. Because of the new connection between ma-\nchine learning and indexing [ 45], the search space has grown ex-\nponentially, including models types (e.g., linear models to neural\nnetworks) as well as their parameters (e.g., regression coefficients,\nweights), hyperparameters (e.g., fitting methods, regularization\nweights), and error correction algorithm (i.e., last mile search). The\nsearch space expands exponentially as each index sub-structure,\nlike layer or node, can choose its model design individually.\nLack of Predictability. Unlike traditional indexes, learned indexes\nhave an unpredictable performance before fitting them to the data,\nwhich consequently increases tuning costs. While we can rigorously\nanalyze some traditional indexes like B-trees [ 17,25] and skip-\nlists [ 57] to predict their worst-case or average-case performance\ngiven a set of hyperparameters (e.g., fanout, level fraction, key prefix\nsize), analyzing learned indexes and learned models is much more\nchallenging because: (1) learning performance depends on non-\ntrivial statistics of dataset, in which the dependency may not yet\nbe explainable, (2) learned models often comprise of many learning\ncomponents whose existing theories may not combine together,\nand (3) learning may unreliably produce poorly fitted models due\nto randomization or numerical instability. As a result, learned index\ntuning needs to pay the price to fit models or restrict the search\nspace to a limited set of well-understood learned models.\nExisting Tuningâ€™s Limitations. Existing tuning methods are ei-\nther restricted, inconclusive, or inefficient. Traditional tuners like\n[36] only apply to restricted sets of indexes prior to learned in-\ndexes, missing opportunities to fit better to data patterns and so\nsave lookup latency. On the other hand, many existing learned\nindex tuners inconclusively recommend many index designs, for\nexample, CDFShop [53] finds many Pareto efficient RMIs while\nPGM-index [33] and PLEX [64] reduce their parameters into fewer\nhyperparameter(s), delegating selection or hyperparameter tuning\nto their users. Lastly, naÃ¯ve methods such as brute-force search,\ngrid search, or binary search incur large overheads due to excessive\nfitting or multiple sequential passes on the full dataset. Later, ourTable 2: Notations and their meaning.\nInput to AirIndex\nğ‘¥ Key\nğ‘¦=[ğ‘¦âˆ’,ğ‘¦+)Position (range) on storage\nğ· Key-position dataset\nğ‘‡(Î”) Storage profile, time to read Î”bytes from storage\nDesign Parameters (Â§4)\nğ¿ Number of index layers\nğš¯ Parameters across all index layers\nÎ˜ğ‘™ Parameters describing the ğ‘™-th index layer\nğ‘ (Î˜ğ‘™) Size of theğ‘™-th index layer\nÎ”(ğ‘¥;Î˜ğ‘™) Read size ofğ‘¥predicted byğ‘™-th index layer\nÎ”(ğ·;Î˜ğ‘™) Average read size over keys in dataset ğ·\nË†ğ‘¦=[Ë†ğ‘¦âˆ’,Ë†ğ‘¦+)A predicted position on storage\nLğ‘†ğ‘€ Index lookup cost from storage model\nSearch Process (Â§5)\nğ¹âˆˆF Node builder mapping a ğ·into aÎ˜\nğ‘˜ Number of top candidates to branch out\n1+ğœ– exponential base for granularity exponentiation\nğœ†ğ‘™ğ‘œğ‘¤,ğœ†â„ğ‘–ğ‘”â„ Bounds for granularity exponentiation\nğœ(ğ·) Index complexity, the ideal index lookup cost\nË†ğœ(ğ·) Step index complexity, an upper bound to ğœ(ğ·)\nexperiments (Â§7.5) verify that these existing methods find subopti-\nmal indexes and incur large tuning overheads. Therefore, a novel\nindex tuning is needed to identify the optimal learned index from a\nmuch larger search space by efficiently balancing learning costs.\n3 SYSTEM OVERVIEW\nWe describe AirIndex â€™s core components (Â§3.1) and a storage pro-\nfile representing I/O performance (Â§3.2).\n3.1 Architecture\nAirIndex is an index library for sorted key-value data stored on\na Storage Layer (e.g., SSD, NFS). AirIndex can work with various\nstorage devices by extending its storage interface. AirIndex stores\nindexes together with the data on Storage Layer while part of them\nmay be cached. Internally, AirIndex consists of three componentsâ€”\nLookup, Builder, and Storage Layer Interfaceâ€”as depicted in Fig-\nure 4. First, Storage Layer Interface provides the consistent ab-\nstraction over different storage interfaces/devices (e.g., virtual file\nsystems (VFS), over SSD or object storage, cloud storage services)\nsuch as creating files and reading/writing serialized objects. Based\non this consistent interface, we can profile the time needed to read\nÎ”bytes (Â§3.2). Second, Lookup provides a querying interface. Given\na key, the module traverses an index as it fetches necessary data\n(e.g., ranges within index layers) if not cached, caches the fetched\ndata if space is available (Â§4), and makes inferences on what data it\nneeds to fetch next (Â§4.2), until it finds the value associated with\nthe key (or if finds there are no such keys indexed). Finally, Builder\nfinds optimal index designs and builds/stores actual indexes on\nstorage (Â§Â§ 5.1 to 5.3). How Builder finds high-quality index designs\nefficiently is the key contribution of this work.\n3.2 Storage Model\nAirIndex relies on storage performance profile ğ‘‡(Î”), which rep-\nresents the time taken for the storage layer to read consecutive\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\n... ...\n... ...\nÎ”(ğ‘¥;Î˜ğ‘™)ğ‘ (Î˜ğ‘™)ğ¿-th Layer\nData (0th Layer)1st Layer2nd Layer\n...DeriveLookup\nFigure 5: A hierarchical index of ğ¿layers. The ğ‘™-th layer looks\nup the data in the (ğ‘™âˆ’1)-th layer. The close-up diagram lay-\nouts key-value pairs (ellipses) stored in pages. It shows layerâ€™s\nsizeğ‘ (Î˜ğ‘™)and precision Î”(ğ‘¥;Î˜ğ‘™)of a key whose node on ğ‘™-th\nlayer and relevant key-value on (ğ‘™âˆ’1)-th are colored.\ndata of size Î”bytes. Considering that the read time Tis proba-\nbilistic (e.g., due to variability, system loads, access paths, address\nalignment, lower-level optimizations), AirIndex is interested in\nthe conditional expectation ğ‘‡(Î”)=E[T|Î”]. For example, ğ‘‡(Î”)\ncan be an affine function ğ‘‡aff(Î”)=â„“+Î”/ğµwith latency â„“and\nbandwidth ğµ. If the latency and bandwidth uniformly varies in\n[â„“0,â„“1]and[ğµ0,ğµ1], after calculating the expectation, the storage\nprofile becomes ğ‘‡aff-uniform(Î”)=â„“1+â„“0\n2+Î”(lnğµ1âˆ’lnğµ0)\nğµ1âˆ’ğµ0. While we\nimplement the affine storage model ğ‘‡aff(Î”)parameterized by â„“and\nğµ, our optimization works with any monotonically increasing ğ‘‡(Î”).\nCurrently, we consider a deterministic and time-independent\nğ‘‡(Î”), summarizing over other variables that are unnecessary for\nindex tuning. Future directions can extend ğ‘‡(Î”)from a determin-\nistic function to a distribution conditioned on the read size Î”to\nincorporate the randomness. Such storage models would enrich\nAirIndex to tune on more complex goals such as fastest tail latency\n(e.g., lowest p99) or highest reliability (e.g., lowest latency variance).\n3.3 Points of Applications\nAirIndex applies to any index building in a system life cycle when\nlookup operations from storage need to be performant. AirIndex\nprimarily aims for two types of applications. (1) Immutable indexesâ€™\nbulk loading: AirIndex naturally builds high-speed indexes that do\nnot change; nonetheless, the application can still support changing\ndata with existing techniques such as gapped arrays and LSM-tree\ncompaction. (2) Updatable indexesâ€™ initial design and maintenance:\nusers can utilize AirIndex to build the initial index structure, then\nfollow any updatable index protocol compatible with the structure.\nAfter the index has mutated significantly, users can re-build the\nindex using AirIndex as a part of vacuum processes.\nAirIndex incurs computation overhead but is designed to mini-\nmize its real-time overhead. Although not required, a system with\nhigh parallelism is preferable. Alternatively, users can trade off\ntuning accuracy for an overhead reduction through configurations.\n4AIRINDEX-MODEL : UNIFIED INDEX MODEL\nIn this section, we mathematically model hierarchical indexes by\nrepresenting them with design parameters ğš¯, which are also used\nto express their lookup latencies. These mathematical models are\nthe foundations of our optimization process described in Â§5.\nFigure 6: Two node types with key-position examples. Left:\n5-piece step. Right: band with points and width.\n4.1 Hierarchical Indexes\nA hierarchical index is a data structure that maintains data locations\nin a layered internal structure, consisting of explicit ğ¿index layers â€”\nğ¼1,ğ¼2,...ğ¼ğ¿. Here,ğ¼ğ¿refers to the root and ğ¼1refers to the bottom-\nmost one, next to the data layer denoted ğ¼0. A data system can\nquery a hierarchical index for the location of a desired item, then\nretrieve the item from the location. Accordingly, a high-quality\nindex must quickly find the location in a database, namely, key-\nposition collection ğ·={(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›\nğ‘–=1, whereğ‘¥ğ‘–is theğ‘–-th key with\ndata on a position ğ‘¦ğ‘–=ğ‘¦(ğ‘¥ğ‘–)=[ğ‘¦âˆ’(ğ‘¥ğ‘–),ğ‘¦+(ğ‘¥ğ‘–))(i.e. range of data).\nIndex Layer. Given a key, an index layer points to a range of data\n(in the next layer) that contains the information associated with\nthe key. The system then can read the range of data from the next\nlayer, and continues the index traversal until it reaches the data\nlayer. To support partial reads, an index layer consists of one or\nmore nodes ; for a specific key, there is only one node associated\nwith it. Conceptually, a node is a function from a key to its position\n(as defined shortly), and an index layer is a piecewise function\ncomprising its node functions. This composite structure enables\npartial data reads and lower data access costs.\nNode. A node is the smallest data structure that maps a key to its\nposition in the next layer. Given a key ğ‘¥, a node predicts a position\nË†ğ‘¦:Xâ†’Y in range that encompasses the actual position ğ‘¦(ğ‘¥).\nNode Ë†ğ‘¦:Ë†ğ‘¦(ğ‘¥)=[Ë†ğ‘¦âˆ’(ğ‘¥),Ë†ğ‘¦+(ğ‘¥))âŠ‡[ğ‘¦âˆ’(ğ‘¥),ğ‘¦+(ğ‘¥))=ğ‘¦(ğ‘¥)(1)\nWhile our optimization framework can support any such func-\ntion Ë†ğ‘¦that satisfies Eq (1), AirIndex currently implements two\ntypes of nodes sketched in Figure 6. First, a step node ( step ) is a\nstep function, or a ğ‘-piece constant function parameterized by par-\ntition keys a=(ğ‘1,...,ğ‘ğ‘)and partition positions b=(ğ‘1,...,ğ‘ğ‘).\nIn other words, Ë†ğ‘¦step(ğ‘¥;a,b)=[ğ‘ğ‘–,ğ‘ğ‘–+1)forğ‘¥âˆˆ [ğ‘ğ‘–,ğ‘ğ‘–+1). Sec-\nond, a linear band node ( band ) is a thick linear function travel-\ning through two key-position points (ğ‘¥1,ğ‘¦1)and(ğ‘¥2,ğ‘¦2)with\na widthğ›¿:Ë†ğ‘¦band(ğ‘¥;ğ‘¥1,ğ‘¦1,ğ‘¥2,ğ‘¦2,ğ›¿)=[ğ‘šğ‘¥+ğ‘âˆ’ğ›¿,ğ‘šğ‘¥+ğ‘+ğ›¿)\nwhereğ‘š=(ğ‘¦2âˆ’ğ‘¦1)/(ğ‘¥2âˆ’ğ‘¥1)andğ‘=ğ‘¦1âˆ’ğ‘šğ‘¥1. A step node\nis16ğ‘bytes in size while a linear band node is 40bytes. For exam-\nple, consider a dataset with 4 key-position pairs: ğ·={(ğ‘¥,ğ‘¦)}=\n{(1,[0,10)),(4,[10,20)),(5,[20,25)),(7,[25,35))}as in Figure 6. A\nstep node can represent this key-position collection with ğ‘=5,\na=(1,4,5,7,âˆ), and b=(0,10,20,25,35), guaranteeing the exact\nprediction Ë†ğ‘¦step(ğ‘¥;a,b)=ğ‘¦for all(ğ‘¥,ğ‘¦)âˆˆğ·. Note that a step\nnode having fewer pieces can be valid but would have a higher er-\nror. Alternatively, a band node can approximately represent ğ·with\n(ğ‘¥1,ğ‘¦1)=(1,0),(ğ‘¥2,ğ‘¦2)=(4,10),ğ›¿=15. We encourage readers to\nverify that Ë†ğ‘¦band(ğ‘¥; 4,0,7,25,35)âŠ‡ğ‘¦for all(ğ‘¥,ğ‘¦)âˆˆğ·.\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\nAlgorithm 1: AirIndex Query Process, Lookup(ğ‘¥;Ë†ğ‘¦ğ¿,ğ¿)\nInput: Query keyğ‘¥, root position Ë†ğ‘¦ğ¿, number of layers ğ¿\nOutput: Relevant key-value (ğ‘¥,ğ‘£)\n1forğ‘™fromğ¿to0do\n2{(ğ‘¥[ğ‘–],ğ‘£[ğ‘–])}ğ‘–â†Read(Ë†ğ‘¦ğ‘™(ğ‘¥)) // Storage access\n3ğ‘£ğ‘™â†Search(ğ‘¥,{(ğ‘¥[ğ‘–],ğ‘£[ğ‘–])}ğ‘–)\n4 ifIn index layer, ğ‘™â‰¥1then\n5 Ë†ğ‘¦ğ‘™âˆ’1â†ReconstructNode(ğ‘£ğ‘™)\n6return(ğ‘¥,ğ‘£)=(ğ‘¥,ğ‘£ 0)\nCurrently, these two node types are sufficient. Together, they fit\nsorted key-position collections accurately. step adapts to discon-\ntinuities while band regresses well with regularly sized key-value\npairs [ 32]. They also possess many efficient fitting methods that\npass over the entire key-position collection only once. Further-\nmore, with these types, AirIndex-Model can already incorporate\nmany existing learned indexes such as PGM-Index [ 33], ALEX [ 31],\nRadixSpline [43], SIndex [69], XModel [70].\nParameters (to be tuned). The collection of all parameters ğš¯is a\nnested tuple of parameters that is sufficient to represent a hierarchi-\ncal index instance. In particular, ğš¯specifies the number of layers ğ¿\nfollowed by ğ¿layer-wise parameters Î˜ğ‘–which in turn specifies the\nnode type, number of nodes ğ‘›ğ‘™, and all node parameters.\nğš¯=(ğ¿,(Î˜1,...,Î˜ğ¿)),Î˜ğ‘™=(NodeType,ğ‘›ğ‘™,(ğœƒ1,...,ğœƒğ‘›ğ‘™))(2)\nNode-specific parameters (ğœƒ1,...,ğœƒğ‘›ğ‘™)forğ‘›ğ‘™nodes depend on\nthe corresponding NodeType . For example, if NodeType =step(ğ‘),\nğœƒğ‘–=(ağ‘–,bğ‘–)where|ağ‘–|=|bğ‘–|=ğ‘. IfNodeType =band ,ğœƒğ‘–=\n(ğ‘¥(ğ‘–)\n1,ğ‘¦(ğ‘–)\n1,ğ‘¥(ğ‘–)\n2,ğ‘¦(ğ‘–)\n2,ğ›¿ğ‘–). We choose to specify a single node type\nper layer over multiple node types per layer because (1) it reduces\nthe serialization overhead per node which reduces read volume and\nso overall lookup latency, and (2) it simplifies our tuning (Â§5.2).\nExamples. As a general class of indexes, hierarchical index exam-\nples include traditional indexes like B-tree and learned indexes like\nRMI,PGM-index , balanced ALEX/APEX , and PLEX . For example,\n2-layer balanced B-tree with fanout 3 is a hierarchical index as in\nEq (3) where ğœƒğ‘–,ğ‘—andğœƒğ‘˜are appropriate step function parameters\nto encode keys and pointers in the leaf and root nodes respectively.\nğš¯B-Tree =(2,(Î˜1,Î˜2)),\nÎ˜2=(step,3,(ğœƒ1,ğœƒ2,ğœƒ3)),\nÎ˜1=(step,32,(ğœƒğ‘–,ğ‘—)ğ‘–,ğ‘—âˆˆ{1,2,3})(3)\nRMI with a cubic root node ğ‘ğ‘¥3+ğ‘ğ‘¥2+ğ‘ğ‘¥+ğ‘‘and 8 linear\nintermediate nodes (ğ›¼ğ‘–ğ‘¥+ğ›½ğ‘–)Â±ğœ€ğ‘–is a hierarchical index as in Eq (4).\nPGM-index , balanced ALEX/APEX , and PLEX can be similarly\ninstantiated as hierarchical indexes by extending the node types.\nğš¯RMI=(2,(Î˜1,Î˜2)),\nÎ˜2=(cubic,1,((ğ‘,ğ‘,ğ‘,ğ‘‘))),\nÎ˜1=(linear,8,((ğ›¼ğ‘–,ğ›½ğ‘–,ğœ€ğ‘–))ğ‘–âˆˆ{1,...,8})(4)\n4.2 Query Process\nFunctionally, a query process takes in a search key ğ‘¥and outputs its\nrelevant key-value (ğ‘¥,ğ‘£). It internally consults index layers inside\na hierarchical index, starting from its root layer ğ¿, traversing downTable 3: Optimization summary\nDesign variables ğš¯:\nğ¿ Number of layers\nNodeTypeğ‘™ Node type in layer ğ‘™âˆˆ{1,...,ğ¿}\nğ‘›ğ‘™ Number of nodes in layer ğ‘™âˆˆ{1,...,ğ¿}\nğœƒğ‘™,ğ‘– Parameters of the ğ‘–-th node in layer ğ‘™,ğ‘–âˆˆ{1,...,ğ‘›ğ‘™}\nFixed variables :\nğ‘‡ Storage profile\nX Query key distribution\nğ· Key-position collection ğ·={(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›\nğ‘–=1\nConstraints Valid index Ë†ğ‘¦(ğ‘¥)âŠ‡ğ‘¦for all(ğ‘¥,ğ‘¦)âˆˆğ·\nObjective Minimize expected latency Lğ‘†ğ‘€(X;ğš¯,ğ‘‡), Eq (7)\nAlgorithm AirTune (Â§5)\none index layer at a time to look up the relevant position of the\nquery key, and finally retrieving the target value.\nAlg. 1 formalizes AirIndex â€™s overall query process, traversing\nthrough the index hierarchy of relevant node(s) Ë†ğ‘¦ğ¿,..., Ë†ğ‘¦0to re-\ntrieve the relevant key-value (ğ‘¥,ğ‘£). There are mainly three steps in\neach iteration in an index layer: (1) AirIndex reads potentially rel-\nevant raw bytes{(ğ‘¥[ğ‘–],ğ‘£[ğ‘–])}ğ‘–, (2) it then searches for the relevant\nraw bytesğ‘£ğ‘™based on the tagged key {ğ‘¥[ğ‘–]}ğ‘–, and (3) AirIndex de-\nserializesğ‘£ğ‘™to reconstruct the next relevant node Ë†ğ‘¦ğ‘™âˆ’1and predicts\nthe next position Ë†ğ‘¦ğ‘™âˆ’1(ğ‘¥). At the end when ğ‘™=0,AirIndex returns\nthe value with the query key (ğ‘¥,ğ‘£0)=(ğ‘¥,ğ‘£).\nSuch a clearly defined query process allows us to estimate a hier-\narchical index performance for tuning. Given appropriate statistics\non the hierarchical index and a storage model, we can translate\nAlg. 1 into the latency formula incorporating different lookup costs.\n4.3 Latency Under Storage Model\nFor index traversals, the dominant costs are storage accesses (Alg. 1,\nline 2), compared to other internal computations including rele-\nvant value searching, data deserialization, and node prediction.\nFollowing the iterations in Alg. 1, there are exactly ğ¿+1sequential\nstorage accesses corresponding to reading ğ¿index layers and the\ndata layer. Specifically, AirIndex first reads the entire root layer\nof sizeğ‘ (Î˜ğ¿)bytes, then partially reads Î”(ğ‘¥;Î˜ğ‘™+1)=|Ë†ğ‘¦ğ‘™(ğ‘¥)|bytes\nfrom the next index layer, and so on until it reaches the data layer\nto read Î”(ğ‘¥;Î˜1)=|Ë†ğ‘¦0(ğ‘¥)|bytes. Using a storage profile ğ‘‡(Â§3.2),\nwe expressLğ‘†ğ‘€(ğ‘¥;ğš¯,ğ‘‡), the query latency to find a value for a\nkeyğ‘¥under the storage model, as follows:\nLğ‘†ğ‘€(ğ‘¥;ğš¯,ğ‘‡)=ğ‘‡(ğ‘ (Î˜ğ¿))+ğ¿âˆ‘ï¸\nğ‘™=1ğ‘‡(Î”(ğ‘¥;Î˜ğ‘™)) (5)\nTo obtain expected latency over multiple keys, we aggregate\nquery latencies, each specific to key ğ‘¥, over a query key distribution\nX. In this work, we set Xto be a uniform distribution over existing\nkeys in the key-position collection ğ·.\nLğ‘†ğ‘€(X;ğš¯,ğ‘‡)=E\nğ‘¥âˆ¼X\"\nğ‘‡(ğ‘ (Î˜ğ¿))+ğ¿âˆ‘ï¸\nğ‘™=1ğ‘‡(Î”(ğ‘¥;Î˜ğ‘™))#\n(6)\nGiven a key-position collection ğ·, a storage profile ğ‘‡, and a\nquery key distribution X, our objective (Eq (7)) is to minimize this\nexpected query latency where ğš¯represents a hierarchical index\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\n0-th Layer (Data)Layer builder ğ¹1\nLayer builder ğ¹2\nLayer builder ğ¹3\nLayer builder ğ¹4\nLayer builder ğ¹5\nLayer builder ğ¹6\nLayer builder ğ¹7root rootBest structure Top-ğ‘˜Candidates Candidate\nroot root root root\nroot\n1st Layer2nd Layer\nRecursion\norder\nFigure 7: An instance of AirTune execution, starting from\nthe bottom (data layer) to the top. The label â€œrootâ€ indicates\nthat the candidate should be the root layer with no further\nindex layer. In this illustration, the algorithm has 7layer\nbuilders and selects ğ‘˜=3top candidates to branch out.\nvalid overğ·. Table 3 summarizes this optimization problem.\nğš¯âˆ—=arg min\nğš¯E\nğ‘¥âˆ¼X\"\nğ‘‡(ğ‘ (Î˜ğ¿))+ğ¿âˆ‘ï¸\nğ‘™=1ğ‘‡(Î”(ğ‘¥;Î˜ğ‘™))#\n(7)\n5AIRTUNE : SEARCH WITH BOUNDED VISITS\nThis section describes AirIndex â€™s optimization algorithm, Air-\nTune , which solves the optimzation defined earlier (Table 3). We\nfirst describe the overall process (Â§5.1). Then we explain important\ncomponents in detail: index layer builders (Â§5.2), pruning technique\nfor computational efficiency (Â§5.3), and parallelization techniques\n(Â§5.4). Finally, we analyze its time complexity (Â§5.5).\n5.1 Guided Graph Search\nAirTune is a guided graph search; it starts from an origin vertex,\nwalks over edges to different vertices, and stops when a stopping\ncriterion is satisfied. Each vertex represents a layer in a hierarchical\nindex. As the special case, the origin vertex ğ‘¢0represents the dataset\nbeing indexed. Each edge from a vertex ğ‘¢to another vertex ğ‘¢â€²\nrepresents a layer builder building an index layer ğ‘¢â€²based onğ‘¢.\nA path from the origin represents a particular hierarchical index\ndesign. For example, a path (ğ‘¢0,ğ‘¢1,ğ‘¢2)is roughly equivalent to data\nand index layers(ğ¼0,ğ¼1,ğ¼2)where the index layers have parameters\nğš¯=(2,(Î˜1,Î˜2)). Two paths with common vertices represent two\nhierarchical index designs that share lower layers; thus, AirTune\ncan reuse layer-building results in those common lower layers.\nOn a vertex, AirTune first explores all outgoing edges, i.e. pos-\nsible candidate index layers from all available layer builders (Â§5.2,\nAlg. 2, lines 3â€“6). Layer builder explorations are the most expensive\nstep, but they are independent of one another and embarrassingly\nparallelizable. AirTune leverages this observation to reduce the\ntuning time overhead (Â§5.4). Upon receiving all candidates, it con-\nsults heuristic guidance to select only the top- ğ‘˜candidates (Â§5.3,\nAlg. 2 line 7) to continue the search recursively (Alg. 2 lines 8â€“12).\nSelecting a few promising candidates is an important mechanism\nto limit the branching factor, avoiding exponential time complexity\n(see analysis in Â§5.5). At the end of a recursive search, AirTuneAlgorithm 2: AirIndex Index Tuning, AirTune(ğ·;ğ‘‡,F)\nInput: Key-position collection ğ·={(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›\nğ‘–=1, storage profile ğ‘‡,\nlayer buildersF\nOutput: Index structure ğš¯âˆ—\n// Check stopping criterion\n1ifLğ‘†ğ‘€(ğ·;(),ğ‘‡)<IdealLatencyWithIndex (ğ‘‡)then\n2 return() // Cannot improve with additional layer\n// Build multiple next layer candidates\n3forğ¹inFdo\n4 Î˜nextâ†ğ¹(ğ·) // Build next layer (Â§5.2)\n5ğ·nextâ†Outline(Î˜next) // Turn into key-positions\n6Câ†CâŠ•{( Î˜next,ğ·next)} // Append candidate\n// Select top- ğ‘˜candidates (Â§5.3)\n7Câ† Select(C,ğ‘˜)\n// Build indexes on top- ğ‘˜candidates\n8for(Î˜next,ğ·next)inCdo\n9ğš¯âˆ—\nnextâ†AirTune(ğ·next;ğ‘‡,F) // Call recursively\n10 ğš¯newâ†(Î˜next)âŠ•ğš¯âˆ—\nnext// Prepend layer\n11 ifLğ‘†ğ‘€(ğ·;ğš¯new,ğ‘‡)<Lğ‘†ğ‘€(ğ·;ğš¯âˆ—,ğ‘‡)then\n12 ğš¯âˆ—â†ğš¯new // Select the better structure\n13return ğš¯âˆ—\ncompares all the options using the latency formula under a storage\nmodel (Eq (6)) and returns the best hierarchical index design.\nTo decide when to stop searching, AirTune determines whether\nan additional index layer will be beneficial. That is, if the ideal index\nlayer â€“the best (possibly impossible) layer we can build on topâ€“does\nnot reduce the query latency, AirTune stops further exploration\nand declare the current vertex as the root index layer (Alg. 2, lines\n1â€“2). Specifically, an ideal index has the minimal size of ğ‘ (Î˜)=1\nbyte and the finest precision Î”(ğ‘¥;Î˜)=1byte.\nExample. If we have 7layer builders and set ğ‘˜=3, an execution\nofAirTune could look like Figure 7. That is, AirTune starts from\nthe origin data-layer vertex (the long rectangle at the bottom) and\nexplores all 7 layer builders, resulting in 7vertices (rectangles of\nvarying sizes in the middle). The guidance then tells AirTune to\nsearch deeper into ğ‘˜=3candidates of them (red and blue high-\nlighted rectangles). AirTune stops at one of the candidates because\nit is too small to gain any benefit from an ideal index layer. For\nthe rest, AirTune continues exploring, selecting top- 3candidates,\nand finally stops at 2nd layer candidates. After comparing all op-\ntions, AirTune reports the best path (all red highlighted rectangles),\nrepresenting the fastest hierarchical index design.\n5.2 Layer Builders\nA layer builder is a method to produce a valid index layer on top of\nexisting index layer(s). In other words, it is a mapping ğ¹(ğ·)=Î˜\nsuch that Î˜satisfies a valid index layer Ë†ğ‘¦(ğ‘¥)âŠ‡ğ‘¦for all(ğ‘¥,ğ‘¦)âˆˆğ·.\nIn theory, there is a large number of ways of building index\nlayers. For example, a method ğ´1can find the smallest collection\nofband that covers ğ·with error at most ğœ†bytes using ğ‘‚(ğ‘›2)for\nğ‘›key-position pairs. In ğ‘‚(ğ‘›), another method ğ´2could quickly\nand mindlessly connect every other ğ‘škey-position points into a\ncollection of band . To avoid exploring every possible method, we\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\n4 8 16 32 64\n1B 1MB 1TB 1EB20406080100\nCollection Size ğ‘ ğ·Ë†ğœ(ğ·;ğ‘‡)(ms)\n(a) Varying ğµ(MB/s),â„“=16ms1B 1MB 1TB 1EB100200300\nCollection Size ğ‘ ğ·Ë†ğœ(ğ·;ğ‘‡)(ms)\n(b) Varying â„“(ms),ğµ=16MB/s\nFigure 8: Index complexity Ë†ğœ(ğ·;ğ‘‡)as function of data size ğ‘ ğ·\nand affine storage profile ğ‘‡(parameterized by latency â„“, and\nbandwidth ğµ). Different line represent different variations\nin bandwidth (left) and latency (right).\nchoose a set of good layer builders that (1) run quickly (say, time\ncomplexityğ‘‚(ğ‘›)), (2) build small and accurate index layers, and (3)\nsynergetically cover different data patterns together. In the earlier\nexamples, method ğ´1builds the optimal band index layer but is\ntoo slow, while method ğ´2is fast but builds a suboptimal band\nindex layer. In addition, {ğ´1,ğ´2}is also not a good set of methods,\nbecause they only cover the band node type.\nTo cover the two types of nodes ( step andband ) on different data\npatterns, AirIndex currently deploys three types of layer builders,\neach generating many layer builders by varying hyperparameters.\n(1)Greedy Step (GStep(ğ‘,ğœ†ğºğ‘†)) buildsğ‘-piece step nodes with\nprecision at most ğœ†ğºğ‘†bytes by greedily packing key-position pairs.\n(2)Greedy Band (GBand(ğœ†ğºğµ)) builds band nodes by greedily fit-\nting as many key-position pairs as possible using the monotone\nchain convex hull [ 10]. (3) Equal Band (EBand(ğœ†ğ¸ğµ)) builds band\nnodes by grouping key-position pairs in equal-size position ranges.\nPlease see our extended script [66] for further details.\nAirIndex generates the set of candidate layer builders Fby\nsampling the granularity exponentially: ğœ†ğ‘™ğ‘œğ‘¤,ğœ†ğ‘™ğ‘œğ‘¤(1+ğœ–),ğœ†ğ‘™ğ‘œğ‘¤(1+\nğœ–)2,...ğœ†â„ğ‘–ğ‘”â„ where(ğœ†ğ‘™ğ‘œğ‘¤,ğœ†â„ğ‘–ğ‘”â„)are the bounds and ğœ–>0controls\nthe exponentiation base. For example, if ğœ†ğ‘™ğ‘œğ‘¤=28,ğœ†â„ğ‘–ğ‘”â„=220, and\n1+ğœ–=2withğ‘=16, thenFcontains 39 builders in total:\nF={GStep(16,28),GStep(16,29),..., GStep(16,220)}\nâˆª{GBand(28),GBand(29),..., GBand(220)}\nâˆª{EBand(28),EBand(29),..., EBand(220)}(8)\n5.3 Top-k Candidates by Index Complexity\nBefore branching out, AirTune selects only top- ğ‘˜candidates with\nthe highest potential to be in the optimal design. For each candi-\ndate(Î˜ğ‘–,ğ·ğ‘–),AirTune evaluates its quality as a summation of a\nâ€œremaining workâ€ heuristic function Ë†ğœ(ğ·;ğ‘‡)and its layer-specific\nlookup latency. Then, it selects top- ğ‘˜candidates with ğ‘˜lowest\nestimated costs ( arg minğ‘˜denotes top- ğ‘˜arguments of the minima).\n{(Î˜ğ‘–,ğ·ğ‘–)}ğ‘˜\nğ‘–=1=arg min\n(Î˜ğ‘–,ğ·ğ‘–)âˆˆCğ‘˜Ë†ğœ(ğ·ğ‘–)+ E\nğ‘¥âˆ¼X[ğ‘‡(Î”(ğ‘¥;Î˜ğ‘–))](9)\nChoice of Heuristic Function. Ideally, if there exists an oracle\nthat reveals the optimal search latency, we could simply select\nthe best candidate and avoid branching out entirely. This optimal\nsearch latency of dataset ğ·under storage profile ğ‘‡is called indexcomplexityğœ(ğ·;ğ‘‡). Unfortunately, ğœ(ğ·;ğ‘‡)is unknown for a large\nclass of indexes supported by AirIndex .\nInstead, AirTune estimates candidatesâ€™ quality using an upper\nbound to the index complexity: step index complexity Ë†ğœ(ğ·;ğ‘‡)â‰¥\nğœ(ğ·;ğ‘‡).Ë†ğœ(ğ·;ğ‘‡)is the optimal search latency considering only\nstep index layers (i.e. B-tree layers). Since the quality of step -\nbased layers can be analytically computed, we obtain an efficient\nalgorithm that depends only on the collection size ğ‘ ğ·and storage\nprofileğ‘‡. Figure 8 shows the general shape of Ë†ğœ(ğ·;ğ‘‡)solved with\nthe algorithm. Please see our extended report [ 66] for more details.\n5.4 Parallel Tuning\nAirIndex is highly parallelizable from three sources of parallelisms\nas described below, ordered from finest to coarsest layers. It is\nworth noting that, with a proper branching (Theorem 5.1), the\nnode-building step is the primary target for parallelization.\nFrom Data Partitioning. AirIndex partitions the key-position\ncollections, uses a layer builder to build sub-range candidates, and\nmerges them into a candidate. This is possible because AirIndex â€™s\nexisting layer builders generate a piecewise function that can be\nmerged together across different key ranges. By default, AirIndex\nbreaks a key-position collection into partitions, each containing 1\nmillion key-position pairs. Thus, AirIndex can scale with growing\ndata sizes by increasing the level of parallelisms accordingly.\nFrom Across Layer Builders. Although Alg. 2 calls layer builders\nin loops, the invocations are independent of one another. AirIndex\nconveniently turns the for-loop into a parallel mapping to produce\n(Î˜next,ğ·next)and collecting into the candidate set C. With more\nparallelisms, AirIndex can then scale along with the diversity of\nlayer builders to capture wider key-position patterns.\nFrom Branching. AirIndex can recursively call Alg. 2 in parallel\nand select the best index structure with the minimum storage model\ncost. This source of parallelism allows AirIndex to explore more\ncandidate branches and especially higher structures when favored\nby the storage profile (e.g., low bandwidth and low latency).\n5.5 Analysis\nBranching recursive optimization requires a balancing between\nthe branching factor and depth. If AirTune branches out to too\nmany candidates relative to the index depth, it would become un-\ncontrollably slow. On the other extreme, it could miss the optimal\ncandidate branch. We first analyze the tuning time complexity with\nrespect to a choice of hyperparameter. Then, we attempt to provide\nan approximation factor of the automatic tuning.\nTheorem 5.1. Time complexity: Let there be ğ‘›key-position pairs,\nğ¿layers to be explored at most according to the storage profile ğ‘‡, and\n|F|layer builders. If AirTune selects at most ğ‘˜â‰¤ğ¿+1âˆšğ‘›candidates\nthen the time complexity is at most ğ‘‚((ğ¿+1)|F|ğ‘›).\nProof. Suppose the data ğ·consist ofğ‘›key-position pairs with\ntotal data size ğ‘ ğ·. Letğ¿be the maximum number of layers expected\nto be explored, which has the upper bound ğ¿maxâ‰¥ğ¿: the number\nof layers chosen by the step index complexity.\nBecause our layer builders all process a ğ‘‚(ğ‘›)key-position collec-\ntion inğ‘‚(ğ‘›)time, the time to build all |F|candidates is ğ‘‚(|F|ğ‘›).\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\nNext, considering the worst case compression ratio ğ‘‚(ğ‘›1\nğ¿+1)and the\nnumber of branches ğ‘˜, we expectğ‘‚(ğ‘›ğ¿\nğ¿+1)key-position pairs and so\nthe time complexity in the next layer is ğ‘‚(|F|ğ‘˜ğ‘›ğ¿\nğ¿+1). The branch-\ning and compression of key-position pairs continue until the root\nlayer. In summary, the total time complexity in ğ¿-layer branching\nrecursion is as followed whose last step is the closed-form formula\nto the geometric series.\nğ‘‚ \n|F|ğ¿âˆ‘ï¸\nğ‘™=0ğ‘˜ğ‘™ğ‘›ğ¿+1âˆ’ğ‘™\nğ¿+1!\n=ğ‘‚ \n|F|ğ‘›1âˆ’ğ‘˜ğ¿+1/ğ‘›\n1âˆ’ğ‘˜/ğ‘›1\nğ¿+1!\n(10)\nUnderğ‘˜ğ¿+1/ğ‘›â‰¤1(i.e.ğ‘˜â‰¤ğ¿+1âˆšğ‘›), this reduces to ğ‘‚(|F|(ğ¿+1)ğ‘›)\nwhenğ‘›â†’âˆ . â–¡\n5.6 Other Implementation Details\nWe implement AirIndex in Rust [ 1]. Like many data systems, it\nhas two explicit levels in its memory hierarchy: the underlying\nstorage and its internal read-through cache. AirIndex interacts\nwith storage through an abstract interface, in which concrete im-\nplementations serve partial range reads at their best effort. Cur-\nrently, AirIndex â€™s internal zero-copy read-through cache employs\na first-in-first-out (FIFO) eviction policy due to its admission sim-\nplicity. Apart from customized node type format, AirIndex serial-\nizes the metadata together with root layer as a byte array in the\nPostcard [55] format via Serde [60].\n6 EXTENSIONS\nSupporting Updates. Although AirIndex does not optimize for\nwrite workloads, it can tune and build an index that supports write\noperations. For example, we can augment the data layer into a\ngapped array, allowing insertion into gaps and deletion without\nchanging index layers. When gaps are filled or expected to be\nfilled, we can enlarge data layerâ€™s gaps and build a new index with\nAirIndex .AirIndex can also serves as the initial bulk loading of an\nupdatable index (e.g. ALEX/APEX ). However, the updatable index\nmay evolve suboptimally. To reduce the frequency of structural\nindex updates, we can enlarge the position granularity from bytes\nto pages, or we can buffer writes similarly to LSM-trees [26, 54].\nCache-aware Optimization. AirIndex can find an optimal cache-\naware index design by additionally considering the distribution of\ncache hitğ¶ğ‘™and the cost of cache access Lcache . This modification\nthen only affects the index complexity Ë†ğœand candidate selection\ninAirTune . While this work does not include explicit results for\ncache-aware optimization, Figure 10 indicates that the indexes built\nwith cache-pessimistic optimization already offer high performance\nthan other existing methods across a wide range of cache warmness.\nPre-Search Assessment. Upon significant data or workload change,\nwe can first assess the potential performance gain through the step\nindex complexity (Â§5.3). Based on the assessment, users can better\ndecide whether to tune the index. Step index complexity is a loose\nupper bound of the gain, however. Future works combining more\naccurate index complexity, what-if index design techniques, and\ndata/workload trackers would help avoid unnecessary search costs\nfor marginal performance gain.7 EXPERIMENT\nWe empirically study AirIndex to demonstrate its faster search\n(Â§7.2), benefits of automatic index designs (Â§7.3), adaptability under\nwide ranges of I/O profile (Â§7.4), and quick build time (Â§7.5).\n7.1 Setup\nThe experiment locates on two physical components: compute and\nstorage. The former hosts benchmark scripts to execute queries\nagainst systems and measure their performance. These scripts to-\ngether with required binaries are stored on local storage (i.e. Azure\nOS Disk). Meanwhile, the latter stores both datasets and indexes.\nOur benchmark consists of 40 runs in each setting: the ğ‘–-th prepares\nthe environment (e.g., clear cache1), loads/executes the ğ‘–-th list of\none million query keys sequentially, and measures the elapsed time.\nWe summarise those runtimes with average and standard deviation.\nSystem Environment. We use Azure cloud platform [ 12], specif-\nically D8s_v3 (8 vCPUs, 32 GiB RAM) with Ubuntu 20.04. The\nVM connects to two types of storage. (1) NFS: Azure network file\nsystem [ 15] hosted on Azure Blob Storage [ 13] (StorageV2, stan-\ndard performance, zone-redundant storage, hot access tier). (2) SSD:\nAzure Premium SSD [ 14] with P20 performance tier (256 GiB, 2300\nIOPS, 150 MBps, read/write host caching). 3) HDD: Azure Stan-\ndard HDD [ 14] (1024 GiB, 500 IOPS, 60 MBps, no host caching). All\nresources are allocated within the same East US region.\nBaselines. We compare AirIndex to a traditional database index,\nlearned indexes, and our manual configuration counterpart. Al-\nthough many of them are in-memory indexes, we integrate them\nonto external storages whose implementations are in their respec-\ntive forks [ 2â€“6]. We manually tune each of the baselines through\nmicrobenchmarks. (1) LMDB :LMDB [48] is a B-tree database that\naccesses its data on storage through mmap . (2)RMI :RMI [41,53] is a\ntop-down learned index with a compact two-layer structure where\nthe top one contains only one perfectly accurate node partitioning\nkey space to the bottom nodes. We utilize CDFShop [53] to recom-\nmend function types and select the most accurate RMI across all\ndatasets. (3) PGM-index :PGM-index [33] is a learned index with\nbounded precision across all layers. PGM-index partitions the key-\nposition collection to build the next bottom-most layer towards the\ntop. (4) ALEX/APEX :ALEX/APEX [31] is an updatable learned in-\ndex built top-down like RMI but further arrange key-value pairs in\nits layout (notably, â€œgapped arrayâ€ to buffer structural changes). (5)\nPLEX :PLEX [64] is a learned index with compact Hist-Tree (CHT)\nlayered on top of RadixSpline [ 43] (RS). Although PLEX optimizes\nmost parameters, its user need to specify the maximum prediction\nerrorğœ–. We select ğœ–=2048 based on a benchmark on a setting\n(Figure 12d). (6) Data Calculator :Data Calculator [38,39]\nis a data layout design engine that calculates the performance of a\ndata structure. We follow its auto-completion and build its recom-\nmended data layout within AirIndex â€™s framework. (7) B-tree : A\nB-tree-like structure implemented using AirIndex (4KB pages and\n255 fanout), which serves as the most controlled baseline.\n1For both NFS and SSD, we execute sysctl vm.drop_caches=3 on a VM, clearing\nLinux-related caches such as page cache, entries, and inodes. For NFS, we also unmount\nand re-mount the Azure Blob Storage NFS to reload its client.\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\n; ; ; ; ; ; ; ; LMDB RMI/CDFShop PGM-index ALEX/APEX PLEX Data Calculator B-tree AirIndex\nbooks fb osm wiki gmm0100200300589ms 833msLatency (ms)\n(a) NFSbooks fb osm wiki gmm05101521ms 20ms 48ms 188msLatency (ms)\n(b) SSDbooks fb osm wiki gmm0306090120130ms 145ms 332ms 471msLatency (ms)\n(c) HDD\nFigure 9: Average first-query latency comparison on NFS, SSD, and HDD storages across different datasets. In each storage and\ndataset setting, the bars represent the average latencies over random keys. LMDB ,RMI,PGM-index ,ALEX/APEX ,PLEX ,Data\nCalculator ,B-tree , and AirIndex , from left to right. The shorter a bar, the faster the corresponding method serves queries.\n; ; ; ; ; ; ; ; LMDB RMI/CDFShop PGM-index ALEX/APEX PLEX Data Calculator B-tree AirIndex\n1 10310610âˆ’1100101102103\nNumber of QueriesLatency (ms/op)\n(a) NFS, books1 10310610âˆ’1100101102103\nNumber of QueriesLatency (ms/op)\n(b) NFS, osm1 10310610âˆ’210âˆ’1100101102\nNumber of QueriesLatency (ms/op)\n(c) SSD, books1 10310610âˆ’210âˆ’1100101102\nNumber of QueriesLatency (ms/op)\n(d) SSD, osm\nFigure 10: Average latency curves on NFS and SSD with the books and osmdatasets. A combination of a line color and a marker\nstyle represents each method: LMDB ,RMI,PGM-index ,ALEX/APEX ,PLEX ,Data Calculator ,B-tree ,AirIndex , respectively.\nNote the logarithm scales on both axes. Latency curves to the bottom-left corner represent faster methods.\nDatasets. First, we use the SOSD benchmark [ 42,52], including\nbooks (800M), fb(200M), osm(800M), and wiki (200M). Each of\nthese contains 200-800 million 64-bit integer keys stored consec-\nutively in an array. Given a query integer key, the task is to find\nits offset position in the array. Equivalently, it asks the systems for\nthe rank of the query integer. As an unusual dataset, wiki contains\nmany duplicated keys in which the task is to find the smallest offset\nof the key. Second, for more diverse data patterns, we also use a\nsynthetic dataset, gmm, generated from a Gaussian mixture model\n(GMM) of 100 normal distribution clusters over 800 million keys.\n7.2 Faster End-to-end Lookup Speed\nWe study cold-state and warm-state latencies separately. Cold-state\nlatency is useful for understanding the performance under short-\nlived executions (e.g., serverless, ad-hoc workloads) and very large\ndata (e.g., many tables, large indexes). Afterward, we study warm-\nstate latency curves over different warmnesses. Â§7.4 later discusses\nindex structures discovered by AirIndex .\nCold-state Latency. AirIndex is consistently one of the fastest\nmethods at searching the first query, across datasets and storage\n(Figure 9). Compared to LMDB (B-tree), AirIndex is2.4Ã—â€“2.7Ã—\nfaster on NFS and 2.6Ã—â€“4.1Ã—faster on HDD. AirIndex is on par\nwith LMDB on SSD. Similarly, AirIndex is2.0Ã—â€“2.4Ã—faster than\nB-tree on NFS but performs equally well on SSD on HDD. This\ndifference across storages suggests that LMDB andB-tree struc-\ntures are tuned to disk-scale storage profiles like SSDâ€™s, so they\nunderperform on storage on a different scale like NFS.\nCompared to learned index baselines, AirIndex is reliably faster\nwithout unexpectedly long latency arising from tuning difficul-\nties. While RMI performs reasonably well, it has two limitations.First, its fixed two-layer structure makes it rigid to the underlying\nstorage. Second, because RMIâ€™s top-down building assigns a dispro-\nportionate amount of data to intermediate nodes, the second-layer\nprecision varies substantially. This later effect is more pronounced\ningmm. Overall, AirIndex delivers lower latencies more reliably\nthan RMI, being 1.2Ã—â€“2.6Ã—faster on NFS, 1.0Ã—â€“2.2Ã—faster on SSD,\nand1.4Ã—â€“5.9Ã—faster on HDD. PGM-index suffers on books ,fb,\nandosm, but is competitive on wiki andgmm. Upon closer inspec-\ntion, PGM-index fits poorly with the former three, creating larger\nindexes than those in the latter two. AirIndex is on par with PGM-\nindex onwiki andgmm, but outperforms on other datasets with\n3.0Ã—â€“7.2Ã—,5.8Ã—â€“11.7Ã—, and 9.0Ã—â€“15.6Ã—speedup on NFS, SSD, and\nHDD respectively. Similarly, AirIndex is faster than ALEX/APEX\nin all settings except in gmmSSD, with 1.7Ã—â€“10.1Ã—,1.3Ã—â€“46.3Ã—, and\n3.0Ã—â€“22.2Ã—speedup on NFS, SSD, and HDD. ALEX/APEX performs\npoorly in osmbecause its root node holds 2M child pointers with\nmore than 15MB of data. Lastly, AirIndex is faster than PLEX\non NFS and HDD with 1.5Ã—â€“2.2Ã—, and 1.7Ã—â€“3.3Ã—speedup. Both\nmethods perform equally well on SSD: AirIndex is1.7Ã—faster\nat searching osm, but 1.4Ã—slower at gmm. Upon closer inspection,\nPLEX â€™s compact histogram tree fit osmpoorly (762KB in size) but\nfitgmmexceptionally better (0.6KB in size).\nCompared to Data Calculator ,AirIndex searches in a richer\nset of indexes and so it is consistently faster: 1.4Ã—â€“2.0Ã—,1.2Ã—â€“1.5Ã—,\nand 1.0Ã—â€“1.4Ã—speedup on NFS, SSD, and HDD. On the bright\nside, Data Calculator generally has a faster lookup than B-tree\nbecause of its storage-aware tuning and B-tree â€™s fixed structure.\nWarm-state Latency Curve. As we continue querying (and caching\nmore), the queries become progressively faster shown as per-query\nlatency curves in Figure 10. Here, a point (ğ‘¥,ğ‘¦)in the latency curve\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\n1 2 3 4 50100200Tuned\nNumber of Layers ğ¿Latency (ms)\n(a) Varying ğ¿on NFS28210212214216216.32182200100200Tuned\nGranularityğœ†Latency (ms)\n(b) Varying ğœ†on NFS1 2 3 4 50246Tuned\nNumber of Layers ğ¿Latency (ms)\n(c) Varying ğ¿on SSD28210211.62122142162182200246Tuned\nGranularityğœ†Latency (ms)\n(d) Varying ğœ†on SSD\nFigure 11: Comparison of average first-query latencies between AirIndex -tuned designs (in red) and manual alternatives across\nNFS and SSD ( fbdataset) varying numbers of layers ğ¿and granularities ğœ†. The error bars display standard deviations.\nAirIndex0100200300400Latency (ms)\n(a)AirIndex1KiB 2KiB 4KiB 8KiB 16KiB 32KiB0100200300400Latency (ms)\n(b)LMDB , varying page size123456789100100200300400Latency (ms)\n(c)RMI/CDFShop , varying configurations28292102112122132142150100200300400Latency (ms)\n(d)PLEX , varyingğœ€\nFigure 12: Comparison of average first-query latencies on the books dataset in NFS between AirIndex -tuned design (left) and\nother methods with varying knobs. RMIâ€™s settings are recommended by CDFShop with the least accurate (fewer models) on the\nleft and the most accurate (more models) on the right. The error bars display standard deviations of the latency.\nimplies that a system completes ğ‘¥queries inğ‘¥Ã—ğ‘¦seconds. The\ndifferences in accelerations across methods can be explained by\ntheir index structures. In hierarchical indexes, shorter and narrower\nindexes accelerate more aggressively than taller and wider indexes\nbecause fewer (random) queries are needed to touch all nodes in\na narrower index layer. For example, in osmdataset, ALEX/APEX\naccelerates faster than LMDB because of its shorter index with a\none-node root as opposed to a full B-tree. Even though AirIndex\noptimizes for cold-state latency, the tuned structure is still faster for\nwarm-state latency, ranging from 100 to 100K queries. Such a range\nof warmness is useful for a large collection of datasets, short-lived\nsearch sessions, or limited memory environments.\n7.3 Layer-wise Optimization Helps\nSpeedup over Hierarchical Indexes. To empirically verify that\nAirIndex tunes accurately and finds a fast index, we compare\nAirIndex â€™s tuned index designs against manually configured ones\nin terms of their first-query latencies. Figure 11 presents the com-\nparison on numbers of layers ğ¿and granularity hyperparameter ğœ†\nacross the two storage within the same dataset fb. In all settings\nand variable dimensions, AirIndex consistently finds the fastest\nindex designs. Inspecting the trends, we observe that ğœ†forgivingly\nadmits a larger optimal region, even in the logarithmic scale, than\nthe number of layers ğ¿. This allows AirIndex to select a coarse\ngranularity exponentiation base 1+ğœ€without risking suboptimality.\nWe have also experimented with other dimensions such as the\ngranularity exponentiation base 1+ğœ€and the set of node estimators\nto discover any trade-off. Lower bases 1+ğœ€result in faster indexes\nbut with only insignificant gain for a higher cost in a longer tuning\ntime. A wider set of node estimators and types provides some fitness\nadvantages. The impact is clear when the data pattern is exclusive\nto a node type, for example, band nodes fit perfectly on a uniformly\nrandom key set ( uden64 from [42]) while step nodes do not.Speedup over Well-tuned Baselines. AirIndex is faster than all\nbaseline configurations, and so is faster than optimal baselines. Fig-\nure 12 varies all permissible page sizes of LMDB , all 10 RMI settings\nrecommended by its optimizer, and 8 chosen ğœ€inPLEX to cover the\noptimal valley. We observe that AirIndex is2.7Ã—,1.5Ã—, and 1.7Ã—\nfaster that the optimal LMDB ,RMI, and PLEX , respectively. Our sim-\nilar experiment with B-tree by varyingğœ†granularity shows 1.3Ã—\nspeed up. These gaps from optimal baselines suggest the benefit to\nconsider a larger class of indexes (i.e. AirIndex-Model ).\n7.4 Adaptive to I/O Performance\nOn Testing Storages. Indeed, AirIndex discovers different optimal\nindex structures for the NFS and SSD/HDD storages in previous\nexperiments. NFS indexes have ğ¿=1index layer with only band\nnode types, while SSD/HDD indexes have ğ¿=2layers with a mix\nofband -band ,band -step , and step -band node types. The sizes of\nroot layersğ‘ (Î˜ğ¿)and precisions Î”range from 36KB to 328KB in\nNFS and 864B to 16KB in SSD/HDD, depending on dataset size and\ncomplexity. Among 5 datasets, osmis the most challenging one,\nreflecting the same observation from [ 52]. Please see our extended\nmanuscript [66] for specific index structures.\nOn Latency-Bandwidth Spectrum. If we have a storage with\nlatencyâ„“and bandwidth ğµ, what would the fastest index look like?\nWe answer this question as a whole, on a wide spectrum of latency\nâ„“âˆˆ [1ğœ‡s,1000 s]and bandwidth ğµâˆˆ [1KB/s,1TB/s]. Figure 13\nshows AirIndex adapting its index to the diverse range of storage\nprofiles. Higher bandwidth or latency promotes shallower indexes\nwith coarser precision (larger total read volume). In the extreme,\nAirIndex proposes no index at all, i.e. fetching the entire data layer\nto search locally. On the other hand, lower bandwidth or latency\npromotes taller indexes with finer precision. Although this trend is\nsimilar to a well-known tuning rule of thumb for B-tree, AirIndex\noffers a more complete tuning on a much larger class of indexes,\nfor any data pattern, and storage profile.\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\n1ğœ‡s 1ms 1s 1000s\nLatency1KB/s1MB/s1GB/s1TB/sBandwidthNumber of Layers\n02468\n(a) Number of layers\n1ğœ‡s 1ms 1s 1000s\nLatency1KB/s1MB/s1GB/s1TB/sBandwidthTotal Read Volume\n2KiB32KiB1MiB32MiB1GiB\n(b) Total Read volume\n1ğœ‡s 1ms 1s 1000s\nLatency1KB/s1MB/s1GB/s1TB/sBandwidthOptimal Lookup Latency\n10ğœ‡s100ğœ‡s1ms10ms100ms1s10s100s1000s\n(c) Optimal cost\n1ğœ‡s 1ms 1s 1000s\nLatency1KB/s1MB/s1GB/s1TB/sBandwidthOptimal EMM CostNFS\nSSD\nHDD\n10ğœ‡s100ğœ‡s1ms10ms100ms1s10s100s1000sFigure 13: Impact of storage latency/bandwidth on AirIndex â€™s index design. The fbdataset is used. Note the logarithm scales\ncovering 1KB/s â€“ 1TB/s bandwidth and 1 ğœ‡s â€“ 1000s latency. The number of layers ğ¿, total read volume ğ‘ (Î˜ğ¿)+Ãğ¿\nğ‘™=1Eğ‘¥âˆ¼XÎ”(ğ‘¥;Î˜ğ‘™),\nand the optimal costs are displayed in color annotated in the sidebar. NFS, SSD, and HDD performances are marked accordingly.\n; ; ; ; ; ;Rel. Bandwidth: 0.01Ã— 0.1Ã— 1Ã— 10Ã— 100Ã—\n0.001Ã— 1Ã— 1000Ã—1Ã—10Ã—100Ã—\nRelative LatencyRel. Slowdown\n(a) Variability on NFS0.001Ã— 1Ã— 1000Ã—1Ã—10Ã—\nRelative LatencyRel. Slowdown\n(b) Variability on SSD\nFigure 14: Extreme errors ( Â±3andÂ±2magnitude differences\nin latencies/bandwidths) expectedly make tuned indexes sub-\noptimal compared to correctly tuned ones. Left: the index is\ntuned for NFS (50 ms, 12 MB/s). Right: the index is tuned for\nSSD (250ğœ‡s, 175 MB/s). fbis the underlying dataset.\nWith Storage Variability. Storage performance may vary. If it\nvaries within a magnitude, AirIndex â€™s tuned index mostly stays\noptimal. In fact, it does so if the performance remains within the\nsame band (i.e. same color in Figure 13a and Figure 13b) as the\nprofiled performance. However, if the actual performance ğ‘‡â€²varies\nacross many magnitudes, the index tuned with inaccurate storage\nprofileğ‘‡can be suboptimal as shown in Figure 14 through the\nrelative slowdown of the index ğš¯tuned with the inaccurate profile\nğ‘‡based on the index ğš¯â€²tuned with the actual profile ğ‘‡â€²in ret-\nrospect:Lğ‘†ğ‘€(X;ğš¯,ğ‘‡)/Lğ‘†ğ‘€(X;ğš¯â€²,ğ‘‡â€²). For example, if the actual\nNFS latency is 0.001 times smaller than the profiled NFS latency\n(i.e., 50ğœ‡s instead of 5ms), the originally tuned index would be 35\ntimes slower than the accurately tuned index.\n7.5 Competitive Build Time\nTotal Build Time. Figure 15a measures index build times on a\nmachine with 2 AMD EPYC 7552 48-Core Processors (192 CPUs in\ntotal). Build times in LMDB ,RMI,PGM-index , and ALEX/APEX\nonly account for data loading, inserting into the system, and writ-\ning to files, excluding their manual hyperparameter tuning. Data\nCalculator â€™s build time includes parallelized autocompletion and\nindex building. All methods use all available cores.\nThanks to its parallel tuning (Â§5.4), AirIndex â€™s total build time\nis competitive with other baselines. AirIndex is3.8Ã—,5.9Ã—, and\n4.3Ã—faster than LMDB ,RMI/CDFShop , and ALEX/APEX . while\nAirIndex both tunes and builds as fast as RMI (excluding CDFShoptime), PGM-index , and PLEX build their indexes. Compared to\nData Calculator â€™s autocompletion and building, AirIndex is\n2.3Ã—faster despite exploring a larger class of indexes. Nonetheless,\nAirIndex tuning and building are 2.7Ã—slower compared to its fixed\nstructure counterpart B-tree . If needed to be faster, AirIndex can\nrelax some hyperparameters (e.g. number of candidates, granularity\nbase and bounds) to trade its speed with its tuning accuracy.\nSearch Overhead. Figure 15b measures search overheadsâ€”the dif-\nferences between total build time and build time given a known\nconfiguration (i.e., CDFShop â€™s search procedure on RMI struc-\ntures, Data Calculator â€™s autocompletion, AirIndex â€™sAirTune\nexcluding the time for building the optimal index). AirIndex incurs\nnon-negligible search overhead (around 50 ns/key on the 192-core\nmachine, or 9.6 ğœ‡s/key on single-core machines); however, this\nsearch overhead is lower compared to other methods. Because of\nits parallelization and top- ğ‘˜candidate selection limiting branching,\nAirIndex finds its index structure 7.8Ã—and3.3Ã—faster than learned\nindex tuning method CDFShop and traditional index tuning method\nData Calculator , respectively. In contrast, Data Calculator â€™s\nparallelized autocompletion is slow because it tries all design com-\nbinations similarly to a grid search. We note that CDFShop outputs\nmultiple index structures on a Pareto front.\n7.6 Applicable to Read-Write Workloads\nWe implement a proof-of-concept updatable AirIndex based on\nthe gapped array [ 31] that allocates empty gaps on data layer for\nAirIndex to insert a key-value at any available gap within the\npredicted position Ë†ğ‘¦(ğ‘¥). Our read-write benchmark follows that of\n[31]. It initially inserts 100M keys sampled from osmand measures\nthe time to complete 10K queries consisting of cycles of ğ‘Ÿread and\nğ‘¤write operations. Four workloads vary the read/write proportion:\n(1)Read-Only :(ğ‘Ÿ,ğ‘¤)=(1,0), (2) Read-Write :ğ‘Ÿ=19,ğ‘¤=1, (3)\nWrite-Heavy :ğ‘Ÿ=1,ğ‘¤=1, (4) Write-Only :ğ‘Ÿ=0,ğ‘¤=1. The\nbenchmark samples read keys uniformly from the inserted key set\nand samples write keys from the non-inserted key set.\nIn Figure 16, our prototype remains the fastest compared to\nupdatable baselines ( LMDB andALEX/APEX ) across all workloads,\nconfirming that tuning for lookup speed is relevant to both read\nand write performances. Apart from the direct relation to read\noperations, lookup speed is relevant to write operations because\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\n200M 400M 600M 800M0100200300400\nData Size (Keys)Build Time (s)LMDB PLEX\nRMI/CDFShop Data Calculator\nPGM-index B-tree\nALEX/APEX AirIndex\n(a) Total Time to Build Index200M 400M 600M 800M050100150200250300\nData Size (Keys)Search Overhead (s)RMI/CDFShop\nData Calculator\nAirIndex\n(b) Search Overhead Time\nFigure 15: Index build and search overhead for different data sizes (200, 400, 600, and 800 million keys) from the gmmdataset.\nBuild times for LMDB ,RMI,PGM-index ,ALEX/APEX , and PLEX donotinclude their manual tuning time.\nRead-Only Read-Write Write-Heavy Write-Only01,0002,0003,000Tput. (op/s)LMDB\nALEX/APEX\nAirIndex\nFigure 16: Average throughputs of LMDB ,ALEX/APEX , and\nAirIndex across read-write workloads on osmdataset in SSD.\nall methods need to first look up the insertion position from their\nindexes before writing the target key-value pair.\n8 RELATED WORK\nOur work is built on top of the vast amount of existing research on\nindex design and optimization as summarized below; however, our\nunified model ( AirIndex-Model ) and efficient search ( AirTune )\nenables a high-quality data and I/O-aware hierarchical index.\nStorage-aware Indexes. Besides the original B-trees [ 17,25], many\nworks have studied unique storage properties to design indexes\nspecifically optimized for certain storage, such as CPU cache [ 35],\nSRAM cache [ 23], disk [ 24], NVMe [ 68], and distributed cloud [ 19,\n71,72]. As the most generic of all, [ 18] designs B-Trees that perform\nwell for any I/O page size ğ‘ƒ; however, its storage profile (cache-\noblivious model) only limits to ğ‘‡(Î”)=ğ‘‚(âŒŠÎ”/ğ‘ƒâŒ‹). Also, skip list\nhas been adapted to various settings, such as multi-core [ 29], cache-\nsensitive for range queries [ 62], non-uniform access [ 27], and dis-\ntributed nodes [ 37]. In contrast, AirIndex takes a general approach\nby composing an optimization problem in consideration of stor-\nage profiles, which makes it possible to adapt its structure without\nre-evaluating the parameters when the transfer size changes.\nIndex Tuning. AirIndex automates index designs by improving\non long-standing heuristics such as â€œuse larger pages for larger\nbandwidthâ€ [ 11,36,49]. Rather than deciding what index to build,\nother index tuning techniques determine when and where to build\nindex, as a well-known index selection problem (ISP) [ 21,28,34,40,\n51, 59, 65], which are orthogonal to our work.\nData Calculator [38,39] helps designing efficient data struc-\ntures by evaluate the cost of a structure in a what-if fashion in\nrelation to workload and hardware. However, its auto-completion\nsearchâ€”recursively trying all possible designs ( |E|=1016dis-\ncretized designs)â€” scales poorly, which worsens if we extend Data\nCalculator â€™s periodic table and cost synthesis flowchart with\nlearned indexes. AirIndex solves this challenge for index design.\nLearned Indexes. Previous works largely focus on tuning in-memory\nindexes. [ 53] demonstrates an interactive model tool that allowsusers to modify RMI configuration (per-layer node type and branch-\ning factor) and observe the resulting model fitness. Although the\ntool provides automatic tuning, it measures the lookup latency\nby benchmarking each configuration, which can be expensive on\na larger scale. [ 64] formulates a lookup cost function and tunes\na single maximum error hyperparameter to build a combination\nof RadixSpline [ 43] and a compact histogram tree. In contrast,\nAirIndex encompasses a larger index design space, and more im-\nportantly, targets a different cost setting where I/O cost is dominant.\nMany manually tuned learned indexes have shown success sto-\nries in the context of external storage. [ 26] studies favorable con-\nditions to learn data patterns and integrates learned indexes as an\noptimization into an LSM-based storage system on disk. For NVM\nstorages, [ 22] adapts ALEX [ 31] to cooperate with the preferred\naccess pattern. Instead of predicting locations of written records, [ 9]\nuses learned indexes to distribute data into blocks in BigTable [ 20].\nSimilarly, [ 47] deploys learned indexes to organize on-disk spatial\ndata into shards and pages, reducing I/O costs over other spatial\ntrees. With the learning paradigm at the core, [ 44] re-designs a\ndatabase system that supports data persistence on disk but is only\nevaluated in the in-memory mode without disk accesses. Many\nof these works have already involved parameter tuning but as a\nmanual tuning step for each setting. While we share common tun-\ning principles, AirIndex can be seen as a fine-grained automatic\noptimization of learned index structures.\n9 CONCLUSION\nThis work presents a novel index-building technique, AirIndex ,\nthat can build high-speed hierarchical indexes by learning from\nboth data and I/O characteristicsâ€”the first of its kind. To achieve its\ngoal, AirIndex formulates an optimization problem consisting of a\nlarge hierarchical index search space and a lookup latency objec-\ntive function ( AirIndex-Model ). To overcome the computational\nchallenges rising from the inter-dependency between index layers\nand exponentially many candidate designs, AirIndex explores the\nsearch space using a purpose-built graph-search method ( AirTune ).\nOur experiments verify that AirIndex accurately finds the optimal\nconfiguration and provides performance gains over conventional\nindexes as well as state-of-the-art learned indexes. In many applica-\ntions, the decisions on data placementsâ€”local disks, cloud storage,\nnetwork file systemâ€”are relatively fixed, which makes AirIndex â€™s\ndata-and-I/O-aware optimization appealing to achieve significantly\nfaster lookup compared to the ones not specifically optimized.\nACKNOWLEDGMENTS\nThis work is supported in part by Microsoft Azure.\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\nREFERENCES\n[1] [n.d.]. https://github.com/illinoisdata/airindex-public.\n[2] [n.d.]. https://github.com/illinoisdata/lmdb.\n[3] [n.d.]. https://github.com/illinoisdata/RMI.\n[4] [n.d.]. https://github.com/illinoisdata/PGM-index.\n[5] [n.d.]. https://github.com/illinoisdata/ALEX_ext.\n[6][n.d.]. https://github.com/illinoisdata/airindex-public/tree/main/src/bin/data_\ncalculator.rs.\n[7][n.d.]. A high-performance distributed shared-log for Ceph. https://github.com/\ncruzdb/zlog. [Online; accessed December-27-2022].\n[8][n.d.]. MySQL. https://www.mysql.com/. [Online; accessed December-27-2022].\n[9]Hussam Abu-Libdeh, Deniz AltinbÃ¼ken, Alex Beutel, Ed H. Chi, Lyric Doshi, Tim\nKraska, Xiaozhou Li, Andy Ly, and Christopher Olston. 2020. Learned Indexes\nfor a Google-scale Disk-based Database. CoRR abs/2012.12501 (2020).\n[10] A. M. Andrew. 1979. Another Efficient Algorithm for Convex Hulls in Two\nDimensions. Inf. Process. Lett. 9, 5 (1979), 216â€“219.\n[11] Raja Appuswamy, Goetz Graefe, Renata Borovica-Gajic, and Anastasia Ailamaki.\n2019. The five-minute rule 30 years later and its impact on the storage hierarchy.\nCommun. ACM 62, 11 (2019), 114â€“120.\n[12] Microsoft Azure. [n.d.]. Azure. https://azure.microsoft.com. [Online; accessed\nJul-17-2022].\n[13] Microsoft Azure. [n.d.]. Azure Blob Storage. https://azure.microsoft.com/en-\nus/services/storage/blobs/. [Online; accessed Jul-17-2022].\n[14] Microsoft Azure. [n.d.]. Azure managed disk types. https://docs.microsoft.com/\nen-us/azure/virtual-machines/disks-types. [Online; accessed Jul-17-2022].\n[15] Microsoft Azure. [n.d.]. Network File System (NFS) 3.0 protocol support for Azure\nBlob Storage. https://docs.microsoft.com/en-us/azure/storage/blobs/network-\nfile-system-protocol-support. [Online; accessed Jul-17-2022].\n[16] Mahesh Balakrishnan, Jason Flinn, Chen Shen, Mihir Dharamshi, Ahmed Jafri,\nXiao Shi, Santosh Ghosh, Hazem Hassan, Aaryaman Sagar, Rhed Shi, et al .2020.\nVirtual consensus in delos. In 14th USENIX Symposium on Operating Systems\nDesign and Implementation (OSDI 20) . 617â€“632.\n[17] R. Bayer and E. M. McCreight. 1972. Organization and maintenance of large\nordered indexes. Acta Informatica 1 (1972), 173â€“189. Issue 3. https://doi.org/10.\n1007/BF00288683\n[18] Michael A. Bender, Erik D. Demaine, and Martin Farach-Colton. 2000. Cache-\nOblivious B-Trees. In FOCS . IEEE Computer Society, 399â€“409.\n[19] Huang Bin and Peng Yuxing. 2014. An efficient distributed B-tree index method\nin cloud computing. Open Cybernetics and Systemics Journal 8 (2014). Issue 1.\nhttps://doi.org/10.2174/1874110x01408010302\n[20] Fay Chang, Jeffrey Dean, Sanjay Ghemawat, Wilson C. Hsieh, Deborah A. Wallach,\nMichael Burrows, Tushar Chandra, Andrew Fikes, and Robert Gruber. 2006.\nBigtable: A Distributed Storage System for Structured Data (Awarded Best Paper!).\nInOSDI . USENIX Association, 205â€“218.\n[21] Surajit Chaudhuri and Vivek R. Narasayya. 1998. AutoAdmin â€™What-ifâ€™ Index\nAnalysis Utility. In SIGMOD Conference . ACM Press, 367â€“378.\n[22] Leying Chen and Shimin Chen. 2021. How Does Updatable Learned Index Perform\non Non-Volatile Main Memory?. In ICDE Workshops . IEEE, 66â€“71.\n[23] Shimin Chen, Phillip B. Gibbons, and Todd C. Mowry. 2001. Improving index\nperformance through prefetching. SIGMOD Record (ACM Special Interest Group\non Management of Data) 30 (2001). Issue 2. https://doi.org/10.1145/376284.375688\n[24] Shimin Chen, Phillip B. Gibbons, Todd C. Mowry, and Gary Valentin. 2002. Fractal\nprefetching B+-Trees: Optimizing both cache and disk performance. Proceedings\nof the ACM SIGMOD International Conference on Management of Data .\n[25] Douglas Comer. 1979. UBIQUITOUS B-TREE. Comput Surv 11 (1979). Issue 2.\n[26] Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth,\nAndrea C. Arpaci-Dusseau, and Remzi H. Arpaci-Dusseau. 2020. From WiscKey\nto Bourbon: A Learned Index for Log-Structured Merge Trees. In OSDI . USENIX\nAssociation, 155â€“171.\n[27] Henry Daly, Ahmed Hassan, Michael F. Spear, and Roberto Palmieri. 2018. Nu-\nMask: High performance scalable skip list for NUMA. Leibniz International Pro-\nceedings in Informatics, LIPIcs 121. https://doi.org/10.4230/LIPIcs.DISC.2018.18\n[28] Debabrata Dash, Neoklis Polyzotis, and Anastasia Ailamaki. 2011. CoPhy: A\nScalable, Portable, and Interactive Index Advisor for Large Workloads. Proc.\nVLDB Endow. 4, 6 (2011), 362â€“372.\n[29] Ian Dick, Alan Fekete, and Vincent Gramoli. 2017. A skip list for multicore.\nConcurrency Computation 29 (2017). Issue 4. https://doi.org/10.1002/cpe.3876\n[30] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\nDavid Lomet, and Tim Kraska. 2020. ALEX: An Updatable Adaptive Learned\nIndex. Proceedings of the ACM SIGMOD International Conference on Management\nof Data . https://doi.org/10.1145/3318464.3389711\n[31] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\nDavid B. Lomet, and Tim Kraska. 2020. ALEX: An Updatable Adaptive Learned\nIndex. In SIGMOD Conference . ACM, 969â€“984.[32] Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. 2020. Why Are Learned\nIndexes So Effective?. In Proceedings of the 37th International Conference on Ma-\nchine Learning (Proceedings of Machine Learning Research) , Hal DaumÃ© III and\nAarti Singh (Eds.), Vol. 119. PMLR, 3123â€“3132. https://proceedings.mlr.press/\nv119/ferragina20a.html\n[33] Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-index: a fully-dynamic\ncompressed learned index with provable worst-case bounds. Proc. VLDB Endow.\n13, 8 (2020), 1162â€“1175.\n[34] Martin R. Frank, Edward Omiecinski, and Shamkant B. Navathe. 1992. Adaptive\nand Automated Index Selection in RDBMS. In EDBT (Lecture Notes in Computer\nScience) , Vol. 580. Springer, 277â€“292.\n[35] Goetz Graefe and Per Ã…ke Larson. 2001. B-tree indexes and CPU caches. Pro-\nceedings - International Conference on Data Engineering (2001). https://doi.org/\n10.1109/ICDE.2001.914847\n[36] Jim Gray and Goetz Graefe. 1997. The Five-Minute Rule Ten Years Later, and\nOther Computer Storage Rules of Thumb. SIGMOD Rec. 26, 4 (1997), 63â€“68.\n[37] Jing He, Shao wen Yao, Li Cai, and Wei Zhou. 2018. SLC-index: A scalable skip\nlist-based index for cloud data processing. Journal of Central South University 25\n(2018). Issue 10. https://doi.org/10.1007/s11771-018-3927-0\n[38] Stratos Idreos, Kostas Zoumpatianos, Brian Hentschel, Michael S. Kester, and\nDemi Guo. 2018. The Data Calculator: Data Structure Design and Cost Synthesis\nfrom First Principles and Learned Cost Models. In SIGMOD Conference . ACM,\n535â€“550.\n[39] Stratos Idreos, Kostas Zoumpatianos, Brian Hentschel, Michael S. Kester, and\nDemi Guo. 2018. The Internals of the Data Calculator. CoRR abs/1808.02066\n(2018).\n[40] Ivo Jimenez, Huascar Sanchez, Quoc Trung Tran, and Neoklis Polyzotis. 2012.\nKaizen: a semi-automatic index advisor. In SIGMOD Conference . ACM, 685â€“688.\n[41] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and\nAlfons Kemper. 2018. Learned cardinalities: Estimating correlated joins with\ndeep learning. arXiv preprint arXiv:1809.00677 (2018).\n[42] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2019. SOSD: A Benchmark for Learned\nIndexes. NeurIPS Workshop on Machine Learning for Systems (2019).\n[43] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. In aiDM@SIGMOD . ACM, 5:1â€“5:5.\n[44] Tim Kraska, Mohammad Alizadeh, Alex Beutel, Ed H. Chi, Ani Kristo, Guillaume\nLeclerc, Samuel Madden, Hongzi Mao, and Vikram Nathan. 2019. SageDB: A\nLearned Database System. In CIDR . www.cidrdb.org.\n[45] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The\ncase for learned index structures. Proceedings of the ACM SIGMOD International\nConference on Management of Data . https://doi.org/10.1145/3183713.3196909\n[46] Kenneth Lange. 2016. MM optimization algorithms . SIAM.\n[47] Pengfei Li, Hua Lu, Qian Zheng, Long Yang, and Gang Pan. 2020. LISA: A Learned\nIndex Structure for Spatial Data. In SIGMOD Conference . ACM, 2119â€“2133.\n[48] LMDB. [n.d.]. Lightning Memory-Mapped Database Manager. http://www.lmdb.\ntech/doc/ Online; accessed Jul-17-2022.\n[49] David B. Lomet. 1998. B-tree Page Size When Caching is Considered. SIGMOD\nRec.27, 3 (1998), 28â€“32.\n[50] Baotong Lu, Jialin Ding, Eric Lo, Umar Farooq Minhas, and Tianzheng Wang.\n2021. APEX: A High-Performance Learned Index on Persistent Memory. arXiv\npreprint arXiv:2105.00683 (2021).\n[51] Vincent Y. Lum and Huei Ling. 1971. An optimization problem on the selection\nof secondary keys. In ACM Annual Conference . ACM, 349â€“356.\n[52] Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra,\nAlfons Kemper, Thomas Neumann, and Tim Kraska. 2020. Benchmarking Learned\nIndexes. Proc. VLDB Endow. 14, 1 (2020), 1â€“13.\n[53] Ryan Marcus, Emily Zhang, and Tim Kraska. 2020. CDFShop: Exploring and\nOptimizing Learned Index Structures. In SIGMOD Conference . ACM, 2789â€“2792.\n[54] Patrick E. Oâ€™Neil, Edward Cheng, Dieter Gawlick, and Elizabeth J. Oâ€™Neil. 1996.\nThe Log-Structured Merge-Tree (LSM-Tree). Acta Informatica 33, 4 (1996), 351â€“\n385.\n[55] Postcard. [n.d.]. Postcard: A no_std + serde compatible message library for Rust.\nhttps://github.com/jamesmunns/postcard. [Online; accessed July-17-2022].\n[56] PostgreSQL. [n.d.]. PostgreSQL: The Worldâ€™s Most Advanced Open Source\nRelational Database. https://www.postgresql.org. [Online; accessed July-17-\n2022].\n[57] William Pugh. 1990. Skip lists: a probabilistic alternative to balanced trees.\nCommun. ACM 33, 6 (1990), 668â€“676.\n[58] Ohad Rodeh, Josef Bacik, and Chris Mason. 2013. BTRFS: The Linux B-tree\nfilesystem. ACM Transactions on Storage (TOS) 9, 3 (2013), 1â€“32.\n[59] Mario Schkolnick. 1975. The Optimal Selection of Secondary Indices for Files.\nInf. Syst. 1, 4 (1975), 141â€“146.\n[60] Serde. [n.d.]. Serde. https://serde.rs. [Online; accessed July-17-2022].\n[61] Facebook Open Source. [n.d.]. RocksDB: A persistent key-value store. https:\n//rocksdb.org/. [Online; accessed July-17-2022].\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\n[62] Stefan Sprenger, Steffen Zeuch, and Ulf Leser. 2017. Cache-sensitive skip list:\nEfficient range queries on modern CPUs. Lecture Notes in Computer Science\n(including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in\nBioinformatics) 10195 LNCS. https://doi.org/10.1007/978-3-319-56111-0_1\n[63] SQLite. [n.d.]. SQLite. https://www.sqlite.org. [Online; accessed April-24-2021].\n[64] Mihail Stoian, Andreas Kipf, Ryan Marcus, and Tim Kraska. 2021. PLEX: Towards\nPractical Learned Indexing. CoRR abs/2108.05117 (2021).\n[65] Michael Stonebraker. 1974. The choice of partial inversions and combined indices.\nInt. J. Parallel Program. 3, 2 (1974), 167â€“188.\n[66] Yongjoo Park Supawit Chockchowwat, Wenjie Liu. 2023. AirIndex: Versatile\nIndex Tuning Through Data and Storage (Extended Version). arXiv preprint\n(2023).\n[67] Alexandre Verbitski, Anurag Gupta, Debanjan Saha, Murali Brahmadesam,\nKamal Gupta, Raman Mittal, Sailesh Krishnamurthy, Sandor Maurice, Tengiz\nKharatishvili, and Xiaofeng Bao. 2017. Amazon aurora: Design considerations\nfor high throughput cloud-native relational databases. In Proceedings of the 2017\nACM International Conference on Management of Data . 1041â€“1052.\n[68] Li Wang, Zining Zhang, Bingsheng He, and Zhenjie Zhang. 2020. PA-Tree: Polled-\nmode asynchronous B+ tree for NVMe. Proceedings - International Conference on\nData Engineering 2020-April. https://doi.org/10.1109/ICDE48307.2020.00054\n[69] Youyun Wang, Chuzhe Tang, Zhaoguo Wang, and Haibo Chen. 2020. SIndex: A\nScalable Learned Index for String Keys. In Proceedings of the 11th ACM SIGOPS\nAsia-Pacific Workshop on Systems (Tsukuba, Japan) (APSys â€™20) . Association for\nComputing Machinery, New York, NY, USA, 17â€“24. https://doi.org/10.1145/\n3409963.3410496\n[70] Xingda Wei, Rong Chen, and Haibo Chen. 2020. Fast RDMA-based Ordered\nKey-Value Store using Remote Learned Cache. In 14th USENIX Symposium on\nOperating Systems Design and Implementation (OSDI 20) . USENIX Association,\n117â€“135. https://www.usenix.org/conference/osdi20/presentation/wei\n[71] Sai Wu, Dawei Jiang, Beng Chin Ooi, and Kunlung Wu. 2010. Efficient btree\nbased indexing for cloud data processing. Proceedings of the VLDB Endowment 3\n(2010). Issue 1. https://doi.org/10.14778/1920841.1920991\n[72] Wei Zhou, Jin Lu, Zhongzhi Luan, Shipu Wang, Gang Xue, and Shaowen Yao.\n2014. SNB-index: A SkipNet and B+ tree based auxiliary Cloud index. Cluster\nComputing 17 (2014). Issue 2. https://doi.org/10.1007/s10586-013-0246-y\nAAIRINDEX IN DETAIL\nA.1 Layer Builders\nA layer builder turns the target key-position collection ğ·into an\nindex layer Î˜. In other words, it is a function ğ¹(ğ·)=Î˜where\nğ·={(ğ‘¥ğ‘–,ğ‘¦ğ‘–)}ğ‘›\nğ‘–=1is a collection of keys ğ‘¥ğ‘–together with their\npositionsğ‘¦ğ‘–, andÎ˜={(ğ‘§ğ‘—,ğœƒğ‘—)}ğ‘›+\nğ‘—=1is the index layer containing\nthe per-node parameters ğœƒğ‘—with per-node key range [ğ‘§ğ‘—,ğ‘§ğ‘—+1). To\nbuild two types of nodes ( step andband , sketched in Figure 6),\nAirIndex currently deploys three types of layer builders below.\n(1)Greedy Step (GStep(ğ‘,ğœ†ğºğ‘†)) builds ağ‘-piece step function\nwith precision at most ğœ†ğºğ‘†bytes. It iterates over each key-\nposition pair(ğ‘¥ğ‘–,ğ‘¦ğ‘–)and greedily determines whether to create\nthe next constant function if ğ‘¦+\nğ‘–âˆ’ğ‘ğ‘˜>ğœ†ğºğ‘†where(ğ‘ğ‘˜,ğ‘ğ‘˜)\nrepresents the current constant function. If so, the next con-\nstant function has a partition key ğ‘ğ‘˜+1=ğ‘¥ğ‘–and partition posi-\ntionğ‘ğ‘˜+1=ğ‘¦ğ‘–. Once it reaches ğ‘pieces of constant functions,\nGStep(ğ‘,ğœ†ğºğ‘†)generates a ğ‘-piece step node.\n(2)Greedy Band (GBand(ğœ†ğºğµ)) builds linear band nodes by greed-\nily fitting as many key-position pairs as possible, using a method\ncalled monotone chain convex hull [ 10], until we have Î”(ğ‘¥ğ‘–)>\nğœ†ğºğµ. Then, it generates a band node with(ğ‘¥1,ğ‘¦1,ğ‘¥2,ğ‘¦2,ğ›¿). For\nğ‘›key-position pairs, the convex hull inserts a key-position pair\ninğ‘‚(ğ‘›)time (ğ‘‚(1)amortized insertion) and answers a feasibil-\nity query in ğ‘‚(ğ‘›logğ‘š)time (ğ‘‚(logğ‘š)amortized query) where\nğ‘šis the average number of key-position pairs included in one\nlinear band. Typically, ğ‘šis small when ğœ†ğºğµis small.\n(3)Equal Band (EBand(ğœ†ğ¸ğµ)) builds linear band nodes by group-\ning key-position pairs in equal-size position ranges. That is,\neach group{(ğ‘¥ğ‘™,ğ‘¦ğ‘™),(ğ‘¥ğ‘™+1,ğ‘¦ğ‘™+1),...,(ğ‘¥ğ‘Ÿ,ğ‘¦ğ‘Ÿ)}has a boundedposition range|ğ‘¦âˆ’\nğ‘™âˆ’ğ‘¦+ğ‘Ÿ|â‰¤ğœ†ğ¸ğµ. It then fits a linear band func-\ntion to each group and creates a band node. Note that the pre-\ncision Î”(ğ‘¥ğ‘–)can vary depending on how â€œlinearâ€ the group is.\nEBand(ğœ†ğ¸ğµ)groups by position ranges rather than key ranges\nso that the worst-case precision is controlled by ğœ†ğ¸ğµ.\nFirst, GStep(ğ‘,ğœ†ğºğ‘†)is equivalent to bulk indexing in a sparse B-tree\nwith a fanout ğ‘and page size ğœ†ğºğ‘†bytes. Second, GBand(ğœ†ğºğµ)is a\ngeneralization from step functions to linear functions with precision\nÎ”(ğ‘¥ğ‘–)â‰¤ğœ†ğºğµ. Third, EBand(ğœ†ğ¸ğµ)is another generalization focusing\non the key-position group size |ğ‘¦âˆ’\nğ‘™âˆ’ğ‘¦+ğ‘Ÿ|â‰¤ğœ†ğ¸ğµ.\nGranularity Exponentiation. ğœ†ğºğ‘†,ğœ†ğºğµ, andğœ†ğ¸ğµare called gran-\nularity , which roughly control layer buildersâ€™ tendency to split\nkey-position pairs apart. Because they correlate with the result-\ning nodeâ€™s precision Î”(ğ‘¥;Î˜),AirIndex needs to determine the\nappropriate granularity for each node type.\nAirIndex creates many candidate layer builders Fby sampling\nthe granularity on an exponential grid: ğœ†ğ‘™ğ‘œğ‘¤,ğœ†ğ‘™ğ‘œğ‘¤(1+ğœ–),ğœ†ğ‘™ğ‘œğ‘¤(1+\nğœ–)2,...ğœ†â„ğ‘–ğ‘”â„ where(ğœ†ğ‘™ğ‘œğ‘¤,ğœ†â„ğ‘–ğ‘”â„)are the bounds and ğœ–>0controls\nthe exponentiation base. Smaller ğœ–implies a finer search which\nimproves optimization accuracy but increases tuning time.\nA.2 Cache\nAirIndex uses a read-through cache in local memory. That is, if a\nread range is present in the cache, AirIndex gets the layer view\ndirectly from it. Otherwise, AirIndex reads from storage and fills\nin the corresponding cache page(s). Filling a cache page and getting\na layer view are both zero-copy operations: they do not copy the\nraw bytes but only their references. As the cache fills up, AirIndex\navoids more expensive storage reads, offering faster lookup speed;\nnevertheless, to offer consistent performance, our optimization\nminimizes the worst-case latency when there is no cached data.\nA.3 Index Complexity\nBefore branching out, AirIndex selects only top- ğ‘˜candidates with\nthe highest potential to be in the optimal design. Suppose there\nexists an oracle that minimizes the objective function on a key-\nposition collection ğ·under the storage profile. We call the optimal\nsearch cost under storage profile ğ‘‡:index complexity ğœ(ğ·;ğ‘‡). If\nğœ(ğ·;ğ‘‡)is known, selection of candidates C={(Î˜ğ‘–,ğ·ğ‘–)}|F|\nğ‘–=1would\nbe as straightforward as Eq (11). That is, we could simply select the\ntop-1 candidate and avoid branching out.\n(Î˜âˆ—,ğ·âˆ—)=arg min\n(Î˜ğ‘–,ğ·ğ‘–)âˆˆCğœ(ğ·ğ‘–)+ E\nğ‘¥âˆ¼X[ğ‘‡(Î”(ğ‘¥;Î˜ğ‘–))] (11)\nUnfortunately, ğœ(ğ·;ğ‘‡)is unknown for a large class of indexes\nsupported by AirIndex . Instead, AirIndex uses a surrogate upper\nbound to the index complexity: step index complexity Ë†ğœ(ğ·;ğ‘‡)â‰¥\nğœ(ğ·;ğ‘‡). Specifically, Ë†ğœ(ğ·;ğ‘‡)imitates a step-function hierarchical\nindex that partitions the key-position collection ğ·into groups with\narbitrary position ranges. Let ğ‘ ğ·=ğ‘¦+\n|ğ·|âˆ’ğ‘¦âˆ’\n1be the total size of\nthe candidate layer, Ë†ğœ(ğ·;ğ‘‡)tries to build ideal step indexes with\ndifferent numbers of layers ğ¿âˆˆ{0,1,...,ğ‘‚(logğ‘ ğ·)}. For eachğ¿, it\nperfectly balances both root layer size and subsequent precisions so\nthatğ‘ (Î˜ğ¿)=Î”(ğ‘¥;Î˜ğ‘™)=ğ¿+1âˆšï¸ƒ\nğ‘ ğ·ğ‘ ğ¿\nğ‘ ğ‘¡ğ‘’ğ‘. This considers the total size\nğ‘ ğ·and the ideal size for each 1-piece step node ğ‘ ğ‘ ğ‘¡ğ‘’ğ‘ (e.g., 16 bytes\nfor 8-byte key and position types). Lastly, Ë†ğœ(ğ·;ğ‘‡)then outputs the\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\n1 102104106050100150\nNumber of QueriesLatency (ms/op)\n(a) NFS ( B-tree )1 102104106050100150\nNumber of QueriesLatency (ms/op)\n(b) NFS ( AirIndex )1 102104106012\nNumber of QueriesLatency (ms/op)\n(c) SSD ( B-tree )1 102104106012\nNumber of QueriesLatency (ms/op)Data Layer\nLayer 1\nLayer 2\nRoot Layer\n(d) SSD ( AirIndex )\nFigure 17: Latency breakdown of B-tree andAirIndex by the time spent reading different layers. The books dataset is used.\nWe vary the warmness by the number of queries from one to 1 million from left to right in logarithmic scale. Layer-wise\nlatencies are stacked from bottom up in their retrieval order (root index layer to data layer). For visual purposes, the plots then\ninterpolate linearly and fill areas in between with different colors indicating different layers.\n1 1021041060%5%10%\nNumber of QueriesLatency FractionSSD\nNFS\n(a) Non-I/O Fraction1 1021041060%0.5%1%\nNumber of QueriesLatency Fraction\n(b) Non-I/O Breakdown on NFS1 1021041060%5%10%\nNumber of QueriesLatency FractionOther\nFind\nPredict\nDeser.\nCache\n(c) Non-I/O Breakdown on SSD\nFigure 18: Latency breakdown of AirIndex â€™s non-I/O operations over different levels of warmness (indicated by the numbers\nof queries from one to 1 million). Left: the fraction of non-I/O operationsâ€”the rest is for I/O operations. Middle and right: a\ndeeper breakdown of latency spent on different types of I/O operations on NFS and SSD, respectively.\nlowest storage model cost as the step index complexity (Eq (12)).\nË†ğœ(ğ·;ğ‘‡)= min\nğ¿âˆˆ{0,1,...,ğ‘‚(logğ‘ ğ·)}(ğ¿+1)Ã—ğ‘‡\u0010\nğ¿+1âˆšï¸ƒ\nğ‘ ğ·ğ‘ ğ¿\nğ‘ ğ‘¡ğ‘’ğ‘\u0011\n(12)\nNote that Ë†ğœ(ğ·;ğ‘‡)is only interested in the integer ğ‘ ğ·(not the dis-\ntribution ofğ·); thus, Ë†ğœ(ğ·;ğ‘‡)can be arithmetically computed (hence\ncheap). Figure 8 shows the general shape of Ë†ğœ(ğ·;ğ‘‡)with respect\nto the collection size ğ‘ ğ·, under an affine storage profile ğ‘‡. Notice\nthe sudden index complexity cliffs (such as those around ğ‘ ğ·=1MB\nin Figure 8b), marking the boundaries between different chosen\nnumbers of layers. The technique to minimize an objective based\non its cheaper upper bound is related to majorize-minimization\nalgorithms [46].\nB BASELINES\nWe compare AirIndex to a traditional database index, learned\nindexes, and our manual configuration counterpart, hosted at their\nrespective forks2.\nLMDB .LMDB [48] is a B-tree database that accesses its data on\nstorage through mmap . We have also tested PostgreSQL [ 56] and\nRocksDB [ 61] but decided to present LMDB due to its competitive\nperformance in our setting.\nRMI.RMI [41] is a top-down learned index with a compact two-\nlayer structure where the top one contains only one perfectly accu-\nrate node partitioning key space to the bottom nodes. To build one,\nwe execute its provided optimizer for each dataset and select the\nmost accurate configuration describing index size and model types.\nWe then integrate RMI onto external memory setting by mmap -ing\n2https://github.com/illinoisdata/lmdb, https://github.com/illinoisdata/RMI, https://\ngithub.com/illinoisdata/PGM-index, https://github.com/illinoisdata/ALEX_ext, https:\n//github.com/illinoisdata/airindex-public/tree/main/src/bin/data_calculator.rsits parameter arrays so RMI can access its parameters through the\nOS buffer cache.\nPGM-index .PGM-index [33] is a learned index with bounded\nprecision across all layers. PGM-index partitions the key-position\ncollection to build the next bottom-most layer towards the top. To\nbenchmark in our settings, we use the MappedPGMIndex variant\nthat operates on file systems. Although its tuner does not satisfy\nour target (fastest index, regardless of size), we adjust its error level\nğœ€âˆˆ {16,32,..., 1024}to microbenchmark on wiki (chosen one\narbitrarily) and finally pick ğœ€=128.\nALEX/APEX .ALEX/APEX [31] is an updatable learned index built\ntop-down like RMI but further arrange key-value pairs in its layout\n(notably, â€œgapped arrayâ€ to buffer structural changes). We inte-\ngrate ALEX/APEX onto external memory setting by mmap -ing its\nserialized node objects, key arrays, and value arrays.\nPLEX .PLEX [64] is a learned index with compact Hist-Tree (CHT)\nlayered on top of RadixSpline [ 43] (RS). We integrate PLEX onto\nexternal memory setting through mmap similarly to ALEX/APEX .\nAlthough PLEX optimizes most parameters, its user need to specify\nthe maximum prediction error ğœ–. We selectğœ–=2048 based on a\nbenchmark on a setting (Figure 12d).\nData Calculator .Data Calculator [38,39] is a data layout\ndesign engine that calculates the performance of a data struc-\nture. For index learning, we extend Data Calculator to auto-\ncomplete recursion allowed (number of layers), fanout ,key\npartitioning . By following its cost synthesis flowcharts (Fig 5 in\n[38] and Fig 29 in [ 39]), we identify data access primitives, profile\nthem on SSD and NFS for cost models, and execute a parallelized\nauto-completion flow. Later, the selected data layout is built within\nAirIndex â€™s framework.\n\nAirIndex : Versatile Index Tuning Through Data and Storage SIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023)\n; ; ; ; LMDB RMI PGM-index ALEX/APEX\n; ; ; Data Calculator B-tree AirIndex\n0.5 1.0 2.00100200300400\nSkewnessLatency (ms)\n(a) One-query Latency0.5 1.0 2.0102103104\nSkewnessLatency (ms)\n(b) 100-query Latency\nFigure 19: Effects of skewed query key distribution latency\nacross different methods on books dataset. Left: first query\nlatency over skewnesses 0.5, 1.0, and 2.0. Right: 100th latency\nover the same skewnesses.\nB-tree .A B-tree-like structure implemented using AirIndex â€™s\nframework. It has 255-piece step nodes built with GStep(ğ‘=\n255,ğœ†ğºğ‘†=4096), which is equivalent to a B-tree with 4KB node\npages and 255 fanout factors. This is the most controlled baseline\nwhere the only difference is AirIndex â€™s storage- and data-aware\ntuning.\nC EXTENDED EXPERIMENTS\nC.1 Latency Breakdown\nWe investigate the effect of our optimization by studying latency\nbreakdowns, by layers and by operations, respectively.\nBy Layer. We first decompose the end-to-end latency into the times\nspent in retrieving each layer which includes I/O, cache read, and\nall internal computation. Apart from some small exceptions, latency\nmeasurements across layers roughly follow the storage profiles:\nlarger root size ğ‘ (Î˜ğ¿)and coarser precision Î”ğ‘™(ğ‘¥;Î˜ğ‘™)reflects in a\nlonger latency spent in the corresponding layer. Over numbers of\nqueries, we also observe the alternating acceleration phenomenon\nin more details. That is, the fast acceleration region indicate that\nthe topmost partially cached index layer is becoming fully cached.\nFor example, in Figure 17c between 103and104queries, B-tree\nsearches faster because the speedup in its layer-1 index.\nThis breakdown also reveals factors unaccounted for in AirIndex .\nFor a prominent example, in the first query under SSD (Figures 17c\nand 17d), both AirIndex andB-tree spend more time reading their\nroot and data layers as opposed to reading other index layers. This\nis because index layers and data layer are stored in separate directo-\nries, forcing the file system ( ext4 ) to slowly walk through different\npaths of directory entries (dentry) to fetch index-layer and data-\nlayer inodes. Consequently, reading subsequent index layers stored\nin the same directory is then significantly faster than expected.\nAlthough these missing characteristics are crucial for future works\ntowards maximally fast indexes, we believe that AirIndex â€™s storage\nprofile is at an appropriate level of abstraction to adapt to diverse\ntypes of storage.\nBy Operation. We categorize AirIndex â€™s operations into I/O and\nnon-I/O groups. The latter group contains in-memory caching,\ndata structure deserialization, node prediction, relevant key-value\nfinding, and other negligible steps. Figure 18a shows that these\nnon-I/O operations only account for up to 1.0%on NFS and 9.0%\non SSD, even after 1 million queries. These small non-I/O fractions\nmatches with our expectation. Because of its 4KBâ€“5KB average0 10 20 30050100150\nğ‘˜, top-ğ‘˜candidatesBuild Time (s)\n780800820840\nCostL(ğœ‡ğ‘ )\nBuild Time\nCostL\nğ‘˜=5\nFigure 20: Effects of hyperparameter ğ‘˜in selecting top- ğ‘˜\ncandidates to overall AirIndex â€™s building time and cost L.\nWe use books dataset and SSD profile.\nprecisions of tuned structures on NFS and SSD, AirIndex needs\nmore than a million query to completely cache the 6.4GB data layer.\nAs an improvement on its warm-state performance, AirIndex can\nprefetch to warm up its cache more aggressively.\nFigures 18b and 18c delve deeper into non-I/O operations to put\ntheir significance into perspective. We found that caching occupies\nnon-I/O latencies increasingly over warmness. In the first query,\ndeserialization dominates because it needs to deserialize the root-\nmetadata file, send the root layer to cache, and reconstruct a nested\ndata structure for query processing. These two observations explain\nthe U-shape fraction of non-I/O operations on SSD. Aside from\nthose, finding operations (i.e. the last mile binary search) take a\nconsiderable portion within non-I/O latency, but incomparably\nsmall compared to I/O. If they were to grow larger, AirIndex would\nhave to consider smoothly transitioning to in-memory index rather\nthan a binary search on cache. Lastly, as expected, node prediction\nis insignificant given that our current node types are simple.\nC.2 Skewed Workload\nAlthough AirIndex â€™s objective (Eq (7)) considers the query dis-\ntributionX, future query distributions may change unexpectedly.\nThis experiment (Figure 19) builds AirIndex on the uniform distri-\nbutionXbut requests keys sampled from a Zipf distribution with\nparameters 0.5 (least skewed), 1.0, and 2.0 (most skewed). The more\nskewed the query is, the faster all methods can respond at warm\nstate (Figure 19b). However, the skew does not affect first-query\nlatency as much across all methods (Figure 19a). Because AirIndex\nis tuned for cold-state latency, higher skewness results in a quicker\ntakeover. For example, it takes 12k uniform queries for any meth-\nods (PGM-index ) to take over AirIndex , but only 70, 41, and 725\nqueries in 0.5, 1.0, and 2.0 Zipf query.\nC.3 Top-k Candidate Parameter Sweep\nAcross all experiments, we set ğ‘˜=5as an arbitrary constant greater\nthan one and less than the number of node builders ( |F|=45). In\nthis experiment, we vary this hyperparameter ğ‘˜to verify our un-\nderstanding: as ğ‘˜increases, build time should increase in ğ¿-degree\npolynomial ( ğ¿=2in this setting) while the optimized cost should\nmonotonically decrease. Figure 20 reaffirms this hypothesis, but also\nshows that the available parallelism (192 CPUs) is able to hide the\npolynomial build time more than we had expected (taking around\n50 seconds up until ğ‘˜=20), implying that we could have selected a\nhigherğ‘˜to get a faster index at no additional build time cost.\n\nSIGMOD â€™24, June 11â€“16, 2024, Santiago, Chile (Accepted 23 May 2023) Supawit Chockchowwat, Wenjie Liu, Yongjoo Park\nReceived 15 January 2023; revised 20 April 2023; accepted 23 May 2023",
  "textLength": 103839
}