{
  "paperId": "2aeab23e567eaa78f2e6704825ba4601472969b8",
  "title": "NeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks",
  "pdfPath": "2aeab23e567eaa78f2e6704825ba4601472969b8.pdf",
  "text": "NeuralVDB: High-resolution Sparse Volume Representation using\nHierarchical Neural Networks\nDOYUB KIM, NVIDIA, USA\nMINJAE LEE, NVIDIA, USA\nKEN MUSETH, NVIDIA, USA\nGround Truth\n1.5 GBNeuralVDB\n25 MBGround Truth\n22.7 GBNeuralVDB\n1.2 GB\nFig. 1. Application of NeuralVDB to the Disney Cloud dataset [Walt Disney Animation Studios 2017] (left) and a time-series of narrow-band level sets of an\nanimated water surface generated from a high-resolution simulation of a space ship breaching rough sea (right). The file size of the Disney Cloud, represented\nby the industry standard OpenVDB encoded with 16-bit quantization and Blosc compression, is 1.5ùê∫ùêµ. However, the corresponding NeuralVDB file only has\na footprint of 25ùëÄùêµ, resulting in a reduction by a factor of 60. For the space ship breaching simulation, the accumulated file sizes for the entire sequence\nof the water surface, using OpenVDB with the same compression (16-bit and Blosc), is 22.7ùê∫ùêµ, whereas the NeuralVDB representations only have a total\nfootprint of 1.2ùê∫ùêµ, corresponding to a reduction by a factor of 18.\nWe introduce NeuralVDB, which improves on an existing industry stan-\ndard for efficient storage of sparse volumetric data, denoted VDB [Museth\n2013], by leveraging recent advancements in machine learning. Our novel\nhybrid data structure can reduce the memory footprints of VDB volumes\nby orders of magnitude, while maintaining its flexibility and only incurring\nsmall (user-controlled) compression errors. Specifically, NeuralVDB replaces\nthe lower nodes of a shallow and wide VDB tree structure with multiple\nhierarchical neural networks that separately encode topology and value\ninformation by means of neural classifiers and regressors respectively. This\napproach is proven to maximize the compression ratio while maintaining the\nspatial adaptivity offered by the higher-level VDB data structure. For sparse\nsigned distance fields and density volumes, we have observed compression\nratios on the order of 10√óto more than 100√ófrom already compressed VDB\ninputs, with little to no visual artifacts. Furthermore, NeuralVDB is shown\nto offer more effective compression performance compared to other neural\nrepresentations such as Neural Geometric Level of Detail [Takikawa et al .\n2021], Variable Bitrate Neural Fields [Takikawa et al .2022a], and Instant\nNeural Graphics Primitives [M√ºller et al .2022]. Finally, we demonstrate how\nwarm-starting from previous frames can accelerate training, i.e., compres-\nsion, of animated volumes as well as improve temporal coherency of model\ninference, i.e., decompression.\nCCS Concepts: ‚Ä¢Computing methodologies ‚ÜíVolumetric models .\nAdditional Key Words and Phrases: sparse volumes, neural networks, implicit\nsurface, volumetric models, compression\nAuthors‚Äô addresses: Doyub Kim, NVIDIA, USA, doyubkim@nvidia.com; Minjae Lee,\nNVIDIA, USA, minjael@nvidia.com; Ken Museth, NVIDIA, USA, kmuseth@nvidia.com.1 INTRODUCTION\nSparse volumetric data are ubiquitous in many fields including sci-\nentific computing and visualization, medical imaging, industrial\ndesign, rocket science, computer graphics, visual effects, robotics,\nand more recently machine learning applications. As such it should\ncome as no surprise that several compact data structures have been\nproposed over the years for efficient representations of sparse vol-\numes. One of these sparse data structures has gained widespread\nadoption in especially the entertainment industry, namely Open-\nVDB, and is showing signs of increased adoption in several other\nfields [Achilles et al. 2016; Boddeti et al. 2020; Vizzo et al. 2022].\nOpenVDB is based on the unique hierarchical tree data structure\nintroduced by [Museth 2013]. At the core it is a shallow (typically\nfour-level) tree with high but varying fanout factors (e.g., 323‚Üí\n163‚Üí83‚Äînumber of nodes per level from top to bottom), and\nthe ability to efficiently look up values through fast bottom-up, vs.\nslower top-down, node access patterns. While its initial open source\nimplementation, OpenVDB, was limited to CPUs, a read-only GPU\nvariant, dubbed NanoVDB, was recently developed [Museth 2021]\nand added to the open source library. However, VDB is obviously\nnot a silver bullet, and fundamentally suffers from the same lim-\nitations as other lossless volumetric data structures: the memory\nfootprint is never smaller than that incurred by the sparse non-\nconstant voxel values, e.g., signed distance or density values. To\na lesser extent the same is true for the topology-information of\nthe sparse voxels, which are compactly encoded into bitmasks of\nthe tree nodes in VDB. To provide some context, the Disney CloudarXiv:2208.04448v2  [cs.LG]  11 Feb 2024\n\n2 ‚Ä¢Kim, Lee, and Museth\nis 1.5 GB with conventional data compression techniques and 16-\nbit quantization (shown in Figure 1). This size can easily explode\ninto terabytes of data per simulation sequence or high-resolution\nvolumetric scenes. These data sets are frequently shared between\ndata consumers and/or cloud storage, where both data storage and\ntransactions are typically costly. While many scenarios require raw,\nlossless data, other workflows can tolerate some degree of lossy\ncompression in exchange for a lighter data footprint, akin to using\nJPEG images in place of raw images. This raises the question, are\nthere more compact, possibly lossy, representations for the topology\nand value information encoded into a VDB structure, that maintain\nmany of the advantages of the proven VDB tree structure?\nWe will spend the remainder of this paper demonstrating, that\nunder the same assumptions as NanoVDB, i.e., static topology and\nvalues, this is indeed the case, resulting in a new hybrid data struc-\nture, which we have dubbed NeuralVDB.\nThe key to unlocking the promise of NeuralVDB is, as the name in-\ndicates, neural networks. Recently neural scene representations have\ngained a lot of attention from the research community, especially\naround implicit geometry [Liu et al .2020; Mescheder et al .2019a;\nMichalkiewicz et al .2019; Park et al .2019] or radiance fields [Milden-\nhall et al .2020; Yu et al .2021]. Essentially, the neural representa-\ntion encodes the field function that maps multi-dimensional input\n(such as positional coordinates or directions) to a field value (such\nas SDF, occupancy, density, or radiance) using neural networks.\nThanks to the flexibility and differentiability of neural networks, this\nnew approach opened up a variety of applications, including novel\nview reconstruction [Mildenhall et al .2020], compression [Davies\net al.2020; Li et al .2022; Takikawa et al .2022a], adaptive resolu-\ntion [Takikawa et al .2021], etc. Nonetheless, as we will illustrate in\nSection 4.6 through additional comparisons with established neural\nscene representation techniques, relying solely on a neural approach\nfalls short in delivering a model that balances both high quality and\ncompact size. By hybridizing a state-of-the-art data structure with a\nneural representation, NeuralVDB surpasses other methods in both\nqualitative and quantitative measures.\nWe propose a new approach to memory efficient representations\nof static sparse volumes that combines the best of two worlds: neural\nscene representations have demonstrated that neural networks can\nachieve impressive compression of 3D data, and VDB offers an effi-\ncient hierarchical partitioning of sparse 3D data. This combination\nallows a VDB tree to focus on coarse upper node level topology\ninformation, while multiple neural networks compactly encode fine-\ngrain topology and value information at the voxel and lower tree\nlevels. This also applies to animated volumes, even maintaining\ntemporal coherency and improving performance with our novel\ntemporal encoding feature.\nWe outline the goals, non-goals, and constraints of NeuralVDB\nas follows:\n‚Ä¢The overarching goal of NeuralVDB is to significantly re-\nduce both the off-line, e.g., file, and on-line, e.g., memory,\nfootprints of sparse volumetric data represented with the\nVDB data structure. We achieve this goal by means of com-\npact neural representations of both the spatial occupancy,\ni.e., topology, and the values of the sparse volumes.‚Ä¢Anon-goal of NeuralVDB is to improve the speed of vol-\nume rendering. That is, we are willing to sacrifice rendering\nspeeds for the sake of reducing the file or memory footprints.\nWhile we make efforts to minimize this performance trade-\noff, and even offer two versions of NeuralVDB with different\nratios of compression to access-performance, we emphasize\nthat the objective of this paper is not to propose a faster data\nstructure for volume rendering.\n‚Ä¢An important design constraint of NeuralVDB is to pre-\nserve information represented in the input VDB volumes as\nmuch as possible, as well as to maintain compatibility with\nexisting VDB pipelines. That is, we reuse the VDB tree struc-\nture and its API as such as possible, use lossless compression\nof spatial occupancy, i.e., topology information, and adaptive\nlossy compression for the values of the sparse volumes.\nMore precisely we summarize our contributions as follows:\nMemory Efficiency. The main focus of NeuralVDB is data compres-\nsion, both out-of-core and in-memory. In contrast, OpenVDB only\nprovides out-of-core compression, like Blosc and Zlib [Gailly and\nAdler 2004]. In-core representations of OpenVDB apply no compres-\nsion to the sparse values, and only per-node bitmask compression\nof the topology, i.e., sparse coordinates. While NanoVDB improves\non OpenVDB by offering in-core variable bitrate quantization of the\nsparse values, the compression ratio of NanoVDB rarely exceeds\n6√ó, when low quantization noise is desired. Conversely, for in-core\nrepresentations NeuralVDB typically offers an order of magnitude\nhigher compression ratio than NanoVDB, and two orders of mag-\nnitude higher compression ratio than OpenVDB. However, neither\ndata-agnostic compression techniques like Zlib nor bit-quantization\nleverage feature level similarities of sparse voxels.\nNeural networks, on the other hand, can be designed to discover\nsuch hidden features and can infer values without reconstructing\nthe entire data set. NeuralVDB exploits such characteristics of neural\nnetworks to effectively compress volumetric data while simultane-\nously supporting random access.\nCompatibility. NeuralVDB is designed to be compatible with ex-\nisting VDB pipelines. Specifically, NeuralVDB representations can\nreadily be encoded from VDB data and decoded back into VDB\nrepresentations, with small often invisible reconstruction errors.\nBorrowing standard terminology from machine learning we refer\nto these steps as training and inference, respectively. While Neu-\nralVDB is designed to encode topology information exactly, values\nare encoded with a lossy compressor whose key objective is to retain\nas much information as possible during the training. For instance,\na NeuralVDB structure shares the same higher level tree structure\nwith standard VDB. The hierarchical network, which replaces the\nlower level structure is also designed to reconstruct the original\nVDB tree levels. As such, NeuralVDB supports both out-of-core and\nin-core decompression, which can be utilized respectively as an\noffline compression codec or alternatively for online applications\nlike rendering that require direct in-memory access.\nThe remainder of this paper is organized as follows: in Section 2\nwe review related work, followed by a brief summary of the key\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢3\nfeatures of VDB and the framework supporting NeuralVDB in Sec-\ntion 3. Finally, we validate our performance claims of NeuralVDB in\nSection 4 and conclude with a discussion of limitations and future\nwork in Section 5.\n2 RELATED WORK\nIn this section, we review previous studies discussing efficient repre-\nsentation and computation of sparsely distributed volumetric data.\n2.1 Data Compression\nWhile there is a wide variety of algorithms for data compression, we\nshall limit our discussion to three subcategories that best highlight\nthe difference between traditional compression techniques and the\nnovel approach of NeuralVDB.\nThe first category of compression techniques includes data-agnostic\nalgorithms like Zlib [Gailly and Adler 2004]. As mentioned in the\nprevious section, these algorithms are great at compressing arbi-\ntrary data, but by design cannot exploit geometric structures or\npatterns present in the data. It can, however, be utilized to com-\npress the last layer of our neural networks. For instance, similarly\nto OpenVDB, NeuralVDB uses Blosc [The Blosc Development Team\n2020] to compress the serialized buffer.\nThe second class of compression techniques is best described\nasapplication-specific algorithms similar to JPEG [Pennebaker and\nMitchell 1992] for images or MPEG [Le Gall 1991] for videos. The\nextension of 2D JPEG algorithms to 3D can be a good candidate for\nvolumetric data. However, it is not directly applicable to VDB, since\nJPEG is based on spectral analysis of 2D images (by means of discrete\ncosine transformations), which operates on dense domains, whereas\nVDB is inherently sparse in 3D. However, we have seen promise\nin recent studies that employ neural networks for compression\nproblems [Kirchhoffer et al .2021; Ma et al .2019] or even combining\nconventional compression techniques with neural approaches [Liu\net al.2018] to exceed the compression performance of the original\nalgorithm. There are mesh based compression methods [Pajarola\nand Rossignac 2000; Sattler et al .2005; Valette and Prost 2004], which\ncan only handle meshes as oppose to sparse volumes.\nLastly, the third type of compression is statistical approaches such\nas principal component analysis (PCA) or auto-encoders (AE). These\ntechniques are based on learned models that are derived from train-\ning data. By transforming the input space into a reduced latent\nspace, high dimensional input data can be represented with rela-\ntively small-sized vectors. In fact, some of the earlier studies on\nneural-implicit representation, such as DeepSDF [Park et al. 2019],\nutilize AE to further compress the SDF volumes. This approach,\nhowever, requires the input space to be known and/or normalized\ninto a known shape. NeuralVDB takes a different approach in that\nit deliberately \"over-fits\" to the input volume, i.e., memorizes the\ninput as much as possible. This approach trades off statistical knowl-\nedge that could be learned from data with flexibility that can take\narbitrary inputs.\n2.2 Sparse Grid\nWhile there is a large body of work on sparse data structures in\ncomputer graphics, we shall limit our discussion to sparse grids inthe context of numerical simulation and rendering, which are the\ncore target applications of NeuralVDB.\nOne such key application is level set methods, which are essen-\ntially time-dependent truncated signed distance fields (SDF). These\nare efficiently implemented with narrow-band methods that track\na deforming zero-crossing interface [Peng et al .1999]. Additional\nmemory efficiently has been demonstrated with adaptive structures\nlike octree grids [Bargteil et al .2006; Losasso et al .2004; Strain\n2001], Dynamic Tubular Grids (DT-Grid, based on compressed-row-\nstorage) [Nielsen and Museth 2006], or tall-cell grids [Chentanez\nand M√ºller 2011; Irving et al. 2006].\nMore flexible data structures for generic simulation and data\ntypes include Hierarchical Run-length Encoding (HRLE) grid [Hous-\nton et al .2006], B+Grid (precursor to VDB) [Museth 2011], VDB\n(open sourced as OpenVDB) [Museth 2013], Field3D (tiled dense\ngrid) [Wrenninge et al .2020], Sparse Paged Grid (SPGrid, inspired\nby VDB) [Setaluri et al .2014], GVDB (loosely based on VDB) [Hoet-\nzlein 2016], KDSM (Kinematically Deforming Skinned Mesh) [Lee\net al.2018, 2019] and more recently NanoVDB (strictly based on\nVDB) [Museth 2021].\n2.3 Neural Representation\nThe idea of utilizing neural networks to represent volumetric data is\nby no means novel. Examples include occupancy field [Mescheder\net al.2019a; Peng et al .2020], implicit surface like SDF [Chen and\nZhang 2019; Mescheder et al .2019b; Michalkiewicz et al .2019;\nPark et al .2019; Tang et al .2018, 2020], and multi-dimensional\ndata like radiance field [Mildenhall et al .2020] are encoded using\nneural networks. Most of these studies utilize coordinate-based\nneural networks and feature mapping/encoding techniques such\nas SIREN [Sitzmann et al .2020b], Fourier Feature Mapping [Tan-\ncik et al .2020], and Neural Hashgrid [M√ºller et al .2022]. We refer\nreaders to [Xie et al. 2022] for a general survey on neural fields.\n2.4 Hybrid Methods\nThe desire for neural representations that are both memory efficient\nand allow for fast random queries, has led to the development of hy-\nbrid methods that combines neural networks and sparse data struc-\ntures. Recent examples hereof are Neural Sparse Voxel Fields [Liu\net al.2020], Neural Geometric Level of Detail [Takikawa et al .2021],\nBaking NeRF [Hedman et al .2021], and Adaptive Coordinate Net-\nworks [Martel et al .2021]. Learning a tree data structure indexing\nwas also presented in [Kraska et al. 2018].\nNeuralVDB also falls into this category. The main difference be-\ntween existing hybrid methods and NeuralVDB lies in the key de-\nsign goals we mentioned earlier ‚Äì better memory efficiency and\ncompatibility with VDB. While the previous hybrid approaches are\nmemory-efficient compared to conventional neural representations,\nthey are less efficient compared with the non-neural sparse grid\nstructures. We carefully allocate and train parameters such that\nNeuralVDB can achieve high-fidelity reconstruction while consum-\ning much less memory than compressed VDB. Also, NeuralVDB is\ncompatible with existing VDB pipelines by design and can retain\ninput (standard) VDB‚Äôs original hierarchical structure with minimal\nerror. Additionally, NeuralVDB is not limited to specific types of\n\n4 ‚Ä¢Kim, Lee, and Museth\nvolumes such as occupancy, signed distance field, volume density,\nor even vector fields. Finally, NeuralVDB is an open framework that\ndoes not require a dedicated network architecture. Therefore, any\npurely neural or even hybrid methods can be used as a black box\nsubmodule of NeuralVDB.\n3 METHOD\nThis section will briefly outline the original VDB tree structure\nand explain how it is used to derive NeuralVDB, which combines\nexplicit tree and implicit neural representations. More precisely,\nwe demonstrate how different neural networks can be designed to\nseparately encode topology and value information in NeuralVDB.\nWe demonstrate how the decoder in NeuralVDB can be used for\nboth offline/out-of-core and online/in-memory applications. Finally,\nwe introduce a novel temporal warm-starter that encodes animated\nVDBs with improved training performance and temporal coherency\nof the reconstructed VDBs.\n3.1 VDB\nLet us briefly summarize the main characteristics of a VDB tree\nstructure as well as its unique terminology. (For more details we\nrefer the reader to the original paper [Museth 2013]).\nIn a VDB tree structure, values are associated with all levels of\nthe tree, and exist in a binary state referred to as respectively ac-\ntive or inactive values. Specifically, values at the leaf level, i.e., the\nsmallest addressable (integer) coordinate space, are denoted voxels ,\nwhereas values residing in the upper node levels are referred to\nastile values , and cover larger coordinate domains. That is, tile\nvalues conceptually corresponding to uniform values assigned to\nall voxels subsumed by the node that the tile resides in, thus com-\npactly representing constant regions of space. While the VDB tree\nstructure, detailed in [Museth 2013], can have arbitrarily many con-\nfigurations, we will exclusively focus on the default configuration\nused in OpenVDB, which has proven useful for most practical ap-\nplications of VDB. This configuration uses four levels of a tree with\na sparse unbounded root node followed by three levels of dense\nnodes of coordinate domains 40963,1283and83. Thus, leaf nodes\ncan be thought of as small dense grids of size 8√ó8√ó8, arranged in\na shallow tree of depth four with variable fanout factors ( ùëõas inùëõ3,\nthe number of nodes per level) of 32and16respectively. We will\nrefer to the leaf level as level 0, internal nodes as level 1 and 2, and\nthe top-most root level as level 3. Thus, a default VDB tree can be\nimplemented as a hash table of dense child nodes of size 323, each\nwith dense child nodes of size 163, each with dense child nodes of\nsize83. Figure 2 illustrates this tree structure in one and two spatial\ndimensions. Finally, note that all internal nodes (at level 1 and 2)\nhave two bitmasks, denoted active mask ùëéùëôandchild mask ùëêùëô,\nwhich respectively indicate if a tile value is active or whether it\nis connected to a child node. Conversely, leaf nodes only have an\nactive mask ùëéùëôused to distinguished active vs inactive voxels.\nThroughout this paper we will adopt the same notation for VDB\ntree configurations that was introduced in [Museth 2013]. Thus,\nthe configuration outlined above, which is the default in OpenVDB,\nis denoted[Hash,5,4,3], where Hash refers to the fact that the\nroot node employs a sparse hash-table whereas the remaining treelevels are dense, i.e., fixed-size, with nodes logarithmic sizes 5,4,3,\ncorresponding to the dimensions 323,163,83, which in turn covers\nthe coordinate domains 40963,1283and 83. In the appendix we\nexplain how VDB facilitates fast random access, and how NanoVDB\noffers GPU acceleration [Museth 2021].\n3.2 NeuralVDB\nNeuralVDB retains the VDB tree structure outlined above, but em-\nploys novel techniques to encode values, of both tiles and vox-\nels, and topologies, of both nodes and the active states of values,\ncf. active-masks mentioned in Section 3.1. Whereas OpenVDB en-\ncodes values explicitly at full bit-precision, and NanoVDB (option-\nally) uses explicit but adaptive bit-precision, NeuralVDB instead\nuses neural representations for values, their states, and (optionally)\nparts of the tree-structure itself. Specifically, we are proposing two\ntypes of NeuralVDB that are optimized for respectively speed and\nmemory. The first version, which we denote [Hash,5,4,NN(3)],\nonly applies neural networks to the leaf nodes, whereas the sec-\nond version is dubbed [Hash,5,NN(4),NN(3)]and applies neu-\nral networks heuristically to the two lower levels. As we shall\ndemonstrate[Hash,5,4,NN(3)]favors fast random access whereas\n[Hash,5,NN(4),NN(3)]achieves a smaller memory footprint at the\ncost of slower access.\nOur neural network architecture is based on several multi-layer\nperceptrons (MLPs) that partition the entire coordinate span of the\nsparse volume into partially overlapping domains (more on this\npartitioning in Section 3.4). Each MLP maps floating-point voxel\ncoordinates(ùë•,ùë¶,ùëß)to the relevant value type of the VDB tree,\ne.g., scalar, vector, and binary mask values. For the scalar and vector\nvalues, we use the MLP as a regression network. We encode the\nbinary mask, which indicates whether a given coordinate maps to\nan active value/child or not, using an MLP classifier. We will cover\nthe details of this classifier network in Section 3.3.1.\nThe regression MLPs are defined through training, which opti-\nmizes a mean squared error (MSE) loss function of the type\nùêøùëÄùëÜùê∏(ùëì,ÀÜùëì)=1\nùëÅùëÅ‚àëÔ∏Å\nùëñ=1(ùëì‚àíÀÜùëìùëñ)2(1)\nwhereùëìis the target value and ÀÜùëìis the predicted value from the\nnetwork. For an SDF data, we scale the target to be in the range of\n[‚àí1,1], whereas for the fog volumes, we keep the original range,\nwhich is typically[0,1]. For the classification MLPs, we use cross-\nentropy loss. We also use stochastic gradient descent with an Adam\noptimizer [Kingma and Ba 2014]. Learning rate is scheduled to\ndecay exponentially for every epoch. In Section 4, we list all the\nhyperparameters that we used to perform the experiments.\nWhile training of MLPs is occasionally straightforward, it is\nwell-known that in many practical applications MLPs often fail\nto reconstruct high-frequency signals, even with high-capacity,\ni.e., wide/deep, networks [Jacot et al .2018]. We apply two different\ntechniques to mitigate this issue: Firstly we restrict the training\nsamples to active values only, and secondly we map the low dimen-\nsional feature(ùë•,ùë¶,ùëß)to different feature spaces for better accuracy.\nWe will elaborate more on both these ideas below.\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢5\nActive Mask a1\nActive Mask a0\nVoxel Values fChild Mask c1Active Mask a2\nChild Mask c2\nTile Values /\nChild PointersRoot node\n(Level 3, Unbounded)\nInternal Node\n(Level 2)\nInternal Node\n(Level 1)\nLeaf Node\n(Level 0)32¬≥ Nodes\n16¬≥ Nodes\n8¬≥ Voxels\nFig. 2. 1D and 2D illustrations of VDB data structures. Left: A 1D 4-level VDB tree hierarchy is shown with its various node structures and bitmasks. The\ntop-most root node (level 3) holds an unbounded set of internal nodes (level 2), and the red/blue internal nodes encode tile values or child pointers using\nbitmasks (ùëéùëôandùëêùëô). The lower green leaf nodes store voxel values ùëìand their active masks ùëé0.Right: 2D illustration of the hierarchical tree nodes that\nintersect the sparse (gray) pixels. The color schemes are shared between the 1D and 2D illustrations. The number of nodes per level are indicated where the\nlevel 2 and 1 internal nodes have 323and163children nodes and level 0 (leaf) nodes have 83voxels per node.\n3.2.1 Sparse Field Training. The encoding process of the value\nregression MLP starts with an existing VDB grid, either represented\nas an OpenVDB or NanoVDB. For each epoch, i.e., pass over the\ntraining set, we randomly sample the active voxels, thus explicitly\nexcluding all inactive values, e.g., background values, encoded in\nthe VDB tree since, by design, active values are used to indicate that\na value is significant. This is a simple but efficient way to introduce\nsparseness in the training despite the fact that tree nodes are dense.\nFor instance, a narrow-band level set is represented as a truncated\nsigned distance field where the active voxels ‚Äúuniformly sandwich‚Äù\nthe zero-crossing surface, i.e., a narrow-band level set of width six\nhas active voxels in the range [ ‚àí3Œî,3Œîùë•] where Œîùë•denotes the\nsize of a voxel. Conversely, a fog, i.e., normalize density, volume\ntypically has a wider active value set, but they are still sparse in\nthe sense that the active set is bounded, typically with non-trivial\nboundaries, e.g., see the cloud example from Figure 4. Training a\nnetwork with only these active voxels allows the model to focus\nits learning capacity on the most important content encoded into a\nVDB tree; thus the adaptive structure of VDB is encoded implicitly\ninto the network during training. The effect of training with sparsity\ninformation is demonstrated in Appendix C. Obviously, this network\nalone will not extrapolate well outside the active voxels, which is\nby-design. Therefore, the hierarchical structure from the source\nVDB is embedded as part of the NeuralVDB data, except the dense\nleaf nodes, to mask out any random access outside the active voxel\nregions which are not trained.3.2.2 Feature Mapping. As shown in recent work on spectral bias\nand Neural Tangent Kernels [Jacot et al .2018; Rahaman et al .2019;\nTancik et al .2020], a vanilla MLP tends to fail to capture high-\nfrequency details even with deep and wide networks. It was demon-\nstrated in [Jacot et al .2018] that the effective regression kernel width\nof a regular MLP is too wide to represent such signals. To overcome\nthis issue, a number of different techniques have been proposed,\nincluding positional encoding [Mildenhall et al .2020], and Fourier\nfeature mapping (FFM) [Tancik et al .2020] as its generalization.\nDifferent mapping techniques have been proposed from different\ncontexts as well such as one-blob encoding [M√ºller et al .2019, 2020],\ntriangle wave [M√ºller et al .2021], or neural hash encoding [M√ºller\net al.2022]. These mapping (or encoding) techniques transform\ninput coordinates, x‚ààR3, into higher dimension vectors ùõæ(x)\nz=ùõæ(x) (2)\nwhere z‚ààRùëõandùëõ‚â´3whereùëõis the new feature dimension. By\napplying such mappings, an MLP can converge faster with fewer\nparameters and shorter training times. Alternatively, the domain\nitself can be decomposed into smaller geometrical representations,\nsuch as octrees [Takikawa et al .2021] or grid of subdomains [Mose-\nley et al .2021], which tackles the spectral bias problem, i.e., the fact\nthat networks tend to bias towards low frequency signals in the\ntraining set. However, we prefer feature mapping techniques over\nthe geometric approaches to decouple the neural network design\nfrom the VDB tree structure. This way, the architecture is open to\nother feature mapping methods such as neural hash grids [M√ºller\n\n6 ‚Ä¢Kim, Lee, and Museth\na) [Hash, 5, 4, NN(3)] b) [Hash, 5, NN(4), NN(3)]\nVoxel Value\nRegressor\nLevel-0 Mask ClassiÔ¨Åer Voxel Value Regressor\nLevel-1 Mask ClassiÔ¨Åer\n Tile Value Regressor\nActive Mask a1\nChild Mask c1\nTile Values /\nChild Pointers\nActive Mask a0\nFig. 3. Illustration of two different NeuralVDB structures: a) a standard VDB tree with neural voxel values ( [Hash,5,4,NN(3)]using the VDB tree notation),\nand b) a hybrid VDB/neural tree with neural representations of both nodes and their values ( [Hash,5,NN(4),NN(3)]using the tree notation).\nGround Truth\n1.5 GBNeuralVDB\n25 MB\nFig. 4. Examples of reconstructed volumes from NeuralVDB on Disney Cloud dataset [Walt Disney Animation Studios 2017]\net al.2022] and can adopt new techniques without heavy refactoring.\nTherefore, we implement FFM as the main feature mapping method\nin the NeuralVDB framework.\nThe final NeuralVDB data is then a concatenation of mask-only\nVDB trees with the value regressor MLP network (see Figure 3).\nWhile this already reduced the memory footprint significantly (see\nTable 1), we show that the memory efficiency can be further im-\nproved by encoding the hierarchy of the VDB tree with neural\nnetworks in the following section.3.3 Hierarchical Networks\nAs indicated above, NeuralVDB achieves a significant reduction\nin its memory footprint, relative to OpenVDB, by replacing dense\ntree nodes with a shared neural network. To motivate some of our\ndesign decisions consider Table 1, where we quantify this mem-\nory reduction for a specific sparse volume, namely the level set\nmodel of the dragon shown in third column of Figure 5. This table\nshows node counts and memory footprints at different tree levels\nfor one standard and two neural representations with the same low\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢7\nStandard VDB NeuralVDB ([Hash,5,4,NN(3)]) NeuralVDB ([Hash,5,NN(4),NN(3)])\nNum. Nodes Bytes Num. Nodes Params Bytes Num. Nodes Params Patches Bytes\nInternal (Level 2) 8 327,776 8 327,776 8 327,776\nInternal (Level 1) 318 5,539,560 318 5,539,560 318 99,332 1,879 423,692\nMask (Level 0) 124,166 9,436,616 124,166 9,436,616 395,268 7,293 1,668,588\nVoxels (Level 0) 63,572,992 254,291,968 398,352 1,593,408 395,268 1,581,072\nTotal 269,595,920 16,897,360 4,001,128\n6.268% 1.484%\nTable 1. Memory Cost of the VDB Hierarchy. Columns on the left (Standard VDB) show the statistics of the dragon model represented in standard VDB format.\nColumns in the middle (NeuralVDB [Hash,5,4,NN(3)]) show similar statistics when only the voxel values are encoded in neural networks. The right-most\ncolumns (NeuralVDB [Hash,5,NN(4),NN(3)]) shows the numbers when neural networks are used to encode both tree hierarchy and values for two lower\nlevels. NeuralVDB with [Hash,5,4,NN(3)]was able to reduce its size down to 6.268% of the original VDB and NeuralVDB with [Hash,5,NN(4),NN(3)]\nachieved even smaller footprint. Note that due to the sparse domain decomposition described in Section 3.4, the voxel values are encoded with multiple neural\nnetworks where each network encodes its dedicated bounding box.\nBunnyGround Truth\nReconstruction\nArmadillo Crawler Space Thai Statue EMU Lucy Dragon\nFig. 5. Ground truth SDF VDB models (top row) and reconstructed SDF VDB models using NeuralVDB (bottom row).\nreconstruction error (Intersection over Union (IoU) of 99%). The first\ncolumn, with OpenVDB, denoted [Hash,5,4,3], clearly shows that\nthe overall memory footprint is dominated by the voxels, i.e., val-\nues in the leaf nodes, that take up 94%of the total footprint. The\nneural representation of voxels, shown in the middle column and\ndenoted[Hash,5,4,NN(3)], reduces the footprint of the leaf val-\nues to only 6%, corresponding to 16√ó. However, the total footprint\nis now dominated by the leaf bit masks and the internal nodes at\nlevel 1, i.e., the states of the voxels and the nodes just above the\nleaf nodes. As stated in Section 1, one of our key design goals is to\npreserve as much of the information captured in the source VDB\ndata structure as possible, which includes the hierarchical tree struc-\nture as well as the spatial occupancy, i.e., topology, and values ofthe sparse volumetric data. In other words, we seek a more com-\npact neural representation of the source tree structure that encodes\nmost if not all of its payload. A natural approach is therefore to\napply neural representations to all voxels, as well as their masks\nand parent nodes, which is shown in the right-most column of Ta-\nble 1, denoted[Hash,5,NN(4),NN(3)]. This results in an overall\ncompression factor of 68√ówhen comparing[Hash,5,4,3]at257ùëÄùêµ\nto[Hash,5,NN(4),NN(3)]at3.8ùëÄùêµ. Note that we use the same\nnetwork capacity for the voxels and masks at level 0, resulting in\nvirtually identical footprints. Interestingly, the neural compression\nof the two lowest levels of the VDB tree structure results in a hi-\nerarchical representation, [Hash,5,NN(4),NN(3)], whose memory\nfootprint is still dominated by those two lowest levels. This seems\n\n8 ‚Ä¢Kim, Lee, and Museth\nto suggest that neural representations of the remaining top levels, 2\nand3, will have little impact on the overall memory footprint.\n3.3.1 Encoding Hierarchy. Based on the observations above, we\npropose only to introduce hierarchical neural networks at the two\nlowest levels of VDB tree structure. More precisely, we replace voxel\nand tile values at levels 0 and 1 with MLP-based value regression\nnetworks as well as child and active masks at level 1 and active\nmasks at level 0 with classifiers . The root and upper internal levels\nof the tree structure shall remain unchanged. This configuration\nis illustrated in the right column of Figure 3. The mask classifier\nat level 1 is trained with level 1 child nodes‚Äô coordinates as the\ninput and its child and active masks ùëö1‚àà{ùëê1=1,ùëé1=1}as the\ntarget labels. Thus, this ternary classifier predicts three possible\ncases, 1) a leaf child node, 2) an active tile value, or 3) an inactive\ntile value, from the input coordinates. Conversely, the classifier at\nlevel 0 is trained with voxel coordinates as the input and the active\nleaf masksùëö0‚àà{ùëé1=1}as the label. Thus, this binary classifier\npredicts whether given coordinates map to active or inactive voxels.\nTo optimize the parameters, cross-entropy loss is used for the level-\n1 mask classifier and binary cross-entropy (BCE) loss is used for\nthe level-0 mask classifier. For the nodes at level 1 with tile values\n(ùëö1=0), these tile values are also encoded using an MLP-based\nvalue regressor, similar to the voxel value regressor.\nNote that the level-0 mask classifier is essentially an occupancy\nnetwork. When reconstructing voxel occupancy, the BCE loss func-\ntion can be tweaked to tackle sparse and imbalanced distribution as\nwell as the vanishing gradient problem [Brock et al .2016; Saito et al .\n2018]. However, the level-0 mask network is performed within level-\n1‚Äôs chidren nodes which addresses the imbalance problem since the\nchildren nodes are allocated only around where the actual values\nare, instead of its full domain. Also, a typical network depth is not\nvery deep (e.g., [2, 4]), and hence gradients do not vanish easily.\nTherefore, we keep the vanilla BCE without further tuning.\nDue to the hierarchical nature of the tree structure, the capacities\nof mask classifier and tile value regressor at level 1 are typically\nmuch smaller than the capacities of the mask classifier or voxel\nregressor at level 0. During the reconstruction, we perform top-\ndown traversal by first querying the level-1 mask classifier. If the\nquery point is classified as an active tile, then the corresponding\ntile value is predicted and returned using the tile value regressor.\nConversely, if the query is classified as a leaf node, its mask classifier\nis used to determine the active state. The query points that map\nto active states are then used for the final inference through the\nvalue regressor, mimicking the tree traversal/early termination of\nthe standard VDB tree.\n3.3.2 Source Embedding. Although the networks with FFM [Tancik\net al.2020], which is our feature mapper of choice as mentioned in\nSection 3.2.2, can classify level-1 and voxel masks accurately; it still\nmight produce a number of positive samples that are incorrectly\nclassified. However, we observed that the number of such samples\nis relatively small (e.g., <1% of all positive samples for level-1 masks\nand 5% of active voxel masks), and in fact, can be appended to the\ndata structure.\nFor the active mask classifier for voxels, however, even a percent\nof false positives might result in significant number of voxels toembed since the number of active voxels easily exceeds tens of\nmillions (see Table 2 and 3). While this is impractical and defeats the\npurpose of space efficiency, most of such false negatives are near\nthe decision boundaries (not the geometrical boundaries). Based on\nthis observation, we filter out voxels that are far enough from the\nsurface (in case of SDF) or do not have significant value (in case of\nvolume density or any other scalar fields). This remedy seems to\nwork well enough not to show any significant artifacts.\n3.4 Sparse Domain Decomposition\nWhen a scene is too large and/or contains disjoint clusters of vol-\numes, a single network can perform poorly since the input coor-\ndinates are normalized between [0,1]before the feature mapping\nstage. In contrast, the value-mapping in a standard VDB is agnostic\nto such an incoherent clustering of voxels. To address the prob-\nlems above, we propose a sparse domain decomposition approach,\nwhich is inspired by the sparsely-gated Mixture-of-Experts (MoE)\nmethod [Shazeer et al .2017]. First, we decompose the domain with\nfixed-size subdomains where each subdomain ùê∑ùëòspans configurable\nsize in index space in range of 512 to 2048. A subdomain has a fixed-\nwidth halo that overlaps with other adjacent subdomains. We chose\n8 voxels for the halo size which is wide enough to eliminate the\ndiscontinuity and small enough to reduce the compute overhead.\nThe entire domain is partitioned into a regular grid of subdomains,\nwhere empty subdomains are discarded. Also, a dedicated neural\nnetwork (expert) is defined for each subdomain. For simplicity, the\nsame network architecture is used for all the experts. Given this\nsetup, we define a gate function ùê∫(x)ùëòfor each subdomain ùê∑ùëò,\nwhere xis a normalized coordinates between [0,1]for the given\nsubdomain bounding box. This gate function ùê∫(x)ùëòis defined as\na clamped tent function (a tent function with max value of 1 uni-\nformly outside the overlapping region) which covers the subdomain\nùê∑ùëòincluding the halo. When input coordinates are passed, the gate\nfunctions and the expert networks generates the output as\nÀÜùë¶=ùëõ‚àëÔ∏Å\nùëò=1ùê∫(x)ùëòùê∏ùëò(x) (3)\nwhereùëõis the number of subdomains and output ÀÜùë¶can be one of\nthe child/active masks or voxel values, which means the sparse\nsubdomain decomposition can be applied to any neural modules in\nour framework (see Figure 3b for the reference). Note that the gate\nfunction above is not learnable, which is different from the sparsely-\ngated MoE [Shazeer et al .2017]. Also, a single input coordinate\ncan activate (return non-zero output) multiple gate functions (as\nmany as eight) due to the overlapping halos, and we average the\nevaluated values weighted by the gate functions. In practice, we\nexamine the gate function first to determine which network should\nbe invoked and only perform the computation for the networks with\nnon-zero gate values. Since each subdomain has dedicated classifiers\nand regressors, we can train concurrently on multiple GPUs. When\nmultiple GPUs are used, groups of subdomains (since there can be\nmore subdomains than number of available GPUs) are assigned for\neach GPU. After training, the groups of the subdomains are merged\ninto a single NeuralVDB structure.\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢9\nLevel-1 Mask Classifier\nTile Value Regressor\nLevel-0 Mask Classifier V oxel Value RegressorReconstructed Level 1\na) Virtual CoordinatesReconstructed Level 0\nb) d)c)\ne)\nFig. 6. Reconstructing VDB from a NeuralVDB data. Virtual coordinates from level 1 are classified into either one of 1) child node, 2) active tile, 3) inactive tile.\nFrom the resulting vector at b), active mask coordinates are then further passed down to the tile value regressor to reconstruct the tile values at c). Input\ncoordinates with child mask on are passed to the level-0 mask classifier to check active voxel state and then active voxel d) is finally used to infer the voxel\nvalue for the reconstruction of level 0 at e).\nUsing the sparse domain decomposition outlined above, large\nsample scenes like the Space model with a voxel resolution of\n32844√ó24702√ó9156 in Figure 5, can be effectively handled without\nsacrificing accuracy. In this particular case, twelve subdomains for\nthe entire scene are allocated in total by our algorithm (i.e., subdivid-\ning the entire domain into a grid of subdomains and discarding the\nsubdomains without any voxels). The sizes are determined heuristi-\ncally as described in Appendix E.\n3.5 Reconstruction\nSo far we have focused on how standard VDB trees can be com-\npactly encoded in NeuralVDBs by means of training various neural\nnetworks. This of course leaves the problem of efficiently decod-\ningNeuralVDBs by inferencing, which is the topic of this section.\nWe will consider two fundamentally different scenarios. First, we\nshow how a standard VDB can be reconstructed from an existing\nNeuralVDB representation, which is useful when a NeuralVDB is\nstored offline, e.g.‚Äû on disk or transmitted over a network, and needs\nto be decoded into a standard VDB in memory. This is typically\nan offline process where we reconstruct the entire VDB tree in a\nsingle sequential pass thought the NeuralVDB data. Second, we\nshow how we can support random access to values directly from\nin-memory NeuralVDB data, without first fully reconstructing the\nBunny Cloud ChameleonGround Truth\nReconstructionFig. 7. Ground truth volume density VDB models (top row) and recon-\nstructed volume density VDB models using NeuralVDB (bottom row). The\nChameleon model is acquired from Open Scientific Visualization Datasets\nwhere the original dataset is from DigiMorph [Maisano 2003].\nentire VDB tree. The first case favors memory efficiency over re-\nconstruction time, whereas the latter needs to balance these two\nfactors in order to allow for reasonable access times for applications\nlike rendering and collision detection. To this end we propose the\n\n10 ‚Ä¢Kim, Lee, and Museth\ntwo different configurations of NeuralVDB, [Hash,5,4,NN(3)]and\n[Hash,5,NN(4),NN(3)]introduced Section 3.3. We will elaborate\nmore on these two cases below.\nOffline Sequential Access. For applications that prioritize a low\nmemory footprint over fast reconstruction times, we use the Neu-\nralVDB configuration denoted [Hash,5,NN(4),NN(3)]. Examples\nof such applications are storage on slow secondary-storage devices\nlike hard drives and DVDs or transfer over low-bandwidth internet.\nThe reconstruction into a standard VDB tree only requires a single\nsequential pass over the compressed data. Since the root and its\nchild nodes are encoded identically to a standard VDB tree, we will\nlimit our description of the reconstruction to the lower two levels of\nthe tree that use neural representations. Sequential access to level 1\nnodes is straightforward since their coordinates are trivially derived\nfrom the child masks at level 3 (see [Museth 2013] for details on\nhow bit-masks compactly encode coordinates). Thus, for each node\nat level 1 (of size 163) we use standard inference to reconstruct the\nchild and active masks from the classifiers and the tile values from\nthe value regressors described in Section 3.3.1. We correct the masks\nwith the list of false positives that we explicitly encoded during the\ntraining step (see 3.2). Next, using the child masks at level 1 we\nproceed to visit all the leaf nodes (of size 83) and sequentially infer\nthe voxel values and their active states from the value regressor\nand binary classifier at level 0. During the decoding process, we\nuse disjoint blocked ranges, which are distributed amongst multiple\nGPUs and subsequently merged into a single output VDB. Since\neach blocked range has dedicated classifiers and regressors, like in\nthe training stage, inferencing can also be performed concurrently\non multiple GPUs. When reconstructing one of these blocked ranges,\nit still has access to all the networks, meaning it can still reconstruct\nvolumes without discontinuity thanks to Equation 3.\nOnline Random Access. Since[Hash,5,NN(4),NN(3)]employs\nhierarchical neural networks (two levels) we have found this con-\nfiguration to be too slow for real-time random access applications.\nConsequently we propose [Hash,5,4,NN(3)], show in the left col-\numn of Figure 3, for applications that require both fast random\naccess and a small memory footprint since it uses the proven ac-\nceleration techniques of VDB for the tree traversal in combina-\ntion with the compact neural representation of the voxel values\nonly. In other words, random access into [Hash,5,4,NN(3)]has the\nsame performance characteristics as a standard VDB tree, except for\nleaf values that require an additional regression for the voxels. As\nshown in the middle column in Table 1, [Hash,5,4,NN(3)]still has\nan in-memory footprint that an order of magnitude smaller than\n[Hash,5,4,3]. While[Hash,5,4,NN(3)]consumes more memory\nthan[Hash,5,NN(4),NN(3)], it still benefits from a massive com-\npression ratio of the leaf level value regression network. Moreover,\n[Hash,5,4,NN(3)]can be trivially reconstructed from the other\nversion,[Hash,5,NN(4),NN(3)], by leaving the voxel regressor un-\nchanged, and can therefore be seen as a pre-cached representation\nfor the faster access, similar in spirit to [Hedman et al .2021]. Once\nthe[Hash,5,4,NN(3)]representation is available, random access\nbecomes a simple two-step process: 1) Use standard (accelerated)\nrandom access techniques (see [Museth 2013]) to decide if a query\npoint maps to a tile or a voxel, i.e., level {3,2,1}or0. 2) if it is a tile,return the value explicitly encoded into the standard VDB structure,\nand else, predict the voxel values using the regressor.\nWhile[Hash,5,4,NN(3)], the in-memory representation of Neu-\nralVDB, can be viewed as a cached evaluation of offline represen-\ntation[Hash,5,NN(4),NN(3)], there are still room for more active\ncaching mechanism such as caching of evaluated voxel masks/values\nin a cyclic buffer to reduce number of neural network inferences.\nWe are investigating this approach as part of our future work.\n3.6 Temporally-Coherent Warm-Start Encoder\nOne of the main sources of sparse volumetric data are simulations.\nAs such, one of the key applications for OpenVDB, and hence by\nextension NeuralVDB, is time-sequences of animated sparse vol-\numes. This presents both an opportunity for acceleration as well as\na challenge in terms of expected temporal coherence. We achieve\nboth of these with a relatively simple idea, namely that of warm\nstarting the neural training, i.e., encoding, of one frame with the con-\nverged network weights from the previous frame. As indicated, this\nhas two significant benefits that are unique to NeuralVDB. Firstly,\nthe coupling (through initialization) to a previous frame introduces\ntemporal coherency across frames, and secondly it accelerates the\ntraining times, typically by a factor of 1.5‚àí2.5times, when com-\npared to a ‚Äúcold-start‚Äù training. Thus, our novel warm-start encoder\nleverages temporal coherency of the input volumes to preserve tem-\nporal coherency of the output volumes (see Figure 8), in addition\nto reducing encoding times (see Section 4). Specifically, we run the\nencoder sequentially from the first frame to the last frame, while\nsaving neural networks per frame to re-use them in the following\nframe as a warm-starter to achieve temporally coherent network\nweights. If the input volumes contain high-frequency details, like\nthin layers of smoke, then a naive (‚Äúcold-start‚Äù) encoding can pro-\nduce flickering due to the fact that a fixed learning rate for all frames\ncan introduce discontinuities of network weights across frames. In\norder to fix the issue, we run the first frame with the target learn-\ning rate, and re-process the first frame with the same or smaller\nlearning rate (e.g., up to 100 times smaller). The rest of the frames\nare processed only once using the new learning rate, and this step\nreduces the training iteration when the loss becomes lower than the\nfirst frame‚Äôs final loss. This technique is similar to the fine-tuning\nmethod for transfer learning [Zhou et al .2017] where it adapts to\nthe new target (new frame) without drifting too much from the old\ntarget (previous frame). When the domain decomposition step adds\na new domain in the middle of the animated sequence, we repeat the\nsame process of encoding the domain with the target learning rate,\nthen again with the smaller one. Warm starting not only produces\ntemporally coherent results but also boosts encoding performance\nwhile satisfying both quality and compression ratio requirements\nas shown in Table 3.\n4 RESULTS\nIn this section, we test NeuralVDB under a number of scenarios,\nincluding encoding, decoding, and random access. All the numerical\nexperiments were performed on a virtual machine with NVIDIA\nRTX A40 GPUs and a host AMD EPYC 7502 CPU. NeuralVDB\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢11\nSmoke Plume\nShip Breach\nDust ImpactFrame 0Frame 28\nFrame 112Frame 56\nFrame 140Frame 84\nFrame 165\nFrame 102Frame 0\nFrame 136Frame 34\nFrame 170Frame 68\nFrame 200\nFrame 30Frame 5\nFrame 40Frame 10\nFrame 50Frame 20\nFrame 60\nFig. 8. Reconstructions from temporally encoded NeuralVDB examples. Smoke Plume is simulated density volumes for 0‚àí165frames, Ship Breach is signed\ndistance fields of a spaceship breaching a water surface for 0‚àí200frames, and Dust Impact is simulated density volumes for 0‚àí166frames.\nis implemented in C++17 and makes use of both CUDA and Py-\nTorch [Paszke et al. 2019].\n4.1 Encoding\nWe first evaluate our new VDB architecture by analyzing its effi-\nciency at encoding a variety of model volumes with a given quality\ncriteria expressed as specific error tolerances. We define our main\ntarget error metric to be Intersection of Union (IoU) for narrow-\nband level sets, i.e., truncated signed distance fields (SDF), and Root\nMean Squared Error (RMSE) for density volumes. Modified Chamfer\nDistance (mCD), which is a modified version of standard Chamfer\nDistance [Wu et al .2021], is also measured for level sets, which is\ndefined as:mCD =1\n2ùëÅ1ùëÅ1‚àëÔ∏Å\nùëñ=1ùëÜùê∑ùêπ 2(v1,ùëñ)+1\n2ùëÅ2ùëÅ2‚àëÔ∏Å\nùëñ=1ùëÜùê∑ùêπ 1(v2,ùëñ) (4)\nwhere the sampling points v1‚ààùëâ1andv2‚ààùëâ2were generated by\nextracting the isosurfaces from both ground truth ( ùëÜùê∑ùêπ 1,ùëâ1) and the\nreconstructed VDBs ( ùëÜùê∑ùêπ 2,ùëâ2). Note that the closest points to each\nother‚Äôs surface are measured by directly sampling the SDF from the\nVDB data, which is different from the original Chamfer distance\ndefinition. We acknowledge that relying solely on the mCD as a\nmetric is insufficient, particularly because it was originally designed\nto evaluate point clouds [Bouaziz et al .2016]. Nevertheless, the\nmCD can still offer an indication of geometrical deviation when an\nimplicit surface (SDF) is rendered as an explicit surface. Hence, we\nenhance its assessment by incorporating IoU, following a similar\n\n12 ‚Ä¢Kim, Lee, and Museth\nFrame 0 Frame 38 Frame 76\nFrame 114 Frame 150 Frame 188\nFrame 226 Frame 264 Frame 300\nFig. 9. Reconstruction from temporally encoded NeuralVDB data for 0‚àí300\nframes, procedurally generated based on LeVeque‚Äôs Test [LeVeque 1996]\n(also known as Enright test).\nFrame 0 Frame 10 Frame 20\nFrame 30 Frame 40 Frame 50\nFig. 10. Reconstruction from temporally encoded NeuralVDB data from\nsimulated density volumes for 0‚àí127frames, dataset generated from\nEmberGen Tornado simulation [JangaFX 2020].\nFig. 11. The offset between the ground truth and reconstructed meshes\nare rendered with a color map. Red and blue indicate positive and negative\ndisplacements relative to the outward normal direction. Unit of the color\nmap is the voxel size of the source VDB grid.\nFig. 12. Error visualization for the Bunny Cloud example. The absolute error\nis averaged in z-axis.\napproach to NGLOD [Takikawa et al .2021]. The hyperparameters\nwere tuned to exceed 99 %IoU for SDFs and produce an RMSE of less\nthan 0.1 for the densities. Tables 2 and 3 list the compression ratios\nfor respectively non-temporal and temporal encoders. For the SDF\nmodels,[Hash,5,NN(4),NN(3)]achieved a compression ratio up\nto61.2, whereas for the density volumes, the compression ratio is\nas high as 140.9 . Figures 5 and 7 compare the ground truth with the\nreconstruction results of [Hash,5,NN(4),NN(3)]. The Chameleon\nmodel achieved the best compression ratio among our dataset (140.9)\nsince the data was smoother and evenly distributed compared to the\nother volumes. Consequently, the decision boundary of the classifier\ndoes not have to fit against high-frequency details, and the value\nregressor can use less neurons to represent a rather smooth value\ndistribution.\nFigure 9 shows reconstruction results from procedurally advected\nSDFs called LeVeque‚Äôs Test [LeVeque 1996]. Figure 8 and 10 shows\nsimulation examples, Smoke Plume, Dust Impact, and Tornado from\nEmberGen VDB Dataset [JangaFX 2020] and Ship Breach from the\noutput of a high-resolution particle-based fluid solver. Table 3 shows\nmin, max, and mean values per column to illustrate variance of the\ntemporal data.\nWhile most of the compression ratios for the SDF volumes are\nin the range from 20 to 60, the Crawler model is an outlier in the\nsense that it only has a compression ratio of 13.3. This particular\nSDF model is uniquely challenging because it contains some ex-\nceptionally thin geometric features as well as large flat surfaces.\nThis amounts to both high- and low-frequency details, which are\nchallenging to capture with a band-limited neural network. Conse-\nquently, this Crawler model requires a wider network with a higher\ncapacity than most of the other SDF models, which in turn accounts\nfor its lower relative compression radio.\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢13\nEMU Crawler\nFig. 13. Visualization of the error convergence as more network parameters are used. For each example, the left-most column corresponds to the baseline\nreconstruction where fewer parameters are used. The center column shows the result from a larger network (2 √óthe width). The right-most column shows the\nground truth. For the EMU example, the compression ratio is 40.9 and 11.4 for the smaller and larger models, respectively. For the Crawler example, the\ncompression ratio is 13.8 and 3.8 for the smaller and larger models.\n4.2 Reconstruction Error\nGiven the fact that the proposed NeuralVDB representations are\nconceptually lossy compressions of standard VDB values (but impor-\ntantly not its topology), it is essential to investigate and understand\nthe nature of these reconstruction errors.\nIn Figure 11, we visualize the error of the SDF reconstruction\non the iso-surface mesh of the dragon model, by color-coding the\nclosest distance to the ground truth. Specifically, the offset between\nthe ground truth and the reconstruction is measured for each vertex\nof the reconstructed mesh. The blue-white-red color map shows the\n‚Äúblobby‚Äù error pattern generated by the NeuralVDB compression.\nThis ‚Äúblobby‚Äù error pattern is even more evident on flat surfaces, as\nshown in the two middle images of Figure 13 based on the spacesuit\nand Crawler SDF models. The right-most images in Figure 13 clearly\nshow that this error can be significantly reduced by employing\nwider networks, of course at the expense of reduced compression\nratios.\nFinally, in Figure 12, we compare renderings of the reconstructed\ndensity volumes relative to their ground truth representation. Small\nreconstruction errors are (barely) visible along the silhouettes in\nregions with small-scale details.\n4.3 Hyperparameters\nWe have listed the hyperparameters used throughout this paper in\nTable 4. Currently the capacity of the networks (number and width\nof the multiple MLP layers) is chosen heuristically based on the\ncomplexity of the input volumes (more hidden neurons for more\ncomplex volume). Different activation functions are used for each\nexample, based on heuristics discussed in Appendix E. For all the\nexamples shown in Figure 5 and 7, we use FFM [Tancik et al .2020].\n4.4 Performance\nAs described in Section 3.4, the sparse domain decomposition allows\nthe encoding and decoding processes to be accelerated by multipleGPUs. In Table 5, we report these speedup factors as a function of\nthe number of GPUs applied to large volumes. For training, the sub-\ndomain resolutions listed Table 2 and 3 are used. For reconstruction,\nblocked ranges of size 5123are used for the job distribution onto\nmultiple GPUs. As expected the strong-scaling is sub-linear, which\nis a consequence of the fact that both training and reconstruction\nhave several sequential steps. This includes file I/O, domain decom-\nposition, and gathering. Another factor that results in sub-linear\nstrong-scaling is poor load balancing caused by imbalanced sub-\ndomains due to fluctuating sparse voxel counts in the subdomains.\nStill, Table 5 shows a significant benefit of using multiple GPUs for\nNeuralVDB. For certain combinations of input volumes and GPU\ncounts, the automatic load balancers for the encoder and decoder\ndetermined that there are simply not enough subdomains and/nor\nblocked ranges to decompose and/or that using more GPUs is not\nbeneficial. For instance, the Bunny model is smaller than the con-\nfigured subdomain size (see Table 2). Also, the number of decoding\nblocked ranges (where each range has size of 5123) from the model\nis not large enough to use multiple GPUs. This decoding criterion\nis determined heuristically by checking if the number of average\nactive voxels√ónumber of blocked ranges is greater than or equal\nto 200√ónumber of GPUs.\nThe temporal warm-start encoder of NeuralVDB boosts perfor-\nmance of LeVeque‚Äôs Test 2.4times, Smoke Plume 2.5times, Ship\nBreach 1.6times, Dust Impact 1.2times, and Tornado 3.1times.\nThis is a significant benefit of warm starting each encoder with the\nconverged neural network weights from the previous frame.\nAs described in Section 3, for in-memory random access the Neu-\nralVDB representation of choice, [Hash,5,4,NN(3)], combines a\nstandard VDB tree with neural networks for the voxel values only.\nIn Table 6, we compare the performance of the in-memory ran-\ndom access of[Hash,5,4,NN(3)]and[Hash,5,4,3], implemented\nas NanoVDB, by randomly sampling 1M points inside the bounding\n\n14 ‚Ä¢Kim, Lee, and Museth\nFig. 14. Bunny Cloud model rendered with ray-marching directly on in-\nmemory NeuralVDB.\nbox of a given volume. The NanoVDB results are generated by per-\nforming zeroth (nearest neighbor), first-order (tri-linear), and third-\norder (tri-cubic) interpolation using nanovdb::SampleFromVoxels\nfunction object for each random sample. The time-complexity of\nNeuralVDB is a combination of that of NanoVDB‚Äôs random access\ntree-traversal, which is identical for the two representations, and\nthe neural network inference applied to a subset of the original sam-\npling points. The NeuralVDB random access is more expensive than\nboth nearest neighbor and tri-linear interpolation of NanoVDB, but\nsimilar to third-order interpolation, and cheaper than pure neural\nnetwork predictions since it prunes out queries that fall into tiles,\ni.e., non-voxels.\nAs an additional benchmark test we implemented a simple ray-\nmarcher that operates on [Hash,5,4,NN(3)], see Figure 14. Ren-\ndering of the bunny model with [Hash,5,4,3]using the zeroth-\norder sampler took 75 ms, first-order sampler took 97 ms, and the\nthird-order sampler took 1660 ms, compared to 1316 ms for the\n[Hash,5,4,NN(3)]grid. This benchmark test illustrates that while\nNeuralVDB can replace OpenVDB for run-time applications like\nrendering that require in-memory random access, it does come with\na performance trade off which is comparable to the higher-order\nsamplers. All results were measured with a single NVIDIA A40 GPU.\n4.5 Random Sampling Error\nWe already showed the quantitative measurement of the NeuralVDB‚Äôs\nreconstruction accuracy in Table 2 and 3, and the qualitative visu-\nalization in Figure 11 and 12. Here, we show a further experiment\nwhere we compare the sampling errors between conventional grid-\nbased interpolation methods and NeuralVDB consuming the same\namount of memory. We first create a NanoVDB grid initialized with\na simplex noise function. We also generate a NeuralVDB grid with\napproximately the same ‚Äúin-memory‚Äù footprint, which is trained\nwith the same noise function. We then generate 1M random sam-\npling points and perform zeroth, first-order, and third-order queries\nto the NanoVDB grid and the voxel value regression for the Neu-\nralVDB grid. We measure RMSE error for each sampling strategy to\nevaluate their accuracy compared to the ground truth noise function.The results are shown in Table 7. We can observe that the accuracy\ngoes up when higher-order methods are used, and NeuralVDB can\nhave better performance than even the third-order cubic sampling\nresult.\n4.6 Comparison\nThe goal of this paper is to effectively encode volumetric data with\ngood reconstruction quality. Therefore, we designed our comparison\nexperiments to focus on how well a given method can reconstruct\nvolumes with low-quality loss for the same model sizes. We com-\npared NeuralVDB with three different neural representation meth-\nods, including Neural Geometric Level of Details (NGLOD) [Takikawa\net al.2021], Variable Bitrate Neural Fields (VBNF) [Takikawa et al .\n2022a], and Instant Neural Graphics Primitives (INGP) [M√ºller et al .\n2022], as they provide compact neural representations using dedi-\ncated data structures (octree for NGLOD and VBNF or hash grid for\nINGP) as well as quantization (VBNF). We used Kaolin Wisp as a\nreference implementation for these three methods [Takikawa et al .\n2022b].\nFor the encoding process, the input was a mesh, and the output\nwas a trained SDF neural model. In the case of NeuralVDB, the input\nmesh was converted into a narrow-band level set using OpenVDB‚Äôs\nvdb_tool . Other methods used Kaolin Wisp‚Äôs mesh sampler, which\nutilizes an octree data structure for generating samples. While the\nCPU-based mesh sampler is available as part of the open source\nrepository, we also acquired a private GPU implementation of the\nmesh sampler from the authors of the library. We included both\nperformance results from the public and private codes in our com-\nparison. For the decoding (reconstruction) process, the input was\nthe trained model, and the output was a volume represented in\nOpenVDB format. For non-NeuralVDB methods, we densely sam-\npled the bounding boxes and extracted a narrow band of the SDF\nvolume to reconstruct VDB grids.\nIn the first comparison experiment, we made each method pro-\nduce similar model sizes to NeuralVDB for a given input mesh. We\ntested with three different input meshes (Bunny, Armadillo, and\nDragon) and evaluated the IoU, mCD, encoding and decoding times.\nThe reported encoding time includes the following steps: reading\nand processing of the input mesh, generation of samples, training\nof the model, and compression/serialization of the model to disk.\nSimilarly, the decoding times measure deserialization of the model,\ninference, and writing back to the VDB data structure. The results\nare summarized in Table 8 and visualized in Figure 15. NeuralVDB\nachieved the best performance with respect to most of the metrics,\nboth in terms of quality and encoding/decoding timings. A notable\nexception is the encoding time of the Dragon model where NGLOD\nwith private GPU mesh sampler code was the fastest. Among the\nnon-NeuralVDB methods, INGP achieved the best accuracy and\ndecoding performance, since this method was specifically designed\nfor fast inference with a hash grid that can utilize larger feature\ndimensions for better reconstruction quality.\nIn the second comparison experiment, we compared the rate\ndistortion plot, which measures the distortion loss for different\ncompression levels. We used mCD for the distortion loss and the\nmodel size of the compression level. We used the Bunny model\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢15\nName Num. Active Voxels Effective Res. VDB Raw VDB Comp. [Hash,5,NN(4),NN(3)] Num. Params Num. Patches Comp. Ratio IoU mCD RMSE\nBunny 5,513,993 628 √ó621√ó489 33.3 15.2 0.2 125,379 0 61.2 0.999 0.072 -\nArmadillo 22,734,512 1276 √ó1519√ó1160 137.7 63.5 1.5 752,274 9,402 41.3 0.998 0.115 -\nDragon 23,347,893 2023 √ó911√ó1347 140.0 65.0 1.8 889,868 9,172 36.2 0.997 0.125 -\nLucy 61,305,123 1866 √ó1073√ó3200 679.7 167.5 3.3 1,184,774 134,360 50.1 0.998 0.138 -\nEMU 96,956,688 1481 √ó2609√ó1843 541.8 232.3 5.7 2,661,894 71,793 40.9 0.999 0.106 -\nThai Statue 141,166,655 2358 √ó3966√ó2038 1522.8 377.5 13.6 3,812,364 759,320 27.8 0.997 0.249 -\nSpace 165,909,193 32844 √ó24702√ó9156 950.2 439.7 14.3 5,995,044 344,405 30.8 1.000 0.169 -\nCrawler 181,196,266 2619 √ó511√ó2149 846.2 254.3 18.5 9,160,716 118,464 13.8 0.996 0.174 -\nSmoke Plume 11,111,873 254 √ó500√ó319 31.4 24.1 0.9 459,622 2,616 26.7 - - 0.081\nBunny Cloud 19,210,271 577 √ó572√ó438 139.7 43.8 0.9 323,014 41,395 48.0 - - 0.073\nChameleon 93,994,042 1016 √ó1012√ó700 445.1 160.2 1.1 592,387 10 140.9 - - 0.025\nDisney Cloud 1,487,654,107 1987 √ó1351√ó2449 3947.5 1491.5 25.0 11,825,176 293,110 59.6 - - 0.080\nTable 2. List of input grid statistics for SDF models and density volumes: OpenVDB file sizes for both raw 32-bit precision with no compression and 16-bit\nprecision with Blosc compression [The Blosc Development Team 2020] in MB, NeuralVDB file size with 16-bit precision with Blosc compression in MB, number\nof total parameters (both learnable and static) of neural networks, number of false positive patches for the classifiers, compression ratio comparing 16-bit\ncompressed file sizes, and evaluation metrics including IoU and mCD for the selected SDF volumes, and RMSE for the selected density volumes.\nName Num. Active Voxels Effective Res. VDB Raw VDB Comp. [Hash,5,NN(4),NN(3)] Num. Params Num. Patches Comp. Ratio IoU mCD RMSE\nLeVeque‚Äôs Test Min 7,084,662 572 √ó547√ó547 81.1 19.6 0.6 333,699 8 -0.954 0.133 -\nMax 29,117,298 1351 √ó1155√ó1155 325.4 78.5 6.4 3,336,990 2,929 - 1 0.345 -\nMean 17,700,052 1053.7 √ó970.6√ó970.6 201.2 48.5 3.3 1,718,383 91 14.7 0.992 0.167 -\nSmoke Plume Min 9,462,168 231 √ó493√ó319 27.2 20.5 1.4 673,126 2,126 - - - 0.071\nMax 11,453,882 272 √ó500√ó319 32.0 24.7 1.4 673,126 4,828 - - - 0.075\nMean 10,658,599 254.0 √ó496.3√ó319.0 30.0 23.0 1.4 673,126 3,870 17 - - 0.073\nTornado Min 7,084,010 321 √ó284√ó447 27.1 16.8 0.4 213,350 819 - - - 0.025\nMax 7,909,306 303 √ó305√ó447 27.4 18.0 0.4 213,350 4,223 - - - 0.035\nMean 7,342,839.5 312.9 √ó309.3√ó446.6 27.2 17.3 0.4 213,350 2,537 40.5 - - 0.03\nDust Impact Min 34 163 √ó139√ó25 0.0 0.0 0.3 180,582 2 - - - 0\nMax 25,553,596 716 √ó855√ó339 89.2 55.8 2.1 1,083,492 16,872 - - - 0.034\nMean 13,160,681.80 630.4 √ó720.1√ó227.3 46.7 28.5 1.5 771,442 5,105 18.8 - - 0.009\nShip Breach Min 29,539,953 1295 √ó204√ó1440 296.5 76.2 4.0 2,056,716 8,496 -0.989 0.095 -\nMax 54,216,738 1728 √ó1419√ó1970 596.6 145.2 12.1 6,170,148 96,707 -0.998 0.265 -\nMean 41,325,814 1490.7 √ó727.3√ó1793.7 488.4 112.7 6.1 2,844,612 26,584 18.4 0.995 0.131 -\nTable 3. List of input grid statistics for animated SDF models and density volumes: OpenVDB file sizes for both raw 32-bit precision with no compression and\n16-bit precision with Blosc compression [The Blosc Development Team 2020] in MB, NeuralVDB file size with 16-bit precision with Blosc compression in MB,\nnumber of total parameters (both learnable and static) of neural networks, number of false positive patches for the classifiers, compression ratio comparing\n16-bit compressed file sizes, and evaluation metrics including IoU and mCD for the selected SDF volumes, and RMSE for the selected density volumes.\nSubdomain Size L-1 Net. Tile Val. Net. L-0 Net. Voxel Val. Net. Activation/Freq. FFM Scale/Size Learning Rate LR Decay/Interval Max. Epochs Sample Interval Batch Size\nBunny 1024 3 √ó48 - 3 √ó96 3√ó96 sin/ 3.0 5.0/192 0.001 0.975/100 2500 1 216\nArmadillo 1024 3 √ó48 - 3 √ó96 3√ó96 sin/ 3.0 5.0/192 0.001 0.975/100 2500 1 216\nDragon 1024 3 √ó64 - 3 √ó128 3√ó128 sin/ 1.5 10.0/256 0.001 0.975/100 2500 1 216\nLucy 2048 3 √ó128 - 3 √ó256 3√ó256 sin/ 1.5 10.0/256 0.001 0.975/100 2500 1 216\nEMU 2048 3 √ó192 - 3 √ó384 3√ó384 ReLU 10.0/384 0.001 0.75/1000 10000 500 212\nThai Statue 2048 3 √ó128 - 4 √ó256 3√ó256 sin/ 1.5 10.0/512 0.001 0.975/100 2500 1 216\nSpace 2048 3 √ó96 - 3 √ó192 3√ó192 ReLU 10.0/384 0.001 0.975/100 2500 1 216\nCrawler 1536 3 √ó192 - 4 √ó384 4√ó384 ReLU 20.0/768 0.0002 0.75/1000 6000 100 216\nBunny Cloud 1024 3 √ó64 3√ó16 3√ó192 3√ó192 sin/ 3.0 5.0/192 0.001 0.975/100 2500 1 216\nChameleon 1024 3 √ó128 - 3 √ó256 3√ó256 sin/ 3.0 10.0/256 0.001 0.975/100 2500 1 216\nDisney Cloud 1536 3 √ó256 3√ó128 4√ó512 4√ó512 sin/ 2.0 20.0/512 0.001 0.75/1000 10000 500 212\nLeVeque‚Äôs Test 1024 3 √ó96 - 3 √ó192 3√ó192 sin/ 1.5 2.0/192 0.001/0.0002 0.975/100 2500 1 216\nSmoke Plume 512 3 √ó48 3√ó16 3√ó256 3√ó256 sin/ 3.0 10.0/384 0.001/0.0001 0.975/100 2500 1 216\nDust Impact 512 3 √ó48 3√ó16 3√ó128 3√ó128 sin/ 1.5 15.0/192 0.001 0.975/100 2500 1 216\nTornado 512 3 √ó48 3√ó16 3√ó128 3√ó128 sin/ 1.5 15.0/256 0.001 0.975/100 2500 1 216\nShip Breach 1024 3 √ó96 - 3 √ó192 3√ó256 sin/ 1.5 10.0/384 0.001/0.001 0.975/100 5000 1 216\nTable 4. List of hyperparameters used in all the experiments, including subdomain size (in voxel dimension for a cubic subdomain), the number of layers and\nneurons per layer for the level-1 classifier (L-1 Net.), the tile value regressor, and the level-0 classifier (L-0 Net.), and the voxel value regressor. The activation\nfunction is either sinor ReLU, and if sinis used, the frequency parameters are noted. All these examples were trained using FFM, and the mapping scale and\nfeature size are shown as well. Finally, learning rate (LR), LR decay rate and its interval, resampling interval, and maximum epochs for each example are listed.\nFor the animation examples (LeVeque‚Äôs Test, Smoke Plume, Ship Breach, Dust Impact, and Tornado), two different learning rates are shown where the first\nvalue is the initial (cold-start) learning rate whereas the second value is for the refinement (warm-start).\nas the input for each method. As shown in Figure 16, the results\nwere consistent compared to the first experiment above, whereNeuralVDB showed better accuracy (lower mCD) across different\ncompression levels. Among the other methods, NGLOD performed\n\n16 ‚Ä¢Kim, Lee, and Museth\nBunny\nArmadillo\nNGLOD VBNF INGP NeuralVDB Ground TruthDragon\nFig. 15. Visualization of different neural representation methods on various SDF geometries.\n0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0\nModel size (MB)0.00.20.40.60.81.01.2mCDRate-Distortion Plot\nNGLOD (Octree)\nVariable Bitrate\nInstantNGP\nNeuralVDB\nFig. 16. Rate-distortion plot for different neural representation methods.better than other non-NeuralVDB methods as it can effectively\nleverage sparsity of the volume distribution. The INGP does show\nbetter accuracy over other methods for the smallest model size, and\nit converges slower than NGLOD with more model parameters. The\nVBNF also performed worse than NGLOD, which is expected as it\nhas been found perform better on NeRF representations but exhibits\nhigh-frequency errors on SDF models [Takikawa et al. 2022a].\nNote that the comparisons in these experiments were conducted\nsolely on SDF representations. We couldn‚Äôt directly compare density\nvolume encodings with the existing methods, as they only support\nSDF or NeRF models. However, these methods also address spar-\nsity using their own approaches, such as octrees or hash grids, in\ncontrast to the VDB tree in NeuralVDB. Nonetheless, NeuralVDB\nhas demonstrated superior performance, although its advantage in\nterms of sparsity diminishes in denser volumes like clouds, com-\npared to truncated SDFs. For these denser volumes, all methods\nwould need to increase their capacity, either by expanding the MLP\nnetwork to be wider and deeper or by increasing the feature vector\ndimension. In the case of INGP, the size of the hash table is also cru-\ncial. Therefore, we maintain that there will likely be a performance\ngap between NeuralVDB and other methods.\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢17\nEncoding Time Decoding Time\n# GPUs 1 2 4 1 2 4\nBunny 32.020 - - 1.683 - -\n1.000 - - 1.000 - -\nArmadillo 84.262 46.123 44.632 6.897 - -\n1.000 1.827 1.888 1.000 - -\nDragon 66.244 38.506 33.369 7.913 - -\n1.000 1.720 1.985 1.000 - -\nLucy 85.650 58.407 - 25.530 17.036 -\n1.000 1.466 - 1.000 1.499 -\nEMU 151.618 91.497 - 43.943 30.367 25.176\n1.000 1.657 - 1.000 1.447 1.745\nThai Statue 148.361 104.713 99.304 75.917 51.958 24.852\n1.000 1.417 1.494 1.000 1.461 3.055\nSpace 158.421 101.308 75.100 79.580 51.995 41.334\n1.000 1.564 2.109 1.000 1.531 1.925\nCrawler 284.042 156.179 110.086 103.198 59.391 44.362\n1.000 1.819 2.580 1.000 1.738 2.326\nBunny Cloud 55.614 - - 5.181 - -\n1.000 - - 1.000 - -\nChameleon 74.923 - - 22.678 - -\n1.000 - - 1.000 - -\nDisney Cloud 709.446 431.065 285.415 397.376 269.628 180.088\n1.000 1.646 2.486 1.000 1.474 2.207\nTable 5. Encoding/decoding performance measured using multiple GPUs\nfor the static volumes. The timing in seconds and relative scaling factor is\npresented for each volume.\nName NanoVDB (0) NanoVDB (1) NanoVDB (3) NeuralVDB Neural Net\nBunny 0.107 0.287 4.548 2.762 40.481\nArmadillo 0.073 0.169 3.916 3.634 44.320\nDragon 0.068 0.166 3.850 6.174 50.245\nLucy 0.072 0.135 3.513 1.313 79.199\nEMU 0.090 0.282 4.068 6.506 94.817\nThai Statue 0.073 0.178 3.897 6.740 95.810\nSpace 0.058 0.155 3.763 5.797 49.250\nCrawler 0.159 0.968 5.034 10.345 156.831\nBunny Cloud 0.074 0.217 4.579 11.325 59.108\nChameleon 0.086 0.241 3.239 9.653 71.046\nDisney Cloud 0.122 0.533 4.397 24.617 191.327\nTable 6. Random access performance measured for NanoVDB (zeroth, first,\nand third-order interpolation), NeuralVDB ( [Hash,5,4,NN(3)]), and pure\nneural networks (same structure as the voxel value regressor of the Neu-\nralVDB) in milliseconds. For each static test model, 1M random samples\nwith batch size of 216were generated within the model‚Äôs bounding box.\nMethod NanoVDB (0) NanoVDB (1) NanoVDB (3) NeuralVDB\nRMSE 0.206 0.157 0.149 0.133\nTable 7. RMSE measured for both NanoVDB and NeuralVDB\n([Hash,5,4,NN(3)]) where both grids encode a fractal Brownian\nmotion field [Vivo and Lowe 2015]. For NanoVDB, four different sampling\nmethods are tested (zeroth, first, and third-order interpolation). Both\nNanoVDB and NeuralVDB have similar ‚Äúin-memory‚Äù footprint. For each\ntest model, 1M random samples with batch size of 216were generated\nwithin the model‚Äôs bounding box.5 DISCUSSION\nIn this paper, we presented NeuralVDB, a new, highly compact VDB\nframework using hierarchical neural networks. We combined the\neffectiveness of the standard sparse VDB structure and the highly\nefficient compression capability of neural networks. To further lever-\nage the high compression ratio of neural networks, we use them to\nencode both voxel values as well as the topology (i.e., node and tile\nconnectivity) of the two lowest levels of the tree structure itself. This\nresults in a novel representation, dubbed [Hash,5,NN(4),NN(3)],\nthat reduces the memory footprint of the already compact VDB,\nwith up to a factor of 100 in some cases. We also propose a Neu-\nralVDB configuration, denoted [Hash,5,4,NN(3)], which balances\nmemory reduction and random access performance. While both\nconfigurations feature highly attractive characteristics in terms of\nthe reduced memory footprints, they are by no means silver bul-\nlets. More to the point, we are not proposing that NeuralVDB can\nreplace standard VDBs for all applications. In fact, we primarily\nrecommend[Hash,5,NN(4),NN(3)]as a very efficient but lossy\noffline representation.\nAs indicated already there are some limitations to NeuralVDB\nthat we seek to improve in future work. While NeuralVDB can en-\ncode and decode most of the examples in a couple of minutes, some\nexamples like the Disney Cloud takes nearly five minutes to encode\nand three minutes to decode. Also, the random query performance\nis comparable to the third-order interpolation of NanoVDB, but\nstill slower than the first-order sampler, which is typically used in\ncomputer graphics applications. We expect to achieve improved\nperformance by further reducing the size of the neural networks,\ne.g., by means of improved feature mapping like neural hash en-\ncoding [M√ºller et al .2022] and/or applying mixed-precision infer-\nence. Specifically for encoding/training, data-driven approaches like\nMetaSDF [Sitzmann et al .2020a] can help warm starting the training\nprocess. Such warm starting feature has already been leveraged in\nour animated examples with great success. Also, while most of the\noffline compressors like Zlib [Gailly and Adler 2004] or Blosc [The\nBlosc Development Team 2020] have a few control parameters, Neu-\nralVDB has even more hyperparameters that need to be specified\nfor optimal performance. This usability issue can be improved by\nsystematic/automated parameter selection, potentially using data-\ndriven approaches. Additionally, in the context of the temporal\nencoder, although initializing the network with the previous frame\nsignificantly diminishes artifacts, there is still a noticeable level\nof reconstruction artifacts present. Lastly, NeuralVDB shares one\nfundamental limitation with NanoVDB, notably not shared with\nthe standard VDB, namely that it assumes the tree and its values to\nbe fixed. This is an assumption that we also plan to relax in future\nwork.\n6 ACKNOWLEDGEMENTS\nWe thank Nvidia for supporting this project and in particular Christo-\npher Horvath, Alexandre Sirois-Vigneux, Greg Klar, Jonathan Leaf,\nAndre Pradhana, and Wil Braithwaite for the water simulation and\nrendering of Ship Breach, and Nuttapong Chentanez, Matthew Cong,\nStefan Jeschke, Eric Shi, Ed Quigley, and Byungsoo Kim for proof-\nreading our paper. We also thank to Towaki Takikawa, Or Perel, and\n\n18 ‚Ä¢Kim, Lee, and Museth\nModel File Size (MB) IoU mCD Encoding (Public/Private) (sec.) Decoding (sec.)\nBunny NGLOD 0.2 0.966 0.516 96.318 / 99.078 8.815\n34,835 vertices VBNF 0.2 0.980 0.762 182.459 / 163.218 24.722\nINGP 0.2 0.992 0.449 630.898 / 342.754 8.063\nNeuralVDB 0.2 0.997 0.122 62.048 1.683\nArmadillo NGLOD 1.8 0.984 0.853 193.397 / 119.767 82.909\n172,976 vertices VBNF 1.7 0.941 1.084 1365.301 / 1055.914 1065.290\nINGP 1.8 0.989 0.767 1690.559 / 358.348 47.917\nNeuralVDB 1.5 0.998 0.115 88.558 6.897\nDragon NGLOD 1.9 0.773 1.032 2121.700 / 157.234 140.994\n5,832,139 vertices VBNF 1.8 0.929 1.313 9203.716 / 1133.834 1205.431\nINGP 1.8 0.969 0.784 45833.001 / 435.927 70.087\nNeuralVDB 1.8 0.997 0.125 191.716 7.913\nTable 8. Performance comparison of different neural representation methods on various SDF geometries. All inputs were mesh geometries. The encoding\ntimings include generating samples from input meshes. For non-NeuralVDB methods, we included both public open source version of the mesh sampler\n(Public) as well as the private GPU-accelerated version of the mesh sampler (Private) that we acquired from the authors. While NeuralVDB supports multi-GPU\nencoding and decoding, single GPU is used for all the experiments for the comparison\nClement Fuji Tsang for their help on conducting the comparison\nexperiment using Kaolin Wisp[Takikawa et al. 2022b].\nREFERENCES\nFelix Achilles, Alexandru-Eugen Ichim, Huseyin Coskun, Federico Tombari, Soheyl\nNoachtar, and Nassir Navab. 2016. Patient MoCap: Human pose estimation under\nblanket occlusion for hospital monitoring applications. Medical Image Computing\nand Computer-Assisted Intervention‚ÄìMICCAI 2016: 19th International Conference ,\n491‚Äì499.\nAdam W Bargteil, Tolga G Goktekin, James F O‚Äôbrien, and John A Strain. 2006. A\nsemi-Lagrangian contouring method for fluid simulation. ACM Transactions on\nGraphics (TOG) 25, 1 (2006), 19‚Äì38.\nNarasimha Boddeti, Yunlong Tang, Kurt Maute, David W Rosen, and Martin L Dunn.\n2020. Optimal design and manufacture of variable stiffness laminated continuous\nfiber reinforced composites. Scientific reports 10 .\nSofien Bouaziz, Andrea Tagliasacchi, Hao Li, and Mark Pauly. 2016. Modern techniques\nand applications for real-time non-rigid registration. In SIGGRAPH ASIA 2016\nCourses . 1‚Äì25.\nAndrew Brock, Theodore Lim, James M Ritchie, and Nick Weston. 2016. Generative\nand discriminative voxel modeling with convolutional neural networks. Advances\nin Neural Information Processing Systems (2016).\nZhiqin Chen and Hao Zhang. 2019. Learning Implicit Fields for Generative Shape\nModeling. Proceedings of IEEE Conference on Computer Vision and Pattern Recognition\n(CVPR) (2019).\nNuttapong Chentanez and Matthias M√ºller. 2011. Real-time Eulerian water simulation\nusing a restricted tall cell grid. In ACM Siggraph 2011 Papers . 1‚Äì10.\nThomas Davies, Derek Nowrouzezahrai, and Alec Jacobson. 2020. On the effectiveness\nof weight-encoded neural implicit 3D shapes. arXiv preprint arXiv:2009.09808 (2020).\nJean-loup Gailly and Mark Adler. 2004. Zlib compression library. (2004).\nPeter Hedman, Pratul P Srinivasan, Ben Mildenhall, Jonathan T Barron, and Paul\nDebevec. 2021. Baking Neural Radiance Fields for Real-Time View Synthesis. arXiv\npreprint arXiv:2103.14645 (2021).\nRama Karl Hoetzlein. 2016. GVDB: Raytracing sparse voxel database structures on the\nGPU. In Proceedings of High Performance Graphics . 109‚Äì117.\nBen Houston, Michael B Nielsen, Christopher Batty, Ola Nilsson, and Ken Museth.\n2006. Hierarchical RLE level set: A compact and versatile deformable surface\nrepresentation. ACM Transactions on Graphics (TOG) 25, 1 (2006), 151‚Äì175.\nGeoffrey Irving, Eran Guendelman, Frank Losasso, and Ronald Fedkiw. 2006. Efficient\nSimulation of Large Bodies of Water by Coupling Two and Three Dimensional\nTechniques. ACM Trans. Graph. 25, 3 (jul 2006), 805‚Äì811.\nArthur Jacot, Franck Gabriel, and Clement Hongler. 2018. Neural Tangent Kernel: Con-\nvergence and Generalization in Neural Networks. Advances in Neural Information\nProcessing Systems 31 (2018).\nJangaFX. 2020. EmberGen VDB Dataset . Accessed: 2022-02-15.\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization.\narXiv preprint arXiv:1412.6980 (2014).\nHeiner Kirchhoffer, Paul Haase, Wojciech Samek, Karsten M√ºller, Hamed Rezazadegan-\nTavakoli, Francesco Cricri, Emre B Aksu, Miska M Hannuksela, Wei Jiang, WeiWang, et al .2021. Overview of the neural network compression and representation\n(NNR) standard. IEEE Transactions on Circuits and Systems for Video Technology 32,\n5 (2021), 3203‚Äì3216.\nTim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The case\nfor learned index structures. In Proceedings of the 2018 international conference on\nmanagement of data . 489‚Äì504.\nDidier Le Gall. 1991. MPEG: A video compression standard for multimedia applications.\nCommun. ACM 34, 4 (1991), 46‚Äì58.\nMinjae Lee, David Hyde, Michael Bao, and Ronald Fedkiw. 2018. A skinned tetra-\nhedral mesh for hair animation and hair-water interaction. IEEE Transactions on\nVisualization and Computer Graphics (2018).\nMinjae Lee, David Hyde, Kevin Li, and Ronald Fedkiw. 2019. A robust volume conserv-\ning method for character-water interaction. Proceedings of the 18th annual ACM\nSIGGRAPH/Eurographics Symposium on Computer Animation (2019).\nR. J. LeVeque. 1996. High-resolution conservative algorithms for advection in incom-\npressible flow. SIAM J. Numer. Anal. 33 (1996), 627‚Äì665.\nYuanzhan Li, Yuqi Liu, Yujie Lu, Siyu Zhang, Shen Cai, and Yanting Zhang. 2022.\nHigh-fidelity 3D Model Compression based on Key Spheres. arXiv preprint\narXiv:2201.07486 (2022).\nLingjie Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, and Christian Theobalt. 2020.\nNeural Sparse Voxel Fields. NeurIPS (2020).\nZihao Liu, Tao Liu, Wujie Wen, Lei Jiang, Jie Xu, Yanzhi Wang, and Gang Quan. 2018.\nDeepN-JPEG: A deep neural network favorable JPEG-based image compression\nframework. In Proceedings of the 55th annual design automation conference . 1‚Äì6.\nFrank Losasso, Fr√©d√©ric Gibou, and Ron Fedkiw. 2004. Simulating Water and Smoke\nwith an Octree Data Structure. ACM Trans. Graph. 23, 3 (aug 2004), 457‚Äì462.\nSiwei Ma, Xinfeng Zhang, Chuanmin Jia, Zhenghui Zhao, Shiqi Wang, and Shanshe\nWang. 2019. Image and video compression with neural networks: A review. IEEE\nTransactions on Circuits and Systems for Video Technology 30, 6 (2019), 1683‚Äì1698.\nJessie Maisano. 2003. CT Scan of a Chameleon . Accessed: 2022-02-15.\nJulien NP Martel, David B Lindell, Connor Z Lin, Eric R Chan, Marco Monteiro, and\nGordon Wetzstein. 2021. ACORN: Adaptive Coordinate Networks for Neural Scene\nRepresentation. arXiv preprint arXiv:2105.02788 (2021).\nLars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas\nGeiger. 2019a. Occupancy networks: Learning 3d reconstruction in function space.\nInProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .\n4460‚Äì4470.\nLars Mescheder, Michael Oechsle, Michael Niemeyer, Sebastian Nowozin, and Andreas\nGeiger. 2019b. Occupancy Networks: Learning 3D Reconstruction in Function Space.\nInProceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) .\nMateusz Michalkiewicz, Jhony K Pontes, Dominic Jack, Mahsa Baktashmotlagh, and\nAnders Eriksson. 2019. Implicit surface representations as layers in neural networks.\nInProceedings of the IEEE/CVF International Conference on Computer Vision . 4743‚Äì\n4752.\nBen Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ra-\nmamoorthi, and Ren Ng. 2020. Nerf: Representing scenes as neural radiance fields\nfor view synthesis. In European conference on computer vision . Springer, 405‚Äì421.\nBen Moseley, Andrew Markham, and Tarje Nissen-Meyer. 2021. Finite Basis Physics-\nInformed Neural Networks (FBPINNs): a scalable domain decomposition approach\nfor solving differential equations. arXiv preprint arXiv:2107.07871 (2021).\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢19\nThomas M√ºller, Alex Evans, Christoph Schied, and Alexander Keller. 2022. Instant\nNeural Graphics Primitives with a Multiresolution Hash Encoding. arXiv:2201.05989\n(Jan. 2022).\nThomas M√ºller, Brian McWilliams, Fabrice Rousselle, Markus Gross, and Jan Nov√°k.\n2019. Neural importance sampling. ACM Transactions on Graphics (TOG) 38, 5\n(2019), 1‚Äì19.\nThomas M√ºller, Fabrice Rousselle, Alexander Keller, and Jan Nov√°k. 2020. Neural\ncontrol variates. ACM Transactions on Graphics (TOG) 39, 6 (2020), 1‚Äì19.\nThomas M√ºller, Fabrice Rousselle, Jan Nov√°k, and Alexander Keller. 2021. Real-time\nNeural Radiance Caching for Path Tracing. ACM Trans. Graph. 40, 4, Article 36 (Aug.\n2021), 36:1‚Äì36:16 pages.\nKen Museth. 2011. DB+Grid: A Novel Dynamic Blocked Grid For Sparse High-\nResolution Volumes and Level Sets. In ACM SIGGRAPH 2011 Talks (Vancouver,\nBritish Columbia) (SIGGRAPH ‚Äô11) . ACM, New York, NY, USA, Article 5, 1 pages.\nKen Museth. 2013. VDB: High-resolution sparse volumes with dynamic topology. ACM\ntransactions on graphics (TOG) 32, 3 (2013), 1‚Äì22.\nKen Museth. 2021. NanoVDB: A GPU-Friendly and Portable VDB Data Structure For\nReal-Time Rendering And Simulation. In ACM SIGGRAPH 2021 Talks . 1‚Äì2.\nMichael B. Nielsen and Ken Museth. 2006. Dynamic Tubular Grid: An Efficient Data\nStructure and Algorithms for High Resolution Level Sets. J. Sci. Comput. 26 (March\n2006), 261‚Äì299. Issue 3. https://doi.org/10.1007/s10915-005-9062-8\nRenato Pajarola and J Rossignac. 2000. Compressed progressive meshes. IEEE Transac-\ntions on Visualization and Computer Graphics (2000).\nJeong Joon Park, Peter Florence, Julian Straub, Richard Newcombe, and Steven Love-\ngrove. 2019. Deepsdf: Learning continuous signed distance functions for shape\nrepresentation. In Proceedings of the IEEE/CVF Conference on Computer Vision and\nPattern Recognition . 165‚Äì174.\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory\nChanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Des-\nmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan\nTejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chin-\ntala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learning Library.\nInAdvances in Neural Information Processing Systems 32 , H. Wallach, H. Larochelle,\nA. Beygelzimer, F. d 'Alch√©-Buc, E. Fox, and R. Garnett (Eds.). Curran Associates,\nInc., 8024‚Äì8035. http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-\nhigh-performance-deep-learning-library.pdf\nDanping Peng, Barry Merriman, Stanley Osher, Hongkai Zhao, and Myungjoo Kang.\n1999. A PDE-based fast local level set method. Journal of computational physics 155,\n2 (1999), 410‚Äì438.\nSongyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas Geiger.\n2020. Convolutional occupancy networks. In European Conference on Computer\nVision . Springer, 523‚Äì540.\nWilliam B Pennebaker and Joan L Mitchell. 1992. JPEG: Still image data compression\nstandard . Springer Science & Business Media.\nNasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred Ham-\nprecht, Yoshua Bengio, and Aaron Courville. 2019. On the spectral bias of neural\nnetworks. In International Conference on Machine Learning . PMLR, 5301‚Äì5310.\nShunsuke Saito, Liwen Hu, Chongyang Ma, Hikaru Ibayashi, Linjie Luo, and Hao Li.\n2018. 3D hair synthesis using volumetric variational autoencoders. ACM Transactions\non Graphics (TOG) 37, 6 (2018), 1‚Äì12.\nMirko Sattler, Ralf Sarlette, and Reinhard Klein. 2005. Simple and Efficient Compression\nof Animation Sequences. In Proceedings of the 2005 ACM SIGGRAPH/Eurographics\nSymposium on Computer Animation (SCA ‚Äô05) . Association for Computing Machinery,\n209‚Äì217.\nRajsekhar Setaluri, Mridul Aanjaneya, Sean Bauer, and Eftychios Sifakis. 2014. SPGrid: A\nsparse paged grid structure applied to adaptive smoke simulation. ACM Transactions\non Graphics (TOG) 33, 6 (2014), 1‚Äì12.\nNoam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geof-\nfrey E. Hinton, and Jeff Dean. 2017. Outrageously Large Neural Networks: The\nSparsely-Gated Mixture-of-Experts Layer.. In ICLR (Poster) .\nVincent Sitzmann, Eric Chan, Richard Tucker, Noah Snavely, and Gordon Wetzstein.\n2020a. Metasdf: Meta-learning signed distance functions. Advances in Neural\nInformation Processing Systems 33 (2020), 10136‚Äì10147.\nVincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, and Gordon\nWetzstein. 2020b. Implicit neural representations with periodic activation functions.\nAdvances in Neural Information Processing Systems 33 (2020).\nJohn Strain. 2001. A fast semi-Lagrangian contouring method for moving interfaces. J.\nComput. Phys. 170, 1 (2001), 373‚Äì394.\nTowaki Takikawa, Alex Evans, Jonathan Tremblay, Thomas M√ºller, Morgan McGuire,\nAlec Jacobson, and Sanja Fidler. 2022a. Variable bitrate neural fields. In ACM\nSIGGRAPH 2022 Conference Proceedings . 1‚Äì9.\nTowaki Takikawa, Joey Litalien, Kangxue Yin, Karsten Kreis, Charles Loop, Derek\nNowrouzezahrai, Alec Jacobson, Morgan McGuire, and Sanja Fidler. 2021. Neural\ngeometric level of detail: Real-time rendering with implicit 3D shapes. In Proceedings\nof the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 11358‚Äì11367.Towaki Takikawa, Or Perel, Clement Fuji Tsang, Charles Loop, Joey Litalien, Jonathan\nTremblay, Sanja Fidler, and Maria Shugrina. 2022b. Kaolin Wisp: A PyTorch Library\nand Engine for Neural Fields Research. https://github.com/NVIDIAGameWorks/\nkaolin-wisp.\nMatthew Tancik, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin\nRaghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan T. Barron, and Ren Ng.\n2020. Fourier Features Let Networks Learn High Frequency Functions in Low\nDimensional Domains. NeurIPS (2020).\nDanhang Tang, Mingsong Dou, Peter Lincoln, Philip Davidson, Kaiwen Guo, Jonathan\nTaylor, Sean Fanello, Cem Keskin, Adarsh Kowdle, Sofien Bouaziz, et al .2018. Real-\ntime compression and streaming of 4d performances. ACM Transactions on Graphics\n(TOG) 37, 6 (2018), 1‚Äì11.\nDanhang Tang, Saurabh Singh, Philip A Chou, Christian Hane, Mingsong Dou, Sean\nFanello, Jonathan Taylor, Philip Davidson, Onur G Guleryuz, Yinda Zhang, et al .\n2020. Deep implicit volume compression. In Proceedings of the IEEE/CVF conference\non computer vision and pattern recognition . 1293‚Äì1303.\nThe Blosc Development Team. 2020. Blosc . Accessed: 2022-02-04.\nS√©bastien Valette and R√©my Prost. 2004. A Wavelet-Based Progressive Compression\nScheme For Triangle Meshes : Wavemesh. IEEE Transactions on Visualization\nand Computer Graphics 10, 2 (2004), 123‚Äì129. https://doi.org/10.1109/TVCG.2004.\n1260764\nPatricio Gonzalez Vivo and Jen Lowe. 2015. The Book of Shaders: Fractal Brownian\nMotion. Patricio Gonzalez Vivo, https://thebookofshaders. com/13 (2015).\nIgnacio Vizzo, Tiziano Guadagnino, Jens Behley, and Cyrill Stachniss. 2022. Vdbfusion:\nFlexible and efficient tsdf integration of range sensor data. Sensors 22 .\nWalt Disney Animation Studios. 2017. Disney Clouds Dataset . Accessed: 2021-12-09.\nMagnus Wrenninge, Chris Allen, Sosh Mirsepassi, Stephen Marshall, Chris Bur-\ndorf, Henrik Falt, Scot Shinderman, and Doug Bloom. 2020. Field3D.\nhttps://github.com/imageworks/Field3D.\nTong Wu, Liang Pan, Junzhe Zhang, Tai Wang, Ziwei Liu, and Dahua Lin. 2021. Density-\naware chamfer distance as a comprehensive metric for point cloud completion. arXiv\npreprint arXiv:2111.12702 (2021).\nYiheng Xie, Towaki Takikawa, Shunsuke Saito, Or Litany, Shiqin Yan, Numair Khan,\nFederico Tombari, James Tompkin, Vincent Sitzmann, and Srinath Sridhar. 2022.\nNeural Fields in Visual Computing and Beyond. Computer Graphics Forum (2022).\nhttps://doi.org/10.1111/cgf.14505\nAlex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa. 2021. pixelNeRF: Neural\nRadiance Fields from One or Few Images. In CVPR .\nZongwei Zhou, Jae Shin, Lei Zhang, Suryakanth Gurudu, Michael Gotway, and Jianming\nLiang. 2017. Fine-tuning convolutional neural networks for biomedical image\nanalysis: actively and incrementally. In Proceedings of the IEEE conference on computer\nvision and pattern recognition . 7340‚Äì7351.\nA RANDOM ACCESS IN VDB\nRandom (i.e., coordinate-based) access to values in a VDB structure\nis fast (on average constant time) due to a unique caching mecha-\nnism and the fact that the tree structure has a fixed depth of only\nfour levels. Whenever a random value query is performed, a value\naccessor caches all the nodes visited. For subsequent queries, the\ncached nodes are initially visited bottom-up, and the first node that\ncontains the new query point is used as the starting point for a\ntop-down traversal, which also updates the cache with newly vis-\nited nodes. Consequently, a value accessor effectively performs a\nbottom-up, versus a traditional top-down, tree traversal, which is\nvery fast for typical access patterns, like Finite-Difference stencils\nthat are spatially coherent.\nB NANOVDB\nThe open source C++ implementation of VDB, dubbed OpenVDB,\nmakes use of several libraries that only work on CPUs, or more\nto the point not on GPUs. NanoVDB [Museth 2021] addressed this\nlimitation by offering C++ and C99 implementations of the VDB tree\nstructure without any external library dependencies. Consequently,\nNanoVDB runs on both CPUs and GPUs, and supports most graph-\nics APIs including CUDA, DX12, OptiX, OpenGL, OpenCL, Vulcan\nand GLSL. However, one limitation is that NanoVDB assumes the\n\n20 ‚Ä¢Kim, Lee, and Museth\ntopology of the tree to be static, which follows from the entire tree\ncan be serialized (or linearized) into a single continuous block of\nmemory. Other than GPU support, NanoVDB offers another advan-\ntage over OpenVDB, namely in-memory compression by means\nof variable bit-rate quantization with dithering to randomize the\ninevitable quantization noise. This typically reduces the memory\nfootprints of NanoVDB volumes by a factor of 4-6 relative to Open-\nVDB representations, at the cost of small quantization errors and\nthe assumption of fixed trees, which is ideal for especially rendering\nand some simulation applications.\nC EFFECT OF TRAINING WITH SPARSITY\nINFORMATION\nAs an ablation study, we performed an experiment where the Bunny\nCloud model is trained on 1) a dense grid, 2) a block grid (represented\nby dense leaf nodes in a VDB tree), and 3) sparse voxels represented\nby the active voxel in a VDB grid. We trained these models with\nidentical configurations including the MLP architecture as well as\ntraining parameters. As shown in Figure 17, the results from the\ndense grid contain the highest amount of noise, whereas the other\nmodels show much better visual quality. The noise is still visible in\nthe blocked (2) fog volume, which does not make use of the active\nvoxel masks in VDB. However, when using the sparse VDB voxel\nrepresentation (3), the same network can effectively reconstruct the\nmodel with low noise.\nD EFFECT OF ACTIVATION FUNCTIONS\nWhile the ReLU activation function works for most of the cases, we\nnoticed that different activation functions could affect the recon-\nstruction quality as well as the convergence rate. In our experiments,\nthe ReLU works great for flat, structured, or artificial models, while\nthesinandtanh function can work better for smooth or unstruc-\ntured models as shown in Figure 18. Furthermore, although it is\nredundant to the Fourier feature mapping, we noticed that the sin\nfunction, as shown in SIREN [Sitzmann et al .2020b] also can be used\nfor specific smooth and unstructured models and also accelerate the\nconvergence compared to ReLU or tanh functions.\nE HEURISTIC ESTIMATION OF HYPER-PARAMETERS\nTable 4 lists several hyperparameters for NeuralVDB that impact\nboth accuracy and efficiency. In this section, we elaborate on the ef-\nfect of each hyperparameter and provide heuristics for determining\ntheir values.\nThe subdomain size affects both training accuracy and time. If\ntoo large, most of the subdomains will be empty, wasting computing\nresources. If the domain is too small, the cost of dispatching query\npoints can be non-negligible, and overlapping halo regions can\nbecome dominant, which in turn results in redundant computation.\nWe picked a subdomain size for each experiment with a multiple of\n512, which proved sufficient to efficiently subdivide the examples\nstudies in this paper.\nFor the network parameters, level-1 networks use half of the width\nof the level-0 networks. We found that for most examples, three\nlayers were sufficient for the desired tolerances, while four layers\nare used for volumes with more details to capture. As mentioned inD, we used either sinor ReLU activations depending on how smooth\nor structured the input volume is. The frequency of sinactivation\nranged from 1.5 to 3.0.\nThe parameters for Fourier feature mapping are determined by\nthe width of the network. For a wide network, which normally\nmeans there are high-frequency details to capture, the same number\nof mapped features (FFM size) to the network width and a larger\nFFM scale are used (see Section 3.2.2).\nThe sampling strategy for the batches was either drawing 216\nrandom samples for each epoch or resampling a subset of input\nvoxels for a given interval and drawing smaller batches ( 212) for\neach epoch. In the latter case, the number of a subset to be resampled\nis determined by the number of resampling intervals (either 100 or\n500 in our examples) times batch size. This resampling is used when\nfine details with thin structures are critical.\nFor the network optimizer, a learning rate of 0.001 was used\nfor most of the experiments, except the Crawler model which has\nuniquely complex geometric features. We decayed the learning rate\nwith 0.975 with an interval of 100 when no subset resampling was\nused. When we performed the resampling, we used a decay rate\nof 0.75 with an interval of 1000. The number of maximum epochs\nwas 2500 for non-resampled cases. More epochs were used for the\nresampled cases.\nIn general, for less artificially shaped geometry or small volumes,\na level-0 network with width 128, depth 3, sinactivation with fre-\nquency 1.5, matching feature mapping size with the width, and FMM\nscale of 5 or greater proved to be a good starting point. (Level-1\nnetwork should be half of the width.) Similar to our examples, a\nlearning rate of 0.001, decay rate and interval of 0.975 and 100, and\nmaximum epochs of 2500 with a batch size of 216should be suffi-\ncient for most cases. For a structured geometry or a volume with\nhigh-frequency details, wider networks with the subset resampling\napproach and its parameter set from one of our examples should be\na good baseline.\n\nNeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks ‚Ä¢21\nUsing Sparse Leaf Nodes Using Dense Leaf Nodes Using Dense Grid\nFig. 17. Comparison of the effects that sparse vs dense representations have on training of sparse volumes. The left image is trained with a dense grid with no\nsparsity information. The middle image is trained with a sparse blocked grid, but without active voxel masks. The right image is trained with a VDB grid that\noffers both sparse nodes and active voxel masks. All experiments were trained with the same network architecture and hyper-parameters.\nsin Ground Truth ReLU\nFig. 18. Comparison of the effect of sin(middle column) and ReLU activation functions (right-most column) for the Armadillo example. The ground truth\nmodel (left) has both smooth geometry as well as flat surfaces from the coarse input mesh. The ùë†ùëñùëõactivation function tends to smooth out the sharp edges\nwhile ReLU can introduce more high-frequency noise.",
  "textLength": 103022
}