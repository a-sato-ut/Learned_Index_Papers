{
  "paperId": "26026085f04b1e19f4429239046306c1817487a9",
  "title": "Algorithms for Caching and MTS with reduced number of predictions",
  "pdfPath": "26026085f04b1e19f4429239046306c1817487a9.pdf",
  "text": "arXiv:2404.06280v2  [cs.LG]  10 Apr 2024Published as a conference paper at ICLR 2024\nALGORITHMS FOR CACHING AND MTS\nWITH REDUCED NUMBER OF PREDICTIONS\nKarim Abdel Sadek\nUniversity of Amsterdam∗\nkarim.abdel.sadek@student.uva.nlMarek Eliáš\nDepartment of Computing Sciences\nBocconi University\nmarek.elias@unibocconi.it\nABSTRACT\nML-augmented algorithms utilize predictions to achieve pe rformance beyond\ntheir worst-case bounds. Producing these predictions migh t be a costly operation\n– this motivated Im et al. (2022) to introduce the study of alg orithms which use\npredictions parsimoniously. We design parsimonious algor ithms for caching and\nMTS with action predictions , proposed by Antoniadis et al. (2023), focusing on\nthe parameters of consistency (performance with perfect pr edictions) and smooth-\nness (dependence of their performance on the prediction err or). Our algorithm for\ncaching is 1-consistent, robust, and its smoothness deteriorates with the decreas-\ning number of available predictions. We propose an algorith m for general MTS\nwhose consistency and smoothness both scale linearly with t he decreasing num-\nber of predictions. Without the restriction on the number of available predictions,\nboth algorithms match the earlier guarantees achieved by An toniadis et al. (2023).\n1 I NTRODUCTION\nCaching, introduced by Sleator and Tarjan (1985), is a funda mental problem in online computation\nimportant both in theory and practice. Here, we have a fast me mory (cache) which can contain up\ntokdifferent pages and we receive a sequence of requests to page s in an online manner. Whenever\na page is requested, it needs to be loaded in the cache. Theref ore, if the requested page is already in\nthe cache, it can be accessed at no cost. Otherwise, we suffer apage fault : we have to evict one page\nfrom the cache and load the requested page in its place. The pa ge to evict is to be chosen without\nknowledge of the future requests and our target is to minimiz e the total number of page faults.\nCaching is a special case of Metrical Task Systems introduce d by Borodin et al. (1992) as a general-\nization of many fundamental online problems. In the beginni ng, we are given a metric space Mof\nstates which can be interpreted as actions or conﬁgurations of some system. We start at a predeﬁned\nstatex0∈M. At time steps t= 1,2,..., we receive a cost function ℓt:M→R+∪{0,+∞}and\nwe need to make a decision: either to stay at xt−1and pay a cost ℓt(xt−1), or to move to another,\npossibly cheaper state xtand payℓt(xt) +d(xt−1,xt), where the distance d(xt−1,xt)represents\nthe transition cost between states xt−1andxt.\nThe online nature of both caching and MTS forces an algorithm to make decisions without knowl-\nedge of the future which leads to very suboptimal results in t he worst case (Borodin et al., 1992;\nSleator and Tarjan, 1985). A recently emerging ﬁeld of learn ing-augmented algorithms, introduced\nin seminal papers by Kraska et al. (2018) and Lykouris and Vas silvitskii (2021), investigates ap-\nproaches to improve the performance of algorithms using pre dictions, possibly generated by some\nML model. In general, no guarantee on the accuracy of these pr edictions is assumed. Therefore,\nthe performance of learning-augmented algorithms is usual ly evaluated using the following three\nparameters:\nConsistency. Performance with perfect predictions, preferably close to optimum.\nRobustness. Performance with very bad predictions, preferably no worse than what is achievable by\nknown algorithms which do not utilize predictions.\n∗The presentation of this paper was ﬁnancially supported by t he Amsterdam ELLIS Unit and Qualcomm.\nWork completed while Abdel Sadek was in his ﬁnal year of BSc at Bocconi University\n1\n\nPublished as a conference paper at ICLR 2024\nSmoothness. Algorithm’s performance should deteriorate smoothly with increasing prediction error\nbetween the consistency and robustness bound.\nThese three parameters express a desire to design algorithm s that work very well when receiving\nreasonably accurate predictions most of the time and, in the rest of the cases, still satisfy state-of-\nthe-art worst-case guarantees. See the survey by Mitzenmac her and Vassilvitskii (2020) for more\ninformation.\nProducing predictions is often a computationally intensiv e task, therefore it is interesting to under-\nstand the interplay between the number of available predict ions and the achievable performance. In\ntheir inspiring work, Im et al. (2022) initiated the study of learning-augmented algorithms which use\nthe predictions parsimoniously. In their work, they study c aching with next-arrival-time predictions\nintroduced by Lykouris and Vassilvitskii (2021). Their alg orithm uses O(blogb+1k)OPT predic-\ntions, where OPT is the number of page faults incurred by the ofﬂine optimal so lution and b∈N\nis a parameter. It achieves smoothness linear in the predict ion error. It satisﬁes tight consistency\nbounds: with perfect predictions, it incurs at most O(logb+1k)OPT page faults and no algorithm\ncan do better. In other words, it achieves a constant competi tive ratio with unrestricted access to pre-\ndictions ( b=k) and, with ba small constant, its competitive ratio deteriorates to O(logk)which is\ncomparable to the best competitive ratio achievable withou t predictions. One of their open questions\nis whether a similar result could be proved for MTS.\nIn this paper, we study parsimonious algorithms for MTS work ing with action predictions which\nwere introduced by Antoniadis et al. (2023). Here, each pred iction describes the state of an optimal\nalgorithm at the given time step and its error is deﬁned as the distance from the actual state of the\noptimal algorithm. The total prediction error is the sum of e rrors of the individual predictions. In\nthe case of caching, action predictions have a very concise r epresentation, see Section 2.1. Unlike\nnext-arrival-time predictions, action predictions can be used for any MTS. Using the method of\nBlum and Burch (2000), it is easy to achieve near-optimal rob ustness for any MTS losing only a\nfactor(1+ǫ)in consistency and smoothness. Therefore, we study how the r educed number of pre-\ndictions affects the consistency and smoothness parameter s. We consider the following two regimes.\nBounded number of predictions: The algorithm can request a prediction whenever it prefers a s far as\nthe total number of requested predictions is bounded by bOPT , wherebis a parameter. This regime\nis similar to Im et al. (2022).\nWell-separated queries to the predictor: The queries to the predictor need to be separated by at least\natime steps, for some parameter a. This captures the situation when producing each predictio n\ntakes more than one time step.\n1.1 O UR RESULTS\nWe evaluate the algorithm’s performance using competitive ratio which is, roughly speaking, the\nworst-case ratio between the cost incurred by the algorithm and the cost of the ofﬂine optimum, see\nSection 2 for a formal deﬁnition. We say that an algorithm ach ieves consistency αand robustness β\nif its competitive ratio is at most αwhen provided with perfect predictions and at most βwith arbi-\ntrarily bad predictions. For a given function g, we call an algorithm g(η)-smooth if its competitive\nratio is at most g(η)whenever provided with predictions with the total error at m ostη.\nOur ﬁrst contribution is an algorithm for caching which rece ives action predictions describing the\nstates of the optimal ofﬂine algorithm Belady proposed by Belady (1966). High quality such pre-\ndictor based on imitation learning was already designed by L iu et al. (2020). Its empirical evalua-\ntion within existing algorithms designed for action predic tions was performed by Chledowski et al.\n(2021).\nTheorem 1.1. Letfbe an increasing convex function such that f(0) = 0 andf(i)≤2i−1for each\ni≥0. There is an algorithm for caching requiring O(f(logk))OPT predictions which achieves\nconsistency 1, robustness O(logk), and smoothness O(f−1(η/OPT)), whereηdenotes the total\nprediction error with respect to Belady andOPT is the number of page faults of Belady .\nIn fact, the number of required predictions is slightly smal ler than what is stated in the theorem. Ta-\nble 1 shows numbers of predictions and achieved smoothness f or some natural choices of f. Already\nwithO(√\nk)OPT predictions, our bounds are comparable to Antoniadis et al. (2023) whose algo-\n2\n\nPublished as a conference paper at ICLR 2024\nTable 1: Smoothness vs. number of predictions.\nf(i) # of predictions smoothness\n2i−1O(√\nk)OPT O(1+log(η\nOPT+1))\ni2O(log2k)OPT O(/radicalbig\n2η\nOPT)\ni O (logk)OPT O(η\nOPT)\n0 2OPT O(kη\nOPT)\nrithm asks for a prediction in every step, its consistency is constant and its smoothness is logarithmic\ninη. The algorithm also works with f(i) = 0 . In that case, it asks for at most 2OPT predictions\nand still remains 1-consistent. However, its smoothness is not very good. We us e sliding marking\nphases and a careful distribution of queries of the predicto r over the time horizon. This allows us\nto avoid dealing with so called \"ancient\" pages considered b y Rohatgi (2020) and Antoniadis et al.\n(2023), resulting in an algorithm with better consistency a nd a simpler analysis.\nWe discuss tightness of our bounds in Section 7. We show that w ith, for example, only 0.5OPT\navailable predictions, no algorithm can be better than O(logk)-competitive – a guarantee compa-\nrable to the best classical online algorithms without predi ctions. We also show that the number of\npredictions used by our algorithm is close to optimal.\nTheorem 1.2. Letfbe an increasing function. Any f(η)-smooth algorithm for caching with action\npredictions, i.e., an algorithm whose competitive ratio wi th predictions of error ηisf−1(η)for any\nη >0, has to use at least f(lnk)OPT predictions.\nFor general MTS, we cannot bound the number of used predictio ns as a function of OPT . The\nreason is that any instance of MTS can be scaled to make OPT arbitrarily small, allowing us to use\nonly very few predictions. We propose an algorithm which que ries the predictor once in every a\ntime steps, making at most T/a queries in total, where Tdenotes the length of the input sequence.\nTheorem 1.3. There is a deterministic algorithm for any MTS which receive s a prediction only once\nper eachatime steps and its cost is at most O(a)·(OFF+2 η), whereOFF denotes the cost of an\narbitrary ofﬂine algorithm and ηthe error of predictions with respect to this algorithm.\nThis is a more general statement than Theorem 1.1 which requi resOFF to beBelady . Consider-\ning any ofﬂine optimal algorithm OFF , Theorem 1.3 implies a smoothness O(a)·(1+2η/OPT)\nand consistency O(a). Our algorithm is based on work functions. For a= 1, its smoothness\nis1 + 2η/OFF , see Section 4, which improves upon the smoothness bound of 1 + 4η/OFF by\nAntoniadis et al. (2023). It is not robust on its own. However , it can be combined with any on-\nline algorithm for the given MTS using the result of Blum and B urch (2000) achieving robustness\ncomparable to that algorithm and losing only a factor of (1+ǫ)in smoothness and consistency.\nNo algorithm receiving a prediction only once in atime steps can be o(a)-consistent. This follows\nfrom the work of Emek et al. (2009) on advice complexity, see S ection 7 for more details. The\nsame can be shown for smoothness by modifying the lower bound construction of Antoniadis et al.\n(2023).\nTheorem 1.4. There is no o(aη/OPT) -smooth algorithm for MTS with action predictions which\nreceives predictions only once in atime steps.\nWe can modify our algorithm for caching to ensure that the mom ents when the predictions are\nqueried are separated by at least atime steps, not losing too much of its performance.\nTheorem 1.5. There is an algorithm for caching which receives prediction at most once in a≤k\ntime steps and using at most O(f(logk))OPT predictions in total which is O(1)-consistent,\nO(logk)-robust and O(f−1(aη/OPT)) -smooth.\nIn Section 5, we provide empirical results suggesting that o ur algorithm’s performance can be com-\nparable to the performance of algorithms imposing no limita tions on their use of predictions. Our\nalgorithm may therefore be useful especially with heavy-we ight predictors like (Liu et al., 2020).\n3\n\nPublished as a conference paper at ICLR 2024\nIn Section 8, we provide an algorithm for an alternative pred iction setup which we call FitF oracle:\neach prediction says which of the pages in the current algori thms cache will be requested furthest in\nthe future.\n1.2 R ELATED WORK\nThe most related work is by Im et al. (2022), who studied cachi ng with next arrival time predictions.\nA smaller number of predictions affects the consistency of t heir algorithm: with b(logk/logb)OPT\npredictions, they achieve consistency O(logk/logb)and they show that this is tight. They also show\nthat their algorithm achieves linear smoothness. In contra st, our algorithm is 1-consistent when re-\nceiving at least OPT predictions. This demonstrates that action predictions, a lthough not contain-\ning more bits, seem to contain useful information about the i nput instance in a more condensed\nform. See (Antoniadis et al., 2023) for comparison and conne ctions between these prediction setups.\nDrygala et al. (2023) study ski rental and bahncard problems with predictions of a ﬁxed cost.\nThere are several other papers on caching with predictions, including (Lykouris and Vassilvitskii,\n2021; Rohatgi, 2020; Wei, 2020; Emek et al., 2009; Antoniadi s et al., 2023; 2022) which design\nalgorithms asking for a prediction at each time step. Consis tency parameters achieved by these\nalgorithms are constants greater than 1. Note that those using black-box methods to achieve ro-\nbustness are (1 +ǫ)-consistent (e.g. (Wei, 2020)). We can explicitly compare o ur smoothness\nbounds to Antoniadis et al. (2023) who use the same kind of pre dictions: their smoothness is\nO(1 + log(η\nOPT+ 1)) with unlimited use of predictions while our algorithm achie ves the same\nsmoothness bound with O(√\nk)OPT predictions. We compare the smoothness of the other algo-\nrithms experimentally in Section 5. Antoniadis et al. (2022 ) study a prediction setup where each pre-\ndiction is only a single bit, however their algorithms need t o receive it in every time step. Gupta et al.\n(2022) study several problems including caching in a settin g where each prediction is correct with a\nconstant probability.\nAntoniadis et al. (2023) proposed a 1-consistent and (1+4η/OPT) -smooth algorithm for MTS with\naction predictions which can be robustiﬁed by loosing facto r(1+ǫ)in consistency and smoothness.\nGetting smoothness bounds sublinear in η/OPT for speciﬁc MTS problems other than caching\nremains a challenging open problem even with unlimited numb er of predictions and this holds even\nfor weighted caching. Speciﬁc results on weighted caching a re by Jiang et al. (2022) who studied it\nin a setup requiring very verbose predictions and by Bansal e t al. (2022) whose bounds depend on\nthe number of weight classes. There is also a consistency/ro bustness trade-off by Lindermayr et al.\n(2022) for k-server.\nSince the seminal papers by Kraska et al. (2018) and Lykouris and Vassilvitskii (2021) which initi-\nated the study of learning-augmented algorithms, many comp utational problems were considered.\nThere are papers on ski rental (Purohit et al., 2018; Antonia dis et al., 2021), secretary and match-\ning problems (Dütting et al., 2021; Antoniadis et al., 2020) , online-knapsack (Im et al., 2021;\nZeynali et al., 2021; Boyar et al., 2022), graph exploration (Eberle et al., 2022), online TSP\n(Bernardini et al., 2022), energy efﬁcient scheduling (Bam as et al., 2020), ﬂow-time scheduling\n(Azar et al., 2021; 2022), restricted assignment (Lattanzi et al., 2020), non-clairvoyant schedul-\ning Purohit et al. (2018); Lindermayr and Megow (2022), and o nline page migration (Indyk et al.,\n2022). In ofﬂine setting, there is a work of Dinitz et al. (Din itz et al., 2021) on matching, Chen et\nal. (Chen et al., 2022) on graph algorithms, Polak and Zub (Po lak and Zub, 2022) on ﬂows, Sakaue\nand Oki (Sakaue and Oki, 2022) on discrete optimization prob lems, and Ergun et al. (Ergun et al.,\n2022) on clustering. We also refer to (Lindermayr and Megow, 2022) to an updated list of results in\nthe area.\nThere are numerous works on advice complexity of online prob lems, where algorithms are given\ncertain number of bits of information about the future which are guaranteed to be correct. This is\ndifferent from our setting, where we receive predictions of unknown quality. We refer to the survey\nby Boyar et al. (2017), work of Dobrev et al. (2009) on caching , Emek et al. (2009) on MTS, and\nfurther papers by Hromkovi ˇc et al. (2010); Böckenhauer et al. (2017).\nThere are already works on predictors for caching. Jain and L in (2016) proposed a binary classiﬁer\ncalled Hawkey which predicts which pages will be kept in cach e byBelady , providing us with\naction predictions. Their result was later improved by Shi e t al. (2019) who designed a model called\n4\n\nPublished as a conference paper at ICLR 2024\nGlider for the same classiﬁcation problem. There is a very pr ecise model by Liu et al. (2020) whose\nmain output can be interpreted as an action prediction altho ugh it has a second prediction head\nwhich produces next arrival predictions. This model is larg e and relatively slow and served as\na motivation for this work. Chledowski et al. (2021) evaluat ed the performance of existing ML-\naugmented algorithms with this predictor.\n2 P RELIMINARIES\nConsider an algorithm ALG for MTS which produces a solution x0,x1,...,x Tfor an instance I\nconsisting of cost functions ℓ1,...,ℓ T. We denote cost(ALG( I)) =/summationtextT\nt=1(ℓt(xt) +d(xt−1,xt)).\nWe say that ALG isr-competitive with respect to an ofﬂine algorithm OFF if there is an absolute\nconstantα∈Rsuch that E[cost(ALG( I))]≤r·cost(OFF( I)) +αfor any instance I. IfALG\nisr-competitive with respect to an optimal ofﬂine algorithm, w e say that ALG isr-competitive\nand callrthe competitive ratio of ALG . In the classical setting (without predictions), the best\nachievable competitive ratios are Θ(logk)for caching (Fiat et al., 1991) and of order polylognfor\nMTS (Bartal et al., 2006; Bubeck et al., 2019), where nis the number of points in the underlying\nmetric space M. We refer to (Borodin and El-Yaniv, 1998) for a textbook trea tment.\n2.1 A CTION PREDICTIONS FOR MTS\nAntoniadis et al. (2023) proposed a prediction setup which t hey call action predictions , where the\npredictions tell us what a good algorithm would do. More prec isely, at each time t, the algorithm\nreceives a prediction ptof a state where some ofﬂine algorithm OFF moves to at time t. The error of\nprediction ptis thenηt=d(pt,ot), whereotis the real state of OFF at timet. The total prediction\nerror is deﬁned as η=/summationtextT\nt=1ηt.\nConsidering the case of caching, the state corresponds to a c ache content, and the prediction error\nis the number of pages present in the cache of OFF and absent from the predicted cache content. A\nwhole cache content may seem like a huge piece of information , but action predictions for caching\ncan be implemented in a very succinct way. Antoniadis et al. ( 2023) explain how to represent them\nwith only O(logk)bits per time step when they are received at each time step. Ou r algorithm\nasks, in each query, a speciﬁc number of indices of pages whic h are present in its cache but absent\nfrom the predicted cache. When we talk about a bound on the num ber of provided predictions,\nthis bound applies both to the number of such queries as well a s to the total number of indices\nreported by the predictor during the running time of the algo rithm. There are predictors which can\ngenerate predictions of a similar kind by Jain and Lin (2016) ; Shi et al. (2019); Liu et al. (2020). See\n(Antoniadis et al., 2023) for a detailed treatment of this pr ediction setup and a comparison to other\nsetups for caching.\n2.2 C ACHING : BELADY ’S ALGORITHM , MARKING ,AND LAZY ALGORITHMS\nThe classical optimal ofﬂine algorithm for caching propose d by Belady (1966) is denoted Belady in\nthis paper. At each page fault, it evicts a page which is going to be requested furthest in the future.\nIn the case of a tie, i.e., if there are several pages in the cac he which will not be requested anymore,\nit chooses one of them arbitrarily. Our caching algorithm as sumes that the predictor is trying to\nsimulateBelady . The following useful property allows us to detect errors in the predictions quickly.\nIt was recently used by Eliáš et al. (2024).\nObservation 2.1. Consider request sequence r1,...,r T. For any t≤T, the cost incurred by\nBelady forr1,...,r Tuntil time tis the same as the cost of Belady with input r1,...,r t.\nTo see this, it is enough to note that the solution produced by Belady with input r1,...,r Tagrees\nuntil time twith the solution produced by Belady onr1,...,r twhich breaks ties based on the\narrival times in rt+1,...,r T.\nWe use properties of marking algorithms in this work. Such algorithms split the input seq uence\ninto phases, i.e., maximal subsequences where at most kdistinct pages are requested. Usually, the\nﬁrst phase starts in the beginning and the next phase follows just after the end of the previous one.\nHowever, we will consider phases starting at arbitrary mome nts. LetObe the cache content of an\n5\n\nPublished as a conference paper at ICLR 2024\nalgorithm in the beginning of the phase. Whenever a page is re quested for the ﬁrst time during\nthe phase, we call this moment an arrival and we mark the page. At the end of the phase, the set\nMof marked pages will have size k: some of them belong to Oand are called oldwhile those in\nC=M\\Oare called clean . Exactly |C|pages from Oremain unmarked until the end of the phase.\nMarking algorithms is a class of algorithms which never evic t a marked page and all of them have\ncache content Mat the end of the phase. Belady is not marking and our algorithm is not marking\neither, although it uses ideas from marking to achieve desir ed robustness and smoothness properties.\nAt the end of each phase, we can bound the difference between t he cache content of some algorithm\nand marking.\nObservation 2.2. Letcbe the cost incurred by some algorithm during a marking phase . Then,\nc≥ |M\\S|, whereSis the cache content of the algorithm at the end of the phase an dMis the set\nofkpages requested during the phase.\nThis is because each page in p∈Mhas to be present in algorithm’s cache when requested during\nthe phase. If p /∈S, then the algorithm must have evicted it during the phase inc urring cost 1.\nObservation 2.3. If a page pis evicted by Belady at timet, thenpis not going to be requested in\nthe marking phase containing tanymore.\nIfpis evicted by Belady at timet, then the currently requested page rtandk−1pages from the\ncache are kdistinct pages that are requested before the moment when pis requested next time. The\ncurrent phase then needs to end before that moment.\nWe say that an algorithm is lazyif it evicts only one page at a time and only at a page fault. Belady\nis lazy while our algorithm, as described, may not be. Howeve r, any algorithm can be made lazy\nwithout increasing its cost. See (Borodin and El-Yaniv, 199 8) for more information about caching.\nObservation 2.4. The difference in the cache content of two lazy algorithms ca n increase only if\nboth of them have a page fault. In that case, it can increase by at most 1.\n2.3 MTS AND ADVICE COMPLEXITY\nAdvice complexity studies the performance of algorithms de pending on the number of bits of precise\ninformation about the instance available in advance. In the case of MTS, Emek et al. (2009) study\nthe situation when algorithm receives1\nalognbits of information about the state of some optimal\nofﬂine algorithm, being able to identify its true state once inatime steps. They formulate the\nfollowing proposition for OFF being an optimal algorithm, but the proof does not use its opt imality\nand it can be any algorithm located at qiat timeia.\nProposition 2.5 (Emek et al. (2009)) .There is an algorithm which, with knowledge of state qiof\nalgorithm OFF at timeiafori= 1,...,T/a , isO(a)-competitive w.r.t. OFF .\nIn our context, we can say that the algorithm from the precedi ng proposition is O(a)-consistent if\nq1,...,q T/aare states of an optimal solution. However, it is not smooth b ecause it may not be\npossible to relate the cost of OFF to the prediction error with respect to OPT .\n3 B OUNDED NUMBER OF PREDICTIONS\nIn this section, we prove Theorem 1.1. We propose an algorith m calledF&R which consists of two\nparts:Follower andRobust . It starts with Follower which is1-consistent, but lacks in smoothness\nand robustness. At each page fault, Follower recomputes Belady for the part of the sequence seen so\nfar and checks whether it also has a page fault. If yes, it copi es the behavior of the predictor (Line 3).\nOtherwise, it must have received an incorrect prediction be fore. Therefore, it switches to Robust\n(Line 5) which is no more 1-consistent, but achieves desired smoothness and robustne ss.Robust\nruns for one marking phase and then returns back to Follower . At such moment, the predictor’s and\nthe algorithm’s cache can be very different and Follower may need to lazily synchronize with the\npredictor (Line 4).\nAlgorithm Robust runs during a single marking phase starting at the same momen t, splitting it into\nwindows as follows (assuming kis a power of 2): The ﬁrst window W1starts at the beginning of the\nphase and lasts k/2arrivals, i.e., it ends just before the arrival number k/2+1 .Wifollows the Wi−1\n6\n\nPublished as a conference paper at ICLR 2024\nAlgorithm 1: Follower\n1P:=initial cache content; // Prediction for time 0\n2foreach pagefault do\n3 ifrt/∈PandBelady has a pagefault then query new prediction Pand evict any\np∈C\\P;\n4 else ifrt∈Pthen evict arbitrary p /∈P;\n5 else Switch to Robust (Algorithm 2);\nand its length is half of the remaining arrivals in the phase. The last window Wlogk+1={k}lasts\nuntil the end of the phase. Robust comes with an increasing convex function fsuch that f(0) = 0\nandf(i)≤2j−1. Faster growing fdoes not further improve our smoothness bounds. Function\nfdetermines that we should request f(i)−f(i−1)predictions in window i. If the window is too\nsmall, we ask for prediction at each time step. Robust starts with the cache content of a marking\nalgorithm whose new phase would start at the same moment (Lin e 1). In the case of a page fault,\nit evicts an unmarked page chosen uniformly at random. At arr ivals belonging to the sets Sand\nF, it performs synchronization with the predictor and querie s the predictor’s state respectively. The\nsynchronization is always performed with respect to the mos t recent prediction Pwhich, in the case\nof lazy (or laziﬁed) predictors, implicitly incorporates i nformation from the previous predictions.\nAlgorithm 2: Robust f(one phase)\n1 1Loadkdistinct most recently requested pages;\n2S:={k−2j+1|j= logk,...,0};\n3Wi:= [k−2logk−i+1+1,k−2logk−i]fori= 1,...,logkandWlogk+1={k};\n4ChooseF⊆ {1,...,k}such that |F∩Wi|= min{f(i)−f(i−1),|Wi|}for eachi;\n5foreach pagefault during the phase do\n6 ifit is arrival belonging to Fthen ask for new prediction P;\n7 ifit is arrival belonging to Sthen synchronize with P;\n8 ifrequested page is still not in cache then evict random unmarked page;\n9Load all pages marked during the phase;\n10Switch to Follower (Algorithm 1);\nSynchronization with P(Line 7) works as follows. All pages previously evicted by ra ndom evictions\nreturn to the cache and the same number of pages not present in Pis evicted. We denote Ei=\nE−\ni∪E+\nithe set of pages evicted at the beginning of Wi, where pages in E−\niare requested during\nWiwhile those in E+\niare not. Note that algorithm’s and predictor’s cache may not become the same\nafter the synchronization. Since the algorithm starts with pages inMand loads only clean pages,\nwe have the following observation.\nObservation 3.1. LetCi,|Ci|=cibe the set of clean pages arriving before the start of Wi. Then,\nEi⊆M∪Ciand|Ei|=|M∪Ci|−k=ci.\nWe assume that the predictor is lazy and does not load pages th at are not requested. Therefore, no\npage from E+\niwill be loaded during Wiby the predictor and the same holds for Robust , implying\nthe following.\nObservation 3.2. For every i= 1,...,logk, we have E+\ni⊆Ei+1and therefore Ei\\Ei+1⊆E−\ni.\nSynchronization with the marking cache performed by Robust is to ensure that the difference be-\ntween the cache of the algorithm and Belady can be bounded by costs incurred by Belady locally\nusing Observation 2.2 instead of diverging over time solely due to incorrect predictions.\nImplementation suggestions. Algorithms are described as to simplify the analysis. Synch roniza-\ntion inRobust (line 7) should be done lazily as to make use of the most recent prediction. At arrivals\nof clean pages, one may evict a page not present in predictor’ s cache instead of a random unmarked\npage; one can also ask for a fresh prediction (at most 2OPT additional queries). The second syn-\nchronization with the marking cache in Robust (line 9) can be omitted. With f(i) = 0 , one can\n7\n\nPublished as a conference paper at ICLR 2024\nquery the predictor only at clean arrivals, using at most 2OPT predictions in total. We recommend\na lazy implementation. Since Robust is not1-consistent, one may also switch from Follower only\nonceFollower ’s cost is at least a constant (e.g. 2 or 3) times higher than th e cost ofBelady .\nWe denote Hitheith phase of Robust fandH−\nia hypothetical marking phase which ends just\nbeforeHistarts. Note that H−\nimight overlap with Hi−1. ButH1,H2,... are disjoint and we\ndenoteGi,i+1the time interval between the end of Hiand the beginning of Hi+1.c(Hi)is the\nnumber of clean pages during phase Hi. For a given time period X, we deﬁne ∆A(X),∆B(X),\nand∆P(X)the costs incurred by F&R ,Belady , and the predictor respectively during Xandη(X)\nthe error of predictions received during X.\nHere is the main lemma about the performance of Robust . Its proof is deferred to Section 3.2.\nLemma 3.3. DenoteXi=Hi−1∪H−\ni∪Hi. During the phase Hi,Robust freceives at most\nf(logk)+1 predictions and we have\nE[∆A(Hi)]≤O(1)f−1/parenleftbiggη(Hi)\n∆B(Xi)/parenrightbigg\n∆B(Xi). (1)\nAt the same time, we also have\nE[∆A(Hi)]≤O(logk)∆B(Xi)and (2)\n∆A(Hi)≤O(k)+O(k)η(Hi). (3)\n3.1 A NALYSIS OF FOLLOWER\nLemma 3.4. Consider the gap Gi,i+1between phases HiandHi+1ofRobust f. We have\n∆A(Gi,i+1)≤∆B(Gi,i+1)+∆B(Hi).\nProof. There are ∆B(Gi,i+1)page faults served at line 3 because Belady also has those page faults.\nTo bound the cost incurred on line 4, we denote P,B,M the cache contents of the predictor, Belady ,\nandRobust respectively at the end of the phase Hi. The synchronization with Pcosts at most\n|(P\\M)∩B|if we omit costs incurred by Belady which were already accounted for above. However,\n(P\\M)∩B= (B\\M)∩P⊆B\\Mand|B\\M| ≤∆B(Hi)by Observation 2.2.\nProof of Theorem 1.1. The cost of Follower until the start of H1is the same as the cost of Belady .\nTherefore, by lemmas 3.4 and 3.3 equation 1, the cost of F&R , in expectation, is at most\nOPT+/summationdisplay\ni∆B(Hi)+/summationdisplay\niO(1)∆B(Xi)f−1/parenleftbiggη(Hi)\n∆B(Xi)/parenrightbigg\n,\nwhere the sums are over all phases of Robust and Xi=Hi−1∪H−\ni∪Hi. Since phases Hiare\ndisjoint and the same holds for H−\ni, this expression is at most OPT·O(f−1(η/OPT)) by concavity\noff−1, implying the smoothness bound for F&R .\nIf we use bound equation 2 instead of equation 1, we get O(logk)OPT – the robustness bound.\nSince there must be at least one error during the execution of Follower to trigger each execution\nofRobust , equation 3 implies that the cost of F&R is at most OPT+ηO(k). Withη= 0, this\nimplies1-consistency of F&R .Follower queries the predictor only at a page fault by OPT and the\nprediction consists of a single page evicted by the predicto r.Robust may ask for up to f(logk)+1\npredictions in each phase, each of them consisting of indice s of at most c(Hi)pages from F&R\ncache not present in the predictor’s cache. This gives both O(f(logk))OPT queries to the predictor\nas well as O(f(logk))OPT predicted indices in total.\nNote that Robust fcan rarely use full O(f(logk))predictions, because the last windows are not\nlong enough. More precise calculation of numbers of predict ions can be found in Appendix A.\n8\n\nPublished as a conference paper at ICLR 2024\n3.2 A NALYSIS OF Robust f\nFirst, we relate the number of clean pages in a robust phase to the costs incurred by Belady .\nObservation 3.5. Consider a phase HdenotingC(H)the set of clean pages arriving during H. We\nhave\nc(H) :=|C(H)| ≤∆B(H−)+∆B(H).\nProof. There are k+c(H)pages requested during H−∪H. Therefore, any algorithm, and Belady\nin particular, has to pay cost ∆B(H−∪H)≥c(H).\nLemma 3.6. Consider phase Hi. Cost incurred by Robust for synchronization with marking in\nLine 1 is at most ∆B(Hi−1∪H−\ni).\nProof. LetMdenote the kdistinct most recently requested pages – these are marked pa ges during\nH−\ni. We consider two cases.\nIfH−\ni∩Hi−1=∅, then whole H−\niwas served by Follower . Eachp∈Mmust have been in the\ncache of both Follower andPwhen requested and Follower would evict it afterwards only if Pdid\nthe same. Therefore, Robust needs to load at most ∆P(H−\ni) = ∆B(H−\ni)pages.\nIfH−\niandHi−1overlap, let M′denote the set of pages marked during Hi−1. At the end of Hi−1,\nRobust loadsM′andFollower loads only pages from Muntil the end of H−\ni. Therefore, Robust\nstartingHineeds to evict only pages from M′\\M. Now, note that there are |M′∪M|distinct pages\nrequested during Hi−1∪H−\niand therefore |M′\\M|=|M′∪M|−k≤∆B(Hi−1∪H−\ni).\nWe consider costs incurred by Robust during window Wifori= 1,...,logk+ 1. Note that\nE1=E+\n1=E−\n1=∅, sinceW1starts at the beginning of the phase and there are no clean pag es\narriving strictly before W1.\nLemma 3.7. Expected cost incurred by Robust fduringW1is at most 2c2. Fori= 2,...,logk+1,\nwe have\nE[∆A(Wi)]≤ |E−\ni−1|+ci−ci−1+2(|E−\ni|+ci+1−ci),\ndenotingclogk+2=c(H).\nProof. First, consider the costs during W1. There are c2−c1=c2clean pages arriving during W1\nandRobust has a page fault due to each of them, evicting a random unmarke d page. In the worst\ncase, all these clean pages arrive at the beginning of W1. Therefore, at arrival c2+ 1, there are c2\npages evicted which were chosen among unmarked pages unifor mly at random. Let Uadenote the\nset of unmarked pages at arrival a. We have U1=M(the initial cache content of Robust ) and\nnone of those pages get marked during ﬁrst c2arrivals. During every arrival a=c2+1,...,k/2 =\nS[2]−1, a single unmarked page is marked and we have |Ua|=k−(a−c2). As in the classical\nanalysis of Marker (see (Borodin and El-Yaniv, 1998) and ref erences therein), the probability of the\nrequested unmarked page being evicted is c2/|Ua|. We have\n∆A(W1) =c2+S[2]−1/summationdisplay\na=c2+1c2\n|Ua|≤c2+k\n2·c2\nk/2= 2c2.\nFori≥2, there are cipages evicted before the start of Wi: those in E+\ni−1were evicted due to\nsynchronization with the predictor and the rest were evicte d in randomized evictions – those are\nloaded back to the cache at the beginning of Wi, causing cost ci− |E+\ni−1|=|E−\ni−1|+ci−ci−1.\nAfter this synchronization, all unmarked pages are in the ca che except those belonging to Ei.\nDuringWi, pages from E−\niandci+1−cinew clean pages are requested causing page faults which\nare resolved by evicting a random unmarked page from the cach e. In the worst case, these page\nfaults all happen in the beginning of the window, leaving mor e time for page faults on randomly-\nevicted pages. Let ¯adenote the ﬁrst arrival after these page faults and U¯athe set of unmarked pages\nat that moment. At arrival ¯a, there are ci+1pages missing from the cache: pages from E+\niwhich\nare not going to be requested during Wiand|E−\ni|+ci+1−ci=ci+1−|E+\ni|unmarked pages were\n9\n\nPublished as a conference paper at ICLR 2024\nchosen uniformly at random from U¯a\\Ei=U¯a\\E+\ni. This is because only pages which were\nmarked since the beginning of Wiuntil¯aare those from E−\niand they were not present in the cache\nbefore they got marked. We compute the expected number of pag e faults on the randomly evicted\npages. Since they are unmarked when evicted, such page fault s can happen only on arrivals.\nAt arrival a, the set of unmarked pages Uahas sizek−(a−ci+1). For any a∈Wisuch that a≥¯a,\nwe haveUa∩E−\ni=∅and pages in Ua∩E+\niare evicted with probability 1. So, ci+1−|E+\ni|evicted\npages are picked uniformly at random from Ua\\E+\niof size at least k−(a−ci+1)−|E+\ni|. Therefore,\nour expected cost is at most\nS[i+1]−1/summationdisplay\na=¯aci+1−|E+\ni|\nk−a+ci+1−|E+\ni|≤/summationdisplay\na∈Wici+1−|E+\ni|\nk−a≤k\n2i·ci+1−|E+\ni|\nk/2i=ci+1−|E+\ni|\nwhich is equal to |E−\ni−1|+ci−ci−1. Note that k−a≥k−S[i+1]−1 = 2logk−i=k/2i.\nFori= 1,...,logk, we deﬁne\nrank(Wi) :=|Ei+1∩Bi+1|−∆B(Wi),\nwhereBidenotes the cache content of Belady at the beginning of Wi. We do not deﬁne rank(Wi)\nfori= 1+log k. Later, we relate rank to the prediction error. We have the fo llowing lemma.\nLemma 3.8. During a phase H, the expected cost of Robust fis at most\n3logk+1/summationdisplay\ni=1rank(Wi−1)+3c(H)+6∆B(H).\nProof. First, we observe that\n|E−\ni| ≤rank(Wi−1)+∆B(Wi−1)+∆B(Wi) (4)\nholds for i= 2,...,logk+1. This is because |E−\ni∩Bi| ≤ |Ei∩Bi|= rank(Wi−1)+∆B(Wi−1)\nand|E−\ni\\Bi| ≤∆B(Wi)due to pages from E−\nibeing requested during WiandBelady having\nto load them. Combining equation 4 with Lemma 3.7, and summin g over all windows, we get the\nstatement of the lemma.\nNow, we relate the rank of a window to the prediction error.\nLemma 3.9. Denoteηithe error of predictions arriving during Wi. We have\nη(Wi)≥ |F∩Wi|rank(Wi).\nProof. Prediction error at time tisηt=|Bt\\Pt|. At the end of Wi, it is at least |Ei+1∩Bi+1|.\nDue to laziness of the predictor, |Bt\\Pt|can increase only if both predictor and Belady have a page\nfault: in that case it may increase by 1, see Observation 2.4. Therefore, at any time tduringWi, we\nhaveηt=|Bt\\Pt| ≥ |Ei+1∩Fi+1| −∆B(Wi) = rank( Wi). Since we query the predictor at\narrivals belonging to F, the total error of received predictions is at least |F∩Wi|rank(Wi).\nWe will analyze intervals of windows starting when some part icular incorrect prediction was intro-\nduced and ending once it was corrected. The following lemma c harging the increase of rank to\nthe arriving clean pages and costs incurred by Belady will be used to bound the number of such\nintervals.\nLemma 3.10. Fori= 1,...,logk, we have\nrank(Wi)−rank(Wi−1)≤∆B(Wi−1)+ci+1−ci,\ndenotingW0an empty window before W1withrank(W0) = 0 .\n10\n\nPublished as a conference paper at ICLR 2024\nProof. It is enough to show that\n|Ei+1∩Bi+1| ≤ |Ei∩Bi|+∆B(Wi)+ci+1−ci.\nSince the right-hand side is always non-negative, we only ne ed to consider the case when the left-\nhand side is positive. We show how to charge pages in Ei+1∩Bi+1either to pages in Ei∩Bior to\n∆B(Wi)andci+1−ci.\nSince|Ei|=ci≤ci+1=|Ei+1|, we can construct an injective map β:Ei→Ei+1, such that\nβ(p) =pfor eachp∈Ei∩Ei+1. There are |Ei+1|−|Ei|=ci+1−cipagespsuch that β−1(p)\nis not deﬁned. We show that, for each p∈Ei+1∩Bi+1for which it is deﬁned, β−1(p)is either a\npage inEi∩Bior a page loaded by Belady duringWi. There are two cases.\n•p∈Ei∩Ei+1implying β−1(p) =p. Then either p∈Biand therefore p∈Ei∩Bi, or\np∈Bi+1\\Biimplying that Belady has loaded pduringWi.\n•p /∈Ei∩Ei+1implying q=β−1(p)∈Ei\\Ei+1. By Observation 3.2, q∈E−\ni, i.e., it\nmust have been requested during Wi. Ifq∈Bithen,q∈Ei∩Bi. Otherwise, Belady\nmust have loaded qduringWi.\nTo sum up: βis an injective map and β−1(p)does not exist for at most ci+1−cipagesp∈\nEi+1∩Bi+1. All other p∈Ei+1∩Bi+1are mapped by β−1to a unique page either belonging to\nEi∩Bior loaded by Belady duringWi.\nProof of Lemma 3.3. Robust freceives a prediction only at an arrival belonging to F. SinceF\ncontains/summationtextlogk+1\ni=1|F∩Wi| ≤/summationtextlogk\ni=1(f(i)−f(i−1)) +|Wlogk+1| ≤f(logk) + 1 arrivals,\nbecause|Wlogk+1|= 1andf(0) = 0 , there are at most f(logk)+1 queries to the predictor.\nTo prove equations (1,2,3), we always start with bounds prov ed in lemmas 3.5, 3.8 and 3.6. In the\nrest of the proof, we write Hinstead of HiandXinstead of Hito simplify the notation.\nTo get equation equation 2, note that rank(Wi)≤c(H)for each window i. Therefore, by lemmas\n3.5, 3.8 and 3.6, we can bound E[∆A(H)]by\n∆B(X)+3c(H)logk+3c(H)+6∆B(H)≤O(logk)∆B(X).\nTo get equation equation 3, note that ∆B(H)≤k,c(H)≤k, andrank(Wi)>0only ifηi≥\n|Ei+1∩Bi+1|>1. Therefore, we get ∆A(H)≤O(k)+η(H)O(k).\nNow we prove equation equation 1. We deﬁne Qm={i|rank(Wi)< m andrank(Wi+1)≥m}\nandQ=/summationtextk\nm=1|Qm|. We can bound Qusing Lemma 3.10. We have\nQ=k/summationdisplay\nm=1|Qm|=logk/summationdisplay\ni=1max{0,rank(Wi)−rank(Wi−1)} ≤logk/summationdisplay\ni=1(2∆B(Wi)+ci+1−ci),(5)\nwhich is equal to 2∆B(H)+c(H).\nWe bound/summationtextlogk\nj=1rank(Wj)as a function of Qandη(H)\nlogk/summationdisplay\ni=1rank(Wi)≤2Q·f−1(aη(H)\nQ). (6)\nThis relation is proved in Proposition 3.11 with a= 1 and, together with equation 5, gives us the\ndesired bound\nE[∆A(H)]≤O(1)∆B(H)f−1(aη(H)\nQ). (7)\nProposition 3.11.\nlogk/summationdisplay\ni=1rank(Wi)≤2Q·f−1(η(H)\nQ).\n11\n\nPublished as a conference paper at ICLR 2024\nProof. We rearrange the sum of ranks in the following way. We deﬁne Lm={i|rank(Wi)≥m},\nandai,m, such that Lm=/uniontext\ni∈Qm(i,i+ai,m]for eachm. We can write\nlogk/summationdisplay\ni=1rank(Wi) =k/summationdisplay\nm=1|Lm|=k/summationdisplay\nm=1/summationdisplay\ni∈Qmai,m. (8)\nOn the other hand, we can write ηi≥/summationtextrank(Wi)\nm=1|F∩Wi|(Lemma 3.9) which allows us to decom-\npose the total prediction error η(H)as follows:\nη(H)≥k/summationdisplay\nm=1/summationdisplay\ni∈Lm|F∩Wi|=k/summationdisplay\nm=1/summationdisplay\ni∈Qmai,m/summationdisplay\nj=1|F∩Wi+j|.\nLeti∗denote the ﬁrst window such that |Wi∗|< f(i∗)−f(i∗−1). Ifi+ai,m< i∗, then/summationtextai,m\nj=1|F∩Wi+j|=f(i+ai,m)−f(i)≥f(ai,m)by convexity of f. If this is not the case, we\nclaim that/summationtextai,m\nj=1|F∩Wi+j| ≥f(ai,m/2). This is clearly true if i+⌈ai,m/2⌉< i∗. Otherwise, we\nhave/summationtextai,m\nj=1|F∩Wi+j| ≥/summationtextai,m\nj=⌈ai,m/2⌉|F∩Wi+j| ≥2ai,m/2becausei+ai,m≤kand therefore\n|Wi+⌈ai,m/2⌉| ≥2ai,m/2. By our assumptions about f, we have f(ai,m/2)≤2ai,m/2.\nSo, we have the following lower bound on η(H):\nη(H)≥k/summationdisplay\nm=1/summationdisplay\ni∈Qmf(ai,m/2). (9)\nBy convexity of f, this lower bound is smallest if all am\niare the same, i.e., equal to the total rank\ndivided by Q=/summationtext\nm|Qm|and thenf(ai,m/2) =η(H)/Qfor eachiandm. Combining equation 8\nand equation 9, we get\nlogk/summationdisplay\ni=1rank(Wi)\n2=k/summationdisplay\nm=1/summationdisplay\ni∈Qmf−1/parenleftbig\nf/parenleftbigai,m\n2/parenrightbig/parenrightbig\n≤Q·f−1/parenleftbigη(H)\nQ/parenrightbig\n.\n4 W ELL-SEPARATED QUERIES TO THE PREDICTOR\n4.1 MTS\nWe consider the setting when we are able to receive a predicti on once every atime steps, for some\nparameter a∈N. Without loss of generality, we assume that Tis a multiple of a. In time steps\nia, wherei= 1,...,T/a , we receive a prediction pi∈M. Statepiitself might be very bad, e.g.\nℓia(pi)might be inﬁnite. We use work functions to see whether there i s a more suitable point nearby\npi.\nWork functions. Consider an MTS on a metric space Mwith a starting state x0∈Mand a\nsequence of cost functions ℓ1,...,ℓ T. For each time step t= 1,...,T and state x∈M, we deﬁne\nawork function as\nwt(x) = min/braceleftbig\nd(yt,x)+t/summationdisplay\ni=1d(yi−1,yi)+ℓi(yi)/bracerightbig\n,\nwhere the minimum is taken over all y0,...,y tsuch that y0=x0. In other words, it is the cheapest\nway to serve all the cost functions up to time tand end in state x. Work function is a major tool for\ndesign of algorithms for MTS and satisﬁes the following prop erty.\nObservation 4.1. For anyx,y∈Mand any time t, we have wt(x)≤wt(y)+d(y,x).\nThis holds because one way to serve the cost functions ℓ1,...,ℓ tis to follow the best solution which\nends in state yand then move to x. Ifwt(pi) =wt(y) +d(y,pi), we can see that piis not a very\ngood state, since the best solution ending in pigoes viay. We say that piissupported byy.\n12\n\nPublished as a conference paper at ICLR 2024\nAlgorithm 3: One cycle of algorithm by Emek et al. (2009)\n1qi:=reported state of OFF at timeia;\n2j:= 0,c:= 0;\n3fort=ia+1,...,(i+1)ado\n4x′\nt:= argmin x∈B(qi,2j){d(x,xt−1)+ℓt(x)};\n5 whilec+d(x,x′\nt)+ℓt(x′\nt)>2jdo\n6 j:= 2∗j;\n7 x′\nt:= argmin x∈B(qi,2j){d(x,xt−1)+ℓt(x)};\n8xt:=x′\nt,c:=c+d(x,xt)+ℓt(xt);\nAlgorithm of Emek et al. (2009). Algorithm 3 was proposed by Emek et al. (2009) in the context\nof advice complexity. It receives the state of an ofﬂine opti mum algorithm every atime steps.\n4.2 A LGORITHM FTSP\nGivenqi−1andℓtfort= (i−1)a+1,...,ia , we deﬁne\nwfi(x) = min/braceleftbigg\nd(xia,x)+iα/summationdisplay\nj=(i−1)a+1d(xj−1,xj)+ℓj(xj)/bracerightbigg\n,\nwhere the minimum is taken over x(i−1)α,...xiα∈Msuch that x(i−1)a=qi−1. In fact, it is\nthe work function at the end of an MTS instance with initial st ateqi−1and request sequence ℓtfor\nt= (i−1)a+1,...,ia . Instead of pi, we choose point\nqi= argmin\nx∈M/braceleftbigg\nwfi(x)/vextendsingle/vextendsingle/vextendsingle/vextendsinglewfi(x) = wf i(pi)−d(x,pi)/bracerightbigg\n,\ni.e., the \"cheapest\" state supporting piinwfi. After computing qi, we run one cycle of Algorithm 3.\nThis algorithm which we call “Follow the Scarce Predictions ” (FtSP), is summarized in Algorithm 4.\nAlgorithm 4: FtSP\n1fori= 0,...,T/a do\n2 receive prediction pi;\n3 usepito compute qi;\n4 run one cycle of Algorithm 3 starting at qi;\nLetQdenote the best (ofﬂine) algorithm which is located at qiat time step iafor each i=\n1,...,T/a . We have\ncost(Q) =T/a/summationdisplay\ni=1wfi(qi).\nWe can relate the cost of Qto the prediction error using the following lemma. Together with Propo-\nsition 2.5, it gives a bound\ncost(ALG) ≤O(a)(OFF+2 η),\nimplying Theorem 1.3.\nLemma 4.2. LetOFF be an arbitrary ofﬂine algorithm and oidenote its state at time iafori=\n1,...,T/a . If Q was computed from predictions p1,...,p T/a, we have\ncost(Q)≤OFF+2η,\nwhereη=/summationtextT/a\ni=1d(pi,oi)is the prediction error with respect to OFF .\nProof. DenoteAian algorithm which follows the steps of Quntil time iaand then follows the steps\nofOFF . We have\ncost(Ai)≤cost(Ai−1)+wf i(qi)−wfi(oi)+d(qi,oi)\n13\n\nPublished as a conference paper at ICLR 2024\nbecause both AiandAi−1are atqi−1at time(i−1)a, andAi−1then travels to oipayingwfi(oi)\nwhileAitravels to qiatiapayingwfi(qi)and its costs after iawill be by at most d(qi,oi)larger\nthan the costs of Ai−1.\nBy Observation 4.1 and the choice of qi, we have\nwfi(oi)≥wfi(pi)−d(oi,pi) = wf i(qi)+d(qi,pi)−d(oi,pi).\nCombining the two preceding inequalities, we get\ncost(Ai)≤cost(Ai−1)+wf i(qi)−wfi(qi)\n+d(oi,pi)−d(pi,qi)+d(qi,oi)\n≤cost(Ai−1)+2d(oi,pi),\nwhere the last step follows from the triangle inequality.\nSinceOFF =A0andQ=AT/a, we have\nQ≤OFF+2T/a/summationdisplay\ni=1d(oi,pi) = OFF+2 η.\n4.3 C ACHING\nFollower cannot maintain 1-consistency in this setting. For the sake of theoretical bound, we can\ndo the following: We serve the whole input sequence by subseq uent phases of Robust fwhich is\nO(1)-consistent with Fchosen in such a way that the arrivals in Fare separated by at least a. We\nprove the following replacement of Proposition 3.11.\nProposition 4.3.\nlogk/summationdisplay\ni=1rank(Wi)≤2Q·f−1/parenleftbiggaη(H)\nQ/parenrightbigg\n.\nProof. We rearrange the sum of ranks in the following way. We deﬁne Lm={i|rank(Wi)≥m},\nQm={i|rank(Wi)< m andrank(Wi+1)≥m}, andai,m, such that Lm=/uniontext\ni∈Qm(i,i+ai,m]\nfor eachm. We can write\nlogk/summationdisplay\ni=1rank(Wi) =k/summationdisplay\nm=1|Lm|=k/summationdisplay\nm=1/summationdisplay\ni∈Qmai,m. (10)\nOn the other hand, we can write ηi≥/summationtextrank(Wi)\nm=1|F∩Wi|(Lemma 3.9) which allows us to decom-\npose the total prediction error η(H)as follows:\nη(H)≥k/summationdisplay\nm=1/summationdisplay\ni∈Lm|F∩Wi|=k/summationdisplay\nm=1/summationdisplay\ni∈Qmai,m/summationdisplay\nj=1|F∩Wi+j|.\nLeti∗denote the ﬁrst window such that|Wi∗|\na< f(i∗)−f(i∗−1). Ifi+ai,m< i∗, then/summationtextai,m\nj=1|F∩Wi+j|=f(i+ai,m)−f(i)≥f(ai,m)by convexity of f. If this is not the case, we\nclaim that/summationtextai,m\nj=1|F∩Wi+j| ≥a−1f(ai,m/2).\n• Ifi+⌈ai,m/2⌉< i∗: we have\nai,m/summationdisplay\nj=1|F∩Wi+j| ≥⌈ai,m/2⌉/summationdisplay\nj=1|F∩Wi+j| ≥f(ai,m/2).\n• Otherwise: we have\nai,m/summationdisplay\nj=1|F∩Wi+j| ≥ai,m/summationdisplay\nj=⌈ai,m/2⌉|F∩Wi+j| ≥ai,m/summationdisplay\nj=⌈ai,m/2⌉1\na|Wi+j| ≥1\na2ai,m/2≥a−1f(ai,m/2)\nBy our assumptions about fsaying that f(ai,m/2)≤2ai,m/2.\n14\n\nPublished as a conference paper at ICLR 2024\nSo, we have the following lower bound on η(H):\naη(H)≥k/summationdisplay\nm=1/summationdisplay\ni∈Qmf(ai,m/2). (11)\nBy convexity of f, this lower bound is smallest if all am\niare the same, i.e., equal to aη(H)divided\nbyQ=/summationtext\nm|Qm|and thenf(ai,m/2) =aη(H)/Qfor eachiandm. Combining equation 10 and\nequation 11, we get\nlogk/summationdisplay\ni=1rank(Wi)\n2=k/summationdisplay\nm=1/summationdisplay\ni∈Qmf−1/parenleftbig\nf/parenleftbigai,m\n2/parenrightbig/parenrightbig\n≤Q·f−1/parenleftbigaη(H)\nQ/parenrightbig\nUsing the proposition above in Equation equation 6 in the pro of of Lemma 3.3 gives us the following\nsmoothness bound:\nLemma 4.4. DenoteXi=Hi−1∪H−\ni∪Hi. During the phase Hi,Robust freceiving at most one\nprediction in atime steps incurs the cost\nE[∆A(Hi)]≤O(1)f−1/parenleftbiggaη(Hi)\n∆B(Xi)/parenrightbigg\n∆B(Xi).\nTheorem 1.5 follows from summation of the bound above over al l phases of Robust and concavity\noff−1, as in proof of Theorem 1.1.\n5 E XPERIMENTS\nWe perform an empirical evaluation of our caching algorithm F&R on the same datasets and with\nthe same predictors as the previous works (Lykouris and Vass ilvitskii, 2021; Antoniadis et al., 2023;\nIm et al., 2022). We use the following datasets.\n• BrightKite dataset (Cho et al., 2011) contains data from a c ertain social network. We create\na separate caching instance from the data of each user, inter preting check-in locations as\npages. We use it with cache size k= 10 and choose instances corresponding to the ﬁrst 100\nusers with the longest check-in sequences requiring at leas t 50 page faults in the optimal\npolicy.\n• CitiBike dataset contains data about bike trips in a bike sh aring platform CitiBike. We\ncreate a caching instance from each month in 2017, interpret ing starting stations of the\ntrips as pages, and trimming length of each instance to 25 000 . We use it with cache size\nk= 100 .\nSome of the algorithms in our comparison use next-arrival pr edictions while F&R uses action pre-\ndictions that can be generated from next-arrival predictio ns. Therefore, we use predictors which\npredict the next arrival of the requested page and convert it to action predictions. This process was\nused and described by Antoniadis et al. (2023) and we use thei r implementation of the predictors.\nOur algorithm is then provided limited access to the resulti ng action predictions while the algorithm\nof Im et al. (2022) has limited access to the original next-ar rival predictions.\n• Synthetic predictions: compute the exact next arrival tim e computed from the data and\nadd noise to this number. This noise comes from a log-normal d istribution with the mean\nparameter µ= 0and the standard deviation parameter σ. We useσ∈[0,50].\n• PLECO predictor proposed by Anderson et al. (2014): This mo del estimates the probability\npof a page being requested in the next time step and we interpre t this as a prediction that\nthe next arrival of this page will be in 1/ptime steps. The model parameters were ﬁtted to\nBrightKite dataset and not adjusted before use on CitiBike.\n• POPU – a simple predictor used by Antoniadis et al. (2023): i f a page appeared in pfraction\nof the previous requests, we predict its next arrival in 1/ptime steps.\n15\n\nPublished as a conference paper at ICLR 2024\n0 10 20 30 40 50\nNoise parameter σof the synthetic predictor1.01.11.21.3Competitive ratioLRU\nMarker\nFtP\nAQ_b2\nFtPM\nT&D\nF&R\nFigure 1: BrightKite dataset with Synthetic predictor: com petitive ratio\nIn our comparison, we include the following algorithms: ofﬂ ine algorithm Belady which\nwe use to compute the optimal number of page faults OPT, stand ard online algorithms LRU\nand Marker (Fiat et al., 1991), ML-augmented algorithms usi ng next arrival predictions L&V\n(Lykouris and Vassilvitskii, 2021), LMark and LnonMark (Ro hatgi, 2020), FtPM which, at each\nstep, evicts an unmarked page with the furthest predicted ne xt arrival time, and algorithms for action\npredictions FtP and T&D (Antoniadis et al., 2023). We use the implementation of all these algo-\nrithms published by Antoniadis et al. (2023). We implement a lgorithm AQ (Im et al., 2022) and our\nalgorithm F&R .\nNotes on implementation of F&R .We follow the recommendations in Section 3 except that\nFollower switches to Robust whenever its cost is α= 1 times higher compared to Belady in the\nsame period. With higher α, the performance of F&R approaches FtP on the considered datasets.\nWithk= 10 (BrightKite dataset), we use F= [1,6,9]corresponding to f(i) =i. Note that,\nwith such small k, polynomial and exponential fwould also give a very similar F. Withk= 100\n(CitiBike dataset), we use exponential f(i) = 2i+1−1. Witha-separated queries, Follower uses\nLRU heuristic when prediction is unavailable, and Robust ignoresF, querying the predictor at each\npage fault separated from the previous query by at least atime steps.\nResults. Figures 1 and 3 contain averages of 10 independent experimen ts. Figure 1 shows that\nthe performance of F&R with high-quality predictions is superior to the previous M L-augmented\nalgorithms except for FtP which follows the predictions bli ndly and is also 1-consistent. With high\nσ, the performance of T&D becomes better. This is true also for F&R withF= [1..10], suggesting\nthat T&D might be more efﬁcient in using erroneous predictio ns. Figure 2 shows the total number\nof times algorithms query the predictor over all instances. Response to such query is a single page\nmissing from predictor’s cache in the case of F&R and T&D and next arrival times of bpages in\nthe case of AQ_ b. Note that FtPM is equivalent to the non-parsimonious versi on of AQ with b=k.\nF&R makes the smallest number of queries: with perfect predicti ons, it makes exactly OPT queries\nand this number decreases with higher σasF&R spends more time in Robust .\nFigure 3 shows that F&R performs well in regime with a-separated queries. While the performance\nof FtPM with POPU predictor worsens considerably towards Ma rker already with a= 5, the perfor-\nmance of F&R worsens only very slowly. On CitiBike dataset, it keeps its i mprovement over Marker\neven with a= 20 (note that we use k= 100 with this dataset). Predictions produced by PLECO\nseem much less precise as suggested by FtP with PLECO being wo rse than Marker and smaller\nnumber of such predictions either improves (AQ, FtPM) or doe s not affect performance ( F&R ) of\nconsidered algorithms.\n16\n\nPublished as a conference paper at ICLR 2024\n0 10 20 30 40 50\nNoise parameter σof the synthetic predictor2500030000350004000045000Number of queries to the predictorFtP\nFtPM\nAQ_b2\nT&D\nF&R\nFigure 2: BrightKite dataset with Synthetic predictor: num ber of used predictors\nDataset Predictor Marker F&R_a1 F&R_a2 F&R_a3 F&R_a5 F&R_a 8 F&R_a20\nCitiBike POPU 1.862 1.800 1.802 1.802 1.802 1.803 1.803\nCitiBike PLECO 1.862 1.878 1.878 1.878 1.879 1.879 1.879\nBrightKite POPU 1.333 1.320 1.328 1.332 1.336 1.337 1.341\nBrightKite PLECO 1.333 1.371 1.374 1.376 1.377 1.378 1.378\nDataset Predictor T&D FtP FtPM_a1 FtPM_a5 AQ_b8 L&V LMark Ln onMark\nCitiBike POPU 1.776 1.739 1.776 1.833 1.782 1.776 1.780 1.77 1\nCitiBike PLECO 1.847 2.277 1.877 1.866 1.875 1.877 1.876 1.8 63\nBrightKite POPU 1.276 1.707 1.262 1.306 1.263 1.262 1.264 1. 266\nBrightKite PLECO 1.292 2.081 1.341 1.337 1.342 1.340 1.337 1 .333\nFigure 3: Competitive ratios with predictors POPU and PLECO\n17\n\nPublished as a conference paper at ICLR 2024\n0 10 20 30 40 50\nNoise parameter σof the synthetic predictor1.01.11.21.3Competitive ratioLRU\nMarker\nFtP\nL&V\nLnonMark\nF&R\nFigure 4: BrightKite dataset with Synthetic predictor: com petitive ratio\n0 10 20 30 40 50\nNoise parameter σof the synthetic predictor2500030000350004000045000Number of queries to the predictorFtP\nL&V\nLnonMark\nF&R\nFigure 5: BrightKite dataset with Synthetic predictor: num ber of used predictions\n18\n\nPublished as a conference paper at ICLR 2024\n0 10 20 30 40 50\nNoise parameter σof the synthetic predictor1.001.051.101.151.201.251.30Competitive ratioLRU\nMarker\nFtP\nT&D\nF&R_a1\nF&R_a2\nF&R_a3\nF&R_a5\nFigure 6: BrightKite dataset with Synthetic predictor: com petitive ratio\nFigures 4 and 5 complements the comparison of F&R to existing ML-augmented algorithms for\npaging by including those omitted in Figure 1. With smaller σ, it again demonstrates the better\nconsistency of F&R . With higher σ,F&R achieves performance comparable to both L&V and\nLnonMark, while using a smaller number of predictions. We ha ve decided not to include LMark\nbecause its performance as well as number of predictions use d were almost the same as of LnonMark.\nNote that, in the case of both algorithms, the number of used p redictions is equal to the number of\nclean arrivals and therefore it does not change with the pred iction error.\nFigures 6 and 7 shows performance of F&R in regime with a-separated queries for different values\nofa. It shows a signiﬁcant loss of consistency already with a= 2 compared to a= 1. However,\nwith higher noise parameter σ, the difference in performance does not seem large. In this r egime, the\nfocus is on the gap between predictor queries rather than the total number of queries: F&R queries\na predictor at each page fault separated from previous query by at least atime steps. However, we\ndecided to include also the plot of the total number of querie s (Figure 7) because it shows that with\nσ >20,F&R witha= 1 uses a smaller number of predictions than with a= 2 and even a= 3,\nwhile maintaining a better performance. This suggests that the freedom to choose the right moment\nfor a query might be more important for the performance than t he total number of used predictions.\nFigure 8 shows experiments with a probabilistic predictor o n the BrightKite dataset. In this setting,\nwe consider a predictor that evicts the page requested furth est in the future with a given probability\n1−p. On the other hand, it evicts a random page with probability p. The horizontal axis corresponds\nto the probability p. We can observe that better consistency of our algorithm com pared to T&D is\nvisible for pup to0.4.\nEach plot and table contains averages of 10 independent expe riments. We have seen standard devia-\ntions at most 0.004 in the case of ﬁgures 1, 4, 6; 0.0015 for Fig ure 3 on CitiBike dataset and 0.0025\non BrightKite dataset, and 300 for ﬁgures 2, 5, 7, counting nu mbers of used predictions.\n6 C ONCLUSIONS\nWe present algorithms for MTS and caching with action predic tions working in the setting where the\nnumber of queries or the frequency of querying the predictor are limited. We have shown that one\ncan achieve theoretical as well as empirical performance co mparable to the setting with unlimited\n19\n\nPublished as a conference paper at ICLR 2024\n0 10 20 30 40 50\nNoise parameter σof the synthetic predictor15000200002500030000350004000045000Number of queries to the predictorFtP\nT&D\nF&R_a1\nF&R_a2\nF&R_a3\nF&R_a5\nFigure 7: BrightKite dataset with Synthetic predictor: num ber of used predictions\n0.0 0.2 0.4 0.6 0.8 1.0\nProbability Error1.01.11.21.31.4Competitive ratio\nLRU\nMarker\nFtP\nT&D\nF&R\nFigure 8: BrightKite dataset with probabilistic predictor : competitive ratio\n20\n\nPublished as a conference paper at ICLR 2024\naccess to the predictor, possibly enabling usage of precise but heavy-weight prediction models in\nenvironments with scarce computational resources.\n7 L OWER BOUNDS\n7.1 C ACHING\nProof of the following proposition can be found in (Borodin a nd El-Yaniv, 1998, Theorem 4.4).\nProposition 7.1 ((Fiat et al., 1991)) .For any randomized algorithm ALG for caching there is an\ninput instance on universe of k+1pages such that the expected cost of ALG is more than lnktimes\nthe cost of the ofﬂine optimal solution.\nFor a given algorithm, it constructs an instance consisting of marking phases, each with a single\nclean page such that the optimal algorithm pays 1 and the onli ne algorithm pays at least lnk.\nImagine an algorithm receiving at most 0.5OPT predictions during this instance. Then, there must\nbe at least 0.5OPT phases during which the algorithm receives no prediction. I ts cost is at least lnk\nin each such phase, giving total cost 0.5OPTln k.\nTheorem 1.2 is implied by the following more general stateme nt withc= 1andd= 0.\nTheorem 7.2. Letc≥1andd≥0be constants. Any (cf−1(η)+d)-smooth algorithm for caching\nwith action predictions has to use at least f(c−1lnk−d)OPT predictions.\nProof. Consider a ﬁxed algorithm accepting action predictions. Ch ooseTlong enough, an arbitrary\nprediction for each time step t= 1,...,T , and give them to the algorithm at time 0. Having the\npredictions already, this algorithm becomes a standard ran domized algorithm which does not use any\nfurther predictions. We use Proposition 7.1 to generate an i nstance such that E[ALG]≥OPTlnk,\nwhereALG denotes the cost of the algorithm with predictions generate d in advance. It is clear\nthat these predictions, generated before the adversary has chosen the input instance, are useless, not\nhelping the algorithm to surpass the worst-case bounds. How ever, since the universe of pages has\nsize only k+1, each of the predictions can differ from an optimal algorith m by at most one page.\nIf we want to haveE[ALG]\nOPT≤cf−1(η\nOPT)+d, then we need\nη\nOPT≥f/parenleftbiggE[ALG]\ncOPT−d/parenrightbigg\n> f/parenleftbigglnk\nc−d/parenrightbigg\n.\nSince every prediction has error at most 1, we need to receive at leastη≥f(c−1lnk−d)OPT\npredictions.\n7.2 MTS\nAntoniadis et al. (2023) showed the following lower bound on smoothness of algorithms for general\nMTS with action predictions.\nProposition 7.3 (Antoniadis et al. (2023)) .Forη≥0andn∈N, every deterministic (or random-\nized) online algorithm for MTS on the n-point uniform metric with access to an action prediction\noracle with error at least ηwith respect to some optimal ofﬂine algorithm has competiti ve ratio\nΩ/parenleftbig\nmin/braceleftbig\nαn,1+η\nOPT/bracerightbig/parenrightbig\n, whereαn= Θ(n)(orαn= Θ(logn)) is the optimal competitive ratio of\ndeterministic (or randomized) algorithms without predict ion.\nWe use this proposition to prove the following theorem from w hich Theorem 1.4 directly follows.\nTheorem 7.4. Forη≥0andn∈N, every deterministic (or randomized) online algorithm for\nMTS on the n-point uniform metric with access to an action prediction or acle at most once in a\ntime steps with error at least ηwith respect to some optimal ofﬂine algorithm has competiti ve ratio\nΩ/parenleftbig\nmin/braceleftbig\nαn,1+aη\nOPT/bracerightbig/parenrightbig\n, whereαn= Θ(n)(orαn= Θ(logn)) is the optimal competitive ratio of\ndeterministic (or randomized) algorithms without predict ion.\nProof. We extend the (n−1)-point uniform metric from the proposition above by a single pointp∞\nwhose cost will be +∞at each time step, ensuring the optimal algorithm will never be located there.\n21\n\nPublished as a conference paper at ICLR 2024\nConsider a ﬁxed algorithm and a predictor producing at most o ne prediction in atime steps with the\ntotal prediction error η. By issuing prediction p∞in all missing time steps, we complete predictions\nfor each time step with error at least η′≥aη.\nBy proposition above, the algorithm with completed predict ions has competitive ratio at least\nΩ/parenleftbigg\nmin/braceleftbig\nαn−1,1+η′\nOPT/bracerightbig/parenrightbigg\n≥Ω/parenleftbigg\nmin/braceleftbig\nαn,1+aη\nOPT/bracerightbig/parenrightbigg\n,\nsinceαnandαn−1differ by at most a constant factor.\n8 F ITFORACLE\nIn this section we work with a predictor which tells us which p age in our current cache will be\nrequested furthest in the future, we call it a FitF page. Note that this is not the same as the predictions\nconsidered in Section 3, where we receive a page not present i nBelady ’s cache. Belady evicts a\nFitF page from its current cache content which may be differe nt from the FitF page from the current\ncache content of our algorithm. Prediction error is the tota l number of times the predictor reports an\nincorrect FitF page.\nWe split our algorithm into Follower andRobust part. The Follower (Algorithm 5), checks at each\npage fault whether Belady starting at the same time with the same cache content also has a page\nfault. If yes, it evicts a page reported by the predictor. Oth erwise, it switches to the Robust part\n(Algorithm 6).\nAlgorithm 5: Follower with FitF oracle\n1P:=starting cache content;\n2foreach pagefault do\n3 Compute Belady for the sequence from the beginning of this execution starti ng withP;\n4 ifBelady has page fault as well then\n5 p:=page in the current cache chosen by the predictor;\n6 evictp;\n7 else\n8 Run one phase of Algorithm 6 starting with the current cache c ontent;\nLemma 8.1. Consider one execution of Algorithm 5, denoting σthe request subsequence and ϕthe\nnumber of incorrect predictions received during this execu tion. Algorithm 5 pays the same cost as\nBelady servingσand starting with cache content P. There is a tie-breaking rule for Belady such\nthat the cache contents of both algorithms after processing σdiffer in at most ϕpages.\nProof. Whenever the algorithm has a page fault and Belady not, the execution of Algorithm 5\nterminates. Therefore, both algorithms have the same cost d uring the execution.\nDenoteAandBthe cache contents of our algorithm and Belady respectively. We choose the\nfollowing tie-breaking rule for Belady : whenever the algorithm evicts p∈A∩Bwhich is no more\nrequested in σ,Belady evictspas well. The size of A\\Bincreases only when the algorithm evicts\na predicted page p∈A∩BandBelady evicts a different page q∈A∩B. This can happen only if\nthe next request of pcomes earlier than qby the tie-breaking rule above. Since p,q∈A, the oracle\nmade a prediction error.\nRobust part (Algorithm 6) uses a parameter bwhich controls the number of predictions used during\nits execution. It runs for a duration of a single marking phas e split into logkwindows, as in Section 3,\nmaking sure that the number of predictions received in each w indow is at most the number of clean\npages received so far. Evictions of random unmarked pages ar e used at page faults with no available\nprediction. At the end, it loads all marked pages. This is to e nsure that the difference between the\noptimal and algorithm’s cache content can be bounded by the c ost of the optimal algorithm during\nthe phase (using Observation 2.2) instead of accumulating o ver repeated executions of Follower and\nRobust .\n22\n\nPublished as a conference paper at ICLR 2024\nAlgorithm 6: Robust with FitF oracle\n1P:=starting cache content;\n2S:= [t=k−2j+1|forj= logk,...,0];\n3Wi:= [S[i],S[i+1]−1]fori= 1,...,logk+1;// Split the phase into\nwindows\n4foreach pagefault at time tduring the phase do\n5ct:=number of clean pages which arrived so far;\n6 ifnumber of received predictions in the phase is less than bctthen\n7 ifnumber of received predictions in this window is less than ctthen\n8 p:=page in the current cache chosen by the predictor;\n9 evictp;\n10 else\n11 evict a random unmarked page;\n12Once phase has ended, load all marked pages to the cache and ru n Algorithm 5;\nLemma 8.2. Consider one execution of Algorithm 6 during which it receiv esϕincorrect predictions.\nThe expected cost incurred by Algorithm 6 is at most 2∆B+3ϕ(1+b−1logk), where∆Bdenotes\nthe cost incurred by Belady starting at the same time with the same cache content.\nProof. There are three kind of page faults:\n1. evicted page is chosen by the predictor\n2. requested page was chosen before by the predictor, evicte d page was chosen at random\n3. both evicted and requested pages were chosen at random\nIn the worst case, we can assume that once we run out of budget f or predictions, all incorrectly\nevicted pages are requested in page faults of type 2 and retur ned to the cache. Now, let gdenote\nthe number of pages evicted due to correct predictions – they are not going to be requested in this\nphase anymore (Observation 2.3). All other evicted pages ar e chosen uniformly at random among\nunmarked pages which were not evicted due to correct predict ions. So, until another batch of page\nfaults of type 1, we have only page faults on arrivals and the p robability of a page fault on arrival a\nis at most\nca−g\nk−(a−ct)−g,\nwherecais the number of clean pages until arrival aandk−(a−ct)is the number of unmarked\npages, at most gof them were evicted due to correct predictions.\nWe count the number of page faults in window ifori= 1,...,logk+1. We denote mithe number\nof page faults of type 1 and resulting into eviction of gicorrectly predicted pages. Then, by our\nassumption, we have mi−gipage faults of type 2. The expected number of page faults of ty pe 3\ndepends on when do types 1 and 2 happen. In the worst case, they all happen in the beginning of Wi\nas well as all arrivals of clean pages. We consider three case s.\nCase A. Prediction budget was not depleted, there were only evictio ns of type 1.\n∆A(Wi) =mi=ϕi+gi.\nCase B. There were mi=ci+1predictions during Wiand we have ϕi=ci+1−gi. After page\nfaults of type 2, there are at most ci+1−girandomly chosen unmarked pages evicted. Therefore,\n23\n\nPublished as a conference paper at ICLR 2024\nthe expected number of page faults of type 3 is at most\n/summationdisplay\na∈Wici+1−ga\nk−(a−ci+1)−ga≤/summationdisplay\na∈Wici+1−gi\nk−(a−ci+1)−gi\n≤/summationdisplay\na∈Wici+1−gi\nk−a≤k\n2i·ci+1−gi\nk/2i=ci+1−gi.\nTherefore, counting evictions of types 1, 2, and 3, we have\n∆A(Wi)≤(ϕi+gi)+ϕi+(ci+1−gi)≤gi+3ϕi.\nCase C. There were bci+1predictions since the beginning of the phase. We have mi≤ci+1and\nci+1−gi≤1\nb(bci+1−gi)≤1\nbϕwhereϕis the total number of incorrect predictions received since\nthe beginning of the phase. We have\n∆A(Wi)≤ci+1+(ci+1−gi)+(ci+1−gi)≤gi+3(ci+1−gi),\nwhich is at most gi+3ϕ/b.\nNow, the sum of costs over all the windows is at most\n/summationdisplay\nigi+/summationdisplay\ni3ϕi+/summationdisplay\ni3ϕ/b+c≤2c+3ϕ+3ϕ\nblogk,\nwherec=/summationtext\nici≤∆B, because we consider Belady starting with the same cache content as the\nalgorithm which does not contain the clean pages.\nTheorem 8.3. Letb∈ {1,...,logk}be a parameter. During a request sequence with optimum\ncostOPT , our algorithm receives at most O(b)OPT predictions and its expected cost is always\nbounded by O(logk)OPT . If onlyϕpredictions are incorrect, its expected cost is at most\n/parenleftbigg\n2+ϕ\nOPT(4+3b−1logk)/parenrightbigg\nOPT.\nMoreover, if ϕ= 0, its cost is equal to OPT .\nProof. We split the time horizon into intervals corresponding to ex ecutions of Follower andRobust .\nFor each interval i, we denote ϕithe number of received incorrect predictions, ∆B\nithe cost incurred\nbyBelady started with the same content as our algorithm and ∆O\nithe cost incurred by the optimal\nsolution during interval i. We denote Fthe set of intervals during which Follower was executed and\nRthe set of intervals during which Robust was executed. We also deﬁne 0∈Ran empty interval\nin the beginning of the request sequence with ∆O\n0= ∆B\n0= 0.\nIn order to prove bounds on robustness and number of used pred ictions, we provide relations be-\ntween∆B\niand∆O\niindependent of ϕ. For each i∈F, we have i−1∈R. Interval i−1is a marking\nphase and Robust has all marked pages in the cache at the end (Lemma 8.2). By Obs ervation 2.2,\nthe starting cache content of Follower in interval idiffers from optimal cache in at most ∆O\ni−1pages.\nTherefore, we have\n∆B\ni≤∆O\ni+∆O\ni−1∀i∈F. (12)\nFor eachi∈R, we have i−1∈Fandi−2∈R. By Observation 2.4, the difference between the\ncache ofFollower and optimum increases during interval i−1by at most ∆O\ni−1. Since the starting\ncache ofFollower in interval i−1differs from optimal in ∆O\ni−2pages, the starting cache of Robust\nin interval idiffers from optimum by at most ∆O\ni−2+∆O\ni−1. Therefore, we have\n∆B\ni≤∆O\ni+∆O\ni−1+∆O\ni−2∀i∈R. (13)\nUsing equations equation 12 and equation 13, we can bound the number of used predictions as\n/summationdisplay\ni∈F∆B\ni+/summationdisplay\ni∈Rb∆B\ni≤3bOPT.\n24\n\nPublished as a conference paper at ICLR 2024\nSinceϕ≤∆B\ni, fori∈F, andϕi≤b∆B\nifori∈R, we have the following robustness bound:\nALG≤/summationdisplay\ni∈F∆B\ni+/summationdisplay\ni∈R/parenleftbig\n∆B\ni+ϕi(3+3b−1logk)/parenrightbig\n≤/summationdisplay\ni∈F∆B\ni+/summationdisplay\ni∈R∆B\ni(1+b)(3+3b−1logk)\n≤OPT·O(logk),\nwhere the last inequality follows from equation 12, equatio n 13, and b≤logk.\nNow, we analyze smoothness. We can bound ∆B\ni−∆O\niby the difference between optimal and\nalgorithm’s cache in the beginning of the interval i. This is at most ϕi−1for eachi∈R(Lemma 8.1)\nand at most ∆O\ni−1for eachi∈Fby equation 12. Lemmas 8.1 and 8.2 imply\nALG≤/summationdisplay\ni∈F∆B\ni+/summationdisplay\ni∈R/parenleftbig\n2∆B\ni+ϕi(3+3b−1logk)/parenrightbig\n≤/summationdisplay\ni∈F(∆O\ni+∆O\ni−1)+/summationdisplay\ni∈R/parenleftbig\n∆O\ni+ϕi−1+ϕi(3+3b−1logk)/parenrightbig\n≤2OPT+ ϕ(4+3b−1logk).\n1-consistency of our algorithm can be seen from the fact that e ach execution of Robust is triggered\nby an incorrect prediction. Therefore, with perfect predic tions, only Follower is used and behaves\nthe same as Belady .\nREFERENCES\n[1] A. Anderson, R. Kumar, A. Tomkins, and S. Vassilvitskii. The dynamics of repeat con-\nsumption. In Proceedings of conference World Wide Web ’14 , pages 419–430, 2014. doi:\n10.1145/2566486.2568018.\n[2] A. Antoniadis, T. Gouleakis, P. Kleer, and P. Kolev. Secr etary and online matching problems\nwith machine learned advice. In NeurIPS , 2020.\n[3] A. Antoniadis, C. Coester, M. Eliáš, A. Polak, and B. Simo n. Learning-augmented dynamic\npower management with multiple states via new ski rental bou nds. In NeurIPS , 2021.\n[4] A. Antoniadis, J. Boyar, M. Eliáš, L. M. Favrholdt, R. Hoe ksma, K. S. Larsen, A. Polak, and\nB. Simon. Paging with succinct predictions, 2022.\n[5] A. Antoniadis, P. J. Ganje, and G. Shahkarami. A novel pre diction setup for online speed-\nscaling. In SWAT , volume 227 of LIPIcs , pages 9:1–9:20. Schloss Dagstuhl - Leibniz-Zentrum\nfür Informatik, 2022.\n[6] A. Antoniadis, C. Coester, M. Eliáš, A. Polak, and B. Simo n. Online metric algorithms with\nuntrusted predictions. ACM Trans. Algorithms , 19(2), apr 2023. ISSN 1549-6325. doi: 10.\n1145/3582689. URL https://doi.org/10.1145/3582689 .\n[7] Y . Azar, S. Leonardi, and N. Touitou. Flow time schedulin g with uncertain process-\ning time. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theor y of\nComputing , STOC 2021, page 1070–1080, New York, NY , USA, 2021. Associa tion for\nComputing Machinery. ISBN 9781450380539. doi: 10.1145/34 06325.3451023. URL\nhttps://doi.org/10.1145/3406325.3451023 .\n[8] Y . Azar, S. Leonardi, and N. Touitou. Distortion-oblivi ous algorithms for minimizing ﬂow\ntime. In Proceedings of the 2022 ACM-SIAM Symposium on Discrete Algo rithms, SODA 2022,\nVirtual Conference / Alexandria, VA, USA, January 9 - 12, 202 2, pages 252–274. SIAM, 2022.\nURLhttps://doi.org/10.1137/1.9781611977073.13 .\n[9] É. Bamas, A. Maggiori, L. Rohwedder, and O. Svensson. Lea rning augmented energy mini-\nmization via speed scaling. In NeurIPS , 2020.\n25\n\nPublished as a conference paper at ICLR 2024\n[10] N. Bansal, C. Coester, R. Kumar, M. Purohit, and E. Vee. L earning-augmented weighted\npaging. In SODA , 2022.\n[11] Y . Bartal, B. Bollobás, and M. Mendel. Ramsey-type theo rems for metric spaces with applica-\ntions to online problems. J. Comput. Syst. Sci. , 72(5):890–921, 2006.\n[12] L. A. Belady. A study of replacement algorithms for virt ual-storage com-\nputer. IBM Syst. J. , 5(2):78–101, 1966. doi: 10.1147/sj.52.0078. URL\nhttps://doi.org/10.1147/sj.52.0078 .\n[13] G. Bernardini, A. Lindermayr, A. Marchetti-Spaccamel a, N. Megow, L. Stougie, and\nM. Sweering. A universal error measure for input prediction s applied to online graph\nproblems. CoRR , abs/2205.12850, 2022. doi: 10.48550/arXiv.2205.12850. URL\nhttps://doi.org/10.48550/arXiv.2205.12850 .\n[14] A. Blum and C. Burch. On-line learning and the metrical t ask system problem. Mach. Learn. ,\n39(1):35–58, 2000. doi: 10.1023/A:1007621832648.\n[15] H. Böckenhauer, D. Komm, R. Královi ˇc, R. Královi ˇc, and T. Mömke. Online algorithms with\nadvice: The tape model. Inf. Comput. , 254:59–83, 2017.\n[16] A. Borodin and R. El-Yaniv. Online computation and competitive analysis . Cambridge Uni-\nversity Press, 1998. ISBN 978-0-521-56392-5.\n[17] A. Borodin, N. Linial, and M. E. Saks. An optimal on-line algorithm for metrical task system.\nJ. ACM , 39(4):745–763, 1992. doi: 10.1145/146585.146588.\n[18] J. Boyar, L. M. Favrholdt, C. Kudahl, K. S. Larsen, and J. W. Mikkelsen. Online Algorithms\nwith Advice: A Survey. ACM Computing Surveys , 50(2):1–34, 2017. Article No. 19.\n[19] J. Boyar, L. M. Favrholdt, and K. S. Larsen. Online unit p roﬁt knapsack with untrusted predic-\ntions. In SWAT , volume 227 of LIPIcs , pages 20:1–20:17. Schloss Dagstuhl - Leibniz-Zentrum\nfür Informatik, 2022.\n[20] S. Bubeck, M. B. Cohen, J. R. Lee, and Y . T. Lee. Metrical t ask systems on trees via mirror\ndescent and unfair gluing. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on\nDiscrete Algorithms, SODA 2019 , pages 89–97, 2019. doi: 10.1137/1.9781611975482.6. URL\nhttps://doi.org/10.1137/1.9781611975482.6 .\n[21] J. Chen, S. Silwal, A. Vakilian, and F. Zhang. Faster fun damental graph algorithms via learned\npredictions. In Proceedings of the 39th International Conference on Machin e Learning , vol-\nume 162 of Proceedings of Machine Learning Research , pages 3583–3602. PMLR, 17–23 Jul\n2022. URL https://proceedings.mlr.press/v162/chen22v.html .\n[22] J. Chledowski, A. Polak, B. Szabucki, and K. T. Zolna. Ro bust learning-augmented caching:\nAn experimental study. In M. Meila and T. Zhang, editors, Proceedings of the 38th Interna-\ntional Conference on Machine Learning, ICML 2021, 18-24 Jul y 2021, Virtual Event , volume\n139 of Proceedings of Machine Learning Research , pages 1920–1930. PMLR, 2021. URL\nhttp://proceedings.mlr.press/v139/chledowski21a.htm l.\n[23] E. Cho, S. A. Myers, and J. Leskovec. Friendship and mobi lity:\nuser movement in location-based social networks. In Proceedings of\nSIGKDD’11 , pages 1082–1090, 2011. doi: 10.1145/2020408.2020579. UR L\nhttps://snap.stanford.edu/data/loc-brightkite.html .\n[24] CitiBike. Citi bike trip histories. https://www.citibikenyc.com/system-data .\n[25] M. Dinitz, S. Im, T. Lavastida, B. Moseley, and S. Vassil vitskii. Faster matchings via learned\nduals. In NeurIPS , pages 10393–10406, 2021.\n[26] S. Dobrev, R. Královi ˇc, and D. Pardubská. Measuring the problem-relevant inform ation in\ninput. RAIRO - Theor. Inf. Appl. , 43(3):585–613, 2009.\n26\n\nPublished as a conference paper at ICLR 2024\n[27] M. Drygala, S. G. Nagarajan, and O. Svensson. Online alg orithms with costly predic-\ntions. In F. Ruiz, J. Dy, and J.-W. van de Meent, editors, Proceedings of The 26th In-\nternational Conference on Artiﬁcial Intelligence and Stat istics , volume 206 of Proceed-\nings of Machine Learning Research , pages 8078–8101. PMLR, 25–27 Apr 2023. URL\nhttps://proceedings.mlr.press/v206/drygala23a.html .\n[28] P. Dütting, S. Lattanzi, R. P. Leme, and S. Vassilvitski i. Secretaries with advice. In EC, pages\n409–429. ACM, 2021.\n[29] F. Eberle, A. Lindermayr, N. Megow, L. Nölke, and J. Schl öter. Robustiﬁcation of online graph\nexploration methods. In AAAI , pages 9732–9740. AAAI Press, 2022.\n[30] M. Eliáš, H. Kaplan, Y . Mansour, and S. Moran. Learning- augmented algorithms with explicit\npredictors, 2024. URL https://arxiv.org/abs/2403.07413 .\n[31] Y . Emek, P. Fraigniaud, A. Korman, and A. Rosén. Online c omputation with advice. In Au-\ntomata, Languages and Programming, 36th International Col loquium, ICALP 2009, Proceed-\nings, Part I , volume 5555 of Lecture Notes in Computer Science , pages 427–438. Springer,\n2009. URL https://doi.org/10.1007/978-3-642-02927-1_36 .\n[32] J. C. Ergun, Z. Feng, S. Silwal, D. P. Woodruff, and S. Zho u. Learning-\naugmented k-means clustering. In The Tenth International Conference\non Learning Representations, ICLR 2022 . OpenReview.net, 2022. URL\nhttps://openreview.net/forum?id=X8cLTHexYyY .\n[33] A. Fiat, R. M. Karp, M. Luby, L. A. McGeoch, D. D. Sleator, and N. E. Young.\nCompetitive paging algorithms. Journal of Algorithms , 12(4):685–699, 1991.\nISSN 0196-6774. doi: https://doi.org/10.1016/0196-6774 (91)90041-V. URL\nhttps://www.sciencedirect.com/science/article/pii/0 19667749190041V .\n[34] A. Gupta, D. Panigrahi, B. Subercaseaux, and K. Sun. Aug menting online algo-\nrithms with \\varepsilon-accurate predictions. In S. Koyej o, S. Mohamed, A. Agar-\nwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Pro-\ncessing Systems , volume 35, pages 2115–2127. Curran Associates, Inc., 2022 . URL\nhttps://proceedings.neurips.cc/paper_files/paper/20 22/file/0ea048312aa812b2711fe765 \n[35] J. Hromkovi ˇc, R. Královi ˇc, and R. Královi ˇc. Information complexity of online problems. In\nMFCS , volume 6281 of LNCS , pages 24–36. Springer, 2010.\n[36] S. Im, R. Kumar, M. M. Qaem, and M. Purohit. Online knapsa ck with frequency predictions.\nInNeurIPS , pages 2733–2743, 2021.\n[37] S. Im, R. Kumar, A. Petety, and M. Purohit. Parsimonious learning-augmented caching. In\nICML , 2022.\n[38] P. Indyk, F. Mallmann-Trenn, S. Mitrovic, and R. Rubinf eld. Online page migration with\nml advice. In G. Camps-Valls, F. J. R. Ruiz, and I. Valera, edi tors, Proceedings of The\n25th International Conference on Artiﬁcial Intelligence a nd Statistics , volume 151 of Pro-\nceedings of Machine Learning Research , pages 1655–1670. PMLR, 28–30 Mar 2022. URL\nhttps://proceedings.mlr.press/v151/indyk22a.html .\n[39] A. Jain and C. Lin. Back to the future: Leveraging belady ’s algorithm for improved cache\nreplacement. SIGARCH Comput. Archit. News , 44(3):78–89, June 2016. ISSN 0163-5964. doi:\n10.1145/3007787.3001146. URL https://doi.org/10.1145/3007787.3001146 .\n[40] Z. Jiang, D. Panigrahi, and K. Sun. Online algorithms fo r weighted paging with predic-\ntions. ACM Trans. Algorithms , 18(4):39:1–39:27, 2022. doi: 10.1145/3548774. URL\nhttps://doi.org/10.1145/3548774 .\n[41] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis . The case for learned index structures.\nInProceedings of SIGMOD’18 , pages 489–504, 2018. doi: 10.1145/3183713.3196909.\n27\n\nPublished as a conference paper at ICLR 2024\n[42] S. Lattanzi, T. Lavastida, B. Moseley, and S. Vassilvit skii. Online schedul-\ning via learned weights. In Proceedings of the 2020 ACM-SIAM Symposium\non Discrete Algorithms, SODA 2020 , pages 1859–1877. SIAM, 2020. URL\nhttps://doi.org/10.1137/1.9781611975994.114 .\n[43] A. Lindermayr and N. Megow. Permutation predictions fo r non-clairvoyant scheduling. In\nSPAA , pages 357–368. ACM, 2022.\n[44] A. Lindermayr and N. Megow. Algorithms with prediction s.\nhttps://algorithms-with-predictions.github.io , 2022. URL\nhttps://algorithms-with-predictions.github.io . [Online; accessed\n8-September-2022].\n[45] A. Lindermayr, N. Megow, and B. Simon. Double coverage w ith machine-learned advice. In\nM. Braverman, editor, 13th Innovations in Theoretical Computer Science Conferen ce, ITCS\n2022, January 31 - February 3, 2022, Berkeley, CA, USA , volume 215 of LIPIcs , pages 99:1–\n99:18. Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 2022. doi: 10.4230/LIPIcs.ITCS.\n2022.99. URL https://doi.org/10.4230/LIPIcs.ITCS.2022.99 .\n[46] E. Liu, M. Hashemi, K. Swersky, P. Ranganathan, and J. Ah n. An imitation learning approach\nfor cache replacement. In Proceedings of the 37th International Conference on Machin e Learn-\ning, volume 119 of Proceedings of Machine Learning Research , pages 6237–6247. PMLR,\n13–18 Jul 2020. URL https://proceedings.mlr.press/v119/liu20f.html .\n[47] T. Lykouris and S. Vassilvitskii. Competitive caching with machine learned advice. J. ACM ,\n68(4):24:1–24:25, 2021.\n[48] M. Mitzenmacher and S. Vassilvitskii. Algorithms with predictions. In Beyond the Worst-Case\nAnalysis of Algorithms , pages 646–662. Cambridge University Press, 2020.\n[49] A. Polak and M. Zub. Learning-augmented maximum ﬂow. CoRR , abs/2207.12911, 2022.\n[50] M. Purohit, Z. Svitkina, and R. Kumar. Improving online algorithms via ML predictions. In\nNeurIPS , 2018.\n[51] D. Rohatgi. Near-optimal bounds for online caching wit h machine learned advice. In SODA ,\n2020.\n[52] S. Sakaue and T. Oki. Discrete-convex-analysis-based framework for warm-starting algorithms\nwith predictions. CoRR , abs/2205.09961, 2022. doi: 10.48550/arXiv.2205.09961.\n[53] Z. Shi, X. Huang, A. Jain, and C. Lin. Applying deep learn ing to the cache replacement\nproblem. In Proceedings of the 52nd Annual IEEE/ACM International Symp osium on Mi-\ncroarchitecture , MICRO ’52, page 413–425, New York, NY , USA, 2019. Associati on for\nComputing Machinery. ISBN 9781450369381. doi: 10.1145/33 52460.3358319. URL\nhttps://doi.org/10.1145/3352460.3358319 .\n[54] D. D. Sleator and R. E. Tarjan. Amortized efﬁciency of li st update and paging rules. Commun.\nACM , 28(2):202–208, 1985. doi: 10.1145/2786.2793.\n[55] A. Wei. Better and simpler learning-augmented online c aching. In APPROX/RANDOM , 2020.\n[56] A. Zeynali, B. Sun, M. H. Hajiesmaili, and A. Wierman. Da ta-driven competitive algorithms\nfor online knapsack and set cover. In AAAI , pages 10833–10841. AAAI Press, 2021.\n28\n\nPublished as a conference paper at ICLR 2024\nA C OMPUTATIONS FOR TABLE 1\nIn this section, we present the computations for the numbers of predictions we obtained in Table 1.\nForf(i) =iandf(i) =i2, we have f(logk)equal tologkandlog2krespectively.\nForf(i) = 2i−1, we identify the ﬁrst window ilonger than f(i)−f(i−1). Note that the length\nof window iisk/2i= 2logk−iand this is equal to the sum of lengths of the windows j > i . The\ntotal number of predictions used will be therefore f(i) + 2logk−i. Fori= log√\nk+ 1, we have\nf(i)−f(i−1)= 2i= 21\n2logk+1>2logk−i. Therefore, we use 2i−1+2logk−i≥3√\nkpredictions\nin each robust phase. Since ofﬂine optimum has to pay at least 1per robust phase, we use at most\nO(√\nk)OPT predictions in total.\nForf(i) = 0 , we ask for a prediction at each arrival of a clean page. The nu mber of queries used\nwill therefore be at most the number of clean arrivals, which is at most 2OPT .\n29",
  "textLength": 86459
}