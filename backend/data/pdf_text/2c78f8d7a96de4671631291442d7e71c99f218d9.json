{
  "paperId": "2c78f8d7a96de4671631291442d7e71c99f218d9",
  "title": "Estimating Cardinalities with Deep Sketches",
  "pdfPath": "2c78f8d7a96de4671631291442d7e71c99f218d9.pdf",
  "text": "Estimating Cardinalities with Deep Sketches\nAndreas Kipf\nTechnical University of Munich\nkipf@in.tum.deDimitri Vorona\nTechnical University of Munich\nvorona@in.tum.deJonas Müller\nTechnical University of Munich\njonas.mueller@in.tum.de\nThomas Kipf\nUniversity of Amsterdam\nt.n.kipf@uva.nlBernhard Radke\nTechnical University of Munich\nradke@in.tum.deViktor Leis\nTechnical University of Munich\nleis@in.tum.de\nPeter Boncz\nCentrum Wiskunde & Informatica\nboncz@cwi.nlThomas Neumann\nTechnical University of Munich\nneumann@in.tum.deAlfons Kemper\nTechnical University of Munich\nkemper@in.tum.de\nABSTRACT\nWe introduce Deep Sketches, which are compact models of\ndatabases that allow us to estimate the result sizes of SQL\nqueries. Deep Sketches are powered by a new deep learning\napproach to cardinality estimation that can capture corre-\nlations between columns, even across tables. Our demon-\nstration allows users to define such sketches on the TPC-H\nand IMDb datasets, monitor the training process, and run\nad-hoc queries against trained sketches. We also estimate\nquery cardinalities with HyPer and PostgreSQL to visualize\nthe gains over traditional cardinality estimators.\n1 INTRODUCTION\nWe introduce Deep Sketches, compact model-based represen-\ntations of databases that allow us to estimate the result sizes\nof SQL queries. Deep Sketches are powered by a new deep\nlearning approach to cardinality estimation [ 7] (code: [ 1]).\nThis approach builds on sampling-based estimation and ad-\ndresses its weaknesses when no sampled tuples qualify a\npredicate. A Deep Sketch is essentially a wrapper for a (seri-\nalized) neural network and a set of materialized samples.\nEstimates of intermediate query result sizes are the core\ningredient to cost-based query optimizers [ 11,12]. While the\nfocus of this work is notto show the effect of better cardinal-\nity estimates on the quality of resulting query plans—which\nis orthogonal to having better estimates in the first place, we\ndemonstrate that the estimates produced by Deep Sketches\nare superior to estimates of traditional optimizers and often\nclose to the ground truth. The estimates produced by Deep\nSketches can directly be leveraged by existing, sophisticated\njoin enumeration algorithms and cost models. This is a more\ngradual approach than the one taken by machine learning\n(ML)-based end-to-end query optimizers [16].\nOur demonstration allows users to define Deep Sketches\non the TPC-H and Internet Movie Database (IMDb) datasets.\nAcknowledgements. T.K. acknowledges funding by SAP SE.The latter is a real-world dataset that contains many cor-\nrelations and therefore proves to be very challenging for\ncardinality estimators. To create a Deep Sketch, users select\na subset of tables and define a few parameters such as the\nnumber of training queries. Users can then monitor the train-\ning progress, including the execution of training queries and\nthe training of the deep learning model. Once the model\nhas been trained, users can issue ad-hoc queries against the\nresulting Deep Sketch. Our user interface makes it easy to\ncreate such queries graphically. Users can optionally specify\na placeholder for a certain column to define a query template.\nFor example, a movie producer might be interested in the\npopularity of a certain keyword over time:\nSELECT COUNT(*)\nFROM title t, movie_keyword mk, keyword k\nWHERE mk.movie_id=t.id AND mk.keyword_id=k.id\nAND k.keyword= 'artificial-intelligence '\nAND t.production_year=?\nA placeholder has a similar effect as a group-by operation,\nexcept that it does not operate on all distinct values of the\ngroup-by column but instead only on the values present\nin the column sample that comes with the sketch. In other\nwords, we instantiate the query template with values (literals)\nfrom the column sample. Besides this being an interesting\nfeature for data analysts, it serves the purpose of visualizing\nthe robustness of our deep learning approach to cardinality\nestimation1. The result of a query template can be displayed\nas a bar or as a line plot with one data point per template\ninstance. Using overlays, we show the difference to the car-\ndinality estimates produced by HyPer2[6] and PostgreSQL\n1Note that the deep learning model is not necessarily trained with literals\npresent in the column sample. In fact, it can happen (and is even likely for\ncolumns with many distinct values) that a literal from the column sample\nhas never been seen by the model.\n2We are referring to the research version of HyPer developed at the Techni-\ncal University of Munich.arXiv:1904.08223v1  [cs.DB]  17 Apr 2019\n\nas well as to the true cardinalities—obtained by executing\nthe queries with HyPer.\nDeep Sketches feature a small footprint size (a few MiBs)\nand are fast to query (within milliseconds). Due to these\nfacts, another application of Deep Sketches lies in the area\nof previewing query result sizes. Often, rough estimates are\nsufficient to inform users whether executing a certain query\nwould be worthwhile, and sometimes even all they need—\ne.g., to get an idea about the data distribution of a certain\ncolumn given some selections and/or joins. For example,\nDeep Sketches could be deployed in a web browser or within\na cell phone to preview query results.\n2 DEEP SKETCHES\nDeep Sketches are powered by a new (supervised) deep learn-\ning approach to cardinality estimation [7] that has recently\nbeen adopted in [ 4]. The idea of this approach is to execute\ngenerated queries against a database to obtain true cardinali-\nties ( labels in ML), featurize these queries, and feed them into\na neural network. Of course, instead of generating queries\nand uniformly sampling the search space, one could also use\npast user queries.\nBesides static query features—such as selections or joins,\nwe featurize information about qualifying base table sam-\nples. In other words, in addition to executing a training query\nagainst the full database, we execute each base table selection\nagainst a set of materialized samples (e.g., 1000 tuples per\nbase table). Thus, we derive bitmaps indicating qualifying\nsamples for each base table. These bitmaps are then used as\nan additional input to the deep learning model. Besides this\nintegration of (runtime) sampling, another differentiating\nfactor from other learning-based approaches to cardinality\nestimation [ 18,20] is the use of a model that employs set\nsemantics , inspired by recent work on Deep Sets [22], a neural\nnetwork module that operates on sets. This decision rests\non the fact that the cardinality of a query is independent of\nits query plan—e.g., both (AZB)ZCandAZ(BZC)can\nbe represented as{A,B,C}. While the Deep Sets model only\naddresses single sets, our model—called multi-set convolu-\ntional network (MSCN)—represents three sets (tables, joins,\nand predicates) and can capture correlations between sets.\nOn a high level, the MSCN model can be described as fol-\nlows: For each set, it has a separate module, comprised of\none fully-connected multi-layer perceptron (MLP) per set\nelement with shared parameters. We average module out-\nputs, concatenate them, and feed them into a final output\nMLP, which captures correlations between sets and outputs\na cardinality estimate. The featurization of a query is very\nstraightforward. Based on the training data, we enumerate\ntables, columns, joins, and predicate types ( =,<, and >) and\nrepresent them as unique one-hot vectors. We represent eachmedian 90th 95th 99th max mean\nDeep Sketch 3.82 78.4 362 927 1110 57.9\nHyPer 14.6 454 1208 2764 4228 224\nPostgreSQL 7.93 164 1104 2912 3477 174\nTable 1: Estimation errors on the JOB-light workload.\nliteral in a query as a value val(val∈[0,1]), normalized\nusing the minimum and maximum values of the respective\ncolumn. Similarly, we logarithmize and then normalize car-\ndinalities (labels) using the maximum cardinality present\nin the training data. For a detailed description of the model\nand the featurization, we refer the reader to [ 7]. Finally, we\ntrain our model with the objective of minimizing the mean\nq-error [17]q(q≥1). The q-error is the factor between the\ntrue and the estimated cardinality.\nOne advantage of our approach over pure sampling-based\ncardinality estimators is that it addresses 0-tuple situations,\nwhich is when no sampled tuples qualify. In such situations,\nsampling-based approaches usually fall back to an “educated”\nguess—causing large estimation errors. Our approach, in\ncontrast, handles such situations reasonably well [ 7] as it\ncan use the signal of individual query features (e.g., predicate\ntypes) to provide a more precise estimate. In addition, it can—\nto some degree—capture correlations across joins and can\nthus estimate joins without assuming independence.\nTable 1 shows the estimation errors (q-errors) of our ap-\nproach (Deep Sketch) compared to the cardinality estimators\nof HyPer and PostgreSQL version 10.3. The results are on\nJOB-light [ 1], which is a workload derived from the Join\nOrder Benchmark (JOB) [ 11] containing 70 of the original\n113 queries. In contrast to JOB, JOB-light does not contain\nany predicates on strings nor disjunctions and only contains\nqueries with one to four joins. Most queries in JOB-light have\nequality predicates on dimension table attributes. The only\nrange predicate is on production_year . Considering that\nMSCN was trained with a uniform distribution between =,\n<, and >predicates, it performs reasonably well. This exper-\niment shows that MSCN can generalize to workloads with\ndistributions different from the training data. By allowing\nusers of our demonstration to issue ad-hoc queries, we want\nto enable them to experience this generalizability.\nWe believe that Deep Sketches are an important step to-\nwards a learned database system [ 8], and can be used in con-\njunction with other recently proposed ML-powered compo-\nnents for join enumeration [ 10,14], adaptive query process-\ning [19], indexing [ 9,21], view materialization [ 13], workload\nmanagement [5], and query performance prediction [15].\n\nDefine Deep Sketch: \n●set of tables \n●number of materialized samples \n●number of training queries \n●number of training epochs 1\nGenerate  train. queries: \n●uniformly choose tables, columns, \nand predicate types \n●draw literals from database 2 Execute train. queries: \n●against database to obtain true \ncardinalities for entire queries \n●against materialized samples 3Train Deep Sketch: \n●featurize static query features \nand bitmaps \n●train neural network for \nspecified number of epochs 4(a) Creation of a sketch.\nDeep Sketch { A, B}\nMSCN\n(a neural network) \nSQL query cardinality \nestimate \nsample\ntable A\ntuple 1\ntuple 2\ntuple nsample\ntable B\ntuple 1\ntuple 2\ntuple n (b) Result size estimation with a sketch.\nFigure 1: Creation and usage of a Deep Sketch. Depending on the number of training queries, training can be\nexpensive. However, once a sketch is trained, it allows for an efficient result size estimation of SQL queries.\n3 DEMONSTRATION\nAs stated earlier, a Deep Sketch is essentially a wrapper for\na trained MSCN model and a set of materialized samples.\nIn our demonstration, users can experience the end-to-end\nprocess of defining, training, and using trained sketches to\nestimate the result sizes of ad-hoc SQL queries. We support\nthe TPC-H and IMDb datasets.\nFigure 1a shows the four steps involved to create a new\nsketch. First ( 1), users need to select a subset of tables from\neither schema and define a few parameters, including the\nnumber of materialized base table samples, the number of\ntraining queries, and the number of training epochs. Next\n(2), we generate uniformly distributed training queries on\nthe specified tables in our backend, and ( 3) execute them\nwith HyPer to obtain true cardinalities and to extract bitmaps\nindicating qualifying samples. To accelerate this process\nduring our demonstration, we plan to execute the training\nqueries (in parallel) on multiple HyPer instances. Finally ( 4),\nwe featurize the training queries and train the MSCN model\nfor the specified number of epochs.\nTo give a point of reference on the training costs, training\nthe model with 90,000 queries over 100 epochs takes almost\n39 minutes on an Amazon Web Services (AWS) ml.p2.xlarge\ninstance using the PyTorch framework [ 2] with CUDA. Since\nthis number is too high for an interactive user experience,\nwe address this problem in three ways.\nFirst, we allow users to control the number of training\nqueries and epochs. For a small number of tables, 10,000\nqueries will already be sufficient to achieve good results.\nNote that the training time decreases linearly with fewer\nepochs. From our experience, 25 epochs are usually enough\nto achieve a reasonable mean q-error on a separate validation\nset. Second, we offer pre-built (high quality) models that can\nbe queried right away. Third, we allow users to train new\nmodels while querying existing ones.Figure 1b illustrates a Deep Sketch on two tables A and B.\nThe interface of a sketch is very simple, it consumes a SQL\nquery and returns a cardinality estimate.\nFigure 2 shows our web interface for Deep Sketches. On\nthe left, we allow users to specify SQL queries, and on the\nright, we display query results (estimated and true cardinali-\nties). On the top ( SHOW SKETCHES ), users can select existing\nand create new sketches as described above. To query a\nsketch, users do not need enter SQL directly (the SQL string\nshown in the web interface is only displayed for information\npurposes). Instead, we provide them with a simple graphical\nquery interface. By clicking on a table, it is added to the\nquery. When a user selects multiple tables, we automatically\nadd the corresponding join predicates to the query (based\non the single PK/FK relationships that exist between tables).\nUsers can also define selections on base tables by click-\ning the respective columns in the schema. We support both\nequality and range predicates. In addition, we allow users to\nspecify a placeholder for a certain column. Since our Deep\nSketch implementation can only estimate single queries, we\nautomatically instantiate such query templates and—in the\nbackground—execute each instance separately against the\nsketch. To create such an instance, we draw a value from\nthe column sample that is part of the sketch. Optionally,\nusers can select a function to be applied to these values. For\nexample, for columns with many distinct values—such as\nDate columns, users may want to “group” the results by year\n(e.g., EXTRACT(YEAR FROM date) ). To serve such queries, we\ngenerate multiple range queries (one for each year found in\nthe sample) to be issued against the sketch. We also support\ngrouping the output into equally sized buckets based on the\nminimum and maximum values from the sample.\nWhen a user hits the EXECUTE button, we issue the query\nagainst HyPer to compute its true cardinality as well as\nagainst the Deep Sketch and the cardinality estimators of\nHyPer and PostgreSQL to obtain estimates. The query results\n\nFigure 2: Web interface for Deep Sketches.\nare displayed with different overlays as they arrive. On the\nX-axis we denote values from the placeholder column and\non the Y-axis we plot the estimated and true cardinalities.\nWe support both bar and line charts and allow users to hide\nthe results of individual systems.\nWe also use TensorBoard [ 3] to visualize the neural net-\nwork architecture of our model and the training phase.\n4 CONCLUSIONS\nWe have introduced Deep Sketches, which are compact rep-\nresentations of databases that allow us to estimate the result\nsizes of SQL queries. Our demonstration allows users to expe-\nrience the end-to-end training and querying process of these\nsketches. The goal of this work is to show that a learned\ncardinality model can compete with and even outperform\ntraditional cardinality estimators, especially for highly cor-\nrelated data. Our audience can specify ad-hoc queries and\nthereby observe that ML might indeed be the right hammer\nfor the decades-old cardinality estimation job. Clearly, more\nresearch is needed to automate the training and utilization of\nDeep Sketches in query optimizers. One question—that we\ncurrently outsource to our users—is for which schema parts\nwe should build such sketches. Besides further improving car-\ndinality estimation for query optimization, another avenue\nwe could take in future work is to deploy Deep Sketches—\nwhich offer a small footprint size—on the client to preview\nquery results.\nREFERENCES\n[1]Learned Cardinalities in PyTorch. https://github.com/andreaskipf/\nlearnedcardinalities.\n[2] PyTorch. https://pytorch.org/.\n[3] TensorBoard. https://www.tensorflow.org/tensorboard.\n[4]S. Hasan, S. Thirumuruganathan, J. Augustine, N. Koudas, and G. Das.\nMulti-Attribute Selectivity Estimation Using Deep Learning. CoRR ,\nabs/1903.09999, 2019.\n[5]S. Jain, J. Yan, T. Cruanes, and B. Howe. Database-Agnostic Workload\nManagement. In CIDR , 2019.[6]A. Kemper and T. Neumann. HyPer: A Hybrid OLTP & OLAP Main\nMemory Database System Based on Virtual Memory Snapshots. In\nICDE , 2011.\n[7]A. Kipf, T. Kipf, B. Radke, V. Leis, P. A. Boncz, and A. Kemper. Learned\nCardinalities: Estimating Correlated Joins with Deep Learning. In\nCIDR , 2019.\n[8]T. Kraska, M. Alizadeh, A. Beutel, E. H. Chi, A. Kristo, G. Leclerc,\nS. Madden, H. Mao, and V. Nathan. SageDB: A Learned Database\nSystem. In CIDR , 2019.\n[9]T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The Case for\nLearned Index Structures. In SIGMOD , 2018.\n[10] S. Krishnan, Z. Yang, K. Goldberg, J. M. Hellerstein, and I. Stoica.\nLearning to Optimize Join Queries With Deep Reinforcement Learning.\nCoRR , abs/1808.03196, 2018.\n[11] V. Leis, A. Gubichev, A. Mirchev, P. Boncz, A. Kemper, and T. Neumann.\nHow Good Are Query Optimizers, Really? PVLDB , 2015.\n[12] V. Leis, B. Radke, A. Gubichev, A. Mirchev, P. Boncz, A. Kemper, and\nT. Neumann. Query Optimization Through the Looking Glass, and\nWhat We Found Running the Join Order Benchmark. VLDBJ , 2018.\n[13] X. Liang, A. J. Elmore, and S. Krishnan. Opportunistic View Materi-\nalization with Deep Reinforcement Learning. CoRR , abs/1903.01363,\n2019.\n[14] R. Marcus and O. Papaemmanouil. Deep Reinforcement Learning for\nJoin Order Enumeration. In aiDM , 2018.\n[15] R. Marcus and O. Papaemmanouil. Plan-Structured Deep Neural Net-\nwork Models for Query Performance Prediction. CoRR , abs/1902.00132,\n2019.\n[16] R. Marcus and O. Papaemmanouil. Towards a Hands-Free Query\nOptimizer through Deep Learning. In CIDR , 2019.\n[17] G. Moerkotte, T. Neumann, and G. Steidl. Preventing Bad Plans by\nBounding the Impact of Cardinality Estimation Errors. PVLDB , 2009.\n[18] J. Ortiz, M. Balazinska, J. Gehrke, and S. S. Keerthi. Learning State\nRepresentations for Query Optimization with Deep Reinforcement\nLearning. In DEEM , 2018.\n[19] I. Trummer, S. Moseley, D. Maram, S. Jo, and J. Antonakakis. Skin-\nnerDB: Regret-Bounded Query Evaluation via Reinforcement Learning.\nPVLDB , 2018.\n[20] C. Wu, A. Jindal, S. Amizadeh, H. Patel, W. Le, S. Qiao, and S. Rao.\nTowards a Learning Optimizer for Shared Clouds. PVLDB , 2018.\n[21] Y. Wu, J. Yu, Y. Tian, R. Sidle, and R. Barber. Designing Succinct\nSecondary Indexing Mechanism by Exploiting Column Correlations.\nCoRR , abs/1903.11203, 2019.\n[22] M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Póczos, R. R. Salakhutdinov,\nand A. J. Smola. Deep Sets. In NIPS , 2017.",
  "textLength": 19351
}