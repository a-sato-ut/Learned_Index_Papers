{
  "paperId": "b0de3619d63ed3b53c89e4347a7249fb9438400d",
  "title": "On the Suitability of Neural Networks as Building Blocks for The Design of Efficient Learned Indexes",
  "pdfPath": "b0de3619d63ed3b53c89e4347a7249fb9438400d.pdf",
  "text": "On the Suitability of Neural Networks as\nBuilding Blocks for The Design of E\u000ecient\nLearned Indexes?\nDomenico Amato1, Giosu\u0013 e Lo Bosco1, and Ra\u000baele Giancarlo1\n1Dipartimento di Matematica e Informatica\nUniversit\u0013 a degli Studi di Palermo, ITALY\nAbstract. With the aim of obtaining time/space improvements in clas-\nsic Data Structures, an emerging trend is to combine Machine Learning\ntechniques with the ones proper of Data Structures. This new area goes\nunder the name of Learned Data Structures . The motivation for its study\nis a perceived change of paradigm in Computer Architectures that would\nfavour the use of Graphics Processing Units and Tensor Processing Units\nover conventional Central Processing Units. In turn, that would favour\nthe use of Neural Networks as building blocks of Classic Data Struc-\ntures. Indeed, Learned Bloom Filters, which are one of the main pillars\nof Learned Data Structures, make extensive use of Neural Networks to\nimprove the performance of classic Filters. However, no use of Neural\nNetworks is reported in the realm of Learned Indexes, which is another\nmain pillar of that new area. In this contribution, we provide the \frst,\nand much needed, comparative experimental analysis regarding the use\nof Neural Networks as building blocks of Learned Indexes. The results\nreported here highlight the need for the design of very specialized Neu-\nral Networks tailored to Learned Indexes and it establishes solid ground\nfor those developments. Our \fndings, methodologically important, are\nof interest to both Scientists and Engineers working in Neural Networks\nDesign and Implementation, in view also of the importance of the appli-\ncation areas involved, e.g., Computer Networks and Data Bases.\n1 Introduction\nLearned Data Structures is a new research area based on the combination of\nMachine Learning (ML) techniques with the ones proper of Data Structures,\nwith the aim of obtaining time/space improvements in classic Data Structures.\nIt was initiated by [18], it has grown very rapidly [10] and now it has been\nextended to include also Learned Algorithms [22].\n?This research is funded in part by MIUR Project of National Relevance\n2017WR7SHH \\Multicriteria Data Structures and Algorithms: from compressed to\nlearned indexes, and beyond\". We also acknowledge an NVIDIA Higher Education\nand Research Grant (donation of a Titan V GPU).arXiv:2203.14777v1  [cs.DB]  21 Feb 2022\n\n1.1 Computer Architectures as a Motivation for Learned Data\nStructures\nThe ML models with the most potential in this area are undoubtedly Neural\nNetworks (NNs), because of their learning power, e.g., [24]. Unfortunately, they\nrequire prohibitive computational power. In recent years, the introduction of\nGraphics Processing Unit (GPU) and Tensor Processing Unit (TPU) architec-\ntures in commercial computers [25,28], and the deployment of highly engineered\ndevelopment platforms such as Tensor\row [2], has de facto removed the com-\nputational bottleneck referred to earlier. In fact, ML Models, and in particular\nNNs, have been increasingly used in many application domains [19].\nThe major strength of these new architectures is that they can parallelise\nmaths operations made by NNs very well, compared to a general-purpose set of\ninstructions. In particular, recent studies even argue that the power of the GPU\ncan be improved by 1000x in terms of time in the next few years, while, due to\nMoore's Law constraints [23], those improvements are not seen for classic CPUs.\nFurthermore, a programming paradigm based on branches of the if-then-else type\nseems to have been overcome in favour of a paradigm that promotes straight-\nline mathematical operations, which can be pipelined e\u000eciently on those modern\narchitectures. For these reasons, using ML models such as NNs, on such advanced\narchitectures instead of the classic Data Structures, which make extensive use of\nbranch instructions in their code, may lead to the deployment of substantially\nbetter Data Structures, with bene\fts in many areas such as Computer Networks\nand Data Bases.\nUnfortunately, although the above motivation for the design of Learned Data\nStructures based on NNs is indeed a strong one, the potential gain that can be\nachieved is either at an initial stage of assessment or it has not been assessed at\nall, as we outline next.\n1.2 From Motivation to Design and Implementation of Learned\nData Structures: The role of NNs\n{ Learned Bloom Filters. NNs have been extensively used within the design\nand implementation of Learned Bloom Filters, since the very start of the\narea of Learned Data Structure [18]. W recall that, given a universe Uof\nelements, a Bloom Filter [6] is a Data Structure to solve the Approximate\nMembership Problem for a given set A\u001aU. That is, given a query element\nx2U, establish whether x2A, with a speci\fc False Positive Rate (FPR)\n\u000fand zero False Negatives. Essential parameters for the evaluation of the\nperformance of Bloom Filters are FPR, Query Time and Space Occupancy.\nThose parameters are very intimately connected, as well explained in [8].\nThe current versions of Learned Bloom Filters that have been proposed in\nthe literature [9,18,21,27] use convolutional and recurrent neural networks.\nThe interested reader can \fnd details in [13], together with experimental\ncomparative performance analysis.\n\n{ Learned Indexes. Learned Indexes [18] have been introduced to solve the\nso-called Predecessor Search Problem . Given a sorted table Aofnkeys taken\nfrom a universe U, and a query element xinA, the Predecessor Search Prob-\nlem consists in \fnding the A[j] such that A[j]\u0014x<A [j+ 1]. A synopsis of\nthe Learned Indexes Methodology is presented in Section 2. Although several\nversions of Learned Indexes have been proposed, e.g., [3,4,10,11,15,18,20],\nsurprisingly, none of them use NNs. Even more surprisingly, no comparative\nperformance analysis regarding the use of NNs in Learned Indexing has been\ncarried out.\n{ Additional Learned Data Structures. Learned Hash Functions [18] as\nwell as Learned Rank and Select Data Structures [7] do not use NNs. Again,\nno performance analysis regarding those models has been carried out.\n1.3 Our Results: The Role of Neural Networks in the Design of\nLearned Indexes - the Atomic Case\nIn view of the State of the Art reported in Section 1.2, our novel contribution to\nthe advancement of the area of Learned Data Structures is the \frst assessment\nof the suitability of NNs as building blocks of Learned Indexes. Indeed, in order\nto provide a clear comparative assessment of the potential usefulness of NNs in\nthe mentioned domain, we consider Atomic Models for Learned Indexes, de\fned\nin Section 3. Intuitively, they are the simplest models one can think of. The\nrationale for their choice is that, if NNs do not provide any signi\fcant advance\nwith respect to very simple Learned Indexes, in view of the results in [3, 4],\nthey have very little to o\u000ber to Learned Indexing in their current generic, if not\n\\textbook\", form. Even with the advantage of GPU processing. Technically, we\no\u000ber the following contributions.\n{The \frst design of a Learned Index based on NNs Models only. We choose\nFeed Forward NNs because they o\u000ber a good compromise between time ef-\n\fciency, space occupancy and ability to learn [5]. Since this Learned Index\nhas no other ML subcomponent, we refer to it as an Atomic Learned Index.\n{An extensive experimental study about the e\u000bectiveness of this Atomic\nLearned Index, both in the case of CPU and GPU processing.\n{An extensive comparison of this Atomic Learned Index with respect to anal-\nogous Atomic Indexes that use only Linear Regression [12] as the learned\npart. Those models have been formalized and studied in [3, 4] and they are\nvalid building blocks of more complex models used for Learned Indexes, e.g.,\ntheRMI family [20].\nAs opposed to Learned Bloom Filters, our results clearly indicate the need to\ndesign NNs speci\fcally focused on their use in the Learned Indexing paradigm. A\nstudy analogous to ours, that paves the way to developments of NNs more speci\fc\nfor Learned Indexing, is not available in the Literature and it is of Methodological\nimportance.\nThe software we have used for our experiments is available at [1].\n\n1.4 Organization of the Paper\nThis paper is organized as follows. Section 2 provides a synoptic description on\nLearned Indexing. Section 3 presents the Atomic Models that we consider for\nthis research. In Section 4, we illustrate the adopted experimental methodology.\nSection 5 reports experiments and \fndings. Finally, in Section 6, we provide\nconclusions and future direction of research.\nQuery Element\n{1\n5\n11\n14\n58\n59\n60\n97\n100\n101Model\nFig. 1: A general paradigm of Learned Searching in a Sorted Set [20]. The model is trained\non the data in the table. Then, given a query element, it is used to predict the interval in the table\nwhere to search (included in brackets in the \fgure).\n2 Learned Indexes: a Synopsis\nConsider a sorted table Aofnkeys, taken from a universe U. It is well known\nthat Sorted Table Search can be phrased as the Predecessor Search Problem: for\na given query element x, return the A[j] such that A[j]\u0014x<A [j+ 1]. Kraska\net al. [18] have proposed an approach that transforms such a problem into a\nlearning-prediction one. With reference to Figure 1, the model learned from the\ndata is used as a predictor of where a query element may be in the table. To\n\fx ideas, Binary Search is then performed only on the interval returned by the\nmodel.\nWe now outline the basic technique that one can use to build a model for\nA. It relies on Linear Regression [12]. With reference to the example in Figure\n2 and assuming that one wants a linear model, i.e., F(x) =ax+b, Kraska et\nal. note that one can \ft a straight line to the CDF and then use it to predict\nwhere a point xmay fall in terms of rank and accounting also for approximation\nerrors. In terms of regression, the function FaModel for the CDF function.\nMore in general, in order to perform a query, the model is consulted and\nan interval in which to search for is returned. Then, to \fx ideas, Binary Search\non that interval is performed. Di\u000berent models may use di\u000berent schemes to\ndetermine the required range, as outlined in Section 2. The reader interested in\na rigorous presentation of those ideas can consult Markus et al. [20].\n\n(a)\n (b)\n (c)\ne\nFig. 2: The Process of Learning a Simple Model via Linear Regression. LetAbe\n[47;105;140;289;316;358;386;398;819;939]. (a) The CDF of A. In the diagram, the abscissa in-\ndicates the value of an element in the table, while the ordinate is its rank. (b) The aandbvalues of\nthe straight line F(x) =ax+bare obtained via Linear Regression, with Mean Square Error Mini-\nmization. (c) The maximum error \u000fone can incur in using Fis\u000f= 3, i.e., accounting for rounding, it\nis the maximum distance between the rank of a point in the table and its rank as predicted by F. In\nthis case, the interval to search into, for a given query element x, is given by I= [F(x)\u0000\u000f;F(x)+\u000f].\n3 Atomic Models for Learned Indexes\nAs outlined in Section 2, a simple linear function that provides a model for the\nCDF of the data is a model for Learned Indexes. With reference to Figure 1,\nwhen the model consists of either a closed-form formula or a simple program that\nprovide an estimation of the CDF on a given point, we refer to it as Atomic . That\nis, it has no sub-component that has been learned from the data. As stated in\nthe Introduction, more complex models exist. However, as already outlined, for\nthe aim of this research, it is best to consider Atomic Models only. In particular,\nwe consider models that come from an analytical solution to regression problems\n(see Section 3.1), and models that use NNs (see Section 3.2).\n3.1 CDF Function Models Based on Analytic Solutions to\nRegression Problems\nRegression is a methodology for estimating a given function G:Rm!Rvia\na speci\fc function model ~G. The independent variables in x2Rmand the\ndependent variable y2Rare usually referred to as predictors and outcome,\nrespectively. The parameters of ~Gare estimated by minimizing an error function,\ncomputed using a sample set of predictors-outcome measurements. The most\ncommonly used Regression Loss Function is the Mean Square Error. Such a task\ncan be accomplished in several ways. Here we follow the method outlined in [14].\nIn particular, we present closed-form formulae solving the posed minimization\nproblem, with a linear (as a matter of fact, polynomial).\nLinear regression ( LRfor short) is the case when a geometric linear form is\nassumed as a model. In the case, when m= 1, it is referred to as Simple Linear\nRegression ( SLR for short) and as Multiple Linear Regression ( MLR for short),\notherwise.\nFor the general case of LR, given a training set of npredictor-outcome cou-\nples ( xi;yi), where xi2Rmandyi2R, the goal is to characterize the linear\nfunction model ~G(x) =^ wxT+^bby estimating the parameters ^ w2Rmand\n^b2R, using the sample set. We can de\fne a matrix Zof sizen\u0002(m+ 1) (usu-\nally referred to as the design matrix), where Ziis thei-th row of Zsuch that\n\nZi= [xi;1]. Moreover, yindicates the vector of size nsuch that the outcome yj\nis itsj-th component. The Mean Square Error minimization on the basis of the\nestimation is:\nMSE (w;b) =1\nn\r\r[w;b]ZT\u0000y\r\r2\n2(1)\nMSE is a convex quadratic function on [ w;b], so that the unique values that\nminimize it can be obtained by setting its gradient rw;bequal to zero. The\nclosed form solution for the parameters w;bis\n[^ w;^b] =yZ(ZTZ)\u00001(2)\nIt is to be noted that the SLR case is characterized by the choice of a\npolynomial of degree g= 1. The general case of Polynomial Regression ( PRfor\nshort), using polynomials with degree g>1, are special cases of MLR . Indeed,\nwe can consider the model:\n~G(z) =gX\ni=1wixi+b=wzT+b;\nwherewis of sizeg,z= [x;::;xg\u00001;xg]2Rgis the predictor vector for MLR .\nIn this paper, we use linear, quadratic and cubic regression models to ap-\nproximate the function Fgiven by the CDF of the data. In particular, the\ncorresponding models are pre\fxed by L, Q, orC.\n3.2 CDF Function Models Based on Neural Networks\nAnother method to learn a function G:Rm!Ris to use NNs. In particular, we\nfocus on Feed-Forward NNs, where the general strategy consists of an iterative\ntraining phase during which an improvement of the ~Gapproximation is made.\nStarting from an initial approximation ~G0, at each step i, an attempt is made\nto minimize an error function Eso thatE(~Gi\u00001)\u0015E(~Gi). The minimization is\ncarried out on a training set Tof examples. The process can stop after a \fxed\nnumber of steps or when, given a tolerance \u000e,jE(~Gi\u00001)\u0000E(~Gi)j\u0014\u000e. In the\nfollowing, we report the basic elements that characterize the type of NN we use.\n1.ARCHITECTURE TOPOLOGY .\n(a) As atomic element of our NN, we use a standard Perceptron [5]. with\nreluactivation function.\n(b) The number of Hidden Layers H.\n(c) For each hidden layer hi, its number of Perceptrons nhi.\n(d) The connection between each layer. In our case, a Fully Connected NN is\nused, i.e. each Perceptron of layer hiis connected with each Perceptron\nof the next layer hi+1.\n2.THE LEARNING ALGORITHM .\n(a) The error function E, that is used to measure how close is ~GtoG.\n\n(b) The gradient descent iterative process that starts from a ~G0and, at\neach step, better approximates GreducingE, changing layer by layer,\nby a backward and forward pass, the parameters of each layer. It can be\ncharacterized by a learning rate, i.e. the multiplicative constant of the\ngradient error.\n3.THE TRAINING SCHEME .\n(a) The size of a batch B, i.e., the number of elements to extract from\nthe training set T. At each extraction of the batch, the parameters are\nupdated.\n(b) The number of epochs nethat corresponds to the number of times the\ntraining set Tis presented to the NN for the minimization of E.\nThe learning algorithm of a NN uses a proper training set to perform the\ngradient descent iterative process. For the purpose of indexing, which is our goal,\nthe training data are in the form of scalar integers. To perform a Regression using\na NN, it is mandatory to represent the scalar integer xwith a vector representa-\ntion\u0000 !x. In this work,\u0000 !xis a string containing the 64-bit binary representation\nofx, as suggested also by Kraska et al. [18].\n3.3 Prediction Accuracy of an Atomic Model\nAs well illustrated in Figure 2, the approximation error is very important in\nreducing the size of the interval to be searched into. Smaller the error, the smaller\nthe portion of the table in which the \fnal search must be performed. In this\npaper, we characterize the accuracy in prediction of a model via the reduction\nfactor (RF): the percentage of the table that is no longer considered for searching\nafter a prediction. Because of the diversity across models to determine the search\ninterval, and in order to place all models on a par, we estimate empirically the\nRFof a model. That is, with the use of the model and over a batch of queries,\nwe determine the length of the interval to search into for each query (the interval\nIin Figure 2). Based on it, it is immediate to compute the reduction factor for\nthat query. Then, we take the average of those reduction factors over the entire\nset of queries as the reduction factor of the model for the given table.\n4 Experimental Methodology\n4.1 Hardware and Datasets\nExperiments have been performed using a workstation equipped with an Intel\nCore i7-8700 3.2GHz CPU and an Nvidia Titan V GPU. The total amount of\nsystem memory is 32 Gbyte of DDR4. The GPU is also supplied with its own 12\nGbyte of DDR5 memory and adopts a CUDA parallel computing platform. CPU\nand GPU are connected with a PCIe 3 bus with a bandwidth of 32Gbyte/s. The\noperating system is Ubuntu LTS 20.04.\nWe have used both synthetic and real datasets, taken from previous studies on\nLearned Indexes [11,18]. The synthetic ones have been generated using random\n\nsampling in [1 ;2r\u00001\u00001], withr= 64. Datasets are sorted and without duplicates.\nWe anticipate that, as evident from the analysis in Section 5, the use of GPU\ntraining for the NNs severely limits the size of the datasets that we can use.\n1.Uni that contains data sample from a Uniform distribution de\fned as\nU(x;a;b ) =(\n1\nb\u0000aifx2[a;b]\n0otherwise(3)\nwherea= 1 eb= 2r\u00001\u00001. Its size is 1.10e+04 Kb and it contains 1.05e+06\nintegers.\n2.Logn that contains data sample from a Log-normal distribution de\fned as\nL(x;\u0016;\u001b ) =e\u0000(lnx\u0000\u0016)2\n2\u001b2\nxp\n2\u0019\u001b(4)\nwhere\u0016= 0 e\u001b= 1 are respectively mean and variance of the distribution.\nIts size is 1.05e+04 Kb and it contains 1.05e+06 integers.\n1.Real-wl that contains timestamps of about 715M requests performed by a\nweb server during 2016. Its size is 3.48e+05 Kb and it contains 3.16e+07\nintegers.\n2.Real-iot that consists of timestamps of about 26M events recorded during\n2017 by IoT sensors deployed in academic buildings. Its size is 1.67e+05 Kb\nand it contains 1.52e+07 integers.\nAs for the query dataset, for each of the above tables, it has a size equal to 50%\nof the reference table and contains, in equal parts, both elements present and not\npresent in the table. For all the experiments, the query datasets are not sorted.\n4.2 Binary Search and the Corresponding Atomic Learned Indexes\nFor the \fnal search stage, in addition to a standard Binary Search method, we\nuse also Uniform Binary Search [17] (see also [16,26]). Indeed, based on work by\nKhuong and Morin [16], it can be streamlined to avoid \\branchy\" instructions\nin its implementation. Such a streamlining results in a speed-up in regard to\nthe standard procedure. The interested reader can \fnd details in [16]. We refer\nto the standard procedure as Branchy Binary Search ( BBS ) and to the other\nversion as a Branch-Free ( BFS ).\nAs for Atomic Models, we use L, Q, andC. Additional Atomic Models are\nobtained via NNs. Indeed, we consider three types of NNs with di\u000berent hidden\nlayers, as speci\fed next. NN0 for zero hidden layers, NN1 for one hidden layer,\nNN2 for two hidden layers, each layer consisting in 256 units.\nEach of the above models provides two Atomic Learned Indexes, one for each\nBinary Search routine used for the \fnal search stage.\n\n5 Experiments and Findings\nWe use the datasets described in Section 4.1. Both training and query datasets\nare transformed, as outlined in Section 3.2, to use them as input of the NNs.\nFor NN training, we use the highly-engineered Tensor\row platform, with GPU\nsupport. The results are reported in Section 5.1.\nAs for queries, we perform the following experiments.\n{ TensorFlow . We have carried out query experiments by uploading the plat-\nform to GPU, in order to perform query searches with the Learned Indexes\nbased on NNs. Because of the overhead to upload Tensor\row in the GPU, re-\nsults are very disappointing and therefore not reported. This is in agreement\nwith considerations in [18].\n{ NVIDIA CUDA Implementation . We use our own implementation of\nthe Learned Index corresponding to NN0 and with BBS for the \fnal search\nstage. The results are reported in Section 5.2. As discussed in that Section,\nthis experiment indicates that the use of the GPU is not advantageous,\neven with respect to the baseline BBS , implemented in a parallel version.\nTherefore, no further experiment on the GPU has been performed.\n{ CPU . In this case, we have performed the entire set of experiments. For\nconciseness, we report the results only with the use of BFS , since the ones\ninvolving BBS would add very little to the discussion. They are reported\nand discussed in Section 5.3.\n5.1 Training: GPU vs CPU\nIn Table 1, we report the training times per element for each method described\nin the preceding Section, and we also indicate the respective RF, computed as\nindicated in Section 3.3. For what concerns Atomic Models L,QandC, the\ntraining time is the time needed to solve Eq. 2. Regarding the NN models, the\nused learning algorithm is stochastic gradient descent with momentum param-\neter equal to 0 :9 and learning rate equal to 0 :1. The Batch size is 64, and the\nnumber of epochs is 2000.\nAs is evident from the results reported in Table 1, even with GPU support and\nthe use of the highly-engineered Tensor\row platform, NNs are not competitive\nwith respect to the L,QandCAtomic Models, both in training time and\nRF. Indeed, for each dataset, the NNs training time per item is four orders of\nmagnitude higher than the one obtained with the non-NN Atomic Models, with\ncomparable RF.\n5.2 Query: GPU Only for NNs\nWe perform an experiment, only on NN0 anduni, to see if there could be a\nreal advantage from using the GPU for queries. In Table 2, we report the query\ntime per element resulting from this experiment. As evident from that Table,\non GPUs, the copy operations from CPU to GPU, and vice versa, cancel the\n\nuni logn real-wl real-iot\nTT (s) RF (%) TT (s) RF (%) TT (s) RF (%) TT (s) RF (%)\nNN0 2.55e-04 94.08% 1.39e-04 54.40% 2.50e-04 99.99% 1.28e-04 89.90%\nNN1 4.18e-04 99.89% 3.79e-04 94.21% 2.31e-04 99.88% 4.20e-04 98.54%\nNN2 4.49e-04 99.87% 8.60e-04 97.14% 2.33e-04 99.8% 3.57e-04 97.31%\nL8.20e-08 99.94% 5.61e-08 77.10% 5.82e-08 99.99% 7.70e-08 96.48%\nQ1.27e-07 99.98% 1.02e-07 90.69% 1.14e-07 99.99% 1.25e-07 99.1%\nC1.84e-07 99.97% 1.74e-07 95.76% 1.24e-07 99.45% 1.63e-07 98.87%\nTable 1: Atomic Indexes Training Time and Reduction Factor . For each datasets and each\nmodel, it is shown: the training time per element expressed in seconds (column TT (s) ) and the\npercentage of the table reduction (column RF (%) ), as described in Section 3.3.\nMethods Copy (s) Op. (s) Search (s) Query (s)\nNN0-BBS 3.27e-08 4.20e-09 1.84e-09 3.27e-08\nBBS 2.55e-09 - 1.89e-09 4.44e-09\nTable 2: Query Time on GPUs .NN0-BBS refers to Binary Search with NN0 as the prediction\nstep, while BBS is the parallel Binary Search executed on GPU without a previous prediction. For\neach of these methods executed on GPU, we report: the time for CPU-GPU, and vice versa, copy\noperations (column Copy (s) ), the time for maths operation (column Op. (s) ), the time to search\ninto the interval (column Search (s) ) and the total time to complete the query process (column\nQuery (s) ). Every time in the Table is per element and is expressed in seconds.\none order of magnitude speed-up of the maths operations. In addition, a classic\nparallel Binary Search BBS on the GPU is by itself faster than its Learned\ncounterparts, making the use of NNs on this architecture unnecessary.\n5.3 Query: CPU Only for All Atomic Models\nThe query experiments results are summarized in Tables 3 and 4. As we can see,\nNNs are also not competitive for the query phase.\nThe query time on NN1 andNN2 is even two orders of magnitude greater\nthan the one obtained with the simple LModel. In addition, in some cases,\nthe transformed dataset is too large to be stored entirely in the CPU memory,\ncausing a space allocation error.\n6 Conclusions\nA perceived paradigm shift is one of the motivations for the introduction of\nthe Learned Indexes. Despite that, the use of a GPU architecture for Learned\nIndexes based on NNs seems not to be appropriate when we use generic NNs\nas we have done here. It is to be pointed out that certainly, the use of a GPU\naccelerates the performance of maths operations, but the data transfer between\nCPU and GPU is a bottleneck in the case of NNs: not only data but also the\nsize of the model matters. When we consider CPU only, NN models are not\ncompetitive with very simple models based on Linear Regression.\nThis research clearly points to the need to design NN architectures special-\nized for Learned Indexing, as opposed to what happens for Bloom Filters where\ngeneric NN models guarantee good performance to their Learned versions. In\nparticular, those new NN models must be competitive with the Atomic Models\n\nDataset BFS NN0-BFS NN1 NN2\nuni 2.81e-07 1.31e-07 1.56e-06 5.16e-06\nlogn 2.08e-07 1.92e-07 1.69e-06 5.24e-06\nreal-wl 3.38e-07 4.59e-07 Space Error Space Error\nreal-iot 3.07e-07 4.76e-07 1.90e-06 1.94e-05\nTable 3: CPU Prediction E\u000bectiveness-NN Atomic Models .NN0-BFS refers to Binary Search\nwithNN0 as the prediction step, while the other two columns refer to the time taken by NN1 and\nNN2 to predict the search interval only. The time is reported as time per query in second. When\nthe model and the queries are too big to \ft in the main memory, a space error is reported.\nDataset BFS L-BFS Q-BFS C-BFS\nuni 2.81e-07 9.42e-08 8.11e-08 9.39e-08\nlogn 2.08e-07 1.60e-07 1.59e-07 1.54e-07\nreal-wl 3.38e-07 5e05e-08 2.12e-7 1.80e-7\nreal-iot 3.07e-07 8.32e-08 1.99e-7 2.57e-7\nTable 4: CPU Prediction E\u000bectiveness-Non NN Atomic Models . The Table reports results\nwith Linear, Quadratic and Cubic models. The Legend is as in Table 3.\nbased on Linear Regression, which are widely used as building blocks of more\ncomplex models [3, 4, 20]. This study provides solid grounds and valuable in-\ndications for the future development of Learned Data Structures, which would\ninclude a pervasive presence of NNs.\nReferences\n1.https://github :com/DomenicoAmato01/A-Benchmarking-Platform-for-\nAtomic-Learned-Indexes .\n2. M. Abadi. TensorFlow: Large-scale Machine Learning on Heterogeneous Dis-\ntributed Systems. http://download :tensorflow :org/paper/whitepaper2015 :pdf,\n2015.\n3. D. Amato, G. Lo Bosco, and R. Giancarlo. Learned Sorted Table Search and Static\nIndexes in Small Model Space. CoRR , abs/2107.09480, 2021.\n4. D. Amato, G. Lo Bosco, and R. Giancarlo. Learned Sorted Table Search and\nStatic Indexes in Small Model Space (Extended Abstract). In Proc. of the 20-th\nItalian Conference in Arti\fcial Intelligence (AIxIA), to appear in Lecture Notes in\nComputer Science , 2021.\n5. C.M. Bishop. Neural Networks for Pattern Recognition . Oxford University Press,\nUSA, 1995.\n6. B. H. Bloom. Space/Time Trade-o\u000bs in Hash Coding with Allowable Errors. Com-\nmun. ACM , 13(7):422{426, 1970.\n7. A. Bo\u000ba, P. Ferragina, and G. Vinciguerra. A \\Learned\" Approach to Quicken\nand Compress Rank/Select Dictionaries. In Proceedings of the SIAM Symposium\non Algorithm Engineering and Experiments (ALENEX) , 2021.\n8. A. Broder and M. Mitzenmacher. Network Applications of Bloom Filters: A Survey.\nInternet Mathematics , 1(4):485{509, 2003.\n9. Z. Dai and A. Shrivastava. Adaptive Learned Bloom Filter (Ada-BF): E\u000ecient\nUtilization of the Classi\fer with Application to Real-Time Information Filtering\non the Web. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin,\neditors, Advances in Neural Information Processing Systems , volume 33, pages\n11700{11710. Curran Associates, Inc., 2020.\n\n10. P. Ferragina and G. Vinciguerra. Learned Data Structures. In Recent Trends in\nLearning From Data , pages 5{41. Springer International Publishing, 2020.\n11. P. Ferragina and G. Vinciguerra. The PGM-Index: A Fully-Dynamic Compressed\nLearned Index with Provable Worst-case Bounds. PVLDB , 13(8):1162{1175, 2020.\n12. D. Freedman. Statistical Models: Theory and Practice . Cambridge University Press,\n2009.\n13. G. Fumagalli, D. Raimondi, R. Giancarlo, D. Malchiodi, and M. Frasca. On the\nChoice of General Purpose Classi\fers in Learned Bloom Filters: An Initial Analysis\nwithin Basic Filters. In Proceedings of the 11th International Conference on Pattern\nRecognition Applications and Methods (ICPRAM) , pages 675{682, 2022.\n14. I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning . The MIT Press, 2016.\n15. A. Hadian and T. Heinis. Interpolation-friendly B-trees: Bridging the Gap Between\nAlgorithmic and Learned Indexes. In Advances in Database Technology - 22nd\nInternational Conference on Extending Database Technology, EDBT 2019, Lisbon,\nPortugal, March 26-29, 2019 , pages 710{713, 2019.\n16. P.V. Khuong and P. Morin. Array Layouts for Comparison-Based Searching. J.\nExp. Algorithmics , 22:1.3:1{1.3:39, 2017.\n17. D. E. Knuth. The Art of Computer Programming, Vol. 3 (Sorting and Searching) ,\nvolume 3. Addison-Wesley, 1973.\n18. T. Kraska, A. Beutel, E. H Chi, J. Dean, and N. Polyzotis. The Case for Learned\nIndex Structures. In Proceedings of the 2018 International Conference on Man-\nagement of Data , pages 489{504. ACM, 2018.\n19. Y. LeCun, Y. Bengio, and G. Hinton. Deep Learning. Nature , 521(7553):436, 2015.\n20. R. Marcus, A. Kipf, A. van Renen, M. Stoian, S. Misra, A. Kemper, T. Neumann,\nand T. Kraska. Benchmarking Learned Indexes. Proc. VLDB Endow. , 14(1):1{13,\nsep 2020.\n21. M. Mitzenmacher. A Model for Learned Bloom Filters and Optimizing by Sand-\nwiching. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,\nand R. Garnett, editors, Advances in Neural Information Processing Systems , vol-\nume 31. Curran Associates, Inc., 2018.\n22. M. Mitzenmacher and S. Vassilvitskii. Algorithms with Predictions. In TimEd-\nitor Roughgarden, editor, Beyond the Worst-Case Analysis of Algorithms , page\n646{662. Cambridge University Press, 2021.\n23. G. E. Moore. Cramming More Components Onto Integrated Circuits. Electronics ,\n38(8), April 1965.\n24. I. Ohn and Y. Kim. Smooth Function Approximation by Deep Neural Networks\nwith General Activation Functions. Entropy , 21(7):627, 2019.\n25. K. Sato, C. Young, and D. Patterson. An In-Depth Look at Google's First Tensor\nProcessing Unit (TPU). https://cloud :google :com/blog/products/ai-machine-\nlearning/an-in-depth-look-at-googles-first-tensor-processing-unit-\ntpu, 2017.\n26. L. Schulz, D. Broneske, and G. Saake. An Eight-Dimensional Systematic Evalua-\ntion of Optimized Search Algorithms on Modern Processors. Proc. VLDB Endow. ,\n11:1550{1562, 2018.\n27. K. Vaidya, E. Knorr, T. Kraska, and M. Mitzenmacher. Partitioned learned bloom\n\flter. ArXiv , abs/2006.03176, 2020.\n28. B. Wang. Moore's Law is Dead but GPU Will Get 1000x Faster By\n2025. https://www :nextbigfuture :com/2017/06/moore-law-is-dead-but-gpu-\nwill-get-1000x-faster-by-2025 :html, 2017.",
  "textLength": 31760
}