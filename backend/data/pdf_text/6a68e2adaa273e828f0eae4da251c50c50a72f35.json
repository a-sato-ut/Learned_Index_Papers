{
  "paperId": "6a68e2adaa273e828f0eae4da251c50c50a72f35",
  "title": "Dynamic Index Construction with Deep Reinforcement Learning",
  "pdfPath": "6a68e2adaa273e828f0eae4da251c50c50a72f35.pdf",
  "text": "Vol.:(0123456789)1 3Data Science and Engineering (2022) 7:87‚Äì101 \nhttps://doi.org/10.1007/s41019-022-00186-4\nRESEARCH PAPERS\nDynamic Index Construction with¬†Deep Reinforcement Learning\nSai¬†Wu1 ¬†¬∑ Ying¬†Li2¬†¬∑ Haoqi¬†Zhu2¬†¬∑ Junbo¬†Zhao1¬†¬∑ Gang¬†Chen1\nReceived: 23 February 2022 / Revised: 14 March 2022 / Accepted: 15 April 2022 / Published online: 6 May 2022 \n¬© The Author(s) 2022\nAbstract\nThanks to the rapid advances in artificial intelligence, a brand new venue for database performance optimization is through \ndeep neural networks and the reinforcement learning paradigm. Alongside the long literature in this regime, an iconic and \ncrucial problem is the index structure building. For this problem, the prior works have largely adopted a pure learning-based \nsolution replacing the traditional methods such as a B-tree and Hashing. While this line of research has drawn much attention \nin the field, they ubiquitously abandon the semantic guarantees and also suffer from performance loss in certain scenarios. \nIn this work, we propose the Neural Index Search (NIS) framework. The core to this framework is to train a search policy to \nfind a near optimal combination plan over the existing index structures, together with the required configuration parameters \nassociated with each index structure in the plan. We argue that compared against the pure learning approaches, NIS enjoys \nthe advantages brought by the chosen conventional index structures and further robustly enhances the performance from any \nsingular index structure. Extensive empirical results demonstrate that our framework achieves state-of-the-art performances \non several benchmarks.\nKeywords Index¬†¬∑ NAS¬†¬∑ Reinforcement learning¬†¬∑ Database tuning\n1 Introduction\nA variety of index structures have been proposed in the liter -\nature. Some of them are included in the commercial DBMS \n(Database Management System), such as B-tree, R-tree and \nHash index, while most others are invented to support spe-\ncific types of applications [1 ‚Äì3]. Indeed, it is a challeng-\ning task to design a new index structure for every particular \napplication. In this paper, we propose NIS, a Neural Index Search approach, to automatically assemble an index from \nexisting index structures for a given dataset and query work -\nload. The only assumption NIS bases on is that the users \ncan provide a function to sort or partition the data, which is \nvery much valid for most applications. Generally, the NIS \nframework first categorizes a variety of index structures \ninto two abstract index building blocks‚Äîordered block and \nunordered block. The ordered block, where keys are sorted \nin ascending order, can be implemented as B +-Tree node. \nOn the other hand, an unordered block, where keys are par -\ntitioned using customized functions, can be implemented \nas hash bucket. Both abstract blocks follow the format of \n[key ,value]+ , where key denotes the indexed key, and value  \nrefers to the pointer to the next index block or the memory/\ndisk address for the data values.\nWe apply the policy gradient algorithm¬†[4 ] to train a rein-\nforcement learning policy model employing a RNN (Recur -\nrent Neural Network) as backbones, which can\n‚Ä¢ Construct a tree-like index in a layer-by-layer way, where \neach layer is a sequence of abstract index blocks parti-\ntioning the search space with a pre-defined function. * Sai Wu \n wusai@zju.edu.cn\n Ying Li \n hzliying3@corp.netease.com\n Haoqi Zhu \n zhuhaoqi@corp.netease.com\n Junbo Zhao \n j.zhao@zju.edu.cn\n Gang Chen \n cg@zju.edu.cn\n1 College of¬†Computer Science, Zhejiang University, \nHangzhou, Zhejiang, China\n2 Netease(Hangzhou) Network Co., Ltd., Hangzhou, Zhejiang, \nChina\n\n88 S.¬†Wu et al.\n1 3\n‚Ä¢ Search the optimal configuration for each index block, \nincluding block type, block size, minimal and maximal \nnumber of keys in a block and etc.\nIn this paper, we focus on the in-memory version of NIS, \nwhere all index data are maintained in memory. Compared to \nthe disk version, in-memory NIS is more challenging because \n(1) the in-memory index can have multiple layers, while the \ndisk-based one is limited to 2‚Äì3 layers; (2) since fragmenta-\ntion does not apply to memory-optimized indexes, each index \nblock can have a customized size; and (3) in-memory index \nis more sensitive to the access patterns. In our experiments, \nNIS outperforms many existing state-of-the-art in-memory \nindexes on various workloads. Moreover, we also provide an \nincremental learning mechanism for NIS. So it can handle the \ncase where query/data distribution changes gradually over \ntime. Our experiments show that if newly inserted data follow \nthe same distribution, indexes generated by NIS can provide \na good performance without any adjustment. If only a few \nportion (e.g., 10%) of new data show a different distribu-\ntion, NIS employs an economic incremental learning model \nto adjust the index configurations. Experiments show that it \nstill provides a better performance than others.\nThe closest work to ours is the Learned Index Struc -\ntures proposed by Google [5 ]. It tries to learn an ordered \nneural mapping function for each key and stack those \nfunctions as a tree index. While being conceptually \npromising, replacing the conventional index structures \nwith learned indexes neglects the semantic guarantees \nand requires a significant amount of engineering efforts. \nBy contrast, NIS adopts a different strategy by searching \nfor the solution of how to combine existing index blocks \nand tune their parameters for specific applications. NIS \ndoes not suffer from the slow prediction of neural models, \nsince once the index has been materialized, they work \nindependently.\nIn summary, we make the following contributions in NIS.\n‚Ä¢ We propose a full-fledged index structure solution to \nsearch and tune the generated indexes for a given dataset \nand query workload accordingly, based on a reinforce-\nment learning paradigm.\n‚Ä¢ We showcase a valid policy network construction by \nemploying a conditional RNN as the backbone, where it \ngenerates multi-layer tree-like indexes, where each layer \nis a list of index blocks and the construction of a layer \ndepends on all existing layers.\n‚Ä¢ On top of the policy network deployment, we develop an \nincremental learning process to support and adapt to the \ngradually updated query patterns.\n‚Ä¢ Experiments with state-of-the-art indexes show that the \nNIS-generated index outperforms the current state-of-\nthe-art results published by prior work.2  Background and¬†Overview\n2.1  Problem Formulations\nGiven a column C  and workload W , how can we generate a \nproper tree-like hierarchical index structure I for C , which \nis tuned to minimize the total processing latency of W  with \na storage budget B, computed as:\nf(qi) returns the latency of processing qi with the existence \nof I . w(qi) represents the weight of qi , which is set as the \nfrequency of qi in W currently. The total storage cost of the \nindex should be less than B.\nIn [5 ], the index block is formalized as a function:\nwhere p is the position of the value referred by the key  and N \nis the total number of keys. The intuition is to learn a cumu-\nlative distribution function (CDF). So we can locate the key \nbased on the estimation of the CDF. As mentioned before, \nwe adopt a different strategy from [5 ]. Instead of learning \nthe CDF, our model tries to predict how data can be parti-\ntioned using basic index blocks. In NIS, two abstract index \nblocks are supported, the ordered index block and unordered \nindex block. We do not intent to invent new index struc-\ntures. Instead, our plan is to reuse existing index structures \nand fine-tune them for our target workloads. Therefore, we \nintroduce two abstract index blocks that can be materialized \nas popular existing index structures.\nDefinition 1 The ordered index block is described as \nIo={S,F,[L,U),pt} , where S denotes a sorted list of keys, \nF is the mapping function, [L ,¬†U) denotes the key range of \nthe block and pt  points to the next sibling block. For Io , we \nhave the properties:\n‚Ä¢ ‚àÄS[i]‚àà S,L‚â§S[i]<U.\n‚Ä¢ S[i]‚â§S[j] , if i<j.\n‚Ä¢ F(S[i])‚â§F(S[j]) , if i<j\nIn the ordered index block, the mapping function F  is \nmaintained as a list of sorted key-value pairs [(ki,vi)‚àó] , where \nki<kj for i<j and vi refers to the position of the index block \nin the next layer or the real data values.\nDefinition 2 The unordered index block is denoted as \nIu={S,H,[L,U),pt} , where S is a set of keys, H  is a \nhash function(currently, we use the standard SHA-1 \nhash function), [L ,¬†U) denotes the key range of the block \nand pt points to the next sibling block. For Iu , we have ct=/uni2211.s1\n‚àÄqi‚ààWf(qi)√ów(qi)\np=F(key)‚àóN\n\n89 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\n‚àÄS[i]‚àà S,L‚â§S[i]<U . The hash function H  maps S [i] into \nthe corresponding bucket which points to the index block of \nthe next layer.\nEach index block can hold up to m  keys. m  can be cal-\nculated by the key size and the cache line size(for memory \nindex) or block size(for disk index). However, the initial \nnumber of keys inside each block(denoted as x ) is a tunable \nparameter, which is learned by the NIS through training. In \nunordered index block, the whole block is maintained as a \nhash table, where we have maximal m buckets and the buck -\nets maintain pointers to index blocks in next layer.\nTable¬† 1 lists the parameters learned by the NIS.\n2.2  Overview of¬†NIS\nThe design of NIS follows the same philosophy of the \nNAS. Figure¬† 1 shows the general architecture. Given a \ndatabase D and query workload W , NIS employs a control-\nler to generate the architectural parameters of an index, \nwhich includes all the parameters listed in Table¬† 1 and \ndecides how the abstract index blocks can be assembled as \nan index. In this paper, the controller is a reinforcement-\nlearning model, implemented as stacked RNNs, which \napplies the policy gradient [4 ] to update its policy. After \nthe controller generates an index architecture, the index \nbuilder materializes the corresponding index and deploys \nit on the database by loading the data. We execute the query workload W  using the index to get the latency and \nspace utilization as our rewards, which are used as feed-\nbacks for the controller to update its policy. In the next \niteration, the controller will generate a new index archi-\ntecture with its updated policy. The process loops, until \nthe controller policy converges. Finally, the controller will \nreturn an optimal index structure for a given database D \nand workload W.\nOne challenging of applying NIS to predict the index \nstructure is the scalability. Suppose we have 10 million \nkeys and each block can hold up to 200 keys. We need at \nleast 50,000 blocks to maintain those keys. In other words, \nthe NIS needs to generate parameters for a large number of \nblocks sequentially. However, existing neural models are dif -\nficult to predict such a long sequence. To reduce the predic -\ntion cost of NIS, we classify the blocks into groups.\nDefinition 3 An index block group G  is a set of index blocks \nresponsible for consecutive key ranges and sharing the same \nparameters.\nWe use a simple example to intuitively describe the role of \ngroup. Suppose the initial number of keys in an index block \nis set as 200. We try to predict the parameters( Block Type  , x, \n/u1D6FC , /u1D6FD ) for its 200 child blocks in the next layer. By adopting \nthe group strategy, we can effectively reduce the prediction \noverhead. Suppose the 200 child blocks are grouped into two \ngroups, consisting of 50 and 150 child blocks, respectively. \nWe only need to predict parameters for two groups, as blocks \nof the same group adopt the same parameter configurations.\nGiven a set of keys in [min,¬† max), to generate a new \nindex, the controller first creates a layer with one index block \nand predicts its parameters. Suppose the block type is set \nas ordered and the initial number of keys is set as x  by the \ncontroller. Namely, the block partitions the key range into x \nsmall ranges R0=[k0,k1) , R1=[k1,k2),..., Rx‚àí1=[kx‚àí1,kx) . \nBy default, we partition the key range evenly. The controller \nstarts building the second layer of index for each range by \nadaptively generating an index block group. The parameters \nof a group are learned by the controller. Besides the single \nblock parameters (  Block Type  , x, /u1D6FC and /u1D6FD ), we need to pre -\ndict parameter y  (the number of blocks in the group). In this \nway, y index blocks are created for each group and the cor -\nresponding key range is partitioned into y non-overlapped \nconsecutive ranges, one for each block.\nInside each group, to facilitate the query, each index \nblock can create skip links up to logy blocks inside the same \ngroup. In particular, suppose current group G  has y  index \nblocks: {B0,B1...,By‚àí1} . For block Ba , it will create a skip \nlink to Bb with a probability pi , if b=a+2i(1‚â§i‚â§logy) \nand b<y . The probability pi is estimated by the controller, \nso we have a parameter /u1D6FE={p1,p2, ...,plogy} , a probability \nvector for creating skip links inside a group.Table 1  Tunable Parameters\nParameter Description\nBlock Type Ordered/unordered\nx The initial number of keys in an index block\ny The number of blocks in a group\n/u1D6FC The block split when more than /u1D6FCm keys possess\n/u1D6FD Two blocks merge when both have less than /u1D6FDm keys\n/u1D6FE Aprobability vector for creating skip links\nCont roller\n(Stacked  RNN)Materializa/g415onIndex Builder\nDatabse\nCompute Gradient of p and scale it \nby Reward to update ControllerSample Index Architecture \nwith probability pIndex \nArchitecture \nReward: \nLatency & Space \nU/g415liz a/g415onLogical\nIndex\nPhysical\nIndexData\nWorkload\nFig. 1  General Idea of NIS\n\n90 S.¬†Wu et al.\n1 3\nThe above index construction process continues for each \nindex block, until no key range has more than /u1D6FDm keys. In \nthis way, we may generate an imbalanced index search tree \nwith skip links inside each block group.\nThe controller outputs its final decision as a sequence \nof operations, which are read by the index builder for con-\nstruction. The index builder adopts a streaming approach to \nmaterialize the index. In particular, it first creates an abstract \nindex by stacking the index blocks predicted by the control-\nler. Then, it reads in the data and applies the data stream to \nmaterialize the index. During materialization, block separa-\ntion and merging may occur. If block bi is split into bi and b/uni2032.var\ni , \nthe new generated block b/uni2032.var\ni will share the same parameters \nof bi . However, if the controller generates a good prediction, \nwe do not need to split data blocks frequently. To speed up \nthe index construction, the index builder employs multiple \nthreads to assemble the index. Finally, the index is deployed \non the database and tested against the given workload to get \nthe corresponding latency and space utilization.\nAs an example, Fig.¬† 2 shows an index generated by NIS. \nThe blue and yellow nodes represent the ordered and unor -\ndered index blocks, respectively. The green part is a detailed \ndescription of the skip links inside a group. For simplic-\nity, we only show the segmentation details of the first index \nblock in each group. To process a query, we start from the \nroot block as searching a B +-tree. When reaching a group, \nwe pick the skip links to simulate the search process as the \nskip-list.\nBy learning different parameters, NIS can simulate dif -\nferent types of conventional indexes, such as:\n‚Ä¢ B+-tree All the index blocks are ordered blocks with the \nsame configuration of m  and /u1D6FC and /u1D6FD are set to 1 and 0.5, \nrespectively. y is set as 1 for all groups.\n‚Ä¢ Hash All the index blocks are unordered blocks and the \nindex only has one layer.‚Ä¢ Skip-list Each layer only has one index group and the \nupper layer group has fewer blocks (a smaller y).\n¬†¬†¬†¬†¬†¬†¬†¬†¬†It can be seen that the large search space of NIS allows \nus to explore more new index structures by combining dif-\nferent existing index structures for specific workloads and \ndatasets.\n3  Implementation of¬†Controller\nIn this section, we show how the controller learns to predict \nthe parameters for the index. We first discuss the architecture \nof our neural model and then elaborate on how the training \nprocess works.\n3.1  The Architecture of¬†Controller\nAnalogous to NAS [6 ], we consider the prediction of param-\neters as a task of sequence prediction since the list of the \nblock configurations of each layer can be viewed as a param-\neter sequence, a variable-length string. The controller pre-\ndicts one parameter at a time which is conditioned on previ-\nous predictions. Therefore, the backbone of our controller \nis a RNN network powered by the LSTM [7 ], which works \nwell for prediction of long sequences. Figure¬† 3 illustrates \nthe basic architecture of the controller. The controller con-\nsists of multiple layers of LSTMs to predict a tree-like index \narchitecture, which can be expressed as multiple parameter \nsequences. The index architecture is constructed in a top-\ndown manner. The new layer will use the hidden states of \nprevious layers as the context during its prediction.\nOur model consists of a basic building block as shown \nin the bottom left part of Fig.¬† 3. The neural block predicts \nthe six parameters ( Block Type , x, y, /u1D6FC , /u1D6FD and /u1D6FE ) for an index \nblock group as a sequence via the RNN model. The whole \nblock consists of three neural layers, an embedding layer, a \nLSTM layer and a softmax layer.\nThe bottom layer is an embedding layer, formalizing the \ninput as a binary vector representation. For the first time step \nof the RNN, the min/max values of the keys, the number of \nunique keys and a coarse histogram are transformed into \nbinary vectors and concatenated together as the input. For \nthe following time steps, the generated vector from the soft-\nmax layer for previous state is used as the input, because the \nparameter prediction of the current time step are conditioned \non previous prediction.\nThe middle layer applies the LSTM to learn the correla-\ntions between different time steps. Selections of previous \nparameters affect the choices for the following ones.\nThe top layer is a softmax layer for prediction. We \ntransform our task into a classification problem by creat-\ning a set of pre-defined values for each parameter and only Data Bloc ksUnordered block\nOrdered block\nFig. 2  An Example Index Generated by NIS\n\n91 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\nallowing the neural model to pick one of the pre-defined \nvalues. Table¬† 2 lists our current pre-defined values. The \nparameter /u1D6FE has no default values, since it depends on the \nvalue of y . Specifically, we will generate a probability vec-\ntor {p1,p2, ...,plogy} indicating whether to create skip links \nto the neighboring logy blocks in the same group. The skip \nlink between index block Ba and Ba+2i will be established \nwith a probability pi.\nThe basic neural blocks are chained together to predict the \nparameters for index block groups. After successfully gener -\nating the prediction for one layer of index, the controller can \nstart up a new layer, if some index blocks need to be further \npartitioned. Then, the hidden states of current layer are used \nas the context during the prediction for the next layer.\nFigure¬† 3 illustrates the idea. The outputs from the softmax \nlayer of a neural block are concatenated together and used \nas input to the neural blocks in the next layer. The neural \nblock predicts the initial number of keys as x and the number \nof blocks in a group as y , indicating that all y  blocks in the \ncurrent group will be divided into x  sub-ranges, resulting \ninto a total of x√óy sub-ranges. If we continue to divide and \nbuild the next layer, we will use both the hidden outputs and \nsoftmax outputs of current neural block as the contexts for \nneural blocks in the following layer. In this way, we can pro-\ngressively generate the parameters for a multi-level index, \nwhich, in fact, can simulate most existing index structures.\n3.2  Training the¬†Controller\nThe parameter sequences generated by the controller \ncan be considered as a series of operators a1‚à∂t (opera-\ntors from the start to time t ) which are used to construct a new index for a given workload W  and database D . At \nconvergence, the new index is integrated into D  and we \ntest it against the workload W . The total processing time \nct and the index space utilization cost cs (the percentage \nof the index that has been used for maintaining keys) are \nour main concerns. So the evaluation metric is defined as \nfollows, which is called reward :\ncb is the baseline processing time without any index and /u1D70C \nis a tunable parameter to balance the importance of the two \nterms. We have conducted experiments to show the effect \nof /u1D70C.\nWe have more than 1000 parameter combinations \nfor just one index block group. For datasets containing \nmore than 100 million keys, we have thousands of block \ngroups, resulting in millions of parameters for search. \nWhen the number of blocks increases, the exploration \nspace becomes very large. Besides, the metric that our \nmethod needs to optimize is non-differentiable. So, we \nuse the Reinforcement Learning which can learn directly R=/u1D70Ccb‚àíct\ncb+(1‚àí/u1D70C)csFig. 3  The Neural Model of NIS\nTable 2  Pre-defined Values\nParameters Values\nxm\n4 , m\n2 , 3m\n4 , m\ny 32, 64, 128, 256\n/u1D6FC 0.6, 0,7, 0.8, 0.9, 1\n/u1D6FD 0.1, 0.2, 0.3, 0.4, 0.5\n\n92 S.¬†Wu et al.\n1 3\nfrom the reward signal. Since we cannot get a single-step \nreward1, we can only learn the policy of actor, not critic, \nso we choose the policy-based reinforcement learning \nmethod.\nTo find the optimal index, we ask the controller to maxi-\nmize its expected reward, represented as J(/u1D703) . We use /u1D703 to \ndenote all parameters of the controller model. We have:\nThe reward R  is achieved by monitoring the performance of \ndatabase D and, hence, is not differentiable. We apply the \npolicy gradient strategy as in [4 ]:\nT is the total number of parameters for predicting and b is \na baseline function to reduce the variance of the reward. \nIn fact, b is the exponential moving weighted average of \nreward. Let /u1D707 be the aging factor. b(n) in nth training sample \nis recursively defined as\nAs a result, b(n) can be estimated as:\nEquation¬† 1 shows how the parameters /u1D703 of the controller \nnetwork are updated based on the reward R  gradually, which \nis represented as\nwhere /u1D70E is the learning rate.\nIn practice, we use the exhaustive weighted summation \nform to replace the expected value in Eq.¬† 1. If we have \nenough training samples, we can estimate the ‚àáJ(/u1D703) as (N \nis the batch size of the controller):\nIn our experiments, we find that a small N  is good enough \nfor the model to converge to a satisfied result.\nThe intuition of policy gradient is to increase the prob-\nability of P(at‚à£at‚àí1) , if R‚àíb is positive. Otherwise, we \ndecrease the probability. However, during the training \nprocess, we find that if P(at‚à£at‚àí1) is large enough, R‚àíb J(/u1D703)=E1‚à∂T;/u1D703[R]\n(1) ‚àáJ(/u1D703)=EP(a1‚à∂T;/u1D703)T/uni2211.s1\nt=1(R‚àíb)‚àá logP(at‚à£at‚àí1)\nb(n)=/braceleft.s30 ifn=0\n/u1D707b(n‚àí1)+(1‚àí/u1D707)R(n)n‚â•1\nb(n)=(1‚àí/u1D707)(R(n)+/u1D707R(n‚àí1)+/u1D7072R(n‚àí2)+‚ãØ+/u1D707t‚àí1R(1))\n/u1D703‚à∂=/u1D703+/u1D70E‚àáJ(/u1D703)\n(2) ‚àáJ(/u1D703)=1\nNN/uni2211.s1\nn=1T/uni2211.s1\nt=1(R(n)‚àíb(n))‚àálogP(a(n)\nt‚à£a(n)\nt‚àí1)will be always positive (because the model gives up on \nexploring new results and sticks to current sub-optimal \none), causing P(at‚à£at‚àí1) to converge to 1. On the con -\ntrary, if P(at‚à£at‚àí1) is very small, R‚àíb will be negative in \nmost estimations, and hence, P(at‚à£at‚àí1) will converge to \n0. In both cases, we obtain a local optimal results. To avoid \nsuch problems, we clip the sample data and only update the \nprobabilities within [/u1D716,1‚àí/u1D716] , where 0< ùúñ << 1.\nSimilar to other policy gradient approaches, the training \nprocess lasts for days, since we need to build each predicted \nindex and performs benchmarking to gather corresponding \nrewards. To speed up the training process, we apply two \noptimization techniques.\nWe generate a set of probabilities after the softmax layer \nof the controller. They are used to select the parameters. \nFor example, we obtain the probabilities [p1,p2,p3,p4] for \nparameter y, indicating that we may set y as 32, 64, 128, \n256 with probabilities p1 , p2 , p3 and p4 , respectively. In \nvalue-based learning approach, it was shown that random \nexploration can speed up the convergence. We adopt this \napproach for our policy-based approach. In particular, we \nask the controller to ignore the generated probabilities and \nrandomly pick a value for a parameter with a pre-defined \nprobability /u1D706 . But we only use it in the first few epochs of \ntraining. Initially, /u1D706=1 to allow a fast random exploration \nand quickly, we decrease /u1D706 to 0.\nThe training of vanilla policy gradient approach is \nextremely slow due to a large exploration space and the long \ninteraction time of building the index and getting the reward. \nA new approach, PPO(Proximal Policy Optimization) [8 ], \ncan be used to facilitate the parameter updates. In policy \ngradient, we update model parameters, only when we obtain \nnew training samples. This strategy is called ‚Äúon-policy‚Äù \nstrategy. Instead, in PPO, we create a new controller model \n/u1D703/uni2032.var , which is employed with the environment(in our case, \nthe index builder and database) to get training samples. The \ntraining samples obtained from /u1D703/uni2032.var are repeatedly used by the \nreal model /u1D703 , so that parameters of /u1D703 get multiple updates for \none sample, which significantly reduce the time overhead of \ninteracting with the environment. This is called ‚Äúoff-policy‚Äù \nstrategy.\nUsing PPO, Eq.¬† 1 is rewritten as:\nHowever, if the distribution of /u1D703/uni2032.var and /u1D703 differs a lot, the \napproach may not work. So, PPO introduces the KL-diver -\ngence to balance the difference between two distributions. \nThe equation is further revised as:(3) EP(a1‚à∂T;/u1D703ÔøΩ)T/uni2211.s1\nt=1/bracketleft.s3p/u1D703(at‚à£at‚àí1)\np/u1D703ÔøΩ(at‚à£at‚àí1)(R/u1D703ÔøΩ‚àíb)‚àá logp/u1D703(at‚à£at‚àí1)/bracketright.s3\n1 Single-step reward requires that only one parameter is predicted \neach time. However, such a reward cannot be obtained, because we \nmust establish the whole index structure before we can deploy it on \nthe database.\n\n93 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\nwhere /u1D719 is a hyper-parameter that controls the penalty of \nKL divergence.\n3.3  Incremental Updating\nAs mentioned before, most applications have a stable data \nand query distribution. So we can learn an index to achieve \na good performance. However, data and query will slowly \nevolve. Hence, we design an incremental updating model, \nwhich is a by-product of the controller. In other words, we \nreuse training samples from controller to build the incre-\nmental updating model.\nThe intuition of incremental updating model is to learn a \nperformance prediction function G . Given a data distribu-\ntion D , query distribution Q and specific index I , G(D,Q,I) \nreturns the estimated processing latency of Q . We use equi-\nwidth histograms to maintain data distribution and query dis-\ntribution. We generate a vector representation for each index \nblock by encoding its configuration parameters. Finally, G  is \nlearned through a tree structured LSTM model [ 9]. Figure¬† 4 \nshows the architecture of our model.\nWe train a neural block for each index block group and \nconnect them as a tree structure, where parent node accepts \nhidden states from its child nodes as context for prediction. \nAll neural blocks actually share the same network param-\neters trained with samples from controller. During the train-\ning of a controller, we obtain an index structure under a spe-\ncific data distribution D and query distribution Q . We collect \nthe statistics of the processing latency for each index block. \nIf a block is a leaf block, its latency is its total cost of pro-\ncessing queries. If the block is an internal block, its latency (4)J/u1D703ÔøΩ\nPPO(/u1D703)=J/u1D703ÔøΩ(/u1D703)‚àí/u1D719KL (/u1D703,/u1D703ÔøΩ)\n=EP(a1‚à∂T;/u1D703ÔøΩ)T/uni2211.s1\nt=1/bracketleft.s3p/u1D703(at‚à£at‚àí1)\np/u1D703ÔøΩ(at‚à£at‚àí1)(R/u1D703ÔøΩ‚àíb)/bracketright.s3\n‚àí/u1D719KL (/u1D703,/u1D703ÔøΩ)includes both its own cost and the accumulative costs of all \nits descendants. Then, we train a performance prediction net-\nwork G to predict the cost of each index block. The network \naccepts D , Q , index configuration I of the block and hidden \nstates from child nodes as input. It outputs a hidden state \nwhich is further applied to generate predictions for inter -\nnal nodes. Since we do not need a very precise estimation \nof latency, we transform the prediction into a classification \nproblem, where we create 100 different performance classes \nand pick the class with maximal probability.\nWe consider queries in Q as a training batch and also \npropose a batch loss function. The loss function is based on \nthe KL-divergence:\nwhere i is a performance class, P (i) and Q (i) indicate how \nmany queries are assigned to class i in the prediction and \nreal statistics.\nThe tree-LSTM is trained together with the controller. \nThen, it is applied to help us identify performance outli-\ners. During the query processing, we collect the statistics \nof our index and use it to make a prediction for the per -\nformance periodically. Let x0 be the initial performance of \nan index block after the last update. We use xt and x/uni2032.var\nt to \ndenote its predicted performance and real performance at \nthe tth epoch. An index block is marked as an outlier if \nxt‚àíx0>ùúî x0 . /u1D714 can be tuned to balance the index tuning \ncost and processing cost.\nTo reduce the tuning cost, we identify the outliers in a \nbottom-up way. If an index block is outlier, we continue to \ncheck its parent. If all child blocks are not outliers, we stop \nthe check for this block.\n4  Processing of¬†the¬†Index\nIn this section, we introduce how the predicted index can be \nmaterialized as a physical index, and how the index can be \napplied to process queries and updates.\n4.1  Index Materialization\nThe index construction is performed in two steps. In the first \nstep, the index builder loads the parameter predictions from \nthe controller, which are indexed in a key-value store, to \nbuild a logical index. The logic index establishes the general \nstructure of the index, but cannot support queries. In the \nsecond step, index builder scans data and feeds them into \nthe logical index in a streaming way. The logical index fills \nin detailed key ranges and builds necessary pointers, which \nare finally materialized as a physical index.loss =/uni2211.s1\niP(i) logP(i)\nQ(i)Fig. 4  A Tree-LSTM for Incremental Updating\n\n94 S.¬†Wu et al.\n1 3\n4.1.1  Logical Index\nTo create the logical index, we first set up the parent-child \nrelationships between index groups. The left index in Fig.¬† 5 \nshows a logical index (to simplify the diagram, the skip \nlinks are not shown). During the construction of the logical \nindex, we create the parent-child pointers, the key ranges of \neach index blocks and the skip links inside each index block \ngroup. Algorithm¬†1 shows the workflow of how the logi -\ncal index is established. If parent node is an ordered block, \nwe split its key range evenly and assign to each child block \ngroup. Otherwise, child block groups will share the same \nkey range with their parent block, because the hash function \nwill project keys into random block groups. Algorithm¬†2 \nillustrates how an index block group is set up. First, it parti-\ntions the key range evenly and generates a fixed number of \nindex blocks based on the predicted parameters. Then, it \ncreates multiple skip links with the probabilities specified \nin the parameters.\nAlgorithm 1Logical Index\nInput: ParentBlockp,ParameterInde xin\nOutput: RootoftheIndex\nfori=1to p.xdo\nifpisordered blockthen\nr=[p.L+(p.U‚àíp.L)( i‚àí1)\np.x,p.L+(p.U‚àíp.L)i\np.x)\ng=CreateIndexBlo ckGroup (r,i,in)\np.chi ld[i]=g\nelse\nr=[p.L, p.U)\ng=CreateIndexBlo ckGroup (r,i,in)\np.chi ld[i]=g\nend\nendAlgorith m2 CreateIndexBlo ckGroup\nInput: Range r,Idi,ParameterIndex in\nOutput: pointeroftheindex blockgroup\nparams=in.getP arameters( i)\nList group=‚àÖ\nforj=1toparams.y do\nr/prime=[r.L+(r.U‚àír.L)(j‚àí1)\nparams.y,(r.U‚àír.L)j\nparams.y)\nIndexBl ockB=new IndexBl ock(params,r/prime)\ngroup.add( B)\nend\nforj=0toparams.y -1do\nIndexBlo ckB=group.get( j)\nfork=1tologydo\ntarget=j+2k\niftarget>params.y then\nbreak\nend\n¬Øp=rolladice\nif¬Øp‚â§params.Œ≥ [k]then\nIndexBl ockB/prime=group.get( target)\ncreateaskip linkbetweenBandB/prime\nend\nend\nend\nIf all index blocks are ordered blocks, the generated index \nstructure is similar to the B +-tree. However, if unordered index \nblocks are adopted, the index structure becomes a hybrid one. \nFor the left index in Fig.¬† 5, suppose x  is 2 for the root index \nblock group. The first index block group and second index \nblock group at level 2 are responsible for the key range [0, 99] \nand [100, 199], respectively. The first group is ordered blocks Fig. 5  Materialization of the Index\n\n95 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\nand suppose its y is set as 3. We create three ordered index \nblocks inside the group and partition the key range evenly as \n[0, 33], [34, 66] and [67, 99]. The second index block group \nin level 2 is unordered index group. If y=4 , we will create \nfour unordered blocks by partitioning the key range [100, 199] \nuniformly. Because unordered block applies hash functions to \nmap keys to its child block groups, the child block groups share \nthe same key range with their parent. For example, group 4 \nand group 5 all have the key range [100, 124]. However, group \n4 creates 3 blocks and group 5 creates 2 blocks. Note that in \nour index, two index block groups may have overlapped key \nranges, but for the index blocks in the same group, they always \nmaintain sorted non-intersected ranges.\n4.1.2  Physical Index\nThe logical index cannot be applied to process queries, since \nit does not set up the pointers to data. In the second phase, the \nindex builder loads data from the disk and feeds them to the \nlogical index to materialize the index. The right index in Fig.¬† 5 \nshows the corresponding physical index for the left logic index. \nThe materialization process mainly handles three tasks: \n1. Update key ranges of index blocks. The key range of \neach block in logical index is just a rough estimation. \nDuring the materialization process, we maintain a set of \n[Min, Max] values for each block, indicating the actual \nminimal and maximal keys in each key range. After all \ndata have been processed, we shrink the key ranges of \nan index block by the values. This helps us reduce the \nsearch cost by filtering the blocks as early as possible.\n2. Set up hash tables for unordered blocks. As shown in \nFig.¬†5, when data are streamed over an unordered block, we will set up the corresponding hash table. Suppose \nthere are x  child index block groups and the next key is \nk. k will be routed to the i th group, where i=hash(k )%x . \nTo help the search, we also create a bloom filter for each \nunordered block to check whether a key exists or not.\n3. Create pointers to disk data. When a key is routed to the \nbottom level of the index, we will create a pointer from \nthe key to the disk offset of the corresponding record. For \nsecondary index, one key may refer to multiple records. \nThen, we will merge them as a sorted list for disk offsets.\nAlgorithm 3Materializatio n\nInput: BlockGrou pG,TupleT,OÔ¨ÄsetO\nOutput: theindex structure\nifGisordered blockgroupthen\nB=G.Ô¨ÅndOv erlapp edBlo ck(T.k)\nifBisatthebottom level then\nB.insert( T.k,O)\nelse\ni=B.Ô¨Ånd(T.k)\nB[i].updateMinMax( T.k)\nMaterialize( B[i],T,O)\nend\nelse\nB=Ô¨ÅndOv erlapp edBlo ck(T.k)\nifBisatthebottom level then\nB.hash [T.k]=O\nelse\ni=B.hash (T.k)%B.x\nB[i].updateMinMax( T.k)\nB.updateBlo omFilter( T.k)\nMaterialize( B[i],T,O)\nend\nend\nAlgorithm¬†3 summarizes the whole materialization \nprocess. For a new tuple T  and its disk offset O , we first \nretrieve the block whose key range overlaps with T .k. If \ncurrent group is at the bottom level, we just insert the \nkey and its offset. Otherwise, we forward the tuple to the \ncorresponding child group. The same process repeats for \nthe unordered block group. The only difference is that \nwe apply the hash function to map the tuple to a specific \nchild group.\nThe right index in Fig.¬† 5 is the materialized index for the \nleft one. We can find that the key ranges of index blocks \nare shrunk. E.g., the ranges of group 1 change from [0, \n199], [200, 399], [400, 599], [600, 799] to [0,198], [212, \n352],[429, 579], [654, 760]. The hash tables have been set \nup (we show the hash table of the third block in group 3). Fig. 6  Processing of Lookup Queries\n\n96 S.¬†Wu et al.\n1 3\nNote that we do not need to maintain the hash tables explic -\nitly. We only need to know which hash function is being \napplied. Finally, we create the links from the keys to their \ndisk offsets in the bottom level. Note that in Fig.¬† 5, the gray \nnodes indicate that the nodes are empty, since their key \nranges do not contain any keys. During the materialization, \nan index block at bottom layer may be overloaded during \nthe materialization process, triggering the block splitting \noperation. We will discuss this issue in our index update \nsection.\n4.2  Search Via Index\nAfter the index has been materialized, we can apply it to \nprocess queries. In this paper, we focus on the lookup and \nrange queries. As a hybrid index, our search process is a \ncombination of B +-tree, Hash and skip-list. We use two \nexamples in Figs.¬† 6 and 7  to demonstrate the lookup and \nrange queries, respectively.\nSuppose a lookup query retrieves the key ‚Äú167‚Äù. The \nsearch process works as follows. We first check the root \nblock group(Group 1). Because the second key range of the \nfirst block contains 167, we route the query to the second \nchild index group of the first block(Group 3). In group 3, the \nkey ranges of the first block do not contain the key. So we \nroute the queries based on the skip link to the third block. \nThen, we apply the hash function to retrieve the next index \ngroup(Group 7). Before forwarding the query to group 7, \nwe also test it against the bloom filter of the block. If bloom \nfilter returns a positive result, we continue the query in group \n7. Since no skip link is set up in group 7, we scan the blocks \none by one until reaching the third one, where the key is \nlocated.Algorithm 4Lookup\nInput: Keyk,Grou pG\nOutput: disk oÔ¨Äset ofthetuple\nB=G.SkipListSearc h(k)\nifBisanordered blockthen\nifBisatthebottom level then\nreturn B.Ô¨Ånd(k)\nelse\ni=B.Ô¨Ånd(k)\nLookup( k,B[i])\nend\nelse\nifnotB.bloomÔ¨Ålter( k)then\nreturn NULL\nend\nifBisatthebottom level then\nreturn B.hash [k]\nelse\ni=B.hash [k]%B.x\nLookup( k,B[i])\nend\nend\nAlgorithm¬†4 gives the pseudo-code for the lookup. \nThe function SkipListSearch simulates the search of skip \nlist, where we follow the skip link which points to the \nblock satisfying: either its key range contains the key or \nits maximal key is the largest maximal key smaller than \nthe search key. For the range query [118, 124] in Fig.¬† 7, \nwe start the same process as the lookup query. The main \ndifference is how the query is processed when reaching an \nunordered block group(Group 3). The query overlaps with \nthe first block. But a hash function may distribute the \nkeys to all the child block groups (Group 4 and Group 5). \nSo the range query should be forwarded to both groups. \nInside each group, we follow the skip link to locate the \nsmallest key and then scan the remaining blocks until \nreaching the largest key. We discard the details of range \nsearch algorithm.\n4.3  Update of¬†the¬†Index\nDuring the index materialization, blocks at the bottom level \nmay be overflowed, if more than /u1D6FCm keys are inserted. This \nwill trigger a node splitting operation. If the controller gen-\nerates a good estimation for the data distribution, this prob-\nlem can be partially avoided by generating an index tailored \nfor the data distribution.\nOne key design philosophy of the NIS is that the index \ndoes not need to be balanced. It may create more levels of Fig. 7  Processing of Range Queries\n\n97 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\nblocks for high-density data partition to facilitate the search. \nThe unbalanced assumption reduces the complexity of node \nsplitting and merging, since we can limit node splitting and \nmerging to the groups at bottom level and do not propagate \nto the upper level.\nWhen a bottom index block has more than /u1D6FCm keys, we \nsplit the block evenly into two new blocks. The new blocks \nshare the same parameters as they reside in the same group. \nThe splitting does not affect the parent block, since the key \nrange of the index group does not change. However, we need \nto update the skip links, since new blocks are inserted into \nthe group.\nThe merge process follows the same strategy as the split \none. Two consecutive blocks are merged together when both \nblocks have less than /u1D6FDm keys. And we update the skip links \nof the new block. During the insertion and deletion, we \nalso need to handle the changes of key ranges. As shown in \nFig.¬†5, the initial key ranges are setup during the materializa-\ntion process. When a new key ‚Äú150‚Äù is inserted, no existing \nindex blocks can hold the key. So we need to find the nearest \nblock to expand it key range. We called the process, expand-\ning. The nearest block is defined as block B  in the group with \nthe minimal min (/uni007C.varB.L ‚àík/uni007C.var,/uni007C.varB.U ‚àík/uni007C.var) , where [B .L,¬†B.U] is \nB‚Äôs key range.\nIn Fig.¬† 5, the insertion process invokes the expanding \nfunction for group 3, who finds the closest block to key \n‚Äú150‚Äù is the third one and expands its range from [151, 174] \nto [150, 174]. Since this is an unordered block, it applies the \nhash function to decide which child index group should han-\ndle the insertion. Suppose it is group 6, who has one empty \nblock and one block for [164, 172]. The empty block has the \nhighest priority during the expanding process. So key ‚Äú150‚Äù \nwill be stored at the empty block, which updates its range as \n[150, 150]. The deletion process follows the same strategy \nby introducing a range shrinking processing. We will not \nelaborate the details.5  Experiments\nWe train the NIS using two servers sharing the same hard-\nware configurations (Xeon CPU 32 cores, 64GB DDR3 \nRAM, 2MB L2 and 20MB L3 and NVIDIA GTX TITAN \nX). One server is dedicated to the training process of con -\ntroller and the other one is used for index materialization \nand evaluations. We employ four datasets for evaluations: a \nsynthesis uniform dataset (uniform64) and three real datasets \n(amzn, facebook, osmc). All datasets have 200 million keys. \nDetailed descriptions of the datasets can be found in [10].\nFor comparison purpose, we use the open-sourced imple-\nmentations of B +-Tree, SkipList, ART [11], FAST [12], Bw-\nTree [13], Learned Index [5 ] (denoted as RMI) and PGM \n[14] as our baselines2. All indexes are in-memory indexes \nand no disk I/Os are involved.\n5.1  Training the¬†NIS\nWe first show the training performance of the controller \nfor the osmc64 dataset with 1 million read-only workloads. \nDuring our training, the batch size of the controller is set \nas 16. Namely, it will generate 16 different index structures \nin one batch. To obtain proper rewards, those indexes are \nmaterialized by the index builder and deployed to be evalu-\nated against the pre-defined workloads. The training pro-\ncess for one batch is considered as an epoch for the learning \nmodel. The training time is mainly composed of three parts: \ncontroller prediction, index materialization, and workload \nexecution.\nWe tested different data size from 1 million to 100 mil-\nlion. Figure¬† 8a illustrates that the controller can converge \nto a quite good value in only a few epochs (less than 5). \nFigure¬† 8b shows the training time for different data volumes. 05 10 15 20 25\nEpoch\n(a)01000200030004000Latency per query(ns)Convergenc e\n100M\n10M\n1M\n05 10 15 20 25\nEpoch\n(b)01000200030004000Training Time (s)Training Time\n100M\n10M\n1M\n05 10 15 20 25\nEpoch\n(c)10-310-210-1100101102103Materialization Time (s)Materialization\n100M\n10M\n1M\n600 700 800 900\nLatency per query(ns)\n(d)0.990.9920.9940.9960.9981Space UtilizationReward Function\nFig. 8  Training of the Controller\n2 https:// github. com/ learn edsys  tems/ rmi\n\n98 S.¬†Wu et al.\n1 3\nAfter the index structure has been predicted, we need to \nconstruct the index on the database system. Figure¬† 8c shows \nthe cost of index materialization. The materialization cost \nreduces during the training, since the index structure has \nbeen cached and is only partially updated in the following \nepochs.\nThe reward function used in the controller is a combi-\nnation of the processing latency and index space utiliza-\ntion cost. We use parameter /u1D70C to tune the weights of the \ntwo terms. Figure¬† 8d shows the effect of different reward \nfunctions. When /u1D70C=0 , we only consider the space utiliza-\ntion and hence the generated index is almost full. On the \nother hand, if /u1D70C=1 , the latency is the only concern. We \nobserve that by tuning parameter /u1D70C , we can achieve a trade-\noff between the latency and space utilization. In the follow -\ning experiments, /u1D70C is set as 1 to minimize the search latency.\nIn addition, the system storage overhead consists of the \nstorage cost of the policy network and the constructed index. \nIn our experiments, we set the hidden size of LSTM to 256 \nand the layer to 4. For different datasets with 200 million \nkeys, our network parameters are about 10M. However, \nthe learning model is only employed to predict the index \nstructure. During running time, the learning model is not \ninvolved in the query processing. In fact, the size of index \nis not determined by neural architecture but the dataset. So \nwe only consider the storage cost of the constructed index \nwhen comparing with other indexes. Figure¬† 9 reveals that on \nuniform64, NIS and RMI require 19MB and 11MB, respec-\ntively, while on osmc64, NIS(21M) incurs less overhead than RMI(40M). This is because the complex CDF of osmc64  \nrequires more network parameters for RMI, while NIS is \nless influenced by the complexity of distribution. Figure¬† 9 \nreveals that the complex CDF of osmc64 requires more net-\nwork parameters for RMI, while NIS is much less influenced \nby the complexity of distribution.\n5.2  Performance of¬†Lookup‚ÄëOnly Workload\nIn this experiment, we compare the NIS with other baseline \napproaches. We generate 10 million single key lookup que-\nries following the same distribution with the corresponding \ndataset. Namely, we have more queries for high-density data \nranges.\nFigure¬† 10 shows the performances of different approaches \non different datasets. The y-axis denotes the average process-\ning cost of queries in nano-seconds.\nuniform64 is a synthetic dataset with uniform distribu-\ntion and is easier to simulate with neural models. Hence, \nRMI performs best on the uniform64, followed by our NIS. \nThe reason is that NIS still maintains the structures of con-\nventional indexes, incurs additional overhead, while RMI is \nmore flexible by adopting a new index design. osmc, amzn  \nand facebook are three different real datasets. Due to com-\nplex distributions, it is challenging for the RMI to precisely \nmodel the data, especially for the most complex dataset \nosmc64. So the performance of RMI may not be as good \nas some baseline indexes. On the contrary, NIS is able to \nlearn the optimal index architecture for a given dataset and \nworkload distribution.\n5.3  Performance of¬†Mixed Workload\nIn this experiment, we focus on two datasets, osmc and uni-\nform , and generate four different workloads. W1 denotes the \nworkload that we used in previous experiment (10 million \nlookup queries). W2 contains 1 million range queries with \na selectivity 0.1%. W3 mixes 5 millions lookups and 5 mil-\nlions insertions. W4 mixes 2 millions lookups, 2 millions uniform64\nNISR MI PGMB +tree0102030Storage overhead(M)osmc64\nNISR MI PGM B+tree010203040Storage overhead(M)\nFig. 9  Storage Overhead\nosmc64\nB+treeARTRMINIS\nMasstree\nBwtreePGM020040060080010001200Latency per query(ns)uniform64\nB+treeARTRMINIS\nMasstree\nBwtreePGMFAST020040060080010001200Latency per query(ns)amzn32\nB+treeARTRMINIS\nMasstree\nBwtreePGMFAST020040060080010001200Latency per query(ns)face64\nB+treeARTRMINIS\nMasstree\nBwtreePGMFAST0200400600800100012001400Latency per query(ns)duplicate64\nB+treeARTRMINIS\nMasstree\nBwtreePGM020040060080010001200Latency per query(ns)\nFig. 10  Performance of Lookup-Only Workload\n\n99 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\ninsertions and 1 million range queries (selectivity = 0.1%). \nWe show the average query processing cost in nano-seconds. \nFigure¬† 11 shows the results. RMI is only shown in W1 and \nW2, because current open-sourced RMI implementation \ndoes not support updates.\nWe observe that for range workload and mixed workload, \nNIS shows a superior performance than the other indexes \nboth on uniform dataset and real dataset.\n5.4  Performance of¬†Incremental Learning\nNIS assumes that data and query distributions of an appli-\ncation only change slowly and we propose an incremental \nlearning technique to periodically update our index struc-\nture. In this experiment, we evaluate the robustness of our \nindex with different distribution scenarios. There are four \nscenarios: (a) both dataset and workload distribution remains \nunchanged; (b) dataset distribution changes while the work -\nload distribution remains unchanged; (c) both dataset and \nworkload distribution changes; and (d) dataset distribution \nremains unchanged while the workload distribution changes.\nAll experiments are conducted on the uniform dataset \nwith 200 million keys initially. Each experiment is run for \n6 episodes, and different workloads are submitted for pro-\ncessing during each episode. Each workload contains 5 mil-\nlion lookups and 5 million insertions. So the size of dataset \nincreases from 200 millions to 230 millions with 30 mil-\nlions newly inserted data which may change the distribution. Specifically, the first workload is used to train the NIS model \nto get the initial index architecture. In the next 5 episodes, \nwe apply the incremental learning approach to maintain the \nindex. We compare three approaches. The orig approach will \nprocess the rest 5 workloads with the initial index without \ntuning. The inc approach applies the incremental training in \nnext 5 episodes to update part of the index architecture and \nthen process the workload. The retrain approach represents \nthe ideal case, where we retrain a new model from scratch to \nget a new index architecture at each episode for all existing \ndata and queries.\nFigure¬† 12 shows the results for scenario (a) to (d). We \nobserve that when the distribution changes significantly, the \nindex performance is also affected. Compared to the data dis-\ntribution, the change on workload distribution has a more seri-\nous impact on performance, while incremental learning can \npartially address the problem.\nWe show the progress of incremental learning with a \ndramatic changing workload in Figure¬† 13. We use a dataset \nwith 50 million keys randomly sampled from osmc64 and \n9 different workloads, each of which contains 10 million \nlookups and 10 million insertions, and follows a log-normal \ndistribution with a different center. Due to a large number of \ninsertions, the data size grows dramatically and so does the \ndistribution. Every 10 seconds, the incremental learning is \ninvoked to update the index. And we can see that the new \nindex structure can provide a better performance until the \nnext workload starts.osmc w1\nB+treeART\nSkipList\nRMI NIS\nMasstreeBwtree01000200030004000Latency per query(ns)osmc w2\nB+treeART\nSkipListNIS\nMasstreeBwtree0123Latency per query(ns)104 osmc w3\nB+treeART\nSkipListNIS\nMasstreeBwtree010002000300040005000Latency per query(ns)osmc w4\nB+treeART\nSkipListNIS\nMasstreeBwtree0200040006000800010000Latency per query(ns)\nuniform w1\nB+treeART\nSkipList\nRMI NIS\nMasstreeBwtree0100020003000Latency per query(ns)uniform w2\nB+treeART\nSkipListNIS\nMasstreeBwtree00.511.522.5Latency per query(ns)104 uniform w3\nB+treeART\nSkipListNIS\nMasstreeBwtree01000200030004000Latency per query(ns)uniform w4\nB+treeART\nSkipListNIS\nMasstreeBwtree01500300045006000Latency per query(ns)\nFig. 11  Performance of Mixed Workload\n\n100 S.¬†Wu et al.\n1 3\n6  Related Work\nIn the database tuning area, the CMU group designs the \nOtterTune3, an autonomous database system [15‚Äì 17]. The \nOtterTune collects the data for the running status of the \ndatabase and builds a series of machine learning models \nto find the optimal configuration knobs. Following their \napproach, CBDTune [18] proposes to use the reinforcement \nlearning model to perform the configuration tuning for the \ncloud database. By contrast, Li et. al. propose a query-aware \nautomatic tuning approach, QTune[19]. QTune vectorizes \na set of SQL queries by extracting the semantic features of \nthe SQL queries.\nKrishnan et. al. propose applying the deep learning tech-\nniques for join query optimization[20]. Their reinforcement \nlearning model is integrated with Postgres and SparkSQL and \nis shown to be able to generate plans with optimization costs \nand query execution times competitive with the native query \noptimizer. Li et¬†al. [21] propose using reinforcement learning \nwith Tree-LSTM to select a proper join order and achieve \ngood performances. SkinnerDB [ 22] further improves the \nprediction of join queries by splitting queries into many \nsmall time slices. Neo [23], on the other hand, tries to rewrite \nthe database optimizer in a learning language. Instead of replacing the whole database optimizer, some work also try \nto improve the cost estimation using the deep learning model. \nIn [24‚Äì27], deep learning models are applied to estimate the \nquery selectivities or data cardinalities.\nThe deep learning approach can be adopted to search \nfor new data structures for the DBMS [28]. The closest \nwork to ours is the learned index from Google [5 ]. They \nformalize the index as a key mapping function and apply \nthe neural models to learn the index in an ad hoc way. To \nmake the approach support update and multi-dimensional \ndata, a series of optimization techniques have been proposed \n[14, 29‚Äì32]. RadixSpline [32] improves the construction \nefficiency of existing learned index through a single-pass \napproach, while delivering comparable query performance. \nThe key idea behind PGM [14] is to learn (k , rank( k)) for any \nkey k through a piecewise geometric model. On the other \nhand, [33] proposed a Reinforcement Learning approach to \nfind a proper index.\n7  Conclusion\nIn this paper, we propose a Neural Index Search(NIS) \napproach to automatically tune indexes for a given dataset \nand workload. The NIS applies the reinforcement learn-\ning approach to assemble abstract index blocks into a full-\nfledged index and tests it against the target workload. The \nindex performance is used as the reward for the learning \nmodel to update its strategy. Gradually, the predicted index \nconverges to a fine-tuned structure. In theory, our NIS can \nsimulate many existing index structures, such as B +-tree \nindex, Hash index and Skip List index. It can also explore \nthe index structures that have never been examined. We \nalso propose an incremental learning approach to support \nprogressive updates of NIS. In our experiments, the index \ngenerated by NIS achieves a comparable performance to \nexisting state-of-the-art index structures. Future and ongo-\ning work include building a learning-based approach for \nselecting column(s) to index and extending our results to \nmulti-dimensional index structures.200 205 210 215 220 225\nDatasize(M)\n(a)720750780810840870900Latency per query(ns)orig\ninc\nretrain\n200 205 210 215 220 225\nDatasize(M)\n(b)640670700730760Latency per query(ns)orig\ninc\nretrain\n200 205 210 215 220 225\nDatasize(M)\n(c)610650690730770810Latency per query(ns)orig\ninc\nretrain\n200 205 210 215 220 225\nDatasize(M)\n(d)850900950100010501100Latency per query(ns)orig\ninc\nretrain\nFig. 12  Robustness and Incremental Learning\n01 02 03 04 05 06 07 08 09 0 100\nTime(s)5006007008009001000110012001300Latency per query(ns)\nFig. 13  Performance of Incremental Learning\n3 https:// github. com/ cmu- db/ otter  tune.\n\n101 Dynamic Index Construction with¬†Deep Reinforcement Learning  \n1 3\nAcknowledgements This work was supported by the Key Research \nProgram of Zhejiang Province [Grant Numbers 2021C01109] and the \nFundamental Research Funds for Alibaba Group through Alibaba Inno-\nvative Research (AIR) Program.\nOpen Access This article is licensed under a Creative Commons Attri-\nbution 4.0 International License, which permits use, sharing, adapta-\ntion, distribution and reproduction in any medium or format, as long \nas you give appropriate credit to the original author(s) and the source, \nprovide a link to the Creative Commons licence, and indicate if changes \nwere made. The images or other third party material in this article are \nincluded in the article's Creative Commons licence, unless indicated \notherwise in a credit line to the material. If material is not included in \nthe article's Creative Commons licence and your intended use is not \npermitted by statutory regulation or exceeds the permitted use, you will \nneed to obtain permission directly from the copyright holder. To view a \ncopy of this licence, visit http:// creat iveco mmons. org/ licen ses/ by/4. 0/.\nReferences\n 1. Zhang C, Zhang Y, Zhang W, Lin X (2013) Inverted linear \nquadtree: efficient top k spatial keyword search. In: 29th IEEE \nInt Conf Data Eng, pp 901‚Äì912\n 2. Cong G, Jensen CS, Wu D (2009) Efficient retrieval top-k most \nrelevant spatial web objects. PVLDB 2(1):337‚Äì348\n 3. Wang X, Zhang Y, Zhang W, Lin X, Wang W (2015) Ap-tree: effi-\nciently support continuous spatial-keyword queries over stream. \nIn: 31st IEEE Int Conf Data Eng, pp 1107‚Äì1118\n 4. O‚ÄôDonoghue B, Munos R, Kavukcuoglu K, Mnih V (2017) Combining \npolicy gradient and q-learning. In: 5th Int Conf Learn Representations\n 5. Kraska T, Beutel A, Chi EH, Dean J, Polyzotis N (2018) The case \nfor learned index structures. In: Proc 2018 Int Conf Manag of \nData, pp 489‚Äì504\n 6. Zoph B, Le QV (2017) Neural architecture search with reinforce -\nment learn. In: 5th Int Conf Learn Representations\n 7. Hochreiter S, Schmidhuber J (1997) Long short-term memory. \nNeural Comput 9(8):1735‚Äì1780\n 8. Schulman J, Wolski F, Dhariwal P, Radford A, Klimov O \n(2017) Proximal policy optimization algorithms, CoRR, vol. \nabs/1707.06347\n 9. Tai KS, Socher R, Manning CD (2015) Improved semantic repre-\nsentations from tree-structured long short-term memory networks. \nIn: Proc 53rd Ann Meeting Assoc for Comput Linguistics and \nthe 7th Int Joint Conf Natural Lang. Process. Asian Federation of \nNatural Lang. Process., pp 1556‚Äì1566\n 10. Kipf A, Marcus R, van Renen A, Stoian M, Kemper A, Kraska \nT, Neumann T (2019) Sosd: a benchmark for learned indexes. \nNeurIPS Workshop Mach Learn for Syst\n 11. Leis V, Kemper A, Neumann T (2013) The adaptive radix tree: \nartful indexing for main-memory databases. In: 29th IEEE Int \nConf Data Eng, pp 38‚Äì49\n 12. Kim C, Chhugani J, Satish N, Sedlar E, Nguyen AD, Kaldewey \nT, Lee VW, Brandt SA, Dubey P (2010) FAST: fast architecture \nsensitive tree search modern cpus and gpus. In: Proc ACM SIG-\nMOD Int Conf Manag of Data, pp 339‚Äì350\n 13. Wang Z, Pavlo A, Lim H, Leis V, Zhang H, Kaminsky M, \nAndersen DG (2018) Building a bw-tree takes more than just buzz \nwords. In: Proc 2018 Int Conf Manag of Data, pp 473‚Äì488\n 14. Ferragina P, Vinciguerra G (2020) The pgm-index: a fully-\ndynamic compressed learned index with provable worst-case \nbounds. Proc VLDB Endow 13(8):1162‚Äì1175\n 15. Pavlo A, Angulo G, Arulraj J, Lin H, Lin J, Ma L, Menon P, Mowry \nT, Perron M, Quah I, Santurkar S, Tomasic A, Toor S, Aken DV, Wang Z, Wu Y, Xian R, Zhang T (2017) Self-driving database man-\nagement systems. In: Conf Innov Data Syst, Research\n 16. Zhang B, Aken DV, Wang J, Dai T, Jiang S, Lao J, Sheng S, Pavlo \nA, Gordon GJ (2018) A demonstration ottertune automatic data-\nbase manag. System tuning service. PVLDB 11(12):1910‚Äì1913\n 17. Pavlo A, Butrovich M, Joshi A, Ma L, Menon P, Aken DV, Lee L, \nSalakhutdinov R (2019) External vs. internal: an essay machine \nlearning agents for autonomous database management systems. \nIEEE Data Eng Bull, pp 32‚Äì46\n 18. Zhang J, Liu Y, Zhou K, Li G, Xiao Z, Cheng B, Xing J, Wang \nY, Cheng T, Liu L, Ran M, Li Z (2019) An end-to-end automatic \ncloud database tuning system using deep reinforcement learning. \nIn: Proc 2019 Int Conf Manag of Data, pp 415‚Äì432\n 19. Li G, Zhou X, Li S, Gao B (2019) Qtune: a query-aware data-\nbase tuning system with deep reinforcement learning. PVLDB \n12(12):2118‚Äì2130\n 20. Krishnan S, Yang Z, Goldberg K, Hellerstein JM, Stoica I (2018) \nLearning to optimize join queries with deep reinforcement learn-\ning, CoRR, vol. abs/1808.03196\n 21. Yu X, Li G, Chai C, Tang N (2020) Reinforcement learning with \ntree-lstm for join order selection. In: 36th IEEE Int Conf Data \nEng, IEEE pp 1297‚Äì1308\n 22. Trummer I, Wang J, Maram D, Moseley S, Jo S, Antonakakis \nJ (2019) Skinnerdb: regret-bounded query evaluation via rein -\nforcement learning. In: Proc 2019 Int Conf Manag of Data, pp \n1153‚Äì1170\n 23. Marcus RC, Negi P, Mao H, Zhang C, Alizadeh M, Kraska T, \nPapaemmanouil O, Tatbul N (2019) Neo: a learned query opti-\nmizer. PVLDB 12(11):1705‚Äì1718\n 24. Woltmann L, Hartmann C, Thiele M, Habich D, Lehner W (2019) \nCardinality estimation with local deep learning models. In: Proc \nSecond Int Workshop Exploiting Artif Intell Techn for Data \nManag, pp 5:1‚Äì5:8\n 25. Yang Z, Liang E, Kamsetty A, Wu C, Duan Y, Chen X, Abbeel P, \nHellerstein JM, Krishnan S, Stoica I (2019) Selectivity estimation \nwith deep likelihood models. CoRR, vol abs/1905.04278\n 26. Sun J, Li G (2019) An end-to-end learning-based cost estimator. \nProc VLDB Endow 13(3):307‚Äì319\n 27. Kipf A, Kipf T, Radke B, Leis V, Boncz PA, Kemper A (2019) \nLearned cardinalities: estimating correlated joins with deep learn-\ning. In: 9th Biennial Conf Innovative Data Syst, Research\n 28. Kraska T, Alizadeh M, Beutel A, Chi EH, Kristo A, Leclerc G, \nMadden S, Mao H, Nathan V (2019) Sagedb: a learned database \nsystem. In: 9th Biennial Conf Innovative Data Syst, Research\n 29. Marcus R, Zhang E, Kraska T (2020) Cdfshop: exploring and opti-\nmizing learned index structures. In: Proc 2020 Int Conf Manag of \nData. ACM, pp 2789‚Äì2792\n 30. Galakatos A, Markovitch M, Binnig C, Fonseca R, Kraska T \n(2019) Fiting-tree: a data-aware index structure. In: Proc 2019 \nInt Conf Manag of Data. ACM, pp 1189‚Äì1206\n 31. Ding J, Minhas UF, Yu J, Wang C, Do J, Li Y, Zhang H, Chan-\ndramouli B, Gehrke J, Kossmann D, Lomet DB, Kraska T (2020) \nALEX: an updatable adaptive learned index. In: Proc 2020 Int \nConf Manag of Data. ACM, pp 969‚Äì984\n 32. Kipf A, Marcus R, van Renen A, Stoian M, Kemper A, Kraska T, \nNeumann T (2020) Radixspline: a single-pass learned index. In: \nProc Third Int Workshop Exploiting Artif Intell Techn for Data \nManag. ACM, pp 5:1‚Äì5:5\n 33. Lan H, Bao Z, Peng Y (2020) An index advisor using deep rein-\nforcement learning,‚Äù in CIKM ‚Äô20: the 29th ACM International \nconference on information and knowledge management, virtual \nevent, Ireland, d‚Äô Aquin M, Dietze S, Hauff C, Curry E, Cudr√©-\nMauroux P, Eds. ACM, 2020, pp 2105‚Äì2108. [Online]. Available: \nhttps:// doi. org/ 10. 1145/ 33405 31. 34121 06",
  "textLength": 63961
}