{
  "paperId": "33531b70cbb563c15a608981fe57b07c51ff1db3",
  "title": "SLBRIN: A Spatial Learned Index Based on BRIN",
  "pdfPath": "33531b70cbb563c15a608981fe57b07c51ff1db3.pdf",
  "text": "Citation: Wang, L.; Hu, L.; Fu, C.; Yu,\nY.; Tang, P .; Zhang, F.; Liu, R. SLBRIN:\nA Spatial Learned Index Based on\nBRIN. ISPRS Int. J. Geo-Inf. 2023 ,12,\n171. https://doi.org/10.3390/\nijgi12040171\nAcademic Editors: Huayi Wu and\nWolfgang Kainz\nReceived: 13 January 2023\nRevised: 4 April 2023\nAccepted: 12 April 2023\nPublished: 15 April 2023\nCopyright: © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\n International Journal of\nGeo-Information\nArticle\nSLBRIN: A Spatial Learned Index Based on BRIN\nLijun Wang\n , Linshu Hu\n , Chenhua Fu, Yuhan Yu\n , Peng Tang\n , Feng Zhang *\n and Renyi Liu\nSchool of Earth Sciences, Zhejiang University, 38 Zheda Road, Hangzhou 310027, China\n*Correspondence: zfcarnation@zju.edu.cn; Tel.: +86-571-8707-3186\nAbstract: The spatial learned index constructs a spatial index by learning the spatial distribution,\nwhich performs a lower cost of storage and query than the spatial indices. The current update\nstrategies of spatial learned indices can only solve limited updates at the cost of query performance.\nWe propose a novel spatial learned index structure based on a Block Range Index (SLBRIN for\nshort). Its core idea is to cooperate history range and current range to satisfy a fast spatial query and\nefﬁcient index update simultaneously. SLBRIN deconstructs the update transaction into three parallel\noperations and optimizes them based on the temporal proximity of spatial distribution. SLBRIN also\nprovides the spatial query strategy with the spatial learned index and spatial location code, including\npoint query, range query and kNN query. Experiments on synthetic and real datasets demonstrate\nthat SLBRIN clearly outperforms traditional spatial indices and state-of-the-art spatial learned indices\nin the cost of storage and query. Moreover, in the simulated real-time update scenario, SLBRIN has\nthe faster and more stable query performance while satisfying efﬁcient updates.\nKeywords: learned index; spatial index; BRIN; index update\n1. Introduction\nIn the current normal environment of COVID-19, location-based services (LBS) have\nbecome an important part of the infrastructure of people’s daily lives [ 1]. It produces\nreal-time spatial big data, and meanwhile, exposes the urgency of spatial interoperability.\nFor instance, we record our trips (data update) and query the epidemic distribution (spatial\nquery) frequently through various terminal devices. In database management systems\n(DBMS), indexing is a powerful means to speed up a query by trading space for time. There\nare also plenty of spatial indices for spatial data [ 2], of which the most typical is R-tree [ 3].\nHowever, with the increasing complexity of spatial big data, the bottlenecks of traditional\nspatial indices are emerging [4], such as a large cost on storage and queries.\nLearned indices [ 5], a new direction for DBMS, simplify the index relationship between\nthe index value and the physical location into a nonlinear regression function. Henceforth,\nmore and more studies have introduced learned indices into geographic information sci-\nence (GIS), eventually forming the spatial learned index. Spatial learned indices mainly\nsolve four problems: (1) Order spatial data: due to spatial heterogeneity [ 6], it is difﬁcult to\nquantify the spatial proximity through a single dimension. Most spatial learned indices\njust map spatial data into one-dimensional values by dimensionality reduction, i.e., via a\nspace-ﬁlling curve (SFC) [ 7,8], i-Distance [ 9]. (2) Homogenize distribution: homogenizing\nthe data distribution makes its cumulative distribution function (CDF) easier to learn,\nthereby improving the training efﬁciency and query performance, such as quantile trans-\nformation [ 10] and rank space ordering [ 11]. (3) Partition data: the partitioned index, with\na higher overall accuracy, are mainly divided into two types, i.e., data-based partition and\nspatial-based partition [ 12]. (4) Handle update: the update strategies of spatial learned\nindices basically follow that of the normal learned index.\nExisting spatial learned indices, beneﬁting from learned indices, have lower cost of\nstorage and query. However, the methods to ﬁt spatial data also complicate the index\nISPRS Int. J. Geo-Inf. 2023 ,12, 171. https://doi.org/10.3390/ijgi12040171 https://www.mdpi.com/journal/ijgi\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 2 of 24\nstructure. In addition, their update strategies sacriﬁce a certain amount of query perfor-\nmance and only support a limited number of updates. Block range index (BRIN) [ 13] and\nBRIN-Spatial [ 14] divides index entries into ranges along the physical order and statistics\nsummary info as index values, naturally taking the smallest size and the fastest update.\nWhen data are stored in order, their monotonic summary info offers the best query perfor-\nmance. Index update should not only guarantee the update performance, but also reduce\nthe query performance penalty. However, current spatial indices are caught in the conﬂict\nbetween them, such as R-tree and Learned Index structure for Spatial dAta (LISA) [ 15]\n(weak in update), and BRIN-Spatial (weak in query).\nWith the purpose of optimizing both query performance and update performance,\nwe propose a novel spatial learned index structure, SLBRIN. Its core idea is to simplify\nthe problem of spatial index by dividing the index object into two parts: the history range\n(HR) suitable for spatial query and the current range ( CR) suitable for index update, and\noptimize the processing strategies with the spatio-temporal features of spatial big data. For\nHR, the spatial ﬁelds are ﬁrst encoded and sorted to form index entries based on Geohash.\nThen the index entries are partitioned into range s, with the minimum decimal geohash code\nas summary info. These range s are a set of regular quad-partitions with approximate data\nvolume in spatial. Finally, for each range , we build a one-dimensional learned index for\nspatial queries. For CR, to minimize the update cost, the range s are partitioned directly\nalong the physical order and take a simple MBR as summary info.\nThe rest of the paper is organized as follows: Section 2 discusses the related work.\nSection 3 presents the methodology of our index, including its structure and the strategies in\nbuild processing, update processing and query processing. Section 4 provides an extensive\nexperimental evaluation of the proposed work and Section 5 discusses the experimental\nresults. Finally, Section 6 concludes the paper.\n2. Related Work\n2.1. Spatial Indices\nSpatial indices [ 12] organize spatial data to provide efﬁcient query processing. On\nthe basis of organization, they can be classiﬁed into dimensionality reduction, space-based\npartitioning and data-based partitioning.\nDimensionality reduction maps multidimensional data to one-dimensional values, and\nthen uses one-dimensional indices to index the mapped values. Space ﬁll curves (SFCs) [ 16]\nare the most popular, which connect spatial partitions with fractal curves. SFCs mainly\ninclude Z-curve [ 17] and Hilbert-curve [ 18], as well as their variants, to ﬁt non-point\nobjects [ 19] and spatio-temporal data [ 20]. Geohash [ 21] encodes space with Z-curve\nand provides advanced methods such as neighbor query. S2 [ 22] is a method library for\nthree-dimensional space with more reﬁned partitions and shorter codes.\nSpace-based partitioning divides space recursively based on speciﬁc rules and records\nthe mapping relationship between partitions and data. The simplest is grid ﬁle [ 23], which\ndivides space into grids of the same size and uses a hash function to encode grids. KD-\ntree [ 24] selects dimensions iteratively and build a binary search tree for multidimensional\ndata. Quadtree [ 25] and octree [ 26] use four and eight nodes to achieve uniform partition\nin two and three dimensions, respectively. Point range quadtree [ 27], a variant of quadtree,\ncontrols the volume of leaf nodes to make partitions closer to the data distribution.\nData-based partitioning relies on the data distribution, with strong query performance,\nbut also high update cost. The most classic is R-tree [ 3], a B-tree with MBR as summary info.\nEach node of R-tree stores a set of MBRs and the pointers to child nodes or index entries.\nThere are lots of variants of R-tree, such as STR-tree [ 28] to accelerate index construction and\nR+-tree [ 29] and R*-tree [ 30] to solve spatial overlap. Additionally, Q+R-tree [ 31] and Hilbert\nR-tree [ 32] mix other indices to improve performance, and TPR-tree [ 33] adapts to spatio-\ntemporal data. Unlike R-tree, BRIN [ 13] is not based on the spatial distribution, but the\nstorage order. BRIN divides pages into range s along the physical order with an extremely\nlow update cost. BRIN is designed for handling very large tables in which certain columns\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 3 of 24\nhave some natural correlation with their physical location. BRIN-Spatial [ 14] extends BRIN\nby using MBR as summary info. Its query processor only searches the index entries within\ncertain range s of which the MBR intersects with the query.\n2.2. Learned Indices\nLearned indices interpret indices as a function that take the query condition as input\nand physical location of data as output. They take a regression model instead of the\ntraditional indices to solve this function. Kraska et al. [ 5] proposed the learned index, as\nwell as recursive-model indices (RMI) for the last-mile search of big data. From then on,\nthe studies on the learned index mainly focus on index update and dimension expansion.\nIndex update . In response to any updates, the learned index must retrain models\nto ensure the validity of error bounds, which is costly in time. ASLM [ 34] partitions\ndata with the maximum intervals, and uses cache as a transfer for updates. Hybrid-\nLR [ 35] stores outliers separately in B-tree to stabilize model accuracy. FITing-tree [ 36]\nreserves extra physical space for each partition. IFB-tree [ 37] evaluates the update cost\nwith interpolation-friendliness, such as a partition in uniform distribution with higher\ninterpolation-friendliness. PGM-index [ 38] admits a streaming algorithm to partition,\ninstead of using FITing-tree’s greedy algorithm, and handles updates using LSM-tree.\nShift-table [ 39] resolves the local biases of learned models at the cost of (at most) one\nmemory lookup.\nDimension expansion . The index is built for query requirements. Spatial learned index is\na special learned index, taking coordinates as queries. To learn spatial distribution, the ﬁrst\nchallenge is to order spatial data. SageDB [ 40] sorts data based on the speciﬁed dimension\nand learns the granularity of partitions automatically based on data distribution and query\ndistribution. Similar to KD-tree, Flood [ 41] sorts and partitions multidimensional data\nbased on each dimension. ZM-index [ 7], HM-index [ 8], ML-index [ 9] and LISA [ 15] use\nZ-curve, Hilbert-curve, i-Distance, and Lebesgue Measure respectively to reduce dimen-\nsionality. Some studies replace deep learning models with piecewise linear functions [ 36]\nand spline interpolation functions [ 42] to improve model accuracy. Similarly, PolyFit [ 43]\nand SPRIG [ 44] ﬁt spatial distribution using piecewise polynomial functions and spatial\ninterpolation functions to avoid ordering spatial data.\n3. Methodology\nOur proposed method consists of the overall architecture and the strategies in building,\nupdating and query processing. Table 1 lists some important notations.\nTable 1. Notation.\nNotation Deﬁnitions\nP a spatial dataset\nd, n, S dimensionality, cardinality and scope of P\nL length of Geohash\nHR,CR history range and current range\nM a learned model\nIE an index entry\nTN, TL thresholds for HR’s number of IEs and actual geohash length\nTS threshold for CR’s number of IEs\nTM threshold for the number of CRs\nTE threshold for M’s error bounds\n3.1. SLBRIN Architecture\nThe core concept of BRIN is range (Deﬁnition 1). The summary info of range is the\nkey to judge whether the target exists in range . The most commonly used summary info is\nthe minimum and maximum of all index entries in those pages. The range s may overlap,\nand the degree of overlap determines their query performance. To process queries, BRIN\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 4 of 24\ncollects the eligible candidate pages by simply scanning all the summary info. BRIN-Spatial,\nthe spatial variant of BRIN, takes MBR as its summary info, as shown in Table 2.\nDeﬁnition 1. A range is a group of the ﬁxed disk page units (128 pages per range by default) and it\nstores the brief summary information for all index entries in those pages as a query ﬁlter.\nTable 2. The summary information of BRIN,BRIN-Spatial and SLBRIN.\nRange ID PagesBRIN\n(Min, Max)BRIN-Spatial/SLBRIN CR\n(xmin, ymin, xmax, ymax)SLBRIN HR\n(gmin)\n0 1, 128 0, 8 0, 0, 4, 4 0\n1 129, 256 2, 7 1, 1, 8, 8 4\n2 257, 384 4, 9 2, 0, 7, 2 8\nOur SLBRIN goes beyond BRIN and extends the range toHRand CR. For HR, we\nﬁrst used Geohash to order spatial data. Geohash uses base-32 to reduce the code length\nand accelerate the preﬁx match, but raises the likelihood of jumping nature. Therefore,\nwe retreated to base-10 to have a more reasonable spatial representation. IEs are sorted\nby the decimal geohash code both among and within HRs, and thus HRs are strictly non-\noverlapping in spatial. We can only use their minimum IEs’ key as the summary info, as\ntheir maximum is equal to the minimum of the next HR. As the summary info is monotonic\n(ordered and unique), we designed the decimal geohash match ( DGM ) based on a binary\nsearch to ﬁnd out the candidate HR. Given that the preﬁx match of Geohash can only use\n‘=’,DGM takes full advantage of the monotonicity to use ‘>’ and ‘<’ additionally. As in\nAlgorithm 1, Ais the summary info of all HRs and qis the decimal geohash of query point.\nIfAmid= q, then HR midcontains q. If it is not found in the end, then HR rightcontains q.\nAlgorithm 1: Decimal Geohash Match\nInput :A: a sorted decimal geohash array; q: a geohash query; ( l,r): the initial left and right.\nOutput : the key to q.\n1:while l\u0014rdo\n2: mid (l+r)/2\n3: ifAmid= qthen\n4: return mid\n5: else if Amid< qthen\n6: l mid+1\n7: else\n8: r mid-1\n9:return r\nForCR, new IEs in a speciﬁc time period are temporarily stored in CRs. The front\nCRis merged into HRﬁrst and stores the oldest IEs. The temporal proximity of spatial\ndistribution indicates the continuity of CRs in time, which means CRs are likely to overlap\nin spatial. So, unlike HR, we simply used the MBR as its summary info.\nAs shown in Table 3, SLBRIN’s structure is mainly composed of ﬁve physical objects\nand ﬁve logical objects.\n(1) Meta Page records the metadata, including the pointers of the last HRand the last\nCR, the length of the geohash Land ﬁve thresholds of TH,TL,TS,TMand TE. The two\npointers help to locate the most active range quickly when handling updates; THand TL\ndetermine the spatial granularity of HR, which is related to query performance; TS,TM\nand TEare used to trigger the three parallel operations in update processing.\n(2)HRPages record HRin pages with attributes as follows: (a) value records the\nminimum decimal geohash code as summary info; (b) lenand num record the actual\ngeohash length and current volume of IEs to assist in partitioning HR; (c)*model records\nthe pointer of Min Model Pages; (d) state records whether HRis inefﬁcient.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 5 of 24\n(3)CRPages record CRin pages. CRis simpler than HR, only containing three at-\ntributes: (a) value records the MBR as summary info; (b) num records the current number of\nIEs; (c) state records whether CRis full or outdated.\n(4) Model Pages record all Msin pages. The attribute matrices records the slope and bias\nof each layer and minErr and maxErr deﬁne the error bounds. The approximate physical\nlocation of the target can be calculated directly by matrix operations, and the exact physical\nlocation can be found by a second scan within the error bounds.\n(5) Data Pages record all the IEs in pages. IEs take the decimal geohash code as the\nkey and the physical location as the value, and preserve the spatial ﬁelds to assist queries.\nIn the logical structure, both HRand CRstore IEs. However, in the physical structure, Data\nPages store all the IEs, while HRPages and CRPages only store the metadata of range s.\nTable 3. SLBRIN objects.\nPhysical Object Logical Object Attributes\nMeta Page Meta int32 *lastHR , int32 *lastCR , int8 L, 5\u0002int16 thresholds\nHRPages HR int64 value , int8 len, int16 num , int32 *model , int8 state\nCRPages CR 4\u0002int64 value , int16 num , int8 state\nModel Pages M Matrix matrices , int32 minErr , int32 maxErr\nData Pages IE int64 geohash ,d\u0002ﬂoat64 spatialFields , int32 *data\n3.2. Build Processing\nWe present the details of SLBRIN through its build processing as Algorithm 2. (1) For\nspatial data as Figure 1a, we reduced its dimensionality and sorted it by Geohash to build\nordered IEs as Figure 1b. (2) We recursively partitioned HRwith IEs and built the physical\nstructure of SLBRIN as Figure 1c. Since there is no update in build processing, CRis empty.\n(3) For each HR, we built the learned model by learning its spatial distribution, which is the\nmain way to ﬁlter IEs within HR.\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  5 of 24 \n \n (1) Meta Page records the metadata,  including  the pointers of the last HR and the last \nCR, the length of the geohash L and five thresholds  of TH, TL, TS, TM and TE. The two \npointers help to locate the most active range quickly when handling  updates;  TH and TL \ndetermine  the spatial granularity  of HR, which is related to query performance;  TS, TM \nand TE are used to trigger the three parallel operations  in update processing.  \n(2) HR Pages record HR in pages with attributes  as follows: (a) value records the min-\nimum decimal geohash code as summary  info; (b) len and num record the actual geohash \nlength and current volume of IEs to assist in partitioning  HR; (c) *model records the pointer \nof M in Model Pages; (d) state records whether HR is inefficient.  \n(3) CR Pages record CR in pages. CR is simpler than HR, only containing  three attrib-\nutes: (a) value records the MBR as summary  info; (b) num records the current number of \nIEs; (c) state records whether CR is full or outdated.  \n(4) Model Pages record all Ms in pages. The attribute  matrices records the slope and \nbias of each layer and minErr and maxErr define the error bounds. The approximate  phys-\nical location of the target can be calculated  directly by matrix operations,  and the exact \nphysical location can be found by a second scan within the error bounds.  \n(5) Data Pages record all the IEs in pages. IEs take the decimal geohash code as the \nkey and the physical location as the value, and preserve  the spatial fields to assist queries. \nIn the logical structure,  both HR and CR store IEs. However, in the physical structure,  \nData Pages store all the IEs, while HR Pages and CR Pages only store the metadata  of \nranges. \nTable 3. SLBRIN objects. \nPhysical  Object  Logical Object  Attributes  \nMeta  Page  Meta  int32  *lastHR , int32  *lastCR , int8 L, 5 × int16  thresholds  \nHR Pages  HR int64  value, int8 len, int16  num , int32  *model , int8 state \nCR Pages  CR 4 × int64  value , int16  num , int8 state  \nModel  Pages  M Matrix  matrices , int32  minErr , int32  maxErr  \nData  Pages  IE int64  geohash , d × float64  spatialFields , int32  *data  \n3.2. Build Processing  \nWe present the details  of SLBRIN through its build processing  as Algorithm  2. (1) For \nspatial data as Error! Reference source not found. a, we reduced its dimensionality  and \nsorted it by Geohash  to build ordered IEs as Error! Reference source not found. b. (2) We \nrecursively  partition ed HR with IEs and built the physical structure  of SLBRIN as Error! \nReference source not found. c. Since there is no update in build processing,  CR is empty. \n(3) For each HR, we built the learned model by learning its spatial distribution,  which is \nthe main way to filter IEs within HR. \n \n(a) (b) (c) \nFigure 1. Build processing  in SLBRIN.  (a) Spatial dataset. (b) Index entries. (c) Structure  of SLBRIN.  \n3.2.1. Ordering  Data  \nFigure 1. Build processing in SLBRIN. ( a) Spatial dataset. ( b) Index entries. ( c) Structure of SLBRIN.\n3.2.1. Ordering Data\n(1)Calculate geohash length. Geohash partitions space in the way of recursive dichotomy.\nThe deeper the recursive level Rof Geohash, the smaller the unit scope of partitions.\nEquation (1) shows that once the unit scope is more reﬁned than the data precision, Geohash\nencodes all the data uniquely. Based on this, the minimum recursive level Rmincan be\nderived as Equation (2), where Siis the scope in the i-th dimension, S Ris the unit scope in\nlevel Rand prec is the data precision.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 6 of 24\nAlgorithm 2: Build SLBRIN\nInput: P: a spatial dataset; ( TH,TL,TS,TM,TE): the thresholds\nOutput: I: our index.\n1: calculate the geohash encoding length of PtoL\n2: calculate and sort IEs by Geohash (L) toieList\n3: initial rangeStack and rangeList\n4:rangeStack .push (CreateRange (0, 0, P.size, [0,P.size- 1]))\n5:while rangeStack.size6=0do\n6: range rangeStack .pop(-1)\n7: ifrange .num >TNand range .len<TLthen\n8: initial childs ;lk,rk range .keyBound ;tlklk\n9: fori2[0, 3] do\n10: len range .len+ 2;value range .value + (i<<L-len)\n11: breakpoint range .value + (i+ 1 << L-len)\n12: trkDGM (ieList ,breakpoint ,tlk,rk);num trk–rlk+ 1\n13: childs .push (CreateRange (value ,len,num , [tlk,trk]));tlk trk+ 1\n14: rangeStack .push (Reverse (childs ))\n15: else\n16: rangeList .push (range )\n17: create HRfor each range inrangeList and store to HRPages\n18: create empty CRand store to CRPages\n19: create Meta and store to Meta Page\n20: reorganize ieList and store to Data Pages\n21: build and train Mand store extract args to Model Pages\n22:return I\nSR=min\n8i2dfSi,max\u0000Si,ming/2R\u0014prec (1)\nRmin=\u0016\nlog2\u0012\nmin\n8i2dfSi,max\u0000Si,ming/prec\u0013\u0017\n(2)\n(2)Encode single dimension. Geohash dichotomizes coordinates recursively in each\ndimension and records the binary value for each dichotomy. Since Rminis determined, the\ngeohash code can be calculated directly with simple bit operations as in Equation (3), where\nviis the coordinate in the i-th dimension and bin(x) means to obtain the binary of x. If the\ngeohash length is less than Rmin, it must be completed with 0 on the left side.\ngi=bin\u0012vi\u0000Si,min\nSi,max\u0000Si,min\u0002(1\u001cRmin)\u0013\n(3)\n(3)Merge geohash codes. The geohash codes in each dimension were cross-merged into\nsingle code of length L=d\u0002Rmin. We further compressed geohash codes to the decimal to\nreduce the cost in storage and query.\n(4)Build IE. IE is more compact than data itself in physical space, which can reduce\nthe IO cost of spatial query. We took the decimal geohash code as the key of IEand then\nsorted all the IEs by their keys.\n3.2.2. Building SLBRIN\nThe build processing of SLBRIN was carried out around HR, which was similar to\npoint range quadtree [27] in terms of partitioning.\n(1)Initial range. The beginning of recursion is the initial range for all IEs. We recorded\nthe start pointer and end pointer of IEs in keyBound for each range . All the range s to be\npartitioned were recorded in a stack rangeStack , of which the ﬁrst member was the initial\nrange. In addition, the eligible range s were recorded in a linked list rangeList (Lines 3–4).\n(2)Partition recursively. Partitioning of HRresults in a set of range s that satisfy the\ncondition num <TNand len<TL(Lines 5–16). TNbalances the volume of IEs among HRs.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 7 of 24\nHowever, the aggregation of spatial data is likely to bring about a deep partition, especially\nan inﬁnite partition when its scope is reﬁned than its precision. To avoid this, we used TL\nto limit the actual geohash length. The details of partitioning are as follows: (a) Iterate over\neach range in rangeStack ; (b) If the range does not meet the condition, ﬁnd the quartiles of\nkeyBound byDGM , partition into four children and push into rangeStack ; (c) Else, push into\nrangeList . The children are a quarter of their parent in spatial, so their lenand value (land v\nin short) can be derived from their parent using Equations (4) and (5).\nlchild=lparent +2 (4)\nvchild ,i=vparent +(i\u001cL\u0000lchild), 0\u0014i<2d(5)\n(3)Create SLBRIN. We created the logical and physical objects. For HR, we transformed\neach range inrangeList toHRand store them into HRPages. For CR, empty CRs are enough\nfor build processing, as there is no update. For Meta, we extracted the pointers of last HR\nand CR, as well as the thresholds and L, and stored them into Meta Page.\n(4)Reorganize IE s. The physical space of range is of the same size and continuous.\nHowever, the IEs mapped by keyBound are in varying quantities, so we reorganized and\nstored them into Data Pages. When num\u0015TNand len\u0015TL, the physical space cannot\nstore all the IEs of the HR. To solve the overﬂow of IEs, we created empty pages at the end\nofHRPages and recorded the pointer of these pages as an external link in the HR.\n3.2.3. Building Learned Model\n(1)Build model. Dimensionality reduction transforms the independent variable of index\nfrom multi-dimensional spatial ﬁelds to one-dimensional geohash code. After ordering,\ndata are unordered in physical location. Instead, we took the ordered physical location of\nIEas the dependent variable and constructed a learnable CDF, as in Equation (6).\np.key=F(p.cord)\u0002n)F(Geohash (p.cord))\u0002n (6)\nThe physical location of IEin Data Pages is only continuous within HRs, so we\nused piecewise nonlinear function to ﬁt its CDF. A piecewise nonlinear function can be\ndescribed as Equation (7), where Miis the unary nonlinear relation of the i-thHR, and\nb=(b0,b1,\u0001\u0001\u0001,bs)is a set of breakpoints.\nF(x)=8\n>><\n>>:M0(x),b0\u0014x<b1\nM1(x),b1\u0014x<b2\n. . . . . .\nMs(x),bs\u0014x<bs+1(7)\nTo solve F, we only needed to solve Mi, as breakpoints are known as the adjacent\nvalue s. We ensured that the monotonicity was not only within but also among HRs to\nachieve the overall monotonicity of F. As in Equation (8), each Miis monotonic and the left\nborder should not be smaller than the right border of the previous.\nMi\"\\Mi(bi)\u0015Mi\u00001(bi) (8)\nFollowing the ﬁrst learned index [ 5], we chose multi-layer perceptron (MLP) to learn\nthe non-linear function rather than the other regression model. We built an MLP with one\nhidden layer and sigmoid activation function, as in the universal approximation theorem:\nAn MLP , with a linear output layer and at least one hidden layer with enough neurons and\nany kind of squeezed activation function, can ﬁt any Borel measurable function from one\nﬁnite dimensional space to another with any accuracy [45].\n(2)Deﬁne error bounds. For the multi-staged spatial learned indices, such as the RMI\nversion of ZM-index [ 7] and RSMI [ 11], the upper stage tends to take larger error bounds\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 8 of 24\nthan the lower, or worse, resulting in the overall unsatisfactory error bounds. SLBRIN\ntakes a hash function ( DGM ) as the upper stage, and thus its error bounds exist within HRs,\nwhich guarantees the last-mile search and reduces the overall error bounds.\nThe error extremes are as important as the overall ﬁtting degree, which is directly\nrelated to the query performance. As in Equation (11), we used a weighted sum of cross\nentropy and error extremes as the loss function, explaining the ﬁtting degree and error\nextremes respectively, where wis the weight to eliminate the impact of different units.\negmin=min\n8x2PfM(x)\u0000yg (9)\negmax=max\n8x2PfM(x)\u0000yg (10)\nLM=1\nnå8x2P(M(x)\u0000y)2+w\u0002(egmax\u0000egmin) (11)\n(3)Train and extract model. ForMi, the training data are all the IEs ofHR i, as well as\nthe breakpoints value iand value i+1for the constraint in Equation (8). We normalized the\ntraining data by the maximum and minimum, choose Adam as the optimizer and used the\nearly stopping mechanism to shorten the training time. After training, to reduce the cost\nof storage and query, we extracted the weights and error bounds from the complex deep\nlearning framework, and stored them into Model Pages.\n3.3. Update Processing\nAlgorithm 3 shows the pseudo code of the update handling in SLBRIN. The cascading\noperations of data update are deconstructed into serial operations and parallel operations.\nSerial operations are blocking to keep the data consistency, i.e., the next update cannot be\nstarted until the current serial operation is completed. Parallel operations are non-blocking\nand triggered by pre-deﬁned conditions, including summarize CR, merge CRand retrain\nmodel, as shown in Figure 2. We further divided them into two sub-operations, GET and\nPOST, to improve parallelism.\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  8 of 24 \n \n achieve the overall monotonicity  of F. As in Equation  (8), each \niM is monotonic  and the \nleft border should not be smaller than the right border of the previous . \n()()1       i i i i iMM β Mβ−\n (8) \nFollowing  the first learned index [5], we chose multi-layer perceptron  (MLP) to learn \nthe non-linear function rather than the other regression  model. We built an MLP with one \nhidden layer and sigmoid activation  function,  as in the universal  approximation  theorem: \nAn MLP, with a linear output layer and at least one hidden layer with enough neurons \nand any kind of squeezed  activation  function,  can fit any Borel measurable  function from \none finite dimensional  space to another with any accuracy  [45]. \n(2) Define error bounds. For the multi-staged spatial learned indices, such as the RMI \nversion of ZM-index [7] and RSMI [11], the upper stage tends to take larger error bounds \nthan the lower, or worse, resulting  in the overall unsatisfactory  error bounds. SLBRIN \ntakes a hash function (DGM) as the upper stage, and thus its error bounds exist within \nHRs, which guarantees  the last-mile search and reduces the overall error bounds.  \nThe error extremes  are as important  as the overall fitting degree, which is directly \nrelated to the query performance.  As in Equation  (11), we used a weighted  sum of cross \nentropy and error extremes  as the loss function,  explaining  the fitting degree and error \nextremes  respectively,  where\nwis the weight to eliminate  the impact of different  units.  \n() minminxPeg M x y\n=−\n (9)  \n() maxmaxxPeg M x y\n=−\n (10) \n()()( )2 1\nM max minxPM x y w eg egn= − +  −\n (11) \n(3) Train and extract model. For Mi, the training data are all the IEs of HRi, as well as \nthe breakpoints valuei and valuei+1 for the constraint  in Equation  (8). We normalize d the \ntraining data by the maximum  and minimum,  choose Adam as the optimizer  and used \nthe early stopping  mechanism  to shorten the training time. After training,  to reduce the \ncost of storage and query, we extracted the weights and error bounds from the complex  \ndeep learning framework,  and stored them into Model Pages.  \n3.3. Update Processing  \nAlgorithm  3 shows the pseudo code of the update handling  in SLBRIN.  The cascad-\ning operations  of data update are deconstructed  into serial operations  and parallel opera-\ntions. Serial operation s are blocking  to keep the data consistency,  i.e., the next update can-\nnot be started until the current serial operation  is completed.  Parallel operations  are non-\nblocking  and triggered  by pre-defined conditions,  including  summarize  CR, merge CR \nand retrain model, as shown in Error! Reference source not found. . We further divided \nthem into two sub-operations,  GET and POST, to improve parallelism.  \n \nFigure 2. Update processing  in SLBRIN.  \nAlgorithm  3: Update SLBRIN  \nInput:  p: the data  item  to be updated;  I: our index.  \nFigure 2. Update processing in SLBRIN.\nAlgorithm 3: Update SLBRIN\nInput: p: the data item to be updated; I: our index.\n1:g Encode (p,I.meta .L)\n2:ie (g,p.spatialFields ,p.key)\n3:lastCR I.meta .lastCR\n4:lastCR .num lastCR .num + 1\n5:I.data.append (ie)\n6:Listening Trigger:\n7: lastCR .num >TS)summarize full CRs\n8: ( lastCR –lastHR )/size(CR) >TM)merge outdated CRs\n9: newErr/oldErr >TE)retrain models of inefﬁcient HRs\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 9 of 24\n(1)Build IE. As with build processing, we ﬁrst encoded the updated data by Geohash\nand built the new IE(Lines 1–2). To simplify the modiﬁcation and deletion of data, we\nuniﬁed them as insertions. For example, the modiﬁcation takes the modiﬁed value as key,\nwhile deletion takes null as key.\n(2)Insert to CR. The new IEis stored in CRtemporarily and will be persisted into HR\nafter merging CR. The speciﬁc operation is to increment the attribute num of the last CR,\nand append the new IEto Data Pages (Lines 3–5).\n(3)Summarize CR (Parallel). Summarizing CRaims to create summary info to enhance\nthe performance of the last CR. In most cases, only the last CRneeds to be summarized, but\ngiven that it takes time to summarize, multiple CRs may be summarized at the same time.\nIf queries come when the last CRis not full, the summarizing can be advanced passively.\n(a) GET: monitor the num of the last CR; once num reaches TS, update the attribute state to 1\nand append an empty CRto the last CRPages. (b) POST: collect all the full CRs (state = 1);\nfor each full CR, summarize MBR, update value with MBR and reset status .\n(4)Merge CR (Parallel). Merging CRaims to transfer IEs from CRtoHRto decrease\nthe slow query in CRs and increase the fast query in HRs. We merged only the oldest TM\nCRs to decouple from the IEinsertion. (a) GET: monitor the total number of CRs; once the\nnumber reaches TM, update the state of the ﬁrst TM CR s to 2. The number of CRs can be\ncalculated based on the attributes *lastCR and *lastHR of Meta using Equation (12), where\nsize(CR) is the physical size of CR. (b) POST: collect all outdated CRs (state = 2); partition all\ntheIEs of the outdated CRs into several parts by the way of HRpartitioning (Lines 5–19 of\nAlgorithm 2); match all the IEparts and HRs on the same geohash code, and merge their\nIEs in Data Pages; delete the ﬁrst TM CR s from CRPages.\nnCR=*lastCR\u0000*lastHR\nsize(CR)(12)\n(5)Retrain M (Parallel). After merging CR, we needed to correct the error bounds\nfor models relative with the updated HRs. The retraining model aims to reduce the error\nbounds for all updated models to stabilize their query performance. (a) GET: monitor the\nattributes minErr and maxErr of the updated models; once the new error bound exceeds the\nold error bound by TEtimes, update the state of its relative HRto 1. (b) POST: collect all\ninefﬁcient HRs (state = 1); for each inefﬁcient HR, retrain its model with the new IEs, update\nit into Model Pages and reset state. Before retraining, we also used breakpoints to maintain\nthe monotonicity in Equation (8).\nThe temporal proximity of spatial distribution shows that spatial data in continuous\ntime have similar spatial distribution [ 46]. In other words, given a spatio-temporal dataset\nwith the spatial distribution as D, when its cardinality is sufﬁcient, its sub-dataset at any\ntime has the similar spatial distribution to D.Based on this, we propose the following two\nhypotheses for SLBRIN:\n1. For overall HRor any CR, in case of sufﬁcient IEs, the spatial distribution tends to D.\n2. The scope of the local range can be encoded uniquely as gby Geohash. For any local\nrange , in case of sufﬁcient IEs, its spatial distribution Dgtends to the part of Din the\nscope g.\nIn real-time spatial scenarios, the IEs inHRand CRare often sufﬁcient to support these\nhypotheses. Even for the insufﬁcient IEs, the insigniﬁcant trends in the hypotheses are still\nbeneﬁcial for optimizing the update processing.\nBased on hypothesis 1, the overall HRhas the optimal query performance as its spatial\ndistribution tends to D. However, the opposite is true for CR. When the spatial distribution\nofCRtends to D, the spatial ﬁltering ability of MBR degrades rapidly. So, TSshould be\nsmall enough to avoid hypothesis 1 to hold in CR.\nBased on hypothesis 2, for any range during merging CRand any HR, its spatial\ndistribution only depends on its geohash code. Therefore, we used DGM to solve the\nCartesian product between the outdated CRs and HRs, reducing the time complexity of\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 10 of 24\nmerging CRfrom O(nm) toO(n + m ), where nand mis the number of range s. From another\nperspective of hypothesis 2, the range s with the same scope have similar spatial distribution.\nAfter merging CR, for the updated HRs, their old models have a certain ability to ﬁt the\nnew spatial distribution. So, we only updated their error bounds based on Equations (9)\nand (10) rather than retraining.\nThe updated HRmay be partitioned into several child range s, whose models can\ninherit from the parent HRwithout retraining. In d= 2, we took the ﬁrst of the four child\nrange s as an example to present the derivation process of model inheritance:\n1. The child’s input domain [ \u00000.5, 0.5] corresponds that of parent [ \u00000.5,\u00000.25], so the\ninput layer of MLP is calculated as follow:\nY=Sigmoid\u0010\nWi\u0010\n0.25\u0010\nYT+0.5\u0011\n\u00000.5\u0011\n+Bi\u0011\n(13)\n2. The child’s output domain [0, 1] corresponds that of parent [ M(\u00000.5), M(\u00000.25)], so\nthe output layer of MLP is calculated as follow:\nY=\u0000\nWoYT+Bo\u0001\u0000M(\u00000.5)\nM(\u00000.25)\u0000M(\u00000.5)(14)\nAbove, M(x) is the attribute matrices of parent model, Wi,Bi,Wo, and Boare the slope\nand bias of M(x) of the input and output layers, respectively. In summary, the model\ninheritance of the ﬁrst child is as shown in Equations (15) and (16).\nWi=0.25Wi,Bi=\u00000.375 Wi+Bi (15)\nWo=Wo\nM(\u00000.25)\u0000M(\u00000.5),Bo=Bo\u0000M(\u00000.5)\nM(\u00000.25)\u0000M(\u00000.5)(16)\nInefﬁcient HRmeans that its learned model no longer tends to Dg, which is basically\ncaused by three cases: (1) The old IEs are not sufﬁcient resulting in that the old distribution\ndoes not reach Dg. (2) The new IEs are not sufﬁcient resulting in that the overall distribution\nis deviated from Dg. (3) The long-term accumulated error bound eventually reaches TE. In\neither case, the old learned model can still ﬁt Dgto some extent, and thus we can initialize\nthe new model with the attribute matrices of old model to shorten the retraining time and\nnarrow the error bound.\n3.4. Query Processing\nBased on the SLBRIN’s structure, we designed the query strategy based on learned\nindex and spatial location code, including point query, range query and kNN query. We\nalso considered the repetition of spatial data during the query processing.\n3.4.1. Point Queries\nGiven a query point p, the target keys may exist in both HRs and CRs. The query\nprocessing, as shown in Algorithm 4, can be detailed into the following three steps:\nAlgorithm 4: Point Query\nInput: p: a point query; I: our index.\nOutput: result : the key to p.\n1:crLsit search crfrom I.CRswhere cr.value\u001bp\n2:result search iefrom crLsit where ie=p\n3:g Encode (p,I.Meta .L)\n4:hr DGM (I.HRs, g)\n5:model hr.model\n6:pre model .predict (g)\n7:result .push (MBS (I.IEs,pre,model ))\n8:return result\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 11 of 24\n(1)Filter CR s. The MBR and IEs ofCRare both unordered. To collect the target keys in\nCRs, we traversed all the CRs to ﬁnd the candidate CRs whose MBR contains p, and then\nﬁlter the IEsin all candidate CRs (Lines 1–2).\n(2)Filter HR s. The value ofHRis monotonic decimal geohash code. To compare with\nit, we encoded ptogand then use DGM to ﬁnd the candidate HR(Lines 3–4).\n(3)Filter in HR. The IEs in candidate HRcan be ﬁltered by replicating the forward\npropagation of MLP (Lines 5–6). It mainly includes three steps: (a) Normalize gwith the\nvalues of candidate HRand its next HRas the minimum and maximum. (b) Compute the\nresult by matrix operations with g,as in Equation (17), where the output of each layer\nis used as the input of the next layer, and the last layer does not use activation function.\n(c) Inversely normalize the result with the physical space of HR, and ﬁnally obtain the\npredicted physical location preof the query point p.\nY=Sigmoid\u0010\nWYT+B\u0011\n(17)\nAs the principle of learned index [ 5],p.key must lie within the error bound, as in\nEquation (18), which can be found out by Model Biased Search ( MBS ) (Line 7). The\ndifference of MBS from binary search is that its initial position is pre, which is more suitable\nfor the learned index.\np.key2[pre\u0000egmax,pre\u0000egmin] (18)\n3.4.2. Range Queries\nRange query aims to ﬁnd all the targets falling in the query range qr. Similar to point\nquery, it also requires the ﬁltering of both CRs and HRs, as shown in Algorithm 5.\nAlgorithm 5: Range Query\nInput: qr: a range query; I: our index.\nOutput: result : the keys falling in qr.\n1:crList search crfrom I.CRswhere cr.value\\qr\n2:result search iefrom crList where ie\u001aqr\n3:pb,ptqr;gb,gt Encode ([pb,pt],I.Meta .L)\n4:rangeList GeohashRangeQuery (gb,gt)\n5:range .hr DGM (I.HRs,range .g)for each range inrangeList\n6: group rangeList byrange .hrand merge range .pos\n7:for each range inrangeList do\n8: get gb,gtwith range .pos;preb,pret range .hr.model .predict ([gb,gt])\n9: keyb,keyt MBS (I.IEs, [preb,pret],range .hr.model )\n10: fork2[keyb,keyt]do\n11: ifiek\u001aqrthen\n12: result .push (k)\n13:return result\n14:\n15:function GeohashRangeQuery (gb,gt)\n16: initial rangeList ;l Max (Len(gb),Len(gt))\n17: gxb,gyb,gxtgyt Decode ([gb,gt],l)\n18: gxl gxt-gxb;gyl gyt-gyb\n19: gList Encode (gx,gy,L)forgx2[gxb,gxt],gy2[gyb,gyt]\n20: forgingList do\n21: pos check position by gxl,gyl\n22: rangeList .push (CreateRange (g,pos))\n23: sort rangeList byrange.g\n24: return rangeList\n(1)Filter CR s. We ﬁltered CRs to ﬁnd the candidates whose MBR intersects qr, and\nthen ﬁltered the candidates to obtain the target keys contained by qr(Lines 1–2).\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 12 of 24\n(2)Filter HR s. Figure 3 shows the process to ﬁlter HRs, where the grid layout represents\nthe spatial distribution of HRs. In line 3, qris simpliﬁed to the decimal geohash codes gb\nand gtof the bottom-left corner pband top-right corner pt, as shown in Figure 3a. The\njudgement of whether qrcontains pis also simpliﬁed as Equation (19).\np.cord i\n8i2d2[qri,min,qri,max])gp2[gb,gt] (19)\nFor ordered data, we can obtain the key range only by the left and right bounds of qr.\nHowever, Geohash is not a complete order, so qrcontains several key ranges of geohash\ncode in most cases. We designed the geohash range query method to ﬁnd the candidate\nHRs and determine their spatial relationship with qr. As shown in Algorithm 5, we used a\nseparate function GeohashRangeQuery () to show its details.\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  12 of 24 \n \n 8:     get gb, gt with range.pos; preb, pret\nrange.hr.model.predict([gb, gt]) \n9:     keyb, keyt\nMBS(I.IEs, [preb, pret], range.hr.model)  \n10:     for k\n[keyb, keyt] do \n11:         if iek ⸦ qr then  \n12:             result.push(k)  \n13: return result  \n14: \n15: function  GeohashRangeQuery (gb, gt)  \n16:     initial rangeList ; l\nMax(Len(gb), Len(gt)) \n17:     gxb, gyb, gxt gyt\nDecode([gb, gt], l)  \n18:     gxl\ngxt - gxb; gyl\ngyt - gyb \n19:     gList\nEncode(gx, gy, L) for gx\n[gxb, gxt], gy\n[gyb, gyt] \n20:     for g in gList do \n21:         pos\ncheck position by gxl, gyl \n22:         rangeList .push(CreateRange (g, pos)) \n23:     sort rangeList  by range.g  \n24:     return rangeList  \n(1) Filter CRs. We filtered CRs to find the candidates  whose MBR intersects qr, and \nthen filtered the candidates  to obtain the target keys contained  by qr (Lines 1–2). \n(2) Filter HRs. Error! Reference source not found.  shows the process to filter HRs, \nwhere the grid layout represents  the spatial distribution  of HRs. In line 3, qr is simplified  \nto the decimal geohash codes gb and gt of the bottom-left corner pb and top-right corner pt, \nas shown in Error! Refer ence source not found. a. The judgement  of whether qr contains \np is also simplified  as Equation  (19). \n,,. , ,i i min i max p b t\nidp cord qr qr g gg\n    \n (19) \nFor ordered data, we can obtain the key range only by the left and right bounds of qr. \nHowever,  Geohash  is not a complete  order, so qr contains several key ranges of geohash \ncode in most cases. We designed the geohash range query method to find the candidate  \nHRs and determine  their spatial relationship  with qr. As shown in Algorithm  5, we used \na separate function GeohashRangeQuery () to show its details. \n   \n(a) (b) (c) \nFigure 3. Range query processing  in SLBRIN.  (a) Spatial range query. (b) Use spatial location code \nto mark candidate  ranges. (c) Filter candidate  HRs. \n1. Calculate  the granularity  of candidate  ranges. A moderate  granularity  helps to filter \nHRs effectively.  The granularity  l lies between the maximum  geohash length of all \nFigure 3. Range query processing in SLBRIN. ( a) Spatial range query. ( b) Use spatial location code to\nmark candidate range s. (c) Filter candidate HRs.\n1. Calculate the granularity of candidate ranges . A moderate granularity helps to ﬁlter\nHRs effectively. The granularity llies between the maximum geohash length of all\ncandidate ranges and L. We used the larger geohash length of gband gt, which yields\nthe best performance in experiments (Line 16).\n2. Decode gband gtinto one-dimensional geohash code gxb,gyb,gxt,gytby Geohash,\nand calculate the number of candidate ranges along horizontal and vertical directions\nasgxland gyl(Lines 17–18).\n3. Create the Cartesian product by all one-dimensional geohash codes in the domain of\n[gxb,gxt] and [ gyb,gyt], and encode each member by Geohash as gList (Line 19).\n4. In spatial, each range ingList is contained or intersected by qr. In lines 20–22, we\nmarked the spatial relationship between range and qrwith the spatial location code,\nwhich consists of four binary bits, indicating that range intersects the bottom, top, left,\nright of qr, respectively. For example, a spatial location code of [1 0 0 0] means the range\nintersects the bottom of qr. Based on the order of the Cartesian product, we conﬁrmed\nthat the ﬁrst gxl range s intersect the bottom of qr, and the last gxl range s intersect the\ntop of qr. In addition, the range s whose sequence is divisible by gylintersect the left\nofqr, and their previous range s intersect the right of qr. All the others are contained\nbyqr, initialized as [0 0 0 0]. As a range has multiple spatial relationships with qr, the\nspatial position codes can be combined with the OR operation, i.e., [1 0 0 0] |[0 0 1 0]\n= [1 0 1 0] means the range intersects the bottom and left corner of qr, and [1 1 1 1]\nmeans the range contains qr.\n5. Sort rangeList by decimal geohash code (Line 23).\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 13 of 24\nAs shown in Figure 3b, the candidate range s inrangeList are a set of grids with uniform\nspatial scope, and are inconsistent with HRs in terms of geohash length. So, we need to\nsolve the many-to-many connections between candidate range s and HRs, which can be\naccelerated by DGM . As shown in Figure 3c, we ﬁnally obtained all the candidate HRs as\nwell as their spatial location codes (Lines 5–6).\n(3)Filter in HR. First, we obtained the two corners gband gtof the spatial intersection\nbetween HRand qrwith spatial location code. Then, we used a learned model to obtain the\npredicted physical locations keyband keytand form a key range of [ keyb,keyt] (Lines 8–9).\nDue to the jumping nature of SFC, the IEs within the key range were probably not contained\nbyqr. So, a second scan was required. We simpliﬁed the judgement in Equation (19) using\nspatial position code. For example, we only judged p.cord y\u0015bottom for the HRintersecting\nthe bottom of qr, and there was no second scan for the HRcontained by qr.\n3.4.3. kNN Queries\nWe designed a bottom-up kNN query strategy as Algorithm 6. As CRis not friendly\ntokNN query, we ﬁltered HRs ﬁrst to narrow the query scope for CR. Given a point pand a\nnumber k, we used a priority queue pQueue to store the target keys. It always contained k\npoints with the smallest distance to p. The query processing is as follows:\n(1)Filter HR s. We found the key keypofpby point query (Algorithm 4). Then, we\nselected kpoints nearby keypas the initial result and offer their distance to pinto pQueue\n(Lines 2–5). The current maximum distance of initial result is dst. The jumping nature\nof SFC is likely to bring about a larger dst. However, its probability can be reduced by\nselecting redundant points. We selected kpoints before and after keypas the initial result,\na total of 2 k+ 1 points, which offer the best performance in experiments. The selection\nprocess may cross HRs because of the discontinuity of the physical locations. To solve this,\nwe jumped the pointer with the help of the logical object of HR.\nAlgorithm 6: kNN Query\nInput: p: a point of kNN; k: a positive number of kNN.\nOutput: pQueue : a priority queue contains the nearest kkeys to p.\n1:pQueue PriorityQueue ((-1, +¥),k)\n2: key p PointQuery (p)\n3: for key2[keyp-k,keyp+k] do\n4: pQueue .offer(key,Distance (p,pkey))\n5:dst pQueue .peek()\n6: construct qrwith pand dst\n7:pb,pt qr;gb,gt Encode ([pb,pt],I.Meta .L)\n8:rangeList GeohashRangeQuery (gb,gt)\n9:range .hr DGM (I.HRs,range .g)for each range inrangeList\n10: group rangeList byrange .hrand merge range .pos\n11:range .dst Distance (range .hr,p)for each range inrangeList\n12: sort rangeList byrange .dst\n13:for each range inrangeList do\n14: ifrange .dst>dstthen\n15: break\n16: else\n17: get gb,gtwith range .pos;preb,pret range .hr.model .predict ([gb,gt])\n18: keyb,keyt MBS (I.IEs, [preb,pret],range .hr.model )\n19: fork2[keyb,keyt]do\n20: pQueue .offer(key,Distance (p,pkey))\n21: dst pQueue .peek()\n22: update qrbydst\n23:crList search crfrom I.CRswhere cr.value\\q\n24:pQueue .offer(keyie,Distance (p,ie))for each ieincrList\n25:return pQueue\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 14 of 24\nIt is known that the maximum distance to pof the targets must be smaller than dst. To\nﬁnd the candidate HRs, we created a query range qrwith pas center and dstas radius, and\nperformed a range query with qr(Lines 6–11). In contrast to range query, we sorted the\ncandidate HRs by their distance to pin positive order (Line 12).\n(2)Filter in HR. For each candidate HR, we offered all the IEs topQueue and updated\ndstat the end of each loop (Line 13–21). Once the distance of candidate HRexceeds dst, we\nbroke the loop early, as all the subsequent candidates were out of the query scope.\n(3)Filter CR s. For the range query of CR, the smaller the query range, the greater the\nﬁltering ability of MBR. After ﬁltering in HR, the query scope of pQueue is close enough to\nthe scope of targets, which is efﬁcient to ﬁlter CRs. We took the latest dstofpQueue as the\nradius of qr, and performed a range query with qrforCR(Lines 22–24). Eventually, all the\npoints in pQueue are the targets of kNN query.\n4. Experiments\nIn this section, we report on the experimental studies that compare SLBRIN with\nselected alternative methods.\n4.1. Experimental Settings\nAll experiments were implemented in Python 3.7.10 and executed on a 64-bits Ubuntu\n16.04 with a 3.50 GHz Intel Xeon CPU E5, 8 GB RAM and a 1 TB hard disk.\nDatasets . We used the following spatial datasets. Each dataset is sorted by the temporal\nﬁeld. We selected the ﬁrst half to build indices and test the query performance, and inserted\nthe other half into indices to test the update performance.\n1. NYCT is a historical repository of 750 million rides of taxi medallions over a period\nof four years (2010–2013) in New York City [ 47]. We extracted the part of January and\nFebruary 2013, about 28,236,977 records (2.84 GB in size), with the pickup time as\ntemporal ﬁeld and the pickup coordinates as spatial ﬁelds.\n2. UNIFORM and NORMAL are synthetic datasets in uniform and normal distributions.\nThe synthetic data falls into the unit square, with a random temporal ﬁeld and the\nsame cardinality as NYCT (1.58 GB in size).\nCompetitors . We compared with the following indices:\n3. R-tree [3] ( RT): The most typical spatial index.\n4. Point range quadtree [ 27] (PRQT ): A variant of quad-tree, balancing the cardinality\nbetween partitions with a threshold, similar to HR.\n5. BRIN-Spatial [14] ( BRINS ): The spatial variant of BRIN with MBR as summary info.\n6. Z-order model [ 7] (ZM): A classical spatial learned index using Z-curve to reduce\ndimensionality. We used Geohash instead of Z-curve for ease of comparison.\n7. LISA [15]: A spatial learned index structure designed for disk-resident spatial data,\nwhich has shown strong query performance.\nImplementation. We used the original implementation of all the competitors following\ntheir papers. The environment variables were set as follows: page size was 4096 bytes,\naddress size was 4 bytes and the spatial ﬁelds and decimal geohash code were stored in\ndouble (8 bytes) and long integer (8 bytes), respectively. For RT, we used a node capacity of\n113 and stored a single node per page. For PRQT, we implemented the breadth-ﬁrst search\nversion with a threshold of 500, which shows the best performance during grid search. For\nBRINS, we sorted data by Geohash and took 64 pages per range . For SLBRIN, ZM and\nLISA, we used the same MLP and determined the hyper-parameters as learning_rate = 0.1,\nbatch_num = 64, w= 10.\nEvaluation Metrics. To evaluate the performance of all competitors, we used three\nkinds of metrics. For build processing, we used index size to show storage cost and build\ntime to show build performance. For query processing, we used query time and IO cost to\nshow query performance. Query time indicates the average response time for a query; IO\ncost indicates the average number of pages to be loaded for a query, which serves as an\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 15 of 24\nimportant indicator for the index based on external memory. For update processing, we\nused update time to show update performance, which indicates the average response time\nof for an update.\n4.2. Effect of Thresholds\nWe ﬁrst study the effect of the ﬁve thresholds on the performance of SLBRIN.\nTL.TLis the maximum level of HRpartitioning, which ensures HR’s spatial scope is\nalways larger than the data precision. Generally, TLis less than L, which is calculated by\nthe scope and precision of dataset (Section 3.2). We set TL= 40, when L= 52 for all datasets.\nTN.TNis the maximum number of HR’sIEs. If HRstores more IEs than TNduring\nthe building processing or update processing, it needs to be partitioned. In addition, TN\nis closely related to the query performance of HR, so we built SLBRIN on NYCT with TN\nvarying from 5 K to 20 K and report the range query performance. As shown in Figure 4a,\nincreasing TNalways increases the IO cost. This is expected because the larger TNbrings\nabout the larger error bounds, resulting in ﬁltering out more unqualiﬁed IEs. However, the\naverage query time decreases and then increases progressively. That is because when TNis\nless than 10 K, the cost to ﬁlter HRs is more expensive than the cost to ﬁlter the IEs within\nHRs. So, we set TN= 10 K which has the lowest query time.\nTS.Corresponding to TN,TSis the maximum number of CR’sIEs and is related to\nthe query performance of CR. We also varied TSfrom 5 K to 20 K and insert NYCT into\nan empty SLBRIN, so as to only test the range query performance of CR. As shown in\nFigure 4b, the average query time presents a down and up trend, whereas the lowest\nvalue turns out at TS= 10 K, as the best TSis a trade-off between ﬁlter CRs and ﬁlter IEs.\nAccording to hypothesis 1 (Section 5), the spatial distribution of large CRtends to S, which\nlowers the earning of ﬁltering CRs. In other words, although the number of CRs decreases,\nthe number of candidate CRs increases, and more IEs need to be ﬁltered. We set TS= 10 K.\nTM. TM is the number of CRs to be merged into HRs at one time. Since HRoutperforms\nCRin query performance, we should handle as many CRs as possible in update processing.\nIn a production environment, we adjust TMdynamically according to the actual update\nworkload. We set TM= 50 for ease of experiments.\nTE. TE is the critical ratio of error bound to trigger the model retraining for HRs. After\nmerging CRs, we update the error bounds for all relative HRs. However, HRs are retrained\nonly when their error bounds are TEtimes the old. The smaller the TE, the more frequent\nthe retraining, but also the better the query performance of HR. We recommend setting\nTE= 1.5 to reduce the frequency of model retraining properly.\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  16 of 24 \n \n large CR tends to S, which lowers the earning of filtering CRs. In other words, although  \nthe number of CRs decreases,  the number of candidate  CRs increases , and more IEs need \nto be filtered. We set TS = 10 K. \nTM. TM is the number of CRs to be merged into HRs at one time. Since HR outper-\nforms CR in query performance,  we should handle as many CRs as possible in update \nprocessing.  In a production  environment,  we adjust TM dynamically  according  to the ac-\ntual update workload.  We set TM = 50 for ease of experiments.  \nTE. TE is the critical ratio of error bound to trigger the model retraining  for HRs. After \nmerging CRs, we update the error bounds for all relative HRs. However,  HRs are retrained  \nonly when their error bounds are TE times the old. The smaller the TE, the more frequent \nthe retraining,  but also the better the query performance  of HR. We recommend  setting TE \n= 1.5 to reduce the frequency  of model retraining  properly.  \n  \n  \n(a) (b) \nFigure 4. Effect of thresholds  on range query. (a) TN. (b) TS. \n4.3. Build Performance  \nThe first set of experiments  studies the build performance  under different  datasets.  \nIndex size. The index size contains two parts: (1) IE size. BRINS, ZM, LISA and \nSLBRIN,  are all larger than the others (387.4 MB vs. 276.7 MB), as they record the mapped \ngeohash code additionally.  (2) Index structure size, as shown in Error! Reference source \nnot found. a. R-tree (660.4 MB) is the largest, even larger than its IEs because it stores a \nlarge number of MBRs. It is followed  by PRQT (5.9 MB) that stores only a small amount \nof MBRs. BRINS (0.04 MB) is the smallest,  indicating  that the storage cost of range is ex-\ntremely low. Under the premise of the same number of sub-models, SLBRIN is smaller \nthan ZM and LISA, which also benefits from range structure  (7.2 MB vs. 7.4 MB, 18.6 MB). \n \n  \n(a) (b) \nFigure 5. Build performance  vs. data distribution.  (a) Index structure  size. (b) Build time.  \nFigure 4. Effect of thresholds on range query. ( a)TN. (b)TS.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 16 of 24\n4.3. Build Performance\nThe ﬁrst set of experiments studies the build performance under different datasets.\nIndex size. The index size contains two parts: (1) IE size . BRINS, ZM, LISA and SLBRIN,\nare all larger than the others (387.4 MB vs. 276.7 MB), as they record the mapped geohash\ncode additionally. (2) Index structure size , as shown in Figure 5a. R-tree (660.4 MB) is the\nlargest, even larger than its IEs because it stores a large number of MBRs. It is followed by\nPRQT (5.9 MB) that stores only a small amount of MBRs. BRINS (0.04 MB) is the smallest,\nindicating that the storage cost of range is extremely low. Under the premise of the same\nnumber of sub-models, SLBRIN is smaller than ZM and LISA, which also beneﬁts from\nrange structure (7.2 MB vs. 7.4 MB, 18.6 MB).\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  16 of 24 \n \n large CR tends to S, which lowers the earning of filtering CRs. In other words, although  \nthe number of CRs decreases,  the number of candidate  CRs increases , and more IEs need \nto be filtered. We set TS = 10 K. \nTM. TM is the number of CRs to be merged into HRs at one time. Since HR outper-\nforms CR in query performance,  we should handle as many CRs as possible in update \nprocessing.  In a production  environment,  we adjust TM dynamically  according  to the ac-\ntual update workload.  We set TM = 50 for ease of experiments.  \nTE. TE is the critical ratio of error bound to trigger the model retraining  for HRs. After \nmerging CRs, we update the error bounds for all relative HRs. However,  HRs are retrained  \nonly when their error bounds are TE times the old. The smaller the TE, the more frequent \nthe retraining,  but also the better the query performance  of HR. We recommend  setting TE \n= 1.5 to reduce the frequency  of model retraining  properly.  \n  \n  \n(a) (b) \nFigure 4. Effect of thresholds  on range query. (a) TN. (b) TS. \n4.3. Build Performance  \nThe first set of experiments  studies the build performance  under different  datasets.  \nIndex size. The index size contains two parts: (1) IE size. BRINS, ZM, LISA and \nSLBRIN,  are all larger than the others (387.4 MB vs. 276.7 MB), as they record the mapped \ngeohash code additionally.  (2) Index structure size, as shown in Error! Reference source \nnot found. a. R-tree (660.4 MB) is the largest, even larger than its IEs because it stores a \nlarge number of MBRs. It is followed  by PRQT (5.9 MB) that stores only a small amount \nof MBRs. BRINS (0.04 MB) is the smallest,  indicating  that the storage cost of range is ex-\ntremely low. Under the premise of the same number of sub-models, SLBRIN is smaller \nthan ZM and LISA, which also benefits from range structure  (7.2 MB vs. 7.4 MB, 18.6 MB). \n \n  \n(a) (b) \nFigure 5. Build performance  vs. data distribution.  (a) Index structure  size. (b) Build time.  \nFigure 5. Build performance vs. data distribution. ( a) Index structure size. ( b) Build time.\nBuild time. Figure 5b reports the build time across data distribution. RT and PRQT\nare 1394.3 s and 238.8 s, respectively. BRINS (115.3 s) is the fastest because both writing\nIEs sequentially and summarizing range have low IO cost, which is the same with CRof\nSLBRIN. Due to training models, HRof SLBRIN, ZM and LISA are the slowest (2636.9 s vs.\n2752.0 s, 8797.3 s), which can be accelerated with GPU and multi-process. With RTX 1080 Ti\nGPU and 5 parallel processes, SLBRIN reduces the build time by 8.2 times (320.0 s), but\nZM only reduces by 5.9 times (469.5 s) and LISA only reduces by 4.3 times (1795.4 s). This\nis because the concurrency of ZM and LISA is limited within stages and the lower stage\nwill wait for the upper stage to calculate the training data. In contrast, SLBRIN, directly\npartitioned based on data distribution, offers higher concurrency in build processing.\n4.4. Point Query Performance\nThe second set of experiments studies the point query performance under different\ndatasets. We randomly sampled 1000 points in each dataset as query points, and report the\nquery time and IO cost per point query.\nQuery time. Figure 6a reports the query time across different datasets. SLBRIN offers\nthe best query performance on both synthetic and real datasets. It improves the query time\nby at least 2.8 times and up to 6.3 times compared with the competitors, i.e., 41.5 \u0016s vs.\n117.3 \u0016s (ZM) and 260.0 \u0016s (LISA) on NYCT. In the order of UNIFORM, NORMAL and\nNYCT, the complexity of spatial distribution and the query time for all competitors both\nincrease. For example, RT and PRQT are 69.3 \u0016s and 125.0 \u0016s on UNIFORM, but increase\nto 258.4 \u0016s and 154.0 \u0016s on NYCT. This is because, under the complex spatial distribution,\nPRQT and the spatial meaning of RT tend to be unbalanced indicating the performance\ndegradation. In contrast, BRINS, ZM and LISA are more stable, 150.0 \u0016s, 115.1 \u0016s and\n265.3 \u0016s for all datasets, indicating the query performance of range and learned index are\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 17 of 24\nmore stable in terms of spatial distribution. Inheriting both advantages, SLBRIN holds\nlower error bounds, the shortest query time (41.2 \u0016s), and the strongest stability.\nIO cost. Figure 6b reports the IO cost across different datasets, and SLBRIN also\nimproves by at least 1.3 times and up to 3.7 times. On NYCT, BRINS is the highest (308.6),\nas it needs to ﬁlter all IEs within a speciﬁc range . RT and PRQT spend 9.0 and 12.7 on\nﬁltering the tree structure and a speciﬁc leaf node. SLBRIN has a lower IO cost than ZM\nand LISA (7.8 vs. 38.5 and 8.0). This is because SLBRIN optimizes the spatial partition of\nrange and uses the spatial learned index to lower the IO cost within range .\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  17 of 24 \n \n Build time.  Error! Reference source not found. b reports the build time across data \ndistribution. RT and PRQT are 1394.3 s and 238.8 s, respectively. BRINS (115.3 s) is the \nfastest because both writing IEs sequentially and summarizing range have low IO cost, \nwhich is the same with CR of SLBRIN. Due to training models, HR of SLBRIN, ZM and \nLISA are the slowest (2636.9 s vs. 2752.0 s, 8797.3 s), which can be accelerated with GPU \nand multi -process. With RTX 1080 Ti GPU and 5 parallel processes, SLBRIN reduces the \nbuild time by 8.2 times (320.0 s), but ZM o nly reduces by 5.9 times (469.5 s) and LISA only \nreduces by 4.3 times (1795.4 s). This is because the concurrency of ZM and LISA is limited \nwithin stages and the lower stage will wait for the upper stage to calculate the training \ndata. In contrast, SLBRIN,  directly partitioned based on data distribution, offers higher \nconcurrency in build processing.  \n4.4. Point Query Performance  \nThe second set of experiments  studies the point query performance  under different  \ndatasets.  We randomly  sampled 1000 points in each dataset as query points, and report \nthe query time and IO cost per point query.  \nQuery time. Error! Reference source not found. a reports the query time across differ-\nent datasets.  SLBRIN offers the best query performance  on both synthetic  and real da-\ntasets. It improves  the query time by at least 2.8 times and up to 6.3 times compared  with \nthe competitors,  i.e., 41.5 µs vs. 117.3 µs (ZM) and 260.0 µs (LISA) on NYCT. In the order \nof UNIFORM,  NORMAL  and NYCT, the complexity  of spatial distribution  and the query \ntime for all competitors  both increase. For example,  RT and PRQT are 69.3 µs and 125.0 \nµs on UNIFORM,  but increase to 258.4 µs and 154.0 µs on NYCT. This is because, under \nthe complex  spatial distribution,  PRQT and the spatial meaning  of RT tend to be unbal-\nanced indicating  the performance  degradation.  In contrast,  BRINS, ZM and LISA are more \nstable, 150.0 µs, 115.1 µs and 265.3 µs for all datasets,  indicating  the query performance  of \nrange and learned index are more stable in terms of spatial distribution.  Inheriting  both \nadvantages,  SLBRIN holds lower error bounds, the shortest query time (41.2 µs), and the \nstrongest  stability.  \nIO cost. Error! Reference source not found. b reports the IO cost across different  da-\ntasets, and SLBRIN also improves  by at least 1.3 times and up to 3.7 times. On NYCT, \nBRINS is the highest (308.6), as it needs to filter all IEs within a specific range. RT and \nPRQT spend 9.0 and 12.7 on filtering the tree structure  and a specific leaf node. SLBRIN \nhas a lower IO cost than ZM and LISA (7.8 vs. 38.5 and 8.0). This is because SLBRIN opti-\nmizes the spatial partition  of range and uses the spatial learned index to lower the IO cost \nwithin range. \n \n  \n(a) (b) \nFigure 6. Point query performance  vs. data distribution.  (a) Query time. (b) IO cost.  \n4.5. Range Query Performance  \nFigure 6. Point query performance vs. data distribution. ( a) Query time. ( b) IO cost.\n4.5. Range Query Performance\nThe third set of experiments studies the range query performance under different\ndata distributions and different query range sizes. We generated 1000 random windows\nwithin the scope of each dataset as query ranges and report the query time and IO cost per\nrange query.\nVarying the data distribution. As Figure 7a,b shows, SLBRIN offers the best query\nperformance on all datasets and the largest improvement on NYCT across all datasets. On\nNYCT, compared with the competitors, it improves the query time by at least 9.8 times\nand up to 76.4 times (0.2 ms vs. LISA’s 2.3 ms and ZM’s 17.9 ms), and improves the IO\ncost by at least 1.7 times and up to 30.1 times (67.1 vs. LISA’s 115.9 and ZM’s 2018.6).\nConversely, ZM and LISA show the worst performance on NYCT than the other datasets.\nIn addition, ZM shows the worst performance of all competitors, as the jumping nature of\nSFC makes its range queries ﬁlter out vast invalid IEs. It indicates that SLBRIN learns the\nspatial distribution better, and its range query strategy with spatial location code effectively\nreduce the ﬁltering of IEs.\nVarying the query range size. We varied the query range size from 0.0006% to 0.16%\nof the dataset scope and report the query time and IO cost on NYCT as Figure 7c,d. The\nquery performance of SLBRIN is optimal for all range sizes, and the larger the range size,\nthe higher the improvement. We measured the stability of query performance over range\nsize by the growth ratio of query time. When the range size is small, RT takes on a natural\nadvantage in ﬁltering nodes and has a query performance close to SLBRIN. When the range\nsize is large, the inefﬁcient ﬁltering of IEs indicates a rapid performance degradation, with\na high growth ratio of 2.2. ZM, LISA and BRINS beneﬁt from learned index and range ,\nbut also suffer from the jumping nature of SFC. Overall, they have larger query time at all\nrange sizes, but lower growth ratios of 0.2, 1.0 and 0.8. SLBRIN offers a low growth ratio of\n0.7, indicating its query performance is more stable across query range size.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 18 of 24\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  18 of 24 \n \n The third set of experiments  studies the range query performance  under different  \ndata distributions  and different  query range sizes. We generate d 1000 random windows  \nwithin the scope of each dataset as query ranges and report the query time and IO cost \nper range query.  \nVarying the data distribution.  As Error! Reference source not found. a,b shows, SLBRIN \noffers the best query performance  on all datasets and the largest improvement  on NYCT \nacross all datasets.  On NYCT, compared  with the competitors,  it improves  the query time \nby at least 9.8 times and up to 76.4 times (0.2 ms vs. LISA’s 2.3 ms and ZM’s 17.9 ms), and \nimproves  the IO cost by at least 1.7 times and up to 30.1 times (67.1 vs. LISA’s 115.9 and \nZM’s 2018.6). Conversely,  ZM and LISA show the worst performance  on NYCT than the \nother datasets.  In addition,  ZM shows the worst performance  of all competitors,  as the \njumping nature of SFC makes its range queries filter out vast invalid IEs. It indicates  that \nSLBRIN learns the spatial distribution  better, and its range query strategy with spatial \nlocation code effectively  reduce the filtering of IEs. \nVarying the query range size. We varied the query range size from 0.0006% to 0.16% of \nthe dataset scope and report the query time and IO cost on NYCT as Error! Reference \nsource not found. c,d. The query performance  of SLBRIN is optimal for all range sizes, \nand the larger the range size, the higher the improvement.  We measure d the stability of \nquery performance  over range size by the growth ratio of query time. When the range size \nis small, RT takes on a natural advantage  in filtering nodes and has a query performance  \nclose to SLBRIN.  When the range size is large, the inefficient  filtering of IEs indicates  a \nrapid performance  degradation,  with a high growth ratio of 2.2. ZM, LISA and BRINS \nbenefit from learned index and range, but also suffer from the jumping nature of SFC. \nOverall, they have larger query time at all range sizes, but lower growth ratios of 0.2, 1.0 \nand 0.8. SLBRIN offers a low growth ratio of 0.7, indicating  its query performance  is more \nstable across query range size.  \n \n  \n(a) (b) \n  \n(c) (d) \nFigure 7. Range query performance. ( a,b) Vs. data distribution. ( c,d) Vs. query range size on NYCT.  \n4.6. kNN Query Performance  \nFigure 7. Range query performance. ( a,b) Vs. data distribution. ( c,d) Vs. query range size on NYCT.\n4.6. kNN Query Performance\nThe fourth set of experiments studies the kNN query performance under different\ndata distributions and different ks. We randomly generated 1000 kNN queries within the\nscope of each dataset and report the query time and IO cost per kNN query. BRINS and\nZM do not come with a kNN algorithm, so we used RSMI’s kNN algorithm [11] for them.\nVarying the data distribution. Figure 8a,b reports the kNN query performance across\ndifferent datasets. BRINS and ZM offer the highest query time (14.3 ms and 18.8 ms) and\nthe largest IO cost (369.1 and 691.2). In contrast, SLBRIN yields the best query performance\nand the strongest stability across data distribution, with a stable query time of 0.29 ms and\na low IO cost of 10. This indicates SLBRIN’s kNN query strategy effectively reduce the\nﬁltering of invalid IEs caused by the jumping nature of SFC. The query performance of RT\nand PRQT is lower than all the others except SLBRIN, as SLBRIN not only uses the partition\nof spatial indices, but also has lower error bounds than the other spatial learned indices.\nVarying k. We varied the query parameter kfrom 4 to 64 and report the query time and\nIO cost on NYCT as Figure 8c,d. Overall, SLBRIN has the best query performance on all ks.\nIn terms of the stability of query time, SLBRIN (0.30) is second only to RT (0.07) in terms of\nthe stability. In terms of the stability of IO cost, SLBRIN (0.10) is third only to PRQT (0.02)\nand BRINS (0.05). This is expected because ks are much smaller than the capacity of leaf\nnodes or range s. ZM and LISA have the worst stability in both terms, i.e., 0.66 and 0.36\nin query time, 0.54 and 0.45 in IO cost, indicating SLBRIN takes advantage of the learned\nindex better in the kNN query strategy.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 19 of 24\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  19 of 24 \n \n The fourth set of experiments  studies the kNN query performance  under different  \ndata distributions  and different  ks. We randomly  generate d 1000 kNN queries within the \nscope of each dataset and report the query time and IO cost per kNN query. BRINS and \nZM do not come with a kNN algorithm,  so we used RSMI’s kNN algorithm  [11] for them.  \nVarying the data distribution.  Error! Reference source not found. a,b reports the kNN \nquery performance  across different  datasets.  BRINS and ZM offer the highest query time \n(14.3 ms and 18.8 ms) and the largest IO cost (369.1 and 691.2). In contrast,  SLBRIN yields \nthe best query performance  and the strongest  stability across data distribution,  with a sta-\nble query time of 0.29 ms and a low IO cost of 10. This indicates  SLBRIN’s kNN query \nstrategy effectively  reduce the filtering of invalid IEs caused by the jumping nature of SFC. \nThe query performance  of RT and PRQT is lower than all the others except SLBRIN,  as \nSLBRIN not only uses the partition  of spatial indices, but also has lower error bounds than \nthe other spatial learned indices.  \nVarying k. We varied the query parameter k from 4 to 64 and report the query time \nand IO cost on NYCT as Error! Reference source not found. c,d. Overall, SLBRIN has the  \nbest query performance on all ks. In terms of the stability of query time, SLBRIN (0.30) is \nsecond only to RT (0.07) in terms of the stability. In terms of the stability of IO cost, SLBRIN \n(0.10) is third only to PRQT (0.02) and BRINS (0.05). This is expe cted because ks are much \nsmaller than the capacity of leaf nodes or ranges. ZM and LISA have the worst stability in \nboth terms, i.e., 0.66 and 0.36 in query time, 0.54 and 0.45 in IO cost, indicating SLBRIN \ntakes advantage of the learned index better in th e kNN query strategy.  \n \n  \n(a) (b) \n  \n(c) (d) \nFigure 8. kNN query performance.  (a,b) Vs. data distribution.  (c,d) Vs. k on NYCT.  \n4.7. Update Performance  \nThe fifth set of experiments  studies the update performance.  We divided the second \nhalf of each dataset into five group and inserted each group into the index according  to \nthe temporal  field. We report the update time and query performance  for each group up-\ndated points. We also used RSMI’s update algorithm  [11] for ZM, as it does not handle \nupdates.  \nFigure 8. kNN query performance. ( a,b) Vs. data distribution. ( c,d) Vs. kon NYCT.\n4.7. Update Performance\nThe ﬁfth set of experiments studies the update performance. We divided the second\nhalf of each dataset into ﬁve group and inserted each group into the index according to the\ntemporal ﬁeld. We report the update time and query performance for each group updated\npoints. We also used RSMI’s update algorithm [11] for ZM, as it does not handle updates.\nVarying the data distribution. Figure 9a reports the update time across different datasets.\nBRINS beneﬁts from range and has the lowest update time on all datasets. SLBRIN is faster\nthan ZM and LISA, i.e., 1270.9 s vs. 1925.6 s and 2847.6 s on NYCT. This is because, in\naddition to the beneﬁt of range , the update strategy based on the temporal proximity of\nspatial distribution reduces the duration and frequency to retrain the model. However, all\nthe spatial learned indices are slower than RT and PRQT. As with build processing, SLBRIN\ncan also be accelerated by GPU and multi-process, and yields a closer update time to RT\nand PRQT, i.e., 145.2 s vs. 286.2 s and 149.1 on NYCT.\nVarying the updated points. Figure 9b–d report the update time and query performance\nacross the ratio of update points to datasets. BRINS has the lowest update time, but also\nthe highest and fastest rising query time and IO cost, as updated points disrupt its original\nstorage order. With more updates, all competitors increase query time and IO cost, as there\nare more data to query. For all query scenarios, SLBRIN offers not only the best query\nperformance, but also the strongest stability across index updates. For example, the growth\nratios of query time are 0.85 and lower than the best RT of 0.89, and the growth ratios of IO\ncost are 0.31 and lower than the best LISA of 0.38.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 20 of 24\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  20 of 24 \n \n Varying the data distribution.  Error! Reference source not found. a reports the update \ntime across different  datasets.  BRINS benefits from range and has the lowest update time \non all datasets.  SLBRIN is faster than ZM and LISA, i.e., 1270.9 s vs. 1925.6 s and 2847.6 s \non NYCT. This is because, in addition to the benefit of range, the update strategy based on \nthe temporal  proximity  of spatial distribution  reduces the duration  and frequency  to re-\ntrain the model. However,  all the spatial learned indices are slower than RT and PRQT. \nAs with build processing,  SLBRIN can also be accelerated  by GPU and multi-process, and \nyields a closer update time to RT and PRQT, i.e., 145.2 s vs. 286.2 s and 149.1 on NYCT.  \nVarying the updated points. Error! Reference source not found. b–d report the update \ntime and query performance  across the ratio of update points to datasets.  BRINS has the \nlowest update time, but also the highest and fastest rising query time and IO cost, as up-\ndated points disrupt its original storage order. With more updates,  all competitors  in-\ncrease query time and IO cost, as there are more data to query. For all query scenarios,  \nSLBRIN offers not only the best query performance,  but also the strongest  stability across \nindex updates.  For example,  the growth ratios of query time are 0.85 and lower than the \nbest RT of 0.89, and the growth ratios of IO cost are 0.31 and lower than the best LISA of \n0.38.  \n \n  \n(a) (b) \n  \n(c) (d) \nFigure 9. Update performance.  (a,b) Update time vs. data distribution  and updated points. (c,d) \nRange query performance  vs. update points.  \nSLBRIN variants. To demonstrate  the contribution  of each parallel operation  to the \nupdate strategy,  we extended SLBRIN to four variants,  as shown in Table 4. SLBRIN_SCR  \njust summarizes  CR. SLBRIN_MCR  summarizes  and merges CR. SLBRIN_RM  retrains \nmodels with random weights, which is different  from SLBRIN.  \nTable 4. SLBRIN Variants.  \nVariant  Summarize  CR Merge CR Retrain M Retrain M with Old Weights  \nSBRIN_SCR  √ × × × \nSBRIN_MCR  √ √ × × \nFigure 9. Update performance. ( a,b) Update time vs. data distribution and updated points.\n(c,d) Range query performance vs. update points.\nSLBRIN variants. To demonstrate the contribution of each parallel operation to the\nupdate strategy, we extended SLBRIN to four variants, as shown in Table 4. SLBRIN_SCR\njust summarizes CR. SLBRIN_MCR summarizes and merges CR. SLBRIN_RM retrains\nmodels with random weights, which is different from SLBRIN.\nTable 4. SLBRIN Variants.\nVariant Summarize CR Merge CR Retrain MRetrain Mwith\nOld Weights\nSBRIN_SCRp\u0002 \u0002 \u0002\nSBRIN_MCRp p\u0002 \u0002\nSBRIN_RMp p p\u0002\nSBRINp p\u0002p\nWe performed the same update experiments for SLBRIN variants on NYCT and report\nthe update time in Figure 10b. We report the error bounds in Figure 10a, which are critical\nfor the performance of the learned index. SLBRIN-SCR’s error bounds are constant and\nlower than ZM and LISA (268.1 vs. 1400.6 and 466.8), as it does not retrain, and its data-\nbased partition makes HRlearn the spatial distribution better. With more updates, the\nincreasing error bounds of SLBRIN_MCR indicate the old models gradually fail to ﬁt the\nupdated distribution. SLBRIN_RM has lower error bounds and a smaller growth ratio than\nSLBRIN_MCR (340.8 vs. 427.3, 0.54 vs. 1.19), indicating the retraining corrects old models\nto reﬁt the updated distribution. SLBRIN has the lowest error bounds and the smallest\ngrowth ratio (291.3, 0.18), and takes a lower update time than SLBRIN_RM, 1270.9 s vs.\n2190.4 s. It indicates that compared with a random initial model, the old model helps the\nretraining to learn the updated distribution better and faster. In other words, the temporal\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 21 of 24\nproximity of spatial distribution contributes to our update strategy. Figure 10c,d report the\nrange query performance. SLBRIN offers the lowest query time (0.8 ms) and IO cost (80.9)\nacross index updates. SLBRIN_SCR has the lowest error bounds, but also has the highest\nquery time of 1.9 ms and IO cost of 95.2, as CRis far inferior to HRin spatial queries.\nISPRS Int. J. Geo -Inf. 2023 , 12, x FOR PEER REVIEW  21 of 24 \n \n SBRIN_RM  √ √ √ × \nSBRIN  √ √ × √ \nWe performed the same update experiments  for SLBRIN variants on NYCT and re-\nport the update time in Error! Reference source not found. b. We report the error bounds \nin Error! Reference source not found. a, which are critical for the performance  of the \nlearned index. SLBRIN-SCR’s error bounds are constant and lower than ZM and LISA \n(268.1 vs. 1400.6 and 466.8), as it does not retrain, and its data-based partition  makes HR \nlearn the spatial distribution  better. With more updates,  the increasing  error bounds of \nSLBRIN_MCR  indicate the old models gradually  fail to fit the updated distribution.  \nSLBRIN_RM  has lower error bounds and a smaller growth ratio than SLBRIN_MCR  (340.8 \nvs. 427.3, 0.54 vs. 1.19), indicating  the retraining  corrects old models to refit the updated \ndistribution.  SLBRIN has the lowest error bounds and the smallest growth ratio (291.3, \n0.18), and takes a lower update time than SLBRIN_RM,  1270.9 s vs. 2190.4 s. It indicates  \nthat compared  with a random initial model, the old model helps the retraining  to learn \nthe updated distribution  better and faster. In other words, the temporal  proximity  of spa-\ntial distribution  contributes  to our update strategy.  Error! Reference source not found. c,d \nreport the range query performance.  SLBRIN offers the lowest query time (0.8 ms) and IO \ncost (80.9) across index updates.  SLBRIN_SCR  has the lowest error bounds, but also has \nthe highest query time of 1.9 ms and IO cost of 95.2, as CR is far inferior to HR in spatial \nqueries.  \n \n  \n(a) (b) \n  \n(c) (d) \nFigure 10. Update performance  of SLBRIN variants vs. updated points. (a) Error bounds. (b) Update \ntime. (c,d) Range query performance.  \n5. Discussion  \nIn the first experiment,  we showed the impact of five thresholds  on SLBRIN.  (1) TL \nwas calculated  by the scope and precision  of the dataset. (2) TN and TS are critical to the \nquery performance  of HR and CR, respectively.  The experiments  gave an example to find \nthe optimal value according  to the average query time, and we automatically  determine d \nFigure 10. Update performance of SLBRIN variants vs. updated points. ( a) Error bounds. ( b) Update\ntime. ( c,d) Range query performance.\n5. Discussion\nIn the ﬁrst experiment, we showed the impact of ﬁve thresholds on SLBRIN. (1) TL\nwas calculated by the scope and precision of the dataset. (2) TNand TSare critical to the\nquery performance of HRand CR, respectively. The experiments gave an example to ﬁnd\nthe optimal value according to the average query time, and we automatically determined\nTNand TSby means of sample range query in a production environment. (3) Both TMand\nTE are a trade-off between query performance and update performance. We dynamically\nadjusted them based on the ratio of queries and updates. For example, when queries are\nmuch more than updates, we set TM= max and TE= 1.0 so that merging CRand retraining\nHRwas as frequent as possible to improve the overall query performance.\nIn the third to ﬁfth experiments, we compared the query performance of SLBRIN with\nthe traditional spatial indices (RT) and state-of-the-art spatial learned indices (LISA). As\nSLBRIN has the characteristics of range , SFC and spatial partition, we also compared it\nwith BRINS, ZM and PRQT. The experimental results showed that SLBRIN not only offers\nthe best query performance on point query, range query and kNN query, but also has the\nstrongest stability in terms of data distribution, query range size, and k. The reasons are as\nfollows: (1) the index structure based on range is designed for physical storage, which has\nlower IO cost; (2) the partition of HRis beneﬁcial to ﬁt the spatial distribution and earns\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 22 of 24\nlower error bounds; (3) the query strategy with spatial location code effectively reduce the\nﬁltering of invalid IEs caused by the jumping nature of SFC.\nIn the second and sixth experiments, we compared the build performance and update\nperformance of SLBRIN with competitors. Beneﬁting from learned index and lightweight\nrange , SLBRIN offers lower storage cost and better performance in build processing and\nupdate processing. Moreover, SLBRIN exhibits stronger stability of query performance\nduring updates, which is important for real-time spatial scenarios. We extended SLBRIN to\nfour variants and their experimental gaps indicate the effects of three parallel operations\nand temporal proximity of spatial distribution. Retraining models makes spatial learned\nindices slower than spatial indices in build processing and update processing, which can\nbe accelerated by GPU and multi-process. For example, the accelerated SLBRIN has the\nhighest optimization ratio and is even faster than RT and PRQT, which indicates SLBRIN\nhas more reasonable spatial partition and more dynamic index structure.\nSLBRIN relies on the spatio-temporal continuity of spatial distribution and is not\nsuitable for the irregular or fast-changing scenarios. Although all experiments are based\non two-dimensional datasets, all the strategies in SLBRIN, such as HRand spatial location\ncode, are also applicable for multi-dimensional datasets. In addition, both HRand CRcan\nsupport spatial queries and index updates independently, but yield signiﬁcant performance\nshortcomings, which prompts the combination in order complement each other.\n6. Conclusions\nIn this paper, we proposed a novel Spatial Learned index structure based on Block\nRange INdex, SLBRIN, with the concept of range , history range ( HR) and current range\n(CR). We also provided the update strategy and query strategy to meet the urgent demands\nof index updates and spatial queries for real-time spatial data. The contributions of this\nstudy are summarized as follows:\n\u000f For update processing, we deconstructed update transactions into serial and parallel\noperations to improve parallelism, and made full use of the temporal proximity of\nspatial distribution to stabilize query performance and improve update performance.\n\u000f For query processing, we designed the strategies of point query, range query and\nkNN query based on the spatial learned index, and optimized them with the spatial\npartition of HRand the proposed spatial location code.\n\u000f Using synthetic and real data, our extensive experiments showed that SLBRIN outper-\nformed all competitors in storage cost, query performance and update performance.\nFurthermore, SLBRIN offered the strongest performance stability in update processing.\nThis paper opens up several directions for future research on spatial learned index.\nFirst, it is meaningful to adjust the granularity of the spatial location code dynamically\nbased on the workloads. Second, it works in theory to design a more efﬁcient strategy for\nthe spatial join query with spatial location code. Last but not least, the temporal proximity\nof spatial distribution is capable of giving rise to the spatio-temporal learned index.\nAuthor Contributions: Conceptualization, Lijun Wang, Linshu Hu and Feng Zhang; Data curation,\nChenhua Fu and Peng Tang; Funding acquisition, Renyi Liu; Methodology, Lijun Wang, Linshu Hu\nand Chenhua Fu; Project administration, Feng Zhang; Supervision, Feng Zhang; Validation, Lijun\nWang; Writing—original draft, Lijun Wang; Writing—review & editing, Yuhan Yu and Feng Zhang.\nAll authors have read and agreed to the published version of the manuscript.\nFunding: This work was ﬁnancially supported by the National Natural Science Foundation of China\n(42171412, 42050105).\nData Availability Statement: https://github.com/zju-niran/SLBRIN (accessed on 6 January 2022).\nConﬂicts of Interest: The authors declare no conﬂict of interest.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 23 of 24\nReferences\n1. Zhu, Q.; Hu, H.; Xu, C.; Xu, J.; Lee, W. Geo-social group queries with minimum acquaintance constraints. VLDB J. 2017 ,26,\n709–727. [CrossRef]\n2. Manolopoulos, Y.; Nanopoulos, A.; Papadopoulos, A.N.; Theodoridis, Y. R-Trees Have Grown Everywhere. Technical Report.\n2003, p. 3. Available online: http://www.rtreeportal.org (accessed on 6 January 2022).\n3. Guttman, A. R-trees: A dynamic index structure for spatial searching. In Proceedings of the 1984 ACM SIGMOD International\nConference on Management of Data, Boston, MA, USA, 18–21 June 1984; pp. 47–57.\n4. Rigaux, P .; Scholl, M.; Voisard, A. Spatial Databases: With Application to GIS ; Morgan Kaufmann: Burlington, MA, USA, 2003;\nVolume 32, p. 111.\n5. Kraska, T.; Beutel, A.; Chi, E.H.; Dean, J.; Polyzotis, N. The case for learned index structures. In Proceedings of the 2018\nInternational Conference on Management of Data, Houston, TX, USA, 10–15 June 2018; pp. 489–504.\n6. Anselin, L. Lagrange multiplier test diagnostics for spatial dependence and spatial heterogeneity. Geogr. Anal. 1988 ,20, 1–17.\n[CrossRef]\n7. Wang, H.; Fu, X.; Xu, J.; Lu, H. Learned index for spatial queries. In Proceedings of the 20th IEEE International Conference on\nMobile Data Management, Hongkong, China, 10–13 June 2019; pp. 569–574.\n8. Wang, N.; Xu, J. Spatial queries based on learned index. In Proceedings of the 1st International Conference on Spatial Data and\nIntelligence, Hongkong, China, 18–19 December 2020; Springer: Hongkong, China, 2020; pp. 245–257.\n9. Davitkova, A.; Milchevski, E.; Michel, S. The ML-index: A multidimensional, learned index for point, range, and nearest-neighbor\nqueries. In Proceedings of the 2020 23rd International Conference on Extending Database Technology, Copenhagen, Denmark,\n30 March–2 April 2020; pp. 407–410.\n10. Hu, L. Efﬁcient Learning Spatial-Temporal Query and Computing Framework for Geographic Flow Data. Ph.D. Thesis, Zhejiang\nUniversity, Zhejiang, China, 2021.\n11. Qi, J.; Liu, G.; Jensen, C.S.; Kulik, L. Effectively learning spatial indices. Proc. VLDB Endow. 2020 ,13, 2341–2354. [CrossRef]\n12. Gaede, V .; Günther, O. Multidimensional access methods. ACM Comput. Surv. 1998 ,30, 170–231. [CrossRef]\n13. Herrera, A. Block Range Index. Available online: https://www.postgresql.org/docs/9.6/brin.html (accessed on 6 January 2022).\n14. Yu, J.; Sarwat, M. Indexing the pickup and drop-off locations of NYC taxi trips in PostgreSQL—Lessons from the road. In\nProceedings of the 15th International Symposium on Spatial and Temporal Databases, Washington, DC, USA, 21–23 August 2017;\npp. 145–162.\n15. Li, P .; Lu, H.; Zheng, Q.; Yang, L.; Pan, G. LISA: A learned index structure for spatial data. In Proceedings of the 2000 ACM\nSIGMOD International Conference on Management of Data, Dallas, TX, USA, 15–18 May 2000; pp. 2119–2133.\n16. Sagan, H. Space-Filling Curves ; Springer Science & Business Media: New York, NY, USA, 2012; p. 291.\n17. Ramsak, F.; Markl, V .; Fenk, R.; Zirkel, M.; Elhardt, K.; Bayer, R. Integrating the UB-tree into a database system kernel. In\nProceedings of the 26th International Conference on Very Large Data Bases, San Francisco, CA, USA, 10–14 September 2000;\npp. 263–272.\n18. Faloutsos, C.; Roseman, S. Fractals for secondary key retrieval. In Proceedings of the 8th ACM SIGACT-SIGMOD-SIGART\nSymposium on Principles of Database Systems, Philadelphia, PA, USA, 29–31 March 1989; pp. 247–252.\n19. Hughes, J.N.; Annex, A.; Eichelberger, C.N.; Fox, A.; Hulbert, A.; Ronquest, M. Geomesa: A distributed architecture for spatio-\ntemporal fusion. In Proceedings of the Geospatial Informatics, Fusion, and Motion Video Analytics V , Baltimore, MD, USA, 20–24\nApril 2015; pp. 128–140.\n20. Li, R.; He, H.; Wang, R.; Huang, Y.; Liu, J.; Ruan, S.; He, T.; Bao, J.; Zheng, Y. Just: JD urban spatio-temporal data engine. In\nProceedings of the IEEE 36th International Conference on Data Engineering, Dallas, TX, USA, 20–24 April 2020; pp. 1558–1569.\n21. Ni, E. Geohash. Available online: http://geohash.org (accessed on 6 January 2022).\n22. Google. S2 Geometry. Available online: http://s2geometry.io (accessed on 6 January 2022).\n23. Nievergelt, J.; Hinterberger, H.; Sevcik, K.C. The grid ﬁle: An adaptable, symmetric multi-key ﬁle structure. In Proceedings of the\n3rd Conference of the European Cooperation in Informatics, Munich, Germany, 20–22 October 1981; pp. 236–251.\n24. Bentley, J.L. Multidimensional binary search trees used for associative searching. Commun. ACM 1975 ,18, 509–517. [CrossRef]\n25. Finkel, R.A.; Bentley, J.L. Quad trees a data structure for retrieval on composite keys. Acta Inform. 1974 ,4, 1–9. [CrossRef]\n26. Meagher, D. Geometric modeling using octree encoding. Comput. Graph. Image Process. 1982 ,19, 129–147. [CrossRef]\n27. Samet, H. The quadtree and related hierarchical data structures. ACM Comput. Surv. 1984 ,16, 187–260. [CrossRef]\n28. Leutenegger, S.T.; Lopez, M.A.; Edgington, J. STR: A simple and efﬁcient algorithm for R-tree packing. In Proceedings of the 13th\nInternational Conference on Data Engineering, Birmingham, UK, 7–11 April 1997; pp. 497–506.\n29. Sellis, T.; Roussopoulos, N.; Faloutsos, C. The R+-Tree: A dynamic index for multi-dimensional objects. In Proceedings of the 13th\nInternational Conference on Very Large Data Bases, Brighton, UK, 1–4 September 1987; pp. 507–518.\n30. Beckmann, N.; Kriegel, H.; Schneider, R.; Seeger, B. The R*-tree: An efﬁcient and robust access method for points and rectangles.\nIn Proceedings of the 1990 ACM SIGMOD International Conference on Management of Data, Atlantic, NJ, USA, 23–25 May 1990;\npp. 322–331.\n31. Xia, Y.; Prabhakar, S. Q+Rtree: Efﬁcient indexing for moving object databases. In Proceedings of the 8th International Conference\non Database Systems for Advanced Applications, Kyoto, Japan, 26–28 March 2003; pp. 175–182.\n\nISPRS Int. J. Geo-Inf. 2023 ,12, 171 24 of 24\n32. Kamel, I.; Faloutsos, C. Hilbert R-tree: An improved R-tree using fractals. In Proceedings of the 20th International Conference on\nVery Large Data Bases, Santiago, Chile, 12–15 September 1994; pp. 500–509.\n33. Šaltenis, S.; Jensen, C.S.; Leutenegger, S.T.; Lopez, M.A. Indexing the positions of continuously moving objects. In Proceedings of\nthe 2000 ACM SIGMOD International Conference on Management of Data, Dallas, TX, USA, 15–18 May 2000; pp. 331–342.\n34. Li, X.; Li, J.; Wang, X. ASLM: Adaptive single layer model for learned index. In Proceedings of the 2019 24th International\nConference on Database Systems for Advanced Applications, Chiang Mai, Thailand, 22–25 April 2019; pp. 80–95.\n35. Qu, W.; Wang, X.; Li, J.; Li, X. Hybrid indexes by exploring traditional B-tree and linear regression. In Proceedings of the 2019 16th\nInternational Conference on Web Information Systems and Applications, Qingdao, China, 20–22 September 2019; pp. 601–613.\n36. Galakatos, A.; Markovitch, M.; Binnig, C.; Fonseca, R.; Kraska, T. Fiting-tree: A data-aware index structure. In Proceedings of the\n2019 International Conference on Management of Data, Amsterdam, The Netherlands, 30 June–5 July 2019; pp. 1189–1206.\n37. Hadian, A.; Heinis, T. Interpolation-friendly B-trees: Bridging the gap between algorithmic and learned indexes. In Proceedings\nof the 22nd International Conference on Extending Database Technology, Lisbon, Portugal, 26–29 March 2019; pp. 710–713.\n38. Ferragina, P .; Vinciguerra, G. The PGM-index: A fully-dynamic compressed learned index with provable worst-case bounds. Proc.\nVLDB Endow. 2020 ,13, 1162–1175. [CrossRef]\n39. Hadian, A.; Heinis, T. Considerations for handling updates in learned index structures. In Proceedings of the 2019 2nd\nInternational Workshop on Exploiting Artiﬁcial Intelligence Techniques for Data Management, Amsterdam, The Netherlands, 5\nJuly 2019; pp. 1–4.\n40. Kraska, T.; Alizadeh, M.; Beutel, A.; Chi, H.; Kristo, A.; Leclerc, G.; Madden, S.; Mao, H.; Nathan, V . SageDB: A learned database\nsystem. In Proceedings of the 2019 9th Biennial Conference on Innovative Data Systems Research, Asilomar, CA, USA, 13–16\nJanuary 2019.\n41. Nathan, V .; Ding, J.; Alizadeh, M.; Kraska, T. Learning multi-dimensional indexes. In Proceedings of the 2000 ACM SIGMOD\nInternational Conference on Management of Data, Dallas, TX, USA, 15–18 May 2000; pp. 985–1000.\n42. Kipf, A.; Marcus, R.; van Renen, A.; Stoian, M.; Kemper, A.; Kraska, T.; Neumann, T. RadixSpline: A single-pass learned index. In\nProceedings of the 3rd International Workshop on Exploiting Artiﬁcial Intelligence Techniques for Data Management, Portland,\nOR, USA, 14–20 June 2020; pp. 1–5.\n43. Li, Z.; Chan, T.N.; Yiu, M.L.; Jensen, C.S. PolyFit: Polynomial-based indexing approach for fast approximate range aggregate\nqueries. arXiv 2020 , arXiv:2003.08031. [CrossRef]\n44. Zhang, S.; Ray, S.; Lu, R.; Zheng, Y. Spatial interpolation-based learned index for range and kNN queries. arXiv 2021 ,\narXiv:2102.06789. [CrossRef]\n45. Hornik, K.; Stinchcombe, M.; White, H. Multilayer feedforward networks are universal approximators. Neural Netw. 1989 ,2,\n359–366. [CrossRef]\n46. Li, X.; Cao, C.; Chang, C. The ﬁrst law of geography and spatial-temporal proximity. Chin. J. Nat. 2007 ,29, 69–71. [CrossRef]\n47. NYC Open Data. Available online: https://data.ny.gov (accessed on 6 January 2022).\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.",
  "textLength": 99940
}