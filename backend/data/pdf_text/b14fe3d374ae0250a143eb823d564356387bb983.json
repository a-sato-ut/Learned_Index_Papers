{
  "paperId": "b14fe3d374ae0250a143eb823d564356387bb983",
  "title": "LeaFi: Data Series Indexes on Steroids with Learned Filters",
  "pdfPath": "b14fe3d374ae0250a143eb823d564356387bb983.pdf",
  "text": "LeaFi: Data Series Indexes on Steroids with Learned Filters\nQITONG WANG, LIPADE, UniversitÃ© Paris CitÃ©, France\nIOANA ILEANA, LIPADE, UniversitÃ© Paris CitÃ©, France\nTHEMIS PALPANAS, LIPADE, UniversitÃ© Paris CitÃ© & French University Institute (IUF), France\nThe ever-growing collections of data series create a pressing need for efficient similarity search, which serves\nas the backbone for various analytics pipelines. Recent studies have shown that tree-based series indexes\nexcel in many scenarios. However, we observe a significant waste of effort during search, due to suboptimal\npruning. To address this issue, we introduce LeaFi, a novel framework that uses machine learning models\nto boost pruning effectiveness of tree-based data series indexes. These models act as learned filters, which\npredict tight node-wise distance lower bounds that are used to make pruning decisions, thus, improving\npruning effectiveness. We describe the LeaFi-enhanced index building algorithm, which selects leaf nodes and\ngenerates training data to insert and train machine learning models, as well as the LeaFi-enhanced search\nalgorithm, which calibrates learned filters at query time to support the user-defined quality target of each\nquery. Our experimental evaluation, using two different tree-based series indexes and five diverse datasets,\ndemonstrates the advantages of the proposed approach. LeaFi-enhanced data-series indexes improve pruning\nratio by up to 20x and search time by up to 32x, while maintaining a target recall of 99%.\nCCS Concepts: â€¢Information systems â†’Data management systems ;â€¢Computing methodologies â†’\nMachine learning .\nAdditional Key Words and Phrases: Data Series, Similarity Search, Index, Machine Learning\nACM Reference Format:\nQitong Wang, Ioana Ileana, and Themis Palpanas. 2025. LeaFi: Data Series Indexes on Steroids with Learned\nFilters. Proc. ACM Manag. Data 3, N1 (SIGMOD), Article 51 (February 2025), 27 pages. https://doi.org/10.1145/\n3709701\n1 Introduction\nBackground. With the rapid advancements and implementations of modern sensors, there is\na significant rise in the generation, collection, and analysis of large datasets consisting of data\nseries across various scientific fields [ 43]. Common techniques employed in the analysis of data\nseries include classification [ 19], clustering [ 45], pattern mining [ 10], anomaly detection [ 46],\nvisualization [ 23], etc. However, as the data series collection grows largely in scale, it becomes\ncrucial to incorporate similarity search methods to maintain their efficiency and effectiveness [ 42].\nData series similarity search is the technique used to identify the most similar series (usually the\nnearest neighbors) in a dataset, given a query series and a specific similarity measure (usually\nEuclidean distance [11]).\nIndexes are widely employed to speed up series similarity search. Among various series indexing\ntechniques, tree-based indexes have demonstrated state-of-the-art (SOTA) performance in numerous\nscenarios [ 15,16], including in the context of hybrid solutions [ 4,66,69]. A tree-based index is\nbuilt using lower-dimensional summarizations of data series [ 55,65]. Its index structure consists\nof internal nodes, which determine the order of visiting nodes, and leaf nodes, which store the\nAuthorsâ€™ Contact Information: Qitong Wang, LIPADE, UniversitÃ© Paris CitÃ©, Paris, France, qitong.wang@u-paris.fr; Ioana\nIleana, LIPADE, UniversitÃ© Paris CitÃ©, Paris, France, ioana.ileana@parisdescartes.fr; Themis Palpanas, LIPADE, UniversitÃ©\nParis CitÃ© & French University Institute (IUF), Paris, France, themis@mi.parisdescartes.fr.\nThis is the authorâ€™s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version\nof Record was published in Proceedings of the ACM on Management of Data.\nÂ©2025 Copyright held by the owner/author(s).\nACM 2836-6573/2025/2-ART51\nhttps://doi.org/10.1145/3709701\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.arXiv:2502.01836v1  [cs.DB]  3 Feb 2025\n\n51:2 Qitong Wang, Ioana Ileana, & Themis Palpanas\n0 1k 2k 3k 4k\nNumber of searched leaf nodes0.50.60.70.80.91.0Recall-at-1RandWalk\nSeismic\nAstroNearest neighbor foundSearch terminated\n(a) Average recall-at-1 compared to the number of searched DSTree\nleaf nodes. The search algorithm continues after finding the nearest\nneighbors.\n0 1k 2k 3k 4k\nNumber of visited leaf nodes0102030Best-so-far distances\nLower bounds without LeaFiOptimal lower bounds\nLower bounds with LeaFi\n(b) Using the LeaFi predictions ( â˜…) instead of current lower bounds\n(+) boosts the pruning ratio for an Astro query from 23% to 89.4%\n(examples above the best-so-far curve can be pruned). Particularly,\nthe pruning enhancement brought by LeaFi is observed both before\nand after the nearest neighbors are found. The LeaFi filters are\ntrained to predict the optimal lower bounds ( Ã—), which can prune\n99% leaf nodes.\nFig. 1. A waste of data series search time, caused by insufficient pruning, is observed across various datasets.\nEmploying the LeaFi predictions for the optimal lower bounds, instead of the current summarization-based\nlower bounds, improves the pruning ratios significantly.\noriginal series values. Each node uses an aggregated summarized representation of the series it\ncontains, in order to calculate a distance lower bound, which is compared with the best-so-far\nresult to determine if this node can be pruned during query answering.\nMotivation. Tree-based indexes greatly enhance the efficiency of series similarity search. However,\nwe argue that there are still significant opportunities for further acceleration. This potential is\nhighlighted in Figure 1a by the large gap in search time1, between when the nearest neighbor\nresults are found and when they are actually returned [ 22,33]. The search algorithm spends this\nsignificant amount of extra time trying to verify that there is no other better answer. We attribute\nthis inefficiency to the inability of existing tree-based series indexes to provide tight distance lower\nbounds for effective pruning. Figure 1b reveals that only 23% of the summarization-based lower\nbounds (cf. Figure 1b, Lower bounds without LeaFi) exceed the best-so-far distances (cf. Figure 1b,\n1We use the number of searched leaf nodes as a hardware-agnostic surrogate for search time [ 3]. In our context, searching a\nleaf node means calculating the distances for all series it contains. Visiting a node, on the other hand, refers to checking its\nlower bound to determine whether it can be pruned. A leaf node may be visited during a query, but not searched.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:3\nI!L\"I#L#â‹¯â‹¯\nâ‹®\nâ‹®0110passed01101passedğŒğŸ‘\t\t\t\t\t\tL!\nroot\nquery10000ğŒğ¢\t\t\t\t\t\t\t\nprunedL&L#LeafnodewithfilterL!I!InternalnodeLeafnodewithoutfilterNodesummarizationğŒğ¢LearnedfilterConformalAuto-tuner10000\nFig. 2. An illustration of a LeaFi-enhanced tree-based index structure, along with an example of its search\nprocedure.\nblack line), resulting in a 23% pruning ratio for a query on the Astro dataset, which is a rather poor\nperformance.\nOur key insight to this problem focuses on the introduction of the optimal lower bound for\na leaf node, which is the smallest distance between a query and all the series that the leaf node\ncontains; we call this distance the node-wise nearest neighbor distance . By leveraging these node-\nwise distances, 99% of the leaf nodes (up from 23%) can be pruned (cf. Figure 1b, Optimal lower\nbounds). However, directly calculating these distances by searching each leaf node is impractical.\nTo overcome this challenge, we opt to employ machine learning models to predict the node-wise\nnearest neighbor distances. These models act as Learned Filters (LeaFi), improving the pruning\neffectiveness of tree-based series indexes.\nOur solution: LeaFi. In this paper, we introduce LeaFi, a novel general framework that introduces\nmachine learning models into tree-based series indexes to improve their pruning capability for\nsearch acceleration. We name these machine learning models learned filters , and the index that\nuses them LeaFi-enhanced index . In essence, LeaFi carefully places learned filters in a selected\nsubset of leaf nodes, with each filter dedicated to one leaf node. These learned filters are trained to\npredict the node-wise nearest neighbor distances for a given query, which serve as lower bounds\nfor comparison against the best-so-far distance. Since the predictions are much tighter than the\noriginal node summarization-based lower bounds, the leaf node pruning ratios are largely improved.\nIn our example, we go from 23% pruning to 90% pruning (cf. Figure 1b, Lower bounds with LeaFi).\nThough, this comes at the expense of a slight reduction in accuracy, which is controlled by the user\nand can be determined at query time (independently for each query). Note that a LeaFi-enhanced\nindex can always provide exact results (guaranteed 100% recall) for a specific query, simply by\ndisabling the filter-based pruning strategy at query time. Our experimental evaluation shows that\nLeaFi-enhanced indexes achieve a remarkable improvement in pruning ratio (up to 20x more) and\nsearch time (up to 32x faster), while maintaining almost perfect accuracy (i.e., 99% recall).\nFigure 2 illustrates the structure of a LeaFi-enhanced index. For the selected leaf nodes ğ¿2,ğ¿3\nandğ¿ğ‘–, learned filters are paired with their node summarizations. When these nodes are visited\nby a query, a cascade of summarization-based lower bounds and filter predictions are computed\nto determine whether these nodes should be pruned. To the best of our knowledge, LeaFi is the\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:4 Qitong Wang, Ioana Ileana, & Themis Palpanas\nfirst framework that incorporates machine learning models into data series indexes for improving\npruning during similarity search.\nTechnical challenges. Incorporating learned filters into tree-based series indexes is not straight-\nforward. The LeaFi workflow unfolds in three main stages. It starts by selecting the subset of leaf\nnodes for filter insertion. Next, it prepares the training data needed to train these filters. The last\nstep is to calibrate the filtersâ€™ predictions to better serve as lower bounds. We outline these steps\nalong with their challenges and our solutions as follows.\nFirst, effectively inserting learned filters requires identifying the subset of leaf nodes that offer\nthe most significant reduction in search time. As modern machine learning models are accelerated\nusing Graphics Processing Devices (GPU) [ 40], indiscriminately adding one learned filter to every\nleaf node could overwhelm the GPU memory. Typical number of leaf node in tree-based series\nindexes can reach the range of 100K [ 67]). Moreover, applying learned filters might not always\nimprove search time. For example, directly searching a small leaf node of 100 series can be faster\nthan predicting a lower bound using a Multilayer Perceptron (MLP) [ 1] model. To address these\nissues systematically, we design a general formalization that treats leaf node selection as a knapsack\nproblem [ 27]. In this analogy, adding a learned filter to a leaf node is considered adding an \"item\",\nwhere its \"value\" is the expected reduction of this nodeâ€™s search time. Given the constraint of\navailable GPU memory, our goal in this setup is to identify which leaf nodes will yield the highest\nexpected search time savings, when equipped with learned filters. We further show that under\ncertain assumptions, this general formalization can be simplified and solved by a greedy algorithm.\nSecond, training the inserted filters requires generating appropriate training data. A key challenge\nis that the majority of the node-wise nearest neighbor distances fall out of the value range of global\nnearest neighbor distances. Figure 1b, shows that node-wise nearest neighbor distances lie around\nthe value of 20, while the global nearest neighbor distance is 4.9. Traditional training data generation\nmethods, which typically involve random sampling combined with Gaussian noise [ 13], tend to\nbias training towards these larger, node-wise distances, neglecting the global distances [ 63]. To\nresolve this issue, we propose a novel twofold strategy for training data generation. It consists of\ngenerating global training queries that are derived from the entire series collection and applicable\nto all leaf nodes, alongside node-wise training queries that are derived from and specific to each\nleaf node. Our twofold approach ensures that the training data encompasses both local (node-wise)\nand global contexts, facilitating unbiased filter training across all necessary value ranges.\nLastly, learned filters, being machine learning models, cannot ensure consistent prediction\nquality [ 32]. This compromises the exactness of the search result in original series indexes [ 62].\nTo mitigate the uncertainty of the search quality, we propose conformal auto-tuners , a method\ninspired by conformal regressions [ 2] to enable support for user-requested search quality (e.g.,\nrecall, tightness, etc.) targets. Our conformal auto-tuners calibrate the filter prediction using a\nlearned offset, determined by a certain quality target that can be set at query time, independently for\neach query. We employ a separate calibration set [ 44] to simulate search under different offsets and\ncollect the result qualities. The conformal auto-tuners learn the mapping between observed result\nqualities and corresponding calibration offsets, such that the calibration offset can be dynamically\nobtained for any given quality target.\nContributions. Our contributions can be summarized as follows.\n(1)We introduce the first approach that uses learned filters to improve the pruning effectiveness\nof tree-based series indexes, and hence accelerate data series similarity search.\n(2)We design LeaFi, a novel general framework that effectively integrates learned filters into\n(different) tree-based series indexes. LeaFi carefully selects an optimal subset of leaf nodes for filter\ninsertion, and generates appropriate training data for filter training.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:5\n(3)We propose conformal auto-tuners to mitigate the uncertainty in the results of machine\nlearning models. Conformal auto-tuners calibrate learned filters at query time to support the\nuser-defined quality target, independently for each query (the user may also choose to disable the\nlearned filters).\n(4)Our experimental evaluation, using two diverse tree-based series indexes and five diverse\ndatasets, demonstrates the benefits of the proposed approach, and its advantages when compared\nto alternatives. LeaFi-enhanced series indexes improve pruning ratio by up to 20x and search time\nby up to 32x, while maintaining a target recall of 99%. Codes and datasets are available online2.\n2 Related Work\nData series indexes. The most prominent data series indexing techniques can be categorized into\ngraph-based indexes [ 38], quantization [ 21] and inverted indexes [ 5], locality-sensitive hashes [ 24],\nand tree-based indexes [ 55,65]. Recent studies [ 15,16] have demonstrated that tree-based in-\ndexes [47] achieve SOTA performance under several conditions (e.g., large-scale dataset).\niSAX [ 55] and DSTree [ 65] are two SOTA tree-based indexes for series similarity search of\ndifferent strengths [ 15,16]. iSAX is based on Symbolic aggregate approximation (SAX) [ 55], a\ndiscretized series summarization based on piecewise aggregate approximation (PAA) [ 28]. PAA first\ntransforms the data series into ğ‘™real values, and then SAX quantizes each PAA value using discrete\nsymbols. iSAX (indexable SAX) [ 55] enables the comparison of SAXs of different cardinalities, that\nmakes SAX indexable through a prefix trie [ 7]. DSTree [ 65] is a dynamic splitting tree based on\nthe adaptive piecewise constant approximation (EAPCA). Furthermore, ADS+ [ 74] makes iSAX\ncontinuously adaptive to queries, ULISSE[ 36,37] supports variable-length queries, Coconut [ 30]\ndelivers a sortable iSAX variant, DPiSAX [ 71] and Odyssey [ 8] make iSAX distributed, ParIS [ 49],\nMESSI [ 47,48] and SING [ 50] bring in modern hardware, FreSh [ 18] adds lock-freedom, Dumpy [ 67]\nand DumpyOS [ 68] introduce a data-adaptive multi-ary structure, while Hercules [ 13] and Elpis [ 3]\ncombine the iSAX and EAPCA [65] summarizations.\nThe proposed LeaFi framework is index agnostic. We instantiate and evaluate it on both MESSI [ 48]\nand DSTree [65], making its improvements translatable to most tree-based indexes.\nMachine learning applications in series indexes. Machine learning techniques have proven\neffective in enhancing various components of databases [ 34,54], such as indexes [ 12,31,35,39,62],\ncardinality estimators [ 29,58,70], etc. A few existing works are also motivated by the fact that there\nis waste in search time [ 14,22]. These works can be divided into two categories, early stopping\napproaches [14, 16, 22] and leaf node reordering approaches [26].\nIn the context of data series similarity search, ğœ–-search identifies heuristic stopping criteria when\nbest-so-far results are in the ğœ–neighborhood of nearest neighbor results [ 16].ğ›¿ğœ–-search extends\nğœ–-search by supporting a confidence level ğ›¿, based on estimated pairwise distance distribution [ 16].\nProgressive Search (ProS) incorporates machine learning models to estimate when the exact\nresults are retrieved, using the query and best-so-far distances [ 14,22]. Learned Reordering (LR)\ndetermines the visiting order of the leaf nodes by predicting their probabilities of containing the\nnearest neighbor results for a given query [26].\nFigure 3 illustrates the improvement potential for DSTree index on Astro dataset, as in Figure 1a,\nof early stopping approaches ( ğœ–-search,ğ›¿ğœ–-search, ProS and FLT), leaf node reordering approaches\n(LR), and our proposed learned filter approach (LeaFi). These optimal performance is simulated by\nassuming all machine learning models make no mistake. Leaf node reordering approaches help\nseries indexes find the nearest neighbor results in the first node being visited and employ the\ntightest best-so-far distance. However, as shown in Figure 1b, a tight best-so-far distance provide\n2https://github.com/qtwang/LeaFi\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:6 Qitong Wang, Ioana Ileana, & Themis Palpanas\nYaxis: Recall-at-1       Xaxis: Number of searched leaf nodes\n01k2k3k4k0.50.60.70.80.91.0\n   NN found  \n  & Search \n  terminated\n(a) Early stopping\n01k2k3k4k0.50.60.70.80.91.0\nNN found\n    Search   \nterminated (b) Reordering\n01k2k3k4k0.50.60.70.80.91.0\n NN found\n& Search\nterminated (c) LeaFi\nFig. 3. The optimal search time that can be possibly achieved by early-stopping approaches [ 14,16,22], leaf\nnode reordering approaches [ 26] and LeaFi for DSTree index on Astro dataset. The axes are the same as\nFigure 1b (x-axis in Figure 3c has a different scale).\nmarginal help in pruning more leaf nodes - most of the summarization-based lower bounds are still\nsmaller than that. Early stopping approaches can terminate search right after the nearest neighbor\nresults are retrieved, but it cannot reduce the search time before the retrieval.\nOn the other hand, LeaFi helps series indexes to search only those leaf nodes that can update\nthe best-so-far distances, as the tightest lower bounds are employed in pruning decision, hence\nattaining a significant and consistent improvement potential. Moreover, as trained using the node-\nwise distance information instead of index-wise leaf node searching information, LeaFi can be\nefficiently trained using 2k examples (0.002% of the collection), compared to 100k to 1m examples\n(0.1% of the collection) in the literature [ 26,33]. As far as we are aware, LeaFi represents the\nfirst framework that incorporates learned filters in data series indexes and provides substantial\nimprovement in pruning ratio and search time.\nFAISS Learned Termination (FLT) is an early-termination technique proposed for vector similarity\nsearch using kNN graphs [ 33]. Its stopping criterion is predicted by a nontrivial expert-crafted\nfeature set, which cannot be directly applied to tree-based series indexes, and, in contrast to LeaFi,\nit does not offer a mechanism to set search quality targets.\nConformal regressions. Conformal regression is a statistical approach that enhances existing\nregression methods by providing predictive intervals with a guarantee on their coverage proba-\nbility [ 61]. It involves fitting a regression model to a dataset and then generating predictions that\ninclude an interval which, with a specified level of confidence (e.g., 95%), is expected to cover the\ntrue target values. This process relies on the computation of nonconformity scores that measure\nhow unusual new observations are compared to training data [2, 44].\nHowever, the direct application of existing conformal regression techniques cannot help LeaFi\nsupport the user-requested search quality. This is because the conformal prediction intervals are\nderived independently for each model, whereas achieving an expected target of a LeaFi-enhanced\nsearch result, e.g., 99% recall, requires tuning all learned filters collaboratively at the same time.\nHence, in LeaFi, we further design our auto-tuning approach based on the conformal regression\nframework. To the best of our knowledge, LeaFi demonstrates the first effort to introduce conformal\nregression techniques into the domain of learned indexes.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:7\n3 Preliminaries\nData series. Adata series ,ğ‘†={ğ‘1,...,ğ‘ğ‘š}, is a sequence of points, where each point ğ‘ğ‘–=(ğ‘£ğ‘–,ğ‘¡ğ‘–),\n1â‰¤ğ‘–â‰¤ğ‘šis associated to a real value ğ‘£ğ‘–and a position ğ‘¡ğ‘–. We callğ‘šthelength of the series.S\ndenotes a collection of data series, i.e., S={ğ‘†1,...,ğ‘†ğ‘›}. We callğ‘›thesizeof the series collection.\nAsummarization ğ¸={ğ‘’1,...,ğ‘’ğ‘™}of a seriesğ‘†is its lower-dimensional representation, that\npreserves some desired properties of S. For example, SAX in MESSI [ 55] and APCA in DSTree [ 65]\nare two popular series summarizations. In series similarity search, summarizations can be utilized\nto calculate lower bounds between a series or a set of series and a query.\nSimilarity search. Given a query series ğ‘†ğ‘, a series collection Sof sizeğ‘›, a distance measure\nğ‘‘,similarity search targets to identify the series ğ‘†ğ‘âˆˆSwhose distance to ğ‘†ğ‘is the smallest, i.e.,\nâˆ€ğ‘†ğ‘œâˆˆS,ğ‘†ğ‘œâ‰ ğ‘†ğ‘,ğ‘‘(ğ‘†ğ‘,ğ‘†ğ‘)â‰¤ğ‘‘(ğ‘†ğ‘œ,ğ‘†ğ‘).\nThe LeaFi framework works for any distance measure supported by the backbone index, in-\ncluding Euclidean and Dynamic Time Warping (DTW), two popular distances for series similarity\nsearch [11].\nTree-based indexes. Tree-based series indexes, including DSTree [ 65] and MESSI [ 55], are con-\nstituted by internal nodes ğ¼ğ‘–s and leaf nodesğ¿ğ‘–s, as shown in Figure 2. We use ğ‘ğ‘–to denote a node\nwhen there is no need to distinguish between it being an internal node or leaf node. Only leaf nodes\nstore the raw series. An internal node routes a series to one of its child node that this series should\nbe inserted into. Both types of nodes contain a node summarization ğ¸ğ‘\nğ‘–that aggregates the series\nsummarizations of all series it contains. Node summarizations are used to calculate distance lower\nbounds for search routing and leaf node pruning.\nDuring query answering, internal nodes navigate the query series ğ‘†ğ‘to visit leaf nodes according\nto their lower bounds to the query. Only the leaf nodes whose subtree cannot be pruned are visited.\nWe maintain a best-so-far result ğ‘‘bsf(ğ‘†ğ‘,ğ‘ğ‘–), i.e., the smallest distance before visiting a node ğ‘ğ‘–.\nGiven a node ğ‘ğ‘–, we first calculate the node summarization-based lower bound ğ‘‘lb(ğ‘†ğ‘,ğ‘ğ‘–)for the\ndistances between ğ‘†ğ‘and all series ğ‘ğ‘–contains. When the context is clear, we remove inputs (Â·)\nor subscripts ğ‘–in the equations for clarity. We then compare ğ‘‘lbwithğ‘‘bsf.ğ‘‘lb>ğ‘‘bsfindicates all\nseries in a leaf node ğ¿ğ‘–or a subtree ğ¼ğ‘–have larger distances to ğ‘†ğ‘, thusğ¿ğ‘–orğ¼ğ‘–can be safely pruned.\nOtherwise, there might be a series that has smaller distance to ğ‘†ğ‘. Forğ¿ğ‘–, we have to search ğ¿ğ‘–to\nget its node-wise nearest neighbor distance ğ‘‘L(ğ‘†ğ‘,ğ¿ğ‘–)=minğ‘˜ğ‘‘(ğ‘†ğ‘,ğ‘†ğ‘˜),ğ‘†ğ‘˜âˆˆğ¿ğ‘–, and check whether\nğ‘‘Lcan update ğ‘‘bsf. Forğ¼ğ‘–, we repeat the pruning checking for the nodes in its subtree. After all\nnodes are either visited or pruned, ğ‘‘bsfis returned as the true nearest neighbor result.\nConformal regression. Conformal regression utilizes posterior statistics to auto-tune machine\nlearning predictions to target at a certain confidence level [ 2]. Suppose we collect a training set\n{(ğ‘¥1,ğ‘¦1),(ğ‘¥2,ğ‘¦2),...,(ğ‘¥ğ‘™,ğ‘¦ğ‘™)}ofğ‘™examples. In our case, ğ‘¥ğ‘–is a training query (i.e., ğ‘†ğ‘) andğ‘¦ğ‘–is the\nnode-wise nearest neighbor distance ğ‘‘N. Given a confidence level 1âˆ’ğ›¿,conformal regression [2]\npredicts an interval, instead of a single value, such that the true ğ‘¦ğ‘™+1of a new example ğ‘¥ğ‘™+1will be\ncovered by this interval with a 1âˆ’ğ›¿confidence.\nIn LeaFi, we embrace the core designs from the classic inductive conformal regression [44] as a\nproof-of-concept study. Inductive conformal regression splits the training data into two subsets: the\nproper training set{(ğ‘¥1,ğ‘¦1),(ğ‘¥2,ğ‘¦2),...,(ğ‘¥ğ‘š,ğ‘¦ğ‘š)}and the calibration set{(ğ‘¥ğ‘š+1,ğ‘¦ğ‘š+1),(ğ‘¥ğ‘š+2,ğ‘¦ğ‘š+2),\n...,(ğ‘¥ğ‘™,ğ‘¦ğ‘™)}. After training a machine learning model on the proper training set, we calculate and sort\nthenon-conformity measures on the calibration set: ğ›¼ğ‘–â‰”|ğ‘¦ğ‘š+1âˆ’ğ‘¦Ë†ğ‘š+ğ‘–|,ğ‘–=1,2,...,ğ‘™âˆ’ğ‘š, whereğ‘¦Ë†ğ‘š+ğ‘–\nis the prediction of a sample ğ‘¥ğ‘š+ğ‘–. We use[ğ›¼(1),ğ›¼(2),...,ğ›¼(ğ‘™âˆ’ğ‘š)]to denote the descending-ordered\nğ›¼s on the calibration set. Let ğ‘—ğ‘ =|{ğ›¼ğ‘–:ğ›¼ğ‘–â‰¥ğ›¼(ğ‘ )}|,ğ‘ =1,2,...,ğ‘™âˆ’ğ‘šbe the number of ğ›¼s that are at\nleast as large as ğ›¼(ğ‘ ). Given the confidence level 1âˆ’ğ›¿and a new example ğ‘¥ğ‘™+1, the predictive region\nis derived as(ğ‘¦Ë†ğ‘™+1âˆ’ğ›¼(ğ‘ ),ğ‘¦Ë†ğ‘™+1+ğ›¼(ğ‘ )), by choosing the ğ‘—ğ‘ such thatğ›¿=ğ‘—ğ‘ /(ğ‘™âˆ’ğ‘š+1).\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:8 Qitong Wang, Ioana Ileana, & Themis Palpanas\nâ‹¯SelectnodesSec4.2â‹¯MMâ‹¯MCollecttrainsetSec4.3\ntrainqueriesTrainfiltersFitauto-tunersSec4.4MMâ‹¯M\n(a) The LeaFi index building workflow.\nTunefiltersSec4.4\n(Recalltarget:99%)Query:Search\nAnswer(s):MMâ‹¯M\n(b) The LeaFi query answering workflow. The quality target can be\nauto-tuned for each individual query.\nFig. 4. The index building and query answering workflow of a LeaFi-enhanced series index.\nIn Section 4.4, we further discuss how to establish the mapping between ğ›¼s and search result\nquality, and then identify the corresponding ğ›¼s to auto-tune the filter predictions for the support\nof search quality targets.\n4 The LeaFi Framework\nIn this section, we present the algorithm details of enhancing data series indexes with learned filters.\nWe start with developing the notations for a LeaFi-enhanced index structure. Then, in Section 4.1,\nwe outline the LeaFi-enhanced series index building and search workflow, illustrated in Figure 4.\nThe details of leaf node selection, training data generation and filter conformal auto-tuning, are\npresented in Section 4.2, Section 4.3 and Section 4.4, respectively.\nAs illustrated in Figure 2, a LeaFi-enhanced tree-based series index contains learned filters in\na selected subset of its leaf nodes. A learned filter ğ‘€ğ‘–in a nodeğ¿ğ‘–is a trained machine learning\nmodel, which takes in a query ğ‘†ğ‘and predicts ğ‘‘L. We denote the prediction as ğ‘‘f(ğ‘†ğ‘,ğ‘€ğ‘–), and the\nconformal adjusted prediction as ğ‘‘F(ğ‘†ğ‘,ğ‘€ğ‘–). Hence, the learned filter-based pruning decision can\nbe made by comparing the best-so-far distance ğ‘‘bsfwith the predicted lower bound ğ‘‘F. Ifğ‘‘F>ğ‘‘bsf,\nwe pruneğ¿ğ‘–, otherwise we search ğ¿ğ‘–.\n4.1 LeaFi-enhanced Series Index Workflow\nWe modify both the index building workflow and the search workflow of original tree-based series\nindexes to enable learned filters, as illustrated in Figure 4. We outline these procedures as follows,\nand present the details in later sections.\n4.1.1 LeaFi-enhanced Index Building Overview. For index building, we add three main steps after\nthe original index is built, illustrated in Figure 4a. These steps are (a) select leaf nodes for filter\ninsertion, (b) generate training data from both global (index-wise) context and local (node-wise)\ncontext, and train the inserted filters, and (c) collect conformal training data and fit the conformal\nauto-tuners.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:9\nAlgorithm 1 LeaFi-enhanced Index Building\nInput: a series collectionSof sizeğ‘›, a tree-based index ğ¼, the training data size ğ‘›ğ‘=ğ‘›ğ‘(ğ‘”)+ğ‘›ğ‘(ğ‘™),\nand the available GPU memory ğ‘M\nOutput: the LeaFi-enhanced index ğ¼F\n1:{ğ‘F\nğ‘–}=SelectLeafNode (ğ¼,ğ‘M)\n2:Sğ‘(ğ‘”)=GenerateGlobalQueries (S)\n3:ğ‘‡ğ‘”â‰”{(ğ‘‘ğ‘ğ‘ ğ‘“,ğ‘‘L)}=SearchGlobalQueries (ğ¼,ğ‘›ğ‘(ğ‘”),{ğ‘F\nğ‘–})\n4:Sğ‘(ğ‘™)=âˆ…,ğ‘‡ğ‘™=âˆ…\n5:for allğ‘F\nğ‘–âˆˆ{ğ‘F\nğ‘–}do\n6:Sğ‘(ğ‘™),ğ‘–=GenerateLocalQueries (ğ‘F\nğ‘–,ğ‘›ğ‘(ğ‘™),ğ‘‡ğ‘”)\n7:ğ‘‡ğ‘™,ğ‘–â‰”{ğ‘‘L}=SearchLocalQueries (ğ‘F\nğ‘–,ğ‘›ğ‘(ğ‘™),)\n8:Sğ‘(ğ‘™)=Sğ‘(ğ‘™)âˆªSğ‘(ğ‘”),ğ‘–,ğ‘‡ğ‘™=ğ‘‡ğ‘™âˆªğ‘‡ğ‘™,ğ‘–\n9:ğ¼f=TrainFilters ({ğ‘F\nğ‘–},Sğ‘(ğ‘”),ğ‘‡ğ‘”,Sğ‘(ğ‘™),ğ‘‡ğ‘™)\n10:ğ¼F=FitAutoTuners (ğ¼f,Sğ‘(ğ‘”),ğ‘‡ğ‘”)\n11:returnğ¼F\nSelect leaf nodes (Section 4.2). We first establish a general framework that selects the optimal\nsubset of leaf nodes that maximize the benefit of learned filter insertion, using knapsack solvers [ 27].\nWe show that, under certain assumptions, we can simplify the framework and select leaf nodes\nusing a greedy algorithm. In brief, LeaFi calculates a leaf node size threshold ğ‘¡â„, based on the\nnumber of distance calculations that execute in the same time as one filter inference. We then select\nthe leaf nodes according to their sizes until ğ‘¡â„is met, or the GPU memory is fully occupied.\nGenerate training data (Section 4.3). We generate training data Sğ‘from both global and local\ncontexts. Index-wise training data Sğ‘(ğ‘”)is sampled from the whole dataset and shared among all\nselected leaf nodes, while node-wise training data Sğ‘(ğ‘™)is sampled individually from each node\nand is only available to their corresponding node. There is no additional expense by splitting\nSğ‘intoSğ‘(ğ‘”)âˆªSğ‘(ğ‘™). The collection time for Sğ‘(ğ‘”)andSğ‘(ğ‘™)node-wise data is the same as for\nğ‘›ğ‘=ğ‘›ğ‘(ğ‘”)+ğ‘›ğ‘(ğ‘™)index-wise training data.\nFit conformal auto-tuners (Section 4.4). After inserted filters fit the training set, we fit the\nconformal auto-tuners to enable the support for user-request search quality targets. The absolute\nprediction errors{ğ›¼ğ‘–}, i.e., the non-conformity scores in the conformal regression context [ 2], are\nemployed as offsets to auto-tune the predictions. One auto-tuner is added to each learned filter.\nIndex building pseudocode. We describe the LeaFi-enhanced index building pseudocode for a\ngeneral tree-based index building algorithm in Algorithm 1. The sub-functions S elect LeafNodeis\ndefined later in Algorithm 3 and F itAutoTuners in Algorithm 4.\nGiven a series collection S, a tree-based index ğ¼, the training data size ğ‘›ğ‘=ğ‘›ğ‘(ğ‘”)+ğ‘›ğ‘(ğ‘™), and\nthe available GPU memory ğ‘M, we first select the subset of leaf nodes {ğ‘F\nğ‘–}. We then generate\nthe collect the index-wise training data from line 2 to line 3. From line 5 to line 8, we iterate\nover each selected leaf node ğ‘F\nğ‘–and generate its corresponding node-wise training data. Line 9\ntrains all the inserted filters using the both index-wise and node-wise training data. We finalize the\nLeaFi-enhanced index building workflow by fitting the conformal auto-tuners in line 10.\n4.1.2 LeaFi-enhanced Search Overview. There are two new operations in LeaFi-enhanced search\nworkflow, illustrated in Figure 4b, compared to the original search workflow. Before searching for\na query, we first auto-tune the filters according to the user-request search quality target. Then, we\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:10 Qitong Wang, Ioana Ileana, & Themis Palpanas\nAlgorithm 2 LeaFi-enhanced Search\nInput: a queryğ‘†ğ‘, a LeaFi-enhanced index ğ¼F, the result quality target ğ‘„, and the number of nearest\nneighborsğ‘˜\nOutput: the search resultsSğ‘Ÿ\n1:ğ¼F=AutoTuneFilters (ğ¼F,ğ‘„)\n2:ğ‘‘bsf= INF,Sğ‘Ÿ=PriorityQueue (âˆ…,ğ‘˜)\n3:for allğ‘ğ‘–âˆˆ[ğ‘ğ‘—], ordered by ğ¼Fdo\n4: ifğ‘‘lb>ğ‘‘bsfthen\n5: continue\n6: ifğ‘€ğ‘–âˆˆğ‘ğ‘–&ğ‘‘F>ğ‘‘bsfthen\n7: continue\n8:ğ‘†ğ‘Ÿ,ğ‘–,ğ‘‘L=SearchNode (ğ‘ğ‘–,ğ‘‘bsf)\n9: ifğ‘‘L<=ğ‘‘bsfthen\n10:ğ‘‘bsf=ğ‘‘L,Sğ‘Ÿ=Sğ‘ŸâŠ•ğ‘†ğ‘Ÿ,ğ‘–\n11:returnSğ‘Ÿ\nvisit each leaf node, and check whether it can be pruned using a cascade of summarization-based\nstrategy and learned filter-based strategy as in Figure 2.\nAuto-tune learned filters (Section 4.4). Given a user-specified search quality target ğ‘ğ‘—, we use\nthe learned mapping ğ‘“ğ‘to calculate the corresponding adjusting offset ğ‘œğ‘–,ğ‘—=ğ‘“ğ‘(ğ‘ğ‘—)for each filter\nğ‘€ğ‘–. Then, we use the left boundary ğ‘‘ğ‘“\nğ‘–âˆ’ğ‘œğ‘–,ğ‘—of the adjusted interval as the predicted lower bound\nğ‘‘ğ¹\nğ‘–,ğ‘—, to be compared with ğ‘‘ğ‘ğ‘ ğ‘“for the pruning decision of node ğ‘ğ‘–.\nSearch pseudocode. We describe the LeaFi-enhanced search pseudocode for a general tree-based\nindex search algorithm in Algorithm 2.\nGiven a query ğ‘†ğ‘, a LeaFi-enhanced index ğ¼F, the result quality target ğ‘„, and the number of\nnearest neighbors ğ‘˜, we first auto-tune the learned filters based on the target ğ‘„. A hash table is\nemployed to avoid redundant computation for the same ğ‘„s, which we omitted in Algorithm 2 for\nsimplicity. We then iterate across the leaf nodes according to the order suggested by ğ¼F. When\nvisiting a node ğ‘ğ‘–, we first check whether it can be pruned using ğ‘‘lbin line 4. Otherwise, we check\nwhetherğ‘ğ‘–can be pruned using ğ‘‘F, if a learned filter ğ‘€ğ‘–resides inğ‘ğ‘–in line 6. If neither ğ‘‘lbnorğ‘‘F\ncan pruneğ‘ğ‘–, we searchğ‘ğ‘–forğ‘†ğ‘to obtain its node-wise nearest neighbor results Sğ‘Ÿ,ğ‘–and update\nSğ‘Ÿfrom line 8 to line 10.\n4.2 Leaf Node Selection\nIn this section, we present how the problem of leaf node selection can be formalized as a knapsack\nproblem [ 27] in Section 4.2.1. We show that this general formalization can be simplified under\ncertain assumptions and solved efficiently by a greedy algorithm.\nBriefly speaking, our greedy leaf node selection algorithm works as follows. First, we sort all leaf\nnodes{ğ‘ğ‘–}by their sizes{|ğ‘ğ‘–|}in a non-increasing order. Then, we select those nodes whose sizes\nexceed a threshold ğ‘¡â„to insert filters, until all available GPU memory is occupied. We describe how\nğ‘¡â„is derived from a simplified knapsack formalization and how it is determined in Section 4.2.2.\n4.2.1 A general solution framework as a knapsack problem. We start with a brief review of the\nknapsack problem, and then built the analogy between the knapsack problem and leaf node\nselection.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:11\nThe knapsack problem is a classic example of combinatorial optimization [ 27]. It is a type of\nresource allocation problem where the objective is to maximize the total value of items placed in a\nknapsack without exceeding its capacity. Given a set of ğ‘›items, each with a weight ğ‘¤ğ‘–and a value\nğ‘£ğ‘–, and a knapsack with a weight capacity ğ‘Š, the goal is to determine the subset of items to include\nin the knapsack such that the total weight does not exceed ğ‘Šand the total value is maximized.\nThis can be represented by the following optimization problem: maximizeâˆ‘ï¸ğ‘›\nğ‘–=1ğ‘£ğ‘–ğ‘¥ğ‘–, subjective to\nğ‘¥ğ‘–âˆˆ{0,1}andâˆ‘ï¸ğ‘›\nğ‘–=1ğ‘¤ğ‘–ğ‘¥ğ‘–â‰¤ğ‘Š. Here,ğ‘¥ğ‘–is a binary decision variable that indicates whether item ğ‘–\nis included ( ğ‘¥ğ‘–=1) or excluded ( ğ‘¥ğ‘–=0) in the knapsack. There are several variants of the knapsack\nproblem, among which we only consider 0/1 knapsack problem in this paper.\nThe analogy between a knapsack problem is built as the following. For ğ‘›ğ‘leaf nodes, we consider\nthat there are ğ‘›ğ‘filters, each of which is corresponding to one specific node. In this case, a filter\nğ‘€ğ‘–can be considered as an item. Its value is the expected reduction of search time, denoted by\nğ‘ğ‘–, induced by inserting ğ‘€ğ‘–into its corresponding leaf node ğ‘ğ‘–. The weight of an item ğ‘€ğ‘–is its\nGPU memory footprint, and the weight capacity of the knapsack is the volume of available GPU\nmemoryğ‘M. Hence, by solving the mapped knapsack problem, we identify the subset of leaf nodes\nthat obtain the optimal search time improvement by learned filter insertion. We formalize the leaf\nnode selection as a knapsack problem in Equation 1:\nmaxâˆ‘ï¸‚\nğ‘–ğ‘ğ‘–ğ‘¥ğ‘–\ns.t.âˆ‘ï¸‚\nğ‘–ğ‘¤ğ‘–ğ‘¥ğ‘–â‰¤ğ‘M\nğ‘¥ğ‘–âˆˆ{0,1},âˆ€ğ‘–=1,...,ğ‘›N.(1)\nwhereğ‘¤ğ‘–andğ‘Mcan be calculated analytically [ 20] or measured empirically using GPU profiling\ntools [ 41]. In this work, we only consider the case where all learned filters share the same neural\nnetwork architecture. As a result, they also share the same memory footprint, i.e., ğ‘¤ğ‘–=ğ‘¤,âˆ€ğ‘–=\n1,...,ğ‘›N. This general framework can also tackle the case where different filters have different\nnetwork architectures by extending it to a multiple-choice knapsack problem [ 27]. We will study\nthis case in our future work.\nFormulate the expected time reduction ğ‘ğ‘–.To solve Equation 1, we need to estimate the only\nunknown variable ğ‘ğ‘–, i.e., the reduced search time by adding a filter ğ‘€ğ‘–to a specific leaf node ğ‘ğ‘–.\nWe observe that ğ‘ğ‘–is influenced by the following factors: the node size |ğ‘ğ‘–|, the summarization-\nbased pruning probability ğ‘lb, the filter-based pruning probability ğ‘F. A larger|ğ‘ğ‘–|or a smaller\nğ‘lbindicates the original index ğ¼spent more effort on node ğ‘ğ‘–, and a larger ğ‘Fhints that filter ğ‘€ğ‘–\nworks well for node ğ‘ğ‘–. Hence,ğ‘ğ‘–can be formulated using |ğ‘ğ‘–|,ğ‘lbandğ‘Fas Equation 2:\nğ‘ğ‘–=(1âˆ’ğ‘lb\nğ‘–)Ã—(ğ‘F\nğ‘–Ã—ğ‘¡SÃ—|ğ‘ğ‘–|âˆ’ğ‘¡F) (2)\nwhereğ‘¡Sdenotes the distance calculation time for one series and ğ‘¡F\nğ‘—denotes the inference time for\nfilterğ‘€ğ‘–. Note thatğ‘ğ‘–can be negative in cases where |ğ‘ğ‘–|is small orğ‘¡Fis large. We describe how\nwe prohibit such insertions by automatically establishing a threshold for |ğ‘ğ‘–|usingğ‘¡Sandğ‘¡Fin\nSection 4.2.2.\nChallenge: estimate the filter-based pruning probability ğ‘F.Although we can measure the\nwall-clock time for ğ‘¡Sandğ‘¡Fempirically using trial experiments, there are two other variables in\nEquation 2 that cannot be directly calculated or measured, i.e., the summarization-based pruning\nprobabilityğ‘lband the filter-based pruning probability ğ‘F.\nIn our preliminary studies, we find ğ‘lbcan be estimated by collecting ğ‘‘lbalong withğ‘‘bsfandğ‘‘L\nusing trial experiments. However, estimating ğ‘Fmeans to accurately estimate the performance of\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:12 Qitong Wang, Ioana Ileana, & Themis Palpanas\nAlgorithm 3 Leaf Node Selection\nInput: the leaf nodes{ğ‘ğ‘–}of indexğ¼F, the available GPU memory ğ‘Mand hyperparameter ğ‘\nOutput: a selected subset of leaf nodes {ğ‘ğ¹\nğ‘–}for filter insertion\n1:ğ‘¤=MeasureFilterGPUMemory (ğ‘€)\n2:ğ‘¡F=MeasureFilterInferenceTime (ğ‘€)\n3:ğ‘¡S=MeasureDistanceCalculationTime (Â·)\n4:ğ‘¡â„=ğ‘Ã—ğ‘¡F/ğ‘¡S\n5:[ğ‘(ğ‘–)]=SortBySize ({ğ‘ğ‘–})\n6:Nğ‘Ÿ=âˆ…,ğ‘¤M=0\n7:for allğ‘(ğ‘—)âˆˆ[ğ‘(ğ‘–)]do\n8: if|ğ‘(ğ‘—)|â‰¥ğ‘¡â„&ğ‘¤M<ğ‘Mthen\n9:Nğ‘Ÿ=Nğ‘ŸâŠ•ğ‘(ğ‘—),ğ‘¤M=ğ‘¤M+ğ‘¤\n10:returnNğ‘Ÿ\nmachine learning models without fully fitting their respective training data. This is a nontrivial task,\nand has been under extensive studies in the automated machine learning (AutoML) literature [ 53,72].\nConsidering the positioning of LeaFi is a proof-of-concept study to demonstrate the potential of\nembracing learned filters in series indexes, we opt to simplify Equation 2 by assuming that ğ‘lband\nğ‘Fare the same across leaf nodes.\n4.2.2 The Greedy Selection Algorithm. To tackle the challenge of accurately estimating the perfor-\nmance of machine learning models, we propose to assume that ğ‘lbandğ‘Fare the same across leaf\nnodes in LeaFi. That is, âˆ€ğ‘–=1,...,ğ‘›N, bothğ‘lb\nğ‘–=ğ‘lbandğ‘F\nğ‘–=ğ‘Fhold. Although this assumption is\ncoarse-grained, we show later in Equation 4 that it can derive a safe greedy algorithm that has no\nnegative effect. Under this assumption, Equation 2 can be simplified into Equation 3:\nğ‘ğ‘–=(1âˆ’ğ‘lb)Ã—(ğ‘FÃ—ğ‘¡SÃ—|ğ‘ğ‘–|âˆ’ğ‘¡F) (3)\nwhereğ‘ğ‘–is only correlated to |ğ‘ğ‘–|(ğ‘¡Sandğ‘¡Fare also the same across leaf nodes). Moreover, the\ncorrelation between ğ‘ğ‘–and|ğ‘ğ‘–|is positive. That is, a larger node size |ğ‘ğ‘–|introduces larger search\ntime reduction ğ‘ğ‘–under this assumption. Hence, we can sort the leaf nodes based on their sizes and\nselect them the larger nodes until consuming all available GPU memory.\nHowever, as mentioned in Section 4.2, ğ‘ğ‘–can be negative in cases where |ğ‘ğ‘–|is small orğ‘¡Fis\nlarge, which should be prohibited. To formalize the constraint, we set ğ‘ğ‘–>0, transform Equation 3\nand get a threshold ğ‘¡â„for leaf node size|ğ‘ğ‘–|in Equation 4:\nğ‘ğ‘–>0â‡’ |ğ‘ğ‘–|>1\nğ‘FÃ—ğ‘¡F\nğ‘¡Sâ‡’ |ğ‘ğ‘–|>ğ‘ğ‘¡F\nğ‘¡S(4)\nwhereğ‘â‰”1/ğ‘Fis a hyperparameter. ğ‘¡F/ğ‘¡Sis the number of series that its distance calculation\ntime is equivalent to the inference time of a learned filter. By its definition 1/ğ‘F,ğ‘has an intrinsic\ninterpretation as being the inverse of the filter-based pruning probability ğ‘F. Hence, it is intuitive\nto setğ‘by choosing a lower bound for ğ‘Fto ensureğ‘ğ‘–>0. In our experiments, we set ğ‘=2(i.e.,\nğ‘F=50%) and evaluated that it worked well across different index prototypes, datasets, query noise\nlevels and search quality targets.\nLeaf node selection pseudocode. Putting all these designs together, we present our leaf node\nselection approach of the LeaFi index building workflow in Algorithm 3.\nWe first collect all necessary runtime statistics, including the GPU memory footprint of a filter in\nline 1, the filter inference time in line 2 and the series distance calculation time in line 3. Then, we\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:13\nğ‘‘!ğ‘‘\"!Node7.98.4ğ”¾,ğ¿#ğ‘†$11.19.8ğ”¾,ğ¿%ğ‘†&7.72.3ğ”¾,ğ¿$ğ‘†'â€¦\u0004\u0007\b\u0005\u0006\n\u0013\u000b\u0010\u0011\u0010\u0011\u000f\u0003\u0014\u000b\u0013\u000f\u000e\u0014\u0004\u0007\b\u0005\u0006\t\u0013\u000e\r\u0010\f\u0014\u0010\u0012\u0011ğ‘ºğŸğ‘ºğŸğ‘ºğŸ‘\n(a) Only global training data ( Ã—in figure, Gin table) for leaf node\nğ¿1. The Node column indicates in which node each series finds its\nnearest neighbor.\nğ‘‘!ğ‘‘\"!Node7.58.4ğ”¾,ğ¿#ğ‘†$11.99.8ğ”¾,ğ¿%ğ‘†&3.82.3ğ”¾,ğ¿$ğ‘†'â€¦2.42.1ğ•ƒ,ğ¿$ğ‘†()$*3.93.9ğ•ƒ,ğ¿$ğ‘†(*\u0004\u0007\b\u0005\u0006\n\u0013\u000b\u0010\u0011\u0010\u0011\u000f\u0003\u0014\u000b\u0013\u000f\u000e\u0014\u0004\u0007\b\u0005\u0006\t\u0013\u000e\r\u0010\f\u0014\u0010\u0012\u0011ğ‘ºğŸğ‘ºğŸğ‘ºğŸ‘ğ‘ºğ’$ğ‘ºğ’%ğŸ$\n(b) Both global (Ã—) and local ( â˜…in figure, Lin table) training data.\nFig. 5. The value distribution of the training targets (x-axis) for filters. Considering the global examples only\noverlooks the more important small value ranges, where the global nearest neighbor results are found.\ncalculate the node size threshold ğ‘¡â„based on Equation 4 in line 4. In line 5, we sort all the leaf node\nin a non-increasing order in line 5. From line 6 to line 9, for each leaf node ğ‘(ğ‘—), if its size|ğ‘(ğ‘—)|\nexceedsğ‘¡â„and there is GPU memory available, we add ğ‘(ğ‘—)into the set of selected leaf nodes Nğ‘Ÿ.\nAfter checking all leaf nodes, we return Nğ‘Ÿas in line 10.\n4.3 Training Data Generation\nAfter inserting filters into the selected subset of leaf nodes, we need to train these filters using\nproper training data.\nChallenge: imbalanced target value range. However, we observe that even in the presence of a\nlarge real workload, preparing training data for the filters is nontrivial. The challenge lies in the\nfact that the majority of the node-wise nearest neighbor distances fall out of the value range of\nglobal nearest neighbor distances. This observation holds in general, because the tree-based series\nindexes are expected to group similar series into the same leaf nodes. Only a few leaf nodes should\nhave similar series to the query, which have small node-wise nearest neighbor distances close to\nthe global nearest neighbor distances.\nFigure 5 further illustrates this observation and demonstrates its pollution in filter training. In\nFigure 5a, only five example fall into the global nearest neighbor distance range around [3,5], and\nonlyğ‘†3finds its nearest neighbor in ğ¿ğ‘–with a distance 2.3. The majority of the node-wise nearest\nneighbor distances are located in [7.5,12.5]. Thus, the model being trained on targets of [7.5,12.5],\nalso predicts ğ‘‘ğ‘“(ğ‘†3,ğ¿1)=7.7, which is much larger than the actual 2.3. This causes the model\nto generate inaccurate predictions, hence, requiring large adjusting ranges, and leading to small\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:14 Qitong Wang, Ioana Ileana, & Themis Palpanas\n1.9â€¦.17.11ğ›¼!2.4â€¦.15.12ğ›¼!MMâ‹¯MMMâ‹¯Mğ‘›â€¦21ğ‘–.72.61ğ‘Ÿ!1.0â€¦.72.61ğ‘Ÿ!2.4â€¦.15.12ğ›¼!Step2:traverseğ‘–,getğ‘Ÿ!Step1:sortprederrors\nStep3:learnğ‘“\":\tğ‘Ÿ!â†’ğ›¼!MMâ‹¯M\nFig. 6. Collect training examples on calibration set for conformal auto-tuners, and learn the mapping between\nsearch result qualities and prediction adjusting offsets.\npruning enhancements. This disparity not only brings harmful target bias on filter training [ 51,73],\nbut also invalidates the conformal regression as the absolute prediction errors will possess difference\ndifferent distributions for the examples in different target ranges [44, 61].\nOur solution: generating both global and local data. To resolve this issue, we propose a novel\ntwofold strategy for training data generation. It consists of generating global training queries that\nare derived from the entire series collection and applicable to all leaf nodes, alongside node-wise\ntraining queries that are derived from and specific to each selected leaf node. As illustrated in\nFigure 5b, our twofold approach ensures that the training data encompasses both global (index-wise)\nand local (node-wise) contexts, providing unbiased training target value ranges.\nIn LeaFi, we employ the conventional query generating approach from the data series litera-\nture [ 13,15,16] for both index-wise and node-wise training data. We uniformly select ğ‘›ğ‘(ğ‘”)random\nseriesSğ‘(ğ‘”)from the entire collection, as well as ğ‘›ğ‘(ğ‘™)random seriesSğ‘(ğ‘™),ğ‘–from each select leaf\nnodeğ‘ğ¹\nğ‘–, and then add random Gaussian noise. We then search the index for Sğ‘(ğ‘”)to collect the\ntraining targets ğ‘‡ğ‘”â‰”{(ğ‘‘ğ‘ğ‘ ğ‘“,ğ‘‘L)}, i.e., the node-wise nearest neighbor distances {ğ‘‘L}and the\nbest-so-far distances {ğ‘‘bsf}.{ğ‘‘bsf}is utilized later to fit the auto-tuners for the support of user-\nrequested search quality targets. For each set of node-wise training series Sğ‘(ğ‘™),ğ‘–, we only search\nits corresponding leaf node ğ‘ğ¹\nğ‘–to collect the training targets ğ‘‡ğ‘™,ğ‘–â‰”{ğ‘‘L}. To train the filter ğ‘€ğ‘–\ninserted into ğ‘ğ¹\nğ‘–, we useSğ‘(ğ‘”)âˆªSğ‘(ğ‘™),ğ‘–as the input and ğ‘‡ğ‘”âˆªğ‘‡ğ‘™,ğ‘–as the targets. In our experiments,\nwe empirically set the split ğ‘›ğ‘(ğ‘”)/ğ‘›ğ‘(ğ‘™)=3to obtain a balanced target values ranges. This process\nis presented in lines 5-8 of Algorithm 1.\n4.4 Filter Conformal Auto-tuning\nIn this section, we describe how the LeaFi-enhanced indexes can be auto-tuned to support some\nuser-defined qualities of the query answers. The conformal auto-tuners make use of the prediction\nstatistics from a separate calibration set [ 44] to build a mapping between the search quality and\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:15\nAlgorithm 4 Auto-tuner Learning\nInput: a set of learned filters {ğ‘€ğ‘–}for indexğ¼F, a set of calibration series Sğ‘(ğ‘)\nOutput: learned auto-tuners {ğ‘“ğ‘\nğ‘–}\n1:for allğ‘€ğ‘–âˆˆ{ğ‘€ğ‘–}do\n2:ğ¸ğ‘–=âˆ…\n3:{ğ›¼}ğ‘–=CalAbsPredErrors (ğ‘€ğ‘–,Sğ‘(ğ‘))\n4:[ğ›¼]ğ‘–=Sort ({ğ›¼}ğ‘–)\n5:for allğ‘—âˆˆ[1,|Sğ‘(ğ‘)|]do\n6: for allğ‘€ğ‘–âˆˆ{ğ‘€ğ‘–}do\n7:ğ‘œğ‘—,ğ‘–=ğ›¼ğ‘–,(ğ‘—)\n8: for allğ‘†ğ‘(ğ‘),ğ‘˜âˆˆSğ‘(ğ‘)do\n9:Sğ‘Ÿ,ğ‘˜=SimulateSearch (ğ¼F,{ğ‘œğ‘–}ğ‘—,ğ‘†ğ‘(ğ‘),ğ‘˜)\n10:ğ‘ğ‘—,ğ‘˜=EvaluateQuality (Sğ‘Ÿ,ğ‘˜)\n11: for allğ‘€ğ‘–âˆˆ{ğ‘€ğ‘–}do\n12: ğ¸ğ‘–=ğ¸ğ‘–âŠ•(ğ‘ğ‘—,ğ‘˜,ğ‘œğ‘—,ğ‘–)\n13:for allğ‘€ğ‘–âˆˆ{ğ‘€ğ‘–}do\n14:ğ‘“ğ‘\nğ‘–=FitSplineRegression (ğ¸ğ‘–)\n15:return{ğ‘“ğ‘\nğ‘–}\nprediction adjusting offset for each trained filter. In LeaFi, the calibration set is a subset of the\nindex-wise training data.\nBriefly speaking, we employ absolute prediction errors ğ›¼as the adjusting offsets ğ‘œ, following the\ncommon exercise of inductive conformal regression [ 44]. During LeaFi-enhanced index building, the\ntraining data for auto-tuners are the examples of the mapping between offsets ğ‘œand search result\nqualitiesğ‘, simulated and collected using the calibration set. We then fit a spline regression [ 57]\non these examples to obtain a learned mapping ğ‘“ğ‘:ğ‘â†’ğ‘œ. In LeaFi-enhanced search, given a\nuser-requested quality target ğ‘, we first determine the corresponding adjusting offset ğ‘œğ‘–=ğ‘“ğ‘\nğ‘–(ğ‘)for\neach learned filter ğ‘€ğ‘–. Then, the adjusted filter prediction ğ‘‘F\nğ‘–=ğ‘‘f\nğ‘–âˆ’ğ‘œğ‘–is calculated to help prune\nnodeğ‘ğ‘–if necessary.\n4.4.1 Conformal Auto-tuner Learning in Index Building. Figure 6 shows how we prepare the training\ndata for the conformal auto-tuners in three steps.\nFirst, we calculate the absolute prediction errors {ğ›¼}ğ‘–on the calibration set for each learned filter\nğ‘€ğ‘–.{ğ›¼}ğ‘–are then employed as the candidate adjusting offsets ğ‘œğ‘–. To avoid enumerating all possible\ncombinations of candidate offsets for all inserted leaf nodes, we sort ğ‘œğ‘–(Step 1 in Figure 6), such\nthat we can iterate over the sorted positions (ğ‘—), instead of enumerating the combinations. Second,\nwe iterate over sorted positions (ğ‘—)to get the corresponding result quality ğ‘(ğ‘—)on the calibration\nset. For each(ğ‘—), we select the corresponding error ğ‘œğ‘–,(ğ‘—)as the adjusting offset of ğ‘€ğ‘–. We then\nsimulate LeaFi-enhanced search for the calibration queries, and calculate the result quality ğ‘(ğ‘—)\n(Step 2 in Figure 6). After checking all sorted positions, we collect the examples {(ğ‘(ğ‘—),ğ‘œğ‘–,(ğ‘—)}of the\nmapping between the result quality and the adjusting offset for each ğ‘€ğ‘–. Using these examples,\nwe train a spline regression model [ 57] as the auto-tuner to fit the mapping ğ‘“ğ‘\nğ‘–:ğ‘Ÿâ†’ğ›¼(Step 3 in\nFigure 6).\nAuto-tuner learning pseudocode. We present the auto-tuner training pseudocode in Algorithm 4.\nIn line 1 to line 4, we traverse each inserted filter ğ‘€ğ‘–, evaluate it on the calibration set Sğ‘(ğ‘), calculate\nand sort the absolute prediction errors. We then iterate over all sorted position in line 5. For each\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:16 Qitong Wang, Ioana Ileana, & Themis Palpanas\nsorted position ğ‘—, we set the adjusting offset ğ‘œğ‘—ğ‘–to be the sorted error ğ›¼ğ‘–,(ğ‘—)for each filter ğ‘€ğ‘–in\nline 7. We simulate the LeaFi-enhanced search for the calibration queries Sğ‘(ğ‘)and calculate their\nachieved result qualities {ğ‘ğ‘—,ğ‘˜}in line 9 to line 10, and add the (adjust offset, result quality) pair\n(ğ‘ğ‘—,ğ‘˜,ğ‘œğ‘—,ğ‘–)toğ‘€ğ‘–â€™s auto-tuner training set in line 12. Finally, we train and return the auto-tunes {ğ‘“ğ‘\nğ‘–}.\n4.4.2 Filter Prediction Auto-tuning in Search. In LeaFi-enhanced search stage, given a user-requested\nquality target ğ‘, we first determine the corresponding adjusting offset ğ‘œğ‘–using the learned mapping\nğ‘“ğ‘\nğ‘–(ğ‘)for each learned filter ğ‘€ğ‘–. The filter prediction is adjusted accordingly, i.e., ğ‘‘F\nğ‘–=ğ‘‘f\nğ‘–âˆ’ğ‘œğ‘–, based\non which the filter-based pruning for node ğ‘ğ‘–is triggered.\n4.5 Complexity Analysis\nIn this section, we briefly analyze the time and space complexity for the LeaFi framework. The cost\nof LeaFi is mainly from LeaFi-enhanced index building. In LeaFi-enhanced search, the overhead of\nfilter inference is expected to be covered by search time reduction through the leaf node selection\nprocedure in Section 4.2.\nAmong the four steps in LeaFi-enhanced index building, we note that the time bottleneck lies\nin training data generation and filter learning, rather than leaf node selection and conformal\nauto-tuner learning. The complexity of training data generation is O(ğ‘›ğ‘Ã—ğ‘›), linear to the training\ndata sizeğ‘›ğ‘and dataset size ğ‘›. The filter training is proportional to the number of inserted filters\nğ‘›ğ¹as well as the training time of an individual filter ğ‘¡ğ¹, resulting in a complexity of O(ğ‘¡ğ¹Ã—ğ‘›ğ¹).\nHence, the time complexity of LeaFi enhancement in index building (i.e., besides the original index\nbuilding time complexity) is O(ğ‘›ğ‘ğ‘›+ğ‘¡ğ¹ğ‘›ğ¹).\nThe space complexity of LeaFi O(ğ‘›ğ‘+ğ‘ ğ¹ğ‘›ğ¹), although proportional to the training data size ğ‘›ğ‘\nand number of inserted filters ğ‘›ğ¹, is negligible compared to the dataset size ğ‘›.\nWe note that with a reasonable training data size (2K series in our experiments) and a proper\nnode size threshold ( ğ‘¡â„=ğ‘Â·ğ‘¡F/ğ‘¡Sin our experiments), LeaFi can provide considerable benefits\nwhen compared to the original indexes.\n5 Experiments\nIn this section, we report our experiment evaluation using two different tree-based series indexes\nand five diverse datasets. The source code and datasets are available online2.\n5.1 Evaluation Setup\nThe experiments were carried out on a server equipped with an Intel(R) Xeon(R) Gold 6242R\nCPU, 520 GB RAM, and an NVIDIA Quadro RTX 6000 with 24 GB GDDR6 memory. The soft-\nware environments were gcc/9.4.0, cuda/11.2, libtorch/1.13.1 (for MLP), and gsl/2.7.2 (for spline\nregression).\nDatasets. We include a variety of datasets in our evaluation, consisting of one synthetic dataset and\nfour real datasets from different domains. For the synthetic dataset, we choose RandWalk [ 17], which\nis generated by accumulating steps following a standard Gaussian distribution ğ‘(0,1). Regarding\nthe real datasets, we select Seismic [ 59] from seismology, Astro [ 56] from astronomy, Deep [ 6]\nand SIFT [ 25] from image processing. Note that Deep and SIFT are two popular high-dimensional\nvector datasets of image descriptors (not data series). The series length is 256, except for Deep\n(96) and SIFT (128). Each dataset contains 25 million (i.e., 25M) data series in our experiments. In\naddition, we experimented with datasets of sizes between 10M-100M to test the scalability of LeaFi.\nFollowing recent data series studies [ 13], we create four different query sets with varying levels\nof difficulty for every dataset. Each query set consists of 1,000 series, generated by adding 10%, 20%,\n30%, and 40% Gaussian noise into uniform random samples. Additionally, we generate one training\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:17\nset of 2,000 series for each dataset, by adding random levels of Gaussian noise âˆˆ[10%, 40%]. The\nsplit of training and validation is 4:1.\nTree-based series indexes. We choose MESSI [ 47] (the SOTA variant of iSAX [ 55]) and DSTree [ 65]\nas the backbone indexes. The split threshold of node size is 10k for both indexes. We use 16 threads\nin MESSI for index building and query answering.\nLeaFi instantiation. We use MLP to instantiate learned filters. Each MLP model have one hidden\nlayer, whose dimension is set the same as the input series. We train these models using the stochastic\ngradient descent (SGD) [ 52] algorithm for at most 1,000 epochs. The learning rate, initialized as\n0.01, is divided by 10 (until 10âˆ’5) when the validation errors plateau.\nWe leverage multicore processing to accelerate the collecting of training data and the training of\ninserted filters. For the efficient collecting of training data, we propose a two-pass strategy that\nworks for all tree-based indexes. In the first pass, we detach all the leaf nodes with inserted filters\nto calculate their node-wise nearest neighbor distances in parallel. Then in the second pass, we\nsearch for the global queries and collect the best-so-far distances efficiently by reusing the distances\ncalculated in the first pass. For filter training, we assign one CUDA stream to each thread [ 40] and\nuse 16 threads to train the models in parallel.\nComparison approaches. The exact search performance of the original indexes is an important\nbaseline for LeaFi. Additionally, we choose ğœ–-search,ğ›¿ğœ–-search [ 16], ProS [ 14,22] and LT [ 33] to\nrepresent the early-stopping strategy, as well as LR [26] to represent the reordering strategy.\nNote that the comparison approaches do not natively support result quality targets. Moreover, LT\nemploys sets of features designed specifically for graph-based indexes [ 38] and inverted indexes [ 5],\nwhich do not apply to the tree-based data-series indexes used in this study. Hence, we need to adjust\nthese approaches to fit our scenario, and then also pay the cost to fine-tune them. Specifically:\n(1)Forğœ–-search, we grid-search for the maximal ğœ–âˆˆ[1,7]that providesâ‰¥99% recall on the\nvalidation set [ 16]. A largerğœ–results in larger acceleration but lower recall. We set ğœ–=1 when 99%\nrecall cannot be achieved.\n(2)Forğ›¿ğœ–-search, we set ğœ–=0 and then grid-search for the smallest ğ›¿âˆˆ[90%,99.9%]that provides\nâ‰¥99% recall on the validation set [ 16]. A largerğ›¿results in smaller acceleration but higher recall.\nWe setğ›¿=99.9% when 99% recall cannot be achieved. We estimate the nearest neighbor distances\nusing the node-wise nearest neighbor distances on the validation set.\n(3)For ProS, we choose the early-stopping strategy that predicts whether the nearest neighbor\nresults have been found after checking certain number of leaf nodes using the best-so-far dis-\ntances [ 14,22]. We set the early-stopping checking nodes to be [16, 64, 256, 512, 1024, 2048] for\nDSTree, and also [4096, 8192] for iSAX.\n(4)For LT, we design our own features for tree-based series indexes following similar intu-\nitions [ 33]: (a) the input query, (b) the ratio between the node-wise nearest neighbor distances of\nthe first leaf node and the first [2, 4, 8, 16] leaf nodes for DSTree ([8, 16, 32, 64] for MESSI), (c) the\nbest-so-far distances after examining the first [1, 2, 4, 8, 16] leaf nodes for DSTree ([1, 8, 16, 32,\n64] for MESSI), and (d) the ratio between the node-wise nearest neighbor distance of the first leaf\nnode and the best-so-far distance after examining the 16th node for DSTree (or 64th for MESSI).\nBesides the need for a new feature template, we also need to tune the multiplier, a hyperparameter\nthat expands the predicted number of early-stop nodes. We grid-search for the minimal multiplier\nâˆˆ[1,20]that can provideâ‰¥99% recall on the validation set. A larger multiplier results in smaller\nacceleration but higher recall. We set multiplier=20 when 99% recall cannot be achieved.\n(5)For LR [ 26], we use the optimal reordering, i.e., the nearest neighbor results lie in the first\nexamined leaf node, to provide the largest possible acceleration by any reordering strategies.\nEvaluation measures. We report the query time (lower is better), recall-at-1 [ 33] (higher is better)\nand series pruning ratio (higher is better) in our experiments.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:18 Qitong Wang, Ioana Ileana, & Themis Palpanas\nExact LRÎ´-Îµ-search LTÎµ-search ProS LeaFi\nRWDeep SIFT Seis. Astro012345Query Time (seconds)\n(a) Query time (DSTree)\nRWDeep SIFT Seis. Astro0.80.91.0Achieved Recall (b) Recall for 99% target (DSTree)\nRWDeep SIFT Seis. Astro0.00.51.01.5Query Time (seconds)\n(c) Query time (MESSI)\nRWDeep SIFT Seis. Astro0.80.91.0Achieved Recall (d) Recall for 99% target (MESSI)\nFig. 7. The query time and achieved recalls at a target 99% recall for enhanced DSTree and MESSI indexes\nacross datasets.\n5.2 Main Results\nWe first report the average query time and actual recalls for a recall target 99% in Figure 7. We also\nprovide a detailed analysis for the enhanced DSTree indexes by reporting the detailed results over\ndifferent query noise levels, in Figure 8.\nOverall, we find that LeaFi is the only solution that can provide a substantial search time\nimprovement while achieving 99% recall in all test cases. LeaFi-enhanced series indexes improved\npruning ratio by up to 20x (by DSTree on SIFT dataset with queries of 40% noise) and search time by\nup to 32x (by DSTree on RandWalk dataset with queries of 20% noise), while maintaining a target\nrecall of 99%. Moreover, LeaFi is the only solution that supports ad-hoc quality targets, chosen at\nquery time, independently for each query.\nOn the contrary, despite our best efforts to tune the comparison methods, none of the early-\nstopping strategies ( ğ›¿ğœ–-search, LT, ğœ–-search, and ProS) can consistently achieve 99% recall across\nfour query subsets of different noise levels. The reordering strategy (LR) failed to provide query\ntime improvement. These empirical observations comply to our analysis in Section 2.\n5.2.1 Main Results on DSTree. We first discuss the average search time and actual recalls for a\nrecall target 99% on DSTree in Figure 7a and 7b. The split-down results across different query noise\nlevels are reported in Figure 8.\nLeaFi-enhanced DSTree obtained 99% recall on all 5 datasets, with an average speedup of 9.2x,\nand best speedup of 12.7x, when compared to the exact search. This is attributed to the largely\nimproved pruning capability of DSTree leaf nodes. LeaFi achieved an average pruning ratio of 95.6%,\ncompared to 59.8% without any learned filters (cf. Figure 8). ğœ–-search and ğ›¿ğœ–-search for DSTree\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:19\nYaxis: Achieved Recall, Xaxis: Added Noise Level Exact DSTree LRÎ´-Îµ-search LTÎµ-search ProS LeaFi\n10%20%30%40%0.80.91.0\n(a) RandWalk\n10%20%30%40%0.80.91.0 (b) Deep\n10%20%30%40%0.80.91.0 (c) SIFT\n10%20%30%40%0.80.91.0 (d) Seismic\n10%20%30%40%0.80.91.0 (e) Astro\nYaxis: Query Time (in Second), Xaxis: Added Noise Level Exact DSTree LRÎ´-Îµ-search LTÎµ-search ProS LeaFi\n10%20%30%40%012\n(f) RandWalk\n10%20%30%40%0246 (g) Deep\n10%20%30%40%02468 (h) SIFT\n10%20%30%40%02468 (i) Seismic\n10%20%30%40%02468 (j) Astro\nYaxis: Series Pruning Ratio, Xaxis: Added Noise Level Exact DSTree LRÎ´-Îµ-search LTÎµ-search ProS LeaFi\n10%20%30%40%0.00.20.40.60.81.0\n(k) RandWalk\n10%20%30%40%0.00.20.40.60.81.0 (l) Deep\n10%20%30%40%0.00.20.40.60.81.0 (m) SIFT\n10%20%30%40%0.00.20.40.60.81.0 (n) Seismic\n10%20%30%40%0.00.20.40.60.81.0 (o) Astro\nFig. 8. The actual recall (8a to 8e), average query time (8f to 8j) and average series pruning ratio (8k to 8o) for\nenhanced DSTree indexes, targeting at 99% recall.\nindexes also provided 99% recall on 5 datasets. However, LeaFi-enhanced DSTree are much more\nefficient, i.e., 2.4x faster than ğœ–-search and 8.1x faster than ğ›¿ğœ–-search on average. This observation\nindicates that although heuristic early-stopping approaches can effectively support quality targets,\nmachine learning-based enhancements can provide larger query acceleration. We also observe\nthatğ›¿ğœ–-search requires the accurate estimation of the nearest neighbor distances [ 16], which is\nextremely hard.\nProS- and LT-enhanced DSTree achieved 99% recall on only 2 datasets, which are RandWalk and\nSeismic for ProS, and Deep and Seismic for LT. The average recall of ProS is 96%, largely lagging\nbehind the 99% target. Although the average recall of LT is 98.9%, LeaFi-enhanced DSTree are 1.9x\nfaster than LT on average. LTâ€™s inability to achieve 99% recall by tuning the multiplier also implies\nthat the model training for LT is much harder than LeaFi. This is because LeaFi fits one model to\none leaf node with a small target range âˆˆ[0, 10], while LT fits one model to the whole datasets with\nlarge target range [ 102,105].\nDetailed analysis at different query noise levels. Breaking down the results across different\nquery noise levels, we report the average search time, actual recalls and pruning ratios in Figure 8.\nLeaFi-enhanced DSTree achieved 99% recall on 17 of 20 (85%) cases, with an average of 99.4% and the\nlowest of 97.6%. The 3 cases of <99% recall are with queries of small noise levels, 10% on RandWalk,\n10% and 20% on Astro. This is because these cases are equipped with much smaller nearest neighbor\ndistances than cases of higher noise, hence challenging LeaFiâ€™s conformal auto-tuners. The best\nspeedup of LeaFi-enhanced DSTree is 32.4x, obtained on RandWalk with queries of 20% noise. LeaFi\nachieved an average pruning ratio of 95.6%, compared to 59.8% without any learned filters.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:20 Qitong Wang, Ioana Ileana, & Themis Palpanas\nSimilarly to the aggregated results in Figure 8, ğœ–-search and ğ›¿ğœ–-search perform well in achieving\nthe 99% recall target, but with small time performance improvements. ğœ–-search achieved 99% recall\non all 20 cases, while ğ›¿ğœ–-search achieved 99% recall on 17 of 20 (85%) cases. On the other hand,\nProS- and LT-enhanced DSTree struggled in achieving 99% recall target. ProS-enhanced DSTree\nachieved 99% recall on 7 (35%) cases, while LT-enhanced DSTree achieved 99% recall on 11 (55%)\ncases. LR, as expected, provided 100% recall with marginal improvement in terms of search time\nand pruning ratio, compared to LeaFi.\nIn conclusion, LeaFi is the only solution that can provide a substantial improvement in search\ntime (up to 32.4x faster) and pruning ratio (up to 20x more), while consistently maintaining 99%\nrecall.\n5.2.2 Main Results on iSAX. We provide the average search time and actual recalls for a recall\ntarget 99% on MESSI in Figure 7c and 7d. Due to the lack of space, we remove the splitting-down\nfigures across query noise levels to an extended version.\nMESSI differs from DSTree in the following aspects: (1) MESSI has more leaf nodes, yet with\nsmaller filling factors, than DSTree; (2) MESSI can provide tighter node summarization than DSTree,\nwhile DSTree better groups similar series into the same leaf nodes [ 3]. Moreover, the fact that\nMESSI utilizes the parallelization capabilities of modern hardware is an additional factor that affects\nperformance. These elements explain the performance differences between enhanced DSTree and\nMESSI.\nLeaFi improved MESSI query time on all 5 datasets while maintaining 99% recall, with an average\nspeedup of 2.7x and the best speedup of 4x. In the splitting-down results across query noise levels,\nthe best speedup is 13x on RandWalk with queries of 20% noise. The search time improvement is\nless than the pruning ratio improvement, which is improved from 55.2% to 86.2% on average (which\nis expected to provide a 3.2x speedup). We believe this is due to GPU resource contention as a result\nof concurrent filter inference requests. We further verified this speculation by varying the leaf node\nthresholds in Section 5.3.3. These results verified LeaFi can provide a substantial improvement in\nsearch time and pruning ratio, while achieving 99% recall for MESSI in a multithread environment.\nFor the comparison methods, only LT-enhanced MESSI achieved 99% recall on only 2 of the\ndatasets. Other comparison methods cannot achieve 99% recall in any dataset, despite thorough\ntuning using the validation set. In the detailed results across query noise levels, LeaFi-enhanced\nMESSI achieved 99% recall on 14 of 20 (70%) cases, while ğœ–-search and LT on 6 (30%) cases, ğ›¿ğœ–-search\nand ProS on 1 (5%) case. Moreover, LeaFi-enhanced MESSI is faster than LT-enhanced MESSI on 3\ndatasets.\nIn summary, the results on MESSI are consistent with those on DSTree. LeaFi is the only solution\nthat maintains 99% recall across queries of all noise levels, while providing considerable query\nspeedups (up to 13x) and pruning ratio improvements (up to 76.2%).\n5.3 Extended Analysis\nIn this section, we report the actual recalls under different recall targets in Figure 9, the query time\nfor 100M datasets in Figure 10, and the query time across different leaf node threshold in Figure 11\nto better understand the performance of LeaFi-enhanced indexes.\n5.3.1 Varying Recall Target. We present the actual recalls of LeaFi-enhanced DSTree and MESSI\nfor user-requested high recalls âˆˆ[95%, 99.9%] in Figure 9. These results verify that the conformal\nauto-tuner of LeaFi can effectively adjust the filter predictions to accommodate user quality targets.\nOverall, LeaFi-enhanced DSTree achieved the recall targets on 31 of 35 (88.6%) cases and LeaFi-\nenhanced MESSI achieved the recall targets on 28 of 35 (80%). The recall difference when the target\nrecall cannot be achieved is marginal, i.e., 0.54% for DSTree and 0.35% for MESSI. The largest\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:21\nRandWalk Deep SIFT Seismic Astro\n0.95 0.97 0.99 .995 .999\nT arget recall0.9.95.96.97.98.991.0Actual recall\n(a) DSTree\n0.95 0.97 0.99 .995 .999\nT arget recall0.9.95.96.97.98.991.0Actual recall (b) MESSI\nFig. 9. The target recall and actual (achieved) recall for LeaFi-enhanced DSTree and MESSI indexes across\ndatasets.\nRandWalk Deep SIFT Seismic Astro\n10m 25m 50m 100m\nDataset size510152025times faster\n(a) DSTree\n10m 25m 50m 100m\nDataset size12345times faster\n (b) MESSI\nFig. 10. The query time improvements at a target 99% recall for LeaFi-enhanced DSTree and MESSI when\nvarying the dataset size between 10M-100M.\ndifference was found by DSTree on the SIFT dataset, with a 95% recall target. We believe that the\nsmall number of validation examples (300) resulted in imbalanced statistics, leaving some queries\nsensitive to the adjusting offset for the 95% recall target. Even though our focus has been on very\nhigh recall targets, we note that LeaFi-enhanced indexes are effective for smaller recall targets, as\nwell. As the recall target decreases, LeaFi leads to increased speedups. We omit these results for\nbrevity.\n5.3.2 Varying Dataset Size. In Figure 10, we present the query time improvements of LeaFi-\nenhanced DSTree and MESSI for 99% recall target as we vary the dataset size between 10M-100M.\nWe note that in this experiment, we build a different index structure for each dataset size (i.e., a tree\nwith a different number of leaves and different sets of series in each leaf), which leads to a different\nset of inserted and trained filters in each case. This explains the non-smooth curves shown in the\ngraphs.\nOverall, the results demonstrate that LeaFi-enhanced series indexes consistently improve query\nanswering times across all dataset sizes (while maintaining the 99% target recall). They also show\na trend for larger query time improvements as the dataset size grows larger. Delving into the\nresults, we observe that LeaFi-enhanced DSTree obtained an average speedup of 9.2x on the 25M\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:22 Qitong Wang, Ioana Ileana, & Themis Palpanas\n100300500700900\nNode size threshold0.51.01.52.0Query time (seconds)\n(a) Query time vs. node size\nthreshold\n100300500700900\nNode size threshold10k20k30k40kNumber of filters\n(b) Number of inserted filters\nvs. node size threshold\n100300500700900\nNode size threshold0.40.50.60.70.80.9Pruning ratio\n(c) Pruning ratio vs. node size\nthreshold\n04812162024\nGPU memory (GB)0.500.550.600.650.700.75Query time (seconds)\n(d) Query time vs. GPU mem-\nory size\nFig. 11. Tradeoff between the available GPU memory and leaf node size threshold ğ‘¡â„, and the query time,\npruning ratio, and number of inserted filters (for LeaFi-enhanced MESSI).\ndatasets, and a 13.6x average speedup on the 100M datasets. This increase in speedup is attributed\nto the increased pruning ratio for the 100M dataset (from 94.5% to 97.6%). On the other hand,\nLeaFi-enhanced MESSI obtained a 2.7x average speedup on the 25M datasets, and a 2.4x speedup\non the 100M datasets. This behavior is due to the increased number of inserted filters (from âˆ¼10k\ntoâˆ¼30k), which overwhelms the GPU access. Exploring techniques for efficient GPU utilization\nwould be a promising direction going forward [64].\n5.3.3 Varying Node Size Threshold. Figures 11a-c depict the search time and pruning ratios of\nLeaFi-enhanced MESSI across a range of leaf node thresholds on the 25M Deep dataset, with queries\nof 40% noise. With the increase of leaf node size threshold ğ‘¡â„, the search time first decreased\nthen increased, while the pruning ratios kept decreasing. The decrease of the search time came\nfrom both the filter inference time and the multithreading GPU access competition overhead.\nEmpirically, we measured ğ‘¡F/ğ‘¡Sâ‰ˆ279for the Deep dataset. By setting the hyperparameter ğ‘=2,\nLeaFi usedğ‘¡â„=558for Deep dataset, which provided near-optimal performance on iSAX. Without\nthe multithreading GPU access competition, LeaFi-enhanced DSTree has a turning point of âˆ¼100.\n5.3.4 Varying GPU Memory. We present in Figure 11d the search time of LeaFi-enhanced MESSI\nacross a range of GPU memory limits under the same setting as in Figures 11a-c. All reported\nresults targeted at 99% recall, and achieved at least 99.3% actual recall. Overall, the query time starts\nto decrease and then stabilizes as we increase the available GPU memory. The decreasing phase\nis bounded by GPU memory, while the stabilization phase is bounded by the number of filters\nthat are expected to improve query time. The point where improvement stops is at 6.9 GB, which\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:23\nTable 1. Filter inference time ( ğœ‡s)\nand the node size threshold ğ‘¡â„de-\nrived for Deep (length 96).\nType Timeğ‘¡â„\nMLP 46 558\nCNN 258 3,129\nRNN 11,695 141k\nğ‘‘(Â·,Â·) 0.16 -\nRWDeep SIFT Seis. Astro0246Query Time (seconds)Exact\nLeaFi-CNN\nLeaFi Fig. 12. LeaFi with CNN filters on\nDSTree.\nTable 2. Query time (seconds) and actual recall for LeaFi-enhanced DSTree without ( âˆ’Local) and with (+Local)\nlocal training data, for 99% recall target; +Local corresponds to our proposed LeaFi solution.\nQuery time (s) Actual recall\nDataset Exactâˆ’Local+Localâˆ’Local+Local\nRandWalk 1.2 0.4 0.1 0.98âœ— 1.0âœ“\nDeep 3.6 0.7 0.3 0.96âœ— 0.99âœ“\nSIFT 5.3 1.3 1.0 0.94âœ— 0.99âœ“\nSeismic 4.9 0.3 0.4 0.99âœ“ 1.0âœ“\nAstro 5.5 1.0 1.6 0.91âœ— 0.99âœ“\ncorresponds to inserting filters to the 14K leaf nodes with more than ğ‘¡â„=500series. Inserting\nmore filters would mean that these additional filters would end up in leaf nodes with less the 500\nseries: in such cases, the filter inference time would be larger than the time to scan all series in the\nleaf, bringing no additional benefit. (The LeaFi-enhanced DSTree results are similar, and omitted\nfor brevity.)\n5.3.5 Varying Model Type. Table 1 and Figure 12 illustrate the results on instantiating LeaFi filters\nwith Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) models. The\nCNN model has 2 convolutional layers with kernel size 3 and latent channel size equal to the series\nlength. Similarly, the RNN model contains 2 LSTM blocks. Both CNN and RNN are much more\ncomputationally expensive than MLP, resulting in 5.6x and 254x larger node size thresholds. These\nhigh thresholds render the deployment of RNN filters not suitable in our setting (the RNN inference\ntime would only be justified for leaf nodes of size â‰¥11ğ‘˜/0.16âˆ—2=141ğ¾series, while our leaves\nhave a maximum capacity of 10K). Having ğ‘¡â„=3ğ‘˜, the benefit of CNN is also limited, leading to\na much smaller number of inserted filters (when compared to MLP), and in general, significantly\nsmaller pruning ratios and query time improvements.\n5.3.6 Without Local Training Data. We study the impact of local training data in Table 2. We\nobserve that training LeaFi without local training data can still bring improvements in query time,\nbut it cannot consistently achieve the 99% recall target. This is because the nodewise NN distances\nof the global queries are larger than the distances of their query results. Removing the local training\nqueries also removes the query resultsâ€™ distance ranges from the training data, making these lower\nranges ignored by the filters and conformal auto-tuners. These results confirm that local training\ndata is necessary for LeaFi.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:24 Qitong Wang, Ioana Ileana, & Themis Palpanas\nTable 3. Indexing time breakdown (minutes) for\nLeaFi-enhanced DSTree and MESSI on Seismic 100M.\nDSTree MESSI\nIndexing 28.6 5.3\nCollecting data 104.2 67.5\nTraining 46.4 48.3Table 4. Additional space overhead (GB) for LeaFi-\nenhanced DSTree and MESSI on Seismic 100M.\nDSTree MESSI\nData 100 100\nIndex structure 1.5 0.3\nFilters 4.7 4.8\n5.3.7 Training Time. We report the indexing and training time for LeaFi-enhanced indexes in\nTable 3. LeaFi-enhanced DSTree spends more time in indexing and collecting training data, because\nit employs a more complex summarization (EAPCA), while LeaFi-enhanced MESSI needs longer\ntraining time, because it employes more filters than DSTree (19k vs. 18k). We note that if training\ntime is a critical resource, the users can choose to train fewer filters, yet, still benefit from the\nimproved pruning ratios. As Figure 11a shows, reducing the number of filters from âˆ¼14k toâˆ¼7k\nreduces the training time to half, while the query time only increases from âˆ¼0.5 toâˆ¼0.75 seconds,\nstill outperforming the baseline.\n5.3.8 Space Overhead. We report the space overhead for LeaFi-enhanced indexes in Table 3. The\nadditional space needed by the filters is comparable for DSTree and MESSI, and is in both cases a\nsmall percentage ( <5%) of the data size.\n6 Conclusions and Future Work\nIn this paper, we present LeaFi, a framework that enhances tree-based series indexes with learned\nfilters in order to accelerate data series similarity search, while satisfying a user-defined target\nrecall. LeaFi can improve pruning ratio by up to 20x, and query answering time by up to 32x, while\nmaintaining a target recall of 99%. These results set the foundations for future advancements in\nemploying learned filters for data series similarity search, including the development of algorithms\nfor inserting filters into both internal nodes and leaf nodes, estimating filter-based pruning ratios\neffectively, choosing among different learned filter models, and supporting updates. As updates\nmay trigger node splitting, incremental learning [ 60] could play an important role in efficiently\ntraining the new filters of the children nodes based on the filter of the parent [ 9]. It would also be\ninteresting to study the potential of LeaFi to enhance the performance of other index types, such as\ninverted indexes [5] and Locality-Sensitive Hashing (LSH) [24].\nAcknowledgments\nWork partially supported by EU Horizon projects AI4Europe (101070000), TwinODIS (101160009),\nARMADA (101168951), DataGEMS (101188416) and RECITALS (101168490).\nReferences\n[1]Shun-ichi Amari. 1967. A Theory of Adaptive Pattern Classifiers. IEEE Transactions on Electronic Computers 16, 3\n(1967), 299â€“307.\n[2]Anastasios N. Angelopoulos and Stephen Bates. 2023. Conformal Prediction: A Gentle Introduction. Found. Trends\nMach. Learn. 16, 4 (2023), 494â€“591.\n[3]Ilias Azizi, Karima Echihabi, and Themis Palpanas. 2023. Elpis: Graph-Based Similarity Search for Scalable Data Science.\nPVLDB 16, 6 (2023), 1548â€“1559.\n[4]Ilias Azizi, Karima Echihabi, and Themis Palpanas. 2025. Graph-Based Vector Search: An Experimental Evaluation of\nthe State-of-the-Art. PACMMOD (2025).\n[5] Artem Babenko and Victor S. Lempitsky. 2015. The Inverted Multi-Index. TPAMI 37, 6 (2015), 1247â€“1260.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:25\n[6]Artem Babenko and Victor S. Lempitsky. 2016. Efficient Indexing of Billion-Scale Datasets of Deep Descriptors. In\nCVPR . 2055â€“2063.\n[7]Rene De La Briandais. 1959. File searching using variable length keys. In IRE-AIEE-ACM Computer Conference (Western) .\n295â€“298.\n[8]Manos Chatzakis, Panagiota Fatourou, Eleftherios Kosmas, Themis Palpanas, and Botao Peng. 2023. Odyssey: A\nJourney in the Land of Distributed Data Series Similarity Search. PVLDB 16, 5 (2023), 1140â€“1153.\n[9]Tianyi Chen, Jun Gao, Hedui Chen, and Yaofeng Tu. 2023. LOGER: A Learned Optimizer towards Generating Efficient\nand Robust Query Execution Plans. PVLDB 16, 7 (2023).\n[10] Bill Yuan-chi Chiu, Eamonn J. Keogh, and Stefano Lonardi. 2003. Probabilistic discovery of time series motifs. In KDD .\n493â€“498.\n[11] Hui Ding, Goce Trajcevski, Peter Scheuermann, Xiaoyue Wang, and Eamonn J. Keogh. 2008. Querying and mining of\ntime series data: experimental comparison of representations and distance measures. PVLDB 1, 2 (2008), 1542â€“1552.\n[12] Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. 2020. Tsunami: A Learned Multi-dimensional\nIndex for Correlated Data and Skewed Workloads. PVLDB 14, 2 (2020), 74â€“86.\n[13] Karima Echihabi, Panagiota Fatourou, Kostas Zoumpatianos, Themis Palpanas, and Houda Benbrahim. 2022. Hercules\nAgainst Data Series Similarity Search. PVLDB 15, 10 (2022), 2005â€“2018.\n[14] Karima Echihabi, Theophanis Tsandilas, Anna Gogolou, Anastasia Bezerianos, and Themis Palpanas. 2023. ProS: data\nseries progressive k-NN similarity search and classification with probabilistic quality guarantees. VLDBJ 32, 4 (2023),\n763â€“789.\n[15] Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, and Houda Benbrahim. 2018. The Lernaean Hydra of Data\nSeries Similarity Search: An Experimental Evaluation of the State of the Art. PVLDB 12, 2 (2018), 112â€“127.\n[16] Karima Echihabi, Kostas Zoumpatianos, Themis Palpanas, and Houda Benbrahim. 2019. Return of the Lernaean Hydra:\nExperimental Evaluation of Data Series Approximate Similarity Search. PVLDB 13, 3 (2019), 403â€“420.\n[17] Christos Faloutsos, M. Ranganathan, and Yannis Manolopoulos. 1994. Fast Subsequence Matching in Time-Series\nDatabsases. In SIGMOD . 419â€“429.\n[18] Panagiota Fatourou, Eleftherios Kosmas, Themis Palpanas, and George Paterakis. 2023. FreSh: A Lock-Free Data Series\nIndex. In SRDS . 209â€“220.\n[19] Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain Muller. 2019. Deep\nlearning for time series classification: a review. DMKD 33, 4 (2019), 917â€“963.\n[20] Yanjie Gao, Yu Liu, Hongyu Zhang, Zhengxian Li, Yonghao Zhu, Haoxiang Lin, and Mao Yang. 2020. Estimating GPU\nmemory consumption of deep learning models. In ESEC/FSE . 1342â€“1352.\n[21] Tiezheng Ge, Kaiming He, Qifa Ke, and Jian Sun. 2014. Optimized Product Quantization. TPAMI 36, 4 (2014), 744â€“755.\n[22] Anna Gogolou, Theophanis Tsandilas, Karima Echihabi, Anastasia Bezerianos, and Themis Palpanas. 2020. Data Series\nProgressive Similarity Search with Probabilistic Quality Guarantees. In SIGMOD . 1857â€“1873.\n[23] Anna Gogolou, Theophanis Tsandilas, Themis Palpanas, and Anastasia Bezerianos. 2019. Comparing Similarity\nPerception in Time Series Visualizations. TVCG 25, 1 (2019), 523â€“533.\n[24] Qiang Huang, Jianlin Feng, Yikai Zhang, Qiong Fang, and Wilfred Ng. 2015. Query-Aware Locality-Sensitive Hashing\nfor Approximate Nearest Neighbor Search. PVLDB 9, 1 (2015), 1â€“12.\n[25] HervÃ© JÃ©gou, Romain Tavenard, Matthijs Douze, and Laurent Amsaleg. 2011. Searching in one billion vectors: Re-rank\nwith source coding. In ICASSP . 861â€“864.\n[26] Rong Kang, Wentao Wu, Chen Wang, Ce Zhang, and Jianmin Wang. 2021. The case for ml-enhanced high-dimensional\nindexes. In AIDB@VLDB .\n[27] Hans Kellerer, Ulrich Pferschy, and David Pisinger. 2004. Knapsack problems . Springer.\n[28] Eamonn J. Keogh, Kaushik Chakrabarti, Sharad Mehrotra, and Michael J. Pazzani. 2001. Locally Adaptive Dimensionality\nReduction for Indexing Large Time Series Databases. In SIGMOD . 151â€“162.\n[29] Kyoungmin Kim, Jisung Jung, In Seo, Wook-Shin Han, Kangwoo Choi, and Jaehyok Chong. 2022. Learned Cardinality\nEstimation: An In-depth Study. In SIGMOD . 1214â€“1227.\n[30] Haridimos Kondylakis, Niv Dayan, Kostas Zoumpatianos, and Themis Palpanas. 2018. Coconut: A Scalable Bottom-Up\nApproach for Building Data Series Indexes. PVLDB 11, 6 (2018), 677â€“690.\n[31] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The Case for Learned Index Structures.\nInSIGMOD . 489â€“504.\n[32] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature 521, 7553 (2015), 436â€“444.\n[33] Conglong Li, Minjia Zhang, David G. Andersen, and Yuxiong He. 2020. Improving Approximate Nearest Neighbor\nSearch through Learned Adaptive Early Termination. In SIGMOD . 2539â€“2554.\n[34] Guoliang Li, Xuanhe Zhou, and Lei Cao. 2021. AI Meets Database: AI4DB and DB4AI. In SIGMOD . 2859â€“2866.\n[35] Mingjie Li, Ying Zhang, Yifang Sun, Wei Wang, Ivor W. Tsang, and Xuemin Lin. 2020. I/O Efficient Approximate\nNearest Neighbour Search based on Learned Functions. In ICDE . 289â€“300.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\n51:26 Qitong Wang, Ioana Ileana, & Themis Palpanas\n[36] Michele Linardi and Themis Palpanas. 2018. Scalable, Variable-Length Similarity Search in Data Series: The ULISSE\nApproach. PVLDB 11, 13 (2018), 2236â€“2248.\n[37] Michele Linardi and Themis Palpanas. 2020. Scalable data series subsequence matching with ULISSE. VLDBJ 29, 6\n(2020), 1449â€“1474.\n[38] Yury A. Malkov and Dmitry A. Yashunin. 2020. Efficient and Robust Approximate Nearest Neighbor Search Using\nHierarchical Navigable Small World Graphs. TPAMI 42, 4 (2020), 824â€“836.\n[39] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learning Multi-Dimensional Indexes. In\nSIGMOD . 985â€“1000.\n[40] NVIDIA Corporation and Affiliates. 2023. CUDA Toolkit Documentation. https://docs.nvidia.com/cuda/. [Online;\naccessed 29-July-2023].\n[41] NVIDIA Corporation and Affiliates. 2023. NVIDIA Management Library (NVML). https://developer.nvidia.com/nvidia-\nmanagement-library-nvml. [Online; accessed 3-July-2023].\n[42] Themis Palpanas. 2015. Data Series Management: The Road to Big Sequence Analytics. SIGMOD Rec. 44, 2 (2015),\n47â€“52.\n[43] Themis Palpanas and Volker Beckmann. 2019. Report on the First and Second Interdisciplinary Time Series Analysis\nWorkshop (ITISA). SIGMOD Rec. 48, 3 (2019), 36â€“40.\n[44] Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alexander Gammerman. 2002. Inductive Confidence\nMachines for Regression. In ECML , Vol. 2430. 345â€“356.\n[45] John Paparrizos and Luis Gravano. 2015. k-Shape: Efficient and Accurate Clustering of Time Series. In SIGMOD .\n1855â€“1870.\n[46] John Paparrizos, Yuhao Kang, Paul Boniol, Ruey S. Tsay, Themis Palpanas, and Michael J. Franklin. 2022. TSB-UAD:\nAn End-to-End Benchmark Suite for Univariate Time-Series Anomaly Detection. PVLDB 15, 8 (2022), 1697â€“1711.\n[47] Botao Peng, Panagiota Fatourou, and Themis Palpanas. 2020. MESSI: In-Memory Data Series Indexing. In ICDE .\n337â€“348.\n[48] Botao Peng, Panagiota Fatourou, and Themis Palpanas. 2021. Fast Data Series Indexing for In-Memory Data. VLDBJ\n(2021).\n[49] Botao Peng, Panagiota Fatourou, and Themis Palpanas. 2021. ParIS+: Data Series Indexing on Multi-Core Architectures.\nTKDE 33, 5 (2021), 2151â€“2164.\n[50] Botao Peng, Panagiota Fatourou, and Themis Palpanas. 2021. SING: Sequence Indexing Using GPUs. In ICDE . 1883â€“1888.\n[51] Rita P. Ribeiro and Nuno Moniz. 2020. Imbalanced regression and extreme value prediction. Machine Learning 109,\n9-10 (2020), 1803â€“1835.\n[52] Herbert Robbins and Sutton Monro. 1951. A stochastic approximation method. The Annals of Mathematical Statistics\n(1951), 400â€“407.\n[53] Shubhra Kanti Karmaker Santu, Md. Mahadi Hassan, Micah J. Smith, Lei Xu, Chengxiang Zhai, and Kalyan Veera-\nmachaneni. 2022. AutoML to Date and Beyond: Challenges and Opportunities. ACM Computing Survey 54, 8 (2022),\n175:1â€“175:36.\n[54] Gaurav Saxena, Mohammad Rahman, Naresh Chainani, Chunbin Lin, George Caragea, Fahim Chowdhury, Ryan\nMarcus, Tim Kraska, Ippokratis Pandis, and Balakrishnan (Murali) Narayanaswamy. 2023. Auto-WLM: Machine\nLearning Enhanced Workload Management in Amazon Redshift. In SIGMOD . 225â€“237.\n[55] Jin Shieh and Eamonn J. Keogh. 2008. iSAX: indexing and mining terabyte sized time series. In KDD . 623â€“631.\n[56] S Soldi, Volker Beckmann, Wayne H Baumgartner, Gabriele Ponti, Chris R Shrader, P LubiÅ„ski, HA Krimm, F Mattana,\nand Jack Tueller. 2014. Long-term variability of agn at hard x-rays. Astronomy and Astrophysics 563 (2014), A57.\n[57] Matthias Steffen. 1990. A simple method for monotonic interpolation in one dimension. Astronomy and Astrophysics\n239 (1990), 443.\n[58] Ji Sun, Guoliang Li, and Nan Tang. 2021. Learned Cardinality Estimation for Similarity Queries. In SIGMOD . 1745â€“1757.\n[59] Chad Trabant, Alexander R Hutko, Manochehr Bahavar, Richard Karstens, Timothy Ahern, and Richard Aster. 2012.\nData products at the IRIS DMC: Stepping stones for research and other applications. Seismological Research Letters 83,\n5 (2012), 846â€“854.\n[60] Gido M. van de Ven, Tinne Tuytelaars, and Andreas S. Tolias. 2022. Three types of incremental learning. Nature\nMachine Intelligence 4, 12 (2022).\n[61] Vladimir Vovk, Alexander Gammerman, and Glenn Shafer. 2005. Algorithmic learning in a random world . Vol. 29.\nSpringer.\n[62] Qitong Wang and Themis Palpanas. 2021. Deep Learning Embeddings for Data Series Similarity Search. In KDD .\n1708â€“1716.\n[63] Qitong Wang, Stephen Whitmarsh, Vincent Navarro, and Themis Palpanas. 2022. iEDeaL: A Deep Learning Framework\nfor Detecting Highly Imbalanced Interictal Epileptiform Discharges. PVLDB 16, 3 (2022), 480â€“490.\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.\n\nLeaFi: Data Series Indexes on Steroids with Learned Filters 51:27\n[64] Shang Wang, Peiming Yang, Yuxuan Zheng, Xin Li, and Gennady Pekhimenko. 2021. Horizontally Fused Training\nArray: An Effective Hardware Utilization Squeezer for Training Novel Deep Learning Models. In MLSys .\n[65] Yang Wang, Peng Wang, Jian Pei, Wei Wang, and Sheng Huang. 2013. A Data-adaptive and Dynamic Segmentation\nIndex for Whole Matching on Time Series. PVLDB 6, 10 (2013), 793â€“804.\n[66] Zeyu Wang, Peng Wang, Themis Palpanas, and Wei Wang. 2023. Graph- and Tree-based Indexes for High-dimensional\nVector Similarity Search: Analyses, Comparisons, and Future Directions. IEEE Data Eng. Bull. 46, 3 (2023), 3â€“21.\n[67] Zeyu Wang, Qitong Wang, Peng Wang, Themis Palpanas, and Wei Wang. 2023. Dumpy: A Compact and Adaptive\nIndex for Large Data Series Collections. PACMMOD 1, 1 (2023), 111:1â€“111:27.\n[68] Zeyu Wang, Qitong Wang, Peng Wang, Themis Palpanas, and Wei Wang. 2024. DumpyOS: A data-adaptive multi-ary\nindex for scalable data series similarity search. VLDBJ 33, 6 (2024), 1887â€“1911.\n[69] Jiuqi Wei, Botao Peng, Xiaodong Lee, and Themis Palpanas. 2024. DET-LSH: A Locality-Sensitive Hashing Scheme\nwith Dynamic Encoding Tree for Approximate Nearest Neighbor Search. PVLDB 17, 9 (2024), 2241â€“2254.\n[70] Ziniu Wu, Parimarjan Negi, Mohammad Alizadeh, Tim Kraska, and Samuel Madden. 2023. FactorJoin: A New\nCardinality Estimation Framework for Join Queries. PACMMOD 1, 1 (2023), 41:1â€“41:27.\n[71] Djamel Edine Yagoubi, Reza Akbarinia, Florent Masseglia, and Themis Palpanas. 2017. DPiSAX: Massively Distributed\nPartitioned iSAX. In ICDM . 1135â€“1140.\n[72] Chengrun Yang, Jicong Fan, Ziyang Wu, and Madeleine Udell. 2020. AutoML Pipeline Selection: Efficiently Navigating\nthe Combinatorial Space. In KDD . 1446â€“1456.\n[73] Yuzhe Yang, Kaiwen Zha, Ying-Cong Chen, Hao Wang, and Dina Katabi. 2021. Delving into Deep Imbalanced Regression.\nInICML , Vol. 139. 11842â€“11851.\n[74] Kostas Zoumpatianos, Stratos Idreos, and Themis Palpanas. 2014. Indexing for interactive exploration of big data\nseries. In SIGMOD . 1555â€“1566.\nReceived July 2024; revised September 2024; accepted November 2024\nProc. ACM Manag. Data, Vol. 3, No. N1 (SIGMOD), Article 51. Publication date: February 2025.",
  "textLength": 90907
}