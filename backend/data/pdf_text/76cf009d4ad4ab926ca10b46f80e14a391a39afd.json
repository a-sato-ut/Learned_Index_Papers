{
  "paperId": "76cf009d4ad4ab926ca10b46f80e14a391a39afd",
  "title": "TALI: An Update-Distribution-Aware Learned Index for Social Media Data",
  "pdfPath": "76cf009d4ad4ab926ca10b46f80e14a391a39afd.pdf",
  "text": "/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046Citation: Guo, N.; Wang, Y.; Jiang, H.;\nXia, X.; Gu, Y. TALI: An\nUpdate-Distribution-Aware Learned\nIndex for Social Media Data.\nMathematics 2022 ,10, 4507. https://\ndoi.org/10.3390/math10234507\nAcademic Editors: Fei Hao,\nDoo-Soon Park, Carson K. Leung and\nWei Song\nReceived: 20 October 2022\nAccepted: 23 November 2022\nPublished: 29 November 2022\nPublisher’s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional afﬁl-\niations.\nCopyright: © 2022 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nmathematics\nArticle\nTALI: An Update-Distribution-Aware Learned Index for Social\nMedia Data\nNa Guo1,2,*,†, Yaqi Wang2,*,†, Haonan Jiang2, Xiufeng Xia2and Yu Gu1\n1School of Computer Science in Addition, Engineering, Northeastern University, Shenyang 110169, China\n2School of Computer Science, Shenyang Aerospace University, Shenyang 110136, China\n*Correspondence: 1710582@stu.neu.edu.cn (N.G.); wangyaqi@stu.sau.edu.cn (Y.W.);\nTel.: +86-1384-020-1913 (N.G.); +86-1384-209-2120 (Y.W.)\n† These authors contributed equally to this work.\nAbstract: In the growing mass of social media data, how to efﬁciently extract the collection of inter-\nested concerns has become a research hotspot. Due to the large size and regularity of social media\ndata, traditional indexing techniques are not applicable. Our “Learned Index”, which is a part of so-\ncial media intelligence solutions, uses mathematical principles to summarize the laws from the data.\nIt predicts the location of the data by learning the mathematical properties of the data distribution\nto build the model. Although existing methods over single dimension and multi-dimension such\nas setting gaps are proposed to further optimize the performance of index, they do not consider\nthe update-distribution of data. In this paper, we propose an update-distribution-aware learned\nindex for social media data (TALI) to support update operations and handle the data sliding. In TALI,\nunderlying data are learned through machine learning models, and a recursive hierarchical model is\nbuilt. It also learns the update-distribution of data to adjust the size of each leaf node. Thus, it can\nmore effectively support all kinds of operations in databases due to the decrease of the leaf nodes’\nsliding. In addition, TALI uses the model-based insertion method for bulkload and query, resulting\nin a small prediction error. Thus, exponential search is used to perform secondary lookup to improve\nquery efﬁciency. Experiments were tested and compared on four realistic and synthetic social media\ndatasets. Through extensive experiments, TALI performed better than the existing state-of-the-art\nlearned index with less space occupancy on four realistic and synthetic social media datasets.\nKeywords: social media data; learned index; update distribution\nMSC: 68P20\n1. Introduction\nSocial Media data come in many forms: Social networking sites, Blogs, Wikis, Reviews,\nSocial bookmarking sites, News portals, and Multimedia sharing websites [ 1] . The Social\nMedia data extraction and analysis are important as it helps with grabbing the ever-\nexpanding user generated content that companies are interested in for product or service\nreviews, feedback, complaints, trend watching, and more. It also includes fetching and\nanalysis of speciﬁc tweets, followings, likes, updates, group discussions, posts, and so on.\nSocial network community discovery and inﬂuence analysis [ 1], maximal cliques detection\nand management [ 2] in social Networks, Knowledge Discovery [ 3] in Social Networks, and\npredictive routing scheme [ 4] for Social Networks are so meaningful that research on social\nnetwork analysis also ﬂourishes precisely. As shown in Figure 1, hundreds of millions\nof users are accessing different social media every moment. In addition, social media data\nare becoming more and more regular due to the lifestyle of people. For example, people\nalways take the same route to work and always log on to entertainment websites after work.\nHow to use the regularity of social media data to achieve efﬁcient indexing has become\na new research problem. Mathematical theories such as linear algebra, probability and\nMathematics 2022 ,10, 4507. https://doi.org/10.3390/math10234507 https://www.mdpi.com/journal/mathematics\n\nMathematics 2022 ,10, 4507 2 of 19\nstatistics, and optimization methods are widely used in the ﬁeld of AI to express the struc-\nture, distribution and update characteristics of data. Therefore, the concept of learned index\nhas been proposed to offer a new direction on indexing with the distribution characteristics\nof the data. Given a key value, determining the location of the key through the ML model\nand secondary search is a query operation. An insert operation is given a key to ﬁnd its\ncorresponding position and insert it into the speciﬁed position. For example, in social media\ndatabases, a relevant index can be built based on the distribution of user IDs. The user’s\nlogin to his account can be regarded as performing a query operation; whenever a new user\nregisters an account, it represents an insert operation to be performed. With the develop-\nment of social media, it is increasingly difﬁcult for traditional indexes to efﬁciently process\nhuge social media data. Many studies address the data updates by avoiding the impact\nof partially contiguous regions (Deﬁnition 1, Section 2). However, these learned indexes\nare limited by the large amount of repeatedly growing data. On the one hand, as a large\namount of data are inserted, the distribution of data is becoming increasingly difﬁcult\nto ﬁt. On the other hand, these learned indexes do not exploit the feature of updating data.\nFor example, users always log in to their accounts after work in the evening.\n 0 5 10 15 20 25 30\nFB Whats Y2b Msgr Vx IG Trill QQ Wbo QZUser Visits per Month (hundred million/month)\nDifferent Social Media Platforms\nFigure 1. Monthly user visits of different social media platforms.\nIn this work, to solve the problem of updating social media data, we propose an Update-\nDistribution-Aware Learned Index for Social Media Data (TALI). To solve the update prob-\nlem, TALI assumes that the mathematical properties of the data—the update distribution—\nis known. TALI can change the capacity of nodes according to the data update rule.\nOther indexes, however, are underutilized the update-distribution to improve performance.\nTALI dynamically allocates space via learning data and update distribution.\nTherefore, it could avoid overheads brought by allocating and removing space.\nThe rest of this paper is organized as follows: Section 2 introduces the background\nfor learned index and related definition. Section 3 expounds the key insight and operations\nof TALI. Section 4 displays the experiment setup, datasets, and experimental results. Section 5\ndiscusses the related work and results. In addition, finally , we conclude the paper in Section 6.\n2. Background and Deﬁnition\nIndex is an indispensable component in the database system. There are rich studies\non the traditional index to address different problems. With the development of the ML, a\nlearned index is applied to handling one-dimensional and multi-dimensional problems.\n\nMathematics 2022 ,10, 4507 3 of 19\n2.1. Traditional Index\nVarious indexes have been proposed over the last several decades. B-Tree [ 5] and\nits variants are fundamental index structures in the modern database system to support\ndatabase operations. The hash [ 6] index has been proposed to effectively support point\nquery with hash function. LSM-tree [ 7] is a hierarchical, ordered, disk-oriented data\nstructure. ART [ 8] is an adaptive radix tree for efﬁcient indexing in main memory with little\nstorage footprint. Speciﬁcally, B+Tree is a dynamic height-balanced tree which is a variant\nof B-Tree. It provides efﬁcient support for all kinds of index operations. However, all these\ntraditional index structures underutilize the distribution of data to improve the performance\nof the index.\n2.2. Static Learned Index\nMany studies advanced new index structures including one-dimensional and multi-\ndimensional based on ML. RMI [ 9] ﬁrst learns the distribution of the data and utilizes\nCDF to build models to predict the position of keys based on the spline index, which\nuses spline interpolation to ﬁt data and employs a radix tree and radix table to index\ndata in RS [ 10]. Pavo [ 11] proposes a new unsupervised learning strategy to construct\nthe hash function. Flood [ 12] ﬁrst proposes a learned multi-dimensional index which\nchooses optimal layouts and learns query workloads distribution to improve performance.\nThere are two index structures in [ 13], which automatically optimize its structure to address\ndata skewed. ZM [ 14] tunes each partitioning technique to accelerate the index. The ML-\nindex [ 15] is a multi-dimensional index which partitions the data and proposes a new offset\nscaling method to transform the point to one-dimensional.\nAlthough these indexes utilize the distribution of data to further improve query\nperformance, all these index structures do not effectively support updatable operations\nwhich are necessary in the database and could seriously inﬂuence the performance of index.\n2.3. Updatable Learned Index\nTo address the problem of update, [ 16] uses GA and PMA [ 17], two layouts to set\ngaps for inserting to accelerate update performance. In [ 18], B+Tree leaf nodes are replaced\nwith a piecewise linear model to compress index size. The work [ 19], which uses a greedy\nstreaming algorithm rather than a greedy algorithm to obtain the optimal piecewise linear\nmodel to index data. To achieve real-time update, extra Overﬂow Array (OFA) is proposed\nin [20]. The research [ 21] utilizes a learned index to improve traditional B+Tree perfor-\nmance. XIndex [ 22] is an index structure which considers the concurrency. Learned index\nin variable-length string key workloads is effectively achieved in [ 23]. The work [ 24] is\na learned index with a previous bloom ﬁlter and a post bloom ﬁlter. There is a method\nto eliminate the drift in [ 25]. LIPP [ 26] is an index which ﬁnishes precise prediction by\nthree item types and the conﬂict algorithm. The research [ 27] uses ML models to generate\nsearchable data layout in disk pages for an arbitrary spatial dataset.\nAlthough these index structures support updatable operations, they all underutilize\nthe update-distribution of data. Therefore, in this paper, a new insight is described: learning\nthe update-distribution to lookup and inserting more effectively.\n2.4. Related Deﬁnition\nDeﬁnition 1. Partially continuous area. A partially continuous area is an array of closely linked\ndata. Inserting a key may shift most or even all of these data to ﬁnish the operation, as shown\nin Figure 2.\n\nMathematics 2022 ,10, 4507 4 of 19\n. . . 1 2 3 4 5 6 . . .Partially continuous area\n. . . 0 1 2 3 4 5 6 . . .new create insert key=0\nall sliding\nFigure 2. Partially continuous area.\n3. The TALI Index\nThe TALI takes advantage of two main insights. Firstly, it proposes an approach\nto accelerate lookup and insert, since inserting a key may cause massive data sliding,\nwhich will lead to the actual position being far away from the predicted position in ALEX.\nThe TALI index is presented to reduce the number of sliding by learning the update-\ndistribution of data. Secondly, three hyper-parameters min_num, max_num, and density\nare deﬁned at each leaf node for better index performance. While maintaining the bound\nand precision, we go for a smaller number of models. To accomplish robust search and\ninsert performance, an adaptive RMI structure is adopted according to different workloads.\nThe overall design structure of TALI can be seen in Figure 3.\nroot model\nmodel 2.1 model 2.2\nmodel 3.1 model 3.2\nmodel 4.1 model 4.2input key\n. . .\n. . .\ndata\ngapposition\nFigure 3. TALI Structure.\n3.1. Overview\nTALI is an in-memory, learning update-distribution, updatable learned index. Com-\npared with a typical B+Tree, TALI stores two or four 8-byte values rather than an array\nof keys and values in each node. Therefore, TALI has a smaller index size and storage\nfootprint. Furthermore, TALI bases on trained models to predict the position of a key rather\nthan a lot of comparisons and branches. The method can improve search performance be-\ncause it can directly locate the leaf node of predicted position. While locating the predicted\nposition, TALI uses an exponential search from a predicted position instead of binary search\nwithin page size such as B+Tree. If a key needs to be inserted, RMI must create a new array\nwhich equals the length of the old array, add one, and shift massive data to create a position.\nAs more keys are inserted, the models will be seriously inaccurate. The cost of insertion\nwill be extremely expensive, and the performance of the insertion will be much lower.\nSecondly, TALI adopts a node per leaf like ALEX instead of a single sorted array in a\nstatic Learned Index. As is described just now, if a key will be inserted, RMI must create\na new array whose length is equal to the old array plus one. Since the array is single\nwithout a gap, it must copy all elements to the new array and shift data to make a position\n(Figure 4a). In the worst case, inserting a key needs to shift all elements. However, TALI\n\nMathematics 2022 ,10, 4507 5 of 19\nadopts a node per leaf with some gaps. Hence, it does not create a new array but only shifts\na little data to insert a key (Figure 4c). Therefore, the approach increases insert performance\nand ﬂexibility as a new element is inserted. In addition, TALI uses model-based insertion\nto dynamically insert elements. This method utilizes models to predict the position at\nwhich the key should be inserted, which improves the insert performance since it decreases\nthe model’s prediction error effectively.\nmodel 1.1\nmodel 2.1 model 2.2\nmodel 3.1 model 3.2 model 3.3\nk1/k2/k/primek3/k2k4/k3k5/k4k/prime\n/k5\nBinary Searchpos\nminerr max err\n(a) Learned Index (b) ALEX (c) LUDBmodel 1.1\nmodel 2.1 model 2.2\nmodel 3.1 model 3.2k/prime\nk2/k3/k/prime/k3pos\nExponential Searchshiftmodel 1.1\nmodel 2.1 model 2.2\nmodel 3.1 model 3.2k/prime\nk2/ /k/primek3/ /k4pos\nExponential Search\nFigure 4. Insert methods’ comparisons.\nCompared with ALEX, TALI reduces the data sliding by learning update-distribution.\nUnlike ALEX, which sets gaps only based on initialized data, the bound is broken frequently\nwith more and more elements being inserted. Then, a lot of split and expansion will be\nimplemented and generally shift elements to make an inserted position if a key is inserted\n(Figure 4b). TALI learns the update-distribution of data to predetermine some gaps for in-\nsert keys while bulk loading. It can enhance insert performance because it reduces the split\nand rewrite time of each node. If a k4will be inserted after insert k0ALEX must expand\nthe node and rewrite keys, TALI can directly insert into its reserved position, as shown\nin Figure 4b,c. If the model is very accurate, it only needs O(1) to insert. Furthermore,\nTALI sets a minimum and maximum value to bind the number of each node. It can lessen\nthe number of model nodes to obtain a smaller index size and storage footprint.\n3.2. Index Structure\nIn this section, the two methods LUD and LUDB are introduced. The section also\ndiscusses their ideas, implementation process, and related query and update operations.\n3.2.1. LUD\nTo achieve update operations and reduce the data sliding to improve the performance\nof search and insert keys, TALI ﬁrst proposes the LUD (Learn Update Distribution) method.\nIt adopts adaptive RMI like ALEX to support insertion effectively, and uses the insight\nof predetermined gaps to decrease partially continuous areas. As is displayed in Figure 4b,\nif a conﬂict occurs on a position which equals 2, ALEX must move nearly all elements\nto make a gap to ﬁnish insertion. This process critically inﬂuences the performance of insert\noperations. Therefore, LUD proposes to reduce the number of nodes splitting, expansion,\nand predetermined gaps for inserting elements via learning the update-distribution of data.\nThen, calculate the sum of initial keys and inserting keys. According to the value of al-\nlocating corresponding space, this strategy amortizes the cost of shifting data for each\ninsertion. If all the nodes are processed, the merge algorithm will be implemented, based\non the merged cost which is less than the cost of nodes and merged in a bottom-up order.\n\nMathematics 2022 ,10, 4507 6 of 19\nHowever, the performance of LUD gradually decreases as the inserted data increases.\nThis is due to the fact that, if a node is inserted with a lot of keys, the capacity of the node is\ntoo large based on the LUD method. While inserting massive keys in this node, there will\nbe a large number of partially continuous areas which decrease the performance of LUD.\nAlthough the performance of LUD gradually decreases, it also achieves slightly higher\nperformance than ALEX as we described in Section 4.\n3.2.2. LUDB\nTo handle the problem of LUD, LUDB (Learn Update Distribution with Bound) is\nproposed. It also adopts a similar algorithm to LUD. However, when LUDB obtains\nthe number of inserting keys via learning the update-distribution of data and calculates\nthe sum of initial and inserting keys, it does not directly allocate corresponding space\naccording to the sum rather than setting a ﬁxed boundary to limit the capacity of the node.\nWhen the sum of initial keys and inserting keys are calculated, LUDB ﬁrst judges whether\nthe value violates the boundary. If it is violated, the value is too large to allocate space\nbased on the sum, and the capacity of the node equals initial keys divided by initial density.\nOtherwise, LUDB allocates space based on the sum as described in Section 3.3.\nIf all the nodes are processed, the merge algorithm will be implemented. This is\nthe second idea of LUDB, which sets the minimum amount of data. To a certain degree,\nthe method can decrease the index size and space occupation. If the count of the node is less\nthan the min_value, the performance of search and insert will not be improved obviously.\nAt the same time, this method can limit the number of models. Therefore, LUDB can spend\nnegligible time cost obtaining a smaller index size. This strategy achieves better index\nperformance to a certain extent.\nAs for a lookup operation, LUDB first locates the corresponding leaf and then predicts its\nposition based on the model. While finding the predicted position, use an exponential search\nto locate the actual position of element. It also implements range scan by two point queries.\nFor insert operation, utilize a point query to find the actual insert position first. Then, it judges\nwhether it violates the max_bound or not, if the insert operation violates the boundary of the\nsegment to which the key belongs, moving some other keys to adjacent segments until all\nsegments are violated if inserting a key , implementing an expansion algorithm.\n3.3. Bulk Load\nTo bulk load and build the index, we learn that the CDF is a part of the dataset and\nbuild a temporary root model, which outputs a CDF in the range [0, 1] by Equations (1)–(3)\nto ﬁrst divide the range of different linear functions based on ﬁxed fanouts. Then, recur-\nsively bulk the load based on fanout:\na=1\nmax_key\u0000min_key(1)\nb=\u00001\nmax_key\u0000min_key\u0002min_key (2)\ny=a\u0002x+b (3)\nwhere max_keyand min_keyrepresent the maximum and minimum value of key array,\nrespectively, xrepresents the input key, and yrepresents the corresponding position, \u0002\nrepresents multiplication, +represents an addition operation, \u0000represents a subtraction\noperation, and aand brepresent sloop and intercept, respectively.\nThen, the parameter of each linear function is computed according\nto Equations (4)–(6), and the number of elements will be inserted:\nˆb1=ån\n1(xi\u00001\nnån\n1xi)(yi\u00001\nnån\n1yi)\nån\n1(xi\u00001\nnån\n1xi)2(4)\n\nMathematics 2022 ,10, 4507 7 of 19\nˆb0=1\nnn\nå\n1yi\u0000ˆb1\u00021\nnn\nå\n1xi (5)\nˆy=ˆb0+ˆb1\u0002x (6)\nwhere xiandyirepresent each key and the position of the key , respectively; nrepresents the num-\nber of keys and ån\n1represents sum operation, \u0002represents multiplication, ˆb1and ˆb0represent\nsloop and intercept, respectively . xrepresents the given key and ˆyrepresents the predicted\nposition. +represents an addition operation, and \u0000represents a subtraction operation.\nAccording to CDF, the best fanout tree is built which stores used nodes.\nMeanwhile, LUDB is based on the cost of each node to decide whether it belongs to a\nmodel node or a data node. If the node is a model node, the above process will be executed\nagain. Otherwise, the number of this node and insert keys are calculated. The above\nprocess is cyclically executed until each leaf node is small enough. The above procedure is\nlisted in Algorithm 1.\nAlgorithm 1: Bulkload (k,n).\nInput : number of collected keys k; keys number num\nOutput : M: the index structure\n1fanout_tree[]; /* tree structure */ it  fanout_tree[0];\n2while it.next() do\n3 ifit == data_node then\n4 ifkeys + insertkeys <min_keys then\n5 capacity = ( keys + insertkeys ) / dmax;\n6 else\n7 capacity = keys / d;\n8 end\n9 else\n10 build_model(); /* run from start */\n11 end\n12 it it.next() ;\n13end\n14link_data_nodes(); /* link all data nodes */\n15return M;\n3.4. Learn Update Distribution\nThe main insight of this paper is learning the update-distribution of data to reserve\ngaps in predicted leaf nodes for inserting keys. In Algorithm 2, the Learn Update Dis-\ntribution algorithm is used as is described to achieve the operation. Firstly, the keys\nwhich will be inserted to sort out are collected. Then, use the model and best fanout\ntree as is described in Section 3.3 to calculate the number of inserting keys in each node.\nThe insert_left_boundary is calculated by Equation (7):\nilb=(\n0, i=0\nlevel[i\u00001].irb,otherwise(7)\nwhere irepresents the position of a node in a level of the fanout tree, ilb,irbrepresent\nthe insert_left_boundary and insert_right_boundary, respectively. level[i\u00001]represents\nthe previous node in this level.\nIn addition, calculate the insert_right_boundary by Equation (8), and the number\nof inserting keys equals insert_right_boundary minus insert_left_boundary:\nirb=(\n((i+1)\u0000b)/a\u0000k, i6=f anout\u00001\n((i+1)\u0000b)/a\u0000k\u00001,i=f anout\u00001(8)\n\nMathematics 2022 ,10, 4507 8 of 19\nwhere f anout represents the number of fanout in this level. aand brepresent slope and\nintercept, respectively, krepresents the ﬁrst key in the insert array, /represents a division\noperation, +represents an addition operation, and \u0000represents a subtraction operation.\nAlgorithm 2: TALI (k,n).\nInput : number of collected insert keys k; number of keys num\n1i = 0;\n2insert_key k;\n3insert_key.sort();\n4build_model(); /* train linear models */\n5it fanout_tree;\n6while i<it.fanout do\n7 /* learn update distribution */;\n8 ilb(); /* calculate insert_left_boundary */\n9 irb(); /* calculate insert_right_boundary */\n10 error(); /* Account for off-by-one errors */\n11 insert_num_keys = irb - ilb;\n12 build_model();\n13 update(); /* update stats */\n14 i++;\n15end\nWhile the current node is the ﬁrst node in this level, the insert_left_boundary equals 0;\notherwise, it equals the insert_right_boundary of the previous node. In addition, if the node\nis the last node in the fanout tree level, the insert_right_boundary equals min between\ninserting number and calculating the value based on Equation (8). Otherwise, it equals\nthe ﬁrst value, which is more than the ﬁrst key of the next node. Note that there may\nbe errors caused by ﬂoating-point precision issues, Therefore, LUDB has an extra step\nto correct the error.\nIf all data nodes are calculated, then LUDB builds models according to Equations (4)–(6)\nand allocates space size according to the number of the data node keys and inserting keys\nas is described in Section 3.3. When the above process is ﬁnished, it updates stats at last.\nIt is important that, if the inserting keys are massive, the overhead that calculates all\nthe elements belonging to each node is expensive. In addition, the entire number of keys\nand inserting keys in the node are possibly more than the predetermined threshold. To\naddress the problem, LUDB samples a part of the data to estimate the number and set\na suitable capacity if there are too many inserting keys. The approach not only decreases\nthe bulk load time but also achieves better index performance.\n3.5. Query Operation\nTo look up a given key, LUDB starts from the root model of the index structure, and\nthe model is used to compute the leaf node to which the query key belongs. The position\nof the target key is predicted based on the leaf model. If the given key is located, return its\npayload; otherwise, return nullptr.\nAccording to the root model the leaf node can be located; then, judge whether the node\nincludes the given key. If the maximum key is less than the given key, the next node of cur-\nrent node will be judged until the given key is found in the range of a node. Otherwise,\nif the minimum key is also more than the given key, the previous node of the current node\nwill be judged until the correct leaf node is located. Then, predict the position of the given\nkey based on the model of leaf node. If the predicted position is more than the data capacity\nor less than 0, this represents that the given key is not found. Otherwise, an exponential search\nwill be executed from the predicted position until a key not less than or more than the given\nkey is found. Next, a binary search to locate the first position greater than the key between\nthe position of a given key and the key searched for by exponential search.\n\nMathematics 2022 ,10, 4507 9 of 19\nFinally, LUDB judges whether the position returned by binary search is the position\nof the given key. If the key equals the given key, this represents that the given key is found;\nthen, ﬁnd the corresponding payload of the key and return it. The above procedure is listed\nin Algorithm 3.\nAlgorithm 3: Point_Query (k,n).\nInput : number of lookup keys k; keys number num\nOutput : payload : payload value corresponding to input key\n1i = 0;\n2lookup_keys get_search_keys();\n3while i<ndo\n4 key = lookup_keys [i];\n5 leaf get_leaf(key);\n6 pos ﬁnd_key(key);\n7 actual_pos exponential_search(pos,key);\n8 target_pos binary_search(l,r,key);\n9 ifﬁnd target key then\n10 payload get_payload(key);\n11 return payload;\n12 else\n13 return NULL;\n14 end\n15 i++;\n16end\n3.6. Insert Operation\nInsert operation is indispensable in database engines to achieve data access dynami-\ncally. Inserting a given key, the leaf node is located ﬁrst according to the root model, and\nﬁnd the target leaf node which includes the given key by comparing the leaf node with its\nnext or previous node. After the target leaf node is found, the position of the given key is\npredicted by the model of the target leaf node. In addition, then use an exponential search\nto narrow the range from the predicted position. In the smaller range, use a binary search\nto locate the precise insert position.\nWhen the precise insert position is located, check whether this insert operation violates\nthe bound of its segment. If this insert does not violate the bound, check whether the\ninserted position is a gap. If the inserted position is a gap, insert the key to the position\ndirectly and update stats. Otherwise, ﬁnd the closest gap and shift some data to keep a\nmonotonic ascending order. Then, the given key can be inserted into the gap which is\ncreated by shifting data.\nOtherwise, if inserting a key in this segment violates the bound, shift the maximum\nkey in the current segment to the next segment until no segments will be violated. Then,\nthe given key can be inserted into the inserted position, and the stats are updated. If\nthe boundary of all the segments are violated, expand the node and then rewrite elements\nand ﬁnish the insert operation.\nThe procedure of inserting the key is described in Algorithm 4. Note that the in-\ndex may also shift a little data because LUDB does not predetermine inserting gaps\nin each node due to the capacity bound of each node. However, compared with ALEX,\nthe amount of shifting data is low since LUDB learns the update distribution of data.\nTherefore, the insert time of LUDB is less than ALEX. Related experimental results will be\nshown in Section 4.\n\nMathematics 2022 ,10, 4507 10 of 19\nAlgorithm 4: Insert_Operation (k,n,p).\nInput : number of collected insert keys k; keys number num ; payload p\nOutput : insert _pos: the position of key\n1i = 0;\n2while i<ndo\n3 key = k [i];\n4 payload = p [i];\n5 /* check and update key domain */;\n6 should_expand();\n7 leaf get_leaf(key);\n8 pos predicted_position (key);\n9 insert_pos exponential_search(pos,key);\n10 /* check if the insert_pos is a gap */;\n11 ifinsert_pos is a gap then\n12 /* insert key and payload to insert_pos */;\n13 insert();\n14 else\n15 /* ﬁnd closest_gap */;\n16 closest_gap closest_gap(insert_pos);\n17 /* shift data to closest_gap and insert */;\n18 shift_data();\n19 insert();\n20 end\n21 return insert_pos;\n22 update(); /* update stats */\n23 i++;\n24end\n3.7. Other Operations\nDelete: Delete operation includes deleting a single key and deleting a range of keys.\nDeleting a given key LUDB ﬁrst needs to locate the position of the key by a point query.\nIf the deleted key is found, delete the value and free up the space. Then, judge whether,\nafter deleting a key, the gaps violate the maximum bound. If it violates the bound, we\ncontract the array and copy the data to a new array; otherwise, delete it directly. In addition,\ndelete a range of keys that needs to execute two point queries like range query. Delete\nfrom the start key until reaching the position of the end key and updating stats.\nRewrite: If updating the corresponding payload of a key, LUDB ﬁrst should locate\nthe position of the key by a point query. Then, ﬁnd the corresponding payload and modify\nit; stats are updated at last.\nSplit: If the key cannot be inserted due to massive costs caused by shifting data, then\nsplit the current node into two nodes and train its model. Finally, link the data nodes and\ninsert again.\nExpand: If the key cannot be inserted due to insertion, a key will violate the maximum\nbound, expand the node, and copy data to a new array. Then, update the slope and intercept\nof a new node according to the expand factor.\nContract: If deleting a key violates the maximum value of gaps, LUDB ﬁrst judges\nwhether a lot of keys will be inserted into the current node. If massive keys are inserted,\nchange the capacity of the node based on the bulk load algorithm described in Algorithm 1.\nOtherwise, contract and update the slope and intercept of the new node according to the\ncontract factor.\n\nMathematics 2022 ,10, 4507 11 of 19\n4. Evaluation\nIn this section, the experiment setup and four datasets used are described. Then,\nwe describe the detailed results such as throughput, index size, average lookup time,\naverage insert time, average sliding per insert, scalability, latency, and lifetime in four\nworkloads. In addition, present the results that compare LUDB with RMI, B+Tree, LIPP ,\nand ALEX in different datasets and workloads. LUDB learns the update distribution\nof the data to decrease the amount of shifting data and present a merge and contract\nalgorithm to reduce the index size. Therefore, LUDB beats other index structures in different\ndatasets and workloads:\n• On read-only workloads, LUDB beats the RMI and LIPP by up to 2.21 ×, 2.35 ×search\nperformance and 600 ×, 30,000 ×smaller index size, respectively; LUDB also beats\nthe B+Tree by up to 4.65 ×search performance and 1200 ×smaller index size; but LUDB\nachieves only comparable performance and index size with ALEX;\n• On read-only workloads, LUDB beats the RMI and LIPP by up to 2.21 ×, 2.35 ×search\nperformance and 600 ×, 30,000 ×smaller index size, respectively; LUDB also beats\nthe B+Tree by up to 4.65 ×search performance and 1200 ×smaller index size; but LUDB\nachieves only comparable performance and index size with ALEX;\n• On write-heavy workloads, LUDB achieves up to 1.42 ×operation performance and\n2.59×smaller index size than the ALEX; and beats the B+Tree by up to 3.58 ×perfor-\nmance and 2100 ×smaller index size. LUDB also achieves 2.45 ×higher performance\nand 72,000× smaller index size than LIPP;\n• On write-only workloads, LUDB beats the B+Tree by up to 3.40 ×operation perfor-\nmance and 1500 ×smaller index size; and beats the ALEX by up to 1.42 ×operation\nperformance and comparable index size. LUDB also achieves 3.84 ×higher perfor-\nmance and 93,000× smaller index size than LIPP .\n4.1. Experiment Setup\nIn this part, the environment, datasets, workloads, and baselines of the experiment are\ndescribed in detail.\n4.1.1. Environment\nLUDB is implemented in C++ and compiled with GCC 9.4.0 in O3 optimization mode.\nAll of the experiments are conducted on an Ubuntu 20.04 Linux machine9 (Canonical,\nLondon, UK) with 2.8 GHz Intel Core i7 (2 cores and 2 threads) and 8 GB memory.\n4.1.2. Datasets\nLUDB uses a key-payload pair to accomplish index operations, where key is an 8-byte\nvalue from the dataset, and payload is a randomly generated ﬁxed-size value. The experi-\nments are run using four popular social media benchmarks (path information and user ID\ninformation) listed in Table 1 to evaluate the method.\n• LTD: The LTD dataset consists of the longitudes of locations around the world\nfrom Open Street Maps [28];\n• LAT: The LAT dataset consists of compound keys which combine the longitudes\nand latitudes from Open Street Maps by applying the transformation to each pair\nof longitudes and latitudes. The distribution of the longlat dataset is highly nonlinear;\n• LNM: The LNM dataset is generated artiﬁcially according to a lognormal distribution;\n• YCSB: The YCSB dataset is also generated artiﬁcially, which represents the user IDs\naccording to the YCSB Benchmark. The dataset follows the uniform distribution and\nuses an 8-byte payload.\nUnless stated, the above datasets do not contain duplicated elements. We simulate\nthe real-world scenarios by randomly shufﬂing these four datasets.\n\nMathematics 2022 ,10, 4507 12 of 19\nTable 1. Datasets.\nParameter LTD LAT LNM YCSB\nNum keys 1B 200 M 190 M 200 M\nKey type double double int64 int64\nPayload size 8 B 8 B 8 B 80 B\nTotal size 16 GB 3.2 GB 3.04 GB 17.6 GB\nbulkload keys 1 × 1071 × 1071 × 1071 × 107\nTotal num 1 × 1081 × 1081 × 1081 × 108\n4.1.3. Workloads\nAverage throughput is the primary metric to evaluate the performance of LUDB\ncompared with other different index structures. To suggest the performance of different\noperations, the throughput, index size, average lookup, and insert time are evaluated\non four different workloads:\n• The read-only workload, which only performs lookup operations on the indexes;\n• The read-heavy workload, which contains 30% writes to insert the element into indexes\nand 70% reads to lookup keys;\n• The read-heavy workload, which contains 50% writes to insert the element into indexes\nand 50% reads to lookup keys;\n• The write-only workload, which only contains write operations to insert keys.\nFor all four of the workloads, read operation represents looking up a single key,\nwhich is selected randomly from the set of existing keys in the index according to a\nZipﬁan or a uniform distribution. Therefore, a lookup operation will always locate the key.\nGiven a dataset, the indexes are ﬁrst built and bulk load is according to Table 1. Then,\nrunning a given workload for 60 s and report the total number of operations completed\nin that time. These operations are either inserts or lookups. Speciﬁcally, for the read-heavy\nworkload, it performs 7 reads, then 3 insertions, then repeats the cycle; for the write-heavy\nworkload, it performs 1 read, then 1 insertion, then repeats the cycle; for the write-only\nworkload, we only perform insert operations on the indexes.\n4.1.4. Baselines\nThe LUDB is compared with four existing index structures:\n• Standard B+Tree: it is implemented as STX B+Tree. The STX B+ Tree is a set of C++\ntemplate classes implementing a B+ tree key/data container in main memory. It can\nachieve all kinds of index operations;\n• RMI: it is a static index structure which uses two levels RMI to lookup;\n• LIPP: it is a precise index structure to ﬁnish lookup and insert, which uses three-item\ntypes to address the problem of “last mile”;\n• ALEX: which is an updatable adaptive learned index in memory. It uses gaps\nto achieve insert operation and a ﬂexible layout to improve performance.\nTo evaluate these index structures’ throughput, index size and average lookup and\ninsert time as main parameters are calculated. To measure throughput for LUDB, ALEX,\nB+Tree, and RMI, all of these indexes ﬁrst calculate the throughput of each batch, then ob-\ntains the overall throughput. To measure index size for B+Tree, one only needs to calculate\nthe sum of all inner node sizes. For RMI, ALEX, and LUDB, they calculate the sum of all\nmodel node sizes, which include pointers and metadata. To measure average lookup and\ninsert time, lookup and insert throughput of each batch are calculated ﬁrst; then, calculate\naverage lookup and insert time of each lookup or insert operation according to throughput.\n4.2. Result Analysis\nIn this section, the experimental results are analyzed in four different datasets. The re-\nsults suggest that the performance of LUDB gradually decreases as the insertion ratio\n\nMathematics 2022 ,10, 4507 13 of 19\nincreases, but performance gradually becomes higher than ALEX, LIPP , and B+Tree. This is\nbecause insert operations are more time-consuming than lookup operations. Furthermore,\nsince LUDB learns the update-distribution of the data as described above, LUDB always has\nhigher performance as the insertion ratio increases. Due to the fact that LUDB uses bounds\nto limit the capacity of nodes, the index size of LUDB is always less than ALEX and B+Tree.\n4.2.1. Read-Only Workloads\nFor read-only workloads, LUDB achieves up to 4.65 ×, 2.35 ×, and 2.21 ×throughput\ncompared to B+Tree, LIPP , and RMI, as shown in Figure 5a. Compared with B+Tree and RMI,\nLUDB adopts a gaps array and flexible node layout like ALEX; it sets a bound to decrease\nthe influence of a partially continuous area. It also utilizes segments to support the index\neffectively . Furthermore, the error between the predicted position and actual position is small\nbecause LUDB uses a based-model method to insert. LUDB uses an exponential search instead\nof a binary search within an error bound. For each lookup, the search method needs to find\nthe actual position according to the predicted position. Because the error is small, exponential\nsearch can be faster for locating the actual position. However, B+Tree and RMI do not use\na based-model method for insertion so the error is bigger than LUDB. In addition, they use\nbinary search in error bound, so the search performance is lower. LIPP is a precise index\nto support query and insert, but as the number of keys increases, it needs massive time and\nspace to maintain the index. We use 107to bulk load and based on the structure to query,\nas shown in Figure 5a. LIPP only has a similar performance to RMI and one that is worse\nthan LUDB. The LAT data distribution is highly nonlinear so it is more difficult to model.\nTherefore, LUDB has lower throughput compared with other datasets.\n 0 4 8 12 16 20\nLTD LAT LNM YCSBThroughput (106 ops/sec)\nDataset(a) Read-onlyB+Tree\n 0 2 4 6 8\nLTD LAT LNM YCSBThroughput (106 ops/sec)\nDataset(b) Read-heavyLIPP\n 0 2 4 6\nLTD LAT LNM YCSBThroughput (106 ops/sec)\nDataset(c) Write-heavyALEX\n 0 1 2 3\nLTD LAT LNM YCSBThroughput (106 ops/sec)\nDataset(d) Write-onlyLUDB\n1021041061081010\nLTD LAT LNM YCSBIndex Size (bytes)\nDataset(e) Index Size: Read-onlyRMI\n1021041061081010\nLTD LAT LNM YCSBIndex Size (bytes)\nDataset(f) Index Size: Read-heavy\n1021041061081010\nLTD LAT LNM YCSBIndex Size (bytes)\nDataset(g) Index Size: Write-heavy\n1021041061081010\nLTD LAT LNM YCSBIndex Size (bytes)\nDataset(h) Index Size: Write-only\nFigure 5. Throughput and index size: comparisons with other baselines.\nLUDB also achieves up to ﬁve orders of magnitude, 600 ×, 1200 ×index size smaller\nthan LIPP , RMI, and B+Tree, as shown in Figure 5e. The index size of LUDB depends on how\nwell the index structure models the dataset distribution. For the YCSB dataset, it is highly\nlinear, so LUDB does not need massive models to model the distribution. Then, the index\nsize of the dataset is smaller than other datasets. However, for the LAT dataset, which is\nhighly nonlinear, LUDB requires many models to model its distribution, so it has a larger\nindex size compared with other datasets. This phenomenon suggests that, if LUDB only\nneeds a few models, it will have higher throughput and smaller index size. Furthermore,\nLUDB also sets a bound of node sizes to achieve faster merge operation and smaller index\nsize. Then, LUDB can reduce bulk load time and obtain a better index performance.\n\nMathematics 2022 ,10, 4507 14 of 19\nHowever, since there is no insert operation, we cannot learn the update-distribution.\nTherefore, LUDB is only the same as ALEX on search performance and index size, as shown\nin Figure 5a,e.\n4.2.2. Read-Write Workloads\nFigures 5b,c and 6 show that LUDB achieves up to 3.58 ×higher performance than\nthe B+Tree and up to 1.42 ×and 2.45 ×higher perfermance than ALEX and LIPP . Since\nthe RMI cannot effectively support update operations, we do not include it in read-write\nand write-only workloads. The results show that the LUDB, which beats other index\nstructures on three datasets, expects to be comparable with ALEX for the YCSB dataset.\nBecause YCSB has uniform distribution, LUDB sets a merge bound to accelerate merge\nand decrease index size. However, YCSB only needs 20 models to model it by ALEX, but\nLUDB needs 30 models to model it according to the merge bound. Obviously, this method\ndecreases the throughput on performance if the dataset has uniform distribution.\n 0 1 2 3 4 5\nLTD LAT LNM YCSBAve Lookup Time (102 ns/lookup)\nDataset(a) Read-heavy: LookupB+Tree\n 0 1 2 3 4 5\nLTD LAT LNM YCSBAve Lookup Time (102 ns/lookup)\nDataset(b) Write-heavy: LookupLIPP\n 0 2 4 6 8\nLTD LAT LNM YCSBAve Insert Time (102 ns/insert)\nDataset(c) Read-heavy: InsertALEX\n 0 3 6 9\nLTD LAT LNM YCSBAve Insert Time (102 ns/insert)\nDataset(d) Write-heavy: InsertLUDB\nFigure 6. Average lookup and insert time: comparisons with other baselines.\nConversely, this method is well used in the other three datasets, as shown in Figure 5b.\nBecause the three datasets are not as easy to model as YCSB, especially the LAT dataset,\nwhich is highly nonlinear, it is not easy to model its distribution so it will lead to massive\nexpansion and split operations. Then, a lot of data sliding will happen and lead to the pre-\ndicted position of a given key being far from its actual position. However, LUDB learns\nthe update-distribution of data, so it can pre-allocate positions for inserting keys. This\nmethod avoids lots of data sliding to improve performance.\nFigures 5f,g and 6a,b suggest that LUDB beats B+Tree, LIPP , and ALEX by up to 2100 ×,\n72,000 ×, and 2.59 ×smaller index size. For B+Tree, since it does not have any obvious tunable\nparameters other than page size, it only changes page size to obtain better performance\nand smaller index size. If looking up or inserting a key, there are massive launches and\ncomparisons to locate the leaf node of the given key. Then, it has a binary search on page size.\nHowever, LUDB only consists of two double-precision ﬂoating point numbers in each\nmodel, which represent the sloop and intercept of a linear regression model. Therefore,\nthe size of a model node in LUDB is less than one of an inner node in B+Tree. For ALEX,\nsimilar to throughput on performance, the index size is based on how well the models\nmodel its distribution. For LIPP , in order to maintain the precise position, it needs extra\nspace to store the item types. With the number of insert keys increasing, the index size\nof LIPP will increase accordingly.\n4.2.3. Write-Only Workloads\nFigure 5d shows that LUDB also achieves better performance than B+Tree, LIPP , and\nALEX, and it achieves up to 3.40 ×higher throughput than the B+Tree, up to 3.84 ×higher\nthroughput than the LIPP , and up to 1.42 ×higher throughput than ALEX. The LUDB still\nbeats ALEX on three datasets and has comparable throughput on YCSB.\nFigure 5h displays the index size on write-only workloads. In general, the index\nsize of LUDB and ALEX will be bigger with the number of insert keys increasing. Since\nthe B+Tree is robust, it may slightly increase with the number increasing. Due to LIPP\n\nMathematics 2022 ,10, 4507 15 of 19\nneeding space to store the item types, as the number of insert keys increases, the index size\nof it also will be higher.\n4.3. Detailed Performance Study\nIn this section, the scalability, data sliding, and latency of LUDB, ALEX, LIPP , and\nB+Tree on four different datasets and four different workloads are discussed.\n4.3.1. Scalability\nTo explore the scalability of the LUDB, the LTD dataset is run on read-heavy and write-\nheavy workloads as shown in Figure 7. The total number of keys equals 108and batch size\nequals 106. Then, change the number of initialization keys instead of a fixed number and\nrecord its corresponding throughput. As the number of initialization keys increases, LIPP\ncannot support index operation, as shown in Figure 7. This is because the index size and\ndata size are too big to support index operations as discussed before. Figure 7 demonstrates\nthat, although the overall performance decreases as the number of initialization keys increase,\nLUDB still maintains a better performance than ALEX and B+Tree on read-heavy and write-\nheavy workloads. Furthermore, due to the fact that LUDB maintains a fixed bound and\ndensity for keys and learns the update-distribution of data, the rate of throughput decreases\nslowly . In addition, it has gaps for keys, so for inserting a key , the time does not increase a lot.\nTherefore, LUDB performance can scale well to larger datasets.\n 0 2 4 6\n1 5 10 30 50 70Throughput (106 ops/sec)\nNum Initialization keys (106)(a) Read-heavy\nB+Tree LIPP ALEX LUDB\n 0 2 4 6\n1 5 10 30 50 70Throughput (106 ops/sec)\nNum Initialization keys (106)(b) Write-heavy\nB+Tree LIPP ALEX LUDB\nFigure 7. Scalability.\n4.3.2. Latency\nTo further display the inner performance of LUDB compared with other index struc-\ntures, this paper compares LUDB with B+Tree, LIPP , and ALEX on write-only workloads\nand uses 1000 keys to calculate the latency of insert. Figure 8 demonstrates the 99th per-\ncentile latency while implementing insert keys until reaching 1000. Each batch size is 100.\nThe 99th percentile latency of LUDB on LTD and LAT datasets beats ALEX, LIPP , and\nB+Tree by up to 1.33 ×, 1.47 ×, and 1.36 ×lower time. In particular, LUDB has a smaller 99th\npercentile latency on the LNM dataset, but ALEX has a larger 99th percentile latency. This\nis because the distribution of the ﬁrst one thousand keys in the LNM dataset is not uniform,\nand ALEX needs a large number of shift operations to insert a key, which causes higher\nlatency. However, due to the fact that LUDB learns the update-distribution of inserting\ndata, it can address the problem of massive sliding and has smaller insert latency. However,\non the YCSB dataset, LUDB has a higher 99th percentile latency than ALEX and B+Tree.\nSince B+Tree can deal with datasets which have different distributions, the performance\nof B+Tree is therefore neither good nor bad; however, the distribution of the dataset is\nuniform or highly nonlinear. In addition, due to the fact that the distribution of YCSB\nis uniform, ALEX can model it by only a few models. Then, it has a better performance\nand a smaller 99th percentile latency. Although LUDB learns the distribution of data,\nit also sets a merge bound and a density bound, which causes more models to model\nits distribution. Therefore, it has poor performance and a higher 99th percentile latency.\nHowever, as Figures 5 and 6 displayed, the performance of LUDB is better as the insert\n\nMathematics 2022 ,10, 4507 16 of 19\nnumber is increasing. In addition, in the real world, the dataset is enormous, so it will have\ncomparable performance with ALEX on LAT.\n 0 4 8 12 16 20\nLTD LAT LNM YCSB99% Latency (104ns)\nDatasetB+Tree\nLIPP\nALEX\nLUDB\nFigure 8. Latency.\n4.3.3. Data Sliding\nAs shown in Figure 9, LUDB beats ALEX by up to 3.8 ×lower data sliding on all\ndatasets. Speciﬁcally, on the LAT dataset, whose distribution is highly nonlinear, LUDB\nalso achieves 3.1 ×lower average sliding per insert than ALEX. This is why LUDB can accom-\nplish better performance compared with ALEX on this dataset. Furthermore, the number\nof average data sliding per insert decreases as the insert fraction increases.\n 0 3 6 9 12 15\nLTD LAT LNM YCSBAve Sliding per Insert\nDataset(a) Read-heavy\nALEX\nLUDB\n 0 2 4 6 8\nLTD LAT LNM YCSBAve Sliding per Insert\nDataset(b) Write-heavy\nALEX\nLUDB\n 0 1 2 3 4\nLTD LAT LNM YCSBAve Sliding per Insert\nDataset(c) Write-only\nALEX\nLUDB\nFigure 9. Average sliding per Insert.\nBecause LUDB and ALEX both set a maximum segment bound and node density,\ninserting massive keys will violate the bound of the node. Then, it will expand or split\nthe node and reallocate the keys based on a ﬁxed gap. After reallocating the predicted\nposition of an insert key to be very close to its actual position, the average sliding per insert\ndecreases correspondingly.\nFigure 9 also shows that LUDB is only slightly decreased compared with ALEX on the\nYCSB dataset. As described in the above sections, the merge bound method increases\nthe number of models to model its distribution due to the fact that the YCSB has uni-\nform distribution. Therefore, it may lead to slightly lower performance than ALEX, but\nas the number of models increases, each model has a smaller length than less models, which\ncauses lower average sliding. This is why LUDB has lower performance than ALEX but\nhas lower average sliding per insert.\n4.3.4. Lifetime Study\nLUDB has a better lifetime than ALEX, LIPP , and B+Tree. Figure 10 displays average\nlookup time and average insert time on LTD and LAT datasets. The total number of keys\nequals 108, the number of initial data equals 106, and each batch size equals 106. Then,\nchange the insert proportion and calculate different index structures, which correspond\nwith the average lookup time and average insert time.\n\nMathematics 2022 ,10, 4507 17 of 19\n 0 2 4 6\n0.1 0.2 0.3 0.4 0.5 0.6 0.7Ave Lookup Time (101 ns/lookup)\nInsert Fraction(a) LTD: Lookup TimeB+Tree\n 2 4 6 8 10\n0.1 0.2 0.3 0.4 0.5 0.6 0.7Ave Insert Time (102 ns/lookup)\nInsert Fraction(b) LTD: Insert TimeLIPP\n 0 2 4 6\n0.1 0.2 0.3 0.4 0.5 0.6 0.7Ave Lookup Time (102 ns/lookup)\nInsert Fraction(c) LAT: Lookup TimeALEX\n 2 4 6 8 10\n0.1 0.2 0.3 0.4 0.5 0.6 0.7Ave Insert Time (102 ns/lookup)\nInsert Fraction(d) LAT: Insert TimeLUDB\nFigure 10. Lifetime studies.\nFigure 10 suggests that, even with increasing the number of insert keys, LUDB still\nhas lower average lookup and insert time. Figure 10a indicates that, on the LTD dataset,\nLUDB has an average lookup time similar to ALEX, but achieves up to 5.31 ×, 3.10 ×shorter\nthan B+Tree and LIPP because ALEX also uses a model-based method to insert and LTD is\nnot highly nonlinear. ALEX and LUDB both use adaptive RMI; it does not grow over time\nand gaps are maintained according to the density. However, B+Tree and LIPP must have\na series of split and re-balance operations while inserting a large number of keys. Therefore,\nB+Tree and LIPP grow deeper over time, which makes lookup costs expensive. For inserts,\nLUDB has 1.32 ×lower average insert time than ALEX, 2.07 ×lower than B+Tree, and 1.93 ×\nlower average insert time than LIPP , as shown in Figure 10b. Because ALEX does not learn\nupdate-distribution for inserting keys, its array still contains partially continuous areas\nwhich will reduce the performance of ALEX.\nFigure 10c,d shows that, even on the LAT dataset, which is highly nonlinear, LUDB\nalso beats ALEX by having a slightly lower average lookup time and achieves a much\nlower average insert time than ALEX, LIPP , and B+Tree. Although LUDB learns the update-\ndistribution of data, the LAT dataset is highly nonlinear, so it does not model it perfectly\neither. Therefore, the performance of LUDB on the LAT dataset is degraded compared\nto other datasets. All these phenomena suggest that LUDB has a long lifetime and better\nperformance than the other three indexes.\n5. Discussion\nIn this section, relevant experiments and results are discussed.\nB+Tree: B+Tree uses split and merge operations to ﬁnish the update operations. By\npacking multiple value pairs into each node of the tree, the B+tree reduces heap fragmenta-\ntion and utilizes cache-line effects better than the standard red-black binary tree.\nRMI: RMI uses the Cumulative Distribution Function (CDF) of the dataset to train\nmodels and build the Recursive Model Index. Then, it learns the distribution of data\nto build models that predict the position of a key in the database. Due to the existing errors\nof the ML models, the position predicted by the model may be not accurate. RMI needs\nto have a binary search between min_error and max_error to locate the accurate position.\nHowever, because RMI stores data in a tight array, it cannot handle data updates efﬁciently.\nALEX: It is a learned index which can effectively handle data updates and use an adap-\ntive RMI structure to handle different data distributions. ALEX utilizes two leaf node\nlayouts gap array (GA), and packed memory array (PMA) to process updates. When\ninserting a key, a point query will be executed to ﬁnd the position of the key. If the current\nposition is the reserved gap, it can be directly inserted; otherwise, the insertion is done\nby moving the data to create a gap. In addition, ALEX uses exponential search instead\nof binary search because ALEX uses model-based insertion to make it easier for the lookup\nto fall near the correct position. However, ALEX has to move a lot of data to process updates\nwhen the data are updated frequently, and this can cause a dramatic drop in performance.\nLIPP: It implements precise queries by building a tree-structured learned index to han-\ndle data conﬂicts. It solves data conﬂicts through three types of items, and uses the FMCD\nalgorithm to calculate the conﬂict degree and then trains the model according to the conﬂict\n\nMathematics 2022 ,10, 4507 18 of 19\ndegree. LIPP also designs a merge strategy to control the height of the tree and reduce\nspace overhead. However, LIPP is still limited by large data volumes because it stores real\ndata at nodes, and performance is affected by tree height.\nTALI: To achieve update operations and reduce the data sliding to improve the perfor-\nmance of search and insert keys, TALI ﬁrst proposes to ﬁrst reduce the number of node\nsplitting, expansion, and predetermined gaps for inserting elements via learning the update-\ndistribution of data. It adopts adaptive RMI like ALEX to support insert effectively, and\nuses the insight of predetermined gaps to decrease partially continuous areas. It also sets\nthe boundary of data capacity to improve performance and the minimum amount of data\nto limit the number of models. Therefore, compared with other index structures, TALI can\nachieve better index performance.\nSince TALI learns to the update distribution of the data, it can better handle the update\ndata sliding situation. At the same time, the impact of partial continuous regions on index\nperformance is reduced, so it can be well scaled to large datasets.\n6. Conclusions\nIn this paper, an index structure TALI is proposed which learns the update-distribution\nof social media data to solve the problem of frequent and regular updates of social media\ndata. TALI efﬁciently solves the indexing problem of frequently updated social media data,\nand improves the performance of querying and inserting social media data by learning\nthe basis of social media data and update distribution law. This approach results in better\noverall performance and improves the performance of query and insertion. Since TALI\nadopts adaptive RMI and gaps like ALEX, it can address datasets with different distribu-\ntions and workloads. Because TALI is less affected by partial continuous regions, it can\nbe well extended to large data sets and has a certain robustness. Experimental results\nsuggest that TALI beats B+Tree, LIPP , and RMI on four datasets and workloads, and beats\nALEX on three of the four datasets. Speciﬁcally, there are no insert operations on read-only\nworkloads, so TALI has a similar performance to ALEX.\nAuthor Contributions: This research was jointly performed by N.G., Y.W., H.J., X.X. and Y.G. Method-\nology, N.G.; Resources, H.J.; Writing—original draft, Y.W.; Supervision, X.X. and Y.G. All authors\nhave read and agreed to the published version of the manuscript.\nFunding: This research was funded by the National Key Research and Development Program\nof China (No. 2021YFB1716100) and the Fundamental Research Funds of the Central Universities\n(no. N2216017).\nData Availability Statement: Publicly available datasets were analyzed in this study. The data\ncan be found here: LTD: https://drive.google.com/ﬁle/d/1zc90sD6Pze8UM_XYDmNjzPLqmKly8\njKl/view?usp=sharing (accessed on 22 July 2022); LAT: https://drive.google.com/ﬁle/d/1mH-y_\nPcLQ6p8kgAz9SB7ME4KeYAfRfmR/view?usp=sharing (accessed on 22 July 2022); LNM: https:\n//drive.google.com/ﬁle/d/1y-UBf8CuuFgAZkUg_2b_G8zh4iF_N-mq/view?usp=sharing (accessed\non 22 July 2022); YCSB : https://drive.google.com/ﬁle/d/1Q89-v4FJLEwIKL3YY3oCeOEs0VUuv5\nbD/view?usp=sharing (accessed on 22 July 2022).\nConﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n1. Hao, F.; Min, G.; Pei, Z.; Park, D.-S.; Yang, L.T. k-clique Community Detection in Social Networks based on Formal Concept\nAnalysis. IEEE Syst. J. 2017 ,11, 250–259. [CrossRef]\n2. Yang, Y.; Hao, F.; Pang, B.; Min, G.; Wu, Y. Dynamic Maximal Cliques Detection and Evolution Management in Social Internet\nof Things: A Formal Concept Analysis Approach. IEEE Trans. Netw. Sci. Eng. 2021 ,9, 1020–1032. [CrossRef]\n3. Fei, H.; Yixuan, Y.; Geyong, M.; Vincenzo, L. Incremental Construction of Three-way Concept Lattice for Knowledge Discovery\nin Social Networks. Inf. Sci. 2021 ,578, 257–280.\n4. Zhao, L.; Zheng, T.; Lin, M.; Hawbani, A.; Shang, J.; Fan, C. SPIDER: A Social Computing Inspired Predictive Routing Scheme\nfor Softwarized Vehicular Networks. IEEE Trans. Intell. Transp. Syst. (T-ITS) 2021 ,23, 9466–9477. . [CrossRef]\n5. The Case for b-Tree Index Structures. 2018. Available online: http://databasearchitects.blogspot.com/2017/12/the-case-for-b-\ntree-index-structures.html (accessed on 22 July 2022).\n\nMathematics 2022 ,10, 4507 19 of 19\n6. Stanford DAWN Cuckoo Hashing. Available online: https://github.com/stanford-futuredata/index-baselines (accessed on 22\nJuly 2022).\n7. O’Neil, P .; Cheng, E.; Gawlick, D.; O’Neil, E. The Log-Structured Merge-Tree (LSM-Tree). Acta Inform. 1996 ,33, 351–385. [CrossRef]\n8. VLeis, V .; Kemper, A.; Neumann, T. The adaptive radix tree: ARTful indexing for main-memory databases. In Proceedings of the\n2013 IEEE 29th International Conference on Data Engineering, Brisbane, Australia, 8–11 April 2013; pp. 38–49.\n9. Kraska, T.; Beutel, A.; Chi, E.H.; Dean, J.; Polyzotis, N. The Case for Learned Index Structures. In Proceedings of the 2018\nInternational Conference on Management of Data, Houston, TX, USA, 10–15 June 2018; pp. 489–504.\n10. Kipf, A.; Marcus, R.; van Renen, A.; Stoian, M.; Kemper, A.; Kraska, T.; Neumann, T. RadixSpline: A single-pass learned index. In\nProceedings of the Third International Workshop on Exploiting Artiﬁcial Intelligence Techniques for Data Management, Portland,\nOG, USA, 14–20 June 2020; pp. 1–5.\n11. Xiang, W.; Zhang, H.; Cui, R.; Chu, X.; Li, K.; Zhou, W. 2018.Pavo: A RNN-Based Learned Inverted Index, Supervised\nor Unsupervised? IEEE Access 2018 ,7, 293–303. [CrossRef]\n12. Nathan, V .; Ding, J.; Alizadeh, M.; Kraska, T. Learning Multi-dimensional Indexes. In Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data, Portland, OR, USA, 14–19 June 2020; pp. 985–1000.\n13. Ding, J.; Nathan, V .; Alizadeh, M.; Kraska, T. Tsunami: A Learned Multi-dimensional Index for Correlated Data and Skewed\nWorkloads. arXiv 2020 , arXiv:2006.13282.\n14. Pandey, V .; van Renen, A.; Kipf, A.; Sabek, I.; Ding, J.; Kemper, A. The Case for Learned Spatial Indexes. arXiv 2020 ,\narXiv:2008.10349.\n15. Davitkova, A.; Milchevski, E.; Michel, S. The ML-Index: A multidimensional, learned index for point, range, and nearest-neighbor\nqueries. EDBT 2020 , 407–410. [CrossRef]\n16. Ding, J.; Minhas, U.F.; Yu, J.; Wang, C.; Do, J.; Li, Y.; Zhang, H.; Chandramouli, B.; Gehrke, J.; Kossmann, D.; et al. ALEX: An\nupdatable adaptive learned index. In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data,\nPortland, OR, USA, 14–19 June 2020; pp. 969–984.\n17. Bender, M.A.; Hu, H. An adaptive packed-memory array . ACM T rans. Database Syst. (TODS) 2007 ,32, 26. [CrossRef]\n18. Galakatos, A.; Markovitch, M.; Binnig, C.; Fonseca, R.; Kraska, T. FITing-Tree: A data-aware index structure. In Proceedings of\nthe 2019 International Conference on Management of Data, Amsterdam, The Netherlands, 30 June–5 July 2019; pp. 1189–1206.\n19. Ferragina, P .; Vinciguerra, G. The PGM-index: A fully-dynamic compressed learned index with provable worst-case bounds.\nPVLDB 2020 ,13, 1162–1175. [CrossRef]\n20. Mishra, M.; Singhal, R. RUSLI: Real-time updatable spline learned index. In Proceedings of the Fourth Workshop in Exploiting\nAI Techniques for Data Management, Virtual, 20–25 June 2021.\n21. Hadian, A.; Heinis, T. Interpolation-friendly B-trees: Bridging the gap between algorithmic and learned indexes. In Proceedings\nof the 22nd International Conference on Extending Database Technology (EDBT 2019), Lisbon, Portugal, 26–29 March 2019.\n[CrossRef]\n22. Tang, C.; Wang, Y.; Dong, Z.; Hu, G.; Wang, Z.; Wang, M.; Chen, H. XIndex: A scalable learned index for multicore data storage.\nIn Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, New, York, NY, USA,\n26–31 March 2020; pp. 308–320.\n23. Wang, Y.; Tang, C.; Wang, Z.; Chen, H. SIndex: A scalable learned index for string keys. In Proceedings of the 11th ACM\nSIGOPSAsia-Paciﬁc Workshop on Systems, Tsukuba, Japan, 24–25 August 2020; pp. 17–24.\n24. Mitzenmacher, M. A model for learned bloom ﬁlters and optimizing by sandwiching. Adv. Neural Inf. Process. Syst. 2018 ,31,\n464–473.\n25. Hadian, A.; Heinis, T. Considerations for handling updates in learned index structures. In Proceedings of the Second International\nWorkshop on Exploiting Artiﬁcial Intelligence Techniques for Data Management, Amsterdam, The Netherlands, 5 July 2019.\n26. Wu, J.; Zhang, Y.; Chen, S.; Wang, J.; Chen, Y.; Xing, C. Updatable learned index with precise positions. Proc. VLDB Endow. 2021 ,\n14, 1276–1288. [CrossRef]\n27. Li, P .; Lu, H.; Zheng, Q.; Yang, L.; Pan, G. LISA: A learned index structure for spatial data. In Proceedings of the 2020 ACM\nSIGMOD International Conference on Management of Data, Portland, OR, USA, 14–19 June 2020.\n28. Openstreetmap on Aws. 2018. Available online: https://registry.opendata.aws/osm/ (accessed on 2 December 2021).",
  "textLength": 63814
}