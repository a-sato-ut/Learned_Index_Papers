{
  "paperId": "2522c23c32aa60d6a7bdb642973218860d9c2ed5",
  "title": "SOSD: A Benchmark for Learned Indexes",
  "pdfPath": "2522c23c32aa60d6a7bdb642973218860d9c2ed5.pdf",
  "text": "SOSD: A Benchmark for Learned Indexes\nAndreas Kipf\u0003\nTUM\nkipf@in.tum.deRyan Marcus\u0003\nMIT CSAIL\nryanmarcus@mit.eduAlexander van Renen\u0003\nTUM\nrenen@in.tum.deMihail Stoian\nTUM\nstoian@in.tum.de\nAlfons Kemper\nTUM\nkemper@in.tum.deTim Kraska\nMIT CSAIL\nkraska@mit.eduThomas Neumann\nTUM\nneumann@in.tum.de\nAbstract\nA groundswell of recent work has focused on improving data management systems\nwith learned components. Speciﬁcally, work on learned index structures has\nproposed replacing traditional index structures, such as B-trees, with learned\nmodels. Given the decades of research committed to improving index structures,\nthere is signiﬁcant skepticism about whether learned indexes actually outperform\nstate-of-the-art implementations of traditional structures on real-world data.\nTo answer this question, we propose a new benchmarking framework that comes\nwith a variety of real-world datasets and baseline implementations to compare\nagainst. We also show preliminary results for selected index structures, and ﬁnd\nthat learned models indeed often outperform state-of-the-art implementations, and\nare therefore a promising direction for future research.\n1 Introduction\nThere has been a recent surge in proposals to replace traditional database system components, such as\nquery optimizers and index structures, with learned counterparts [12,13,16,17]. In particular, learned\nindexes [14] raised a lot of attention in the database community. Learned indexes replace structures\nsuch as B-trees with learned models that can accelerate lookups by predicting the position of a sought\nkey in a sorted array (i.e., approximating the underlying cumulative distribution function, or CDF).\nHowever, [14] lacked an open-source implementation and thus left many in the community skeptical\nthat learned models could outperform optimized in-memory data structures [11, 15]. Thus, we\nintroduce the Search OnSorted Data Benchmark (SOSD), a framework that allows researchers\nto compare their new (learned) index structures on both synthetic and real-world datasets. The\nbenchmark is provided as open-source code [4] and comes with diverse datasets and highly-optimized\nbaseline implementations. To the best of our knowledge, our implementation is the ﬁrst performant\nand publicly available implementation of the Recursive Model Index (RMI) proposed in [14].1\nThis extended abstract additionally presents preliminary results from an experimental study using\nSOSD. We show end-to-end latency measurements and explain the results using performance counters\n(e.g., cache misses, branch mispredictions) for several index structures, including a novel spline-based\napproach which is trained bottom-up (RMIs are trained top-down). We ﬁnd that learned index\nstructures can indeed outperform traditional index structures in many scenarios. Finally, we explore\nthe implications of our preliminary ﬁndings for practitioners.\n\u0003equal contribution\n1Note, this is a novel implementation, not the implementation used in [14].\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.arXiv:1911.13014v1  [cs.DB]  29 Nov 2019\n\n0 10.00.51.0Position\namzn64\n face64\n logn64\n norm64\n osmc64\n uden64\n uspr64\n wiki64\nKeyFigure 1: CDFs of datasets\n2 Techniques\nAt a high level, the techniques studied in this work (cf. Table 1) can be categorized into on-the-ﬂy\nalgorithms, auxiliary indexes, approaches that approximate the cumulative distribution function\n(CDF) of the data (i.e., learned structures), and traditional index structures. In the context of this\nwork, these techniques are used as in-memory secondary indexes that associate each keywith a 64-bit\ntuple identiﬁer (TID). When queried, each index structure must ﬁnd all keys (unsigned integers) that\nqualify under the query predicate, and their associated TIDs.\nTable 1: Categorization of techniques\ncategory technique layout\non-the-ﬂyBinarySearch (BS) array\nInterpolationSearch (IS) array\nTIP array\naux. index RadixBinarySearch (RBS) array\napprox. CDFRadixSpline (RS) array\nRMI array\nindexART custom\nB-tree custom\nFAST customAs representatives of on-the-ﬂy algorithms,\nwe studied binary search (BS), interpola-\ntion search (IS), and the recently proposed\nthree point interpolation search (TIP) [20].\nThese algorithms operate directly on a\nsorted array, do not build an index, and\ndo not need to examine the data ahead of\nquery time. Binary search takes O(logn)\nsteps to ﬁnd the sought key, and can cause\nas many cache misses. In contrast, inter-\npolation search “guesses” the position of\nthe key by interpolating between the cur-\nrent min and max keys. For dense integer\ndata such as sequential primary keys, this\nstrategy works extremely well and might,\nin the best case, only incur a single cache\nmiss [10]. For highly skewed data, on the other hand, it can degrade to a linear scan. TIP, an improved\ninterpolation search algorithm, addresses this problem by using linear fractions for interpolation [20].\nSimilar to on-the-ﬂy algorithms, auxiliary indexes operate on the sorted array, but they additionally\nbuild small and thus cache-efﬁcient auxiliary structures. RadixBinarySearch (RBS) pre-scans the data\nto populate a ﬂat radix structure : an array mapping ﬁxed-length key preﬁxes to the ﬁrst occurrence of\nthat preﬁx in the sorted array. To process a lookup, RBS determines bounds on the key’s position\nusing the radix structure. RBS then preforms a binary search in this much smaller range.\nCDF approximation algorithms directly estimate a lookup key’s position using pre-trained / ﬁtted\nmodels, and can thus be considered learned index structures. The RMI builds (a typically 2-level) tree\nof models (e.g., linear, linear spline, log linear) to approximate the CDF, and is constructed top-down\nas described in [14]. In contrast, and similar to [9], RadixSpline (RS) is built bottom-up, by ﬁtting\na linear spline to the CDF [18], and indexes the resulting spline segments in a radix structure. At\nlookup time, RS locates the corresponding spline segment using the radix structure and performs a\nlinear interpolation between the two spline points.\nWe also include traditional index structures as baselines: ART [15] represents radix trees, B-tree is\na popular B+-tree implementation [5] (STX, v0.9), and FAST [11] is a cache-optimized binary search\ntree. Notably, all of these structures reorganize the data into a specialized structure.\n3 Search on Sorted Data Benchmark\nSOSD is a new benchmarking framework that allows researchers to compare in-memory search\nalgorithms on sorted data. It is provided as C++ open source code [4] that incurs little overhead (8\ninstructions and 1 cache miss per lookup), comes with diverse synthetic and real-world datasets, and\nprovides efﬁcient baseline implementations.\n2\n\nTable 2: Lookup latencies in nanoseconds per lookup. Top approach in each row is green. Yellow\nindicates 2-3x degraded performance. Red indicates > 3x degraded performance.\nART B-tree BS FAST IS RBS RMI RS TIP\namzn32 n/a 529 773 244 4604 325 264 275 731\nface32 187 524 771 229 1285 312 274 386 964\nlogn32 n/a 522 765 294 n/a 471 97.0 105 744\nnorm32 191 522 771 229 10257 355 71.7 70.9 884\nuden32 102 521 771 228 39.8 333 54.2 64.2 176\nuspr32 n/a 524 771 230 469 301 153 200 400\nsize overhead 47% 16% 0% 123% 0% < 1% 3% < 1% 0%\namzn64 n/a 601 804 n/a 4736 387 266 288 759\nface64 391 592 784 n/a 1893 337 334 461 1232\nlogn64 309 597 784 n/a n/a 753 179 120 454\nnorm64 266 592 785 n/a 10510 405 71.5 70.5 862\nosmc64 n/a 599 785 n/a 95076 492 402 437 7186\nuden64 112 592 784 n/a 43.4 344 54.3 53.9 193\nuspr64 287 591 785 n/a 449 313 169 214 428\nwiki64 n/a 608 802 n/a 7846 364 222 218 1019\nsize overhead 25% 16% 0% n/a 0% < 1% 3% < 1% 0%\nDatasets. SOSD currently includes eight different datasets. Each dataset consists of 200 million 64-\nbit unsigned integers (keys) with very few duplicates (if at all): amzn represents book sale popularity\ndata [1], face is an upsampled version of a Facebook user ID dataset [20], logn andnorm are\nlognormal (0, 2) and normal distributions respectively, osmc is uniformly sampled OpenStreetMap\nlocations [19] represented as Google S2 CellIds [3], uden is dense integers, uspr is uniformly\ndistributed sparse integers, and wiki is Wikipedia article edit timestamps [6]. Figure 1 shows the\nCDFs of these datasets. In addition, there are 32-bit versions of all datasets (except osmc andwiki )\nwith similar CDFs. We use different parameters, (0, 1), for logn in the 32-bit case to reduce the\nnumber of duplicates. When loading the datasets, we generate 64-bit TIDs and store them alongside\nthe keys in row format, although we plan to add support for columnar formats as well.\nQueries. We perform 10 million equality lookups on a given dataset. Lookup keys are uniformly\nchosen from the set of keys. Note that we disallow hashing implementations (e.g., hash tables)\nsince we want to support range-based lookups (e.g., lower bound searches). We ensure that lookup\nkeys have at most 100 matches to limit the impact of result materialization. Lookups are performed\none-at-a-time in a single thread. Our framework veriﬁes each query result for correctness with low\noverhead (two instructions and a cache miss) and allows for out-of-order execution of lookups.\nResults. To encourage reproducibility, we use the AWS machine type c5.4xlarge for benchmarking.\nUsing the Intel Memory Latency Checker [2], we measured a DRAM latency (LLC miss) of 90 ns.\nface32 face64\nDataset0102030Build Time (s)ART\nB-tree\nBS\nFAST\nIS\nRBS\nRMI\nRS\nTIP\nFigure 2: Build timesTable 2 shows the lookup performance (in nanosec-\nonds per lookup) for each technique as well as their\naverage size overheads with respect to the data ar-\nray (the 32-bit array is stored in packed format\ni.e., no padding). ART performs very well for the\n32-bit datasets and even outperforms all others for\nface32 . Note that ART does not support duplicate\nkeys without modiﬁcation. B-tree, BinarySearch,\nand FAST (which only supports 32-bit keys) are\nhardly affected by the data distribution. Interpola-\ntionSearch produces very low numbers for the dense\ndata ( uden32 anduden64 ) but is heavily affected\nby skew. RadixBinarySearch shows consistent improvements over BinarySearch. The CDF approxi-\nmators RMI and RadixSpline both have very low lookup latencies, highlighting the beneﬁt learned\nindex structures receive from ﬁtting a model to the data distribution. TIP improves over the textbook\ninterpolation search in most cases, but is affected by the many steps in osmc64 (cf. Figure 1).\n3\n\n0 5 10\nBranch Mispredictions400600800Search Time (ns)32643264\n32 32\n643264B-tree\nBS\nFAST\nRMI\nRS(a) Branch mispredictions\n200 300 400 500\nInstructions400600800Search Time (ns)32643264\n3232\n643264B-tree\nBS\nFAST\nRMI\nRS (b) Instructions executed\n10 20 30 40\nCache Misses400600800Search Time (ns)32643264\n32\n32643264B-tree\nBS\nFAST\nRMI\nRS (c) LL cache misses\nFigure 3: Performance counter breakdown of amzn32 and amzn64 data\nFigure 2 shows a preliminary analysis of build times. Note that we have not optimized build phases:\nfor example, ART could achieve lower build times with bulk loading, and RMI could be improved by\nbuilding models on samples. BS, IS, and TIP do not spend any time on build, except for copying\nthe data vector due to our framework design (an approximately two second cost, paid once). The\nsame holds for RBS, which only needs to perform a scan over the data to build its auxiliary structure.\nRS experiences the highest build times for ﬁtting a ﬁne-grained linear spline to the CDF of the data.\nHowever, even without optimizations, the build times of the CDF approximators may be acceptable\nfor many applications.\nFigure 3 shows performance counters (per lookup) for selected algorithms on amzn32 andamzn64 ,\ngenerated automatically by SOSD in perf mode. Here, we use an Intel Xeon E5-2680 v4 CPU,\nsince AWS does not expose hardware counters. FAST incurs less than ﬁve cache misses per lookup,\nwhile RMI and RS incur around ten. However, RMI and RS have similar or superior search times,\nindicating that analyzing cache misses alone is not sufﬁcient to understand search time. Similarly,\nneither instructions executed nor branch mispredictions fully explain deviations in search time. SOSD\nautomatically analyzes branch mispredictions and instructions executed as well.\n4 Takeaways\nWe have seen that the CDF approximators (RMI, RS) can outperform our baseline implementations.\nFor the tested datasets, we have shown that simple models are sufﬁcient for efﬁcient learned indexes.\nWe next explore potential decision points for choosing between different index structures.\nFor the trivial case of uniform dense integers, non-surprisingly IS is the clear winner. Otherwise,\nthe optimal search strategy depends on whether a user can afford to manually tune and ﬁt a CDF\nmodel, as both RMI and RS require dataset-speciﬁc tuning. The upside of these models is that they\nconsume very little space compared to our studied index structures. If users can afford this tuning\nstep, we recommend using either RMI or RS.2However, it might be possible to signiﬁcantly improve\nthe training times of RMI/RS and to do it entirely automatically, without user-intervention. Until\nthen, if users cannot afford the training time, we recommend using ART or FAST for 32-bit keys and\nART or RBS for 64-bit keys. Unlike ART, RBS can operator directly on a sorted array (i.e., RBS has\nlow space overhead compared to ART).\nA current drawback of learned indexes is the lack of support for efﬁcient updates, an arguably\nimportant feature for index structures. However, several recent works have shown progress towards\naddressing updates [7, 9, 21]. Moreover, it should be pointed out that many of the benchmarked\nmethods (e.g., RBS and FAST) also do not support efﬁcient updates.\nWe plan to extend SOSD with multi-threaded/vectorized lookups, updates, and integration into real\ndatabase systems to support measuring the impact of these structures on SQL queries. We will\nadditionally compare with recent variants of learned index structures [7,8]. We hope SOSD can serve\nas a platform for testing multi-dimensional index structures, accelerators such as GPUs and FPGAs,\nand just-in-time compiled custom-tailored data structures for speciﬁc queries or datasets.\n2RMI and RS both represent learned models – the primary difference is that RMI is built top-down (starting\nwith the root model), while RS is built bottom-up (starting by ﬁtting linear splines to the data, though other\nmodels could be used as well).\n4\n\nReferences\n[1]Amazon sales rank data for print and kindle books. https://www.kaggle.com/ucffool/\namazon-sales-rank-data-for-print-and-kindle-books .\n[2]Intel Memory Latency Checker. https://software.intel.com/en-us/articles/\nintelr-memory-latency-checker .\n[3] S2 Geometry. https://s2geometry.io/ .\n[4] Search on Sorted Data Benchmark. https://github.com/learnedsystems/SOSD .\n[5] STX B+ Tree. https://panthema.net/2007/stx-btree/ .\n[6] Wikimedia Downloads. http://dumps.wikimedia.org .\n[7]J. Ding, U. F. Minhas, H. Zhang, Y . Li, C. Wang, B. Chandramouli, J. Gehrke, D. Kossmann,\nand D. B. Lomet. ALEX: an updatable adaptive learned index. CoRR , abs/1905.08898, 2019.\n[8]P. Ferragina and G. Vinciguerra. The PGM-index: A multicriteria, compressed and learned\napproach to data indexing. arXiv:1910.06169 [cs] , Oct. 2019.\n[9]A. Galakatos, M. Markovitch, C. Binnig, R. Fonseca, and T. Kraska. FITing-Tree: A Data-aware\nIndex Structure. In Proceedings of the 2019 International Conference on Management of Data ,\nSIGMOD ’19, pages 1189–1206, New York, NY , USA, 2019. ACM.\n[10] G. Graefe. B-tree indexes, interpolation search, and skew. In Workshop on Data Management\non New Hardware, DaMoN 2006, Chicago, Illinois, USA, June 25, 2006 , page 5, 2006.\n[11] C. Kim, J. Chhugani, N. Satish, E. Sedlar, A. D. Nguyen, T. Kaldewey, V . W. Lee, S. A. Brandt,\nand P. Dubey. FAST: fast architecture sensitive tree search on modern cpus and gpus. In\nProceedings of the ACM SIGMOD International Conference on Management of Data, SIGMOD\n2010, Indianapolis, Indiana, USA, June 6-10, 2010 , pages 339–350, 2010.\n[12] A. Kipf, T. Kipf, B. Radke, V . Leis, P. Boncz, and A. Kemper. Learned Cardinalities: Estimating\nCorrelated Joins with Deep Learning. In 9th Biennial Conference on Innovative Data Systems\nResearch , CIDR ’19, 2019.\n[13] T. Kraska, M. Alizadeh, A. Beutel, E. H. Chi, A. Kristo, G. Leclerc, S. Madden, H. Mao, and\nV . Nathan. SageDB: A learned database system. In 9th Biennial Conference on Innovative Data\nSystems Research , CIDR ’19, 2019.\n[14] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The case for learned index structures.\nInProceedings of the 2018 International Conference on Management of Data, SIGMOD\nConference 2018, Houston, TX, USA, June 10-15, 2018 , pages 489–504, 2018.\n[15] V . Leis, A. Kemper, and T. Neumann. The adaptive radix tree: Artful indexing for main-memory\ndatabases. In 29th IEEE International Conference on Data Engineering, ICDE 2013, Brisbane,\nAustralia, April 8-12, 2013 , pages 38–49, 2013.\n[16] R. Marcus, P. Negi, H. Mao, C. Zhang, M. Alizadeh, T. Kraska, O. Papaemmanouil, and\nN. Tatbul. Neo: A Learned Query Optimizer. PVLDB , 12(11):1705–1718, 2019.\n[17] R. Marcus, O. Papaemmanouil, S. Semenova, and S. Garber. NashDB: An Economic Approach\nto Fragmentation, Replication and Provisioning for Elastic Databases. In 37th ACM Special\nInterest Group in Data Management , SIGMOD ’18, Houston, TX, 2018.\n[18] T. Neumann and S. Michel. Smooth interpolating histograms with error guarantees. In Sharing\nData, Information and Knowledge, 25th British National Conference on Databases, BNCOD\n25, Cardiff, UK, July 7-10, 2008. Proceedings , pages 126–138, 2008.\n[19] V . Pandey, A. Kipf, T. Neumann, and A. Kemper. How good are modern spatial analytics\nsystems? PVLDB , 11(11):1661–1673, 2018.\n[20] P. V . Sandt, Y . Chronis, and J. M. Patel. Efﬁciently searching in-memory sorted arrays:\nRevenge of the interpolation search? In Proceedings of the 2019 International Conference on\nManagement of Data, SIGMOD Conference 2019, Amsterdam, The Netherlands, June 30 - July\n5, 2019. , pages 36–53, 2019.\n[21] Y . Wu, J. Yu, Y . Tian, R. Sidle, and R. Barber. Designing succinct secondary indexing\nmechanism by exploiting column correlations. In Proceedings of the 2019 International\nConference on Management of Data, SIGMOD Conference 2019, Amsterdam, The Netherlands,\nJune 30 - July 5, 2019. , pages 1223–1240, 2019.\n5",
  "textLength": 18485
}