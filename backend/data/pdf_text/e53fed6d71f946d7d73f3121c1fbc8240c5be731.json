{
  "paperId": "e53fed6d71f946d7d73f3121c1fbc8240c5be731",
  "title": "An HBase-Based Optimization Model for Distributed Medical Data Storage and Retrieval",
  "pdfPath": "e53fed6d71f946d7d73f3121c1fbc8240c5be731.pdf",
  "text": "Citation: Zhu, C.; Liu, Z.; Zou, B.;\nXiao, Y.; Zeng, M.; Wang, H.; Fan, Z.\nAn HBase-Based Optimization Model\nfor Distributed Medical Data Storage\nand Retrieval. Electronics 2023 ,12,\n987. https://doi.org/10.3390/\nelectronics12040987\nAcademic Editor: Fabio Grandi\nReceived: 9 December 2022\nRevised: 25 January 2023\nAccepted: 12 February 2023\nPublished: 16 February 2023\nCopyright: © 2023 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).\nelectronics\nArticle\nAn HBase-Based Optimization Model for Distributed Medical\nData Storage and Retrieval\nChengzhang Zhu1,2,3,4, Zixi Liu1,3,4\n, Beiji Zou1,3,4, Yalong Xiao1,2,3,4,*, Meng Zeng1,3,4, Han Wang1,3,4\nand Ziang Fan2,3\n1Department of Computer Science, Central South University, Changsha 410083, China\n2Department of Literature and Journalism, Central South University, Changsha 410083, China\n3Mobile Medical Ministry of Education-China Mobile Joint Laboratory, Changsha 410083, China\n4Machine Vision and Smart Medical Engineering Technology Center, Changsha 410083, China\n*Correspondence: ylxiao@csu.edu.cn\nAbstract: In medical services, the amount of data generated by medical devices is increasing ex-\nplosively, and access to medical data is also put forward with higher requirements. Although\nHBase-based medical data storage solutions exist, they cannot meet the needs of fast locating and\ndiversiﬁed access to medical data. In order to improve the retrieval speed, the recognition model\nS-TCR and the dynamic management algorithm SL-TCR, based on the behavior characteristics of\naccess, were proposed to identify the frequently accessed hot data and dynamically manage the\ndata storage medium as to maximize the system access performance. In order to improve the search\nperformance of keys, an optimized secondary index strategy was proposed to reduce I/O overhead\nand optimize the search performance of non-primary key indexes. Comparative experiments were\nconducted on real medical data sets. The experimental results show that the optimized retrieval\nmodel can meet the needs of hot data access and diversiﬁed medical data retrieval.\nKeywords: big medical data; HBase; retrieval optimization; hot data; secondary index\n1. Introduction\nWith the rapid development of medical information technology, medical treatment\nand medical research are stepping into the era of big data [ 1]. According to the National\nHospital Information Construction Standard and Speciﬁcation (Trial) issued by the National\nHealth Commission in 2018, the data storage part of the infrastructure construction of the\ninformation platform should realize the uniﬁed storage, processing, and management of\nthe platform data [ 2]. Massive medical big data contains a great value and can provide\ndata support for remote consultation, medical consultation, medication recommendation,\ndaily health care, and other services. Therefore, it is of great signiﬁcance to construct\nuniﬁed storage and retrieval of medical data. However, big medical data are characterized\nby their large scale, diverse structure, fast growth, and multiple modes, which brings\ngreat challenges to uniﬁed storage, retrieval, and management. The traditional relational\nstorage system can no longer guarantee low-cost, large-capacity storage and fast retrieval\nof massive medical data [ 3–5]. Due to the development of emerging distributed systems,\nHBase [ 6–8], a distributed column database, has become a mainstream medical data storage\nmodel that meets the goal of low-cost and high-capacity storage of massive medical data.\nConsidering the speciﬁcity of the medical service industry, fast response and diversiﬁed\nretrieval have become the necessary design objectives for the medical data storage model\nbecause of the large amount of data required to support clinical decision-making and other\ntasks [ 9,10]. Hence, how to meet the need for the fast and diverse retrieval for HBase-based\nmedical data storage models is an urgent problem.\nIn order to achieve the fast and diverse retrieval of medical data, this paper is opti-\nmized from the following two aspects. First, aiming at meeting the requirements of the\nElectronics 2023 ,12, 987. https://doi.org/10.3390/electronics12040987 https://www.mdpi.com/journal/electronics\n\nElectronics 2023 ,12, 987 2 of 20\nrapid retrieval of data, data that are frequently accessed are called hot data, while data that\nare occasionally accessed or not accessed are called cold data [ 11–14]. Considering that\nmodern computers use a hybrid storage architecture, the closer the storage media is to the\nCPU, the faster the access speed, the smaller the capacity, and the higher the cost, which is\nused to balance the cost and performance of storage media. We designed a data dynamic\nmanagement model to realize hot data identiﬁcation and storage media management. By\nusing this model, the hot data were stored on the high-speed device (i.e., the Hot Area)\nwhile the cold data were stored on the low-speed device (i.e., the Cold Area), thus meeting\nthe performance requirements of the frequent interactions of hot medical data. Second,\na secondary index was constructed to support the retrieval of non-primary keys and to\nmeet the needs of medical data diversity queries. Inverted indexing was used to build a\nsecondary index with the core idea of storing a map from the keys to the corresponding\nprimary key [ 15–18]. This solution was simple and easy to implement, but multiple I/O\noperations may lead to high time overhead and even performance bottlenecks. Therefore,\nin the current study, Bloom Filter (BF) and index position optimization methods were\nadopted to reduce the overhead of I/O and optimize the secondary index.\nIn conclusion, in order to optimize the storage system’s performance, a model for\ndynamically identifying and managing hot and cold data and an optimized secondary\nindex optimization strategy were proposed in this study. The main contributions of this\npaper are as follows:\n(1) A data temperature recognition method S-TCR and a data management algorithm\nSL-TCR were proposed to manage medical data dynamically;\n(2) An optimized secondary indexing strategy was proposed to improve the speed of\nmedical data diversity queries;\n(3) The feasibility and efﬁciency of the proposed model were veriﬁed by experiments on\nreal medical data sets.\nThis paper is organized as follows: (1) the background knowledge was summarized\nin Section 2; (2) the dynamic data management model and the optimization strategy of\nsecondary index retrieval were introduced in Section 3; (3) the experimental setup and\nresults were given in Section 4; and (4) this paper was summarized in Section 5.\n2. Background Knowledge\nIn this section, the HBase database was first briefly introduced. Then, the hot and cold data\nmanagement algorithms were studied. Finally , the idea of a secondary index was introduced.\n2.1. HBase Database\nHBase is a column-oriented database running on a Hadoop cluster. Hadoop is a\ndistributed cluster deployed on multiple machines. A Hadoop cluster connects multiple\nservers through a network to provide external storage services as a whole [ 19,20]. Hadoop\nDistributed File System (HDFS) can store and read massive amounts of data in a distributed\nmanner and provide high-throughput data access. Therefore, Hadoop is well suited for\nbuilding a mass data storage platform [21,22].\nFor application requests that require random data to be read, data can be chosen to\nbe stored in HBase. HBase stores underlying data in the HDFS to ensure data reliability.\nAs shown in Figure 1, the HBase cluster consists of Master, RegionServer, Region, and\nZookeeper components [ 23]. The Master is the primary server of the HBase cluster and\nallocates RegionServers to regions. The RegionServer component is responsible for provid-\ning write, delete, and search services to clients [ 24]. The Region component is a sub-table\ndivided by RowKey. It is the smallest storage and processing unit in HBase. The RowKey\nis the unique identiﬁer for the HBase record [ 25]. The ZooKeeper provides application\ncoordination services for the HBase cluster, detects and clears failed Masters, and elects a\nnew active Master.\n\nElectronics 2023 ,12, 987 3 of 20\nElectronics 2023 , 12, x FOR PEER REVIEW 3 of 20 \n \n providing write, delete, and search services to clients [24]. The Region component is a \nsub-table divided by RowKey. It is the smalle st storage and processing unit in HBase. \nThe RowKey is the unique identifier for the HBase record [25]. The ZooKeeper provides \napplication coordination services for the HBas e cluster, detects and clears failed Masters, \nand elects a new active Master. \n \nFigure 1. The structure of HBase.  \n2.2. Hot and Cold Data Management Algorithms \nIn order to utilize the Hot Area more effe ctively and ensure its hit rate, the Hot Ar-\nea and Cold Area should have efficient management algorithms , which are commonly \nused as follows:  \n2.2.1. LRU \nThe LRU (Least Recently Used) [26] algorithm manages data in the Hot Area ac-\ncording to the access time of historical records. The algorithm is shown in Figure 2, \nwhere the recently accessed data are more likely  to be accessed in the future. It is simple \nand easy to implement, but the hit rate is low for random and periodic accesses, i.e., the \nHot Area is heavily contaminated.  \n \nFigure 2. The idea of the LRU . \n2.2.2. LFU \nThe LFU (Least Frequently Used) algorithm [27] manages the data in the Hot Area \naccording to the access frequency of historical records. The idea of the algorithm is \nshown in Figure 3. It uses a counter to coun t the number of accesses to each object, and \nFigure 1. The structure of HBase.\n2.2. Hot and Cold Data Management Algorithms\nIn order to utilize the Hot Area more effectively and ensure its hit rate, the Hot Area\nand Cold Area should have efﬁcient management algorithms, which are commonly used\nas follows:\n2.2.1. LRU\nThe LRU (Least Recently Used) [ 26] algorithm manages data in the Hot Area according\nto the access time of historical records. The algorithm is shown in Figure 2, where the\nrecently accessed data are more likely to be accessed in the future. It is simple and easy to\nimplement, but the hit rate is low for random and periodic accesses, i.e., the Hot Area is\nheavily contaminated.\nElectronics 2023 , 12, x FOR PEER REVIEW 3 of 20 \n \n providing write, delete, and search services to clients [24]. The Region component is a \nsub-table divided by RowKey. It is the smalle st storage and processing unit in HBase. \nThe RowKey is the unique identifier for the HBase record [25]. The ZooKeeper provides \napplication coordination services for the HBas e cluster, detects and clears failed Masters, \nand elects a new active Master. \n \nFigure 1. The structure of HBase.  \n2.2. Hot and Cold Data Management Algorithms \nIn order to utilize the Hot Area more effe ctively and ensure its hit rate, the Hot Ar-\nea and Cold Area should have efficient management algorithms , which are commonly \nused as follows:  \n2.2.1. LRU \nThe LRU (Least Recently Used) [26] algorithm manages data in the Hot Area ac-\ncording to the access time of historical records. The algorithm is shown in Figure 2, \nwhere the recently accessed data are more likely  to be accessed in the future. It is simple \nand easy to implement, but the hit rate is low for random and periodic accesses, i.e., the \nHot Area is heavily contaminated.  \n \nFigure 2. The idea of the LRU . \n2.2.2. LFU \nThe LFU (Least Frequently Used) algorithm [27] manages the data in the Hot Area \naccording to the access frequency of historical records. The idea of the algorithm is \nshown in Figure 3. It uses a counter to coun t the number of accesses to each object, and \nFigure 2. The idea of the LRU.\n2.2.2. LFU\nThe LFU (Least Frequently Used) algorithm [ 27] manages the data in the Hot Area\naccording to the access frequency of historical records. The idea of the algorithm is shown\nin Figure 3. It uses a counter to count the number of accesses to each object, and when a\nreplacement occurs only the least accessed data needs to be moved out of the Hot Area.\nHowever, it does not consider the object access interval and object size, resulting in dead\nhot data wrote to storage space and the pollution of the Hot Area.\n\nElectronics 2023 ,12, 987 4 of 20\nElectronics 2023 , 12, x FOR PEER REVIEW 4 of 20 \n \n when a replacement occurs only the least ac cessed data needs to be moved out of the \nHot Area. However, it does not consider the object access interval and object size, re-\nsulting in dead hot data wrote to storag e space and the pollution of the Hot Area.  \n \nFigure 3. The idea of the LFU.  \n2.2.3. Size \nThe Size algorithm [28] is a representative  algorithm based on th e size of the data. \nWhen replacement occurs, larger data are del eted preferentially. This algorithm prefer-\nentially deletes large data and has high stor age space utilization. However, it may cause \nhot data to move frequently, which reduces the hit rate and increases the access delay.  \n2.2.4. TCR \nThe TCR (Temperature Calculation Replacem ent) algorithm [29] takes into account \nthe time interval and access frequency of da ta access. The calculat ion formula of the al-\ngorithm is given in Equation (1). T୲౤ indicates the temperature of the data at the time t୬. \nThe cooling coefficient α is the change rate of the data temperature T୦ୣୟ୲, denoting that \nthe temperature has increased since the data were accessed. \nT୲౤ = T ୲౤షభeି஑(୲౤ି୲౤షభ )+T ୦ୣୟ୲ ∗ c,൜ data are visited in t ୬,c = 1\n data are not visited in t ୬,c = 0 (1) \nWhen replacement occurs, the algorithm preferentially deletes low-temperature \ndata. It considers many factors, such as time  interval and access frequency, and performs \nwell. However, it needs to consider the size of the data, resulting in a waste of storage \nspace. In addition, it wastes storage space by not taking into account the size of the data, \nand a lot of time is spent sorting the data.  \n2.3. Secondary Index \nIndex stores values of specific columns in  the table and pointers to the addresses i \nthe row [30–33]. Other fields corresponding to a record are not usually stored in the in-\ndex, so a pointer is needed to find the history. Data structures commonly used to store \nindexes include B-Tree [34], hash index [35], R- Tree [36], bitmap index [37], etc. The time \ncomplexity of the B-tree is low. Its addition, deletion and changes in logarithmic time \nand the stored data are ordered. The hash index is based on a hash table. It only stores \nthe corresponding hash value, and its structur e is very compact. Its search speed is very \nfast. The R-Tree index is the extension of th e B-Tree in the multidimensional index space \nand has high storage efficiency but low retrieval efficiency.  \nHBase uses Log Structure Merge Tree (LSM-Tree) to improve writing speed as an \nindex structure [38–40]. LSM-Tree is a disk-b ased data structure that can significantly \nreduce the cost of disk traversal [41]. It stor es recently used or frequently used data in \nmemory and infrequently used data in hard disks, significantly reducing storage costs. \nAs shown in Figure 4, it uses multiple small trees to store data. Its retrieval process is to build an ordered small tree in memory. As the amount of data grows, the data in \nmemory is flushed to disk. However, it does  not achieve a fast response because its re-\ntrieval result is obtained by traversing all the small trees [42,43].  \nFigure 3. The idea of the LFU.\n2.2.3. Size\nThe Size algorithm [ 28] is a representative algorithm based on the size of the data.\nWhen replacement occurs, larger data are deleted preferentially. This algorithm preferen-\ntially deletes large data and has high storage space utilization. However, it may cause hot\ndata to move frequently, which reduces the hit rate and increases the access delay.\n2.2.4. TCR\nThe TCR (Temperature Calculation Replacement) algorithm [ 29] takes into account the\ntime interval and access frequency of data access. The calculation formula of the algorithm\nis given in Equation (1). Ttnindicates the temperature of the data at the time tn. The cooling\ncoefﬁcient \u000bis the change rate of the data temperature Theat, denoting that the temperature\nhas increased since the data were accessed.\nTtn=Ttn\u00001e\u0000\u000btn\u0000tn\u00001+Theat\u0003c,\u001adata are visited in t n,c=1\ndata are not visited in t n,c=0(1)\nWhen replacement occurs, the algorithm preferentially deletes low-temperature data.\nIt considers many factors, such as time interval and access frequency, and performs well.\nHowever, it needs to consider the size of the data, resulting in a waste of storage space. In\naddition, it wastes storage space by not taking into account the size of the data, and a lot of\ntime is spent sorting the data.\n2.3. Secondary Index\nIndex stores values of speciﬁc columns in the table and pointers to the addresses i the\nrow [ 30–33]. Other ﬁelds corresponding to a record are not usually stored in the index, so\na pointer is needed to ﬁnd the history. Data structures commonly used to store indexes\ninclude B-Tree [ 34], hash index [ 35], R-Tree [ 36], bitmap index [ 37], etc. The time complexity\nof the B-tree is low. Its addition, deletion and changes in logarithmic time and the stored\ndata are ordered. The hash index is based on a hash table. It only stores the corresponding\nhash value, and its structure is very compact. Its search speed is very fast. The R-Tree index\nis the extension of the B-Tree in the multidimensional index space and has high storage\nefﬁciency but low retrieval efﬁciency.\nHBase uses Log Structure Merge Tree (LSM-Tree) to improve writing speed as an index\nstructure [ 38–40]. LSM-Tree is a disk-based data structure that can signiﬁcantly reduce\nthe cost of disk traversal [ 41]. It stores recently used or frequently used data in memory\nand infrequently used data in hard disks, signiﬁcantly reducing storage costs. As shown\nin Figure 4, it uses multiple small trees to store data. Its retrieval process is to build an\nordered small tree in memory. As the amount of data grows, the data in memory is ﬂushed\nto disk. However, it does not achieve a fast response because its retrieval result is obtained\nby traversing all the small trees [42,43].\n\nElectronics 2023 ,12, 987 5 of 20\nElectronics 2023 , 12, x FOR PEER REVIEW 5 of 20 \n \n  \nFigure 4. The structure of LSM-Tree. \nUsing secondary indexes is an effective method to support diversified queries in \nHBase. To date, many researchers have proposed a variety of HBase-based secondary \nindex design methods [44–46], including a linear index, a double-layer index, and an in-\nverted index.  \nLinear indexing achieves multidimensional indexing by mapping K-dimensional \ndata to a one-dimensional space. This method is effective for processing \nhigh-dimensional spatial data but is not ap plicable to indexing other modal data [44]. \nThe double-layer index matches the global in dex with the local index, thus reducing the \nnumber of query nodes and narrowing the quer y range from the high-level index to the \nlow-level index. However, it requires maintaining two indexes and has a high write overhead. In addition, the two indexes require using different data structures and are \nvery complex to implement [45]. The inverted index is the simplest multilevel index so-\nlution. Figure 5 shows the secondary index cr eated based on the inverted index idea in \nHBase. The core idea is to use the index colu mn in the main table as the key of the index \ntable and the key of the main table as the va lue of the index table [46]. However, it can-\nnot avoid querying the index table and the main table, resulting in high I/O overhead.  \n \nFigure 5. The secondary index in HBase. \n2.4. Summary \nAs discussed in this section, the storage architecture of the HBase database was an-\nalyzed. It was found that HBase did not dyna mically manage hot data, and the retrieval \nperformance of non-primary keys was poor. Inspired by hot and cold management al-\ngorithms and secondary indexes, we proposed an HBase-based distributed storage and \nretrieval optimization model to optimize the retrieval scenario of data in the medical \nfield. \n  \nFigure 4. The structure of LSM-Tree.\nUsing secondary indexes is an effective method to support diversified queries in HBase.\nTo date, many researchers have proposed a variety of HBase-based secondary index design\nmethods [44–46], including a linear index, a double-layer index, and an inverted index.\nLinear indexing achieves multidimensional indexing by mapping K-dimensional data\nto a one-dimensional space. This method is effective for processing high-dimensional\nspatial data but is not applicable to indexing other modal data [ 44]. The double-layer index\nmatches the global index with the local index, thus reducing the number of query nodes\nand narrowing the query range from the high-level index to the low-level index. However,\nit requires maintaining two indexes and has a high write overhead. In addition, the two\nindexes require using different data structures and are very complex to implement [ 45].\nThe inverted index is the simplest multilevel index solution. Figure 5 shows the secondary\nindex created based on the inverted index idea in HBase. The core idea is to use the index\ncolumn in the main table as the key of the index table and the key of the main table as the\nvalue of the index table [ 46]. However, it cannot avoid querying the index table and the\nmain table, resulting in high I/O overhead.\nElectronics 2023 , 12, x FOR PEER REVIEW 5 of 20 \n \n  \nFigure 4. The structure of LSM-Tree. \nUsing secondary indexes is an effective method to support diversified queries in \nHBase. To date, many researchers have proposed a variety of HBase-based secondary \nindex design methods [44–46], including a linear index, a double-layer index, and an in-\nverted index.  \nLinear indexing achieves multidimensional indexing by mapping K-dimensional \ndata to a one-dimensional space. This method is effective for processing \nhigh-dimensional spatial data but is not ap plicable to indexing other modal data [44]. \nThe double-layer index matches the global in dex with the local index, thus reducing the \nnumber of query nodes and narrowing the quer y range from the high-level index to the \nlow-level index. However, it requires maintaining two indexes and has a high write overhead. In addition, the two indexes require using different data structures and are \nvery complex to implement [45]. The inverted index is the simplest multilevel index so-\nlution. Figure 5 shows the secondary index cr eated based on the inverted index idea in \nHBase. The core idea is to use the index colu mn in the main table as the key of the index \ntable and the key of the main table as the va lue of the index table [46]. However, it can-\nnot avoid querying the index table and the main table, resulting in high I/O overhead.  \n \nFigure 5. The secondary index in HBase. \n2.4. Summary \nAs discussed in this section, the storage architecture of the HBase database was an-\nalyzed. It was found that HBase did not dyna mically manage hot data, and the retrieval \nperformance of non-primary keys was poor. Inspired by hot and cold management al-\ngorithms and secondary indexes, we proposed an HBase-based distributed storage and \nretrieval optimization model to optimize the retrieval scenario of data in the medical \nfield. \n  \nFigure 5. The secondary index in HBase.\n2.4. Summary\nAs discussed in this section, the storage architecture of the HBase database was an-\nalyzed. It was found that HBase did not dynamically manage hot data, and the retrieval\nperformance of non-primary keys was poor. Inspired by hot and cold management al-\ngorithms and secondary indexes, we proposed an HBase-based distributed storage and\nretrieval optimization model to optimize the retrieval scenario of data in the medical ﬁeld.\n\nElectronics 2023 ,12, 987 6 of 20\n3. Materials and Methods\n3.1. Overview\nHBase was employed to store medical data, where a column cluster stores one form\nof medical data. In order to improve the retrieval performance of the medical storage\nsystem, an HBase-based retrieval optimization model was proposed, and its design frame-\nwork is depicted in Figure 6. The optimization module consists of four parts: the Access\nRequest Management Module, the Temperature Marking Module, the Data Dynamically\nManagement Module, and the Index Management Module. The Access Request Manage-\nment Module manages access requests by analyzing the type of data to be retrieved. The\nTemperature Marking Module identiﬁes the temperature of the data by analyzing data\naccess records. The Data Dynamic Management Module dynamically manages the optimal\nstorage medium for data by designing the algorithm SL-TCR. The Index Management\nModule, based on the improved secondary index strategy, can realize diversiﬁed retrieval\nof medical data.\nElectronics 2023 , 12, x FOR PEER REVIEW 6 of 20 \n \n 3. Materials and Methods \n3.1. Overview \nHBase was employed to store medical data, where a column cluster stores one form \nof medical data. In order to  improve the retrieval perfor mance of the medical storage \nsystem, an HBase-based retrieval optimiza tion model was proposed, and its design \nframework is depicted in Figure 6. The optimization module consists of four parts: the \nAccess Request Management Module, the Te mperature Marking Module, the Data Dy-\nnamically Management Module, and the In dex Management Module. The Access Re-\nquest Management Module manages access requests by analyzing the type of data to be \nretrieved. The Temperature Marking Module identifies the temperature of the data by \nanalyzing data access records. The Data Dynamic Management Module dynamically manages the optimal storage medium for data  by designing the algorithm SL-TCR. The \nIndex Management Module, based on the impr oved secondary index strategy, can real-\nize diversified retrieval of medical data. \n \nFigure 6. Overview of the model designed.  \nAfter introducing dynamic data management and index optimization strategies, the \nsteps to retrieve medical data are as follows. \nStep 1. The client sends a medical data access request to the Access Request Man-\nagement Module. \nStep 2. According to the retrieval keywords, the Access Request Management \nModule estimates whether it is a primary key. The request is passed to the Data Dynam-\nic Management Module if it is. Otherwise, it is given to the Index Management Module \n(the retrieval process for non-primary keys is described in Section 3.4). \nStep 3. The Data Dynamic Management Module determines whether the data to be \nretrieved is hot. If it is, the data in the Hot Ar ea is retrieved, and go to Step 8. Otherwise, \ngo to Step 4. \nFigure 6. Overview of the model designed.\nAfter introducing dynamic data management and index optimization strategies, the\nsteps to retrieve medical data are as follows.\nStep 1. The client sends a medical data access request to the Access Request Manage-\nment Module.\nStep 2. According to the retrieval keywords, the Access Request Management Module\nestimates whether it is a primary key. The request is passed to the Data Dynamic Manage-\nment Module if it is. Otherwise, it is given to the Index Management Module (the retrieval\nprocess for non-primary keys is described in Section 3.4).\nStep 3. The Data Dynamic Management Module determines whether the data to be\nretrieved is hot. If it is, the data in the Hot Area is retrieved, and go to Step 8. Otherwise,\ngo to Step 4.\n\nElectronics 2023 ,12, 987 7 of 20\nStep 4. Interact with the Meta Cache to read information about the RegionServer\nwhere the Meta table is located. If the Meta Cache does not match, connect to Zookeeper to\nobtain information about the RegionServer where the Meta table resides.\nStep 5. Obtain the speciﬁc location of the Meta table, locate the RegionServer where\nthe Meta table is situated, communicate with the node to obtain the Meta table, and write\nthe Meta table metadata information to the Meta Cache.\nStep 6. Interact with the Meta Table to read information about the RegionServer where\nthe data to be retrieved is located, establish a connection with the node, and retrieve data\nin HBase. If no match is performed, go to Step 7. Otherwise, go to Step 8.\nStep 7. An initial temperature is assigned to the retrieved data, and the algorithm\nSL-TCR is invoked to insert it into the Warm Area.\nStep 8. Return the results to the Client.\n3.2. Temperature Marking Module\nBy analyzing data access records in various specific medical scenarios, this paper finds\nthat medical data has a relatively fixed access mode in different business scenarios, especially\nwhen specific data are accessed more frequently [ 47], called hot data. On the contrary, cold\ndata are data that is accessed occasionally or will not be accessed in the future.\nDifferent “measurement criteria” under the cold and hot degree of data will appear in\ndifferent results. [ 48–50] The existing scheme usually uses the following three methods to\nidentify the cold and hot degree of data: one is based on the sequence of data generation\nidentiﬁcation method, i.e., the earlier the data generated, the colder, the later the data\ngenerated, the hotter, usually using FIFO maintenance data insertion sequence; The second\nis the identiﬁcation method based on data access frequency, i.e., the data with higher\nhistorical access frequency is hotter, and the data with lower access frequency is colder.\nUsually, the LFU algorithm can be used to maintain the sequence of data according to the\nhistorical access frequency. The third is the recognition method based on the data access\nsequence. That is, the more recently accessed data are hotter, and the earlier accessed\ndata are colder. LRU algorithm is used to maintain data access to identify the degree of\ncold or hot data. However, these identiﬁcation methods consider a single factor, and the\nidentiﬁcation effect of identifying the cold and hot degree of data simply according to the\naccess time or frequency of data are relatively poor, which cannot truly represent the real\ncold and hot situation of data.\nOn this basis, a method of size–temperature computational recognition (S-TCR) is\nproposed in order to better identify the computational recognition of hot and cold data\nand take various factors into consideration. The method of S-TCR data cooling and heat\nlabeling is to learn from Newton’s cooling law and simulate the process of temperature\nchange through exponential attenuation. As shown in Formula (2), Newton’s cooling law\nproposes that an object with a high temperature in the physical environment will gradually\ncool down, and the temperature of the object will tend to the ambient temperature with the\npassage of time. Similarly, the temperature of the stored data decreases over time; when\naccessing data, it is similar to “warming” the data. The temperature of the data increases.\nIn this way, we can acquire the temperature value of the data in the Hot Area at any time,\nand then sort the data according to the temperature value and deﬁne the K data with the\nlowest temperature as the cold data so as to realize the identiﬁcation of hot and cold data.\nTt= (T0\u0000H)e\u0000kt+H (2)\nwhere Ttrepresents the current temperature of the object, H is the ambient temperature,\nand k is the proportional coefﬁcient of the difference between the speed of temperature\nchange in an object and the temperature of the surrounding environment.\nThe change law of objects in the physical environment affected by ambient temperature\nis slightly different from the change law of cold and hot degrees of data in data storage.\nIn data storage, each datum is independent; the temperature of the data is not affected\nby other data or the storage media, but by the number of and access time of the data\n\nElectronics 2023 ,12, 987 8 of 20\nitself. Therefore, if data are not accessed for a long time, its temperature will eventually be\ninﬁnitely close to 0. That is to say, for data, its ambient temperature has no effect on its own\ntemperature, thus the ambient temperature can be ignored when calculating the change\nin data temperature over time. Therefore, for the application scenario of measuring the\ncold and hot degree of data, Formula (2) is deformed, ignoring the inﬂuence of ambient\ntemperature H, and variable T heatis added, namely, the “warming” amplitude of data after\neach visit. Formula (3) can be obtained:\nTtn=Ttn\u00001e\u0000\u000btn\u0000tn\u00001+Theat\u0003c (3)\nwhere Ttnindicates the temperature of the data at the time tn, the cooling coefﬁcient \u000bis the\nchange rate of the data temperature, Theatdenotes the temperature increase since the data\nwere accessed, and crepresents whether the data are accessed at tn. If so, it is 1. Otherwise,\nit is 0.\nMedical data includes KB of text data and MB of image data, meaning that one also\nneeds to consider the size of the data. At the same time, the log value of the data size is\nused to reduce the weight of the data block size, as to avoid large data blocks from being\nmislabeled and residing in high-cost media for a long time [ 51]. To sum up, the calculation\nformula of the S-TCR identiﬁcation method is shown in Formula (4). Where Size denotes\nthe size of the data.\nTtn=Ttn\u00001e\u0000\u000blg(Size)tn\u0000tn\u00001+Theat\u0003c (4)\nThe S-TCR method measures the degree of cooling and heating of data in data storage,\nspeciﬁcally for the following three applications. (1) Data insertion: When the data are newly\ninserted, the ambient temperature of the data storage is taken as the initial temperature T0\nof the data and assigned to the data; (2) Data access: When the data are accessed (Select,\nUpdate), the heat of the data increases. It is assumed that different access operations\nincrease the temperature of the data equally, which is T heat. Therefore, the temperature at\nthe time when the data are accessed is the temperature obtained with time cooling, and\nthen T heatis added; (3) Cold and the hot degrees of data: This method can calculate the\nreal-time temperature of any data at any time and mark the cold and hot degrees of data. If\nyou want to compare the cold and hot degrees of different data, you can directly compare\nthe temperature values of the data. The data with a high temperature are relatively hot,\nwhile the data with a low temperature is rather cold.\nThe temperature model plays an important role in identifying hot and cold data.\nThrough the exact temperature value, the temperature model realizes the quantiﬁcation\nand identiﬁcation of the cold and hot degrees of the data. Because the temperature model\nnot only considers the inﬂuence of access frequency, time factor, and Size on the cold and\nhot degree of the data, it also uses the exponential calculation, thus, in the actual workload\nat any point in time, the temperature of any two data is different. It is more conducive to\nidentifying the cold and hot degrees of data. In order to analyze the performance of the\nS-TCR method, the general properties of the S-TCR in quantifying the degree of cooling\nand heating of data are discussed.\nIn the following example, a variety of typical examples are selected. Formula 4 is used to\ncalculate the real-time temperature of the data, assuming that the initial temperature of the\ndata is the same, T 0= 30, T heat= 2, and the cooling rate of the data temperature is \u000b=\u00000.05.\n(1) The temperature change in S-TCR with time was simulated only considering the\naccess time. Data-1 was the data that had never been accessed. Data-2 refers to the\ndata that wre frequently accessed in the ﬁrst 100 s and never accessed in the last 200 s .\nData-3 refers to the data that were never accessed in the ﬁrst 200 s and frequently\naccessed in the following 100 s. Data-4 is the data that were never accessed in the ﬁrst\n280 s and frequently accessed in the second 20 s. The temperature changes of four\nkinds of data over time are shown in Figure 7.\n\nElectronics 2023 ,12, 987 9 of 20\nElectronics 2023 , 12, x FOR PEER REVIEW 9 of 20 \n \n refers to the data that were never accessed in the first 200 s and frequently accessed in \nthe following 100 s. Data-4 is the data that were never accessed in the first 280 s and fre-\nquently accessed in the second 20 s. The temp erature changes of four kinds of data over \ntime are shown in Figure 7. \n \nFigure 7. Influence of access time on temperature in S-TCR method.  \nAs shown in Figure 7, when Size, access  frequency, and other conditions are con-\nsistent, the hot data frequently accessed in the early stage will gradually cool down to \ncold data due to the cooling mechanism. When  other conditions, such as Size and access \nfrequency, are consistent, the frequently accessed data in the later period will gradually \nheat up to become hot data. It shows that this method pays more attention to the recent thermal data and avoids the pollution of the Hot Area. \n(2) The temperature change in S-TCR with time was simulated only considering the \naccess frequency. Data-1, Data-2, and Data-3 are the data that were never accessed in the \nfirst 280 s but were frequently accessed in the later 20 s. In addition, Data-1 was the con-\ntrol group; Data-2 was accessed twice as often as Data-1; Data-3 was accessed three times as often as Data-1. The temperature changes of three kinds of data over time are \nshown in Figure 8. \n \nFigure 8. Influence of access frequency on temperature in S-TCR method.  \nAs shown in Figure 8, when the number of  accesses is different, the temperature of \nthe later accessed data may not be high. When conditions such as Size and access time \nare consistent, the higher the access frequency in the S-TCR method, the higher the tem-\nperature. \n(3) Temperature changes of S-TCR over time  were simulated only considering data \nSize. Data-1, Data-2, and Data-3 are the data that were never accessed in the first 280 0 s but were frequently accessed in the later 20 s. In addition, Data-1 was the control group; 0102030405060\n0 100 200 300 400Temperature\nquery time/sData-1\nData-2\nData-3\nData-4\n020406080100\n0 100 200 300 400Temperatur e\nquery time/sData-1\nData-2\nData-3\nFigure 7. Inﬂuence of access time on temperature in S-TCR method.\nAs shown in Figure 7, when Size, access frequency, and other conditions are consistent,\nthe hot data frequently accessed in the early stage will gradually cool down to cold data\ndue to the cooling mechanism. When other conditions, such as Size and access frequency,\nare consistent, the frequently accessed data in the later period will gradually heat up to\nbecome hot data. It shows that this method pays more attention to the recent thermal data\nand avoids the pollution of the Hot Area.\n(2) The temperature change in S-TCR with time was simulated only considering the\naccess frequency. Data-1, Data-2, and Data-3 are the data that were never accessed in\nthe ﬁrst 280 s but were frequently accessed in the later 20 s. In addition, Data-1 was\nthe control group; Data-2 was accessed twice as often as Data-1; Data-3 was accessed\nthree times as often as Data-1. The temperature changes of three kinds of data over\ntime are shown in Figure 8.\nElectronics 2023 , 12, x FOR PEER REVIEW 9 of 20 \n \n refers to the data that were never accessed in the first 200 s and frequently accessed in \nthe following 100 s. Data-4 is the data that were never accessed in the first 280 s and fre-\nquently accessed in the second 20 s. The temp erature changes of four kinds of data over \ntime are shown in Figure 7. \n \nFigure 7. Influence of access time on temperature in S-TCR method.  \nAs shown in Figure 7, when Size, access  frequency, and other conditions are con-\nsistent, the hot data frequently accessed in the early stage will gradually cool down to \ncold data due to the cooling mechanism. When  other conditions, such as Size and access \nfrequency, are consistent, the frequently accessed data in the later period will gradually \nheat up to become hot data. It shows that this method pays more attention to the recent thermal data and avoids the pollution of the Hot Area. \n(2) The temperature change in S-TCR with time was simulated only considering the \naccess frequency. Data-1, Data-2, and Data-3 are the data that were never accessed in the \nfirst 280 s but were frequently accessed in the later 20 s. In addition, Data-1 was the con-\ntrol group; Data-2 was accessed twice as often as Data-1; Data-3 was accessed three times as often as Data-1. The temperature changes of three kinds of data over time are \nshown in Figure 8. \n \nFigure 8. Influence of access frequency on temperature in S-TCR method.  \nAs shown in Figure 8, when the number of  accesses is different, the temperature of \nthe later accessed data may not be high. When conditions such as Size and access time \nare consistent, the higher the access frequency in the S-TCR method, the higher the tem-\nperature. \n(3) Temperature changes of S-TCR over time  were simulated only considering data \nSize. Data-1, Data-2, and Data-3 are the data that were never accessed in the first 280 0 s but were frequently accessed in the later 20 s. In addition, Data-1 was the control group; 0102030405060\n0 100 200 300 400Temperature\nquery time/sData-1\nData-2\nData-3\nData-4\n020406080100\n0 100 200 300 400Temperatur e\nquery time/sData-1\nData-2\nData-3\nFigure 8. Inﬂuence of access frequency on temperature in S-TCR method.\nAs shown in Figure 8, when the number of accesses is different, the temperature\nof the later accessed data may not be high. When conditions such as Size and access\ntime are consistent, the higher the access frequency in the S-TCR method, the higher the\ntemperature.\n\nElectronics 2023 ,12, 987 10 of 20\n(3) Temperature changes of S-TCR over time were simulated only considering data Size.\nData-1, Data-2, and Data-3 are the data that were never accessed in the first 280 s but\nwere frequently accessed in the later 20 s. In addition, Data-1 was the control group; The\nSize of data 2 was 100 times that of Data-1. Data-2 was 1000 times larger than Data-1.\nThe temperature changes of three kinds of data over time are shown in Figure 9.\nElectronics 2023 , 12, x FOR PEER REVIEW 10 of 20 \n \n The Size of data 2 was 100 times that of Da ta-1. Data-2 was 1000 times larger than Da-\nta-1. The temperature changes of three kinds of data over time are shown in Figure 9. \n \nFigure 9. Influence of Size on temperature in S-TCR method. \nAs shown in  Figur e 9,  we  fo und th at d ata with larg er s izes in  th e S -TCR method \ncooled down faster and warmed up faster. In addition, we found that the cooling and \nwarming amplitude of the data caused by Size was reasonable despite the large differ-\nence in the size of the data, which also sh owed that formula 4 was reasonable for the \ntreatment of Size. \nIn summary, the S-TCR identification meth od comprehensively considers the access \nfrequency, access time, and size of multi-modal medical data. It realizes the temperature identification of any data at any time, avoiding the performance limitation caused by a \nsingle factor of LRU, LFU, Size, and other al gorithms. Similarly, it is more suitable for \nmulti-mode medical data than the TCR algorithm. Therefore, the S-TCR identification \nmethod is in line with our design expectations and can effectively identify hot and cold \nmedical data. \n3.3. Dynamic Management Module of Data \nAccess to data is dynamic, and the storage capacity of high-cost storage media is \nlimited. Therefore, it is necessary to design cold and hot data management modules and \nrealize a dynamic data management model base d on data temperature to improve access \nperformance. The module uses the HBase database as the Cold Area and memory as the Hot Area. It mainly implements the following three functions: (1) Data insertion: when \nnewly accessed data are not in the Hot Area, an initial temperature T\n0 is assigned to the \nnumber and inserted into the Hot Area; (2) Da ta query: when an access request arrives, \nthe data will be retrieved in the Hot Area, an d the result will be returned. If the search \nkeyword does not exist, the request will be returned; (3) Data replacement: when the \nHot Area reaches the threshold, an appropriate replacement algorithm is selected to de-\nlete the Cold Data that have been cooled in the Hot Area in bulk. \nThe performance of the data replacement algorithm is analyzed below. Since we \nhave proposed the temperature identification method S-TCR in Section 3.2, we naturally \nthought of using it to replace the cooled data in the Hot Area. By calculating the temper-\nature of all the data in the Hot Area, we used  the sorting algorithm to select the K cold-\nest data. Although this method is simple and easy to implement, the cost is very high, \nand the cost of data replacement is very high. However, the LRU algorithm can be com-pleted only in O (1) time complexity. According to statistics, under 100 K visits, the time \nspent by the S-TCR algorithm is about three times that of the LRU algorithm [29]. Com-\npared with LRU, the hit rate of the S-TCR model can be increased by about 1.5 times, \nwhich indicates that the S-TCR method is more  accurate in identifying the degree of cold \nand hot data. While the LRU algorithm has a lower time cost, the two can be combined 01020304050\n0 100 200 300 400Temperature\nquery time/sData-1\nData-2\nData-3\nFigure 9. Inﬂuence of Size on temperature in S-TCR method.\nAs shown in Figure 9, we found that data with larger sizes in the S-TCR method cooled\ndown faster and warmed up faster. In addition, we found that the cooling and warming\namplitude of the data caused by Size was reasonable despite the large difference in the size\nof the data, which also showed that formula 4 was reasonable for the treatment of Size.\nIn summary, the S-TCR identiﬁcation method comprehensively considers the access\nfrequency, access time, and size of multi-modal medical data. It realizes the temperature\nidentiﬁcation of any data at any time, avoiding the performance limitation caused by a\nsingle factor of LRU, LFU, Size, and other algorithms. Similarly, it is more suitable for\nmulti-mode medical data than the TCR algorithm. Therefore, the S-TCR identiﬁcation\nmethod is in line with our design expectations and can effectively identify hot and cold\nmedical data.\n3.3. Dynamic Management Module of Data\nAccess to data is dynamic, and the storage capacity of high-cost storage media is\nlimited. Therefore, it is necessary to design cold and hot data management modules and\nrealize a dynamic data management model based on data temperature to improve access\nperformance. The module uses the HBase database as the Cold Area and memory as the\nHot Area. It mainly implements the following three functions: (1) Data insertion: when\nnewly accessed data are not in the Hot Area, an initial temperature T 0is assigned to the\nnumber and inserted into the Hot Area; (2) Data query: when an access request arrives,\nthe data will be retrieved in the Hot Area, and the result will be returned. If the search\nkeyword does not exist, the request will be returned; (3) Data replacement: when the Hot\nArea reaches the threshold, an appropriate replacement algorithm is selected to delete the\nCold Data that have been cooled in the Hot Area in bulk.\nThe performance of the data replacement algorithm is analyzed below. Since we have\nproposed the temperature identiﬁcation method S-TCR in Section 3.2, we naturally thought\nof using it to replace the cooled data in the Hot Area. By calculating the temperature of\nall the data in the Hot Area, we used the sorting algorithm to select the K coldest data.\nAlthough this method is simple and easy to implement, the cost is very high, and the cost\nof data replacement is very high. However, the LRU algorithm can be completed only in\nO (1) time complexity. According to statistics, under 100 K visits, the time spent by the\nS-TCR algorithm is about three times that of the LRU algorithm [ 29]. Compared with LRU,\n\nElectronics 2023 ,12, 987 11 of 20\nthe hit rate of the S-TCR model can be increased by about 1.5 times, which indicates that\nthe S-TCR method is more accurate in identifying the degree of cold and hot data. While\nthe LRU algorithm has a lower time cost, the two can be combined to take advantage of\neach other. The SL-TCR (Size & LRU–temperature Calculation Recognition) algorithm is\nproposed to replace hot and cold data.\nThe Hot Area is divided into Hot Area and a Warm Area by the SL-TCR algorithm.\nwarm data refers to cooler hot data, and the rate of Hot Area and Warm Area is 3:1. The\nSL-TCR algorithm uses the LRU algorithm to manage data in Hot Area dynamically, and\nthe S-TCI temperature recognition method uses a sorting algorithm to dynamically manage\ndata in Warm Area, which avoids traversing all the cached data, reduces the time overhead\nof the algorithm, and improves the performance of the algorithm. Figure 10 describes\nthe replacement idea of the SL-TCR algorithm. In the beginning, both the Hot Area and\nthe Warm Area are empty. As time goes by, data are accessed continuously. The recently\naccessed data are recorded as warm data, and the warm data are moved into the Warm\nArea. If the Warm Area is full, the heated data in the Warm Area, namely, hot data, are\ntransferred into the Hot Area, and the warm data are moved into the Warm Area. If the\nHot Area and Warm Area are both full, the cooled Data in the Hot Area and Warm Area\nare deleted, and the warm data are moved into the Warm Area.\nElectronics 2023 , 12, x FOR PEER REVIEW 11 of 20 \n \n to take advantage of each other. The SL-TCR (Size & LRU–temperature Calculation \nRecognition) algorithm is proposed to replace hot and cold data. \nThe Hot Area is divided into Hot Area and a Warm Area by the SL-TCR algorithm. \nwarm data refers to cooler hot data, and the rate of Hot Area and Warm Area is 3:1. The \nSL-TCR algorithm uses the LRU algorithm to manage data in Hot Area dynamically, \nand the S-TCI temperature recognition method uses a sorting algorithm to dynamically \nmanage data in Warm Area, which avoids traversing all the ca ched data, reduces the \ntime overhead of the algorithm, and improves  the performance of the algorithm. Figure \n10 describes the replacement idea of the SL-TCR algorithm. In the beginning, both the \nHot Area and the Warm Area are empty. As time goes by, data are accessed continu-\nously. The recently accessed data are reco rded as warm data, an d the warm data are \nmoved into the Warm Area. If the Warm Area is full, the heated data in the Warm Area, \nnamely, hot data, are transferred into the Ho t Area, and the warm data are moved into \nthe Warm Area. If the Hot Area and Warm Area are both full, the cooled Data in the Hot \nArea and Warm Area are deleted, and the wa rm data are moved into the Warm Area. \n \nFigure 10. Data dynamic management model data replacement idea. \nThe algorithm SL-TCR (Size & LRU-temperature Calculation Recognition) is used \nto manage hot and cold data. This algorithm uses the LRU algorithm to dynamically \nmanage data in Hot Area and the S-TCR te mperature recognition method and sorting \nalgorithm to manage data in Warm Area dy namically. The data block, designed by \nSL-TCR for storing data, is composed of five parts: key, value, T, t, and size. They repre-\nsent, respectively, the key of the data, the valu e of that key, the temperature of the data \nblock, the timestamp when the temperature was last calculated, and the size of the data \nblock. \nThe process of the SL-TCR algorithm proposed in this paper is shown in Algorithm \n1. Lines 2 through 4 indicate that if the Warm  Area is not full, new data are inserted di-\nrectly into the Warm Area. Lines 5 through 11 state that if the Warm Area is full and the \nHot Area is not, then the heated warm data from the Warm Area will be moved to the Hot Area. Lines 12 through 17 suggest deleting the warm, cooled data in the Warm Area \nwhen both Warm and Hot Areas are full. The temperature of the KTH data is denoted as \nCold. Data blocks with lower temperatures than Cold are deleted from the Hot Area. \nLine 18 indicates inserting data into the Warm Area. \nAlgorithm 1. The process of algorithm SL-TCR \nInput : key, value, T, t, size, threshold1, threshold2 \nOutput  \n1.  data = new  Node(key, value, T, t, size) \n2.  if WarmArea.size() < threshold1 then  \n3.    WarmArea.put(data); \n4.  end \n5.  else if WarmArea.size() ≥ threshold1  then  \n6.    update_Temperature(); \nFigure 10. Data dynamic management model data replacement idea.\nThe algorithm SL-TCR (Size & LRU-temperature Calculation Recognition) is used to\nmanage hot and cold data. This algorithm uses the LRU algorithm to dynamically manage\ndata in Hot Area and the S-TCR temperature recognition method and sorting algorithm to\nmanage data in Warm Area dynamically. The data block, designed by SL-TCR for storing\ndata, is composed of ﬁve parts: key, value, T, t, and size. They represent, respectively, the\nkey of the data, the value of that key, the temperature of the data block, the timestamp\nwhen the temperature was last calculated, and the size of the data block.\nThe process of the SL-TCR algorithm proposed in this paper is shown in Algorithm 1.\nLines 2 through 4 indicate that if the Warm Area is not full, new data are inserted directly\ninto the Warm Area. Lines 5 through 11 state that if the Warm Area is full and the Hot\nArea is not, then the heated warm data from the Warm Area will be moved to the Hot Area.\nLines 12 through 17 suggest deleting the warm, cooled data in the Warm Area when both\nWarm and Hot Areas are full. The temperature of the KTH data is denoted as Cold. Data\nblocks with lower temperatures than Cold are deleted from the Hot Area. Line 18 indicates\ninserting data into the Warm Area.\n\nElectronics 2023 ,12, 987 12 of 20\nAlgorithm 1. The process of algorithm SL-TCR\nInput: key, value, T, t, size, threshold1, threshold2\nOutput\n1. data = new Node(key, value, T, t, size)\n2.ifWarmArea.size() < threshold1 then\n3. WarmArea.put(data);\n4.end\n5.else if WarmArea.size()\u0015threshold1 then\n6. update_Temperature();\n7. HotCold sort(stcr);\n8. ifltcr.size < threshold2 then\n9. WarmArea.remove(Hot);\n10. HotArea.put(Hot);\n11. end\n12. else\n13. fori 0tokdo\n14. Cold WarmArea.remove();\n15. end\n16. HotArea.remove(node.T < Cold.T);\n17. end\n18. WarmArea.put(data);\n19.end\n3.4. Index Management Module\nWhen searching in HBase for data by non-primary key, the result can be obtained\nonly by scanning the entire table and ﬁltering the data that does not meet the search\ncriteria. However, scanning tables with hundreds of millions of records will take up a lot\nof resources. Therefore, we need to design a secondary index for HBase tables to avoid\nthe time consumption in retrieving non-primary keys. The secondary index stores the\nmapping between index columns and keys and is a common and efﬁcient solution for\nsearching for non-primary keys. It searches the RowKey through the secondary index, and\nthe corresponding complete data can then be searched via the RowKey.\nFurther, two optimization strategies for the secondary index were proposed in the\npresent study to reduce the retrieval time and improve the retrieval efﬁciency of the index.\nFirstly, Bloom Filter was used to optimize the performance of the secondary index. BF is\nan effective method to judge whether an element w exists in set A, especially when the\nnumber of elements in A is very large and the amount of data far exceeds the memory\nspace of the machine [ 52–55]. Hence, BF is used to discover non-existent search keywords\nto avoid unnecessary time overhead generated by extreme I/O. The BF mapping index\nkeyword is shown in Figure 11, and its idea is described as follows:\nElectronics 2023 , 12, x FOR PEER REVIEW 13 of 20 \n \n 𝐹௕=ሾ 1−൬ 1−1\n𝑚൰௞௡\nሿ௞ ൎ ൬ 1−𝑒ି௞௡\n௠൰௞\n (5) \n \nFigure 11. The process of hash mapping of BF. \nSecondly, the storage location of the secondary index is designed to reduce the time \ncost of the index based on an inverted index. Generally, if an HBase table is not large, a \nRegion is used to store the table and a Region Server [56] is used to monitor the table. As \nthe data size increases, the Region may be split and monitored by multiple RegionServ-\ners [56]. Due to the large size of the medi cal data, secondary indexes and primary data \nare likely to be in different Regions and monitored by different RegionServers [57], re-\nsulting in non-primary key retrieval requests requiring four I/O operations to acquire results. Specific operations are as follows: (1) the client queries the index table based on \nthe retrieval keyword; (2) acquire the RowKey of the main table and return it to the cli-\nent; (3) the client queries the main table according to the RowKey; (4) the retrieval result \nis returned to the client. Obviously, multiple communications with the RegionServer in-\ncreases the time overhead and leads to low retr ieval efficiency. Therefore, it is very nec-\nessary to optimize the storag e location of secondary indexes and reduce the number of \nI/O communication to improve the retrieval efficiency of secondary indexes. \nThe retrieval performance can be improved by reducing the number of I/O opera-\ntions. Suppose the main table and index reside on the same RegionServer and are run on \nit using the coprocessor provided by HBase. In  that case, the query requires only 2 I/O \noperations: (1) query the index table and obtain the RowKey according to the data to be \nqueried, then query the main table in accord ance with the RowKey; (2) return the result \nto the client. Therefore, for optimization, we should consider how to host the main and index tables on the same RegionServer. For the purpose of achieving the goal, the field \nof RowKey is designed as demonstrated in Figure 12. The RowKey of the secondary in-\ndex consists of 3 fields: (1) 0 to 8 bits indica te the start key of the Region where the data \nin the main table resides. The search of RowK ey follows the rule of the leftmost prefix. \nTherefore, the index table and the main table are in the same RegionServer; (2) 9 to 16 is the index name that uniquely identifies the index; (3) 17 to 17 + m bits to ensure the \nuniqueness of RowKey. m is the minimum nu mber of bytes required to provide the \nuniqueness of RowKey. \n \nFigure 12. The RowKey of designed secondary index.  \nAfter the introduction of the secondary index optimization strategy, the retrieval \nsteps are shown in Figure 13. \nStep 1. The client sends a medical retrie val request to the Access Request Manage-\nment Module. \nFigure 11. The process of hash mapping of BF.\n\nElectronics 2023 ,12, 987 13 of 20\nStep 1. Create an array A of length n with elements of 0 or 1.\nStep 2. Each element w of A is initially set to 0.\nStep 3. For each keyword w of the index, conduct k hashes, the i’th hashes modulo N,\ngenerate the mappings, and set them to 1 (for example, the x, y, and z are mapped to 1, 5,\n13, 4, 11, 16 and 3, 5, 11 by hash function).\nStep 4. When a non-primary key retrieval occurs, the mapping values of the search\nkeywords are obtained through k hashes, and the values of their corresponding bits are\nobtained in the A.\nIf any are not 1, the keyword will fail to be matched. This situation means that\nthe query result does not exist, and the query will be ﬁltered out (for example, the w is,\nrespectively, mapped to bit 0, bit 3, and bit 15 because there are non-1 bits in the resulting\nmapping value, thus it is determined that w must not be in the A).\nStep 5. If the keyword is successfully matched, continue to retrieve.\nIt is worth noting that there is a case where the match is successful, but the element\ndoes not exist in set A. Such a miscalculation is called a False Positive. For example, the\nmapping values of t is 5, 11, and 13, respectively, and these positions are all 1 in A. In fact,\nt is not in A. As indicated in that study, let F bbe the rate of the False Positive. F bcan be\nexpressed as Equation 5, where m represents the bit number of BF, k represents the number\nof hash functions, and n represents the number of elements in the set [ 52]. Due to the low\nFb, it is assumed in this paper that there is no keyword misjudgment.\nFb= [1\u0000\u0012\n1\u00001\nm\u0013kn\n]k\n\u0019\u0010\n1\u0000e\u0000kn\nm\u0011k\n(5)\nSecondly, the storage location of the secondary index is designed to reduce the time\ncost of the index based on an inverted index. Generally, if an HBase table is not large, a\nRegion is used to store the table and a RegionServer [ 56] is used to monitor the table. As the\ndata size increases, the Region may be split and monitored by multiple RegionServers [ 56].\nDue to the large size of the medical data, secondary indexes and primary data are likely to\nbe in different Regions and monitored by different RegionServers [ 57], resulting in non-\nprimary key retrieval requests requiring four I/O operations to acquire results. Speciﬁc\noperations are as follows: (1) the client queries the index table based on the retrieval\nkeyword; (2) acquire the RowKey of the main table and return it to the client; (3) the client\nqueries the main table according to the RowKey; (4) the retrieval result is returned to\nthe client. Obviously, multiple communications with the RegionServer increases the time\noverhead and leads to low retrieval efﬁciency. Therefore, it is very necessary to optimize\nthe storage location of secondary indexes and reduce the number of I/O communication to\nimprove the retrieval efﬁciency of secondary indexes.\nThe retrieval performance can be improved by reducing the number of I/O operations.\nSuppose the main table and index reside on the same RegionServer and are run on it using\nthe coprocessor provided by HBase. In that case, the query requires only 2 I/O operations:\n(1) query the index table and obtain the RowKey according to the data to be queried, then\nquery the main table in accordance with the RowKey; (2) return the result to the client.\nTherefore, for optimization, we should consider how to host the main and index tables\non the same RegionServer. For the purpose of achieving the goal, the ﬁeld of RowKey is\ndesigned as demonstrated in Figure 12. The RowKey of the secondary index consists of\n3 ﬁelds : (1) 0 to 8 bits indicate the start key of the Region where the data in the main table\nresides. The search of RowKey follows the rule of the leftmost preﬁx. Therefore, the index\ntable and the main table are in the same RegionServer; (2) 9 to 16 is the index name that\nuniquely identiﬁes the index; (3) 17 to 17 + m bits to ensure the uniqueness of RowKey. m\nis the minimum number of bytes required to provide the uniqueness of RowKey.\n\nElectronics 2023 ,12, 987 14 of 20\nElectronics 2023 , 12, x FOR PEER REVIEW 13 of 20 \n \n 𝐹௕=ሾ 1−൬ 1−1\n𝑚൰௞௡\nሿ௞ ൎ ൬ 1−𝑒ି௞௡\n௠൰௞\n (5) \n \nFigure 11. The process of hash mapping of BF. \nSecondly, the storage location of the secondary index is designed to reduce the time \ncost of the index based on an inverted index. Generally, if an HBase table is not large, a \nRegion is used to store the table and a Region Server [56] is used to monitor the table. As \nthe data size increases, the Region may be split and monitored by multiple RegionServ-\ners [56]. Due to the large size of the medi cal data, secondary indexes and primary data \nare likely to be in different Regions and monitored by different RegionServers [57], re-\nsulting in non-primary key retrieval requests requiring four I/O operations to acquire results. Specific operations are as follows: (1) the client queries the index table based on \nthe retrieval keyword; (2) acquire the RowKey of the main table and return it to the cli-\nent; (3) the client queries the main table according to the RowKey; (4) the retrieval result \nis returned to the client. Obviously, multiple communications with the RegionServer in-\ncreases the time overhead and leads to low retr ieval efficiency. Therefore, it is very nec-\nessary to optimize the storag e location of secondary indexes and reduce the number of \nI/O communication to improve the retrieval efficiency of secondary indexes. \nThe retrieval performance can be improved by reducing the number of I/O opera-\ntions. Suppose the main table and index reside on the same RegionServer and are run on \nit using the coprocessor provided by HBase. In  that case, the query requires only 2 I/O \noperations: (1) query the index table and obtain the RowKey according to the data to be \nqueried, then query the main table in accord ance with the RowKey; (2) return the result \nto the client. Therefore, for optimization, we should consider how to host the main and index tables on the same RegionServer. For the purpose of achieving the goal, the field \nof RowKey is designed as demonstrated in Figure 12. The RowKey of the secondary in-\ndex consists of 3 fields: (1) 0 to 8 bits indica te the start key of the Region where the data \nin the main table resides. The search of RowK ey follows the rule of the leftmost prefix. \nTherefore, the index table and the main table are in the same RegionServer; (2) 9 to 16 is the index name that uniquely identifies the index; (3) 17 to 17 + m bits to ensure the \nuniqueness of RowKey. m is the minimum nu mber of bytes required to provide the \nuniqueness of RowKey. \n \nFigure 12. The RowKey of designed secondary index.  \nAfter the introduction of the secondary index optimization strategy, the retrieval \nsteps are shown in Figure 13. \nStep 1. The client sends a medical retrie val request to the Access Request Manage-\nment Module. \nFigure 12. The RowKey of designed secondary index.\nAfter the introduction of the secondary index optimization strategy, the retrieval steps\nare shown in Figure 13.\nElectronics 2023 , 12, x FOR PEER REVIEW 14 of 20 \n \n Step 2. The Access Request Management Module determines whether the keyword \nis a primary key. If it is a non-primary key query, the request will be passed to the Index \nManagement Module. \nStep 3. The BF determines whether the keyword matches successfully. \nStep 4. If the match is successful, go to Step 5. Otherwise, go to Step 9. \nStep 5. Connect to HBase. \nStep 6. Interact with the Meta Cache to read information from the RegionServer \nabout where the Meta table is. Communicate with the RegionServer where the Meta ta-\nble is located to obtain the Meta table. \nStep 7. Communicate with the RegionServ er about where the data are located. \nStep 8. The coprocessor receives the requ est and then parses and queries it. After-\nwards, query the index table to receive Ro wKey. Then, the main table is queried by \nRowKey. \nStep 9. Return the results to the client. \n \nFigure 13. The retrieval steps of the secondary index . \n4. Experiments and Results \nIn the experiments, 15 servers were empl oyed to build a Hadoop-distributed clus-\nter. Hadoop 3.1.1, Ubuntu 16.04, a Core i7-10700 CPU, 32 GB RAM, and the HBase soft-\nware version 1.4.13 were used in the cluste r. According to the model designed in this \npaper, the MIMIC-IV dataset [58] was stored in HBase. MIMIV-IV is one of the com-monly used international public healthcare data sets, which contains data in three \nmodes: two-dimensional tabular data, text-based diagnostic reports, and image data. \nThe performance of the dynamic management  model was verified by comparing the hit \nratio and access latency. Moreover, the perf ormance of the index op timization strategy \nwas verified by comparing the access delay of non-primary key retrieval under different \nmodels. \n  \nFigure 13. The retrieval steps of the secondary index.\nStep 1. The client sends a medical retrieval request to the Access Request Management Module.\nStep 2. The Access Request Management Module determines whether the keyword\nis a primary key. If it is a non-primary key query, the request will be passed to the Index\nManagement Module.\nStep 3. The BF determines whether the keyword matches successfully.\nStep 4. If the match is successful, go to Step 5. Otherwise, go to Step 9.\nStep 5. Connect to HBase.\nStep 6. Interact with the Meta Cache to read information from the RegionServer about\nwhere the Meta table is. Communicate with the RegionServer where the Meta table is\nlocated to obtain the Meta table.\nStep 7. Communicate with the RegionServer about where the data are located.\nStep 8. The coprocessor receives the request and then parses and queries it. Afterwards,\nquery the index table to receive RowKey. Then, the main table is queried by RowKey.\nStep 9. Return the results to the client.\n4. Experiments and Results\nIn the experiments, 15 servers were employed to build a Hadoop-distributed cluster.\nHadoop 3.1.1, Ubuntu 16.04, a Core i7-10700 CPU, 32 GB RAM, and the HBase software\nversion 1.4.13 were used in the cluster. According to the model designed in this paper,\nthe MIMIC-IV dataset [ 58] was stored in HBase. MIMIV-IV is one of the commonly\n\nElectronics 2023 ,12, 987 15 of 20\nused international public healthcare data sets, which contains data in three modes: two-\ndimensional tabular data, text-based diagnostic reports, and image data. The performance\nof the dynamic management model was veriﬁed by comparing the hit ratio and access\nlatency. Moreover, the performance of the index optimization strategy was veriﬁed by\ncomparing the access delay of non-primary key retrieval under different models.\n4.1. Performance of Dynamic Management Model\nThis experiment used memory and the HBase database as the Hot Area and the Cold\nArea, respectively. The hit rate of SL-TCR, LRU [ 26], and S-TCR algorithms in Hot Areas\nwere compared to verify the performance of the proposed SL-TCR algorithm through the\nmedical data query experiment. The speciﬁc settings of the experiment were as follows:\nthe initial query times were 2000, and the query times were increased by 2000. The number\nof batch deletions K was 5%, and the temperature attenuation coefﬁcient \u000bwas 0.01.\nThe comparison results of the three algorithms are shown in Figure 14. In addition, the\nperformance of the model in this paper was conﬁrmed by comparing the access latency of\nthe original HBase, S-TCR, and SL-TCR models. The access delay experimental results of\nthe three models are shown in Figure 15.\nElectronics 2023 , 12, x FOR PEER REVIEW 15 of 20 \n \n 4.1. Performance of Dynamic Management Model \nThis experiment used memory and the HBase database as the Hot Area and the \nCold Area, respectively. The hit rate of SL -TCR, LRU [26], and S-TCR algorithms in Hot \nAreas were compared to verify the perfor mance of the proposed SL-TCR algorithm \nthrough the medical data query experiment. Th e specific settings of the experiment were \nas follows: the initial query times were 2 000, and the query times were increased by \n2000. The number of batch deletions K was 5%, and the temperature attenuation coeffi-\ncient α was 0.01. The comparison results of the three algorithms are shown in Figure 14. \nIn addition, the performance of the model in this paper was confirmed by comparing the \naccess latency of the original HBase, S-TCR, and SL-TCR models. The access delay ex-\nperimental results of the three models are shown in Figure 15. \n \nFigure 14. Hit rate comparison of three algorithms.\n \nFigure 15. Access latency comparison of three models.  \nAccording to the experimental results in Figure 14, the following conclusions can be \ndrawn: First, the hit rate of the three algori thms increased with the increase in the num-\nber of queries. It showed that the algorithm had good adaptability and stability to his-\ntorical access records. Second, the hit rate of SL-TCR algorithm was higher than that of \nthe LRU and S-TCR algorithm. The hit rate of SL-TCR was 28.76–45.51% higher than that \nof LRU. This can be attributed to the fact that the SL-TCR algorithm took more factors \ninto account than LRU, such as access frequency and size. As Warm Area was intro-0102030405060708090100\n2 4 6 8 10 12 14 16 18 20Hit Rate/%\nNumber of \nqueries/KSL-TCR S-TCR LRU\n02000400060008000 10,000 12,000 14,000\n2 4 6 8 10 12 14 16 18 20Access\ndelay/s              \nNumber of \nqueries/KHBase\nHot Area(S-TCR)\nHot Area(SL-TCR)\nFigure 14. Hit rate comparison of three algorithms.\nElectronics 2023 , 12, x FOR PEER REVIEW 15 of 20 \n \n 4.1. Performance of Dynamic Management Model \nThis experiment used memory and the HBase database as the Hot Area and the \nCold Area, respectively. The hit rate of SL -TCR, LRU [26], and S-TCR algorithms in Hot \nAreas were compared to verify the perfor mance of the proposed SL-TCR algorithm \nthrough the medical data query experiment. Th e specific settings of the experiment were \nas follows: the initial query times were 2 000, and the query times were increased by \n2000. The number of batch deletions K was 5%, and the temperature attenuation coeffi-\ncient α was 0.01. The comparison results of the three algorithms are shown in Figure 14. \nIn addition, the performance of the model in this paper was confirmed by comparing the \naccess latency of the original HBase, S-TCR, and SL-TCR models. The access delay ex-\nperimental results of the three models are shown in Figure 15. \n \nFigure 14. Hit rate comparison of three algorithms.\n \nFigure 15. Access latency comparison of three models.  \nAccording to the experimental results in Figure 14, the following conclusions can be \ndrawn: First, the hit rate of the three algori thms increased with the increase in the num-\nber of queries. It showed that the algorithm had good adaptability and stability to his-\ntorical access records. Second, the hit rate of SL-TCR algorithm was higher than that of \nthe LRU and S-TCR algorithm. The hit rate of SL-TCR was 28.76–45.51% higher than that \nof LRU. This can be attributed to the fact that the SL-TCR algorithm took more factors \ninto account than LRU, such as access frequency and size. As Warm Area was intro-0102030405060708090100\n2 4 6 8 10 12 14 16 18 20Hit Rate/%\nNumber of \nqueries/KSL-TCR S-TCR LRU\n02000400060008000 10,000 12,000 14,000\n2 4 6 8 10 12 14 16 18 20Access\ndelay/s              \nNumber of \nqueries/KHBase\nHot Area(S-TCR)\nHot Area(SL-TCR)\nFigure 15. Access latency comparison of three models.\n\nElectronics 2023 ,12, 987 16 of 20\nAccording to the experimental results in Figure 14, the following conclusions can be\ndrawn: First, the hit rate of the three algorithms increased with the increase in the number\nof queries. It showed that the algorithm had good adaptability and stability to historical\naccess records. Second, the hit rate of SL-TCR algorithm was higher than that of the LRU\nand S-TCR algorithm. The hit rate of SL-TCR was 28.76–45.51% higher than that of LRU.\nThis can be attributed to the fact that the SL-TCR algorithm took more factors into account\nthan LRU, such as access frequency and size. As Warm Area was introduced into SL-TCR,\nthe mining of medical hot spot data was more effective, and its hit rate was 13.98–22.11%\nhigher than S-TCR. In addition, compared with S-TCR and SL-TCR, the higher the hit rate\nof the algorithm, the lower the time cost of the algorithm. If the number of access times was\nW, the average hit ratio was r, the number of batch deletes was K, and the number of data\nstored in the Hot Area was S, the number of data replacement times was (W(1\u0000r)\u0000S)/K .\nIt can be seen that the higher the hit rate of the algorithm, the fewer the number of data\nreplacement and the lower the time cost of the algorithm. For example, if the Hot Area\ncould hold 400 pieces of data, the hit rate of access using S-TCR algorithm was 60%, K = 40,\nand about 1000 culling will occur. The hit rate of SL-TCR algorithm access was 80%, K = 40,\nand about 500 eliminations occur. In addition, because SL-TCR algorithm avoids traversing\nall cached data, the time cost of SL-TCR algorithm was much lower than that of S-TCR\nalgorithm. In addition, the hit rate of SL-TCR model was about two times higher than that\nof LRU. In conclusion, the experimental results show that SL-TCR algorithm realized the\ncomplementary advantages of the two algorithms, which is more accurate in identifying\nthe degree of cold and hot data, and the algorithm also had lower time cost.\nAccording to the experimental results in Figure 15, queries on the Hot Area storage\nmodel have lower access latency than those on HBase. This is because the dynamic\nmanagement model improves the utilization rate of the hotspot area and proves that the\ndynamic management model can optimize the access performance of the system. Second,\nthe effect of SL-TCR algorithm is more signiﬁcant than that of S-TCR algorithm. The\naccess latency of S-TCR ranges from 49.08% to 77.61%, lower than that of HBase. The\naccess latency of SL-TCR ranges from 56.21% to 90.66%, lower than that of HBase, because\nthe Warm Area is introduced in SL-TCR to reduce the amount of data sorting and time\noverhead.\nIn summary, the dynamic data management model based on the SL-TCR algorithm\ngreatly improves the retrieval efﬁciency of the original HBase model, improves the accu-\nracy of hot data identiﬁcation, optimizes the algorithm performance compared with LRU\nalgorithm and S-TCR, and can greatly improve the retrieval performance of HBase-based\nmedical storage systems.\n4.2. Performance of Secondary Index\nMedical data were queried to verify the performance of the proposed secondary index\nstrategy. Access delay was the evaluation index for this experiment. Four groups of\ncomparison experiments were set up: the original HBase system, the system using the\nadding Bloom Filter, the system using the index storage location optimization, and the\nsystem using both optimization strategies. Other settings were as follows: the initial query\ntimes were 200, and the query times were increased by 200. The experimental results are\ndemonstrated in Table 1.\nTable 1. Performance of secondary index optimization strategies.\nNumber of Queries HBase Bloom Filter Same RegionServer Ours\n200 332.78 292.988 324.5 279.1359\n400 685.27 573.3687 658.03 552.9814\n600 1027.73 822.6875 965.95 774.67\n800 1358.72 1050.404 1279.28 985.3437\n1000 1704.06 1290.018 1583.52 1179.21\n\nElectronics 2023 ,12, 987 17 of 20\nAccording to the experimental results of the secondary l index optimization strategies\nobtained in Table 1, the following conclusions can be acquired. First, the two optimization\nstrategies can improve the speed of non-primary key retrieval. Adding Bloom Filter\nreduced access delay by 12.0–26.6% compared to the HBase. This can be attributed to\navoiding the I/O overhead of non-existent keywords to be retrieved. Second, compared\nwith the HBase, the system with the index and main data on the same RegionServer had\nreduced access latency by 3.4% to 7.1%. This can be explained by the fact that this strategy\nreduced the number of I/O operations in a single retrieval from 4 to 2. Third, using both\noptimization strategies simultaneously reduced the access delay by 16.1–30.8%. Since the\ntwo optimization strategies have different optimization directions and do not interfere\nwith each other, the simultaneous use of both optimization strategies was better than using\nonly one optimization strategy. Consequently, it was demonstrated that the optimized\nsecondary index optimization strategies proposed in this study improve the performance\nof non-primary key retrieval and can meet the objectives of fast and diversiﬁed medical\ndata retrieval.\n5. Conclusions\nAn HBase-based distributed storage and retrieval optimization model for medical\ndata was proposed, and a retrieval optimization model based on dynamic management\nof the temperature of data and the improved secondary index was implemented. The\ndynamic management of data was introduced to identify the temperature of data, and\ndata with different temperatures were stored in the corresponding areas, which can make\nfull use of high-cost media and speed up retrieval. The improved secondary index uses a\nBloom Filter to ﬁlter non-existent keywords and the designed RowKey to optimize index\nstorage location, reducing I/O overhead and improving the retrieval performance of non-\nprimary keys. The comparison with the original HBase system proves that the proposed\noptimization strategy can give full play to the advantages of the storage model, greatly\nreduce access latency, and meet the access requirements of frequent interaction of hot data\nand diversiﬁed queries in the medical service.\nWith the increase in the amount of medical data and the development of storage\ntechnology, HBase-based retrieval optimization will continue to be a research hotspot in the\nfuture under the retrieval scenario of massive medical data. In order to solve this problem,\nwe hope to conduct further in-depth research on the following aspects: (1) Integrate the\nS-TCR method and SL-TCR algorithm into an open-source system to verify the model effect\nat the system level. (2) How to apply the optimized two-level strategy proposed in this\npaper to the multi-ﬁeld query and range query is also one of the key points to be studied in\nthe future.\nAuthor Contributions: Conceptualization, C.Z. and Z.L.; Formal analysis, H.W.; Funding acquisi-\ntion, C.Z.; Investigation, Z.L.; Methodology, Z.L. and Z.F.; Project administration, C.Z. and B.Z.;\nResources, Z.F.; Software, M.Z.; Validation, H.W.; Visualization, M.Z.; Writing—original draft, Y.X.;\nWriting—review and editing, Z.L. and Y.X. All authors have read and agreed to the published version\nof the manuscript.\nFunding: This research was funded by the National Key R&D Program of China, grant number\n2018AAA0102100. This research was financed in part by the International Science and Technology\nInnovation Joint Base of Machine Vision and Medical Image Processing in Hunan Province, grant\nnumber 2021CB1013. This research was financed in part by the National Natural Science Foundation of\nChina, grant number 61902434. This research was financed in part by the Natural Science Foundation\nof Hunan Province of China, grant numbers 2019JJ50826, 2022JJ30762. This research was financed in\npart by the Key Research and Development Program of Hunan Province, grant numbers 2022SK2054.\nInstitutional Review Board Statement: Not applicable.\nInformed Consent Statement: Not applicable.\nData Availability Statement: MIMIC-IV Database dataset: https://mimic.mit.edu/docs/gettingstarted,\naccessed on 1 December 2022.\n\nElectronics 2023 ,12, 987 18 of 20\nAcknowledgments: This work was financed in part by the National Key R&D Program of China\nand funded by 2018AAA0102100. This work was financed in part by the International Science and\nTechnology Innovation Joint Base of Machine Vision and Medical Image Processing in Hunan Province\nand funded by 2021CB1013. This work was financed in part by the National Natural Science Foundation\nof China and funded by 61902434. This work was financed in part by the Natural Science Foundation of\nHunan Province of China and funded by 2019JJ50826 and 2022JJ30762. This work was financed in part\nby the Key Research and Development Program of Hunan Province and funded by 2022SK2054.\nConﬂicts of Interest: The authors declare no conﬂict of interest.\nReferences\n1. Ch, R.; Srivastava, G.; Nagasree, Y.L.V .; Ponugumati, A.; Ramachandran, S. Robust Cyber-Physical System Enabled Smart\nHealthcare Unit Using Blockchain Technology. Electronics 2022 ,11, 3070. [CrossRef]\n2. Hamid, S.; Bawany, N.Z.; Sodhro, A.H.; Lakhan, A.; Ahmed, S. A Systematic Review and IoMT Based Big Data Framework for\nCOVID-19 Prevention and Detection. Electronics 2022 ,11, 2777. [CrossRef]\n3. Zeng, N.; Zhang, G.Q.; Li, X.; Cui, L. Evaluation of relational and NoSQL approaches for patient cohort identiﬁcation from\nheterogeneous data sources. In Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine, BIBM,\nKansas City, MO, USA, 13–16 November 2017.\n4. Chui, K.T.; Alhalabi, W.; Pang, S.S.H.; Pablos, P .O.D.; Liu, R.W.; Zhao, M. Disease Diagnosis in Smart Healthcare: Innovation,\nTechnologies and Applications. Sustainability 2017 ,9, 2309. [CrossRef]\n5. Nasajpour, M.; Pouriyeh, S.; Parizi, R.M.; Dorodchi, M.; Valero, M.; Arabnia, H.R. Internet of Things for Current COVID-19 and\nFuture Pandemics: An Exploratory Study. J. Health Inform. Res. 2020 ,4, 325–364. [CrossRef]\n6. Tsai, C.P .; Chang, C.W.; Hsiao, H.C.; Shen, H. The Time Machine in Columnar NoSQL Databases: The Case of Apache HBase.\nFuture Internet 2022 ,14, 92. [CrossRef]\n7. Ahmad, G.; Mariam, M.; Mohamad, J.; Yli ès, F. User-based Load Balancer in HBase. In Proceedings of the 7th International\nConference on Cloud Computing and Services Science, CLOSER, Porto, Portugal, 24–26 April 2017.\n8. Wang, S. Research on Key Technologies of HBase Database Evaluation. Master Thesis, Harbin Institute of Technology, Harbin,\nChina, 2015.\n9. Uzunidis, D.; Karkazis, P .; Roussou, C.; Patrikakis, C.; Leligou, H.C. Intelligent Performance Prediction: The Use Case of a\nHadoop Cluster. Electronics 2021 ,10, 2690. [CrossRef]\n10. Kavitha, C.; Srividhya, S.R.; Lai, W.-C.; Mani, V . IMapC: Inner MAPping Combiner to Enhance the Performance of MapReduce in\nHadoop. Electronics 2022 ,11, 1599. [CrossRef]\n11. Zhu, Y. Research on Hot Spot Load Balancing in Distributed Database System. Master’s Thesis, Huazhong University of Science\nand Technology, Wuhan, China, 2015.\n12. Yi, C. Analysis and Optimization of Hybrid Storage Cold and Hot Data Based on Machine Learning. Master’s Thesis, Huazhong\nUniversity of Science and Technology, Wuhan, China, 2020.\n13. Kunhui, L.; Kun, G.; Hong, G. Financial Big Data Hot and Cold Separation Scheme Based on HBase and Redis. In Proceedings\nof the IEEE International Conference on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing,\nSustainable Computing & Communications, Social Computing & Networking, ISPA/BDCloud/SocialCom/SustainCom, Xiamen,\nChina, 16–18 December 2019.\n14. Hsieh, J.W.; Kuo, T.W.; Chang, L.P . Efﬁcient identiﬁcation of hot data for ﬂash memory storage systems. ACM Trans. Storage 2006 ,\n2, 22–40. [CrossRef]\n15. Qader, M.A.; Cheng, S.; Hristidis, V . A Comparative Study of Secondary Indexing Techniques in LSM-based NoSQL Databases.\nIn Proceedings of the International Conference on Management of Data, SIGMOD, Houston, TX, USA, 10–15 June 2018.\n16. Cao, C.; Wang, W.; Ying, Z. Embedding Index Maintenance in Store Routines to Accelerate Secondary Index Building in HBase.\nIn Proceedings of the 11th IEEE International Conference on Cloud Computing, CLOUD, San Francisco, CA, USA, 2–7 July 2018.\n17. Ye, F.; Zhu, S.; Lou, Y. Research on Index Mechanism of HBase Based on Coprocessor for Sensor Data. In Proceedings of the 43rd\nAnnual Computer Software and Applications Conference, COMPSAC, Milwaukee, WI, USA, 15–19 July 2019.\n18. Cui, C.; Zheng, L.; Han, F. Design of secondary indexes in HBase based on memory. J. Comput. Appl. 2018 ,38, 1584–1590.\n19. Shen, B.; Liao, Y.C.; Liu, D. A Method of HBase Multi-Conditional Query for Ubiquitous Sensing Applications. Sensors 2018 ,18,\n3064. [CrossRef]\n20. Ali, M.; Mohajeri, J.; Sadeghi, M.R. Attribute-Based Fine-Grained Access Control for Outscored Private Set Intersection Computa-\ntion. Inf. Sci. 2020 ,536, 222–243. [CrossRef]\n21. Zhang, H.; Rong-Li, G.A.I. Distributed HBase Cluster Storage Engine and Database Performance Optimization. In Pro-\nceedings of the 23rd Int Conf on High Performance Computing & Communications; 7th Int Conf on Data Science & Sys-\ntems; 19th Int Conf on Smart City; 7th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application,\nHPCC/DSS/SmartCity/DependSys, Haikou, China, 20–22 December 2021.\n22. Hassan, M.U.; Yaqoob, I.; Zulﬁqar, S.; Hameed, I.A. A Comprehensive Study of HBase Storage Architecture—A Systematic\nLiterature Review. Symmetry 2021 ,13, 109. [CrossRef]\n\nElectronics 2023 ,12, 987 19 of 20\n23. Liu, S.; Guo, Z.; Chen, L. The Read Ampliﬁcation Analysis of NoSQL Database on Top of OSDs: A Case Study of HBase. In\nProceedings of the 4th International Conference on Big Data Computing and Communications, BigCom, Chicago, IL, USA,\n7–9 August 2018.\n24. Wen, S. Efﬁcient DNA Sequences Storage Scheme based on HBase. In Proceedings of the 2nd International Conference on\nMechanical, Electronic, Control and Automation Engineering, MECAE, Qingdao, China, 30–31 March 2018.\n25. Haifa, A.; Chase, Q.W. On Performance Modeling and Prediction for Spark-HBase Applications in Big Data Systems.\nIn Proceedings of the IEEE International Conference on Communications, ICC, Seoul, Republic of Korea, 16–20 May 2022.\n26. Xiong, W.; Szefer, J. Leaking Information Through Cache LRU States. In Proceedings of the High-Performance Computer\nArchitecture, HPCA, San Diego, CA, USA, 22–26 February 2020.\n27. Hasslinger, G.; Ntougias, K.; Hasslinger, F. Comparing Web Cache Implementations for Fast O(1) Updates Based on LRU, LFU\nand Score Gated Strategies. In Proceedings of the 23rd IEEE International Workshop on Computer Aided Modeling and Design\nof Communication Links and Networks, CAMAD, Barcelona, Spain, 17–19 September 2018.\n28. Li, P .; Pronovost, C.; Wilson, W. Beating OPT with Statistical Clairvoyance and Variable Size Caching. In Proceedings of the 24th\nInternational Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS, Providence,\nRI, USA, 13–17 April 2019.\n29. Xie, Y. Research on Cold and Hot Data Identiﬁcation Mechanism Based on Data Temperature. Master’s Thesis, Zhejiang\nUniversity, Hangzhou, China, 2019.\n30. Kraska, T.; Beutel, A.; Chi, E.H. The Case for Learned Index Structures. In Proceedings of the International Conference on\nManagement of Data, SIGMOD, Houston, TX, USA, 10–15 June 2018.\n31. He, J.; Yao, S.W.; Cai, L. SLC-index: A scalable skip list-based index for cloud data processing. J. Cent. South Univ. 2018 ,25,\n2438–2450. [CrossRef]\n32. Niu, S.; Wang JWang, B. Ciphertext Sorting Search Scheme Based on B+ Tree Index Structure on Blockchain. J. Electron. Inf.\nTechnol. 2019 ,41, 2409–2415.\n33. Schlosser, R.; Kossmann, J.; Boissier, M. Efﬁcient Scalable Multi-Attribute Index Selection Using Recursive Strategies. In\nProceedings of the 35th IEEE International Conference on Data Engineering, ICDE, Macao, China, 8–11 April 2019.\n34. Wu, J.; Lu, W.; Yan, G.; Li, X. HyperTree: High Concurrency B+ tree index accelerator. Comput. Res. Dev. 2022 ,11, 1–16.\n35. Hu, Z.; Hu, M. Design and Implementation of T-Hash Tree in Main Memory DataBase. In Proceedings of the 3rd International\nConference on Image, Vision and Computing, ICIVC, Chongqing, China, 27–29 July 2018.\n36. Chen, Y.; Li, J.; Li, Y. SBS: Efﬁcient R-tree query algorithm based on Internal Parallelism of Solid State Drive. J. Comput. Res. Dev.\n2020 ,57, 2404–2418.\n37. Chee-Yong, C.; Ioannidis, Y.E. Bitmap index design and evaluation. In Proceedings of the ACM SIGMOD International Conference\non Management of Data, SIGMOD, Seattle, DC, USA, 2–4 June 1998.\n38. Zou, Z.; Zheng, L.; Xia, D. CSIndex: A Coprocessor-Based Classiﬁed Secondary Index Mechanism for Efﬁcient HBase Query.\nIn Proceedings of the IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing,\nSustainable Computing & Communications, Social Computing & Networking, ISPA/BDCloud/SocialCom/SustainCom, Xiamen,\nChina, 16–18 December 2019.\n39. Chen, W. Storage and Retrieval of Medical Image Files Based on Hadoop. Master’s Thesis, Beijing University of Technology,\nBeijing, China, 2019.\n40. Chen, S.; Zou, Z.; Liu, R.; Tao, T.; Wang, C.; ZHENG, L. Design of HBase classiﬁcation secondary index based on coprocessor.\nJ. Chongqing Univ. Technol. 2021 ,35, 142–151.\n41. Li, F.; Lu, Y.; Yang, Z. SineKV: Decoupled Secondary Indexing for LSM -based Key-Value Stores. In Proceedings of the 40th\nInternational Conference on Distributed Computing Systems, ICDCS, Singapore, 29 November 2020.\n42. Chen, H.; Ruan, C.; Li, C. SpanDB: A Fast, Cost-Effective LSM-tree Based KV Store on Hybrid Storage. In Proceedings of the 19th\nUSENIX Conference on File and Storage Technologies, FAST, Santa Clara, CA, USA, 23–25 February 2021.\n43. Wang, H.; Li, Z.; Zhang, X. A Performance Optimization Method for Key -Value Store Based on LSM-tree. In Proceedings of the\n3rd International conference on IMAGE, VISION and COMPUTING, ICIVC, Chongqing, China, 27–29 July 2018.\n44. Tian, X.; Wang, C. Index and Matching Method of Linear Algebraic Expressions. Comput. Eng. 2018 ,44, 201–207.\n45. Zhou, W.; Lu, J.; Zhou, K.; Wang, S.; Yao, S. Research on double-layer index architecture of cloud data processing based on\nconcurrent skip list. Comput. Res. Dev. 2015 ,52, 1531–1545.\n46. Zhang, K.; Zhou, W.; Sun, S. Multiple complementary inverted indexing based on multiple metrics. Multim. Tools Appl. 2019 ,78,\n7727–7747. [CrossRef]\n47. Singh, M.; Sural, S.; Vaidya, J.; Atluri, V . Managing Attribute-Based Access Control Policies in a Uniﬁed Framework using Data\nWarehousing and In-Memory Database. Comput. Secur. 2019 ,86, 183–205. [CrossRef]\n48. Levandoski, J.J.; Larson, P .Å.; Stoica, R. Identifying hot and cold data in main-memory databases. In Proceedings of the 29th IEEE\nInternational Conference on Data Engineering, ICDE, Brisbane, QLD, Australia, 8–12 April 2013.\n49. Moghimi, A.; Eisenbarth, T.; Sunar, B. MemJam: A False Dependency Attack Against Constant-Time Crypto Implementations.\nInt. J. Parallel Program 2019 ,47, 538–570. [CrossRef]\n50. Einziger, G.; Friedman, R.; Manes, B. TinyLFU: A Highly Efﬁcient Cache Admission Policy. ACM Trans. Storage 2017 ,13, 1–31.\n[CrossRef]\n\nElectronics 2023 ,12, 987 20 of 20\n51. Waldspurger, C.A.; Saemundson, T.; Ahmad, I. Cache modeling and optimization using miniature simulations. In Proceedings of\nthe USENIX Annual Technical Conference, USENIX ATC, Santa Clara, CA, USA, 12–14 July 2017.\n52. Beiji, Z.; Meng, Z.; Chengzhang, Z.; Ling, X.; Zhi, C. A Learned Preﬁx Bloom Filter for Spatial Data. In Proceedings of the 33rd\nInternational Conference Database and Expert Systems Applications, DEXA, Vienna, Austria, 22–24 August 2022.\n53. Pu, C.; Choo, K. Lightweight Sybil Attack Detection in IoT based on Bloom Filter and Physical Unclonable Function. Comput.\nSecur. 2022 ,113, 102541. [CrossRef]\n54. Pei, S.; Xie, K.; Wang, X. BhBF: A Bloom Filter Using Bh Sequences for Multi-set Membership Query. ACM Trans. Knowl. Discov.\nData 2022 ,16, 3502735. [CrossRef]\n55. Hua, W.; Gao, Y.; Lv, M. Survey of Bloom ﬁlter research. Appl. Comput. 2022 ,42, 1729–1747.\n56. Chen, Y.; Xiang, X.; Ling, X. Dynamic Load Balance for Hot-spot and Unbalance Region Problems in HBase. In Proceedings of the\nIEEE International Conference on Big Data, Atlanta, GA, USA, 10–13 December 2020.\n57. Yang, L.; Chen, J.; Xiang, Y. Performance Optimization Strategy for Distributed Storage of industrial Time series Big Data Based\non HBase. Comput. Appl. 2022 ,33, 21–27.\n58. Alistair, E.W.J.; David, J.S.; Leo, A.C.; Tom, J.P . The MIMIC Code Repository: Enabling reproducibility in critical care research.\nJ. Am. Med. Inform. Assoc. 2018 ,25, 32–39.\nDisclaimer/Publisher’s Note: The statements, opinions and data contained in all publications are solely those of the individual\nauthor(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to\npeople or property resulting from any ideas, methods, instructions or products referred to in the content.",
  "textLength": 95216
}