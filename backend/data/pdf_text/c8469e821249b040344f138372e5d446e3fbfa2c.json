{
  "paperId": "c8469e821249b040344f138372e5d446e3fbfa2c",
  "title": "Towards a GML-Enabled Knowledge Graph Platform",
  "pdfPath": "c8469e821249b040344f138372e5d446e3fbfa2c.pdf",
  "text": "Towards a GML-Enabled Knowledge Graph Platform\nHussein Abdallah\nConcordia University,\nhussein.abdallah@concordia.caEssam Mansour\nConcordia University,\nessam.mansour@concordia.ca\nAbstract —This vision paper proposes KGNet, an on-demand\ngraph machine learning (GML) as a service on top of RDF\nengines to support GML-enabled SPARQL queries. KGNet\nautomates the training of GML models on a KG by identifying\na task-speciﬁc subgraph. This helps reduce the task-irrelevant\nKG structure and properties for better scalability and accuracy.\nWhile training a GML model on KG, KGNet collects metadata\nof trained models in the form of an RDF graph called KGMeta,\nwhich is interlinked with the relevant subgraphs in KG. Finally,\nall trained models are accessible via a SPARQL-like query. We\ncall it a GML-enabled query and refer to it as SPARQLML.\nKGNet supports SPARQLMLon top of existing RDF engines as\nan interface for querying and inferencing over KGs using GML\nmodels. The development of KGNet poses research opportunities\nin several areas, including meta-sampling for identifying task-\nspeciﬁc subgraphs, GML pipeline automation with computational\nconstraints, such as limited time and memory budget, and\nSPARQLMLquery optimization. KGNet supports different GML\ntasks, such as node classiﬁcation, link prediction, and semantic\nentity matching. We evaluated KGNet using two real KGs of\ndifferent application domains. Compared to training on the entire\nKG, KGNet signiﬁcantly reduced training time and memory\nusage while maintaining comparable or improved accuracy. The\nKGNet source-code1is available for further study.\nI. I NTRODUCTION\nKnowledge graphs (KGs) are constructed based on\nsemantics captured from heterogeneous datasets using various\nArtiﬁcial Intelligence (AI) techniques, such as representation\nlearning and classiﬁcation models [1]. Graph machine learning\n(GML) techniques, such as graph representation learning and\ngraph neural networks (GNNs), are powerful tools widely\nused to solve real-world problems by deﬁning them as\nprediction tasks on KGs. For instance, node classiﬁcation\ntasks for problems, such as recommendations [2] and entity\nalignment [3], can be solved using GML techniques. Similarly,\ndrug discovery [4] and fraud detection [5], [6] problems are\ntackled as link prediction tasks using GML techniques.\nData scientists often work with KGs, which are typically\nstored in RDF engines. They are responsible for developing\nGML pipelines using frameworks, such as PyG [7] and\nDGL [8], to train models on these KGs. However, there is\noften a gap between the GML frameworks and RDF engines.\nThis necessitates an initial step of transforming the entire KG\nfrom RDF triple format into adjacency matrices in a traditional\nGML pipeline. Afterward, the data scientist needs to select a\nsuitable GML method from a wide range of KG embedding\n(KGE) or GNN methods [9], [10] to train the model. For\nthe average user, this responsibility is time-consuming.\n1https://github.com/CoDS-GCS/KGNET\nPaper01\nAuthor\naffiliation\npublish \nyear\nauthoredBy\n   \nPrimary \nAffiliation\nyearOfPublication\nPaper02\nauthoredBy\nFeatures\nVenue\npublishedIn\nFeatures\npublishedIn\npublish \nyear\nyearOfPublicationFig. 1: A KG with nodes/edges in red, which could be pre-\ndicted by classiﬁcation and link prediction models on the ﬂy.\n1prefix dblp : <https://www. dblp .org/>\n2prefix kgnet : <https://www. kgnet .com/>\n3select ?title ?venue\n4where {\n5?paper a dblp :Publication.\n6?paper dblp :title ?title.\n7?paper ?NodeClassifier ?venue.\n8?NodeClassifier a kgnet:NodeClassifier .\n9?NodeClassifier kgnet :TargetNode dblp :Publication.\n10 ?NodeClassifier kgnet :NodeLabel dblp :venue.}\nFig. 2: SPARQLML\npv: a SPARQLMLquery uses a node\nclassiﬁcation model to predict a paper’s venue by querying\nand inferencing over the KG shown in Figure 1.\nFurthermore, the trained models are isolated from the RDF\nengine, where the KG is stored. Therefore, automating the\ntraining of GML models on KGs and providing accessibility\nto the trained models via a SPARQL-like query is essential.\nWe refer to this query as a SPARQLMLquery.\nThe KG shown in Figure 1 contains information about pub-\nlished papers in DBLP [11]. However, the traditional SPARQL\nquery language cannot be used to apply GML models on top of\na KG, such as predicting a node’s class or a missing afﬁliation\nlink for an author. For instance, the venue node in Figure 1 is a\nvirtual node that could be predicted using a node classiﬁcation\n(NC) model. It would be fascinating to query this KG using\na GML model for NC through a SPARQL-like query to\nobtain the paper-venue node, as shown in the SPARQLML\npvin\nFigure 2. This query uses a model of type kgnet:NodeClassiﬁer\nto predict a venue for each paper. The SPARQLMLtriple\npatterns in lines 8-10 will retrieve all models of type\nkgnet:NodeClassiﬁer that predict a class of type dblp:venue .\nIn the triple pattern h?paper ;?NodeClassifier ,?venue i,\nwe refer to ?NodeClassiﬁer as a user-deﬁned predicate.arXiv:2303.02166v1  [cs.DB]  3 Mar 2023\n\nEnabling queries like SPARQLML\npv, shown in Figure 2,\npresents several challenges. These include: ( i) automatically\ntraining GML models for various tasks, ( ii) optimizing\nSPARQLMLfor GML model selection based on accuracy and\ninference time, and ( iii) efﬁciently interacting with the selected\nmodel during query execution. Additionally, seamless integra-\ntion of GML models into RDF engines is necessary. As a re-\nsult, users should be able to express their SPARQLMLqueries\neasily by following the SPARQL logic of pattern matching,\navoiding the explicit use of user-deﬁned functions (UDFs).\nThere is a growing adoption of integrating GML with\nexisting graph databases, such as Neo4j [12] or Stardog [13].\nHowever, while these databases offer some machine learning\nprimitive methods, such as PageRank and shortest-path using\ntheCypher language, they do not address the challenges of\nintegrating GML models with RDF engines. For example,\nNeo4j Graph Data Science [14] supports limited graph\nembedding methods in a beta version, such as FastRP [15],\nNode2Vec [16], and Graph-SAGE [17]. However, a user must\ntrain the models separately as an initial step. To address\nthese challenges, there is a need to bring GML to data stored\nin RDF engines instead of getting data to machine learning\npipelines. This would encourage the development of KG data\nscience libraries powered by the expressiveness of SPARQL,\nenabling better analysis and insight discovery based on KG\nstructure and semantics. These libraries would empower data\nscientists with a full breadth of KG machine learning services\non top of KGs stored in RDF engines.\nThis vision paper proposes KGNet, an on-demand GML-\nas-a-service on top of RDF engines to support SPARQLML\nqueries, as illustrated in Figure 3. KGNet extends existing\nRDF engines with two main components GML-as-a-\nservice (GMLaaS) and SPARQLMLas a Service. KGNet\nautomatically trains a GML model on a KG for tasks,\nsuch as node classiﬁcation or like prediction, and maintains\nmetadata of the trained model as an RDF graph called\nKGMeta . To reduce training time and memory usage while\nimproving accuracy on a speciﬁc task A, KGNet performs\nmeta-sampling to identify a task-speciﬁc subgraph KG0of\nthe larger KG that preserves essential characteristics relevant\ntoA. This enables KGNet to scale on large KGs. GMLaaS\nis in charge of: ( i) selecting the near-optimal GML method\nfor training Ausing KG0based on a given time or memory\nbudget, and ( ii) communicating with RDF engines via HTTP\ncalls requesting inferencing of a speciﬁc trained model, ( iii)\nstoring the trained models and embeddings related to KGs.\nThe SPARQLMLservice transparently: ( i) maintains and\ninterlinks the KGMeta with associated KGs, ( ii) optimizes the\nGML model selection for a user-deﬁned predicate, and ( iii)\nﬁnally rewrites the SPARQLMLquery as a SPARQL query.\nIn summary, the contributions of this paper are:\n\u000fa fully-ﬂedged GML-enabled KG platform2on top of\nexisting RDF engines.\n\u000fGML-as-a-service to provide automatic training of\nGML models based on a given memory or time budget.\n2https://github.com/CoDS-GCS/KGNET\nSPARQL\nML\n \nas \na \nService\nGML \nas \na \nService\nApache-Jena\nOpenlink-Virtuoso\nStar-dog\nSPARQL\nML\nResult\nSPARQL \nQueries\nresults\nresults\nHTTP \nCalls\nKGMeta\nGoverner\nGML \nTraining\nManager\nGML \nInference\nManager\nMeta\nSampler\nRDF \nEngine\nEmbeddings\n \nModels\nKG'\n, \nKG'\nMeta \nData\nQuery\nParser\nQuery\nRe-writer\nQuery\nOptimizer\n{(m\ni\n, \np\nj\n)}\nQuery \nManagerFig. 3: The KGNet architecture, which provides an interface\nlanguage (SPARQLML) and enables AI applications and data\nscientists to automatically train GML models on top of KGs\nfor querying and inferencing KGs based on the trained models.\nThis automatic training utilizes task-speciﬁc subgraphs\nextracted using our meta-sampling approach.\n\u000fSPARQLMLas a Service to perform meta-sampling,\nmaintain training meta-data in KGMeta, and optimize the\nGML model selection, i.e., opt for the near-optimal model\nbased on constraints on accuracy and inference time.\n\u000fA comprehensive evaluation with different GML methods\nusing three GML tasks on real KGs. Our experiments\nshow that KGNet achieved comparable or improved\naccuracy compared to training on the entire KG, while\nsigniﬁcantly reducing training time and memory usage.\nThe remainder of this paper is organized as follows. Sec-\ntion II provides a background about existing graph machine\nlearning pipelines. Section III outlines the main research chal-\nlenges of developing a GML-enabled KG engine. Section IV\npresents the KGNet platform. Section V discusses the results\nof evaluating our automated pipeline for training GML models.\nSections VI and VII are related work and conclusion.\nII. B ACKGROUND : ML PIPELINES FOR KG S\nML pipelines developed to train models on a KG can be\ngrouped into three main categories: ( i) traditional ML on KG\ndata in tabular format, ( ii) traditional ML on KG embeddings,\nand ( iii) graph neural networks (GNNs) trained directly on\nthe KG. In the traditional ML approach using KG data in\ntabular format, data from the KG is transformed into in-\nmemory data frames, and classical ML classiﬁers are trained\nusing feature engineering techniques and libraries, such as\nScikit-Learn or SparkMLib. In contrast, traditional ML on\nKG embeddings avoids the feature engineering process and\ngenerates embeddings for nodes and edges. Apple Saga [18]\nis an example of this approach, which uses graph ML libraries\nlike DGL-KE [8] to generate KG embeddings. Data scientists\nhave the ﬂexibility to choose the ML method for training.\nGNNs have gained signiﬁcant popularity in recent years.\nHence, data scientists frequently utilize them to perform GML\ntasks. The Open Graph Benchmark (OGB) [19] standardized\nthe GNN training pipeline, emphasizing the best practices for\ntackling GML tasks and building a GNN training pipeline.\nFigure 4 summarizes this pipeline, which involves encoding\n\nDataset \nEncoding\nIn-memory\n \nData \nLoading\nTraining\nInferencing\nCSV\nAdjacency \nMatrices\nSparse \nMatrices\nDataset \nTransformer\nGML \nMethod\nGML \nFramework\nGraph \nDBFig. 4: A traditional GML pipeline [19] using a GML frame-\nwork. The pipeline starts with extracting the graph data,\nfollowed by data transformation into sparse matrices to train\nmodels for a GML task. Finally, the inference step is ready to\npredict results in isolation from the graph databases.\nKG nodes and edges, generating adjacency matrices, loading\nthem into memory, and training GNNs using speciﬁc methods.\nVarious GML frameworks, such as DGL [8] and PyG\n[7], offer multiple implementations of GNN methods.\nThese frameworks support data transformation by loading\ngraphs into memory as graph data structures and applying\ntransformations. However, existing GML frameworks require\nsigniﬁcant memory and processing time for large KGs and a\ndeep understanding of various GNN methods. In comparison,\nthe OGB pipeline is simple, but it is a semi-automated process\nthat necessitates human intervention and ML expertise to\nconstruct an effective pipeline and select an appropriate GNN\nmethod. Data scientists may choose the most appropriate\nGNN method based on various constraints, such as time or\nmemory limitations. Furthermore, as depicted in Figure 4, the\nseparation of the trained models from the KG engines adds\nan extra layer of complexity for data scientists to apply their\nmodels when inferring the KG.\nIII. C HALLENGES OF GML- ENABLED KG E NGINE\nThis section highlights the open research challenges and\nopportunities raised by developing GML-enabled KG Engine.\nA. Automatic Training: Method Selection and Meta-sampling\nThere are numerous methods for training models for GML\ntasks, as summarized in Figure 5. These methods could be\nclassiﬁed mainly into two categories KG embeddings (KGE)\nor graph neural network (GNN) methods. Examples of KGE\nmethods are TransE, RotatE, ComplEx, and DistMult [10].\nSome GNN methods support sampling on full graph, such as\nGraph-SAINT [20], Shadow-SAINT [21], and MorsE [22].\nExamples of GNN full-batch training (without sampling)\nmethods are RGCN [23] and GAT [24]. Our taxonomy has\nmore categories, as shown in Figure 5.\nGML methods vary signiﬁcantly in terms of their accuracy,\ntraining time, and memory requirements. Furthermore, the\ncomplexity of each GML task may differ depending on various\nfactors, such as the size of KGs and the number of node/edge\ntypes related to the task. For example, link prediction can\nbe more resource-intensive than node classiﬁcation. Different\nGNN\nSampling\nFull \nPropagation\nPooling\nspectral\nGCN\nAGCN\nRGCN\n...\nAttentional\nGAT\nrGAT\nGAAN\n...\nNode/Layer\nSubgraph\nGraph-SAGE\nLADIES\nCluster-GCN\nGraph-SAINT\nSHADOW-GNN\nSimple-P\nSort-P\nKGE\nGraph \nEmbedding\nTranslational\nRotatE\nTransR\n.....\nSemantic\nDistMullt\nComplEx\n.....\nVector \npoint-based \nRandom \n-Walk\nDeepWalk\nnode2vec\ndeep-learning\nConvR\n...\nHomogenouse\nHetergenouse\nNARS\nMAGNN\nMHGNN\nSeHGNN\n.....Fig. 5: A taxonomy of methods for training GML models.\nGML methods may perform differently under the same budget\nconstraints, and selecting the best method can depend on\nseveral factors. Hence, automating a training pipeline for a spe-\nciﬁc GML task based on a user’s budget for time and memory\nis challenging. For instance, some GML methods perform full-\nbatch training, which requires more memory budget. These\nmethods require huge memory to train models on large KGs.\nSome other GNN methods may suffer from over-smoothing,\nwhich can cause accuracy degradation. Sampling-based GNN\n(mini-batch training) methods use different types of sampling,\nwhich vary in avoiding these limitations. Therefore, automat-\ning the selection of GML methods for a speciﬁc task based\non a given time or memory budget is challenging.\nReal KGs can contain millions to billions of triples, such as\nDBLP [11] and MAG [25]. However, training GML models\non these large KGs requires colossal computing resources that\nexceed the capabilities of a single machine. As a result, there\nis a need for identifying a smaller training dataset of the KG,\nwhich is speciﬁc to the task at hand. This process is known\nas meta-sampling. It has been proposed in various application\ndomains, including computer vision [26], [27] and speech\nrecognition [28], to extract a training dataset that is tailored to\nthe given task. In the context of GML, meta-sampling presents\nan opportunity to optimize training models on large KGs by\nselecting a representative sub-graph that is relevant to the task.\nThis approach can help reduce time and memory requirements\nwithout sacriﬁcing accuracy. Therefore, exploring the potential\nbeneﬁts of using meta-sampling in training GML models to\nextract task-speciﬁc subgraphs is crucial. By doing so, we can\nimprove the efﬁciency and effectiveness of GML methods on\nlarge-scale KGs. This raises a research opportunity to explore\ndifferent meta-sampling approaches for GML methods on\nlarge knowledge graphs (KGs).\nB. Seamless Integration Between GML Models and KGs\nEnabling GML on top of RDF engines poses signiﬁcant\nchallenges, mainly interfacing between the trained models\nand the underlying data management engine. One common\napproach is to use user-deﬁned functions (UDFs) to implement\nthis interface [29]–[31]. However, this comes with a cost for\nquery optimizations in data systems [32]. The existence of an\nextensive catalog of UDFs can limit the expressiveness of ML-\nbased queries. For instance, a large catalog of UDFs makes\nit difﬁcult for users to choose between UDFs and ﬁnd the\n\nDataset \nTransformer\nA\nB\nC\nA\n0\n1\n1\nB\n1\n0\n1\nC\n1\n1\n0\nAdjacency \nMatrices\nPreprocessing/\nStatstics \ngeneration\nTrain-Valid-Test \nSplit\nRandom\nComunityGML-Task\nTask \nBudget\nInput\nTask-Specific \nSubgraph\nOptimal \nGML \nMethod \nSelection\nbudget\nResouces \nSpecifications\nGNN \nMethods\nGML \nOptimizer\nTraining \nGML \nModel\nGraph\nSamplers\nGNN \nMethod\nTrain \n| \nEvaluate\nAdicancy \nMatrices \nData \nLoader\n(\nTORCH.SPARSE\n)\nGCN\nRGCN\nGraph-SAINT\nShadow-SAINT\nMorsE\nComplEx\n...\nGNN \nModel \nSaving\nGML \nInferencing\n \nModel \nLoader\nJSON\nStatstics\nResouces \nSpecifications\n \nKG'\nmodel.pklFig. 6: The automation of training pipeline and inference in our GML-as-a-service (GMLaaS). GMLaaS interacts with the\nKGMeta Manager to train a model for a speciﬁc task with limited budget. The automated pipeline opt to the near-optimal GML\nmethod for training a model within a limited budget. GMLaaS supports task inference through RestAPI that is called by a UDF.\nright one for their needs. Most existing query optimizers do\nnot have models estimating the cost of these UDFs. Hence,\nautomating the query optimization of SPARQLMLqueries\nis challenging. There is a research opportunity for seamless\nintegration between trained GML models and RDF. To address\nthese challenges, we proposed KGMeta as a graph representa-\ntion of metadata of trained models interlinked with the KGs.\nC. Optimizing SPARQLMLQueries and Benchmarks\nUser-deﬁned predicates were ﬁrst proposed for SQL [33].\nIn SPARQLML, a user-deﬁned predicate is used to get a\nprediction from one of the trained models associated with a\nspeciﬁc node in the graph. Estimating the cost of evaluating\na user-deﬁned predicate is more complex than estimating the\ncost of a traditional RDF predicate. While cardinality estima-\ntion is used to optimize only the execution time for the latter, a\nuser-deﬁned predicate in a SPARQLMLquery can be inferred\nby multiple models, each with varying accuracy and inference\ntime. RDF engines are unaware of this information, leading\nto the problem of selecting the best model for inference.\nFor a SPARQLMLquery, the inference step in an RDF\nengine using a chosen model is a challenging task that requires\noptimization, speciﬁcally for rank-ordering the inference pro-\ncess. The challenge lies in deciding whether to perform the\ninference in a single call to a UDF or per instance, which may\nresult in an extensive number of UDF calls. Additionally, each\nmodel has a unique cardinality, i.e., the total number of predic-\ntions it can make. This makes predicting rank-ordering com-\nplex as RDF engines lack accurate estimation of UDF costs.\nTo address these challenges, there are research opportunities\nfor developing benchmarks to evaluate optimization\napproaches for SPARQLMLqueries. These benchmarks\nshould consider various models for different user-deﬁned\npredicates and be designed to work with large datasets.\nFurthermore, each SPARQLMLquery should vary in the\nnumber of user-deﬁned predicates and be associated with\nvariables of different cardinalities. This will enable a\ncomprehensive evaluation of the performance and scalability\nof varying optimization approaches for SPARQLMLqueries.IV. T HEKGN ETPLATFORM\nKGNet provides two main services, namely GML as a\nService (GMLaaS) and SPARQLMLas a Service on top of\nexisting RDF engines, as shown in Figure 3.\nA. GML as a Service (GMLaaS)\nKGNet is a platform that offers end-to-end automation of\nGML training on KGs, as depicted in Figure 6. The platform\nprovides GMLaaS , a Restful service that manages GML mod-\nels in terms of automatic training and interactive inferencing.\nAdditionally, it utilizes an embedding store to facilitate entity\nsimilarity search tasks by computing the similarity between\nembedding vectors. The GML training manager automates the\ntraining pipeline per task. However, the automation of GML\ntraining on KGs is challenging due to the complexity and\nsize of KGs. Therefore, KGNet leverages our meta-sampling\napproach to optimize the training process by selecting a task-\nspeciﬁc subgraph ( KG0) that is speciﬁc to the given task.\nThis step helps reduce the time and memory required without\ntrading accuracy. The pipeline takes as input a task-speciﬁc\nsubgraph ( KG0), the GML task, the task budget, and the\navailable resources within the ML environment.\nThe Data Transformer step converts the subgraph into a\nsparse-matrix format optimized for in-memory and matrix\noperations. This format is compatible with popular graph ML\ndata loaders, such as Py-Geometric and DGL, and is ideal\nfor sparse KGs. Our pipeline ensures data consistency by\nvalidating node/edge types counts, removing literal data and\ntarget class edges, and generating graph statistics. We also\nperform a train-validation-test split using different strategies\nlike random and community-based. KGNet automates this\ntransformation, making ad-hoc GML training queries possible.\nThe Optimal GML Method Selection step selects the best\nGML method for a given task. KGNet supports various GNN\nmethods, including GCN, RGCN, Graph-SAINT, Shadow-\nSAINT, Morse, and KGE methods such as ComplEx. We\nestimate the required memory for each method based on the\nsize and the number of generated sparse-matrices, as well as\nthe training time based on the matrix dimensions and feature\naggregation approach. Moreover, we estimate the training time\n\n(A): \nLink \nPrediction \nTask\nGML\nModel\nNode\nClassiferTask\nInference \nT\nF1 \nScore\nGNN\nSampler\nNode\nClasssifer\na\nuses\nVenue\ndblp:Publication\nHasGMLTask\nTargetNode\nPublished \nIn\nModel \nAccuracy\nSampler\nInference \nTime\nGML\nModel\nInference \nT\nMRR \nScore\nGNN\nSampler\nModel \nAccuracy\nSampler\nInference \nTime\nTaskBudget\nLink\nPredictorTask \nuses\nHasGMLTask\nSourceNode\nDestinationNode\naffiliation\nPrimary \nAffiliation\nLink\nPredictor\na\ndblp:Person\n(B): \nNode \nClassification \nTask\nG-SAINT\nGML\nMethod\nMorsE\nGML\nMethod\nBudget\nBudget\nTaskBudget\nNodeLabelFig. 7: A KGMeta graph of two trained models for node\nclassiﬁcation and link prediction tasks. The white nodes are\nnodes from the original data KG. The dashed nodes/edges are\nmetadata collected per trained model.\n1prefix dblp :<https://www. dblp .org/>\n2prefix kgnet :<https://www. kgnet .com/>\n3Insert into < kgnet > { ?s ?p ?o }\n4where {select *from kgnet.TrainGML(\n5{Name: ’MAG _Paper-Venue _Classifer’,\n6 GML-Task:{ TaskType: kgnet:NodeClassifier ,\n7 TargetNode: dblp :publication,\n8 NodeLable: dblp :venue},\n9 Task Budget:{ MaxMemory:50GB, MaxTime:1h,\n10 Priority:ModelScore} } )};\nFig. 8: A SPARQLMLinsert query that trains a paper-venue\nclassiﬁer on DBLP. The TrainGML function is a UDF that is\nimplemented inside the RDF engine.\nbased on the dimension of the sparse-matrices and GNN\nneighbour nodes features aggregation approach adopted by\neach method. For GNN sampling-based methods, the sampling\ncost basically depends on the sampling heuristic used [34].\nThus, we are working on a more advanced estimation method\nbased on sampling the sparse-matrices and running a few\nepochs on them.\nKGNet’s GML-optimizer determines the necessary re-\nsources for each method and optimizes the training set-\ntings, ensuring scalability in distributed environments. The\nautomated pipeline trains a model and collects evaluation\nmetrics and inference time statistics. A URI is generated for\nthe trained model to distinguish it from other models used\nfor inference tasks. The model meta-data is returned to the\nKGMeta Manager to update the KGMeta graph. Figure 7.a\nand b show the generated meta-data for link prediction and\nnode classiﬁcation models, respectively. The Embedding Store\nsub-component, shown in Figure 3, is used for fast similarity\nsearch by storing, indexing, and searching embeddings. The\nGML Inferencing receives HTTP calls for inference, serializes\nthe result into a JSON Restful-API response, and sends it back\nto the RDF engine, as shown in Figure 3. The current version\nuses FAISS embedding store [35] to enable ad-hoc queries for\nnode similarity search.1prefix dblp :<https://www. dblp .org/>\n2prefix kgnet :<https://www. kgnet .com/>\n3delete {?NodeClassifier ?p ?o}\n4where {\n5?NodeClassifier a kgnet :NodeClassifier.\n6?NodeClassifier kgnet :TargetNode dblp :Publication.\n7?NodeClassifier kgnet :NodeLabel dblp :venue.}\nFig. 9: A SPARQLMLdelete query that deletes a trained\nmodel and its meta-data.\n1prefix dblp : <https://www. dblp .com/>\n2prefix kgnet : <https://www. kgnet .com/>\n3select ?author ?affiliation\n4where { ?author a dblp :person.\n5?author ? LinkPredictor ?affiliation.\n6?LinkPredictor a kgnet:LinkPredictor .\n7?LinkPredictor kgnet :SourceNode dblp :person.\n8?LinkPredictor kgnet :DestinationNode dblp :affiliation.\n9?LinkPredictor kgnet :TopK-Links 10.}\nFig. 10: A SPARQLMLquery predicting author afﬁliation link\n(edge) on DBLP KG.\nB. The SPARQLMLas a Service\nWe offer a SPARQLMLas a Service, which comprises three\nmain components: Query Manager, KGMeta Governor, and\nMeta-sampler. In addition, we provide an interfacing language\ncalled SPARQLMLthat enables users to express SPARQL-\nlike queries for INSERT, DELETE, or SELECT operations,\nsuch that: ( i) a SPARQLMLINSERT query is used to train a\nGML model and maintain its metadata in KGMeta (as shown\nin Figure 8), ( ii) a SPARQLMLDELETE query is used to\ndelete trained model ﬁles and associated embeddings from\nthe GML-aaS component and then deletes its metadata from\nthe KGMeta (as in Figure 9), ( iii) a SPARQLMLSELECT\nquery is for querying and inferencing the KG, e.g., the query\nin Figure 10. When a SPARQLMLquery is received, the\nQuery Manager parses it. An INSERT or DELETE query is\nsent to the KGMeta Governor. If it is a SELECT query, it is\noptimized and rewritten as a SPARQL query.\n1) KGMeta Governor: The KGMeta Governor maintains\na KGMeta graph for each KG, using statistics and metadata\ncollected from trained GML models speciﬁc to that KG.\nThe INSERT query is a request to train a task on a certain\nKG. The parsed information includes the task type (such as\nnode classiﬁcation or link prediction), the task inputs (such\nas the target nodes and classiﬁcation labels (Y classes) for\na classiﬁcation task), and a budget (such as memory and\ntime budget). Experienced ML users can provide additional\ninformation, such as hyperparameters or a speciﬁc GML\nmethod. This information is encapsulated as a JSON object,\nas shown in Figure 8. At line 4, the TrainGML is a UDF that\ntakes as input a JSON object that encapsulates all required\ninformation to train a GML model. The KGMeta Governor\nsends the task to the meta-sampler to obtain a task-speciﬁc\nsubgraph ( KG0) for the given task. Then governor interacts\nwith the GML Training Manager to automate the training\n\n1prefix dblp : <https://www. dblp .org/>\n2prefix kgnet : <https://www. kgnet .com/>\n3select ?title\n4 sql:UDFS. getNodeClass ($m,?paper) as ?venue\n5where {\n6 ?paper a dblp :Publication.\n7 ?paper dblp :title ?title.\n8}\nFig. 11: A candidate SPARQL for SPARQLML\npv\npipeline for this task. Once training is complete, the KGMeta\nGovernor receives the trained model’s metadata, including\naccuracy and inference time, to maintain the KGMeta, as\nillustrated in Figure 7.\n2) Meta-sampler: Our meta-sampler aims to identify\na task-speciﬁc subgraph ( KG0) for training a GML task.\nEach GML task targets nodes of a speciﬁc type, such as\ndblp:Publication in SPARQLML\npv. Our meta-sampler extracts\na task-speciﬁc subgraph ( KG0), which comprises a set of\ntriples with representative triples associated with the target\nnodes. Based on the KG schema structure the size of KG0\nis much smaller than the size of KG. This smaller size will\noptimize training time and require less memory for training\nthe GML task A. However, the KG may contain triples that\nare not reachable from a target node vTor connected via\nmore than three hops from vT. These triples do not assist\nthe model in generalizing and may lead to over-smoothing\nproblems [36], [37].\nOur SPARQL-based meta-sampling method determines the\nscope of the extracted subgraph based on two parameters: ( i)\nthe direction d, where d= 1 for outgoing and d= 2 for bidi-\nrectional (i.e., both outgoing and incoming), and ( ii) the num-\nber of hops h. We evaluated the performance of our method us-\ning four combinations of d2 f1;2gandh2 f1;2g. Our meta-\nsampling approach achieved better results with d= 1andh=\n1for node classiﬁcation, whereas for link prediction, our meta-\nsampling method performed better with d= 2 andh= 1.\n3) The Query Manager: The Query Manager is responsible\nfor optimizing SPARQLMLqueries for model selection and\nrank-ordering to evaluate user-deﬁned predicates. In the case\nof SPARQLML\npvshown in Figure 2, the query optimizer fetches\nall URIs of the models satisfying the conditions associated\nwith the user-deﬁned predicate ?NodeClassiﬁer . The KGMeta\nis an RDF graph containing optimizer statistics, such as model\naccuracy, inference time, and model cardinality. Therefore, we\nuse a SPARQL query to obtain the models’ URIs, accuracy,\ninference time, and cardinality. The query optimizer selects\nthe near-optimal GML model that achieves high accuracy and\nlow inference time. We deﬁne this problem as an integer pro-\ngramming optimization problem to minimize total execution\ntime or maximize inference accuracy.\nThe SPARQLMLQuery Re-writer uses the near-optimal\nGML model with URI mto generate a candidate SPARQL\nquery. KGNet currently supports two possible execution plans,\nwhose query templates are shown in Figures 11 and 12. The\ncore idea is to map a user-deﬁned predicate into a user-deﬁned\nfunction (UDF), such as sql:UDFS.getNodeClass , to send\nHTTP calls during the execution time to the GML Inference1prefix dblp : <https://www. dblp .org/>\n2prefix kgnet : <https://www. kgnet .com/>\n3select ?title\n4 sql:UDFS. getKeyValue (?venues _dic,?paper) as ?venue\n5where {\n6 ?paper a dblp :Publication.\n7 ?paper dblp :title ?title.\n8{select sql:UDFS. getNodeClass ($m, dblp :Publication)\n9 as ?venues _dic where { } }}\nFig. 12: A candidate SPARQL for SPARQLML\npv\nManager in our GMLaaS to get inference based on the pre-\ntrained model m. The number of HTTP calls may dominates\nthe query execution cost. For example, SPARQLML\npvpredicts\nthe venue of all papers, whose size is |?papers|.\nThe query template shown in Figure 11 will generate\n|?papers| HTTP calls. However, the query template shown in\nFigure 12 reduces the number of HTTP calls to one by enforc-\ning an inner select query constructing a dictionary of all papers\nand their predicted venues. Then, sql:UDFS.getKeyValue is\nused to look up the venue of each paper. Our query optimizer\ndecomposes the triple patterns related quering the KG triples\nin the SPARQLMLquery into sets per variable associated\nwith a user-deﬁned predicate. For example, in the SPARQLML\npv\nquery shown in Figure 2, our optimizer identiﬁes two triple\npatterns that match the variable ?paper and one triple pattern\nthat matches the variable ?venue . We use a SPARQL query to\nget the cardinality of each set, which is the number of distinct\nvalues of the variable in the dataset. We formulate this problem\nas another integer programming optimization problem [38]\nthat minimizes the total number of HTTP calls or minimizes\nthe constructed dictionary size, which is based on the model\ncardinality. For instance, in the query shown in Figure 12,\nour optimizer generates a dictionary of all papers and their\npredicted venues, which is then used to retrieve the venue of\neach paper using the UDF sql:UDFS.getKeyValue .\nV. E XPERIMENTAL EVALUATION\nThis section analyzes the ability of KGNet in automating\npipelines to train a model for a speciﬁc task with less time\nand memory w.r.t traditional pipelines on full graphs.\nA. Evaluation Setup\nCompared Methods: We used RGCN [23] as a full-batch\ntraining method and GraphSAINT [20], ShadowSAINT [21]\nas mini-batch sampling-based methods for node classiﬁcation\nand MorsE [22] as edge sampling-based method for link\nprediction. The OGB [19] default conﬁgurations are used\nin both sampling and training. Node features are initialized\nrandomly using Xavier weight initialization in all experiments.\nComputing Infrastructure: All experiments are conducted\non Ubuntu server virtual machine that is equipped with dual\n64-core Intel Xeon 2.4 GHZ (Skylake, IBRS) CPUs, 256 GB\nof main memory and 1TB of disk storage.\nReal KGs: We mainly focus on two benchmark KGs\ndistinguishing in graph size, graph data domain, task type,\nand connection density including (DBLP [11] and Yago-4\n\nTABLE I: Statistics of the used KGs and GNN tasks. We\nused four times larger KGs (DBLP and Yago) than the ones\nreported in OGB [19].\nKnowledge Graph DBLP YAGO4\n#Triples 252M 400M\n#Targets50 Venue\n51K Afﬁliations\n1.2M paper200 Country\n#Edge Types 48 98\n#Node Types 42 104\nTasks NC,LP,ES NC\nG-SAINT RGCN SH-SAINT020406080100120Accuracy (%)82\n748590\n8091DBLP(KG)\nKGNET(KG')\nG-SAINT RGCN SH-SAINT036912Time in Hours\n1.9 29.2\n1.4 1.45.9DBLP(KG)\nKGNET(KG')\nG-SAINT RGCN SH-SAINT073146219292Memory in GB\n46220\n94\n3682\n54DBLP(KG)\nKGNET(KG')\n(A) (B) (C)\nFig. 13: (a) Accuracy, (B) Training Time, and (C) Training\nMemory for DBLP KG Paper-Venue node classiﬁcation task.\nThe KGNet task-oriented sampled subgraph (KG’) signiﬁ-\ncantly improves accuracy, training time, and memory.\n[39]). We conducted two node classiﬁcation tasks and one\nlink prediction. We followed the tasks used in OGB [19].\nStatistics about used KG and tasks are provided in Table I.\nEndpoints: We use Virtuoso 07.20.3229 as a SPARQL\nendpoint, as it is widely adopted as an endpoint for large\nKGs, such as DBLP. The standard, unmodiﬁed installation of\nthe Virtuoso engine was run at the endpoints and used in all\nexperiments.\nB. GML Experiments With Real KGs\nThree GML tasks are conducted to evaluate the KGNet\nautomated GML pipeline. For Node classiﬁcation task , GNN\nmethods are used to train node classiﬁers to predict a venue\nfor each DBLP paper. The KG is loaded into the Virtuoso RDF\nengine. KGNet performs meta-sampling using d1h1to extract\nthe task-speciﬁc subgraph ( KG0) to train RGCN, Graph-\nSAINT, and Shadow-SAINT methods. The task results in\nFigures 13 and 14 show that our KGNet training pipeline using\n(KG0) outperforms the traditional pipeline on the full KG in\nall methods with up to 11% accuracy score. The automated\ntraining pipeline of KGNet has successfully enabled GNN\nmethods to achieve signiﬁcant reductions in memory consump-\ntion and training time. Speciﬁcally, KGNet has demonstrated\na reduction of at least 22% in memory consumption and 27%\nin training time. These results demonstrate that KGNet can\neffectively discover task-speciﬁc subgraphs for each task.\nOurLink prediction task aims to predict an author’s afﬁl-\niation link based on their publications and afﬁliations history\nG-SAINT RGCN SH-SAINT020406080100120Accuracy (%)7995 94\n90\n8194YAGO(KG)\nKGNET(KG')\nG-SAINT RGCN SH-SAINT0246810Time in Hours7.3\n26.4\n1.82.12.6YAGO(KG)\nKGNET(KG')\nG-SAINT RGCN SH-SAINT073146219292Memory in GB130220\n150\n30100\n50YAGO(KG)\nKGNET(KG')\n(A) (B) (C)Fig. 14: (a) Accuracy, (B) Training Time, and (C) Training\nMemory for YAGO-4 KG Place-Country node classiﬁcation\ntask. The KGNet task-oriented sampled subgraph (KG’) sig-\nniﬁcantly improves accuracy, training time, and memory.\nMorsE020406080100120Hits @ 10 (%)\n1689DBLP(KG)\nKGNET(KG')\nMorsE019385776Time in Hours58.8\n3.1DBLP(KG)\nKGNET(KG')\nMorsE04590135180Memory in GB136\n6DBLP(KG)\nKGNET(KG')\n(A) (B) (C)\nFig. 15: (a) Accuracy, (B) Training Time, and (C) Training\nMemory for the DBLP Author Afﬁliation link prediction\ntask. The KGNet task-oriented edge sampled subgraph (KG’)\nsigniﬁcantly improves the Hits@10 MRR score, training time,\nand training memory.\non the DBLP knowledge graph. MorsE [22] is the state-of-the-\nart link-prediction sampling-based method. We use the MorsE\nin the traditional pipeline with the full KG. In the KGNet\npipeline, our meta-sampling ﬁrst extracts the task-speciﬁc\nsubgraph ( KG0) using d2h1to train MorsE. The results,\nshown in Figure 15, demonstrate that the KGNet automated\npipeline outperforms the pipeline trained on the full KG in\nterms of Hits@10 MRR score. KGNet achieves a signiﬁcant\nreduction in memory usage and training time, with a reduction\nof 94% compared to the pipeline trained on the full KG.\nVI. R ELATED WORK\nThe adoption of combining AI and database systems has\nbeen growing rapidly, with two main approaches emerging:\nAI models incorporated in DB systems (AI4DB) and database\ntechniques optimized for AI systems for better scalability\n(DB4AI) [40]. In KGNet, we classify SPARQLMLas part\nof the AI4DB approach since we have extended the KG\nengine to query and perform inference on KGs using GML\n\nmodels. However, we classify GMLaaS as part of the DB4AI\napproach since we have optimized the training pipeline using\nour meta-sampling approach, which queries a KG to extract a\ntask-speciﬁc subgraph. Works RDFFrames [41], DistRDF2ML\n[42], and Apple Saga [18] aim to bridge the gap between ML\nand RDF systems by enabling the user to extract data from\nheterogeneous graph engines in a standard tabular format to\napply traditional ML tasks such as classiﬁcation, regression,\nand clustering or use KGE methods to generate node/edge\nembeddings for similarity search applications.\nYuo Lu et.al. addressed the problem of AI-enabled query\noptimization for SQL in [29] and introduced the probabilistic\npredicates (PPs) method that can be trained without any knowl-\nedge of the inference models. In Learned B+tree [43], the\nB+tree index is optimized based on AI models that map each\nquery key to its page. Hasan et al [44] allow fast join queries\nby utilizing auto-regressive densities model to represent the\njoint data distribution among columns. ITLCS [45] introduced\nan index selection ML-based method that uses a classiﬁer\nmodel as well as a genetic algorithm that selects the accurate\nindex. Stardog [13] supports supervised learning to build\npredictive analytics models. Stardog enables users to write\nSPARQL queries that collect the ML training features set in a\ntabular format and apply classical ML, i.e., classiﬁcation, clus-\ntering, and regression that can be used for inference queries.\nGoogle’s BigQuery ML [46] provides user-friendly tools\nto support AI models in SQL statements by introducing a\nhybrid language model that contains both AI and DB oper-\nations, which executes AI operations on AI platforms such as\nTensorFlow and Keras. SQL4ML [47] translates ML operators\nimplemented in SQL into a TensorFlow pipeline for efﬁcient\ntraining. To enable ad-hoc GML pipelines using SPARQL,\nRDF engines require this level of support.\nBordawekar et al. [48] built a cognitive relation database\nengine that queries database records utilizing word similarity\nusing word2vec embeddings and extends results with external\ndata sources. The cognitive DB represents a step towards\nlinking representation learning with DB using text embedding\ntechniques. EmbDI [49] automatically learns local relation\nembeddings with high quality from relational datasets using a\nword embedding to support datasets schema matching. Unlike\nall the above-mentioned systems, KGNet proposed a platform\ncombining DB4AI and AI4DB approaches to bridge the gap\nbetween GML frameworks and RDF engines.\nVII. C ONCLUSION\nThe lack of integration between GML frameworks and RDF\nengines necessitates that data scientists manually optimize\nGML pipelines to retrieve KGs stored in RDF engines\nand select appropriate GML methods that align with their\ncomputing resources. Furthermore, the trained models cannot\nbe directly used for querying and inference over KGs, which\nimpedes systems’ scalability, particularly as KGs grow in\nsize and require excessive computing resources. Additionally,\nthese limitations impact the system’s ﬂexibility, as descriptive\nquery languages are incapable of incorporating GML models.\nTo overcome these limitations, this vision paper proposedKGNet, an on-demand GML-as-a-service (GMLaaS) platform\non top of RDF engines to support GML-enabled SPARQL\nqueries (SPARQLML). KGNet uses meta-sampling to extract\na task-speciﬁc subgraph ( KG0) as a search query against\na KG for a speciﬁc task. Our GMLaaS automates a cost-\neffective pipeline using KG0to train a model within a given\ntime or memory budget. KGNet maintains the metadata and\nstatistics of trained models as an RDF graph called KGMeta,\nwhich is stored alongside associated KGs. KGMeta leads to a\nseamless integration between GML models and RDF engines,\nallowing users to easily express their SPARQLMLqueries\nbased on the SPARQL logic of pattern matching. Moreover,\nKGMeta enables KGNet to optimize SPARQLMLqueries\nfor model selection and rank-ordering for the inferencing\nprocess. KGNet raises research opportunities spanning across\ndata management and AI.\nREFERENCES\n[1] H. Aidan, B. Eva, and et.al., “Knowledge graphs,” ACM Comput.\nSurv. , vol. 54, no. 4, 2021. [Online]. Available: https://doi.org/10.1145/\n3447772\n[2] S. Wu, F. Sun, W. Zhang, X. Xie, and B. Cui, “Graph neural\nnetworks in recommender systems: A survey,” ACM Comput.\nSurv. , vol. 55, no. 5, pp. 97:1–97:37, 2023. [Online]. Available:\nhttps://doi.org/10.1145/3535101\n[3] Z. Wang, Q. Lv, X. Lan, and Y . Zhang, “Cross-lingual knowledge\ngraph alignment via graph convolutional networks,” in Proceedings\nof the Conference on Empirical Methods in Natural Language\nProcessing (EMNLP) , 2018, pp. 349–357. [Online]. Available:\nhttps://aclanthology.org/D18-1032\n[4] X. Lin, Z. Quan, Z. Wang, T. Ma, and X. Zeng, in Proceedings of the\nInternational Joint Conference on Artiﬁcial Intelligence (IJCAI) , 2020,\npp. 2739–2745. [Online]. Available: https://doi.org/10.24963/ijcai.2020/\n380\n[5] Y . Dou, Z. Liu, L. Sun, Y . Deng, H. Peng, and P. S. Yu, “Enhancing\ngraph neural network-based fraud detectors against camouﬂaged\nfraudsters,” in The ACM International Conference on Information\nand Knowledge Management (CIKM) , 2020, pp. 315–324. [Online].\nAvailable: https://doi.org/10.1145/3340531.3411903\n[6] Y . Dou, Z. Liu, and et.al., “Enhancing graph neural network-based\nfraud detectors against camouﬂaged fraudsters.” ACM, 2020. [Online].\nAvailable: https://doi.org/10.1145/3340531.3411903\n[7] PyG. (2022) Torch geometric documentation. [Online]. Available:\nhttps://pytorch-geometric.readthedocs.io/en/latest/index.html\n[8] D. Zheng, C. Ma, M. Wang, and et.al., “Distdgl: Distributed graph neural\nnetwork training for billion-scale graphs,” in IEEE/ACM,10th . IEEE,\n2020.\n[9] Z. Wu, S. Pan, F. Chen, and et.al., “A comprehensive survey\non graph neural networks,” IEEE Trans. Neural Networks Learn.\nSyst., vol. 32, no. 1, pp. 4–24, 2021. [Online]. Available: https:\n//doi.org/10.1109/TNNLS.2020.2978386\n[10] Q. Wang, Z. Mao, B. Wang, and L. Guo, “Knowledge graph embed-\nding: A survey of approaches and applications,” IEEE Transactions on\nKnowledge and Data Engineering , vol. 29, no. 12, pp. 2724–2743, 2017.\n[11] M. R. Ackermann. (2022) dblp in rdf. [Online]. Available: https:\n//blog.dblp.org/2022/03/02/dblp-in-rdf/\n[12] D. Gordon. (2021) Fulltext search in neo4j. [Online]. Available:\nhttps://neo4j.com/developer/kb/fulltext-search-in-neo4j/\n[13] docs@stardog.com. Stardog documentation-machine learning. [Online].\nAvailable: https://docs.stardog.com/machine-learning#machine-learning\n[14] Neo4j.Inc. (2022) Neo4j graph data science for machine learning.\n[Online]. Available: https://neo4j.com/docs/graph-data-science/current/\nmachine-learning/machine-learning/\n[15] H. Chen, S. F. Sultan, and et.al., “Fast and accurate network\nembeddings via very sparse random projection,” in Proceedings of the\n28th ACM International Conference on Information and Knowledge\nManagement , ser. CIKM ’19, 2019, p. 399–408. [Online]. Available:\nhttps://doi.org/10.1145/3357384.3357879\n\n[16] A. Grover and J. Leskovec, “node2vec: Scalable feature learning for\nnetworks,” in Proceedings of the 22nd ACM SIGKDD , 2016, pp.\n855–864. [Online]. Available: https://doi.org/10.1145/2939672.2939754\n[17] W. L. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation\nlearning on large graphs,” in NeurIPS , 2017, pp. 1024–\n1034. [Online]. Available: https://proceedings.neurips.cc/paper/2017/\nhash/5dd9db5e033da9c6fb5ba83c7a7ebea9-Abstract.html\n[18] I. F. Ilyas, T. Rekatsinas, V . Konda, J. Pound, X. Qi, and M. A.\nSoliman, “Saga: A platform for continuous construction and serving\nof knowledge at scale,” in SIGMOD , 2022, pp. 2259–2272. [Online].\nAvailable: https://doi.org/10.1145/3514221.3526049\n[19] W. Hu, M. Fey, M. Zitnik, Y . Dong, H. Ren, B. Liu, M. Catasta, and\nJ. Leskovec, “Open graph benchmark: Datasets for machine learning on\ngraphs,” in NeurIPS , 2020.\n[20] H. Zeng, H. Zhou, and et.al., “Graphsaint: Graph sampling based\ninductive learning method,” in ICLR(8) , 2020. [Online]. Available:\nhttps://openreview.net/forum?id=BJe8pkHFwS\n[21] H. Zeng, M. Zhang, Y . Xia, and et.al., “Decoupling the depth and\nscope of graph neural networks,” CoRR , vol. abs/2201.07858, 2022.\n[Online]. Available: https://arxiv.org/abs/2201.07858\n[22] M. Chen, W. Zhang, and et.al., “Meta-knowledge transfer for inductive\nknowledge graph embedding,” in ACM SIGIR , 2022, p. 927–937.\n[Online]. Available: https://doi.org/10.1145/3477495.3531757\n[23] M. S. Schlichtkrull, T. N. Kipf, and e. a. Peter Bloem, “Modeling\nrelational data with graph convolutional networks,” in ESWC ,\nvol. 10843. Springer, 2018, pp. 593–607. [Online]. Available:\nhttps://doi.org/10.1007/978-3-319-93417-4_38\n[24] M. Chen, Y . Zhang, X. Kou, and et.al., “r-gat: Relational graph attention\nnetwork for multi-relational graphs,” CoRR , vol. abs/2109.05922, 2021.\n[Online]. Available: https://arxiv.org/abs/2109.05922\n[25] M. Färber, “The microsoft academic knowledge graph: A linked\ndata source with 8 billion triples of scholarly data,” in ISWC , vol.\n11779, 2019, pp. 113–129. [Online]. Available: https://doi.org/10.1007/\n978-3-030-30796-7_8\n[26] T. Y . Cheng, Q. Hu, Q. Xie, N. Trigoni, and A. Markham, “Meta-\nsampler: Almost-universal yet task-oriented sampling for point clouds,”\nECCV , 2022. [Online]. Available: https://doi.org/10.48550/arXiv.2203.\n16001\n[27] O. Dovrat, I. Lang, and S. Avidan, “Learning to sample,”\nin IEEE CVPR , 2019, pp. 2760–2769. [Online]. Avail-\nable: http://openaccess.thecvf.com/content_CVPR_2019/html/Dovrat_\nLearning_to_Sample_CVPR_2019_paper.html\n[28] Y . Xiao, K. Gong, P. Zhou, G. Zheng, X. Liang, and L. Lin,\n“Adversarial meta sampling for multilingual low-resource speech\nrecognition,” in AAAI , 2021, pp. 14 112–14 120. [Online]. Available:\nhttps://ojs.aaai.org/index.php/AAAI/article/view/17661\n[29] Y . Lu, A. Chowdhery, S. Kandula, and S. Chaudhuri, “Accelerating\nmachine learning inference with probabilistic predicates,” in SIGMOD ,\nser. SIGMOD ’18, 2018, p. 1493–1508. [Online]. Available: https:\n//doi.org/10.1145/3183713.3183751\n[30] R. Bordawekar and O. Shmueli, “Enabling cognitive intelligence queries\nin relational databases using low-dimensional word embeddings,”\nCoRR , vol. abs/1603.07185, 2016. [Online]. Available: http://arxiv.org/\nabs/1603.07185\n[31] M. Schule, H. Lang, M. Springer, A. Kemper, T. Neumann, and\nS. Gunnemann, “In-database machine learning with sql on gpus,”\ninSSDBM , 2021. [Online]. Available: https://doi.org/10.1145/3468791.\n3468840\n[32] K. Awada, M. Y . Eltabakh, C. Tang, M. Al-Kateb, S. Nair, and G. Au,“Cost estimation across heterogeneous sql-based big data infrastructures\nin teradata intellisphere,” in EDBT , 2020.\n[33] S. Chaudhuri and K. Shim, “Optimization of queries with user-deﬁned\npredicates,” ACM Trans. Database Syst. , vol. 24, no. 2, pp. 177–228,\n1999. [Online]. Available: https://doi.org/10.1145/320248.320249\n[34] M. Seraﬁni, “Scalable graph neural network training: The case for\nsampling,” ACM SIGOPS Oper. Syst. Rev. , vol. 55, no. 1, pp. 68–76,\n2021. [Online]. Available: https://doi.org/10.1145/3469379.3469387\n[35] J. Johnson, M. Douze, and H. Jégou, “Billion-scale similarity search\nwith gpus,” IEEE Trans. Big Data , vol. 7, no. 3, pp. 535–547, 2021.\n[Online]. Available: https://doi.org/10.1109/TBDATA.2019.2921572\n[36] D. Chen, Y . Lin, W. Li, P. Li, J. Zhou, and X. Sun, “Measuring and\nrelieving the over-smoothing problem for graph neural networks from\nthe topological view,” in IAAI , 2020, pp. 3438–3445.\n[37] J. Liu, K. Kawaguchi, B. Hooi, Y . Wang, and X. Xiao, “Eignn:\nEfﬁcient inﬁnite-depth graph neural networks,” in NIPS , vol. 34, 2021,\npp. 18 762–18 773. [Online]. Available: https://proceedings.neurips.cc/\npaper/2021/ﬁle/9bd5ee6fe55aaeb673025dbcb8f939c1-Paper.pdf\n[38] S. Bradley, A. Hax, A. Hax, and T. Magnanti, Chapter 9: Integer\nProgramming . Addison-Wesley, 1977.\n[39] T. P. Tanon, G. Weikum, and F. M. Suchanek, “YAGO 4: A reasonable\nknowledge base,” in ESWC , vol. 12123, 2020, pp. 583–596. [Online].\nAvailable: https://doi.org/10.1007/978-3-030-49461-2_34\n[40] X. Zhou, C. Chai, G. Li, and J. Sun, “Database meets artiﬁcial\nintelligence: A survey,” IEEE TKDE , vol. 34, no. 3, pp. 1096–1116,\n2022.\n[41] A. Mohamed, G. Abuoda, and et.al., “Rdfframes: Knowledge graph\naccess for machine learning tools,” PVLDB , vol. 13, no. 12, 2020.\n[Online]. Available: http://www.vldb.org/pvldb/vol13/p2889-mohamed.\npdf\n[42] C. F. Draschner, C. Stadler, F. Bakhshandegan Moghaddam, J. Lehmann,\nand H. Jabeen, “Distrdf2ml-scalable distributed in-memory machine\nlearning pipelines for rdf knowledge graphs,” in Proceedings of\nthe 30th ACM , 2021, p. 4465–4474. [Online]. Available: https:\n//doi.org/10.1145/3459637.3481999\n[43] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis, “The case\nfor learned index structures,” in SIGMOD . ACM, 2018, pp. 489–504.\n[Online]. Available: https://doi.org/10.1145/3183713.3196909\n[44] S. Hasan, S. Thirumuruganathan, J. Augustine, N. Koudas, and G. Das,\n“Multi-attribute selectivity estimation using deep learning,” CoRR , vol.\nabs/1903.09999, 2019. [Online]. Available: http://arxiv.org/abs/1903.\n09999\n[45] W. G. Pedrozo, J. C. Nievola, and D. C. Ribeiro, “An adaptive approach\nfor index tuning with learning classiﬁer systems on hybrid storage\nenvironments,” in HAIS , vol. 10870, 2018, pp. 716–729. [Online].\nAvailable: https://doi.org/10.1007/978-3-319-92639-1_60\n[46] S. Fernandes and J. Bernardino, “What is bigquery?” Proceedings of the\n19th International Database Engineering & Applications Symposium ,\n2015.\n[47] N. Makrynioti, R. Ley-Wild, and V . Vassalos, “sql4ml A declarative\nend-to-end workﬂow for machine learning,” CoRR , vol. abs/1907.12415,\n2019. [Online]. Available: http://arxiv.org/abs/1907.12415\n[48] R. Bordawekar, B. Bandyopadhyay, and O. Shmueli, “Cognitive\ndatabase: A step towards endowing relational databases with\nartiﬁcial intelligence capabilities,” vol. abs/1712.07199, 2017. [Online].\nAvailable: http://arxiv.org/abs/1712.07199\n[49] C. Riccardo, P. Paolo, and T. Saravanan, “Creating embeddings\nof heterogeneous relational datasets for data integration tasks,” in\nACM SIGMOD , USA, 2020, p. 1335–1349. [Online]. Available:\nhttps://doi.org/10.1145/3318464.3389742",
  "textLength": 51418
}