{
  "paperId": "06f260815a256dd2aed21d2b1f3002e081bab3bd",
  "title": "Algorithms with predictions",
  "pdfPath": "06f260815a256dd2aed21d2b1f3002e081bab3bd.pdf",
  "text": "Algorithms with Predictions\u0003\nMichael MitzenmacherySergei Vassilvitskiiz\nJune 17, 2020\nAbstract\nWe introduce algorithms that use predictions from machine learning applied to the input to circumvent\nworst-case analysis. We aim for algorithms that have near optimal performance when these predictions\nare good, but recover the prediction-less worst case behavior when the predictions have large errors.\n1 Introduction\nIn \fnding ways to go beyond worst case analysis, previous chapters have described di\u000berent ways to\nmodel the inputs seen by an algorithm in order to avoid fragile bad examples, give better guarantees, or\nexplain the e\u000ecacy of methods in practice. Many of these approaches are based on assuming a model of\nthe input that includes randomness in a very speci\fc way. For instance, in average case analysis data is\ndrawn from a \fxed but unknown distribution, and with random arrival models the input is assumed to\nbe randomly permuted. In this chapter, instead of posing a speci\fc model or a set of assumptions on the\ninput, we provide a general framework designed to make use of the rapidly growing power of machine\nlearning techniques. In our framework, we assume that we have a machine learning method that provides\nus with predictions about the input, and we use the prediction to make a more e\u000bective algorithm. We\nthen analyze the performance of the algorithm as a function of how accurate the prediction is; ideally,\nthe better the prediction, the better the performance.\nOne thing that distinguishes this approach from other work is its natural connection to practice, as\nfor many problems machine learning can be readily applied to data to provide the necessary prediction\nfor new inputs. Moreover, if we can successfully tie the performance of an algorithm to the quality of\nthe predictions it receives, then as machine learning technology evolves and the quality of predictions\nimproves, we get better performing algorithms essentially for free.\nWhen designing these kinds of algorithms with predictions, there are several new challenges. One\nis a new goal for our theoretical analysis. We wish to provide formal guarantees of the following form:\nif our predictor has a given level of performance, our algorithm will achieve a corresponding level of\nperformance. A further challenge is to identify what quantity or quantities to predict, as these will\ngenerally be problem speci\fc. Choosing the right quantity to predict can a\u000bect both the algorithm\nperformance and the bounds from our analysis. Finally, an additional challenge is that by nature machine\nlearning methods are imperfect. They have errors that can be large and surprising, and the algorithms\nwe design using machine learning predictions should be robust enough to cope with them.\nWe start with some very simple examples suggesting why this framework might be useful, and then\npresent some additional examples of more complicated algorithms and data structures that make use of\npredictions.\n\u0003This survey is to appear as a chapter in Beyond the Worst-Case Analysis of Algorithms, a collection edited by Tim\nRoughgarden. We hope to occasionally update the survey here, with new versions that include discussions of new results and\nadvances in the area of Algorithms with Predictions.\nySchool of Engineering & Applied Sciences, Harvard University, Cambridge, Massachusetts, USA.\nmichaelm@eecs.harvard.edu .http://www.eecs.harvard.edu/~michaelm . Supported by NSF grants CCF-1563710 and\nCCF-1535795.\nzGoogle Research, New York, New York, USA. sergeiv@google.com .http://theory.stanford.edu/~sergeiv\n1arXiv:2006.09123v1  [cs.DS]  16 Jun 2020\n\n1.1 Warm-up: Binary search\nAs a \frst example, consider the binary search problem. Given a sorted array Aonnelements and a\nquery element q, the goal is to either \fnd the index of qin the array, or state that it is not in the set.\nThe textbook method is binary search: compare the value of qto the value of the middle element of A,\nand recurse on the correct half of the array. After O(logn) probes, the method either \fnds qor correctly\nreturns that qis not in the array.\nBinary search optimizes for the worst case, but there are often times when we can do better. For\nexample, most bookstores have books arranged alphabetically by the authors' last name within a par-\nticular section. If we were looking for an Agatha Christie mystery, we would likely start our search near\nthe beginning of the section; if, instead, we were to look for a Dorothy Sayers novel, we'd start further\ntowards the end. We \frst look at the approximate location where we expect to \fnd the book, using our\nknowledge of the alphabet.\nHow can we generalize this approach? Let us assume we have a predictor hwhich, for every query, q,\nreturns our best guess for the position of qin the array. To use h, a natural approach is to \frst probe the\nlocation at h(q); ifqis not found there, we immediately know whether it is smaller or larger. Suppose q\nis larger than the element in A[h(q)] and the array is sorted in increasing order. We probe elements at\nh(q) + 2;h(q) + 4;h(q) + 8, and so on, until we \fnd an element larger than q(or we hit the end of the\narray). Then we apply binary search on the interval that's guaranteed to contain q(if it exists). The\nbookstore example uses interpolation search as a classi\fer; since 'C' is the third letter out of 26, we start\nour search for the Agatha Christie book about3=26\u001912% of the way through the Mysteries section.\nWhat is the cost of such an approach, in terms of the number of comparisons? Let t(q) be the true\nposition of qin the array (or the position of the largest element smaller than qif it is not in the array).\nSuppose the error of the classi\fer on qis\u0011q=jh(q)\u0000t(q)j. The cost of running the above algorithm\nstarting at h(q) is at most 2(log jh(q)\u0000t(q)j) = 2 log\u0011q.\nIf the queries qcome from a distribution, then the expected cost of the algorithm is:\n2Eqh\nlog (jh(q)\u0000t(q)j)i\n\u00142 logEqh\njh(q)\u0000t(q)ji\n= 2 log Eq[\u0011q];\nwhere the inequality follows by Jensen's inequality. This gives a guarantee on the performance of the\nalgorithm parametrized by the error of the predictor. In particular, even a classi\fer with an average\nerror ofO(polylogn) leads to an improvement in asymptotic performance. Moreover, since \u0011qis trivially\nbounded by n, even an exceptionally bad predictor cannot do much harm.\n1.2 Online algorithms: Ski Rental\nThe above example has the nice property that the use of predictions is essentially free. On the one\nhand, as the prediction error tends to zero, the running time approaches the best possible for this task\n(a constant). On the other hand, the error is naturally bounded by the number of elements, so even bad\npredictions will not asymptotically degrade the algorithm's performance. In other situations there can\nbe a more dramatic trade-o\u000b between the bene\ft of using the predictions and the cost incurred when\nthese predictions are wildly incorrect.\nConsider the SkiRental problem. At the beginning of the ski season, a new skier has the option to\nbuy skis for $b dollars, or to rent them every day for $1 per day. This is one of the simplest settings of\ndecision making under uncertainty | the skier does not know how many days she will ski, yet a simple\ndeterministic strategy will guarantee that she does not spend more than twice as much as she would have\nhad she known the future.\nThe algorithm achieving that bound rents skis for the \frst bdays, and then buys them on day b+ 1.\nIf the skier skis bor fewer days, she has spent the optimal amount. If, by chance, she stops skiing after\ndayb+ 1, she's spent at most $2 bin total, which is less than twice the optimal amount.\nSuppose the skier has access to a prediction h(d) of how many days she will ski. How should she\nuse this information? Let d\u0003be the true number of skiing days, and \u0011=jh(d)\u0000d\u0003jbe the error in the\nprediction. It is easy to verify that the algorithm that treats the prediction as truth (i.e. buying skis\non day 1 if h(d)>band renting daily otherwise) has a total cost of OPT +\u0011. We observe that in this\ncase, the use of predictions is not \\free.\" While the algorithm performs optimally when the prediction\nis correct, if the skier trusts the prediction and doesn't buy the skis when she should, she can spend\narbitrarily more money than if she applies the simple deterministic strategy above.\n2\n\nThere is, however, a simple \fx. Let \u00152[0;1] be a tunable parameter, and consider the following\nalgorithm. If h(d)>b, the skier buys on day d\u0015be, and otherwise, she buys on day db=\u0015e. A case analysis\nshows that the competitive ratio of this algorithm is bounded by:\n1 + min\u00101\n\u0015;\u0015+\u0011\n(1\u0000\u0015)OPT\u0011\n: (1)\nIn particular, as the error of the prediction drops to 0, the competitive ratio is no more than 1 + \u0015. On\nthe other hand, even for large errors, the ratio is never worse than 1 +1=\u0015. Note that \u0015= 1 recovers the\nalgorithm we described originally.\n1.3 Model\nThe two examples above outline the desiderata that we have for algorithms that use predictions. There\nare three properties that we highlight.\nFirst, we have isolated the inner workings of the predictor from the algorithm that uses the predictions,\ninstead simply abstracting the predictor as a function h. Our algorithms are accordingly not tied to a\nspeci\fc type of predictor. We can apply decision trees, neural networks, or any other approach to obtain\npredictions; any hwith low error su\u000eces.\nSecond, the goal is to tie the performance of the algorithms to the observed loss of the predictor. In\nthe setting of our examples, where we used competitive analysis, we further isolated two concepts. We\nwant the algorithms to be consistent ; that is, ideally their performance should recover that guaranteed\nby the o\u000fine optimal algorithm given an error-free prediction. Additionally, to capture the fact that\nmachine learning systems sometimes have very large errors, we want algorithms to be robust ; that is,\nideally their performance should not be worse than standard online algorithms that use no predictions\nwhatsoever.\nWhile ideal consistency and robustness may be quite challenging, we can loosen the goals using an\napproximation. Formally, we say that an algorithm is \u000b-consistent if its competitive ratio tends to \u000bas\nthe error in the predictions goes to 0, and \f-robust if the competitive ratio is bounded by \feven with\narbitrarily bad predictions.\nAs we saw in the ski-rental example, there is often a tension between consistency and robustness. A\npractitioner who has high con\fdence in the predictions may aim for high consistency and low robustness\nby choosing a small value of \u0015. On the other hand, a risk-averse decision maker may choose a higher\nvalue for\u0015, limiting the bene\ft of the predictions but also the additional cost when they turn out to be\nincorrect.\n2 Counting Sketches\nAnother example of a problem where predictions have been shown to boost performance is in the setting\nof counting sketches for data streams. We brie\ry describe the Count-Min sketch as an example of a\ncounting sketch. For simplicity, we assume items come in as a data stream one at a time; for example,\nthese could be URLs or IP addresses being accessed. Keeping a separate counter for each item may require\ntoo much space, and so we can instead use a sketch that requires less memory at the cost of obtaining\nonly an approximate count for each item, with some chance of failure for each item. The Count-Min\nsketch sets up a rectangular array of counters with rrows andccolumns. Each item hashes to one\ncounter location in each row; when an item passes in the stream, each of its counters is incremented.\nThe approximate count for an item is the minimum counter value associated with the item, which can\nonly yield an overestimate of the actual count for the item. Various results are known that show the\nerror for such a sketch can be small for appropriate values of randc. Note that if an item has at least\none counter where no other item hashes to it, the resulting approximate count will in fact be the exact\ncount. The idea behind the good performance of the Count-Min sketch is that for most items, there\nwill be at least one counter for which the item collides with very few other items, leading to an accurate\nestimate. In particular, for skewed data streams where item frequencies follow a Zip\fan distribution (or\nmore generally for heavy-tailed distributions), so much of the total count is based on a small number\nof items that the approach can be very accurate, as most collisions introduce only a small error in the\ncounter.\n3\n\nSuppose, however, that we had a predictor that could reasonably accurately predict which items were\nthe \\heavy hitters,\" that is the most frequent items. Since the idea of using a data sketch is to save\nspace, we do not want to use a separate counter for every item, but we may be willing to use space to\nkeep individual counters for each item that is predicted to have a high count. This assures accuracy for\ncorrectly predicted heavy hitters, which is often important, but also importantly it greatly reduces the\npossibility of a large error for an item with a small count, since removing potential heavy hitters from\nthe larger array greatly reduces the possibility that a small item will have all of its counters collide with\na large item.\nThe works (Hsu et al., 2019; Aamand et al., 2019) have formalized this high-level argument with\nprovable results for the Count-Min sketch and Count-Sketch for Zip\fan frequency distributions, showing\nthey can improve the space/performance tradeo\u000b over sketches without predictions. They also show this\nimprovement holds in practice. While we do not go into further details here, the example of counting\nsketches provides an intuitive approach for using predictions within algorithms and data structures: if\nthere are a limited set of problematic elements, such as outliers or high weight elements, that greatly\ne\u000bect performance when they are not known in advance, a predictor may allow these elements to be\nseparated out and correspondingly improve overall performance.\n3 Learned Bloom Filters\nAn early proposed example of how predictions from machine learning could improve data structures\nprovided a novel variation of the Bloom \flter (Kraska et al., 2018).\nTo start, let us brie\ry review standard Bloom \flters (Bloom, 1970; Broder and Mitzenmacher, 2004),\na data structure used to answer set membership queries using small space. A Bloom \flter for representing\na setS=fx1;x2;:::;xngofnelements corresponds to an array of mbits, and uses kindependent hash\nfunctionsh1;:::;hkwith rangef0;:::;m\u00001g. Note that the number of bits per item used by the Bloom\n\flter is given by m=n. Here we assume that these hash functions are perfectly random. Initially all array\nbits are 0. For each element x2S, the array bits hi(x) are set to 1 for 1 \u0014i\u0014k; a bit may be repeatedly\nset to 1. To check if an item yis inS, we check whether all hi(y) are set to 1. If not, then clearly yis\nnot a member of S. If allhi(y) are set to 1, we conclude that yis inS, although this may be a false\npositive . A Bloom \flter does not produce false negatives.\nLetybe an element such that y =2S, whereyis chosen independently of the hash functions used to\ncreate the \flter. Let \u001abe the fraction of bits set to 1 after the elements are hashed. Then the probability\nof a false positive is \u001ak. Now the expected value of \u001ais easily calculated, as the probability a speci\fc bit\nin the \flter stays 0 is just\n\u0012\n1\u00001\nm\u0013kn\n\u0019e\u0000kn=m:\nStandard techniques show the \u001ais close to its expectation with high probability, so using the expectation\nin place of\u001a, we see the false positive probability will be concentrated near\n(1\u0000e\u0000kn=m)k\nwhenkandm=n are constant. Choosing kappropriately (the optimal value for kis (m=n)\u0001ln 2), We see\nthe false positive probability for an element falls exponentially with m=n, the number of bits per item\nused in the \flter.\nThe idea of a learned Bloom \flter is to train a neural network or other machine learning algorithm\nto recognize the set S. We represent the algorithm by a function f, so that on input xthe algorithm\nreturns a value f(x) between 0 and 1. The algorithm ideally would return 1 for every element in the set\nand 0 for every element not in the set. If we had such a predictor, we would not need any data structure,\nas we could just use the function to represent the set. This is too much to expect in practice; instead,\nwe consider an algorithm that returns a value 0 \u0014f(x)\u00141. We might intuitively interpret f(x) as an\nestimate of the probability that xis an element from the set, although this interpretation is not necessary\nin what follows.\nWe can choose a threshold \u001c, and have the algorithm return that any element that satis\fes f(x)\u0015\u001c\nis in the set and otherwise it is not in the set. Indeed, if we choose \u001c= minx2Sf(x) then there will be\n4\n\nLearned Function\nBackup Filter\nInput\nPositivesNegatives\nPositives\nNegatives\nLearned Function\nBackup Filter\nPositives\nPositivesNegatives\nPositives\nNegatives\nInitial Filter\nInput\nNegatives\nFigure 1: The left side shows a learned Bloom \flter. Negatives from the learned function are checked against\nthe backup \flter to prevent false negatives. The right side shows the sandwiched learned Bloom \flter. An\ninitial \flter removes many true negatives from reaching the learned function, reducing the false positives\nfrom the learned function.\nno false negatives. But unless the predictor fis very good, it is likely that this value of \u001cwill lead to\ntoo many false positives.\nThe alternative approach we apply is to use the learned function fas a pre\flter, selecting a larger\nvalue of\u001cto cut down on false positives, and then using a standard Bloom \flter as a backup to prevent\nfalse negatives. The setup is shown in Figure 1. The initial learned function should correctly identify a\nsubstantial number of set elements, with a low false positive rate. The backup Bloom \flter then holds\nall the set elements that are incorrectly rejected by the learned function; to be clear, we determine these\nin advance and set up the backup Bloom \flter accordingly, which means the data set and the learned\nfunction must be \fxed before setting up the back Bloom \flter. The backup Bloom \flter again yields\nfalse positives, but prevents any false negatives.\nTo see how there might be gains from this approach, imagine a small learned function that correctly\nidenti\fes half of the original set. Then the backup Bloom \flter needs to only correct the erroneous false\nnegatives of the predictor, which means the backup \flter needs to represent only half the original set\nelements. Accordingly, the backup \flter could be roughly half the size of a Bloom \flter for the entire\nset with roughly the same false positive rate. If the learned function has a small enough representation,\nnamely less than half the size of a Bloom \flter for the entire set, then this combination will be a win in\nterms of the space versus false positive probability tradeo\u000b against a standard Bloom \flter. Empirical\nresults from Kraska et al. (2018) show that learned Bloom \flters can outperform standard Bloom \flters\nfor real-world data sets.\nWe emphasize that the threshold \u001cwill typically be chosen empirically, based on test queries, to\npredict the rate of false positives that will occur. This empirical evaluation of test data to determine the\nrelationship between \u001cand the rate of false positives we expect to \fnd in future queries depends on our\ntest queries being representative of the future; otherwise we may obtain a higher false positive rate over\nfuture queries than expected. A learned Bloom \flter thus requires di\u000berent additional assumptions than\na standard Bloom \flter in order to make statements about its performance. Further details are discussed\nin Mitzenmacher (2018).\nLearned Bloom \flters are relatively new; given the large number of variations of Bloom \flters, there\nmay be interesting improvements for and variations of learned Bloom \flters that will appear. Indeed, it is\nalready known that a \\sandwiched\" learned Bloom \flter that uses a learned \flter between two standard\nBloom \flters, also shown in Figure 1, can yield better performance (Mitzenmacher, 2018).\n5\n\n4 Caching with Predictions\nThe caching or paging problem is both a canonical example of online algorithms, and a problem which\nhas necessitated beyond worst-case analysis.\nRecall the problem setup. We are given a machine with a slow memory that can hold Npages, and\na fast memory with kslots. Page requests arrive one at a time, and must be served out of fast memory.\nIf the page is already in fast memory (cache), then a hitoccurs, and the operation is free. Otherwise,\nthere is a cache miss , the page is brought into fast memory, and one of the kexisting pages in the cache\nis evicted. The goal is to minimize the number of cache misses over the sequence of page requests.\n4.1 What to Predict?\nThe \frst question to address is to decide on the quantity that should be predicted by the machine learning\nsubsystem. We look for predictions that are both useful to the algorithm and e\u000eciently learnable. The\nlatter highlights the fact that predictions should be grounded in reality. Speci\fcally, we want to make\nsure that we only need polynomially many examples to learn a good predictor; formally, we ensure that\nthe function has a low sample complexity. As long as the family of functions specifying the predictor is\nrelatively simple and well behaved, this condition is satis\fed. However, an approach to fully predict the\nwhole instance would fail the test and be untenable.\nWhat are good candidates for predictions for the paging problem? One algorithm that minimizes the\nnumber of cache misses is the Furthest-In-Future (FIF) algorithm, also known as B\u0013 el\u0013 ady's rule (Belady,\n1966). This method always evicts the element that is latest to come back. In order to be able to emulate\nit online, a useful prediction to be made at the time of each request is the next arrival time of this\nelement. Formally, let next(t) be the next arrival time of the element that appeared at time t, andh(t)\ndenote the predicted time of the next arrival of this element.\nArmed with such a predictor a natural approach is to plug it into the Furthest-In-Future algorithm,\ninstead of the ground truth. We call this the PFIF for Predicted Furthest-In-Future.\nThe analysis of the FIF algorithm directly implies that if the predictor his perfect, that is h(t) =\nnext(t) for allt, then PFIF is optimal. In other words, PFIF is consistent. But is the approach robust?\nFirst we must de\fne an error metric. For a hypothesis hlet us de\fne \u0011(h) =P\ntjh(t)\u0000next(t)j:\nThe question we want to ask is how the competitive ratio of PFIF scales with \u0011(h). The \frst thing to\nobserve is that, as we de\fned it, the error grows with the input length. This is undesirable. Suppose\nwe duplicate a request sequence and the predictions. The competitive ratio would remain the same, but\nthe error de\fned above would double. We can normalize by the input length, but this, too, leads to\npathological cases. For instance, take any request sequence of length n, and repeat the last element n\ntimes. Since all of these extra requests would be cache hits, the performance of any algorithm remains the\nsame as well. However, if the last npredictions are perfect, then \u0011does not change, but error normalized\nby sequence length would decrease by a factor of two. Instead, we will normalize the error by the cost of\nthe optimum solution opt, which behaves correctly in both of these examples.\nWe show that the competitive ratio of PFIF grows linearly with the error. Formally, the competitive\nratio of PFIF is \n( \u0011(h)=opt).\nConsider a simple example with a cache of size 2, and three elements, a,b, andc. The true sequence\nwill bec;a;b;a;b;:::;a;b;c . The predictions will be correct for elements aandb, but the prediction for\ncwill always be at time 0. Hence \u0011(h) is the length of the sequence. In this case PFIF will keep cin the\ncache, and su\u000ber a cache miss almost every time. On the other hand, the optimal solution never misses\nonaandbonce they are in the cache, and has a constant number of misses overall. We note that while it\nmay be tempting to attempt to \fx this algorithm by disregarding elements whose predicted appearance\ntime has passed, this also has an \n( \u0011(h)=opt) competitive ratio.\n4.2 Marking Algorithms\nA natural question then is whether we can get competitive ratios with a more benign dependence on\n\u0011(h)=opt.\nTo proceed we introduce the Marking family of algorithms, \frst introduced by Fiat et al. (1991). These\nalgorithms proceed in phases. Every phase begins with every cache position \\unmarked.\" Whenever there\nis a cache miss, an unmarked element is evicted, and the new element is marked. When a cache hit occurs\n6\n\nthe element is marked as well. This continues until all elements in the cache are marked, at which point\nthe phase ends, and all of the marks are cleared. It is easy to show that any Marking algorithm is\nO(k)-competitive, where kis the cache size. Moreover, Fiat et al. (1991) show that if an algorithm evicts\na uniformly random unmarked element, then the expected competitive ratio is O(logk).\nTo prove a bound on the competitive ratio of the marking algorithm, we must get a lower bound on\nthe optimum. To do so, we partition elements that arrive during a phase into two categories: clean and\nstale. Clean elements in phase iare those that did not appear in phase i\u00001. In contrast, stale elements\nare those that were seen in the previous phase. Consider the following sequence with a cache of size 3.\na;a;b;a;b;c;|{z}\nphase 1b;b;c;b;d;|{z}\nphase 2a;a;d;c|{z}\nphase 3\nNote that each phase ends as soon as three distinct elements appear. In phase 2, elements bandcare\nstale (since they appeared in phase 1), and element dis clean. In contrast, in phase 3, dis stale (as is\nc), andais clean.\nLetCibe the number of clean elements in phase i. Consider the performance of any algorithm on\nthe clean elements. For some element j2Ci, if it is not present in the cache in the beginning of phase\ni, then it will incur a cache miss. On the other hand, if it is in the cache at the beginning of the phase,\nit must have stayed in the cache throughout phase i\u00001, even though it did not appear, thus e\u000bectively\nreducing the working cache size. This argument can be made precise, to show that\nOPT\u00151\n2X\niCi: (2)\nIn other words, the number of misses in any strategy is at least half the number of all clean elements.\nWe will relate the misses su\u000bered by our algorithm to the number of clean elements in each phase.\nIn order to utilize predictions in the marking framework, we modify the eviction strategy of the\nmarking algorithm. If the arriving element is clean, we evict the unmarked element predicted to appear\nfurthest in the future. If the arriving element is stale, we proceed as before, and evict a uniformly random\nunmarked element. We refer to this variant as PredictiveMarker .\nTheorem 1. PredictiveMarker has a competitive ratio of O\u0000\nlog\u0011(h)\nopt\u0001\n.\nTo prove the theorem, let us try to understand the reason behind cache misses incurred by the\nalgorithm. Suppose an element earrives and eis not in the cache, causing a cache miss. If the element\neis clean, Equation 2 tells us we can charge its eviction directly to opt. Suppose eis stale. By the\nde\fnition of stale elements, ewas in the cache when the phase began, thus it must have been evicted\nat some point between the beginning of the phase and its arrival. Let ev(e) denote the element whose\narrival caused the eviction of e. Eitherev(e) is clean, or it is another stale element, e1, whose arrival\ntime is earlier than e. In this case let us look why e1was evicted, i.e. ev(e1) =ev(ev(e)). By the same\nlogic, either ev(e1) is a clean element, or it is another stale element whose \frst arrival in this phase was\nearlier still. Therefore, repeatedly applying the evfunction to an element leads to a clean element whose\narrival set o\u000b this chain of events.\nTo get a bound on the competitive ratio, we ask how long can this chain be? This gives us the desired\nbound because each link in the chain represents a cache miss, each chain terminates with a clean element,\nand the number of clean elements is comparable to optby Equation 2. It is clear that the length of the\nchain depends on the eviction rule: if we always evict the element that is latest to arrive (FIF) then each\nchain is of length 1. If we do the reverse and evict the element that is next to arrive, then a chain can\ngrow to be \n( k) in length.\nWe \frst analyze the standard Marking algorithm which evicts elements uniformly at random.\nLemma 2. When evicting a random unmarked element, the expected length of each chain is O(logk).\nProof. We need only consider stale elements in every phase, and there may be as many as k\u00001 of them.\nOrder them by their arrival time, with e1arriving \frst, then e2, and so on. Denote by Lithe length of\nthe chain starting with element ei. We can write down the recurrence for eias:\nLi= 1 +1\nk\u0000ik\u00001X\nj=1Lj;\nwhich solves to L0= \u0002(logk) whenLk\u00001= 0.\n7\n\nOn the other hand, in PredictiveMarker , when a clean element arrives, we evict the element\npredicted to arrive furthest in the future. Let cbe a clean element that arrives at time tc,sdenote\nthe element we chose to evict, and tsbe the next time of arrival of s. Note that any stale element that\narrives between tcandtscannot increase the chain started at c. Therefore the only elements that can\ncontribute to the growth of the chain are those who arrive after time ts. But this is exactly in violation\nof our prediction, thus we can charge these cache misses to the error of the predictor. Let invh(s) denote\nthe set of elements that arrive after seven though they were predicted by hto arrive before. It is easy\nto extend Lemma 2 to show that the length of the chain starting with sis \u0002(loginvh(s)).\nTo complete the analysis, we need to bound the number of inversions as a function of the accuracy\nof the predictor. For any two permutations, the total number of inversions and the `1distance of the\nelements are known to always be within a factor of two by the celebrated Diaconis-Graham inequality (Di-\naconis and Graham, 1977). The latter is also exactly \u0011(h) decomposed across phases. Further, since log\nis a concave function, to maximize the total length of all chains, we should partition errors equally among\nthem. These two facts imply that the expected error of the above algorithm is O(log(\u0011(h)=opt)).\n4.3 Summary of Caching\nThe caching problem is illustrative of the power of algorithms with predictions and the care that must\nbe taken in designing them. We relied on the o\u000fine algorithm to identify the quantity that we wished\nto predict: the next appearance of every arriving element. We then proved that simply using this\nprediction as a proxy for the truth in the optimal o\u000fine algorithm allowed for pathological examples\nwhere the predictions led the algorithm astray. We then showed a di\u000berent algorithm which, by using\nthe predictions in a more careful manner, leads to a marked improvement in the competitive ratio over\nthe na \u0010ve way of using the predictor. In addition, we can show that even if the error is very large, we can\nguarantee performance within a constant factor of the standard marking algorithm. (See Exercise 2.)\nFinally, as Lykouris and Vassilvitskii (2018) showed, these gains are not just theoretical; even with o\u000b-\nthe-shelf prediction models PredictiveMarker consistently outperformed standard methods like the\nLeast Recently Used (LRU) policy.\n5 Scheduling with Predictions\nWe consider the problem of scheduling jobs on a single machine to minimize the total \row time. One\nof the key points is that if job times are known, the simple greedy algorithm of Shortest Remaining\nProcessing Time (SRPT) is optimal for this objective. Here we consider the potential of strategies such\nas SRPT in the context of scheduling and for queueing systems, where arrivals occur over time, but\nwhere the job times are only predicted, instead of known exactly.\n5.1 A Simple Model with Predictions\nWe start with a very simple example. Suppose we have njobsj1;:::;jn, each of which is either short\nor long. Short jobs require time sto process and long jobs require time ` > s to process. Jobs are all\navailable at time 0, and they are to be ordered and then processed sequentially. When the job times are\nknown, shortest job \frst minimizes the total waiting time over all jobs. If there are nsshort jobs and n`\nlong jobs, it is easy to check that the average waiting time is\n1\nn\u0012\nnsns\u00001\n2s+n`n`\u00001\n2`+n`nss\u0013\n:\nIf one has no information about the job times, then one might randomly order the jobs, in which case\nthe expected waiting time over all jobs is\n1\nn\u0012\nns\u0012ns\u00001\n2s+n`\n2`\u0013\n+n`\u0012ns\n2s+n`\u00001\n2`\u0013\u0013\n:\nFinally, suppose we have an algorithm that can predict a job's type. We assume short jobs are misclassi\fed\nas long jobs with some probability pand long jobs are misclassi\fed as short jobs with some probability\n8\n\nq. The natural approach would be to use shortest-predicted-job-\frst ; that is, we apply shortest-job-\frst\nbased on the predictions. Some case arithmetic shows that the expected waiting time is then\n1\nn\u0012\n(1\u0000p)ns\u0012(1\u0000p)(ns\u00001)\n2s+qn`\n2`\u0013\n+pns\u0012\n(1\u0000p)(ns\u00001)s+p(ns\u00001)\n2s+(1\u0000q)n`\n2`+qn``\u0013\n+ (1\u0000q)n`\u0012(1\u0000q)(n`\u00001)\n2`+q(n`\u00001)`+pns\n2s+ (1\u0000p)nss\u0013\n+qn`\u0012q(n`\u00001)\n2`+(1\u0000p)ns\n2s\u0013\u0013\n:\nWith these expressions, one can determine the gain from using predictions over randomly ordering jobs,\nand the loss from using predictions in place of exact information. Mitzenmacher (2019) suggests that\nwe might also consider the ratio between the expected waiting time with imperfect information and\nthe expected waiting time with perfect information. Mitzenmacher (2019) further suggests that for\nany algorithm where it makes sense to use predicted information in place of exact information one can\nconsider this ratio, which is there referred to as the price of misprediction, using the following de\fnition:\nDe\fnition 3. LetMA(Q;I) be the value of some measure (such as the expected waiting time) for a\nsystemQgiven information Iabout the system using algorithm A, and letMA(Q;P) be the value of\nthat metric using predicted information Pin place of Iwhen using algorithm A. Then the price of\nmisprediction is de\fned as MA(Q;I)=MA(Q;P).\nNotice here that (unlike many other uses of the \\price of\" language in algorithm analysis) the denom-\ninator is not necessarily an optimal algorithm, but the corresponding algorithm with exact information.\n(One could, of course, also compare against an optimal algorithm, as we have seen elsewhere in this\nchapter.)\n5.2 More General Job Service Times\nWe can consider a more general model where a job's actual and predicted time for service are real-\nvalued random variables. A natural probabilistic model is to suppose that the job sizes are governed by\nsome distribution, and correspondingly, for each possible service time x, the output of the predictor y\nis governed by some distribution that depends only on x. For example, we might model the prediction\nyas the value xwith some additional random noise, where the distribution of the noise might depend\nonx. Equivalently, we can describe jobs according to a density function g(x;y), giving the density for\na job that has service time xand predicted service time y. (For convenience we assume that g(x;y)\nis \\well-behaved\" throughout, so that it is continuous and all necessary derivatives exist; the analysis\ncan be readily modi\fed to handle point masses or other discontinuities in the distribution.) This model\nmakes some assumptions, most notably that each job corresponds to an independent instantiation of\nthis density function. However, it does seem sensible to model a machine learning algorithm that has\nbeen trained on lots of data as providing an estimated service time that corresponds to a conditional\ndistribution based on the actual service time, as is done here, as long as the future jobs we are going to\nsee can be thought of as coming from the same distribution as the jobs we used for training { that is,\nroughly speaking, if the future is going to look like the past.\nAgain, we assume that all jobs are given at time 0, and we simply order the jobs according to the\nshortest predicted job \frst. We let fs(x) =R1\ny=0g(x;y)dybe the corresponding density function for the\nservice time, and fp(y) =R1\nx=0g(x;y)dxbe the corresponding density function for the predicted service\ntime. If there are ntotal jobs, the expected waiting time for a job using shortest job \frst given full\ninformation is given by\n(n\u00001)Z1\nx=0fs(x)\u0012Zx\nz=0zfs(z)dz\u0013\ndx;\nwhile the expected waiting time for a job using predicted information using shortest predicted job \frst\nis given by\n(n\u00001)Z1\ny=0fp(y)\u0012Z1\nx=0Zy\nz=0xg(x;z)dzdx\u0013\ndy:\nIn words, in the full information case, given the service time for a job, we determine its expected waiting\ntime from each other job by taking the expectation conditioned on the other job having a smaller service\ntime. In the predicted information case, to compute the expected waiting time for a job given its predicted\n9\n\nservice time, we determine its expected waiting time from each other job by taking the expectation based\non the other job's actual service time, conditioned on the other job having a smaller predicted service\ntime than the original job.\nIn this case, the price of misprediction is given by the ratio\nR1\ny=0fp(y)\u0000R1\nx=0Ry\nz=0xg(x;z)dzdx\u0001\ndy\nR1\nx=0fs(x)\u0000Rx\nz=0zfs(z)dz\u0001\ndx; (3)\nwhile this is not the simplest of expressions, given g(x;y) it can be numerically evaluated. As an interest-\ning albeit not necessarily realistic example, suppose that jobs have service times that are exponentially\ndistributed with mean 1, but the service time prediction for a job with actual service time xis exponential\nwith mean x, so that the mean of the prediction is correct but the prediction itself can be signi\fcantly\ninaccurate. It can be shown that the price of misprediction in this case is 4 =3; this is given as Exercise 3.\n5.3 Scheduling Queues\nThis type of analysis can be extended, with some more involved work, to the case of queues. In the\nqueueing setting, we still just have one machine, but jobs both enter for service and leave after \fnishing\nservice over time, and we typically \frst look at the average time in the system when considering per-\nformance. For example, in standard queueing theory, the prototypical queue is known as the M/M/1\nqueue, where arrivals are a Poisson process of rate \u0015<1, service times are independently and identically\nexponentially distributed with mean 1, and there is a single server serving the customers. (The\\M\" in\nthe M/M/1 queue stands for memoryless.) One of the fundamental results in queueing theory is that the\nexpected time a customer spends waiting for and obtaining service in equilibrium in an M/M/1 queue\nwith First Come First Served (FCFS) scheduling (also called First In First Out (FIFO)) is given by\n1=(1\u0000\u0015). In this section we consider queues with Poisson arrivals but general service time distributions,\nnot just exponential.\nIf one knows the service time for a job, one can try to schedule better than FCFS. Shortest Job First\n(SJF) is the non-preemptive strategy that schedules the queued job with the shortest service time when\na job completes. Preemptive Shortest Job First (PSJF) acts similarly, but will preempt a running job if\nnew job with a smaller service time arrives. Shortest Remaining Processing Time (SRPT) will instead\nschedule and preempt jobs based on their remaining processing time instead of their service time.\nIn Mitzenmacher (2019), these strategies are considered in the setting where one has predicted service\ntimes instead of actual service times, leading to the strategies Shortest Predicted Job First (SPJF),\nPreemptive Shortest Predicted Job First (PSPJF), and Shortest Predicted Remaining Processing Time\n(SPRPT). Equations for all three strategies are provided under the assumption that there is a joint\ndensity distribution g(x;y) for jobs with service time xand predicted service time y, and that each job\nindependently yields predicted and actual service times from this distribution.\nFor example, comparing SJF and SPJF, we \frst set up the following notation. Let fs(x) =R1\ny=0g(x;y)dy\nandfp(y) =R1\nx=0g(x;y)dxbe the corresponding service and predicted service density functions. Finally,\nthe quantity \u001ax=\u0015Rx\nt=0tfs(t)dtis the rate of work entering the queue from jobs with service time at\nmostx, and\u001a0\ny=\u0015Ry\nt=0R1\nx=0g(x;t)xdxdt is the corresponding rate of work entering the queue from jobs\nwith predicted service at most y.\nFor SJF, it is known that W(x), the time spent waiting in the queue (not being served) for jobs with\nservice time x, in the steady state satis\fes\nE[W(x)] =\u001aE[S2]\n2E[S] (1\u0000\u001ax)2:\nNote that the waiting time for a job with service time xdepends on the general service distribution but\nalso speci\fcally on the work from jobs with service time at most x, as one might expect. The overall\nexpected time waiting in a queue, which we denote by E[W], is then simply\nE[W] =Z1\nx=0f(x)E[W(x)]dx:\nIt turns out that for SPJF, a similar analysis to that used to derive the performance equations for SJF\napplies. If we let W0(y) be the distribution of time spent waiting in the queue for a job with predicted\n10\n\n 0 2 4 6 8 10\n 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9average time in system\nalpha: prediction parameterSPJF (exp)\nPSPJF (exp)\nSPRPT (exp)\nSPJF (wei)\nPSPJF (wei)\nSPRPT (wei)Figure 2: Results from simulations at \u0015= 0:95 for exponential and Weibull distributions. A job with service\ntimexhas predicted service time uniform over [(1 \u0000\u000b)x;(1 +\u000b)x]. Performance degrades gracefully with \u000b.\nservice time yin the steady state, then\nE[W0(y)] =\u001aE[S2]\n2E[S]\u0000\n1\u0000\u001a0y\u00012:\nThe price of misprediction for the time waiting in queue for SJF/SPJF is then expressed as\nR1\ny=0fp(y)\n(1\u0000\u001a0y)2dy\nR1\nx=0fs(x)\n(1\u0000\u001ax)2dx:\nSimilar analyses can be done for PSJF/PSPJF and SRPT/SPRPT, although the resulting expressions\nare more complicated.\nSimulations show that even fairly weak predictors can provide signi\fcant performance gains for queues\nunder high load (that is, as \u0015gets close to 1), as FIFO queues relatively frequently stack short jobs behind\na long job, and this is a primary reason for long expected waiting times. Predictors that simply keep\nlong jobs behind short jobs most of the time therefore greatly improve the expected waiting time over\nall jobs. For example, a predictor with a multiplicative error can do quite well. Figure 2 provides an\nexample with \u0015= 0:95 and two types of service distributions: exponential with mean 1, and a Weibull\ndistribution with cumulative distribution 1 \u0000e\u0000p\n2x. (The Weibull distribution also has mean 1, but\nis more heavy-tailed, so longer jobs occur with higher probability.) The results are averaged over 1000\ntrials over a time period of 1 million time units, where each trial averages the time in system for jobs\nthat complete after the \frst 100 ;000 time units. A job with service time xhas a predicted service time\nthat is uniform over [(1 \u0000\u000b)x;(1 +\u000b)x] for a parameter \u000b; we try\u000b=j=10 for integer jfrom 0 to 9.\nWe observe that performance degrades gracefully with \u000b, and is much better than without predictions,\nwhere the steady state average time in the system is 20 for the exponential distribution and 58 for the\nWeibull distribution.\n6 Bibliographic Notes\nThe use of advice to assist online algorithms has been studied in the past (Boyar et al., 2016). But previous\nwork has focused on minimizing the number of advice bits from omniscient sources to achieve optimal or\nnear-optimal competitive ratios. The motivation of the work in online algorithms using learning-based\npredictions more closely mirrors the use of machine learning in practice, focusing on improvements in\nthe competitive ratio that can arise with realistic advice.\n11\n\nThe idea of learning in order to improve algorithms' performance, especially in the realm of online\nalgorithms, has appeared in some works in the past. For instance, Devanur and Hayes (2009) and Vee\net al. (2010) explored how predictions can be used to obtain nearly optimal online matching bounds,\nwhile Cole and Roughgarden (2014) and Medina and Vassilvitskii (2017) showed how to learn from\nsamples to maximize revenue in auction settings. In parallel Kraska et al. (2018) showed that these\nendeavors are not simply theoretical, building a system that used machine learning to improve retrieval\nspeed for index data structures.\nA formal model of learning with predictions, including the notions of \u000b-consistency and \f-robustness,\nwas presented by Lykouris and Vassilvitskii (2018). They were also the \frst ones to analyze this setting\nfor the caching problem. The analysis we presented here is due to Rohatgi (2020). Additionally Purohit\net al. (2018) demonstrated explicit trade-o\u000bs between these two concepts in the context of ski-rental and\nonline scheduling.\nA good general reference for queueing theory, including derivations for SJF and SRPT with exact\ninformation, is Harchol-Balter (2013).\nIn scheduling for queues, some works have looked at the e\u000bects of using imprecise information for\nload balancing in multiple queue settings. For example, Mitzenmacher (2000) considers using old load\ninformation to place jobs in the context of the power of two choices. For single queues, Wierman and\nNuyens (2008) look at variations of SRPT and SJF with inexact job sizes, bounding the performance gap\nbased on bounds on how inexact the estimates can be. Dell'Amico, Carra, and Michardi empirically study\nscheduling policies for queueing systems with estimated sizes (Dell'Amico et al., 2015). As mentioned,\nPurohit et al. (2018) speci\fcally looked at scheduling with predictions in the standard online setting,\nwhere they considered variants of shortest predicted processing time that yield good performance in\nterms of the competitive ratio, with the performance depending on the accuracy of the predictions.\nThe Count-Min Sketch (Cormode and Muthukrishnan, 2005) and the Count-Sketch (Charikar et al.,\n2002) are well known data structures for \fnding heavy hitters in data streams, and have found many\nadditional applications.\nBloom \flters were originally developed by Bloom (1970), and have proven useful for a number of\napplications (Broder and Mitzenmacher, 2004). Learned Bloom \flters were originally described by Kraska\net al. (2018), where other additional possible examples of using learning to improve index data structures\nwere proposed.\nReferences\nAamand, Anders, Indyk, Piotr, and Vakilian, Ali. 2019. (Learned) Frequency Estimation Algorithms\nunder Zip\fan Distribution. arXiv preprint arXiv:1908.05198 .\nBelady, Laszlo A. 1966. A study of replacement algorithms for a virtual-storage computer. IBM Systems\njournal ,5(2), 78{101.\nBloom, Burton H. 1970. Space/time trade-o\u000bs in hash coding with allowable errors. Communications of\nthe ACM ,13(7), 422{426.\nBoyar, Joan, Favrholdt, Lene M, Kudahl, Christian, Larsen, Kim S, and Mikkelsen, Jesper W. 2016.\nOnline algorithms with advice: a survey. Acm Sigact News ,47(3), 93{129.\nBroder, Andrei, and Mitzenmacher, Michael. 2004. Network applications of bloom \flters: A survey.\nInternet mathematics ,1(4), 485{509.\nCharikar, Moses, Chen, Kevin, and Farach-Colton, Martin. 2002. Finding frequent items in data streams.\nPages 693{703 of: International Colloquium on Automata, Languages, and Programming . Springer.\nCole, Richard, and Roughgarden, Tim. 2014. The sample complexity of revenue maximization. Pages\n243{252 of: Symposium on Theory of Computing, STOC 2014, New York, NY, USA, May 31 - June\n03, 2014 .\nCormode, Graham, and Muthukrishnan, Shan. 2005. An improved data stream summary: the count-min\nsketch and its applications. Journal of Algorithms ,55(1), 58{75.\n12\n\nDell'Amico, Matteo, Carra, Damiano, and Michiardi, Pietro. 2015. PSBS: Practical size-based scheduling.\nIEEE Transactions on Computers ,65(7), 2199{2212.\nDevanur, Nikhil R., and Hayes, Thomas P. 2009. The adwords problem: online keyword matching with\nbudgeted bidders under random permutations. Pages 71{78 of: Proceedings 10th ACM Conference on\nElectronic Commerce (EC-2009), Stanford, California, USA, July 6{10, 2009 .\nDiaconis, P., and Graham, R.L. 1977. Spearman's footrule as a measure of disarray. J. Roy. Statist. Soc.\nSer. B ,39(2), 262{268.\nFiat, Amos, Karp, Richard M., Luby, Michael, McGeoch, Lyle A., Sleator, Daniel Dominic, and Young,\nNeal E. 1991. Competitive Paging Algorithms. J. Algorithms ,12(4), 685{699.\nHarchol-Balter, Mor. 2013. Performance modeling and design of computer systems: queueing theory in\naction . Cambridge University Press.\nHsu, Chen-Yu, Indyk, Piotr, Katabi, Dina, and Vakilian, Ali. 2019. Learning-Based Frequency Estimation\nAlgorithms. In: 7th International Conference on Learning Representations .\nKraska, Tim, Beutel, Alex, Chi, Ed H, Dean, Je\u000brey, and Polyzotis, Neoklis. 2018. The case for learned\nindex structures. Pages 489{504 of: Proceedings of the 2018 International Conference on Management\nof Data . ACM.\nLykouris, Thodoris, and Vassilvitskii, Sergei. 2018. Competitive Caching with Machine Learned Advice.\nPages 3302{3311 of: Proceedings of the 35th International Conference on Machine Learning, ICML\n2018, Stockholmsm assan, Stockholm, Sweden, July 10-15, 2018 .\nMedina, Andres Mu~ noz, and Vassilvitskii, Sergei. 2017. Revenue Optimization with Approximate Bid\nPredictions. Pages 1858{1866 of: Advances in Neural Information Processing Systems 30: Annual\nConference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA,\nUSA.\nMitzenmacher, Michael. 2000. How useful is old information? IEEE Transactions on Parallel and\nDistributed Systems ,11(1), 6{20.\nMitzenmacher, Michael. 2018. A model for learned bloom \flters and optimizing by sandwiching. Pages\n464{473 of: Advances in Neural Information Processing Systems .\nMitzenmacher, Michael. 2019. Scheduling with Predictions and the Price of Misprediction. arXiv preprint\narXiv:1902.00732 .\nPurohit, Manish, Svitkina, Zoya, and Kumar, Ravi. 2018. Improving online algorithms via ml predictions.\nPages 9661{9670 of: Advances in Neural Information Processing Systems .\nRohatgi, Dhruv. 2020. Near-Optimal Bounds for Online Caching with Machine Learned Advice. In:\nSymposium on Discrete Algorithms (SODA) .\nVee, Erik, Vassilvitskii, Sergei, and Shanmugasundaram, Jayavel. 2010. Optimal online assignment with\nforecasts. Pages 109{118 of: Proceedings 11th ACM Conference on Electronic Commerce (EC-2010),\nCambridge, Massachusetts, USA, June 7-11, 2010 .\nWierman, Adam, and Nuyens, Misja. 2008. Scheduling despite inexact job-size information. Pages 25{36\nof:ACM SIGMETRICS Performance Evaluation Review , vol. 36. ACM.\n13\n\nExercises\n1. Prove the competitive ratio bound given in equation 1 for the ski rental with predictions algorithm.\n2. Consider the caching problem, and suppose we have two data-dependent eviction algorithms. For\nan inputx, one of them has competitive ratio a(x) while the other has ratio b(x). Develop an\nalgorithm that for every input xhas competitive ratio O(min(a(x);b(x))).\n3. Consider the setting of equation 3, where job sizes are exponentially distributed with mean 1, and\na job with mean service time xhas a predicted service time that is itself exponentially distributed\nwith mean x. Show via numerical evaluation or integration (perhaps using a software package for\nevaluating integrals) that the \\price of misprediction\" in this case is 4 =3.\n4. Write a simulation to study one of the problems discussed in the chapter. For example, you could\nwrite a simulation for a queue that uses predicted service times, and use it to explore how the\nservice time distribution and the quality of the prediction a\u000bect the average time spent waiting\nin the queue. Or you could implement an Count-Min sketch and simulate a predictor for heavy\nhitter elements, and use it to explore how the accuracy of the sketch improves with the quality of\nthe prediction or varies with how skewed the frequency distribution of items is. Your simulation\ncan use an actual learned function as a predictor, or you could use a synthetic prediction (by for\nexample adding noise in some speci\fed way to the ground truth to obtain a prediction).\n14",
  "textLength": 52280
}