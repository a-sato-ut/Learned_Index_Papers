{
  "paperId": "cc8e4ffc119566b210811e5ef973f45ca0fe1bd7",
  "title": "On Optimal Consistency-Robustness Trade-Off for Learning-Augmented Multi-Option Ski Rental",
  "pdfPath": "cc8e4ffc119566b210811e5ef973f45ca0fe1bd7.pdf",
  "text": "On Optimal Consistency-Robustness Trade-Off for\nLearning-Augmented Multi-Option Ski Rental\nYongho Shin, Changyeol Lee, and Hyung-Chan An∗\nDepartment of Computer Science, Yonsei University, Seoul, South Korea\nAbstract\nThe learning-augmented multi-option ski rental problem generalizes the classical ski rental prob-\nlem in two ways: the algorithm is provided with a prediction on the number of days we can ski, and\nthe ski rental options now come with a variety of rental periods and prices to choose from, unlike the\nclassical two-option setting. Subsequent to the initial study of the multi-option ski rental problem\n(without learning augmentation) due to Zhang, Poon, and Xu, significant progress has been made for\nthis problem recently in particular. The problem is very well understood when we relinquish one of\nthe two generalizations—for the learning-augmented classical ski rental problem, algorithms giving\nbest-possible trade-off between consistency and robustness exist; for the multi-option ski rental prob-\nlem without learning augmentation, deterministic/randomized algorithms giving the best-possible\ncompetitiveness have been found. However, in presence of both generalizations, there remained a\nhuge gap between the algorithmic and impossibility results. In fact, for randomized algorithms, we\ndid not have any nontrivial lower bounds on the consistency-robustness trade-off before.\nThis paper bridges this gap for both deterministic and randomized algorithms. For deterministic\nalgorithms, we present a best-possible algorithm that completely matches the known lower bound.\nFor randomized algorithms, we show the first nontrivial lower bound on the consistency-robustness\ntrade-off, and also present an improved randomized algorithm. Our algorithm matches our lower\nbound on robustness within a factor of e/2 when the consistency is at most 1 .086.\n1 Introduction\nThe learning-augmented multi-option ski rental problem is a generalization of classical ski rental. In\nthis problem, we are required to choose from multiple ski rental options so that we have a pair of skis\navailable as long as the ski resort is open. The number of days for which the resort will be open is not\nknown in advance, making this problem an online optimization, yet a prediction on the number of days\nis provided to the algorithm. With the help of this prediction, the algorithm has to ensure that a pair of\nskis is available by choosing from a multiple number of rental options that come with a variety of rental\nperiods and costs. Naturally, the objective is to minimize the total cost paid.\nThis problem generalizes the classical ski rental problem in two ways. Firstly, the algorithm is\nprovided with a prediction on the number of days, which does not exist in the classical setting. This pre-\ndiction is usually obtained via machine learning (ML). As such, while the prediction may be empirically\naccurate, there is no guarantee whatsoever on the quality of this prediction. The challenge is therefore in\nobtaining an algorithm that can effectively exploit the prediction when it is accurate while at the same\ntime guaranteeing a certain “minimum” level of performance even when the prediction is bad. Secondly,\nthere can be more than two ski rental options in this problem. In the classical two-option problem, skis\ncan be either rented for a single day or purchased for good. This problem lifts this restriction and allows\nrental options that rent a pair of skis for a finite number of days at a certain cost. These rental periods\nand costs are given as part of the input.\nThis problem is very well-understood when we relinquish one of these two generalizations. For\nthe learning-augmented classical (two-option) ski rental problem, Kumar, Purohit, and Svitkina [38]\ngave a best-possible deterministic algorithm for this problem. Learning-augmented algorithms are often\nevaluated by analyzing their consistency androbustness [34, 38]: we say an algorithm is χ-consistent and\nρ-robust if it produces a solution whose cost is within a factor of χwhen the given prediction is accurate\n∗Corresponding author: hyung-chan.an@yonsei.ac.kr\n1arXiv:2312.02547v1  [cs.DS]  5 Dec 2023\n\nand within a factor of ρno matter how bad the prediction is. Kumar et al.’s deterministic algorithm\nis (1 + λ)-consistent and (1 + 1 /λ)-robust, where λ∈(0,1) is a parameter taken by the algorithm;\nAngelopoulos, D¨ urr, Jin, Kamali, and Renault [5] showed that this is a best-possible for a deterministic\nalgorithm. For randomized algorithms, Kumar et al. [38] gave an algorithm that was later shown to be\nasymptotically best possible due to Wei and Zhang [43] and Bamas, Maggiori, and Svensson [11].\nFor the multi-option ski rental problem without learning augmentation, Zhang, Poon, and Xu [45]\ngave a deterministic 4-competitive algorithm, along with a matching lower bound on the competitiveness\nof deterministic algorithms. Their algorithm, however, relied on a mild assumption that the per-day\ncosts of the options are monotone with respect to rental period, which was later lifted by a general\n4-competitive algorithm of Anand, Ge, Kumar, and Panigrahi [3]. For randomized algorithms, Shin,\nLee, Lee, and An [40] gave a best-possible e-competitive algorithm; they also showed a matching lower\nbound on the competitive ratio.\nIn presence of both generalizations, however, the learning-augmented multi-option ski rental problem\nhad a huge gap between the known algorithmic results and the impossibility results, despite the significant\nrecent progress in this problem [3, 40]. On the algorithmic side, Anand et al. [3] gave the first deterministic\nalgorithm that is (1 + ε)-consistent and (5 + 5 /ε)-robust for ε >0, which was improved by Shin et al.’s\nmax(1 + 2 λ,4λ)-consistent (2 + 2 /λ)-robust deterministic algorithm [40] for λ∈[0,1]; they also gave a\nrandomized χ(λ)-consistent eλ/λ-robust algorithm for λ∈[0,1], where χ(λ) :={1+λ,\n(e+1)λ−lnλ−1,ifλ<1/e,\notherwise .\nOn the lower bounds side, however, the best bound known for deterministic algorithms was that, for any\nλ∈(0,1), a (1 + λ)-consistent algorithm cannot be better than (2 + λ+ 1/λ)-robust [40], leaving a huge\ngap between the best deterministic algorithm known. Our understanding was even poorer for randomized\nalgorithms: no nontrivial lower bounds on the consistency-robustness trade-off of randomized algorithms\nwere previously known.\nIn this paper, we bridge this gap in our understanding of the learning-augmented multi-option ski\nrental problem, for both deterministic and randomized algorithms. Following are the main results pre-\nsented in this paper.\n•We present a deterministic1\n(1−λ)-consistent1\nλ(1−λ)-robust algorithm for the problem, parameterized\nbyλ∈[0,1/2].1This consistency-robustness trade-off matches the lower bound of Shin et al. [40],\nshowing that our algorithm is a best-possible deterministic algorithm. Interestingly, despite being a\nbest-possible algorithm, both the algorithm and its analysis are significantly simpler than previous\nalgorithms [40].\n•We present a randomized χ(δ, s)-consistent ρ(δ, s)-robust algorithm parameterized by δ≥eand\ns≥0, where\nχ(δ, s) :=(\n1 +δ−s\nlnδ, s > 1,\nδ+1\nlnδδ−s+s−1\nlnδ,0≤s≤1,andρ(δ, s) :=δ\nelnδ·eδ−s\nδ−s.\nThis improves upon the best trade-off attained by previous randomized algorithms [40].\n•We provide the first nontrivial lower bound for randomized learning-augmented algorithms. We\nprove that no (1+ λ)-consistent algorithm can have a robustness better than(1+λ)2\n2λfor all λ∈(0,1).\nWe note that this bound is within a constant factor of our randomized algorithm’s performance\nwhen λis small, i.e., when the prediction is relatively well trusted.\nFigure 1 summarizes our results. The graph on the left shows the gap that existed between the best\nalgorithm and the best lower bound known for deterministic algorithms. Our new algorithm (red solid\nline) matches the previously known lower bound. For randomized algorithms, no nontrivial lower bounds\nwere previously known, and the gap between algorithms and lower bounds was rather wide (light+dark\ngray region). We present an improved randomized algorithm (blue solid line) and the first nontrivial\nlower bound (red dotted line) to significantly narrow this gap, shown as the dark gray region.\nSection 3 presents our best-possible deterministic algorithm. Our improved randomized algorithm\nis presented in Section 4. Section 5 then presents the first lower bound on the consistency-robustness\ntrade-off of randomized algorithms.\n1We note that, when λ= 1/2, the algorithm becomes 4-robust. Since this matches the lower bound on the competi-\ntiveness without learning augmentation, there is no hope that we can further improve the robustness of the algorithm and\ntherefore we do not consider any higher value of λ.\n2\n\nFigure 1: Overview of our results. (Left) The red solid line depicts the trade-off of our best-possible\ndeterministic algorithm, whereas the blue dotted line represent the trade-off of Shin et al.’s deterministic\nalgorithm [40]. (Right) The trade-off of our randomized algorithm is drawn as the blue solid line and\nthat of Shin et al.’s randomized algorithm is shown as the blue dashed line. The red dotted line depicts\nour lower bound on the trade-off. The red dash-dotted line indicates the trivial lower bound of e[40].\nThe dark gray region depicts the new gap between the algorithmic and impossibility bound, narrowing\nthe previous gap marked as the light+dark gray region.\nRelated Work Since the seminal work of Lykouris and Vassilvitskii [34], a tremendous amount of\nresearch on learning-augmented algorithms has surged. This algorithmic paradigm gives a sweet break-\nthrough for online optimization in particular; many online optimization problems suffer from pessimistic\nguarantees in the worst case since the full information of the input is not given while an irrevocable deci-\nsion should be made for each timestep. However, we can improve the performance guarantee when we are\ngiven a prediction on the future data. To name a few examples of successful augmentation of prediction\nto online optimization problems, it has been studied for caching/paging [34, 39, 6, 42, 20], weighted\npaging [22, 13], ski rental [18, 4], scheduling problems [38, 36, 43, 19, 8, 33], load balancing [29, 30],\nenergy minimization [10], matching problems [7, 31, 23], network design problems [44, 16], optimization\nproblems in metric spaces [6, 2, 32, 21, 9], and convex function chasing [14]. Learning-augmented algo-\nrithms have also been used to improve an algorithm’s running time [28, 15]. We refer interested readers\nto the survey of Mitzenmacher and Vassilvitskii [37] for a gentle introduction to learning-augmented\nalgorithms.\nThe ski rental problem is a canonical online optimization problem, and has been intensively studied.\nFor the classical two-option problem, Karlin, Manasse, Rudolph, and Sleator [26] gave a deterministic\n2-competitive algorithm and Karlin, Manasse, McGeoch, and Owicki [25] gave a randomized e/(e−1)-\ncompetitive algorithm. Both algorithms are best possible. Ski rental problems have been widely studied\nunder various settings including, for example, multi-shop ski rental [1, 41], snoopy caching [26, 25],\ndynamic TCP acknowledgment [24, 12], the parking permit problem [35], the Bahncard problem [17],\nand applications to online cloud file systems [27].\n2 Preliminaries\nIn the learning-augmented multi-option ski rental problem , we are given as input a set of options for\nrenting skis and a prediction bTon the number of days for which the ski resort will be open. For each\noption i, we are given ci∈Q>0anddi∈Z>0∪ {∞} : when we rent option i, we pay the cost of ciand\ncan use skis for didays from the day of renting. Renting for ∞days corresponds to buying. Without\nloss of generality, let us assume that ci≥1 for every option i; otherwise, we may multiply all ci’s by a\nsufficiently large number.\n3\n\nOn each day, we learn whether the ski resort is open for that day; if the resort is open, but we have\nno skis available for the day, we need to choose one of the rental options and pay for it. Let Tbe the\nnumber of days the resort is open; the objective is to have skis available for the entire Tdays at the\nminimum cost.\nFor every t∈Z>0, let OPT( t) denote an optimal solution (i.e., a minimum-cost sequence of rental\noptions) that covers tdays at minimum cost. Let opt( t) denote the total cost incurred by OPT( t). Note\nthat, by a standard dynamic programming, we can easily compute OPT( t) and opt( t) for any t. We\ntherefore assume in what follows that, for all t, OPT( t) and opt( t) are readily available whenever we\nwant to use it. Note that opt( t)≥1 for all t, due to our assumption that ci≥1 for every option i.\nA standard way of measuring the performance of learning-augmented algorithms is the consistency-\nrobustness trade-off analysis [34, 38]. We say that a learning-augmented algorithm for this problem is\nχ-consistent if the (expected) cost incurred by the algorithm is at most χ·opt(T) when the prediction\nis accurate (i.e., bT=T). On the other hand, we say that an algorithm is ρ-robust if the (expected) cost\nof the algorithm’s solution does not exceed ρ·opt(T) no matter how (in)accurate the prediction is (i.e.,\nfor any bT).\nWe introduce some definitions before we present our algorithms. Given two solutions S1andS2, we\nsay that we append S1toS2when we concatenate S1after S2. That is, the concatenated solution is\nto pay for each option in S2and then for each option in S1. (If an option appears a multiple number\nof times, we choose and pay for it each time it appears.) For all v≥1, let B( v) be a solution covering\nthe most number of days among those whose cost does not exceed v: i.e., B( v) := OPT( t⋆) where t⋆:=\nmax{t∈Z>0∪{∞} | opt(t)≤v}. We set B( v) as an empty solution if {t∈Z>0∪{∞} | opt(t)≤v}=∅.\nFinally, for simplicity of presentation, we will describe our algorithms as if they never terminate\nand keep choosing rental options; however, this is to be interpreted really as an algorithm that gets\nimmediately halted once the solution output by the algorithm so far covers the last day T.\n3 Best-Possible Deterministic Algorithm\nIn this section, we present our deterministic algorithm for the learning-augmented multi-option ski rental\nproblem. This algorithm is best possible for a deterministic algorithm; moreover, it admits a much simpler\nanalysis than previous algorithms.\nThe algorithm takes an input parameter λ∈[0,1/2]. Let us assume that λ >0; we will later discuss\nhow to handle λ= 0. We can assume without loss of generality that opt( bT) = (1 /λ)kfor some integer k\nsince, if (1 /λ)k−1<opt(bT)<(1/λ)k, we may multiply the cost of every option by(1/λ)k\nopt(bT).\nThe algorithm is very simple: the algorithm consists of several iterations , and in each iteration i(for\ni= 0,1,2, . . .), we append B((1 /λ)i) to our solution.\nTheorem 1. Forλ∈(0,1/2], the given algorithm is a deterministic1\n1−λ-consistent1\nλ(1−λ)-robust\nalgorithm.\nProof. Consistency. Suppose T=bT. Observe that the algorithm terminates at iteration k(or earlier)\nby the fact that opt( bT) = (1 /λ)kand the definition of B( ·). Moreover, in each iteration i, the algorithm\nincurs the cost of at most (1 /λ)ifrom the definition of B( ·). Hence, the total cost incurred by the\nalgorithm is at mostPk\ni=0(1/λ)i≤(1/λ)k+1\n(1/λ)−1,implying that the consistency ratio is at most(1/λ)\n(1/λ)−1=1\n1−λ\nas desired.\nRobustness. Suppose that opt( T) = (1 /λ)i⋆for some i⋆∈R≥0. Again by the definition of B( ·), note\nthat the algorithm terminates at iteration ⌈i⋆⌉(or earlier). Therefore, the total cost incurred by the\nalgorithm is at mostP⌈i⋆⌉\ni=0(1/λ)i≤(1/λ)⌈i⋆⌉+1\n(1/λ)−1≤(1/λ)i⋆+2\n(1/λ)−1,giving the desired robustness ratio since we\nhave(1/λ)2\n(1/λ)−1=1\nλ(1−λ).\nRemark 1. Forλ= 0, we can easily obtain a 1-consistent ∞-robust algorithm: consider an algorithm\nthat appends OPT(bT)at the very beginning of the execution.\nWe now show that our deterministic algorithm is best possible. Shin et al. [40] gave the following\nlower bound for deterministic algorithms.\nTheorem 2 ([40], Theorem 6) .For all constant c∈(1,2)andε > 0, the robustness ratio of any\ndeterministic c-consistent algorithm must be greater than c2/(c−1)−ε.\n4\n\nLet us substitute c:= 1/(1−λ) in Theorem 1. We can then easily see that1\nλ(1−λ)=c2\nc−1,showing\nthat our algorithm is the best possible.\n4 Improved Randomized Algorithm\nThis section is devoted to an improved randomized learning-augmented algorithm for the multi-option\nski rental problem. The algorithm takes two parameters δandsthat adjust the trade-off between the\nconsistency and robustness of the algorithm. We prove the following theorem in this section.\nTheorem 3. For all δ≥eands≥0, there exists a randomized χ(δ, s)-consistent ρ(δ, s)-robust algorithm\nfor the multi-option ski rental problem, where\nχ(δ, s) :=(\n1 +δ−s\nlnδ, s > 1,\nδ+1\nlnδδ−s+s−1\nlnδ,0≤s≤1,andρ(δ, s) :=δ\nelnδ·eδ−s\nδ−s.\nSimilarly to the previous section, let us assume without loss of generality that opt( bT) =δkfor some\ninteger k≥s+ 2. Recall that, for all v≥1, B( v) is a solution that covers the most number of days\namong those whose cost does not exceed v.\n4.1 Our algorithm\nAt the beginning, we first sample α∈[1, δ) from a distribution whose probability density function fis\ngiven by f(α) :=1\nαlnδ.Note that findeed defines a probability distribution.\nThe algorithm consists of three phases. In the first phase, the algorithm runs kiterations named\niteration ifori= 0,1, . . . , k −1. In iteration i, ifαδi< δk−s, we append B( αδi) and continue to the\nnext iteration; if αδi≥δk−s, we immediately proceed to the second phase without appending anything.\nIn iteration k−1, ifαδk−1< δk−s, we append B( αδk−1) and proceed to the third phase (skipping the\nsecond one); if αδk−1≥δk−s, we proceed to the second phase without appending anything.\nIn the second phase, we append OPT( bT) and proceed to the third phase.\nThe third phase also consists of iterations. They are named iteration ifori=k, k+ 1, . . ., starting\nfrom k. In each iteration iof this phase, we append B( αδi).\nWe have also provided a pseudocode of our algorithm. See Algorithm 1.\nAlgorithm 1: Our randomized algorithm\n▷initialization\nsample α∈[1, δ) from p.d.f. f(α) := 1 /(αlnδ)\n▷first phase\nfori= 0,1, . . . , k −2do\nifαδi< δk−sthen\nappend B( αδi)\nelse\nproceed to the second phase\ni←k−1\nifαδi< δk−sthen\nappend B( αδi)\nproceed to the third phase\nelse\nproceed to the second phase\n▷second phase\nappend OPT( bT)\nproceed to the third phase\n▷third phase\nfori=k, k+ 1, . . .do\nappend B( αδi)\n5\n\n4.2 Analysis\nWe now prove Theorem 3. We begin with the consistency analysis of the algorithm, followed by the\nrobustness analysis.\nConsistency Suppose that T=bT.\nCase 1. s > 1.We will examine this first case in much more detail compared to the following\ncases. Let r:=⌊k−s⌋. Observe that, by the choice of kands, we have 2 ≤r≤k−2. By definition of\nr, we also have δk−s−r∈[1, δ). Let us first consider the execution of the algorithm when α < δk−s−r.\nFor each iteration i= 0, . . . , r , (provided that the algorithm enters this iteration without terminating\nearlier) the algorithm appends B( αδi) since αδi≤αδr< δk−s. When the algorithm enters iteration\n(r+ 1), which is still in the first phase because r≤k−2, the algorithm proceeds to the second phase\nsince αδr+1≥δr+1≥δk−s. Then it will append OPT( bT) during the second phase. Appending OPT( bT)\nby itself is sufficient to cover T=bTdays, and the algorithm terminates.\nOn the other hand, let us now consider the execution of the algorithm when α≥δk−s−r. In it-\neration i= 0, . . . , r −1, the algorithm appends B( αδi) since αδi< δr≤δk−s, unless the algorithm\nterminates earlier than that. When the algorithm enters iteration r, since αδr≥δk−s, it proceeds to the\nsecond phase, appends OPT( bT), and terminate there.\nTo sum, the algorithm appends B( αδi) in iterations 0 , . . . , r −1 unless it terminated earlier than the\niteration; in iteration r, the algorithm may append B( αδi) only if α < δk−s−r; the algorithm leaves the\nfirst phase after iteration r−1 orr, so no other iterations of the first phase are entered; the algorithm\nmay append OPT( bT) during the second phase; it never enters the third phase. Therefore, the total\nexpected cost incurred by the algorithm is bounded from above by\nZδ\n1r−1X\ni=0αδif(α)dα+Zδk−s−r\n1αδrf(α)dα+δk=δr−1\nlnδ+δk−s−δr\nlnδ+δk(1)\n≤\u0012\n1 +δ−s\nlnδ\u0013\nopt(bT).\nCase 2. 0≤s≤1.Note that k≥2 by the choice of k, and δ1−s∈[1, δ]. Let us consider the\nexecution of the algorithm when α < δ1−s. For each iteration i= 0, . . . , k −1, the algorithm appends\nB(αδi) since αδi< δk−s. The algorithm then proceeds to the third phase, appends B( αδk), and then\nterminates (unless it terminated even earlier).\nLet us now consider the execution when α≥δ1−s. For each iteration i= 0, . . . , k −2, the algorithm\nappends B( αδi) since αδi< δk−1≤δk−s. In iteration ( k−1), since αδk−1≥δk−s, the algorithm\nproceeds to the second phase, appends OPT( bT), and terminates (unless it terminated even earlier).\nWe can thus conclude that the algorithm in expectation incurs the cost of at most\nZδ\n1k−2X\ni=0αδif(α)dα+Zδ1−s\n1(αδk−1+αδk)f(α)dα+Zδ\nδ1−sδkf(α)dα\n=δk−1−1\nlnδ+(δk−1+δk)(δ1−s−1)\nlnδ+sδk(2)\n≤\u0012δ+ 1\nlnδδ−s+s−1\nlnδ\u0013\nopt(bT).\nRobustness Let opt( T) =δi⋆for some i⋆∈R≥0and let r:=⌊k−s⌋. As we did in the consistency\nanalysis, we will describe the execution of the algorithm as if it terminates only after appending a\n(sub)solution covering Tdays or more, in favor of the simplicity of analysis. Note that the algorithm\nmay terminate earlier than that, but this still gives a valid upper bound on the algorithm’s output cost.\nCase 1. s= 0ori⋆< r−1.We claim that, in this case, the algorithm never enters the second\nphase. If s= 0, note that αδi< δk−salways holds for every i= 0, . . . , k −1 since α < δ . Ifi⋆< r−1,\nobserve that ⌊i⋆⌋+ 1≤r−1≤k−1, implying that iteration ( ⌊i⋆⌋+ 1) is in the first phase.2For\n2When we say an iteration xis in the first phase, we are not implying that the particular iteration is actually entered\nby the algorithm at some point of its execution: we are simply stating that x∈ {0, . . . , k −1}. Recall that the iterations\nin the first phase are named 0 , . . . , k −1.\n6\n\neach iteration i= 0, . . . ,⌊i⋆⌋+ 1, we have αδi≤αδr−1< δk−s, and hence, the algorithm appends\nB(αδi) instead of proceeding to the second phase. Observe that, after iteration ( ⌊i⋆⌋+ 1), the algorithm\nterminates since αδ⌊i⋆⌋+1≥δi⋆.\nFor each iteration i= 0, . . . ,⌊i⋆⌋, the algorithm appends B( αδi). In iteration ⌊i⋆⌋, ifα≥δi⋆−⌊i⋆⌋, the\nalgorithm terminates since it appends B( αδ⌊i⋆⌋) with αδ⌊i⋆⌋≥δi⋆. On the other hand, if α < δi⋆−⌊i⋆⌋, the\nalgorithm enters the next iteration, appends B( αδ⌊i⋆⌋+1) and terminates. Therefore, the total expected\ncost is bounded by\nZδ\n1⌊i⋆⌋X\ni=0αδif(α)dα+Zδi⋆−⌊i⋆⌋\n1αδ⌊i⋆⌋+1f(α)dα (3)\n=δ⌊i⋆⌋+1−1\nlnδ+δi⋆−⌊i⋆⌋−1\nlnδ·δ⌊i⋆⌋+1≤δ\nlnδopt(T)≤ρ(δ, s) opt( T),\nwhere the last inequality holds since ez≥ezfor all z. (By choosing z:=δ−s,eδ−s\neδ−s≥1.)\nIn what follows, let us assume that s >0. Observe that 2 ≤r≤k−1.\nCase 2. r−1≤i⋆< r.Remark that r≤k−1. Let m:= min( i⋆+ 1, k−s). Note that m≥r\nsince i⋆≥r−1 and k−s≥r, and m−r≤i⋆−r+ 1<1. Observe that ⌊i⋆⌋=r−1.\nLet us first consider the execution when α < δm−r. For each iteration i= 0, . . . , r of the first phase,\nthe algorithm appends B( αδi) since αδi< δm≤δk−s. The algorithm terminates after iteration rsince\ni⋆< r.\nForδm−r≤α < δi⋆−r+1, observe that this case is nonempty only when k−s < i⋆+ 1 (and hence\nm−r=k−s−r < i⋆−r+ 1). For each iteration i= 0, . . . , r −1 of the first phase, the algorithm\nappends B( αδi). On the other hand, when it enters iteration r, it now proceeds to the second phase\nsince αδr≥δm=δk−s. It then appends OPT( bT) and terminates.\nFinally, if α≥δi⋆−r+1, the algorithm appends B( αδi) in iterations 1 , . . . , r −1. Moreover, it terminates\nin iteration ( r−1) since αδr−1≥δi⋆.\nWe can thus derive that the total expected cost incurred by the algorithm is bounded from above by\nZδ\n1r−1X\ni=0αδif(α)dα+Zδm−r\n1αδrf(α)dα+Zδi⋆−r+1\nδm−rδkf(α)dα\n=δr−1\nlnδ+δm−δr\nlnδ+ (i⋆+ 1−m)δk≤δm\nlnδ+ (i⋆+ 1−m)δk. (4)\nIfi⋆+ 1≤k−s(and hence m=i⋆+ 1), the above equation can further be bounded by ρ(δ, s)·opt(T)\nsince ez≥ezfor all z:=δ−s.\nNow let us assume i⋆+ 1> k−s. Note that the right-hand side of (4) can be written as follows:\n\u0012δk−s−i⋆\nlnδ+ (i⋆+ 1−k+s)δk−i⋆\u0013\nopt(T).\nLet us substitute z:=k−s−i⋆. The following technical lemma then completes the proof of this case.\nLemma 1. Given fixed δ≥eands >0, letg(z) :=δz\nlnδ+ (1−z)δz+sbe a function of z. We then have\ng(z)≤ρ(δ, s)for every z.\nProof. From the derivative g′(z) =δz−δz+s+ (1−z)δz+slnδ=δz(1−δs+δslnδ−zδslnδ), we can see\nthat the maximum of gis attained at z=z0:= 1 +δ−s−1\nlnδwith valueδ\nelnδ·eδ−s\nδ−s=ρ(δ, s), completing\nthe proof of the lemma. Note that we have g′(z)≥0 for all z < z 0andg′(z)≤0 for all z > z 0since\nδz>0 and z7→1−δs+δslnδ−zδslnδis a decreasing function of z.\nCase 3. r≤i⋆< k−s.Recall that r:=⌊k−s⌋and hence r≤k−1. For each iteration\ni= 0,1, . . . , r −1 of the first phase, the algorithm appends B( αδi) and enters the next iteration since\nαδi< δr≤δi⋆< δk−s.\nIn iteration r, let us first consider the execution when δi⋆−r≤α < δk−s−r. The algorithm appends\nB(αδr) and terminates after this iteration since δi⋆≤αδr< δk−s. When α≥δk−s−r, it proceeds to the\n7\n\nsecond phase after this iteration since αδr≥δk−s; the algorithm then appends OPT( bT) and terminates\nin the second phase.\nLastly when α < δi⋆−r, the algorithm appends B( αδr) in iteration rsince i⋆< k−s. The behavior\nof the algorithm from this point differs depending on the value of s. Ifs > 1, we have r≤k−2,\nimplying that the algorithm enters iteration ( r+ 1) which is still in the first phase. Observe that the\nalgorithm then proceeds to the second phase without appending in this iteration since αδr+1≥δk−s.\nThe algorithm then appends OPT( bT) and terminates in the second phase. On the other hand, if s≤1,\nthis implies r=k−1, showing that iteration ris the last iteration of the first phase and therefore the\nalgorithm directly proceeds to the third phase, iteration k. In iteration k, the algorithm appends B( αδk)\nand terminates since k > k−s > i⋆.\nLet us now bound the robustness. If s >1, we have the following upper bound on the total expected\ncost:\nZδ\n1r−1X\ni=0αδif(α)dα+Zδi⋆−r\n1(αδr+δk)f(α)dα+Zδk−s−r\nδi⋆−rαδrf(α)dα+Zδ\nδk−s−rδkf(α)dα\n=δr−1\nlnδ+Zδk−s−r\n1αδrf(α)dα+ Zδi⋆−r\n1f(α)dα+Zδ\nδk−s−rf(α)dα!\nδk\n=δr−1\nlnδ+δk−s−δr\nlnδ+ (i⋆+ 1−k+s)δk≤\u0012δk−s−i⋆\nlnδ+ (1−(k−s−i⋆))δk−i⋆\u0013\nopt(T)\n≤ρ(δ, s) opt( T),\nwhere the last inequality comes from Lemma 1 by letting z:=k−s−i⋆.\nIfs≤1, recall that r=k−1. We then have\nZδ\n1k−2X\ni=0αδif(α)dα+Zδi⋆−k+1\n1(αδk−1+αδk)f(α)dα+Zδ1−s\nδi⋆−k+1αδk−1f(α)dα+Zδ\nδ1−sδkf(α)dα\n=δk−1−1\nlnδ+Zδ1−s\n1αδk−1f(α)dα+Zδi⋆−k+1\n1αδkf(α)dα+Zδ\nδ1−sδkf(α)dα\n=δk−1−1\nlnδ+δk−s−δk−1\nlnδ+δi⋆+1−δk\nlnδ+sδk≤\u0012δ\nlnδ+δ−s−1\nlnδδk−i⋆+sδk−i⋆\u0013\nopt(T)\n≤\u0012δ1−s\nlnδ+sδ\u0013\nopt(T),\nwhere the last inequality holds from the fact that i⋆≥r=k−1. We now claim\nδ1−s\nlnδ+sδ≤ρ(δ, s) (5)\nfor all δ≥eands >0, which would complete the proof.\nLemma 2. For every z >0, we have g(z) :=ez−1−z2+zlnz≥0.\nProof. Remark that the derivative and the second derivative of gis given as follows: g′(z) :=ez−1−2z+\nlnz+ 1 and g′′(z) :=ez−1+ 1/z−2.Note that, for all z >0,g′′(z) =ez−1+ 1/z−2≥z+ 1/z−2≥0,\nimplying that g′is nondecreasing over z >0. Observe that g′(1) = 0. Hence, the minimum value of gis\nattained at z= 1, where g(1) = 0.\nRecall that ρ(δ, s) =δ\nelnδ·eδ−s\nδ−s. Dividing both sides of (5) byδ\nδ−slnδyields δ−2s+sδ−slnδ≤eδ−s−1.\nThis inequality holds from Lemma 2 by letting z:=δ−s.\nCase 4. k−s≤i⋆< k.In this case, we will re-use the argument from the consistency analysis.\nThe only difference of the current case from the consistency analysis is that Tis not equal to bT. In\nfact, we have T <bT. However, the only place where the fact T=bTwas used in the previous analysis\nis the observation that appending OPT( bT) or B( αδk) causes the algorithm to terminate. Since T <bT,\nappending one of these two (sub)solutions causes the algorithm to terminate in this case, too, and the\nupper bounds (1) and (2) continue to hold.\n8\n\nIfs >1, (1) implies that the total expected cost incurred by the algorithm is at most\nδr−1\nlnδ+δk−s−δr\nlnδ+δk≤\u00121\nlnδ+δs\u0013\nδk−s≤ρ(δ, s) opt( T),\nwhere the last inequality follows from i⋆≥k−sand Lemma 3 below.\nIfs≤1, we have from (2) that the total expected cost is at most\nδk−1−1\nlnδ+(δk−1+δk)(δ1−s−1)\nlnδ+sδk≤\u0012δ+ 1\nlnδ+sδs−δs\nlnδ\u0013\nδk−s≤ρ(δ, s) opt( T),\nwhere the last inequality follows from i⋆≥k−sand Lemma 4 below.\nLemma 3. For any δ≥eands∈R, we have1\nlnδ+δs≤δ\nelnδ·eδ−s\nδ−s.\nProof. By multiplying both sides by eδ−slnδ >0 and substituting z:=δ−s, it suffices to show that\nδez−ez≥elnδ.By taking the partial derivative of the left-hand side with respect to z, we can infer\nthat the left-hand side is minimized at z= ln( e/δ) = 1−lnδ.\nLemma 4. For any δ≥eand0≤s≤1, we haveδ+1\nlnδ+sδs−δs\nlnδ≤δ\nelnδ·eδ−s\nδ−s\nProof. By multiplying both sides by eδ−slnδ >0 and substituting z:=δ−s(where s=−lnz/lnδ), it\nis sufficient to prove that, for every z∈[1/δ,1],g(z) :=δez−e(δ+ 1)z+elnz+e≥0.Observe first\nthatg(1) = δe−e(δ+ 1) + e= 0 and\ng(1/δ) =δe1/δ−e(1 + 1 /δ) +eln(1/δ) +e=δe1/δ−e/δ+eln(1/δ).\nRemark that, by Lemma 2 with z:= 1/δ, we have1\nδeg(1/δ)≥0.\nLet us now consider the partial derivative of gwith respect to z:∂g\n∂z=δez+e\nz−e(δ+1).Since ezand\ne/zare both strictly convex over z >0, we can see that ∂g/∂z is also strictly convex over z >0. Note\nalso that∂g\n∂z\f\f\nz=1=δe+e−e(δ+ 1) = 0 .We can thus conclude that ghas at most two solutions where\none is z= 1. Moreover, as we have g(1/δ)≥0, we can see that g(z)≥0 for all z∈[1/δ,1], completing\nthe proof.\nCase 5. i⋆≥k.Recall that our assumption is that the algorithm terminates only after appending\na (sub)solution covering Tdays or more. When i⋆> k, the algorithm never appends such a solution\nduring the first and second phases, and the algorithm does proceed to the third phase. This may not\nbe the case when i⋆=kfor a technical reason, but for the analysis’s sake, we will just assume that\nthe algorithm always proceeds to the third phase without getting prematurely terminated. This may\noverestimate the cost incurred by the algorithm, but still gives a valid upper bound.\nWe will bound the expected cost incurred during the first and second phases, separately from the cost\nincurred during the third one. In fact, we will re-use (1) and (2) again, as we did in the previous case.\nWhen s >1, we derived (1) based on the observation that the algorithm always proceeds to the second\nphase and terminates after this phase. Therefore, (1) can be used as is to bound the expected cost of\nthe first two phases. On the other hand, when s≤1, the derivation of (2) was based on the observation\nthat the algorithm terminates after either the second phase or the third phase. As such, we will slightly\nmodify (2) to remove the contribution from the third phase: the expected cost incurred during the first\ntwo phases when s≤1 is at most\nZδ\n1k−2X\ni=0αδif(α)dα+Zδ1−s\n1αδk−1f(α)dα+Zδ\nδ1−sδkf(α)dα≤δk−s\nlnδ+sδk. (6)\nNow let us focus on the expected cost the algorithm incurs during the third phase. A similar argument\nto Case 1 can be applied here. Consider how the algorithm behaves when it enters iteration ⌊i⋆⌋. If\nαδ⌊i⋆⌋< δi⋆(orα < δi⋆−⌊i⋆⌋), the algorithm further enters iteration ( ⌊i⋆⌋+ 1) and terminates after\nit. However, if αδ⌊i⋆⌋≥δi⋆(orα≥δi⋆−⌊i⋆⌋), the algorithm terminates after iteration ⌊i⋆⌋. Since\nthe algorithm appends B( αδi) for iteration iin the third phase, the contribution of the third phase is\nbounded from above by\nZδ\n1⌊i⋆⌋X\ni=kαδif(α)dα+Zδi⋆−⌊i⋆⌋\n1αδ⌊i⋆⌋+1f(α)dα=δi⋆+1−δk\nlnδ. (7)\n9\n\nLet us combine these bounds. If s >1, (1) and (7) yield the following upper bound on the total\nexpected cost:\nδk−s\nlnδ+δk+δi⋆+1−δk\nlnδ=δi⋆+1+ (δ−s+ lnδ−1)δk\nlnδ≤δ+δ−s+ lnδ−1\nlnδopt(T)\n=δ+δ−s+ min( s,1) lnδ−1\nlnδopt(T),\nwhere the inequality holds since δ≥eandi⋆≥k, and the last equality follows from s >1. On the other\nhand, if 0 ≤s≤1, (6) and (7) yield the following bound:\nδk−s\nlnδ+sδk+δi⋆+1−δk\nlnδ=δi⋆+1+ (δ−s+slnδ−1)δk\nlnδ≤δ+δ−s+slnδ−1\nlnδopt(T)\n=δ+δ−s+ min( s,1) lnδ−1\nlnδopt(T),\nwhere the inequality holds since δ−s+slnδ−1 =e−slnδ−(−slnδ+ 1)≥0 and i⋆≥k.\nThe following lemma completes the proof for this case.\nLemma 5. For every δ≥eands≥0, we haveδ+δ−s+min( s,1) lnδ−1\nlnδ≤δ\nelnδ·eδ−s\nδ−s.\nProof. Consider both sides of the inequality as a function of sby treating δas a fixed constant. It is\nthen easy to see that the left-hand side is decreasing over s≥1. The right-hand side on the other hand\nis increasing over s≥1 since x7→ex\nxis a decreasing function of xfor 0 < x < 1, and s7→δ−sis a\ndecreasing function of sfors≥1. Note that δ−s∈(0,1) for all s≥1. Therefore, it suffices to prove\nthe given inequality only for 0 ≤s≤1. Under this condition, the inequality to prove can be rewritten\nasδ+δ−s+slnδ−1\nlnδ≤δ\nelnδ·eδ−s\nδ−sby removing the min operator.\nBy multiplying both sides with eδ−slnδ >0 and letting z:=δ−s(and therefore s=−lnz/lnδ), we\ncan rearrange this inequality as g(z) :=δez+ezlnz−ez2−e(δ−1)z≥0, which we need to show for all\nz∈[1/δ,1]. We will show this inequality instead for all z∈(0,1].\nThe first and second derivative of g, which we treat as a function of z, are: g′(z) =δez+elnz−\n2ez+ (2−δ)eandg′′(z) =δez+e/z−2e. Observe that g′′(z) =δez+e/z−2e≥e(ez+ 1/z−2)≥\ne(z+ 1/z−2)≥0,where the first inequality follows from δ≥e. This implies that g′is nondecreasing\nover (0 ,1]. Note that g′(1) = 0, and hence g′(z)≤0 for z∈(0,1]. This shows that the minimum of gis\nattained at z= 1. Observe that g(1) = 0.\n4.3 Choice of Parameters and Comparison to Lower Bound\nFigure 2 shows the trade-off between consistency and robustness offered by Theorem 3 as δandsvaries.\nEach choice of the two parameters is shown as a point in the picture. Although these points form a region\nin the graph, we would naturally want to use only those choices of parameters that result in points on\nthe boundary, shown as the blue solid line, which are pareto-optimal points.\nWe now compare the trade-off given by our algorithm against the lower bound presented in Section 5.\nTo this end, we first obtain an alternative parametrization of the algorithm using a single parameter when\nthe consistency is small.\nTheorem 4. Letλ⋆≈0.0861 be the positive solution ofλ+1\n2·ln2λ\nλ+1=−1.Then, for λ∈(0, λ⋆), there\nexists a randomized (1 +λ)-consistente(λ+1)2\n4λ-robust algorithm for the learning-augmented multi-option\nski rental problem.\nProof. Let us choose δ:=e2/(λ+1)ands:=−λ+1\n2·ln2λ\nλ+1>1. It is easy to verify that Theorem 3 gives\nχ(δ, s) = 1 + λandρ(δ, s) =e(λ+1)2\n4λ.\nNote that, compared to the lower bound given by Theorem 5, the algorithm’s robustness is within a\nfactor of e/2.\n5 Lower Bound for Randomized Algorithms\nIn this section, we present the first nontrivial lower bound on the trade-off between consistency and\nrobustness of randomized algorithms for the learning-augmented multi-option ski rental problem. The\nfollowing theorem is to be shown.\n10\n\nFigure 2: The trade-off between consistency and robustness as δandsvaries, shown as the yellow region.\nThe blue solid line is the pareto-optimal points.\nTheorem 5. For all constant λ∈(0,1)andε∈(0,1), any (1 +λ)-consistent algorithm must have the\nrobustness ratio greater than max{(1+λ)2\n2λ, e} −ε.\nThe trivial bound of einherits from the lower bound on the competitive ratio (see Theorem 5 of\n[40]). Therefore, it suffices to prove that any (1 + λ)-consistent algorithm must have the robustness ratio\ngreater than(1+λ)2\n2λ−ε.\nShin et al. [40] consider the button problem and give a linear program (LP) that yields a lower bound\non the competitiveness of a randomized algorithm for this problem. The button problem is defined as\nfollows. We are given a list of Jbuttons where each button jis associated with a price bj. The prices\nare monotone: b1≤ ··· ≤ bJ. Some buttons are designated as target buttons, which form a suffix of the\nbutton list, i.e., there exists J⋆≤Jsuch that buttons J⋆through Jare all targets and none of the other\nbuttons is a target. We can learn whether a button jis a target or not only by pressing the button, at\nthe price of bj. We do not know “the first target button” J⋆but are given a prediction bJonJ⋆. The\nobjective of this problem is to press one of the target buttons at the minimum total price.\nThis button problem is useful since the lower bound for this problem is (almost) inherited by the\nmulti-option ski rental problem:\nLemma 6 ([40], Lemma 1) .Suppose there exists a χ-consistent ρ-robust algorithm for the learning-\naugmented multi-option ski rental problem. Then there exists a (χ+ε)-consistent (ρ+ε)-robust algorithm\nfor the button problem for all constant ε∈(0,1).\nAlthough any lower bound results on the button problem will immediately extend to the learning-\naugmented multi-option ski rental problem, Shin et al. [40] unfortunately did not show any lower bounds\non the consistency-robustness trade-off: they only showed a lower bound on the competitiveness of\nrandomized algorithms without learning augmentation.\nBefore we prove Theorem 5, observe that an algorithm’s decision cannot be “adaptive” since the\nalgorithm, until it presses a target and immediately terminates, will always learn that the button it\npressed is not a target. As such, any deterministic algorithm for the button problem is nothing more\nthan a fixed sequence of buttons. The algorithm just presses the buttons according to this sequence until\nit eventually presses a target. We can assume without loss of generality that this sequence is increasing\nand the last button of the sequence is button J, since the target buttons form a suffix of the list. A\nrandomized algorithm can be viewed as a probability distribution over increasing sequence of buttons\nwhose last button is button J.\nLet us consider the following instance of the button problem. The number of buttons Jwill be chosen\nlater as a sufficiently large number. Let bj:=jfor every j= 1, . . . , J . In what follows, we will always\nusejitself instead of bjto denote the price of button j. The prediction given to the algorithm will\n11\n\nalways point to the last button J, i.e.,bJ=J. Note that we did not specify what the first target button\nJ⋆is; in fact, we will consider a family of Jinstances with J⋆= 1, . . . , J .\nThe following LP reveals a lower bound on the robustness of any (1 + λ)-consistent randomized\nalgorithm for this family of instances.\nminimize γ\nsubject toPJ\nj=1xj= 1,\nPJ\nj=t+1yt,j=xt+Pt−1\nj=1yj,t, ∀t= 1, . . . , J −1\nPJ\nj′=1j′·\u0010\nxj′+Pmin(j,j′)−1\nt=1yt,j′\u0011\n≤γ·j, ∀j= 1, . . . , J,\nPJ\nj′=1j′·\u0010\nxj′+PJ−1\nt=1yt,j′\u0011\n≤(1 +λ)·J,\nxj≥0, ∀j= 1, . . . , J,\nyt,j≥0,∀t= 1, . . . , J −1,\n∀j=t+ 1, . . . , J.\nIn order to see that this indeed reveals a lower bound, fix an arbitrary (1 + λ)-consistent randomized\nalgorithm. Let xjbe the probability that button jis the first button in the sequence, i.e., the first button\npressed by the algorithm is button j. For every tandjsuch that t < j , letyt,jbe the probability that\nbuttons tandjappear consecutively in the sequence. In other words, yt,jis the marginal probability\nthat the algorithm presses button timmediately followed by button j, assuming that t < J⋆. We can\nnow see that the first constraint requires that {xj}gives a probability distribution; the left-hand side and\nthe right-hand side of the second set of constraints are two alternative ways of calculating the marginal\nprobability that button tappears in the sequence. The left-hand side of the third set of constraints is\nthe expected cost of the algorithm’s output when J⋆=j, because xj′+Pmin(j,j′)−1\nt=1yt,j′is the marginal\nprobability that button j′is pressed when J⋆=j. These constraints therefore ensure that γin an\noptimal solution is a lower bound on the robustness. The fourth constraint must be satisfied by (the\nprobabilities exhibited by) any (1 + λ)-consistent algorithm.\nThe dual of this LP is as follows.\nmaximize w−(1 +λ)Jbv\nsubject toPJ\nj=1j·vj= 1,\nw≤uj+j·\u0010\nbv+PJ\nj′=1vj′\u0011\n, ∀j= 1, . . . , J −1\nw≤J·\u0010\nbv+PJ\nj′=1vj′\u0011\n, (D1)\nut−uj≤j·\u0010\nbv+PJ\nj′=t+1vj′\u0011\n,∀t= 1, . . . , J −2,\n∀j=t+ 1, . . . , J −1,\nut≤J·\u0010\nbv+PJ\nj′=t+1vj′\u0011\n, ∀t= 1, . . . , J −1,\nw∈R,\nut∈R, ∀t= 1, . . . , J −1,\nvj≥0, ∀j= 1, . . . , J,\nbv≥0.\nWe will construct a feasible solution to this dual LP by constructing a solution to the following auxiliary\n12\n\nLP first.\nmaximize w−(1 +λ)Jbv\nsubject to w≤uj+j·\u0010\nbv+PJ\nj′=1vj′\u0011\n, ∀j= 1, . . . , J,\nut−uj≤j·\u0010\nbv+PJ\nj′=t+1vj′\u0011\n,∀t= 1, . . . , J −1,\n∀j=t+ 1, . . . , J,(D2)\nuJ= 0,\nw∈R,\nut∈R, ∀t= 1, . . . , J,\nvj≥0, ∀j= 1, . . . , J,\nbv≥0.\nNote that, as long asPJ\nj=1j·vj̸= 0, any feasible solution to (D2) can be converted into a feasible\nsolution to (D1) by dividing every variable byPJ\nj=1j·vj.\nLet us construct a solution to (D2). Let ℓ:=l\n2λ\n1+λJm\n. Note that ℓ≤Jsince λ∈(0,1). Let\nvj:=(\n1,if 1≤j≤ℓ,\n0,otherwise,\nbv:=J−ℓ,\nut:=J(J−t),for all t= 1, . . . , J and\nw:=J2.\nIt is clear that the solution satisfies the last five sets of constraints. The following two lemmas show that\nthe above solution is indeed feasible to (D2).\nLemma 7. For all 1≤t < j≤J,ut−uj≤j·\u0010\nbv+PJ\nj′=t+1vj′\u0011\n.\nProof. Remark thatPJ\nj′=t+1vj′=ℓ−tift < ℓ , andPJ\nj′=t+1vj′= 0 otherwise. We first bound from\nbelow the right-hand side by considering two cases. If t < ℓ , then j(bv+ℓ−t) =j(J−t) =jJ−jt≥\njJ−Jt=J(j−t); otherwise, jbv=j(J−ℓ)≥j(J−t)≥jJ−Jt=J(j−t). Combining with the fact\nthat the left-hand side is equal to J(j−t), the lemma follows.\nLemma 8. For all j= 1, . . . , J ,w≤uj+j·\u0010\nbv+PJ\nj′=1vj′\u0011\n.\nProof. We have by construction uj+j·\u0010\nbv+PJ\nj′=1vj′\u0011\n=uj+j(bv+ℓ) =J(J−j) +jJ=w.\nWe are now ready to prove Theorem 5. Recall that we can construct a feasible solution to (D1) by\nscaling down a feasible solution to (D2). In light of this fact, it suffices to show that there always exists\na family of instances such thatw−(1 +λ)JbvPJ\nj=1j·vj≥(1 +λ)2\n2λ−ε. Note that\nJX\nj=1j·vj=ℓX\nj=1j=ℓ(ℓ+ 1)\n2≤\u00122λ\n1 +λJ+ 1\u0013\u0012λ\n1 +λJ+ 1\u0013\n(8)\nwhere the inequality follows from ℓ=l\n2λ\n1+λJm\n≤2λ\n1+λJ+ 1. We then have\nw−(1 +λ)JbvPJ\nj=1j·vj=J2−(1 +λ)J(J−ℓ)PJ\nj=1j·vj\n≥J2−(1 +λ)J1−λ\n1+λJ\u0010\n2λ\n1+λJ+ 1\u0011\u0010\nλ\n1+λJ+ 1\u0011\n=λJ2\n\u0010\n2λ\n1+λJ+ 1\u0011\u0010\nλ\n1+λJ+ 1\u0011, (9)\n13\n\nwhere the inequality follows from J−ℓ≤J\u0010\n1−2λ\n1+λ\u0011\n=1−λ\n1+λJand (8). By choosing Jto be sufficiently\nlarge, we can see that (9) becomes arbitrarily close to(1+λ)2\n2λ. The conclusion follows from the weak LP\nduality.\nReferences\n[1] Lingqing Ai, Xian Wu, Lingxiao Huang, Longbo Huang, Pingzhong Tang, and Jian Li. The multi-\nshop ski rental problem. In The 2014 ACM International Conference on Measurement and Modeling\nof Computer Systems (SIGMETRICS) , pages 463–475, 2014.\n[2] Matteo Almanza, Flavio Chierichetti, Silvio Lattanzi, Alessandro Panconesi, and Giuseppe Re.\nOnline facility location with multiple advice. In Advances in Neural Information Processing Systems\n(NeurIPS) , volume 34, pages 4661–4673, 2021.\n[3] Keerti Anand, Rong Ge, Amit Kumar, and Debmalya Panigrahi. A regression approach to learning-\naugmented online algorithms. In Advances in Neural Information Processing Systems (NeurIPS) ,\nvolume 34, pages 30504–30517, 2021.\n[4] Keerti Anand, Rong Ge, and Debmalya Panigrahi. Customizing ML predictions for online algo-\nrithms. In International Conference on Machine Learning (ICML) , pages 303–313. PMLR, 2020.\n[5] Spyros Angelopoulos, Christoph D¨ urr, Shendan Jin, Shahin Kamali, and Marc P. Renault. Online\ncomputation with untrusted advice. In 11th Innovations in Theoretical Computer Science Con-\nference (ITCS) , volume 151, pages 52:1–52:15. Schloss Dagstuhl - Leibniz-Zentrum f¨ ur Informatik,\n2020.\n[6] Antonios Antoniadis, Christian Coester, Marek Eli´ aˇ s, Adam Polak, and Bertrand Simon. Online\nmetric algorithms with untrusted predictions. ACM Transactions on Algorithms , 19(2):1–34, 2023.\n[7] Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online match-\ning problems with machine learned advice. In Advances in Neural Information Processing Systems\n(NeurIPS) , volume 33, pages 7933–7944, 2020.\n[8] Yossi Azar, Stefano Leonardi, and Noam Touitou. Flow time scheduling with uncertain processing\ntime. In Proceedings of the 53rd Annual ACM Symposium on Theory of Computing (STOC) , pages\n1070–1080, 2021.\n[9] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. Online graph algorithms with predictions.\nInProceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) , pages\n35–66. SIAM, 2022.\n[10] Etienne Bamas, Andreas Maggiori, Lars Rohwedder, and Ola Svensson. Learning augmented energy\nminimization via speed scaling. In Advances in Neural Information Processing Systems (NeurIPS) ,\nvolume 33, pages 15350–15359, 2020.\n[11] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning aug-\nmented algorithms. In Advances in Neural Information Processing Systems (NeurIPS) , volume 33,\npages 20083–20094, 2020.\n[12] Shom Banerjee. Improving online rent-or-buy algorithms with sequential decision making and ML\npredictions. In Advances in Neural Information Processing Systems (NeurIPS) , volume 33, pages\n21072–21080, 2020.\n[13] Nikhil Bansal, Christian Coester, Ravi Kumar, Manish Purohit, and Erik Vee. Learning-augmented\nweighted paging. In Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms\n(SODA) , pages 67–89. SIAM, 2022.\n[14] Nicolas Christianson, Tinashe Handina, and Adam Wierman. Chasing convex bodies and functions\nwith black-box advice. In Conference on Learning Theory (COLT) , pages 867–908. PMLR, 2022.\n[15] Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Faster\nmatchings via learned duals. In Advances in Neural Information Processing Systems (NeurIPS) ,\nvolume 34, pages 10393–10406, 2021.\n14\n\n[16] Thomas Erlebach, Murilo Santos de Lima, Nicole Megow, and Jens Schl¨ oter. Learning-augmented\nquery policies for minimum spanning tree with uncertainty. In 30th Annual European Symposium\non Algorithms (ESA) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2022.\n[17] Rudolf Fleischer. On the Bahncard problem. Theoretical Computer Science , 268(1):161–174, 2001.\n[18] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert advice.\nInInternational Conference on Machine Learning (ICML) , pages 2319–2327. PMLR, 2019.\n[19] Sungjin Im, Ravi Kumar, Mahshid Montazer Qaem, and Manish Purohit. Non-clairvoyant schedul-\ning with predictions. In Proceedings of the 33rd ACM Symposium on Parallelism in Algorithms and\nArchitectures (SPAA) , pages 285–294, 2021.\n[20] Sungjin Im, Ravi Kumar, Aditya Petety, and Manish Purohit. Parsimonious learning-augmented\ncaching. In International Conference on Machine Learning (ICML) , pages 9588–9601. PMLR, 2022.\n[21] Shaofeng H.-C. Jiang, Erzhi Liu, You Lyu, Zhihao Gavin Tang, and Yubo Zhang. Online facility\nlocation with predictions. In International Conference on Learning Representations (ICLR) , 2022.\n[22] Zhihao Jiang, Debmalya Panigrahi, and Kevin Sun. Online algorithms for weighted paging with\npredictions. ACM Transactions on Algorithms , 18(4):1–27, 2022.\n[23] Billy Jin and Will Ma. Online bipartite matching with advice: Tight robustness-consistency tradeoffs\nfor the two-stage model. In Advances in Neural Information Processing Systems (NeurIPS) , 2022.\n[24] Anna R Karlin, Claire Kenyon, and Dana Randall. Dynamic TCP acknowledgement and other\nstories about e/(e−1). In Proceedings of the Thirty-third Annual ACM Symposium on Theory of\nComputing (STOC) , pages 502–509, 2001.\n[25] Anna R Karlin, Mark S Manasse, Lyle A McGeoch, and Susan Owicki. Competitive randomized\nalgorithms for non-uniform problems. In Proceedings of the First Annual ACM-SIAM Symposium\non Discrete Algorithms (SODA) , pages 301–309. SIAM, 1990.\n[26] Anna R Karlin, Mark S Manasse, Larry Rudolph, and Daniel D Sleator. Competitive snoopy\ncaching. In 27th Annual Symposium on Foundations of Computer Science (FOCS) , pages 244–254.\nIEEE, 1986.\n[27] Ali Khanafer, Murali Kodialam, and Krishna PN Puttaswamy. The constrained ski-rental problem\nand its application to online cloud cost optimization. In The 32nd IEEE International Conference\non Computer Communications (INFOCOM) , pages 1492–1500. IEEE, 2013.\n[28] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proceedings of the 2018 International Conference on Management of Data\n(SIGMOD) , SIGMOD ’18, page 489–504, New York, NY, USA, 2018. Association for Computing\nMachinery.\n[29] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online scheduling\nvia learned weights. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete\nAlgorithms (SODA) , pages 1859–1877. SIAM, 2020.\n[30] Thomas Lavastida, Benjamin Moseley, R Ravi, and Chenyang Xu. Learnable and instance-robust\npredictions for online matching, flows and load balancing. In 29th Annual European Symposium on\nAlgorithms (ESA) . Schloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2021.\n[31] Thomas Lavastida, Benjamin Moseley, R Ravi, and Chenyang Xu. Using predicted weights for ad\ndelivery. In SIAM Conference on Applied and Computational Discrete Algorithms (ACDA) , pages\n21–31. SIAM, 2021.\n[32] A Lindermayr, N Megow, and B Simon. Double coverage with machine-learned advice. In 13th\nInnovations in Theoretical Computer Science (ITCS) , volume 215, page 99, 2022.\n[33] Alexander Lindermayr and Nicole Megow. Permutation predictions for non-clairvoyant scheduling.\nInProceedings of the 34th ACM Symposium on Parallelism in Algorithms and Architectures (SPAA) ,\npages 357–368, 2022.\n15\n\n[34] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice. Jour-\nnal of the ACM , 68(4):1–25, 2021.\n[35] Adam Meyerson. The parking permit problem. In 46th Annual IEEE Symposium on Foundations\nof Computer Science (FOCS) , pages 274–282. IEEE, 2005.\n[36] Michael Mitzenmacher. Scheduling with predictions and the price of misprediction. In 11th Innova-\ntions in Theoretical Computer Science Conference (ITCS 2020) . Schloss Dagstuhl-Leibniz-Zentrum\nf¨ ur Informatik, 2020.\n[37] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. Communications of\nthe ACM , 65(7):33–35, 2022.\n[38] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ML predictions.\nInAdvances in Neural Information Processing Systems (NeurIPS) , volume 31, 2018.\n[39] Dhruv Rohatgi. Near-optimal bounds for online caching with machine learned advice. In Proceedings\nof the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) , pages 1834–\n1845. SIAM, 2020.\n[40] Yongho Shin, Changyeol Lee, Gukryeol Lee, and Hyung-Chan An. Improved learning-augmented\nalgorithms for the multi-option ski rental problem via best-possible competitive analysis. arXiv\npreprint arXiv:2302.06832 , 2023.\n[41] Shufan Wang, Jian Li, and Shiqiang Wang. Online algorithms for multi-shop ski rental with machine\nlearned advice. In Advances in Neural Information Processing Systems (NeurIPS) , volume 33, pages\n8150–8160, 2020.\n[42] Alexander Wei. Better and simpler learning-augmented online caching. In Approximation, Random-\nization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2020) .\nSchloss Dagstuhl-Leibniz-Zentrum f¨ ur Informatik, 2020.\n[43] Alexander Wei and Fred Zhang. Optimal robustness-consistency trade-offs for learning-augmented\nonline algorithms. In Advances in Neural Information Processing Systems (NeurIPS) , volume 33,\npages 8042–8053, 2020.\n[44] Chenyang Xu and Benjamin Moseley. Learning-augmented algorithms for online steiner tree. In\nProceedings of the AAAI Conference on Artificial Intelligence (AAAI) , volume 36, pages 8744–8752,\n2022.\n[45] Guiqing Zhang, Chung Keung Poon, and Yinfeng Xu. The ski-rental problem with multiple discount\noptions. Information Processing Letters , 111(18):903–906, 2011.\n16",
  "textLength": 51946
}