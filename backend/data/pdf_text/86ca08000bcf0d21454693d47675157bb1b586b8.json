{
  "paperId": "86ca08000bcf0d21454693d47675157bb1b586b8",
  "title": "Learned Index Baseado na Predição de Vértices iniciais em Grafos de Proximidade",
  "pdfPath": "86ca08000bcf0d21454693d47675157bb1b586b8.pdf",
  "text": "Learned Index Baseado na Predic ¸ ˜ao de V ´ertices iniciais em\nGrafos de Proximidade\nMatheus B. Bastos1, Daniel S. Kaster1\n1Departamento de Computac ¸ ˜ao – Universidade Estadual de Londrina (UEL)\nCaixa Postal 10.011 – 86.057-970 – Londrina – PR – Brasil\nmathheusb@gmail.com, dskaster@uel.br\nAbstract. Similarity searches on complex data rely on methods to speed up\nqueries, such as spatial approximation on proximity graphs, which suffer from\nthe initial vertex selection problem. Recently, learned indexes have emerged\nusing machine learning to model the data distribution and other characteris-\ntics, showing promising results. This paper presents an efficient learned index\non graph-based methods for similarity searching. Our method employs super-\nvised learning to predict the seed vertices. The method reduced the distance\ncomputations needed to obtain high recall rates on various datasets evaluated.\nResumo. Buscas por similaridade em dados complexos utilizam m ´etodos para\nacelerar consultas, como a aproximac ¸ ˜ao espacial em grafos de proximidade,\nque sofre com o problema da escolha do v ´ertice inicial. Recentemente, le-\narned indexes surgiram utilizando aprendizado de m ´aquina para modelar a\ndistribuic ¸ ˜ao de dados e outras caracter ´ısticas, apresentando resultados promis-\nsores. Este artigo apresenta um learned index eficiente sobre m ´etodos baseados\nem grafos para buscas por similaridade. O m ´etodo proposto aplica aprendizado\nsupervisionado para predic ¸ ˜ao dos v ´ertices iniciais de busca. O m ´etodo reduziu\no n´umero de computac ¸ ˜oes de dist ˆancia necess ´arias para alcanc ¸ar uma alta taxa\nde recall em v ´arios conjuntos de dados avaliados.\n1. Introduc ¸ ˜ao\nRecentemente, aplicac ¸ ˜oes que usam dados complexos viram sua utilizac ¸ ˜ao crescer, assim\ncomo a necessidade de armazenar esses dados. Exemplos incluem imagens, sons e dados\ngeorreferenciados. Diferentemente dos estruturados, dados complexos n ˜ao podem ser or-\ndenados e comparac ¸ ˜oes exatas n ˜ao fazem tanto sentido. No caso desses tipos de dados,\nbuscas por similaridade s ˜ao mais adequadas, retornando, por exemplo, quais s ˜ao os kele-\nmentos mais similares a um elemento de consulta. Para realizar buscas por similaridade,\nv´arias estruturas de ´ındice foram propostas na literatura, entre elas as baseadas em grafos\nde proximidade [Hajebi et al. 2011].\nOHGraph [Shimomura and Kaster 2019] carrega grande import ˆancia para este\ntrabalho. Ele ´e um m ´etodo para construc ¸ ˜ao de grafos de proximidade, como grafos k-\nNN. A construc ¸ ˜ao´e feita atrav ´es de uma estrat ´egia de divis ˜ao e conquista, que cria v ´arias\npartic ¸ ˜oes. Elas s ˜ao conectadas atrav ´es de regi ˜oes de sobreposic ¸ ˜ao e long-range edges ,\narestas criadas posteriormente que aumentam a qualidade das consultas. Com o grafo\nconstru ´ıdo, um algoritmo baseado em aproximac ¸ ˜ao espacial [Navarro 2002] pode ser uti-\nlizado para realizar consultas sobre ele. Um problema nesses algoritmos ´e quando oCompanion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n223\n\nv´ertice inicial est ´a “muito longe” do resultado ideal. Dependendo do tamanho do grafo,\nessa condic ¸ ˜ao causa uma necessidade de percorrer uma regi ˜ao muito grande do grafo\n[Shimomura and Kaster 2019]. Para contornar esse problema, ´e necess ´ario determinar os\nv´ertices iniciais de busca de maneira mais adequada.\nNos ´ultimos anos, learned indexes surgiram como fortes alternativas ou comple-\nmentos a estruturas tradicionais [Antol et al. 2021, Kraska et al. 2018]. Utilizando mo-\ndelos de aprendizado de m ´aquina, muitos deles conseguem se aproveitar de padr ˜oes exis-\ntentes nos dados para acelerar consultas. O Learned Metric Index [Antol et al. 2021], por\nexemplo, pode se basear em ´ındices como o M-Index [Novak et al. 2011] para construir\nsua pr ´opria estrutura constitu ´ıda por modelos, eliminando c ´alculos de dist ˆancia em passos\nintermedi ´arios da busca.\nEste trabalho prop ˜oe um novo learned index baseado em grafos constru ´ıdos por\nparticionamento, como ´e o caso do HGraph . A ideia principal ´e aproveitar a estrutura\ndo grafo para treinar modelos que ter ˜ao o papel de determinar os v ´ertices iniciais das\nconsultas por similaridade. Com a predic ¸ ˜ao, as buscas s ˜ao iniciadas em regi ˜oes mais\nadequadas e necessitam de menos c ´alculos de dist ˆancia para atingir o mesmo resultado.\nPara tal, uma estrutura auxiliar ao HGraph foi implementada utilizando duas abordagens:\n(1) utilizando um ´unico modelo e (2) utilizando uma hierarquia de modelos. As predic ¸ ˜oes\ndos modelos s ˜ao utilizadas como ponto de partida para as buscas.\nExperimentos utilizando diferentes conjuntos de dados indicam que as abordagens\npropostas possibilitaram uma reduc ¸ ˜ao significativa de c ´alculos de dist ˆancia necess ´arios\npara obter um n ´ıvel de recall equivalente, quando comparadas ao grafo original.\n2. Fundamentos e Trabalhos Relacionados\nGrafos de proximidade s ˜ao grafos comumente utilizados para a realizac ¸ ˜ao de consultas\npor similaridade [Ocsa et al. 2007]. Neles, uma propriedade P, chamada de crit´erio de\nvizinhanc ¸a ,´e definida, e cada par de v ´ertices u, v∈V´e conectado por uma aresta e∈E\nse, e somente se, eles satisfizerem a propriedade P. As arestas geralmente tem como peso\na dist ˆancia entre os dois elementos correspondentes aos v ´ertices. Esses grafos refletem a\nproximidade entre os elementos conectando objetos espacialmente pr ´oximos.\nNesse tipo de grafo, consultas de similaridade podem ser respondidas atrav ´es da\naproximac ¸ ˜ao espacial , definida por [Navarro 2002]. Sendo N(u)os vizinhos de u, inicia-\nse o processo em um elemento qualquer de V, que ´e atribu ´ıdo`a vari ´avela. Em cada passo,\n´e escolhido um dos vizinhos b∈N(a), o qual deve ter menos dist ˆancia ao elemento de\nconsulta do que ae todos os seus outros vizinhos, e atribu ´ıdob`a vari ´avela. O processo\n´e repetido at ´e que n ˜ao seja poss ´ıvel escolher um vizinho de acom esse crit ´erio, o que\nsignifica que a´e o v ´ertice mais pr ´oximo ao objeto de consulta.\nOs algoritmos de aproximac ¸ ˜ao espacial sofrem com um problema: se os v ´ertices\niniciais escolhidos estiverem muito “longe” do objeto de consulta – o que n ˜ao´e inco-\nmum, principalmente quando a escolha ´e aleat ´oria – ser ´a necess ´ario percorrer uma grande\nparte do grafo para atingir a resposta ideal, realizando c ´alculos de dist ˆancia excessivos.\nAinda mais, em consultas aproximadas, buscas gulosas podem retornar respostas longe da\nideal. Algoritmos como o GNNS [Hajebi et al. 2011] contornam o problema realizando\nv´arias buscas, denominadas restarts , cada uma iniciando em um v ´ertice aleat ´orio dife-Companion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n224\n\nrente. Por ´em, em alguns casos ´e necess ´ario realizar muitos restarts para atingir uma taxa\nderecall satisfat ´oria.\nPara melhorar esse cen ´ario e evitar que v ´ertices inadequados sejam escolhidos,\nt´ecnicas de aprendizado de m ´aquina podem ser empregadas. O uso de aprendizado de\nm´aquina para realizar consultas em conjuntos de dados tem sido o foco de v ´arios trabalhos\nrecentes. Esse tipo de ´ındice ´e chamado de learned index .\nUm dos precursores dos learned indexes ´e oRecursive Model Index , ou RMI\n[Kraska et al. 2018], constitu ´ıdo por uma hierarquia de modelos. Seu objetivo ´e apro-\nximar a func ¸ ˜ao de distribuic ¸ ˜ao acumulada do conjunto de dados ordenado, assim sendo\ncapaz de predizer posic ¸ ˜oes para chaves de entrada. Na predic ¸ ˜ao, cada n ´ıvel na hierarquia\n´e respons ´avel por escolher um modelo do n ´ıvel abaixo, at ´e que na folha a posic ¸ ˜ao´e pre-\ndita. Por exigir que o dom ´ınio de dados seja orden ´avel, a estrutura n ˜ao´e adequada para\ndados complexos e buscas por similaridade.\nOutro learned index ´e oLearned Metric Index , ou LMI [Antol et al. 2021]. Ele\nusa como base outro ´ındice como o M-Index [Novak et al. 2011] para criar uma nova es-\ntrutura que substitui a original. Essa estrutura tamb ´em´e constitu ´ıda por uma hierarquia de\nmodelos, usando como label na predic ¸ ˜ao ocluster em que cada cada objeto foi inserido na\nestrutura original. Ao final, s ˜ao retornados poss ´ıveis clusters onde a resposta se encontra,\nque devem ser varridos sequencialmente. O LMI ´e capaz de indexar conjuntos de dados\nem um espac ¸o m ´etrico, n ˜ao exigindo que sejam orden ´aveis, assim sendo adequado para o\nuso em dados complexos.\nPara empregar aprendizado de m ´aquina em uma busca por aproximac ¸ ˜ao espacial,\n´e necess ´ario que haja alguma noc ¸ ˜ao de posic ¸ ˜ao ou cluster no grafo que possa ser usada na\npredic ¸ ˜ao. Nesse contexto, este trabalho utiliza o HGraph [Shimomura and Kaster 2019]\ncomo base. O HGraph ´e um m ´etodo que constr ´oi grafos de proximidade atrav ´es do par-\nticionamento do conjunto de dados, utilizando uma estrat ´egia de divis ˜ao e conquista.\nSeu objetivo ´e acelerar a construc ¸ ˜ao dos grafos atrav ´es do potencial de paralelizac ¸ ˜ao, ao\nmesmo tempo que adiciona caracter ´ısticas capazes de melhorar a qualidade das consultas.\nO particionamento no HGraph ´e feito de forma recursiva: em cada passo, s ˜ao\nselecionados elementos aleat ´orios para serem piv ˆos. Ent ˜ao, cada um dos elementos res-\ntantes ´e adicionado ao subconjunto do piv ˆo mais pr ´oximo. O processo se repete at ´e que\nseja atingida uma determinada cardinalidade em cada subconjunto, quando em cada um ´e\nconstru ´ıdo um grafo como o k-NNG . Os v ´arios grafos constru ´ıdos s ˜ao conectados atrav ´es\nde: (1) arestas de longa dist ˆancia, que conectam piv ˆos e n ˜ao seguem o crit ´erio de proxi-\nmidade; e (2) regi ˜oes de sobreposic ¸ ˜ao, onde v ´ertices pr ´oximos `a “borda” da partic ¸ ˜ao s˜ao\nduplicados, ficando presentes em duas partic ¸ ˜oes e, assim, conectando-as. Ao final, tem-se\numa aproximac ¸ ˜ao do grafo original. A pr ´oxima sec ¸ ˜ao apresenta a proposta do trabalho.\n3. Proposta de um Learned Index Baseado na Predic ¸ ˜ao de V ´ertices Iniciais\nA proposta apresentada neste trabalho tira proveito do particionamento realizado pelo\nHGraph , que tende a agrupar elementos similares, para determinar em que parte do grafo\numa busca por aproximac ¸ ˜ao espacial ser ´a iniciada. Isso pode ser feito atrav ´es da predic ¸ ˜ao\nda partic ¸ ˜ao mais pr ´oxima ao objeto de consulta com modelos de aprendizado de m ´aquina.\nDessa forma, o label atribu ´ıdo aos elementos e utilizado no treinamento dos modelosCompanion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n225\n\n´e uma posic ¸ ˜ao na estrutura original, que no caso ´e um grafo. O objetivo ´e trazer uma\nnova abordagem ao problema da escolha dos v ´ertices iniciais, na tentativa de iniciar a\naproximac ¸ ˜ao espacial em um v ´ertice mais pr ´oximo do resultado ideal, assim necessitando\nmenos c ´alculos de dist ˆancia.\nA proposta adiciona alguns passos ap ´os a construc ¸ ˜ao do HGraph , onde modelos de\nclassificac ¸ ˜ao s˜ao treinados. Al ´em disso, o GNNS [Hajebi et al. 2011], principal algoritmo\nde busca utilizado nos experimentos, foi alterado para predizer os v ´ertices iniciais ao inv ´es\nde escolh ˆe-los aleatoriamente. A implementac ¸ ˜ao foi feita parte em C++, junto ao c ´odigo\ndoHGraph , e parte em Python, utilizando a biblioteca scikit-learn [Pedregosa et al. 2011]\nnas partes correspondentes ao treinamento e predic ¸ ˜ao. O classificador Random Forest\n[Cutler et al. 2012] foi utilizado para induzir os modelos.\nLogo ap ´os o t ´ermino do processo de construc ¸ ˜ao do HGraph ,´e gerado um con-\njunto de dados contendo as caracter ´ısticas dos elementos correspondentes a cada v ´ertice\ndo grafo, rotulados com o identificador da partic ¸ ˜ao onde se encontram. O identificador ´e\nformado pelo “caminho” na ´arvore de recurs ˜ao percorrido durante o processo de particio-\nnamento. Dessa forma, ele carrega informac ¸ ˜oes que podem ser aproveitadas para agrupar\npartic ¸ ˜oes. O conjunto de dados gerado ´e tratado antes de ser utilizado para treinamento.\nDevido `as regi ˜oes de sobreposic ¸ ˜ao do HGraph , muitos elementos aparecem duplicados.\nPara evitar problemas no treinamento, os dados s ˜ao deduplicados, mantendo-se os mais\npr´oximos a algum piv ˆo.\nCom o conjunto de dados gerado e tratado, s ˜ao propostas duas abordagens para\nrealizar o treinamento e predic ¸ ˜ao em cima dele: (1) modelo ´unico, onde o conjunto de\ndados ´e usado diretamente para treinar um ´unico classificador, que ent ˜ao j´a´e capaz de\nrealizar as predic ¸ ˜oes desejadas; e (2) hierarquia de modelos, onde h ´a dois ou mais n ´ıveis\nde modelos, sendo que cada um dos modelos de um n ´ıvel inferior ´e respons ´avel por uma\nparte do conjunto. A primeira abordagem pode ser suficiente em v ´arios casos, princi-\npalmente em conjuntos de dados com baixa cardinalidade/dimensionalidade. A segunda,\nmais frequentemente adotada em learned indexes , tem a motivac ¸ ˜ao de tornar a tarefa de\nclassificac ¸ ˜ao mais simples para os modelos, pois o n ´umero de classes envolvidas ´e re-\nduzido nos casos individuais, o que ´e particularmente relevante para conjuntos de dados\nmaiores. Contudo, ´e importante manter um balanc ¸o entre o n ´umero reduzido de classes\ne o n ´umero significativo de inst ˆancias de cada classe, para possibilitar um aprendizado\nadequado.\nA construc ¸ ˜ao de uma hierarquia de modelos ´e feita de maneira bottom-up . Pri-\nmeiramente, ´e necess ´ario formar agrupamentos de partic ¸ ˜oes, os quais corresponder ˜ao a\num modelo de n ´ıvel folha. Assim, um modelo de n ´ıvel folha ser ´a respons ´avel por realizar\npredic ¸ ˜oes apenas entre as partic ¸ ˜oes que est ˜ao no seu grupo. ´E importante que partic ¸ ˜oes\nsimilares sejam agrupadas para que as predic ¸ ˜oes tenham boa qualidade. H ´a v´arias ma-\nneiras de realizar os agrupamentos. A proposta apresentada neste artigo ´e chamada uni˜ao\nde partic ¸ ˜oes irm ˜as. Nesta proposta, partic ¸ ˜oes irm ˜as s˜ao partic ¸ ˜oes que surgiram de uma\nmesma divis ˜ao no processo de particionamento do HGraph , ou seja, t ˆem o mesmo n ´o pai\nna´arvore de recurs ˜ao. Assim, s ˜ao formados grupos com no m ´aximo Npartic ¸ ˜oes, tentando\nunir sempre partic ¸ ˜oes irm ˜as, por ´em n ˜ao formando grupos com apenas uma partic ¸ ˜ao. A\nimplementac ¸ ˜ao usa os identificadores das partic ¸ ˜oes para determinar se duas partic ¸ ˜oes s ˜ao\nirm˜as: basta verificar se o caminho at ´e as duas na recurs ˜ao´e o mesmo. Na Figura 1(a) ´eCompanion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n226\n\nexibido um exemplo de aplicac ¸ ˜ao do algoritmo. Com os agrupamentos feitos, ´e treinado\num modelo para cada grupo, utilizando do conjunto de dados apenas os elementos per-\ntencentes `as partic ¸ ˜oes do grupo. Por fim, o modelo raiz ´e treinado, e ser ´a respons ´avel por\nescolher qual dos modelos de n ´ıvel folha utilizar. Para seu treinamento, ´e utilizado o con-\njunto gerado por inteiro, mas os labels s˜ao trocados: cada elemento deve ser rotulado por\num identificador do grupo de partic ¸ ˜oes no qual ele est ´a inserido, e n ˜ao mais da partic ¸ ˜ao.\nDessa maneira, o n ´umero de classes ´e dividido por aproximadamente N.\n3.0 3.2\n0 1 2 3\n0.0 0.1 1.0 3.1\n3.0.1 3.0.2 3.0.03.0 3.2Modelo raiz\nModelo folha 1\n0.1 0.2 1Modelo folha 2\n0.0 2.0 2.1Modelo folha 3\n2.2 2.3Entrada: objeto de consulta\n(vetor de características)\nEntrada: objeto de consulta\n(vetor de características)Saída: índice do grupo\nex: 2\nSaída: identificador da partição\nex: 0.0a)b)\nFigura 1. a) Exemplo de aplicac ¸ ˜ao do agrupamento por partic ¸ ˜oes irm ˜as com\nN= 3. b) Processo de predic ¸ ˜ao em uma hierarquia de modelos.\nAssim, os modelos treinados podem ser utilizados na fase de busca. O algoritmo\nGNNS, antes de iniciar a busca, foi alterado para realizar uma predic ¸ ˜ao com o objeto de\nconsulta. No caso da abordagem com modelo ´unico, o identificador da partic ¸ ˜ao inicial\n´e retornado diretamente. J ´a na hierarquia de modelos, o modelo raiz prediz um modelo\nde n´ıvel folha, o qual efetivamente retorna uma partic ¸ ˜ao com base no objeto de consulta,\ncomo pode ser visto na Figura 1(b). Em ambos os casos, com a partic ¸ ˜ao escolhida, os\nrestarts do algoritmo s ˜ao feitos em seus v ´ertices.\n4. Experimentos\nEsta sec ¸ ˜ao apresenta resultados de experimentos comparando os m ´etodos propostos com\nobaseline sem o seu uso, todos implementados em C++ usando a biblioteca Non-Metric\nSpace Library [Boytsov and Naidan 2013], com os m ´etodos propostos fazendo chama-\ndas em Python. O HGraph original ´e rotulado como HGraph ; o m ´etodo utilizando a\nabordagem hier ´arquica, como HGraph H; e o com a abordagem de modelo ´unico, como\nHGraph S. Os resultados apresentados neste trabalho referem-se aos conjuntos de dados\nlistados na Tabela 1. A execuc ¸ ˜ao dos testes foi single-threaded em um Intel(R) Core(TM)\ni7-8700 e 32GB de RAM a 2666 MHz, executando o Ubuntu 20.04.2 LTS.\nOs par ˆametros utilizados na RandomForestClassifier , do scikit-learn , foram 100\n´arvores ( nestimators ) e 30 de profundidade m ´axima ( max depth ). No HGraph , foi\nescolhido o grafo kNNG , com o= 0,1enP= 10 ,NN ={5,10,55}em=\n{5000,10000}. Foram feitas consultas k-NN comk={1,10,30}e n´umero de restarts\nr={1,5,10,20,40,80,120,240}.\nPara analisar os ganhos dos m ´etodos propostos, foram feitas comparac ¸ ˜oes entre os\ndiferentes m ´etodos relacionando o n ´umero de computac ¸ ˜oes de dist ˆancia feitas nas consul-\n1https://archive.ics.uci.edu/ml/datasets/corel+image+featuresCompanion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n227\n\nTabela 1. Conjuntos de dados utilizados nos experimentos.\nDataset Elementos Dimens ˜oes Fonte\nColor Moments 68.040 9 Corel Image Features1\nColor Histogram 68.040 32 Corel Image Features\nCoPhIR Colour Layout 1.000.000 12 CoPhIR [Bolettieri et al. 2009]\ntas e o recall atingido. A Figura 2 mostra que abordagem hier ´arquica apresentou melhor\ndesempenho, com menos c ´alculos sendo exigidos para atingir um mesmo valor de recall\nno conjunto CoPhIR Colour Layout . A de modelo ´unico vem em segundo lugar, ainda\napresentando ganhos em relac ¸ ˜ao ao HGraph original. Os par ˆametros utilizados neste teste\nforam NN = 10 em= 5000 . A diferenc ¸a entre a abordagem hier ´arquica e a simples\nfoi reduzida `a medida que o valor do kda consulta k-NN aumentou, mas o ganho em\ncomparac ¸ ˜ao ao original permaneceu existindo.\n0\n500010000 15000 20000 25000 30000 35000 40000\nComputações de distância0.10.20.30.40.50.60.70.80.9Recall\nCoPhIR Colour Layout (12D) - K = 1\nHGraph\nHGraph_H\nHGraph_S\n0\n500010000 15000 20000 25000 30000 35000 40000\nComputações de distância0.10.20.30.40.50.60.70.80.9Recall\nCoPhIR Colour Layout (12D) - K = 30\nHGraph\nHGraph_H\nHGraph_S\n0\n500010000 15000 20000 25000 30000 35000 40000\nComputações de distância0.20.30.40.50.60.70.80.9Recall\nCoPhIR Colour Layout (12D) - K = 10\nHGraph\nHGraph_H\nHGraph_S\nFigura 2. Desempenho das propostas com variac ¸ ˜ao do kem consultas k-NN no\nconjunto CoPhIR Colour Layout .\nO par ˆametro NN dokNNG determina o n ´umero de vizinhos mais pr ´oximos que\nser˜ao conectados a cada v ´ertice atrav ´es de arestas no grafo. A fim de analisar o impacto\ndesse par ˆametro, foram fixados m= 5000 ek= 10 . A Figura 3 mostra um sum ´ario dos\ncen´arios para o conjunto Corel Color Moments por meio de boxplots . Evidentemente,\nquanto maior o NN, maior o recall . Em contrapartida, mais c ´alculos de dist ˆancia s ˜ao\nfeitos. Nota-se que, `a medida que valor de NN cresce, os ganhos das novas abordagens\nem quest ˜ao de recall s˜ao reduzidos. Isso ´e mais vis ´ıvel em conjuntos de dados menores e\npode ser explicado pela selec ¸ ˜ao do v ´ertice inicial ter um impacto menor na aproximac ¸ ˜ao\nespacial quando h ´a tantas arestas em relac ¸ ˜ao ao valor de k. Em compensac ¸ ˜ao, esse va-\nlor pode causar mais c ´alculos de dist ˆancia, reduzidos significativamente pelos m ´etodos\npropostos, al ´em de aumentar o tempo de construc ¸ ˜ao do grafo.\nPor fim, foi feita uma an ´alise para cada conjunto de dados em cima das diferentes\nconfigurac ¸ ˜oes que foram capazes de obter valores de recall≥0,9nas consultas. As\nconfigurac ¸ ˜oes foram ordenadas por c ´alculos de dist ˆancia realizados e as 10 melhores de\ncada conjunto de dados foram selecionadas. A Figura 4 mostra o resultado dessa an ´alise\npara consultas com k= 10 . V´arias configurac ¸ ˜oes do HGraph com predic ¸ ˜ao de v ´ertice\ninicial foram capazes de diminuir os c ´alculos de dist ˆancia necess ´arios para se obter um\nrecall maior ou igual a 0,9nos conjuntos avaliados. A figura mostra que houve claros\nganhos para o conjunto CoPhIR Colour Layout , onde a melhor configurac ¸ ˜ao do HGraph\noriginal teve que realizar 138% mais c ´alculos de dist ˆancia do que a abordagem hier ´arquicaCompanion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n228\n\n5 10 55\nNN01000020000300004000050000Computações de distância\nCorel Color Moments (9D)\nHGraph\nHGraph_H\nHGraph_S\n5 10 55\nNN0.00.20.40.60.81.0Recall\nCorel Color Moments (9D)\nHGraph\nHGraph_H\nHGraph_SFigura 3. Computac ¸ ˜ao de dist ˆancias e recall variando-se o par ˆametro NN no\nconjunto Color Moments .\ncomm= 10000 eNN = 55 . A Figura 4 tamb ´em mostra que os m ´etodos propostos\nforam as melhores opc ¸ ˜oes para o conjunto Corel Color Histogram , exigindo at ´e40%\nmenos c ´alculos do que a melhor configurac ¸ ˜ao do HGraph original.\nHGraph_H\nm=10000\nNN=55HGraph_H\nm=5000\nNN=55HGraph_S\nm=5000\nNN=55HGraph_S\nm=10000\nNN=55HGraph\nm=5000\nNN=55HGraph\nm=10000\nNN=55HGraph_H\nm=5000\nNN=10HGraph\nm=5000\nNN=1005000100001500020000250003000035000Computações de distância\n1419,72 1455,46 1510,892921,873384,65 3411,8913119,2038176,40CoPhIR Colour Layout (12D)\nHGraph_S\nm=5000\nNN=55HGraph_H\nm=5000\nNN=55HGraph_H\nm=10000\nNN=55HGraph_S\nm=10000\nNN=55HGraph\nm=5000\nNN=55HGraph\nm=10000\nNN=55HGraph_H\nm=5000\nNN=10HGraph_H\nm=10000\nNN=10HGraph_S\nm=10000\nNN=10HGraph_S\nm=5000\nNN=10010002000300040005000600070008000Computações de distância1453,17 1531,99 1533,56 1593,012421,21 2425,835446,586180,686688,257913,84Corel Color Histogram (32D)\nFigura 4. Configurac ¸ ˜oes com recall ≥0,9para consultas 10-NN nos conjuntos\nCoPhIR Colour Layout eCorel Color Histogram .\n5. Conclus ˜ao\nNeste artigo, foi apresentado um novo learned index baseado em grafos constru ´ıdos com\nparticionamento, como o HGraph . O´ındice se aproveita do particionamento realizado\ndurante a construc ¸ ˜ao do grafo para treinar um classificador (um modelo ´unico ou umaCompanion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n229\n\nhierarquia de modelos), o qual ´e capaz de prever uma posic ¸ ˜ao inicial adequada para de-\nterminada busca se iniciar. Nos experimentos, ambas as abordagens foram capazes de\nreduzir o n ´umero de c ´alculos de dist ˆancia necess ´ario para se atingir um recall satisfat ´orio.\nComo trabalhos futuros, destacam-se uma experimentac ¸ ˜ao mais extensa para ana-\nlisar compromissos da abordagem, como n ´umero de modelos (classes) por n ´ıvel, avaliar\nimpactos nos tempos de construc ¸ ˜ao e consulta e realizar comparac ¸ ˜oes com outras estru-\nturas na literatura, em particular, o LMI. Al ´em disso, conjuntos de dados maiores e/ou\ncom mais dimensionalidade devem ser testados, a fim de verificar se os ganhos s ˜ao in-\ntensificados nesses casos. Tamb ´em, outros tipos de modelos de classificac ¸ ˜ao devem ser\nexplorados, como redes neurais e redes neurais de grafos.\nRefer ˆencias\nAntol, M., Ol’ha, J., Slanin ´akov ´a, T., and Dohnal, V . (2021). Learned metric in-\ndex—proposition of learned indexing for unstructured data. Information Systems ,\n100:101774.\nBolettieri, P., Esuli, A., Falchi, F., Lucchese, C., Perego, R., Piccioli, T., and Rabitti, F.\n(2009). Cophir: a test collection for content-based image retrieval. arXiv preprint\narXiv:0905.4627 .\nBoytsov, L. and Naidan, B. (2013). Engineering efficient and effective non-metric space\nlibrary. In International Conference on Similarity Search and Applications , pages 280–\n293. Springer.\nCutler, A., Cutler, D. R., and Stevens, J. R. (2012). Random forests. In Ensemble machine\nlearning , pages 157–175. Springer.\nHajebi, K., Abbasi-Yadkori, Y ., Shahbazi, H., and Zhang, H. (2011). Fast approximate\nnearest-neighbor search with k-nearest neighbor graph. In Twenty-Second Internatio-\nnal Joint Conference on Artificial Intelligence .\nKraska, T., Beutel, A., Chi, E. H., Dean, J., and Polyzotis, N. (2018). The case for learned\nindex structures. In Proceedings of the 2018 International Conference on Management\nof Data , pages 489–504.\nNavarro, G. (2002). Searching in metric spaces by spatial approximation. The VLDB\nJournal , 11(1):28–46.\nNovak, D., Batko, M., and Zezula, P. (2011). Metric index: An efficient and scalable so-\nlution for precise and approximate similarity search. Information Systems , 36(4):721–\n733.\nOcsa, A., Bedregal, C., and Cuadros-Vargas, E. (2007). A new approach for similarity\nqueries using neighborhood graphs. In SBBD , pages 131–142.\nPedregosa, F., Varoquaux, G., Gramfort, A., Michel, V ., Thirion, B., Grisel, O., Blondel,\nM., Prettenhofer, P., Weiss, R., Dubourg, V ., et al. (2011). Scikit-learn: Machine\nlearning in python. the Journal of machine Learning research , 12:2825–2830.\nShimomura, L. C. and Kaster, D. S. (2019). Hgraph: a connected-partition approach to\nproximity graphs for similarity search. In International Conference on Database and\nExpert Systems Applications , pages 106–121. Springer.Companion Proceedings of the 37thBrazilian Symposium on Data Bases September 2022 – B´ uzios, RJ, Brazil\n230",
  "textLength": 25762
}