{
  "paperId": "1e3128c9516f1de92aa55d5cc56893e080939b3b",
  "title": "Faster Matchings via Learned Duals",
  "pdfPath": "1e3128c9516f1de92aa55d5cc56893e080939b3b.pdf",
  "text": "Faster Matchings via Learned Duals\nMichael Dinitz∗Sungjin Im†Thomas Lavastida‡Benjamin Moseley§\nSergei Vassilvitskii¶\nJuly 22, 2021\nAbstract\nA recent line of research investigates how algorithms can be augmented with machine-learned\npredictions to overcome worst case lower bounds. This area has revealed interesting algorithmic\ninsights into problems, with particular success in the design of competitive online algorithms.\nHowever, the question of improving algorithm running times with predictions has largely been\nunexplored.\nWe take a ﬁrst step in this direction by combining the idea of machine-learned predictions\nwith the idea of “warm-starting\" primal-dual algorithms. We consider one of the most important\nprimitives in combinatorial optimization: weighted bipartite matching and its generalization to\nb-matching. We identify three key challenges when using learned dual variables in a primal-dual\nalgorithm. First, predicted duals may be infeasible, so we give an algorithm that eﬃciently maps\npredicted infeasible duals to nearby feasible solutions. Second, once the duals are feasible, they may\nnot be optimal, so we show that they can be used to quickly ﬁnd an optimal solution. Finally, such\npredictions are useful only if they can be learned, so we show that the problem of learning duals\nfor matching has low sample complexity. We validate our theoretical ﬁndings through experiments\non both real and synthetic data. As a result we give a rigorous, practical, and empirically eﬀective\nmethod to compute bipartite matchings.\n1 Introduction\nClassical algorithm analysis considers worst case performance of algorithms, capturing running times,\napproximation and competitive ratios, space complexities, and other notions of performance. Recently\nthere has been a renewed interest in ﬁnding formal ways to go beyond worst case analysis [ 48], to\nbetter understand performance of algorithms observed in practice, and develop new methods tailored\nto typical inputs observed.\nAn emerging line of research dovetails this with progress in machine learning, and asks how\nalgorithms can be augmented with machine-learned predictors to circumvent worst case lower bounds\nwhen the predictions are good, and approximately match them otherwise (see Mitzenmacher and\nVassilvitskii [39]for a survey). Naturally, a rich area of applications of this paradigm has been in\nonline algorithms, where the additional information revealed by the predictions reduces the uncertainty\n∗Department of Computer Science, Johns Hopkins University, Baltimore, MD. mdinitz@cs.jhu.edu . Supported in\npart by NSF grant CCF-1909111.\n†Electrical Engineering and Computer Science, University of California, 5200 N. Lake Road, Merced CA 95344.\nsim3@ucmerced.edu . Supported in part by NSF grants CCF-1617653 and CCF-1844939.\n‡Tepper School of Business, Carnegie Mellon University, Pittsburgh, PA. tlavasti@andrew.cmu.edu . Supported in\npart by NSF grants CCF-1824303, CCF-1845146, CCF-1733873 and CMMI-1938909.\n§Tepper School of Business, Carnegie Mellon University, Pittsburgh, PA. moseleyb@andrew.cmu.edu . Supported in\npart by a Google Research Award, an Infor Research Award, a Carnegie Bosch Junior Faculty Chair and NSF grants\nCCF-1824303, CCF-1845146, CCF-1733873 and CMMI-1938909.\n¶Google Research New York, NY. sergeiv@google.com\n1arXiv:2107.09770v1  [cs.LG]  20 Jul 2021\n\nabout the future and can lead to better choices, and thus better competitive ratios. For instance,\nsee the work by Lykouris and Vassilvitskii [36], Rohatgi [47], Jiang et al. [31]on caching; Antoniadis\net al.[4], Dütting et al. [22]on the classic secretary problem; Purohit et al. [46], Lattanzi et al. [34]on\nscheduling; Purohit et al. [46], Anand et al. [2] on ski rental; and Bamas et al. [9] on set cover.\nHowever, the power of predictions is not limited to improving online algorithms. Indeed, the aim of\nthe empirical paper that jump-started this area by Kraska et al. [33]was to improve running times for\nbasic indexing problems. The main goal and contribution of this work is to show that at least in one\nimportant setting (weighted bipartite matching), we can give formal justiﬁcation for using machine\nlearned predictions to improve running times: there are predictions which can provably be learned,\nand if these predictions are “good” then we have running times that outperform standard methods\nboth in theory and empirically.\nHow can predictions help with running time? One intuitive approach, which has been used\nextensively in practice, is through the use of “warm-start\" heuristics [ 54,26,25,41], where instead of\nstarting with a blank slate, the algorithm begins with some starting state (which we call a warm-start\n“solution\" or “seed\") which hopefully allows for faster completion. While it is a common technique, there\nis a dearth of analysis understanding what constitutes a good warm-start, when such initializations\nare helpful, and how they can best be leveraged.\nThus we have a natural goal: put warm-start heuristics on ﬁrm theoretical footing by interpreting\nthe warm-start solution as learned predictions. In this set up we are given a number of instances of the\nproblem (the training set), and we can use them to compute a warm-start solution that will (hopefully)\nallow us to more quickly compute the optimal solution on future, test-time, instances. There are three\nchallenges that we must address:\n(i)Feasibility. The learned prediction (warm-start solution) might not even be feasiblefor the\nspeciﬁc instance we care about! For example, the learned solution may be matching an edge that\ndoes not exist in the graph at testing time.\n(ii)Optimization. If the warm-start solution is feasible and near-optimal then we want the\nalgorithm to take advantage of it. In other words, we would like our running time to be a function\nof the quality of the learned solution.\n(iii)Learnability. It is easy to design predictions that are enormously helpful but which cannot\nactually be learned (e.g., the “prediction\" is the optimal solution). We need to ensure that a\ntypical solution learned from a few instances of the problem generalizes well to new examples,\nand thus oﬀers potential speedups.\nIf we can overcome these three challenges, we will have an end-to-end framework for speeding up\nalgorithms via learned predictions: use the solution to challenge (iii) to learn the predictions from\nhistorical data, use the solution to challenge (i) to quickly turn the prediction into something feasible\nfor the particular problem instance while preserving near-optimality, and then use this as a warm-start\nseed in the solution to challenge (ii).\n1.1 Our Contributions\nWe focus on one of the fundamental primitives of combinatorial optimization: computing bipartite\nmatchings. For the bipartite minimum-weight perfect matching (MWPM) problem, as well as its\nextension to b-matching, we show that the above three challenges can be solved.\nInstead, following the work of [ 17,53], we look at the dualproblem; that is, the dual to the natural\nlinear program. We quantify the “quality” of a prediction ^yby its`1-distance from the true optimal\ndualy\u0003, i.e., byk^y\u0000y\u0003k1. The smaller quantities correspond to better predictions. Since the dual\nis a packing problem we must contend with feasibility: we give a simple linear time algorithm that\nconverts the prediction ^yinto a feasible dual while increasing the `1distance by a factor of at most 3.\nNext, we run the Hungarian method starting with the resulting feasible dual. Here, we show\nthat the running time is in proportional to the `1distance of the feasible dual to the optimal dual\n(Theorem 13). Finally, we show via a pseudo-dimension argument that not many samples are needed\nbefore the empirically optimal seed is a good approximation of the true optimum (Theorem 14), and\n2\n\nthat this empirical optimum can be computed eﬃciently (Theorem 23). For the learning argument, we\nassume that matching instances are drawn from a ﬁxed but unknown distribution D.\nPutting it all together gives us our main result.\nTheorem 1 (Informal) .There are three algorithms (learning, feasibility, optimization) with the\nfollowing guarantees.\n•Given a (possibly infeasible) dual ^yfrom the learning algorithm, there exists an O(m+n)\ntime algorithm that takes a problem instance c, and outputs a feasible dual ^y0(c)such that\nk^y0(c)\u0000y\u0003(c)k1\u00143k^y\u0000y\u0003(c)k1.\n•The optimization algorithm takes as input feasible dual ^y0(c)and outputs a minimum weight\nperfect matching, and runs in time ~O(mpn\u0001minfk^y0(c)\u0000y\u0003(c)k1;png).\n•After ~O(C2n3)samples from an unknown distribution Dover problem instances, the learning\nalgorithm produces duals ^yso that Ec\u0018D[k^y\u0000y\u0003(c)k1]is approximately minimum among all\npossible choices of ^y, whereCis the maximum edge cost and y\u0003(c)is an optimal dual for instance\nc.\nCombining these gives a single algorithm that, with access to ~O(C2n3)problem instance samples\nfromD, has expected running time on future instances from Dof only ~O(mpnminf\u000b;png), where\n\u000b= minyEc\u0018D[ky\u0000y\u0003(c)k1].\nWe emphasize that the Hungarian method with ~O(mn)running time is the standard algorithm in\npractice. Although there are other theoretically faster exact algorithms for bipartite minimum-weight\nperfect matching [ 44,24,23,21], including [ 21] that runs in O(mpnlog(nC)), they are relatively\ncomplex (using various scaling techniques). In fact, we could not ﬁnd any implementation of them,\nwhile multiple implementations of the Hungarian method are readily available.\nNote that our result shows that we can speed up the Hungarian method as long as the `1-norm\nerror of the learned dual, i.e., k^y\u0000y\u0003(c)k1iso(pn). Further, as the projection step that converts\nthe learned dual into a feasible dual takes only linear time, the overhead of our method is essentially\nnegligible. Therefore, even if the prediction is of poor quality, our method has worst-case running\ntime that is neverworse than that of the Hungarian algorithm. Even our learning algorithm is simple,\nconsisting of a straightforward empirical risk minimization algorithm (the analysis is more complex\nand involves bounding the “pseudo-dimension” of the loss functions).\nWe validate our theoretical results via experiments. For each dataset we ﬁrst feed a small number of\nsamples (fewer than our theoretical bounds) to our learning algorithm. We then compare the running\ntime of our algorithm to that of the classical Hungarian algorithm on new instances.\nDetails of these experiments can be found in Section 4. At a high level they show that our algorithm\nissigniﬁcantly faster in practice. Further, our experiment shows only very few samples are needed to\nachieve a notable speed-up. This conﬁrms the power of our approach, giving a theoretically rigorous\nyet also practical method for warm-start primal-dual algorithms.\n1.2 Related Work\nMatchings and b-Matchings: Bipartite matchings are one of the most well studied problems in\ncombinatorial optimization, with a long history of algorithmic improvements. We refer the interested\nreader to Duan and Pettie [20]for an overview. We highlight some particular results here. We are\ninterested in the weighted versions of these problems and when all edge weights are integral. Let Cbe\nthe maximum edge weight, nbe the number of vertices, and mthe number of edges. For ﬁnding exact\nsolutions to the minimum weight perfect matching problem, the scaling technique leads to a running\ntime ofO(mpnlog(nC))[44,24,23,21]. For dense graphs there is a slightly better algorithm running\nin timeO(n5=2log(nC)(log log(n)\nlog(n))1=4)[14]. Finally, algebraic techniques can be used to get a run time\nofO(Cn!)[49], where !is the exponent for fast matrix multiplication.\nThe minimum cost b-matching problem and its generalization, the minimum cost ﬂow problem,\nhave also been extensively studied. See [ 42] for a summary of classical results. More recently there\n3\n\nhas been improvements by applying interior point methods. The algorithm of [ 16] has running time\n~O(m3=2log2(C)) and it is improved by the algorithm of [ 35] which runs in time ~O(mpnlogO(1)(C)).\nLarge scale bipartite matchings have been studied extensively in the online setting, as they represent\nthe basic problem in ad allocations [ 37]. While the ad allocation is inherently online, most of the\nmethods precompute a dual based solution based on a sample of the input [ 17,53], and then argue\nthat this solution is approximately optimal on the full instance. In contrast, we strive to compute the\nexactly optimal solution, but use previous instances to improve the running time of the approach.\nAlgorithms with Predictions: Kraska et al. [33]showed how to use machine learned predictions to\nimprove heavily optimized indexing algorithms. The original paper was purely empirical and came with\nno rigorous guarantees; recently there has been a ﬂurry of work putting such approaches on a strong\ntheoretical foundation, evaluating the beneﬁt of augmenting classical algorithms with machine learned\npredictions, see [ 39] for a survey. Online and streaming algorithms in particular have seen signiﬁcant\nsuccesses, as predictions reveal information about the future and can help guide the algorithms’ choices.\nThis has led to the design of new methods for caching [ 36,47,31], scheduling [ 46,34], frequency\ncounting [ 15,30,1], and membership testing [ 38,51] that can break through worst-case lower bounds\nwhen the predictions are of suﬃciently high quality.\nMost of the above work abstracts the predictions as access to an error-prone oracle and asks how to\nbest use predictions: getting performance gains when the predictions are good, but limiting the losses\nwhen they are not. A related emergent area is that of data driven algorithm design [ 28,8,6,5,7,13].\nHere, the objective is to “learn” a good algorithm for a particular family of inputs. The goal is not\ntypically to tie the performance of the algorithm to the quality of the prediction, but rather to show\nthat the prediction makes sense; that is only a small number of problem samples are needed in order\nto ensure the learned algorithm generalizes to new data points.\nComparison to Dynamic Algorithms: A natural counterpoint to our approach is the area of\ndynamic algorithms . In dynamic algorithms, we attempt to design algorithms that allow us to very\nquickly recompute the optimal solution when there is a single (or a very small number) of changes\nin the input. In other words, the input is changing over time, and we need to always maintain an\noptimal solution as it changes. There has been an active line of work on dynamic matching algorithms,\nsee [11, 50].\nThis is in some sense very similar to what we are trying to do, since we are also trying to quickly\ncompute an optimal solution when we have a history and previous optimal solutions. But these\ntwo approaches, of dynamic algorithms and of machine-learned predictions for warm-start, are quite\ndiﬀerent and are actually highly complementary. Dynamic algorithms work extremely well in the setting\nwhere the input changes slowly but where the output can change quickly, since they are optimized to\nhandlesinglechanges in the input (e.g., a single edge being added or removed from the graph). Our\napproach, on the other hand, works extremely well when the input can change dramatically but the\noptimal solution is relatively stable, since then our learned dual values will be quite close to optimal.\n1.3 Roadmap\nWe begin with preliminaries and background in Section 2. We then present our main theoretical results\non min-cost perfect bipartite matching in Section 3. The experiments are presented in Section 4.\nFinally, the extension to b-matching is presented in Section 5.\n2 Preliminaries\nNotation: LetG= (V;E)be an undirected graph. We will use N(i) :=fe2Eji2egto be the\nset of edges adjacent to vertex i. Similarly if Gis directed, then we use N+(i)andN\u0000(i)to be the\nset of edges leaving iand the set of edges entering i, respectively. For a set S\u0012V, let\u0000(S)be the\nvertex neighborhood of S. For a vector y2Rn, we letkyk1=P\nijyijbe its`1-norm. Lethx;yibe the\nstandard inner product on Rn.\n4\n\nLinear Programming and Complementary Slackness: Here we recall optimality conditions\nfor linear programming that are used to ensure the correctness of some algorithms we present. Consider\nthe primal-dual pair of linear programs below.\nminc>x\nAx=b\nx\u00150(P)\nmaxb>y\nA>y\u0014c(D)\nA pair of solutions x;yfor(P)and(D), respectively, satisfy complementary slackness if x>(c\u0000\nA>y) = 0. The following lemma is well-known.\nLemma 2. Letxbe a feasible solution for (P)andybe a feasible solution for (D). If the pair x;y\nsatisﬁes complementary slackness, then xandyare optimal solutions for their respective problems.\nMaximum Cardinality Matching: LetG= (V;E)be a bipartite graph on nvertices and medges.\nA matching M\u0012Eis a collection of non-intersecting edges. The Hopcroft-Karp algorithm for ﬁnding\na matching maximizing jMjruns in time O(pn\u0001m)[29], which is still state-of-the-art for general\nbipartite graphs. For moderately dense graphs, a recent result by van den Brand et al. [52]gives a\nbetter running time of ~O(m+n1:5)(where ~Ohides polylogarithmic factors).\nMinimum Weight Perfect Matching (MWPM): Again, letG= (V;E)be a bipartite graph on\nnvertices and mwith costsc2ZE\n+on the edges, and let Cbe the maximum cost. A matching Mis\nperfectif every vertex is matched by M. The objective of this problem is to ﬁnd a perfect matching\nMminimizing the cost c(M) :=P\ne2Mce.\nWhen looking for optimal solutions we can assume that Gis a complete graph by adding all possible\nedges not in Ewith weight Cn2. It is easy to see that any o(n)approximate solution would not use\nany of these edges.\nMaximum Flow: Now letG= (V;E)be a directed graph on nvertices and medges with a capacity\nvectoru2RE\n+. Letsandtbe distinct vertices of G. Anst-ﬂow is a vector f2RE\n+satisfyingP\ne2N+(i)fe\u0000P\ne2N\u0000(i)fe= 0for all vertices i6=s;t. Anst-ﬂowfis maximum if it maximizesP\ne2N+(s)fe=P\ne2N\u0000(t)fe. The algorithm due to Orlin [ 43] and King, Rao, and Tarjan [ 32] runs in\ntimeO(nm).\n3 Faster Min-Weight Perfect Matching\nIn this section we describe how predictions can be used to speed up the bipartite Minimum Weight\nPerfect Matching (MWPM) problem.\nThe MWPM problem can be modeled by the following linear program and its dual – the primal-dual\nview will be very useful for our algorithm and analysis. We will sometimes refer to a set of dual\nvariablesyas dualprices. Both LPs are well-known to be integral, implying that there always exist\nintegral optimal solutions.\nminX\ne2Ecexe\nX\ne2N(i)xe= 18i2V\nxe\u001508e2E(MWPM-P)\nmaxX\ni2Vyi\nyi+yj\u0014ce8e=ij2E(MWPM-D)\n5\n\nSuppose we are given a prediction ^yof a dual solution. If ^yis feasible, then by complementary\nslackness we can check if ^yrepresents an optimal dual solution by running a maximum cardinality\nmatching algorithm on the graph G0= (V;E0), whereE0=fe=ij2Ej^yi+^yj=cijgis the set of\ntight edges. If this matching is perfect, then its incidence vector xsatisﬁes complementary slackness\nwith ^yand thus represents an optimal solution by Lemma 2.\nWe now consider the problem from another angle, factoring in learning aspects. Suppose the graph\nG= (V;E)is ﬁxed but the edge cost vector c2ZE\n+varies (is drawn from some distribution D). If\nwe are given an optimal dual y\u0003as a prediction, then we can solve the problem by solving the max\ncardinality matching problem only once. However, the optimal dual can signiﬁcantly change depending\non edge cost c. Nevertheless, we will show how to learn “good” dual values and use them later to solve\nnew MWPM instances faster. Speciﬁcally, we seek to design an end-to-end algorithm addressing all\nthe aforementioned challenges:\n1.Feasiblity (Section 3.1). The learned dual ^ymay not be feasible for MWPM-D with some\nspeciﬁc cost vector c. We show how to quickly convert it to a feasible dual ^y0(c)by appropriately\ndecreasing the dual values (the more we decrease them, the further we move away from the\noptimum). Finding the feasible dual minimizing k^y\u0000^y0(c)k1turns out to be a variant of the\nvertex cover problem, for which we give a simple 2-approximation running in O(m+n)time. As\na result, we have k^y0(c)\u0000y\u0003(c)k1\u00143k^y\u0000y\u0003(c)k1. See Theorem 7.\n2.Optimization (Section 3.2). Now that we have a feasible solution ^y0(c), we want to ﬁnd an\noptimal solution starting with ^y0(c)in time that depends on the quality of ^y0(c). Fortunately, the\nHungarian algorithm can be seeded with any feasible dual, so we can “warm-start\" it with ^y0(c).\nWe show that its running time will be proportional to jk^y0(c)k1\u0000ky\u0003(c)k1j\u0014k ^y0(c)\u0000y\u0003(c)k1.\nSee Theorem 13. Our analysis does not depend on the details of the Hungarian algorithm, and\nso applies to a broader class of primal-dual algorithms.\n3.Learnability (Section 3.3). The target dual we seek to learn is arg minyEc\u0018Dky\u0000y\u0003(c)k; here\ny\u0003(c)is the optimal dual for MWPM-D with cost vector c. We show we can eﬃciently learn ^y\nthat is arbitrarily close to the target vector after ~O(C2n3)samples fromD. See Theorem 14.\nCombining all of these gives the following, which is a more formal version of Theorem 1. Let Dbe\nan arbitrary distribution over edge costs where every vector in the support of Dhas maximum cost C.\nFor any edge cost vector c, lety\u0003(c)denote the optimal dual solution.\nTheorem 3. For anyp;\u000f> 0, there is an algorithm which:\n•AfterO\u0010\u0000nC\n\u000f\u00012(nlogn+ log(1=p))\u0011\nsamples fromD, returns dual values ^ysuch that Ec\u0018D[k^y\u0000\ny\u0003(c)k1]\u0014min\nyEc\u0018D[ky\u0000y\u0003(c)k1] +\u000fwith probability at least 1\u0000p.\n•Using the learned dual ^y, given edge costs c, computes a min-cost perfect matching in time\nO(mpn\u0001minfk^y\u0000y\u0003(c)k1;png).\nIn the rest of this section we detail our proof of this Theorem.\n3.1 Recovering a Feasible Dual Solution (Feasibility)\nLet^ybe an infeasible set of (integral) dual prices – this should be thought of as the “good\" dual\nobtained by our learning algorithm. Our goal in this section is to ﬁnd a new feasibledual solution\n^y0(c)that is close to ^y, for a given MWPM-D instance with cost c. In particular we seek to ﬁnd the\nclosest feasible dual under `1norm, i.e. one minimizing k^y0(c)\u0000^yk1.\nLooking at (MWPM-D) , it is clear that we need to decrease the given dual values ^yin order to\nmake it feasible. More formally, we are looking for a vector of non-negative perturbations \u000esuch that\n^y0:=^y\u0000\u000eis feasible. We model ﬁnding the best set of perturbations, in terms of preserving ^y’s dual\nobjective value, as a linear program. Let F:=fe=ij2Ej^yi+^yj>cijgbe the set of dual infeasible\nedges under ^y. Deﬁnere:=^yi+^yj\u0000cefor each edge e=ij2F. Asserting that ^y\u0000\u000eis feasible\nfor(MWPM-D) while minimizing the amount lost in the dual objective leads to the following linear\n6\n\nprogram:\nminX\ni2V\u000ei\n\u000ei+\u000ej\u0015rij8ij2F\n\u000ei\u001508i2V(1)\nNote that this is a variant of the vertex cover problem—the problem becomes exactly the vertex\ncover problem if rij= 1for all edges ij. We could directly solve this linear program, but we are\ninterested in making this step eﬃcient. To ﬁnd a fast approximation for (1), we take a simple greedy\napproach.\nAlgorithm 1 Fast Approx. for Distance to Feasibility\n1:procedure FastApprox (G= (V;E);r)\n2:8i2V,\u000ei 0\n3:whileE6=;do\n4: Letibe an arbitrary vertex of G\n5:whileihas a neighbor do\n6: j arg maxj02N(i)rij0\n7: \u000ei rij\n8: \rij= 1=2 . \rijis only used for analysis\n9: Deleteiand all its edges from G\n10: i j\n11:Return\u000e\nAlgorithm 1 is a modiﬁcation of the algorithm of Drake and Hougardy [18]which walks through\nthe graph setting \u000eiappropriately at each step to satisfy the covering constraints in (1). The analysis\nis based on interpreting the algorithm through the lens of primal-dual—the dual of (1)turns out to be\na maximum weight matching problem with new edge weights rij. The dual is the following:\nmaxX\nere\re\nX\ne2N(i)\\F\re\u001418i2V\n\re\u001508e2F(2)\nFirst we show the algorithm is fast.\nLemma 4. Algorithm 1 runs in time O(n+m).\nProof.This follows from the trivial observation that each vertex/edge is considered O(1)times.\nNext, by construction the algorithm constructs a feasible dual solution.\nLemma 5. The perturbations \u000ereturned by Algorithm 1 is feasible for (1).\nProof.We want to show that \u000ei+\u000ej\u0015refor all edges e=ij2E. We claim that this condition holds\nwhenever the edge is deleted from G. Suppose that the algorithm is currently at iand letij0be the\nedge selected by the algorithm in this step. By deﬁnition of the algorithm we have \u000ei=rij0\u0015rijso\n\u000ei+\u000ej\u0015rij.\nFinally, we address the objective.\nLemma 6. The perturbations \u000ereturned by Algorithm 1 are a 2-approximation for (1).\n7\n\nProof.In each iteration, the increase of the primal objective ( \u000ei=rijin Line 7) is exactly twice the\nincrease of the dual objective ( rij\rij=rij=2in Line 8). Thus, due to weak duality, it suﬃces to show\nthat the dual is feasible. This follows from the observation that fijj\rij= 1=2gforms a collection of\nvertex disjoint paths and cycles. Thus, for every i2V, there are at most two edges eadjacent to i\nsuch that\re>0, and for those edges e,\re= 1=2. Therefore, the dual is feasible.\nThis shows we can project the predicted dual prices ^yonto the set of feasible dual prices at\napproximately the minimum cost. The prior lemmas give the following theorem by noticing that y\u0003(c)\nis a possible feasible solution. Note that integrality is immediate from the algorithm.\nTheorem 7. There is aO(m+n)time algorithm that takes an infeasible integer dual ^yand constructs\na feasible integer dual ^y0(c)for MWPM-D with cost vector csuch thatk^y0(c)\u0000^yk1\u00142k^y\u0000y\u0003(c)k1\nwherey\u0003(c)is the optimal dual solution for MWPM-D with cost vector c. Thus by triangle inequality\nwe havek^y0(c)\u0000y\u0003(c)k1\u00143k^y\u0000y\u0003(c)k1.\n3.2 Seeding Hungarian with a Feasible Dual (Optimization)\nIn this section we assume that we are given a feasible integral dual ^y0(c)for an input with cost vector\ncand the goal is to ﬁnd an optimal solution. We want to analyze the running time in terms of\nk^y0(c)\u0000y\u0003(c)k1, the distance to optimality. We use a simple primal-dual schema to achieve this, which\nis given formally in Algorithm 2.\nAlgorithm 2 Simple Primal-Dual Scheme for MWPM\n1:procedure MWPM-PD (G= (V;E);c;y)\n2:E0 fe2Ejyi+yj=cij} .Set of tight edges in the dual\n3:G0 (V;E0) . Gcontaining only tight edges\n4:M Maximum cardinality matching in G0\n5:whileMis not a perfect matching do\n6: FindS\u0012Lsuch thatjSj>j\u0000(S)jinG0.Exists by Hall’s Theorem\n.Can be found in O(m+n)time\n7:\u000f mini2S;j2Rn\u0000(S)fcij\u0000yi\u0000yjg\n8:8i2S,yi yi+\u000f\n9:8j2\u0000(S),yj yj\u0000\u000f\n10: UpdateE0;G0\n11:M Maximum cardinality matching in G0\n12:ReturnM\nTo satisfy complementary slackness, we must only choose edges with yi+yj=cij. LetE0be\nthe set of such edges. We ﬁnd a maximum cardinality matching in the graph G0= (V;E0). If the\nresulting matching Mis perfect then we are done by complementary slackness (Lemma 2) Otherwise,\nin steps 7-9 we modify the dual in a way that guarantees a strict increase in the dual objective. Since\nall parameters of the problem are integral, this strict increase then implies our desired bound on the\nnumber of iterations.\nWe now analyze Algorithm 2. Recall that LandRgive the bipartition of V. First we show that\nthe algorithm is correct. The main claim we need to establish is that if yis initially dual feasible, then\nit remains dual feasible throughout the algorithm. First we check that the update deﬁned in lines 6-10\nis well deﬁned, i.e. in line 6 such a set Salways exists and \u000fdeﬁned in line 7 is always strictly positive.\nProposition 8. IfMis not a perfect matching in G0, then there exists a set S\u0012Lsuch that\njSj>j\u0000(S)jinG0. Further, such Scan be found in O(m+n)time.\nProof.The ﬁrst claim follows directly from Hall’s Theorem applied to G0. It is well-known that the\nmaximum matching size is equal to the minimum vertex cover size when the underlying graph is\n8\n\nbipartite. Further, a minimum vertex cover Ccan be derived from a maximum matching Min time\nO(m+n). We setS=LnC. Then, we have \u0000(S)\u0012C[Rdue toCbeing a vertex cover, and\njC\\Lj+jC\\Rj=jCj<nas the minimum cover size is less than n; recallMis not perfect. Thus,\nwe havejSj=n\u0000jC\\Lj>jC\\Rj\u0015j\u0000(S)j, as desired.\nProposition 9. Letybe dual feasible and suppose that S\u0012LwithjSj>j\u0000(S)jinG0. Let\u000f=\nmini2S;j2Rn\u0000(S)cij\u0000yi\u0000yj. Then as long as candyare integer we have \u000f\u00151.\nProof.Every edge ijconsidered in the deﬁnition of \u000fis not inE0and thus must have cij>yi+yj.\nThus for all such edges we have cij\u0000yi\u0000yj\u00151sincecandyare integer, and so \u000f\u00151.\nIf no such edge exists, then we have a set S\u0012Lsuch thatjSjis strictly larger than its neighborhood\ninG(rather than G0) which shows that the problem is infeasible. This contradicts our assumption\nthat the original problem is feasible.\nWe now show the main claims we described above.\nLemma 10. If Algorithm 2 is given an initial dual feasible y, thenyremains dual feasible throughout\nits execution.\nProof.Inductively, it suﬃces to show that if yis dual feasible then it remains so after the update steps\ndeﬁned in lines 6-10. To make the notation clear, let y0be the result of applying the update rule to\ny. Consider an edge ij2E. We want to show that y0\ni+y0\nj\u0014cijafter the update step. There are 4\ncases to check: (1) i2LnS;j2Rn\u0000(S), (2)i2LnS;j2\u0000(S), (3)i2S;j2Rn\u0000(S), and (4)\ni2S;j2\u0000(S).\nIn the ﬁrst case, neither yinoryjare modiﬁed, so we get y0\ni+y0\nj=yi+yj\u0014cijsinceywas initially\ndual feasible. In the second case we have y0\ni+y0\nj=yi+yj\u0000\u000f\u0014cijsince\u000f>0. In the third case we\nhavey0\ni=yi+\u000fand soy0\ni+y0\nj=yi+\u000f+yj\u0014cijsince there was slack on these edges and \u000fwas\nchosen to be the smallest such slack. Finally, in the last case we have y0\ni+y0\nj=yi+\u000f+yj\u0000\u000f\u0014cij.\nThus we conclude that yremains feasible throughout the execution of Algorithm 2.\nLemma 11. Each iteration strictly increases the value of the dual solution.\nProof.Note that in each iteration yiincreases by \u000ffor alli2Sandyjdecreases by \u000ffor all\nj2\u0000(S); and all other dual variables remain unchanged. Thus, the dual objective increases by\n\u000f(jSj\u0000j\u0000(S)j)\u0015\u000f.\nThe above lemma allows us to analyze the running time of our algorithm in terms of the distance\nto optimality.\nLemma 12. Consider an arbitrary cost vector c. Suppose that ^y0(c)is an integer dual feasible solution\nandy\u0003(c)is an integer optimal dual solution. If Algorithm 2 is initialized with ^y0(c), then the number\nof iterations is bounded by k^y(c)\u0000y\u0003(c)k1.\nProof.By Lemma 11, we have that the value of the dual solution increases by at least 1 in each iteration.\nThus the number of iterations is at mostP\niy\u0003\ni(c)\u0000P\ni^yi(c)\u0014P\nijy\u0003\ni(c)\u0000^yi(c)j=ky\u0003(c)\u0000^y(c)k1.\nFinally, we get the following theorem as a corollary of the lemmas above and the O(mpn)runtime\nof the Hopcroft-Karp algorithm for maximum cardinality matching [ 29]. More precisely, the above\nlemmas show that the algorithm performs at most O(ky\u0003(c)\u0000^y0(c)k1)iterations, each running in\nO(mpn)time. We can further improve this by ensuring the algorithm runs no longer than the standard\nHungarian algorithm in the case that we have large error in the prediction, i.e., ky\u0003(c)\u0000^y0(c)k1is\nlarge. In particular, steps 6 and 11 do not precisely specify the choice of the set Sand the matching\nM. If we instantiate these steps appropriately (let S=LnCfor step 6, where Cis a minimum vertex\ncover, and update Malong shortest-augmenting-paths for step 11) then we recover the Hungarian\nAlgorithm and its ~O(mn)running time.\n9\n\nTheorem 13. Consider an arbitrary cost vector c. There exists an algorithm which takes as input a fea-\nsible integer dual solution ^y0(c)and ﬁnds a minimum weight perfect matching in ~O(minfmpnky\u0003(c)\u0000^y0(c)k1;mng)\ntime, where y\u0003(c)is an optimal dual solution.\n3.3 Learning Optimal Advice (Learning)\nNow we want to formally instantiate the “learning\" part of our framework: if there is a good starting\ndual solution for a given input distribution, we want to ﬁnd it without seeing too many samples. The\nformal model we will use is derived from data driven algorithm design and PAC learning.\nWe imagine solving many problem instances drawn from the same distribution. To formally model\nthis, we letDbe an unknown distribution over instances. For simplicity, we consider the graph\nG= (V;E)to be ﬁxed with varying costs. Thus Dis a distribution over cost vectors c2RE. We\nassume that the costs in this distribution are bounded. Let C:=maxc\u0018Dmaxe2Ecebe ﬁnite and\nknown to the algorithm. Our goal is to ﬁnd the (not necessarily feasible) dual assignment that performs\n“best” in expectation over the distribution. Based on Theorems 7 and 13 , we know that the “cost”\nof using dual values ywhen the optimal dual is y\u0003is bounded by O(mpnky\u0003\u0000yk1), and hence it is\nnatural to deﬁne the “cost\" of yasky\u0003\u0000yk1.\nFor everyc2REwe will lety\u0003(c)be a ﬁxed optimal dual solution for c:\ny\u0003(c) := arg max\nynX\niyij8ij2E;yi+yj\u0014cijo\n:\nHere we assume without loss of generality that y\u0003(c)is integral as the underlying polytope is known to\nbe integral. We will let the loss of a dual assignment ybe its`1-distance from the optimal solution:\nL(y;c) =ky\u0000y\u0003(c)k1:\nOur goal is to learn dual values ^ywhich minimizes Ec\u0018D[L(y;c)]. Lety\u0003denote the vector\nminimizing this objective, y\u0003= arg min yEc\u0018D[L(y;c)].\nWe will give PAC-style bounds, showing that we only need a small number of samples in order to\nhave a good probability of learning an approximately-optimal solution ^y. Our algorithm is conceptually\nquite simple: we minimize the empirical loss after an appropriate number of samples. We have the\nfollowing theorem.\nTheorem 14. There is an algorithm that after s=O\u0010\u0000nC\n\u000f\u00012(nlogn+ log(1=p))\u0011\nsamples returns\ndual values ^ysuch that Ec\u0018D[L(^y;c)]\u0014Ec\u0018D[L(y\u0003;c)] +\u000fwith probability at least 1\u0000p. The algorithm\nruns in time polynomial in n;mands.\nThis theorem, together with Theorems 7 and 13, immediately implies Theorem 3.\n3.3.1 Proof of Theorem 14\nWe now discuss the main tools we require from statistical learning theory in order to prove Theorem 14.\nFor every dual assignment y2RV, we deﬁne a function gy:RE!Rbygy(c) =L(y;c) =ky\u0003(c)\u0000yk1.\nLetH=fgyjy2RVgbe the collection of all such functions. It turns out that in order to prove\nTheorem 14, we just need to bound the pseudo-dimension of this collection. Note that the notion of\nshattering and pseudo-dimension in the following is a generalization to real-valued functions of the\nclassical notion of VC-dimension for boolean-valued functions (classiﬁers).\nDeﬁnition 15. [45,3,40] LetFbe a class of functions f:X!R. LetS=fx1;x2;:::;xsg\u001aX.\nWe say that that Sisshattered byFif there exist real numbers r1;:::;rsso that for all S0\u0012S, there\nis a function f2Fsuch thatf(xi)\u0014ri()xi2S0for alli2[s]. Thepseudo-dimension ofFis\nthe largestssuch that there exists an S\u0012XwithjSj=sthat is shattered by F.\n10\n\nTheconnectionbetweenpseudo-dimensionandlearningisgivenbythefollowinguniformconvergence\nresult.\nTheorem 16. [45,3,40] LetDbe a distribution over a domain XandFbe a class of functions\nf:X![0;H]with pseudo-dimension dF. Consider sindependent samples x1;x2;:::;xsfromD.\nThere is a universal constant c0, such that for any \u000f>0andp2(0;1), ifs\u0015c0\u0000H\n\u000f\u00012(dF+ln(1=p))\nthen we have \f\f\f\f\f1\nssX\ni=1f(xi)\u0000Ex\u0018D[f(x)]\f\f\f\f\f\u0014\u000f\nfor allf2Fwith probability at least 1\u0000p.\nIntuitively, this theorem says that the sample average1\nsPs\ni=1f(xi)is close to its expected value for\nevery function f2Fsimultaneously with high probability so long as the sample size sis large enough.\nThis theorem can be utilized to give a learning algorithm for our problem by considering an algorithm\nwhich minimizes the empirical loss. In general, the “best” function is the one which minimizes the\nexpected value over D, i.e.f\u0003=arg minf2FEx\u0018D[f(x)]. We have the following simple corollary for\nlearning and approximately best function ^h.\nCorollary 17. Consider a set of sindependent samples x1;x2;:::;xsfromDand let ^fbe a function\ninFwhich minimizes1\nsPs\ni=1^f(xi). Ifsis chosen as in Theorem 16, then with probability 1\u0000pwe\nhaveEx\u0018D[^f(x)]\u0014Ex\u0018D[f\u0003(x)] + 2\u000f\nThus based on the above Theorem and Corollary, to prove Theorem 14 we must accomplish the\nfollowing tasks. First and foremost, we must bound the pseudo-dimension of our class of functions H.\nNext, we need to check that the functions are bounded on the domain we consider, and ﬁnally we need\nto give an algorithm minimizing the empirical risk. The latter two tasks are simple. By assumption\nthe edge costs are bounded by C. If we restrictHto be within a suitable bounding box, then one\ncan verify that we can take H=O(nC)to satisfy the conditions for Theorem 16. Additionally, the\ntask of ﬁnding a function to minimize the loss on the sample can be done via linear programming. We\nformally verify these details in Sections 3.3.2 and 3.3.3. This leaves bounding the pseudo-dimension of\nthe classH, which we focus on now.\nTo bound the pseudo-dimension of H, we will actually consider a diﬀerent class of functions Hn: for\neveryy2Rnwe deﬁne a function fy:Rn!Rbyfy(x) =ky\u0000xk1, and we letHn=ffyjy2Rng.\nIt is not hard to argue that it is suﬃcient to bound the pseudo-dimension of this class.\nLemma 18. If the pseudo-dimension of Hnis at mostk, then the pseudo-dimension of His at most\nk.\nProof.We prove the contrapositive: we start with a set of size swhich is shattered by H, and use it\nto ﬁnd a set of size swhich is shattered by Hn. LetS=fc1;c2;:::;csgwith eachci2REbe a set\nwhich is shattered by H. Then there are real numbers r1;r2;:::;rsso that for all S0\u0012[s], there is a\nfunctiong2Hwhereg(ci)\u0014ri()i2S0. By deﬁnition of H, thisgisgyS0for someyS02Rn, and\nsokyS0\u0000y\u0003(ci)k1\u0014ri()i2S0.\nLet^S=fy\u0003(c1);y\u0003(c2);:::;y\u0003(cs)g. We claim that ^Sis shattered byHn. To see this, consider the\nsame real numbers r1;:::;rsand someS0\u0012[s]. ThenfyS0(y\u0003(ci)) =kyS0\u0000y\u0003(ci)k1=gyS0(ci)and\nhencefyS0(y\u0003(ci))\u0014ri()gyS0(ci)\u0014ri()i2S0. Thus ^Sis shattered byHn.\nSo now our goal is to prove the following bound, which (with Lemma 18 and Theorem 16) implies\nTheorem 14.\nTheorem 19. The pseudo-dimension of Hnis at mostO(nlogn).\n11\n\nLetkbe the pseudo-dimension of Hn. Then by the deﬁnition of pseudo-dimension there is a set\nP=fx1;x2;:::;xkgwhich is shattered by Hn, so there are values r1;r2;:::;rk2R\u00150so that for all\nS\u0012Pthere is anf2Hnsuch thatf(xi)\u0014ri()xi2S. By our deﬁnition of Hd, this means that\nthere is ayS2Rnso thatkyS\u0000xik1\u0014ri()xi2S.\nFor eachS\u0012P, deﬁne the regionofS(denoted by r(S)) to be\nr(S) =fy2Rn:ky\u0000xik1\u0014ri()xi2Sg;\ni.e., the set of points that are at `1-distance at most rifromxifor precisely the xi’s that are in S.\nClearly each r(S)is nonempty for every S\u0012Pdue to the existence of yS. Letm= 2kbe the number\nof nonempty regions.\nTo upper bound the pseudo-dimension kwe will prove that there cannot be too many nonempty\nregions (i.e., mis small). This is somewhat complex since the `1-balls have complex structure (in\nparticular, have 2dfacets), so we will do this by partitioning Rnintocellsin which the `1balls are\nsimpler. For each xi2Pandj2[n], letQi\njbe the hyperplane in Rnthat passes through yiand is\nperpendicular to the axis ej(i.e.,Qi\nj=fy2Rn:hy\u0000xi;eji= 0g). Clearly there are knof these\nhyperplanes. Deﬁne a cellto be a maximal set of points in Rnwhich are the same side of every\nhyperplane. Note that there are (k+ 1)nof these cells, they partition Rn, and every cell which is\nbounded is a hypercube.\nLemma 20. LetCbe a cell and xi2P. There is a halfspace Hsuch thatB1(xi;ri)\\C=H\\C.\nProof.IfB1(xi;ri)\\C=;then we are done. So suppose that B1(xi;ri)\\C6=;. By deﬁnition,\nB1(xi;ri)is the set of points y2Rnsuch thatPn\nj=1jxi\nj\u0000yjj\u0014ri. HenceB1(xi;ri)is deﬁned by the\nintersection of 2nhalfspaces:\nB1(xi;ri) =8\n<\n:y2RnjnX\nj=1aj(xi\nj\u0000yj)\u0014ri8a2f\u0000 1;+1gn9\n=\n;\nIf the intersection of the boundary of B1(xi;ri)withCis one of these hyperplanes, then we are\nﬁnished. Otherwise, there are at least two of these hyperplanes H1= (a1;:::an)andH2= (a0\n1;:::;a0\nn)\nsuch thatB1(xi;ri)\\Ccontains a point y2H1nH2and a point y02H2nH1, both of which are also\non the boundary of B1(xi;ri). Letj2[n]such thataj=\u0000a0\nj. Thenyj\u0000xi\njhas a diﬀerent sign than\ny0\nj\u0000xi\nj, since the fact that yandy0are on the boundary of B1(xi;ri)but on diﬀerent facets implies\nthatxi\nj\u0000yjhas signajwhilexi\nj\u0000y0\njhas signa0\nj. But this contradicts the deﬁnition of C, since it\nmeans that yandy0are on diﬀerent sides of Qi\njand hence not in the same cell.\nThis lemma allows us to analyze the number of regions that intersect any cell.\nLemma 21. LetCbe a cell. The number of regions that intersect Cis at most 2O(n)kn.\nProof.For everyS\u0012P, the region r(S)is the set of points that are in B1(xi;ri)for allxi2Sand are\nnot inB1(xi;ri)for allxi62S. By Lemma 20, r(S)\\Cis the intersection of Cwithkhalfspaces (one\nfor eachxi2P). It is well-known that khalfspaces can divide Rninto at mostPn\ni=0\u0000k\ni\u0001\n=O(n)kn\nregions, and hence the same bound holds for C.\nNow some standard calculations imply Theorem 19, and hence Theorem 14.\nProof of Theorem 19. Lemma 21, together with the fact that there are at most (k+ 1)ncells, implies\nthat the number of nonempty regions mis at mostO(n)kn\u0001(k+ 1)n\u0014O(n)(k+ 1)2n. Sincem= 2k,\nthis implies that 2k\u0014O(n)(k+ 1)2n. Taking logarithms of both sides yields that\nk\u0014log(k+ 1)\u0001O(n); (3)\nand then taking another logarithm and rearranging yields that logn\u0015\n(logk\u0000log logk) = \n( logk)\nand hence log(k+ 1)\u0014O(logn). Plugging this into (3) implies Theorem 19.\n12\n\n3.3.2 Bounding the Range\nIn this section we verify the condition for Theorem 16 that every function in Hhas its range in [0;H]\nforH=O(nC). This is actually not quite true as deﬁned, but it is easy enough to ensure: we just\nconsider a restricted class of functions H0=fgyjgy2H;y2[\u0000C;C]Vg. Note that for any ﬁxed set of\ncostscthe classH0containsy\u0003(c), so without loss of generality we can just use H0instead ofH. From\nthe deﬁnition of pseudo-dimension and H0\u0012H, it immediately follows that the pseudo-dimension of\nH0is at most that of H. Thus, we just need to ensure that the range of the restricted functions are\nbounded.\nLemma 22. Each function gy2H0has its range in [0;H]forH=O(nC).\nProof.Let’s bound the range by considering the maximum value gycan take on a set of costs c.\nRecall that gy(c) =ky\u0000y\u0003(c)k1. Each coordinate can contribute at most O(C)to the sum since\ny\u0003\ni(c)2[\u0000C;C]andyi2[\u0000C;C]. Summing over the ncoordinates gives H=O(nC).\n3.3.3 Minimizing the Empirical Loss\nNow we give an algorithm to minimize the empirical loss on a collection of sample instances. Let\nc1;c2;:::;csbe a collection of samples from D. Our goal is to ﬁnd dual prices yminimizing\n1\nsPs\ni=1gy(ci) =1\nsPs\ni=1ky\u0000y\u0003(ci)k1. Letxi=y\u0003(ci). Then the problem amounts to minimiz-\ning1\nsPs\ni=1ky\u0000xik1overy2[\u0000C;C]V. Then, for each coordinate jit suﬃces to ﬁnd yjminimizingPs\ni=1kyj\u0000xi\njk1, whereyjandxi\njdenote the j-th coordinate of yandxi, respectively. Further, it is\neasy to see thatPs\ni=1kyj\u0000xi\njk1is a continuous piece-wise linear function in yjwhere the slope can\nchange only atfxi\njgi2[s]. Recalling that we can assume wlog that xi=y\u0003(ci)is an integer vector, we\nonly need to consider setting yjto each value infxi\njgi2[s], which is a set of integers. This leads to the\nfollowing result.\nTheorem 23. Givenssamplesc1;c2;:::;cs, there exists a polynomial time algorithm which ﬁnds\ninteger dual prices yminimizing1\nsPs\ni=1ky\u0000y\u0003(ci)k1.\nWe remark that minimizing this empirical loss can be eﬃciently implemented by taking the\ncoordinate-wise median of each optimal dual, i.e. taking yj=median (x1\nj;x2\nj;:::;xs\nj)for eachj2V.\n4 Experiments\nIn this section we present experimental results on both synthetic and real data sets. Our goal is to\nvalidate the two main hypotheses in this work. First we show that warm-starting the Hungarian\nalgorithm with learned duals provides an empirical speedup. Next, we show that the sample complexity\nof learning good duals is small, ensuring that our approach is viable in practice. We present some\nrepresentative experimental results here; additional results are in the Appendix A.\nExperimentSetup: AllofourexperimentswererunonGoogleCloudPlatform[ 27]e2-standard-2\nvirtual machines with 2 virtual CPU’s and 8 GB of memory.\nWe consider two diﬀerent setups for learning dual variables and evaluating our algorithms.\n•Batch: In this setup, we receive ssamplesc1;c2;:::;csfrom the distribution of problem instances,\nlearn the appropriate dual variables, and then test on new instances drawn from the distribution.\n•Online: A natural use case for our approach is an onlinesetting, where instance graphs G1;G2;:::\narrive one at a time. When deciding on the best warm start solution for Gtwe can use all of the\ndata fromG1;:::;Gt\u00001. This is a standard scenario in industrial applications like ad matching,\nwhere a new ad allocation plan may need to be computed daily or hourly.\nDatasets: To study the eﬀect of the diﬀerent algorithm parameters, we ﬁrst run a study on\nsynthetic data. Let nbe the number of nodes on one side of the bipartition and let `;vbe two\nparameters we set later. First, we divide the nnodes on each side of the graph into `groups of equal\n13\n\nDataset Blog Feedback [12] Covertype KDD Skin [10] Shuttle\n# of Points ( n) 52,397 581,012 98,942 100,000 43500\n# of Features ( d) 281 54 38 4 10\nTable 1: Datasets used in experiments based on Euclidean data\nsize. The weight of all edges going from the i’th group on the left side and the j’th group on the right\nside is initialized to some value Wi;jdrawn from a geometric distribution with mean 250. Then to\ngenerate a particular graph instance, we perturb each edge weight with independent random noise\naccording to a binomial distribution, shifted and scaled so that it has mean 0 and variance v. We refer\nto this as the typemodel (each type consists of a group of nodes). We use n= 500,`2f50;100gand\nvaryvfrom 0to220.\nWe use the following model of generating instances from real data. Let Xbe a set of npoints in\nRd, and ﬁx a parameter k. We ﬁrst divide Xrandomly into two sets, XLandXRand compute a\nk-means clustering on each partition. To generate an instance G= (L[R;E), we sample one point\nfrom each cluster on each side, generating 2kpoints in total. The points sampled from XL(resp.XR)\nform the vertices in L(resp.R). The weight of an (i;j)edge is the Euclidean distance between these\ntwo points. Changing kallows us to control the size of the instance.\nWe use several datasets from the UCI Machine Learning repository [ 19]. See Table 1 for a summary.\nFor the KDD and Skin datasets we used a sub-sample of the original data (sizes given in Table 1).\nImplemented Algorithms and Metrics: We implemented the Hungarian Algorithm (a par-\nticular instantiation of Algorithm 2, as discussed in Section 3.2) allowing for arbitrary seeding of a\nfeasible integral dual. We experimented with having initial dual of 0(giving the standard Hungarian\nAlgorithm) as the baseline and having the initial duals come from our learning algorithm followed by\nAlgorithm 1 to ensure feasibility (which we refer to as “Learned Duals”). We also added the following\n“tightening” heuristic, which is used in all standard implementations of the Hungarian algorithm: given\nany feasible dual solution y, setyi yi+minj2N(i)fcij\u0000yi\u0000yjgfor all nodes ion one side of the\nbipartition. This can be quickly carried out in O(n+m)time, and guarantees that each node on\nthat side has at least one edge in E0. We compare the runtime and number of primal-dual iterations,\nreporting mean values and error bars denoting 95% conﬁdence intervals. The runtime results can\nbe found in Appendix A, and exhibit similar behavior (i.e., the extra running time caused by using\nAlgorithm 1 in Learned Duals is negligible).\nTo learn initial duals we use a small number of independent samples of each instance type. We\ncompute an optimal dual solution for each instance in the sample. To combine these together into\na single dual solution, we compute the median value for each node’s set of dual values. This is an\neﬃcient implementation of the empirical risk minimization algorithm from Section 3.3.\nResults: First, we examine the performance of Learned Duals in the batch setting described above.\nFor these experiments, we used 20 training instances to learn the initial duals and then tested those on\n10 new instances. For the type model, we used `= 50and considered varying the variance parameter\nv. The left plot in Figure 1 shows the results as we increase vfrom 0to300. We see a moderate\nimprovement in this case, even when the noise variance is larger than the mean value of an edge weight.\nGoing further, in the middle plot of Figure 1 we consider increasing the noise variance in powers of two\ngeometrically. For both of these plots, we mark the x-axis according to v=250which is the ratio of the\nnoise variance to the mean value of the original weights. Note that even when the noise signiﬁcantly\ndominates the original signal from the mean weights (and hence the training instances should not help\non the test instances), our method is comparable to the Hungarian method.\nContinuing with the Batch setting, the right plot in Figure 1 summarizes our results for the\nclustering derived instances on all datasets with k= 500(similar results hold for other values of k; see\nFigure 4). We see an improvement across all datasets, and a greater than 2x improvement on all but\nthe Covertype dataset.\nFigures 2 and 3 display our results in the online setting. We aim to show that not too many\nsamples are needed to learn eﬀective duals. From left to right, the plots in Figure 2 show the\n14\n\nperformance averaged over 20 repetitions of the experiment with 20 time points on the type model\nwith`= 100;v= 200, and the clustering derived instances on the KDD and Covertype datasets with\nk= 500, respectively. We see that only a few iterations are needed to see a signiﬁcant separation\nbetween the run time of our method with learned duals and the standard Hungarian method, with\nfurther steady improvement as we see more instances.\nWe see similar trends in both the real and synthetic data sets. We conclude the following.\n•The theory is predictive of practice. Empirically, learning dual variables can lead to signiﬁcant\nspeed-up. This speed-up is achieved in both the batch and online settings.\n•As the distribution is more concentrated, the learning algorithm performs better (as one would\nsuspect).\n•When the distribution is not concentrated and there is little to learn, then the algorithm has\nperformance similar to the widely used Hungarian algorithm.\nAll together, these results demonstrate the strong potential for improvements in algorithm run\ntime using machine-learned predictions for the weighted matching problem.\n/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000019 /uni00000013/uni00000011/uni0000001b /uni00000014/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000015\n/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000012/uni00000003/uni00000030/uni00000048/uni00000044/uni00000051/uni00000003/uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000013/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013/uni00000019/uni00000013/uni0000002c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000037/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000030/uni00000052/uni00000047/uni00000048/uni0000004f/uni00000003/uni0000002c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000003/uni00000059/uni00000056/uni00000011/uni00000003/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048\n/uni00000030/uni00000048/uni00000057/uni0000004b/uni00000052/uni00000047\n/uni0000002b/uni00000058/uni00000051/uni0000004a/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051\n/uni0000002f/uni00000048/uni00000044/uni00000055/uni00000051/uni00000048/uni00000047/uni00000003/uni00000027/uni00000058/uni00000044/uni0000004f/uni00000056\n/uni00000015/uni00000019\n/uni00000015/uni00000016\n/uni00000015/uni00000013\n/uni00000015/uni00000016\n/uni00000015/uni00000019\n/uni00000015/uni0000001c\n/uni00000015/uni00000014/uni00000015\n/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000012/uni00000003/uni00000030/uni00000048/uni00000044/uni00000051/uni00000003/uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000015/uni00000016/uni00000015/uni00000017/uni00000015/uni00000018/uni00000015/uni00000019/uni00000015/uni0000001a/uni00000015/uni0000001b/uni00000015/uni0000001c/uni00000015/uni00000014/uni00000013/uni0000002c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000037/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000030/uni00000052/uni00000047/uni00000048/uni0000004f/uni00000003/uni0000002c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000026/uni00000052/uni00000058/uni00000051/uni00000057/uni00000003/uni00000059/uni00000056/uni00000011/uni00000003/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048\n/uni00000030/uni00000048/uni00000057/uni0000004b/uni00000052/uni00000047\n/uni0000002b/uni00000058/uni00000051/uni0000004a/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051\n/uni0000002f/uni00000048/uni00000044/uni00000055/uni00000051/uni00000048/uni00000047/uni00000003/uni00000027/uni00000058/uni00000044/uni0000004f/uni00000056\nShuttle Skin Blog Feedback Covertype KDD\nDataset02004006008001000Iteration CountClustering-Based Instances, k = 500\nMethod\nHungarian\nLearned Duals\nFigure 1: Iteration count results for the Batch setting. The left ﬁgure gives the iteration count for the\ntype model (synthetic data) versus linearly increasing v, while the middle geometrically increases v.\nThe right ﬁgure summarizes the results for clustering based instances (real data) in the batch setting.\n012345678910111213141516171819\nInstance Number25.027.530.032.535.037.540.042.545.0Iteration CountType Model, v = 200 - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number40060080010001200Iteration CountKDD - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number350400450500550600Iteration CountCovertype - Online Setting\nMethod\n Hungarian\n Learned Duals\nFigure 2: Iteration count results for the Online setting. The left ﬁgure is for the type model (synthetic\ndata), while the middle and right are for the clustering based instances (real data) with k= 500on\nKDD and Covertype, respectively.\n5 Extending to b-Matching\nWe now extend the results from Section 3 to the minimum weight perfect b-matching problem on\nbipartite graphs. In the extension we are given a bipartite graph G= (V;E), whereV=L[R, a\n15\n\n012345678910111213141516171819\nInstance Number450500550600650700Iteration CountBlog Feedback - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number50100150200250300350400Iteration CountShuttle - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number405060708090100110Iteration CountSkin - Online Setting\nMethod\n Hungarian\n Learned DualsFigure 3: More iteration count results for the Online setting. From left to right, we have the results\nfor the clustering based instances on Blog Feedback, Shuttle, and Skin, all with k= 500.\nweight vector c2ZE\n+and a demand vector b2ZV\n+. As before, we assume that the primal is feasible\nfor the remainder of this section. Note that the feasibility of the primal can be checked with a single\ncall to a maximum ﬂow algorithm.\nThe problem is modeled by the following linear program and its dual linear program.\nminX\ne2Ecexe\nX\ne2\u000e(i)xe=bi8i2V\nxe\u001508e2E(MWBM-P)\nmaxX\ni2Vbiyi\nyi+yj\u0014cij8ij2E(MWBM-D)\nFirst we show how to project an infeasible dual onto the set of feasible solutions, then we give a\nsimple primal dual scheme for moving to an optimal solution. The end goal of this section is proving\nthe following theorem.\nTheorem 24. There exists an algorithm which takes as input a (not necessarily feasible) dual as-\nsignmentyand ﬁnds a minimum weight perfect b-matching in O(mnky\u0003\u0000yk1)time, where y\u0003is an\noptimal dual solution and ky\u0003\u0000ykb;1:=P\nibijy\u0003\ni\u0000yij.\n5.1 Recovering a Feasible Dual Solution for b-Matching\nAs in Section 3, our goal now is to ﬁnd non-negative perturbations \u000esuch that ^y0:=^y\u0000\u000eis feasible\nfor(MWPM-D) . We would like these perturbations to preserve as much of the dual objective value as\npossible. Again we deﬁne re:=^yi+^yj\u0000cefor each edge e=ij2E. Following the same steps as\nbefore, this leads to the following linear program and it’s dual.\nminX\ni2Vbi\u000ei\n\u000ei+\u000ej\u0015re8e=ij2E\n\u000ei\u001508i2V(4)\n16\n\nShuttle Skin Blog Feedback Covertype KDD\nDataset020406080100120140160Iteration CountClustering-Based Instances, k = 100\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset050100150200250300350400Iteration CountClustering-Based Instances, k = 200\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset0100200300400500600700Iteration CountClustering-Based Instances, k = 300\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset02004006008001000Iteration CountClustering-Based Instances, k = 400\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset020040060080010001200Iteration CountClustering-Based Instances, k = 600\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset025050075010001250150017502000Iteration CountClustering-Based Instances, k = 700\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset0500100015002000Iteration CountClustering-Based Instances, k = 800\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset05001000150020002500Iteration CountClustering-Based Instances, k = 900\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset0500100015002000Iteration CountClustering-Based Instances, k = 1000\nMethod\nHungarian\nLearned DualsFigure 4: Iteration count results for clustering derived instances in the Batch setting on other values\nofk. Here we give the results for each kinf100\u0001ij1\u0014i\u001410gnf500g.\nmaxX\ne2Ere\re\nX\ne2N(i)\re\u0014bi8i2V\n\re\u001508e2E(5)\nAgain we are interested in ﬁnding a fast approximate solution to this problem. We develop a new\nalgorithm diﬀerent than that used in the prior section and show it is a 2approximation to (4). To\ndo so, consider the dual LP above. This is an instance of the weighted b-matching problem where\nedges can be selected any number of times. We will ﬁrst develop a 2approximation to this LP in\nO(mlogm+n)time. The analysis will be done via a dual ﬁtting analysis. This analysis will give us\nthe corresponding 2-approximate fractional primal solution that will be used to construct ^y0.\nConsider the following algorithm for the dual problem. Sort the edges ein decreasing order of re.\nWhen considering an edge e0=i0j0in this order set \re0as large as possible such thatP\ne2N(i0)\re\u0014bi0\n17\n\nandP\ne2N(j0)\re\u0014bj0. Notice the running time of the algorithm is bounded by O(mlogm+n).\nWhen the algorithm terminates we construct a corresponding primal solutions. For each i2V, set\n\u000ei=P\ne2N(i)\rere\nbi. That is,\u000eiis the summation of the weights rof the adjacent edges divided by the\nb-matching constraint value bi. We will show that \u000eis a feasible primal solution. Moreover that the\nprimal and dual objectives are within a factor two of each other.\nLemma 25. The solution \u000eis feasible for LP (4) and \ris feasible for the dual LP (5).\nProof.The feasibility for the dual is by construction, so consider the primal. Consider any edge\ne0=i0j0. Our goal is to show that \u000ei0+\u000ej0\u0015re0. LetAe0be the set of edges considered by the\nalgorithm up to edge e0including the edge itself. These edges have weight at least as large e0. We\nclaim that eitherP\ne2N(i0)\\Ae0\re=bi0orP\ne2N(j0)\\Ae0\re=bj0. Indeed, otherwise we would increase\n\re0until this is true. Without loss of generality say thatP\ne2N(i0)\\Ae0\re=bi0. We will argue that\n\u000ei0\u0015re0. Knowing that \u000ej0is non-negative, this will complete the proof.\nConsider the value of \u000ei0. This isP\ne2N(i0)\rere\nbi0=P\ne2N(i0)\\Ae0\rere\nbi0. We know from the above that\nP\ne2N(i0)\\Ae0\re=bi0and every edge in Ae0has weight greater than e0. Thus,P\ne2N(i0)\\Ae0\rere\nbi0\u0015\nre0P\ne2N(i0)\\Ae0\re\nbi0=re0\nNext we bound the objective of the primal as a function of the dual.\nLemma 26. The primal objective is exactly twice the dual objective.\nProof.It suﬃces to show each edge e=ijcontributes twice as much to the primal objective as it does\nto the dual objective. First, e’s contribution to the dual objective is clearly re\re. For the dual, edge e\ncontributes to the summation for both end points. That is, econtributes to \u000eiby\rere=biand to\u000ejby\n\rere=bj. Thus, edge e’s contribution to the primal objective is bi\rere\nbi+bj\rere\nbj= 2\rere, as desired.\nThus, we have found a 2-approximate solution to the primal LP (4). However, the solution is not\nnecessarily integral. Thus, to make it integral, we do the following simple rounding:\n\u000ei (\nb2\u000eicif\u000ei\u00150:5\n0if\u000ei2[0;0:5)\nClearly this update can double the cost in the worst case. Hence we only need to check that every\nconstraint remains satisﬁed. To see this consider an edge e=ijand let\u000eiand\u000ejbe the dual values\nbefore the update. Note that reis an integer assuming that we are given integer dual values ^y. Assume\nre\u00151since otherwise the constraint trivially holds true. It is an easy exercise to see that b2xc\u0015x\nfor allx\u00150:5. Thus, if\u000ei;\u000ej\u00150:5, then the update only increases the value of \u000eiand\u000ej, keeping\nthe constraint satisﬁed. Further, as re\u00151, it must be the case that \u000ei\u00150:5or\u000ej\u00150:5. So, we only\nneed to consider the case either \u000ei\u00150:5and\u000ej<0:5; or\u000ei<0:5and\u000ej\u00150:5. Assume wlog that the\nlatter is the case. Since \u000ei\u0014\u000ej, if\u000ei+\u000ej\u0015re, we have 2\u000ej\u0015re. Then, we haveb2\u000ejc\u0015reasreis an\ninteger. Again, the constraint is satisﬁed.\nThus, we obtain the following which is analogous to Theorem 7.\nTheorem 27. There is aO(mlogm+n)time algorithm that takes an infeasible integer dual ^yand\nconstructs a feasible integer dual ^y0such thatk^y\u0000^y0kb;1\u00144ky\u0003\u0000^ykb;1wherey\u0003is the optimal dual\nsolution. Thus, we have k^y0\u0000y\u0003kb;1\u00145k^y\u0000y\u0003kb;1.\n5.2 Converting a Feasible Dual Solution to an Optimal Primal Solution\nNow we consider taking a feasible dual yand moving to an optimal solution for the b-matching problem.\nThe algorithm we use is a simple primal-dual scheme that generalizes Algorithm 2. See Algorithm 3\n18\n\nfor details. Below we give a brief analysis of this algorithm. The objective is to establish a running\ntime in terms of the following distance ky\u0003\u0000ykb;1:=P\nibijy\u0003\ni\u0000yij. One can view this distance as the\n`1norm distance where each coordinate axis is given a diﬀerent level of importance by the bivalues.\nAlgorithm 3 Simple Primal-Dual Scheme for MWBM\n1:procedure MWBM-PrimalDual (G= (V;E);c;y)\n2:E0 fij2Ejyi+yj=cij} .Set of tight edges in the dual\n3:G0 (L[R[fs;tg;E0[fsiji2Lg[fjtjj2Rg) .Network of tight edges\n4:8e2E(G0)s.t.e=siore=it,ue bi\n5:ue 1for all other edges of G0\n6:f Maximums\u0000tﬂow inG0with capacities u\n7:whileValue offis<P\ni2Lbido\n8: Find a setS\u0012Lsuch thatP\ni2Sbi>P\nj2\u0000(S)bj .Exists by Lemma 28\n.Can be found in O(m+n)time\n9:\u000f mini2S;j2Rn\u0000(S)fcij\u0000yi\u0000yjg\n10:8i2S,yi yi+\u000f\n11:8j2\u0000(S),yj yj\u0000\u000f\n12: UpdateE0;G0;u\n13:f Maximums\u0000tﬂow inG0with capacities u\n14:x frestricted to edges of G\n15:Returnx\nFirst we consider the correctness of the algorithm. As before, we need to show that the update rule\nis well deﬁned. The following is a well known generalization of Hall’s theorem, showing that line 8 is\nwell deﬁned. Further, the step can be implemented eﬃciently given f. The proof closely follows that\nof Proposition 8 – the only diﬀerence is factoring bin the matching size and vertex cover size.\nProposition 28. LetG0be the ﬂow network deﬁned in Algorithm 3 with capacities \u001aand letfbe\nthe maximum s\u0000tﬂow inG0if the value of fis less thanP\ni2Lbithen there exists S\u0012Lsuch thatP\ni2Sbi>P\nj2\u0000(S)bj. Further, such Scan be found in O(m+n)time.\nThe following is analogous to Proposition 9 in Section 3.\nProposition 29. Letybe dual feasible and suppose that S\u0012LwithP\ni2Sbi>P\nj2\u0000(S)bjinG0. Let\n\u000f= mini2S;j2Rn\u0000(S)fcij\u0000yi\u0000yjg. Then as long as candyare integers we have \u000f\u00151.\nAdditionally, we need to establish that yremains feasible throughout the execution of the algorithm.\nThis is nearly identical to the corresponding lemma in Section 3 so we state it as the following lemma\nwithout proof.\nLemma 30. If Algorithm 3 is given an initial dual feasible y, thenyremains dual feasible throughout\nits execution.\nThe above statements can be combined to give the following theorem.\nTheorem 31. There exists an algorithm for minimum weight perfect b-matching in bipartite graphs\nwhich runs in time O(nmky\u0003\u0000ykb;1), wherey\u0003is an optimal dual solution and yis the initial dual\nfeasible solution passed to the algorithm.\nProof.The correctness of the algorithm is implied by Lemma 30 and the fact that the ﬂow network G0\nensures that the resulting solution xthat it ﬁnds satisﬁes complementary slackness with y. Thus we\njust need to establish the running time.\nNote that it suﬃces to bound the number of iterations in terms of O(ky\u0003\u0000ykb;1)since the most\ncostly step of each iteration is ﬁnding the maximum ﬂow in the network G0, which can be done in time\nO(nm). The two propositions above state that the net increase in the dual objective is always at least\n1, and so the number of iterations is at mostP\nibiy\u0003\ni\u0000P\nibiyi\u0014P\nibiky\u0003\ni\u0000yik=ky\u0003\u0000ykb;1.\n19\n\nThis theorem, combined with Theorem 27, gives Theorem 24, as desired.\n5.3 Learning the Dual Prices\nIn this section we extend the results from Section 3.3 to the case of b-matching. As before, we consider\na graph with ﬁxed demands band an unknown distribution Dover the edge costs c. We are interested\nin learning a ﬁxed set of prices ywhich is in some sense best for this distribution. Since the running\ntime of the algorithms we consider depends on ky\u0003\u0000ykb;1it is natural to choose this as our loss\nfunction with respect to the learning task. Thus we deﬁne Lb(y;c) =ky\u0000y\u0003(c)kb;1, where again y\u0003(c)\nis a ﬁxed optimal dual vector for costs c. Our goal is to perform well against the best choice for the\ndistribution. Formally, let y\u0003:=arg minyEc\u0018D[Lb(y;c)]. Additionally, let Cbe a bound on the edge\ncosts andB=maxi2Vbibe a bound on the demands. We have the following result which is analogous\nto Theorem 14.\nTheorem 32. There is an algorithm that after s=O\u0010\u0000nCB\n\u000f\u00012(nlogn+ log(1=\u001a)\u0011\nsamples returns\ninteger dual values ^ysuch that Ec\u0018D[Lb(^y;c)]\u0014Ec\u0018D[L(y\u0003;c] +\u000fwith probability at least 1\u0000\u001a. The\nalgorithm runs in time polynomial in n;mands.\nAt a high level, we can prove this theorem by again applying Theorem 16 and Corollary 17. To do\nthis we deﬁne the following family of functions Hb=fgyjy2RVgwheregy=ky\u0000y\u0003(c)kb;1. We need\nto verify the following: (1) the range of these functions are bounded in [0;H]for someH=O(nCB ),\n(2) minimizing the empirical loss can be done eﬃciently, and (3) the pseudo-dimension of Hbis bounded\nbyO(nlogn). Applying similar arguments as in Sections 3.3.2 and 3.3.3 give us the ﬁrst two points.\nHere we focus on the last point, bounding the pseudo-dimension.\nNote that for b2Rn\n+,k\u0001kb;1is a norm. Intuitively, the geometry induced by k\u0001kb;1is the same as\nthe geometry induced by k\u0001k 1except some axes are stretched by an appropriate amount. This should\nimply that the functions in Hbshould not be more complicated than the functions in H. We make\nthis intuition more formal by arguing that we can map from one setting to the other while preserving\nmembership in the respective balls induced by these norms. The following key lemma will imply that\nthe pseudo-dimension of Hbis no larger than the pseudo-dimension of H.\nLemma 33. LetBb;1(x;r) =fyjkx\u0000ykb;1\u0014rgandB1(x;r) =fyjkx\u0000yk1\u0014rgbe the balls of\nradiusrunder each norm, respectively. There is a mapping \u001e:Rn!Rnsuch thaty2Bb;1(x;r)if\nand only if \u001e(y)2B1(\u001e(x);r).\nProof.Deﬁne\u001e(y)i=biyifori= 1;2;:::;n. Now we have the following which implies the lemma.\nkx\u0000ykb;1=X\nibijxi\u0000yij=X\nijbixi\u0000biyij\n=k\u001e(x)\u0000\u001e(y)k1\nThus one of these is at most rif and only if the other is.\nNow deﬁne the family of functions Hb;n=ffy:Rn!Rjy2Rn;fy(x) =ky\u0000xkb;1g, we have the\nfollowing which is analogous to Lemma 18.\nLemma 34. The pseudo-dimension of Hbis at most the pseudo-dimension of Hb;n\nProof.Nearly identical to that of Lemma 18 but with k\u0001k 1replaced withk\u0001kb;1.\nWe can now prove that the pseudo-dimension of Hbis bounded by O(nlogn).\nLemma 35. The pseudo-dimension of Hbis at mostO(nlogn).\nProof.By Lemma 34 we have that the pseudo-dimension of Hbis at mostHb;n. We now show that the\npseudo-dimension of Hb;nis at most the pseudo-dimension of Hnusing Lemma 33. Let x1;:::;xk2Rn\nbe given. Now consider yj=\u001e(xj)forj= 1;:::;k. By Lemma 33 we can see that x1;:::;xkare\nshattered byHb;nif and only if y1;:::;ykare shattered byHn. Thus the pseudo-dimension of Hb;nis\nat mostHnand then the lemma follows by Theorem 19.\n20\n\n6 Conclusion and Future Work\nIn this work we showed how to use learned predictions to warm-start primal-dual algorithms for\nweighted matching problems to improve their running times. We identiﬁed three key challenges of\nfeasibility, learnability and optimization, for any such scheme, and showed that by working in the dual\nspace we could give rigorous performance guarantees for each. Finally, we showed that our proposed\nmethods are not only simpler, but also more eﬃcient in practice.\nAn immediate avenue for future work is to extend these results to other combinatorial optimization\nproblems. The key ingredient is identifying an appropriate intermediate representation: it must be\nsimple enough to be learnable with small sample complexity, yet sophisticated enough to capture the\nunderlying structure of the problem at hand.\nReferences\n[1]Anders Aamand, Piotr Indyk, and Ali Vakilian. (learned) frequency estimation algorithms under\nzipﬁan distribution. arXiv preprint arXiv:1908.05198 , 2019.\n[2]Keerti Anand, Rong Ge, and Debmalya Panigrahi. Customizing ML predictions for online\nalgorithms. In Proceedings of the 37th International Conference on Machine Learning, ICML\n2020, 13-18 July 2020, Virtual Event , volume 119 of Proceedings of Machine Learning Research ,\npages 303–313. PMLR, 2020. URL http://proceedings.mlr.press/v119/anand20a.html .\n[3]MartinAnthonyandPeterLBartlett. Neural network learning: Theoretical foundations . cambridge\nuniversity press, 2009.\n[4]Antonios Antoniadis, Christian Coester, Marek Eliás, Adam Polak, and Bertrand Simon. Online\nmetric algorithms with untrusted predictions. In Proceedings of the 37th International Conference\non Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event , volume 119 of Proceedings\nof Machine Learning Research , pages 345–355. PMLR, 2020. URL http://proceedings.mlr.\npress/v119/antoniadis20a.html .\n[5]Maria-Florina Balcan, Travis Dick, Tuomas Sandholm, and Ellen Vitercik. Learning to branch.\nIn Jennifer G. Dy and Andreas Krause, editors, Proceedings of the 35th International Conference\non Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018 ,\nvolume 80 of Proceedings of Machine Learning Research , pages 353–362. PMLR, 2018. URL\nhttp://proceedings.mlr.press/v80/balcan18a.html .\n[6]Maria-Florina Balcan, Travis Dick, and Ellen Vitercik. Dispersion for data-driven algorithm\ndesign, online learning, and private optimization. In Mikkel Thorup, editor, 59th IEEE Annual\nSymposium on Foundations of Computer Science, FOCS 2018, Paris, France, October 7-9,\n2018, pages 603–614. IEEE Computer Society, 2018. doi: 10.1109/FOCS.2018.00064. URL\nhttps://doi.org/10.1109/FOCS.2018.00064 .\n[7]Maria-Florina Balcan, Travis Dick, and Colin White. Data-driven clustering via parameterized\nlloyd’s families. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicolò\nCesa-Bianchi, and Roman Garnett, editors, Advances in Neural Information Processing Systems\n31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8\nDecember 2018, Montréal, Canada , pages 10664–10674, 2018.\n[8]Maria-Florina Balcan, Dan F. DeBlasio, Travis Dick, Carl Kingsford, Tuomas Sandholm, and Ellen\nVitercik. How much data is suﬃcient to learn high-performing algorithms? CoRR, abs/1908.02894,\n2019. URL http://arxiv.org/abs/1908.02894 .\n21\n\n[9]Étienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning\naugmented algorithms. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina\nBalcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems\n33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, De-\ncember 6-12, 2020, virtual , 2020. URL https://proceedings.neurips.cc/paper/2020/hash/\ne834cb114d33f729dbc9c7fb0c6bb607-Abstract.html .\n[10]Rajen Bhatt and Abhinav Dhall. Skin segmentation dataset, uci machine learning repository,\n2012.\n[11]Sayan Bhattacharya, Monika Henzinger, and Danupon Nanongkai. New Deterministic Approxima-\ntion Algorithms for Fully Dynamic Matching , page 398–411. Association for Computing Machinery,\nNew York, NY, USA, 2016. ISBN 9781450341325. URL https://doi.org/10.1145/2897518.\n2897568.\n[12]Krisztian Buza. Feedback prediction for blogs. In Myra Spiliopoulou, Lars Schmidt-Thieme,\nand Ruth Janning, editors, Data Analysis, Machine Learning and Knowledge Discovery , pages\n145–152, Cham, 2014. Springer International Publishing. ISBN 978-3-319-01595-8.\n[13]ShuchiChawla, EvangeliaGergatsouli, YifengTeng, ChristosTzamos, andRuiminZhang. Learning\noptimal search algorithms from data. CoRR, abs/1911.01632, 2019. URL http://arxiv.org/\nabs/1911.01632 .\n[14]Joseph Cheriyan and Kurt Mehlhorn. Algorithms for dense graphs and networks on the random\naccess computer. Algorithmica , 15(6):521–549, 1996. doi: 10.1007/BF01940880. URL https:\n//doi.org/10.1007/BF01940880 .\n[15]Edith Cohen, Oﬁr Geri, and Rasmus Pagh. Composable sketches for functions of frequencies:\nBeyond the worst case. CoRR, abs/2004.04772, 2020. URL https://arxiv.org/abs/2004.04772 .\n[16]Samuel I. Daitch and Daniel A. Spielman. Faster approximate lossy generalized ﬂow via interior\npoint algorithms. In Cynthia Dwork, editor, Proceedings of the 40th Annual ACM Symposium\non Theory of Computing, Victoria, British Columbia, Canada, May 17-20, 2008 , pages 451–460.\nACM, 2008. doi: 10.1145/1374376.1374441. URL https://doi.org/10.1145/1374376.1374441 .\n[17]Nikhil R. Devanur and Thomas P. Hayes. The adwords problem: online keyword matching with\nbudgeted bidders under random permutations. In Proceedings 10th ACM Conference on Electronic\nCommerce (EC-2009), Stanford, California, USA, July 6–10, 2009 , pages 71–78, 2009.\n[18]Doratha E. Drake and Stefan Hougardy. A simple approximation algorithm for the weighted\nmatching problem. Inf. Process. Lett. , 85(4):211–213, 2003. doi: 10.1016/S0020-0190(02)00393-9.\nURL https://doi.org/10.1016/S0020-0190(02)00393-9 .\n[19]Dheeru Dua and Casey Graﬀ. UCI machine learning repository, 2017. URL http://archive.\nics.uci.edu/ml .\n[20]Ran Duan and Seth Pettie. Linear-time approximation for maximum weight matching. J. ACM,\n61(1):1: 1–1: 23, 2014. doi: 10.1145/2529989. URL https://doi.org/10.1145/2529989 .\n[21]Ran Duan and Hsin - Hao Su. A scaling algorithm for maximum weight matching in bipartite\ngraphs. In Yuval Rabani, editor, Proceedings of the Twenty-Third Annual ACM-SIAM Symposium\non Discrete Algorithms, SODA 2012, Kyoto, Japan, January 17-19, 2012 , pages 1413–1424. SIAM,\n2012. doi: 10.1137/1.9781611973099.111. URL https://doi.org/10.1137/1.9781611973099.\n111.\n[22]Paul Dütting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with advice.\nCoRR, abs/2011.06726, 2020. URL https://arxiv.org/abs/2011.06726 .\n22\n\n[23]Harold N. Gabow. A scaling algorithm for weighted matching on general graphs. In 26th\nAnnual Symposium on Foundations of Computer Science, Portland, Oregon, USA, 21-23 October\n1985, pages 90–100. IEEE Computer Society, 1985. doi: 10.1109/SFCS.1985.3. URL https:\n//doi.org/10.1109/SFCS.1985.3 .\n[24]Andrew V. Goldberg and Robert Kennedy. Global price updates help. SIAM J. Discret.\nMath., 10(4):551–572, 1997. doi: 10.1137/S0895480194281185. URL https://doi.org/10.\n1137/S0895480194281185 .\n[25]Jacek Gondzio. Warm start of the primal-dual method applied in the cutting-plane scheme.\nMath. Program. , 83:125–143, 1998. doi: 10.1007/BF02680554. URL https://doi.org/10.1007/\nBF02680554 .\n[26]JacekGondzioandPabloGonzález-Brevis. Anewwarmstartingstrategyfortheprimal-dualcolumn\ngeneration method. Math. Program. , 152(1-2):113–146, 2015. doi: 10.1007/s10107-014-0779-8.\nURL https://doi.org/10.1007/s10107-014-0779-8 .\n[27] Google Cloud Platform. https://cloud.google.com/ .\n[28]Rishi Gupta and Tim Roughgarden. A PAC approach to application-speciﬁc algorithm selection.\nSIAM J. Comput. , 46(3):992–1017, 2017. doi: 10.1137/15M1050276. URL https://doi.org/10.\n1137/15M1050276 .\n[29]John E. Hopcroft and Richard M. Karp. An n5=2-algorithm for maximum matchings in bipartite\ngraphs.SIAM Journal on Computing , 2(4):225–231, 1973. doi: 10.1137/0202019. URL https:\n//doi.org/10.1137/0202019 .\n[30]Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency estimation\nalgorithms. In 7th International Conference on Learning Representations , 2019.\n[31]Zhihao Jiang, Debmalya Panigrahi, and Kevin Sun. Online algorithms for weighted paging\nwith predictions. In Artur Czumaj, Anuj Dawar, and Emanuela Merelli, editors, 47th Interna-\ntional Colloquium on Automata, Languages, and Programming, ICALP 2020, July 8-11, 2020,\nSaarbrücken, Germany (Virtual Conference) , volume 168 of LIPIcs, pages 69:1–69:18. Schloss\nDagstuhl - Leibniz-Zentrum für Informatik, 2020. doi: 10.4230/LIPIcs.ICALP.2020.69. URL\nhttps://doi.org/10.4230/LIPIcs.ICALP.2020.69 .\n[32]V. King, S. Rao, and R. Tarjan. A faster deterministic maximum ﬂow algorithm. Journal of\nAlgorithms , 17(3):447 – 474, 1994. ISSN 0196-6774. doi: https://doi.org/10.1006/jagm.1994.1044.\nURL http://www.sciencedirect.com/science/article/pii/S0196677484710443 .\n[33]Tim Kraska, Alex Beutel, Ed H Chi, Jeﬀrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proceedings of the 2018 International Conference on Management of Data ,\npages 489–504. ACM, 2018.\n[34]Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online scheduling\nvia learned weights. In Shuchi Chawla, editor, Proceedings of the 2020 ACM-SIAM Symposium\non Discrete Algorithms, SODA 2020, Salt Lake City, UT, USA, January 5-8, 2020 , pages\n1859–1877. SIAM, 2020. doi: 10.1137/1.9781611975994.114. URL https://doi.org/10.1137/1.\n9781611975994.114 .\n[35]Yin Tat Lee and Aaron Sidford. Path ﬁnding methods for linear programming: Solving linear\nprograms in o (vrank) iterations and faster algorithms for maximum ﬂow. In 55th IEEE Annual\nSymposium on Foundations of Computer Science, FOCS 2014, Philadelphia, PA, USA, October\n18-21, 2014 , pages 424–433. IEEE Computer Society, 2014. doi: 10.1109/FOCS.2014.52. URL\nhttps://doi.org/10.1109/FOCS.2014.52 .\n23\n\n[36]Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice.\nInProceedings of the 35th International Conference on Machine Learning, ICML 2018, Stock-\nholmsmässan, Stockholm, Sweden, July 10-15, 2018 , pages 3302–3311, 2018.\n[37]Aranyak Mehta, Amin Saberi, Umesh V. Vazirani, and Vijay V. Vazirani. Adwords and generalized\nonline matching. J. ACM, 54(5):22, 2007. doi: 10.1145/1284320.1284321. URL https://doi.\norg/10.1145/1284320.1284321 .\n[38]Michael Mitzenmacher. A model for learned bloom ﬁlters and optimizing by sandwiching. In\nAdvances in Neural Information Processing Systems , pages 464–473, 2018.\n[39]Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. CoRR,\nabs/2006.09123, 2020. URL https://arxiv.org/abs/2006.09123 .\n[40]Jamie H Morgenstern and Tim Roughgarden. On the pseudo-dimension of nearly\noptimal auctions. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama,\nand R. Garnett, editors, Advances in Neural Information Processing Systems 28 ,\npages 136–144. Curran Associates, Inc., 2015. URL http://papers.nips.cc/paper/\n5766-on-the-pseudo-dimension-of-nearly-optimal-auctions.pdf .\n[41]Vinod Nair, Dj Dvijotham, Iain Dunning, and Oriol Vinyals. Learning fast optimizers for\ncontextual stochastic integer programs. In Amir Globerson and Ricardo Silva, editors, Proceedings\nof the Thirty-Fourth Conference on Uncertainty in Artiﬁcial Intelligence, UAI 2018, Monterey,\nCalifornia, USA, August 6-10, 2018 , pages 591–600. AUAI Press, 2018. URL http://auai.org/\nuai2018/proceedings/papers/217.pdf .\n[42]James B. Orlin. A faster strongly polynomial minimum cost ﬂow algorithm. opera. Res. , 41(2):\n338–350, 1993. doi: 10.1287/opre.41.2.338. URL https://doi.org/10.1287/opre.41.2.338 .\n[43]James B. Orlin. Max ﬂows in o(nm) time, or better. In Proceedings of the Forty-Fifth Annual\nACM Symposium on Theory of Computing , STOC ’13, page 765–774, New York, NY, USA, 2013.\nAssociation for Computing Machinery. ISBN 9781450320290. doi: 10.1145/2488608.2488705. URL\nhttps://doi.org/10.1145/2488608.2488705 .\n[44]James B. Orlin and Ravindra K. Ahuja. New scaling algorithms for the assignment and minimum\nmean cycle problems. math. Program. , 54:41–56, 1992. doi: 10.1007/BF01586040. URL https:\n//doi.org/10.1007/BF01586040 .\n[45] David Pollard. Convergence of stochastic processes . Springer Science & Business Media, 2012.\n[46]Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predictions.\nInAdvances in Neural Information Processing Systems , pages 9661–9670, 2018.\n[47]Dhruv Rohatgi. Near-optimal bounds for online caching with machine learned advice. In\nSymposium on Discrete Algorithms (SODA) , 2020.\n[48]Tim Roughgarden. Beyond the Worst-Case Analysis of Algorithms . Cambridge University Press,\n2020.\n[49]Piotr Sankowski. Weighted bipartite matching in matrix multiplication time. In Michele Bugliesi,\nBart Preneel, Vladimiro Sassone, and Ingo Wegener, editors, Automata, Languages, and Program-\nming, 33rd International Colloquium, ICALP 2006, Venice, Italy, July 10-14, 2006, Proceedings,\nPart I, volume 4051 of Lecture Notes in Computer Science , pages 274–285. Springer, 2006. doi:\n10.1007/11786986\\_25. URL https://doi.org/10.1007/11786986_25 .\n24\n\n[50]Piotr Sankowski. Faster dynamic matchings and vertex connectivity. In Proceedings of the\nEighteenth Annual ACM-SIAM Symposium on Discrete Algorithms , SODA ’07, page 118–126,\nUSA, 2007. Society for Industrial and Applied Mathematics. ISBN 9780898716245.\n[51]Kapil Vaidya, Eric Knorr, Tim Kraska, and Michael Mitzenmacher. Partitioned learned bloom\nﬁlter.CoRR, abs/2006.03176, 2020. URL https://arxiv.org/abs/2006.03176 .\n[52]Jan van den Brand, Yin Tat Lee, Danupon Nanongkai, Richard Peng, Thatchaphol Saranurak,\nAaron Sidford, Zhao Song, and Di Wang. Bipartite matching in nearly-linear time on moderately\ndense graphs. In 61st IEEE Annual Symposium on Foundations of Computer Science, FOCS 2020,\nDurham, NC, USA, November 16-19, 2020 , pages 919–930. IEEE, 2020. doi: 10.1109/FOCS46700.\n2020.00090. URL https://doi.org/10.1109/FOCS46700.2020.00090 .\n[53]Erik Vee, Sergei Vassilvitskii, and Jayavel Shanmugasundaram. Optimal online assignment with\nforecasts. In Proceedings 11th ACM Conference on Electronic Commerce (EC-2010), Cambridge,\nMassachusetts, USA, June 7-11, 2010 , pages 109–118, 2010.\n[54]Hiroshi Yamashita and Takahito Tanabe. A primal-dual exterior point method for nonlinear\noptimization. SIAM Journal on Optimization , 20(6):3335–3363, 2010. doi: 10.1137/060676970.\nURL https://doi.org/10.1137/060676970 .\nA Additional Experimental Results\nHere we present additional experimental results that were omitted from Section 4. First we present\nour results while looking at the running time as opposed to the number of primal dual iterations.\nA.1 Running Time\nFigure 5 gives running time results for the batch setting, while Figure 6 give the results for the online\nsetting. Finally, Figure 7 looks at the clustering derived instances for other values of k. We see similar\nperformance improvements for Learned Duals against the standard Hungarian algorithm, showing that\nthe impact of running Algorithm 1 to make the predicted duals feasible is minimal.\n/uni00000013/uni00000011/uni00000013 /uni00000013/uni00000011/uni00000015 /uni00000013/uni00000011/uni00000017 /uni00000013/uni00000011/uni00000019 /uni00000013/uni00000011/uni0000001b /uni00000014/uni00000011/uni00000013 /uni00000014/uni00000011/uni00000015\n/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000012/uni00000003/uni00000030/uni00000048/uni00000044/uni00000051/uni00000003/uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000014/uni00000017/uni00000014/uni00000019/uni00000035/uni00000058/uni00000051/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c/uni00000037/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000030/uni00000052/uni00000047/uni00000048/uni0000004f/uni00000003/uni00000035/uni00000058/uni00000051/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni00000059/uni00000056/uni00000011/uni00000003/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048\n/uni00000030/uni00000048/uni00000057/uni0000004b/uni00000052/uni00000047\n/uni0000002b/uni00000058/uni00000051/uni0000004a/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051\n/uni0000002f/uni00000048/uni00000044/uni00000055/uni00000051/uni00000048/uni00000047/uni00000003/uni00000027/uni00000058/uni00000044/uni0000004f/uni00000056\n/uni00000015/uni00000019\n/uni00000015/uni00000016\n/uni00000015/uni00000013\n/uni00000015/uni00000016\n/uni00000015/uni00000019\n/uni00000015/uni0000001c\n/uni00000015/uni00000014/uni00000015\n/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048/uni00000003/uni00000012/uni00000003/uni00000030/uni00000048/uni00000044/uni00000051/uni00000003/uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000015/uni00000014/uni00000015/uni00000015/uni00000015/uni00000016/uni00000015/uni00000017/uni00000015/uni00000018/uni00000015/uni00000019/uni00000015/uni0000001a/uni00000015/uni0000001b/uni00000035/uni00000058/uni00000051/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c/uni00000037/uni0000005c/uni00000053/uni00000048/uni00000003/uni00000030/uni00000052/uni00000047/uni00000048/uni0000004f/uni00000003/uni00000035/uni00000058/uni00000051/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni00000059/uni00000056/uni00000011/uni00000003/uni00000031/uni00000052/uni0000004c/uni00000056/uni00000048/uni00000003/uni00000039/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051/uni00000046/uni00000048\n/uni00000030/uni00000048/uni00000057/uni0000004b/uni00000052/uni00000047\n/uni0000002b/uni00000058/uni00000051/uni0000004a/uni00000044/uni00000055/uni0000004c/uni00000044/uni00000051\n/uni0000002f/uni00000048/uni00000044/uni00000055/uni00000051/uni00000048/uni00000047/uni00000003/uni00000027/uni00000058/uni00000044/uni0000004f/uni00000056\nShuttle Skin Blog Feedback Covertype KDD\nDataset050100150200250300350400Runtime (seconds)Clustering-Based Instances, k = 500\nMethod\nHungarian\nLearned Duals\nFigure 5: Running time results (in seconds) for the Batch setting. The left ﬁgure gives the iteration\ncount for the type model (synthetic data) versus linearly increasing v, while the middle geometrically\nincreasesv. The right ﬁgure summarizes the results for clustering based instances (real data) in the\nbatch setting.\n25\n\n012345678910111213141516171819\nInstance Number89101112Runtime (seconds)Type Model, v = 200 - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number100150200250300Runtime (seconds)KDD - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number90100110120130140150160Runtime (seconds)Covertype - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number110120130140150160170180Runtime (seconds)Blog Feedback - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number1020304050607080Runtime (seconds)Shuttle - Online Setting\nMethod\n Hungarian\n Learned Duals\n012345678910111213141516171819\nInstance Number12.515.017.520.022.525.027.5Runtime (seconds)Skin - Online Setting\nMethod\n Hungarian\n Learned DualsFigure 6: Running time results for the Online setting. The top left ﬁgure is for the type model\n(synthetic data). The rest, in order, are KDD and Covertype, Blog Feedback, Shuttle, and Skin. All\nusek= 500.\n26\n\nShuttle Skin Blog Feedback Covertype KDD\nDataset0.00.20.40.60.81.0Runtime (seconds)Clustering-Based Instances, k = 100\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset0.02.55.07.510.012.515.017.520.0Runtime (seconds)Clustering-Based Instances, k = 200\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset01020304050607080Runtime (seconds)Clustering-Based Instances, k = 300\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset050100150200250Runtime (seconds)Clustering-Based Instances, k = 400\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset0100200300400500600700Runtime (seconds)Clustering-Based Instances, k = 600\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset02004006008001000120014001600Runtime (seconds)Clustering-Based Instances, k = 700\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset05001000150020002500Runtime (seconds)Clustering-Based Instances, k = 800\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset05001000150020002500300035004000Runtime (seconds)Clustering-Based Instances, k = 900\nMethod\nHungarian\nLearned Duals\nShuttle Skin Blog Feedback Covertype KDD\nDataset05001000150020002500300035004000Runtime (seconds)Clustering-Based Instances, k = 1000\nMethod\nHungarian\nLearned DualsFigure 7: Running time results (in seconds) for clustering derived instances in the Batch setting on\nother values of k. Here we give the results for each kinf100\u0001ij1\u0014i\u001410gnf500g.\n27",
  "textLength": 91667
}