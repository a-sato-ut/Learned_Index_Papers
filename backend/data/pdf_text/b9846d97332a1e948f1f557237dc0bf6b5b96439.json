{
  "paperId": "b9846d97332a1e948f1f557237dc0bf6b5b96439",
  "title": "DeepDB",
  "pdfPath": "b9846d97332a1e948f1f557237dc0bf6b5b96439.pdf",
  "text": "DeepDB: Learn from Data, not from Queries!\nBenjamin Hilprecht\nTU Darmstadt, GermanyAndreas Schmidt\nKIT, GermanyMoritz Kulessa\nTU Darmstadt, Germany\nAlejandro Molina\nTU Darmstadt, GermanyKristian Kersting\nTU Darmstadt, GermanyCarsten Binnig\nTU Darmstadt, Germany\nABSTRACT\nThe typical approach for learned DBMS components is to\ncapture the behavior by running a representative set of queries\nand use the observations to train a machine learning model.\nThis workload-driven approach, however, has two major\ndownsides. First, collecting the training data can be very ex-\npensive, since all queries need to be executed on potentially\nlarge databases. Second, training data has to be recollected\nwhen the workload and the data changes.\nTo overcome these limitations, we take a di\u000berent route:\nwe propose to learn a pure data-driven model that can be\nused for di\u000berent tasks such as query answering or cardinal-\nity estimation. This data-driven model also supports ad-hoc\nqueries and updates of the data without the need of full re-\ntraining when the workload or data changes. Indeed, one\nmay now expect that this comes at a price of lower accu-\nracy since workload-driven models can make use of more\ninformation. However, this is not the case. The results of\nour empirical evaluation demonstrate that our data-driven\napproach not only provides better accuracy than state-of-\nthe-art learned components but also generalizes better to\nunseen queries.\n1. INTRODUCTION\nMotivation. Deep Neural Networks (DNNs) have not only\nbeen shown to solve many complex problems such as im-\nage classi\fcation or machine translation, but are applied in\nmany other domains, too. This is also the case for DBMSs,\nwhere DNNs have successfully been used to replace exist-\ning DBMS components with learned counterparts such as\nlearned cost models [8, 32] as well as learned query optimiz-\ners [20], or even learned indexes [9] or query scheduling and\nquery processing schemes [17, 30].\nThe predominant approach for learned DBMS compo-\nnents is that they capture the behavior of a component by\nrunning a representative set of queries over a given database\nand use the observations to train the model. For example,\nfor learned cost models such as [8, 32] di\u000berent query plans\nneed to be executed to collect the training data, which cap-\ntures the runtime (or cardinalities), to then learn a model\nthat can estimate costs for new query plans. This obser-\nvation also holds for the other approaches such as learned\nquery optimizers or the learned query processing schemes,\nwhich are also based on collected training data that requires\nthe execution of a representative workload.\nA major obstacle of this workload-driven approach to learn-\ning is that collecting the training data is typically very ex-\npensive since many queries need to be executed to gather\n4 5 6\nTables100101q-errorMCSN\nDeepDB (ours)Figure 1: Cardinality Estimation Errors per Join Size.\nenough training data. For example, approaches like [8, 32]\nhave shown that the runtime of hundreds of thousands of\nquery plans is needed for the model to provide a high accu-\nracy. Still, the training corpora often only cover a limited\nset of query patterns to avoid even higher training costs. For\nexample, in [8] the training data covers only queries up to\ntwo joins (three tables) and \flter predicates with a limited\nnumber of attributes.\nMoreover, the training data collection is not a one-time\ne\u000bort since the same procedure needs to be repeated over\nand over if the workload changes or if the current database\nis not static and the data is constantly being updated as\nit is typical for OLTP. Otherwise, without collecting new\ntraining data and retraining the models for the character-\nistics of the changing workload or data, the accuracies of\nthese models degrade with time. To illustrate this, consider\nFigure 1. Here, we see (orange bars) the error of the car-\ndinality estimation model of Kipf et al. [8], called MCSN,\nthat was trained on queries with three joined tables only.\nOn queries with four and more tables that the model has\nnot seen, however, the error quickly increases.\nContributions. In this paper, we take a di\u000berent route. In-\nstead of learning a model over the workload, we propose to\nlearn a purely data-driven model that captures the joint\nprobability distribution of the data and re\rects important\ncharacteristics such as correlations across attributes but also\nthe data distribution of single attributes. Another impor-\ntant di\u000berence to existing approaches is that our data-density\napproach supports direct updates; i.e., inserts, updates, and\ndeletes on the underlying database can be absorbed by the\nmodel without the need to retrain the model.\nAs a result, since our model only captures information\nof the data (and this is workload-independent) it can not\nonly be used for one task but supports many di\u000berent tasks\nranging from query answering, over cardinality estimation\nto machine learning tasks such as classi\fcation or regres-\nsion. One could now think that this all comes at a price\nand that the accuracy of our approach must be lower since\nthe workload-driven approaches get more information than\na pure data-driven approach. However, as we demonstrate\n1arXiv:1909.00607v1  [cs.DB]  2 Sep 2019\n\nAd-hoc\nAQP QueryRegression/  \nClassification T ask\nN ⋅P(C) ⋅E(X) ⋅E(Y)\nRSPN\nEnsemble DeepDB  \nLearning\nT2⟗T4RSPN2DeepDB\nRSPN1\nT1⟗T2⟗T3+\nx x\nT5+\nx xRSPN3+\nx x\nRuntime\nOfflineDBMSSQL Query\nQuery\nOptimizer\nDataCardinality\nQuery Probabilistic Query\nCompilationFigure 2: Overview of DeepDB .\nin our experiments, this is not the case. Our approach actu-\nally outperforms many state-of-the-art workload-driven ap-\nproaches. Furthermore, it generalizes much better. Recon-\nsider Figure 1. The blue bars show the results when using\nour model for cardinality estimation, proving that it pro-\nvides an order-of-magnitude better accuracies.\nIndeed, we do not argue that data-driven models are a\nsilver bullet to solve all possible tasks in a DBMS. Instead,\nwe think that data-driven models should be combined with\nworkload-driven models when it makes sense. For exam-\nple, a workload-driven model for a learned query optimizer\nmight use the cardinally estimates of our model as input fea-\ntures. This combination of data-driven and workload-driven\nmodels provides an interesting avenue for future work but is\nbeyond the scope of this paper.\nTo summarize, the main contributions of this paper are:\n1. We developed a new class of deep probabilistic models\nover databases, called Relational Sum Product Net-\nworks (RSPNs), that can capture important charac-\nteristics of a database.\n2. To support di\u000berent tasks, we devise a probabilistic\nquery compilation approach that translates incoming\ndatabase queries into probability and expectations for\nRSPNs (that are learned over a given database).\n3. We implemented our data-driven approach in a proto-\ntypical DBMS architecture, called DeepDB , and evalu-\nated it against state-of-the-art learned and non-learned\napproaches that are workload-aware, showing the ben-\ne\fts of our approach over these baselines.\nOutline. The remainder of the paper is organized as fol-\nlows. In Section 2 we \frst present an overview of DeepDB\nand then discuss details of our models and the query com-\npilation in Sections 3 and 4. Afterwards, we explain further\nextensions of DeepDB in Section 5 before we show an exten-\nsive evaluation comparing DeepDB against state-of-the art\napproaches for various tasks. Finally, we iterate over related\nwork in Section 7 and conclude in Section 8.\n2. OVERVIEW AND APPLICATIONS\nOverview. As shown in Figure 2, the main idea of DeepDB\nis to learn a distribution of the data. An important aspect\nofDeepDB is that we do not aim to replace the original data\nwith a model (or a set of models as we discuss later). In-\nstead, a model created in DeepDB augments a database sim-\nilar to indexes to speed-up query processing and to provide\nadditional query capabilities while we can still run standard\nSQL queries over the original database.\nTo optimally capture relevant characteristics of relational\ndata, we developed a new class of models called Relational\nSum Product Networks (RSPNs). RSPNs are based on thebasic structure of Sum Product Networks (SPNs) [28]. In\na nutshell, SPNs are deep probabilistic models that capture\nthe joint probability distribution of a given data set. RSPNs\nextend SPNs to optimize them for the use in a relational\nDBMS. First, RSPNs provide additional algorithms to sup-\nport a wider class of applications. Also database-speci\fc\nextensions such as correct NULL-value handling etc. are\nhandled by RSPNs. Most importantly, what di\u000berentiates\nRSPNs from many other ML models, is that they support\ndirect updates; i.e., the model does not need to be retrained\nbut can be updated directly if new tuples are inserted into\nor tuples are deleted from the underlying database.\nInDeepDB , we create an ensemble of RSPNs that repre-\nsents a given database in an o\u000fine learning procedure (sim-\nilar to bulk loading an index). Once the RSPNs are created,\nthe models can be leveraged at runtime for di\u000berent tasks.\nSince RSPNs capture the joint probability distribution of the\nunderlying database, they can support a wide variety of dif-\nferent applications, ranging from user-facing tasks (e.g., to\nprovide fast approximate answers for SQL queries or to exe-\ncute ML tasks on the model) to system-internal tasks (e.g.,\nto provide estimates for cardinalities). In order to support\nthese tasks, DeepDB provides a new so called probabilistic\nquery compilation that translates a given task into products\nof expectations and probability queries on the RSPNs.\nIn the following, to show that our approach is capable of\nsupporting a range of applications, we give a brief overview\nof how we support these tasks in DeepDB . The main goal of\nthis paper is to show the potentials of our data-driven learn-\ning approach to support a wide variety of di\u000berent applica-\ntions. However, DeepDB is not limited to the applications\npresented next and can be easily extended to other applica-\ntions by providing a translation of queries into products of\nexpectations and probabilities.\nCardinality Estimation. The \frst task DeepDB supports\nis cardinality estimation for a query optimizer. Cardinality\nestimation is needed to provide cost estimates but also to\n\fnd the correct join order during query optimization. Since\nDeepDB learns a representation of the data, it can also be\nleveraged to provide precise cardinality estimates. A par-\nticular advantage of DeepDB is that we do not have to cre-\nate dedicated training data, i.e. pairs of queries and cardi-\nnalities. Instead, since RSPNs capture information of the\ndata, we can support arbitrary queries without the need to\ntrain the model for the particular workload. Moreover, since\nRSPNs are easy to update they can be kept up to date at\nlow costs similar to traditional histogram-based approaches,\nwhich is di\u000berent from existing learned approaches for car-\ndinality estimation such as [8].\nApproximate Query Processing (AQP). The second task\nwe currently support in DeepDB is AQP. AQP aims to pro-\nvide approximate answers to support faster query response\ntimes on large data sets. Currently, aggregate queries with\nequi-joins and typical selection predicates with group-by\nclauses are supported. The basic idea of how a query on a\nsingle table is executed inside DeepDB is simple: for exam-\nple, an aggregate query AVG(X) with a where condition Cis\nequal to the conditional expectation E(XjC). These condi-\ntional expectations can be approximated with RSPNs. This\nprinciple can also be applied to approximate join queries. In\nthe simplest case, a full model was learned already on the\njoin of the corresponding tables. An alternative is to use\n2\n\ncid c age c region\n1 80 EUROPE\n2 70 EUROPE\n3 60 ASIA\n4 20 EUROPE\n... ... ...\n998 20 ASIA\n998 25 EUROPE\n999 30 ASIA\n1000 70 ASIA\n(a) Example Tablecage c region\n80 EUROPE\n70 EUROPE\n60 ASIA\n20 EUROPE\n... ...\n... ...\n20 ASIA\n25 EUROPE\n30 ASIA\n70 ASIA\n(b) Learning with Row/Col-\numn Clustering\n+\nx x\nEUASIA 20100P(cregion , cage)\n0.3 0.7\nEUASIA 20100\n(c) Resulting SPN\n+\nx x\nEUASIA2010015%\nEUASIA2010080%12%\n20%2%5%\n0.3 0.7\n10% (d) Probability of European\nCustomers younger than 30\nFigure 3: Customer Table and corresponding SPN.\nmultiple but smaller RSPNs that have to be combined to\nexecute a join. All these cases are supported by our proba-\nbilistic query compilation engine, which is explained in more\ndetail in Section 4.\nMachine Learning (ML). Finally, many ML tasks can also\ndirectly be conducted in DeepDB based on our models with-\nout any further learning. For instance, DeepDB can provide\nanswers for regression or classi\fcation tasks for every col-\numn of the database using any set of columns as features.\n3. LEARNING A DATA MODEL\nIn this section, we introduce Relational Sum Product Net-\nworks (RSPNs), which we use to learn a representation of\na database and, in turn, to answer queries using our query\nengine explained in the next section. We \frst review Sum\nProduct Networks (SPNs) and then introduce RSPNs. Af-\nterwards, we describe how an ensemble of RSPNs can be\ncreated to encode a given database multiple tables.\n3.1 Sum Product Networks\nSum-Product Networks (SPNs) [28] learn the joint proba-\nbility distribution P(X1;X2;:::;X n) of the variables X1;X2;\n:::;X n, which are present in the data set. They are an ap-\npealing choice because probabilities for arbitrary conditions\ncan be computed very e\u000eciently . We will later make use of\nthese probabilities for our applications like AQP and cardi-\nnality estimation.\n(Tree-structured) SPNs are trees with sum and product\nnodes as internal nodes and leaves. Intuitively, sum nodes\nsplit the population (i.e., the rows of data set) into clusters\nand product nodes split independent variables of a popula-\ntion (i.e., the columns of a data set). Leaf nodes represent\na single attribute and approximate the distribution of that\nattribute either using histograms for discrete domains or\npiecewise linear functions for continuous domains [22].\nFor instance, in Figure 3c, an SPN was learned over the\nvariables region and ageof the corresponding customer ta-\nble in Figure 3a. The top sum node splits the data into twogroups: The left group contains 30% of the population which\nis dominated by older European customers (corresponding\nto the \frst rows of the table) and the right group contains\n70% of the population with younger Asian customers (cor-\nresponding to the last rows of the table). In both groups\nregion and age are independent and thus split by a product\nnode each. The leaf nodes determine the probability distri-\nbutions of the variables region and agefor every group.\nWith an SPN at hand, one can compute probabilities for\nconditions on arbitrary columns. Intuitively, the conditions\nare \frst evaluated on every relevant leaf. Afterwards, the\nSPN is evaluated bottom up. For instance in Figure 3d, to\nestimate how many customers are from Europe and younger\nthan 30, we compute the probability of European customers\nin the corresponding blue region leaf nodes (80% and 10%)\nand the probability of a customer being younger than 30\n(15% and 20%) in the green ageleaf nodes. These probabil-\nities are then multiplied at the product node level above, re-\nsulting in probabilities of 12% and 2%, respectively. Finally,\nat the root level (sum node), we have to consider the weights\nof the clusters, which leads to 12% \u00010:3 + 2%\u00010:7 = 5%:\nMultiplied by the number of rows in the table, we get an\napproximation of 50 European customers who are younger\nthan 30.\n3.2 Relational Sum-Product Networks\nUsing standard SPNs directly as models for DeepDB is\ninsu\u000ecient due to the following problems: they cannot be\nupdated easily, leading to an obsolete data representation\nover time. Moreover, for our applications it is insu\u000ecient\nto just compute probabilities; we require extended inference\nalgorithms, which in particular consider database-speci\fcs\nlike NULL values and functional dependencies. This led us\nto develop Relational SPNs (RSPNs)1.\nUpdatability. This is the most important extensions of RS-\nPNs over SPNs. If the underlying database tables are up-\ndated, the model might become inaccurate. For instance,\nif we insert more young European customers in the table\nin Figure 3a, the probability computed in Figure 3d is too\nlow and thus the RSPN needs to be updated. As described\nbefore, an RSPN consists of product and sum nodes, as well\nas leaf nodes, which represent probability distributions for\nindividual variables. The key-idea to support direct updates\nof an existing RSPN is to traverse the RSPN tree top-down\nand update the value distribution of the weights of the sum-\nnodes during this traversal. For instance, the weight of a\nsum node for a subtree of younger European customers could\nbe increased to account for updates. Finally, the distribu-\ntions in the leaf-nodes are adjusted. The detailed algorithm\nof how to directly update RSPNs is discussed in Section 5.2.\nDatabase-speciﬁcs. First, SPNs do not provide mecha-\nnisms for handling NULL values. Hence, we developed an\nextension where NULL values are represented as a dedicated\nvalue for both discrete and continuous columns at the leaves\nduring learning. Furthermore, when computing conditional\nprobabilities and expectations, NULL values must be han-\ndled according to the three-valued logic of SQL.\n1Nath et al. [24] also modi\fed SPNs to deal with relational\ndata. Di\u000berent from RSPNs, they did neither handle up-\ndates, nor NULL-values or functional dependencies. The\nrelational structure was exploited solely for the learning pro-\ncess (i.e., to avoid joining the tables before building an SPN).\n3\n\n+\nx x\nEUASIA2010060\nEUASIA2010080%48\n3010%316.5\n0.3 0.7(a)E(cage \u00011cregion='EU' )\n+\nx x\nEUASIA20100EUASIA2010080%80%\n10%10%31%\n0.3 0.7 (b)P(cregion='EU' )\nFigure 4: Process of computing E(cagejcregion='EU' ).\nSecond, SPNs aim to generalize the data distribution and\nthus approximate the leaf distribution abstracting away speci-\n\fcs of the data set to generalize. For instance, in the leaf\nnodes for the age in Figure 3c, a piecewise linear function\nwould be used to approximate the distribution [22]. Instead,\nwe want to represent the data as accurate as possible. Hence,\nfor continuous values, we store each individual value and its\nfrequency. If the number of distinct values exceeds a given\nlimit, we also use binning for continuous domains.\nThird, functional dependencies between non-key attributes\nA!Bare not well captured by SPNs. We could simply\nignore these and learn the RSPN with both attributes Aand\nBbut this often leads to large SPNs since the data would be\nsplit into many small clusters (to achieve independence of\nAandB). Hence, we allow users to de\fne additional func-\ntional dependencies along with a table schema. If a func-\ntional dependency A!Bis de\fned, we store the mapping\nfrom values of Ato values of Bin a separate dictionary of the\nRSPN and omit the column Bwhen learning the RSPN. At\nruntime, queries with \flter predicates for Bare translated\nto queries with \flter predicates for A.\nExtended Inference Algorithms. A last important exten-\nsion is that for many queries such as AVG and SUM ex-\npectations are required (e.g., to answer a SQL aggregate\nquery which computes an average over a column). In order\nto answer these queries, RSPNs allows computing expecta-\ntions over the variables on the leaves to answer those ag-\ngregates. To additionally apply a \flter predicate, we still\ncompute probabilities on the leaves for the \flter attribute\nand propagate both values up in the tree. At product nodes,\nwe multiply the expectations and probabilities coming from\nchild nodes whereas on sum nodes the weighted average is\ncomputed. In Figure 4 we show an example how the average\nage of European customers is computed. The ratio of both\nterms yields the correct conditional expectation.\nA related problem is that SPNs do not provide con\fdence\nintervals. We also developed corresponding extensions on\nSPNs in Section 5.1.\n3.3 Learning Ensembles of RSPNs\nAn RSPN can easily be used to represent the attributes\nof a single table. However, given a more complex database\nwith multiple tables, we have to decide which RSPNs to\nlearn. Naively, one could learn a single RSPN per table.\nHowever, then important information about dependencies\nbetween tables might be lost and lead to inaccurate approx-\nimations. For learning an ensemble of RSPNs for a given\ndatabase in DeepDB , we thus take into account if tables of\na schema are correlated.\nIn the following, we describe our procedure that con-\nstructs a so called base ensemble for a given database scheme.\nIn this procedure, for every foreign key!primary key rela-\ntionship we learn an RSPN over the corresponding full outerjoin of two tables if there is a correlation between attributes\nof the di\u000berent tables. Otherwise, RSPNs for the single ta-\nbles will be learned. For instance, if the schema consists of a\nCustomer and an Order table as shown in Figure 5, we could\neither learn two independent RSPNs (one for each table) or\na joint RSPN (over the full outer join). In order to test in-\ndependence of two tables and thus to decide if one or two\nRSPNs are more appropriate, we check for every pair of at-\ntributes from these tables if they can be considered indepen-\ndent or not. In order to enable an e\u000ecient computation, this\ntest can be done on a small random sample. As a correlation\nmeasure that does not make major distributional assump-\ntions, we compute RDC values [16] between two attributes,\nwhich are also used in the MSPN learning algorithm [22]. If\nthe maximum pairwise RDC value between all attributes of\ntwo tables exceeds a threshold (where we use the standard\nthresholds of SPNs), we assume that two tables are corre-\nlated and learn an RSPN over the join. Otherwise, single\nRSPNs are learned.\nIn the base ensemble only correlations between two tables\nare captured. While in our experiments, we see that this\nalready leads to highly accurate answers, there might also\nbe correlations not only between directly neighboring ta-\nbles. Learning these helps to further improve the accuracy\nof queries that span more than two tables. For instance, if\nthere was an additional Product table that can be joined\nwith the Orders table and the product prize is correlated\nwith the customers region, this would not be taken into ac-\ncount in the base ensemble . In Section 5.3, we extend our\nbasic procedure for ensemble creation to take dependencies\namong multiple tables into account.\n4. PROBABILISTIC QUERY COMPILATION\nThe main challenge of probabilistic query compilation is\nto translate an incoming query (e.g., for AQP) into an infer-\nence procedure against an ensemble of RSPNs. To this end,\nrecall that an ensemble for a given database either consists\nof RSPNs for single tables or spanning two (or more) tables.\nIn the following, we \frst describe how the translation pro-\ncedure for a COUNT query works (which can be used either\nfor AQP or for cardinality estimation) and then extend it to\nmore complex queries (e.g., AVG and SUM). We then show\nhow machine learning tasks can be supported with the help\nof RSPNs.\n4.1 COUNT Queries\nIn this section, we explain how we can translate simple\nCOUNT queries with and without \flter predicates over sin-\ngle tables as well as COUNT queries that join multiple tables\nusing inner joins (equi-joins). For \flter predicates we sup-\nport conjunctions of predicates of the form aopc whereais\nan attribute, ca constant, and opone of the comparison op-\nerators>;<;\u0015;\u0014;6= or an IN-comparison (e.g., age IN (20,\n30, 40)). String or arithmetic expressions, as well as user-\nde\fned functions are currently not supported. Disjunctions\ncould be realized using the inclusion-exclusion principle.\nThese types of queries can be used already for cardinality\nestimation but also cover some cases of aggregate queries\nfor AQP. We later show the extensions to support a broader\nset of queries for AQP including other aggregates (AVG and\nSUM) as well as group-by statements. For answering the\nsimple COUNT queries, we distinguish three cases of how\nqueries can be mapped to RSPNs: (1) an RSPN exists that\n4\n\n+\nx x\nCustomer+\nx x\nOrderCustomer\ncid c age c regionFC O\n1 20 EUROPE 2\n2 50 EUROPE 0\n3 80 ASIA 2Order\noid c id o channel\n1 1 ONLINE\n2 1 STORE\n3 3 ONLINE\n4 3 STORE\n(a) Ensemble with Single Tables\n+\nx x\nOrder CustomerCustomer d|><|dOrder\nNC cid c age c regionF0\nC ONO oid o channel\n1 1 20 EUROPE 2 1 1 ONLINE\n1 1 20 EUROPE 2 1 2 STORE\n1 2 50 EUROPE 1 0 NULL NULL\n1 3 80 ASIA 2 1 3 ONLINE\n1 3 80 ASIA 2 1 4 STORE\n(b) Ensemble with Full Outer Join\nFigure 5: Two RSPN Ensembles for the same Schema. Additional (blue) columns are also learned by the RSPNs.\nexactly matches the tables of the query, (2) the RSPN is\nlarger and covers more tables, and (3) we need to combine\nmultiple RSPNs since there is no single RSPN that contains\nall tables of the query.\nCase 1: Exact matching RSPN available. The simplest\ncase is a single table COUNT query with (or without) a\n\flter predicate. If an RSPN is available for this table and N\ndenotes the number of rows in the table, the result is simply\nN\u0001P(C). For instance, the query\nQ1: SELECT COUNT (*)\nFROM CUSTOMER C\nWHERE c_region ='EUROPE ';\ncan be answered with the CUSTOMER RSPN in Figure 5a. The\nresult isjCj\u0001E(1cregion='EUROPE' ) = 3\u00012\n3= 2. Note that 1 C\ndenotes the random variable being one if the condition Cis\nful\flled and thus E(1C) =P(C).\nA natural extension for COUNT queries over joins could\nbe to learn an RSPN for the underlying join and use the\nformulajJj\u0001P(C) where the size of the joined tables without\napplying a \flter predicate is jJj. For instance, the query\nQ2: SELECT COUNT (*)\nFROM CUSTOMER C\nNATURAL JOIN ORDER O\nWHERE c_region ='EUROPE '\nAND o_channel ='ONLINE ';\ncould be represented as jC./Oj\u0001P(ochannel='ONLINE' \\\ncregion='EUROPE' ) which is 4\u00011\n4= 1.\nHowever, joint RSPNs over multiple tables are learned\nover the full outer join. By using full outer joins we pre-\nserve all tuples of the original tables and not only those that\nhave one or more join partner in the corresponding table(s).\nThis way we are able for example to answer also single ta-\nble queries from a joint RSPN, as we will see in Case 2.\nThe additional NULL tuples that result from a full outer\njoin must be taken into account when answering an inner\njoin query. For instance, the second customer in Figure 5b\ndoes not have any orders and thus should not be counted\nfor queryQ2:To make it explicit which tuples have no join\npartner and thus would not be in the result of an inner join,\nwe add an additional column NTfor every table such as in\nthe ensemble in Figure 5b. This column is also learned by\nthe RSPN and can be used as an additional \flter column to\neliminate tuples that do not have a join partner for the join\nquery given. Hence, the complete translation of query Q2\nfor the RSPN learned over the full outer join in Figure 5b is\njC d|><|dOj\u0001P(ochannel='ONLINE' \\cregion='EUROPE' \\NO=\n1\\NC= 1) = 5\u00011\n5= 1.Case 2: Larger RSPN available. The second case is that\nwe have to use an RSPN that was created on a set of joined\ntables, however, the query only needs a subset of those ta-\nbles. For example, let us assume that the query Q1asking\nfor European customers is approximated using an RSPN\nlearned over a full outer join of customers and orders such\nas the one in Figure 5b. The problem here is that customers\nwith multiple orders would appear several times in the join\nand thus be counted multiple times. For instance, the ratio\nof European customers in the full outer join is 3 =5 though\ntwo out of three customers in the data set are European.\nTo address this issue, for each foreign key!primary key\nrelationship S Pbetween tables PandSwe add a column\nFS Pto tableSdenoting how many corresponding join\npartners a tuple has. We call these tuple factors and later\nuse them as correction factor. For instance, in the customer\ntable in Figure 5a for the \frst customer the tuple factor is\ntwo since there are two tuples in the order table for this\ncustomer. It is important to note that tuple factors have to\nbe computed only once per pair of tables that can be joined\nvia a foreign key. In DeepDB , we do this when the RSPNs\nfor a given database are created and our update procedure\nchanges those values as well. Tuple factors are included as\nadditional column and learned by the RSPNs just as usual\ncolumns. When used in a join, we denote them as F0\nS P.\nSince we are working with outer joins, the value of F0is at\nleast 1.\nWe can now express the query that asks for the count of\ncustomers from Europe as\njC d|><|dOj\u0001E\u00121\nF0C O\u00011cregion='EUROPE'\u0001NC\u0013\nwhich results in 5 \u00011=2+1=2+1\n5= 2. First, this query both\nincludes the \frst customer (who has no orders) because the\nRSPN was learned on the full outer join. Second, the query\nalso takes into account that the second and third customer\nhave two orders each by normalizing them with their tuple\nfactorF0\nC O.\nIn general, we can de\fne the procedure to compile a query\nrequiring only a part of an RSPN as follows:\nTheorem 1.LetQbe a COUNT query with a \flter pred-\nicateCwhich only queries a subset of the tables of a full\nouter join J:LetF0(Q;J)denote the product of all tuple\nfactors that cause result tuples of Qto appear multiple times\ninJ:The result of the query is equal to:\njJj\u0001E \n1\nF0(Q;J)\u00011C\u0001Y\nT2QNT!\n5\n\nFor an easier notation, we write the required factors of query\nQasF(Q). The expectation E(F(Q)) of theorem 1 can be\ncomputed with an RSPN because all columns are learned.\nCase 3: Combination of multiple RSPNs. As the last\ncase, we handle a COUNT query that needs to span over mul-\ntiple RSPNs. We \frst handle the case of two RSPNs and\nextend the procedure to nRSPNs later. In this case, the\nquery can be split into two subqueries QLandQR, one for\neach RSPN. There can also be an overlap between QLand\nQRwhich we denote as QO(i.e., a join over the shared com-\nmon tables). The idea is \frst to estimate the result of QL\nusing the \frst RSPN. We then multiply this result by the\nratio of tuples in QRvs. tuples in the overlap QO. Intu-\nitively, this expresses how much the missing tables not in\nQLincrease the COUNT value of the query result.\nFor instance, there is a separate RSPN available for the\nCustomer and the Order table in Figure 5a. The query Q2,\nas shown before, would be split into two queries QLandQR,\none against the RSPN built over the Customer table and the\nother one over the RSPN for the Order table.QOis empty\nin this case. The query result of Q2can thus be expressed\nusing all these sub-queries as:\njCj\u0001E(1cregion='EUROPE'\u0001FC O)|{z}\nQL\u0001E(1ochannel='ONLINE' )|{z}\nQR\nwhich results in 3 \u00012+0\n3\u00012\n4= 1:The intuition of this query is\nthat the left-hand side that uses QLcomputes the orders of\nEuropean customers while the right-hand side computes the\nfraction of orders that are ordered online out of all orders.\nWe now handle the more general case that the overlap\nis not empty and that there is a foreign key relationship\nS Tbetween a table SinQO(andQL) and a table Tin\nQR(but not in QL). In this case, we exploit the tuple factor\nFS Tin the left RSPN. We now do not just estimate the\nresult ofQLbut ofQLjoined with the table T:Of course\nthis increases the overlap which we now denote as Q0\nO:As a\ngeneral formula for this case, we obtain Theorem 2:\nTheorem 2.Let the \flter predicates and tuple factors of\nQLnQOandQRnQObe conditionally independent given\nthe \flter predicates of QO. LetS Tbe the foreign key\nrelationship between a table SinQLand a table TinQR\nthat we want to join. The result of Qis equal to\njJLj\u0001E(F(QL)\u0001FS T)\u0001E(F(QR))\nE(F(Q0\nO)):\nIndependence across RSPNs is often given since our en-\nsemble creation procedure preferably learns RSPNs over cor-\nrelated tables as discussed in Section 3.\nAlternatively, we can start the execution with QR. In our\nexample query Q2whereQRis the query over the orders\ntable, we can remove the corresponding tuple factor FC O\nfrom the left expectation. However, we then need to normal-\nizeQLby the tuple factors to correctly compute the fraction\nof customers who come from Europe. To that end, the query\nQ2can alternatively be computed using:\njOj\u0001E(1ochannel='ONLINE' )\u0001E(1cregion='EUROPE'\u0001FC OjFC O)\nE(FC OjFC O>0)\nExecution Strategy. If multiple RSPNs are required to an-\nswer a query, we have several possible execution strategies.Our goal should be to handle as many correlations between\n\flter predicates as possible because predicates across RSPNs\nare considered independent. For instance, assume we have\nboth the Customer ,Order and Customer-Order RSPNs of\nFigure 5 in our ensemble, and a join of customers and or-\nders would have \flter predicates on cregion;cageand\nochannel:In this case, we would prefer the Customer-Order\nRSPN because it can handle all pairwise correlations be-\ntween \flter columns ( cregion -cage,cregion -ochannel ,\ncage-cchannel ). Hence, at runtime we greedily use the\nRSPN that currently handles the \flter predicates with the\nhighest sum of pairwise RDC values. We also experimented\nwith strategies enumerating several probabilistic query com-\npilations and using the median of their predictions. How-\never, this was not superior to our RDC-based strategy. More-\nover, the RDC values have already been computed to decide\nwhich RSPNs to learn. Hence, at runtime this strategy is\nvery compute-e\u000ecient.\nThe \fnal aspect is how to handle joins spanning over more\nthan two RSPNs. To support this, we can apply Theorem 2\nseveral times.\n4.2 Other AQP Queries\nSo far, we only looked into COUNT queries without group-\nby statements. In the following, we \frst discuss how we ex-\ntend our query compilation to also support AVG and SUM\nqueries before we \fnally explain group-by statements as well\nas outer joins.\nAVG Queries. We again start with the case that we have\nan RSPN that exactly matches the tables of a query and\nlater discuss the other cases. For this case, queries with AVG\naggregates can be expressed as conditional expectations. For\ninstance, the query\nQ3: SELECT AVG( c_age )\nFROM CUSTOMER C\nWHERE c_region ='EUROPE ';\ncan be formulated as jC|\u0001E(cagejcregion='EUROPE' )\nwith the ensemble in Figure 5a.\nHowever, for the case that an RSPNs spans more tables\nthan required, we cannot directly use this conditional ex-\npectation because otherwise customers with several orders\nwould be weighted higher. Again, normalization by the tu-\nple factors is required. For instance, if the RSPN spans\ncustomers and orders as in Figure 5b for query Q3we use\nE\u0010\ncage\nF0C Ojcregion='EUROPE'\u0011\nE\u0010\n1\nF0C Ojcregion='EUROPE'\u0011=20=2 + 20=2 + 50\n1=2 + 1=2 + 1= 35:\nIn general, if an average query for the attribute Ashould\nbe computed for a join query Qwith \flter predicates C\non an RSPN on a full outer join J, we use the following\nexpectation to answer the average query:\nE\u0012A\nF0(Q;J)jC\u0013\n=E\u00121\nF0(Q;J)jC\u0013\n:\nThe last case is where the query needs more than one\nRSPN to answer the query. In this case, we only use one\nRSPN that contains Aand ignore some of the \flter predi-\ncates that are not in the RSPN. As long as Ais independent\nof these attributes, the result is correct. Otherwise, this is\njust an approximation. For selecting which RSPN should be\n6\n\nused, we again prefer RSPNs handling stronger correlations\nbetweenAandPquanti\fed by the RDC values. The RCDs\ncan also be used to detect cases where the approximation\nwould ignore strong correlations with the missing attributes\ninP.\nSUM Queries. For handling SUMqueries we run two queries:\none for the COUNT and AVGqueries. Multiplying them yields\nthe correct result for the SUMquery.\nGroup-by Queries. Finally, a group by query can be han-\ndled also by several individual queries with additional \flter\npredicates for every group. This means that for ngroups\nwe have to compute ntimes more expectations than for the\ncorresponding query without grouping. In our experimental\nevaluation, we show that this does not cause performance\nissues in practice if we compute the query on the model.\nOuter Joins. Query compilation can be easily extended to\nsupport outer joins (left/right/full). The idea is that we\nonly \flter out tuples that have no join partner for all inner\njoins (case 1 and 2 in Section 4.1) but not for outer joins\n(depending on the semantics of the outer join). Moreover, in\ncase 3, the tuple factors Fwith value zero have to be handled\nas value one to support the semantics of the corresponding\nouter join.\n4.3 Machine Learning (ML) Tasks\nMany ML tasks can directly also be expressed using RSPNs.\nFor example, regression tasks can directly be translated into\nconditional expectations. For classi\fcation we can use most\nprobable explanation (MPE) algorithms [22]. RSPNs are\noptimized to accurately represent the data which is bene-\n\fcial for AQP and cardinality estimation. However, they\nstill generalize since the dependency structure of the data is\nidenti\fed and thus the regression and classi\fcation perfor-\nmances are competitive as we show in our experiments.\n5. DEEPDB EXTENSIONS\nWe now describe important extensions of our basic frame-\nwork presented before. We \frst explain how con\fdence in-\ntervals are provided, which is especially important for AQP.\nWe then discuss how RSPNs can be updated if the database\nis changed. Finally, we present how we can optimize the ba-\nsic ensemble of RSPNs by additional RSPNs that can span\nmore than two tables.\n5.1 Support for Conﬁdence Intervals\nEspecially for AQP con\fdence intervals are important.\nHowever, SPNs do not provide those. After the probabilis-\ntic query compilation the query is expressed as a product of\nexpectations. We \frst describe how to estimate the uncer-\ntainty for each of those factors and eventually how a con\f-\ndence interval for the \fnal estimate can be derived.\nFirst, we split up expectations as a product of probabili-\nties and conditional expectations. For instance, the expec-\ntation E(X\u00011C) would be turned into E(XjC)\u0001P(C). This\nallows us to treat all probabilities for \flter predicates Cas\na single binomial variable with probability p=Y\nP(Ci)\nand the amount of training data of the RSPN as nsamples .\nHence, the variance isp\nnsamplesp(1\u0000p). For the condi-\ntional expectations, we use the Koenig-Huygens formula\nV(XjC) =E(X2jC)\u0000E(XjC)2. Note that also squared\nfactors can be computed with RSPNs since the square canbe pushed down to the leaf nodes. We now have a variance\nfor each factor in the result.\nFor the combination we need two simplifying assumptions:\n(i) the estimates for the expectations and probabilities are\nindependent, and (ii) the resulting estimate is normally dis-\ntributed. In our experimental evaluation, we show that de-\nspite these assumptions our con\fdence intervals match those\nof typical sample-based approaches.\nWe can now approximate the variance of the product using\nthe independence assumption by recursively applying the\nstandard equation for the product of independent random\nvariables: V(XY) =V(X)V(Y)+V(X)E(Y)2+V(Y)E(X)2.\nSince we know the variance of the entire probabilistic query\ncompilation and we assume that this estimate is normally\ndistributed we can provide con\fdence intervals.\n5.2 Support for Updates\nThe intuition of our update algorithm is to regard RSPNs\nas indexes. Similar to these, insertions and deletions only\na\u000bect subtrees and can be performed recursively. Hence,\nthe updated tuples recursively traverse the tree and passed\nweights of sum nodes and the leaf distributions are adapted.\nOur approach supports insert and delete operations, where\nanupdate -operation is mapped to a pair of delete andinsert\noperations.\nAlgorithm 1 Incremental Update\n1:procedure update tuple (node; tuple )\n2: ifleaf-node then\n3: update leafdistribution( node; tuple )\n4: else if sum-node then\n5: nearest child getnearest cluster (node; tuple )\n6: adapt weights( node; nearest child )\n7: update tuple( nearest child; tuple )\n8: else if product-node then\n9: forchild inchild nodes do\n10: tuple proj project tochild scope (tuple )\n11: update tuple( child; tuple proj)\nThe update algorithm is summarized in Algorithm 1. Since\nit is recursive, we have to handle sum, product and leaf\nnodes. At sum nodes (line 4) we have to identify to which\nchild node the inserted (deleted) tuple belongs to determine\nwhich weight has to be increased (decreased). Since children\nof sum nodes represent row clusters found by KMeans dur-\ning learning [22], we can compute the closest cluster center\n(line 5), increase (decrease) its weight (line 6) and propa-\ngate the tuple to this subtree (line 7). In contrast, product\nnodes (line 8) split the set of columns. Hence, we do not\npropagate the tuple to one of the children but split it and\npropagate each tuple fragment to the corresponding child\nnode (lines 9-11). Arriving at a leaf node, only a single\ncolumn of the tuple is remaining. We now update the leaf\ndistribution according to the column value (line 2).\nThis approach does not change the structure of the RSPN,\nbut only adapts the weights and the histogram values. If\nthere are new dependencies as a result of inserts they are\nnot represented in the RSPN. As we show in Section 6.1 on\na real-word data set, this typically does not happen, even for\nhigh incremental learning rates of 40%. Nevertheless, in case\nof new dependencies the RSPNs have to be rebuilt. This is\nsolved by checking the database cyclically for changed de-\npendencies by calculating the pairwise RDC values as ex-\nplained in Section 5.3 on column splits of product nodes.\nIf changes are detected in the dependencies, the a\u000bected\n7\n\nState\nCustomer Order Orderline0.6\n0.50.6 0.70.20.1(a) Schema with pairwise Dependencies (RDC)\n+\nx x+\nx x\nOrder Customer\n+\nx x+\nx x\nOrder Customer OrderlineState Customer Order OrderlineBase\nensemble\nAdditional RSPN  \nselected by\nOptimization\n(b) Base RSPN Ensemble with RDC threshold 0.3 and addi-\ntional RSPN selected by Optimization\nFigure 6: RSPN ensemble\nRSPNs are regenerated. As for traditional indexes, this can\nbe done in the background.\n5.3 Ensemble Optimization\nAs mentioned before, we create an ensemble of RSPNs for\na given database. The base ensemble contains either RSPNs\nfor single tables or they span over two tables connected by a\nforeign key relationship if they are correlated. Correlations\noccurring over more than two tables are ignored so far since\nthey lead to larger models and higher training times. In\nthe following, we thus discuss an extension of our ensemble\ncreation procedure that allows a user to specify a training\nbudget (in terms of time or space) and DeepDB selects the\nadditional larger RSPNs that should be created. We for-\nmulate the problem of which additional RSPNs to learn as\nconstrained optimization problem.\nTo quantify the correlations between tables, as mentioned\nalready before, we compute the pairwise RDC values for ev-\nery pair of attributes in the schema. For every pair of tables,\nwe de\fne the maximum RDC value between two columns\nmaxc2Ti;c02Tjrdc(c;c0) as the dependency value. The de-\npendency value indicates which tables should appear in the\nsame RSPN and which not. An example is given in Fig-\nure 6a. Here, the Customer ,Order and Orderline tables\nhave high pairwise correlations while the State table is only\nhighly correlated with the Customer table.\nFor every RSPN the goal is to achieve a high mean of\nthese pairwise maximal RDC values. This ensures that\nonly tables with high pairwise correlation are merged in an\nRSPN. For instance, the mean RDC value for the RSPN\nlearned over the full outer join of the tables Customer ,Order\nand Orderline would be (0 :6 + 0:7 + 0:5)=3 = 0:6. This\nRSPN is more valuable than an RSPN learned over the\nState ,Customer and Order tables with a mean RDC value\nof (0:6 + 0:6 + 0:2)=3 = 0:46. The overall objective function\nfor our optimization procedure to create an ensemble is thus\nto maximize the sum of all mean RDC values of the RSPNs\nin the ensemble.\nThe limiting factor (i.e., the constraint) for the additional\nRSPN ensemble selection should be the budget (i.e., extra\ntime compared to the base ensemble) we allow for the learn-\ning of additional RSPNs. For the optimization procedure,\nwe de\fne the maximum learning costs as a factor Brelativeto the learning costs of the base ensemble CBase. Hence,\na budget factor B= 0 means that only the base ensemble\nwould be created. For higher budget factors B > 0, addi-\ntional RSPNs over more tables are learned in addition. If\nwe assume that an RSPN ramong the set of all possible\nunique RSPNs Rhas a costC(r), then we could formulate\nthe optimization problem as follows:\nminimize\nEX\nr2Efmax\nc2Ti;c02Tjrdc(c;c0)jTi;Tj2rg\nsubject toX\nr2EC(r)\u0014B\u0001CBase\nHowever, estimating the real cost C(r) (i.e., time) to build\nan RSPNris hard and thus we can not directly solve the op-\ntimization procedure. Instead, we estimate the relative cost\nto select the RSPN rthat has the highest mean RDC value\nand the lowest relative creation cost. To model the relative\ncreation cost, we assume that the costs grow quadratic with\nthe number of columns cols(r) since the RDC values are\ncreated pairwise and linear in the number of rows rows (r).\nConsequently, we pick the RSPN rwith highest mean RDC\nand lowest cost which is cols(r)2\u0001rows (r) as long as the\nmaximum training time is not exceeded.\n6. EXPERIMENTAL EV ALUATION\nIn this Section, we show that DeepDB outperforms state-\nof-the-art systems for both cardinality estimation and AQP,\nwhere we not only demonstrate the performance of DeepDB\nfor both tasks but also show the capabilities of updating\nRSPNs. Moreover, we also study the performance of DeepDB\nfor di\u000berent ML tasks.\nThe RSPNs we used in all experiment were implemented\nin Python as extensions of SPFlow [23]. As hyperparam-\neters, we used an RDC threshold of 0 :3 and a minimum\ninstance slice of 1% of the input data, which determines the\ngranularity of clustering. Moreover, we used a budget factor\nof 0.5, i.e. the training of the larger RSPNs takes approxi-\nmately 50% more training time than the base ensemble. We\ndetermined the hyperparameters using a grid-search, which\ngave us the best results across di\u000berent data sets.\n6.1 Exp. 1: Cardinality Estimation\nFirst, we compare the prediction quality of DeepDB which\nis purely data-driven with state-of-the-art learned cardinal-\nity estimation techniques that take the workload into ac-\ncount.\nBaselines. In addition to the learned baselines, we also\ncompare against non-learned baselines. First we trained a\nMulti-Set Convolutional Network (MCSN) [8] as a learned\nbaseline. MCSNs are specialized deep neural networks using\nthe join paths, tables and \flter predicates as inputs. Also,\nwe use Index-Based Join Sampling [13] as a non-learned\nbaseline. This algorithm exploits secondary indexes to es-\ntimate the full join size using sampling. Furthermore, the\nstandard cardinality estimation of Postgres 11.5 was em-\nployed as another non-learned baseline. Additionally, we\nimplemented random sampling.\nWorkload. As in [8, 12], the JOB-light benchmark is used.\nThe benchmark uses the real-world IMDb database and de-\n\fnes 70 queries. Furthermore, we additionally de\fned a syn-\nthetic query set of 200 queries were joins from three to six\n8\n\nmedian 90th 95th max\nDeepDB (ours) 1.27 2.50 3.16 39.66\nMCSN 3.22 65 143 717\nPostgres 6.84 162 817 3477\nIBJS 1.67 72 333 6949\nRandom Sampling 5.05 73 10371 49187\nTable 1: Estimation Errors for the JOB-light Benchmark\ntables and one to \fve \flter predicates appear uniformly on\nthe IMDb data set. We use this query set to compare the\ngeneralization capabilities of the learned approaches.\nTraining Time. In contrast to other learned approaches for\ncardinality estimation [8, 32], no dedicated training data is\nrequired for DeepDB . Instead, we just learn a representation\nof the data. The training of the base ensemble takes 48 min-\nutes. The creation time includes the data preparation time\nto compute the tuple factors as introduced in Section 4.1.\nIn contrast, for the MCSN [8] approach, 100k queries need\nto be executed to collect cardinalities resulting in 34 hours\nof training data preparation time (when using Postgres).\nMoreover, the training of the neural network takes about 15\nminutes on a Nvidia V100 GPU.\nWe see that our training time is much lower since we do\nnot need to collect any training data for the workload. An-\nother advantage is that we do not have to re-run the queries\nonce the database is modi\fed. Instead, we provide an e\u000e-\ncient algorithm to update RSPNs in DeepDB as discussed\nin Section 3.2.\nEstimation Quality. The prediction quality of cardinality\nestimators is usually evaluated using the q-error which is the\nfactor by which an estimate di\u000bers from the real execution\njoin size. For example, if the real result size of a join is\n100, the estimates of 10 or 1000 tuples both have a q-error\nof 10. Using the ratio instead of an absolute or quadratic\nerror captures the intuition that for making optimization\ndecisions only relative di\u000berences matter.\nIn Table 1 we depicted the median, 90-th and 95-th per-\ncentile and max q-errors for the JOB-light benchmark of our\napproach compared to the baselines. As we can see DeepDB\noutperforms the best competitors in every percentile often\nby orders of magnitude. In the median it outperforms the\nbest competitor Index Based Join Sampling (1.23 vs. 1.59).\nThe advantage of the learned approach MCSN is that it\noutperforms traditional approaches by orders of magnitude\nfor the higher percentiles and is thus more robust. Even\nfor these outliers, DeepDB provides additional robustness\nhaving a 95-th percentile for the q-errors of 3.16 vs. 143\n(MCSN). The q-errors of both Postgres and random sam-\npling are again signi\fcantly larger both for the medians and\nthe higher percentiles. The estimation latencies for cardi-\nnalities using DeepDB are currently in the order of \u0016s to\nms which su\u000eces for complex join queries that can often\nrun multiple son larger data sets. By using smaller RSPNs\nor an optimized implementation of SPNs such as [31], the\nlatencies could further be reduced.\nGeneralization Capabilities. Especially for learned ap-\nproaches the question of generalization is important, i.e.\nhow well the models perform on previously unseen queries.\nFor instance, by default the MCSN approach is only trained\nwith queries up to three joins because otherwise the train-\ning data generation would be too expensive [8]. Similarly in\nour approach, in the ensemble only few RSPNs with large\n4-1 4-2 4-3 4-4 4-5 5-1 5-2 5-3 5-4 5-5 6-1 6-2 6-3 6-4 6-5\nTables and Predicates101102q-errorMCSN\nDeepDB (ours)Figure 7: Median q-errors (logarithmic Scale) for di\u000berent\nJoin Sizes (4,5,6) and Number of Filter Predicates (1-5).\nRandom 0% 5% 10% 20% 40%\nSplit\nMedian 1.22 1.26 1.30 1.28 1.37\n90th 3.45 3.04 2.94 3.15 3.60\n95th 4.77 4.50 4.19 4.32 3.79\nTemporal <2019 <2011 <2009 <2004 <1991\nSplit (0%) (4.7%) (9.3%) (19.7%) (40.1%)\nMedian 1.22 1.28 1.31 1.34 1.41\n90th 3.45 3.17 3.23 3.60 4.06\n95th 4.77 4.30 3.83 4.07 4.35\nTable 2: Estimation Errors for JOB-light after Updates for\na random and temporal Split.\njoins occur because otherwise the training would also be too\nexpensive. However, both approaches support cardinality\nestimates for unseen queries.\nTo compare both learned approaches, we randomly gen-\nerated queries for joins with four to six tables and one to\n\fve selection predicates for the IMDb data set. In Figure 7,\nwe plot the resulting median q-errors for both learned ap-\nproaches: DeepDB and MCSN [8]. The median q-errors\nofDeepDB are orders of magnitude lower for larger joins.\nAdditionally, we can observe that for the MCSN approach\nthe estimates tend to become less accurate for queries with\nfewer selection predicates. One possible explanation is that\nmore tuples qualify for such queries and thus higher cardi-\nnalities have to be estimated. However, since there are at\nmost three tables joined in the training data such higher\ncardinality values are most likely not predicted. We can\nconclude that using RSPNs leads to superior generalization\ncapabilities.\nUpdates. In this experiment, we show that updated RSPN\nensembles can precisely estimate cardinalities. To this end,\nwe \frst learn the base RSPN ensemble on a certain share of\nthe full IMDb data set (95%, 90%, 80% and 60%) and then\nupdate it using the remaining tuples. In a \frst experiment,\nthe IMDb data set is randomly split while in the second\nexperiment we learn the initial RSPNs on all movies up to\na certain production year. Both experiments show that the\nq-error does not change signi\fcantly for the updated RSPN\nensembles. Detailed results are given in Table 2. We use\nzero as the budget factor to demonstrate that even base\nensembles provide good estimates after updates. This is\nalso the reason that the estimation errors slightly deviate\nfrom Table 1.\nSince in the initial learning of the RSPN ensemble we learn\nthe RSPN on a sample of the full outer join, the same sample\nrate has to be used for the updates, i.e. we only update the\nRSPN with a sample of all inserted tuples. Using a sampling\nrate of 1%, we can handle up to 55,000 updates per second.\nThe structure of the RSPN tree is not changed during up-\ndates, but only the parameters are updated according to the\nnew tuples. However, in the experiments we could show that\nthis does not impair the accuracy on a real-world data set.\nThe updateability is a clear advantage of DeepDB com-\npared to deep-learning based approaches for cardinality es-\n9\n\n0 1 2 3\nEnsemble Learning Budget1.851.90q-error\n500010000\nTraining time (s)\nq-error\nTraining time\n105107\nSamples per RSPN (Base Ensemble)2.02.22.4q-error\n10002000\nTraining time (s)\nq-error\nTraining timeFigure 8: Q-errors and Training Time (in s) for varying\nBudget Factors and Sample Sizes.\ntimation [8, 32]. Since these model the problem end-to-end\nall training data queries would have to be run again on the\ndatabase to gather the updated cardinalities.\nParameter Exploration. Finally, in the last experiment we\nexplore the tradeo\u000b between ensemble training time and pre-\ndiction quality of DeepDB . We \frst vary the budget factor\nused in the ensemble selection between zero (i.e. learning\nonly the base ensemble with one RSPN per join of two ta-\nbles) and B=3 (i.e. the training of the larger RSPNs takes\napproximately three times longer than the base ensemble)\nwhile using 107samples per RSPN. We then use the result-\ning ensemble to evaluate 200 queries with three to six tables\nand one to \fve selection predicates. The resulting median q-\nerrors are shown in Figure 8. For higher budget factors the\nmeans are improving but already saturate at B= 0:5. This\nis because there are no strong correlations in larger joins\nthat have not already been captured in the base ensemble.\nWe moreover evaluate the e\u000bect of the sampling to reduce\nthe training time. In this experiment we vary the sample size\nfrom 1000 to 10 million. We observe that while the training\ntime increases, the higher we choose this parameter, the\nprediction quality improves (from 2.5 to 1.9 in the median).\nIn summary, the training time can be signi\fcantly reduced\nif slight compromises in prediction quality are acceptable.\nWhen minimization of training time is the more important\nobjective we can also fall back and only learn RSPNs for all\nsingle tables and no joins at all. This reduces the ensemble\ntraining time to just \fve minutes. However, even this cheap\nstrategy is still competitive. For JOB-light this ensemble\nhas a median q-error of 1.98, a 90-th percentile of 5.32, a\n95-th percentile of 8.54 and a maximum q-error of 186.53.\nSetting this in perspective to the baselines, this ensemble\nstill outperforms state of the art for the higher percentiles\nand only Index Based Join Sampling is slightly superior in\nthe median. This again proves the robustness of RSPNs.\n6.2 Exp. 2: AQP\nIn this Section, we compare DeepDB with state-of-the-art\nsystems for AQP.\nSetup. We evaluated the approaches on both a synthetic\ndata set and a real-world data set. As synthetic data set,\nwe used the Star Schema Benchmark (SSB) [25] with a scale\nfactor of 500 with the standard queries (denoted by S1.1-\nS4.3). As the real-world data set, we used the Flights data\nset2with queries ranging from selectivities between 5% an\n0.01% covering a variety of group by attributes, AVG,SUMand\nCOUNT queries (denoted by F1.1-F5.2). To scale the data set\nup to 1 billion records we used IDEBench [3].\nBaselines. As baselines we used VerdictDB [26], Wander\nJoin [14] and the Postgres TABLESAMPLE command (which\n2https://www.kaggle.com/usdot/\right-delays\nF1.1 F1.2 F2.1 F2.2 F2.3 F3.1 F3.2 F3.3 F4.1 F4.2 F5.1 F5.2\nQuery010Relative Error (%)\n0.00%\n0.14%\n0.28%0.00%\n0.20%\n0.18%0.00%\n0.15%\n0.46%\n0.58%\n0.77%\n0.39%\n0.02%\n0.75%\n0.27%Verdict DB Tablesample DeepDB (ours)\nF1.1 F1.2 F2.1 F2.2 F2.3 F3.1 F3.2 F3.3 F4.1 F4.2 F5.1 F5.2\nQuery02Latency (s)\n6ms\n2ms\n3ms\n10ms\n4ms\n7ms\n10ms\n9ms\n20ms\n9msVerdict DB Tablesample DeepDB (ours)Figure 9: Average relative Error and Latencies for the\nFlights data set.\nuses random samples). VerdictDB is a middleware that can\nbe used with any database system. It creates a strati\fed\nand a uniform sample for the fact tables to provide approx-\nimate queries. For VerdictDB, we used the default sample\nsize (1% of the full data set) for the Flights data set. For\nthe SSB benchmark, this led to high query latencies and we\nthus decided to choose a sample size such that the query\nprocessing time was two seconds on average. Wander Join\nis a join sampling algorithm leveraging secondary indexes to\ngenerate join samples quickly. We set the time bound also\nto two seconds for a fair comparison and only evaluated this\nalgorithm for data sets with joins. To this end, we created\nall secondary indexes for foreign key relationships and pred-\nicates on the dimension tables. For the TABLESAMPLE com-\nmand we chose a sample percentage such that the queries\ntake two seconds on average as well.\nTraining Time. For DeepDB the same hyperparameters\nwere used as for the previous experiment (Exp. 1). The\ntraining took just 17 minutes for the SSB data set and 3\nminutes for the Flights data set. The shorter training times\ncompared to the IMDb data set are due to fewer cross-table\ncorrelations and hence fewer large join models in the en-\nsemble. For VerdictDB, scrambles have to be created, i.e.\nuniform and strati\fed samples from the data set. This took\n10 hours for the \rights data set and 6 days for the SSB\nbenchmark using the standard implementation.3For wan-\nder join, secondary indexes had to be created also requiring\nseveral hours for the SSB data set.\nAccuracy and Latency. For AQP two dimensions are of\ninterest. First, the quality of the approximation quanti\fed\nwith the relative error. Second, the latency of the result is\nrelevant when evaluating AQP systems. The relative error\nis de\fned asjatrue\u0000apredictedj\natruewhereatrueandapredicted are the\ntrue and predicted aggregate function, respectively. If the\nquery is a group by query, several aggregates have to be\ncomputed. In this case, the relative error is averaged over\nall groups. The results for the Flights data set are given in\nFigure 9.\nFor the Flights data set, we can observe that DeepDB al-\nways has the lowest average relative error. This is often the\ncase for queries with lower selectivities where sample-based\napproaches have few tuples that satisfy the selection pred-\nicates and thus the approximations are very inaccurate. In\ncontrast, DeepDB does not rely on samples but models the\ndata distribution and leverages the learned representation\n3https://docs.verdictdb.org/reference/pyverdict/\n10\n\nS1.1 S1.2 S1.3 S2.1 S2.2 S2.3 S3.1 S3.2 S3.3 S3.4 S4.1 S4.2 S4.3\nQuery10−1102Relative Error (%)\n0.80%\n5.25%\nNo result\n9.20%No result\nNo result\nNo result\nNo result\nNo result\nNo result\nNo result\nNo result\nNo result0.16%\n0.00%\n0.41%\n0.41%\n1.04%\n1.05%\n0.64%\n0.24%\n1.32%\n1.03%\n3.21%\n0.14%\n0.41%\n5.91%VerdictDB\nWander Join\nTablesample\nDeepDB (ours)Figure 10: Average relative Error for SSB data set. Note the logarithmic Scale for the Errors.\nto provide estimates. For instance, for query 11 with a se-\nlectivity of 0.5% VerdictDB and the TABLESAMPLE strategy\nhave an average relative error of 15.6% and 13.6%, respec-\ntively. In contrast, the average relative error of DeepDB is\njust 2.6%.\nMoreover, the latencies for both TABLESAMPLE and Ver-\ndictDB are between one and two seconds on average. In\ncontrast, DeepDB does not rely on sampling but on evalu-\nating the RSPNs. This is signi\fcantly faster resulting in a\nmaximum latency of 31ms. This even holds true for queries\nwith several groups where more expectations have to be\ncomputed (at least one additional per di\u000berent group).\nThe higher accuracies of DeepDB are even more severe\nfor the SSB benchmark. The queries have even lower selec-\ntivities between 3.42% and 0.0075% for queries 1 to 12 and\n0.00007% for the very last query. This results in very in-\naccurate predictions of the sample-based approaches. Here,\nthe average relative errors are orders of magnitude lower\nforDeepDB always being less than 6%. In contrast, Ver-\ndictDB, Wander Join and the TABLESAMPLE approach often\nhave average relative errors larger than 100%. Moreover,\nfor some queries no estimate can be given at all because no\nsamples are drawn that satisfy the \flter predicates. How-\never, while the other approaches take two seconds to provide\nan estimate, DeepDB requires no more than 293ms in the\nworst case. In general the latencies for DeepDB are lower\nfor queries with fewer groups because less expectations have\nto be computed.\nConﬁdence Intervals. In this experiment, we evaluate how\naccurate the con\fdence intervals predicted by DeepDB are.\nTo this end, we measure the relative con\fdence interval\nlength de\fned as:apredicted\u0000alower\napredicted, whereapredicted is the pre-\ndiction and alower is the lower bound of the con\fdence in-\nterval.\nThis relative con\fdence interval length is compared to the\ncon\fdence interval of a sample-based approach. For this we\ndraw 10 million samples (as many samples as our models use\nfor learning in this experiment) and compute estimates for\nthe average, count and sum aggregates. We then compute\nthe con\fdence intervals of these estimates using standard\nstatistical methods. For COUNT aggregates, the estimator is\nsimply a binomial variable with parameters n=nsamples\nandp=apredicted=nsamples for which we can compute a con-\n\fdence interval. For AVGqueries we exploit the central limit\ntheorem stating that the estimator is normally distributed.\nWe then compute the standard deviation on the sample and\nderive the con\fdence interval for a normal variable having\nthis standard deviation and the mean of our estimate. For\nSUMqueries we model the estimator as a product of both\nestimators. The resulting con\fdence interval lengths can be\nseen as ground truth and are compared to the con\fdence\nintervals of our system in Figure 11. Note that we excluded\nqueries where less than 10 samples ful\flled the \flter predi-\nF1.1 F1.2 F2.1 F2.2 F2.3 F3.1 F3.2 F3.3 F4.1 F4.2 F5.1 F5.2\nQuery020Relative CI (%)Sample-based\nDeepDB (ours)\nS1.1 S1.2 S1.3 S2.1 S2.2 S2.3 S3.1 S3.2 S3.3 S4.1 S4.2\nQuery020Relative CI (%)Sample-based\nDeepDB (ours)Figure 11: True and predicted relative length of the Con\f-\ndence Intervals.\ncates. In these cases the estimation of a standard deviation\nhas itself a too high variance.\nIn all cases, the con\fdence intervals of DeepDB are very\ngood approximations of the true con\fdence intervals. The\nonly exception is query F5.2 for the Flights data set which is\na di\u000berence of two SUMaggregates. In this case, assumption\n(i) of Section 5.1 does not hold: the probabilities and expec-\ntation estimates cannot be considered independent. This is\nthe case because both SUMaggregates contain correlated at-\ntributes and thus the con\fdence intervals are overestimated.\nHowever, note that in the special case of the di\u000berence of\ntwo sum aggregates the AQP estimates are still very precise\nas shown in Figure 9 for the same query F5.2. Only the\ncon\fdence interval is overestimated. Such cases can easily\nbe identi\fed and only occur when arithmetic expressions of\nseveral aggregates should be estimated.\nOther ML-based Approaches. The only learned approach\nfor AQP that was recently published is DBEst [18]. Other\napproaches like [34] cannot provide estimates for joins and\nare thus similarly excluded. DBEst creates density and re-\ngression models for popular queries. They can be reused if\nonly where conditions on numeric attributes or ordinal cat-\negorical attributes are changed. But if an unseen new query\narrives and there is no model available we have to create a\nbiased sample ful\flling the non-ordinal conditions on cate-\ngorical columns.\nDepending on the selectivity, this comes at a cost. Af-\nterwards, the density and regression models on the sample\nhave to be learned. In contrast, in our approach, we learn\nan RSPN ensemble once and can provide estimates for ar-\nbitrary queries immediately. In Figure 12, we thus compare\nthe cumulative training time including sampling and data\npreparation times of DBEst and DeepDB for SSB. As we\ncan see, for query S1.2 and S1.3 the model of query S1.1 can\nbe reused and thus the cumulative training time does not\nincrease. In contrast, for some selective queries like S3.3 the\nbiased sampling and training takes very long ( >3 hours).\nForDeepDB the ensemble has to be trained just once and\nany query can be answered ad-hoc.\n11\n\nS1.1S1.2S1.3S2.1S2.2S2.3S3.1S3.2S3.3S3.4S4.1S4.2S4.3\nQuery010000CumulativeTraining Time (s)\nDBEst\nDeepDB (ours)Figure 12: Cumulative Time to create DBEst and DeepDB\nmodels for SSB Queries.\nArr. Delay Dep. Delay Taxi Out Taxi In Air Time Distance0100RMSERegression Tree\nNeural Network\nDeepDB (ours)\nArr. Delay Dep. Delay Taxi Out Taxi In Air Time Distance0100101102103Training Time (s)\n0s\n0s\n0s\n0s\n0s\n0sRegression Tree\nNeural Network\nDeepDB (ours)\nFigure 13: Estimation Errors and Training Times for Re-\ngression Tasks.\n6.3 Exp. 3: Machine Learning\nIn this experiment we show that RSPNs are competitive\nML regression models. We \frst predict all di\u000berent numeric\nattributes for the Flights data set using all other columns as\nfeatures with the same RSPN we used for the AQP queries.\nAs baselines we trained standard ML models on the same\ntraining data to solve the same prediction task and compare\nthe training time and Root Mean Squared Error (RMSE) on\nthe test set in Figure 13. The advantage of DeepDB is that\nno additional training is required to execute the regression\ntask while the RMSE is comparable to standard models.\nConsequently, using RSPNs we obtain a free classi\fcation\nand regression model for any combination of features.\n7. RELATED WORK\nBefore concluding, we discuss further related work on us-\ning ML for cardinality estimation and AQP and SPNs.\nLearned Cardinality Estimation. The problem of selec-\ntivity estimation for single tables is a special case of car-\ndinality estimation. There is a large body of work apply-\ning di\u000berent ML approaches including probabilistic graphi-\ncal models [35, 5, 4], neural networks [10, 15] and specialized\ndeep learning density models [6] to this problem. Recently,\nDutt et al. [2] suggested using lightweight tree-based mod-\nels in combination with log-transformed labels leading to\nsuperior predictions.\nThe \frst works applying ML to cardinality estimation in-\ncluding joins used simple regression models [1, 19]. More\nrecently, Deep Learning was speci\fcally proposed to solve\ncardinality estimation end-to-end [8, 32]. Woltmann et al.\n[36] also separate the problem of cardinality estimation ona large schema. To this end, deep learning models similar\nto [8] are learned for certain schema sub-parts. However,\ntwo models for schema sub-parts cannot be combined to\nprovide estimates for a larger join. Other techniques ex-\nploit learned models for overlapping subgraph templates for\nrecurring cloud workloads [37]. All these models need a\nworkload to be executed and used as training data which is\ndi\u000berent from our data-driven approach.\nLearned AQP. Early work [29] suggests to approximate\nOLAP cubes by mixture models based on found clusters in\nthe data. Though greatly reducing the required storage,\nthe approximation errors are relatively high. FunctionDB\n[33] constructs piecewise linear functions as approximation.\nIn contrast to DeepDB , only continuous variables are sup-\nported. DBEst [18] builds models for popular queries and\nthus samples do not have to be kept. However, in contrast to\nDeepDB only those popular queries and no ad-hoc queries\nare supported. Park et al. suggested Database Learning\n[27] which builds a model from query results that is lever-\naged to provide approximate results for future queries. In\ncontrast, DeepDB is data-driven and does not require past\nquery results. Moreover, specialized generative models were\nsuggested to draw samples for AQP [34]. However, this tech-\nnique does not work for joins.\nSPNs. Sum Product Networks [28, 21, 22] have recently\ngained attention because these graphical models allow an\ne\u000ecient inference process. Furthermore, our update process\ncan be seen as an orthogonal approach to online learning for\nSPNs [7]. In contrast to incremental learning schemes [11]\nfor SPNs, we do not change the structure if new tuples are\ninserted for performance reasons.\n8. CONCLUSION AND FUTURE WORK\nIn this work we have proposed DeepDB which is a data-\ndriven approach for learned database components. We have\nshown that our approach is general and can be used to sup-\nport various tasks including cardinality estimation and ap-\nproximate query processing. Our experiments demonstrate\nthat DeepDB outperforms both traditional and learned state-\nof-the-art techniques often by orders of magnitude. In addi-\ntion, we leveraged the same approach to support ML tasks\non the data set with accuracies competitive with neural net-\nworks while not requiring any additional training time.\nWe believe our data-driven approach for learning can also\nbe exploited to improve other database internals. For in-\nstance, it has already been shown that column correlations\ncan be exploited to improve indexing [38]. In addition, SPNs\nnaturally provide a notion of correlated clusters that can also\nbe used for suggesting using interesting patterns in data ex-\nploration. Finally, we believe that it is an interesting avenue\nof future work to combine data-driven and workload-driven\napproaches to combine the best of both worlds.\n12\n\n9. REFERENCES[1] M. Akdere, U. C \u0018etintemel, M. Riondato, E. Upfal, and S. B.\nZdonik. Learning-based query performance modeling and\nprediction. In 2012 IEEE 28th International Conference on\nData Engineering , pages 390{401. IEEE, 2012.\n[2] A. Dutt, C. Wang, A. Nazi, S. Kandula, V. R. Narasayya, and\nS. Chaudhuri. Selectivity estimation for range predicates using\nlightweight models. PVLDB , 12(9):1044{1057, 2019.\n[3] P. Eichmann, C. Binnig, T. Kraska, and E. Zgraggen. Idebench:\nA benchmark for interactive data exploration, 2018.\n[4] L. Getoor and L. Mihalkova. Learning statistical models from\nrelational data. In Proceedings of the 2011 ACM SIGMOD\nInternational Conference on Management of Data , SIGMOD\n'11, pages 1195{1198, New York, NY, USA, 2011. ACM.\n[5] L. Getoor, B. Taskar, and D. Koller. Selectivity estimation\nusing probabilistic models. In Proceedings of the 2001 ACM\nSIGMOD International Conference on Management of Data ,\nSIGMOD '01, pages 461{472, New York, NY, USA, 2001. ACM.\n[6] S. Hasan, S. Thirumuruganathan, J. Augustine, N. Koudas,\nand G. Das. Multi-attribute selectivity estimation using deep\nlearning. CoRR , abs/1903.09999, 2019.\n[7] A. Kalra, A. Rashwan, W.-S. Hsu, P. Poupart, P. Doshi, and\nG. Trimponias. Online structure learning for feed-forward and\nrecurrent sum-product networks. In Advances in Neural\nInformation Processing Systems , pages 6944{6954, 2018.\n[8] A. Kipf, T. Kipf, B. Radke, V. Leis, P. A. Boncz, and\nA. Kemper. Learned cardinalities: Estimating correlated joins\nwith deep learning. In CIDR 2019, 9th Biennial Conference\non Innovative Data Systems Research, Asilomar, CA, USA,\nJanuary 13-16, 2019, Online Proceedings , 2019.\n[9] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The\ncase for learned index structures. In Proceedings of the 2018\nInternational Conference on Management of Data , SIGMOD\n'18, pages 489{504, New York, NY, USA, 2018. ACM.\n[10] M. S. Lakshmi and S. Zhou. Selectivity estimation in extensible\ndatabases - a neural network approach. In Proceedings of the\n24rd International Conference on Very Large Data Bases ,\nVLDB '98, pages 623{627, San Francisco, CA, USA, 1998.\nMorgan Kaufmann Publishers Inc.\n[11] S.-W. Lee, M.-O. Heo, and B.-T. Zhang. Online incremental\nstructure learning of sum{product networks. In International\nConference on Neural Information Processing , pages 220{227.\nSpringer, 2013.\n[12] V. Leis, A. Gubichev, A. Mirchev, P. Boncz, A. Kemper, and\nT. Neumann. How good are query optimizers, really? Proc.\nVLDB Endow. , 9(3):204{215, Nov. 2015.\n[13] V. Leis, B. Radke, A. Gubichev, A. Kemper, and T. Neumann.\nCardinality estimation done right: Index-based join sampling.\nInCIDR 2017, 8th Biennial Conference on Innovative Data\nSystems Research, Chaminade, CA, USA, January 8-11,\n2017, Online Proceedings , 2017.\n[14] F. Li, B. Wu, K. Yi, and Z. Zhao. Wander join: Online\naggregation via random walks. In Proceedings of the 2016\nInternational Conference on Management of Data , SIGMOD\n'16, pages 615{629, New York, NY, USA, 2016. ACM.\n[15] H. Liu, M. Xu, Z. Yu, V. Corvinelli, and C. Zuzarte.\nCardinality estimation using neural networks. In Proceedings of\nthe 25th Annual International Conference on Computer\nScience and Software Engineering , CASCON '15, pages 53{59,\nRiverton, NJ, USA, 2015. IBM Corp.\n[16] D. Lopez-Paz, P. Hennig, and B. Sch olkopf. The randomized\ndependence coe\u000ecient. In Advances in neural information\nprocessing systems , pages 1{9, 2013.\n[17] Q. Ma and P. Trianta\fllou. Dbest: Revisiting approximate\nquery processing engines with machine learning models. In\nProceedings of the 2019 International Conference on\nManagement of Data, SIGMOD Conference 2019,\nAmsterdam, The Netherlands, June 30 - July 5, 2019. , pages\n1553{1570, 2019.\n[18] Q. Ma and P. Trianta\fllou. Dbest: Revisiting approximate\nquery processing engines with machine learning models. In\nProceedings of the 2019 International Conference on\nManagement of Data , SIGMOD '19, pages 1553{1570, New\nYork, NY, USA, 2019. ACM.\n[19] T. Malik, R. Burns, and N. Chawla. A black-box approach to\nquery cardinality estimation. In CIDR , 2007.[20] R. Marcus, P. Negi, H. Mao, C. Zhang, M. Alizadeh, T. Kraska,\nO. Papaemmanouil, and N. Tatbul. Neo: A learned query\noptimizer. CoRR , abs/1904.03711, 2019.\n[21] A. Molina, S. Natarajan, and K. Kersting. Poisson\nSum-Product Networks: A Deep Architecture for Tractable\nMultivariate Poisson Distributions. 2017.\n[22] A. Molina, A. Vergari, N. D. Mauro, S. Natarajan, F. Esposito,\nand K. Kersting. Mixed Sum-Product Networks: A Deep\nArchitecture for Hybrid Domains. In AAAI , 2018.\n[23] A. Molina, A. Vergari, K. Stelzner, R. Peharz, P. Subramani,\nN. D. Mauro, P. Poupart, and K. Kersting. Sp\row: An easy\nand extensible library for deep probabilistic learning using\nsum-product networks, 2019.\n[24] A. Nath and P. Domingos. Learning relational sum-product\nnetworks. In Proceedings of the Twenty-Ninth AAAI\nConference on Arti\fcial Intelligence , pages 2878{2886. AAAI\nPress, 2015.\n[25] P. ONeil, E. ONeil, X. Chen, and S. Revilak. The star schema\nbenchmark and augmented fact table indexing. In Technology\nConference on Performance Evaluation and Benchmarking ,\npages 237{252. Springer, 2009.\n[26] Y. Park, B. Mozafari, J. Sorenson, and J. Wang. Verdictdb:\nUniversalizing approximate query processing. In Proceedings of\nthe 2018 International Conference on Management of Data ,\nSIGMOD '18, pages 1461{1476, New York, NY, USA, 2018.\nACM.\n[27] Y. Park, A. S. Tajik, M. Cafarella, and B. Mozafari. Database\nlearning: Toward a database that becomes smarter every time.\nInProceedings of the 2017 ACM International Conference on\nManagement of Data , SIGMOD '17, pages 587{602, New York,\nNY, USA, 2017. ACM.\n[28] H. Poon and P. Domingos. Sum-product networks: A New\nDeep Architecture. In 2011 IEEE International Conference on\nComputer Vision Workshops , pages 689{690, November 2011.\n[29] J. Shanmugasundaram, U. Fayyad, P. S. Bradley, et al.\nCompressed data cubes for olap aggregate query approximation\non continuous dimensions. 1999.\n[30] Y. Sheng, A. Tomasic, T. Zhang, and A. Pavlo. Scheduling\nOLTP transactions via learned abort prediction. In Proceedings\nof the Second International Workshop on Exploiting Arti\fcial\nIntelligence Techniques for Data Management,\naiDM@SIGMOD 2019, Amsterdam, The Netherlands, July 5,\n2019, pages 1:1{1:8, 2019.\n[31] L. Sommer, J. Oppermann, A. Molina, C. Binnig, K. Kersting,\nand A. Koch. Automatic mapping of the sum-product network\ninference problem to fpga-based accelerators. In 2018 IEEE\n36th International Conference on Computer Design (ICCD) ,\npages 350{357, 2018.\n[32] J. Sun and G. Li. An end-to-end learning-based cost estimator.\nCoRR , abs/1906.02560, 2019.\n[33] A. Thiagarajan and S. Madden. Querying continuous functions\nin a database system. In Proceedings of the 2008 ACM\nSIGMOD international conference on Management of data ,\npages 791{804. ACM, 2008.\n[34] S. Thirumuruganathan, S. Hasan, N. Koudas, and G. Das.\nApproximate query processing using deep generative models.\nCoRR , abs/1903.10000, 2019.\n[35] K. Tzoumas, A. Deshpande, and C. S. Jensen. E\u000eciently\nadapting graphical models for selectivity estimation. The\nVLDB Journal , 22(1):3{27, Feb. 2013.\n[36] L. Woltmann, C. Hartmann, M. Thiele, D. Habich, and\nW. Lehner. Cardinality estimation with local deep learning\nmodels. In Proceedings of the Second International Workshop\non Exploiting Arti\fcial Intelligence Techniques for Data\nManagement , aiDM '19, pages 5:1{5:8, New York, NY, USA,\n2019. ACM.\n[37] C. Wu, A. Jindal, S. Amizadeh, H. Patel, W. Le, S. Qiao, and\nS. Rao. Towards a learning optimizer for shared clouds. Proc.\nVLDB Endow. , 12(3):210{222, Nov. 2018.\n[38] Y. Wu, J. Yu, Y. Tian, R. Sidle, and R. Barber. Designing\nsuccinct secondary indexing mechanism by exploiting column\ncorrelations. In Proceedings of the 2019 International\nConference on Management of Data , SIGMOD '19, pages\n1223{1240, New York, NY, USA, 2019. ACM.\n13",
  "textLength": 78477
}