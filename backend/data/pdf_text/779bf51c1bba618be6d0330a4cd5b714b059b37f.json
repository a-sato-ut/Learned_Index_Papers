{
  "paperId": "779bf51c1bba618be6d0330a4cd5b714b059b37f",
  "title": "Online Covering with Multiple Experts",
  "pdfPath": "779bf51c1bba618be6d0330a4cd5b714b059b37f.pdf",
  "text": "Online Covering with Multiple Experts\nKevi Enik ˝o and Nguyễn Kim Thắng\nLIG, University Grenoble-Alpes, France\nDecember 25, 2023\nAbstract\nDesigning online algorithms with machine learning predictions is a recent technique beyond\nthe worst-case paradigm for various practically relevant online problems (scheduling, caching,\nclustering, skirental, etc.). Whilemostpreviouslearning-augmentedalgorithmapproachesfocus\non integrating the predictions of a single oracle, we study the design of online algorithms with\nmultiple experts. To go beyond the popular benchmark of a static best expert in hindsight,\nwe propose a new dynamic benchmark (linear combinations of predictions that change over\ntime). We present a competitive algorithm in the new dynamic benchmark with a performance\nguarantee of O(logK), where Kis the number of experts, for 0−1online optimization problems.\nFurthermore, our multiple-expert approach provides a new perspective on how to combine in an\nonline manner several online algorithms - a long-standing central subject in the online algorithm\nresearch community.\n1 Introduction\nThe domain of algorithms with predictions [24] - or learning augmented algorithms - emerged re-\ncently and grown immensely at the intersection of (discrete) algorithm design and machine learning\n(ML). Combining ML techniques with traditional algorithm design methods enables online algo-\nrithms to benefit from predictions that can infer future information from patterns in past data. On-\nline algorithms with predictions can obtain performance guarantees beyond the worst-case analysis\nand provide fine-tuned solutions to various problems. In the literature, many significant problems\nhave new learning-augmented results, for example, scheduling [20, 23], caching (paging) [21, 25, 4],\nski rental [14, 19, 3], counting sketches [16], bloom filters [18, 22], and metric task systems [5].\nEven though predictions provide a glimpse of the future, there is no mathematical guarantee\nof their accuracy. Adjusting the algorithm’s trust in the predictions is a significant challenge since\nonline algorithms must make irrevocable decisions at each time step. Ideally, if the predictions are\naccurate, the algorithm should perform well compared to the offline setting. In contrast, if the\npredictions are misleading, the algorithm should maintain a competitive solution, similar to the\nonline setting where no predictive information is available. In other words, online algorithms with\npredictions are expected to bring the best of both worlds: mathematical performance guarantees\nof classical algorithms and good future prediction capabilities of machine learning methods.\nPredictions can come from multiple sources (heuristics, oracles, randomized methods, etc.), but\nwe ignore their nature and call all of them experts. An algorithm’s consistency with the experts’\nsuggestions is typically measured by comparing the algorithm’s result with the solution of the best\nexpert. A representative example is the popular notion of regret in online learning, which fueled\nthe development of many powerful algorithms and techniques.\n1arXiv:2312.14564v1  [cs.DS]  22 Dec 2023\n\nA natural research question is whether it is possible to design competitive algorithms with\nmathematical performance guarantees with a stronger benchmark than the best expert. Comparing\nan algorithm with a stronger benchmark could provide deeper insights into the learning process\nand give better ways of exploiting the experts’ predictions.\nTaking a broader view, we can study whether combining predictions of several experts is similar\nto combining multiple online algorithms and whether we can expect to achieve better solutions with\nthe combination. Assuming that we do not know in advance which of the given algorithms would\nperform best on the upcoming requests, can we combine the algorithms in some generic way to\nobtain a competitive online strategy? This has been a long-standing question in the community of\nonline algorithms [6, 8]. To find an answer, it is a crucial to understand to what extent such an\nonline strategy can benefit from the input of multiple algorithms and what is a suitable benchmark\nto evaluate its performance.\nWhile in a completely general setting such an online strategy and a corresponding benchmark\nmay not exist, in our paper we propose an algorithm for online linear problems with covering\nconstraints that is competitive with a new benchmark (informally the best linear combination of\nthe experts). Therefore, our paper partially addresses the question we raised in the previous\nparagraph.\n1.1 Model and Problem\nCovering problem with experts. We have nresources and each resource ihas a cost per unit\ncithat we know in advance ( 1≤i≤n). Let xibe a non-negative variable representing the amount\nchosen from resource i. The total cost of a solution (xi)n\ni=1isPn\ni=1cixi. The problem includes K\nexperts and the problem’s (covering type) constraints are revealed online (one by one). At each\ntime t≥1, we receive a covering constraintPn\ni=1at\nixi≥1(where at\ni≥0) and each expert k\n(where 1≤k≤K) provides a solution (st\ni,k)n\ni=1. An algorithm can observe the experts’ solutions\nand afterwards it must update its own solution (denoted as (xt\ni)n\ni=1) to satisfy the new constraint,\nwhile maintaining the satisfaction of the previous ones. This algorithm must update its solution\nin the sense of online algorithms, so it cannot modify the previously made decisions. Formally,\nxt\ni≥xt−1\ni∀i, t. Our goal is to design such an algorithm and minimizePn\ni=1cixT\nisubject to all\nonline covering constraints t, where 1≤t≤T. The value Tis the last time a constraint is released,\nand it is not known by the algorithm.\nExperts. In our model, the experts’ predictions are also online solutions. In other words, the\nexperts’ solutions fulfill the following properties:\n1. for every expert kand for every time tthe solution (st\ni,k)n\ni=1is feasible, therefore, every\nconstraint t′where 1≤t′≤tis satisfied;\n2. for every expert kand for every time tand for every resource i, the previous expert solutions\nare irrevocable, therefore st\ni,k≥st′\ni,kfor all t′≤t.\nThese properties can be verified online. If some experts do not satisfy them, we simply ignore those\nexperts both in the decision-making and in the benchmark. A crucial remark: we do notassume\nthat the experts’ solutions must be tight at each constraint t, meaning thatPn\ni=1at\nist\ni,k= 1∀t, k.\nThis assumption is unrealistic and cannot be maintained in an online manner (see the discussion\nin Appendix A). Besides, assuming tight constraint satisfaction would simplify the problem, while\nintuitively, the difficulty of designing competitive algorithms comes from the lack of obvious ways\nto distinguish good expert solutions from (probably many) non-efficient/misleading ones.\n2\n\nminnX\ni=1cixT\ni= minnX\ni=1ciTX\nt=1\u0000\nxt\ni−xt−1\ni\u0001\nsubject toKX\nk=1wt\nk= 1 ∀t\nxt\ni≥KX\nk=1wt\nkst\ni,k ∀i, t\nxt\ni≥xt−1\ni ∀i, t\nwt\nk≥0 ∀t, k\nwhere 1≤t≤Tand1≤i≤n.\nFigure 1: Formulation of the LIN-COMB benchmark\nBenchmark. We consider a dynamic benchmark that intuitively captures the best linear combi-\nnationof all experts’ solutions over time . Informally, at any online time step, the benchmark can\ntake a linear combination of the experts’ solutions. The linear combination can be changed over\ntime, and it can be different from previous combinations. However, the benchmark’s decisions are\nalso online, so it cannot decrease the value of the decision variables ( xi). We refer to our benchmark\nwith the name LIN-COMB from now on.\nThe LIN-COMB benchmark’s formal description is a linear program, visible on Figure 1. Let\nwt\nk≥0be the weight assigned by the LIN-COMB benchmark to expert k(where 1≤k≤K) at\ntime t. Since we consider a linear combination, the constraintPK\nk=1wt\nk= 1must hold. The\nsolution of LIN-COMB at time tis ideally xt\ni=PK\nk=1wt\nkst\ni,k, however, xt\nimust be larger than xt−1\ni.\nTherefore, we set xt\ni= max\bPK\nk=1wt\nkst\ni,k, xt−1\ni\t\n. In other words, given the chosen weights, ifPK\nk=1wt\nkst\ni,k< xt−1\nithen xt\ni←xt−1\ni, otherwise xt\ni←PK\nk=1wt\nkst\ni,k.\nSince every expert’s solution is feasible by our assumptions, at each time tand for all resource i\n(where 1≤i≤n), the constructed solution xt\ni≥PK\nk=1wt\nkst\ni,kconstitutes a feasible solution to the\ncovering constraints of the original covering problem. Formally, for every constraint t′with t′≤t,\nnX\ni=1at′\nixt\ni≥nX\ni=1at′\ni\u0012KX\nk=1wt\nkst\ni,k\u0013\n=KX\nk=1wt\nk\u0012nX\ni=1at′\nist\ni,k\u0013\n≥KX\nk=1wt\nk≥1\nwhere the second inequality holds due to the feasibility of the experts’ solutions. We highlight that\nthe best-expert benchmark is included in LIN-COMB . By setting wt\nk∗= 1for all t, where 1≤t≤T,\nandwt\nk= 0for all k̸=k∗where k∗we get the best expert in hindsight (so xt\ni=st\ni,k∗for all i, t).\n1.2 Our approach and contribution\nTo design competitive algorithms with the new benchmark, we consider a primal-dual approach.\nFirst, we relax the linear program formulation of LIN-COMB (visible on Figure 1), which serves as a\nlower bound. Then, we take the dual of the relaxation, which is a lower bound on the relaxation.\nTherefore, following the chain of lower bounds, the dual problem is a lower bound on the LIN-COMB\nbenchmark.\n3\n\nAt every time step during the execution, our algorithm constructs decisions based on the solu-\ntion of a convex program. Our approach is inspired by the convex regularization method of [11].\nThe objective of the convex program is a shifted entropy function. These functions have been\nwidely used, in particular in the recent breakthrough related to k-server [10, 12] and metrical tasks\nproblems [9], in which the entropy functions are shifted by constant parameters. A novelpoint\nin our approach is that the entropy function is shifted by the average of the experts’ solutions.\nMoreover, regarding the constraints of the convex program, instead of using the experts’ solutions\ndirectly, we define auxiliary solutions that guarantee tight constraint satisfaction and use them in\nthe constraints. Intuitively, this eliminates/modifies the malicious experts’ solutions.\nLetρbe the maximum ratio between the experts’ solutions on the resources. Formally,\nρ:= max\nimax\nt′,t′′\u001aPK\nk=1st′\ni,kPK\nk=1st′′\ni,k\u001b\ns.t.KX\nk=1st′′\ni,k>0.\nInformally, ρrepresents the discrepancy across the experts’ predictions. Our main result is an\nalgorithm that has an objective cost at most O(ln(Kρ))times the cost of the LIN-COMB benchmark.\nIn particular, for 0-1optimization problems, where the experts provide integer (deterministic or\nrandomized) solutions, our algorithm is O(lnK)-competitive with LIN-COMB . An interesting feature\nof our algorithm is its resilience to the fluctuation of the quality of predictions (as discussed in the\nsection below and illustrated in the experiments).\n1.3 Related work and discussions\nFigure 2: Robustness-ConsistencyMuch of the research focusing on surpassing worst-case\nperformance guarantees is motivated by the spectacu-\nlar advances of machine learning (ML). Specifically, ML\nmethods can detect patterns among the arriving input\nrequests and provide valuable insights for the online algo-\nrithms regarding future requests. [21] introduced a gen-\neral framework to integrate ML predictions into classi-\ncal algorithm designs to surpass the worst-case perfor-\nmance limit. As a result, many practically relevant on-\nline problems were revisited to enhance existing classical\nalgorithms with ML predictions (see the aforementioned\n[20, 23, 21, 25, 4, 14, 19, 3, 16, 18, 22, 5]).\nOnahigh-levelview, weaimtodesignalgorithmsthat\nare robust (competitive) to the offline optimal solution\nand also consistent with the expert’s predictions. Ideally,\ntheperformanceofthedesignedalgorithmshouldsurpasspreviousboundswheneverthepredictions\nare reliable (low errors). However, most learning-augmented algorithms suffer when the error rates\nareneitherverylownorveryhigh, resultinginpredictionconfidencethatisneitherverylownorvery\nhigh. Figure2providesageneralpictureoftheperformanceofanalgorithmwithpredictions, which\nisrepresentativeformanyproblems(forexample, [7,17]). Inthefigure, ηindicatestheconfidencein\nthe predictions (or equivalently the error rate of predictions). The learning-augmented algorithm’s\nperformance bound is the maximum value of the green and orange curves (gray shaded area on the\nfigure). We can observe that when 0.4≤η≤0.9, the algorithm’s performance guarantee is worse\nthan the classical worst-case guarantee (that can be achieved by simply ignoring all predictions).\nIntuitively, in the case of neither very low nor very high confidence in the predictions, the algorithm\n4\n\nhas a hard time deciding if it should follow the predictions or the best-known standard algorithm\nin the worst-case paradigm. It naturally raises the question of whether one can surely guarantee\nto achieve at least a constant factor of the worst-case guarantee (where the constant is as close to\n1 as possible), assuring the resilience of the output solutions despite the quality of the predictions.\nOur algorithm, together with the new benchmark, provides an answer to this question.\nThe paper of [2] is closely related to ours and studies the design of algorithms with multiple\nexperts. They consider a DYNAMIC benchmark that is intuitively the minimum cost solution that is\nsupported by at least one expert solution at each step. Formally:\nDYNAMIC = min\nˆx∈ˆXnX\ni=1ciˆxi, where\nˆX={ˆx:∀i∈[n],∀t∈[T],∃k∈[K]such that st\ni,k≤ˆxi}\nOur benchmark, LIN-COMB , is included in DYNAMIC, since every solution xt\niinLIN-COMB satisfies:\nxt\ni≥X\nkst\ni,kwt\nk≥min\nk{st\ni,k}\ntherefore, for any iandt, there exists ksuch that xt\ni≥st\ni,k. However, the inverse is not true:\na solution ˆxt∈ˆXinDYNAMIC is not necessarily a linear combination of the experts’ solutions.\nThe DYNAMIC benchmark in [2] relied on the assumption that at every time step the experts’ solu-\ntions are tight. This assumption is unrealistic and impossible to maintain in online solutions (see\nAppendix A). [2] claimed an O(logK)-competitive algorithm in the DYNAMIC benchmark. Unfortu-\nnately, this is incorrect ; we show an example in Appendix B in which their algorithm’s performance\nguarantee is unbounded in the DYNAMIC benchmark.\nIntegrating multiple predictions into the online algorithm design was a topic of other papers as\nwell. As an example, [15] studied the ski rental problem with multiple predictions. The authors\ndefined a consistency metric, which compares the performance of their algorithm to the optimal\nsolution, given that at least one prediction (among the kpredictions) is optimal. [1] also considered\nmultiplepredictionsintheonlinefacilitylocationproblem. Theycomparedtheperformanceoftheir\nalgorithm to the best possible solution obtained on the union of the suggestions. Recently, [13]\nstudied the use of multiple predictors for several problems such as matching, load balancing, and\nnon-clairvoyant scheduling. They provided algorithms competitive to the best predictor for such\nproblems. An important remark: all the above benchmarks are captured within LIN-COMB .\nFurthermore, [5] proposed an algorithm with multiple experts for the metrical task system\nproblem. Their benchmark allows switching from one expert to another at each time step, but it\ndoes not allow combinations of experts or any solution not suggested by one of the experts. In our\nLIN-COMB benchmark, the linear combinations that evolve over time could result in a solution that\nis not suggested by one of the experts and potentially they can be much more efficient. In [5] there\nis a cost for state transitions, which is appropriate for their problems, but in many other problems,\nthe smooth transition with additional costs from previous decisions to new ones is not allowed (past\ndecisions are immutable). Therefore, the results of [5] are not applicable to our setting.\nCombining online algorithms into a new algorithm to achieve better results than the individual\ninput algorithms has been a long-standing online algorithm design question [6, 8]. Its intrinsic\ndifficulty is similar to the issue we mentioned earlier: when the performance of the given input\nalgorithms (or heuristics) is unclear (especially in the online setting), it is challenging to create a\ncombination that can surpass the performance of the included algorithms. Following the current\ndevelopment of online algorithm design techniques with multiple predictions, this subject has been\nrenewed with different machine learning approaches. Our paper contributes to this line of research.\n5\n\n2 Online covering with multiple experts\nOur proposed algorithm solves online covering problems by creating linear combinations of the\nsolutions proposed by Kexperts in an online manner. Recall that we evaluate the performance of\nour algorithm with the LIN-COMB benchmark (formalized on Figure 1), which consists of the best\nlinear combination of the experts’ solution at each step.\nSince our LIN-COMB benchmark is a linear combination of the experts’ solutions, the equalityPK\nk=1wt\nk= 1must hold, where wt\nk≥0is the weight assigned to expert k(where 1≤k≤K) at time\nt. Inthefollowing, weformulatearelaxedversionofthe LIN-COMB formulation, wherePK\nk=1wt\nk≥1.\nAdditionally, the relaxed formulation enables us to avoid the (online) hard constraint requiring\nwt\nkst\ni,k≥wt−1\nkst−1\ni,kto hold, and instead, we introduce a new variable, yt\ni, to represent the increase\nofxt\nicompared to xt−1\ni. When wt\nkst\ni,k< wt−1\nkst−1\ni,kduring the execution, we set the contribution of\niat time tto be 0, and therefore, yt\ni= 0. The relaxed formulation is visible on Figure 3.\nDue to the relaxed constraint, the optimal solution of the relaxed linear program is a lower\nbound of our LIN-COMB benchmark. The dual of the relaxation is displayed on Figure 4.\nminTX\nt=1nX\ni=1ciyt\ni\n(αt)KX\nk=1wt\nk≥1 ∀t\n(βt\ni)KX\nk=1\u0010\nwt\nkst\ni,k−wt−1\nkst−1\ni,k\u0011\n≤yt\ni ∀i, t\nwt\nk, yt\ni≥0 ∀i, t, k\nFigure 3: Formulation of the relaxation of the LIN-COMB benchmark\nmaxTX\nt=1αt\n(xt\nk) αt+nX\ni=1st\ni,k(βt+1\ni−βt\ni)≤0 ∀k, t\n(yt\ni) βt\ni≤ci ∀i, t\nαt\ni, βt\ni≥0 ∀i, t\nFigure 4: Dual formulation of the relaxation of the LIN-COMB benchmark\nAccording to the theorem of weak duality, any feasible solution of the dual program lower\nbounds any feasible solution of the primal program, and therefore, any feasible dual solution also\nlower bounds our LIN-COMB benchmark. Following the chain of lower bounds, our approach to\ndesign a competitive algorithm is as follows. At every time step t, we build solutions for all xt\ni\n6\n\ntogether with the solutions for the dual problem (αt, βt\ni). Then, we bound the cost of the algorithm\nto that of the dual. It is important to emphasize that the designed solution for every xt\nimust\nbe feasible to the covering constraints, but it may not necessarily be a linear combination of the\nexperts’ solutions.\n2.1 Competitive Algorithm\nPreprocessing. Recall that by our assumptions, the experts’ solutions are always feasible and\nnon-decreasing. At the arrival of the tthconstraint, expert k(where 1≤k≤K) provides a feasible\nsolution st\nk= (st\ni,k)n\ni=1, such that st\ni,k≥st′\ni,kfor all t′≤tand all iwhere 1≤i≤n. These\nassumptions do not exclude the possibility for the experts to provide malicious solutions that\ninstruct the algorithm to use an unnecessarily large amount of resources. Note that contrary to the\nassumption in [2], we can notexpect the experts’ solutions to be always tight. (In Appendix A we\nshow an example that tight solutions cannot be maintained in an online manner.)\nTo circumvent this issue, we preprocess the experts’ solutions at each iteration. During the\npreprocessing, every solution st\nkis scaled down to make it as tight as possible on the tthconstraint,\nwhile always maintaining st\ni,k≥st−1\ni,kfor all i. Additionally, after the down-scaling, we create an\nauxiliary solution ˆst\nkthat is tight for the tthconstraint. This solution is useful for our algorithm,\nand we create it with the following procedure.\nAfter the down-scaling, do the following for each expert k.\n1. If (st\ni,k)n\ni=1is tight on the tthconstraint, then set ˆst\ni,k←st\ni,kfor every i.\n2. Let ˆst−1\ni,kbe the auxiliary solution of expert kat time t−1, meaning that,Pn\ni=1at−1\niˆst−1\ni,k= 1.\nGiven I:={i:st\ni,k>ˆst−1\ni,k·at−1\ni\nat\ni}, we set ˆst\ni,k←st\ni,kifi /∈Iand set ˆst\ni,kto be some value in\n[ˆst−1\ni,k·at−1\ni\nat\ni, st\ni,k]ifi∈I, s.t. the solution ˆst\ni,kbecomes tight on the tthconstraint.\nLemma 1 Following the preprocessing procedure, we can always obtain the solutions ˆst\ni,ksuch that\nˆst\ni,k≤st\ni,kandPn\ni=1at\niˆst\ni,k= 1.\nProofLet us fix an expert k. We prove the lemma by induction. At time step t= 1, one can\nalways scale down the solution s1\ni,k≥0such that the first constraint becomes tight. Assume\nthat the lemma holds until t−1,Pn\ni=1at−1\niˆst−1\ni,k= 1andˆst−1\ni,k≤st−1\ni,k. Consider time t. If after\nscaling down (at the first step in the procedure) the tthconstraint becomes tight, then we are done.\nOtherwise, we have\n1<nX\ni=1at\nist\ni,k=X\ni∈Iat\nist\ni,k+X\ni/∈Iat\nist\ni,k,\n1 =nX\ni=1at−1\niˆst−1\ni,k=nX\ni=1at\ni\u0012\nˆst−1\ni,k·at−1\ni\nat\ni\u0013\n≥X\ni∈Iat\ni\u0012\nˆst−1\ni,k·at−1\ni\nat\ni\u0013\n+X\ni/∈Iat\nist\ni,k\nHence, there exists ˆst\ni,k∈\u0002\nˆst−1\ni,k·at−1\ni\nat\ni, st\ni,k\u0003\nfor every i, where 1≤i≤n, such thatPn\ni=1at\niˆst\ni,k= 1.\n□\n7\n\nAlgorithm. At the arrival of the tthconstraint,\n1. solve the following convex program and set wtto be the obtained optimal solution\nmin\nw\u001anX\ni=1ci\u0014\u0012KX\nk=1st\ni,kwi,k+δt\ni\u0013\nln PK\nk=1st\ni,kwi,k+δt\niPK\nk=1st−1\nikwt−1\ni,k+δt−1\ni!\n−KX\nk=1st\ni,kwi,k\u0015\u001b\n(γt)nX\ni=1at\ni\u0012KX\nk=1ˆst\ni,kwi,k\u0013\n≥1∀t\n(λt\ni)KX\nk=1wi,k≥1∀i\n(µt\ni)KX\nk=1st\ni,kwi,k≥0∀i, t\nwhere δt\ni=1\nKP\nkst\ni,k. Note that in this program, we use the auxiliary solution ˆst\ni,kin the\nfirst constraint. For every iwhere st\ni,k= 0for all k, the term related to iis not included in\nthe objective function of the convex program. (We can set wi,k= 0for all kbeforehand.)\n2. For all iifPK\nk=1wt\ni,kst\ni,k> xt−1\nithen set xt\ni←PK\nk=1wt\ni,kst\ni,k; otherwise set xt\ni←xt−1\ni.\nNote:To avoid the possible division by 0 in the denominator of the objective function’s logarithm,\nwe can use a dummy expert, who sets each variable to some small value and then follows the greedy\nheuristic to solve the problem at each arriving constraint. The presence of this expert only changes\nthe competitive ratio to O(logK +1). Additionally, upon the arrival of the first constraint, we treat\nthe denominator as 1.\n2.2 Analysis\nAswtis the optimal solution of the convex program and ( γt, λt\ni, µt\ni) is the optimal solution of its\ndual, the following Karush-Kuhn-Tucker (KKT) and complementary slackness conditions hold.\n\u0014nX\ni=1at\ni\u0012X\nkˆst\ni,kwt\ni,k\u0013\n−1\u0015\nγt= 0 ∀t\n\u0014KX\nk=1wt\ni,k−1\u0015\nλt\ni= 0 ∀i, t\n\u0014KX\nk=1st\ni,kwt\ni,k\u0015\nµt\ni= 0 ∀i, t\ncist\nikln PK\nk=1st\ni,kwt\ni,k+δt\niPK\nk=1st−1\nikwt−1\ni,k+δt−1\ni!\n−at\niˆst\ni,kγt−λt\ni−st\ni,kµt\ni= 0 ∀i, k, t\nγt, λt\ni, µt\ni≥0∀i, t\nMoreover, ifPK\nk=1wt\ni,kst\ni,k>0, meaning that µt\ni= 0, then\ncist\nikln PK\nk=1st\ni,kwt\ni,k+δt\niPK\nk=1st−1\nikwt−1\ni,k+δt−1\ni!\n−at\niˆst\ni,kγt−λt\ni= 0 (1)\n8\n\nDual variables and feasibility. Wesetthedualvariablesofthelinearprogramrelaxationofour\nLIN-COMB benchmark based on the dual variables of the convex program used inside the algorithm.\nαt=1\nln(Kρ)\u0012\nγt+X\niλt\ni\u0013\n,\nβt\ni=1\nln(Kρ)ciln \n(1 + 1 /K)·max t′PK\nk=1st′\ni,kPK\nk=1st−1\ni,kwt−1\ni,k+δt−1\ni!\nwhere recall that ρ= max i,t′,t′′\u001aPK\nk=1st′\ni,kPK\nk=1st′′\ni,k:PK\nk=1st′′\ni,k>0\u001b\n.\nLemma 2 Thext\nisolutions set by the algorithm for the original covering problem and the dual\nvariables (αt, βt\ni)of the LIN-COMB benchmark’s linear program relaxation are feasible.\nProofWe first prove that the xt\nivariables satisfy the covering constraints by induction. At time\n0, no constraint has been released yet, and every variable is set to 0. This all-zero solution is\nfeasible. Let us assume that the algorithm provides feasible solutions up to time t−1. At time\nt, the algorithm maintains the inequality xt\ni≥xt−1\ni, so all constraints t′where t′< tare satisfied.\nBesides, xt\niis always at leastP\nkwt\ni,kst\ni,k, which is larger thanP\nkwt\ni,kˆst\ni,ksince st\ni,k≥ˆst\ni,kfor all\ni, kby the preprocessing step. Hence, the constraint tis also satisfied, formally,\nnX\ni=1at\nixt\ni≥nX\ni=1at\ni\u0012X\nkˆst\ni,kwt\ni,k\u0013\n≥1.\nIn the remaining part of the proof, we show the feasibility of αtand every βt\ni. Since γt≥0and\nλt\ni≥0for all iandt, we get that αt≥0. In the definition of βt\ni, the nominator of the logarithm\nterm is always larger than the denominator, and it is smaller than Kρtimes the denominator.\nConsequently, 0≤βt\ni≤ci. Furthermore,\nβt+1\ni−βt\ni=−1\nln(Kρ)ciln PK\nk=1st\ni,kwt\ni,k+δt\niPK\nk=1st−1\ni,kwt−1\ni,k+δt−1\ni!\n.\nSinceP\niat\niˆst\ni,k= 1, using the KKT conditions, we get:\nαt+nX\ni=1st\nik\u0000\nβt+1\ni−βt\ni\u0001\n=1\nln(Kρ)\u0012\nγt+X\niλt\ni\u0013\n−1\nln(Kρ)nX\ni=1st\ni,kciln PK\nk=1st\nikwt\ni,k+δt\niPK\nk=1st−1\nikwt−1\ni,k+δt−1\ni!\n=1\nln(Kρ)\u0014\nγt+nX\ni=1λt\ni−nX\ni=1\u0000\nat\niˆst\ni,kγt+λt\ni+st\ni,kµt\ni\u0001\u0015\n≤0\n□\n9\n\nTheorem 1 The algorithm’s cost is at most O(ln(Kρ))-competitive in the LIN-COMB benchmark.\nProofLemma 2 proved that our algorithm creates feasible solutions for the dual problem of\ntheLIN-COMB benchmark relaxation and for the original covering problem. We show that the\nalgorithm’s solution increases the primal objective value of the original covering problem by at\nmost O(ln(Kρ))times the value of the dual solution, which serves as the lower bound on the\nLIN-COMB benchmark - the best linear combination of the experts’ solutions.\nnX\ni=1ci(xt\ni−xt−1\ni) =X\ni:xt\ni>xt−1\nici(xt\ni−xt−1\ni)\n≤X\ni:xt\ni>xt−1\nici(xt\ni+δt\ni) lnxt\ni+δt\ni\nxt−1\ni+δt\ni(2)\n≤X\ni:xt\ni>xt−1\nici(xt\ni+δt\ni) lnxt\ni+δt\ni\nxt−1\ni+δt−1\ni(3)\n=X\ni:xt\ni>xt−1\nici\" KX\nk=1st\ni,kwt\ni,k+1\nKKX\nk=1st\ni,k!\nln PK\nk=1st\ni,kwt\ni,k+δt\ni\nxt−1\ni+δt−1\ni!#\n(4)\n≤X\ni:xt\ni>xt−1\nici\" KX\nk=1st\ni,kwt\ni,k+1\nKKX\nk=1st\ni,k!\nln PK\nk=1st\ni,kwt\ni,k+δt\niPK\nk=1st−1\ni,kwt−1\ni,k+δt−1\ni!#\n(5)\n=X\ni:xt\ni>xt−1\niKX\nk=1(wt\ni,k+ 1/K)cist\ni,kln PK\nk=1st\ni,kwt\ni,k+δt\niPK\nk=1st−1\ni,kwt−1\ni,k+δt−1\ni!\n=X\ni:xt\ni>xt−1\niKX\nk=1(wt\ni,k+ 1/K)\u0012\nat\niˆst\ni,kγt+λt\ni\u0013\n(6)\n≤nX\ni=1KX\nk=1(wt\ni,k+ 1/K)\u0012\nat\niˆst\ni,kγt+λt\ni\u0013\n=nX\ni=1at\ni\u0012KX\nk=1wt\ni,kˆst\ni,k\u0013\nγt+nX\ni=1\u0012KX\nk=1wt\ni,k\u0013\nλt\ni+1\nKKX\nk=1\u0012nX\ni=1at\niˆst\ni,k\u0013\nγt+1\nKKX\nk=1nX\ni=1λt\ni\n= 2γt+ 2nX\ni=1λt\ni= ln( Kρ)αt(7)\nThe above corresponding transformations hold since:\n(2) follows from the inequality a−b≤aln(a/b)for all 0< b≤a;\n(3) holds since δt\ni≥δt−1\ni(because st\ni,k≥st−1\ni,kfor all i, k, t);\n(4) is valid because xt\ni> xt−1\ni, soxt\ni=PK\nk=1st\ni,kwt\ni,k;\n(5) is by the design of the algorithm: xt−1\ni≥PK\nk=1st−1\ni,kwt−1\ni,k;\n(6) since given that xt\ni> xt−1\ni≥0(soPK\nk=1st\ni,kwt\ni,k=xt\ni>0), the KKT condition (1) applies;\n(7) is true due to the complementary slackness conditions and thatPn\ni=1at\niˆst\ni,k= 1.\n□\n10\n\nCorollary 1 For0-1optimization problems in which experts provide integer (deterministic or ran-\ndomized) solutions, the algorithm is O(lnK)-competitive in the LIN-COMB benchmark. Subsequently,\nthere exists an algorithm such that its performance is O(lnK)-competitive in the LIN-COMB bench-\nmark and is up to a constant factor to the best guarantee in the worst-case benchmark\nProof\nOur Algorithm\nwith K exper tsBest w orst-case\nguarantee algor tihmE1 E2 EK\nOur Algorithm  \nwith 2 exper ts \nFigure 5: Structural overview of the al-\ngorithm’s components. E1, E2, . . . E K\ncorrespond to the experts of the online\nproblem. On the second layer, we in-\ntegrate the best standard online algo-\nrithm with our algorithm.If the value of st\ni,kis in{0,1}for every i, k, t, then\nρ= max\nimax\nt′,t′′(PK\nk=1st′\ni,kPK\nk=1st′′\ni,k:KX\nk=1st′′\ni,k>0)\n≤K\n1\nTherefore, the competitive ratio of the main algorithm in\ntheLIN-COMB benchmark is O(logKρ) =O(logK2).\nToobtainan algorithm thatiscompetitiveinboththe\nLIN-COMB and the worst-case benchmarks, we proceed as\nfollows (an illustration in Figure 5). We first apply the\nmain algorithm on the Kexperts’ predictions to obtain\nan online algorithm, named A. Algorithm AisO(lnK)-\ncompetitive in the LIN-COMB benchmark. Let Bbe the\nalgorithm with the best worst-case guarantee. One ap-\nplies the main algorithm one more on two algorithms, A\nandB. The final algorithm is O(ln 2)-competitive to both\nAandB. In other words, its performance is O(lnK)-\ncompetitive in the LIN-COMB benchmark and is up to a\nconstant factor worse than the best guarantee in the worst-case benchmark.\n□\nBy Corollary 1, given a 0-1optimization problem, if there are Kdeterministic online algo-\nrithms, then we can design an algorithm that has a cost at most O(logK)times that of the best\nlinear combination of those algorithms at any time. Similarly, if Kgiven online algorithms are\nrandomized (they output 0-1solutions with probabilities), then our algorithm has an expected cost\n(randomization over the product of the distributions of those solutions) at most O(logK)times\nthat of the best linear combination of those algorithms at any time. Many practical problems admit\n0-1solutions, for which our algorithm is of interest. Consider problems like network design, ski\nrental, TCP acknowledgement, facility location, etc. Given the fractional solutions constructed by\nour algorithm, we can apply existing online rounding schemes to obtain integral solutions for such\nproblems.\n3 Experiments\nImplementation. The first step of our proposed algorithm is to solve a convex program. In\nthe experiments, we approximate the optimal solution of this program using a vanilla Frank-Wolfe\nimplementation. The linear minimization step within Frank-Wolfe is solved with the Gurobi opti-\nmizer.\nComparison. The best standard online algorithm for general covering problems without ex-\nperts is the online multiplicative weight update (MWA) algorithm. In the experiments we compare\nour algorithm with the MWA algorithm. When a new constraint arrives in the online problem, the\nMWA algorithm increases each variable xiin the constraint with a rate ofat\ni\nci(xi+ 1/n), where nis\n11\n\nthe total number of variables. We also compare our results with the optimum offline solution (that\nknows the whole instance in advance) and the average solution of the experts.\nInput.First, we evaluated the result of our algorithm on the pathological input of the MWA\nalgorithm. This instance includes nvariables and nconstraints with uniform costs and coefficients.\nEach arriving constraint in this pathological example includes one less variable. While the optimal\nsolution is 1, the worst-case guarantee of MWA is O(logn). For our algorithm we provided n\nexperts, where (n−1)experts suggest an adversarial trivial solution to set all variables to 1, while\n1expert suggests the optimal offline solution. The result of this experiment is visible on Figure 6.\nAn important highlight: our algorithm managed to identify the good expert among the majority\nof adversaries, obtaining a better objective value, than MWA. Second, we experimented with the\ncounter example (in Appendix B) to show that the algorithm proposed by [2] has an incorrect\nperformance proof. The result is visible on Figure 6. Finally, we generated some instances to\nobserve the performance of our algorithm on non-specific inputs. The specification for the instance\ngeneration includes several parameters, which we detail on Figure 7.\nResult. Multiplicative weight update is a simple and well-performing algorithm in practice.\nOn its pathological worst-case example, our algorithm performs better, however on most instances\nthe expert suggestions were significantly worse than MWA, which impacted the performance of\nour algorithm. To some extent, our algorithm can detect the good experts and is robust against\neven many adversaries. We think that given a real-life problem, it is possible to construct well-\nperforming experts (for example using past data) and with a fine-tuned convex program solver our\nalgorithm can be of interest for various use-cases.\nWorst-case Counter-ex.\nAlgo name for MWA for [2]Inst. 1Inst. 2Inst. 3Inst. 4\nOPT Offline 1.0 1.0 1.3 1.5 10.6 31.3\nMWA Online 2.9 2.3 2.0 1.7 28.1 63.7\nOur Algo 2.2 4.4 2.0 1.7 26.7 61.7\nAvg of experts 9.1 3.516.4 23.31897.47 96.9\nFigure 6: Objective value of the experiment instances\nInput Generation Parameters Instance 1Instance 2Instance 3Instance 4\nNumber of variables 10 10 44 30\nNumber of constraints 10 25 2 15\nMin objective coefficient 1 10 1 1\nMax objective coefficient 10 25 100 100\nMin constraint coefficient 1 10 1 1\nMax constraint coefficient 10 25 1 1\nMin number of zero coefficient 0 1 11 5\nMax number of zero coefficient 5 5 22 20\nNumber of perfect experts 1 0 0 2\nNumber of online experts 2 1 1 2\nNumber of random experts 1 1 11 0\nNumber of adversaries 1 1 0 0\nFigure 7: Parameters of the generated experiment instances\n12\n\n4 Conclusion\nWe introduce a dynamic LIN-COMB benchmark in the setting of multiple expert predictions beyond\nthetraditionalstaticbenchmarkofthebestexpertinhindsightandgiveacompetitivealgorithmfor\nthe online covering problem in this benchmark. Our approach can provide valuable insights into the\nlearning processes related to predictions, in particular, in aggregating information from predictions\nto improve the performance of existing algorithms, and how to combine online algorithms, an\nimportant subject in the online algorithm design community [6, 8]. The experiments support the\nfact that our algorithm can differentiate between good and adversarial experts to some extent.\nAn interesting open question is to design competitive algorithms in the LIN-COMB benchmark\nfor different classes of problems, such as packing problems and problems with non-linear objectives.\n13\n\nReferences\n[1] Matteo Almanza, Flavio Chierichetti, Silvio Lattanzi, Alessandro Panconesi, and Giuseppe Re.\nOnline facility location with multiple advice. In Advances in Neural Information Processing\nSystems, volume 34, pages 4661–4673, 2021.\n[2] Keerti Anand, Rong Ge, Amit Kumar, and Debmalya Panigrahi. Online algorithms with\nmultiple predictions. In Proc. 39th International Conference on Machine Learning , 2022.\n[3] SpyrosAngelopoulos, ChristophD¨ urr, ShendanJin, ShahinKamali, andMarcRenault. Online\nComputation with Untrusted Advice. In 11th Innovations in Theoretical Computer Science\nConference (ITCS 2020) , volume 151, pages 52:1–52:15, 2020.\n[4] Antonios Antoniadis, Christian Coester, Marek Elias, Adam Polak, and Bertrand Simon. On-\nline metric algorithms with untrusted predictions. In International Conference on Machine\nLearning , pages 345–355, 2020.\n[5] Antonios Antoniadis, Christian Coester, Marek Eliáˇ s, Adam Polak, and Bertrand Simon. Mix-\ning predictions for online metric algorithms, 2023. arXiv:2304.01781 .\n[6] Yossi Azar, Andrei Z Broder, and Mark S Manasse. On-line choice of on-line algorithms. In\nSymposium of Discrete Algorithms (SODA) , pages 432–440, 1993.\n[7] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning\naugmented algorithms. In Advances in Neural Information Processing Systems , volume 33,\npages 20083–20094, 2020.\n[8] Avrim Blum and Carl Burch. On-line learning and the metrical task system problem. Machine\nLearning , 39(1):35–58, 2000.\n[9] Sébastien Bubeck, Michael B Cohen, James R Lee, and Yin Tat Lee. Metrical task systems\non trees via mirror descent and unfair gluing. SIAM Journal on Computing , 50(3):909–923,\n2021.\n[10] Sébastien Bubeck, Michael B Cohen, Yin Tat Lee, James R Lee, and Aleksander Madry.\nK-server via multiscale entropic regularization. In Proc. 50th Symposium on Theory of Com-\nputing, pages 3–16, 2018.\n[11] Niv Buchbinder, Shahar Chen, and Joseph (Seffi) Naor. Competitive analysis via regulariza-\ntion. In Proc. 25th Symposium on Discrete Algorithms , pages 436–444, 2014.\n[12] Niv Buchbinder, Anupam Gupta, Marco Molinaro, and Joseph Naor. k-servers with a smile:\nOnline algorithms via projections. In Proc. 30th Symposium on Discrete Algorithms , pages\n98–116, 2019.\n[13] Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii.\nAlgorithms with prediction portfolios. In Advances in Neural Information Processing Systems ,\n2022.\n[14] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert\nadvice. In International Conference on Machine Learning , pages 2319–2327, 2019.\n14\n\n[15] Sreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert\nadvice. In Proceedings of the 36th International Conference on Machine Learning , 2019.\n[16] Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency estima-\ntion algorithms. In Proc. Conference on Learning Representations , 2019.\n[17] Enik ˝o Kevi and Nguyen Kim Thang. Primal-dual algorithms with predictions for online\nbounded allocation and ad-auctions problems. In International Conference on Algorithmic\nLearning Theory , pages 891–908, 2023.\n[18] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proc. Conference on Management of Data , pages 489–504, 2018.\n[19] Ravi Kumar, Manish Purohit, and Zoya Svitkina. Improving online algorithms via ML predic-\ntions. In Proc. 32nd Conference on Neural Information Processing Systems , pages 9684–9693,\n2018.\n[20] SilvioLattanzi, ThomasLavastida, BenjaminMoseley, andSergeiVassilvitskii. Onlineschedul-\ning via learned weights. In Proc. Symposium on Discrete Algorithms , pages 1859–1877, 2020.\n[21] Thodoris Lykouris and Sergei Vassilvtiskii. Competitive caching with machine learned advice.\nInInternational Conference on Machine Learning , pages 3296–3305, 2018.\n[22] Michael Mitzenmacher. A model for learned bloom filters, and optimizing by sandwiching. In\nProc. Conference on Neural Information Processing Systems , pages 464–473, 2018.\n[23] Michael Mitzenmacher. Scheduling with predictions and the price of misprediction. In Proc.\n11th Innovations in Theoretical Computer Science Conference , 2020.\n[24] Michael Mitzenmacher, Sergei Vassilvitskii, and Tim Roughgarden. Beyond the Worst-Case\nAnalysis of Algorithms , chapter Algorithms with Predictions. Cambridge University Press,\n2020.\n[25] Dhruv Rohatgi. Near-optimal bounds for online caching with machine learned advice. In Proc.\nSymposium on Discrete Algorithms , pages 1834–1845, 2020.\n15\n\nAppendix\nA Counter example for tight online expert solutions\nThe following example shows that we cannot expect online expert solutions (in the sense of online\nalgorithms) to be tight on the arriving constraints. In the example below, we display the experts’\nsolutions after each constraint.\nmin x1+x2\nx1+1\n2x2≥1\nExpert1: 1 0\nExpert2: 0 2\nx2≥1\nExpert1: 1 1\nExpert2: 0 2\nTo have tight a suggestion from Expert 2on the second constraint, Expert 2not only has to decrease\nits value of x2(which is not allowed), but even increase the value of x1for the first constraint. In\nother words, Expert 2has to completely modify its past decisions.\nB Counter example for the performance of the algorithm of [2]\nAnand, Ge, Kumar and Panigrahi [2] recently proposed online algorithms for online covering prob-\nlems with multiple expert solutions. We show here a counter example that contradicts Theorem 2.1\npresented in Section 3of their paper. In the proof of Theorem 2.1the authors state that the total\ncost of the algorithm is at most 3times the potential ϕat the beginning, i.e., at most O(log K)\ntimes the DYNAMIC benchmark . However, in our counter example the total cost of their algorithm\nisO(Llog(K))times the DYNAMIC benchmark, where Lis an arbitrary large number.\nB.1 Setting\nAlgorithm 1(from [2]) receives solutions from Kexperts. The authors denote with xi(j, s)the\nsolution from expert sfor variable ion constraint j. They assume that the expert solutions are\ntight, formally:\nnX\ni=1aijxi(j, s) = 1 ∀s∈[K]\nThe algorithm’s performance is compared to the DYNAMIC benchmark, which is the minimum cost\nsolution that is supported by at least one expert at each step, formally:\nDYNAMIC = min\nˆx∈ˆXnX\ni=1ciˆxi, where\nˆX={ˆx:∀i∈[n],∀j∈[m],∃s∈[K]where the solution xi(j, s)≤ˆxi}\n16\n\nWhile a constraint is not satisfied, their algorithm updates each variable with an increasing rate of\ndxi\ndt=aij\nci(xi+δij)\nwhere δij=1\nKPK\ns=1xi(j, s)is the average of the experts’ solutions for xiat the arrival of constraint\nj. Algorithm 1 of [2] scales down the problem with 0.5, so it does not increase any variable above\n0.5and satisfies each constraint with value 0.5. The exact solution is obtained by doubling the\nvariables at the end of the execution. (This descaling is an important aspect in the authors’ proof.)\nB.2 Counter example\nIn the following example we reveal in an online manner a linear program parametrized by Lwith\nKexperts and observe the behavior of Algorithm 1(from [2]).\nObjective . The example has (L·K+ 1)variables with uniform cost:\nminx1+x2+···+xK+···+x2K+···+xLK+xLK+1\nConstraints . There are Lbatches of (K−1)constraints. The first constraint of each batch has\n(K+ 1)variables. The last variable ( xLK+1) is present in every constraint in every batch, but none\nof the experts suggests to use this variable. Within a batch, each consecutive constraint has one\nless variable. The experts set each variable that appears in later batches to 0. The first batch:\nx1+x2+···+x(K−1)+xK+xLK+1≥1\nExpert1: 1 0 . . . 0 0 0\nExpert2: 0 1 . . . 0 0 0\n...\nExpertK−1: 0 0 . . . 1 0 0\nExpertK: 0 0 . . . 0 1 0\nx2+···+x(K−1)+xK+xLK+1≥1\nExpert1: 1 1 . . . 0 0 0\nExpert2: 0 1 . . . 0 0 0\n...\nExpertK−1: 0 0 . . . 1 0 0\nExpertK: 0 0 . . . 0 1 0\n...\nx(K−1)+xK+xLK+1≥1\nExpert1: 1 1 . . . 1 0 0\nExpert2: 0 1 . . . 1 0 0\n...\nExpertK−1: 0 0 . . . 1 0 0\nExpertK: 0 0 . . . 0 1 0\n17\n\nDuring the first constraint of every batch, the experts’ solutions form an identity matrix. With\neach disappearing variable in the consecutive constraints, experts who suggested to use variables\nwhich are no longer available, choose to set the variable with the smallest index. Consequently,\n(K−1)experts suggest to use variable x(K−1)and one expert suggests to use xKduring the last\nconstraint in the first batch. The pattern of the experts’ solutions are identical for each batch. The\nconstraints of the lthbatch ( 1≤l≤L)are:\nx(l−1)K+1+x(l−1)K+2+···+x(l−1)K+(K−1)+xlK+xLK+1≥1\nx(l−1)K+2+···+x(l−1)K+(K−1)+xlK+xLK+1≥1\n...\nx(l−1)K+(K−1)+xlK+xLK+1≥1\nClaim 1 The objective value of Algorithm 1(from [2]) on our example is O(Llog(K))times the\nDYNAMIC benchmark.\nProofThe optimal solution x∗of the DYNAMIC benchmark is the solution in which x∗\nLK+1= 1\nandx∗\ni= 0fori̸=LK+ 1. We verify that x∗∈ˆX. For each i̸=lKwhere 1≤l≤L, for\neach constraint m,x∗\ni≥0 = xi(m, K ). For i=lKwhere 1≤l≤L, for each constraint m,\nx∗\ni≥0 =xi(m,1) = xi(m,2) = . . .=xi(m, K−1). Moreover, x∗satisfies all constraints (since\nvariable xLK+1appears in all constraints). Hence, x∗∈ˆX. Subsequently, the objective value of\ntheDYNAMIC benchmark is 1.\nBy the design of Algorithm 1, the increasing rate of xLK+1is zero throughout the execution,\nand the variables which are not part of the current constraint are not increased. During the first\nconstraint of each batch, the increasing rate of the first Kvariables in the batch is 1/K, since the\nincreasing rate of variable xiis(xi+1\nKPK\ns=1xi(j, s))and initially every variable is set to zero. At\nthe second constraint, the increasing rate of the second variable in the batch is higher than the other\nvariables’ increasing rate, because the first expert also uses this variable in its solution. Therefore,\nthe increasing rate of the second variable is (x(l−1)K+2+ 2/K), while the other remaining expert\nvariables in the constraint have an increasing rate of (xi+ 1/K). Following the same reasoning\n(apart from the first constraint in the batch), the variable with the smallest index in the constraint\nhas a higher increasing rate, than the other variables. During the last constraint of each batch,\nthe increasing rate of the last two remaining expert variables are (x(l−1)K+(K−1)+ (K−1)/K)and\n(xlK+ 1/K). Keeping the increasing rates and the constraint satisfaction in mind, we can lower\n18\n\nbound the value of each variable:\n1\nK≤x(l−1)K+1\n1\nK−1≤x(l−1)K+2\n1\nK−2≤x(l−1)K+3\n...\n1\n3≤x(l−1)K+(K−2)\n1\n2≤x(l−1)K+(K−1)\n1\nK≤xlK\nSumming the terms together, we get that the objective value increases at least with O(logK)\nduring each batch. There are Lbatches, so the total cost of Algorithm 1is at least O(Llog(K)),\nwhile the total cost of the DYNAMIC benchmark is 1, which concludes the proof. □\nB.3 Comparison\nIn this specific counter-example, the LIN-COMB benchmark is equivalent to the static best-expert\nbenchmark, i.e., the solution of Expert K. The objective value of LIN-COMB isL(since the optimal\nsolution sets xlKvariables for 1≤l≤Lto one and other variables to 0). In this counter-\nexample, the objective value of our algorithm is O(LlogK). Consequently, our proposed algorithm\nisO(logK)competitive in the LIN-COMB benchmark.\n19",
  "textLength": 44665
}