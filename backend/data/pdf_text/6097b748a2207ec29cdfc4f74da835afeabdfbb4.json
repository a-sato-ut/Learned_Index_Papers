{
  "paperId": "6097b748a2207ec29cdfc4f74da835afeabdfbb4",
  "title": "WaZI: A Learned and Workload-aware Z-Index",
  "pdfPath": "6097b748a2207ec29cdfc4f74da835afeabdfbb4.pdf",
  "text": "WaZI : A Learned and Workload-aware Z-Index\nSachith Pai\nUniversity of Helsinki\nHelsinki, Finland\nsachith.pai@helsinki.fiMichael Mathioudakis\nUniversity of Helsinki\nHelsinki, Finland\nmichael.mathioudakis@helsinki.fiYanhao Wang\nEast China Normal University\nShanghai, China\nyhwang@dase.ecnu.edu.cn\nABSTRACT\nLearned indexes fit machine learning (ML) models to the data\nand use them to make query operations more time and space-\nefficient. Recent works propose using learned spatial indexes to\nimprove spatial query performance by optimizing the storage\nlayout or internal search structures according to the data distri-\nbution. However, only a few learned indexes exploit the query\nworkload distribution to enhance their performance. In addition,\nbuilding and updating learned spatial indexes are often costly on\nlarge datasets due to the inefficiency of (re)training ML models.\nIn this paper, we present WaZI , a learned and workload-aware\nvariant of the Z-index, which jointly optimizes the storage layout\nand search structures, as a viable solution for the above chal-\nlenges of spatial indexing. Specifically, we first formulate a cost\nfunction to measure the performance of a Z-index on a dataset for\na range-query workload. Then, we optimize the Z-index structure\nby minimizing the cost function through adaptive partitioning\nand ordering for index construction. Moreover, we design a novel\npage-skipping mechanism to improve the query performance of\nWaZI by reducing access to irrelevant data pages. Our extensive\nexperiments show that the WaZI index improves range query\ntime by 40% on average over the baselines while always per-\nforming better or comparably to state-of-the-art spatial indexes.\nAdditionally, it also maintains good point query performance.\nGenerally, WaZI provides favorable tradeoffs among query la-\ntency, construction time, and index size.\n1 INTRODUCTION\nSpatial query processing has attracted significant interest in the\ndatabase community over the last three decades with the prolif-\neration of location-based services (LBSs). Although numerous\nindex structures such as R-trees [ 17] and k-d trees [ 6] have been\ndeployed in database systems to improve spatial query perfor-\nmance, their efficiency still cannot fully satisfy the requirements\nof real-world applications due to the rapid growth in the volume\nof spatial data.\nThe seminal work of Kraska et al. [ 22] inspired the introduc-\ntion of machine learning (ML) based indexes (i.e., learned indexes )\n[7,10,18,22,27,36,43,46] to replace their traditional counter-\nparts as a way of improving query performance by exploiting\ndata or query patterns or both while reducing space usage. Most\nof the learned indexes developed are specific for one-dimensional\ndata [ 7,10,13,18,22], which follows the abstraction that an index\nis a model that predicts the position of an element in a sorted ar-\nray. Such an abstraction is made possible only by the prerequisite\nthat the data resides in a sorted array. Therefore, any model that\naccurately and efficiently learns the dataâ€™s cumulative density\nfunction (CDF) can serve as an index.\nÂ©2024 Copyright held by the owner/author(s). Published in Proceedings of the\n27th International Conference on Extending Database Technology (EDBT), 25th\nMarch-28th March, 2024, ISBN 978-3-89318-095-0 on OpenProceedings.org.\nDistribution of this paper is permitted under the terms of the Creative Commons\nlicense CC-by-nc-nd 4.0.However, the above abstraction is not squarely applicable to\nspatial indexes since there is no predefined ordering between\ndata points. Nonetheless, a few learned spatial indexes have at-\ntempted to overcome this challenge by using space-filling curves\n(SFCs) to linearize the spatial indexing task [ 36,38,43]. The con-\nstruction procedure for such indexes proceeds in two phases.\nThe first phase uses space-filling curves for data linearization.\nThe second phase performs the transformed one-dimensional\nindexing task. These indexes usually optimize the second phase\nof the construction while using standard methods for the first\nphase (linearization), missing out on the opportunity to tailor\nthe linearization to fit the data and workload better.\nTo remedy the problem, in this work, we present a generalized\nvariant of the Z-index that is both data- and workload-aware. A\nZ-index is an intuitively simple spatial index structure with a long\nhistory in database management systems [ 39]. It uses a Z-curve\n(a.k.a. Z-order curve ) to compute a sort order, denoted by Ord,\nfor multi-dimensional data points. Figure 1a shows an example\nof the Z-curve and the corresponding Z-index. The Z-curve visits\nthe data points according to a hierarchical partitioning of the\ndata space into cells and a specific ordering of these cells. For\ninstance, at the top level, the space is partitioned into four cells,\nnamely A,B,C, and D; at the second level, each of these cells is\npartitioned into four sub-cells, and so on, with the partitioning\nhappening at the coordinates corresponding to the median of the\ndata along each axis. Within each cell, the ordering of its sub-cells\nconsistently follows the same â€˜Zâ€™-like pattern: cells are ordered\nas â€œabcd â€ for the first level, with higher-level cells having higher\npriority in the point ordering. Each cell is further partitioned and\nordered until the cells reach a predetermined size ğ¿.\nThe Z-index has the desirable property of monotonicity ; that\nis, any point â€œdominatedâ€ (i.e., having smaller values in both di-\nmensions) by point ğ‘in the data space will always have a smaller\nsort order Ord thanğ‘. This monotonicity property facilitates the\nprocessing of range queries, represented as rectangles in the data\nspace. A standard range-query algorithm is to obtain the loca-\ntions in Ord of the bottom-left and top-right points of the query\nrectangle, scan the data entries between the two, and filter the\ndata points that satisfy the query range. However, the efficiency\nof such a range-query algorithm could still be vastly improved.\nFor example, let us consider the range query with rectangle ğ‘…\nin Figure 1b: the algorithm processes many data entries outside\nthe result set (e.g., all points in cell B), which could lead to high\nquery latencies.\nOur Contributions. We propose a generalization of the Z-index\nthat adapts gracefully to both the distribution of spatial data and\nthe workload of range queries, mitigating the retrieval of redun-\ndant data entries, and thus leading to improved query latencies\nat little additional cost to index construction. Specifically, we\npresent a method to construct a learned and workload-aware\nspace-filling curve to improve the range-query performance of\na generalized Z-index variant. The Workload- aware Z-Index\n(WaZI ) variant we propose is flexible in two ways compared\nto the base Z-index: the partition location and the ordering ofarXiv:2310.04268v3  [cs.DB]  20 Mar 2024\n\n1 23 4\n5 67 89 1011 12\n13 1415 16\nA BD C\n(a) A base two-level Z-index with\ndefault ordering of cells.A BD C\nBL(R)TR(R)\nR\n(b) Range query on the base vari-\nant of a one-level Z-index.A BD C\nBL(R)TR(R)\nR\n(c) A one-level Z-index with alter-\nnative ordering and partitioning.A BD C\n(d) A two-level Z-index by vary-\ning orderings and partitionings.\nFigure 1: Illustrations of the base Z-curve and Z-index and their variants proposed in this work.\nchild cells. Intuitively, it pays off to partition the data space so\nthat cells correspond to regions that are fetched by several simi-\nlar range queries. Such a partitioning allows the index to avoid\nprocessing points in other cells during the execution of these\nqueries. For example, the Z-index with an alternative ordering\nand partitioning shown in Figure 1c processes fewer redundant\ndata entries than the base Z-index in Figure 1b. Therefore, if\nsimilar queries dominate the anticipated query workload, the\nalternative ordering and partitioning of cells can reduce query la-\ntency. The Z-index variant we propose is general enough to allow\ndifferent ordering and partitioning for each cell across the index\nhierarchy, as shown in Figure 1d. Additionally, by harnessing the\nstructural properties of the index, we develop and incorporate\nan efficient mechanism to reduce the computation required by\nskipping non-overlapping pages during range query processing.\nIn the experiments, we compare WaZI with four state-of-the-\nart spatial indexes including Flood [29],STR[25], a query-aware\nincremental index QUASII [35], and a cost-optimized variant\nof R-tree CUR [40]. The baselines considered cover the scope\nof indexes regarding query-awareness and the use of learned\ncomponents. The results show that WaZI performs better than\nthese baselines in terms of range and point query latency while\nexhibiting favorable tradeoffs regarding construction time and\nindex size. In the critical metric of range query latency, WaZI sig-\nnificantly outperforms all the baselines. The main contributions\nof this paper include:\n1)formalizing the problem of optimizing the partitioning and\nZ-ordering for the given data and anticipated query workload;\n2)providing an index construction algorithm that minimizes the\nretrieval cost;\n3)presenting a mechanism to efficiently skip over large regions\nof irrelevant pages to avoid the computational cost associated\nwith skipped pages;\n4)providing an experimental evaluation of the proposed index\nagainst existing approaches, addressing the cost redemption\nbehavior and effects of workload changes, as well as an abla-\ntion study to demonstrate the benefit from different compo-\nnents of our approach.\nAn extended abstract associated with this work was presented at\na non-archival workshop [33].\n2 RELATED WORK\nIn this section, we review the existing literature on learned indexes\nandspatial indexes , which are closely relevant to the problem we\nstudy in this paper.Traditional Spatial Indexes. Spatial indexes [ 12] were well\nstudied across several decades in the database community. Ex-\nisting (non-learned) spatial indexes are generally categorized\ninto three classes. The first category is space partitioning-based\nindexes , e.g., k-d trees [ 6], Quad-trees [ 11], and Grid Files [ 30],\nwhich recursively split the data space into sub-regions and then\nindex each sub-region hierarchically. The second category is\ndata partitioning-based indexes , including R-tree [ 17] and its vari-\nants [ 2,4,5,20,41], which recursively divide the dataset into\nsubsets and then index each subset hierarchically. The differ-\nences between different R-tree variants lie in how they eval-\nuate the goodness of data partitioning and the algorithms for\nindex construction based on the partitioning scheme. The third\ncategory is data transformation-based indexes , which transform\nmulti-dimensional data into one dimension and then utilize a one-\ndimensional index, e.g., B-trees. Space-filling curves (SFCs) are\nthe typical transformation method. Such data transformations\nact as a hybrid between data and space partitioning methods\nwhere the space partitioning nature of SFC is utilized along with\ndata partitioning methods of the one-dimension index. The Z-\nindex [ 3,39] is a typical index of this kind, based on the Z-curve\nfor data transformation. The index construction for Z-index most\ncommonly proceeds by sorting all the points using the SFC sort-\norder, packing them into leaves, and then building the index\nbottom-up level-by-level. Some mechanisms that utilize proper-\nties of the SFCs have been used to improve range query perfor-\nmance in such indexes: like the BIGMIN algorithm associated\nwith Z-order curves [ 42] or the calculate_next_match function for\nHilbert curves [23]. However, none of the above spatial indexes\ncan be adapted to data or query patterns, and thus they often\nsuffer from inferior query performance compared to their learned\ncounterparts.\nLearned Indexes. Kraska et al . [22] first proposed the learned\nindexes , which utilize machine learning models to enhance or\nreplace traditional indexes for data access in databases. The ab-\nstraction used in [ 22] to motivate such methods was that an\nindex is essentially a structure that predicts the location of an\nitem in a sorted array, or a structure that predicts the cumula-\ntive density function of the underlying data. They propose the\nrecursive model index (RMI), which consists of a hierarchy of\nregression models for capturing the relationship between sorted\nkeys and their ranks in the dataset. According to [22], the bene-\nfits of learned indexes lie in smaller index sizes and lower query\nlatency. After this seminal work, many learned indexes were pro-\nposed in the last four years, such as PGM-Index [ 10], ALEX [ 7],\n\nRadixSpline [ 21], and Shift-Table [ 18]. They outperformed RMI\nby using simpler linear spline models and supporting efficient\nindex updates. Nevertheless, all the learned indexes mentioned\nabove are specific to one-dimensional data and cannot be directly\nused for spatial query processing.\nLearned Spatial Indexes. The most relevant studies to our\nproblem are the ones on learned spatial indexes [ 1,8,9,16,27â€“\n29,36,43,45,46]. The learned spatial indexes can be categorized\ninto two categories. The first category is learned search structure-\nbased indexes, where the methods use learned models to improve\nsearch performance on default data layouts. Wang et al . [43]\nproposed the ZM-index, an extension of RMI [ 22] using a linear\nlayout based on Z-order values for spatial data points. Qi et al .\n[36] proposed a recursive spatial model index ( Rsmi ) to build an\nindex utilizing the Z-order values and using neural networks to\ninfer data partitioning. The intuition behind RSMI is that the\napplication of neural networks to learn fine-grained Z-order\nmappings would result in partitions with better locality. While\nZM and RSMI seem conceptually similar to WaZI , they have\nthree main differences from WaZI . First, ZM and RSMI utilize\nZ-ordering in the rank space of the data, whereas WaZI avoids\nthe rank space projection by operating in the original data space.\nSecond, ZM and RSMI use default Z-ordering for the data layout\nand a hierarchy of learned models for query processing. However,\nWaZI optimizes the data layout using learned models only in the\ntraining phase but does not use them to process queries. Third,\nboth ZM and RSMI (as with other learned search structure-based\nindexes) are workload-agnostic, while WaZI is workload-aware.\nLi et al . [27] proposed LISA, a spatial index that divides the data\nspace into a grid-like layout numbered by a partially monotonic\nfunction and learns functions to map data points to a grid cell\nand subsequently its respective page. Zhang et al . [46] proposed\nSPRIG, a learned spatial index that uses the spatial interpolation\nfunction as a learned model to efficiently filter the cells in the\ngrid file. Al-Mamun et al . [1] proposed a method to improve the\nquery performance of R-trees by using multi-label classification\nmodels to identify the required leaf nodes for a query incurring\nhigh tree-traversal cost.\nThe second category is layout optimization-based indexes,\nwhere data layout is optimized using ML models to improve\nquery performance. Nathan et al . [29] proposed a learned multi-\ndimensional index called Flood based on the Grid File index [ 30]\nusing machine-aware optimizations for grid layouts. Flood is\nconstructed by training a performance prediction model based on\nrandomly sampled layouts, and then using the prediction model\nto select the best layout from a set of candidate grid layouts. The\nmain limitation is that Flood is optimized for an average query\nand performs poorly on skewed query workloads. This limitation\nwas addressed in Tsunami [8], a learned multi-dimensional index\nthat partitions the data space based on statistical tests of query\ndistribution and constructs Flood indexes over each partition.\nThe statistical tests for query distribution changes are based on\nthe shapes and sizes of queries and hence do not apply to our\nsetting in this paper. Yang et al . [45] proposed an index-like struc-\nture called Qd-tree to optimize multi-dimensional data layouts\nusing deep reinforcement learning (RL). Gu et al . [16] proposed a\ntechnique to construct R-trees by training RL-methods to perform\nChooseSubtree and Split operations in required for sequential in-\ndex construction. Dong et al . [9] proposed an R-tree variant that\nutilizes ML models to partition the dataset into homogeneous\nzones.ğ‘‹\nA\n1B C\n9 10 11 12D\n...LeafList\nFigure 2: Illustration of the quaternary tree structure of a\nZ-index. Each leaf node holds a pointer to its subsequent\nleaf node as well as a pointer to the page containing its\ncorresponding data points.\n3 THE BASE Z-INDEX\nIn this section, we provide the basic background on Z-index. A\nZ-index is a space-partitioning index that divides the data space\nhierarchically. At each level, the corresponding data space is\npartitioned into four cells along the median of data points, and\nthe four child cells are ordered in a â€˜Zâ€™-pattern. The complete Z-\nindex thus enforces an ordering on cells of the leaf nodes, hence\nimposing a partial-sort order among the data points.\nTwo elements define a Z-index. The first element is a hier-\narchical partitioning of the data space into cells, with each cell\npartitioned into four child cells down to a predetermined granu-\nlarity of leaf-cell size ğ¿. Corresponding split points hdetermines\nthe hierarchical partitioning: for the base Z-index variant, these\noccur at the median of the ğ‘¥- andğ‘¦-coordinates of all data points.\nThe second element is the ordering oof the cells at each level. The\nfour child cells of each parent cell of the base Z-index variant are\nordered according to the â€œ abcd â€ pattern, whereby higher-level\ncells have higher ordering importance, as shown in Figure 1a.\nThe curve order follows the higher-level ordering to place all\nleaf cells within cell Bafter all the leaf cells within cell A. The\nrelative order of the leaf cells in A(or any other higher-level\ncell) is then determined by the second level of partitioning and\nordering. Therefore, a Z-index instance Zis defined as a set of\npartition points h=(x,y)and orderings oassociated with each\nof the internal nodes of a quaternary tree, as shown in Figure 2.\nEach internal node stores the coordinates of the split point,\naccording to which the corresponding cell is partitioned into\nits child cells and the ordering of the child cells. During tree\ntraversal, say for a point query p, we traverse down the tree by\nidentifying the relevant child node at each internal node. The\nrelevant child node is computed by first comparing the query\npoint pwith the partition point hof the current node to identify\nwhether the presides in quadrants A,B,C, orD(Lines 4â€“5 in\nAlgorithm 1) and picking the appropriate pointer based on the\nordering oused (Lines 6â€“9).\nThe leaf nodes of a Z-index contain a bounding rectangle ( ğ‘ğ‘ğ‘ )\nfor the area spanned by the leaf and a pointer to a page with at\nmostğ¿elements. Each leaf node also contains a pointer to the\nnext leaf node defined by the sort order, creating a linked list\nstructure at the leaf layer of the tree ( LeafList ). Note that Z-index\nis assumed to be clustered , with data points corresponding to\nconsecutive leaf nodes stored in consecutive pages. We consider\nthe data points within a page to be stored in random order.\n\nAlgorithm 1: TreeTraversal\nInput : Z-indexZ, nodeğ‘‹inZ, point query p\nOutput: Boolean bwhether pexists\n1ifğ‘‹is a leaf node then\n2 returnğ‘‹.ğ‘ğ‘ğ‘”ğ‘’\n3else\n4ğ‘ğ‘–ğ‘¡ğ‘¥=p.ğ‘¥>ğ‘‹.ğ‘¥\n5ğ‘ğ‘–ğ‘¡ğ‘¦=p.ğ‘¦>ğ‘‹.ğ‘¦\n6 ifğ‘‹.o==â€œabcd â€then\n7ğ‘ğ‘–ğ‘‘=2ğ‘ğ‘–ğ‘¡ğ‘¦+ğ‘ğ‘–ğ‘¡ğ‘¥\n8 else\n9ğ‘ğ‘–ğ‘‘=2ğ‘ğ‘–ğ‘¡ğ‘¥+ğ‘ğ‘–ğ‘¡ğ‘¦\n10 return TreeTraversal (ğ‘‹.ğ‘â„ğ‘–ğ‘™ğ‘‘[ğ‘ğ‘–ğ‘‘])\nAlgorithm 2: Range-qery\nInput : Z-indexZ, range query R\nOutput: Set of points ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ in range R\n1Page low=TreeTraversal(BL(R))\n2Page high =TreeTraversal(TR(R))\n3Initializeğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡ =âˆ…andğ‘ƒ=low\n4whileğ‘ƒâ‰¤high do\n5ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘ =PageQueryOverlap (ğ‘ƒ,R)\n6 ifoverlap ==truethen\n7ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡â†ğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡âˆªFilter (ğ‘ƒ)\n8ğ‘ƒ=NextPage (ğ‘ƒ,ğ‘œğ‘£ğ‘’ğ‘Ÿğ‘™ğ‘ğ‘ )\n9returnğ‘Ÿğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡\nCrucially, note that the abcd ordering guarantees monotonicity\nfor points that fall within different leaf cells: if point ğ‘in pageğ‘‹\nis dominated by point ğ‘in pageğ‘Œâ‰ ğ‘‹, then leafğ‘‹will appear\nearlier in the LeafList thanğ‘Œ. Here, point ğ‘is dominated by\npointğ‘ifğ‘.ğ‘¥â‰¤ğ‘.ğ‘¥andğ‘.ğ‘¦â‰¤ğ‘.ğ‘¦, and at least one coordinate of\nğ‘is strictly smaller than that of ğ‘. This monotonicity property\nis utilized in a Z-index for a specific range query processing\nmechanism. A range query R, defined by two points BL(R)and\nTR(R)(see Figure 1b), is processed by Z-index in two phases. First,\nthe leaf nodes enclosing two query extremes, BL(R)andTR(R),\nwithin the Z-index are identified (Lines 1â€“2 of Algorithm 2) in\ntheindex lookup phase . Let us refer to these leaf nodes as low\nandhigh . These represent the first and last possible leaf nodes\nin the LeafList that may overlap with R. Second, in the scanning\nphase , we check the leaf nodes within the range [low :high]for\noverlap with Rbased on their ğ‘ğ‘ğ‘ , and pages of overlapping nodes\nare scanned to filter the query results (Lines 3â€“8 of Algorithm 2).\n4 THE WAZI INDEX\nThis section presents our method to build a workload-aware vari-\nant of the Z-index, i.e., WaZI . Within a Z-index, the scanning\nphase completely dominates the query latency. We aim to mini-\nmize the number of points accessed during the scanning phase.\nTowards this end, we present a cost formulation for the number\nof points accessed during range query processing (Section 4.1)\nand an approach to building WaZI based on minimizing the cost\nfunction (Section 4.3).\n4.1 Adaptive Partitioning and Ordering\nThe two defining elements of a Z-index, partitioning and order-\ning, are computed using fixed heuristics for the base variant. By\ncontrast, we propose a generalized variant WaZI of the Z-index,for which the partitioning and ordering can vary for each node,\nas illustrated in Figure 1d. First, whereas for the base variant,\nthe split points are predetermined to be placed at the median\nof the data along the ğ‘¥andğ‘¦axes, for WaZI , we propose that\nthe split points can be placed anywhere within the data range,\nallowing for more flexible data partitioning. Second, whereas for\nthe base variant, the ordering of the child cells is predetermined\nto follow the â€œ abcd â€ pattern for every parent cell, for WaZI , we\npropose the order is allowed to be either â€œ abcd â€ or â€œ acbd â€, as\nboth orderings preserve monotonicity.\nOur aim in making these changes in WaZI is for the index to\nbe adaptive to the given data and anticipated range queries. For\nexample, a Z-index with the alternative partitioning and ordering\nshown in Figure 1c would be better adapted to the range query\nRshown therein than the one shown in Figure 1b, as it would\nretrieve fewer data points in query processing.\nSpecifically, for a given dataset Dand a set of range queries\nQ, we are interested in building an instance of the generalized\nZ-index to minimize a corresponding retrieval cost . The retrieval\ncost for a range query is measured by the number of data points\ncompared against a query box Rin the filtering phase. In prac-\ntice,Qcan be obtained from historical logs of range queries, as\nâ€œrepresentativesâ€ for the application at hand, or in general, as an-\nticipated range queries for which the index should be optimized.\n4.2 Retrieval Cost\nHere we present the objective function we aim to optimize when\nbuilding a Z-index, as described above. For a given Z-index and\nquery R, letğ›¿Râˆˆğ‘‹ğ‘Œbe the function to indicate whether Rhas its\nbottom-left vertex in ğ‘‹and its top-right vertex in ğ‘Œ. As a simple\nillustration case, let us consider a single-level Z-index with cells\nordered according to the â€œ abcd â€ order, and the splits occur as\nin Figure 1b. Following the range query processing discussed\nearlier, the retrieval cost for the chosen split and ordering equals\nğ‘ğ‘œğ‘ ğ‘¡ğ‘‹(R|ğ‘¥,ğ‘¦;abcd)=ğ›¿RâˆˆAD(ğ‘›A+ğ‘›B+ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAC(ğ‘›A+ğ›¼ğ‘›B+ğ‘›C)+ğ›¿RâˆˆBD(ğ‘›B+ğ›¼ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAB(ğ‘›A+ğ‘›B)+ğ›¿RâˆˆCD(ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAAğ‘›A+ğ›¿RâˆˆBBğ‘›B+ğ›¿RâˆˆCCğ‘›C+ğ›¿RâˆˆDDğ‘›D, (1)\nwhereğ‘›ğ‘‹denotes the number of data points in each cell. Notice\nthatğ‘›ğ‘‹andğ›¿Râˆˆğ‘‹ğ‘Œdepend on the split location (ğ‘¥,ğ‘¦); however,\nwe omit the dependency from our notation for simplicity. To\nsee why the formula holds, note that when RâˆˆAB, the Z-index\nretrieves all points only from cells AandB, as no other cells fall\nbetween AandBin the â€œ abcd â€ ordering of cells. However, when\nRâˆˆAC(as in Figure 1b), in addition to filtering points from A\nandC, the Z-index also compares ğ‘ğ‘ğ‘ and skips over the non-\noverlapping leaf node Bas it falls between AandCin the â€œ abcd â€\nordering. The impact of skipping over leaf cells is represented in\nour cost as a fraction ğ›¼<1of the number of points.\nThe rest of the cases follow similarly. Notice that if the ordering\nof the cells is â€œ acbd â€ instead, the cost formula will differ from\nEq. 1:\nğ‘ğ‘œğ‘ ğ‘¡ğ‘‹(R|ğ‘¥,ğ‘¦;acbd)=ğ›¿RâˆˆAD(ğ‘›A+ğ‘›B+ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAB(ğ‘›A+ğ›¼ğ‘›B+ğ‘›C)+ğ›¿RâˆˆCD(ğ‘›B+ğ›¼ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAC(ğ‘›A+ğ‘›C)+ğ›¿RâˆˆBD(ğ‘›B+ğ‘›D)+\nğ›¿RâˆˆAAğ‘›A+ğ›¿RâˆˆBBğ‘›B+ğ›¿RâˆˆCCğ‘›C+ğ›¿RâˆˆDDğ‘›D (2)\nMore generally, when the Z-index consists of more than one\nlevel of partitions, the retrieval cost is defined recursively, as the\n\nZ-index structure of second-level partitions (for each of A,B,C,\nandD) affects the total cost of retrieval. Defining the retrieval\ncost of a Z-index with two levels would involve recursively sub-\nstituting Eq. 1 or 2 for each term of the form ğ›¿Râˆˆğ‘‹ğ‘‹ğ‘›ğ‘‹based on\nthe ordering o ğ‘‹under consideration:\nğ‘ğ‘œğ‘ ğ‘¡ğ‘‹(R|ğ‘¥,ğ‘¦;acbd)=ğ›¿RâˆˆAD(ğ‘›A+ğ‘›B+ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAB(ğ‘›A+ğ›¼ğ‘›B+ğ‘›C)+ğ›¿RâˆˆCD(ğ‘›B+ğ›¼ğ‘›C+ğ‘›D)+\nğ›¿RâˆˆAC(ğ‘›A+ğ‘›C)+ğ›¿RâˆˆBD(ğ‘›B+ğ‘›D)+\nğ‘ğ‘œğ‘ ğ‘¡ A(R|ğ‘¥,ğ‘¦;oA)+ğ‘ğ‘œğ‘ ğ‘¡ B(R|ğ‘¥,ğ‘¦;oB)+\nğ‘ğ‘œğ‘ ğ‘¡ C(R|ğ‘¥,ğ‘¦;oC)+ğ‘ğ‘œğ‘ ğ‘¡ D(R|ğ‘¥,ğ‘¦;oD) (3)\nFor a set of queries Qand a Z-indexZwith cellğ‘‹, the total\ncost of all queries is aggregated to form the full cost C. Specifically,\nif the ordering of ğ‘‹is â€œabcd â€, the cost function is\nCğ‘‹(Q|ğ‘¥,ğ‘¦;abcd)=âˆ‘ï¸‚\nRâˆˆQğ‘ğ‘œğ‘ ğ‘¡ğ‘‹(R|ğ‘¥,ğ‘¦;abcd)\n=ğ‘AD(ğ‘›A+ğ‘›B+ğ‘›C+ğ‘›D)+\nğ‘AC(ğ‘›A+ğ›¼ğ‘›B+ğ‘›C)+ğ‘BD(ğ‘›B+ğ›¼ğ‘›C+ğ‘›D)+\nğ‘AB(ğ‘›A+ğ‘›B)+ğ‘CD(ğ‘›C+ğ‘›D)+\nCA(R|ğ‘¥,ğ‘¦;oA)+C B(R|ğ‘¥,ğ‘¦;oB)+\nCC(R|ğ‘¥,ğ‘¦;oC)+C D(R|ğ‘¥,ğ‘¦;oD), (4)\nwith the terms ğ‘ğ‘‹ğ‘Œ=âˆ‘ï¸\nRâˆˆQğ›¿Râˆˆğ‘‹ğ‘Œ. A similar equation is also\npresent for the alternative ordering of â€œ acbd â€.\n4.3 Index Construction\nThe formulation of retrieval cost in Eq. 4 leads to a cost function\nthat exhibits an optimal substructure, where optimal configura-\ntion and the associated ordering for all possible child cell combi-\nnations should be known before one can compute the optimal\nconfiguration at a given node. Finding the optimal solution under\nthis cost formulation using dynamic programming has a com-\nplexity ofğ‘‚(ğ‘4). The complexity follows because, for ğ‘points\nin two dimensions, there are ğ‘4rectangles enclosing unique sub-\nsets of points. Hence, the state space for dynamic programming\nis at mostğ‘4. Obviously, such an approach is infeasible even for\nmoderately sized datasets.\nInstead, we adopt a Greedy algorithm for index construction.\nTheGreedy algorithm simplifies Eq. 4 by formulating the cost\nfor lower levels as ğ‘ğ‘‹ğ‘‹ğ‘›ğ‘‹. This simplification uses an upper\nbound on the possible retrieval cost of each sub-partition in place\nof the recursive cost definition of Eq. 4. Following this intuition\nalso yields an approach that allows for optimization steps to\nbe performed greedily for each layer hierarchically. Intuitively,\nthe greedy algorithm proceeds at one level at a time, from top\nto bottom, selecting the partition point and ordering using the\nalternative cost function:\nCğ‘‹(Q|ğ‘¥,ğ‘¦;abcd)=âˆ‘ï¸‚\nRâˆˆQğ‘ğ‘œğ‘ ğ‘¡ğ‘‹(R|ğ‘¥,ğ‘¦;abcd)\n=ğ‘AD(ğ‘›A+ğ‘›B+ğ‘›C+ğ‘›D)+\nğ‘AC(ğ‘›A+ğ›¼ğ‘›B+ğ‘›C)+ğ‘BD(ğ‘›B+ğ›¼ğ‘›C+ğ‘›D)+\nğ‘AB(ğ‘›A+ğ‘›B)+ğ‘CD(ğ‘›C+ğ‘›D)+\nğ‘AAğ‘›A+ğ‘BBğ‘›B+ğ‘CCğ‘›C+ğ‘DDğ‘›D (5)\nThe pseudocode for index construction is presented in Algo-\nrithm 3. The steps for index construction are described at three\nlevels of detail. First, our algorithm proceeds greedily, determin-\ning the partitioning and ordering of the cells within the sameAlgorithm 3: Greedy\nInput : Z-indexZ, nodeğ‘‹inZ, workloadQ, dataD\n1ifğ‘›ğ‘‹<ğ¿then return ;\n/* Drawğœ…candidate split points */\n2ğ‘‹ğ‘Œ:=UniformSample (ğ‘‹,ğœ…)\n/* Select split and ordering to minimize Eq. 5 */\n3(x,y,o) =arg min(ğ‘¥,ğ‘¦)âˆˆğ‘‹ğ‘Œ;oâˆˆ{abcd,acbd}C(Q|ğ‘¥,ğ‘¦;o)\n/* Define cells w.r.t. split point */\n4Cells A,B,C,D:=Split(ğ‘‹,(x,y))\n5Add cells A,B,C,Dand ordering otoZ\n/* Apply Greedy to child cells */\n6foreach Cellğ‘Œâˆˆ{A,B,C,D}do\n7 Greedy (Z,ğ‘Œ,Q,D;SolveCell )\nlevel, one level at a time, from top (root) to bottom (leaf). There-\nfore, every time a cell ğ‘‹needs to be split and its children ordered,\nwe use the configuration that minimizes the objective C(Eq. 5).\nSecond, we choose the partitioning and ordering minimiz-\ning the objectiveCfor a given cell ğ‘‹by uniformly sampling\nthe candidate split points and selecting the one that minimizes\nour objective. More specifically, for each cell that it considers\nfor splitting, Greedy samplesğœ…candidate split points uniformly\nat random from the region covered by the cell, evaluates the\nobjectiveCfor each candidate split point for both possible order-\nings, and returns the split-point and ordering with the minimum\nC. We choose sampling-based optimization over more compli-\ncated optimizers (like Bayesian optimization) to avoid the high\ncomputation overhead incurred by such optimizers. More impor-\ntantly, we observed that each iteration of an optimizer incurs\ncomputational cost several magnitudes higher than computing\nthe objective function. In our experiments, we observe no perfor-\nmance improvement over sampling-based optimization to justify\nthe added computational cost of said optimizers.\nThird, we approximate the exact data distribution Dand range\nquery distributionQwith approximate distributions by ML mod-\nels (i.e., â€œlearnedâ€ approaches). These approximate distributions\nallow for efficient estimations of the number of data points (and\nqueries) that fall within each of the child cells resulting from a\ncandidate partitioning of a given cell, as needed to compute the\nobjectiveC. We used Random Forest Density Estimation models\n(RFDE) [ 44] for our density estimation. Specifically, we construct\na forest of k-d trees constructed with randomized split dimen-\nsions at each node. Each node stores the number of data points\n(cardinality ) contained within the region. Density estimation\nin an RFDE model is performed as a tree traversal, collecting\nthe cardinality information from nodes overlapping the density\nestimation query.\n5 SKIPPING MECHANISM\nProcessing range queries involves scanning and filtering points\nfrom an interval[low :high]of leaf nodes within the LeafList\nordered by a Z-index. Figure 3a illustrates such an ordering (solid\ngrey arrows) of leaf nodes. The leaf nodes have been named ğ‘\nthroughğ‘following the ordering shown in grey. Given a range\nquery R(red box), the query processing algorithm will compare\nall leaf nodes within the interval [ğ‘:ğ‘š](shaded in red) and\nreturn points from relevant leaf nodes (i.e., those that overlap\nwith the range query). For the example in Figure 3a, the relevant\nleaf nodes are ğ‘,ğ‘—,ğ‘˜,ğ‘™ , andğ‘š, whereas the pages ğ‘throughğ‘–are\nirrelevant. We perform a bounding box comparison of the pages\n\nğ‘\nğ‘ğ‘ğ‘‘ğ‘’\nğ‘“ğ‘”\nâ„ğ‘–ğ‘—ğ‘˜ğ‘™ğ‘š\nğ‘›ğ‘œ\nğ‘ğ‘\n(a) Pages visited in range query processingBelowRight LeftAbove\n(b) Four different cases within skippingğ‘\nğ‘ğ‘ğ‘‘ğ‘’\nğ‘“ğ‘”\nâ„ğ‘–ğ‘—ğ‘˜ğ‘™ğ‘š\nğ‘›ğ‘œ\nğ‘ğ‘\n(c) Pages visited with efficient skipping\nFigure 3: Illustration of skipping during range query processing; (a) Standard range query processing of range query ğ‘…(red)\nprocesses pages in range [ğ‘:ğ‘š]; (b) The four different irrelevancy criteria explained. (c) Motivating example for efficient\nskipping. As we process page ğ‘, we know that it does not overlap the query because of Below . We also know that the\nnext page in the sort-order that may satisfy the criterion is ğ‘‘. Similarly, at page ğ‘‘we can skip ahead to page ğ‘—, saving the\ncomputation required to process pages ğ‘’throughğ‘–;\nAlgorithm 4: Look-ahead Pointer Construction\nInput: Z-indexZ\n/* Initalize all lookahead pointer */\n1InitializeLookahead (LeafList )\n/* Iterate backward through leaf nodes */\n2foreach nodeğ‘ƒin Reverse( LeafList )do\n3 foreach case in[Below ,Above ,Left ,Right ]do\n/* Init with the next ptr of LeafList */\n4ğ‘ƒ.case =next (ğ‘ƒ)\n5 while case not improved do\n6 ğ‘ƒ.case = (ğ‘ƒ.case ).case\nbefore scanning points stored within them and hence data on\npagesğ‘throughğ‘–are not scanned. But, the number of points ğ‘Ÿ\nreturned by the algorithm for a range query is often comparable\n(or significantly smaller in case of low selectivity queries) than the\ntotal number of leaf nodes ğ‘ for which we compare overlap, that\nis,ğ‘ â‰«ğ‘Ÿ. In such cases, the redundant computation of checking\noverlap between bounding boxes of irrelevant leaf nodes and the\nrange query can become a bottleneck. Our solution to address\nthis issue is skipping over leaf nodes irrelevant to the query.\nFor the example above, Figure 3c depicts two practical instances\nof skipping from ğ‘toğ‘‘andğ‘‘toğ‘—(blue arrows), reducing the\nnumber of leaf nodes visited (shaded red) from 13 to 7.\nWe propose our novel mechanism for efficient skipping in two\nparts. First, we design a skipping mechanism that operates on any\nrange query using look-ahead pointers . Second, we present the\nalgorithm to precompute the look-ahead pointers during index\nconstruction. Finally, we modify the retrieval cost from Eq. 5 to\naccurately incorporate the impact of skipping.\n5.1 Look-ahead Pointers\nIn standard processing (cf. Section 3) for a range query R, we\ncheck whether the bounding box of any leaf node overlaps with R.\nIf so, we read and filter points stored in the page associated with\nthat leaf node. Otherwise, we follow the pointer to the next leaf\nnode in the LeafList , iteratively proceeding until a relevant page\nis found or we reach the end of the interval [low :high]. As\ndiscussed earlier, this may be inefficient. Our solution introduces\nfour additional look-ahead pointers for each leaf node, allowingus to skip irrelevant pages accessed with the standard query\nprocessing algorithm.\nThe four look-ahead pointers map to the four possible criteria\nunder which a leaf node may be irrelevant; we name them Below ,\nAbove ,Left , and Right . For instance, Below indicates that the\nğ‘¦-coordinate of the top-right of the leaf node ğ‘ƒ, represented by\nTR(ğ‘ƒ).ğ‘¦, is lower than the ğ‘¦-coordinate of bottom-left of the\nquery R,TR(ğ‘ƒ).ğ‘¦<BL(R).ğ‘¦. Or put simply, the area covered\nbyğ‘ƒlies entirely below the range query R. The other criteria\nfollow similarly. Figure 3b shows the four criteria for a candidate\nR. For example, in Figure 3a, the leaf node represented by ğ‘‘is\nirrelevant to the range query shown in red as it would satisfy\nBelow criteria, where ğ‘“satisfies both Right andBelow criteria.\nNote that pages within the interval [low :high]of a query\nRcannot lie in the bottom-left and top-right sections due to\nmonotonicity constraint.\nA look-ahead pointer associated with each of the four crite-\nria points to the next possible leaf node that could be relevant,\nskipping over leaf nodes that are guaranteed to be deemed irrele-\nvant due to the same criteria. Specifically, consider a leaf node ğ‘ƒ1\nwhose look-ahead pointer associated with Below points toğ‘ƒ2.ğ‘ƒ2\nis the earliest leaf node in LeafList that satisfies the conditions\nTR(ğ‘ƒ1).ğ‘¦<TR(ğ‘ƒ2).ğ‘¦and Ord(ğ‘ƒ1)<Ord(ğ‘ƒ2). For example,\nleaf nodeğ‘‘in Figure 3a is irrelevant due to the Below criterion.\nConsequently, nodes [ğ‘’:ğ‘–]are guaranteed to be irrelevant to\nRdue to Below asâˆ€ğ‘¥âˆˆ[ğ‘’:ğ‘–],TR(ğ‘¥).ğ‘¦â‰¤TR(ğ‘‘).ğ‘¦. Therefore,\nwe know that for any query Rthat disqualifies ğ‘‘due to Below ,\nnodes[ğ‘’:ğ‘–]will also be deemed irrelevant.\nWe utilize look-ahead pointers to modify the range-query\nprocessing algorithm. If we identify that a leaf node ğ‘ƒdoes not\noverlap with R, we now follow a look-ahead pointer instead of\nfollowing the next pointer. The choice of look-ahead pointer is\nmade by discerning the criteria under which leaf node ğ‘ƒwas\ndeemed irrelevant. If an irrelevant leaf node satisfies multiple cri-\nteria, we pick the look-ahead pointer that skips over the greatest\nnumber of nodes.\n5.2 Building Look-ahead Pointers\nThe algorithm for computing the look-ahead pointers is pre-\nsented in Algorithm 4. The look-ahead pointers are constructed\nin the final phase of index construction for a Z-index, where the\nhierarchical structure already imposes an ordering Ord on the\n\nleaf nodes. The construction of look-ahead pointers considers leaf\nnodes in the reverse order of the LeafList . The look-ahead point-\ners for the last leaf node point to a dummy page signifying the\nend of LeafList . For each subsequent (i.e., earlier in LeafList )\nleaf nodeğ‘ƒ, we utilize the constructed look-ahead pointers within\nthe suffix of LeafList to compute the look-ahead pointer. To\nconstruct a look-ahead pointer associated with a given criterion\n(say, Below ), we temporarily assign the corresponding look-\nahead pointer ğ‘ƒ.Below to the next pointer of LeafList . We then\nrecursively check whether the node pointed to by ğ‘ƒ.Below im-\nproves the criterion. Improving the criterion in this case refers\nto having an improved value for the corresponding disqualifying\ncomparison. In the case of Below , the improved value would\nbe if the pointer ğ‘ƒ.Below points to a page with a greater up-\nper bound value along the ğ‘¦-coordinate; put simply, it is higher\nthan leaf node ğ‘ƒ. If the check for improving criterion fails, we\nfollow the corresponding nodesâ€™s pointer for the criterion, thus\nfinding later nodes recursively (Line 6 of Algorithm 4). For each\nleaf node, the look-ahead construction algorithm performs at\nmostâˆšï¸\n|LeafList|recursion steps. Therefore, the complexity of\nAlgorithm 4 is ğ‘‚(|LeafList|3/2), where|LeafList|â‰ˆğ‘/ğ¿.\nThe retrieval cost formulation presented in Eq. 5 accounts for\nthe skipping cost of irrelevant leaf nodes using ğ›¼. We can now\nupdate the cost formulation to accurately reflect the retrieval\ncost of a given query in light of the skipping mechanism men-\ntioned above and account for the redundant quadrant fetched\nfor processing queries by setting the ğ›¼value to a small constant.\nIn our experiments, we set ğ›¼to10âˆ’5. The small value of ğ›¼will\nmore accurately reflect the cost of skipping over irrelevant pages\nwithin redundant quadrants using the look-ahead pointers. The\nindex construction (Algorithm 3) remains unchanged except for\nthe fact that one would utilize a smaller ğ›¼value for Eq. 5 in Line 3\nof Algorithm 3 when used along with look-ahead pointers.\n6 EXPERIMENTS\nIn this section, we first describe the setup of our experiments.\nThen, we present the experimental results with discussions.\n6.1 Baselines\nWe compare the learned workload-aware Z-Index WaZI with the\nfollowing competitors:\n1)Sort Tile Recursive R-tree ( STR) [25]: a simple R-tree pack-\ning method based on tiling the data space into vertical or\nhorizontal slices recursively to construct an R-tree.\n2)Cost-based unbalanced R-trees ( CUR ) [40]: a query-aware\nunbalanced R-tree construction algorithm which places nodes\nhigher in the tree based on the expected number of access\nunder a given workload.\n3)Flood ( Flood ) [29]: a grid-based index built to efficiently pro-\ncess range queries by optimizing the grid structure based on\nthe estimated query processing cost.\n4)QUery-Aware Spatial Incremental Index ( QUASII ) [35]: a query-\naware index which applies cracking [ 19] during query pro-\ncessing to adapt the index to the query workload.\n5)Base Z-Index ( Base ): the base Z-index built by partitioning\nthe data points using the median along each axis and â€œ abcd â€\nordering of children at each level as presented in Section 3.\nWe also implemented the greedy variant of Qd-tree ( Qd-Gr )\n[45] as the RL-variant requires a large action space which is in-\nfeasible in our setting. The cost formulation of Qd-Gr creates\nunbalanced trees tailored for disk-based indexes. Additionally,\nB/a.sc/s.sc/e.sc CURF/l.sc/o.sc/o.sc/d.sc HRRQD/hyphen.scG/r.sc QUASII QUILTSRSMI STRW/a.scZI Z/p.sc/g.sc/m.sc107Range Query\nlatency(ns)Figure 4: Average range query performance of all indexes\nconsidered in the experiments.\nTable 1: Key properties of indexes in the experiments.\nIndex SFC-based Query-Aware Learned\nSTR\nCUR\nFlood\nQUASII\nBase\nWaZI\nwe experimented with Zpgm [10,42],HRR [37,38],QUILTS [31]\nandRsmi [36]. However, these five indexes performed signifi-\ncantly worse than the other baselines considered (as shown in\nFigure 4). Therefore, we chose to not include them in more de-\ntailed experimentation later. Interestingly, four out of the five\nindexes we discarded ( Zpgm ,HRR ,QUILTS , and Rsmi ) are based\non Z-order curves within the rank space. Additionally, we also\nattempted to use BMTree [26] and LMSFC [15] as baselines in\nour experiments. However, BMTree construction failed to fin-\nish in a reasonable duration and LMSFC does not have publicly\navailable implementation.\nThe indexes considered show a balanced representation along\nthree different categorizations, as presented in Table 1. The â€˜SFC-\nbasedâ€™ column indicates if the construction algorithm of the in-\ndexes utilized space filling curves. The â€˜Query-Awareâ€™ column\nindicates if the index construction tailors for a specific query\nworkload. Finally, the â€˜Learnedâ€™ column refers to indexes that\nutilize any form of learning algorithms (to model cost function,\ndensity estimates, etc.) within the index or during construction.\nImplementation. Base andWaZI are constructed with specific\nalgorithms for finding their respective partition point and order-\ning. The Base version utilizes the naive method of comparing\nbounding boxes to decide if a given page overlaps with the range\nquery before filtering points within the page. Whereas WaZI\nutilizes the efficient skipping mechanism mentioned in Section 5.\nWe implement the two variants of Z-index in C++.1\nSimilarly, we also implement STR [25] and QUASII [35] as de-\nscribed by the original authors. We utilize a converged QUASII in-\ndex for our evaluations, i.e., an index that has completely adapted\nto the query distribution without the need for further incremen-\ntal updates. A simplified Flood -Index for 2D indexing ( Flood ) is\nimplemented in C++, where we identify the optimal grid struc-\nture by evaluating the performance of candidate grid partitions\non a sub-sample of range queries. We adapted the CUR tree\nindex to point data by using a â€˜weightedâ€™ RFDE estimator to\nhold a weighted sum of points covering each node. Each point\nis weighted by the number of distinct queries fetching the point.\nFinally, we use weighted density estimates to select partitions\nfollowing the Sort Tile Recursive algorithm to construct CUR .\n1Our implementation is published at https://version.helsinki.fi/ads/learned-zindex.\n\n(a)DCaliNev\n (b)DNewYork\n (c)DJapan\n (d)DIberia\n(e)QCaliNev\n (f)QNewYork\n (g)QJapan\n (h)QIberia\nFigure 5: Datasets and query workloads in the experiments.\nWe conducted all the experiments on a server with an IntelÂ®\nXeonÂ®E5-2680v4 CPU @ 2.40GHz and 16 GB memory. The exper-\niments were performed on a single thread without multithreading\nor GPUs. All methods were compiled with the -O3 optimizer flag.\nFinally, we set the leaf node capacity ğ¿to 256 in our experiments.\n6.2 Datasets and Query Workloads\nWe utilize real-world datasets along with skewed semi-synthetic\nquery workloads. The real-world datasets consist of points of\ninterest (POI) from OpenStreetMap [ 32] for selected regions. The\nfour regions we chose are: California Coast ( CaliNev ), New York\nCity ( NewYork ), Japan ( Japan ), and Iberian Peninsula ( Iberia ).\nWe extract all POIs from the regions and sample these to produce\ndatasets of appropriate size when required. The distribution of\ndata pointsDare presented in Figures 5aâ€“5d.\nWe focus on skewed query workloads varying from the under-\nlying data distribution for insightful analysis. This setup differs\nfrom past works showcasing experiments that use query dis-\ntributions that follow the data distribution [ 36]. Alternatively,\nwe present results on query workloads with real-world inspired\nskewness on the underlying data distribution. We generate semi-\nsynthetic query workloads for the real-world datasets by utilizing\ncheck-in information in the Gowalla dataset [ 24]. Specifically, we\nextract check-ins that lie within the corresponding region and\nutilize these locations to generate a query workload resembling\nthe distribution of check-in locations. The process for generating\nrange queries proceeds by sampling the centers of query rectan-\ngles from the set of check-in locations and growing along the\nfour directions such that the query covers a portion of data space\nequivalent to the required selectivity. We represent selectivity as a\npercentage of data space. Figure 5 presents the query distribution\nQ(i.e., the check-in locations) for each of the real-world datasets.\nThe distributions of check-in locations are skewed towards pop-\nular locations compared to the underlying data distribution D.\nWe experiment with datasets ranging from 4 to 64 million data\npoints and range query workloads of varying selectivity (ranging\nfrom 0.0004% to 0.1024% of data space). The range of parameters\nused for data generation are presented in Table 2.\n6.3 Range Query Performance\nFigure 6 presents the average range query latencies of different\nindexes at four levels of query selectivities (low to high). These\nindex latencies are evaluated over range-query workloads of\n20,000 queries. We observe that WaZI clearly outperforms all\nother indexes in most cases. The closest competition for WaZITable 2: Parameter setting.\nParameter Values (default in bold)\nDataset size (Ã—106) [4, 8, 16, 32, 64]\nQuery selectivity (%) [0.0016, 0.0064, 0.0256 , 0.1024]\nLeaf-node size 256\nRange-query workload size 20,000\nis from QUASII on the Japan dataset for the selectivity values\n0.0064% (top-right in Figure 6) and 0.1024% (bottom-right). Never-\ntheless, WaZI always performs similarly or (often substantially)\nbetter than QUASII . The improvements are most noticeable for\nthe lower selectivity queries where WaZI is better by about 2.3Ã—\nto8.1Ã—over QUASII . We also note that the indexes showcase\ndifferent scales of range query latencies over different datasets.\nTo further analyze the advantages of WaZI over Base , we\npresent a percentage improvement plot in Figure 7. The per-\ncentages are calculated in comparison with the performance of\nBase for each dataset-workload pair. We present the average\nimprovements of indexes over different datasets and selectivi-\nties. Across different datasets, WaZI showcases improvements\nbetween 12.8% for the Japan dataset and 47.6% for the NewYork\ndataset (top in Figure 7). CUR andSTR showcase improvements\nover Base for two out of the four datasets. We also see that the\npercentage differences between indexes decrease as the selectiv-\nity increases. The improvements by WaZI linearly decrease from\n31% for 0.0016% selectivity queries to 14% for 0.1024% selectivity\nqueries. This indicates that, as the selectivity increases, query\nprocessing encounters fewer false positives relative to the actual\nquery result size. Therefore, a learned and workload-aware index\nis more suited for settings with low-selectivity queries. Finally,\nWaZI is the only index that shows a consistent improvement\nover Base .\nRange Query over Different Dataset Sizes. Additionally, we\nplot the average range query latencies in Figure 8 to analyze the\nperformance of different indexes across varying dataset sizes.\nThe query latencies are recorded for a query workload with a\nselectivity of 0.0256%. We observe that the performance of all\nindexes scales nearly linearly with the dataset size, with WaZI\noutperforming all competing baselines over different data sizes.\nFurthermore, the difference in performance between the competi-\ntors and WaZI remains somewhat constant with an increasing\ndataset size.\nProjection vs Scanning. It is useful to analyze the query pro-\ncessing latency of an index in two parts. In the first part, termed\nProjection, the index traverses its search structure to identify all\nthe leaf nodes (and hence the pages) overlapping a given range\nquery. Second, we scan the data points within the projected pages\nto filter the result set. Such analysis separates the performance\noverhead of the internal search structure from the performance\noverheads originating from the data layout of the constructed\nindex.\nFigure 9 shows the two parts of query time for a 32 million-\nsized dataset under a mid-selectivity query workload. In terms\nof projection (top in Figure 9), CUR ,QUASII , and STR perform\nworst due to its tree-traversal cost, followed by Z-indexes Base\nandWaZI .WaZI performs 4.3Ã—faster projection than Base . This\nspeedup could mostly be attributed to the efficient skipping mech-\nanism. Flood performs the fastest projection (about 20Ã—faster\nthan Base ) of the query to pages, as it does not perform a tree\n\nQUASII CUR STR F/l.sc/o.sc/o.sc/d.sc B/a.sc/s.sc/e.sc W/a.scZICaliNev Iberian Japan NewYork105106Low-Selectivity(0.0016%)\nCaliNev Iberian Japan NewYork105106Mid-Selectivity(0.0064%)\nCaliNev Iberian Japan NewYork106Mid-Selectivity(0.0256%)\nCaliNev Iberian Japan NewYork106107High-Selectivity(0.1024%)Range Query latency(ns)Figure 6: Average range query latency for all the indexes over four selectivity ranges. We observe that WaZI consistently\noutperforms all the competing baselines.\nCaliNev Iberian Japan NewYork\nData Distribution40\n20\n0\n-20\n-40-80\n0.0016 0.0064 0.0256 0.1024\nQuery Selectivities40\n20\n0\n-20\n-40\n-80\nQUASII CUR STR F/l.sc/o.sc/o.sc/d.sc W/a.scZI% improvement over BASE\nFigure 7: Percentage improvements over Base across the\ndifferent data distributions and selectivities (plotted on the\nsymlog scale with a threshold of 50.)\nQUASII CUR STR F/l.sc/o.sc/o.sc/d.sc B/a.sc/s.sc/e.sc W/a.scZI4 8 16 32 64\nSize (in 106)106Range Query time (ns)\nFigure 8: Range query time by varying the dataset size\nfrom 4 to 64 million for a mid-selectivity (0.0256%) query\nworkload.\ntraversal for projection like the other indexes. The scan phase of\nthe indexing dominates the performance of an index. WaZI out-\nperforms other indexes in terms of scan time due to its optimized\ndata layout.\nB/a.sc/s.sc/e.sc CURF/l.sc/o.sc/o.sc/d.sc QUASIISTR W/a.scZI104105Projection(ns)\nB/a.sc/s.sc/e.sc CURF/l.sc/o.sc/o.sc/d.sc QUASIISTR W/a.scZI2.22.53.0Scan(ns)Ã—106Figure 9: Range query latencies of different indexes split\ninto the Projection and Scan phases.\nRemark on kNN and Spatial-Join Queries. For spatial in-\ndexes that are not specialized to kNN or spatial-join queries (as\nis the case for all indexes we evaluate), kNN and spatial-join\nqueries are typically decomposed to and processed as sets of\nrange queries [ 34]. As a result, query performance exhibits the\nsame behavior as their range query performance presented above,\nas we have confirmed experimentally. For this reason, we do not\ninclude additional results for kNN and spatial-join queries.\n6.4 Point Query Performance\nAlthough we focus on optimizing indexes for range-query work-\nloads, we also show the performance of proposed indexes for\npoint queries for completeness. We sample 50,000 point queries\nfrom the data distribution Dof the respective datasets. Figure 10\npresents the average query time (over different datasets) for vari-\nous indexes against increasing data size. Comparing indexes from\nbest to worst, we see that WaZI andBase outperform all other\nbaselines. This performance is due to simpler computations re-\nquired at the internal nodes of a Z-index (see Algorithm 1) to iden-\ntify the relevant child nodes. Flood index performs similarly but\nslower than WaZI andBase .STRandCUR have non-overlapping\n\nQUASII CUR STR F/l.sc/o.sc/o.sc/d.sc B/a.sc/s.sc/e.sc W/a.scZI4 8 16 32 64\nSize (in 106)102103Point Query (ns)\nFigure 10: Point query time by varying the dataset size\nfrom 4 to 64 million. We observe that WaZI performs the\nbest across all dataset sizes.\nTable 3: Build time (in seconds) of all indexes compared.\nSize (Ã—106)Base CUR Flood QUASII STR WaZI\n4 7.4 23.8 4.6 123.6 1.8 25.1\n8 16.2 48.5 10.1 418.1 4.0 51.8\n16 35.0 97.0 25.8 4400.7 8.4 105.3\n32 71.6 188.5 42.1 15781.5 19.1 203.2\n64 154.6 366.9 97.3 57943.8 40.5 414.3\nchild nodes and perform marginally faster than CUR which al-\nlows for overlapping. Finally, QUASII suffers computationally due\nto the heavily fractured data layout caused by database cracking-\nbased index construction. Generally, the performance of each\nindex over point queries is highly correlated with its respective\ncost of tree traversal and the underlying data layout. We see that\nWaZI performs better than the baselines by a factor of 1.5â€“15Ã—\ndue to the efficiency of node-level computations.\n6.5 Build Time\nWe record the build time for all the indexes we compare in Table 3.\nFor all indexes, the build time grows linearly as the dataset size\nincreases. STR takes the least time for index construction as the\nSort-tile recursive algorithm has a log-linear complexity. Among\nthe query-aware indexes (see Table 1), WaZI performs third best\nbehind Flood andCUR . On comparison against learned indexes,\nWaZI performs second best behind Flood .WaZI requires 5.4Ã—\nmore build time than Flood . We mainly attribute this to the need\nfor constructing and evaluating data density estimators required\nfor cost computations. The build-time of WaZI is similar to the\nquery-aware CUR index which utilizes query selectivity estima-\ntion of data points to compute an approximate cost. Therefore,\ncompared to the baselines considered, WaZI has a reasonable\nbuild time.\nCost-redemption . Typically, learned indexes achieve improved\nquery execution time, at the cost of computationally expensive\nindex building. To quantify this trade-off for a given dataset and\nquery workload, we define cost redemption as the number of query\nexecutions for which the cumulative (building+querying) time\nof an index is equal to the respective cumulative time of Base .\nSpecifically, the cost-redemption value of index ğ‘‹is defined as\nğ‘Ÿğ‘’ğ‘‘ğ‘‹=ğ‘‹.ğµğ‘¢ğ‘–ğ‘™ğ‘‘âˆ’Base.ğµğ‘¢ğ‘–ğ‘™ğ‘‘\nBase.ğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦âˆ’ğ‘‹.ğ‘„ğ‘¢ğ‘’ğ‘Ÿğ‘¦.Table 4: Cost-redemption value of indexes against Base .\nLower is better. Missing values indicate that the index does\nnot redeem its high-construction time with efficient query\nperformance compared to Base .\nData Dist. CUR Flood QUASII STR WaZI\nCaliNev(+)550k(âˆ’)13k(âˆ’) (âˆ’) 320k(+)192k\nIberia(âˆ’) (âˆ’) 44k(âˆ’) (âˆ’) 450k(+)746k\nJapan(âˆ’) (âˆ’) 6.5k(âˆ’) (âˆ’) 69k(+)269k\nNewYork(+)1300k(âˆ’)830k(âˆ’) (+) (+) 743k\nTable 5: Sizes (in MBs) of all indexes compared.\nSize (Ã—106)Base CUR Flood QUASII STR WaZI\n4 8.27 10.33 5.39 3.02 7.09 8.99\n8 16.83 19.05 6.14 5.31 15.41 17.80\n16 34.94 36.91 11.00 13.79 23.48 35.15\n32 67.60 74.73 37.18 26.83 66.02 69.84\n64 135.86 149.01 53.13 61.48 112.00 138.83\nWe showcase the cost-redemption of the considered indexes\nin Table 4. Cells marked with (+)correspond to cases where\nthe index eventually redeems its higher building time after the\nreported number of queries. By contrast, cells marked with (âˆ’)\ncorrespond to the opposite behavior: they have faster building\ntime than Base , but larger query execution time, leading to larger\ncumulative time after the reported number of queries. Finally, a\nmissing value indicates that the index has better (+)or worse(âˆ’)\ncumulative time regardless of the number of queries executed.\nFrom Table 4 we can see that Flood andSTR are better than\nBase in the short run due to their smaller build times. CUR is\nbetter than Base in the longer run for CaliNev andNewYork\ndatasets while being clearly worse for Iberia andJapan . The\nmassive build time of QUASII and the slower query performance\nindicate that it is the worst-performing index. Finally, WaZI is a\nbetter choice than Base if the expected query workload has at\nleast 106queries. Therefore, this is a limitation of WaZI as it is\nnot suited for workflows that require quick index construction\nto execute a few queries as found in data analysis workflows.\nInstead, it is suited for workflows where index construction can\nbe performed offline using more computational resources and\ndeployed for an extended amount of time.\n6.6 Index Size\nWe present the size of each index built for the datasets with 32\nmillion points in Table 5. QUILTS ,Flood andQUASII exhibit\n0.31âˆ’0.59Ã—smaller index sizes than WaZI . The index size of\nWaZI is similar to the R-tree-based indexes, CUR andSTR. Cru-\ncially note that the size of WaZI is nearly identical to Base . This\nindicates that the methods presented in this paper construct a\nworkload-aware version of Z-index at no additional space cost.\nFurthermore, we see that the size of all the indexes we utilized\nin our experiment grows linearly with the dataset size.\n6.7 Index Update\nWaZI supports index updates like other tree-based indexes. An\nindex update operation in WaZI is performed similarly to point\nquery processing. Inserting/deleting a point pproceeds by finding\nthe leaf node enclosing p(using Algorithm 1) and updating the\n\nW/a.scZI CUR F/l.sc/o.sc/o.sc/d.sc10 20\n% of inserted data2.55.0Insert latency (ns)Ã—103\n10 20\n% of inserted data5.07.5Range latency(ns)Ã—105\nFigure 11: Insert and range query latencies over inserts.\nB/a.sc/s.sc/e.sc W/a.scZI0 50\n% change3.94.04.14.2Range Query(ns)Ã—106\nUniform\n0 50\n% change3.94.04.1Ã—106\nSkewed\nFigure 12: Range query time of WaZI andBase over the\nchanges in workloads. On the left, higher % change cor-\nresponds to a more uniform workload; on the right, to a\nworkload more similar to a different skewed workload.\ncorresponding page. When any page overflows/underflows, we\nperform a node splitting/merging operation as for any tree index.\nFigure 11 examines the impact of insert queries on a subset\nof indexes each containing 32 million data points. We sample 8\nmillion insert query points uniformly from the data space and\nincrementally insert these points in five equal-sized iterations.\nFor each iteration, we recorded the latencies of insert queries and\nrange queries after insertions. We split any overflowing pages of\nWaZI along the data medians. We see that WaZI performs slowest\nin terms of insert latencies in comparison with CUR andFlood\n(left in Figure 11). This can be attributed to the costly update\ntoPageList during node splits and the need to recompute the\nlook-ahead pointers. We also note that the inserts have a minor\neffect on range query performance, with latencies degrading\nlogarithmically with inserts.\n6.8 Effect of Workload Changes\nWorkload-aware indexes are susceptible to degrading query per-\nformance due to the changes in workloads. In this subsection,\nwe compare the effects of query workload changes on Base and\nWaZI . Specifically, we build Base andWaZI using their original\nquery workload and evaluate them over iteratively changing\nworkloads. We experiment with both uniform and skewed work-\nload changes. In the former case, we replace the datasetâ€™s original\nworkload with uniformly sampled queries over the data space. In\nthe latter case, we replace the datasetâ€™s original workload with\nthe (skewed) workloads of other datasets.\nThe results of the experiment are presented in Figure 12. We\nsee that the performance of Base remains relatively stable across\nthe range of workload changes, while WaZI degrades in perfor-\nmance. As the workload changes to a uniform workload (left in\nFigure 12), WaZI degrades gracefully and remains better than\nBase . This shows that WaZI â€™s skipping mechanism and the layoutwhich is tailored to both the data and the original query workload\n(see Eq. 5) retains some advantage over the Base index even over\nuniform queries. The weakness of WaZI is highlighted in the case\nwhere the workload changes to a differently skewed workload\n(right in Figure 12). The performance of WaZI degrades rapidly\nand becomes slower than Base after the workload changes more\nthan 60%. This indicates that WaZI is most suited for the settings\nwith known query workloads which do not change drastically\nand it requires to be rebuilt if the workload changes sufficiently.\nTo our knowledge, automatically deciding when to rebuild a\nspatial index in case of workload drift is an open problem. How-\never, there have been extensive studies on detecting concept drift\nfor ML models [ 14]. We suggest that similar methods could be\nadapted for rebuilding spatial indexes. However, the exploration\nof such methods is beyond the scope of the paper.\n6.9 Ablation Study\nIn this paper, we presented methods to perform adaptive parti-\ntioning and ordering (Section 4.1) and a novel skipping algorithm\n(Section 5) to create the WaZI index. Here we perform an ablation\nstudy for the two methods we presented. To facilitate compar-\nison of each individual method mentioned above, we compare\ntheBase andWaZI index against two additional methods:\nâ€¢Base+SK : ABase index variant with default partition-\ning upon which we construct and utilize the look-ahead\npointer logic.\nâ€¢WaZI-SK : AWaZI variant with adaptive partitioning, but\nno look-ahead pointers.\nWe perform experiments on a dataset of size 8 million and log\nmetrics of interest. The results of the experiment are presented\nin Figure 13. First, we show the incremental improvements made\nagainst Base by the additional methods in Figure 13 (top-left).\nWe see that both WaZI-SK andBase+SK perform similarly for\nlow selectivity indicating both the methods contribute equally\ntowards the improved performance. However, as selectivity in-\ncreases, WaZI-SK andBase+SK diverge. At higher selectivity\nworkloads, Base+SK tends towards the performance of Base\nindex while WaZI-SK tends towards WaZI . This trend shows that\nadaptive partitioning improves performance by a larger factor\nthan the use of look-ahead pointers at high selectivity ranges.\nSecond, the bottom-left plot of Figure 13 shows the number of\nbounding boxes ( ğ‘ğ‘ğ‘ ) checked for overlap with the range query\nwhile processing leaf nodes in the [low :high]interval. We\nclearly see that the use of look-ahead pointers drastically re-\nduces the number of bounding boxes compared. Indexes with\nlook-ahead pointers perform 50â€“100Ã—fewer bounding box com-\nparisons.\nThird, we show the number of excess points compared (top-\nright) and the number of pages scanned (bottom-right). The un-\nderlying data-layout of an index greatly impacts the performance\non these two metrics. We see that Base andBase+SK perform\nworse than WaZI andWaZI-SK indicating that the adaptive par-\ntitioning is the key differentiating factor. Therefore, we infer that\nadaptive partitioning creates data layouts that are more efficient\nfor range query processing in a Z-index.\nFrom these results, we can conclude that the two methods\nwe present in this paper address two key aspects of range query\nperformance in a Z-index. The adaptive partitioning generates\nbetter data layouts and the look-ahead pointers facilitate quicker\ntraversal of the layout.\n\nB/a.sc/s.sc/e.sc W/a.scZI B/a.sc/s.sc/e.sc+SK W/a.scZI/hyphen.scSK0.0004 0.0064 0.1024104105Query Time(ns)\n0.0004 0.0064 0.1024107108Excess Points\n0.0004 0.0064 0.1024\nselectivity (%)106108/u1D44F/u1D44Fs checked\n0.0004 0.0064 0.1024\nselectivity (%)105106107Pages Scanned\nFigure 13: Results for ablation study regarding query time\n(top-left), excess retrievals (top-right), bounding boxes\nchecked (bottom-left), and pages scanned (bottom-right).\n7 CONCLUSION\nIn this paper, we presented WaZI , a learned and workload-aware\nvariant of a Z-index that jointly optimizes the storage layout\nand search structures for spatial indexing. Our method adapts to\ndata distribution and query workload to build indexes to provide\nbetter range query performance. We began by devising a metric\nfor optimization based on the number of data points fetched dur-\ning query processing, called retrieval cost. Then we proposed an\nalgorithm for building a Z-index variant, WaZI , which minimizes\nthe retrieval cost. Additionally, we designed efficient mechanisms\nforWaZI to skip irrelevant pages accessed during range query\nprocessing. Through extensive experiments, we demonstrated\nthatWaZI improved upon existing spatial indexes, such as Flood\nandCUR , in terms of range query performance for real-world\ndatasets. We presented a comprehensive ablation study, where\nwe showed the relative contribution of each component towards\nimprovements shown by WaZI . Additionally, we see that WaZI\nperforms well on point query performance while providing fa-\nvorable construction time and index size tradeoffs.\nFor future work, we intend to explore three aspects that are\nnot yet covered by this paper. First, we intend to expand the cost\nformulation to account for other factors of index performance\nbeyond retrieval cost so as to fit mixed types of query workloads.\nSecond, we intend to explore ways to solve for the recursive\ncost formulation briefly mentioned in Section 4.3. Specifically,\nwe aim to use machine learning models to efficiently learn the\nretrieval cost, which currently requires a dynamic programming\nalgorithm with a state space of ğ‘‚(ğ‘4). Third, we intend to de-\nvelop mechanisms to decide when to retrain an index when the\ndata distribution and query workload change.\nACKNOWLEDGMENTS\nWe would like to thank Arpit Merchant and Ananth Mahade-\nvan for their useful suggestions regarding the presentation of\nexperimental results. Sachith Pai and Michael Mathioudakis are\nsupported by University of Helsinki and Academy of Finland\nProjects MLDB (322046) and HPC-HD (347747). Yanhao Wangwas supported by the National Natural Science Foundation of\nChina under grant no. 62202169.\nREFERENCES\n[1]Abdullah Al-Mamun, Ch. Md. Rakin Haider, Jianguo Wang, and Walid G. Aref.\n2022. The â€œAI + Râ€-tree: An Instance-optimized R-tree. In 2022 23rd IEEE\nInternational Conference on Mobile Data Management (MDM) . IEEE, 9â€“18.\n[2]Lars Arge, Mark de Berg, Herman J. Haverkort, and Ke Yi. 2004. The Priority\nR-Tree: A Practically Efficient and Worst-Case Optimal R-Tree. In Proceedings\nof the 2004 ACM SIGMOD International Conference on Management of Data\n(SIGMOD â€™04) . Association for Computing Machinery, New York, NY, USA,\n347â€“358.\n[3]Rudolf Bayer. 1997. The Universal B-Tree for Multidimensional Indexing:\nGeneral Concepts. In Worldwide Computing and Its Applications â€“ Interna-\ntional Conference, WWCA â€™97, Tsukuba, Japan, March 10-11, 1997 Proceedings .\nSpringer, Berlin, Heidelberg, 198â€“209.\n[4]Norbert Beckmann, Hans-Peter Kriegel, Ralf Schneider, and Bernhard Seeger.\n1990. The R*-Tree: An Efficient and Robust Access Method for Points and\nRectangles. In Proceedings of the 1990 ACM SIGMOD International Conference\non Management of Data (SIGMOD â€™90) . Association for Computing Machinery,\nNew York, NY, USA, 322â€“331.\n[5]Norbert Beckmann and Bernhard Seeger. 2009. A Revised R*-Tree in Compar-\nison with Related Index Structures. In Proceedings of the 2009 ACM SIGMOD\nInternational Conference on Management of Data (SIGMOD â€™09) . Association\nfor Computing Machinery, New York, NY, USA, 799â€“812.\n[6]Jon Louis Bentley. 1975. Multidimensional Binary Search Trees Used for\nAssociative Searching. Commun. ACM 18, 9 (1975), 509â€“517.\n[7]Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\nDavid B. Lomet, and Tim Kraska. 2020. ALEX: An Updatable Adaptive Learned\nIndex. In Proceedings of the 2020 International Conference on Management of\nData (SIGMOD â€™20) . Association for Computing Machinery, New York, NY,\nUSA, 969â€“984.\n[8]Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. 2020.\nTsunami: A Learned Multi-dimensional Index for Correlated Data and Skewed\nWorkloads. Proc. VLDB Endow. 14, 2 (2020), 74â€“86.\n[9]Haowen Dong, Chengliang Chai, Yuyu Luo, Jiabin Liu, Jianhua Feng, and\nChaoqun Zhan. 2022. RW-Tree: A Learned Workload-aware Framework\nfor R-tree Construction. In 2022 IEEE 38th International Conference on Data\nEngineering (ICDE) . IEEE, 2073â€“2085.\n[10] Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-Index: A Fully-\nDynamic Compressed Learned Index with Provable Worst-Case Bounds. Proc.\nVLDB Endow. 13, 8 (2020), 1162â€“1175.\n[11] Raphael A. Finkel and Jon Louis Bentley. 1974. Quad Trees: A Data Structure\nfor Retrieval on Composite Keys. Acta Inform. 4 (1974), 1â€“9.\n[12] Volker Gaede and Oliver GÃ¼nther. 1998. Multidimensional Access Methods.\nACM Comput. Surv. 30, 2 (1998), 170â€“231.\n[13] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and\nTim Kraska. 2019. FITing-Tree: A Data-aware Index Structure. In Proceedings\nof the 2019 International Conference on Management of Data (SIGMOD â€™19) .\nAssociation for Computing Machinery, New York, NY, USA, 1189â€“1206.\n[14] JoÃ£o Gama, Indr Ì‡e Å½liobait Ì‡e, Albert Bifet, Mykola Pechenizkiy, and Abdelhamid\nBouchachia. 2014. A survey on concept drift adaptation. ACM Comput. Surv.\n46, 4 (2014), 44:1â€“44:37.\n[15] Jian Gao, Xin Cao, Xin Yao, Gong Zhang, and Wei Wang. 2023. LMSFC: A\nNovel Multidimensional Index based on Learned Monotonic Space Filling\nCurves. Proc. VLDB Endow. 16, 10 (2023), 2605â€“2617.\n[16] Tu Gu, Kaiyu Feng, Gao Cong, Cheng Long, Zheng Wang, and Sheng Wang.\n2023. The RLR-Tree: A Reinforcement Learning Based R-Tree for Spatial Data.\nProc. ACM Manag. Data 1, 1, Article 63 (2023), 26 pages.\n[17] Antonin Guttman. 1984. R-Trees: A Dynamic Index Structure for Spatial\nSearching. In Proceedings of the 1984 ACM SIGMOD International Conference\non Management of Data (SIGMOD â€™84) . Association for Computing Machinery,\nNew York, NY, USA, 47â€“57.\n[18] Ali Hadian and Thomas Heinis. 2021. Shift-Table: A Low-latency Learned\nIndex for Range Queries using Model Correction. In Proceedings of the 24th\nInternational Conference on Extending Database Technology (EDBT) . OpenPro-\nceedings.org, 253â€“264.\n[19] Stratos Idreos, Martin L. Kersten, and Stefan Manegold. 2007. Database Crack-\ning. In 3rd Biennial Conference on Innovative Data Systems Research (CIDR) .\ncidrdb.org, 68â€“78.\n[20] Ibrahim Kamel and Christos Faloutsos. 1994. Hilbert R-tree: An Improved\nR-tree using Fractals. In Proceedings of 20th International Conference on Very\nLarge Data Bases (VLDB â€™94) . Morgan Kaufmann, San Mateo, CA, USA, 500â€“\n509.\n[21] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons\nKemper, Tim Kraska, and Thomas Neumann. 2020. RadixSpline: A Single-Pass\nLearned Index. In Proceedings of the Third International Workshop on Exploiting\nArtificial Intelligence Techniques for Data Management (aiDM@SIGMOD â€™20) .\nAssociation for Computing Machinery, New York, NY, USA, 5:1â€“5:5.\n[22] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe Case for Learned Index Structures. In Proceedings of the 2018 International\nConference on Management of Data (SIGMOD â€™18) . Association for Computing\n\nMachinery, New York, NY, USA, 489â€“504.\n[23] Jonathan K. Lawder and Peter J. H. King. 2000. Using Space-Filling Curves for\nMulti-dimensional Indexing. In Advances in Databases â€“ 17th British National\nConference on Databases, BNCOD 17 Exeter, UK, July 3-5, 2000 Proceedings .\nSpringer, Berlin, Heidelberg, 20â€“35.\n[24] Jure Leskovec and Andrej Krevl. 2014. SNAP Datasets: Stanford Large Network\nDataset Collection. http://snap.stanford.edu/data.\n[25] Scott T. Leutenegger, J. M. Edgington, and Mario Alberto LÃ³pez. 1997. STR: A\nSimple and Efficient Algorithm for R-Tree Packing. In Proceedings of the 13th\nInternational Conference on Data Engineering (ICDE) . IEEE, 497â€“506.\n[26] Jiangneng Li, Zheng Wang, Gao Cong, Cheng Long, Han Mao Kiah, and Bin\nCui. 2023. Towards Designing and Learning Piecewise Space-Filling Curves.\nProc. VLDB Endow. 16, 9 (2023), 2158â€“2171.\n[27] Pengfei Li, Hua Lu, Qian Zheng, Long Yang, and Gang Pan. 2020. LISA: A\nLearned Index Structure for Spatial Data. In Proceedings of the 2020 Inter-\nnational Conference on Management of Data (SIGMOD â€™20) . Association for\nComputing Machinery, New York, NY, USA, 2119â€“2133.\n[28] Moin Hussain Moti, Panagiotis Simatis, and Dimitris Papadias. 2022. Waffle:\nA Workload-Aware and Query-Sensitive Framework for Disk-Based Spatial\nIndexing. Proc. VLDB Endow. 16, 4 (2022), 670â€“683.\n[29] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020.\nLearning Multi-Dimensional Indexes. In Proceedings of the 2020 International\nConference on Management of Data (SIGMOD â€™20) . Association for Computing\nMachinery, New York, NY, USA, 985â€“1000.\n[30] JÃ¼rg Nievergelt, Hans Hinterberger, and Kenneth C. Sevcik. 1984. The Grid\nFile: An Adaptable, Symmetric Multikey File Structure. ACM Trans. Database\nSyst. 9, 1 (1984), 38â€“71.\n[31] Shoji Nishimura and Haruo Yokota. 2017. QUILTS: Multidimensional Data\nPartitioning Framework Based on Query-Aware and Skew-Tolerant Space-\nFilling Curves. In Proceedings of the 2017 ACM International Conference on\nManagement of Data (SIGMOD â€™17) . Association for Computing Machinery,\nNew York, NY, USA, 1525â€“1537.\n[32] OpenStreetMap 2017. OpenStreetMap. https://www.openstreetmap.org.\n[33] Sachith Pai, Michael Mathioudakis, and Yanhao Wang. 2022. Towards an\nInstance-Optimal Z-Index. In 4th International Workshop on Applied AI for\nDatabase Systems and Applications (AIDB â€™22) . 4 pages.\n[34] Varun Pandey, Alexander van Renen, Eleni Tzirita Zacharatou, Andreas Kipf,\nIbrahim Sabek, Jialin Ding, Volker Markl, and Alfons Kemper. 2023. Enhancing\nIn-Memory Spatial Indexing with Learned Search. CoRR abs/2309.06354 (2023).\narXiv:2309.06354\n[35] Mirjana Pavlovic, Darius Sidlauskas, Thomas Heinis, and Anastasia Ailamaki.\n2018. QUASII: QUery-Aware Spatial Incremental Index. In Proceedings of\nthe 21st International Conference on Extending Database Technology (EDBT) .\nOpenProceedings.org, 325â€“336.\n[36] Jianzhong Qi, Guanli Liu, Christian S. Jensen, and Lars Kulik. 2020. Effectively\nLearning Spatial Indices. Proc. VLDB Endow. 13, 11 (2020), 2341â€“2354.\n[37] Jianzhong Qi, Yufei Tao, Yanchuan Chang, and Rui Zhang. 2018. Theoretically\nOptimal and Empirically Efficient R-trees with Strong Parallelizability. Proc.\nVLDB Endow. 11, 5 (2018), 621â€“634.\n[38] Jianzhong Qi, Yufei Tao, Yanchuan Chang, and Rui Zhang. 2020. Packing\nR-trees with Space-filling Curves: Theoretical Optimality, Empirical Efficiency,\nand Bulk-loading Parallelizability. ACM Trans. Database Syst. 45, 3 (2020),\n14:1â€“14:47.\n[39] Raghu Ramakrishnan and Johannes Gehrke. 2003. Database Management\nSystems (3rd ed.). McGraw-Hill, New York, NY, USA.\n[40] Kenneth A. Ross, Inga Sitzmann, and Peter J. Stuckey. 2001. Cost-based\nUnbalanced R-Trees. In Proceedings of the 13th International Conference on\nScientific and Statistical Database Management (SSDBM) . IEEE, 203â€“212.\n[41] Timos K. Sellis, Nick Roussopoulos, and Christos Faloutsos. 1987. The R+-Tree:\nA Dynamic Index for Multi-Dimensional Objects. In Proceedings of 13th Inter-\nnational Conference on Very Large Data Bases (VLDB â€™87) . Morgan Kaufmann,\nSan Mateo, CA, USA, 507â€“518.\n[42] Herbert Tropf and Helmut Herzog. 1981. Multidimensional Range Search in\nDynamically Balanced Trees. Angew. Info. 2 (1981), 71â€“77.\n[43] Haixin Wang, Xiaoyi Fu, Jianliang Xu, and Hua Lu. 2019. Learned Index for\nSpatial Queries. In 2019 20th IEEE International Conference on Mobile Data\nManagement (MDM) . IEEE, 569â€“574.\n[44] Hongwei Wen and Hanyuan Hang. 2022. Random Forest Density Estimation.\nInProceedings of the 39th International Conference on Machine Learning . PMLR,\n23701â€“23722.\n[45] Zongheng Yang, Badrish Chandramouli, Chi Wang, Johannes Gehrke, Yinan Li,\nUmar Farooq Minhas, Per-Ã…ke Larson, Donald Kossmann, and Rajeev Acharya.\n2020. Qd-tree: Learning Data Layouts for Big Data Analytics. In Proceedings\nof the 2020 International Conference on Management of Data (SIGMOD â€™20) .\nAssociation for Computing Machinery, New York, NY, USA, 193â€“208.\n[46] Songnian Zhang, Suprio Ray, Rongxing Lu, and Yandong Zheng. 2021. SPRIG:\nA Learned Spatial Index for Range and kNN Queries. In Proceedings of the\n17th International Symposium on Spatial and Temporal Databases (SSTD â€™21) .\nAssociation for Computing Machinery, New York, NY, USA, 96â€“105.",
  "textLength": 75495
}