{
  "paperId": "d350caa058dac68e40df4958f5cc6fc4ed6ebc1c",
  "title": "Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency",
  "pdfPath": "d350caa058dac68e40df4958f5cc6fc4ed6ebc1c.pdf",
  "text": "Robustifying Learning-Augmented Caching Efficiently\nwithout Compromising1-Consistency\nPeng Chen1Hailiang Zhao1∗Jiaji Zhang1Xueyan Tang2\nYixuan Wang3Shuiguang Deng1∗\n1Zhejiang University2Nanyang Technological University\n3Nanjing University of Aeronautics and Astronautics\n{pgchen,hliangzhao,zhangjiaji,dengsg}@zju.edu.cn\nasxytang@ntu.edu.sg wangyixuan@nuaa.edu.cn\nAbstract\nThe online caching problem aims to minimize cache misses when serving a se-\nquence of requests under a limited cache size. While naive learning-augmented\ncaching algorithms achieve ideal 1-consistency, they lack robustness guarantees.\nExisting robustification methods either sacrifice1-consistency or introduce exces-\nsive computational overhead. In this paper, we introduce GUARD, a lightweight\nrobustification framework that enhances the robustness of a broad class of learning-\naugmented caching algorithms to 2Hk−1+ 2, while preserving their 1-consistency.\nGUARDachieves the current best-known trade-off between consistency and ro-\nbustness, with only O(1) additional per-request overhead, thereby maintaining\nthe original time complexity of the base algorithm. Extensive experiments across\nmultiple real-world datasets and prediction models validate the effectiveness of\nGUARDin practice.\n1 Introduction\nThe classicalcaching(orpaging) problem is a fundamental online optimization problem with\nwidespread applications in operating systems, web caching, and database management. It involves\nserving a sequence of npage requests using a cache of limited size k(1≤k≪ ∞ ). A request incurs\nzero cost if the corresponding page is already in the cache (cache hit); otherwise, acache missoccurs,\nrequiring the page to be loaded into the cache, possibly evicting another page to make space. The\nobjective is to minimize the total number of cache misses over the entire request sequence.\nCaching has been extensively studied in both deterministic and randomized settings. In the offline\nsetting where future requests are known, Belady [1]proposed the first optimal strategy,Belady’s\nrule, which evicts the page whose next request lies furthest in the future. In the online setting, where\nfuture requests are unknown, strong theoretical lower bounds exist. Specifically, no deterministic\nalgorithm can achieve a competitive ratio better than k[2], and no randomized algorithm can do\nbetter than Hk[3], where Hk=Pk\ni=11\niis the k-th harmonic number satisfying ln(k+ 1)≤H k≤\nln(k) + 1 . Several algorithms have been developed to approach these bounds: MARKER[ 3] achieves\na competitive ratio of 2Hk−1, while EQUITABLE[ 4] matches the optimal Hk, but at the cost of\nsignificantly higher time complexityO(k2)per request, limiting its practicality.\nRecent advances in machine learning have inspired a new paradigm:learning-augmented algorithms,\nwhich leverage predictive models to guide decision-making in online problems such as caching.\nThese algorithms aim to improve performance when predictions are accurate while remaining robust\nin the face of prediction errors. Their performance is typically evaluated using three key metrics:\n∗Corresponding authors:hliangzhao@zju.edu.cn,dengsg@zju.edu.cn\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).arXiv:2507.16242v7  [cs.DS]  1 Nov 2025\n\nconsistency,robustness, andsmoothness. Consistency measures the competitive ratio under perfect\npredictions; Robustness bounds the algorithm performance under arbitrary prediction errors, and\nsmoothness captures how the competitive ratio degrades as prediction errors increase.\nThis paper focuses on learning-augmented algorithm design for the classical caching problem, which\nlies at the intersection of machine learning and theoretical computer science. While the caching\nproblem itself is fundamental and pervasive in computer systems, our work demonstrates the potential\nfor safely integrating machine learning into cache systems.\n1.1 Related Work\nThe first learning-augmented caching algorithm is BLINDORACLE[ 5], which blindly follows pre-\ndictions by evicting the page predicted to be requested furthest in the future. While this yields ideal\n1-consistency (a competitive ratio of 1 under perfect predictions), the algorithm lacks robustness: it\ncan perform arbitrarily worse when predictions are inaccurate. This limitation has motivated a line of\nwork on robustification methods, which can be broadly categorized into two families.\nEmbedding-based methodsintegrate prediction-driven logic directly into classical caching algo-\nrithms like MARKER[ 3]. For instance, PREDICTIVEMARKER[ 5] modifies the original eviction\npolicy of MARKERbased on predictions and achieves 4Hk-robustness but not 1-consistency. Sub-\nsequently, LMARKER[ 6] improves smoothness and offers a (2Hk+ 4) -robustness bound with\n4-consistency. These algorithms derive their robustness from the marking mechanism inherent in\nMARKER, but this mechanism also restricts their ability to attain1-consistency.\nSwitching-based methodsswitch between learning-augmented and classical algorithms based on past\nperformance comparisons or the detection of prediction errors. For example, BLINDORACLE&LRU\n[7] switches between BLINDORACLEand LRU, following the currently better-performing one,\nand achieves 2k-robustness and 2-consistency. More recently, F&R and F&R (FITF) [ 8] switch\nfrom a non-robust learning-augmented algorithm to a robust one upon detecting prediction errors,\nachieving O(logk) -robustness and 1-consistency. However, both F&R and F&R (FITF) have a total\ncomputational overhead of O(n2logk) , as they require recomputing the optimal solution over the\nentire observed request sequence upon each cache miss, with each recomputation costing O(nlogk) .\nWe provide further related work in Appendix A, along with a comprehensive comparison of existing\nalgorithms in Appendix B. Overall, while prior methods have made progress in improving robustness,\nthey often do so at the cost of compromising 1-consistency or significantly increasing time complexity.\nThis leads to the central question of our work:Can we enhance the robustness of learning-augmented\ncaching algorithms in a time-efficient manner, without compromising1-consistency?\n1.2 Our Contributions\nA New Framework.We answer the above question affirmatively by introducing GUARD, a robus-\ntification framework applicable to any RB-following algorithm, which we formally define in Sec.\n3.2, a broad class of learning-augmented caching algorithms, including BLINDORACLE.Given\nan RB-following algorithmA,GUARD&Amaintains the original asymptotic time complexity2\nofAwhile achieving the trade-off between consistency and robustness: (1,2H k−1+ 2) , which is\nstate-of-the-art.\nGUARDintroduces a novel, lightweight phase-based mechanism for detecting prediction errors. In\ncontrast to switching-based methods, it avoids recomputing costly optimal solutions online and\nmonitoring the performance of alternative algorithms.\nNew Algorithms and Empirical Evaluation.We apply GUARDto three representative RB-following\nalgorithms, i.e., BLINDORACLE[ 5], LRB [ 9], and PARROT[ 10], each using a different type\nof prediction. All resulting variants achieve 1-consistency and (2Hk−1+ 2) -robustness, while\nmaintaining their original asymptotic time complexities. Extensive experiments show that GUARD-\nbased algorithms outperform existing methods and closely approach the state-of-the-art across a\nbroad range of benchmarks with both synthetic and real-world predictors. The combination of strong\ntheoretical guarantees and low runtime overhead underscores their value in practical applications.\n2In this paper, we focus on the algorithm’s time complexity, excluding the cost of predictor calls.\n2\n\n2 Preliminaries\nThe caching problem involves a universe of pages Pand a cache of size k. A sequence of page\nrequests σ:=r 1, r2, ..., r nmust be processed online. Each request riis a pair (ti, pi), where ti\ndenotes the time at which pi∈ P is requested. Upon receiving a request ri, the algorithm must\ndetermine whether the corresponding pagep iresides in the cache. If it does, the request results in a\ncache hit; otherwise, acache missoccurs, and the page must be loaded into the cache. If the cache is\nfull, an eviction decision must be made to accommodate the new page. The objective is to minimize\nthe total number of cache misses over the entire sequenceσ.\nAnonline algorithmmakes eviction decisions without knowledge of future requests, whereas an\noffline algorithmhas complete knowledge of the entire request sequence in advance. For any algorithm\nA, let A(σ) denote its cost when serving the sequence σ, defined as the number of cache misses\nincurred. In the case of randomized algorithms, we consider the expected cost. The performance of\nonline algorithms is typically evaluated using thecompetitive ratio. An algorithm Ahas competitive\nratioαif for every request sequenceσ, the following holds:\nA(σ)≤α·OPT(σ) +c(1)\nwhere OPT(σ) denotes the cost of an optimal offline algorithm, and cis a constant independent of\nthe input. In our algorithms, the additive constant cwill be zero. We also say that Aisα-competitive\nin this case. For brevity, we omitσwhen it is clear from the context.\nFor learning-augmented algorithms, the competitive ratio often takes the form min{γ+f(η), δ} ,\nwhich encapsulates key performance metrics such as consistency, robustness, and smoothness. The\nparameter γreflects the performance when predictions are perfect (i.e., η= 0 ), making the algorithm\nγ-consistent. The bound δensures that the performance never degrades beyond this factor, no matter\nhow inaccurate the predictions are, which defines δ-robustness. The function f(η) characterizes\nhow performance degrades with increasing total prediction error η, reflecting the notion of O(f(η)) -\nsmoothnesswhenγis constant.\n3 Algorithm Optimality and1-Consistency\nTo maintain 1-consistency during robustification, we begin by analyzing structural properties of opti-\nmal offline eviction policies and identifying a broad class of 1-consistent online learning-augmented\nalgorithms. Let OPT denote the optimal offline algorithm that follows Belady’s rule:evicting the\npage whose next request occurs furthest in the future.For each request ri= (t i, pi), letTidenote the\ntime of the next request for pagep iaftert i. Following Antoniadis et al. [11] and Song et al. [9], we\ndefine theBelady’s binary labely ias follows:\nyi=\u001a\n1if OPT evictsp ibeforeT i,\n0otherwise.(2)\nWe refer to the page pias a1-pageif yi= 1, and a0-pageif yi= 0. Note that a page may be a\n1-page at some times and a 0-page at others if it is loaded into the cache multiple times, depending on\nOPT’s eviction decisions. By default, we assume that OPT serves the entire request sequenceσ.\n3.1 RB-Compliant Algorithms\nBelady’s binary labeling naturally gives rise to a class of optimal algorithms that, although not\nnecessarily replicating the exact eviction decisions of OPT, still achieve optimal performance.\nThis is achieved through adherence to a principle we refer to as the relaxed Belady’s rule:prioritizing\nthe eviction of 1-pages over 0-pages whenever a cache replacement is necessary.\nDefinition 3.1.An algorithm is said to be RB-compliant if it adheres to the relaxed Belady’s rule.\nTo analyze the behavior of such algorithms, we define the following notation. Let the sets 1A\niand0A\ni\ndenote the sets of cached 1-pages and 0-pages, respectively, after algorithm A processes request ri.\nSimilarly, let 1∗\niand0∗\nidenote the corresponding sets for OPT. The following lemma provides a key\nstructural property of RB-compliant algorithms: while their eviction decisions may differ from those\nof OPT, they maintain the same set of 0-pages in the cache at all times.\n3\n\nLemma 3.2.For an RB-compliant algorithmA, we have |1A\ni|=|1∗\ni|and0A\ni=0∗\niafter serving\neach requestr i.\nProof.The proof is carried out by exhaustive case analysis. See Appendix C for details.\nThis result implies that an RB-compliant algorithm always caches at least one 1-page when a cache\nmiss occurs; otherwise, OPT would evict a 0-page at that time, contradicting the definition. Therefore,\nwe have the following corollary:\nCorollary 3.3.RB-compliant algorithms evict only 1-pages.\nThis ensures that RB-compliant algorithms match the performance of OPT exactly:\nProposition 3.4.RB-compliant algorithms are optimal, incurring the same cost asOPT.\nProof. Lemma 3.2 implies that an RB-compliant algorithm A maintains the same set of 0-pages\nas OPT at every step. Since 0-pages are precisely those pages that will be accessed again before\nany 1-page is needed, A incurs at least as many cache hits as OPT, and thus no more cache misses.\nTherefore, A is optimal.\nProposition 3.5 reveals a key property concerning the ordering of next request times.\nProposition 3.5.For an RB-compliant algorithmA, after serving each request ri, the next request\ntime of any page in1A\niis later than that of any page in0A\ni.\nProof. The proof follows from several observations about the relationship between the pages cached\nby A and OPT. See Appendix D for details.\n3.2 RB-Following Algorithms\nBuilding on the theory from the previous section, we now define a class of learning-augmented\nalgorithms based on the relaxed Belady’s rule. This class captures a wide range of learning-augmented\nalgorithms that are1-consistent.\nDefinition 3.6.A learning-augmented algorithm is said to be RB-following if it prioritizes evicting\n1-pages over 0-pages under perfect predictions.\nBy definition, an RB-following algorithm is RB-compliant when predictions are accurate. As a result,\nall conclusions and performance guarantees derived for RB-compliant algorithms in Sec. 3.1 apply\ndirectly to RB-following algorithms under perfect predictions. Consequently, we have:\nCorollary 3.7.RB-following algorithms are1-consistent.\nRB-following algorithms can leverage various types of predictions, including predicted next request\ntimes, Belady binary labels (as defined above), or even the optimal eviction choices made by OPT.\nSeveral representative learning-augmented algorithms are RB-following: BLINDORACLE[ 5] evicts\nthe page with the furthest predicted next request time; LRB [ 9] randomly selects a predicted 1-page\nfor eviction, prioritizing them over predicted 0-pages; PARROT[ 10] mimics the eviction decisions\nof OPT by evicting the page predicted to be requested furthest in the future (FitF). See Sec. 4.4 for\nfurther discussion of these algorithms. However, all the aforementioned RB-following algorithms\nfollow predictions blindly, leading to a critical drawback:poor robustness in the face of inaccurate\npredictions.Lemma 3.8 shows that such algorithms can incur unbounded competitive ratios.\nLemma 3.8.RB-following algorithms that blindly follow predictions have unbounded robustness.\nProof.The proof presents a simple adversarial case. See Appendix E for details.\nThis observation motivatesa robustification framework that preserves the 1-consistency of RB-\nfollowing algorithms while significantly enhancing their robustness.\n4\n\n4 GUARD: The Robustification Framework\n4.1 Insights and Overview\nWe now introduce GUARD, a general framework that robustifies RB-following algorithms by mitigat-\ning the impact of prediction errors while preserving their 1-consistency under accurate predictions.\nThe design of GUARDis grounded in three key observations as follows.\nObservation 1: Immediate protection hurts 1-consistency.Marking-based learning-augmented\ncaching algorithms, such as PREDICTIVEMARKER[ 5], LMARKER[ 6], and MARK&PREDICT[ 11],\nuse a fixed mechanism to protect pages from eviction immediately after they are requested. While\nthis method ensures bounded robustness, it may prevent necessary evictions that would otherwise be\njustified by accurate predictions. This observation motivates us to rethink the timing and conditions\nunder which protection is applied, rather than applying it uniformly after every access. In particular,\nwe aim to guard pages only when there is evidence of a prediction error, avoiding overprotection.\nObservation 2: Error detection must balance accuracy and efficiency.Many switching-based\nmethods detect prediction errors at runtime to switch between prediction-driven and robust fallback\npolicies. A common method, as used by BLINDORACLE&LRU and BLINDORACLE&MARKER\n[7], involves comparing the current total cost incurred by the prediction-based algorithm with that of\nthe fallback algorithm. However, this comparison is often insensitive: when the learning-augmented\nalgorithm underperforms relative to the classical one, the accumulated prediction errors can be large,\nas the classical algorithm (e.g., LRU) may perform significantly worse than OPT. Consequently, this\nintroduces a multiplicative factor of 2in the robustness guarantees. Alternatively, some methods, such\nas F&R and F&R (FITF) [ 8], detect prediction errors by explicitly recomputing the optimal solution\nover the observed request sequence up to the point of a cache miss, and checking whether the optimal\nsolution would also incur a miss. While this yields highly accurate error detection, its overhead\nis prohibitive for real-time use. This motivates an error detection mechanism that is lightweight,\nsensitive to errors that trigger cache misses, and practical for real systems.\nObservation 3: RB-compliant algorithms follow an intrinsic eviction pattern.Any RB-compliant\nalgorithm, including OPT, never retains an unrequested page in the cache during the time interval\nbetween the eviction and the next request of another page, revealing the underlying principle of\noptimal eviction decisions. We defer the proof to Appendix G. Formally, if a request riresults in\na cache miss at time ti, and the requested page piwas previously evicted at time µ < t i, then all\npages remaining in the cache at time timust have been requested at least once between µandti. This\nbehavior implies a kind ofcausal chainbetween evictions and requests, which motivates a way to\nidentify mispredictions without recomputing OPT directly.\nInspired by the above, GUARDselectively guards (i.e., protects) a requested page pifrom eviction\nonly when a prediction error is detected, thereby preserving 1-consistency under accurate predictions.\nThis mechanism ensures that pages that should be evicted before piare indeed evicted within the\nsame phase, maintaining bounded robustness even under poor predictions.\nAlgorithm 1 describes GUARD&A. Specifically, the execution of GUARDis divided intophases.\nAt the start of each phase, all cached pages are labeled as old and stored in a set U, which tracks\nunrequested old pages. A new phase begins when Ubecomes empty, indicating that all old pages\nhave either been requested or evicted. The period from the beginning of execution until the first\nreset of U(Line 8) is referred to asthe 0-th phase. When a cache miss occurs, if the requested\npage piwas previously evicted in the current phase (Line 10), this signals a potential prediction\nerror. In response, GUARDevicts a random unguarded page from Uand marks pias guarded,\npreventing it from being evicted until the next phase. Otherwise, A’s eviction policy is followed\nover the set of unguarded pages. This design leverages the intrinsic pattern of the optimal eviction\nbehavior (Observation 3) to detect meaningful mispredictions efficiently without costly recomputation\n(Observation 2), while avoiding immediate protection (Observation 1) and insensitive performance\ncomparisons (Observation 2).\nWe simplify A by omitting its specific eviction behavior and other auxiliary logic in Algorithm 1.\nThis is because, in essence, GUARDoperates as a companion process to A,running concurrently,\ndynamically restricting the set of eviction candidates (Line 14-15) or overridingA’s eviction policy\n(Line 11) when necessary.\n5\n\nAlgorithm 1GUARD&A\n1:U ← ∅(the set tracksunrequested old pagesin the cache)\n2:fori= 1, ..., ndo\n3:Receive a page requestr i= (t i, pi)at timet i\n4:ifp iis not in the cachethen\n5:ifthe cache is fullthen\n6:ifUis emptythen\n7:Unguard all cached pages\n8:U ← {all cached pages}(a new phase begins)\n9:end if\n10:ifp iwas evicted in the current phasethen\n11:Evict a pagexfromUuniformly at random\n12:Guardp i\n13:else\n14:S ← {all unguarded cached pages}\n15:Follow A’s policy to evict a pagexfromSbased on predictions\n16:end if\n17:ifthe evicted pagex∈ Uthen\n18:U ← U\\{x}\n19:end if\n20:end if\n21:Loadp iinto the cache\n22:end if\n23:ifp i∈ Uthen\n24:U ← U\\{p i}\n25:end if\n26:end for\n4.2 Preserving1-Consistency\nProposition 4.1.Under perfect predictions, no page will be guarded byGUARD&A.\nProof. Suppose, for contradiction, that a page pais the first page ever guarded by GUARD&A, and it\nis guarded at time tiupon a request for pa. Before ti, no pages have been guarded, so GUARD&A\nbehaves exactly like A up to this point. Consider the phase during whichp ais guarded.\nBy the algorithm’s logic, pamust have been evicted earlier in this phase, say, at time µ < t i.\nAccording to Corollary 3.3, pais a 1-page at time µ. At time ti, since pawas previously evicted,\nGUARD&A enters the error-handling branch (Lines 10–12), implying there exists an unrequested old\npagepb∈ U at time ti, whose next request occurs at time Tb> ti. Then, pbwas also a 1-page in the\ncache at timeµ, according to Proposition 3.5.\nNow consider an alternative algorithm, GUARD&B, behaves identically to GUARD&A before ti,\nexcept that it evicts pbinstead of paat time µ, keeping pain the cache until ti. Because both paand\npbare 1-pages at time µ, GUARD&B remains RB-compliant before tiunder perfect predictions. At\ntimeti, GUARD&B would experience a cache hit for pa, whereas OPT incurs a cache miss (since pa\nwas a 1-page at time µand was not accessed again until ti). Moreover, GUARD&B and OPT incur\nthe same number of cache misses before ti(see Proposition 3.4), implying GUARD&B performs\nbetter than OPT after serving requests up to timet i, which contradicts the optimality of OPT.\nTherefore, no suchp acan exist, and no page is ever guarded under perfect predictions.\nFrom Proposition 4.1, under perfect predictions, GUARD&A never guards any page and thus behaves\nidentically to A. Since A is 1-consistent by definition, GUARD&A inherits the following property:\nCorollary 4.2.For any RB-following algorithmA,GUARD&Ais 1-consistent.\n6\n\n4.3 Enhancing Robustness\nOur preliminary proof shows the O(logk) -robustness of GUARD&A. A more refined analysis (see\nAppendix J) tightens this bound to2H k−1+ 2.\nTo establish the robustness bound, we introduce several key notations. Let the final phase executed\nby GUARD&A be the Q-th phase and denote by Qthe set {0,1, ..., Q} . A page request riisdistinct\nwithin a phase if the requested page pihas not been previously requested during that phase. Let cq\ndenote the number of distinct new pages requested during theq-th phase.\nAmong the requests leading to evictions in the q-th phase, let nqdenote the number of requests\nfor new pages and oqdenote the number of requests for old pages. We decompose nqintonnew\nq,\nrepresenting the number of requests that cause the eviction of new pages, and nold\nq, representing the\nnumber of requests that result in the eviction of old pages. Therefore, we have nq=nnew\nq+nold\nq.\nThis notation allows us to precisely track the types of evictions occurring during each phase.\nThe following lemma gives a lower bound on the cost of OPT on sequence σ. Note that, in this paper,\nwe denote OPT(σ) by OPT for brevity.\nLemma 4.3.P\nq∈Q1\n2cq≤OPT≤P\nq∈Qnold\nq.\nProof. The proof builds on a phase-based analysis, following the approach of Fiat et al. [3]. See\nAppendix I for details.\nLemma 4.4.For eachq∈ Q,n q≤2c qandnold\nq≤cq.\nProof. Each distinct new page can be loaded into the cache at most twice per phase, as it becomes\nguarded upon its second request. Hence,n q≤2c q.\nIf a new page is loaded into the cache twice within a phase, it must be evicted by a request for another\nnew page before its second request. This is because, if a request for an old page results in a cache\nmiss, GUARD&A only evicts an old page from U. Thus, we have nq−cq≤nnew\nq, which implies\nnold\nq=nq−nnew\nq≤cq.\nTheorem 4.5.GUARD&AisO(logk)-robust.\nProof. We bound the number of evictions. In phase q, letnqbe the number of cache misses due to\nnew pages, and oqthose due to old pages. From Lemma 4.4, nq≤2c q. To upper bound oq, we make\nthe following assumptions, each of which can only increase the number of cache misses.\n1. The number of distinct old-page requests isk(the maximum possible).\n2. Allnold\nqevictions happen before requests for old pages.\n3. Evicted old pages have earlier next request times than remaining ones.\nOn each cache miss for an old-page request, an unrequested page from Uis evicted and the requested\npage is guarded. Let pjdenote the probability of a cache miss for the j-th subsequent distinct old\npage request. We have\npj=(\n1,if1≤j≤nold\nq,\nnold\nq\nk−(j−1),ifj > nold\nq.(3)\n7\n\nThe expected value ofo qis bounded as follows:\nE[oq]≤nold\nq+kX\nj=noldq+1min\b\npj,1\t\n= 2nold\nq+k−nold\nqX\nj=noldq+1nold\nq\nk−(j−1)\n=\u0010\n2 +H k−noldq−H noldq\u0011\nnold\nq\n≤\u0000\nHk+ 1\u0001\ncq.(by Lemma 4.4) (4)\nThe inequalities hold regardless of whether q < Q orq=Q . Let GAqdenote the number of cache\nmisses incurred by GUARD&A during the q-th phase. By (4), GUARD&A’s total expected cost\nE[GA]is bounded by:\nE[GA] =c 0+X\nq∈QE[GA q] =c 0+X\nq∈Q\u0000\nnq+E[o q]\u0001\n≤(H k+ 3)X\nq∈Qcq≤(2H k+ 6)OPT.(by Lemmas 4.3 and 4.4) (5)\nThis completes the proof.\nThe above assumptions simplify the proof and immediately yield logarithmic robustness, but in-\nevitably loosen the result. Theorem 4.6 presents a tight bound.\nTheorem 4.6.GUARD&Ais(2H k−1+ 2)-robust, which is tight.\nProof. The proof analyzes eviction chains that account for each eviction, without relying on any\nassumptions. See Appendix J for details.\n4.4 Applications\nWe apply GUARDto three RB-following algorithms: BLINDORACLE[ 5], LRB [ 9], and PARROT\n[10]. These algorithms are selected because they are representative and rely on predictors that are\npractical in implementation. However, as they blindly follow predictions, they are 1-consistent but\nnot robust. After being robustified via GUARD, each algorithm gains (2Hk−1+ 2) -robustness while\nretaining 1-consistency. Implementing GUARDincurs an O(1) overhead per request when using hash\ntables, so the time complexity remains asymptotically the same as that of the base algorithm.\nBLINDORACLE[ 5] evicts the page with the furthest predicted next request time (NRT), as detailed in\nAlgorithm 3 in Appendix F. LRB [ 9] is an algorithm that has been applied to content distribution\nnetwork caching. See Algorithm 4. It predicts Belady’s binary labels and prioritizes eviction of\npredicted 1-pages over predicted 0-pages, labeled by the OPT that starts from the current cache\ncontent of LRB and serves subsequent requests in σ. Note that LRB remains RB-following, as\nproven in Appendix H. PARROT[ 10] learns to imitate the optimal policy using a neural network\nmodel. See Algorithm 5 for details. It directly evicts the predicted FitF (furthest-in-the-future)\npage, where FitF follows the definition in Sadek and Elias [8]. GUARDis also applicable to more\nsophisticated RB-following algorithms that do not blindly follow predictions, which we leave as\nfuture work.\nTable 1: Robustified RB-following algorithms. B.O. stands for BLINDORACLE. NRT refers to the\nnext request time, while FitF stands for furthest-in-the-future.\nAlgorithm Prediction Consistency Robustness Smoothness Time Complexity\nGUARD&B.O. NRT1 2H k−1+ 2O(log(η t/OPT))O(nlogk)\nGUARD&LRB Binary1 2H k−1+ 2O(H k·ηb/OPT)O(n)\nGUARD&PARROTFitF Page1 2H k−1+ 2O(H k·ηf/OPT)O(n)\n8\n\nRefer to Table 1 for a summary, and to Appendix K for their pseudo-codes, smoothness proofs,\nand implementation details. ηt,ηb, and ηfare error measures for different types of predictions,\nrepresenting the total ℓ1error of predicted next request times, the number of incorrect predictions\nof Belady’s binary labels, and the number of incorrect predictions of FitF pages, respectively. A\ncomprehensive comparison of existing algorithms is provided in Table 4 in Appendix B.\n4.5 Achieving Better Smoothness with EXGUARD\nInspired by F&R [ 8] and ADAPTIVEQUERY-B[ 12], we explore how to trade off smoothness against\npredictor usage. The challenge lies in maintaining logarithmic robustness while adjusting the use\nof predictions. We propose an extension of GUARD, called EXGUARD, which allows for improved\nsmoothness at the cost of increased predictor usage. EXGUARDconstrains subsequent random evic-\ntions triggered by a misprediction-induced eviction, thereby avoiding excessive conservativeness and\nimproving smoothness. Meanwhile, EXGUARDmaintains1-consistency andO(logk)-robustness.\nThe learning-augmented algorithms in this paper invoke the predictor upon eviction, following com-\nmon implementations in prior caching systems [ 9,13,14]. GUARD&B.O. and GUARD&PARROT\ninvoke the predictor O(OPT) times, whereas EXGUARD&B.O. and EXGUARD&PARROTuse\nthe predictor O(d·OPT) times, where d∈[1, H k]. EXGUARD&BLINDORACLEachieves\nO\u0000\nmin(log(η t/OPT), λp\nηt/OPT)\u0001\n-smoothness, where λ=h/eh≤1/e . Here, h=H k/(2d) ,\nand thus h∈[1/2, H k/2]. EXGUARD&PARROTachieves O(H k/d·η f/OPT) -smoothness. Algo-\nrithms using EXGUARDare also included in Table 4 in the Appendix for comparison. In Appendix N,\nwe present a comprehensive introduction to EXGUARD, including its empirical results and formal\nproofs of the favorable trade-offs it achieves.\n5 Experiments\nWe now present a comprehensive evaluation of learning-augmented caching algorithms to assess their\nperformance under both synthetic and real-world predictions.\n5.1 Experimental Setup\nBuilding on the experimental frameworks of Liu et al. [10] and Chł˛ edowski et al. [15], we construct\nan expanded benchmark that includes more algorithm variants, datasets, and prediction types. We\nevaluate algorithms using three types of predictions:Next request times (NRT),Belady’s binary labels,\nandFitF page predictions. We also include F&R [8], whose action predictions can be derived from\npredicted next request times as demonstrated in Sadek and Elias [8]. For switching-based algorithms,\nwe follow Chł˛ edowski et al. [15], setting a deterministic switching bound of 1and a randomized\nweight β= 0.99 . Some algorithms are omitted due to either performance equivalence or excessive\ncomputational overhead.\nDatasets.We use BrightKite [ 16] and Citi [ 17], with cache sizes set to 10 and 100, respectively,\nfollowing Lykouris and Vassilvtiskii [5]. We further use SPEC CPU2006 memory traces [ 18] to\nevaluate real-world performance. Following Chł˛ edowski et al. [15] and Liu et al. [10], we adopt the\n16-way 2MB cache configuration for consistency.\nPredictions.We consider both synthetic and real predictors. For synthetic predictions, NRT and\nbinary label predictions are processed differently. To simulate NRT predictions, we add log-normal\nnoise to true request times. Pages without future requests are assigned a value of n+ 1 , where n\nis the number of requests. On the other hand, binary label predictions are generated by flipping\ntrue Belady labels with a given probability to simulate noisy prediction scenarios. For real-world\npredictors, we consider the following: (i) PLECO [ 19]: A probability-based predictor that estimates\nthe access likelihood pof a page and predicts its next request after 1/psteps; (ii) POPU [ 20]: A\nfrequency-based predictor that assumes a page requested in fraction pof past accesses will reappear\nafter1/psteps; (iii) LRB Predictor: Uses LightGBM [ 21] to predict next request times, then classifies\npages beyond the Belady boundary as predicted 1-pages and others as predicted 0-pages, consistent\nwith Song et al. [9].\n9\n\n5.2 Experimental Results\nAll cost ratios are reported relative to OPT. Figures 1 and 2 show algorithm performance under varying\nlevels of synthetic next request time (NRT) and binary prediction errors on the BrightKite dataset.\nBelow, we abbreviate BLINDORACLE(B.O.), LMARKER(LM.), LNONMARKER(LNONM.),\nPREDICTIVEMARKER(P.M.), and MARK&PREDICT(M.&P.). Due to differing interpretations of\nbinary labels, only synthetic results for M.&P. are included. Both GUARD&B.O. and GUARD&LRB\nexhibit empirical1-consistency and bounded robustness, aligning with theoretical guarantees.\n0 10 20 30 40 5011.11.21.31.41.5\nLog-normal noise parameterσ.Cost RatioLRU\nMARKER\nB.O.\nLM.\nLNONM.\nP.M.\nB.O.&M.D\nB.O.&M.R\nF&R\nGUARD&B.O.\nFigure 1: Performance with synthetic predic-\ntions of NRT on BrightKite.0 0.2 0.4 0.6 0.8 111.21.41.61.82\nProbability of flipping the true binary information.Cost RatioLRU\nMARKER\nLRB\nMARK0\nM.&P.\nGUARD&LRB\nFigure 2: Performance with synthetic predic-\ntions of binary labels on BrightKite.\nTable 2: Average cost ratios on SPEC CPU2006 using PLECO and POPU predictors.\nPredictorLRU B.O. LM. LNONM. P.M. B.O.&M.DF&R GUARD&B.O.\nPLECO 1.478 1.404 1.335 1.346 1.335 1.294 1.3601.226\nPOPU 1.478 1.261 1.320 1.312 1.312 1.233 1.3191.203\nTable 3: Average cost ratios on SPEC CPU2006 Benchmark using LRB predictor.\nPredictorLRU MARKERLRB MARK0 GUARD&LRB\nLRB predictor 1.478 1.394 1.281 1.2681.171\nWe further evaluate the algorithms on the SPEC CPU2006 benchmark using real-world predictors.\nAverage cost ratios across all 13 datasets are shown in Tables 2 and 3. B.O.&M.Ris omitted\ndue to inferior performance compared to B.O.&M.D. Results show that both GUARD&B.O. and\nGUARD&LRB achieve the lowest average cost ratios when using their respective predictors.\nAdditional results, including per-dataset performance and those using the “FitF page” predictor, are\npresented in Appendix M. We implement a new benchmark, Cache-Coliseum, for comprehensive\ncomparison of learning-augmented algorithms (including ours), which is publicly available at https:\n//github.com/OptiSys-ZJU/cache-coliseum.\n6 Conclusion\nIn this paper, we introduced GUARD, a framework designed to robustify learning-augmented caching\nalgorithms that follow the relaxed Belady’s rule. GUARDpreserves 1-consistency, improves robust-\nness to 2Hk−1+ 2, and incurs minimal additional computation, making it highly practical for real-\nworld applications. Experiments across multiple datasets and predictors show that GUARD&B.O.,\nGUARD&LRB, and GUARD&PARROTachieve the best or near-best performance. These results vali-\ndate the effectiveness of GUARDin enhancing both theoretical guarantees and empirical performance.\nOur results highlight the potential of lightweight robustification techniques for integrating machine\nlearning to enhance existing caching systems. Future research includes: (1) whether robustness and\nsmoothness can be further improved toward their respective theoretical lower bounds, as discussed\nin Appendix L, while still preserving 1-consistency and the asymptotic time complexity of the base\nalgorithm; and (2) exploring robust learning-augmented algorithms under other caching models that\narise in modern systems, as discussed in Appendix O, where, for example, the conventional constraint\nthat “the requested item is always stored” is relaxed.\n10\n\nAcknowledgments and Disclosure of Funding\nThis work was supported in part by the National Key Research and Development Program of China\nunder Grant 2022YFB4500100, the National Science Foundation of China (62125206, 62502441),\nthe Major Program of the National Natural Science Foundation of Zhejiang (LD25F020002), and the\nSingapore Ministry of Education under Academic Research Fund Tier 2 Award MOE-T2EP20122-\n0007 and Tier 1 Award RG23/23. Hailiang Zhao’s work was supported in part by the Zhejiang\nUniversity Education Foundation Qizhen Scholar Foundation.\nReferences\n[1]Laszlo A. Belady. A study of replacement algorithms for a virtual-storage computer.IBM\nSystems journal, 5(2):78–101, 1966.\n[2]Daniel D Sleator and Robert E Tarjan. Amortized efficiency of list update and paging rules.\nCommunications of the ACM, 28(2):202–208, 1985.\n[3]Amos Fiat, Richard M Karp, Michael Luby, Lyle A McGeoch, Daniel D Sleator, and Neal E\nYoung. Competitive paging algorithms.Journal of Algorithms, 12(4):685–699, 1991.\n[4]Dimitris Achlioptas, Marek Chrobak, and John Noga. Competitive analysis of randomized\npaging algorithms.Theoretical Computer Science, 234(1-2):203–218, 2000.\n[5]Thodoris Lykouris and Sergei Vassilvtiskii. Competitive caching with machine learned ad-\nvice. In Jennifer Dy and Andreas Krause, editors,Proceedings of the 35th International\nConference on Machine Learning, volume 80 ofProceedings of Machine Learning Research,\npages 3296–3305. PMLR, 10–15 Jul 2018. URL https://proceedings.mlr.press/v80/\nlykouris18a.html.\n[6]Dhruv Rohatgi. Near-optimal bounds for online caching with machine learned advice. In\nProceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages\n1834–1845. SIAM, 2020.\n[7]Alexander Wei. Better and Simpler Learning-Augmented Online Caching. In Jarosław Byrka\nand Raghu Meka, editors,Approximation, Randomization, and Combinatorial Optimization.\nAlgorithms and Techniques (APPROX/RANDOM 2020), volume 176 ofLeibniz International\nProceedings in Informatics (LIPIcs), pages 60:1–60:17, Dagstuhl, Germany, 2020. Schloss\nDagstuhl – Leibniz-Zentrum für Informatik. ISBN 978-3-95977-164-1. doi: 10.4230/LIPIcs.\nAPPROX/RANDOM.2020.60. URL https://drops.dagstuhl.de/entities/document/\n10.4230/LIPIcs.APPROX/RANDOM.2020.60.\n[8]Karim Ahmed Abdel Sadek and Marek Elias. Algorithms for caching and MTS with reduced\nnumber of predictions. InThe Twelfth International Conference on Learning Representations,\n2024. URLhttps://openreview.net/forum?id=QuIiLSktO4.\n[9]Zhenyu Song, Daniel S Berger, Kai Li, Anees Shaikh, Wyatt Lloyd, Soudeh Ghorbani,\nChanghoon Kim, Aditya Akella, Arvind Krishnamurthy, Emmett Witchel, et al. Learning\nrelaxed belady for content distribution network caching. In17th USENIX Symposium on\nNetworked Systems Design and Implementation (NSDI 20), pages 529–544, 2020.\n[10] Evan Liu, Milad Hashemi, Kevin Swersky, Parthasarathy Ranganathan, and Junwhan Ahn. An\nimitation learning approach for cache replacement. InInternational Conference on Machine\nLearning, pages 6237–6247. PMLR, 2020.\n[11] Antonios Antoniadis, Joan Boyar, Marek Eliás, Lene Monrad Favrholdt, Ruben Hoeksma, Kim S\nLarsen, Adam Polak, and Bertrand Simon. Paging with succinct predictions. InInternational\nConference on Machine Learning, pages 952–968. PMLR, 2023.\n[12] Sungjin Im, Ravi Kumar, Aditya Petety, and Manish Purohit. Parsimonious learning-augmented\ncaching. InInternational Conference on Machine Learning, pages 9588–9601. PMLR, 2022.\n11\n\n[13] Xinyue Hu, Eman Ramadan, Wei Ye, Feng Tian, and Zhi-Li Zhang. Raven: belady-guided,\npredictive (deep) learning for in-memory and content caching. InProceedings of the 18th\nInternational Conference on emerging Networking EXperiments and Technologies, pages 72–90,\n2022.\n[14] Zhenyu Song, Kevin Chen, Nikhil Sarda, Deniz Altınbüken, Eugene Brevdo, Jimmy Coleman,\nXiao Ju, Pawel Jurczyk, Richard Schooler, and Ramki Gummadi. {HALP }: Heuristic aided\nlearned preference eviction policy for {YouTube }content delivery network. In20th USENIX\nSymposium on Networked Systems Design and Implementation (NSDI 23), pages 1149–1163,\n2023.\n[15] Jakub Chł˛ edowski, Adam Polak, Bartosz Szabucki, and Konrad Tomasz ˙Zołna. Robust learning-\naugmented caching: An experimental study. In Marina Meila and Tong Zhang, editors,Pro-\nceedings of the 38th International Conference on Machine Learning, volume 139 ofPro-\nceedings of Machine Learning Research, pages 1920–1930. PMLR, 18–24 Jul 2021. URL\nhttps://proceedings.mlr.press/v139/chledowski21a.html.\n[16] Eunjoon Cho, Seth A. Myers, and Jure Leskovec. Friendship and mobility: user movement\nin location-based social networks. InProceedings of the 17th ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining, KDD ’11, page 1082–1090, New\nYork, NY , USA, 2011. Association for Computing Machinery. ISBN 9781450308137. doi:\n10.1145/2020408.2020579. URLhttps://doi.org/10.1145/2020408.2020579.\n[17] CitiBike. Citi bike system data. URLhttps://www.citibikenyc.com/system-data.\n[18] CRC. The 2nd Cache Replacement Championship, 2017., 2017. URL https://crc2.ece.\ntamu.edu/.\n[19] Ashton Anderson, Ravi Kumar, Andrew Tomkins, and Sergei Vassilvitskii. The dynamics of\nrepeat consumption. InProceedings of the 23rd international conference on World wide web,\npages 419–430, 2014.\n[20] Antonios Antoniadis, Christian Coester, Marek Eliáš, Adam Polak, and Bertrand Simon. Online\nmetric algorithms with untrusted predictions. pages 345–355, 2020.\n[21] Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and\nTie-Yan Liu. Lightgbm: a highly efficient gradient boosting decision tree. InProceedings of\nthe 31st International Conference on Neural Information Processing Systems, NIPS’17, page\n3149–3157, Red Hook, NY , USA, 2017. Curran Associates Inc. ISBN 9781510860964.\n[22] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. InProceedings of the 2018 international conference on management of data,\npages 489–504, 2018.\n[23] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predictions.\nAdvances in Neural Information Processing Systems, 31, 2018.\n[24] Antonios Antoniadis, Christian Coester, Marek Eliás, Adam Polak, and Bertrand Simon.\nLearning-augmented dynamic power management with multiple states via new ski rental\nbounds.Advances in neural information processing systems, 34:16714–16726, 2021.\n[25] Marina Drygala, Sai Ganesh Nagarajan, and Ola Svensson. Online algorithms with costly\npredictions. InInternational Conference on Artificial Intelligence and Statistics, pages 8078–\n8101. PMLR, 2023.\n[26] Hailiang Zhao, Xueyan Tang, Peng Chen, and Shuiguang Deng. Learning-augmented algorithms\nfor the bahncard problem.arXiv preprint arXiv:2410.15257, 2024.\n[27] Sungjin Im, Ravi Kumar, Mahshid Montazer Qaem, and Manish Purohit. Online knapsack\nwith frequency predictions.Advances in neural information processing systems, 34:2733–2743,\n2021.\n12\n\n[28] Ali Zeynali, Bo Sun, Mohammad Hajiesmaili, and Adam Wierman. Data-driven competitive\nalgorithms for online knapsack and set cover. InProceedings of the AAAI Conference on\nArtificial Intelligence, volume 35, pages 10833–10841, 2021.\n[29] Giulia Bernardini, Alexander Lindermayr, Alberto Marchetti-Spaccamela, Nicole Megow, Leen\nStougie, and Michelle Sweering. A universal error measure for input predictions applied to\nonline graph problems.Advances in Neural Information Processing Systems, 35:3178–3190,\n2022.\n[30] Evripidis Bampis, Bruno Escoffier, Themis Gouleakis, Niklas Hahn, Kostas Lakis, Golnoosh\nShahkarami, and Michalis Xefteris. Learning-augmented online tsp on rings, trees, flowers and\n(almost) everywhere else.arXiv preprint arXiv:2305.02169, 2023.\n[31] Alexander Lindermayr, Nicole Megow, and Bertrand Simon. Double coverage with machine-\nlearned advice.arXiv preprint arXiv:2103.01640, 2021.\n[32] Nicolas Christianson, Junxuan Shen, and Adam Wierman. Optimal robustness-consistency\ntradeoffs for learning-augmented metrical task systems. InInternational Conference on Artificial\nIntelligence and Statistics, pages 9377–9399. PMLR, 2023.\n[33] Paul Dütting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with\nadvice. InProceedings of the 22nd ACM Conference on Economics and Computation, pages\n409–429, 2021.\n[34] Kaito Fujii and Yuichi Yoshida. The secretary problem with predictions.Mathematics of\nOperations Research, 49(2):1241–1262, 2024.\n[35] Antonios Antoniadis, Hajo Broersma, and Yang Meng. Online graph coloring with predictions.\nInInternational Symposium on Combinatorial Optimization, pages 289–302. Springer, 2024.\n[36] Adela F DePavia, Erasmo Tani, and Ali Vakilian. Learning-based algorithms for graph searching\nproblems. InInternational Conference on Artificial Intelligence and Statistics, pages 928–936.\nPMLR, 2024.\n[37] Honghao Lin, Tian Luo, and David Woodruff. Learning augmented binary search trees. In\nKamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato,\neditors,Proceedings of the 39th International Conference on Machine Learning, volume 162\nofProceedings of Machine Learning Research, pages 13431–13440. PMLR, 17–23 Jul 2022.\nURLhttps://proceedings.mlr.press/v162/lin22f.html.\n[38] Thomas Erlebach, Murilo Santos de Lima, Nicole Megow, and Jens Schlöter. Learning-\naugmented query policies for minimum spanning tree with uncertainty.arXiv preprint\narXiv:2206.15201, 2022.\n[39] Magnus Berg, Joan Boyar, Lene M Favrholdt, and Kim S Larsen. Online minimum spanning\ntrees with weight predictions. InAlgorithms and Data Structures Symposium, pages 136–148.\nSpringer, 2023.\n[40] Hoda Torabi, Hamzeh Khazaei, and Marin Litoiu. A learning-based caching mechanism for\nedge content delivery. InProceedings of the 15th ACM/SPEC International Conference on\nPerformance Engineering, pages 236–246, 2024.\n[41] Akanksha Jain and Calvin Lin. Back to the future: Leveraging belady’s algorithm for improved\ncache replacement.ACM SIGARCH Computer Architecture News, 44(3):78–89, 2016.\n[42] Zhan Shi, Xiangru Huang, Akanksha Jain, and Calvin Lin. Applying deep learning to the cache\nreplacement problem. InProceedings of the 52nd Annual IEEE/ACM International Symposium\non Microarchitecture, pages 413–425, 2019.\n[43] Avrim Blum and Carl Burch. On-line learning and the metrical task system problem. In\nProceedings of the tenth annual conference on Computational learning theory, pages 45–53,\n1997.\n13\n\n[44] Lyle A McGeoch and Daniel D Sleator. A strongly competitive randomized paging algorithm.\nAlgorithmica, 6(1):816–825, 1991.\n[45] Gerth Stølting Brodal, Gabriel Moruz, and Andrei Negoescu. Onlinemin: A fast strongly\ncompetitive randomized paging algorithm.Theory of Computing Systems, 56:22–40, 2015.\n[46] Stéphane Ross, Geoffrey Gordon, and Drew Bagnell. A reduction of imitation learning and\nstructured prediction to no-regret online learning. InProceedings of the fourteenth interna-\ntional conference on artificial intelligence and statistics, pages 627–635. JMLR Workshop and\nConference Proceedings, 2011.\n[47] Nikhil Bansal, Niv Buchbinder, and Joseph Naor. A primal-dual randomized algorithm for\nweighted paging.Journal of the ACM (JACM), 59(4):1–24, 2012.\n[48] Zhihao Jiang, Debmalya Panigrahi, and Kevin Sun. Online algorithms for weighted paging with\npredictions.ACM Transactions on Algorithms (TALG), 18(4):1–27, 2022.\n[49] Nikhil Bansal, Christian Coester, Ravi Kumar, Manish Purohit, and Erik Vee. Learning-\naugmented weighted paging. InProceedings of the 2022 Annual ACM-SIAM Symposium on\nDiscrete Algorithms (SODA), pages 67–89. SIAM, 2022.\n[50] Thomas Anderson and Mike Dahlin.Operating Systems: Principles and Practice, Volume 3:\nMemory Management. Recursive Books, n.d. Available at https://www.kea.nu/files/\ntextbooks/ospp/osppv3.pdf.\n[51] Jim Gray and Andreas Reuter.Transaction processing: concepts and techniques. Elsevier,\n1992.\n[52] Gil Einziger, Roy Friedman, and Ben Manes. Tinylfu: A highly efficient cache admission policy.\nACM Transactions on Storage (ToS), 13(4):1–31, 2017.\n[53] Qilin Fan, Xiuhua Li, Jian Li, Qiang He, Kai Wang, and Junhao Wen. Pa-cache: Evolving\nlearning-based popularity-aware content caching in edge networks.IEEE Transactions on\nNetwork and Service Management, 18(2):1746–1757, 2021.\n14\n\nAppendix\nA Further Related Work\nLearning-Augmented Algorithms.The concept of learning-augmented algorithms was pioneered\nby Lykouris and Vassilvtiskii [5], who introduced the idea of integrating machine-learned predictions\ninto online decision-making frameworks. Since then, this paradigm has gained traction across a\nwide range of algorithmic domains, including index structures [ 22], ski rental problems [ 23,24],\nthe Bahncard problem [ 25,26], online knapsack [ 27,28], online TSP [ 29,30],k-server problems\n[31], metrical task systems (MTS) [ 20,32], secretary problems [ 33,34], graph-related tasks [ 35,36],\nand data structures [ 37–39]. These techniques have also found applications in broader system-level\ncontexts such as networking [9, 40] and caching [41, 42].\nLearning-Augmented Caching.Recently, there has been growing interest in applying learning-\naugmented methods to the caching problem. The first robust learning-augmented caching algorithm,\nPREDICTIVEMARKER, was proposed by Lykouris and Vassilvtiskii [5]. It achieves a competitive ratio\nofmin{2 + 2p\n4ηt/OPT+ 1,4H k}, where OPT is the optimal offline cost and ηtrepresents the\nl1-error of the prediction on next request times. This bound was later improved by Rohatgi [6], who\nintroduced LMARKER, achieving a smoothness guarantee of O(log(η t/OPT)) . The same work also\nproposed LNONMARKER, which offers superior smoothness but sacrifices bounded robustness. Wei\n[7]further improved the competitive ratio by proposing a simple approach to combine BLINDORACLE\nwith LRU, and proved its competitive ratio to be 2 min{1 + 2η t/OPT,4 + 4/(k−1)·η t/OPT, k} .\nWei[7]also combined BLINDORACLEwith the randomized algorithm EQUITABLE, and proved that\nits competitive ratio is (1 +γ) min{1 + 2η t/OPT,4 + 4/(k−1)·η t/OPT, H k}, plus an additive\nconstantO(k/γ), whereγ∈(0,1/4)is a trade-off parameter.\nAntoniadis et al. [20] studied the succinctness of the prediction. They show that it suffices to receive\npredictions of size O(logk) per request, indicating which page should be evicted. This was further\nsimplified by Antoniadis et al. [11], who demonstrated that binary predictions indicating whether\na cached page is expected to be evicted can still yield strong performance. This practical insight\ninspired our exploration of caching with binary predictions and led to the development of the GUARD\nframework based on this minimalistic form of side information.\nIm et al. [12] and Sadek and Elias [8]approached the problem differently, focusing on limiting the\nnumber of times predictions are used. Their work highlights the trade-off between the frequency\nof prediction queries and overall algorithmic performance, which is a consideration of particular\nrelevance in settings where acquiring predictions is costly or resource-intensive.\nB Comparative Analysis of Existing Algorithms\nTable 4 provides a comprehensive comparison of recent learning-augmented caching algorithms,\nfocusing on their performance guarantees and prediction requirements. Below, we analyze key\nalgorithmic paradigms and design principles that distinguish these approaches.\nPrediction Types.The literature explores various forms of predictions, each offering different levels\nof information and utility.\n1.Next Request Time Prediction.The most commonly used prediction type is the next request\ntime of a page, which is utilized by many existing algorithms, including BLINDORACLE[ 5],\nPREDICTIVEMARKER[5], LMARKER[6], and LNONMARKER[6].\n2.Binary Prediction.Binary predictions convey specific binary information and have been\nexplored both in systems [ 41,42] and theoretical studies [ 11]. For example, MARK0 predicts\nBelady’s binary labels to guide eviction decisions. MARK&PREDICTpredicts whether a\npage will be requested during a given phase, rather than estimating the exact request time.\n3.FitF (Furthest-in-the-Future) Page Prediction.Given the cache content, the predictor directly\nidentifies the cached page that will be requested furthest in the future. It is used by F&R\n(FitF) [8], and PARROT[9].\n15\n\nTable 4:Comparison of Learning-Augmented Caching Algorithms. Prediction typecat-\negorizes the algorithms listed in the first column, including NRT (Next Request Time), Bi-\nnary information (e.g., Belady’s binary label or whether a page will be accessed in the cur-\nrent phase), FitF (Furthest-in-the-Future page to be requested), and Action (e.g., cache content\nof an optimal offline algorithm).Abbreviationsinclude PREDICTIVEMARKER(P.M.), LNON-\nMARKER(LNONM.), LMARKER(LM.), BLINDORACLE(B.O.), EQUITABLE(EQ.), BLINDORA-\nCLE&MARKER(B.O.&M.), MARK&PREDICT(M.&P.), and PARROT(PA.). The superscripts D\nandRdenote deterministic switching and randomized switching, respectively. For B.O.&M.Rand\nB.O.&EQ.R,γ∈(0,1\n4)is a tunable trade-off parameter.Time.refers to the time complexity of the\nalgorithm, excluding the cost of making predictor calls. nis the total number of page requests. The\nlogk in the time complexity of algorithms using NRT predictions comes from selecting the page with\nthe furthest next request time.Cons.denotes consistency (i.e., the competitive ratio when predictions\nare perfect).Coefficients and constantspresented in robustness are mostly obtained directly from\nthe conclusions of the respective papers, while those for F&R and F&R (FITF) are derived from\ninequalities and may not be tight.Error measures ηt,ηb,ηa, andηfuse different units across differ-\nent prediction types, so their magnitudes are not directly comparable. For EXGUARD, d∈[1, H k].\nFor EXGUARD&B.O., λ=h/eh≤1/e , where h=H k/(2d) , and thus h∈[1/2, H k/2]. For F&R\n(FITF), parameterb∈ {1, ...,logk}.\nNRT Time. Cons. Robustness Smoothness\nP.M. [5]O(nlogk) 2 4H k O(p\nηt/OPT)\nLM. [6]O(nlogk) 4 2H k+ 4O(log(η t/OPT))\nLNONM. [6]O(nlogk) 4∞ O(log(k)/k·η t/OPT)\nB.O. [5]O(nlogk) 1∞ O(1/k·η t/OPT)\nB.O.&LRU [7]O(nlogk) 2 2kO(1/k·η t/OPT)\nB.O.&M.D[7]O(nlogk) 2 4H k−2O(1/k·η t/OPT)\nB.O.&M.R[7]O(nlogk) 1 +γ(1 +γ)(2H k−1) +O(k\nγ)O(1/k·η t/OPT)\nB.O.&EQ.R[7]O(nk2) 1 +γ(1 +γ)H k+O(k\nγ)O(1/k·η t/OPT)\nGUARD&B.O.O(nlogk) 1 2H k−1+ 2O(log(η t/OPT))\nEXGUARD&B.O.O(nlogk) 1 2H k−1+O(d)O(min(log(ηt\nOPT), λpηt\nOPT))\nBinary Time. Cons. Robustness Smoothness\nM.&P. [11]O(n) 2 4H k+O(1)O(H k·ηb/OPT)\nMARK0 [11]O(n) 1∞ O(H k·ηb/OPT)\nGUARD&LRBO(n) 1 2H k−1+ 2O(H k·ηb/OPT)\nEXGUARD&LRBO(n) 1 2H k−1+O(d)O(H k/d·η b/OPT)\nAction Time. Cons. Robustness Smoothness\nF&R [8]O(n2logk) 1 3(1 + logk) +O(1)O(log(η a/OPT))\nFitF Time. Cons. Robustness Smoothness\nF&R (FITF) [8]O(n2logk) 1 9(1 + 1/b) logk+O(b)O(log(k)/b·η f/OPT)\nGUARD&PA.O(n) 1 2H k−1+ 2O(H k·ηf/OPT)\nEXGUARD&PA.O(n) 1 2H k−1+O(d)O(H k/d·η f/OPT)\n4.Action Prediction.Introduced by Antoniadis et al. [20], action predictions have been\nprimarily used in metrical task systems (MTS). In caching, they indicate the cache contents\nof an optimal algorithm. F&R [ 8] is a recent example that leverages this type of prediction.\nDesign Principles.Below we compare the underlying designs of existing algorithms in detail.\n•Embedding-based methods integrate additional algorithmic logic directly into existing\ncaching algorithms to refine eviction strategies. For instance, PREDICTIVEMARKER[ 5]\nand LMARKER[ 6] refine eviction policies by leveraging eviction chains, i.e., a sequence\nof evictions where each eviction is triggered by a cache miss caused by a prior eviction.\nMARK&PREDICT[ 11] augments the MARKERalgorithm by incorporating binary predic-\ntions to prioritize certain pages for eviction. The MARKERframework marks a requested\npage and prohibits its eviction until the end of a phase. While embedding into MARKER\n16\n\nenables the aforementioned algorithms to achieve logarithmic robustness, this approach\ninherently limits the best achievable consistency to 2. This limitation arises because the\nMARKERframework prevents evicting some marked pages, even when OPT would prioritize\ntheir eviction.\nInstead, some algorithms adopt high-level principles from the MARKERframework without\nstrictly adhering to its structure. For example, LNONMARKER[ 6] and MARK0 [ 11] modify\nthe definition of phases. They both achieve1-consistency but have unbounded robustness.\n•Switching-based methods dynamically alternate between algorithms based on historical\nperformance or detected prediction errors. This approach was first introduced in the seminal\nwork of Fiat et al. [3]and later refined by Blum and Burch [43]. The algorithms proposed by\nWei[7]switch between a 1-consistent learning-augmented algorithm and a classical robust\nalgorithm. Their deterministic variant achieves a consistency of 2, while the randomized\nversion attains(1 +γ)-consistency forγ∈(0,1/4). Although(1 +γ)appears promising,\nthe competitive ratio of the randomized version includes a non-negligible constant term\nO(k/γ) , which degrades practical performance. Sadek and Elias [8]further refine switching-\nbased methods by adopting a more fine-grained approach. Unlike Wei [7], F&R [ 8] switches\nto a robust algorithm only when prediction errors are detected on the fly, thereby ensuring\n1-consistency. However, the detection mechanism is overly sensitive, resulting in high\nalgorithmic complexity of O(n2logk) . The key challenge of switching-based algorithms\nlies in determining the switching timing.\nC Proof of Lemma 3.2\nLemma 3.2.For any RB-compliant algorithmA, we have |1A\ni|=|1∗\ni|and0A\ni=0∗\niafter serving\neach requestr i.\nProof. The proof proceeds by induction. Suppose the cache becomes full for the first time after\nserving mpage requests. For any i= 1, ..., m , the lemma holds trivially, as no eviction occurs for\neither Aor OPT. Now assume that at time ti(i≥m ), the conditions |1A\ni|=|1∗\ni|and0A\ni=0∗\nihold.\nConsider the following two cases whenr i+1arrives at timet i+1:\nCase (i)p i+1∈0∗\ni. By hypothesis 0A\ni=0∗\ni, we have pi+1∈0A\ni. Since 0∗\niand0A\niare the sets of\ncached 0-pages for OPT and A, respectively, ri+1results in a cache hit for both Aand\nOPT.\n(a)Ifyi+1= 1,pi+1is a 1-page at this moment. Then 1∗\ni+1=1∗\ni∪ {p i+1}and\n1A\ni+1=1A\ni∪ {p i+1}. Since |1∗\ni|=|1A\ni|, it follows that |1∗\ni+1|=|1A\ni+1|. On the\nother hand,0∗\ni+1=0∗\ni\\ {pi+1}=0A\ni\\ {pi+1}=0A\ni+1.\n(b)Ifyi+1= 0,pi+1is a 0-page at this moment. Then 1∗\ni+1=1∗\niand1A\ni=1A\ni+1.\nThus,|1∗\ni+1|=|1∗\ni|=|1A\ni|=|1A\ni+1|. Similarly,0∗\ni+1=0∗\ni=0A\ni=0A\ni+1.\nCase (ii)p i+1/∈0∗\ni. Note that pi+1/∈1∗\nimust hold because OPT evicts 1-pages at some time\nbefore they are requested again. Since pi+1is neither in 0∗\ninor in 1∗\ni,ri+1results in a\ncache miss for OPT. By Belady’s rule, OPT evicts the page with the furthest next request\ntime, denoted asp x. This pagep xmust be a 1-page by definition, implying|1∗\ni|>0.\nThen we consider A. By hypothesis 0A\ni=0∗\ni, we have pi+1/∈0A\ni. By hypothesis\n|1A\ni|=|1∗\ni|, we have |1A\ni|>0 . Therefore, if ri+1results in a cache miss for A, it evicts\na 1-page from |1A\ni|, denoted as py; otherwise, ri+1results in a cache hit for A, indicating\npi+1∈1A\ni.\n(a)Ifyi+1= 1,pi+1is a 1-page at this moment. Then 1∗\ni+1=1∗\ni\\ {px} ∪ {p i+1}.\nFor A, |1A\ni+1|=|1A\ni|regardless of whether ri+1results in a cache hit or not for A.\nThus,|1∗\ni+1|=|1A\ni+1|. Moreover,0∗\ni+1=0∗\ni=0A\ni=0A\ni+1.\n(b)Ifyi+1= 0,pi+1is a 0-page at this moment. Then 1∗\ni+1=1∗\ni\\ {p x}and\n0∗\ni+1=0∗\ni∪ {p i+1}. For A, if ri+1results in a cache miss, 1A\ni+1=1A\ni\\ {p y}\nand0A\ni+1=0A\ni∪ {p i+1}; ifri+1results in a cache hit, 1A\ni+1=1A\ni\\ {pi+1}and\n0A\ni+1=0A\ni∪ {p i+1}. Thus,|1A\ni+1|=|1∗\ni+1|and0A\ni+1=0∗\ni+1always hold.\n17\n\nIn both cases, |1A\ni+1|=|1∗\ni+1|and0A\ni+1=0∗\ni+1, completing the induction. Additionally, we observe\nthat A experiences no more cache misses than OPT from the above analysis.\nD Proof of Proposition 3.5\nWe first establish three lemmas to facilitate the proof of Proposition 3.5.\nLemma D.1.For OPT, after serving each request ri, the next request time of any page in 1∗\niis later\nthan that of any page in0∗\ni.\nProof. Suppose that there exists a pair of 1-page a1and 0-page a0in the OPT’s cache such that the\nnext arrival time of a1is smaller than that of a0. That is to say, h1< h 0. Assume a1is evicted at\ntimeµ1, then µ1< h 1since a 1-page is evicted before it is requested again. a0is also cached at\ntimeµ1since µ1< h 1< h 0, and it will be kept cached before h0by the definition of 0-page. This\nimplies at the time µ1, OPT evicts a page whose next arrival time is not the largest, which contradicts\nthe definition.\nLemma D.2.For any algorithmA, after serving each requestr i,0A\ni⊆0∗\niholds.\nProof. Consider any 0-page pj∈0A\niat some time µ∈(t i, ti+1). Its last request occurs at time\ntj≤ti< µ, and its next request occurs at time Tj> µ. Immediately after its last request at tj,pj\nmust be in OPT’s cache, regardless of whether OPT experienced a cache hit or not at tj. Since pj\nis a 0-page, OPT will not evict it before Tj. Thus, at time µ, we have pj∈0∗\ni, which proves the\nlemma.\nFor OPT and an RB-compliant algorithm A, let H∗\niandHA\nidenote theordered setsof the next\nrequest times of 1-pages in 1∗\niand1A\niafter serving request ri, respectively, where the next request\ntimes are arranged in ascending order. We use H∗\ni(l)andHA\ni(l)to represent the l-th element in these\nordered sets.\nLemma D.3.For an RB-compliant algorithmA, after serving each request ri,|H∗\ni|=|HA\ni|and the\nfollowing holds:\n∀l= 1, ...,|H∗\ni|:H∗\ni(l)≤HA\ni(l).(6)\nProof. We prove this proposition by induction. Suppose the cache becomes full for the first time after\nserving mpage requests. The above inequalities hold trivially for any i= 1, ..., m , as no eviction\noccurs for either Aor OPT. Now assume that after serving request ri(i≥m ),|H∗\ni| ≤ |HA\ni|and(6)\nhold. We will show that they also hold after serving request ri+1. There are three cases to consider\nwhenr i+1arrives:\nCase (i)p i+1∈0A\ni. By Lemma D.2, pi+1∈0∗\nialso holds. Thus, ri+1results in a cache hit for\nboth A and OPT. Then, pi+1remains in 0A\ni+1and0∗\ni+1ifyi+1= 0. Otherwise, pi+1\nis moved to 1A\ni+1and1∗\ni+1for A and OPT, respectively. In both scenarios, |H∗\ni+1| ≤\n|HA\ni+1|and element-wise relationship (6) is maintained after servingr i+1.\nCase (ii)p i+1∈0∗\nibutpi+1/∈0A\ni. Since pi+1is a 0-page at this moment, pi+1/∈1A\nialso holds.\nBy Lemma D.2, we know that |0A\ni|<|0∗\ni|. Since |0A\ni|+|1A\ni|=k=|0∗\ni|+|1∗\ni|, we\nhave|1∗\ni|<|1A\ni|and|H∗\ni|<|HA\ni|. In this case, OPT experiences a cache hit while A\nsuffers a cache miss.\nConceptually, cache evolvement for serving request ri+1includes two steps: (i) since\nA is RB-compliant, it must evict a page from 1A\ni; (ii)pi+1’s next request time is either\ninserted to both H∗\ni+1andHA\ni+1(ifyi+1= 1) or none (if yi+1= 0). After these two\nsteps,|H∗\ni+1| ≤ |HA\ni+1|because |H∗\ni|<|HA\ni|before step (i), and step (ii) does not\nchange the relation between |H∗\ni+1|and|HA\ni+1|. Moreover, the element-wise relationship\n(6)continues to hold for i+ 1 . This is because step (i) removes an element from HA\ni,\nwhich can never decrease HA\ni(l)at any index l; and for step (ii), inserting the same\nelement to bothH∗\ni+1andHA\ni+1does not change the element-wise relation.\n18\n\nCase (iii)p i+1/∈0∗\ni. By Lemma D.2, we have pi+1/∈0A\ni. Note that pi+1/∈1∗\nimust hold because\nOPT evicts 1-pages at some time before they are requested again. Thus, OPT suffers a\ncache miss and evicts the 1-page with the furthest next request time from 1∗\ni. Meanwhile,\nA can experience either a cache miss or a cache hit.\n•If A experiences a cache hit, pi+1∈1A\niaspi+1/∈0A\ni. We can conceptually\nconsider cache evolvement as two steps: (i) OPT evicts the 1-page with the furthest\nnext request time from 1∗\ni, and A evicts pi+1from1A\ni; (ii)pi+1is either inserted\nto both 1∗\ni+1and1A\ni+1(ifyi+1= 1) or none (if yi+1= 0). After these two steps,\n|H∗\ni+1| ≤ |HA\ni+1|apparently holds because |H∗\ni| ≤ |HA\ni|before step (i). Moreover,\nstep (i) does not affect the element-wise relationship (6)because OPT evicts the\npage with the furthest next request time from 1∗\ni, i.e., removing the last element\nfromH∗\ni. For step (ii), inserting the same element to both H∗\ni+1andHA\ni+1does not\nchange the element-wise relation either. Therefore, (6) continues to hold fori+ 1.\n•If A suffers a cache miss, it just changes “A evicts pi+1from1A\ni” in step (i) above\nto be “A evicts a page from 1A\ni” since A is RB-compliant. All the above arguments\ncontinue to apply, so both |H∗\ni+1| ≤ |HA\ni+1|and the element-wise relationship (6)\nfori+ 1hold.\nBy induction, |H∗\ni| ≤ |HA\ni|and(6)hold for all i= 1, ..., n , where ndenotes the total number of\nrequests. This completes the proof.\nProposition 3.5.For an RB-compliant algorithmA, after serving each request ri, the next request\ntime of any page in1A\niis later than that of any page in0A\ni.\nProof. Suppose pxandpyare the 1-pages with the earliest next request times in 1A\niand1∗\ni, respec-\ntively. By Proposition D.3, the next request time of pxis not earlier than that of py. By Proposition\nD.1, the next request time of pyis later than any 0-page in 0∗\ni. Thus, the next request time of pxis\nalso later than any 0-page in 0∗\ni. Additionally, we have 0A\ni⊆0∗\niby Lemma D.2. Therefore, the next\nrequest time ofp xis later than any 0-page in0A\ni, completing the proof.\nE Proof of Lemma 3.8\nLemma 3.8.RB-following algorithms that blindly follow predictions have unbounded robustness.\nProof. Consider a cache of size 2, where at time t, pages paandpbare cached. From time tonward,\nan infinite sequence of alternating requests for pcandpbarrives. OPT incurs only one cache miss by\nevicting paupon the first request for pc, making paa 1-page and both pbandpc0-pages indefinitely.\nSuppose an RB-following algorithm Areceives completely incorrect predictions. If Ablindly trusts\nthe predictions, it may instead evict pbandpcalternately, resulting in an infinite number of cache\nmisses. Since OPT incurs only one miss, the competitive ratio of Ais unbounded, implying infinite\nrobustness.\nF RB-Following Algorithms that Blindly Follow Predictions\nAlgorithm 2 gives a template of RB-following algorithms that blindly follow predictions. Refer to\nSec. 3.2 for the definition of RB-following.\n19\n\nAlgorithm 2An RB-following algorithm that blindly follows predictions\n1:fori= 1, ..., ndo\n2:Receive the page requestr i= (t i, pi)at timet i\n3:ifp iis not in the cachethen\n4:ifthe cache is fullthen\n5:Call functionEvict()\n6:end if\n7:Loadp iinto the cache\n8:end if\n9:end for\nAlgorithm 3, 4, and 5 define the eviction functions of BLINDORACLE, LRB, and PARROT, re-\nspectively. They can be embedded into the template Algorithm 2 to restore the corresponding\nalgorithms.\nAlgorithm 3Evict()of BLINDORACLE\n1:Invoke the predictor to get the predicted next request times of cache pages\n2:Evict the page with the furthest predicted next request time\nAlgorithm 4Evict()of LRB\n1:Invoke the predictor to get the predicted Belady’s binary labels of cached pages\n2:ifthere is a predicted 1-pagethen\n3:Evict a predicted 1-page uniformly at random\n4:else\n5:Evict a predicted 0-page uniformly at random\n6:end if\nAlgorithm 5Evict()of PARROT\n1:Invoke the predictor to get the predicted FitF page\n2:Evict the predicted FitF page\nG Proof of Eviction Pattern of RB-Compliant Algorithms\nThe following theorem corresponds to Observation 3 in Section 4.1.\nTheorem G.1.For an RB-compliant algorithmA, it never keeps an unrequested page in the cache\nduring the time interval between the eviction and next request of another page. Formally, if a request\nriresults in a cache miss at time ti, and the requested page piwas previously evicted at time µ < t i,\nthen all pages remaining in the cache at time timust have been requested at least once between µ\nandt i.\nProof. Suppose, for contradiction, that there is a cached page pαat time tithat has not been requested\nsince time µ. Consider an alternative algorithm B, which behaves identically to A up to ti, except\nthat it evicts pαinstead of piat time µ, thereby keeping pαcached until ti. Algorithm B incurs the\nsame number of cache misses as A before time ti. However, at time ti, B experiences a cache hit,\nwhereas A incurs a cache miss due to the prior eviction of pi. This indicates that B outperforms A\nafter servingr i, contradicting the optimality of A, as established in Proposition 3.4.\nH Proof that GUARD&LRB is RB-following\nWe first show a general conclusion below.\nLemma H.1.If algorithmAis RB-following when serving {r1, ..., r j}, thenA&OPT (j)is RB-\nfollowing. Here, we define the following: (1)OPT(A, j) denotes theOPTalgorithm that begins\nwith the cache contentA ({r1, ..., r j})and serves the subsequent requests in σ, whereA ({r1, ..., r j})\n20\n\nrepresents the cache content ofAafter serving the first jrequests; (2)A&OPT (j)denotes the hybrid\nalgorithm that followsAwhen serving {r1, ..., r j}and then followsOPT (A, j) for the remaining\nsequence.\nProof. Since A is RB-following before serving rj+1, we have 0A\nj=0∗\njby Lemma 3.2 and Propo-\nsition 3.4, implying that OPT also incurs a cache miss at time tj+1and evicts a 1-page. Moreover,\n|1A\nj|=|1∗\nj|>0 . By Belady’s rule, at time tj+1, OPT (A, j) evicts the page with the furthest next\nrequest time, denoted as pα. By Proposition 3.5 and |1A\nj|>0 , we have pα∈1A\nj. This implies that\nA&OPT(j)is RB-following until servedr j+1as it prioritizes the eviction of 1-pages.\nTherefore, if algorithm A is RB-following when serving {r1, ..., r j}, then A&OPT (j)remains\nRB-following after serving rj+1. By induction, A&OPT( j) is RB-following for the entire request\nsequence, completing the proof.\nProposition H.2.LRBis RB-following.\nProof. Suppose LRB is RB-following when serving {r1, ..., r j}and incurs a cache miss when\nserving request rj+1. By Lemma H.1 and Corollary 3.3, LRB&OPT (j)is RB-following and always\nevicts only 1-pages under perfect predictions. Recall that LRB relies on predicted 1-pages labeled\nby the OPT that begins with the current cache content of LRB, which corresponds exactly to\nLRB&OPT( j). Consequently, under perfect predictions, all predicted 1-pages are 1-pages labeled by\nOPT. Therefore, LRB remains RB-following after serving rj+1. The proof follows by induction.\nI Proof of Lemma 4.3\nLemma 4.3.P\nq∈Q1\n2cq≤OPT≤P\nq∈Qnold\nq.\nProof. We first show OPT≤P\nq∈Qnold\nq. Assume an alternative algorithm GUARD&B that behaves\nidentically to GUARD&A except that, when serving requests for new pages, it evicts the nold\nqold pages\nwhose next request times are later than those of the remaining old pages. As a result, GUARD&B\nexperiences cache hits when the remaining old pages are requested. Note that at the end of the q-th\nphase, the cache content of GUARD&A is identical to that of GUARD&B. Clearly, the total cost of\nGUARD&B isP\nq∈Qnold\nq, implying that OPT≤P\nq∈Qnold\nq.\nNext, the proof of OPT≥P\nq∈Q1\n2cqfollows from Fiat et al. [3], though our phase definition differs\nfrom theirs.\nLetOPT qrepresent the number of cache misses incurred by OPT while processing the requests that\narrive during the q-th phase of GUARD&A. Let S∗\nqandSGA\nqdenote the sets of cached pages for OPT\nand GUARD&A, respectively, at the beginning of the q-th phase. Define hq(0≤q≤Q ) as the\nnumber of pages in OPT’s cache but absent in GUARD&A’s cache, i.e., hq=k− |S∗\nq∩ SGA\nq|. Note\nthath 0= 0.\nFirst, we claim that OPT q≥cq−hq. Among the cqdistinct new page requests in the q-th phase,\nat most hqof them may already reside in OPT’s cache. Hence, OPT incurs at least cq−hqcache\nmisses.\nNext, we show that OPT q≥hq+1. By definition, the pages in GUARD&A’s cache at the end of the\nq-th phase, SGA\nq+1, remain in the cache at the beginning of the (q+ 1) -th phase. Since OPT’s cache\nS∗\nq+1contains hq+1pages not present in SGA\nq+1, it follows that SGA\nq+1also contains hq+1pages that are\nabsent in S∗\nq+1. Moreover, since every cached page in SGA\nq+1is requested at least once during the q-th\nphase, OPT must have evicted at leasth q+1pages within the same phase.\nNote that the final phase ( Q-th phase) may not end after serving all requests. Thus, to be rigorous, we\ndenote hQ+1 as the number of pages that satisfy two conditions: (1) The page has been requested at\nleast once in the Q-th phase. (2) The page is in GUARD&A’s cache but absent in OPT’s cache after\n21\n\nserving all requests. Similarly, OPT must have evicted at least hQ+1 (hQ+1>0) pages within the\nsame phase.\nCombining the two inequalities, we have:\nQX\nq=0OPT q≥QX\nq=0max\u0010\ncq−hq, hq+1\u0011\n≥QX\nq=01\n2\u0010\ncq−hq+hq+1\u0011\n=QX\nq=01\n2cq−h 0+hQ+1\n≥QX\nq=01\n2cq(sinceh 0= 0, h Q+1≥0), (7)\nwhich completes the proof.\nJ A Tight Analysis of GUARD&A’s Robustness\nTheorem 4.6.GUARD&Ais(2H k−1+ 2)-robust, which is tight.\nProof.We adopt Lemma 4.3, Lemma 4.4, and notations from Sec. 4.3.\nAll evictions that occur during a given phase form an eviction graph. A directed edge (pα, pβ)is\nadded from page pαto page pβifpαis evicted upon the arrival of request rβ, which targets page pβ.\nAt a high level, the directed edge represents “evicted by”. Figure 3 illustrates an example of such\na graph consisting of multiple connected subgraphs. In the graph, edges with “pred.” and “rand.”\ndenote prediction-driven evictions and random evictions, respectively.\nnew new \nnew old old old new chain A (type 2) \nchain B (type 1) \nchain C (type 2) pred. pred. pred. \nrand. rand. \nold old old old old old \nold old old \npred. chain D (type 1) \nFigure 3: Eviction Graph\nThe number of edges in the eviction graph equals the number of evictions that occur during the phase.\nAccording to the definition of GUARD&A, an eviction graph has the following properties:\n1.The out-degree of any page is at most 1, as each page can be evicted no more than once\nwithin the phase under the “guard” mechanism.\n22\n\n2.The in-degree of each old page is at most 1, as it will be guarded after being loaded into the\ncache.\n3.The in-degree of each new page is at most 2, as it can be loaded into the cache at most twice.\nIn addition, a new page with an in-degree of 2 must have an out-degree of 1. It evicts a page\nbased on prediction upon its first cache miss, and a randomly selected old page upon its\nsecond cache miss.\n4.A new page can only point to (be evicted by) another new page (based on predictions), since\na request for an old page or a previously evicted new page only leads to the random eviction\nof an old page upon a cache miss.\n5.A page with an out-degree of 0 must be a new page, as an old page remains in the cache if it\nis not evicted during the phase.\nA chain that contains multiple old pages and a single new page is defined as an old-page eviction\nchain, such as chains A, B, C, and D in Figure 3. The following two conclusions hold regarding the\nlength of an old-page eviction chain, which is defined as the number of edges and depends on the\nchain type. We classify old-page eviction chains based on the first eviction.\n•Type 1:the request for the new page evicts an old page based on predictions. The expected\nlength of this type of chain is at mostH k−1+ 1.\nProof. Denote L(x) as the expected number of subsequent random evictions of old pages\nwhen the number of unrequested old pages in the cache is x. This implies that, subsequently,\nup toxold pages will be requested during this phase. Thus, we have\nL(x)≤1 +1\nxx−1X\ni=0L(i),(8)\nwhereL(0) = 0. Consequently,L(x)≤Px\ni=11\ni=H x.\nIn the worst case, the old page with the earliest next request time is evicted by the request\nfor the new page. Old pages are evicted randomly afterwards, so the expected length of the\nsub-chain is bounded byL(k−1) + 1 =H k−1+ 1.\n•Type 2:the request for the new page evicts an old page uniformly at random. The expected\nlength of this type of chain is at mostH k−1.\nProof. When the request for the new page evicts an old page randomly, at most k−1\nunrequested old pages remain in the cache, since the new page must have been evicted\npreviously. Thus, the expected length of the chain is at mostL(k−1) =H k−1.\nWithin a connected subgraph with xdistinct new pages, all new pages form a chain, according to\nProperties 1 and 4 stated above. Based on Property 3, at most one old-page-eviction chain of type 1\nandx−1 old-page-eviction chains of type 2 exist in the subgraph. See Figure 3 for an illustration.\nTherefore, the expected number of edges within this subgraph is at most Hk−1+ 1 + (x−1)H k−1+\n(x−1) =x(H k−1+ 1).\nBy Lemma 4.4, we know that the number of old-page eviction chains nold\nqis at most cq. This leads to\nthe following lemma directly.\nLemma J.1.At most cqold-page eviction chains exist in the eviction graph of phase q, where cq\ndenotes the number of distinct new pages requested during this phase.\nCombining the above conclusions, the expected number of evictions in phase qis at most cq(Hk−1+1).\nFinally, we derive an upper bound on the total cost of GUARD&A as follows.\nE[GA] =d 0+QX\nq=1E[GA q]≤(H k−1+ 1)QX\nq=0cq\n≤(2H k−1+ 2)OPT,(by Lemma 4.3) (9)\n23\n\nwhere both GUARD&A andOPT experience d0cache misses during the 0-th phase as no evictions\noccur. GUARD&A is(2H k−1+ 2)-robust, as established by (4.3).\nTightness.Consider the case where nqevictions occur at the beginning of the phase, evicting exactly\ncqold pages (i.e., nq=cq) whose next request times are earlier than the remaining old pages. In\nthis case, we can bound GUARD&A’s total cost GA as follows, where jdenotes the j-th subsequent\ndistinct old page request.\nE[GA] =c 0+QX\nq=1E[GA q] =c 0+QX\nq=1\u0010\nnq+E[o q]\u0011\n=c 0+QX\nq=1\u0010\nnq+cq+k−cqX\nj=cq+1cq\nk−(j−1)\u0011\n=c 0+QX\nq=1(2 +H k−cq−H cq)cq(sincen q=cq)\n≤c 0+QX\nq=1(Hk−1+ 1)c q.(equality holds ifc q= 1)\n(10)\nBy (10), we have\nlim\nQ→∞E[GA]≤X\nq∈Q(Hk−1+ 1)c q\n≤(2H k−1+ 2)OPT.(by Lemma 4.3) (11)\nWe now demonstrate that the equality in the final inequality (11) can indeed be achieved under the\nfollowing conditions, where all previously defined settings remain unchanged.\nLetwqdenote the only new page requested during phase q, implying that cq= 1. Consider the cache\ncontents of GUARD&A and OPT after all requests in phaseqhave been served:\n•GUARD&A: GUARD&A’s cache contains wqandk−1 old pages at the end of phase q.\nThis is because the request for wqevicts the old page with the earliest next request time,\nleading to subsequent random evictions of only old pages.\n•OPT: Assume that OPT’s cache content at the beginning of phase qmatches that of\nGUARD&A and that wqis never requested again after its next request. Following Belady’s\nrule, OPT evicts wqduring this phase. All subsequent old page requests result in cache hits.\nConsequently, at the end of phase q, OPT’s cache contains all old pages, with one old page\nnot being requested during phaseq. We denote this old page asu q.\nAs a result, at the start of phase q+ 1 ,uqresides in OPT’s cache but is absent from GUARD&A’s\ncache. Suppose uqserves as the only new page in phase q+ 1 , implying cq+1= 1, and is requested\nbefore any other page in phase q+ 1 . After serving requests to k−1 distinct old pages, phase q+ 1\nends. At this point, both OPT and GUARD&A once again have identical cache contents.\nThis construction enables repeated alternation between the behaviors in phases qandq+ 1 for all\nsubsequent phases. Notably, OPT incurs a total cost of 1 across phases qandq+ 1 , which equals\n(cq+cq+1)/2. Consequently, as this pair of phases repeats andQ→ ∞, we obtain:\nOPT=X\nq∈Q1\n2cq,\nthereby establishing the tightness of the bound in 5. This case confirms the tightness.\n24\n\nK Applications of GUARD\nK.1 Algorithm\nWe first present the pseudo-codes for the three variants of GUARD&A.\nAlgorithm 6GUARD&A\n1:U ← ∅(the set tracksunrequested old pagesin the cache)\n2:fori= 1, ..., ndo\n3:Receive a page requestr i= (t i, pi)at timet i\n4:ifp iis not in the cachethen\n5:ifthe cache is fullthen\n6:ifUis emptythen\n7:Unguard all cached pages\n8:U ← {all cached pages}(a new phase begins)\n9:end if\n10:ifp iwas evicted in the current phasethen\n11:Evict a pagexfromUuniformly at random\n12:Guardp i\n13:else\n14:S ← {all unguarded cached pages}\n15:Call functionEvict(S)\n16:end if\n17:ifthe evicted pagex∈ Uthen\n18:U ← U\\{x}\n19:end if\n20:end if\n21:Loadp iinto the cache\n22:end if\n23:ifp i∈ Uthen\n24:U ← U\\{p i}\n25:end if\n26:end for\nAlgorithms 7, 8, and 9 define the eviction functions of GUARD&BLINDORACLE, GUARD&LRB, and\nGUARD&PARROT, respectively. They can be embedded into Algorithm 6 to restore the corresponding\nalgorithms.\nAlgorithm 7Evict(S)of GUARD&BLINDORACLE\n1:Invoke the predictor to get the predicted next request times of pages inS\n2:Evict the page with the furthest predicted next request time fromS\nAlgorithm 8Evict(S)of GUARD&LRB\n1:Invoke the predictor to get the predicted Belady’s binary labels of pages inS\n2:ifthere is a predicted 1-pagethen\n3:Evict a predicted 1-page fromSuniformly at random\n4:else\n5:Evict a predicted 0-page fromSuniformly at random\n6:end if\nAlgorithm 9Evict(S)of GUARD&PARROT\n1:Invoke the predictor to get the predicted FitF page fromS\n2:Evict the predicted FitF page fromS\n25\n\nAll these algorithms invoke the predictor upon eviction, consistent with common implementations in\nreal systems. GUARD&A restricts the range of predictions only for unguarded pages in the cache,\ndenoted byS. Below, we present implementation details regarding the predictor queries.\n•GUARD&BLINDORACLErequires only the predicted next request times for pages in S,\nwhich is straightforward to implement since each prediction is independent.\n•GUARD&LRB utilizes the predicted Belady’s binary labels only for pages in S, as labeled\nby the OPT algorithm that begins with the current cache content and serving subsequent\nrequests in σwithout evicting pages outside of S. This is achieved by the LRB Predictor\n[9], which first predicts the next request times of pages in Sand then classifies them based\non the predicted Belady boundary.\n•GUARD&PARROTqueries the predictor for the FitF page within S, selected based on\nthe eviction priorities assigned by the FitF page predictor, a neural network-based model\nproposed by Liu et al. [10].\nK.2 Smoothness Proof for GUARD&BLINDORACLE\nWe first show the relationship between prediction errorη tand inversions, as studied by Rohatgi [6].\nDefinition K.1.(Inversion). Given two sequences A= (a 1, a2, ..., a n)andB= (b 1, ..., b n), let\ninv(A, B) be the number of inversions, which denotes the number of pairs of indices (i, j) such that\nai< ajbutb i> bj.\nDefinition K.2.( l1-distance). Given two sequences A= (a 1, ..., a n)andB= (b 1, ..., b n), we define\nl1(A, B) =nP\ni=1|ai−bi|as thel 1-distance between A andB.\nWe then present a lemma from Rohatgi [6], with its descriptive form slightly modified for clarity.\nLemma K.3.(Rohatgi [6], Lemma 4.1) Let A= (a 1, ..., a n)andB= (b 1, ..., b n)be two integer\nsequences. Then inv(A, B)≤2l 1(A, B), with inv(A)andl 1as defined above.\nNext, we relate ηtto the number of inversions. For a page request sequence σ, let their next request\ntime be θ={T 1, T2, ..., T n}, and let ˆθ={ ˆT1, ...,ˆTn}represent the predicted arrival times. By\ndefinition,η t=l1(θ,ˆθ). Then, by Lemma K.3, we have\ninv(θ, ˆθ)≤2l 1(θ,ˆθ) = 2η t (12)\nTheorem K.4.GUARD&BLINDORACLEisO(log(η t/OPT))-smooth.\nProof. In the following, we bound the expected length of an old-page eviction chain in phase q,\ncalledE q, according to the properties of the eviction graph (Figure 3). Denote|E q|as its length.\n•IfEqis a chain of type 1, which consists of a new page and multiple old pages, and the\nrequest for the new page evicts an old page based on predictions. Denote the new page\naspα. Let Uβbe the set of unrequested old pages when the old page pβ, which was\npreviously evicted at time µby the request for pα, is requested and a cache miss occurs.\nThis contributes at least I(Eq) =|U β|inversions, since each pair of pβand a page in Uβ\nindicates an inversion in predictions at timeµ.\nAccording toL(x)≤H xin Appendix J, we haveE[|E q|]≤ O(logI(E q)).\n•IfEqis a chain of type 2, which consists of a new page and multiple old pages, and the\nrequest for the new page pαrandomly evicts an old page. Its new page pαmust be previously\nevicted by another new page pγ, aspαmust have an in-degree of 2 and an out-degree of 1 in\nthe eviction graph, according to Property 3 mentioned in Appendix J. Let Uαbe the set of\nunrequested old pages when the new page pβis requested. Each pair of pαand a page in Uα\nindicates an inversion in predictions when evicting pα. Similarly, this chain contributes at\nleastI(E q) =|U α|inversions, and we haveE[|E q|]≤ O(logI(E q)).\n26\n\nThe total inversions inv(θ, ˆθ)≥P\nq∈QP\nEqI(Eq). Suppose there are a total of Nold-page eviction\nchains across all phases, whereN=P\nq∈QP\nEq1 =P\nq∈Qnold\nqby definition. By Lemma 4.3, we have\nOPT≤N=X\nq∈Qnold\nq≤X\nq∈Qcq≤2OPT.(13)\nGUARD&BLINDORACLE’s expected total costE[G&B]is:\nE[G&B]≤X\nq∈Q\u0000\ncq+X\nEqE[|Eq|]\u0001\n≤X\nq∈Qcq+X\nq∈QX\nEqO(logI(E q))(by Lemma 4.3)\n≤X\nq∈Qcq+N· O(log(inv(θ, ˆθ)\nN))(by Jensen’s inequality and concavity)\n≤2OPT+ 2OPT· O(log(ηt\nOPT))(by (13) and Lemma K.3)\n=O(OPT·log(ηt\nOPT)).(14)\nThis demonstrates theO(log(η t/OPT))-smoothness of GUARD&BLINDORACLE.\nK.3 Smoothness Proof for GUARD&LRB\nWe first present a key lemma that helps establish smoothness. We denote OPT (A, j) as the OPT\nalgorithm that begins with the cache content A ({r1, ..., r j})and serves the subsequent requests in σ\nwithout evicting guarded pages. Here, A ({r1, ..., r j})represents the cache content of A after serving\nthe firstjrequests.\nLemma K.5.When serving request rj+1at time ti+1, ifGUARD&LRBevicts a 1-page px(as\nlabeled byOPT(A,j)), then the current phase must terminate beforep xis requested again.\nProof. Suppose OPT(A, j) evicts page pxat time µ > t i+1. By definition, pxis the page with the\nfurthest next request time at time µ. LetTxdenote the next request time of px. This implies that the\nremainingk−1pages in the cache at timeµwill all be requested beforeT x.\nWhenever one of these remaining pages, sayp α, is requested after timeµ, if it results in a cache hit,\nthenpα/∈ UorU=U \\ {p α}. Otherwise, if a cache miss occurs, GUARD&LRB evicts a random\npage from U. Therefore, after evicting pxand serving requests for all of these k−1 pages, the current\nphase must terminate.\nTheorem K.6.GUARD&LRBisO(H k·ηb/OPT)-smooth.\nProof. According to the description of GUARD&LRB provided in Section K.1, there is at least one\n1-page in the set of unguarded pages Supon a cache miss. Otherwise, the OPT algorithm, starting\nfrom the current cache content, would have to evict a 0-page from S, contradicting the definition of\nBelady’s binary labels. Thus, the algorithm always evicts a 1-page when predictions are accurate\nupon a cache miss.\nAccording to the properties of the eviction graph (Figure 3), each old-page eviction chain results\nfrom a unique prediction-driven eviction. By Lemma K.5, evicting a 1-page leads to no subsequent\nevictions. Thus, given a prediction error of ηb, the total expected length of all old-page eviction\nchains is at mostO(H k·ηb), where each chain has length at mostO(H k)as shown in Appendix J.\nO(H k·ηb)also bounds the expected total cost of GUARD&LRB, thereby completing the proof.\nK.4 Smoothness Proof for GUARD&PARROT\nTheorem K.7.GUARD&PARROTisO(H k·ηf/OPT)-smooth.\n27\n\nProof. According to the properties of the eviction graph (Figure 3), each incorrect prediction of a\nFitF page leads to either (1) the eviction of an old page, which subsequently generates an old-page\neviction chain of type 1, or (2) the eviction of a new page, which subsequently generates an old-page\neviction chain of type 2.\nTherefore, given a prediction error of ηf, there are at most ηfold-page eviction chains in the eviction\ngraphs across all phases. From Appendix J, the expected length of an old-page eviction chain is at\nmostO(H k). Thus, we can bound the expected total cost of GUARD&PARROT, denoted E[G&P] , as:\nE[G&P]≤ O(H k·ηf),(15)\nwhich completes the proof.\nL Lower Bounds\nRobustness.No randomized learning-augmented can achieve robustness better than Hk, which\nis the lower bound of randomized online caching algorithms [ 3]. To the best of our knowledge,\nexisting online algorithms that achieve Hkcompetitive ratio include EQUITABLE [ 4], PARTITION\n[44], ONLINEMIN[ 45], among which ONLINEMINhas the lowest asymptotic time complexity\nand uses O(logk) time per request (or O(logk/log logk) in the RAM model). Thus, we may be\nable to further enhance the consistency/robustness trade-off of the robustification framework to\n(1, H k+O(1)), at the expense of more thanO(1)additional computation per request.\nSmoothness.Rohatgi [6]demonstrates that for a randomized learning-augmented caching al-\ngorithm utilizing next request time (NRT) predictions, the smoothness cannot be better than\nO(log(1/(klogk)·η t/OPT)) . To the best of our knowledge, no existing algorithm has achieved\nthis bound. At the same time, whether improving smoothness to approach this bound compromises\n1-consistency or bounded robustness remains an open problem.\nM More Experimental Results and Discussions\nM.1 Experiments on Brightkite and Citi Using PLECO and POPU\nWe evaluate algorithms that utilize page request time predictions on the BrightKite and Citi datasets\nusing PLECO and POPU, two widely adopted predictors in this domain [ 5,20,8]. For F&R,\npredictions of page request times are converted into action predictions, following the methodology of\nSadek and Elias [8]. Table 5 presents the cost ratios of different algorithms. The results indicate that\nGUARD&B.O. consistently achieves the best or near-best performance.\nTable 5: Cost ratios of algorithms on BrightKite and Citi using PLECO and POPU predictors.\nDataset PredictorB.O. P.M. LM. LNONM. B.O.&M.DF&R GUARD&B.O.\nBrightKitePLECO 2.081 1.341 1.337 1.321 1.317 1.3481.303\nPOPU 1.707 1.262 1.264 1.259 1.305 1.3041.198\nCitiPLECO 2.277 1.877 1.875 1.8881.8601.864 1.900\nPOPU 1.739 1.776 1.779 1.769 1.732 1.7901.693\nM.2 Experiments on SPEC CPU2006 Benchmark Using PLECO and POPU\nTo evaluate the performance of algorithms that utilize predictions of page request times in a more\nrealistic scenario, we employ real-world memory trace datasets from the SPEC CPU2006 benchmark,\nfollowing the setup of Chł˛ edowski et al. [15].\nAverage Cost Ratios.Table 6 presents the average cost ratios of various algorithms relative to OPT\nacross all 13 datasets. The results indicate that GUARD&B.O. achieves the best overall performance\non average.\n28\n\nTable 6: Average cost ratios on SPEC CPU2006 Benchmark using PLECO and POPU predictors.\nPredictorLRU B.O. P.M. LM. LNONM. B.O.&M.DF&R GUARD&B.O.\nPLECO1.478 1.404 1.335 1.335 1.346 1.294 1.3601.226\nPOPU1.478 1.261 1.312 1.320 1.312 1.233 1.3191.203\nLRU-normalized Cost Ratios and Figures.To ensure clear comparisons across different datasets,\nwe adopt the LRU-normalized empirical competitive ratio from Chł˛ edowski et al. [15], referred to as\nthe LRU-normalized cost ratio (LCR) in this study. LCR evaluates an algorithm ALG in relation to\nLRU, and is defined as follows:\nLCR(ALG) =ALG−OPT\nLRU−OPT.\nThe average LRU-normalized cost ratios across all 13 datasets are summarized in Table 7, while\nFigures 4 and 5 provide a dataset-wise performance breakdown. These results further validate\nthat GUARD&B.O. consistently outperforms other methods or remains among the best-performing\nalgorithms.\nTable 7: Average LRU-normalized cost ratios on SPEC CPU2006 Benchmark using PLECO and\nPOPU predictors.\nPredictorLRU B.O. P.M. LM. LNONM. B.O.&M.DF&R GUARD&B.O.\nPLECO1 1.050 0.947 0.943 0.926 0.763 0.8450.625\nPOPU1 0.768 0.881 0.885 0.880 0.664 0.8290.568\nastar\nbwavesbzip\ncactusadmgems lbm\nleslie3dlibq mcf milc\nomnetpp sphinx3xalancOPT0.20.40.60.8LRU1.21.41.61.82.02.22.4LRU-Normalized Cost Ratio\nMARKER B.O. P.M. LM. LNONM.\nB.O.&M.DB.O.&M.RF&R GUARD&B.O.\nFigure 4: LRU-normalized cost ratios on SPEC CPU2006 Benchmark using the PLECO predictor.\nM.3 Experiments on SPEC CPU2006 Benchmark Using LRB predictor\nIn this section, we evaluate the performance of algorithms leveraging binary predictions of Be-\nlady’s binary labels on datasets from the SPEC CPU2006 benchmark, using LRB predictor. The\nalgorithm MARK&PREDICT(M.&P.) is excluded from this comparison, as it employs a different\ninterpretation of predicted binary labels. In addition, we implement LRB&MARKERD(LRB&M.D)\n29\n\nastar\nbwavesbzip\ncactusadmgems lbm\nleslie3dlibq mcf milc\nomnetpp sphinx3xalancOPT0.20.40.60.8LRU1.21.41.61.8LRU-Normalized Cost Ratio\nMARKER B.O. P.M. LM. LNONM.\nB.O.&M.DB.O.&M.RF&R GUARD&B.O.\nFigure 5: LRU-normalized cost ratios on SPEC CPU2006 Benchmark using the POPU predictor.\nand LRB&MARKERR(LRB&M.R), which combine LRB with MARKERusing deterministic and\nrandomized switching, respectively, following the switching-based approach introduced by Wei [7].\nFollowing the methodology of Song et al. [9], we extract features from the SPEC CPU2006 datasets,\nsetting |Delta i|= 10 and|EDC i|= 10 . In addition to the original PC and address features, a total\nof 22 features were used for training. The GBM model is configured with a learning rate of 0.01,\na maximum depth of 6, and 31 leaves. Both the sub-sample rate and column sample rate are set to\n0.8. The model employs L2-norm loss, and early stopping is applied at 8000 rounds to determine the\noptimal parameters.\nAverage Cost Ratios.Table 8 presents the average cost ratios of all evaluated algorithms relative\nto OPT across all 13 datasets. The results show that GUARD&LRB outperforms other algorithms,\nincluding the base algorithm LRB.\nTable 8: Average cost ratios on SPEC CPU2006 Benchmark using LRB predictor.\nPredictorLRU MARKERLRB MARK0 LRB&M.DLRB&M.RGUARD&LRB\nLRB predictor 1.478 1.394 1.281 1.268 1.259 1.2931.171\nLRU-normalized Cost Ratios and Figure.Table 9 and Figure 6 show the LCR comparison when\nusing GBM.\nTable 9: Average LRU-normalized cost ratios on SPEC CPU2006 Benchmark using LRB predictor.\n–PredictorLRU MARKERLRB MARK0 LRB&M.DLRB&M.RGUARD&LRB\nLRB predictor 1 0.970 0.809 0.506 0.714 0.8080.357\n30\n\nastar\nbwavesbzip\ncactusadmgems lbm\nleslie3dlibq mcf milc\nomnetpp sphinx3xalancOPT0.20.40.60.8LRU1.2Normalized Cost Ratio\nMARKER LRB MARK0 LRB&M.DLRB&M.RGUARD&LRB\nFigure 6: LRU-normalized cost ratios on SPEC CPU2006 Benchmark using LRB predictor.\nM.4 Experiments on SPEC CPU2006 Benchmark Using Parrot\nFitF page predictor.We investigate Parrot, a neural network-based model proposed by Liu et al.\n[10], which utilizes an imitation learning approach to approximate the optimal policy. Built on LSTM\nand attention mechanisms, Parrot predicts the page with the highest eviction priority whenever an\neviction is needed. In our experiments, Parrot is trained for 20,000 steps with a batch size of 32,\nwithout applying the Dagger algorithm [46].\nThe Algorithm PARROT.We propose PARROT(abbreviated as PA.), which directly follows\nthe prediction of the Parrot model and evicts the predicted FitF page. PARROTis also an RB-\nfollowing algorithm that blindly follows predictions. It is clear that PARROTis 1-consistent, while\nGUARD&PARROT(abbreviated as GUARD&PA.) is (2Hk−1+ 2)-robust. Additionally, we imple-\nment PARROT&MARKERDand PARROT&MARKERR, which combine PARROTwith MARKER\nusing deterministic and randomized switching, respectively, following the switching-based approach\nintroduced by Wei [7].\nInterestingly, the best algorithms for the two metrics differ due to their different calculations. Nonethe-\nless, GUARD&PARROTconsistently achieves either the best or near-best performance.\nAverage Cost Ratios.Table 10 shows the average cost ratios of algorithms compared to OPT across\nall 13 datasets.\nTable 10: Average cost ratios on SPEC CPU2006 Benchmark using the FitF page predictor.\nPredictorLRU MARKERPA. PA.&M.DPA.&M.RGUARD&PA.\nFitF page predictor 1.478 1.394 1.3631.3151.348 1.338\nLRU-normalized Cost Ratios and Figure.Table 11 and Figure 7 show the LCR comparison.\nTable 11: Average LRU-normalized cost ratios on SPEC CPU2006 Benchmark using the FitF page\npredictor.\nPredictorLRU MARKERPA. PA.&M.DPA.&M.RGUARD&PA.\nFitF page predictor 1 0.970 1.006 0.851 0.9470.816\n31\n\nastar\nbwavesbzip\ncactusadmgems lbm\nleslie3dlibq mcf milc\nomnetpp sphinx3xalancOPT0.20.40.60.8LRU1.21.41.61.8LRU-Normalized Cost Ratio\nMARKER PA. PA.&M.DPA.&M.RGUARD&PA.\nFigure 7: LRU-normalized cost ratios on SPEC CPU2006 Benchmark using the FitF page predictor.\nN The EXGUARDFramework\nN.1 Motivation and Performance Overview\nObservation.Essentially, the bounded robustness of GUARD&A stems from page protection, i.e.,\nthe guard mechanism. Its asymptotic logarithmic robustness depends on random evictions when\nnecessary. However, overly aggressive random evictions may lead to a long eviction chain initiated by\nan eviction based on incorrect predictions, thereby degrading smoothness. Conversely, relying solely\non predictions compromises robustness and may be impractical due to frequent predictor queries.\nThis motivates limiting the number of random evictions (Line 13 in Algorithm 10) on each eviction\nchain, as illustrated in Figure 8. This strikes a balance between smoothness and the number of\npredictions used without compromising the asymptotic robustness. Table 12 compares the applications\nof EXGUARDwith those of GUARD.\nTable 12: Robustified RB-following algorithms. Here, B.O. stands for BLINDORACLE. PA. denotes\nPARROT. Cons., #Pred. and Time. represent consistency, number of predictor calls, and time\ncomplexity, respectively. For EXGUARD, d∈[1, H k]. For EXGUARD&B.O., λ=h/eh≤1/e ,\nwhereh=H k/(2d)andh∈[1/2, H k/2].\nAlgorithm Cons. Robustness Smoothness #Pred. Time.\nGUARD&B.O.1 2H k−1+ 2O(log(η t/OPT))O(OPT)O(nlogk)\nEXGUARD&B.O.1 2H k−1+O(d)O(min(log(ηt\nOPT), λpηt\nOPT))O(d·OPT)O(nlogk)\nGUARD&LRB1 2H k−1+ 2O(H k·ηb/OPT)O(OPT)O(n)\nEXGUARD&LRB1 2H k−1+O(d)O(H k/d·η b/OPT)O(d·OPT)O(n)\nGUARD&PARROT1 2H k−1+ 2O(H k·ηf/OPT)O(OPT)O(n)\nEXGUARD&PA.1 2H k−1+O(d)O(H k/d·η f/OPT)O(d·OPT)O(n)\nnew old old old \npred. at most             random evictions pred. Hk/d \nFigure 8: Random eviction budget along the eviction chain\n32\n\nAlgorithm 10EXGUARD&A\n1:U ← ∅(the set tracksunrequested old pagesin the cache)\n2:fori= 1, ..., ndo\n3:Receive a page requestr i= (t i, pi)at timet i\n4:ifp iis not in the cachethen\n5:ifthe cache is fullthen\n6:ifUis emptythen\n7:Unguard all cached pages\n8:U ← {all cached pages}(a new phase begins)\n9:end if\n10:E ←the corresponding eviction chain ofp i\n11:B(E)←the random eviction budget ofE\n12:ifp iwas evicted in the current phasethen\n13:ifB(E)≤0then\n14:Call functionEvict(U)\n15:B(E) =H k/d\n16:else\n17:Evict a pagexfromUuniformly at random\n18:B(E)←B(E)−1\n19:end if\n20:Guardp i\n21:else\n22:S ← {all unguarded cached pages}\n23:Call functionEvict(S)\n24:B(E) =H k/d\n25:end if\n26:ifthe evicted pagex∈ Uthen\n27:U ← U\\{x}\n28:end if\n29:end if\n30:Loadp iinto the cache\n31:end if\n32:ifp i∈ Uthen\n33:U ← U\\{p i}\n34:end if\n35:end for\nN.2 Algorithm Descriptions\nAlgorithm 10 describes the EXGUARDframework. Algorithm 7, 8, and 9 can also be embed-\nded into Algorithm 10 to generate the corresponding algorithms: EXGUARD&BLINDORACLE,\nEXGUARD&LRB, and EXGUARD&PARROT.\nTheorem N.1.EXGUARD&Ais1-consistent and2H k−1+O(d)-robust.\nProof.We focus on the modification introduced by EXGUARDover GUARD.\nSince EXGUARD&A retains the guard mechanism, it remains 1-consistency, as established by\nProposition 4.1 and Corollary 3.7.\nFrom the analysis in Appendix J, the expected length of an old-page eviction chain is at most O(H k).\nEXGUARDintroduces at most O(d) additional prediction-driven evictions along each chain, resulting\nin(2H k−1+O(d))-robustness.\nN.3 Predictor Usage Proof for EXGUARD\nTheorem N.2.GUARD&AandEXGUARD&Acalls the predictor O(OPT) andO(d·OPT) times,\nrespectively, whereA∈ {BLINDORACLE,LRB,PARROT}.\n33\n\nProof. Recall that the predictor is called only when an eviction is required, consistent with common\nimplementations in real systems. Let A∈ {BLINDORACLE,LRB,PARROT}in the following.\nFor GUARD&A, a prediction-driven eviction occurs only when serving a request for a new page.\nThus, the number of predictor calls in phase qisnq. By Lemma 4.4 and 4.3, we bound the total\nnumber of predictor calls as:\nX\nq∈Qnq≤X\nq∈Q2cq≤4OPT=O(OPT).(16)\nEXGUARD&A introduces additional oq/(Hk/d)calls for the predictor. According to Theorem N.1,\nthe expected total cost of EXGUARD&A satisfiesP\nq∈Q(nq+oq)≤OPT· O(H k). Therefore, the\ntotal number of predictor calls used by EXGUARD&A is bounded by:\nX\nq∈Q(nq+d·o q/Hk)≤ O(d·OPT).(17)\n(16) and (17) complete the proof.\nN.4 Smoothness Proof for EXGUARD&BLINDORACLE\nTheorem N.3.EXGUARD&BLINDORACLEis O\u0000\nmin(log(η t/OPT), h/eh·p\nηt/OPT)\u0001\n-smooth,\nwhereh=H k/(2d).\nProof. For an old-page eviction chain Eqin phase qwithxprediction-driven evictions, the expected\nlength of it is |Eq| ≤x·H k/d. When there are zunrequested old pages in the cache, the expected\nnumber of subsequent random evictions satisfies L(z)≤H z≤ln(k) + 1 . (Refer to Appendix J for\nL(z) .) Thus, if a prediction-based eviction results in ysubsequent random evictions, it implies at\nleastO(ey)inversions in expectation, arising from all pairs between the prediction-driven evicted\npage and other unrequested old pages.\nFrom the above, if Eqcontributes I(Eq)inversions, then I(E)≥ O(x2·eHk/d)since there are x\nprediction-driven evictions. Therefore,|E q| ≤x·H k/d≤ O\u0012\nHk\nd·q\nI(Eq)\neHk/d\u0013\n.\nThe total number of inversions satisfies inv(θ, ˆθ)≥P\nq∈QP\nEqI(Eq). LetNdenote the total number of\nold-page eviction chains, where OPT≤N≤2OPT, as shown in Equation (13) of Appendix K.2.\nWe then bound the total cost of EXGUARD&BLINORACLE, denoted asE[EXG&B], by\nE[EXG&B]≤X\nq∈Qcq+X\nq∈QX\nEqO\u0000\nHk/d·q\nI(Eq)/eHk/d\u0001\n(by Lemma J.1)\n≤X\nq∈Qcq+N· O\u0010\nHk/(deHk/(2d))·s\ninv(θ, ˆθ)\nN\u0011\n(by Jensen’s inequality)\n=O\u0010\nOPT·h/eh·rηt\nOPT\u0011\n,(by Lemma K.3) (18)\nwhere h=H k/(2d) . EXG.&B.O. inherits the O(log(η t/OPT)) smoothness of GUARD&B.O.,\nadding at most O(d) evictions per old-page chain, where 1≤d≤H k. Combining the two bounds\nabove completes the proof.\nN.5 Smoothness Proof for EXGUARD&LRB\nTheorem N.4.EXGUARD&LRBisO(H k/d·η b/OPT)-smooth.\n34\n\nProof. EXGUARD&LRB limits the number of subsequent random evictions to Hk/dafter a\nprediction-based eviction. According to the smoothness analysis of GUARD&LRB (Theorem\nK.6), and given a prediction error of ηb, the expected total cost of EXGUARD&LRB is at most\nO(H k/d·η b), thereby completing the proof.\nN.6 Smoothness Proof for EXGUARD&PARROT\nTheorem N.5.EXGUARD&PARROTisO((H k/d·η f/OPT)-smooth.\nProof. Similarly, EXGUARD&PARROTlimits the number of subsequent random evictions to Hk/d\nafter a prediction-based eviction. Based on the smoothness analysis of GUARD&PARROT(Theorem\nK.7), we can bound the expected total cost of EXGUARD&PARROT, denotedE[EXG&P], as:\nE[EXG&P]≤ O(H k/d·η f),(19)\nwhich completes the proof.\nN.7 Trade-offs Between Smoothness and Predictor Usage in ExGuard\nTable 13:Comparison of Smoothness and Predictor Usage.\nNRT Smoothness #Pred.\nP.M.O(√φt)O(H k·OPT)\nLM.O(log(φ t))O(OPT)\nLNONM.O(log(k)/k·φ t)unbounded\nB.O.O(1/k·φ t)unbounded\nB.O.&LRUO(1/k·φ t)O(k·OPT)\nB.O.&M.DO(1/k·φ t)O(H k·OPT)\nB.O.&M.RO(1/k·φ t)O(H k·OPT)\nB.O.&EQ.RO(1/k·φ t)O(H k·OPT)\nG.&B.O.O(log(φ t))O(OPT)\nEXG.&B.O.O(min(log(φ t), λ√φt))O(d·OPT)\nBinary Smoothness #Pred.\nM.P.O(H k·φb)O(H k·OPT)\nMARK0O(H k·φb)unbounded\nG.&LRBO(H k·φb)O(OPT)\nEXG.&LRBO(H k/d·φ b)O(d·OPT)\nAction Smoothness #Pred.\nF&R (f(i) = 2i−1)O(log(φ a))O(√\nk·OPT)\nF&RO(f−1(φa))O(f(logk)·OPT)\nFitF Smoothness #Pred.\nF&R (FITF)O(log(k)/b·φ f)O(b·OPT)\nG.&PA.O(H k·φt)O(OPT)\nEXG.&PA.O(H k/d·φ f)O(d·OPT)\nNotations in Table 13.Abbreviations include BLINDORACLE(B.O.), PREDICTIVEMARKER\n(P.M.), LNONMARKER(LNONM.), LMARKER(LM.), BLINDORACLE&MARKER(B.O.&M.),\nEQUITABLE(EQ.), MARK&PREDICT(M.&P.), PARROT(PA.), GUARD(G.), and EXGUARD\n(EXG.).\n#Pred. represents the upper bound of the number of predictor calls. F&R’s smoothness depends\nonf(i), which limits predictor calls. Our experiments focus on the F&R variant with optimal\nsmoothness ( f(i) = 2i−1). For clarity, we denote ηt/OPT asφt,ηb/OPT asφb,ηc/OPT asφa,\nandη f/OPT asφ f, whereη t, ηb, ηc, ηfrepresent different types of prediction errors.\nFor EXGUARD, parameter d∈[1, H k]. The smoothness parameter λof EXG.&B.O. satisfies\nλ=h/eh≤1/e (see Theorem N.3), where h=H k/(2d) . For F&R (FITF), parameter b∈\n{1, ...,logk}.\n35\n\nAnalysis of Predictor Usage.B.O. and MARK0. suffer from unbounded robustness and invoke the\npredictor on each cache miss, resulting in unbounded predictor usage. The predictor usage of F&R\nand F&R (FITF) has been analyzed in the corresponding paper.\nP.M. invokes the predictor O(H k·OPT) -times, as it evicts pages based on predictions whenever the\ncorresponding eviction chain has length at most Hk. In contrast, LM. relies on predictions only once\nat the beginning of each eviction chain, resulting in O(OPT) predictor queries. The predictor usage\nof LNONM. is unbounded, as it invokes the predictor once per eviction chain, and the number of\neviction chains depends on the total prediction error.\nM.&P. invokes the predictor on each cache miss, so its predictor usage bound is the product of\nO(OPT) and its robustness. Similarly, the predictor usage of B.O.&A is bounded by the product of\nO(OPT)competitive ratio of the classical algorithm A, where A∈ {LRU,MARKER,EQ.}.\nFavorable Tradeoffs Achieved by EXGUARD.For algorithms relying on NRT predictions,\nEXG.&B.O. achieves better tradeoffs than P.M. and LM. as their tradeoffs are theoretically directly\ncomparable. To compare with other algorithms such as B.O.&LRU, we conduct experiments, and\nthe results indicate that EXG.&B.O. achieves the best empirical tradeoff.\nMoreover, both EXG.&B.O. and G.&B.O. exhibit good smoothness, even with O(OPT) predictor\nusage. This enhances practicality, especially when predictor calls are costly.\nAmong algorithms that rely on binary predictions or the FitF predictor, both EXG.&LRB and\nEXG.&PA. achieve state-of-the-art tradeoffs.\nN.8 Experimental Results for EXGUARD\nWe empirically compare EXGUARD&B.O. with other algorithms, withdset toH k.\n0 10 20 30 40 5011.11.21.31.41.5\nLog-normal noise parameterσ.Cost RatioLRU\nMARKER\nB.O.\nLM.\nLNONM.\nP.M.\nB.O.&M.D\nB.O.&M.R\nG.&B.O.\nEXG.&B.O.\nFigure 9: Performance with synthetic predic-\ntions of NRT on BrightKite.0 10 20 30 40 503.544.5·104\nLog-normal noise parameterσ.Number of predictor callsLRU\nMARKER\nB.O.\nLM.\nLNONM.\nP.M.\nB.O.&M.D\nB.O.&M.R\nG.&B.O.\nEXG.&B.O.\nFigure 10: Number of predictor calls with syn-\nthetic predictions of NRT on BrightKite.\nTable 14: Average cost ratios ( CR), average LRU-normalized cost ratios ( LCR ), and average number\nof predictor calls ( #Pred.) on SPEC CPU2006 Benchmark using PLECO predictor.\nMetricsLRU B.O. P.M. LM. LNONM. B.O.&M.DG.&B.O. EXG.&B.O.\nCR1.478 1.404 1.335 1.335 1.346 1.294 1.2261.225\nLCR1 1.049 0.946 0.942 0.951 0.766 0.6270.623\n#Pred.0 79488 75870 72682 72767 794886209962553\nImproved Performance.Figure 9, 10 and Table 14 show that EXGUARD&B.O. outperforms\nGUARD&B.O. through increased predictor usage, empirically validating its improved smoothness. It\nis noteworthy that G.&B.O. and EXG.&B.O. depend less on the predictor than other algorithms\nutilizing next request time (NRT) predictions.\nIn the above, B.O.&M.Ris excluded due to underperforming relative to B.O.&M.D. F&R is\nexcluded due to its reliance on action prediction. Although action predictions can be generated using\n(NRT), doing so requires NRT predictions for all requested pages. In contrast, other algorithms only\npredict the NRT of cached pages at eviction (predictions can be reused if not requested). Thus, their\npredictor call counts are not comparable.\n36\n\nO Other Caching Models\nBeyond the classical caching model, where item sizes and cache-miss costs are uniform, researchers\nhave also investigated more general variants such as weighted caching, in which different pages\nincur different loading costs, both without machine learning [ 47] and with learning-augmented\napproaches [ 48,49]. However, research on learning-augmented algorithms for general caching\nsettings, such as those with variable-sized items, remains limited and deserves further study.\nIn addition to accounting for cache-miss costs and item sizes, the conventional caching model\ninherently assumes that every requested item is stored upon access. This constraint is prevalent in\nclassical systems. (1) In operating systems, virtual memory management depends on the guarantee\nthat once a page is requested, it must be loaded into physical memory for execution to continue;\notherwise, data errors, crashes, or inconsistent behavior may occur [ 50]. (2) In databases, this\nconstraint ensures data consistency and transaction integrity in relational systems [ 51]. If a page is\nnot retained in memory after being accessed until the transaction completes, it may result in partial\nupdates or lost modifications, thereby violating the transaction’s atomicity.\nIn contrast, the constraint can be relaxed in several modern settings. (1) In web browsers, caching is\nmore flexible, as algorithms such as TinyLFU [ 52] explicitly allow the system to skip caching certain\nrequested items. (2) In content delivery networks, caching decisions are governed by parameters\nlike TTL, content popularity, and regional demand [ 53], meaning that not all requested content is\ncached immediately at the edge. In summary, whether this constraint can be relaxed depends on\nscenario-specific requirements. Future research could explore learning-augmented algorithms that\noperate without this constraint and investigate how cache admission choices impact robustness.\nP Experimental Setup\nMost of our experiments rely solely on a standard computer equipped with a CPU and RAM.\nEvaluating algorithms that use a neural network-based predictor, such as PARROT, requires a GPU.\nQ Broader Impacts\nThis paper presents the design, analysis, and evaluation of learning-augmented algorithms for the\ncaching (paging) problem. Our work has a potential positive societal impact by improving the\nefficiency and performance guarantees of caching systems.\n37\n\nNeurIPS Paper Checklist\n1.Claims\nQuestion: Do the main claims made in the abstract and introduction accurately reflect the\npaper’s contributions and scope?\nAnswer: [Yes]\nJustification: The abstract and introduction clearly reflect the contributions, aligning both\nthe theoretical and experimental results.\nGuidelines:\n•The answer NA means that the abstract and introduction do not include the claims\nmade in the paper.\n•The abstract and/or introduction should clearly state the claims made, including the\ncontributions made in the paper and important assumptions and limitations. A No or\nNA answer to this question will not be perceived well by the reviewers.\n•The claims made should match theoretical and experimental results, and reflect how\nmuch the results can be expected to generalize to other settings.\n•It is fine to include aspirational goals as motivation as long as it is clear that these goals\nare not attained by the paper.\n2.Limitations\nQuestion: Does the paper discuss the limitations of the work performed by the authors?\nAnswer: [Yes]\nJustification: The algorithms proposed in this paper are only for the traditional caching\n(paging) problem, instead of the general caching problem, such as weighted paging or\ncaching with varying sizes, etc. This has been stated at the beginning of our paper in the\nintroduction. For empirical evaluation, we explicitly list all the open-source datasets used.\nAlthough they are extensive, it is not possible to cover every caching scenario.\nGuidelines:\n•The answer NA means that the paper has no limitation while the answer No means that\nthe paper has limitations, but those are not discussed in the paper.\n• The authors are encouraged to create a separate \"Limitations\" section in their paper.\n•The paper should point out any strong assumptions and how robust the results are to\nviolations of these assumptions (e.g., independence assumptions, noiseless settings,\nmodel well-specification, asymptotic approximations only holding locally). The authors\nshould reflect on how these assumptions might be violated in practice and what the\nimplications would be.\n•The authors should reflect on the scope of the claims made, e.g., if the approach was\nonly tested on a few datasets or with a few runs. In general, empirical results often\ndepend on implicit assumptions, which should be articulated.\n•The authors should reflect on the factors that influence the performance of the approach.\nFor example, a facial recognition algorithm may perform poorly when image resolution\nis low or images are taken in low lighting. Or a speech-to-text system might not be\nused reliably to provide closed captions for online lectures because it fails to handle\ntechnical jargon.\n•The authors should discuss the computational efficiency of the proposed algorithms\nand how they scale with dataset size.\n•If applicable, the authors should discuss possible limitations of their approach to\naddress problems of privacy and fairness.\n•While the authors might fear that complete honesty about limitations might be used by\nreviewers as grounds for rejection, a worse outcome might be that reviewers discover\nlimitations that aren’t acknowledged in the paper. The authors should use their best\njudgment and recognize that individual actions in favor of transparency play an impor-\ntant role in developing norms that preserve the integrity of the community. Reviewers\nwill be specifically instructed to not penalize honesty concerning limitations.\n3.Theory assumptions and proofs\n38\n\nQuestion: For each theoretical result, does the paper provide the full set of assumptions and\na complete (and correct) proof?\nAnswer: [Yes]\nJustification: All propositions, lemmas, theorems, and corollaries in the paper are numbered\nand cross-referenced. Each theoretical result is fully proven, either in the main text or in the\nappendix.\nGuidelines:\n• The answer NA means that the paper does not include theoretical results.\n•All the theorems, formulas, and proofs in the paper should be numbered and cross-\nreferenced.\n•All assumptions should be clearly stated or referenced in the statement of any theorems.\n•The proofs can either appear in the main paper or the supplemental material, but if\nthey appear in the supplemental material, the authors are encouraged to provide a short\nproof sketch to provide intuition.\n•Inversely, any informal proof provided in the core of the paper should be complemented\nby formal proofs provided in appendix or supplemental material.\n• Theorems and Lemmas that the proof relies upon should be properly referenced.\n4.Experimental result reproducibility\nQuestion: Does the paper fully disclose all the information needed to reproduce the main ex-\nperimental results of the paper to the extent that it affects the main claims and/or conclusions\nof the paper (regardless of whether the code and data are provided or not)?\nAnswer: [Yes]\nJustification: The code and data are included in the supplementary material. With our\ninstructions, others can easily reproduce experimental results consistent with those reported\nin the paper.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n•If the paper includes experiments, a No answer to this question will not be perceived\nwell by the reviewers: Making the paper reproducible is important, regardless of\nwhether the code and data are provided or not.\n•If the contribution is a dataset and/or model, the authors should describe the steps taken\nto make their results reproducible or verifiable.\n•Depending on the contribution, reproducibility can be accomplished in various ways.\nFor example, if the contribution is a novel architecture, describing the architecture fully\nmight suffice, or if the contribution is a specific model and empirical evaluation, it may\nbe necessary to either make it possible for others to replicate the model with the same\ndataset, or provide access to the model. In general. releasing code and data is often\none good way to accomplish this, but reproducibility can also be provided via detailed\ninstructions for how to replicate the results, access to a hosted model (e.g., in the case\nof a large language model), releasing of a model checkpoint, or other means that are\nappropriate to the research performed.\n•While NeurIPS does not require releasing code, the conference does require all submis-\nsions to provide some reasonable avenue for reproducibility, which may depend on the\nnature of the contribution. For example\n(a)If the contribution is primarily a new algorithm, the paper should make it clear how\nto reproduce that algorithm.\n(b)If the contribution is primarily a new model architecture, the paper should describe\nthe architecture clearly and fully.\n(c)If the contribution is a new model (e.g., a large language model), then there should\neither be a way to access this model for reproducing the results or a way to reproduce\nthe model (e.g., with an open-source dataset or instructions for how to construct\nthe dataset).\n39\n\n(d)We recognize that reproducibility may be tricky in some cases, in which case\nauthors are welcome to describe the particular way they provide for reproducibility.\nIn the case of closed-source models, it may be that access to the model is limited in\nsome way (e.g., to registered users), but it should be possible for other researchers\nto have some path to reproducing or verifying the results.\n5.Open access to data and code\nQuestion: Does the paper provide open access to the data and code, with sufficient instruc-\ntions to faithfully reproduce the main experimental results, as described in supplemental\nmaterial?\nAnswer: [Yes]\nJustification: All datasets used are open-source. The code, data, and detailed instructions\nare included in the supplementary material and will be made available in a public GitHub\nrepository in the future.\nGuidelines:\n• The answer NA means that paper does not include experiments requiring code.\n•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/\npublic/guides/CodeSubmissionPolicy) for more details.\n•While we encourage the release of code and data, we understand that this might not be\npossible, so “No” is an acceptable answer. Papers cannot be rejected simply for not\nincluding code, unless this is central to the contribution (e.g., for a new open-source\nbenchmark).\n•The instructions should contain the exact command and environment needed to run to\nreproduce the results. See the NeurIPS code and data submission guidelines ( https:\n//nips.cc/public/guides/CodeSubmissionPolicy) for more details.\n•The authors should provide instructions on data access and preparation, including how\nto access the raw data, preprocessed data, intermediate data, and generated data, etc.\n•The authors should provide scripts to reproduce all experimental results for the new\nproposed method and baselines. If only a subset of experiments are reproducible, they\nshould state which ones are omitted from the script and why.\n•At submission time, to preserve anonymity, the authors should release anonymized\nversions (if applicable).\n•Providing as much information as possible in supplemental material (appended to the\npaper) is recommended, but including URLs to data and code is permitted.\n6.Experimental setting/details\nQuestion: Does the paper specify all the training and test details (e.g., data splits, hyper-\nparameters, how they were chosen, type of optimizer, etc.) necessary to understand the\nresults?\nAnswer: [Yes]\nJustification: The detailed experimental settings are presented in the experiment section.\nMoreover, the code is provided.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n•The experimental setting should be presented in the core of the paper to a level of detail\nthat is necessary to appreciate the results and make sense of them.\n•The full details can be provided either with the code, in appendix, or as supplemental\nmaterial.\n7.Experiment statistical significance\nQuestion: Does the paper report error bars suitably and correctly defined or other appropriate\ninformation about the statistical significance of the experiments?\nAnswer: [Yes]\nJustification: We have given the distributions and parameters for synthetic prediction gener-\nation in the experiment section.\n40\n\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n•The authors should answer \"Yes\" if the results are accompanied by error bars, confi-\ndence intervals, or statistical significance tests, at least for the experiments that support\nthe main claims of the paper.\n•The factors of variability that the error bars are capturing should be clearly stated (for\nexample, train/test split, initialization, random drawing of some parameter, or overall\nrun with given experimental conditions).\n•The method for calculating the error bars should be explained (closed form formula,\ncall to a library function, bootstrap, etc.)\n• The assumptions made should be given (e.g., Normally distributed errors).\n•It should be clear whether the error bar is the standard deviation or the standard error\nof the mean.\n•It is OK to report 1-sigma error bars, but one should state it. The authors should\npreferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis\nof Normality of errors is not verified.\n•For asymmetric distributions, the authors should be careful not to show in tables or\nfigures symmetric error bars that would yield results that are out of range (e.g. negative\nerror rates).\n•If error bars are reported in tables or plots, The authors should explain in the text how\nthey were calculated and reference the corresponding figures or tables in the text.\n8.Experiments compute resources\nQuestion: For each experiment, does the paper provide sufficient information on the com-\nputer resources (type of compute workers, memory, time of execution) needed to reproduce\nthe experiments?\nAnswer: [Yes]\nJustification: Section P provides detailed requirements for reproducing the experiments.\nGuidelines:\n• The answer NA means that the paper does not include experiments.\n•The paper should indicate the type of compute workers CPU or GPU, internal cluster,\nor cloud provider, including relevant memory and storage.\n•The paper should provide the amount of compute required for each of the individual\nexperimental runs as well as estimate the total compute.\n•The paper should disclose whether the full research project required more compute\nthan the experiments reported in the paper (e.g., preliminary or failed experiments that\ndidn’t make it into the paper).\n9.Code of ethics\nQuestion: Does the research conducted in the paper conform, in every respect, with the\nNeurIPS Code of Ethicshttps://neurips.cc/public/EthicsGuidelines?\nAnswer: [Yes]\nJustification: We have reviewed the NeurIPS Code of Ethics and affirm that the research\nconducted adheres to it in all respects.\nGuidelines:\n•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.\n•If the authors answer No, they should explain the special circumstances that require a\ndeviation from the Code of Ethics.\n•The authors should make sure to preserve anonymity (e.g., if there is a special consid-\neration due to laws or regulations in their jurisdiction).\n10.Broader impacts\nQuestion: Does the paper discuss both potential positive societal impacts and negative\nsocietal impacts of the work performed?\n41\n\nAnswer: [Yes]\nJustification: See Section Q.\nGuidelines:\n• The answer NA means that there is no societal impact of the work performed.\n•If the authors answer NA or No, they should explain why their work has no societal\nimpact or why the paper does not address societal impact.\n•Examples of negative societal impacts include potential malicious or unintended uses\n(e.g., disinformation, generating fake profiles, surveillance), fairness considerations\n(e.g., deployment of technologies that could make decisions that unfairly impact specific\ngroups), privacy considerations, and security considerations.\n•The conference expects that many papers will be foundational research and not tied\nto particular applications, let alone deployments. However, if there is a direct path to\nany negative applications, the authors should point it out. For example, it is legitimate\nto point out that an improvement in the quality of generative models could be used to\ngenerate deepfakes for disinformation. On the other hand, it is not needed to point out\nthat a generic algorithm for optimizing neural networks could enable people to train\nmodels that generate Deepfakes faster.\n•The authors should consider possible harms that could arise when the technology is\nbeing used as intended and functioning correctly, harms that could arise when the\ntechnology is being used as intended but gives incorrect results, and harms following\nfrom (intentional or unintentional) misuse of the technology.\n•If there are negative societal impacts, the authors could also discuss possible mitigation\nstrategies (e.g., gated release of models, providing defenses in addition to attacks,\nmechanisms for monitoring misuse, mechanisms to monitor how a system learns from\nfeedback over time, improving the efficiency and accessibility of ML).\n11.Safeguards\nQuestion: Does the paper describe safeguards that have been put in place for responsible\nrelease of data or models that have a high risk for misuse (e.g., pretrained language models,\nimage generators, or scraped datasets)?\nAnswer: [NA]\nJustification: This paper poses no such risks.\nGuidelines:\n• The answer NA means that the paper poses no such risks.\n•Released models that have a high risk for misuse or dual-use should be released with\nnecessary safeguards to allow for controlled use of the model, for example by requiring\nthat users adhere to usage guidelines or restrictions to access the model or implementing\nsafety filters.\n•Datasets that have been scraped from the Internet could pose safety risks. The authors\nshould describe how they avoided releasing unsafe images.\n•We recognize that providing effective safeguards is challenging, and many papers do\nnot require this, but we encourage authors to take this into account and make a best\nfaith effort.\n12.Licenses for existing assets\nQuestion: Are the creators or original owners of assets (e.g., code, data, models), used in\nthe paper, properly credited and are the license and terms of use explicitly mentioned and\nproperly respected?\nAnswer: [Yes]\nJustification: The data and code for certain existing algorithms were obtained from publicly\navailable datasets or open-source GitHub repositories provided by the corresponding authors.\nGuidelines:\n• The answer NA means that the paper does not use existing assets.\n• The authors should cite the original paper that produced the code package or dataset.\n42\n\n•The authors should state which version of the asset is used and, if possible, include a\nURL.\n• The name of the license (e.g., CC-BY 4.0) should be included for each asset.\n•For scraped data from a particular source (e.g., website), the copyright and terms of\nservice of that source should be provided.\n•If assets are released, the license, copyright information, and terms of use in the\npackage should be provided. For popular datasets, paperswithcode.com/datasets\nhas curated licenses for some datasets. Their licensing guide can help determine the\nlicense of a dataset.\n•For existing datasets that are re-packaged, both the original license and the license of\nthe derived asset (if it has changed) should be provided.\n•If this information is not available online, the authors are encouraged to reach out to\nthe asset’s creators.\n13.New assets\nQuestion: Are new assets introduced in the paper well documented and is the documentation\nprovided alongside the assets?\nAnswer: [Yes]\nJustification: The code is provided along with its documentation.\nGuidelines:\n• The answer NA means that the paper does not release new assets.\n•Researchers should communicate the details of the dataset/code/model as part of their\nsubmissions via structured templates. This includes details about training, license,\nlimitations, etc.\n•The paper should discuss whether and how consent was obtained from people whose\nasset is used.\n•At submission time, remember to anonymize your assets (if applicable). You can either\ncreate an anonymized URL or include an anonymized zip file.\n14.Crowdsourcing and research with human subjects\nQuestion: For crowdsourcing experiments and research with human subjects, does the paper\ninclude the full text of instructions given to participants and screenshots, if applicable, as\nwell as details about compensation (if any)?\nAnswer: [NA]\nJustification: The paper does not involve crowdsourcing nor research with human subjects.\nGuidelines:\n•The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n•Including this information in the supplemental material is fine, but if the main contribu-\ntion of the paper involves human subjects, then as much detail as possible should be\nincluded in the main paper.\n•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,\nor other labor should be paid at least the minimum wage in the country of the data\ncollector.\n15.Institutional review board (IRB) approvals or equivalent for research with human\nsubjects\nQuestion: Does the paper describe potential risks incurred by study participants, whether\nsuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)\napprovals (or an equivalent approval/review based on the requirements of your country or\ninstitution) were obtained?\nAnswer: [NA]\nJustification: The paper does not involve crowdsourcing nor research with human subjects.\nGuidelines:\n43\n\n•The answer NA means that the paper does not involve crowdsourcing nor research with\nhuman subjects.\n•Depending on the country in which research is conducted, IRB approval (or equivalent)\nmay be required for any human subjects research. If you obtained IRB approval, you\nshould clearly state this in the paper.\n•We recognize that the procedures for this may vary significantly between institutions\nand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the\nguidelines for their institution.\n•For initial submissions, do not include any information that would break anonymity (if\napplicable), such as the institution conducting the review.\n16.Declaration of LLM usage\nQuestion: Does the paper describe the usage of LLMs if it is an important, original, or\nnon-standard component of the core methods in this research? Note that if the LLM is used\nonly for writing, editing, or formatting purposes and does not impact the core methodology,\nscientific rigorousness, or originality of the research, declaration is not required.\nAnswer: [NA]\nJustification: The proposed methods do not involve LLMs.\nGuidelines:\n•The answer NA means that the core method development in this research does not\ninvolve LLMs as any important, original, or non-standard components.\n•Please refer to our LLM policy ( https://neurips.cc/Conferences/2025/LLM )\nfor what should or should not be described.\n44",
  "textLength": 130140
}