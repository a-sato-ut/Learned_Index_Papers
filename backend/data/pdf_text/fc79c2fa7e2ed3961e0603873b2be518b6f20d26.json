{
  "paperId": "fc79c2fa7e2ed3961e0603873b2be518b6f20d26",
  "title": "SALI: A Scalable Adaptive Learned Index Framework based on Probability Models",
  "pdfPath": "fc79c2fa7e2ed3961e0603873b2be518b6f20d26.pdf",
  "text": "SALI: A Scalable Adaptive Learned Index Framework based on\nProbability Models\nJiake Geâ™ â™¥, Huanchen Zhangâ™¦Â§, Boyu Shiâ™£â™¥, Yuanhui Luoâ™ â™¥, Yunda Guoâ™ â™¥, Yunpeng Chaiâ™£â™¥âˆ—,\nYuxing Chen+, Anqun Pan+\nâ™ Key Laboratory of Data Engineering and Knowledge Engineering, MOE, China\nâ™£Engineering Research Center of Database and Business Intelligence, MOE, China\nâ™¥School of Information, Renmin University of China\nÂ§China and Shanghai Qi Zhi Institute\nâ™¦Tsinghua University\n+Tencent Inc.\ngejiake@ruc.edu.cn, huanchen@tsinghua.edu.cn, shiboyu5687@ruc.edu.cn, losk@ruc.edu.cn,\nguoyunda@ruc.edu.cn, ypchai@ruc.edu.cn, axingguchen@tencent.com, aaronpan@tencent.com\nABSTRACT\nThe growth in data storage capacity and the increasing demands for\nhigh performance have created several challenges for concurrent\nindexing structures. One promising solution is learned indexes,\nwhich use a learning-based approach to fit the distribution of stored\ndata and predictively locate target keys, significantly improving\nlookup performance. Despite their advantages, prevailing learned\nindexes exhibit constraints and encounter issues of scalability on\nmulti-core data storage.\nThis paper introduces SALI, the Scalable Adaptive Learned Index\nframework, which incorporates two strategies aimed at achieving\nhigh scalability, improving efficiency, and enhancing the robust-\nness of the learned index. Firstly, a set of node-evolving strategies\nis defined to enable the learned index to adapt to various work-\nload skews and enhance its concurrency performance in such sce-\nnarios. Secondly, a lightweight strategy is proposed to maintain\nstatistical information within the learned index, with the goal of\nfurther improving the scalability of the index. Furthermore, to vali-\ndate their effectiveness, SALI applied the two strategies mentioned\nabove to the learned index structure that utilizes fine-grained write\nlocks, known as LIPP. The experimental results have demonstrated\nthat SALI significantly enhances the insertion throughput with 64\nthreads by an average of 2.04Ã—compared to the second-best learned\nindex. Furthermore, SALI accomplishes a lookup throughput similar\nto that of LIPP+.\nCCS CONCEPTS\nâ€¢Information systems â†’Data access methods .\nâˆ—Yunpeng Chai is the corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nÂ©2024 Association for Computing Machinery.\nACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00\nhttps://doi.org/XXXXXXX.XXXXXXXKEYWORDS\nLearned Index; Probability Models; Adaptive Index\nACM Reference Format:\nJiake Geâ™ â™¥, Huanchen Zhangâ™¦Â§, Boyu Shiâ™£â™¥, Yuanhui Luoâ™ â™¥, Yunda Guoâ™ â™¥,\nYunpeng Chaiâ™£â™¥âˆ—, Yuxing Chen+, Anqun Pan+. 2024. SALI: A Scalable Adap-\ntive Learned Index Framework based on Probability Models. In Proceedings\nof In Proceedings of the 2024 International Conference on Management of Data\n(Conference SIGMOD â€™24). ACM, Santiago, Chile, 17 pages.\n1 INTRODUCTION\nWith the exponential growth of the data volume today, efficient\nindexing data structures are crucial for a big data system to sup-\nport timely information retrieval. To improve the performance and\nmemory efficiency of traditional tree-based indexes, Kraska et al.\nintroduced a learned index, called the Recursive Model Indexes\n(RMI) that uses machine learning models to replace the internal\nnodes of a B+tree [ 15,20]. An outstanding problem of the original\nRMI is that it is static: inserting or updating a key in the index\nrequires a significant portion of the data structure to rebuild, thus\nlimiting the use cases of the learned index.\nPrevious work has proposed two strategies to address the up-\ndatability issue of learned indexes. The first (i.e., the buffer-based\nstrategy) is to accommodate new entries in separate insert buffers\nfirst to amortize the index reconstruction cost. XIndex [ 36] and\nFINEdex [ 21] fall into this category. The other strategy (i.e., the\nmodel-based strategy) adopted by ALEX [ 3] and LIPP [ 39] is to re-\nserve slot gaps within nodes to handle new entries with an in-place\ninsertion. Upon an insert collision (i.e., the mapped slot is already\noccupied), ALEX reorganizes the node by shifting the existing en-\ntries, while LIPP utilizes a chaining scheme, creating a new node for\nthe corresponding slot to transform the last-mile search problem\ninto a sub-tree traversal problem.\nWe found, however, that none of the above index designs scale at\na high concurrency. We performed an experiment where we insert\n200 million random integer keys into a learned index, with a varying\nnumber of threads each time. Figure 1 shows the results. Note that\nthe number of threads in the grey area of the figure is larger than\nthe number of hardware threads of the machine. This is common\nin practice as a database/key-value server typically handles a large\nnumber of user connections simultaneously.\n1arXiv:2308.15012v2  [cs.DB]  5 Sep 2023\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nFigure 1: Write-only performance of state-of-the-art learned\nindexes on the FACE dataset [ 11]. The evaluation is con-\nducted on a two-socket machine with two 16-core CPUs.\nAs shown in Figure 1, indexes with a buffer-based strategy (i.e.,\nXIndex and FINEdex) exhibit inferior base performance and worse\nscalability compared to those with a model-based strategy (i.e.,\nALEX+ and LIPP+1). This shows that a larger margin of predic-\ntion errors prevents scaling because the concurrent â€œlast mileâ€\nsearches saturate the memory bandwidth quickly which becomes\nthe systemâ€™s bottleneck [38].\nThe problem is solved in LIPP+ where each position prediction\nis accurate (i.e., no â€œlast mileâ€ search). However, LIPP+ requires\nmaintaining statistics, such as access counts and collision counts,\nin each node to trigger node retraining to prevent performance\ndegradation. These per-node counters create high contention\namong threads and cause severe cacheline ping-pong [ 38]. The\nmodel-based strategy in ALEX+ requires shifting existing entries\nupon an insert collision. Therefore, ALEX+ must acquire coarse-\ngrained write locks for this operation. As the number of threads\nincreases, more and more threads are blocked, waiting for those\nexclusive locks.\nIn this paper, we propose SALI, the Scalable Adaptive Learned\nIndex framework based on probability models to solve the scalabil-\nity issues in existing solutions. To solve the scalability bottleneck\nof maintaining per-node statistics, we developed lightweight prob-\nability models that can trigger node retraining and other structural\nevolving operations in SALI with accurate timing (as if the timing\nwere determined by accurate statistics). In addition, we developed\na set of node-evolving strategies, including expanding an insert-\nheavy node to contain more gaps, flattening the tree structure\nfor frequently-accessed nodes, and compacting the rarely-touched\nnodes to save memory. SALI applies these node-evolving strate-\ngies adaptively according to the probability models so that it can\nself-adjust to changing workloads while maintaining excellent scal-\nability. Finally, SALI adopts the learned index structure that utilizes\nfine-grained write locks, i.e., LIPP+, to validate the effectiveness of\nthe aforementioned two strategies. Note that the lightweight proba-\nbility models and node-evolving strategies are highly versatile and\ncan be applied to various index scenarios, as detailed in Section 5.\nOur microbenchmark with real-world data sets shows that SALI\nimproves the insertion throughput with 64 threads by 2.04Ã—on\naverage compared to the second-best learned index, i.e., ALEX+,\nwhile achieving a lookup throughput comparable to LIPP+.\nWe make three primary contributions in this paper. Firstly, we\nproposed SALI, a high-concurrency learned index framework de-\nsigned to improve the scalability of learned indexes. Secondly, we\n1ALEX+ and LIPP+ are concurrent implementations of ALEX and LIPP, respec-\ntively [38].\nFigure 2: The scheme of the learned index.\ndefined a set of node-evolving strategies in addition to model re-\ntraining to allow the learned index to self-adapt to different work-\nload skews. Thirdly, we replaced the per-node statistics in existing\nlearned indexes with lightweight probability models to remove the\nscalability bottleneck of statistics maintenance while keeping the\ntiming accuracy of node retraining/evolving. Finally, we proved\nthe effectiveness of the proposed approaches by showing that SALI\noutperforms the SOTA learned indexes under high concurrency.\nThe rest of this paper is organized as follows. Section 2 sum-\nmarizes the basics of learned indexes and further motivates the\nscalability problem. Section 3 introduces the structure of SALI with\nan emphasis on the node-evolving strategies and the probability\nmodels. Section 4 presents our experimental results. Section 5 dis-\ncusses the generalizability of the node-evolving strategies and the\nprobability models, as well as the limitations of SALI, followed\nby a related work discussion in Section 6 Section 7 concludes the\npaper. The source code of this paper has been made available at\nhttps://github.com/YunWorkshop/SALI.\n2 BACKGROUND AND MOTIVATION\n2.1 The principle of learned indexes\nThe core concept of the learned index is to employ a set of learning\nmodels to estimate the cumulative distribution function (CDF) of\nthe stored data [ 29], allowing for the prediction of the dataâ€™s storage\nlocation, as depicted in the CDF diagram on Figure 2.\nFigure 2 shows the scheme for the learned index structure. Each\nnode, or only the lowest leaf nodes, stores the slope and intercept\nof the linear function [ 3,5,8,15,21,36,39]. Each segment corre-\nsponds to a linear model, which is responsible for the approximate\nposition of the target key. The index segments correspond to linear\nmodels that estimate the target keyâ€™s position, eliminating the need\nfor multiple indirect search operations in traditional tree-based in-\ndexes. This approach has the potential to improve indexed lookup\nperformance significantly.\n2.2 Scalable Evaluation of Learned Index\nStructures\nCurrently, learned indexes demonstrate good performance in\nsingle-threaded environments. However, their scalability remains\nlimited [ 38]. In this part, our objective is to conduct a thorough\ninvestigation into the factors that contribute to the concurrent\nperformance bottlenecks in existing learned indexes. To achieve\nthis, we begin by introducing the insertion strategies employed in\nlearned indexes, along with their corresponding index structures,\nas these design choices significantly influence the concurrent per-\nformance of the indexes. Additionally, we conduct a comprehensive\n2\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nFigure 3: The updatable strategies in learned indexes.\nevaluation of the index structures and identify their limitations in\nterms of scalability.\n2.2.1 The insertion strategies of learned indexes. In a concurrent\nscenario, the blocking of index operations is primarily due to the\ninsertion of new keys. Understanding the current insertion strate-\ngies is essential for enhancing index scalability. Thus, we present\nthe insertion strategies as follows.\nStrategy 1: Scholars try to design a buffer-based insert strat-\negy, i.e., off-site insertion, on learned indexes to implement insert\noperations [ 5,8,21,36]. As shown in Figure 3, the core idea of\nthe buffer-based strategy is to create a buffer structure for inser-\ntion [ 5,8,21,36]. When the buffer is full, its keys must be merged\nwith those in the upper segment and transformed into a new linear\nmodel. Furthermore, this structure suffers from significant errors\ndue to the intensive storage of keys (no gap) [10].\nStrategy 2: The core idea of the model-based insert strategy, i.e.,\nin-place insertion, involves reserving gaps in the nodes [ 3,39]. If\nthe linear model predicts that the target position of the inserted\nkey is a gap, it is directly inserted. However, if the slot with the key\nalready exists, there are two existing conflict resolution strategies:\nâ€¢Solution 1: One potential solution for resolving conflicts is to\nadopt the â€œshiftâ€ method [ 3]. As shown in Figure 3, this method\ninvolves shifting the existing conflicted key and its adjacent keys to\nthe nearest gap by one slot, allowing the target key to be inserted\ninto the target position. However, the process of key movement\ncan introduce errors.\nâ€¢Solution 2: Another solution to resolve conflicts is to adopt\nthe â€œchainâ€ method [ 39]. As shown in Figure 3, if a key already\nexists at the target position of the newly inserted key, a new node\nis created downward to accommodate the conflicting key. This\nconflict resolution approach does not involve moving any data,\nthus avoiding potential lookup errors (precise lookup).\n2.2.2 In-depth analysis of these strategies. This part will provide\nan in-depth analysis of the index structures corresponding to the\ninsertion strategies mentioned. Building upon the GRE [ 38], we\nfurther performed an in-depth experimental analysis of existing\nlearned indexes and identified the scalability problems in their\ndesigns. Our objective is not to compare them with each other but\nto highlight the scalability bottleneck.\nFigure 4 illustrates the performance for the three structures.\nThe buffer-based structure is denoted by ğ‘ğ‘¢ğ‘“. (i.e., the structure of\nXIndex), the Mod el-based strategy with the Shift method is denoted\nbyğ‘€ğ‘œğ‘‘.+ğ‘†(i.e., the structure of ALEX), the Mod el-based strategy\nwith the Chain method is denoted by ğ‘€ğ‘œğ‘‘.+ğ¶(i.e., the structure of\nFigure 4: The in-depth evaluation of performance on the\nCOVID dataset [ 38], where the workload follows the uniform\ndistribution. The evaluation is conducted on a two-socket\nmachine with two 16-core CPUs.\nLIPP). The notation ğ‘€ğ‘œğ‘‘.+ğ¶+ğ‘ ğ‘¡ğ‘ğ‘¡. is used to represent the ğ‘€ğ‘œğ‘‘.+ğ¶\napproach along with the maintenance of statistics to track index\ndeterioration. Note that except for ğ‘€ğ‘œğ‘‘.+ğ¶+ğ‘ ğ‘¡ğ‘ğ‘¡. , we disabled\nthe statistics maintenance and local adjustment functions with the\npurpose of analyzing the impact of the structures themselves on\nindex concurrency performance.\nFigure 4(a) displays that both ğ‘ğ‘¢ğ‘“. andğ‘€ğ‘œğ‘‘.+ğ‘†exhibit poor\nscalability due to lookup errors, which can impact both the lookup\nand insert performance. Note that, the average search error of ğ‘ğ‘¢ğ‘“.\nis higher compared to ğ‘€ğ‘œğ‘‘.+ğ‘†[10].\nObservation 1: Improved concurrency performance can\nbe achieved through the utilization of precise lookups. The\ninsertion strategy employed by Mod.+C guarantees error-free\ngeneration even during the insertion process.\nFigure 4(b) depicts the insertion performance for the three struc-\ntures. The poor performance of ğ‘ğ‘¢ğ‘“. is attributed to a lookup error\nand an off-site insertion method [ 10].ğ‘€ğ‘œğ‘‘.+ğ‘†has three reasons for\nits poor performance: (1) Severe lookup errors; (2) Significant write\namplification and frequent â€œlast mileâ€ lookup lead to exhaustion\nof memory bandwidth and affect concurrency performance [ 38].\nThis amplification occurs because the moving key and the inserted\ntarget key need to be written into the node together; (3) During\ninsertion, coarse-grained locks can easily cause thread blocking.\nThe shift method leads to significant correlations between keys in\nthe entire node, necessitating the locking of the entire node during\ninsertion to ensure accuracy. Moreover, the thread blocking issue\nis more pronounced in the gray area in Figure 4(b), where threads\nfrequently access nodes locked by coarse-grained locks and release\nCPU time slices, resulting in invalid operations and exacerbating\nperformance degradation. In fact, the coarse-grained locks have al-\nready caused a slowdown in concurrent performance growth under\n64 threads, which may not have been apparent due to the influence\nof other scalability factors, e.g., lookup error.\nObservation 2: Mod.+C facilitates fine-grained locks, i.e.,\none slot, no search errors, and in-place insertion, which en-\nables its good insertion scalability.\nThe scalability of ğ‘€ğ‘œğ‘‘.+ğ¶+ğ‘ ğ‘¡ğ‘ğ‘¡. is severely impacted, depicted in\nFigure 4(b), primarily due to the high level of contention and cache-\nline ping-pong that arises from maintaining statistics in a concur-\nrent scenario, which is consistent with the findings of Wongkham\net al. [ 38]. Figure 4(c) shows that ğ‘€ğ‘œğ‘‘.+ğ¶saves 0.8x-5x the average\ntime compared to ğ‘€ğ‘œğ‘‘.+ğ‘†with different datasets.\nObservation 3: Maintaining statistics within Mod.+C ren-\nders the index non-scalable. Note that the scalability issue is\nnot attributed to the structure of Mod.+C , but rather to the\nabsence of a lightweight statistical approach.\n3\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nObservation 4: The chain method exhibits significantly\nshorter operation times compared to the shift method.\n2.3 The Scalable Learned Index Requirements\nIn consideration of scalability, we have further summarized the\npotential limitations of several SOTA learned indexes in Table 1,\ntaking into account factors such as prediction accuracy ( ğ‘ğ‘œğ‘’ğ‘Ÿğ‘Ÿ ),\ninsert strategy ( ğ¼ğ‘›-ğ‘ğ‘™ğ‘ğ‘ğ‘’ ), lock granularity ( ğ¹ğ‘–ğ‘›ğ‘’ğ‘™ğ‘œğ‘ğ‘˜ ), lightweight\nstatistics support ( ğ‘™-ğ‘¤ğ‘ ğ‘¡ğ‘ğ‘¡. ), etc. A checkmark denotes support for\nthe given factor, while a cross sign indicates the lack of support.\nWe believe that designing a learned index requires prioritiz-\ning concurrency control and robustness as first-class consid-\nerations, adopting a holistic approach to ensure consistency\nin design choices. Therefore, considering the challenges associ-\nated with learned indexes, we propose that a more scalable learned\nindex should simultaneously address the following dimensions:\n2.3.1 Efficient concurrency.\n1) Maintaining statistics should barely impact scalability. To\nenable efficient insertion performance, updatable learned indexes\nmust track statistical information that reflects the degradation of the\nindex structure over time due to new insertions. This information\nis crucial for performing necessary retraining operations. However,\nmaintaining these cumulative statistics jointly by the insertion\nthread can potentially lead to blocking, becoming a scalability bot-\ntleneck for some state-of-the-art learned indexes [ 38]. Therefore,\nthere is an urgent need to develop a lightweight methodology to\nmaintain statistics.\n2) Designing effective index structures for concurrent scenarios.\nIn concurrent scenarios, insertion performance in learned indexes\ncan be hampered by blocking that often arises when multiple inser-\ntion threads work together to uphold key consistency in a single\nlocal structure, particularly under skewed workloads. To mitigate\nthis issue, reducing the manipulation of already-stored keys during\nthe insertion of new ones can help minimize lock granularity and\nlower the risk of thread blocking [21].\n2.3.2 Adaptive ability.\nThe learned index exhibits suboptimal performance under skewed\ninsertion workloads compared to uniform workloads. The lack\nof workload-aware adaptive adjustment capability is the primary\ncause of this deficiency. Therefore, it is critical for a learned in-\ndex to possess the adaptive capacity to guarantee its robustness\nin concurrent scenarios. In addition, the learned index lacks an\noptimization adjustment strategy for the lookup operation, which\nhinders its ability to maximize lookup efficiency in concurrent sce-\nnarios. Furthermore, learned indexes have yet to fully capitalize\non opportunities for significantly reducing index space costs under\nskewed workloads [1].\n2.3.3 Low overheads of basic performance.\n1) Efficient lookup. Achieving high lookup performance in learned\nindexes typically hinges on minimizing prediction errors for lookups,\nas substantial errors can lead to many â€œlast mileâ€ operations in a\nconcurrent scenario. These operations consume additional memory\nbandwidth and negatively impact concurrent performance [38].\n2) Efficient insert. Adopting the model-based strategy (i.e., the\nin-place insertion) rather than the buffer-based strategy (i.e., theTable 1: The limited scalability of existing schemes.\nLearned Basic perform. Concurrency Evolv.\nindex No err In-place Fine lock l-w stat. ability\nRMI[15]Ã—Ã—Ã—Ã—Ã—\nFITing[8]Ã—Ã—Ã—Ã—Ã—\nPGM[5]Ã—Ã—Ã—Ã—Ã—\nALEX+[3]Ã—âˆšÃ—âˆšÃ—\nLIPP+[39]âˆš âˆš âˆšÃ—Ã—\nXIndex[36]Ã—Ã—âˆšÃ—Ã—\nFINEdex[21]Ã—Ã—âˆšÃ—Ã—\nSALIâˆš âˆš âˆš âˆš âˆš\noff-site insertion), can significantly enhance the insert performance\nof learned indexes by reserving gaps in each node (see Section 2.2).\n3 SALI: A PROBABILITY-BASED EVOLVABLE\nLEARNED INDEX FRAMEWORK\nThis section introduces the SALI framework, which addresses the\nconcerns and requirements discussed in Section 1 and 2, and fa-\ncilitates the efficient scalability of learned indexes. Specifically,\nSection 3.1 introduces the overall architecture of SALI, including\nthe architecture built upon ğ‘€ğ‘œğ‘‘.+ğ¶(i.e., the structure of LIPP)\n(columns 2-4 of Table 1). In Section 3.2, we proposed an adaptive\nevolving (adjustment) strategy to further improve the robustness of\nthe learned index under skewed and uniform workloads (columns\n6 of Table 1). Section 3.3 designs a probability-based lightweight\nmethod to maintain statistics of different roles at a meager cost. This\nmethod solves the concurrency performance bottleneck problem\ncaused by the existing high contention statistics method (columns\n5 of Table 1).\n3.1 Overview\n3.1.1 SALI framework. This part introduces the structure of the\nSALI framework, which encompasses the introduction of a probability-\nbased lightweight methodology for statistics maintenance and the\nimplementation of an adaptive evolving strategy. Due to the com-\nmon occurrence of skewed workloads in real-world environments,\nit is advisable to apply different evolution strategies to nodes with\nvarying degrees of read-write hotness. These strategies can serve as\nalternatives to the traditional retraining method, as they are specif-\nically designed to enhance concurrent performance and reduce the\noverhead of index space (Section 3.2). Furthermore, SALI utilizes a\nprobability-based lightweight method to maintain statistics while\nkeeping the timing accuracy of node retraining/evolving without\nblocking insertion operations from multiple threads, unlike the\ntraditional approach of globally maintaining statistics (Section 3.3).\nSpecifically, the SALI framework consists of two phases in Fig-\nure 5. In the first phase, we calculate the probabilities 1for each\nnode that requires evolving during lookup/insert operations to im-\nprove performance. Calculating and maintaining probability models\nis a lightweight alternative to maintaining statistics, which does\nnot cause high contention and thread blocking issues (see Section\n3.3). On the contrary, the traditional manner globally maintains\nstatistics 4, leading to high contention among threads and limiting\nindex scalability. In the second phase, we perform evolving opera-\ntions on nodes that are classified as hot 2or cold 3. Note that\n4\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nFigure 5: The structure of SALI.\nour evolving strategy encompasses the functionality of retraining\noperations in the traditional manner 5(refer to Section 3.2).\n3.1.2 The structure of SALI builds upon the ğ‘€ğ‘œğ‘‘.+ğ¶.Based on our\nobservation in Sections 2.2, we have determined that the structure\nğ‘€ğ‘œğ‘‘.+ğ¶, i.e., the structure of LIPP, exhibits the highest scalability\namong the options considered. Consequently, we have opted to\nimplement and evaluate our novel strategies utilizing ğ‘€ğ‘œğ‘‘.+ğ¶as\nthe underlying index structure. Note that in the subsequent context,\nSALI refers to the structure built upon ğ‘€ğ‘œğ‘‘.+ğ¶, as illustrated in\nFigure 6. Section 3.1.3 and 3.1.4 will introduce the operations of\nSALI and the coordination between different operations.\n3.1.3 Operations of SALI.\n1) Lookup operation: SALI employs a linear model to accurately\npredict the position of the lookup key, except for cold nodes with\nerrors. The search is considered successful during a query if the key\ncontained in the prediction slot is equal to the target key (Algorithm\n1, line 4-6). Otherwise, it does not exist (Algorithm 1, line 7-9).\nHowever, if the predicted slot is a pointer, the search continues in\nthe node pointed to by the pointer (Algorithm 1, line 10-22). At\nthis stage, the type of node needs to be determined. For hot lookup\nnodes, SIMD [ 12] is utilized to locate the node containing the target\nkey, followed by a linear model search in this node (see Figure 7(b)\nand Algorithm 1, line 12-15). In contrast, for cold nodes, where\nthe linear model prediction has an error, a binary search method\ncovers the â€œlast mileâ€ (see Figure 7(c) and Algorithm 1, line 16-18).\nThe rest of the nodes are searched directly using the linear model\n(Algorithm 1, line 19-20).\n2) Insert operation: Initially, the read operation algorithm is used\nto identify the appropriate location for inserting the key. If the key\nalready exists at this position, a new storage space is created below,\nand the key is inserted in this space to handle conflicts (Algorithm\n2, lines 5-9). On the other hand, if the insertion position is a gap,\nthe key is inserted directly (Algorithm 2, lines 2-4).\n3) Evolving operation: See Section 3.2 for details.\n4) Building operation: SALI adopts the structure of LIPP and\ntherefore utilizes the construction algorithm of LIPP, i.e., fastest\nminimum conflict degree (FMCD) [ 39]. In the SALI and the realm of\nthe learned index, other linear and even non-linear approximation\nalgorithms are crucial and intriguing avenues for future research.\nFigure 6: The structure of SALI builds upon the ğ‘€ğ‘œğ‘‘.+ğ¶.\n3.1.4 Coordination between different operations. Reads can pro-\nceed without acquiring the lock as long as SALI verifies that the\nitem being read (i.e., data or child pointer) has not been modified.\nSALI employs an optimistic locking mechanism for the target\nslot during concurrent writing. Since the SALIâ€™s structure ensures\nthat only fine-grained locks are necessary to guarantee mutually\nexclusive writes, write conflicts are rare under a uniform workload.\nTo prevent uncontrollable tail latency that may arise from pro-\nlonged evolution, we restrict the evolution process to nodes with\nless than one million keys. Our observations indicate that indexes\nwith higher write rates require periodic rebuilding to maintain good\nperformance. Consequently, during periods of relative inactivity\nin the storage system, the entire index structure can be rebuilt,\nresulting in a flatter SALI structure and improved performance.\nFurthermore, when the node is evolving, we use the Read-Copy-\nUpdate (RCU) mechanism [ 31,35] to prevent the blocking of read\noperations, i.e., reading the old version of data. Following the evo-\nlution operation, SALI utilizes the RCU to ensure all threads can\naccess the new model. RCU barrier is a synchronization mecha-\nnism designed for concurrent systems, which enables all readers\nto access the new space in shared memory after evolving oper-\nation. In addition, to ensure that child nodes being read are not\ndeleted during the evolution process, SALI utilizes the epoch-based\nreclamation [ 6] that guarantees the safety of node pointers in a\nconcurrent scenario.\n3.2 Evolving Strategies\nA more comprehensive adaptation strategy than simply retraining\nis required to adapt the learned index structure under various work-\nloads. This part presents the design of an evolving strategy that\nfocuses on three aspects to enhance the concurrency performance\nof the learned index. Note that this part only covers the evolving\nstrategy, while the conditions and timing for triggering the evolv-\ning process will be discussed in Section 3.3. Next, we will briefly\nintroduce the difference between evolving and retraining:\na) Retraining is a passive adjustment strategy used in updatable\nlearned indexes to maintain their performance. Its main features\nare: 1) it is driven by the deterioration of the index structure and\ncannot sense different workloads; 2) it is triggered only by insert\noperations optimized exclusively for improving insert performance;\nand 3) it does not change the index structure in essence.\n5\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nFigure 7: The evolving strategies.\nAlgorithm 1 SALI Lookup Operation\nRequire: Target key:ğ‘˜.\n1:functionğ‘™ğ‘œğ‘œğ‘˜ğ‘¢ğ‘ _ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ‘˜)\n2:ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡â†ğ‘Ÿğ‘œğ‘œğ‘¡.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ(ğ‘˜)\n3: while (TRUE) do\n4: ifğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘¡ğ‘¦ğ‘ğ‘’ ==ğ‘˜ğ‘’ğ‘¦then\n5: ifğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘‘ğ‘ğ‘¡ğ‘ ==ğ‘˜then\n6: return (ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘‘ğ‘ğ‘¡ğ‘ )\n7: else\n8: return (ğ‘›ğ‘œğ‘¡ ğ‘“ğ‘œğ‘¢ğ‘›ğ‘‘ )\n9: end if\n10: else âŠ²ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘¡ğ‘¦ğ‘ğ‘’ ==ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿ\n11: ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘â†ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘‘ğ‘ğ‘¡ğ‘\n12: if(ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘¡ğ‘¦ğ‘ğ‘’ ==â„ğ‘œğ‘¡_ğ‘™ğ‘œğ‘œğ‘˜ğ‘¢ğ‘ )then\n13: ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿâ†ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘†ğ¼ğ‘€ğ·(ğ‘˜)\n14: ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡â†ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ(ğ‘˜)\n15: end if\n16: if(ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘¡ğ‘¦ğ‘ğ‘’ ==ğ‘ğ‘œğ‘œğ‘™ğ‘–ğ‘›ğ‘” )then\n17: ğ‘ğ‘Ÿğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡_ğ‘ğ‘Ÿğ‘’â†ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ(ğ‘˜)\n18: ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡â†ğ‘ğ‘–_ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„(ğ‘ğ‘Ÿğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡_ğ‘ğ‘Ÿğ‘’,ğ‘˜)\n19: else âŠ²ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘¡ğ‘¦ğ‘ğ‘’ ==ğ‘›ğ‘œğ‘šğ‘ğ‘™\n20: ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡â†ğ‘›ğ‘œğ‘‘ğ‘’ğ‘  _ğ‘šğ‘’ğ‘¡ğ‘.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ(ğ‘˜)\n21: end if\n22: end if\n23: end while\n24:end function\nb) Evolving, proposed in this paper, is a novel concept in learned\nindexes that includes the retraining function and improves the\nindexâ€™s adjustment mechanism in different dimensions. Its main\nfeatures are: 1) it is an active adjustment strategy that perceives and\nis driven by the workload to improve index performance further;\n2) it can be triggered by any operation (e.g., read); and 3) it can\nâ€œevolveâ€ into a new structure type that is suitable for the current\nworkload for both improving the read and insert performance.\n3.2.1 The insert triggers the evolving operation. Most retraining\nmethods, including SALI, involve expanding the target node or its\nsubtree. This expansion creates more gaps that can be used for in-\nserting keys, thereby improving the overall insertion performance.\nAs shown in Figure 7(a), the gap array within the data node is in-\ncreased from two to five to accommodate more keys. To achieve\nthis, the FMCD algorithm [ 39] is used to expand the node by in-\nputting all of the keys in the node and the desired space size after\nexpansion (see Algorithm 3, lines 1-4).\nHowever, a fixed retraining expansion factor may not be suffi-\ncient to handle sudden increases in local insertions under a skewed\nworkload, which can lead to a high number of insert conflicts in\nconcurrent scenarios. To address this, the expansion factor shouldAlgorithm 2 SALI Insertion Operation\nRequire: Target key:ğ‘˜.\n1:functionğ‘–ğ‘›ğ‘ ğ‘’ğ‘Ÿğ‘¡ğ‘–ğ‘œğ‘› _ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘› (ğ‘˜)\n2:ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡â†ğ‘™ğ‘œğ‘œğ‘˜ğ‘¢ğ‘ _ğ‘œğ‘ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œğ‘›(ğ‘˜)\n3: if(ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡=ğ‘ğ‘ˆğ¿ğ¿ )then\n4: insert(ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡,ğ‘˜ )\n5: else âŠ²ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘¡ğ‘¦ğ‘ğ‘’ ==ğ‘˜ğ‘’ğ‘¦\n6:ğ‘œğ‘™ğ‘‘_ğ‘˜â†ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘‘ğ‘ğ‘¡ğ‘\n7:ğ‘ğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿâ†ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘¡ğ‘¦ğ‘ğ‘’\n8:ğ‘›ğ‘’ğ‘¤ _ğ‘›ğ‘œğ‘‘ğ‘’â†ğ‘ğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ _ğ‘ ğ‘™ğ‘œğ‘¡.ğ‘‘ğ‘ğ‘¡ğ‘\n9: insert(ğ‘›ğ‘’ğ‘¤ _ğ‘›ğ‘œğ‘‘ğ‘’,ğ‘œğ‘™ğ‘‘ _ğ‘˜,ğ‘˜)\n10: end if\n11:end function\nbeadaptively adjusted based on the insertion rate to determine the\noptimal expansion size. Specifically, more gaps are reserved to en-\nhance the insertion performance when the insertion rate increases.\nFor more information, please refer to Equation (1) below:\nğ‘›.ğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ _ğ‘ ğ‘–ğ‘§ğ‘’=ï£±ï£´ï£´ ï£²\nï£´ï£´ï£³ğ›¾Ã—ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ ğ‘¡\nğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ ğ‘¡âˆ’1Ã—ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š,ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ ğ‘¡\nğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ ğ‘¡âˆ’1â‰¥1\nğ›¾Ã—ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š,ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ ğ‘¡\nğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ ğ‘¡âˆ’1<1\n(1)\nAmong them, ğ‘›refers to a specific node, ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š represents\nthe size of the current node. ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡represents the accumulation\nrate at timeğ‘¡, indicating the insertion rate of new keys into a node at\nthat specific time. This rate is determined by a probabilistic model,\nas described in Section 3.3. In Equation (1), a higher speed leads to a\nmore significant expansion rate in the current operation, meaning\nthat more gaps will be reserved compared to the previous expansion\noperation. The expansion factor ğ›¾is defined as follows:\nğ›¾=ï£±ï£´ï£´ ï£²\nï£´ï£´ï£³ğœƒ, ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘šâ‰¥1ğ‘€\n2ğœƒ, ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘šâ‰¥100ğ¾\n5ğœƒ, ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š<100ğ¾(2)\nEquation (2) reveals that nodes of varying sizes should have\ndifferent expansion factors. Equation (1) demonstrates that smaller\nnodes (ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š), need a more significant expansion factor to\nachieve adequate expansion. E.g., if the number of slots in two\nnodes is 4 and 8, respectively, both nodes would need to expand by\n32 units, requiring expansion factors of 8 and 4, respectively. The\nexpansion base factor, denoted by ğœƒ, can be dynamically adjusted\nbased on varying workloads. For our evaluation, we set ğœƒto its\ndefault value of 1.\n3.2.2 The lookup triggers the evolving operation. We have devel-\noped an evolving strategy for hot read nodes to enhance concurrent\nread performance under skewed workloads further. Note that if the\n6\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nFigure 8: The framework for identifying cold nodes.\nAlgorithm 3 SALI Insertion Evolving\nRequire: Sequenceğ‘˜ğ‘’ğ‘¦ğ‘ {ğ¾1,Â·Â·Â·,ğ¾ğ‘›}in ağ‘ğ‘œğ‘‘ğ‘’ and itsğ‘†ğ‘¢ğ‘ğ‘¡ğ‘Ÿğ‘’ğ‘’ .\n1:functionğ¼ğ‘›ğ‘ ğ‘’ğ‘Ÿğ‘¡ _ğ‘ğ‘œğ‘‘ğ‘’ _ğ¸ğ‘£ğ‘œğ‘™ğ‘£ğ‘–ğ‘›ğ‘” (ğ‘˜ğ‘’ğ‘¦ğ‘  )\n2:ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘šğ‘œğ‘‘ğ‘’ğ‘™â†ğ¹ğ‘€ğ¶ğ·(ğ‘˜ğ‘’ğ‘¦ğ‘ ,ğ‘›.ğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ _ğ‘ ğ‘–ğ‘§ğ‘’)\n3:ğ‘“ğ‘ğ‘¡â„ğ‘’ğ‘Ÿ _ğ‘ ğ‘™ğ‘œğ‘¡linkğ‘ ğ‘’ğ‘”ğ‘ .ğ‘šğ‘œğ‘‘ğ‘’ğ‘™\n4:end function\nAlgorithm 4 SALI Lookup Evolving\nRequire: Sequenceğ‘˜ğ‘’ğ‘¦ğ‘ {ğ¾1,Â·Â·Â·,ğ¾ğ‘›}in ağ‘ğ‘œğ‘‘ğ‘’ and itsğ‘†ğ‘¢ğ‘ğ‘¡ğ‘Ÿğ‘’ğ‘’ .\n1:functionğ»ğ‘œğ‘¡_ğ¿ğ‘œğ‘œğ‘˜ğ‘¢ğ‘ _ğ‘ğ‘œğ‘‘ğ‘’ _ğ¸ğ‘£ğ‘œğ‘™ğ‘£ğ‘–ğ‘›ğ‘” (ğ‘˜ğ‘’ğ‘¦ğ‘  )\n2:ğ‘”ğ‘ğ‘_ğ‘ğ‘Ÿğ‘Ÿğ‘ğ‘¦â†ğ‘ğ‘ğ‘™ğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘’ _ğ‘”ğ‘ğ‘(ğ‘˜ğ‘’ğ‘¦ğ‘ )\n3:ğ‘”ğ‘ğ‘_ğ‘ğ‘Ÿğ‘Ÿğ‘ğ‘¦â†ğ‘‡ğ‘œğ‘âˆ’ğ‘˜(ğ‘”ğ‘ğ‘_ğ‘ğ‘Ÿğ‘Ÿğ‘ğ‘¦)\n4: for(ğ‘”ğ‘ğ‘_ğ‘ğ‘Ÿğ‘Ÿğ‘ğ‘¦.ğ‘ ğ‘–ğ‘§ğ‘’ >0)do\n5:ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡.ğ‘˜ğ‘’ğ‘¦â†ğ‘ ğ‘ğ‘™ğ‘–ğ‘¡(ğ‘”ğ‘ğ‘_ğ‘ğ‘Ÿğ‘Ÿğ‘ğ‘¦)\n6:ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿâ†ğ‘ğ‘ğ‘ğ‘Ÿğ‘œğ‘¥ğ‘–ğ‘šğ‘ğ‘¡ğ‘–ğ‘œğ‘› _ğ‘ğ‘™ğ‘”(ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡.ğ‘˜ğ‘’ğ‘¦)\n7:ğ‘ ğ‘’ğ‘”ğ‘ â†ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘ğ‘ğ‘ğ‘’ğ‘›ğ‘‘(ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡.ğ‘˜ğ‘’ğ‘¦,ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡.ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ )\n8: end for\n9:ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘™ğ‘–ğ‘›ğ‘’.ğ‘ ğ‘™ğ‘œğ‘ğ‘’â†ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘™ğ‘–ğ‘›ğ‘’.ğ‘ ğ‘™ğ‘œğ‘ğ‘’Ã—ğ‘›.ğ‘’ğ‘¥ğ‘ğ‘ğ‘›ğ‘‘ _ğ‘ ğ‘–ğ‘§ğ‘’\n10:ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘šğ‘œğ‘‘ğ‘’ğ‘™â†ğ‘–ğ‘›ğ‘ ğ‘’ğ‘Ÿğ‘¡(ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡.ğ‘˜ğ‘’ğ‘¦,ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ )\n11:ğ‘“ğ‘ğ‘¡â„ğ‘’ğ‘Ÿ _ğ‘ ğ‘™ğ‘œğ‘¡linkğ‘ ğ‘’ğ‘”ğ‘ .ğ‘šğ‘œğ‘‘ğ‘’ğ‘™\n12:end function\nAlgorithm 5 SALI Cold Node Evolving\nRequire: Sequenceğ‘˜ğ‘’ğ‘¦ğ‘ {ğ¾1,Â·Â·Â·,ğ¾ğ‘›}in ağ‘ğ‘œğ‘‘ğ‘’ and itsğ‘†ğ‘¢ğ‘ğ‘¡ğ‘Ÿğ‘’ğ‘’ .\n1:functionğ¶ğ‘œğ‘œğ‘™ğ‘–ğ‘›ğ‘” _ğ‘ğ‘œğ‘‘ğ‘’ _ğ¸ğ‘£ğ‘œğ‘™ğ‘£ğ‘–ğ‘›ğ‘” (ğ‘˜ğ‘’ğ‘¦ğ‘  )\n2:ğ‘ ğ‘’ğ‘”ğ‘ .ğ‘šğ‘œğ‘‘ğ‘’ğ‘™â†ğ‘ƒğ¿ğ´ _ğ‘ğ‘™ğ‘”ğ‘œğ‘Ÿğ‘–ğ‘¡â„ğ‘š(ğ‘˜ğ‘’ğ‘¦ğ‘ )\n3:ğ‘“ğ‘ğ‘¡â„ğ‘’ğ‘Ÿ _ğ‘ ğ‘™ğ‘œğ‘¡linkğ‘ ğ‘’ğ‘”ğ‘ .ğ‘šğ‘œğ‘‘ğ‘’ğ‘™\n4:end function\nworkload is uniform, SALI can either choose to disable this evolv-\ning function or treat every node as a hot read node. As depicted in\nFigure 7(b), we have designed a flat structure for hot reads nodes\nand their subtrees. This structure flattens the nodes and promotes\ntheir levels as much as possible. Unlike the initial state where a\nsingle linear segment is linked under one slot, multiple segments\ncan be linked under one slot after evolving. This flattening strategy\nreduces the tree height of the local hot structure. Furthermore, SALI\ncan use SIMD instructions during lookup to quickly find which\nnode the target key belongs to in the same layer.\nWe have developed a method to reconstruct structure, which\nhas the effect of flattening the node and its subtrees (Algorithm 4).\nFirst, we sort all the nodesâ€™ keys, calculate the gap between twoadjacent keys, and select the ğ‘¡ğ‘œğ‘âˆ’ğ‘˜gap (Algorithm 4, line 2). Then,\nwe split into ğ‘˜âˆ’1segments based on these gaps and generate a\nlinear model using the least squares algorithm (Algorithm 4, lines\n3-8). According to Equation (1), we expand the slope of the linear\nmodel by a corresponding multiple to expand the corresponding\nspace (Algorithm 4, line 9). Reserving the gap enables the CDF of\nthe stored data to fit more easily on a line and improve lookup\nperformance. Finally, we calculate the positions of all keys and\ninsert them using the linear model after the slope expands. If there\nare still conflicts, we handle them similarly to SALIâ€™s insertion\nconflict (Algorithm 4, line 10).\n3.2.3 Identify the cold node and trigger evolving operation. We de-\nveloped a cold node-compression evolving strategy to optimize\nspace usage in SALI under skewed workloads. In addition to ini-\ntially creating the SALI index structure, we added a cooling pool\nspace as illustrated in Figure 8. During SALI construction or each\nevolving operation, each node in the index has a 10% probability\nof being chosen for inclusion in the cooling pool. When a node\nundergoes an evolving operation, that node, its subtrees, and all\nnodes above it are removed from the cooling pool. At this stage, the\nnodes that remain in the cooling pool are considered temporarily\ncold. We took inspiration for cold node design from [17].\nOnce each evolving operation finishes, SALI checks whether the\nuser-acceptable index size upper limit has been exceeded. If it has,\nSALI selects the earliest-added node in the cooling pool for the\ncompress operation and deletes it from the cooling pool until the\nspace is reduced to meet the user-acceptable index size.\nFor cold nodes, we implemented a space compression strategy.\nAs depicted in Figure 7(c), we cancel the reserved gaps to save\nspace for cold nodes and their subtrees. We use the PLA algorithm\nin PGM [ 5] to linearly approximate all keys in a cold node and\ngenerate the corresponding segment (Algorithm 5).\n3.3 Probability Model\nIn order to ensure optimum performance, it is imperative that\nlearned indexes monitor degradation statistics to initiate adjusting\nwhen necessary. Unfortunately, existing high-contention statistics\ntechniques severely limit the scalability of learned indexes. More-\nover, the implementation of the complete adjustment strategy, i.e.,\nevolving presented in Section 3.2, demands additional statistics,\nresulting in intolerable overhead in a concurrent scenario.\n7\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nTo address this issue, we propose a probability-based strategy\nthat employs a lightweight approach to maintain various statistics\nin SALI to trigger evolving operations at a minimal cost.\nNote that the fundamental concept behind the probability mod-\nels is to leverage probabilities in simulating the accumulation of\ninformation. For example, when simulating the cumulative num-\nber of inserted keys within a specified timeframe, we design a\nprobability model based on the insertion rate and insertion time.\nFurthermore, the geometric distribution can be utilized to simulate\nthe accumulation of information such as insertion conflicts.\n3.3.1 Probability model for triggering insert evolution. Most retrains\nare triggered by the deterioration of learned indexes caused by\ninsert operations. However, from an overall perspective of index\nperformance, adjustments should be considered based on whether\nthe local structure, following its adjustment, will continue to see\nthe high-frequency insertion of new keys. Such consideration can\nmake the adjustment operation more advantageous, which achieves\nhigh amortized performance benefits.\nTherefore, two conditions need to be considered to trigger in-\nsertion evolution: 1) The assessment of the frequency of new key\ninsertions in a node and its subtree is crucial in determining whether\nan adequate number of keys are being inserted. The nodeâ€™s per-\nformance gains are higher after evolving if the frequency of new\nkey insertions is high. 2) The escalation of conflicts within a node\nalongside the gradual increase in the number of newly inserted keys\nrepresents a critical aspect as it can be used to indicate the deteri-\noration of the index. Identifying deteriorating nodes is crucial, as\nonly evolving such nodes will significantly improve performance.\nNote that when a node satisfies only condition 1) and not condi-\ntion 2), evolving is unnecessary because the insertion performance\nremains satisfactory. When a node satisfies only condition 2) and\nnot condition 1), the amortized performance benefit is low, and\nthe evolving operation entails overhead costs. Therefore, satisfying\nboth conditions simultaneously is a prerequisite for triggering the\ninsert evolving operation. In the subsequent section, we provide a\ncomprehensive analysis of the above two doctrinal conditions.\nCondition (1): the node accommodates a sufficient number\nof newly inserted keys. To determine if this condition is met, we\nneed to satisfy the following equation:\nğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘š\nğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘šâ‰¥ğ›½ (3)\nğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘š refers to the number of keys contained in the\nnode at the end of the current insertion operation. ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š\nindicates the number of keys in the node when the last â€œevolvingâ€\noperation was performed. The tolerance coefficient ğ›½specifies the\nmaximum amount of data that can be inserted into the node before\nit needs to be adjusted. As a general guideline, we set ğ›½=2.\nSince each insertion thread must maintain the cumulative vari-\nableğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘š, conflicts may arise. To address this issue, we\npropose a lightweight probability model.\nFirst, we multiply the insertion rate by the timestamp difference\nto get the total amount of inserted new keys during this period and\nput it into Equation (3) to get:[ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡Ã—(ğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘¡ğ‘–ğ‘šğ‘’âˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘¡ğ‘–ğ‘šğ‘’)]+ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š\nğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘šâ‰¥ğ›½\n(4)\nThe variable ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘¡ğ‘–ğ‘šğ‘’ represents the timestamp correspond-\ning to stateğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š, whileğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘¡ğ‘–ğ‘šğ‘’ represents the cur-\nrent timestamp. The estimated insertion rate, denoted as ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡2,\nis calculated using Equation (5), which takes the quotient of the total\nnumber of insertions and the difference in timestamp from the previ-\nous period. Therefore, we can estimate the value of ğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘š\nusingğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡Ã—(ğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘¡ğ‘–ğ‘šğ‘’âˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘¡ğ‘–ğ‘šğ‘’)]+ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š\nat timeğ‘¡.\nğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘šâˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š\nğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘¡ğ‘–ğ‘šğ‘’âˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘¡ğ‘–ğ‘šğ‘’=ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡+1 (5)\nAdditionally, we define the cumulative probability within a node\nasğ‘ƒğ‘ğ‘ğ‘(see Equation (6)), as obtained through the transformation\nof Equation (4). When ğ‘ƒğ‘ğ‘ğ‘=1, condition (1) is met. When ğ‘ƒğ‘ğ‘ğ‘<1,\nwe determine whether the evolving adjustment is necessary based\non a Bernoulli experiment. If the experiment is successful, condition\n(1) is met; otherwise, it is not met.\nğ‘ƒğ‘ğ‘ğ‘=[ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡Ã—(ğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘¡ğ‘–ğ‘šğ‘’âˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘¡ğ‘–ğ‘šğ‘’)]\n(ğ›½âˆ’1)Ã—ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š(6)\nNote that the calculation of Equation (5) may result in ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘\nbeing zero. In such cases, the cumulative probability computed by\nEquation (6) will always be zero, preventing any further changes\ninğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ . To resolve this issue, we introduce a reconciling vari-\nableğœ–in the numerator of Equation (6). Expressly, we set ğœ–=\nğ‘ğ‘ğ‘¡â„ _ğ‘ ğ‘–ğ‘§ğ‘’/1000, whereğ‘ğ‘ğ‘¡â„ _ğ‘ ğ‘–ğ‘§ğ‘’ denotes the path length from the\nroot node to the current node. The final Equation of the cumula-\ntive probability model, Equation (7), determines whether the node\naccommodates a sufficient number of newly inserted keys.\nğ‘ƒğ‘ğ‘ğ‘=[ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡Ã—(ğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘¡ğ‘–ğ‘šğ‘’âˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘¡ğ‘–ğ‘šğ‘’)]+ğœ–\n(ğ›½âˆ’1)Ã—ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š(7)\nCondition (2): the node accommodates an adequate num-\nber of conflicts. We calculate the ratio of insertion conflicts to the\ntotal number of insertions:\nğ‘›.ğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ _ğ‘›ğ‘¢ğ‘š\nğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘šâˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘šâ‰¥ğ›¼ (8)\nThe variable ğ‘›.ğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ _ğ‘›ğ‘¢ğ‘š denotes the total number of con-\nflicts in the node resulting from the insertions between the last\nevolving operation and the current state. Meanwhile, the conflict\ntolerance coefficient is denoted by ğ›¼, which we typically set to 0.1\nas a rule of thumb. Similar to Condition (1), in a concurrent scenario,\nwe need to develop a probability model to estimate the number of\nconflicts to avoid blocking threads according to Equation (8).\nFor an evolving operation to occur, the node must have sufficient\nnewly inserted keys. Therefore, we use (ğ›½âˆ’1)Ã—ğ‘›.ğ‘ğ‘¢ğ‘™ğ‘–ğ‘‘ _ğ‘›ğ‘¢ğ‘š to\nestimate the number of new insertions according to Equation (3)\nwhen there are enough conflicts to cause evolution:\n(ğ‘›.ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ _ğ‘›ğ‘¢ğ‘šâˆ’ğ‘›.ğ‘ğ‘¢ğ‘–ğ‘™ğ‘‘ _ğ‘›ğ‘¢ğ‘š)â‰ˆ(ğ›½âˆ’1)Ã—ğ‘›.ğ‘ğ‘¢ğ‘™ğ‘–ğ‘‘ _ğ‘›ğ‘¢ğ‘š (9)\n2We assign a specific value to ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ 1.\n8\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nBy substituting Equation (9) into Equation (8), we obtain Equa-\ntion (10):\nğ‘›.ğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ _ğ‘›ğ‘¢ğ‘šâ‰¥ğ›¼Ã—(ğ›½âˆ’1)Ã—ğ‘›.ğ‘ğ‘¢ğ‘™ğ‘–ğ‘‘ _ğ‘›ğ‘¢ğ‘š (10)\nWhen an insertion causes a conflict, we set the conflict adjust-\nment probability to ğ‘ƒğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ . Using the expectation of the geo-\nmetric distribution, we can estimate that the expected number\nof conflicts that trigger evolving after the conflict is1\nğ‘ƒğ‘ğ‘œğ‘›ğ‘“ ğ‘™ğ‘–ğ‘ğ‘¡, i.e.,\n1\nğ‘ƒğ‘ğ‘œğ‘›ğ‘“ ğ‘™ğ‘–ğ‘ğ‘¡â‰ˆğ‘›.ğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ _ğ‘›ğ‘¢ğ‘š. Thus, whenever a conflict occurs in a\nnode, we trigger the probability model specified in Equation (11) to\ndetermine if the model deteriorates and requires evolving.\nğ‘ƒğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ =1\nğ›¼Ã—(ğ›½âˆ’1)Ã—ğ‘›.ğ‘ğ‘¢ğ‘™ğ‘–ğ‘‘ _ğ‘›ğ‘¢ğ‘š(11)\nApplication in SALI: In SALI, we only compute probabili-\nties when a conflict occurs to minimize overhead. We determine\nwhetherğ‘ƒğ‘ğ‘œğ‘›ğ‘“ğ‘™ğ‘–ğ‘ğ‘¡ is triggered; if so, we proceed to determine whether\nğ‘ƒğ‘ğ‘ğ‘is also triggered. If both conditions are met, the evolving oper-\nation is necessary to adjust the insertion structure of SALI.\n3.3.2 Probability model for triggering lookup evolution. We define\nthe probability that a target node is identified as a hot read node due\nto alookup operation, denoted as ğ‘ƒâ„ğ‘™, that is a hyperparameter that\ncan be set to an appropriate value. Whenever the lookup operation\nencounters a node, we can check whether ğ‘ƒâ„ğ‘™is triggered for that\nnode. Ifğ‘ƒâ„ğ‘™is triggered, we consider the node and its subtree as a\nhot lookup structure.\nIn addition to the probability ğ‘ƒâ„ğ‘™, the following conditions for\nsetting the read trigger probability also need to be considered:\n(1) The evolving operation has not been triggered by lookup\noperations on the node for a prolonged period of time.\n(2) The rate at which the node accumulates data ( ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡) through\ninsertions is not slow.\nFor condition (1), if the last evolve operation of a node was\ntriggered by a hot lookup, it means that no insert operation has trig-\ngered the node to evolve since then, i.e., the node has not severely\ndeteriorated, and the number of new insertion keys are likely to be\nfew. In this case, we can adjust ğ‘ƒâ„ğ‘™to a smaller value to prevent\nfrequent evolving, i.e., ğ‘ƒâ„ğ‘™=ğ‘ƒâ„ğ‘™Ã—ğœ†, whereğœ†is a penalty coefficient.\nFor condition (2), in addition to ğ‘ƒâ„ğ‘™, we introduce the probability\nğ‘ƒğ‘ğ‘ğ‘, as defined in Equation (7). If a large number of new keys are\ninserted since the last evolving operation, it suggests that a new\nround of evolving operations may be necessary.\nApplication in SALI: We generate a ğ‘ ğ‘˜ğ‘–ğ‘_ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿ in each\nlookup thread-local, which maintains the number of lookup opera-\ntions. Upon execution of a lookup operation, the ğ‘ ğ‘˜ğ‘–ğ‘_ğ‘ğ‘œğ‘¢ğ‘›ğ‘¡ğ‘’ğ‘Ÿ is\nincremented by 1. After every 10 lookup operations, a Bernoulli\nexperiment is conducted to determine whether ğ‘ƒâ„ğ‘™is triggered. If\nğ‘ƒâ„ğ‘™is triggered, the system verifies whether ğ‘ƒğ‘ğ‘ğ‘is also triggered.\nIfğ‘ƒğ‘ğ‘ğ‘is triggered, SALI proceeds with the evolving operation.\n4 EVALUATION\nThis section conducts a comprehensive evaluation of SALI. Sec-\ntion 4.1 describes the experimental setup. Section 4.2 compares\nSALIâ€™s performance with that of several state-of-the-art concurrent\nlearned indexes and traditional indexes using various datasets andthread counts. Section 4.3 evaluates SALI under skewed workloads.\nFinally, Section 4.4 conducts an ablation study on SALI.\n4.1 Experimental Setup\nAll experiments are conducted on a two-socket server with two\n16-core Intel Xeon Gold 6242 @2.80GHz CPUs (hyper-threading to\n64 threads) and 384GB of DRAM. We implemented SALI with âˆ¼4k\nLOC of C++.\n4.1.1 Baselines. We benchmarked SALI against six baselines. 1)\nMasstree [ 28], a hybrid index structure of B+Tree and Radix Tree;\n2) ART-OLC [ 19], an exemplary concurrency implementation of\nthe Adaptive Radix Tree (ART) [ 18]. 3) ALEX+ [ 38], an exemplary\nconcurrency implementation of the ALEX [ 3]. 4) LIPP+ [ 38], a\nconcurrency implementation of the LIPP [ 39]. 5) XIndex [ 36], a first\nattempt to design a concurrent learned index. 6) FINEdex [ 21], a\nfine-grained updated concurrent learned index.\n4.1.2 Datasets. We selected several real datasets from SOSD [ 29]\nand GRE [38] benchmarks.\nâ€¢COVID: Tweet ID with tag COVID-19 [ 24] (Uniformly sampled).\nâ€¢FACE: Facebook user ID [11].\nâ€¢LIBIO: Repository ID from libraries.io [38].\nâ€¢OSM: OpenStreetMap locations [29] (Uniformly sampled).\nâ€¢GENOME: Pairs of locations on human chromosomes [34].\nNote that according to paper [ 38], the OSM and GENOME datasets\nare considered to be of â€œhardâ€ difficulty for learned indexes, as fit-\nting a Cumulative Distribution Function (CDF) on these datasets\nis challenging. Relatively, fitting remaining datasets with a CDF is\ncomparably easier.\n4.1.3 Workloads. We design workloads to generate requests using\nthe aforementioned datasets. To achieve this, we randomly shuffle\nall 200 million keys for each dataset and issue insert and lookup\nrequests based on the following ratios:\nâ€¢Read-Only: Load all 200M keys and randomly search 800M.\nâ€¢Read-Intensive (20% insert): Load 100M random keys and per-\nform 80% search &20% insert, i.e., insert all the remaining keys.\nâ€¢Balanced (50% insert): Load 100M random keys and perform\n50% search &50% insert, i.e., insert all the remaining keys.\nâ€¢Write-Only: Load 100M keys and insert 100M keys.\nâ€¢Hot-read-A (100% Read): Load 200M keys. Select 1/10 of these\n200M (20M) as hot read keys and execute five rounds of read opera-\ntions on these 20M keys, i.e., 100M read operations.\nâ€¢Hot-read-B (16% insert): Perform an additional insert operation\nof 20M keys based on the keys from Hot-read-A.\nâ€¢Hot-write (100% Insert): Randomly select one-eighth consec-\nutive data in the 200M data as the hot insert, and insert it after\nloading the remaining data.\nWe repeated 10 and 5 experiments for Hot-write and other work-\nloads, respectively, excluding the lowest and the highest measure,\nand reported the average of the results. Between each measurement\nof experiments, we wiped caches and re-loaded the data to avoid\nintermediate results.\n9\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nFigure 9: The indexes scalability on write-only workloads. The grey area indicates that the threads number exceeds the\nmaximum logical cores number. Extended plots with all evaluations are available here: [9]\nFigure 10: The latency of indexes on write-only workloads.\n4.2 Overall Results\nThis section evaluates the SALIâ€™s overall performance against the\nSOTA indexes that support concurrency. In this experiment, uni-\nform workloads were used. To ensure fairness, SALI turns off the\njudgment and evolution modules temporarily of hot read nodes\nbut reserves the evolving operations triggered by the insertion on\nSALI, as all indexes require maintaining statistical information and\nperforming retraining operations when inserting data.\n4.2.1 Write-only workloads. Figure 9 shows the concurrent perfor-\nmance evaluation of various learned indexes when executing the\nwrite-only workload on different datasets. The triggered retraining\nis directly executed in the foreground by the thread responsible for\ntriggering. These threads are represented by the numbers specified\non the x-axis. All indexes except LIPP+ benefit from increasing\nthreads, but performance drops when the number of threads ex-\nceeds the logical thread count.\nIn easy datasets, namely COVID, LIBIO, and FACE, SALI per-\nforms better in terms of throughput overall. Compared to the\nlearned index ALEX+ and traditional index ART-OLC, SALI exhibits\nthe best scalability. ALEX+ and ART-OLC exhibit a sharp perfor-\nmance drop when the number of threads exceeds 60, whereas SALI\nmaintains a high and stable performance. In the COVID dataset,\nSALI outperforms the best two baselines, i.e., ALEX+ and ART-OLC,\nby up to 47% and 73% at the highest solution, respectively, and the\nadvantage continues to expand beyond 60 threads.\nIn hard datasets, SALI outperforms other learned indexes by up\nto a factor of 2.5x to 10x, as SALI can accurately fit complex CDF,\nso that its performance can match ART-OLC and still maintain\nperformance even exceeding the number of logical threads, where,\nin contrast, the performance of ART-OLC sharply declined.\nIt is noteworthy that ALEX+ and ART-OLC exhibit significant\nperformance degradation when threads exceed 60. This issue is\ndue to the coarse-grained lock, resulting in severe thread blocking\nwhen insertion (as discussed in Section 2.2).\nAdditionally, the buffer-based insert strategy used by XIndex\nand FINEdex results in a large lookup error, and frequent â€œlast mileâ€\nsearches result in poor scalability. LIPP+ employs a high-contendmethod for all nodes to statistic information, leading to severe block-\ning of insertion threads and cache-line ping-pong, which complete\nloss of scalability in a concurrent scenario.\nFigure 10 shows the 99.9% tail latency on FACE and OSM datasets.\nAs threads increase, ALEX+ and LIPP+ exhibit significant increases\nin tail latency. ALEX+ has coarse-grained locks, which cause thread\nblocking during insertion and retraining operations, resulting in a\nsignificant increase in tail latency. LIPP+ requires joint maintenance\nof statistical information by different threads, leading to an increase\nin thread blocking and a significant increase in tail latency. In\ncontrast, the other indexes do not show noticeable increases, and\nSALI maintains the lowest in most settings.\nInsight 1: Concurrent insertion often faces three chal-\nlenges: a) high-contend statistics maintenance causing thread\nblocking; b) coarse-grained write locks leading to thread\nblocking; c) write amplification and lookup errors causing\nmemory bandwidth exhaustion. SALI efficiently addresses\nthem, leading to exceptional scalability, especially with hard\ndatasets and a high number of threads.\n4.2.2 Read-write workloads. The performance of different indexes\nunder read-intensive and balanced workloads is shown in Figure 11.\nFigure 11(a,b) exhibit that SALI outperforms other indexes under\nread-intensive workloads, especially in the easy dataset. Compared\nto ART-OLC and ALEX+, SALI improves the performance by up to\n37% and 55%, respectively, under 60 threads.\nFigure 11(c,d) illustrate the performance under the balanced\nworkload. SALI maintains high scalability. Other indexesâ€™ perfor-\nmance also exhibits similar to the read-intensive workloads.\nNevertheless, LIPP+ remains unscalable. And when the number\nof threads exceeds 60, the performance of ALEX+ and ART-OLC\ndegrades significantly. The aforementioned indicates that even with\na low proportion of write operations (20% insert), the indexes expe-\nrience a bottleneck under ultra-high threading conditions.\nIn Figure 11(e), the tail latency of the index under the balanced\nworkload is illustrated. Similar to Figure 10, ALEX+ and LIPP+\nexhibit higher tail latencies compared to the other indexes. However,\nas the read ratio increases, the tail latency of both indexes decreases.\nNotably, SALI maintains consistently low tail latency throughout.\nInsight 2: SALI exhibits outstanding scalability under work-\nloads that involve insertion operations, even under hard\ndatasets. Conversely, other indexes face scalability bottle-\nnecks, even with a low proportion of insert operations.\n4.2.3 Read-only workloads. Figure 12 presents the evaluation of\nthe read-only workload. SALI and LIPP+ outperform other indexes\nin both easy and hard datasets, as they adopt a model-based insert\n+ chain structure, which enables accurate lookups.\n10\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nFigure 11: The indexes scalability on read-write workloads. Extended plots with all evaluations are available here: [9]\nFigure 12: The indexes scalability on read-only workloads. Extended plots with all evaluations are available here: [9]\nFigure 13: The performance of the evolving strategy.\nLIPP+ does not require high-contend maintaining statistics in\nread-only scenarios, while SALI needs to identify hot and cold\nnodes, which adds a slight overhead. Therefore, SALIâ€™s performance\nis slightly lower than that of LIPP+.\nALEX+ exhibits poor lookup performance due to frequent â€œlast\nmileâ€ lookups. XIndex and FINEdex perform unsatisfied in general\ndue to serious lookup errors. ART-OLC does not have high superi-\nority with the read-only workload due to its higher tree height in\ncomparison to the learned index.\nFigure 12(d,e) depict the tail latency on FACE and OSM datasets.\nXIndex and FINEdex perform worse due to the severe lookup errors.\nIn contrast, SALI and LIPP+ have lower tail latency than ALEX+,\nas they do not suffer from any lookup errors.\nInsight 3: All indexes benefit from hyperthreading un-\nder the read-only. Among them, SALI and LIPP+ deliver the\nbest performance due to accurate lookup capability, which\nis essential for improving query performance.\n4.3 Evolving Evaluation\n4.3.1 Evolving triggered by hot read. Figure 13(a,b) compare the\nperformance of the learned index with 48 threads in two hot-read\nworkloads on the OSM dataset. SALI _Prob refers to SALI with only\nthe probability model, while SALI _REvo uses an evolving strategy\ntriggered by read. The figure exhibits that SALI _REvo outperforms\nSALI _Prob by 27% and 36% in the two hot-read workloads, respec-\ntively. In the Hot-read-A workload, SALI _REvo has surpassed the\nperformance of LIPP+.\nMoreover, SALI _REvo performs exceptionally well in OSM and\nGENOME due to the reduction in subtree height of hot read nodes,effectively increasing read performance. Table 2 (in Figure 13) shows\nthat the SALI _Probâ€™s depth on the two hard datasets is up to 5 and\n7, respectively. Therefore, the evolution of the hot node will flatten\nthe node to optimize read performance. However, under the easy\ndatasets, such as LIBIO, the average depth of SALI _Prob is only 1.2,\nso there exists a negligible improvement when using SALI _REvo\nas there is not enough depth to reduce.\nNote that as SALI adopts the LIPP structure, the majority of keys\nare stored in the root node and upper levels, while the deeper sub-\ntree contains fewer keys. Therefore, during the read evolution, we\nfound that connecting two nodes in one slot yields the best perfor-\nmance while connecting more nodes would increase the overhead\nof indexing fewer keys, rendering the evolution strategy ineffective.\nIn this case, we directly determine which of the two nodes the\ntarget key belongs to based on the maximum value of the nodes,\nwhich is more efficient than the SIMD approach. In Section 5, we\nfurther discuss the applicability and limitations of read evolving.\nInsight 4: In skewed workloads, the hot-read evolving can\nsignificantly improve read performance when the subtree\nof the hot-read node is deep. Flattened tree structures under\neasy datasets do not require evolving.\n4.3.2 Evolving triggered by the hot insert. Figure 13(c) presents the\nevaluation of Hot-write workloads with 48 threads. SALI _WEvo\nincludes both the probability model and evolving strategy triggered\nby insertion. SALI _Prob only consists of the probability model and\nan adjustment strategy equipped with a fixed ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡(as described\nin Equation (1)), similar to the adjustment method used by existing\nlearned indexes, i.e., the expansion coefficient is fixed to expand\nthe corresponding node during adjustment.\n11\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nFigure 14: The size of indexes.\nSALI _WEvo outperforms SALI _Prob by 32% to 80%, indicating\nthat the evolving strategy significantly impacts hot write nodes.\nHowever, the performance of the index structure during the hot\nwrite workload is not as good as that of the uniform workload.\nThis is because hot writes cause the local structure of the index to\ndeteriorate continuously and require frequent retraining operations.\nAdditionally, frequent local writes in ALEX+ and ART-OLC index\nstructures with coarse-grained write locks increase thread blocking\nand adversely affect insertion performance.\nNonetheless, SALI _WEvo can adaptively evolve the hot node\nbased on the insertion rate, i.e., ğ‘›.ğ‘ ğ‘ğ‘’ğ‘’ğ‘‘ğ‘¡(see Section 3.2). When\nthe insertion rate becomes faster, more slots are reserved to ensure\nexcellent insertion performance through the expand operation (see\nEquation (1)), which significantly reduces the number of retraining\noperations and improves overall performance.\nInsight 5: Skewed workloads with hot writes often lead to\nsignificant performance deterioration. SALI can effectively\nanalyze and process hot insertion by dynamically reserving\nmore gaps to maintain a high throughput.\n4.3.3 Evolving triggered by cold nodes. Figure 14 illustrates the size\nof learned indexes on OSM. Notably, the size of learned indexes\non OSM is about 1.5 times larger than that of the easy datasets.\nIn particular, Figure 14(a) shows the internal structure size of the\nindexes, indicating that SALI incurs the smallest space overhead.\nNote that the space overhead of the key-value pair could over-\nshadow that of the index. Figure 14(b) presents the sum of the\nindexâ€™s internal structure, the gap, and the key-value pairâ€™s size (no\ncompression). The figure shows that the overall space cost of SALI\nis higher than that of other index structures due to SALI reserving\ngaps for the key to be inserted.\nHowever, when the workload is skewed, the gap utilization in\ncold nodes is low, and thus, it can be compressed to reduce space\noverhead. Table 3 in Figure 13 demonstrates the size of SALI before\nand after compressing cold nodes under the Hot-read-A workload.\nThe results show that the compression scheme in SALI can reduce\nspace cost considerably, with compression ratios of 31% and 37%\nfor cold nodes on OSM and GENOME, respectively, evaluated using\nthe Hot-write workload.\nInsight 6: Compression scheme in SALI can save space\ndramatically while ensuring that all gaps are reserved at the\nhot node, i.e., the gaps are reserved at a more accurate and\nefficient location than other learned indexes.\n4.4 Ablation Study\nAnneser et al. [ 1] proposed a low-cost sampling method to identify\nhot and cold data, compress cold data, and expand hot data based on\ntraditional indexes. However, due to the need to consider the linear\nfitting CDF problem, the compression and expansion operations\nproposed by Anneser et al. cannot be directly applied to the learned\nindex. Nonetheless, this low-cost sampling method can be used in\nFigure 15: Comparison of different maintaining statistics\nmethods.\nSALI for comparison with our proposed probabilistic framework\nand high-contend statistics maintenance.\nTo compare these methods, we maintain statistical information\nusing three approaches, as shown in Figure 15: SALI _Stat. main-\ntains statistical information with the high-contend approach that is\nemployed in many state-of-the-art learned index structures, where\nevery new data insertion triggers a ğ‘›ğ‘¢ğ‘š. ++ operation in all nodes.\nSALI _Samp. maintains statistical information using the sampling\nmethod proposed by Anneser et al., where the ğ‘›ğ‘¢ğ‘š. ++ operation is\ntriggered for every ten inserted data. SALI _Prob. maintains statisti-\ncal information using the probability model proposed in our paper.\nThe results show that SALI _Samp. improves scalability compared\nto SALI _Stat. Furthermore, the decentralized probability-based\nmodel SALI _Prob. is more scalable than SALI _Samp., achieving\nup to 35% higher performance at 60 threads.\nInsight 7: Probability-based models exhibit excellent per-\nformance in concurrent scenarios owing to lightweight statis-\ntical information maintenance. In contrast, any centralized\nmaintenance of statistics can result in performance loss.\n5 DISCUSSION\n5.1 Generalizability and Applicability\nWe will describe the two main ideas in the SALI framework, the\nnode-evolving strategies (Section 3.2) and the probability model\nfor node statistics (Section 3.3), as general approaches that can\npotentially be applied to a wide range of learned indexes.\n1) What we want to emphasize is that in any application scenario,\nincluding but not limited to concurrent settings, if maintaining sta-\ntistics information globally becomes a performance bottleneck for\nthe index, adopting a probability-based lightweight statistical main-\ntenance approach can help enhance performance. For example, Lan\net al. [ 16] evaluated the performance of learned index approaches\non disk and mentioned that the maintenance statistics overhead in\nboth ALEX and LIPP can hurt overall performance because fetching\nmore blocks is required during statistics maintenance. Therefore,\nour lightweight probability models can address this bottleneck. An-\nneser et al. [ 1] still use a global approach to maintain hot-node\ninformation in traditional indexes. Although they designed a sam-\npling method to reduce overhead, our proposed probability models\nhave minimal overhead (see Figure 15). Therefore, using probability\nmodels for maintaining hot-node information has the potential to\nimprove performance. Li et al. [ 23] designed a new model-based\nlearned index framework named DILI, which combines the struc-\ntures of ALEX and LIPP. The probability models can also serve this\nframework to improve its scalability.\n2) The node-evolving strategies can be applied to different learned\nindexes. The read evolving can reduce the height of the hot sub-\ntree, improving read performance. The write evolving can allocate\n12\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nmore space for write-hot nodes in both buffer-based and model-\nbased learned indexes, thereby enhancing insertion performance.\nThe cold node-compression strategy can save space overhead in\nmodel-based learned indexes. Moreover, if applied to buffer-based\nlearned indexes, new compression algorithms need to be designed\nto reduce space overhead, which would be an interesting research\ndirection. Furthermore, Numerous exceptional compression works\ndemonstrate that data compression is a promising research direc-\ntion [ 42,43]. Theoretically, the SALI framework supports the im-\nplementation of any excellent compression algorithm. Improving\nupon current compression strategies is a key focus area for future.\n3) The current experimental results show that the read-evolving\nstrategy of SALI is effective only when a slot connects two nodes\nin the flattened structure. As described in Section 4.3.1, the reason\nis that the read performance improvement from flattening cannot\ncover the overhead of using SIMD to accelerate the node lookup\nprocess. This is because the flattened hot subtree contains a rela-\ntively small number of keys, and two nodes are sufficient to meet\nthe flattening requirement. The number of keys in the subtree de-\npends on the size of the experimental dataset and the LIPP structure.\nHowever, in scenarios with lookup large data volumes, such as Hy-\nbrid Transaction/Analytical Processing (HTAP), the read-evolving\nstrategy of the index requires more nodes to be flattened in the\nsame slot and accelerated by SIMD for the lookup process, result-\ning in performance benefits. In future work, we plan to design an\nautomatic mechanism to determine the optimal number of nodes\nto be flattened based on the current data volume and distribution.\n5.2 Limitation\nWe have identified several limitations in this study:\n1) The read-evolving strategy offers significant advantages in\nscenarios with complex data distributions. Insight 4 in Section 4.3.1\nstates that flattened tree structures under easy datasets do not\nevolve. In such cases, enabling the read-evolving strategy would\nintroduce additional overhead to determine if a target node is a\nhot node, which would compromise the read performance of the\nSALI. The overhead of node determination is detailed in additional\nexperiments in the appendix [ 9]. Therefore, we have encapsulated\nread-evolving as a toggle switch to be enabled in scenarios where it\nis needed. However, we acknowledge that determining the benefit\nof enabling read-evolving in a specific data distribution can be\nchallenging. This will be a focus of our future work.\n2) Currently, SALI does not support duplicate keys. The reason\nfor this is that SALI, being based on the LIPP structure, does not\ncurrently support the insertion of duplicate data. However, Wu\net al. [ 39] have suggested that it is relatively straightforward for\nindexes to accommodate duplicate keys, such as by maintaining a\npointer to an overflow list. As part of our future work, we plan to\nfocus on implementing the insertion of duplicate data.\n6 RELATED WORK\nIn 2018, Kraska et al.[ 7,15,29] introduced a learned index called\nRMI, which sparked a new wave of index design considerations.\nWhile the lookup performance was satisfactory, the first-generation\nlearned indexes, such as RMI and RS[14], did not support updates.\nTo address this limitation, Galakat et al.[ 8] designed FITing-tree, anupdatable learned index. Ferragina et al. [ 5] improved the construc-\ntion algorithm of FITing-tree and introduced the PGM index, which\noptimized the number of linear models generated while setting\nthe maximum error and used an insertion strategy similar to LSM-\nTree [ 33] to ensure worst-case insertion performance. However,\nFITing-tree and PGM suffered from significant lookup errors and\nhad no better insertion performance than traditional indexes due\nto their buffer-based insertion strategy. In response, Ding et al.[ 3]\ndesigned ALEX, which raised the insertion performance of learned\nindexes to a new level by using a model-based insertion strategy.\nHowever, ALEX had prediction errors and coarse-grained write\nlock due to its \"shift\" strategy to resolve conflicts. Wu et al.[ 39] de-\nsigned LIPP, another learned index with an error-free model-based\ninsertion strategy. However, LIPPâ€™s high-contend statistics main-\ntenance approach in every node hindered scalability. TONE [ 45]\nmitigates tail latency by dynamically allocating a secondary array\nto accommodate data, building upon the foundation of ALEX.\nXIndex [ 36,37] was the first to implement a concurrent update-\ncapable learned index. However, frequent â€œlast mileâ€ queries made\nit less competitive. FINEdex [ 21] improved the concurrency per-\nformance by using a flattened structure to avoid coarse-grained\nlocking. Wongkham et al. [ 38] implemented concurrent structures\nfor ALEX and LIPP, named ALEX+ and LIPP+, respectively. Experi-\nmental showed that ALEX+ outperformed LIPP+.\nLearned indexes have also inspired new design ideas for other\napplication scenarios [ 2,4,13,15,22,27,30,41,44]. For instance,\nLu et al. [ 25] developed APEX, a learned index based on NVM.\nMa et al. [ 26] designed FILM, a learned index that supports larger-\nthan-memory databases. Wu et al. [ 40] introduced NFL, a learned\nindex that changes the CDF of stored data through deep learning,\nmaking it easier to approximate. Nathan et al. [ 32] focused on multi-\ndimensional in-memory learned indexes. However, these works are\nbeyond the scope of our discussion.\n7 CONCLUSION\nWe have developed SALI, a highly scalable learned index frame-\nwork. In SALI, we have designed a probability-based framework\nfor monitoring the â€œdegradation signalsâ€ of the index and identify-\ning hot/cold nodes in a decentralized manner, thereby eliminating\nthread blocking and improving the indexâ€™s scalability in a con-\ncurrent scenario. Since the statistical overhead is negligible, the\nprobability framework provides the necessary conditions for the\nindex to evolve separately toward hot and cold data. Furthermore,\nwe have devised evolution strategies that allow SALI to develop\ninto better-performing local structures for hot and cold nodes inde-\npendently. The experimental results demonstrate that SALI built\nupon theğ‘€ğ‘œğ‘‘.+ğ¶structure offers significantly better scalability\nthan state-of-the-art learned indexes, and the evolution strategies\ncan increase read and write performance by at least 25% and 30%,\nrespectively.\nACKNOWLEDGMENTS\nThis work is supported by National Natural Science Foundation of\nChina (No. 61972402 and 61972275). The corresponding author is\nYunpeng Chai (ypchai@ruc.edu.cn).\n13\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nREFERENCES\n[1]Christoph Anneser, Andreas Kipf, Huanchen Zhang, Thomas Neumann, and\nAlfons Kemper. 2022. Adaptive Hybrid Indexes. In Proceedings of the 2022 Inter-\nnational Conference on Management of Data . 1626â€“1639.\n[2]Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan, Brian Kroth,\nAndrea C Arpaci-Dusseau, and Remzi H Arpaci-Dusseau. 2020. From wisckey\nto bourbon: A learned index for log-structured merge trees. In Proceedings of\nthe 14th USENIX Conference on Operating Systems Design and Implementation .\n155â€“171.\n[3]Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\net al.2020. ALEX: an updatable adaptive learned index. In Proceedings of the 2020\nACM SIGMOD International Conference on Management of Data . 969â€“984.\n[4]Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska. 2020.\nTsunami: a learned multi-dimensional index for correlated data and skewed\nworkloads. Proceedings of the VLDB Endowment 14, 2 (2020), 74â€“86.\n[5]Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-index: a fully-dynamic\ncompressed learned index with provable worst-case bounds. Proceedings of the\nVLDB Endowment 13, 8 (2020), 1162â€“1175.\n[6]K Fraser. 2004. Practical lock-freedom (Doctoral dissertation, University of\nCambridge). (2004).\n[7]Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim\nKraska. 2018. A-Tree: A Bounded Approximate Index Structure. (2018).\n[8]Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim\nKraska. 2019. Fiting-tree: A data-aware index structure. In Proceedings of the 2019\nInternational Conference on Management of Data . 1189â€“1206.\n[9]Jiake Ge. 2023. Appendix. https://github.com/YunWorkshop/SALI/blob/main/\nSALI_appendix.pdf\n[10] Jiake Ge, Boyu Shi, Yanfeng Chai, Yuanhui Luo, Yunda Guo, Yinxuan He, and\nYunpeng Chai. 2023. Cutting Learned Index into Pieces: An In-depth Inquiry\ninto Updatable Learned Indexes. In 2023 IEEE 39th International Conference on\nData Engineering (ICDE) . IEEE, 315â€“327.\n[11] Minas Gjoka, Maciej Kurant, Carter T Butts, and Athina Markopoulou. 2010.\nWalking in facebook: A case study of unbiased sampling of osns. In 2010 Proceed-\nings IEEE Infocom . IEEE, 1â€“9.\n[12] Changkyu Kim, Jatin Chhugani, Nadathur Satish, Eric Sedlar, Anthony D Nguyen,\nTim Kaldewey, Victor W Lee, Scott A Brandt, and Pradeep Dubey. 2010. FAST: fast\narchitecture sensitive tree search on modern CPUs and GPUs. In Proceedings of\nthe 2010 ACM SIGMOD International Conference on Management of data . 339â€“350.\n[13] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2019. SOSD: A benchmark for learned\nindexes. NeurIPS Workshop on Learned Systems (2019).\n[14] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. In Proceedings of the Third International Workshop on Exploiting Artificial\nIntelligence Techniques for Data Management . 1â€“5.\n[15] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe case for learned index structures. In Proceedings of the 2018 international\nconference on management of data . 489â€“504.\n[16] Hai Lan, Zhifeng Bao, J Shane Culpepper, and Renata Borovica-Gajic. 2023. Up-\ndatable Learned Indexes Meet Disk-Resident DBMS-From Evaluations to Design\nChoices. Proceedings of the ACM on Management of Data 1, 2 (2023), 1â€“22.\n[17] Viktor Leis, Michael Haubenschild, Alfons Kemper, and Thomas Neumann. 2018.\nLeanStore: In-memory data management beyond main memory. In 2018 IEEE\n34th International Conference on Data Engineering (ICDE) . IEEE, 185â€“196.\n[18] Viktor Leis, Alfons Kemper, and Thomas Neumann. 2013. The adaptive radix tree:\nARTful indexing for main-memory databases. In 2013 IEEE 29th International\nConference on Data Engineering (ICDE) . IEEE, 38â€“49.\n[19] V. Leis, F. Scheibner, Alfons Heinrich Kemper, and T. Neumann. 2016. The ART\nof practical synchronization. In the 12th International Workshop .\n[20] Justin J Levandoski, David B Lomet, and Sudipta Sengupta. 2013. The Bw-Tree:\nA B-tree for new hardware platforms. In 2013 IEEE 29th International Conference\non Data Engineering (ICDE) . IEEE, 302â€“313.\n[21] Pengfei Li, Yu Hua, Jingnan Jia, and Pengfei Zuo. 2021. FINEdex: a fine-grained\nlearned index scheme for scalable and concurrent memory systems. Proceedings\nof the VLDB Endowment 15, 2 (2021), 321â€“334.\n[22] Pengfei Li, Hua Lu, Qian Zheng, Long Yang, and Gang Pan. 2020. LISA: A\nlearned index structure for spatial data. In Proceedings of the 2020 ACM SIGMOD\ninternational conference on management of data . 2119â€“2133.\n[23] Pengfei Li, Hua Lu, Rong Zhu, Bolin Ding, Long Yang, and Gang Pan. 2023. DILI:\nA Distribution-Driven Learned Index. arXiv preprint arXiv:2304.08817 (2023).\n[24] Christian E Lopez and Caleb Gallemore. 2021. An augmented multilingual Twitter\ndataset for studying the COVID-19 infodemic. Social Network Analysis and Mining\n11, 1 (2021), 102.\n[25] Baotong Lu, Jialin Ding, Eric Lo, Umar Farooq Minhas, and Tianzheng Wang. 2021.\nAPEX: a high-performance learned index on persistent memory. Proceedings ofthe VLDB Endowment 15, 3 (2021), 597â€“610.\n[26] Chaohong Ma, Xiaohui Yu, Yifan Li, Xiaofeng Meng, and Aishan Maoliniyazi.\n2022. FILM: A Fully Learned Index for Larger-Than-Memory Databases. Proceed-\nings of the VLDB Endowment 16, 3 (2022), 561â€“573.\n[27] Marcel Maltry and Jens Dittrich. 2022. A critical analysis of recursive model\nindexes. Proceedings of the VLDB Endowment 15, 5 (2022), 1079â€“1091.\n[28] Yandong Mao, Eddie Kohler, and Robert Tappan Morris. 2012. Cache craftiness\nfor fast multicore key-value storage. In Proceedings of the 7th ACM european\nconference on Computer Systems . 183â€“196.\n[29] Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra,\nAlfons Kemper, Thomas Neumann, and Tim Kraska. 2020. Benchmarking learned\nindexes. Proceedings of the VLDB Endowment (2020).\n[30] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: a learned\nquery optimizer. Proceedings of the VLDB Endowment 12, 11 (2019), 1705â€“1718.\n[31] Paul E McKenney, Jonathan Appavoo, Andi Kleen, Orran Krieger, Rusty Russell,\nDipankar Sarma, and Maneesh Soni. 2001. Read-copy update. In AUUG Conference\nProceedings . AUUG, Inc., 175.\n[32] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learn-\ning multi-dimensional indexes. In Proceedings of the 2020 ACM SIGMOD interna-\ntional conference on management of data . 985â€“1000.\n[33] Patrick Oâ€™Neil, Edward Cheng, Dieter Gawlick, and Elizabeth Oâ€™Neil. 1996. The\nlog-structured merge-tree (LSM-tree). Acta Informatica 33, 4 (1996), 351â€“385.\n[34] Suhas SP Rao, Miriam H Huntley, Neva C Durand, Elena K Stamenova, Ivan D\nBochkov, James T Robinson, Adrian L Sanborn, Ido Machol, Arina D Omer, Eric S\nLander, et al .2014. A 3D map of the human genome at kilobase resolution reveals\nprinciples of chromatin looping. Cell159, 7 (2014), 1665â€“1680.\n[35] Dimitrios Siakavaras, Panagiotis Billis, Konstantinos Nikas, Georgios Goumas,\nand Nectarios Koziris. 2020. Efficient Concurrent Range Queries in B+-trees\nusing RCU-HTM. In Proceedings of the 32nd ACM Symposium on Parallelism in\nAlgorithms and Architectures . 571â€“573.\n[36] Chuzhe Tang, Youyun Wang, Zhiyuan Dong, Gansen Hu, Zhaoguo Wang, Minjie\nWang, and Haibo Chen. 2020. XIndex: a scalable learned index for multicore data\nstorage. In Proceedings of the 25th ACM SIGPLAN Symposium on Principles and\nPractice of Parallel Programming . 308â€“320.\n[37] Zhaoguo Wang, Haibo Chen, Youyun Wang, Chuzhe Tang, and Huan Wang. 2022.\nThe concurrent learned indexes for multicore data storage. ACM Transactions on\nStorage (TOS) 18, 1 (2022), 1â€“35.\n[38] Chaichon Wongkham, Baotong Lu, Chris Liu, Zhicong Zhong, Eric Lo, and\nTianzheng Wang. 2022. Are Updatable Learned Indexes Ready? Proceedings of\nthe VLDB Endowment (2022).\n[39] Jiacheng Wu, Yong Zhang, Shimin Chen, Jin Wang, Yu Chen, and Chunxiao Xing.\n2021. Updatable learned index with precise positions. Proceedings of the VLDB\nEndowment 14, 8 (2021), 1276â€“1288.\n[40] Shangyu Wu, Yufei Cui, Jinghuan Yu, Xuan Sun, Tei-Wei Kuo, and Chun Jason\nXue. 2022. NFL: robust learned index via distribution transformation. Proceedings\nof the VLDB Endowment 15, 10 (2022), 2188â€“2200.\n[41] Tong Yu, Guanfeng Liu, An Liu, Zhixu Li, and Lei Zhao. 2023. LIFOSS: a learned\nindex scheme for streaming scenarios. World Wide Web 26, 1 (2023), 501â€“518.\n[42] Huanchen Zhang, David G Andersen, Andrew Pavlo, Michael Kaminsky, Lin\nMa, and Rui Shen. 2016. Reducing the storage overhead of main-memory OLTP\ndatabases with hybrid indexes. In Proceedings of the 2016 International Conference\non Management of Data . 1567â€“1581.\n[43] Huanchen Zhang, Xiaoxuan Liu, David G Andersen, Michael Kaminsky, Kimberly\nKeeton, and Andrew Pavlo. 2020. Order-preserving key compression for in-\nmemory search trees. In Proceedings of the 2020 ACM SIGMOD International\nConference on Management of Data . 1601â€“1615.\n[44] Jiaoyi Zhang and Yihan Gao. 2022. CARMI: a cache-aware learned index with a\ncost-based construction algorithm. Proceedings of the VLDB Endowment 15, 11\n(2022), 2679â€“2691.\n[45] Yong Zhang, Xinran Xiong, and Oana Balmau. 2022. TONE: cutting tail-latency in\nlearned indexes. In Proceedings of the Workshop on Challenges and Opportunities\nof Efficient and Performant Storage Systems . 16â€“23.\nA COMPREHENSIVE EVALUATION RESULTS\nA.1 Throughput\nFigure 16-19 showcase the complete evaluation results for all datasets\nand different read/write ratios (uniform distribution), regarding the\ncomplete assessment of throughput as mentioned in the main text.\nSALI exhibits superior throughput compared to other SOTA learned\nindexes.\n14\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nFigure 16: The indexes scalability on write-only workloads (Throughput).\nFigure 17: The indexes scalability on balance workloads (Throughput).\nFigure 18: The indexes scalability on read-intensive workloads (Throughput).\nFigure 19: The indexes scalability on read-only workloads (Throughput).\nA.2 Tail latency\nFigure 20-23 present the comprehensive evaluation results for all\ndatasets and various read-write ratios (uniform distribution), re-\ngarding the complete assessment of tail latency as mentioned in\nthe main text. SALI maintains low tail latency across the board.\nA.3 Index building and range queries\nFigure 24(a) presents the time required for bulk loading 100M keys\nby various learned indexes. Notably, SALIâ€™s build time is signifi-\ncantly lower than that of ALEX+ and XIndex. This is because SALI\ncreates new nodes for conflicting keys and does not require key\nmovement to maintain gaps, as in ALEX+. SALI needs to create a\ncooling pool, resulting in a slightly longer build time than LIPP+.\nFigure 24(b) presents the evaluation of a range query of 100\nkeys with 48 threads. SALI outperforms XIndex and FINEdex but\nfalls short of ALEX+. This is because SALIâ€™s node layout, which\nresembles that of a B-tree, contains more gaps and interleaves child\npointers and data in the node array. Consequently, scan on the array\nencounters many branches. To mitigate this issue, we make prelim-\ninary optimizations by compressing the hot scan node (similar tothe cold nodes compression designed in Figure 7(c)) to remove the\ngap and store the data in a node, as illustrated in SALI +Comp. in\nFigure 24(b), assuming that we know the hot scan information. The\nresults show that this approach outperforms other baselines. Our\nfuture research will focus on designing more robust methods for\nidentifying hot scan nodes, building on the prerequisites provided\nby the lightweight models.\nB ANALYSIS OF THE LIMITATIONS OF SALI\nB.1 The limitation of read-evolving strategy\nInsight 4 in Section 4.3.1 states that flattened tree structures un-\nder easy datasets do not evolve. In such cases, enabling the read-\nevolving strategy would introduce additional overhead to determine\nif a target node is a hot node, which would compromise the read\nperformance of the SALI.\nSpecifically, we analyze the overhead through experimental eval-\nuation. When SALI activates read-evolving, the overhead during\nlookups on a read-only workload (uniform distribution) with dif-\nferent datasets is illustrated in Figure 25. There are three types of\n15\n\nConference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile Jiake Ge and Huanchen Zhang, et al.\nFigure 20: The indexes scalability on write-only workloads (Latency).\nFigure 21: The indexes scalability on balance workloads (Latency).\nFigure 22: The indexes scalability on read-intensive workloads (Latency).\nFigure 23: The indexes scalability on read-only workloads (Latency).\nFigure 24: bulk time and range query performance.\noverhead during lookups: 1) the if statement to determine whether\nthe lookup triggers probability calculation, where each thread cal-\nculates the probability every 10 lookups, 2) probability calculation,\nand 3) determining whether a node is a hot node. Note that, for\nbetter clarity in illustrating the performance bottlenecks, all nodes\nare non-evolving (manually controlled) as node evolving may not\nalways be applicable due to the small tree depth of certain datasets.\nIn Figure 25, ğ‘†ğ´ğ¿ğ¼+ğ‘ƒğ‘Ÿğ‘œğ‘. represents the throughput of SALI\nwith the first and second types of overhead, while ğ‘†ğ´ğ¿ğ¼+ğ‘….ğ‘’ğ‘£ğ‘œğ‘™.represents the throughput of SALI with all three types of overhead.\nğ‘†ğ´ğ¿ğ¼ represents the read-evolving switch that is turned off. It can\nbe observed that the first two types of overhead are negligible, and\nthe main overhead comes from the third type.\nTherefore, when enabling the read-evolving strategy in easy\ndatasets, the internal nodes of SALI will not undergo evolution,\nand there will be an additional overhead in determining whether a\nnode is a hot node, potentially leading to a loss of lookup perfor-\nmance. We acknowledge that evaluating the benefits of enabling\nread-evolving in specific data distributions can be challenging, and\nthis will be a focal point of our future work.\nFigure 26 illustrates the throughput of the index when read-\nevolving is enabled under a read-only workload (uniform distri-\nbution). In contrast to Figure 25, the ğ‘†ğ´ğ¿ğ¼+ğ‘….ğ‘’ğ‘£ğ‘œğ‘™. configuration\nincludes node evolving in the OSM and GENOME datasets, while\nthe experimental results for the COVID and LIBIO datasets align\nwith those in Figure 25. This is because the flattened tree structures\n16\n\nSALI: A Scalable Adaptive Learned Index Framework based on Probability Models Conference SIGMOD â€™24, June 09â€“15, 2024, Santiago, Chile\nFigure 25: Overhead analysis of the read-evolving strategy.\nFigure 26: Performance of read-evolving strategy under read-only workload (uniform distribution).\nin easy datasets do not undergo evolution (refer to Insight 4 in\nSection 4.3.1).\nB.2 The limitation of supporting duplicate data\nCurrently, SALI does not support duplicate keys. The reason for this\nis that SALI, being based on the LIPP structure, does not currently\nsupport the insertion of duplicate data. However, Wu et al. [ 39]\nhave suggested that it is relatively straightforward for indexes to\naccommodate duplicate keys, such as by maintaining a pointer to\nan overflow list. As part of our future work, we plan to focus on\nimplementing the insertion of duplicate data.\nC BUFFER-BASED AND MODEL-BASED\nINSERTION STRATEGY\nIn this section, we will provide a comprehensive discussion of the\nstrengths and weaknesses of the buffer-based insert strategy (out-\nof-place insert) and the model-based insert strategy (in-place insert).\nOur aim is to emphasize the significance of choosing different index\nstructures based on specific scenarios.\nC.1 buffer-based insertion strategy\nThe major performance limitation of the buffer-based insertion\nstrategy lies in its significant lookup error. Unlike the model-based\nstrategy, it lacks the capability to adjust the distribution of stored\nkeys through reserved gaps, which could result in a linearized\nindex structure and reduce or eliminate errors (i.e., ALEX, LIPP).\nThe larger lookup error adversely affects the lookup and insertion\nperformance of the index.\nFrom a more detailed perspective, there are two ways to insert\ndata in the buffer. The first approach involves maintaining the in-\nsertion order. While this method is more efficient for searching, it\nrequires moving many keys to maintain the order during insertion.\nAs a result, it degrades the insertion performance of the buffer. The\nsecond approach is the append-only insertion method, where there\nis no need to maintain the insertion order. This method is efficient\nfor write operations but introduces additional overhead during\nsearching and retraining processes. Regardless of the approach cho-\nsen, both searching and inserting operations in the buffer result in\nsignificant time overhead, leading to suboptimal index performance.However, the buffer-based insertion strategy is not without its\nopportunities. It demonstrates significant advantages in the fol-\nlowing two scenarios: 1) PGM, a type of learned index similar to\nLSM-Tree, exhibits remarkable performance benefits in write-only\nworkloads. In such scenarios, the buffer-based insertion strategy\nproves highly effective. 2) In certain environments with strict space\nlimitations, such as embedded systems, the buffer-based insertion\nstrategyâ€™s corresponding compact storage (i.e., without gaps) of-\nfers space savings of two orders of magnitude compared to B+\ntrees. Such learned indexes (e.g., PGM) are more suitable for these\napplication scenarios.\nIn summary, while the buffer-based insertion strategy may have\nlimitations, it demonstrates substantial advantages in specific sce-\nnarios, such as write-only workloads and environments with strin-\ngent space constraints.\nC.2 model-based insertion strategy\nThe model-based insertion strategy offers superior performance in\nlearned indexes due to the following reasons:\n1)This strategy introduces gaps between stored keys, altering the\ncumulative distribution of the stored keys to approximate a linear\ndistribution. As a result, the index structure can be approximated\nas a linear model with minimal error (i.e., ALEX). Additionally,\ntechniques like chaining in designs such as LIPP enable conflict\nresolution, ensuring precise lookups and significantly improving\nquery performance. 2)Unlike the buffer-based insertion strategy,\nthe model-based approach reserves gaps that allow for the efficient\ninsertion of new keys without the need to â€™shiftâ€™ many existing\nkeys. This substantially enhances the insertion performance of the\nindex.\nIn summary, the model-based insertion strategy in learned in-\ndexes delivers improved performance through CDF optimization,\nprecise lookups, and efficient insertions facilitated by reserved gaps.\nTherefore, in the application scenarios of this paper, we have opted\nto evaluate SALI using the model-based insertion strategy.\nReceived 15 April 2023; revised 20 July 2023; accepted 23 August 2023\n17",
  "textLength": 91126
}