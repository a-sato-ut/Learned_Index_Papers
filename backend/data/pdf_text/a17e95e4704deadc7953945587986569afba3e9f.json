{
  "paperId": "a17e95e4704deadc7953945587986569afba3e9f",
  "title": "Cabin: A Compressed Adaptive Binned Scan Index",
  "pdfPath": "a17e95e4704deadc7953945587986569afba3e9f.pdf",
  "text": "Cabin: a Compressed Adaptive Binned Scan Index\nYIYUAN CHEN and SHIMIN CHENâˆ—,SKLP and Center for Advanced Computer Systems, Institute of\nComputing Technology, CAS, China and University of Chinese Academy of Sciences, China\nScan is a fundamental operation widely used in main-memory analytical database systems. To accelerate scans,\nprevious studies build either record-order or sort-order structures known as scan indices . While achieving good\nperformance, scan indices often incur significant space overhead, limiting their use in main-memory databases.\nFor example, the most recent and best performing scan index, BinDex, consists of a sort-order position array,\nwhich is an array of rowIDs in the value order, and a set of record-order bit vectors, representing records in\npre-defined value intervals. The structures can be much larger than the base data column size.\nIn this paper, we propose a novel scan index, Cabin, that exploits the following three techniques for better\ntime-space tradeoff. 1) filter sketches that represent every 2ğ‘¤âˆ’2value intervals with a ğ‘¤-bit sketched vector,\nthereby exponentially reducing the space for the bit vectors; 2) selective position array that removes the rowID\narray for a fraction of intervals in order to lower the space overhead for the position array; and 3) data-aware\nintervals that judiciously select interval boundaries based on the data characteristics to better support popular\nvalues in skewed data distributions or categorical attributes. Experimental results show that compared with\nstate-of-the-art scan solutions, Cabin achieves better time-space tradeoff, and attains 1.70 â€“ 4.48x improvement\nfor average scan performance given the same space budget.\nCCS Concepts: â€¢Information systems â†’Data access methods ;Data scans .\nAdditional Key Words and Phrases: scan index; time-space tradeoff; filter sketches; data awareness\nACM Reference Format:\nYiyuan Chen and Shimin Chen. 2024. Cabin: a Compressed Adaptive Binned Scan Index. Proc. ACM Manag.\nData 2, 1 (SIGMOD), Article 57 (February 2024), 26 pages. https://doi.org/10.1145/3639312\n1 INTRODUCTION\nScan is a fundamental operation widely used in analytical data processing [ 9,13,16â€“18,23,25,26,\n30,31,34,35,37]. Given a base data column in a table and a filter predicate, a scan operation returns\na result bit vector or a rowID list that indicates which records satisfy the predicate. A plain scan\nreads the data column sequentially and evaluates the predicate for each data value. There are two\nmain ways to improve the plain scan in the literature. The first approach is to optimize the layout\nof the base data column so that the scan can effectively exploit SIMD to speed up computation, and\nreduce the amount of data accessed with early pruning techniques [ 13,26]. The second approach\ndoes not change the base data. Instead, it builds auxiliary data structures (a.k.a. scan indices ) to\naccelerate scans [ 11,16,25,27,29]. Compared to the first approach, scan indices have been shown to\nachieve higher performance. However, scan indices often incur significant space overhead, limiting\ntheir use in main-memory databases. In this paper, we aim to improve the time-space tradeoff for\nscan indices.\nâˆ—Shimin Chen is the corresponding author.\nAuthorsâ€™ address: Yiyuan Chen, chenyiyuan20s@ict.ac.cn; Shimin Chen, chensm@ict.ac.cn, SKLP and Center for Advanced\nComputer Systems, Institute of Computing Technology, CAS, No. 6 Ke Xue Yuan South Rd, Haidian District, Beijing, China\nand University of Chinese Academy of Sciences, No.1 Yanqihu East Rd, Huairou District, Beijing, China.\nThis work is licensed under a Creative Commons Attribution International 4.0 License.\nÂ©2024 Copyright held by the owner/author(s).\nACM 2836-6573/2024/2-ART57\nhttps://doi.org/10.1145/3639312\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n\n57:2 Yiyuan Chen and Shimin Chen\nWe consider the design principles for scan indices. A scan deals with two data orders: the record\norder and the sort order. Both the base data and the scan result are in the record order. On the\nother hand, for a predicate (e.g., <,>,â‰¤,â‰¥,=,â‰ , or BETWEEN) that compares the data value with\nconstant(s), the evaluation can be better supported if the data is sorted. The two orders are the\nsame if values are sorted in the base data column. In this case, a search on the data column can\nefficiently compute the result bit vector or rowID list. However, the more common and challenging\ncase is where values are not sorted. This is the focus of previous scan index studies, as well as the\nfocus of our work.\nTo improve scans, scan indices build either record-order structures or sort-order structures or\nboth. Record-order structures can reduce the amount of access to the base data, while sort-order\nstructures can accelerate the computation of the predicate.\nâ€¢B+-Tree [ 11] is a sort-order scan index. A scan performs a search, then follows the linked list\nof leaf nodes to retrieve all rowIDs that satisfy the predicate. This process is efficient if the\npredicate selectivity is low. However, for medium to high selectivities, it incurs many expensive\nrandom memory accesses.\nâ€¢Bitmap Index [ 29] maintains record-order bit vectors for each distinct values. It can retrieve a\nstored bit vector for a scan with an equality predicate. However, for other predicate types, it\nhas to merge multiple bit vectors, and thus becomes less efficient if more distinct values satisfy\nthe scan predicate.\nâ€¢Column Sketches [ 16] create a sketched column in the record order. Value ranges are mapped\nto small (e.g., 8-bit) code words. Then the sketched column stores a code per record. A scan\nevaluates the predicate by checking the per-record code in the sketched column. This is sufficient\nfor most records. For a small fraction (e.g.,1\n256) of records, the check is uncertain and the scan\nreads the base data values. In this way, Column Sketches significantly reduce the amount of\ndata to read.\nâ€¢BinDex [ 25], the most recent and best performing solution, combines both sort-order and record-\norder structures to speed up scans. The former is an array of rowIDs (a.k.a. position array) in\nthe sort order of values. The latter is a set of record-order bit vectors, each representing the\nrecords in a pre-defined value range. For a scan, the predicate specifies a target value range.\nBinDex finds the closest pre-defined range to the target range, and copies the associated bit\nvector as the draft result. Then, it searches the position array for records in the intersection of\nthe target and the pre-defined range, and corrects the corresponding bits in the draft result to\nobtain the scan result.\nHowever, the improvement of scan performance comes at a price: scan indices introduce sig-\nnificant space cost. Both record-order and sort-order structures store an element per record. The\nelement size can be comparable or even larger than the value size in the base data. In a B+-Tree [ 11],\nthere is a (value, rowID) entry per record. Suppose the rowID takes 4B. Then the B+-Tree incurs\nat least 5x, 3x, 2x, and 1.5x space overhead for 8-bit, 16-bit, 32-bit, and 64-bit values, respectively.\nIn a Bitmap Index [ 29], every bit vector stores 1 bit per record. The space cost increases linearly\nas the number of distinct values. For example, the bit vectors for 64 distinct values lead to 1â€“8x\nspace overhead for 64-bit â€“ 8-bit values. Column Sketches [ 16] store a (e.g., 8-bit) code per record.\nTherefore, the space overhead is 0.125â€“1x, which is low among scan indices. In a BinDex [ 25],\nthe position array contains a (e.g., 4B) rowID per record. Each bit vector costs 1 bit per record.\nThe number of stored bit vectors is determined by the number of pre-defined value ranges. For\nexample, if there are 64 pre-defined ranges, then the BinDex sees 1.5â€“12x space overhead for 64-bit\nâ€“ 8-bit values. As the number of pre-defined ranges increases, BinDex performs better because\nthe intersection between a target range and its closet pre-defined range tends to become smaller.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:3\nTherefore, for achieving higher scan performance, it can be necessary to store more bit vectors,\nincurring even higher space overhead.\nIn this paper, we propose a novel scan index, Cabin ( compressed adaptive binned scan index).\nCabin exploits the following three techniques for better time-space tradeoff:\nâ€¢Filter Sketches : BinDex stores a bit vector for each value range, which consumes a lot of space.\nTo reduce space, we replace every 2ğ‘¤âˆ’2bit vectors with a ğ‘¤-bit sketched vector (e.g., ğ‘¤â‰¤9).\nAğ‘¤-bit code can represent 2ğ‘¤âˆ’2value intervals (and two reserved virtual intervals for all\nvalues less than or greater than the set of intervals). We call the resulting record-order structure\nfilter sketches . Cabin divides all the value intervals into groups of 2ğ‘¤âˆ’2intervals each, and\nbuildğ‘¤-bit filter sketches per interval group. In this way, Cabin reduces the space cost of bit\nvectors by a factor of2ğ‘¤âˆ’2\nğ‘¤. In addition, we describe a novel encoding and computation scheme,\nMLO, that minimizes the number of SIMD operations for generating a draft result from filter\nsketches given a pre-defined value range.\nâ€¢Selective Position Array : The position array in BinDex incurs a fixed space overhead. If space\nbudget is tight, we propose to selectively store the position array, i.e., storing rowIDs for a\nfraction of intervals. If the predicate of a scan hits a value interval whose rowIDs are not stored,\nCabin relies on the filter sketches for evaluating the predicate. Note that our design of filter\nsketches covers the entire value range (âˆ’âˆ,+âˆ) for every interval group (with the two virtual\nintervals). Consequently, we can use filter sketches in a similar fashion to Column Sketches to\nsupport scans.\nâ€¢Data-aware intervals : Bindex divides the full value range into even-sized intervals for obtaining\nthe pre-defined value ranges. This works well when the number of duplicates of each distinct\nvalue is small. However, real-world data may contain a lot of duplicates because of skewed data\ndistribution (e.g., power-law graphs) or low unique value counts (e.g., categorical attributes). In\nsuch cases, Cabin judiciously makes data-aware selection of intervals to optimize for popular\nvalues.\nContributions. The main contributions of this paper are threefold. First, we propose a scan\nindex, Cabin1, with three novel techniques, i.e., filter sketches, selective position array, and data-\naware intervals, to improve the time-space tradeoff for scans. Second, we model the time and\nspace cost of Cabin, and design an algorithm to compute the optimal design parameters for Cabin.\nFinally, we perform extensive experimental evaluation of Cabin under various data workloads. Our\nexperimental results show that compared with state-of-the-art scan solutions, Cabin achieves better\ntime-space tradeoff, and attains 1.70 â€“ 4.48x improvement for average scan performance given\nthe same space budget. In addition, we evaluate Cabin in a full fledged main memory analytical\ndatabase system, MonetDB, using a subset of queries in TPC-H and SSB benchmarks. Our results\nshow that Cabin can improve the query performance of MonetDB by a factor of 1.1â€“49.9x.\nOrganization. The rest of the paper is organized as follows. Section 2 provides the background on\nexisting scan solutions. Section 3 presents the Cabin design. Then, Section 4 analyzes the space and\ntime cost of Cabin for optimal design selection. After that, Section 5 performs the experimental\nevaluation. Section 6 discusses a number of practical issues. Finally, Section 7 concludes the paper.\n2 BACKGROUND AND RELATED WORK\nWe describe background on data scans in Section 2.1, then discuss related work on scan indices in\nSection 2.2.\n1The source code is available at https://github.com/schencoding/Cabin\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:4 Yiyuan Chen and Shimin Chen\n2.1 Data Scan\nProblem Definition. In this paper, we focus on single-column data scan operations. We consider\nthe same problem definition as in previous studies [13, 16, 25, 26].\nâ€¢Base data : A column of fixed sized values, which is the common storage layout in main-memory\nanalytical databases [ 6,8,12,22,32,38]. Note that variable sized fields are often encoded into\nfixed sized codes with dictionary encoding [7, 12].\nâ€¢Query predicate : A filter predicate (e.g., <,>,â‰¤,â‰¥,=,â‰ , or BETWEEN) that specifies a value\nrange of the input data.\nâ€¢Output : A result bit vector, whose ğ‘–-th bit is set to 1 if the ğ‘–-th record satisfies the predicate.\nCompared to other return formats (e.g., rowID list), bit vectors can be efficiently merged with\nbitwise operations to compute complex predicates [10].\nTwo Ways to Optimize Scans. A plain scan reads the base data sequentially and checks if each\nvalue satisfies the filter predicate. There are two main ways to improve plain scans in the literature.\nThe first approach is to optimize the layout of the base data. The design goals are to exploit\nSIMD and/or to reduce the amount of data accessed by the scan. BitWeaving [ 26] proposes bit-level\nlayouts. In comparison, ByteSlice [ 13] proposes a byte-level columnar layout, where the ğ‘–-th byte of\nall values are stored contiguously. Predicate evaluation employs SIMD to compare multiple values\nfrom the most to the least significant byte. It stops early if the higher-order bytes already determine\nthe predicate outcome. This early pruning technique can significantly reduce the amount of data to\nread.\nThe second approach does not change the base data. Instead, it builds auxiliary data structures\nto improve scan performance. Examples include B+-Tree [ 11], Bitmap Index [ 29], Zone Maps [ 27],\nColumn Sketches [ 16], and BinDex [ 25]. We call such auxiliary data structure scan index . Compared\nto the first approach, scan indices can perform better, but often incur significant space overhead.\nWe aim to design a scan index with better time-space tradeoff.\n2.2 Scan Index\nLet us consider the principles of designing a scan index. From the problem definition, we see that\nthere are two orders: the record order and the sort order. Both the base data and the output bit\nvector are in the record order, while predicate evaluation can be more efficient if the values are\nsorted. As a result, it is natural to consider three types of structures in scan indices:\nâ€¢Record-order structure : It contains one item for every value in the base data. The order of the\nitems is in the record order of the base data. An example is the bit vector in Bitmap Index.\nâ€¢Sort-order structure : It contains one item for every value in the base data. The order of the items\nis in the sort order of the values. An example is the B+-Tree leaf nodes.\nâ€¢Summary structure : The structure is small. It contains aggregates of the base data, or metadata\nof the other structures.\nWe examine the structures of each scan index, as shown in Table 1. Figure 1 depicts a high-level\npicture of the time-space trade-off of scan solutions. (Please see the space-time analysis under\ndifferent workloads in our experiments in Section 5.)\nB+-Trees [ 11].In a B+-Tree, the leaf level stores the list of (value, rowID)â€™s in the sort order. This\nconsumes more space than the base data. A scan performs a search to reach the leaf level, then\nfollows the linked list of leaf nodes to retrieve all rowIDs that satisfy the predicate and sets the\nrelevant bits in the result bit vector. This is efficient when the predicate selectivity is low, as shown\nin Figure 1. However, it can be costly with medium to high selectivities (not shown) because of\npointer chasing and random memory accesses.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:5\nTable 1. Comparing scan index structures.\nScan IndexRecord-Order\nStructureSort-Order\nStructureSummary\nStructure\nB+-Tree - tree nodes -\nBitmap Index bit vectors - key-to-vector map\nZone Maps - - bucket aggregates\nColumn Sketches sketched column - compression map\nBinDex filter bit vectors position array area map\nCabin\n(our solution)filter sketchesselective\nposition arraydata-aware\ninterval table\nZone Maps\nByteSliceBinDex\nCabin\n(our solution)CS\nB+-Tree\n(low selectivity)Scan time\nSpace of auxiliary structures0\nFig. 1. Comparison of optimized scan solutions. (CS stands for Column Sketches. The performance of B+-Tree\nat low selectivity (e.g., 0.1%) is shown.)\nBitmap Index [ 29].Bitmap index stores a bit vector for each distinct value, and a summary\nstructure that maps keys to vectors. For an equality predicate, it returns the relevant bit vector, which\nis very fast. However, there are two main problems. First, for common data columns with many\ndistinct values, Bitmap index can be much larger than other scan indices. Second, predicates that\nspecify value ranges often require merging multiple bit vectors, leading to degraded performance.\nHence, we do not further discuss or evaluate Bitmap index in the paper. Note that the above\nproblems can be addressed by more sophisticated use of bitmaps, such as range-based bit vectors\nin BinDex and filter sketches in our solution.\nZone Maps [ 27].It divides the input data into buckets, and maintains per-bucket aggregates (e.g.,\nmin, max). The summary structure incurs little space overhead, as shown in Figure 1. For a scan,\nZone Maps skip a bucket if the bucket aggregates show that the entire bucket satisfies or dissatisfies\nthe predicate. However, bucket skipping is effective only when values are mostly sorted or the\nselectivity is very low or very high. In other cases, Zone Maps essentially perform a plain scan,\nmaking it the slowest scan index.\nColumn Sketches [ 16].As shown in Figure 2(a), Column Sketches consist of a sketched column\nand a compression map. The latter maps value ranges to codes. The former contains a code per\nvalue in the record order. In the example, ğ‘¥0=5âˆˆ(âˆ’âˆ,8], thus its code is 000.ğ‘¥1=23âˆˆ(22,28], so\nits code is 100. The space cost isğ‘Â·ğ‘¤\n8bytes, where ğ‘is the number of records and ğ‘¤is the code\nwidth. Since ğ‘¤(e.g., 8 bits) is often smaller than value size (e.g., 64 bits), Column Sketches consume\nsmaller space than the base data.\nA scan first maps the predicate value to the (predicate) code. Then, it compares each code in the\nsketched column with the predicate code. In most cases, code â‰ predicate code, then the comparison\nsuffices. When code = predicate code, the scan has to check the value in the base data. Therefore, the\nscan reads the sketched column and1\n2ğ‘¤(e.g.,1\n256forğ‘¤=8) of the base data. Consequently, Column\nSketches significantly reduce the amount of data to read.\nBinDex [ 25].BinDex combines features of B+-Tree and Bitmap Index, as shown in Figure 2(b).\nFirst, the position array and the virtual sorted values are similar to the sorted (value, rowID)â€™s in the\nB+-Treeâ€™s leaf level. To reduce space cost, BinDex stores only the rowIDs. The value part is virtual\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:6 Yiyuan Chen and Shimin Chen\n523 30 12 42 39 21 846 45 22 42 40 16 11 15 25 10 19 036 28 33 9\nğ‘¥0ğ‘¥1ğ‘¥2ğ‘¥3ğ‘¥4ğ‘¥5ğ‘¥6ğ‘¥7ğ‘¥8ğ‘¥9ğ‘¥10ğ‘¥11ğ‘¥12ğ‘¥13ğ‘¥14ğ‘¥15ğ‘¥16ğ‘¥17ğ‘¥18ğ‘¥19ğ‘¥20ğ‘¥21ğ‘¥22ğ‘¥23Column  \nData\n000100101010110110011000111111011110110010001010100001011000101100101001Compression MapSketched Column811 16 22 28 36 42 46\n000001010011100101110111(a) Column Sketches\nFilter Bit Vector\n100000010000000000010000\n100000010000001001010001\n100100010000011101010001\n100100110010011101110001\n111100110010011111110101\n111101110010111111111111\n19 0 723 17 14 315 13 18 610 116 21 222 20 512 411 9 8\n0 5 8 910 11 12 15 16 19 21 22 23 25 28 30 33 36 39 40 42 42 45 46ğ¹1:(âˆ’âˆ,9)\nğ¹2:(âˆ’âˆ,12)\nğ¹3:(âˆ’âˆ,19)\nğ¹4:(âˆ’âˆ,23)\nğ¹5:(âˆ’âˆ,33)\nğ¹6:(âˆ’âˆ,42)\nPosition \nArray \nVirtual\n Value SpaceArea Map\nLower \nBoundIndex in \nPosition Array\nğ´29 3\nğ´312 6\nğ´419 9\nğ´523 12\nğ´633 16\nğ´742 20\nğ´1 ğ´2 ğ´3 ğ´4 ğ´5 ğ´6 ğ´7(b) BinDex\n(c) Cabin Filter Sketches \nğ‘“ğ‘ 0,0011110001101001111000100Interval Table\nğ‘“ğ‘ 0,1100100110010011101110001\n111001010000100010011111ğ‘“ğ‘ 0,2\nSelective Position Array\n19 0 723 17 14 315 13 18 610 116 21 222 20 512 411 9 8\nğ¼0,1 ğ¼0,2 ğ¼0,3 ğ¼0,4 ğ¼0,5 ğ¼0,6Group 0\nGroup 0ğ¼0,0(âˆ’âˆ,0)111 /0/\nğ¼0,1[0,10)110 401\nğ¼0,2[10,16)101 441\nğ¼0,3[16,23)100 481\nğ¼0,4[23,33)011 4120\nğ¼0,5[33,42)010 4161\nğ¼0,6[42,47)001 4200\nğ¼0,7[47,+âˆ)000 ///Range Code\n#RecordsIndex in Selective \nPosition Array ğ‘¥0ğ‘¥1ğ‘¥2ğ‘¥3ğ‘¥4ğ‘¥5ğ‘¥6ğ‘¥7ğ‘¥8ğ‘¥9ğ‘¥10ğ‘¥11ğ‘¥12ğ‘¥13ğ‘¥14ğ‘¥15ğ‘¥16ğ‘¥17ğ‘¥18ğ‘¥19ğ‘¥20ğ‘¥21ğ‘¥22ğ‘¥23ğ‘‹â†¦ğ¶2ğ¶1ğ¶0\nğ‘Ÿğ‘œğ‘¤ğ¼ğ·\nSelective Flagğ¶2\nğ¶0ğ¶1Group 0\nFig. 2. Scan index structures of (a) Column Sketches, (b) BinDex, and (c) Cabin (with uniform data).\nand not physically stored. Second, BinDex divides the position array into even-sized intervals (a.k.a.\nbins or areas), and keeps the interval bound positions in the area map. Third, there is a filter bit\nvector per interval. It stores the result for value < interval upper bound. This structure resembles\nBitmap Index. When the scan predicate coincides with an interval bound, the associated filter bit\nvector can be directly returned.\nFor a scan (e.g., ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’â‰¤10), BinDex uses the area map to locate the corresponding interval (e.g.,\nğ´2=[9,12)). Then, it performs a binary search in the interval, which follows the rowIDs to read the\nvalues in the base data. For example, the search finds the predicate value 10at the second entry in\nğ´2. After that, BinDex chooses and copies a filter bit vector (e.g., ğ¹2that represents(âˆ’âˆ,12)) as the\ndraft result. Finally, it refines the draft result by flipping the wrong bits (e.g., bit 14 that corresponds\nto value 11).\nSuppose there are ğ‘records and ğ‘€intervals. Then, there are ğ‘€âˆ’1filter bit vectors. Suppose\neach rowID takes ğ‘Ÿbits. Thus, the space cost of BinDex isğ‘(ğ‘Ÿ+ğ‘€âˆ’1)\n8bytes. The scan time consists\nof checking the area map ( ğ‘‚(logğ‘€)) , searching the interval ( ğ‘‚(logğ‘\nğ‘€)), copying the filter bit\nvector as draft result (i.e., sequentially copyingğ‘\n8bytes), and refining the draft result (i.e., randomly\naccessing averageğ‘\n4ğ‘€bits). Figure 1 shows the BinDex curve varying the number of intervals ğ‘€. As\nğ‘€increases, the space cost increases linearly, while the number of random bit accesses decreases,\nleading to better performance.\nMotivation of Our Solution: Cabin. While BinDex achieves the best performance among existing\nscan indices, it pays substantial space overhead, as shown in Figure 1. We aim to achieve better\ntime-space tradeoff based on three observations:\nâ€¢Observation 1 : It is costly to keep a filter bit vector per interval. We propose filter sketches, which\nrepresent multiple intervals using sketch codes to reduce space.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:7\nâ€¢Observation 2 : The position array takes a fixed amount of space. If space budget is tight, we\npropose selective position array, i.e. storing position arrays for a fraction of intervals. If the\npredicate falls into an interval without position array, the scan can use filter sketches in a similar\nfashion to Column Sketches.\nâ€¢Observation 3 : When the number of duplicate values is high, the interval boundaries should be\njudiciously chosen for time and space efficiency. Hence, we study data-aware intervals.\n3 CABIN DESIGN\nWe propose Cabin, a compressed adaptive binned scan index. In the following, Section 3.1 overviews\nthe design. Then, Section 3.2â€“ 3.4 describe the three distinctive features of Cabin, i.e., filter sketches,\nselective position array, and data-aware intervals, respectively.\n3.1 Cabin Overview\nFigure 2(c) depicts Cabin. It is composed of three structures:\nâ€¢Filter sketches : According to Observation 1, we can use ğ‘¤-bit sketch codes (e.g., ğ‘¤=3 in\nFigure 2(c)) to represent ğ‘š=2ğ‘¤âˆ’2(e.g., 6) intervals. Then we divide all the intervals into\ngroups ofğ‘šintervals each, and build ğ‘¤filter sketches for every group of ğ‘šintervals. The ğ‘—-th\ninterval in group ğ‘–is denoted as ğ¼ğ‘–,ğ‘—.ğ¼ğ‘–,0andğ¼ğ‘–,ğ‘šâˆ’1are two special virtual intervals, representing\nvalues less than and greater than the entire group ğ¼ğ‘–. In this way, ğ¼ğ‘–,0,ğ¼ğ‘–,1, ...,ğ¼ğ‘–,ğ‘šâˆ’1cover the\nfull value range. (This is important for supporting selective position array.) Note that while\nFigure 2(c) draws only one group of intervals due to paper space constraint, there are usually\nmultiple interval groups in a Cabin.\nâ€¢Selective position array : According to Observation 2, we can remove the portion of the position\narray for a subset of intervals to save space. As shown in Figure 2(c), the shaded portion of\nthe selective position array is not physically stored. However, an interval without physical\nposition array may be visited by a scan. In such cases, we cannot perform binary search of the\npredicate value in the position array. Instead, Cabin relies on the filter sketches for evaluating\nthe predicate. Since the filter sketches of an interval group cover the full range of values, they\ncan be used in a similar fashion to Column Sketches.\nâ€¢(Data-aware) interval table : As shown in Figure 2(c), the interval table keeps the metadata\nof each interval in each group, including the value range, the sketch code word, the number\nof records in the interval, its start location in the selective position array, and a flag used\nby selective position array and data-aware intervals to indicate the interval types. To build\nthe interval table, it is natural to divide the value range into even-sized intervals. However,\naccording to Observation 3, even-sized intervals may be sub-optimal when there are a large\nnumber of duplicate values. In such cases, Cabin judiciously makes data-aware selection of\nintervals to further optimize the scan.\nIn the following subsections, we describe three Cabin designs addressing the three observations\nprogressively:\nâ€¢Cabinğ¹: A design with filter sketches, even-sized intervals, and fully physical position array (cf.\nSection 3.2)\nâ€¢Cabinğ¹ğ‘†:Cabinğ¹with s elective position array (cf. Section 3.3)\nâ€¢Cabinğ¹ğ‘†ğ·:Cabinğ¹ğ‘†with d ata-aware intervals (cf. Section 3.4)\n3.2 Filter Sketches\nWe consider the evaluation of a scan with predicate â€œ ğ‘¥â‰¤10â€ using the index as shown in Figure 2(c).\n(1) Cabin locates the predicate value 10in the interval table. It falls into ğ¼0,2. Sinceğ¼0,2contains 4\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:8 Yiyuan Chen and Shimin Chen\nrecords and starts at ğ‘ğ‘œğ‘ [4], Cabin performs a binary search between ğ‘ğ‘œğ‘ [4]andğ‘ğ‘œğ‘ [7]of the\nposition array. The split point is ğ‘ğ‘œğ‘ [5], which refers to ğ‘¥14=11. (2) There are two options to generate\nthe draft result: a) compute a bit vector for all values < ğ¼0,2(i.e.,ğ‘¥<10, or union of ğ¼0,0andğ¼0,1) then\nflip the bits to the left of the split point in ğ¼0,2(i.e.,ğ‘ğ‘œğ‘ [4]); or b) compute the bit vector representing\nvaluesâ‰¤ğ¼0,2(i.e.,ğ‘¥<16, or union of ğ¼0,0,ğ¼0,1, andğ¼0,2) then flip the bits including and to the right\nof the split point in ğ¼0,2(i.e.,ğ‘ğ‘œğ‘ [5],ğ‘ğ‘œğ‘ [6], andğ‘ğ‘œğ‘ [7]). Cabin chooses a) since it minimizes the\nnumber of bit flips. (3) Cabin combines the set of filter sketches in group 0 to compute the draft\nresult for(âˆ’âˆ,10). (4) Cabin flips the bit for ğ‘ğ‘œğ‘ [4](i.e., bit 17) in the draft result to obtain the\nfinal result.\nCompared to BinDex, Step (1), (2), and (4) are similar. The main novel feature of Cabin Fresides in\nStep (3). In the following, we design filter sketches to optimize the draft result computation. Then,\nwe describe the scan algorithm for Cabin F.\nVertical Bit Layout for Filter Sketches. Let us first consider a horizontal layout for filter sketches.\nIn our design, the optimal sketch code width ğ‘¤is often less than 8. As a result, sketch codes may\nspan byte boundaries, incurring computation costs to reconstruct the codes. Therefore, we store\nfilter sketches in a vertical bit layout, as shown in Figure 2(c). ğ‘“ğ‘ 0,ğ‘(ğ‘= 0, ...,ğ‘¤âˆ’1) stores bitğ‘of\nall the codes. This layout enables the use of SIMD logical operations to efficiently generate draft\nresults.\nDraft Bit Vector Computation Problem. We focus on one of the interval groups. Since the\ncomputation is the same regardless of group ğ‘–, we omit the group ID ğ‘–below for simplicity. Following\nthe example, we first consider a predicate â€œ ğ‘¥â‰¤ğ‘â€.\nFrom Step (2), we see that the draft result is the union of intervals ğ¼0...ğ¼ğ‘—for someğ‘—. Let\nthe code word of interval ğ¼ğ‘—beğ‘ğ‘œğ‘‘ğ‘’(ğ‘—). Then the set of code words associated with ğ¼0...ğ¼ğ‘—is\nğ‘ˆğ‘—={ğ‘ğ‘œğ‘‘ğ‘’(0),...,ğ‘ğ‘œğ‘‘ğ‘’(ğ‘—)}. For every code ğ¶in the filter sketches, we set the corresponding bit\nin the draft result to 1 iff ğ¶âˆˆğ‘ˆğ‘—.\nThen, two related questions arise: 1) What is the encoding ğ‘ğ‘œğ‘‘ğ‘’(ğ‘—)? 2) How to compute ğ¶âˆˆğ‘ˆğ‘—\nefficiently?\nOur Solution: MLO. BitWeaving [ 26] proposed the VBP vertical bit layout. As shown in Figure 3(a),\nğ‘ğ‘œğ‘‘ğ‘’(ğ‘—)=ğ‘—in VBP. To compute ğ¶âˆˆğ‘ˆğ‘—, VBP checks each bit from the most to the least significant\nin a loop. Each loop iteration updates ğ‘šğ‘™ğ‘¡andğ‘šğ‘’ğ‘, which represent the less than and the equal\nto cases. If we omit Â¬(since combined operations, such as andnot, may exist as a single SIMD\ninstruction), VBP performs 5ğ‘¤+1SIMD operations for ğ‘¤-bit codes.\nWe propose MLO (minimal logical operations), a novel encoding and computation scheme that\nminimizes the number operations. Unlike VBP, MLO avoids the per-bit loop. Instead, we derive a\nboolean logical formula to compute ğ¶âˆˆğ‘ˆğ‘—.\nIn MLO, we set ğ‘ğ‘œğ‘‘ğ‘’(ğ‘—)=2ğ‘¤âˆ’ğ‘—âˆ’1. Letğ¶=ğ¶ğ‘¤âˆ’1ğ¶ğ‘¤âˆ’2...ğ¶ 0be a code word. Our target is the\nfunctionğ‘“ğ‘¤(ğ¶,ğ‘ˆğ‘—)s.t.ğ‘“ğ‘¤(ğ¶,ğ‘ˆğ‘—)=1 iffğ¶âˆˆğ‘ˆğ‘—. The subscript ğ‘¤denotes the number of bits in the\ncode word. We derive the functionâ€™s formula by recursion. Suppose ğ‘“ğ‘(ğ¶,ğ‘ˆğ‘—)is 1 iffğ¶âˆˆğ‘ˆğ‘—when\nwe focus on the lower ğ‘bits of the codes. We have the following:\nğ‘“ğ‘(ğ¶,ğ‘ˆğ‘—)=ï£±ï£´ï£´ï£´ ï£²\nï£´ï£´ï£´ï£³ğ¶ğ‘âˆ’1âˆ§ğ‘“ğ‘âˆ’1(ğ¶,ğ‘ˆğ‘—), if0â‰¤ğ‘—â‰¤2ğ‘âˆ’1,\nğ¶ğ‘âˆ’1âˆ¨ğ‘“ğ‘âˆ’1(ğ¶,ğ‘ˆğ‘—âˆ’2ğ‘âˆ’1),if2ğ‘âˆ’1<ğ‘—<2ğ‘âˆ’1.\n1, ifğ‘—=2ğ‘âˆ’1.\nWe can prove the following based on the recurrence relations.\nTheorem 3.1. ğ‘“ğ‘¤(ğ¶,ğ‘ˆğ‘—)can be computed with up to ğ‘¤âˆ’1logical operations.\nAs shown in Figure 3(b), MLO performs the same computation with only two SIMD logical opera-\ntions. In general, compared with VBP, which takes 5ğ‘¤+1SIMD operations, our MLO reduces the\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:9\nCode(j) = j\nğºğ‘œğ‘ğ‘™:ğ‘‡ğ‘’ğ‘ ğ‘¡ğ¶âˆˆ{000,001,010}\nğ‘“ğ‘œğ‘Ÿğ‘–=2,1,0\nğ‘šğ‘™ğ‘¡=ğ‘šğ‘™ğ‘¡âˆ¨ğ‘šğ‘’ğ‘âˆ§ğ‘ˆğ‘–âˆ§Â¬ğ¶ğ‘–\nğ‘šğ‘’ğ‘=ğ‘šğ‘’ğ‘âˆ§Â¬ğ‘ˆğ‘–âŠ•ğ¶ğ‘–\nğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡=ğ‘šğ‘’ğ‘âˆ¨ğ‘šğ‘™ğ‘¡Code(j) = 23âˆ’ğ‘—âˆ’1(w=3)\nğºğ‘œğ‘ğ‘™:ğ‘‡ğ‘’ğ‘ ğ‘¡ğ¶âˆˆ{111,110,101}\nğ‘…ğ‘’ğ‘ ğ‘¢ğ‘™ğ‘¡=ğ‘“3=ğ¶2âˆ§ğ¶1âˆ¨ğ¶01.ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘ğ‘Ÿğ‘’ 2.ğ¶ğ‘œğ‘šğ‘ğ‘¢ğ‘¡ğ‘’\nğ‘ˆ:010\nğ‘šğ‘™ğ‘¡:0\nğ‘šğ‘’ğ‘:1(a) VBP (b) MLO\nFig. 3. VBP vs. our proposed MLO computation.\nnumber of SIMD operations by 5x.\nScan Algorithm for â€œ â‰¤â€ Operator. The scan algorithm of Cabin Ffor a predicate â€œ ğ‘¥â‰¤ğ‘â€ is listed\nin Algorithm 1:\n1. Prepare (Line 2â€“4) . Cabin performs a binary search for the predicate value ğ‘in the interval table.\nThe target interval ğ¼ğ‘–,ğ‘—containsğ‘›ğ‘¢ğ‘š records and starts at ğ‘ğ‘œğ‘ [ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡]. Then, Cabin searches for\nğ‘betweenğ‘ğ‘œğ‘ [ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡]andğ‘ğ‘œğ‘ [ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ +ğ‘›ğ‘¢ğ‘š-1]in the selective position array. The split point is\nğ‘ğ‘. Note that data associated with ğ‘ğ‘œğ‘ [0], ...,ğ‘ğ‘œğ‘ [ğ‘ğ‘âˆ’1]satisfy the predicate â€œ ğ‘¥â‰¤ğ‘â€.\n2. Find Closest Matching Intervals (Line 5â€“8) . To compute the result bit vector, there are two options:\na) compute the bit vector representing all intervals < ğ¼ğ‘–,ğ‘—(i.e.ğ‘†ğ‘’ğ‘¡ğ¼={ğ¼ğ‘–,0...ğ¼ğ‘–,ğ‘—âˆ’1}) then flip the\nbits of the records to the left of ğ‘ğ‘; b) compute the bit vector representing ğ‘†ğ‘’ğ‘¡ğ¼={ğ¼ğ‘–,0...ğ¼ğ‘–,ğ‘—}\nthen flip the bits of the unwanted records including and to the right of ğ‘ğ‘. Cabin chooses the\noption with fewer bit flips.\n3. Generate Draft Bit Vector (Line 9â€“10) . This step calls the MLO computation function for every\nğ‘‰ğ¿(i.e, vector length, e.g., 256 in Intel AVX2) bit segment in filter sketches. Our implementation\npre-generates ğ‘“ğ‘¤(ğ¶,ğ‘ˆğ‘—)function using SIMD operations for all 0â‰¤ğ‘—â‰¤2ğ‘¤âˆ’1and2â‰¤ğ‘¤â‰¤9.\n(This is sufficient since the optimal ğ‘¤is often small.) We store the function pointers in a table\nand invoke the relevant functions for ğ‘ ğ‘˜ğ‘’ğ‘¡ğ‘â„ _ğ‘¡ğ‘œ_ğ‘ğ‘£. (Alternatively, SIMD code can be generated\nonline if the database system supports query compilation [14, 19, 21, 28, 36].)\n4. Refine Bit Vector (Line 11â€“13) . Finally, Cabin performs the bit flips to account for the difference\nbetween the interval boundary and the split point. Step 2 has already recorded the incorrect\nrecordsğ‘ğ‘œğ‘ [ğ‘ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡], ...,ğ‘ğ‘œğ‘ [ğ‘ğ‘’ğ‘›ğ‘‘âˆ’1]. Cabin simply flips the corresponding bits in a loop. We\nuse software prefetching to accelerate the random memory accesses caused by the bit flips.\nScan Algorithms for Other Comparison Operators. The scan algorithms for the other compar-\nison operators are similar to Algorithm 1. We discuss them in the following:\nâ€¢â€œğ‘¥<ğ‘â€: â€œğ‘¥<ğ‘â€ can be transformed to â€œ ğ‘¥â‰¤ğ‘â€²â€ whereğ‘â€²is the next value2less thanğ‘. As there\nare no other values between ğ‘andğ‘â€², the two predicates have the same result.\nâ€¢â€œğ‘¥â‰¥ğ‘â€ and â€œğ‘¥>ğ‘â€: To compute â€œ ğ‘¥â‰¥ğ‘â€, the basic idea is to compute â€œ ğ‘¥<ğ‘â€ and negate the\nresult bit vector. After calling ğ‘ ğ‘˜ğ‘’ğ‘¡ğ‘â„ _ğ‘¡ğ‘œ_ğ‘ğ‘£, we perform one additional SIMD operation ğ‘ğ‘£ğ‘ \nğ‘‘ğ‘Ÿğ‘ğ‘“ğ‘¡\n=Â¬ğ‘ğ‘£ğ‘ \nğ‘‘ğ‘Ÿğ‘ğ‘“ğ‘¡. In this way, we obtain the negation of the result bit vector after the bit flips. Similarly,\nâ€œğ‘¥>ğ‘â€ can be computed by negating the result of â€œ ğ‘¥â‰¤ğ‘â€. In these cases, MLO performs up to\nğ‘¤SIMD operations for every ğ‘‰ğ¿code words.\nâ€¢â€œğ‘1â‰¤ğ‘¥â‰¤ğ‘2â€ : In Cabin, this case is transformed into â€œ ğ‘¥â‰¥ğ‘1â€ and â€œğ‘¥â‰¤ğ‘2â€. Then, Cabin\ncomputes the bitwise AND of the result bit vectors of â€œ ğ‘¥â‰¥ğ‘1â€ and â€œğ‘¥â‰¤ğ‘2â€.\nâ€¢â€œğ‘¥=ğ‘â€ and â€œğ‘¥â‰ ğ‘â€: â€œğ‘¥=ğ‘â€ is transformed into â€œ ğ‘â‰¤ğ‘¥â‰¤ğ‘â€. â€œğ‘¥â‰ ğ‘â€ is supported by negating\nthe result of â€œ ğ‘¥=ğ‘â€.\n2For integer values, we can simply set ğ‘â€²=ğ‘-1. For floating-point values, we can get the next representable value ğ‘â€²using the\nC++ std::nexttoward function.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:10 Yiyuan Chen and Shimin Chen\nAlgorithm 1: Cabin Ffor a predicate â€œ ğ‘¥â‰¤ğ‘â€.\nInput : Input column ğ‘‹1...ğ‘, predicate â€œ ğ‘¥â‰¤ğ‘â€, filter sketches ğ‘“ğ‘ ğ‘–,ğ‘, sketch code width ğ‘¤,\ninterval table ğ‘‡ğ¼, selective position array ğ‘ğ‘œğ‘ []\nOutput: Result bit vector ğ‘ğ‘£\n1Function Cabin FScan( â€œğ‘¥â‰¤ğ‘â€,ğ‘‹)\n2 (ğ¼ğ‘–,ğ‘—, num, start, sflag) = binary_search_interval( ğ‘,ğ‘‡ğ¼);\n3 /* assume selective flag of ğ¼ğ‘–,ğ‘—is1, i.e.,ğ‘ ğ‘“ğ‘™ğ‘ğ‘” ==1*/\n4ğ‘ğ‘= binary_search_pos( ğ‘,ğ‘ğ‘œğ‘ ,ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ ,ğ‘›ğ‘¢ğ‘š);\n5 ifğ‘ğ‘âˆ’ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡â‰¤ğ‘›ğ‘¢ğ‘š\n2then\n6ğ‘†ğ‘’ğ‘¡ğ¼={ğ¼ğ‘–,0...ğ¼ğ‘–,ğ‘—âˆ’1};ğ‘ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ =ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ ;ğ‘ğ‘’ğ‘›ğ‘‘=ğ‘ğ‘;\n7 else\n8ğ‘†ğ‘’ğ‘¡ğ¼={ğ¼ğ‘–,0...ğ¼ğ‘–,ğ‘—};ğ‘ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ =ğ‘ğ‘;ğ‘ğ‘’ğ‘›ğ‘‘=ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ +ğ‘›ğ‘¢ğ‘š;\n9 foreachğ‘‰ğ¿-bit segment ğ‘ in filter sketches do\n10ğ‘ğ‘£ğ‘ \nğ‘‘ğ‘Ÿğ‘ğ‘“ğ‘¡=ğ‘ ğ‘˜ğ‘’ğ‘¡ğ‘â„ _ğ‘¡ğ‘œ_ğ‘ğ‘£(ğ‘†ğ‘’ğ‘¡ğ¼,{ğ‘“ğ‘ ğ‘ \nğ‘–,0...ğ‘“ğ‘ ğ‘ \nğ‘–,ğ‘¤âˆ’1});\n11 forğ‘ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡â‰¤ğ‘Ÿ<ğ‘ğ‘’ğ‘›ğ‘‘do\n12 pipeline prefetch;\n13 flip_bit(ğ‘ğ‘£[ğ‘ğ‘œğ‘ [ğ‘Ÿ]]);\n14 returnğ‘ğ‘£;\nShortcut Optimization. BinDex takes a different approach for evaluating â€œ ğ‘¥=ğ‘â€. The idea is\nto start with an all-zero draft vector, then search the position array to find the small number of\nrecords that satisfy the predicate, and finally set the corresponding bits in the draft vector. We\ncall this approach shortcut optimization . The shortcut optimization reduces the cost of computing\nthe draft bit vector from filter sketches. We find this beneficial for comparison operators (e.g.,\nBETWEEN) other than â€œ=â€ when the selectivity is low. Therefore, we extend the use of shortcut\noptimization for all comparison operators. After searching the selective position array, Cabin knows\nthe selectivity of the scan. If it is lower than a given threshold (e.g., 0.5%), Cabin performs the\nshortcut optimization.\n3.3 Selective Position Array\nLet us consider the space cost of the position array. For 4-byte rowIDs, it takes 4ğ‘bytes, where ğ‘\nis the number of records. Since the rowID size can be similar to or even larger than the data value\nsize, this incurs significant space overhead. For example, the rowIDs of 1 billion records take nearly\n4GB memory space.\nTo save memory space, we propose to selectively store portions of the position array. That is, for\na subset of intervals, we do not store their rowIDs, and set their selective flags to 0 in the interval\ntable. This allows more flexible time-space tradeoff.\nScan Algorithm Without Selective Position Array. The scan algorithm of Cabin FSis listed in\nAlgorithm 2. Compared to Cabin F, the main difference is that Cabin FScannot search the target\ninterval using the selective position array in order to refine the draft bit vector. Instead, we use the\nfilter sketches in a similar fashion to Column Sketches to refine the draft result:\n1. Prepare (Line 2â€“3) . Cabin finds the target interval ğ¼ğ‘–,ğ‘—in the interval table. It checks the selective\nflag. If the flag is 0, meaning that the rowIDs of ğ¼ğ‘–,ğ‘—are not stored, then Cabin executes Cabin FS.\n(If the flag is 1, then Cabin Fis used).\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:11\nAlgorithm 2: Cabin FSfor a predicate â€œ ğ‘¥â‰¤câ€.\nInput : Input column ğ‘‹1...ğ‘, predicate â€œ ğ‘¥â‰¤ğ‘â€, filter sketches ğ‘“ğ‘ ğ‘–,ğ‘, sketch code width ğ‘¤,\ninterval table ğ‘‡ğ¼, selective position array ğ‘ğ‘œğ‘ []\nOutput: Result bit vector ğ‘ğ‘£\n1Function Cabin FSScan( â€œğ‘¥â‰¤ğ‘â€,ğ‘‹)\n2 (ğ¼ğ‘–,ğ‘—, num, start, sflag) = binary_search_interval( ğ‘,ğ‘‡ğ¼);\n3 /* assume selective flag of ğ¼ğ‘–,ğ‘—is0, i.e.,ğ‘ ğ‘“ğ‘™ğ‘ğ‘” ==0*/\n4ğ‘†ğ‘’ğ‘¡ğ¼={ğ¼ğ‘–,0...ğ¼ğ‘–,ğ‘—âˆ’1};\n5 foreachğ‘‰ğ¿-bit segment ğ‘ in filter sketches do\n6ğ‘ğ‘£ğ‘ \nğ‘‘ğ‘Ÿğ‘ğ‘“ğ‘¡=ğ‘ ğ‘˜ğ‘’ğ‘¡ğ‘â„ _ğ‘¡ğ‘œ_ğ‘ğ‘£(ğ‘†ğ‘’ğ‘¡ğ¼,{ğ‘“ğ‘ ğ‘ \nğ‘–,0,...,ğ‘“ğ‘ ğ‘ \nğ‘–,ğ‘¤âˆ’1});\n7ğ‘ğ‘£ğ‘ \nğ‘’ğ‘=ğ‘ ğ‘˜ğ‘’ğ‘¡ğ‘â„ _ğ‘¡ğ‘œ_ğ‘ğ‘£(ğ¼ğ‘–,ğ‘—,{ğ‘“ğ‘ ğ‘ \nğ‘–,0,...,ğ‘“ğ‘ ğ‘ \nğ‘–,ğ‘¤âˆ’1});\n8ğ‘’ğ‘ğ‘ğ‘–ğ‘¡ğ‘ []=ğ‘ğ‘£_ğ‘¡ğ‘œ_ğ‘ğ‘œğ‘ (ğ‘ğ‘£ğ‘ \nğ‘’ğ‘);\n9 foreachğ‘Ÿinğ‘’ğ‘ğ‘ğ‘–ğ‘¡ğ‘ []do\n10 ğ‘ğ‘£ğ‘ =ğ‘ğ‘£ğ‘ \nğ‘‘ğ‘Ÿğ‘ğ‘“ğ‘¡|((ğ‘‹ğ‘ğ‘œğ‘ [ğ‘ âˆ—ğ‘‰ğ¿+ğ‘Ÿ]â‰¤ğ‘)â‰ªğ‘Ÿ);\n11 returnğ‘ğ‘£;\n2. Find Matching Interval (Line 4) . Since the portion of position array for ğ¼ğ‘–,ğ‘—is not stored, we\ncannot search ğ¼ğ‘–,ğ‘—.Cabin FSsimply setsğ‘†ğ‘’ğ‘¡ğ¼to all intervals < ğ¼ğ‘–,ğ‘—.\n3. Generate Draft Bit Vector (Line 5â€“6) . This step is the same as Cabin F.ğ‘ ğ‘˜ğ‘’ğ‘¡ğ‘â„ _ğ‘¡ğ‘œ_ğ‘ğ‘£is invoked to\nobtain the draft bit vector for every ğ‘‰ğ¿code words.\n4. Refine Bit Vector (Line 7â€“10) . For a valueâˆˆğ¼ğ‘–,ğ‘—, filter sketches alone cannot tell the predicate\noutcome. In such cases, Cabin FSvisits the base data to evaluate the predicate. Accordingly, the\nalgorithm obtains all the positions whose sketch code is equal to the code of ğ¼ğ‘–,ğ‘—(Line 7â€“8), then\nchecks the corresponding base value against the predicate (Line 9â€“10).\nSketch Code Equality Comparison. We develop a boolean logical function ğ‘’ğ‘ğ‘¤(ğ¶,ğ¶ğ‘‡), where\nğ¶ğ‘‡is the code of the target interval ğ¼ğ‘–,ğ‘—. Letğ¶=ğ¶ğ‘¤âˆ’1ğ¶ğ‘¤âˆ’2...ğ¶ 0be a code word. ğ‘’ğ‘ğ‘¤(ğ¶,ğ¶ğ‘‡)=1 iff\nğ¶=ğ¶ğ‘‡. We also derive the formula by recursion:\nğ‘’ğ‘ğ‘(ğ¶,ğ¶ğ‘‡)=(\nÂ¬ğ¶ğ‘âˆ’1âˆ§ğ‘’ğ‘ğ‘âˆ’1(ğ¶,ğ¶ğ‘‡), ğ¶ğ‘‡\nğ‘âˆ’1=0,\nğ¶ğ‘âˆ’1âˆ§ğ‘’ğ‘ğ‘âˆ’1(ğ¶,ğ¶ğ‘‡), ğ¶ğ‘‡\nğ‘âˆ’1=1.\nFor example, ğ‘’ğ‘3(ğ¶,010)=Â¬ğ¶2âˆ§ğ¶1âˆ§Â¬ğ¶0. Note that Intel processors support andnot as a single\nSIMD instruction. Therefore, ğ‘’ğ‘ğ‘¤(ğ¶,ğ¶ğ‘‡)takes up toğ‘¤SIMD operations to compute for each SIMD\nsegment.\n3.4 Data-aware Intervals\nInCabin FandCabin FS, we divide the value range into equal-sized intervals. This strategy works\nwell when the number of duplicates for each distinct value is small. However, real-world data may\ncontain a lot of duplicates. Two representative scenarios are as follows:\nâ€¢Skewed data distribution : Real-world data distribution is often skewed. For example, power-law\ndistribution is common in real-world graphs, such as social networks [ 5]. In this scenario, a few\nvalues may have a large number of duplicates, while the number of duplicates of most values is\nsmall.\nâ€¢Small number of distinct values (NDV) : The number of distinct values can be small in a data\ncolumn. Examples are categorical attributes. In this scenario, the number of duplicates can be\nquite large for each distinct value.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:12 Yiyuan Chen and Shimin Chen\n50 245050â€¦ 250\nğ‘¥0ğ‘¥1ğ‘¥2ğ‘¥3ğ‘¥4ğ‘¥ğ‘âˆ’1ğ‘¥ğ‘\nFilter Sketches Interval Table\n0 1 0 0 0â€¦ 1 0 ğ‘“ğ‘ 0,1Column Data\n1 1 1 1 1â€¦ 1 1 ğ‘“ğ‘ 1,0ğ¼0,0(âˆ’âˆ,2)111 /0/\nğ¼0,1[2,4)110â€¦â€¦2\nğ¼0,2[4,20)101â€¦â€¦1\nâ€¦â€¦â€¦â€¦â€¦â€¦\nğ¼0,7(46,+âˆ)000 ///\nğ¼1,0(âˆ’âˆ,50]1â€¦â€¦3\nğ¼1,1(50,+âˆ)0 ///(popular values: 2, 50)Group 0 Group 1flag\n0 0 1 0 0â€¦ 0 0 ğ‘“ğ‘ 0,00 1 1 0 0â€¦ 1 0 ğ‘“ğ‘ 0,2\nInterval\nTypeflag = 0 interval without position array flag = 2 skew interval\nflag =1interval with position array flag =3skew interval group\nFig. 4. Cabin supporting data with duplicates.\nWe call values with a large number of duplicates popular values .Cabin FSDjudiciously chooses\nintervals, interval groups, and/or sketch code widths to better support popular values.\nIn the following, we describe the steps of index building with an emphasis on data-aware\nintervals:\nIndex Building Step 1: Popular Value Discovery. Given a base data column, we consider\nthree alternative methods for discovering popular values. First, the sort-based method allocates a\ntemporary sort buffer and sorts the (value, rowID) pairs in value order. It scans the sorted array\nand computes the number of duplicates for each value. Second, the hash-based method allocates a\ntemporary hash table and counts the number of duplicates per value using the hash table. Third,\nthe sample-based method collects a small (e.g., 1%) sample from the base data. Then, it applies the\nsort-based method on the sample. Since popular values appear in the sample with high probability,\nwe can use the sample based estimates to discover popular values. We record a value as a candidate\npopular value if its number of occurrences â‰¥ğ‘ğ‘ğ‘™. The bound ğ‘ğ‘ğ‘™is computed as the record count\nğ‘divided by the maximal number of intervals given the memory space budget of Cabin. We\nalso collect/estimate other meta-information about the base data, such as the value range and the\nnumber of distinct values.\nIndex Building Step 2: Optimal Design Selection. Given memory space budget and the data\ncharacteristics, we compute the optimal design parameters (cf. Section 4). Then, we compute ğ‘ğ‘,\nthe average interval size, as ğ‘divided by the number of intervals in the optimal parameters. Since\nğ‘ğ‘>ğ‘ğ‘ğ‘™in most cases, we remove unqualified candidates to obtain the popular values. For each\npopular value, we put the value into its own interval. We call such interval skew interval . If the\nnumber of duplicates is larger than the average interval group size ğ‘ğ‘(2ğ‘¤âˆ’2), then we put the\nvalue into its own interval group. We call such interval group skew interval group . The code width of\nall skew interval groups is set to 1. As for unpopular normal values, we create even-sized intervals.\nIndex Building Step 3: Structure Building. Given the selected design parameters in Step 2, we\nbuild the interval table, the selective position array, and the filter sketches. For skew intervals and\nskew interval groups, we do not store the associated portions of the position array. As a skew\ninterval contains only a single value, scans do not need to search the position array in the interval.\nOptimizing for Popular Values. Figure 4 illustrates data-aware intervals for popular values.\nThere are two popular values in the base data: 50and2. First, 50occupies its own skew interval\ngroup (i.e., Group 1). A skew interval group contains only two virtual intervals (âˆ’âˆ,ğ‘£ğ‘]and\n(ğ‘£ğ‘,+âˆ), whereğ‘£ğ‘is the popular value. We set flag=3 to indicate a skew interval group. Second, 2\nhas its own skew interval in Group 0 (i.e., ğ¼0,1). We set flag=2 for skew intervals.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:13\nTable 2. Terms used in cost analysis.\nğ‘¤ sketch code width ğ¼ğ‘–,ğ‘—ğ‘—-th interval in Group ğ‘–\nğ‘” number of groups ğ‘ğ‘–,ğ‘— probability of accessing ğ¼ğ‘–,ğ‘—\nğ‘ ğ‘ percentage of stored pos[] ğ‘†ğ‘’ğ‘¡ğ‘¥Set of intervals w/ property ğ‘¥\nğ‘ number of records ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ time to sequentially read a byte\nğ‘€ number of intervals ğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤ time to sequentially write a byte\n|ğ¼ğ‘–,ğ‘—|number of records in ğ¼ğ‘–,ğ‘—ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘Ÿ time for a random read\nğ‘Ÿ rowID bits ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘¤ time for a random write\nğ‘‰ğ¿ SIMD vector length ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘ time of a SIMD logical operation\nFor a scan with predicate ğ‘¥â‰¤ğ‘,Cabin FSDfinds the target interval in the interval table. There are\ntwo cases for popular values. First, the target is a skew interval group with flag=3 (e.g., ğ‘=50). Then\nthe scan directly returns the single filter sketch (e.g., ğ‘“ğ‘ 1,0). Second, the target interval is a skew\ninterval in a normal group (e.g., ğ‘=2). Then the scan performs a simplified Cabin FScan. Specifically,\nsince the skew interval contains a single value, there is no need to refine the draft result. The draft\nresult bit vector can be returned directly. In both cases, Cabin FSDsimplifies the scan procedure,\nthereby improving scan performance for popular values.\n4 OPTIMAL DESIGN SELECTION\nWe model the time and space cost of Cabin, then describe how to compute the optimal design\nparameters for Cabin.\nDesign Parameters of Cabin. There are three important design parameters in Cabin. (Table 2\nlists the terms used in the analysis.)\nâ€¢Sketch code word width ( ğ‘¤). Asğ‘¤increases, the number of bit vectors in filter sketches increases.\nThe cost of draft bit vector generation becomes proportionally expensive. On the other hand, the\nnumber of intervals per group ( 2ğ‘¤âˆ’2) increases exponentially. Interval size becomes smaller,\nleading to fewer bit flips in the refine step.\nâ€¢Number of groups ( ğ‘”). Every contiguous 2ğ‘¤âˆ’2intervals form a group. The total number of\nnon-virtual intervals is ğ‘€=ğ‘”(2ğ‘¤âˆ’2). Asğ‘”rises,ğ‘€increases. The interval size decreases, and\ntherefore the refine step improves. However, the space for storing all filter sketches grows as ğ‘”\nincreases. The optimal ğ‘”is often larger than 1 (cf. Section 5.4).\nâ€¢Stored proportion of selective position array ( ğ‘ ğ‘).ğ‘ ğ‘âˆˆ[0,1]is the fraction of rowIDs physically\nstored in the selective position array. For even-sized intervals, ğ‘ ğ‘Â·ğ‘€computes the number of\nintervals, whose flag=1 in the interval table. In this work, we assume that every data record is\nequally likely to be the query predicate value. Hence, the probability that the predicate value\nfalls into each equal-sized interval is the same. Therefore, we randomly pick intervals that do\nnot store the position array.\nScan Performance. Letğ‘ğ‘–,ğ‘—be the probability that the scan predicate value falls into interval ğ¼ğ‘–,ğ‘—.\nLet|ğ¼ğ‘–,ğ‘—|be the number of records in ğ¼ğ‘–,ğ‘—. If we assume that every base data record is equally likely\nto be queried, then ğ‘ğ‘–,ğ‘—=|ğ¼ğ‘–,ğ‘—|\nğ‘. Letğ‘†ğ‘’ğ‘¡0be the set of all intervals whose flag=0 (i.e., the rowIDs are\nnot stored). Let ğ‘†ğ‘’ğ‘¡1be the set of all intervals whose flag=1 (i.e. with stored position array). Let\nğ‘†ğ‘’ğ‘¡ğ‘ ğ‘˜ğ‘’ğ‘¤ be the set of all skew intervals. Then the average scan time of Cabin can be modeled as\nfollows:\nğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘› =âˆ‘ï¸\nğ‘†ğ‘’ğ‘¡ 1|ğ¼ğ‘–,ğ‘—|\nğ‘ğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹(ğ¼ğ‘–,ğ‘—)+âˆ‘ï¸\nğ‘†ğ‘’ğ‘¡ 0|ğ¼ğ‘–,ğ‘—|\nğ‘ğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ğ‘†(ğ¼ğ‘–,ğ‘—)+âˆ‘ï¸\nğ‘†ğ‘’ğ‘¡ğ‘ ğ‘˜ğ‘’ğ‘¤|ğ¼ğ‘–,ğ‘—|\nğ‘ğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ğ‘†ğ·(ğ¼ğ‘–,ğ‘—)\nğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ , the scan time of Cabin F, consists of four components:\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:14 Yiyuan Chen and Shimin Chen\n1. Prepare (ğ‘‡ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ ).Cabin Fsearches the interval table containing ğ‘€intervals, and then the target\ninterval with an averageğ‘\nğ‘€records. Hence, this step takes ğ‘‚(logğ‘)time.\n2. Find Closest Matching Intervals (ğ‘‡ğ‘“ğ‘ğ‘šğ‘–). Step 2 involves ğ‘‚(1)comparison and assignment opera-\ntions.\n3. Generate Draft Bit Vector (ğ‘‡ğ‘”ğ‘’ğ‘›ğ‘ğ‘£ ). This step reads a group of ğ‘¤ ğ‘-bit filter sketches, performs\nan average ğ‘¤SIMD logical operations for every ğ‘‰ğ¿code words, and writes a ğ‘-bit result\nvector. Hence, ğ‘‡ğ‘”ğ‘’ğ‘›ğ‘ğ‘£ =max{ğ‘¤ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ,ğ‘¤ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘,ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤}whereğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ,ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘, andğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤ are the time\nto sequentially read a byte, perform a SIMD logical operation, and sequentially write a byte,\nrespectively. The max takes into consideration the overlapping of computation and memory\naccesses [15, 33].\n4. Refine Bit Vector ( ğ‘‡ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘›ğ‘’ğ¹ ). As Step 2 finds the closer interval end to the split point, the number\nof bit flips is at most half of the interval. On average,1\n4of the positions need to be corrected. For\neach position, Step 4 reads the rowIDs in the position array then flips the bit in the draft result.\nHence,ğ‘‡ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘›ğ‘’ğ¹ =|ğ¼ğ‘–,ğ‘—|\n4(ğ‘Ÿ\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ+ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘¤), where|ğ¼ğ‘–,ğ‘—|is the size of interval ğ¼ğ‘–,ğ‘—,ğ‘Ÿis the number of\nbits of rowID, ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘¤ is the time for a random write.\nIt follows from the above discussion:\nğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹(ğ¼ğ‘–,ğ‘—)=ğ‘‡ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹+ğ‘‡ğ‘“ğ‘ğ‘šğ‘–+ğ‘‡ğ‘”ğ‘’ğ‘›ğ‘ğ‘£+ğ‘‡ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘›ğ‘’ğ¹\n=ğ‘‚(logğ‘)+max{ğ‘¤ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ,ğ‘¤ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘,ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤}+|ğ¼ğ‘–,ğ‘—|(ğ‘Ÿ\n32ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ+1\n4ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘¤)\nğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ğ‘† , the scan time of Cabin FS, also consists of four components. The costs of the first three steps\nare similar to those of Cabin ğ‘†except that it does not search the interval. The main difference is the\ncost of the refine step. Since the portion of the selective position array is not stored for the interval,\nCabin FScomputes the equal-code positions with SIMD logical operations, and reads all |ğ¼ğ‘–,ğ‘—|base\ndata values in interval ğ¼ğ‘–,ğ‘—to evaluate the predicate. On average, half the values satisfy the predicate,\nand the scan flips|ğ¼ğ‘–,ğ‘—|\n2bits in the draft result. Hence, ğ‘‡ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘›ğ‘’ğ¹ğ‘† =ğ‘¤ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘+|ğ¼ğ‘–,ğ‘—|(ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘Ÿ+1\n2ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘¤),\nwhereğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘Ÿis the time for a random read. Hence, we have:\nğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ğ‘†(ğ¼ğ‘–,ğ‘—)=ğ‘‡ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘†+ğ‘‡ğ‘“ğ‘ğ‘šğ‘–+ğ‘‡ğ‘”ğ‘’ğ‘›ğ‘ğ‘£+ğ‘‡ğ‘Ÿğ‘’ğ‘“ğ‘–ğ‘›ğ‘’ğ¹ğ‘†\n=ğ‘‚(logğ‘€)+max{ğ‘¤ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ,ğ‘¤ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘,ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤}+ğ‘¤ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘+|ğ¼ğ‘–,ğ‘—|(ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘Ÿ+1\n2ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘¤)\nFinally, we compute ğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ğ‘†ğ· for popular values. The scan searches the interval table in ğ‘‚(logğ‘€)\ntime. Then it computes the result. There are two cases. For a skew group, the scan returns the\nfilter sketches with negligible cost. For a skew interval, the scan generates and returns the draft bit\nvector inğ‘‡ğ‘”ğ‘’ğ‘›ğ‘ğ‘£ time.\nğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘›ğ¹ğ‘†ğ·(ğ¼ğ‘–,ğ‘—)=ğ‘‡ğ‘ ğ‘’ğ‘ğ‘Ÿğ‘â„ğ¹ğ‘†ğ·+ğ‘‡ğ‘“ğ‘ğ‘šğ‘–+ğ‘‡ğ‘”ğ‘’ğ‘›ğ‘ğ‘£\n=(\nğ‘‚(logğ‘€)+max{ğ‘¤ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ,ğ‘¤ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘,ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤}, ğ‘“ğ‘™ğ‘ğ‘” =2,\nğ‘‚(logğ‘€)+max{ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘Ÿ,ğ‘\nğ‘‰ğ¿ğ‘¡ğ‘ ğ‘–ğ‘šğ‘‘,ğ‘\n8ğ‘¡ğ‘ ğ‘’ğ‘ğ‘¤}, ğ‘“ğ‘™ğ‘ğ‘” =3.\nSpace Overhead. We first consider all equal-sized intervals:\nâ€¢Interval table (ğ‘†ğ‘‡ğ¼). It stores meta information of intervals. Its space cost is negligible.\nâ€¢Filter sketches (ğ‘†ğ‘“ğ‘ ). There are ğ‘”interval groups. Each group has ğ‘¤ ğ‘-bit vectors. Hence, ğ‘†ğ‘“ğ‘ =\nğ‘”ğ‘¤ğ‘\n8bytes.\nâ€¢Selective position array (ğ‘†ğ‘ğ‘œğ‘ ). The total size isğ‘ğ‘Ÿ\n8bytes. Since ğ‘ ğ‘portion is physically stored,\nğ‘†ğ‘ğ‘œğ‘ =ğ‘ ğ‘ğ‘ğ‘Ÿ\n8bytes.\nThus, we have the following for equal-sized intervals:\nğ‘†ğ¶ğ‘ğ‘ğ‘–ğ‘› =ğ‘†ğ‘‡ğ¼+ğ‘†ğ‘“ğ‘ +ğ‘†ğ‘ğ‘œğ‘ =ğ‘”ğ‘¤ğ‘\n8+ğ‘ ğ‘ğ‘ğ‘Ÿ\n8\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:15\nAlgorithm 3: Optimal design selection algorithm.\nInput : Column data ğ‘‹1...ğ‘, space budget ğµ\nOutput: Sketch code width ğ‘¤, number of groups ğ‘”, stored proportion of selective position\narrayğ‘ ğ‘\n1Function DesignSelection( ğ‘‹,ğµ)\n2ğ‘=|ğ‘‹|;ğ¶ğ‘ƒ= CandidatePopularValues ( ğ‘‹,ğµ);\n3ğ‘‡ğ‘šğ‘–ğ‘›=+âˆ;\n4 for2â‰¤ğ‘¤â‰¤9do\n5ğ‘”ğ‘šğ‘ğ‘¥=8ğµ\nğ‘¤Â·ğ‘/*ğ‘ ğ‘=0*/;ğ‘”ğ‘šğ‘–ğ‘›=8ğµâˆ’ğ‘Â·ğ‘Ÿ\nğ‘¤Â·ğ‘/*ğ‘ ğ‘=1*/;\n6 forğ‘”ğ‘šğ‘–ğ‘›â‰¤ğ‘”â‰¤ğ‘”ğ‘šğ‘ğ‘¥do\n7 ğ‘€=ğ‘”Â·(2ğ‘¤âˆ’2);\n8 ğ‘†ğ‘’ğ‘¡ğ‘ ğ‘˜ğ‘’ğ‘¤ = DataAwareInterval( ğ‘‹,ğ¶ğ‘ƒ,ğ‘€);\n9 ğ‘†ğ‘’ğ‘¡ğ‘›ğ‘œğ‘Ÿğ‘šğ‘ğ‘™ = EqualInterval( ğ‘‹,ğ‘†ğ‘’ğ‘¡ğ‘ ğ‘˜ğ‘’ğ‘¤,ğ‘€);\n10 ğ‘ ğ‘= ComputeSP(N, ğ‘†ğ‘’ğ‘¡ğ‘ ğ‘˜ğ‘’ğ‘¤,ğ‘†ğ‘’ğ‘¡ğ‘›ğ‘œğ‘Ÿğ‘šğ‘ğ‘™ ,ğ‘”,ğ‘¤);\n11(ğ‘†ğ‘’ğ‘¡0,ğ‘†ğ‘’ğ‘¡ 1)= GetSelPosArray( ğ‘†ğ‘’ğ‘¡ğ‘›ğ‘œğ‘Ÿğ‘šğ‘ğ‘™ ,ğ‘ ğ‘);\n12 Computeğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘› givenğ‘†ğ‘’ğ‘¡0,ğ‘†ğ‘’ğ‘¡1, andğ‘†ğ‘’ğ‘¡ğ‘ ğ‘˜ğ‘’ğ‘¤;\n13 ifğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘› <ğ‘‡ğ‘šğ‘–ğ‘›then\n14 ğ‘‡ğ‘šğ‘–ğ‘›=ğ‘‡ğ¶ğ‘ğ‘ğ‘–ğ‘› ; update (ğ‘¤,ğ‘”,ğ‘ ğ‘);\n15 return (ğ‘¤,ğ‘”,ğ‘ ğ‘);\nFor popular values, Cabin does not store the rowIDs. Therefore, we subtract the number of records\nwith popular values from ğ‘in the computation of ğ‘†ğ‘ğ‘œğ‘ . As for filter sketches, there are two cases.\nFor a skew interval group, Cabin stores only a single ğ‘-bit vector. For a skew interval in a normal\ngroup, the size of filter sketches is the same as that of normal intervals.\nOptimal Design Selection. Given a memory space budget, Algorithm 3 finds the design parameters\nthat optimize the scan time of Cabin. It begins by getting the candidate popular values (Line 2, cf.\nSection 3.4). Then, it enumerates every pair of ( ğ‘¤,ğ‘”). We restrict ğ‘¤to be up to 9, which is sufficient\nin our experiments with up to a billion records. The range of ğ‘”is bounded by the cases where the\nselective position array is entirely stored or removed. Therefore, the procedure is efficient because\nthe search space is limited.\nFor each pair of ( ğ‘¤,ğ‘”), the algorithm computes the set of skew intervals from popular values\n(Line 8, cf. Section 3.4). Then, for unpopular values, it computes equal-sized intervals (Line 9). After\nthat, the algorithm examines the space cost of filter sketches and selective position array by taking\ninto account of both skew intervals and normal intervals. It computes ğ‘ ğ‘(Line 10) and chooses\na subset of intervals to remove the associated portion of the selective position array (Line 11).\nThis completes the tentative design for all intervals. The scan time is estimated using the above\nformulas3(Line 12). Finally, the algorithm returns the design parameters that obtain the minimal\nscan time.\n5 EVALUATION\nWe perform extensive experiments to compare Cabin with existing optimized scan solutions in this\nsection.\n3The asymptotic terms, i.e., ğ‘‚(logğ‘€)andğ‘‚(logğ‘), in the formulas refer to the time of searching the interval table and/or\nthe position array. Since the search time is tiny compared to the ( ğ‘‚(ğ‘)) cost of draft bit vector generation and refinement\n(cf. Figure 11(a) and Figure 12), we omit these terms in the computation.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:16 Yiyuan Chen and Shimin Chen\n5.1 Experimental Setup\nMachine Configuration. The experimental machine is equipped with a 3.0GHz Intel Core i7-9700\nprocessor (8 cores, 12MB L3 cache), 32GB DDR4 DRAM, and 16TB disks. The processor supports\n256-bit SIMD instructions. The operating system is 64-bit Ubuntu Server 20.04 with Linux kernel\n5.13.0-30. All testing programs are compiled using g++ 9.4 (i.e., the default version in Ubuntu 20.04)\nwith optimization flag -O3 and SIMD flag -mavx, -mavx2, -mbmi1, -mbmi2. All experiments are\nperformed in main memory.\nSolutions to Compare. We compare Cabin against five optimized scan solutions: ByteSlice\n(BS) [13], Zone Maps ( ZM) [27], Column Sketches ( CS) [16], B+-tree [ 11], and BinDex [ 25]. We\nobtain the code of ByteSlice and BinDex from their github repositories. We select a widely used\nin-memory B+-tree implementation, STX B+-Tree [ 3]. For Zone Maps and Column Sketches, we\nfollow the papers to faithfully implement the techniques. We use single-byte column sketches as in\nthe original experimental setting. Moreover, we try our best to optimize all scan solutions with\nsoftware prefetching and SIMD techniques.\nBoth BinDex and Cabin can leverage more space to construct more filter bit vectors or filter\nsketches for achieving better scan performance. We set a reasonable space limit by considering the\nspace cost of the B+-Tree. In our experimental setting, a rowID is 32-bit large and each column data\nvalue takes ğ‘‘bits, whereğ‘‘=8, 16, 32, or 64. Hence, the data column takes ğ‘‘ğ‘bits, whereğ‘is the\nnumber of records. Since the B+-Treeâ€™s leaf level contains ğ‘pair of (value, rowID), the B+-Tree size\nis at least(ğ‘‘+32)ğ‘bits. (Note that the B+-Tree consumes more space for storing non-leaf nodes as\nwell as other fields, such as sibling pointers, in leaf nodes.) Consequently, we set the default space\nupper limit of BinDex and Cabin to beğ‘‘+32\nğ‘‘Ã—column size (i.e., 5x for ğ‘‘=8, 3x forğ‘‘=16, 2x forğ‘‘=32,\nand 1.5x for ğ‘‘=64), which is smaller than the B+-Tree.\nNote that this space limit is a lower bound of the space used in tree-structured indices in general,\nincluding not only B+-Trees, but also more recent proposals, such as ART [ 24] and learned index [ 20].\nThis is because values are not sorted and a tree-structured index has to store (value, rowID)s for\nthe data column.\nSynthetic Workload. We generate each synthetic data column with one billion random values.\nWe consider four cases: 1) integer data following uniform distribution over the full value range;\n2) integer data following Zipf distribution to model skew data; 3) integer data with ğ‘ğ·ğ‘‰ distinct\nvalues uniformly distributed in [0,ğ‘ğ·ğ‘‰)to model domain encoded categorical attributes; and 4)\nskewed floating point data following skewed normal distribution (location=0, scale=1, shape=4) or\npareto distribution (scale=1, shape=4) generated with the Boost library. Note that there are few\nduplicate values in case 1 and 4, but a large number of duplicates in case 2 and 3.\nWe perform scan operations with different types of predicates on the synthetically generated\ndata columns. We run all experiments in a single-threaded test program. The output of all scan\nsolutions is a result bit vector except the B+-tree, which outputs a rowID list.\nReal-World Data Sets. We also conduct experiments on two widely used real-world data sets,\nDBLP [ 1] and IMDb [ 2]. The DBLP data set contains 5.26M records. We use the n_citation column\nin the scan experiment. The IMDb data set contains 10.2M records. We use the startYear column\nin the scan experiment. Both data sets contain a lot of duplicates.\nTPC-H and SSB Workloads. Besides the above stand-alone tests, we evaluate Cabin in a full\nfledged main memory database system, MonetDB. To add Cabin to MonetDB, our implementation\nfollows the approach of BinDex. Specifically, the Cabin-based select operator supports the same API\nas the original select operator, which takes a single column and a predicate as input. A new fetch\noperator supports the result bit vector instead of the rowID list in the original fetch operator. To run\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:17\n 0 50 100 150 200 250\n0 20 40 60 80 100\n(a) Varying selectivities with â‰¤ operator.Time (ms)\nSelectivity (%)ZM\nCSBS\nBinDexCabin\n050100150200250\nâ‰¤ BETWEEN =\n(b) Varying operators.Average Time (ms)ZM\nCSBS\nBinDexCabin\nFig. 5. Scan performance (uniform, 32-bit data).\na SQL query, we first invoke MonetDB to generate the corresponding MAL script, which consists of\noperator calls to execute the selected query plan for the query. Then, we modify the MAL script to\ncall either BinDex or Cabin enhanced scan operations. We run the original, BinDex-enhanced, and\nCabin-enhanced MAL scripts to compare the query performance of MonetDB, MonetDB+BinDex,\nand MonetDB+Cabin, respectively. In the MonetDB experiments, we still bound the memory usage\nof BinDex and Cabin byğ‘‘+32\nğ‘‘Ã—column size for each indexed column, where ğ‘‘is the bit width of\ndata values.\nWe run TPC-H and SSB (Star Schema Benchmark) workloads on MonetDB. For TPC-H, we\ngenerate data with scale factor=20. We follow previous study [ 16,25] to run TPC-H Q1 and Q6,\nwhich scan the Lineitem table with various filters to compute aggregates. We also run Q12, which\nperforms a single join between Lineitem and Orders tables in addition to scans and aggregates. For\nSSB, we generate data with scale factor=60. We run all the SSB queries.\n5.2 Scan Performance on Uniform Data\nIn this subsection, we perform scan experiments on uniform data with few duplicates. We vary the\npredicate comparison operator, the data width, and the predicate selectivity in the experiments.\nScan withâ‰¤Operator. Figure 5(a) compares the scan solutions with â‰¤operator on 32-bit integer\ndata. The x-axis varies the selectivity from 0 to 100% with 1% increments. The y-axis reports scan\ntime in ms. Each reported point is the average over 10 runs.\nFirst, we see that Zone Maps, Column Sketches, and ByteSlice show three flat lines as the\nselectivity increases. Zone Maps fall back to plain scans in most cases, reading 32ğ‘bits of data\nand displaying a flat (green) curve. Only at very low or very high selectivities can Zone Maps\neffectively skip entire buckets. Column Sketches out-performs Zone Maps by reducing the amount\nof data to read. Regardless of selectivities, it reads 8ğ‘bits in the sketched column to compare the\npredicate code with the 1-byte sketch codes, and performsğ‘\n256random accesses where sketch code\n= predicate code. ByteSlice reads the byte-level columnar data with an efficient SIMD algorithm. It\naccesses similar amount of data for all selectivities.\nSecond, both BinDex and Cabin see wave-like curves. As the selectivity increases, the predicate\nvalue moves across the intervals in the scan indices. The number of bits to refine depends on how\nfar the predicate value is from the closest interval boundary, and thus varies periodically as the\npredicate value moves across multiple interval boundaries. This causes the wave shapes.\nThird, the space of BinDex and Cabin are bounded by twice the column data size (i.e., 32ğ‘) as\ndiscussed in Section 5.1. Hence, the space limit is 64ğ‘. For BinDex, the position array takes 32ğ‘\nfor storingğ‘32-bit rowIDs. Therefore, BinDex uses the remaining space to store 32 ğ‘-bit filter\nvectors. There are 33 value intervals. In comparison, the optimal design of Cabin has ğ‘”= 6 interval\ngroups, each containing 2ğ‘¤âˆ’2= 30 intervals where ğ‘¤= 5. That is, Cabin supports 180 intervals in\ntotal, over 5x as many as that supported by BinDex. As a result, Cabin reduces the interval size and\nthe average number of bits to refine (i.e.,1\n4Ã—interval size) by over 5x, attaining significant better\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:18 Yiyuan Chen and Shimin Chen\n050100150200250\n0 1 2 3 4 5\n(a) Data width = 8 bits.Average Time (ms)\nNormalization of Index SizeZM CS BS BinDex Cabin\n050100150200250300\n0 0.5 1 1.5 2 2.5 3\n(b) Data width = 16 bits.Average Time (ms)\nNormalization of Index Size\n050100150200250300\n0 0.5 1 1.5 2\n(c) Data width = 32 bits.Average Time (ms)\nNormalization of Index Size0100200300400\n0 0.5 1 1.5\n(d) Data width = 64 bits.Average Time (ms)\nNormalization of Index Size\nFig. 6. Space-time analysis for scans.\nperformance than BinDex.\nOverall, Cabin achieves up to 11.7x, 8.38x, 5.86x, and 3.51x better performance than Zone Maps,\nColumn Sketches, ByteSlice, and BinDex for 1%â€“99% selectivities, respectively. (The improvement\nover Column Sketches and ByteSlice at 0% and 100% is over 20x because of the shortcut optimization.)\nWe compute the average scan time over all the measured selectivities. Compared to Zone Maps,\nColumn Sketches, ByteSlice, and BinDex, Cabin improves the average scan time by 4.48x, 3.27x,\n2.27x, and 1.70x, respectively.\nScan with Different Comparison Operators. Figure 5(b) shows the scan performance of different\nfilter operators. Note that â‰¤performs a single in-equality comparison, representing <,>, andâ‰¥\noperators. For BETWEEN, Cabin decomposes ğ‘1â‰¤ğ‘¥â‰¤ğ‘2intoğ‘¥â‰¥ğ‘1andğ‘¥â‰¤ğ‘2. Hence, BETWEEN\ntakes nearly twice as much time as â‰¤in Cabin. Compared with Zone Maps, Column Sketches,\nByteSlice, and BinDex, Cabin improves the average performance of scans with BETWEEN by 2.82x,\n2.81x, 2.42x, and 1.70x, respectively.\nFor=, Cabin and BinDex use the shortcut optimization that directly sets the matching bits in the\nresult bit vector4. As a result, Cabin and BinDex take a few ms to evaluate scans with =, which are\norders of magnitude faster than the other solutions.\nIndex Space-Time Analysis Varying Data Width. Figure 6 analyzes the time-space trade-off of\nthe scan solutions for queries with â‰¤operator while varying data width. The x-axis is the index\nsize normalized to that of the column data. The space bound is set as discussed in Section 5.1. The\ny-axis reports the scan time averaged across all the measured selectivities. In the figures, Zone\nMaps, Column Sketches, and ByteSlice are single points. Cabin and BinDex can exploit larger space\nto achieve better scan performance, showing two curves. Note that the ByteSlice implementation\ndoes not support 64-bit data and thus is not tested on 64-bit data.\nFrom the figures, we see that Cabin achieves the best performance (at 2xâ€“5x sizes for 8 bits, at\n2xâ€“3x sizes for 16 bits, at 1xâ€“2x sizes for 32 bits, at 0.25xâ€“1.5x column size for 64 bits). Compared\nto BinDex, Cabinâ€™s higher performance mainly comes from filter sketches, which support more\nintervals given the same space budget. Moreover, Cabin enjoys a much wider range of space\n4BinDex implements the shortcut optimization only for =. Cabin extends it to optimize all comparison operators, including\nBETWEEN, when the selectivity is low.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:19\n050100150200250300\n0 0.1 0.2 0.3 0.4\n(a) Varying selectivities.Average Time (ms)\nSelectivity (%)ZM\nCSBS\nBinDexCabin\nB+-Tree\n0100200300400500\n0 0.5 1 1.5 2 2.5\n(b) Space-time analysis.Average Time (ms)\nNormalization of Index Size\nFig. 7. Comparison with B+-Tree at low selectivities.\n 0 50 100 150 200\n0 0.5 1 1.5 2\n(a) Zipf Parameter = 2.Average Time (ms)\nNormalization of Index SizeZM CS BS BinDex Cabin\n 0 50 100 150 200\n0 0.5 1 1.5 2\n(b) NDV = 100.Average Time (ms)\nNormalization of Index Size\nFig. 8. Scan performance on data with duplicates.\nconfigurations than BinDex. BinDex is at least as large as its position array, which takes 4xâ€“0.5x as\nmuch space as the data column for 8-bit â€“ 64-bit values. In contrast, the selective position array\ncan effectively reduce Cabinâ€™s size with graceful performance degradation.\nComparison with B+-Tree When Selectivities are Low. We find that the B+-Tree performs\npoorly at medium to high selectivities. To show good B+-Tree performance, we run scans with\nBETWEEN and focus on low selectivities from 0% to 0.4%. Given a specific selectivity, we randomly\npick 1000 value pairs as the BETWEEN predicate values that satisfy the target selectivity, and\nreport the average time of the 1000 scans in Figure 7(a).\nFrom Figure 7(a), we see that the B+-Tree is the second best solution when the selectivity is\nlower than 0.2%. However, as the selectivity increases, the performance of the B+-Tree quickly\ndegrades because the B+-Tree leaf scan incurs random memory accesses and costly pointer chasing.\nAt 0.4% selectivity, the B+-Tree becomes the slowest solution. In comparison, Cabin achieves the\nbest performance by using the shortcut optimization for low selectivities4.\nFigure 7(b) shows the space-time scatter plot for low selectivities from 0% to 0.4%. We see that\nCabin achieves the best time-space trade-off among all solutions. Note that compared to the B+-\nTree, Cabin is both smaller and faster. When the index size is reduced, Cabin employs the selective\nposition array. If the BETWEEN range falls in intervals where position arrays are not stored, the\nshortcut optimization cannot be applied. Hence, the scan performance degrades gracefully, leading\nto the arc shape for smaller index sizes.\n5.3 Data with Different Characteristics\nScan Performance on Data with Duplicates. We study two representative scenarios where there\ncan be a lot of duplicates in the column data: 1) Skew data with Zipf distribution, which models the\npower-law distribution in real-world data sets; and 2) Data with a small number of distinct values,\nwhich models categorical attributes that are domain encoded.\nFigure 8(a) shows the space-time scatter plot for skew data with the Zipf parameter = 2. Figure 8(b)\nshows the space-time scatter plot when there are 100 distinct values. In both cases, the data column\ncontains popular values that span entire value intervals. Our technique of data-aware intervals\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:20 Yiyuan Chen and Shimin Chen\n050100150200250300\n0 0.5 1 1.5 2\n(a) skewed normal distribution.Average Time (ms)\nNormalization of Index SizeZM CS BinDex Cabin\n050100150200250300\n0 0.5 1 1.5 2\n(b) pareto distribution.Average Time (ms)\nNormalization of Index Size\nFig. 9. Scan performance on skewed floating point values.\n 0 0.2 0.4 0.6 0.8 1\n0 0.5 1 1.5 2\n(a) DBLP.Average Time (ms)\nNormalization of Index SizeZM CS BS BinDex Cabin\n00.40.81.21.6\n0 0.5 1 1.5 2\n(b) IMDb.Average Time (ms)\nNormalization of Index Size\nFig. 10. Scan performance on real-world datasets.\nboth reduces the space cost and improves the scan performance for supporting the popular values.\nAs a result, Cabin achieves the best time-space trade-off in both cases, as shown in Figure 8.\nScan Performance on Skewed Floating Point Data. Figure 9(a) and (b) show the time-space\ntrade-off of scan solutions for 32-bit floating point data that follow skewed normal distribution and\npareto distribution, respectively. (Please note that ByteSlice does not support floating point data.)\nIn both data sets, value ranges contain skewed amount of data but the number of duplicates is low.\nTherefore, equal-sized intervals, which contain equal number of records per interval, still work\nwell. Cabin sees similar benefits as in the case of 32-bit uniform integer data in Figure 6(c).\nScan Performance on Real-World Datasets. Figure 10 shows the scan performance on DBLPâ€™s\nn_citation column and IMDbâ€™s startYear column. Since both data sets contain a lot of duplicates,\nCabin constructs data-aware intervals to achieve good performance. From Figure 10, we see that\nCabin achieves the best scan time at all sizes for DBLP and at 0.5â€“2x column size for IMDb.\n5.4 Benefit of Proposed Techniques in Cabin\nWe study the benefit of the proposed techniques of Cabin. All experiments in this subsection use\n32-bit data and the â‰¤operator.\nFilter Sketches. Figure 11(a) shows the scan time while varying the sketch code width ğ‘¤from 2\nto 9, and limiting Cabinâ€™s size by 2 Ã—column size. The scan time is broken down into three parts of\ntheCabin Falgorithm: 1) prepare and search ( search ), 2) generate the draft bit vector ( draft ), and 3)\nrefine the bit vector ( refine ). Note that the search cost is tiny and hardly visible. As ğ‘¤increases, the\nnumber of intervals increases. Hence, the interval size and the number of bits to refine decrease\naccordingly, leading to the decreasing refine cost. On the other hand, a draft result bit vector is\nconstructed from ğ‘¤filter sketches with MLO computation. As ğ‘¤increases, the draft cost increases\nlinearly as guaranteed by theorem 3.1. Our DesignSelection algorithm computes the optimal design\nparameter. In this case, ğ‘¤=5obtains the best scan time, which is consistent with the output of the\nDesignSelection algorithm.\nScan Time Breakdown Varying ğ‘”andğ‘ ğ‘.Figure 12 depicts the scan performance of Cabin\nwithğ‘¤=5and varying ğ‘”andğ‘ ğ‘to satisfy the space limit. The line shows the average scan time,\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:21\n020406080\n2 3 4 5 6 7 8 90500100015002000\n(a) Filter sketches.Average Time (ms)\n#intervals\nSketch Code Width (bit)search\ndraftrefine\n#intervals\n050100150200\n0 0.5 1 1.5 2\n(b) Selective position array.Average Time (ms)\nNormalization of Index SizeCabin F Cabin FS\nFig. 11. Benefit of proposed techniques in Cabin.\n04080120160\n(5,1,100%) (5,2,100%) (5,3,100%) (5,4,100%) (5,5,100%) (5,6,100%) (5,7,90.7%) (5,8,75%) (5,9,59.4%) (5,10,43,8%) (5,11,28.1%) (5,12,12.5%)Average Time (ms)\nDesign Parameters (w,g,sp)Cabin F(search)\nCabin FS(search)Cabin F(refine)\nCabin FS(refine)Cabin F(draft)\nCabin FS(draft)scan time\nFig. 12. Scan time breakdown varying ğ‘”andğ‘ ğ‘(ğ‘¤=5).\n010203040506070\n2 3 4 5 6 7 8 9\n(a) Computation time.Average Time (ms)\nCode Widthdraft (MLO)\ndraft (VBP)\nmemory r/w\n020406080100120140\n2 3 4 5 6 7 8 9\n(b) Instruction count.Average Instr Num\nCode WidthMLO\nVBP\nFig. 13. Benefit of MLO in draft bit vector generation.\nwhile the bars show the time breakdown into three components, i.e., search, draft, and refine, as in\nFigure 11(a). When ğ‘ ğ‘<100% , a query may hit an interval without the stored position array. In\nsuch cases, Cabin FSis executed instead of Cabin F. From the figure, we see that (1) the search time\nis tiny; (2) refine is more costly in Cabin FSsince Cabin FShas to visit the base data if filter sketches\ncannot tell the predicate outcome; and (3) (5,6,100%), which is chosen by Algorithm 3, achieves the\nbest performance.\nMLO. We compare MLO vs. VBP to understand the benefit of MLO in draft bit vector generation.\nFigure 13(a) and (b) compare the execution time and instruction count of MLO and VBP varying the\ncode width. We see that compared to VBP, MLO significantly reduces the number of instructions\nfor computing the draft bit vectors. While memory accesses account for a large portion of the\nexecution time, the instruction reduction by MLO attains up to 19.6% improvement (at ğ‘¤=2) in\nexecution time.\nSelective Position Array. Figure 11(b) compares Cabin FandCabin FSto understand the benefit of\nthe selective position array. The red dotted line indicates the size of the full position array that\nstoresğ‘32-bit rowIDs. Since it stores the full position array, Cabin Fâ€™s size is always larger than 1\nÃ—column size. In comparison, by setting ğ‘ ğ‘to be less than 1, the technique of selective position\narray stores the position array only for ğ‘ ğ‘fraction of the intervals. In this way, Cabin FSsupports\nspace budges lower than 1 Ã—column size. The selective position array substantially extends the\nrange of index size that can be supported by Cabin.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:22 Yiyuan Chen and Shimin Chen\n0204060\n1 2\n(a) Data with high skewness.Average Time (ms)\nZipf ParameterCabin FS Cabin FSD\n0204060\n10 102103104105106\n(b) Data with a low NDV .Average Time (ms)\nNumber of Distinct ValuesCabin FS Cabin FSD\nFig. 14. Benefit of data-aware intervals.\n050100150200250\nsorthashsample sorthashsample sorthashsample637 641 636\n(a) Uniform data varying normalized index size.Build Time (s)PV OD IT PA FS\n    size=0.25\nsp=0%  size=0.75\nsp=47%size=2\n     sp=100%0306090120150\nsort hash sample sort hash sample\n(b) Data with duplicates varying NDV .Build Time (s)\nNDV=10000 NDV=100\nFig. 15. Cabin build time breakdown.\nTable 3. Build time of scan solutions (in seconds).\nSolutionVary data width ( 109values) Vary data size (32-bit)\n8-bit 16-bit 32-bit 64-bit 106107108109\nZone Maps 0.074 0.12 0.22 0.48 0.00023 0.0023 0.022 0.22\nByteSlice 1.65 1.87 2.17 / 0.0022 0.022 0.22 2.17\nB+-tree 42.3 52.3 85.9 / 0.059 0.68 7.67 85.9\nColumn Sketches 30.2 80.4 108 111 0.082 0.91 9.86 108\nBinDex 48.2 61.2 88.9 101 0.056 0.67 7.80 88.9\nCabin 52.7 81.9 117 132 0.089 0.99 10.8 117\nData-aware Intervals. We compare Cabin FSandCabin FSDto understand the benefit of data-aware\nintervals. Similar to Section 5.3, we consider two cases: 1) skew data with Zipf distribution, and 2)\ndata with a small number of distinct values. Cabin FSDemploys data-aware intervals to optimize for\npopular values.\nFor case 1), Figure 14(a) shows the scan time while varying the Zipf parameter. We see that as\nthe data is more skewed, Cabin FSDachieves more significant improvement over Cabin FS. For case\n2), Figure 14(b) reports the scan performance while varying the number of distinct values. We see\nthat Cabin FSDworks better than Cabin FSwhen there are fewer than 1000 distinct values. In such\ncases, entire intervals contain the same values, and the optimization of data-aware intervals is\napplicable. Cabin FSDimproves the scan time and reduces the space cost at the same time.\n5.5 Build Time\nPopular Value Discovery and Build Time Breakdown. Figure 15 evaluates sort-based ( sort),\nhash-based ( hash), and sample-based ( sample ) methods for discovering popular values during Cabin\nindex building. The build time is decomposed into five components: popular value discovery ( PV),\noptimal design selection (excluding PV) ( OD), and structure building for interval table ( IT), position\narray ( PA), and filter sketches ( FS). We see that the optimal design selection using Algorithm 3 is\nfast (i.e. 3â€“41 microseconds) in all cases. Compared to sort and hash, sample reduces the cost of PV\nby using a small sample. It also avoids the sorting cost in PA for intervals whose position array is\nnot stored (i.e., ğ‘ ğ‘< 100%). Hash works well for data with duplicates, but incurs prohibitively high\nhashing cost for uniform data because the hash table is much larger than the CPU cache. Overall,\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:23\n02468\nQ1 Q6 Q12\n(a) TPC-H.SpeedupMonetDB MonetDB+BinDex MonetDB+Cabin\n1 1 1 1.087.04\n1.17 1.107.48\n1.20\n01020304050\nQ1.1 Q1.2 Q1.3\n(b) SSB.Speedup\n1 1 18.9222.437.6\n9.2323.149.9\nFig. 16. Comparing MonetDB with scan index enhanced MonetDB using TPC-H and SSB workloads.\nTable 4. Total and scan time in ms of TPC-H and SSB queries.\nQueries MonetDB MonetDB+BinDex MonetDB+Cabin\nTPC-H Q1 12670 / 330.9 11699 / 10.3 11548 / 7.7\nTPC-H Q6 521.7 / 468.9 74.1 / 22.3 69.8 / 19.1\nTPC-H Q12 610.2 / 176.8 523.1 / 18.5 508.8 / 11.4\nSSB Q1.1 10286 / 9699 1154 / 30.1 1115 / 17.3\nSSB Q1.2 9214 / 9016 410.8 / 33.7 399.1 / 19.1\nSSB Q1.3 9359 / 9205 248.7 / 40.5 187.5 / 20.5\nSSB Q2.1 8560 / 4.84 8629 / 0.42 8613 / 0.12\nSSB Q2.2 8444 / 1.43 8346 / 0.082 8363 / 0.043\nSSB Q2.3 8333 / 1.89 8246 / 0.22 8309 / 0.11\nSSB Q3.1 30815 / 7.63 28204/ 0.65 28328 / 0.18\nSSB Q3.2 28955 / 5.52 26670 / 0.62 26540 / 0.19\nSSB Q3.3 1517 / 7.13 1424 / 1.52 1467 / 1.35\nSSB Q3.4 169.3 / 6.83 176.5 / 1.57 173.2 / 1.30\nSSB Q4.1 21710 / 12.6 21596 / 1.74 21369 / 0.26\nSSB Q4.2 4353 / 12.8 4411 / 1.80 4401 / 0.35\nSSB Q4.3 2452 / 8.60 2468 / 1.22 2463 / 0.31\nsample achieves good performance in all cases. Hence, we choose sample in Cabin building.\nBuild Time Varying Data Width and Data Size. Table 3 compares the build time of scan solutions.\nWe vary the data width from 8-bit to 64-bit, and the data size ( ğ‘) from 106to109records. We see\nthat Cabin takes modestly longer time than B+-Tree, Column Sketches, and BinDex because of\nits relatively complex structure. Since scan indices can be used by a large number of queries after\nbuilding, it is beneficial to pay the build cost for better query performance in OLAP.\n5.6 TPC-H and SSB Workloads\nTPC-H. Figure 16(a) shows the query performance of TPC-H Q1, Q6, and Q12. Table 4 lists the\ntotal query time and the scan time of the TPC-H queries. We see that compared to MonetDB,\nMonetDB+Cabin achieves 1.10x, 7.48x, and 1.20x performance improvement for Q1, Q6, and Q12,\nrespectively. Q1 and Q12 see less significant improvement than Q6. This is because scan accounts\nfor only 2.6% of Q1â€™s query time and 29.0% of Q12â€™s query time, while scan takes 89.9% of Q6â€™s\nquery time. Focusing on the scan time in Table 4, we see that compared to MonetDB+BinDex,\nMonetDB+Cabin reduces the scan time significantly (by a factor of 1.17â€“1.62x), showing the benefits\nof filter sketches and data-aware intervals.\nSSB. Figure 16(b) shows the query performance of SSB Q1.1, Q1.2, and Q1.3, and Table 4 shows\nthe total query time and scan time for all SSB queries. Each SSB query performs at least one join\noperation. We see that in Q1.1â€“Q1.3, scan plays an important role in the query evaluation. Compared\nto MonetDB, MonetDB+Cabin achieves 9.23â€“49.9x performance improvement for Q1.1â€“Q1.3. In\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:24 Yiyuan Chen and Shimin Chen\ncontrast, in queries Q2.1â€“Q4.3, scan accounts for only a small fraction of the total query time. As a\nresult, the index enhanced solutions have similar performance as MonetDB. Overall, if we focus on\nthe scan time, we see that MonetDB+Cabin improves the scan performance in all SSB queries by a\nfactor of 5.2â€“560x compared with MonetDB and 1.1â€“6.7x compared with MonetDB+BinDex.\n6 DISCUSSION\nPAX Layout. In this work, Cabin is constructed on a whole data column. In addition to the column\nlayout, PAX is another popular data layout in OLAP systems [ 4]. In PAX, a table is divided into\nrow groups, and each row group employs the column layout. To support PAX, we can simply build\na Cabin per row group, and use the per-row-group Cabins to accelerate scans.\nData Updates. For deletes, we can record the deleted rows in a delete bit vector. Then, a scan\ncomputes the bit-wise AND of the scan result bit vector and the delete bit vector. For inserts, we\ncan employ the main+delta approach. We build Cabin indices for the main data, and append newly\ninserted values to the delta data. When merging the main and delta into the new main data, we\nre-construct Cabin indices. In this way, a scan consists of the Cabin-enhanced scan on the main\ndata, and a plain scan on the delta data. An update can be supported as a delete followed by an\ninsert.\nSupport for Strings. Scan indices, including Cabin, mostly focus on numeric values and filter\npredicates (e.g., <,>,â‰¤,â‰¥,=,â‰ , or BETWEEN) that specify value ranges. In many cases, strings\ncan be encoded as numeric values and effectively supported for such predicates. However, string\nmatching operations (e.g., LIKE) cannot be easily supported by scan indices. There is no clear\nsort order for string matching operations, but the sort order is the basis for the design of many\nscan indices. It would be interesting to study how to combine inverted indices and scan indices to\nimprove OLAP queries with string matching operations.\nOptimization Based on Query History. In this work, our Cabin design does not rely on any\nquery history. Here, we consider potential optimizations if the query history is available. (1)\nIndex selection: We can identify frequent queries and analyze the importance of scans to query\nperformance. Then, we can choose a subset of columns to build Cabin indices in order to maximize\nthe performance benefit given memory space budget. (2) Query-aware selective position array:\nInstead of randomly selecting intervals, we can choose which intervals to remove position arrays\nbased on the distribution of query predicate values.\n7 CONCLUSION\nIn this paper, we propose and evaluate a novel scan index, Cabin. Extensive experiments show that\nCabin achieves better time-space tradeoff than state-of-the-art scan solutions. Cabin is a promising\nscan index for main-memory analytical databases.\nACKNOWLEDGMENTS\nThis work is partially supported by Natural Science Foundation of China (62172390). We thank the\nanonymous meta-reviewer and reviewers for their insightful comments and suggestions. Shimin\nChen is the corresponding author.\nREFERENCES\n[1] 2023. DBLP Citation Network Dataset. https://www.aminer.cn/citation.\n[2] 2023. IMDb Datasets. https://developer.imdb.com/non-commercial-datasets/.\n[3] 2023. stx::B+tree(tlx::B+tree). https://github.com/tlx.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\nCabin: a Compressed Adaptive Binned Scan Index 57:25\n[4]Anastassia Ailamaki, David J. DeWitt, Mark D. Hill, and Marios Skounakis. 2001. Weaving Relations for Cache\nPerformance. In VLDB 2001, Proceedings of 27th International Conference on Very Large Data Bases, September 11-14,\n2001, Roma, Italy . Morgan Kaufmann, 169â€“180.\n[5]Albert-LÃ¡szlÃ³ BarabÃ¡si and RÃ©ka Albert. 1999. Emergence of scaling in random networks. science 286, 5439 (1999),\n509â€“512.\n[6]Ronald Barber, Peter Bendel, Marco Czech, Oliver Draese, Frederick Ho, Namik Hrle, Stratos Idreos, Min-Soo Kim,\nOliver Koeth, Jae-Gil Lee, Tianchao Tim Li, Guy M. Lohman, Konstantinos Morfonios, RenÃ© MÃ¼ller, Keshava Murthy,\nIppokratis Pandis, Lin Qiao, Vijayshankar Raman, Richard Sidle, Knut Stolze, and Sandor Szabo. 2012. Business\nAnalytics in (a) Blink. IEEE Data Eng. Bull. 35, 1 (2012), 9â€“14.\n[7]Carsten Binnig, Stefan Hildenbrand, and Franz FÃ¤rber. 2009. Dictionary-based order-preserving string compression for\nmain memory column stores. In Proceedings of the ACM SIGMOD International Conference on Management of Data,\nSIGMOD 2009, Providence, Rhode Island, USA, June 29 - July 2, 2009 . ACM, 283â€“296.\n[8]Peter A. Boncz, Martin L. Kersten, and Stefan Manegold. 2008. Breaking the memory wall in MonetDB. Commun.\nACM 51, 12 (2008), 77â€“85.\n[9]David Broneske, Sebastian BreÃŸ, and Gunter Saake. 2014. Database Scan Variants on Modern CPUs: A Performance\nStudy. In Proceedings of the 2nd International Workshop on In Memory Data Management and Analytics, IMDM 2014,\nHangzhou, China, September 1, 2014 . 1â€“15.\n[10] Chee Yong Chan and Yannis E. Ioannidis. 1998. Bitmap Index Design and Evaluation. In SIGMOD 1998, Proceedings\nACM SIGMOD International Conference on Management of Data, June 2-4, 1998, Seattle, Washington, USA . ACM Press,\n355â€“366.\n[11] Douglas Comer. 1979. The Ubiquitous B-Tree. ACM Comput. Surv. 11, 2 (1979), 121â€“137.\n[12] Franz FÃ¤rber, Sang Kyun Cha, JÃ¼rgen Primsch, Christof BornhÃ¶vd, Stefan Sigg, and Wolfgang Lehner. 2011. SAP HANA\ndatabase: data management for modern business applications. SIGMOD Rec. 40, 4 (2011), 45â€“51.\n[13] Ziqiang Feng, Eric Lo, Ben Kao, and Wenjian Xu. 2015. ByteSlice: Pushing the Envelop of Main Memory Data Processing\nwith a New Storage Layout. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,\nMelbourne, Victoria, Australia, May 31 - June 4, 2015 . ACM, 31â€“46.\n[14] Craig Freedman, Erik Ismert, and Per-Ã…ke Larson. 2014. Compilation in the Microsoft SQL Server Hekaton Engine.\nIEEE Data Eng. Bull. 37, 1 (2014), 22â€“30.\n[15] John L. Hennessy and David A. Patterson. 2012. Computer Architecture - A Quantitative Approach, 5th Edition . Morgan\nKaufmann.\n[16] Brian Hentschel, Michael S. Kester, and Stratos Idreos. 2018. Column Sketches: A Scan Accelerator for Rapid and\nRobust Predicate Evaluation. In Proceedings of the 2018 International Conference on Management of Data, SIGMOD\nConference 2018, Houston, TX, USA, June 10-15, 2018 . ACM, 857â€“872.\n[17] Stratos Idreos, Martin L. Kersten, and Stefan Manegold. 2007. Database Cracking. In Third Biennial Conference on\nInnovative Data Systems Research, CIDR 2007, Asilomar, CA, USA, January 7-10, 2007, Online Proceedings . www.cidrdb.org,\n68â€“78.\n[18] Ryan Johnson, Vijayshankar Raman, Richard Sidle, and Garret Swart. 2008. Row-wise parallel predicate evaluation.\nProc. VLDB Endow. 1, 1 (2008), 622â€“634.\n[19] AndrÃ© Kohn, Viktor Leis, and Thomas Neumann. 2018. Adaptive Execution of Compiled Queries. In 34th IEEE\nInternational Conference on Data Engineering, ICDE 2018, Paris, France, April 16-19, 2018 . IEEE Computer Society,\n197â€“208.\n[20] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The Case for Learned Index Structures.\nInProceedings of the 2018 International Conference on Management of Data, SIGMOD Conference 2018, Houston, TX, USA,\nJune 10-15, 2018 . ACM, 489â€“504.\n[21] Konstantinos Krikellas, Stratis Viglas, and Marcelo Cintra. 2010. Generating code for holistic query evaluation. In\nProceedings of the 26th International Conference on Data Engineering, ICDE 2010, March 1-6, 2010, Long Beach, California,\nUSA. IEEE Computer Society, 613â€“624.\n[22] Tirthankar Lahiri, Shasank Chavan, Maria Colgan, Dinesh Das, Amit Ganesh, Mike Gleeson, Sanket Hase, Allison\nHolloway, Jesse Kamp, Teck-Hua Lee, Juan Loaiza, Neil MacNaughton, Vineet Marwah, Niloy Mukherjee, Atrayee\nMullick, Sujatha Muthulingam, Vivekanandhan Raja, Marty Roth, Ekrem Soylemez, and Mohamed ZaÃ¯t. 2015. Oracle\nDatabase In-Memory: A dual format in-memory database. In 31st IEEE International Conference on Data Engineering,\nICDE 2015, Seoul, South Korea, April 13-17, 2015 . IEEE Computer Society, 1253â€“1258.\n[23] Harald Lang, Tobias MÃ¼hlbauer, Florian Funke, Peter A. Boncz, Thomas Neumann, and Alfons Kemper. 2016. Data\nBlocks: Hybrid OLTP and OLAP on Compressed Storage using both Vectorization and Compilation. In Proceedings of\nthe 2016 International Conference on Management of Data, SIGMOD Conference 2016, San Francisco, CA, USA, June 26 -\nJuly 01, 2016 . ACM, 311â€“326.\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.\n\n57:26 Yiyuan Chen and Shimin Chen\n[24] Viktor Leis, Alfons Kemper, and Thomas Neumann. 2013. The adaptive radix tree: ARTful indexing for main-memory\ndatabases. In 29th IEEE International Conference on Data Engineering, ICDE 2013, Brisbane, Australia, April 8-12, 2013 .\nIEEE Computer Society, 38â€“49.\n[25] Linwei Li, Kai Zhang, Jiading Guo, Wen He, Zhenying He, Yinan Jing, Weili Han, and X. Sean Wang. 2020. BinDex: A\nTwo-Layered Index for Fast and Robust Scans. In Proceedings of the 2020 International Conference on Management of\nData, SIGMOD Conference 2020, online conference [Portland, OR, USA], June 14-19, 2020 . ACM, 909â€“923.\n[26] Yinan Li and Jignesh M. Patel. 2013. BitWeaving: fast scans for main memory data processing. In Proceedings of the\nACM SIGMOD International Conference on Management of Data, SIGMOD 2013, New York, NY, USA, June 22-27, 2013 .\nACM, 289â€“300.\n[27] Guido Moerkotte. 1998. Small Materialized Aggregates: A Light Weight Index Structure for Data Warehousing. In\nVLDBâ€™98, Proceedings of 24rd International Conference on Very Large Data Bases, August 24-27, 1998, New York City, New\nYork, USA . Morgan Kaufmann, 476â€“487.\n[28] Thomas Neumann. 2011. Efficiently Compiling Efficient Query Plans for Modern Hardware. Proc. VLDB Endow. 4, 9\n(2011), 539â€“550.\n[29] Patrick E. Oâ€™Neil and Dallan Quass. 1997. Improved Query Performance with Variant Indexes. In SIGMOD 1997,\nProceedings ACM SIGMOD International Conference on Management of Data, May 13-15, 1997, Tucson, Arizona, USA .\nACM Press, 38â€“49. https://doi.org/10.1145/253260.253268\n[30] Holger Pirk, Stefan Manegold, and Martin L. Kersten. 2014. Waste not... Efficient co-processing of relational data. In\nIEEE 30th International Conference on Data Engineering, Chicago, ICDE 2014, IL, USA, March 31 - April 4, 2014 . IEEE\nComputer Society, 508â€“519.\n[31] Orestis Polychroniou, Arun Raghavan, and Kenneth A. Ross. 2015. Rethinking SIMD Vectorization for In-Memory\nDatabases. In Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data, Melbourne,\nVictoria, Australia, May 31 - June 4, 2015 . ACM, 1493â€“1508.\n[32] Mark Raasveldt and Hannes MÃ¼hleisen. 2019. DuckDB: an Embeddable Analytical Database. In Proceedings of the 2019\nInternational Conference on Management of Data, SIGMOD Conference 2019, Amsterdam, The Netherlands, June 30 - July\n5, 2019 . ACM, 1981â€“1984.\n[33] Scott Rixner, William J. Dally, Ujval J. Kapasi, Peter R. Mattson, and John D. Owens. 2000. Memory access scheduling.\nIn27th International Symposium on Computer Architecture (ISCA 2000), June 10-14, 2000, Vancouver, BC, Canada . IEEE\nComputer Society, 128â€“138.\n[34] Lefteris Sidirourgos and Martin L. Kersten. 2013. Column imprints: a secondary index structure. In Proceedings of the\nACM SIGMOD International Conference on Management of Data, SIGMOD 2013, New York, NY, USA, June 22-27, 2013 .\nACM, 893â€“904.\n[35] Liwen Sun, Michael J. Franklin, Sanjay Krishnan, and Reynold S. Xin. 2014. Fine-grained partitioning for aggressive\ndata skipping. In International Conference on Management of Data, SIGMOD 2014, Snowbird, UT, USA, June 22-27, 2014 .\nACM, 1115â€“1126.\n[36] Skye Wanderman-Milne and Nong Li. 2014. Runtime Code Generation in Cloudera Impala. IEEE Data Eng. Bull. 37, 1\n(2014), 31â€“37.\n[37] Thomas Willhalm, Ismail Oukid, Ingo MÃ¼ller, and Franz Faerber. 2013. Vectorizing Database Column Scans with\nComplex Predicates. In International Workshop on Accelerating Data Management Systems Using Modern Processor and\nStorage Architectures - ADMS 2013, Riva del Garda, Trento, Italy, August 26, 2013 . 1â€“12.\n[38] Marcin Zukowski, Peter A. Boncz, Niels Nes, and SÃ¡ndor HÃ©man. 2005. MonetDB/X100 - A DBMS In The CPU Cache.\nIEEE Data Eng. Bull. 28, 2 (2005), 17â€“22.\nReceived July 2023; revised October 2023; accepted November 2023\nProc. ACM Manag. Data, Vol. 2, No. 1 (SIGMOD), Article 57. Publication date: February 2024.",
  "textLength": 90780
}