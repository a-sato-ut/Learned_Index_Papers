{
  "paperId": "a55e7bfd648666484385352a587514499801a332",
  "title": "Dynamic Indexing Through Learned Indices with Worst-case Guarantees",
  "pdfPath": "a55e7bfd648666484385352a587514499801a332.pdf",
  "text": "arXiv:2503.05007v2  [cs.CG]  2 Jul 2025A Dynamic Piecewise-linear Geometric Index with\nWorst-case Guarantees\nEmil Toftegaard Gæde /envel⌢pe\nTechnical University of Denmark, Denmark\nIvor van der Hoog /envel⌢pe\nIT University of Copenhagen, Denmark\nEva Rotenberg /envel⌢pe\nIT University of Copenhagen, Denmark\nTord Stordalen\nTechnical University of Denmark\nAbstract\nIndexing data is a fundamental problem in computer science. The input is a set Sofndistinct\nintegers from a universe U. Indexing queries take a value q∈Uand return the membership ,\npredecessor orrankofqinS. Arangequery takes two values q,r∈Uand returns the set S∩[q,r].\nRecently, variouspapersstudyaspecialcasewherethetheinputdatabehavesinanapproximately\npiece-wise linear way. Given the sorted (rank,value) pairs, and given some constant ε, one wants\nto maintain a small number of axis-disjoint line-segments such that, for each rank, the value is\nwithin±εof the corresponding line-segment. Ferragina and Vinciguerra (VLDB 2020) observe that\nthis geometric problem is useful for solving indexing problems, particularly when the number of\nline-segments is small compared to the size of the dataset.\nWe study the dynamic version of this geometric problem. In the dynamic setting, inserting or\ndeleting just one data point may cause up to three line-segments to be merged, or one line-segment\nto be split at most three-way. To determine and compute this, we use techniques from dynamic\nmaintenance of convex hulls, and provide new algorithms with worst-case guarantees, including an\nO(logn)algorithm to compute a separating line between two non-intersecting convex hulls – an\noperation previously missing from the literature.\nWe then use our fully-dynamic geometry-based subroutine in an indexing data structure, com-\nbining it with a natural hashing technique. The resulting indexing data structure has theoretically\nefficient worst-case guarantees in expectation. We compare its practical performance to the solution\nof Ferragina and Vinciguerra, which was shown to perform better in certain structured settings [Sun,\nZhou, Li VLDB 2023]. Our empirical analysis shows that our solution supports more efficient range\nqueries in the special case where the update sequence contains many deletions.\n2012 ACM Subject Classification Theory of computation →Computational Geometry\nKeywords and phrases Algorithms Engineering, Data Structures, Indexing, Convex Hulls\nRelated Version Full version :https://arxiv.org/abs/2503.05007\nSupplementaryMaterial Software (Source Code) :https://github.com/Sgelet/DynamicLearnedIndex [20]\nSoftware (Test Bed) :https://github.com/Sgelet/LearnedIndexBench [21]\nFunding This work was supported by the Carlsberg Foundation Fellowship CF21-0302 “Graph\nAlgorithms with Geometric Applications”, the VILLUM Foundation grant (VIL37507) “Efficient\nRecomputations for Changeful Problems”, and the European Union’s Horizon 2020 research and\ninnovation programme under the Marie Skłodowska-Curie grant agreement No 899987.\n\n2 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\n1 Introduction\nWe investigate the use of learned indices for the design of dynamic indexing data structures .\nIndexing data structures. An indexing data structure maintains a set Sofndistinct\nintegers from a universe U. LetRANK :S→[n]be the function mapping each s∈Sto its\nindex in the sorted order of S. The objective is to support the following indexing queries:\nmember(q)returns trueifq∈S.\npredecessor( q)returns max{t∈S|t<q}. (We allow q /∈S.)\nrank(q)returns RANK (predecessor (q)) + 1. (We allow q /∈S.)\nAdditionally, we consider range queries , wherekdenotes the output size:\nrange(q,t)returnsS∩[q,t]. (We allow q,t /∈S.)\nStatic indexing data structures fall into three broad categories: Tree-based solutions store\nSin a sorted array A, requiring no additional space but incurring logarithmic query costs.\nTree traversals enable predecessor ,rank, and memberqueries inO(logn)time and range\nqueries inO(logn+k)time [2,4,35,40].Map-based solutions storeSin sorted order\nand maintain a hash map H:S→[n]mapping each element to its rank [ 5,24,34]. This\nenables constant-time support for member,predecessor , and rankqueries if queries are\nrestricted to elements of S, andO(k)time for rangequeries when both endpoints lie in\nS. The additional space is O(n). A third category use what are called learned indices , a\nrecently introduced term [ 25,18,17,23,9]. Given an integer parameter ε, a learned index is\na functionhε:U→ [0,n]such that\nhε(q)∈[rank (q)−ε,rank (q) +ε].\nThe function hεis learned from Sand used to guide search in a sorted array Astoring\nS. Ferragina and Vinciguerra [ 17] interprethεgeometrically: each s∈Smaps to a point\n(RANK (s),s)in the plane, and hεis learned as a piecewise-linear approximation to FS.\nA notable instance of learned indices is the PGM index [17], wherehεis ay-monotone\npiecewise-linear function made of segments, with the property that each point in FSlies\nwithin anε-wide horizontal strip around some segment. Let |hε|denote the number of\nsegments. The data structure supports indexing queries in O(ε+log|hε|)time and range\nqueries inO(ε+k+log|hε|)time. They also show how to construct a PGM index in linear\ntime, such that there exists no PGM index h′\nεwith|hε|>3\n2|h′\nε|. Ferragina and Vinciguerra\nargue that learned indices are the ‘best of both worlds’ since:\nthe supported queries are as general as those supported by tree-based solutions,\nthe solution uses only O(|hε|)additional space, and\nO(ε+ log|hε|)is, for an appropriate choice of ε, efficient in practice.\nTheir performance has been empirically benchmarked in several studies [16, 25, 41, 40].\nDynamic indexing data structures. Due to their fundamental role, dynamic indexing\nstructures have received extensive theoretical and practical attention. When Sis dynamic,\nmaintaining a sorted array becomes inefficient. Tree-based structures can be updated in\nO(logn)time with tree rotations. Map-based approaches allow constant-time memberupdates\nbut are typically not extended to support other indexing queries. Learned indices offer a\npromising direction by exploiting structural properties of S, akin to parametrised algorithms.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 3\na)\nb)\nc)\nq\n(hε(q), q)\nq′\n(hε(q′), q′)\n2ε\nFigure 1 (a) a set of nvaluesS. (b)Scorresponds to an xy-monotone point set FS. (c) The\nPGM index computes a y-monotone set of segments that starts and ends with a vertical halfline.\nHowever, just as parametrised algorithms, data structures based on learned indices are not\nalways efficient: if Slacks exploitable structure or access patterns are skewed, traditional\nindexingdatastructuresarepreferred[ 36,29]. Experimentalstudieshaveexaminedproperties\nof learned indices [ 15,14,29,36], in an effort to classify when they are appropriate to use.\nAs a brief summary, learned indices pay a price in updates [ 29], and traditional indices are\npreferred if Sor the access pattern is complex or skewed, or if concurrency is possible [ 36].\nIf there is sufficient structure, both space usage and access times can benefit from learned\nindices [14, 15], subject to the strategy employed by the learned index.\nDynamic learned indices through the logarithmic method. The logarithmic method of\nOvermars [ 32] provides an amortised way to maintain learned indices. Sis partitioned into\n⌈logn⌉bucketsBi, each of size 2i. Each bucket is either full or empty, and stores its contents\nin an array Aiin sorted order and maintains a learned index hi\nεoverAi.\nLet the learned index hεhave a construction time of T(n). This data structure can be\nmaintained insertion-only in amortised O(T(n)logn)time. An insertion inserts a new value\nintoB0. Letjbe the maximum integer such that all Bifori∈[0,j−1]are full. This\napproach empties these buckets, fills Bjin sorted order, and constructs (Aj,hj\nε)inO(T(2j))\ntime. Whenever we delete some s∈S, this approach instead inserts a tombstones∗, which\nis a special copy of s. If an insertion fills a new bucket Bj, it first iterates over all elements.\nIfBjcontains both sands∗, it removes both elements. It then constructs (Aj,hj\nε)twice.\nOnce on all ‘normal’ values, and once on all tombstones in Bj. This way, deletions take the\nsame time as insertions do. In this paper, we consider the following open question:\n“Can a learned index be dynamically be maintained with worst-case guarantees?”\nIntermezzo: computing a line cover. The interpretation of learned indices by Ferragina\nand Vinciguerra [ 17] translates to a geometric problem where the goal is to (approximately)\ncover a monotone set of two-dimensional points by a set of line segments. Using the\nlogarithmic method, and the static algorithm of O’Rourke [ 30] to approximately points,\nthey dynamically maintain an ε-cover: a set of lines that are guaranteed to be within an\nεhorizontal distance from each point. We consider the problem of maintaining dynamic\nε-covers to be an interesting geometric problem in its own right.\n\n4 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nFrom learned indices to indexing data structures. Under the logarithmic method, indexing\nqueries decompose naturally across the buckets:\nFormember (q),q∈Sif and only if there exists an i∈[⌈logn⌉]withq∈Bi.\nForpredecessor (q), the output is the maximum predecessor across Bifori∈[⌈logn⌉].\nForrank (q), the rank is the sum of all ranks of qinBifori∈[⌈logn⌉].\nForrange (q,t), the reported range is the union of all ranges in Bifori∈[⌈logn⌉].\nThis way, indexing queries require only an additional factor O(logn)time. Indexing queries\ncan be answered by combining queries to both the normal and tombstone structures. E.g.,\nrank (q)is the rank of qin the ‘normal’ data structure minus the rank of qin the tombstone\nstructure. This approach has two downsides:\nFirst, approach has an amortised update time.\nSecond, this approach does not support output-sensitive range queries – as there may be\nO(n)valuessthat (together with their tombstones s∗) lie in between a query pair (q,t).\nThis leads to the following open question:\n“Can a dynamic learned index be converted into an output-sensitive dynamic indexing\ndata structure with worst-case guarantees?”\nContribution and organization. We propose maintaining a dynamic ε-cover (and thereby a\ndynamic learned index) via dynamic convex hull techniques. Section 3 shows that deciding\nwhetherSadmits anε-cover of complexity 1 is equivalent to convex hull intersection testing\n(Figure 2). Section 4 shows a robust algorithm to compute the intersection between two\nconvex hulls in O(logn)time. We adapt our algorithm to output a separating line (which is\na learned index of complexity 1) in the negative case. Section 5 combines these with dynamic\nconvex hull data structures to yield a dynamic learned index worst-case O(log2n)update\ntime. We empirically compare our learned index to the PGM index from [17].\nSection 6 introduces a novel hashing-based approach to convert learned indices into\ndynamic indexing data structures, using O(ε−1)additional expected overhead. We compare\nour dynamic indexing structure to the amortised PGM index of [ 17] in terms of update time\nand index complexity. We do not benchmark against traditional indexing data structures –\nsince the relation between learned and traditional indices is previously studied [ 36]. Instead,\nour goal is to push the theoretical limits and worst-case guarantees of learned indices.\na)\nb)\nc)\nd)\nFigure 2 For any set FS, we construct two convex hulls. We prove that there exists a segment ℓ\nwithinL∞-distanceεof all points in FSif and only if these hulls do not intersect. We adapt the\nconvex hull intersection testing algorithm to find ℓwhenever these hulls are disjoint.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 5\n2 Preliminaries\nThe input is a dynamic set Sofndistinct positive integers from some universe U. Fora,b∈Z\nwitha≤b, we define S[a,b]as the setS∩[a,b]. We denote by FSthe two-dimensional\npoint set obtained by mapping each s∈Sto(RANK (S),s). Throughout this paper, we\ndistinguish between positions and strict positions. E.g., lying above or strictly above a line.\n▶Definition 1 ([17]).Letεbe a positive integer. A PGM index hεofSis defined as a\ny-monotone set of segments that together cover the y-axis. We regard hεas a map from\ny-coordinates to x-coordinates and require that for all q∈U,hε(q)∈[rank (q)−ε,rank (q)+ε].\nFerragina and Vinciguerra [ 17, Lemma 1] wrongfully claim an O(n)-time algorithm to\ncompute a minimum complexity PGM index hε. They invoke a streaming algorithm by\nO’Rourke [ 30] for fitting straight lines through data ranges. We show that this algorithm\noutputs a PGM index hεsuch that there exists no PGM index h′\nεwith|hε|>3\n2h′\nε(see\nAppendix C). Their algorithm restricts Sto contain no duplicates. We assume the same\nsetting and compute something slightly different as we define an ε-cover instead:\n▶Definition 2. Letεbe a positive integer. We define an ε-coverfofSas a set of vertically\nseparated segments with slope at least 1where all (r,s)∈FSare withinL∞-distanceεoff.\nAnε-cover has a functionality and complexity similar to a learned index:\n▶Observation3. Letfbe anε-cover andQbe a horizontal line with height q∈[minS,maxS].\nLet(s,t)be the segment in fclosest toq. Then (line(s,t)∩Q).x∈[rank (q)−2ε,rank (q)+2ε].\n▶Observation 4. For fixedε, letkdenote the minimum complexity of any PGM index of S.\nIffis anε-cover ofSof minimum complexity, then fcontains at most k−2edges.\n▶Definition 5. For any fixed ε-coverfofS, we define Λ(f)as the set of pairwise interior-\ndisjoint one-dimensional intervals that correspond to the y-coordinates of segments in f.\nDynamic convex hulls. We dynamically maintain an ε-coverfofSof approximately\nminimum complexity. To this end, we use a result by Overmars and van Leeuwen [ 33] to\ndynamically maintain for all [a,b]∈Λ(f)the convex hull of FS[a,b]. For any point set F,\ndenote byCH(F)their convex hull. The data structure in [ 33] is a balanced binary tree over\nF, which at its root maintains a balanced binary tree over the edges CH(F)in their cyclical\nordering. It uses O(n)space and has worst-case O(log2n)update time.\nRank-based convex hulls. For any update in S, up tonvalues inFSmay change their\nx-coordinate. This complicates the maintenance of a dynamic data structure over F. Gæde,\nGørtz, van Der Hoog, Krogh, and Rotenberg [ 19] observe that all algorithmic logic in [ 33]\nrequires only the relativex-coordinates between points. They adapt [ 33] to give an efficient\nand robust implementation of what they call a rank-based convex hull data structure T(S)\nwithO(log2n)update time. For ease of exposition, we overly simplify their functionality:\nFor each [a,b]∈Λ(f), we storeS[a,b]inT(S[a,b]).T(S[a,b])maintains a balanced\nbinary tree γ(S[a,b])storing the edges of CH(FS[a,b])in their cyclical ordering. We use this\ndata structure as a black box, using the following functions that take at most O(log2n)time:\nT(S[a,b]).get_hull() returns the tree γ(S[a,b]).\nT(S[a,b]).split(v)returns, for v∈[a,b],T(S[a,v])andT(S[v,b]).\nT(S[a,b]).split(T([S[b,c]))returnsT(S[a,c]).\nT(S[a,b]).update(v)updates, for v∈[a,b], the setS(deleting or inserting v).\n\n6 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\n3 Testing whether a set can be ε-covered by a single segment\nWe consider the following subproblem: given a parameter ε, a setSofndistinct integers,\nand the edges of CH(FS)stored in a balanced binary tree, can we compute in O(logn)time\nwhether there exists an ε-coverfof complexity 1? Formally, we seek a line ℓof slope at least\n1 such that all points in FSlie withinL∞-distanceεofℓ. LetL(resp.U) denote the set\nobtained by shifting each p∈FSdownwards and rightwards (resp. upwards and leftwards)\nbyε, and adding the point (∞,−∞)(resp. (−∞,∞)).\n▶Lemma 6. Letℓbe a line of slope at least 1. Then all points in FSlie withinL∞-distance\nεofℓif and only if ℓlies below all points in Uand above all points in L.\nProof.Any line with positive slope lies above (∞,−∞)and below (−∞,∞). Consider a\npointp∈FSand the two corresponding points l∈Landu∈Uand denote by Can\naxis-aligned square of radius εcentred atp. Ifℓlies belowlthen all points on ℓleft ofllie\nbelowC. Ifℓlies aboveuthen all points on ℓright ofulie aboveC. Ifℓlies aboveland\nbelowuthen because ℓhas positive slope, it must intersect C. The statement follows. ◀\n▶Corollary 7. ℓis anε-cover ofSiff it has a slope≥1and separates CH(L)fromCH(U).\nGivenCH(FS), we can extract CH(L)andCH(U)inO(logn)time. Chazelle and Dobkin [ 7,\nSection 4.2] remark that, in the negative case, convex hull intersection testing can be modified\nto produce a separating line. In our setting, the hulls consist of segments with slope at least\n1, and any such separator corresponds to an ε-cover. Thus, our problem reduces to the\nclassical convex hull intersection problem and we are seemingly done.\nHowever, the history of convex hull intersection testing is long and intricate. Both Chazelle\nand Dobkin [ 7] and Dobkin and Kirkpatrick [ 11] independently proposed the first O(logn)-\ntime algorithms. In 1987, Chazelle and Dobkin [6] presented a more detailed description of\ntheir method. Dobkin and Kirkpatrick revisited their own work in 1990 [ 12], proposing a\nunifiedO(log2n)-time algorithm for polyhedron intersection, which O’Rourke later identified\nas incorrect [ 31]. He corrected the argument and provided a C-implementation. Further work\nby Dobkin and Souvaine [ 10] noted that earlier implementations lacked robustness. More\nrecently, Barba and Langerman [ 3] observed that the community still lacked a complete,\nrobust algorithm for polyhedral intersection. They proposed an alternative O(logn)algorithm\nbased on polar transformations. Walther’s master’s thesis [ 38], supervised by Afshani and\nBrodal, implemented both this and earlier methods, but the source code is no longer available.\nThis 35-year history highlights the complexity and subtlety of convex hull intersection\ntesting. Despite its history, no robust and modern O(logn)-time implementation is available.\nMoreover, no published algorithm explicitly computes a separating line in the negative case.\nContribution. In Appendix A, we present a robust O(logn)-time algorithm for convex hull\nintersection testing. Our algorithm is specialised to convex hulls composed of positively sloped\nsegments and including the points (∞,−∞)and(−∞,∞). We formally prove its correctness\nand adapt it to compute a separating line in the negative case, thereby constructing an\nε-cover of complexity 1 when it exists. The later adaption and its analysis are nontrivial,\nand arguably (partly) fill a gap in the existing literature on convex hull intersection testing.\n▶Theorem 8. LetAandBbe convex chains of edges with slope at least 1, stored in a balanced\nbinary tree on their left-to-right order. There exists an O(logn)time to decide whether there\nexists a line that separates AandB. This algorithm requires only orientation-testing for\nordered triangles and can output a separating line whenever it exists.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 7\n4 Robustness\nA geometric predicate is a function that takes geometric objects and outputs a Boolean. Our\nalgorithms compute geometric predicates and use their output to branch along a decision\ntree. InFS, consecutive points differ in x-coordinate by exactly 1whilst their y-coordinate\nmay wildly vary. Consequently, any segment that ε-covers a subsequence of FSis quite steep.\nThis quickly leads to rounding errors when computing geometric predicates, which in turn\ncreates robustness errors. To illustrate our point, we discuss one of our main algorithms:\nintersection_test (Algorithm 2) which determines whether an upper quarter convex\nhullCH(A)and a lower quarter convex hull CH(B)intersect. We receive these hulls as two\ntrees. Our algorithm computes a few geometric predicates given the edges αandβstored at\ntheir respective roots. Given (α,β), we either conclude that CH(A)andCH(B)intersect,\nor, that all edges succeeding (or preceding) α(orβ) cannot intersect the other convex hull.\nBased on the Boolean output, our algorithm then branches into a subtree of α(orβ). This\nway, we verify whether CH(A)andCH(B)intersect in logarithmic time. Rounding causes\nthese predicates to output a wrong conclusion, and our algorithm may branch into a subtree\ncontaining edges of CH(A)that are guaranteed to not intersect CH(B). Our algorithm then\nwrongfully concludes that there exists a line ℓseparatingCH(A)andCH(B). Subsequent\nalgorithms then exhibit undefined behaviour when they attempt to compute this line.\nGeometric predicates. Our algorithms use on three predicates for their decision making:\nslope. Given positive segments (α,β), output whether slope (α)<slope (β).\nlies_right . Given two positive segments αandβwith different slopes, output whether\nthe first vertex of βlies right of line(α)∩line(β).\nwedge. Consider a pair of positive segments (α,γ)that share a vertex and define W\nas the cone formed by their supporting halflines containing (∞,−∞). Given a positive\nsegmentβoutside ofW, output whether line(β)intersectsW.\nThe segments are given by points with integer coordinates. The slopes of these segments\n(and thereby any representation of their supporting line) are often not integer. A naive\nway to compute these predicates is to represent slopes using doubles. However, this is both\ncomputationally slow and prone to rounding errors (and thus, robustness errors).\nIf we insist on correct output, one can use an algebraic type instead. This type represents\nvalues using algebraic expressions. E.g., the slope of a positive segment (a,b)is the quotient:\nb.y−a.y\nb.x−a.xand so, in our case, it can be represented as a pair of integers. Algebraic types can\nsubsequently be accurately compared to each other. Indeed, if we want to verify whether\ns\nt<q\nrwe may robustly verify whether sr<qtusing only integers. Exact (algebraic type)\ncomparisons are frequently implemented, and present in the CGAL CORE library [13].\nHowever, exact comparisons are expensive. Our implementation of sloperequires two\ninteger multiplications, which is still relatively efficient. Evaluating more complex expressions\nrequires too much time. As a rule of thumb, we want to avoid compounding algebraic types\nto maintain efficiency. Naïvely, lies_right compounds two quotients and wedgecompounds\nthree. We give robust implementations of these functions by invoking three subfunctions.\nThese compare slopes, or whether a point lies above or below a supporting halfplane:\nslope ((a,b),(c,d)) :=( b.y−a.y)·(d.x−c.x)<(d.y−c.y)·(b.x−a.x)\nabove_line ((a,b),c) :=( b.x−a.x)(c.y−b.y)−(c.x−b.x)(b.y−a.y)≥0\nbelow_line ((a,b),c) :=( b.x−a.x)(c.y−b.y)−(c.x−b.x)(b.y−a.y)≤0\n\n8 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nWe can create lies_right from our robust predicates (see Figure 3 (a)):\n▶Lemma 9. Letα= (a,b)andβ= (c,d)be two positive segments of different slope. Then:\nlies_right (α,β) =/parenleftbig\nslope ((a,b),(c,d)) == above_line ((a,b),c)/parenrightbig\n∨/parenleftbig\nslope ((c,d),(b,c)) == below_line ((a,b),c)/parenrightbig\nProof.Suppose that slope (α)<slope (β). Thenclies right of line(α)∩line(β)if and only\nifclies above the halfplane bounded from above by line((a,b)). That happens if and only if\n(a,b,c )are collinear or make a counter-clockwise turn. This in turn occurs if and only if the\ndeterminant if the matrix/vextendsingle/vextendsingle/vextendsingle/vextendsingle(b.x−a.x) (c.x−b.x)\n(b.y−a.y) (c.y−b.y)/vextendsingle/vextendsingle/vextendsingle/vextendsingleis zero or more. If slope (α)>slope (β)\nthe determinant must be negative instead. ◀\nSimilarly, we can create wedgefrom our robust predicates. We note for the reader that\nexplain our equations in words in the proof of the lemma:\n▶Lemma 10 (Figure 3 (b)) .Ifα= (a,b),γ= (b,c)andβ= (d,e)be three segments of\npositive slope where W=← −α∪− →γbounds a convex area containing (∞,−∞). Then\nwedge (α,γ,β ) :=/parenleftbig\nbelow_line ((b,c),d)∧/parenleftbig\nabove_line ((d,e),b)∨slope ((a,b),(d,e)/parenrightbig/parenrightbig\n∨/parenleftbig\nbelow_line ((a,b),e)∧/parenleftbig\nabove_line ((d,e),b)∨slope ((d,e),(b,c))/parenrightbig/parenrightbig\n∨/parenleftbig\n¬below_line ((a,b),e)∧¬below_line ((b,c),d)∧/parenleftbig\nslope ((a,b),(d,e))∨slope ((b,c),(d,e))/parenrightbig/parenrightbig\nProof.The predicate is a case distinction of three mutually exclusive cases.\nIf the first vertex of βlies below the supporting line of γthenline(β)intersectsWif\nand only if it intersects← −α. This happens if and only if one of two conditions hold: either b\nlies below the supporting line of b, or, slope (α)<slope (β).\nIf the second vertex of βlies belowline(α)then the argument is symmetric.\nIf neither of those cases apply then both endpoints of βmust lie in the open green area.\nIn this case, whenever slope (α)<slope (β), the supporting line of βalways intersects W.\nWhenever slope (β)<slope (γ), the supporting line of βalways intersects W. Whenever\nslope (α)≥slope (β)≥slope (γ), the supporting line of βcannot intersect W. ◀\na)\nβ\nα\nb)\nβ\nα\na\nb\nc\nd\ne\na\nb\nc\nd\ne\nFigure 3 (a) We reduce testing whether the first vertex of βlies right of the intersection point to\ncomparing slopes and the orientation of a triangle. (b) If dlies below the halfplane of line(b,c)then\nline((d,e))intersects the wedge if and only if blies belowline((d,e)).\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 9\n5 Dynamically maintaining a learned index\nWe dynamically maintain a learned index hεofSby maintaining an ε-coverfofS. We\nguarantee that there exists no ε-coverf′ofSwith|f|>3\n2|f′|. By Observation 3, we obtain\na learned index hε. By Observation 4, there exists no PGM index hεwhere|f|>3\n2|hε|.\nTo maintain f, we maintain a balanced binary tree B(f)over Λ(f). Additionally, for\neach [a,b]∈Λ(f), we maintain a rank-based convex hull T(S[a,b])ofS[a,b]as described\nin [19]. We note that we store all segments in fusingrelativex-coordinates. That is, we\nassume for all [a,b]∈Λ(f)that the rank of the first element in S[a,b]is zero. We may then\nuseB(f)to ‘offset’ each line to compute the actual coordinates in rank-space.\n▶Theorem 11. We can dynamically maintain an ε-coverfofSinO(log2n)worst-case\ntime. We guarantee that there exists no ε-coverf′ofSwhere|f|>3\n2|f′|.\nProof.The proof is illustrated by Figure 4. For any s,t∈Zwiths≤t, we say that S[s,t]\nisblockedif there exists no ε-cover ofS[s,t]of size 1. We maintain an ε-coverfwhere for\nall consecutive intervals [a,b],[c,d]∈Λ(f),S[a,d]is blocked. Thereby, |f|≤3\n2|f′|for any\nε-coverf′ofS(we give a proof of this fact in Appendix C).\nWe consider inserting a value sintoS; deletions are handled analogously. We query\nB(f)inO(logn)time for an interval [a,b]that contains s. If no such interval exists, set\n[a,b] = [s,s]. We search T(S[a,b])and test whether s∈S. If so, we reject the update.\nOtherwise, we remove [a,b]from Λ(f)and insert the intervals ([a,s],[s,s],[s,b]). We\nobtainT(S[a,s]),T(S[s,s])andT(S[s,b])through the split operation.\nLet([w,x],[y,z],[a,s],[s,s],[s,b],[c,d],[e,f])be consecutive intervals in Λ(f)and denote\nI= ([y,z],[a,s],[s,s],[s,b],[c,d])(see Figure 4 (c) ). For each (s,t)∈I, we have access to\nT(S[s,t]). For any consecutive pair ([s,t],[q,r])inI, we may join the trees T(S[s,t])and\nT(S[q,r])inO(log2n)time to obtain T([s,r]). We invoke T([s,r]).get_hull() and apply\nTheorem 8 to test in O(log2n)total time whether S[s,r]isblocked. If it is not, we replace\n[s,t]and[q,r]by[s,r]. Otherwise, we keep T(S[s,r])and a complexity-1 ε-cover ofS[s,r].\nBy recursively merging pairs in I, we obtain in O(log2n)time a sequence I′of intervals\n([y,β],..., [γ,d])where consecutive intervals are blocked. Since [y,z]⊆[y,β],([w,x],[y,β])is\nblocked. Similarly, ([γ,d],[e,f])must be blocked. We remove the line segments corresponding\ntoIfromfand replace them with line segments derived from I′in constant time. As a\nresult, we maintain our ε-coverfand our data structure in O(log2n)total time. ◀\na)\nb)\n[y, z]\n[a, b]\n[c, d]\n[e, f]\n[w, x]\nc)\nd)\ns\nI\nI′\nFigure 4 (a) LetSbe a set of values and let us insert s. (b) We consider our ε-coverfand five\nconsecutive intervals in Λ(f). (c) We create seven intervals by splitting [a,b]ons. (d) By recursively\nmerging intervals in I, we obtain a set of intervals I′where consecutive intervals are blocked.\n\n10 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\n6 From an ε-cover to an indexing structure\nA learned index hεdoes not immediately support indexing and range queries. We obtain\nan indexing structure by combining hεwith a hash map H. Combining learned models\nwith hash maps is not new [ 26,37,39] and this technique has even been applied to learned\nindexing [ 25]. The core idea is to store Sin an unordered vector Aand maintain a Hash\nmapH:Z∝⇕⊣√∫⊔≀→[n]. Given some q∈U, the learned function then produces a value vsuch that\nA[h(v)]is ‘close’ to q. It is compelling to create Hsuch thatA[H(h(q))]is (approximately)\nthe predecessor of q. However, dynamically, this approach fails for the same reason that\nstoring each s∈SatA[rank(s)]fails. Since the ranks of elements in Sare constantly\nchanging, we build a hash map using the parts of Sthat remain constant: the values.\nOur data structure. In Appendix B, we define a data structure independent of the learned\nindexhε(we illustrate our approach in Figure 5 (a) + (b)). A pagepis an integer with a\nvector that stores all s∈Swhere⌊s\nε⌋=p, in order. We store all non-empty pages Pin an\nunordered vector A. We maintain a hash map H:P→[|A|], whereA[H(p)]contains the\npagep. We additionally maintain a doubly linked list over all pages in P, arranged in sorted\norder.\nOur queries. We restrict our learned index hεto averticalε-cover. I.e.,hεis ay-monotone\ncollection of line segments such that for all points p∈FS, a vertical line segment of height\n2εcentred atpintersects a segment in hε. We compute hεoblivious of our paging structure.\nGivenq∈U, we project qontohε(Figure 5 (d)). We project to the x-axis, floor the\nvalue, and project back to hε. We prove that the resulting y-value corresponds to the page p\ncontaining predecessor (q). This way, we answer predecessor usingO(ε+ log|hε|)time.\nAs a result, we dynamically maintain a learned index hεand a data structure that updates\ninO(ε+log2n)and supports indexing queries in O(ε+log|hε|)expected time (Theorem 23).\n▶Theorem 12. For anyε, there exists a data structure to dynamically maintain a vertical\nε-coverFof a dynamic set of distinct integers in O(ε+log2n)time. We guarantee that\nthere exists no vertical ε-coverF′with|F|>3\n2|F′|. The data structure supports indexing\nqueries inO(ε+log|F|)expected time and range queries in additional O(k)time where kis\nthe output size.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 11\na)\nc)\n5\n6\n7\n8\n9\n10\n11\n12\n13\nA :\nε= 10\n103\n102\n123\n122\n61\n60\n85\n80\n59\n57\n135\n131\n78\n76\n128\n67\n86\n88\n139\n10\n12\n6\n8\n11\n13\n13\n7\n5\nb)\n105\n59\n57\n106\nd)\n⌊b\nε⌋\n(a, b)\nFigure 5 An illustration of our approach in Appendix B.\n7 Experiments\nOur implementation is written in C++and made publicly available [ 20]. We compare to\ntheC++implementation in [ 17], which uses a PGM index under the logarithmic method.\nThe experiments were conducted on a machine with a 4.2GHz AMD Ryzen 7 7800X3D and\n128GB memory. Our test bench is available [ 21], and can replicate experiments, generate\nsynthetic data, and produce plots. As input we consider two synthetic data sets and two real\nworld data sets. Three contain data of geometric nature, with one of random nature to align\nwith precedent. Each set consists of unique 8 byte integers in randomly shuffled order. In\nAppendix D, we showcase additional experiments on other datasets.\nLINES is a synthetic data set of 5M integers that, in rank space, produces 5 lines of\nexponentially increasing slope. This set models the ideal scenario for a PGM index.\nLONGITUDE is a real world data set that contains the longitudes of roughly 246M\npoints of interest from OpenStreetMap, over the region of Italy. This data is thereby\ninherently of geometric nature. This data set was used in both [ 17] and [22]. We follow [ 17]\nand convert the data to integers by removing the decimal point from the raw longitudes.\nUNIForiginates from [ 17]. It is a synthetic data set, containing a uniform random\nsample of 50M integers from (0,1011). We adapt this data set to our dynamic setting.\nDRIFTER is a real world data set, containing roughly 1.7M steps of accumulated\ndistance travelled by ocean drifters tracked through GPS [8].\nMeasurements. We compare the quality of the learned indices based the complexity of hε,\nin a dynamic setting. We use the same choice of ε= 64as in [17] across our experiments. For\nperformance of the indexing structures, we measure their time per operation in a dynamic\nscenarios with a range of query to update ratios. We note that logarithmic PGM is by default\nequipped with an optimisation that avoids building a PGM for data below a certain size. In\n\n12 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nthis case, it instead only uses an underlying sorted array without additional search structure.\nIn order to properly compare the performances, this optimisation has been disabled.\n7.1 The learned index complexity\nFigure 6 presents the complexity of the learned indices, measured by the number of line\nsegments maintained during random-order insertions. The behaviour differs between datasets.\nFor the geometric LinesandLongitude datasets, the dynamic and logarithmic PGMs\ninitially perform similarly. As the data grows, the performance of the logarithmic PGM\ndegrades and its jagged progression reflects its logarithmic partitioning.\nOn the highly structured synthetic Linesdata, the logarithmic method consistently\nretains more segments than necessary. It misses the optimal line count by a wide margin due\nto its fragmentation across O(logn)buckets. A similar pattern appears in the Longitude\ndataset, where the logarithmic PGM maintains roughly 50 percent more segments than our\nsolution. We note that precisely on these structured data sets, the complexity of the learned\nindices iso(n). I.e., precisely here one also expects improvements in query time.\nFigure 6 The complexity of the learned indices throughout insertion-only construction. The top\ngraphs represent geometrically structured data. The left graphs represent synthetic data.\nFor unstructured data such as Unif, both learned indices display similar asymptotic\ntrends, with the logarithmic PGM using approximately 30 percent fewer segments. Here, the\ncomplexity appears to scale as Ω(n)for both methods, suggesting that learned indices offer few\nto no improvements in the absence of exploitable structure. Surprisingly, the Drifter data –\ndespite its geometric origin – shows similar results to that of Unif. Again, complexity scales\nlinearly, and the logarithmic method outperforms the dynamic one by around 30 percent.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 13\nThis implies that whatever latent geometric structure exists is insufficiently captured by the\nlearned index under either strategy.\nAn interesting observation is that, on unstructured data, the imposed bucketing of the\nlogarithmic PGM index can introduce a form of regularity that the model benefits from,\nessentially imposing artificial structure where none exists.\n7.2 Running time comparisons\nRecall that our indexing structure is composed of a learned index over a vertical ε-cover and\na paging structure. We first examine the performance of both the learned index in its own,\nand then the performance of the full indexing structure.\nFor the dynamic scenarios, we first follow the precedence set by prior papers [ 17,22].\nThese first construct, insertion-only, the indexing structure. They then perform a batch of\n10M operations These batches consist of insertions, deletions, and range queries over ranges\nsuch that the output contains approximately√n\n10elements. We deviate from the precedent by\nalso deleting from the index before performing a batch of operations, to simulate a scenario\nin which the structure has existed and transformed prior to processing.\n7.2.1 Maintaining a learned index\nFigure 7 shows the cost of maintaining each learned index under dynamic operations. Our\nupdate procedure, which ensures worst-case O(log2n)bounds, performs significantly worse\nthan the amortised O(logn)updates offered by the logarithmic method – especially on larger\ndatasets such as Longitude andUnif. On smaller datasets like Drifter , the gap narrows,\nbut the logarithmic method generally remains preferable in these update-only scenarios.\nFigure 7 Update times for maintaining the learned index dynamically.\n7.2.2 Indexing data structures\nWe next assess the complete indexing structures under mixed workloads. Batches contain\na tunable ratio of queries and updates, where updates are evenly split between insertions\nand deletions, and operations are randomly ordered. More experiments can be found in\nAppendix D. For the Linesdataset, updates are constrained to a single line segment to\npreserve its idealised structure. For smaller datasets, batch size is limited to 25 percent.\nAdversarial workload (ADV). In the above scenario by [ 17,22], an update batch of 10M\noperations affects less than ten percent of the data. Therefore, we do not encounter the\nworst case scenario where range queries take O(N+ε+/summationtext⌈logn⌉\nilog|fi|)time. So, the worst\ncase difference in performance does not come to light. Therefore, we additionally construct\nanadversarial scenario consisting of 10M range queries after deleting all but 1.000values.\n\n14 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nFigure 8 Time per operation in dynamic scenario with varying query ratios. For the LINES data\nset updates are restricted to points on a single line. The ADV ratio denotes the adversarial case\nwhere all but a constant number of elements are deleted before the structure is queried.\nOperational performance. Figure 8 summarises the total processing time under varying\nquery-to-update ratios. Structured datasets, particularly Longitude , reveal a trade-off\nbetween the fact that we have a lower-complexity learned index and our update time. On\none hand, our updates are costly due to our line-merging tests which suffer from the poor\ncache behaviour from pointer-based trees, and complex rebalancing that is present in the\nstate-of-the-art practical dynamic convex hull data structures. This behaviour is also reflected\non our previous analysis of maintaining the learned index itself. On the other hand we see\non geometrically structured data that, as the query ratio increases, performance improves.\nThis trend is absent in the Linesdata, where updates are constrained and the structure is\nsmall, mitigating cache penalties. Here, running time is largely driven by query processing,\nwhich increases as expected with query ratio.\nIn contrast, the random data from the Unifdataset shows improved performance with\nhigher query ratios. In our data structure, having smaller segments reduce restructuring\ncosts. Our dynamic implementation suffers greatly from cache inefficiency due to random\naccess during range reporting. The logarithmic PGM, with its lower memory overhead and\nsequential layout, delivers significantly better performance – particularly as sizes increase.\nFor the Drifter data, one would expect a trend similar to that of the Unifdata, based\non the complexity of the ε-cover shown in Figure 6. However, there is little difference in\nperformance for either PGM as the query ratio is varied. This is likely due to the small size\nof the data set, with both structures performing updates in fractions of microseconds on\naverage. The logarithmic PGM does come out slightly on top, likely due to the machine\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 15\nfriendly memory access pattern.\nAdversarial impact. Across all datasets, the logarithmic PGM’s tombstoning strategy\nbecomes a bottleneck in the adversarial scenario. Its range queries must scan and subtract\ndeleted values before outputting results. Our structure, by contrast, is output-sensitive and\navoids such overhead. This illustrates that our data structure, whilst being generally less\nefficient that the logarithmic PGM, offers worst-case guarantees.\n8 Conclusion\nWe studied dynamic learned indices through a geometric perspective. Following the work\nof Ferragina and Vinciguerra [ 17], we maintained a learned index hεof a dynamic set S\nas a piecewise-linear approximation—an ε-cover—of the rank-space point set FS. We used\ntechniques from computational geometry to answer the following question:\n“Can a learned index be dynamically maintained with worst-case guarantees?”\nWe proposed a new approach to maintain a learned index based on dynamic convex hull\ndata structures. We presented an O(log2n)time algorithm to dynamically maintain a\nlearned index hε. To obtain this algorithm, we showed an algorithm to compute a separating\nline between two non-intersecting convex hulls – an operation previously missing from the\nliterature. The existing logarithmic PGM index has an amortised O(logn)time update\nalgorithm which is more efficient in practice. Indeed, although close in theory, the memory\naccess pattern associated with dynamically maintaining convex hulls incurs heavy penalties\nfor large datasets. At the same time, the resulting learned index of the logarithmic PGM,\nh′\nε, can be considerably more complex on geometrically structured data.\nFrom learned indices to indexing. Finally, we considered the following question:\n“Can a dynamic learned index be converted into a dynamic indexing data structure?”\nTo this end, we designed a hybrid technique combining hashing-based fast-access data struc-\ntures with a doubly linked list to support indexing queries. Our method offers output-sensitive\nworst-case guarantees, even in the presence of deletions. As it is known that traditional\nindexing structures currently outperform learned indices in the general dynamic setting [ 36],\nwe focused our comparisons on improving the theoretical and practical performance within\nthe class of learned approaches.\nIn practice, the contiguous memory access of the logarithmic PGM index offsets its\noverhead from querying multiple structures, making it faster in all scenarios, except for\nan adversarial one. This means that the lower complexity of our learned index does not\nimmediately translate to improved efficiency in the indexing data structure. This raises an\ninteresting open question of whether memory-access efficient fully dynamic approaches to\nconvert a learned index into a dynamic indexing structure can exist.\nWhile we acknowledge that our update-times are slow in comparison with state-of-the art,\nour approach does illustrate that it brings worst-case guarantees: as it has an advantage when\nthe query-to-update ratio is large and the index has undergone sufficiently many deletions.\nIn adversarial workloads with frequent deletions followed by range queries, we have seen\nour structure outperform the logarithmic approach – highlighting the value of worst-case\nguarantees even in specialised settings.\n\n16 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nClosing thoughts. We showed what we believe is an interesting connection between the\ngeometric learned index by Ferragina and Vinciguerra, and dynamic convex hulls from\ncomputational geometry. We subsequently provided an implementation of a dynamic learned\nindex that relies on the state-of-the-art dynamic convex hull maintenance algorithms. Our\nempirical analysis shows that the complex tree rebalancing that is used to dynamically\nmaintain a convex hull currently brings considerable operational overhead compared to low-\nmemory techniques under the logarithmic method. Our experiments, though not uniformly\nfavourable, offer interesting insights into the current barriers and adversarial tradeoffs between\nworst-case dynamic algorithms and memory-efficient amortised rebuilding schemes.\nAlgorithm 1 intersection_test (edgeα∈CH(A),edgeβ∈CH(B))\n1:ifα=nullORβ=nullthen\n2:returnNo\n3:end if\n4:s(α,β) =line(α)∩line(β)\n5:ifIfs∈αands∈βthen\n6:returnYes\n7:end if\n8:ifα.slope< β.slopethen\n9:ifα.first.x>s(α,β).xthen\n10: return intersection_test (α.left,β)\n11:else ifβ.first.x>s(α,β).xthen\n12: return intersection_test (α,β.left)\n13:else ifα.first.x > β.second.xANDα.first.y>β.second.ythen\n14: return intersection_test (α.left,β)\n15:else ifα.second.x < β.first.xANDα.second.y<β.first.ythen\n16: return intersection_test (α,β.left)\n17:else\n18: returnyes\n19:end if\n20:end if\n21:ifα.slope >β.slopethen\n22:ifα.second.x < s (α,β).xthen\n23: return intersection_test (α.right,β)\n24:else ifβ.second.x < s (α,β).xthen\n25: return intersection_test (α,β.right)\n26:else ifα.first.x > β.second.xANDα.first.y>β.second.ythen\n27: return intersection_test (α,β.right)\n28:else ifα.second.x < β.first.xANDα.second.y<β.first.ythen\n29: return intersection_test (α.right,β)\n30:else\n31: returnyes\n32:end if\n33:end if\nReferences\n1Mahmuda Ahmed, Sophia Karagiorgou, Dieter Pfoser, and Carola Wenk. A comparison\nand evaluation of map construction algorithms using vehicle tracking data. GeoInformatica ,\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 17\n19(3):601–632, 2015.\n2Manos Athanassoulis and Anastasia Ailamaki. Bf-tree: approximate tree indexing. In\nInternational Conference on Very Large Databases (VLDB) , 2014.\n3Luis Barba and Stefan Langerman. Optimal detection of intersections between convex\npolyhedra. ACM-SIAM Symposium on Discrete Algorithms (SODA) , 2015.\n4Michael A Bender, Erik D Demaine, and Martin Farach-Colton. Cache-oblivious b-trees. In\nSymposium on Foundations of Computer Science (FOCS) . IEEE, 2000.\n5Chee-Yong Chan and Yannis E Ioannidis. Bitmap index design and evaluation. In ACM\nInternational Conference on Management of Data (SIGMOD) , 1998.\n6B. Chazelle and D. P. Dobkin. Intersection of convex objects in two and three dimensions.\nJournal of the ACM , 1987. doi:10.1145/7531.24036 .\n7Bernard Chazelle and David P Dobkin. Detection is easier than computation. In ACM\nSymposium on Theory Of Computing (STOC) , 1980.\n8Jacobus Conradi and Anne Driemel. Finding complex patterns in trajectory data via geometric\nset cover. CoRR, abs/2308.14865, 2023. doi:10.48550/ARXIV.2308.14865 .\n9Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li, Hantian\nZhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann, et al. Alex: an updatable\nadaptive learned index. In ACM International Conference on Management of Data (SIGMOD) ,\n2020.\n10David Dobkin and Diane Souvaine. Detecting the intersection of convex objects in the plane.\nComputer Aided Geometric Design , 1991. doi:10.1016/0167-8396(91)90001-R .\n11David P. Dobkin and David G. Kirkpatrick. Fast detection of polyhedral intersection. Theor-\netical Computer Science (TSC) , 1983. doi:10.1016/0304-3975(82)90120-7 .\n12David P. Dobkin and David G. Kirkpatrick. Determining the separation of preprocessed\npolyhedra - a unified approach. In International Colloquium on Automata, Languages and\nProgramming (ICALP) , 1990.\n13Andreas Fabri, Geert-Jan Giezeman, Lutz Kettner, Stefan Schirra, and Sven Schönherr. On the\ndesign of cgal a computational geometry algorithms library. Software: Practice and Experience ,\n30(11):1167–1202, 2000.\n14Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so effective?\nInProceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18\nJuly 2020, Virtual Event , volume 119 of Proceedings of Machine Learning Research , pages\n3123–3132. PMLR, 2020.\n15Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. On the performance of learned data\nstructures. Theor. Comput. Sci. , 871:107–120, 2021.\n16Paolo Ferragina and Giorgio Vinciguerra. Learned data structures. In Recent Trends in\nLearning From Data: Tutorials from the INNS Big Data and Deep Learning (INNSBDDL) .\nSpringer, 2020.\n17Paolo Ferragina and Giorgio Vinciguerra. The pgm-index: a fully-dynamic compressed learned\nindex with provable worst-case bounds. International Conference on Very Large Databases\n(VLDB), 2020.\n18Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim Kraska.\nFiting-tree: A data-aware index structure. In ACM International Conference on Management\nof Data (SIGMOD) , pages 1189–1206, 2019.\n19Emil Gæde, Inge Li Gørtz, Ivor Van Der Hoog, Christoffer Krogh, and Eva Rotenberg. Simple\nand robust dynamic two-dimensional convex hull. ACM Symposium on Algorithm Engineering\nand Experiments (ALENEX) , 2024.\n20EmilToftegaardGæde, IvorvanderHoog, EvaRotenberg, andTordStordalen. Implementation\nof a Dynamic Learned Index. https://github.com/Sgelet/DynamicLearnedIndex , 2025.\n21Emil Toftegaard Gæde, Ivor van der Hoog, Eva Rotenberg, and Tord Stordalen. Testbed for\nDynamic Learned Indices. https://github.com/Sgelet/LearnedIndexBench , 2025.\n\n18 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\n22Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim\nKraska, and Thomas Neumann. Sosd: A benchmark for learned indexes. Conference on Neural\nInformation Processing Systems (NEURIPS) , 2019.\n23Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska,\nand Thomas Neumann. Radixspline: a single-pass learned index. In International workshop\non exploiting artificial intelligence techniques for data management , 2020.\n24Nick Koudas. Space efficient bitmap indexing. In ACM international conference on Information\nand knowledge management (SIGMOD) , 2000.\n25Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In ACM International Conference on Management of Data (SIGMOD) , 2018.\n26YumingLin, ZhengguoHuang, andYouLi. Learninghashindexbasedonashallowautoencoder.\nApplied Intelligence , 2023.\n27Spyros Makridakis, Evangelos Spiliotis, and Vassilios Assimakopoulos. The m4 competition:\n100,000 time series and 61 forecasting methods. International Journal of Forecasting , 36(1):54–\n74, 2020.\n28Ryan Marcus, Andreas Kipf, and Alex van Renen. Searching on Sorted Data, 2019. doi:\n10.7910/DVN/JGVF9A .\n29Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra, Alfons\nKemper, Thomas Neumann, and Tim Kraska. Benchmarking learned indexes. Proc. VLDB\nEndow., 14(1):1–13, 2020.\n30Joseph O’Rourke. An on-line algorithm for fitting straight lines between data ranges. Com-\nmunications of the ACM , 1981.\n31Joseph O’Rourke. Computational geometry in C (second edition) . Cambridge University Press,\nUSA, 1998.\n32Mark H Overmars. The design of dynamic data structures , volume 156. Springer Science &\nBusiness Media, 1983.\n33Mark H Overmars and Jan Van Leeuwen. Maintenance of configurations in the plane. Journal\nof computer and System Sciences , 1981.\n34Rasmus Pagh and Flemming Friche Rodler. Cuckoo hashing. Journal of Algorithms , 2004.\n35Mihai Pătraşcu and Mikkel Thorup. Time-space trade-offs for predecessor search. In ACM\nSymposium on Theory of Computing (STOC) , 2006.\n36Zhaoyan Sun, Xuanhe Zhou, and Guoliang Li. Learned index: A comprehensive experimental\nevaluation. Proc. VLDB Endow. , 16(8):1992–2004, 2023.\n37Antonio Torralba, Rob Fergus, and William T Freeman. 80 million tiny images: A large data\nset for nonparametric object and scene recognition. IEEE transactions on pattern analysis\nand machine intelligence , 2008.\n38Lukas Walther, Gerth Brodal, and Peyman Afshani. Intersection of convex objects in the\nplane. Master’s thesis, Aarhus University, 2015. Available at https://cs.au.dk/~gerth/\nadvising/thesis/lukas-walther.pdf .\n39Jun Wang, Wei Liu, Sanjiv Kumar, and Shih-Fu Chang. Learning to hash for indexing big\ndata—a survey. Proceedings of the IEEE , 2015.\n40Ziqi Wang, Andrew Pavlo, Hyeontaek Lim, Viktor Leis, Huanchen Zhang, Michael Kaminsky,\nand David G Andersen. Building a bw-tree takes more than just buzz words. In ACM\nInternational Conference on Management of Data (SIGMOD) , 2018.\n41Chaichon Wongkham, Baotong Lu, Chris Liu, Zhicong Zhong, Eric Lo, and Tianzheng Wang.\nAre updatable learned indexes ready? International Conference on Very Large Databases\n(VLDB), 2022.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 19\nA Algorithms engineering for separating lines of convex hulls\nLetA= (α1,...,α n)andB= (β1,...,β n)be convex chains of nedges with positive slope.\nLetCH(A)be an upper-quarter convex hull (the boundary of the minimum convex area\ncontaining Aand(∞,−∞)). LetCH(B)be a lower quarter convex hull (the boundary of\nthe minimum convex area containing Band(−∞,∞)).\nWe do intersection testing between AandB. In addition, we show an algorithm to\ncompute a separating line between AandBin the negative case. We assume that we receive\nAandBin a tree structure. Formally, we define a struct:\nedgeα\nvertexfirst the first endpoint of α\nvertexsecond the second endpoint of α\nedgeleft the median edge of the remaining edges that precede α\nedgeright the median edge of the remaining edges that succeed α\nrealslope the slope of the supporting line of the segment\nFor the first edge of α1ofA, we define α1.left as a vertical downward halfline. For the last\nedgeα2ofA, we define α1.right as a horizontal rightward halfline. The first and last edges\nofBare also incident to either a horizontal and vertical halfline respectively.\nGoal and organisation. We first show an O(logn)-time algorithm to test whether Aand\nBintersect and we prove its correctness. Then we extend this algorithm so that it gives a\nseparating line of CH(A)andCH(B)in the negative case and prove its correctness. These\nalgorithms compare the slopes of edges and compute intersection points between supporting\nlines of edges, which are naïvely not robust operations. By Section 4, we can implement\nthese operations in a robust manner.\n▶Lemma 13. Algorithm 2 correctly determines whether CH(A)andCH(B)intersect.\nProof.The proof follows the approach in [6] and is a case distinction.\nSuppose first thatα.slope< β.slope. We define Was the cone with supporting lines\nline(α)andline(β), that lies left of s(α,β)and hass(α,β)as its apex (Figure 9). The area\nCH(A)is contained in the halfplane bounded from above by line(α). The area CH(B)is\ncontained in the halfplane bounded from below by line(β). Any intersection between CH(A)\nand CH (B)must be contained in Wand therefore lie left of s(α,β).\nIfα.first lies strictly right of s(α,β)(line 11) then αcannot intersect any edge of CH(B).\nMoreover, any edge in the right subtree of αcannot intersect CH(B)and so we may safely\nrecurse onα.left. Ifβ.first lies strictly right of s(α,β)(line 13) then βand its right subtree\ncannot intersect any edge of CH (A)and we may safely recurse on β.left.\na)\ns(α, β)\nW\nb)\nq\nα\nβ\nc)\nβ\nα\nb\na\nq\nFigure 9 (a) The edge βstrictly precedes αand the first vertex of αprecedesq. (b) The edge α\nstrictly precedes β. (c) There exists points (a,b)whereais in the top left quadrant if b.\n\n20 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nAlgorithm 2 intersection_test (edgeα∈CH(A),edgeβ∈CH(B))\n1:ifα=nullORβ=nullthen\n2:returnNo\n3:end if\n4:s(α,β) =line(α)∩line(β)\n5:ifIfs∈αands∈βthen\n6:returnYes\n7:end if\n8:ifα.slope< β.slopethen\n9:ifα.first.x>s(α,β).xthen\n10: return intersection_test (α.left,β)\n11:else ifβ.first.x>s(α,β).xthen\n12: return intersection_test (α,β.left)\n13:else ifα.first.x > β.second.xANDα.first.y>β.second.ythen\n14: return intersection_test (α.left,β)\n15:else ifα.second.x < β.first.xANDα.second.y<β.first.ythen\n16: return intersection_test (α,β.left)\n17:else\n18: returnyes\n19:end if\n20:end if\n21:ifα.slope >β.slopethen\n22:ifα.second.x < s (α,β).xthen\n23: return intersection_test (α.right,β)\n24:else ifβ.second.x < s (α,β).xthen\n25: return intersection_test (α,β.right)\n26:else ifα.first.x > β.second.xANDα.first.y>β.second.ythen\n27: return intersection_test (α,β.right)\n28:else ifα.second.x < β.first.xANDα.second.y<β.first.ythen\n29: return intersection_test (α.right,β)\n30:else\n31: returnyes\n32:end if\n33:end if\n34:ifα.slope =β.slopethen\n35:ifline(β)is aboveline(α)then\n36: returnNo\n37:else ifα.first.x > β.second.xANDα.first.y>β.second.ythen\n38: return intersection_test (α.left,β)\n39:else ifα.second.x < β.first.xANDα.second.y<β.first.ythen\n40: return intersection_test (α,β.left)\n41:else\n42: returnNo\n43:end if\n44:end if\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 21\nLetα.first dominate β.second. Suppose that CH(A)intersects CH(B)in a pointqright\nofα.first (Figure 9 (a)). Since CH(A)has positive slope, qdominates α.first. Consider\nthe convex area Genclosed by a curve γthat traverses CH(B)backwards until β.second,\nat which point it ends with a horizontal leftwards halfline. Since q∈γdominates α.first,\nandα.first dominates β.second∈γ,α.first lies in G. However, CH(A)starts with a vertical\ndownwards halfline left of α.first. It follows that CH(A)andCH(B)also intersect in a point\nq′left ofα.first and so we may safely recurse on α.left.\nLetβ.first dominate α.second. Suppose that CH(B)intersects CH(A)in a pointqright\nofβ.first (Figure 9 (b)). Since CH(B)has positive slope, qdominates β.first. Consider\nthe convex area Genclosed by a curve γthat traverses CH(A)backwards until α.first, at\nwhich point it ends with a vertical downwards halfline. Since q∈γdominatesβ.first and\nβ.first dominates α.second∈γ, it follows that β.first is inG. However, CH(B)starts with a\nhorizontal leftwards halfline below β.first. It follows that CH(A)andCH(B)also intersect\nin a pointq′left ofβ.first and so we may safely recurse on β.left.\nOtherwise, αandβshare a vertical line with αaboveβ(or, a horizontal line with α\nleft ofβ). This is illustrated by Figure 9 (c). Pick a point a∈αandb∈βsuch that they\nshare a vertical line with aaboveb(or, such that they share a horizontal line with aleft\nofb). The curve CH(A)bounds an area containing the quarter plane that has aas its top\nleft corner. The curve CH(B)bounds an area containing the quarter plane that has bas its\nbottom right corner. It follows that CH(A)andCH(B)intersect and so we may output yes.\nSuppose next that slope (α)>slope (β).Consider the cone Wwith supporting lines\nline(α)andline(β), right ofs(α,β), that hass(α,β)as its apex (Figure 10). Any intersection\nbetween CH (A)and CH (B)must be contained in Wand therefore lie right of s(α,β).\nLetα.first dominate β.second. Suppose that CH(A)intersects CH(B)in a pointqleft\nofβ.second. Since CH(B)has positive slope, β.second dominates q. Consider the convex\nareaGenclosed by a curve γthat traverses CH(A)forwards until α.first, at which point it\nends with a horizontal rightwards halfline. Since qis dominated by β.second, and β.second is\ndominated by α.first it follows that β.second lies in G. However, CH(B)ends with a vertical\nupwards halfline right of β.second. It follows that CH(A)andCH(B)also intersect in a\npointq′right ofβ.second and so we may safely recurse on β.right.\nLetβ.first dominate α.second. Suppose that CH(B)intersects CH(A)in a pointqleft of\nα.second. Since CH(A)has positive slope, qis dominated by α.second. Consider the convex\nareaGenclosed by a curve γthat traverses CH(B)forwards until β.first, at which point\nit ends with a vertical upwards halfline. Since qis dominated by α.second and α.second is\ndominated by β.first, it follows that α.second is in G. However, CH(A)ends with a horizontal\nrightwards halfline above α.second. It follows that CH(A)andCH(B)also intersect in a\npointq′right ofα.second and so we may safely recurse on α.right.\nOtherwise, we may find a point a∈αthat lies top left to a point b∈βand soCH(A)\nandCH(B)are guaranteed to intersect.\na)\nb)\nα\nβ\nc)\ns(α, β)\nβ\nα\nFigure 10 (a) The edge βstrictly precedes αand the first vertex of αprecedesq. (b) The edge\nαstrictly precedes β. (c) There exists points (a,b)whereais in the top left quadrant if b.\nOtherwise, let slope (α) =slope (β).If the supporting line of βlies aboveαthenCH(A)\n\n22 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nandCH(B)can never intersect (Figure 11). Otherwise, the argument is identical to the\nprevious two cases. ◀\na)\nb)\nα\nc)\nβ\nq\nq\nα\nβ\nFigure 11 Ifline(α)andline(β)are parallel with the first below the latter, CH(A)andCH(B)\ncannot intersect. Otherwise, we may apply any of the previous arguments.\nA.1 Finding a separating line\nIf Algorithm 2 terminates and outputs that CH(A)andCH(B)do not intersect then we can\nfind a line that separates CH(A)andCH(B). Algorithm 2 outputs noin two cases. The\nfirst case is the special case where there exist two parallel edges α∈CH(A)andβ∈CH(B)\nwhereline(β)lies aboveline(α). In this case both line(α)andline(β)are a separating line.\n▶Definition 14. For any edge α, we denote by← −αand− →αits two supporting leftward and\nrightward halflines. For any pair of edges (β,b)that share a vertex with βleft ofb, we denote\nbyw(β,b) =← −β∪− →btheirwedge.\nThesecondcaseisthateitherargumentofthefunctionwas null. Withoutlossofgenerality,\nweassumethat βwasnull. Thenthereexisttwopairsofedges (α,β),(a,b)∈CH(A)×CH(B)\nwhere intersection_test (α,β)recurses on β.right and intersection_test (a,b)recurses\nonb.left. Moreover, the edges βandbmust share a vertex. By keeping track of the traversal\nof Algorithm 2, we obtain w(β,b)at no overhead.\n▶Lemma 15. Let Algorithm 2 terminate without finding an intersection between CH(A)\nandCH(B)and denote by w(β,b)the corresponding wedge. Then:\nthe halfline← −βcannot intersect CH(A), and\nthe halfline− →bcannot intersect CH(A).\nProof.We first prove that the halfline← −βcannot intersect CH(A). There exists some\nα∈CH(A)where intersection_test (α,β) recurses on β.right. Thus, slope (α)>slope (β).\nDefines(α,β) =line(α)∩line(β). Observe that intersection_test (α,β) recurses on\nβ.right in two cases. The first case is whenever β.second.x < s (α,β).x. SinceCH(A)lies in\nthe plane upper bounded by line(α)this implies that← −βcannot intersect CH(A).\nIn the second case, the vertex α.first dominates β.second (Figure 12 (a)). Suppose for\nthe sake of contradiction that← −βintersectsCH(A)in some point qleft ofβ.second. Since\nline(β)has positive slope, β.second must dominate q. Consider the convex area Gbounded\nby a curve γthat traverses CH(A)backwards until q, after which it becomes a vertical\ndownward halfline. It follows that β.second is contained in G⊆CH(A). This implies that\nCH(A)andCH(B)intersect which is a contradiction.\nWe argue that− →bcannot intersect CH(A)in the same way ( Figure 12 (b)). There must\nexist some a∈CH(A)where intersection_test (a,b) recurses on b.left. Ifslope (a)<\nslope (b)then we first consider the special case where β.first.x > s (a,b).x. SinceCH(A)\nis contained in a halfplane upper bounded by line(a)this implies that− →bcannot intersect\nCH(A).\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 23\nIf the special case does not apply, or whenever slope (α) =slope (β)then it must be that\nais dominated by b. If− →bintersectsCH(A)in a pointqthen we may use qto argue that\nCH(A)andCH(B)intersect in an identical manner as above. ◀\na)\ns(α, β)\nβ\nα\nb\na\nq\nb)\nq\nFigure 12 (a) If there exists an edge αofCH(A)that dominates βand− →βintersectsCH(A)in\na pointqthen we may argue that βis contained in CH(A). (b) If there exists an edge aofCH(A)\nthat is dominated by an edge bthen we make the symmetrical argument.\nGiven the edge w(β,b)we run Algorithm 3, starting with the root of α.\nAlgorithm 3 separation_find (wedgew(β,b),edgea∈CH(A)\n1:ifα=nullthen\n2:returnline(β)orline(b)\n3:end if\n4:ifline(α)∩w(β,b) =∅then\n5:returnline(α)\n6:else if← −α∩w(β,b)̸=∅then\n7:return separation_find (w(β,b),α.left)\n8:else\n9:return separation_find (β,b,α.right)\n10:end if\n▶Lemma 16. Algorithm 3 outputs a edge in CH(A)∪CH(B)whose supporting line separates\nCH(A)andCH(B).\nProof.By Chazelle and Dobkin [ 6] there always exists an edge on CH(A)orCH(B)whose\nsupporting line separates the two convex hulls.\nFirst, we show that our algorithm always finds either an edge of CH(A), or guarantees\nthat for all edges in CH(A)their supporting line intersects w(β,b). Indeed, since CH(B)is\ncontained in w(β,b), a lineline(α)separates the two hulls if it does not intersect w(β,b).\nWheneverline(α)doesintersectw(β,b), either← −αor− →αmust intersect w(β,b). Suppose\nthat← −αintersectsw(β,b). Any edge a∈CH(A)succeeding αmust have lower slope and so\n← −amust intersect w(β,b). Similarly if− →αintersectsw(β,b)for any edge a∈CH(A)preceding\nα,− →aintersectsw(β,b). Finally, since Astarts with a vertical downwards halfline and ends\nwith a horizontal rightwards halfline, it cannot be that for all edges a∈CH(A)the halfline\n← −aintersectsw(β,b)(the same is true for− →a).\nThus, if Algorithm 3 does not output an edge α∈CH(A)then there must exist two\nconsecutive edges (γ,g)onCH(A)with the following property: for all edges γ′ofCH(A)\npreceding and including γ,− →γ′intersectsw(β,b), and, for all edges g′ofCH(A)succeeding\nan including g,← −gintersectsw(β,b). We now make a case distinction.\n\n24 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nIf− →βdoes not intersect CH(A)then by Lemma 15, line(β)separatesCH(A)andCH(B).\nIf← −bdoes not intersect CH(A)then by Lemma 15, line(b)separatesCH(A)andCH(B).\nIf the edge− →βintersectsCH(A)in an edgeγ′that equals or precedes γthen, per definition\nofγ, the halfline− →γ′intersectsw(β,b). It cannot be that− →γ′intersects← −βsinceγ′is\nalready intersected by− →β. And so,− →bintersects− →γ′(Figure 13). In particular, this implies\nthat← −bdoes not intersect line(γ′).\nWe now note that all edges of CH(A)are contained in the halfplane bounded from above\nbyγ′. And so,← −bcannot intersect any edge of CH(A). Lemma 15 guarantees that− →b\ncannot intersect CH(A)and soline(b)separatesCH(A)andCH(B).\nIf the edge← −bintersectsCH(A)in an edgeg′that equals or succeeds gthen it follows by\nsymmetry that line(β)separatesCH(A)andCH(B).\nIt cannot be that− →βintersectsCH(A)on an edge strictly succeeding γandthat← −b\nintersectsCH(A)in an edge strictly preceding g.\nWe showed that Algorithm 3 either outputs a edge αwhereline(α)separatesCH(A)and\nCH(B), or, that either line(β)orline(b)separatesCH(A)orCH(B). ◀\nβ\nb\nγ′\na)\nβ\nb\ng′\nb)\nFigure 13 (a) Letγ′∈CH(A)be an edge where− →γ′intersects− →b. Then← −bdoes not intersect the\nsupporting line of γ′. However, then← −bcannot intersect any edge of CH(A). (b) Letg′∈CH(B)\nbe an edge where← −g′intersects← −β. Then− →βdoes not intersect the supporting line of g′. However,\nthen− →βcannot intersect CH(B).\nA logarithmic-time robust algorithm Algorithms 2 and 3 have a recursive depth of O(logn).\nThus, if each function call takes constant time then these algorithms take O(logn)time. For\nease of exposition, we showed these algorithms using three geometric predicates:\nslope. Given positive segments (α,β), output whether slope (α)<slope (β).\nlies_right . Given two positive segments αandβwith different slopes, output whether\nthe first vertex of βlies right of line(α)∩line(β).\nwedge. Consider a pair of positive segments (β,b)that share a vertex and define w(β,b)\nas the cone formed by their supporting halflines containing (−∞,∞). Given a positive\nsegmentαoutside ofw(β,b), output whether line(α)intersectsw(β,b).\nIn Section 4 we showed, under slightly different notation, that these can be implemented\nas robust, constant-time functions. Thus, we showed:\n▶Theorem 8. LetAandBbe convex chains of edges with slope at least 1, stored in a balanced\nbinary tree on their left-to-right order. There exists an O(logn)time to decide whether there\nexists a line that separates AandB. This algorithm requires only orientation-testing for\nordered triangles and can output a separating line whenever it exists.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 25\nB From a learned index to an indexing structure\nLetSbe a dynamic set of distinct integers in sorted order. Let FSdenote the two-dimensional\npoint set, obtained by mapping each s∈Sto(RANK (s),s).\n▶Definition 17. Letεbe a positive integer. We define a vertical ε-coverFofSas set of\nvertically separated segments with slope at least 1with the following property:\nfor allp∈FS, the vertical line segment with width 2ε, centred at p, intersects a segment\ninF.\nDenote byLthe point set obtained by taking every point in FSand shifting it downwards\nbyε, together with the point (∞,−∞). Denote by Uthe point set obtained by taking every\npoint inFSand shifting it upwards by ε, together with the point (−∞,∞). Then a line ℓis\na verticalε-cover ofSif and only if it separates CH(L)andCH(U). If follows that we may\nimmediately adapt Theorem 11 to the following:\n▶Theorem 18. We can dynamically maintain a vertical ε-coverFofSinO(log2n)worst-\ncase time. We guarantee that there exists no vertical ε-coverF′ofSwith|F|>3\n2|F′|.\nFstores segments from low to high, and we store segments using our segment type:\nsegmentf\nfunctionf the function f(x)that forms the line through start and end\nvaluestart\nvalueend\nsegmentsucc the segment f′inFwith the minimal start value greater than end\nWe assume that all segments in Fare maintained in a balanced binary tree B(F), where\nsegments are ordered by f.start.\nB.1 Defining our data structure\nWe combine the dynamic vertical ε-coverFwith a dynamic data structure to perform\nindexing queries. Interestingly, our data structure is independent of F. The core of our data\nstructure is our value type:\nvaluev\nintv corresponding to a unique v∈S\nintid=⌊v\nε⌋.\nAll values are stored in a page:\nvectorAis a dynamic vector that stores all non-empty pages in arbitrary order.\npagep\nintp where∃v∈Vwithp=v.id\nvector<value>values storing allv∈Vwithp=v.idin sorted order\nintprev the index in Aof the maximum p′∈Awithp′<p\nintsucc the index in Aof the minimum p′′∈Awithp<p′′\nH:int→intis a hash map that for any ID preturns the index isuch thatp=A[i].\n\n26 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nB.2 Answering queries using our data structure\nGiven this data structure, we first show how to support memberand queries (Algorithm 4).\nThen, we show how to answer predecessor and rankqueries 6. Finally, we show how to\nanswer rangequeries.\n▶Lemma 19. Our data structure supports memberqueries inO(ε)time.\nProof.UsingH, Algorithm 4 may access the page pcontaining all values v′withv′.id=\nv.id in constant time. Since all values in Sare distinct, this page contains at most εvalues\nand so the lemma follows. ◀\nAlgorithm 4 member(valuev)\ni←H(⌊v\nε⌋)\nreturnA[i].values.contains( v)\n▶Lemma 20. Our data structure supports rankandpredecessor queries inO(ε+log|F|)\ntime.\nProof.Consider first the special case where vis smaller than all values in S. Then its rank\nis equal to 0and its predecessor is the first element of S.\nOtherwise, let f∈Fsuch thatvis greater than f.start, but less that the start of the\nsuccessor of finF(in the special case where fis the last segment in F, we always say that\nvis less than the start of its successor).\nWe again consider a special case, where vexceeds the value at the end of f. In this\ncase, the horizontal line through vlies in between fand its successor in F. The predecessor\nofvmust therefore be the last value in f. This value is stored in the page patA[i]for\ni=H(f.end.id ). The rank of vis then the rank of its predecessor.\nIf no special case applies then the predecessor sofvhas a rank r=⌊f−1(v)⌋. We\nwant to find the index isuch thatA[i]stores the page pcontaining v. Consider the point\n(r,b) := (r,f(r)). Per definition of a vertical ε-cover, the point (r,s)∈FScorresponding to\nthe predecessor sofvlies within vertical distance εof(r,b). It follows that:\ns.id=/floorleftbiggb−ε\nε/floorrightbigg\nor/floorleftbiggb\nε/floorrightbigg\nor/floorleftbiggb+ε\nε/floorrightbigg\n⇒i=H/parenleftig/floorleftigv\nε/floorrightig\n−1/parenrightig\norH/parenleftig/floorleftigv\nε/floorrightig/parenrightig\norH/parenleftig/floorleftigv\nε/floorrightig\n+ 1/parenrightig\nWe check in constant time which iwe need to choose. We index A[i]to find the page\ncontainings. We then iterate over all values in that page to find s. ◀\n▶Lemma 21. Our data structure supports rangequeries inO(k+ε+log|F|)time where k\ndenotes the output size.\nProof.Given two values uandvwithu < v, we find the predecessors A[i].values[j] and\nA[i′].values[j′] ofuandvinO(k+ log|F|)time.\nEach page pcontains all values in the range [εp,εp +ε−1]in sorted order so within a\npage we can output all values in the range in output-sensitive time. Recall that a page p\nstores the integers s,rwhereA[s]is the page preceding pandA[r]is the page succeeding pin\ntheir sorted order. So we simply iterate over this doubly linked list implementation, iterate\nover all values in these pages to output the range S∩[u,v]in output-sensitive time. ◀\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 27\nAlgorithm 5 index(intv)\n(a,b,c )←(H(⌊v\nε⌋−1),H(⌊v\nε⌋),H(⌊v\nε⌋) + 1)\nreturnargmin{|A[a].values.first−v|,|A[b].values.first−v|,|A[c].values.first−v|}\nAlgorithm 6 predecessor (valuev,B(F))\nifv< F.first.start then\nreturn (0,0)\nend if\nf←segment in Fwherev≥f.start andv<f.succ.start\nifv≥f.endthen\ni=H(f.end.id )\nelse\ni=index (f(⌊f−1(v)⌋))\nend if\nj=A[i].values.size()−1\nwhileA[i].values [j]>vdo\ndecrementj\nend while\nreturn (i,j)\nAlgorithm 7 range(valueu,valuev,B(F))\n(i,j)←predecessor (u,B(F))\n(i′,j′)←predecessor (v,B(F))\nifi=i′then\nreport (A[i].values [j+ 1,j′+ 1])\nelse\nreport (A[i].values [j+ 1,A[i].values.size() ])\nk←A[i].succ\nwhileA[k]<A[i′]do\nreport (A[k].values )\nk←A[k].succ\nend while\nreport (A[i′].values [1,j′+ 1])\nend if\nB.3 Updating our data structure\n▶Lemma 22. Letvbe a value inU. Given predecessor (v), we may update our data\nstructure in O(ε)time.\nProof.Algorithms 8 and 10 show how to insert values into and delete values from S\nrespectively. Let (i,j)be such that A[i].values[j] is the predecessor of v. For insertions, we\nconsider three cases. In the first case, A[i] =v.id. Thenvneeds to be inserted into the page\natA[i], succeeding v′=A[i].values[j]. We achieve this in O(ε)time by first appending v\ntoA[i].values, and then swapping vwith its predecessor in the vector until it is incident\ntov′. In the second case, A[i]< v.id but the successor page of A[i]matchesv.id. We\nobtain this successor by indexing A[A[i].succ ]and then insert vinto the values vector in the\n\n28 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nsame way. Finally, it may be that there exists no page p∈Awherep=v.id. We create a\nnew page, append it to A, add it to the hash map and insert it into our doubly linked list\nimplementation. Deletions are handled analogously. ◀\nAnd so, we may conclude:\n▶Theorem 23. For anyε, there exists a data structure to dynamically maintain a vertical\nε-coverFof a dynamic set of distinct integers in O(ε+log2n)time. We guarantee that\nthere exists no vertical ε-coverF′with|F|>3\n2|F′|. The data structure supports indexing\nqueries inO(ε+log|F|)expected time and range queries in additional O(k)time where kis\nthe output size.\nAlgorithm 8 insert( valuev,B(F))\n(i,j)←predecessor (v,B(F))\nifA[i] =v.idthen\ninsert_into_page (i,v)\nelse ifA[A[i].succ ] =v.idthen\ninsert_into_page (A[i].succ,v)\nelse\ni′←A.size()\npagep←new page (v)\np.prev←P[i]\np.succ←P[i].succ\nA[p.prev ].succ←i′\nA[p.succ ].prev←i′\nA[i′]←p\nH.insert(v.id,i′)\nend if\nAlgorithm 9 insert_into_page (inti,valuev)\nj=A.values.size()\nA.values [j]←v\nwhilej >0andA[i].values [j−1]>A[i].values [j]do\nA[i].values.Swap( j−1,j)\ndecrementj\nend while\nAlgorithm 10 delete(valuev,B(F))\n(i,j)←predecessor (v,B(F))\nifA[i] =v.idthen\ndelete_from_page (i,j+ 1,v)\nelse\ndelete_from_page (A[i].succ, 0,v)\nend if\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 29\nAlgorithm 11 delete_from_page (inti,intj,valuev)\nifA[i].values [j] ==vthen\nfort∈[j,A[i].values.size()−1]do\nA[i].values.Swap( t,t+ 1)\nend for\nA[i].reduce()\nend if\nifA[i].values.size() = 0then\nA[A[i].prev ].succ←A[i].succ\nA[A[i].succ ].prev←A[i].prev\nA.Swap(i,A.size()−1)\nH.insert(A[i],i)\nH.delete (v.id,i)\nend if\nC Remarks on computing a PGM-index or ε-cover\nWe briefly note that Ferragina and Vinciguerra [ 17] wrongfully claim that the algorithm by\nO’Rourke [ 30] computes a PGM-index of minimum complexity. In [ 30], O’Rourke considers\nthe following problem (we flip the xandy-axis to align with [17])\nThe input is a set of data ranges , i.e., horizontal segments in the place, sorted by y-\ncoordinate. The goal is to compute a y-monotone polyline that intersects all data ranges.\nO’Rourke assumes a streaming setting, which adds horizontal segments in sorted order from\nlow to high. This algorithm maintains a line segment from pthat stabs allreceived horizontal\nsegments. The algorithm tests after an insertion whether such a segment still exists. If not,\nit outputs the previous line segment and deletes all horizontal segments (apart from the\ncurrent insertion). This algorithm exists in a streaming setting. However, [ 17] is a normal\nstatic setting where this algorithm is not optimal!\nThe algorithm by O’Rourke can maintain a horizontal ε-cover in the following way: for\neach insertion into G, test whether there exists a segments intersecting all segments in G. If\nthere does not exist such a segment, output the previous segment and delete all segments\nfromG(apart from the segment that was just inserted). This algorithm is also not optimal\nin a static setting, as a similar adversarial input can be constructed. However, it can easily\nbe shown that this algorithm is a3\n2approximation:\nIndeed, this algorithm maintains the invariant that for all consecutive segments λ,λ′\nin the output, the input Icorresponding to these segments is blocked. I.e., there exists no\nsegmentλ∗that intersects all segments in I. This implies that for any three consecutive\nsegments in the output, any other algorithm must include at least two segments and so a3\n2\napproximation follows.\n\n30 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nD Additional Experiments\nWe here describe our full suite of experiments, including additional real world datasets and\nvariations of the experiments shown in Section 7. We’ve used the following datasets, each\nconsisting of unique 8 byte integers in randomly shuffled order:\nLINES is a synthetic data set of 5M integers that, in rank space, produces 5 lines of\nexponentially increasing slope. This set models the ideal scenario for a PGM index.\nLONGITUDE is a real world data set that contains the longitudes of roughly 246M\npoints of interest from OpenStreetMap, over the region of Italy. This data is thereby\ninherently of geometric nature. This data set was used in both [ 17] and [22]. We follow [ 17]\nand convert the data to integers by removing the decimal point from the raw longitudes.\nUNIForiginates from [ 17]. It is a synthetic data set, containing a uniform random\nsample of 50M integers from (0,1011). We adapt this data set to our dynamic setting.\nDRIFTER isarealworlddataset, containingroughly1.7Mstepsofaccumulateddistance\ntravelled by ocean drifters tracked through GPS. Used previously as a subtrajectory\nclustering benchmark [8].\nBOOK, from [28], contains Amazon book sale popularity data. It was used in a\nbenchmarking paper on learned indices [ 22]. We use a truncated sample of 100M integers.\nBERLIN, CHICAGO , datasets each containing roughly 150.000GPS samples from\ncar traffic in these cities. Used often as benchmarks for road map construction [ 1]. We\nuse the accumulated distance travelled as input.\nTIMESERIES , from [27], contains a concatenation of 15.000steps of time series from\nvarious real world domains. Originally used as part of the M4 forecasting competition.\nD.1 Learned index complexity\nAs a measure of the complexity of the learned indices, we count the number of lines stored in\nthe structures during construction. In Figure 14 the measurements across all our data can be\nseen. As the data arrives shuffled, even if the total data set has some underlying structure, it\nmight not come to light until more data arrives. This is easily seen on the synthetic Lines\ndata, where the structure starts decreasing in complexity roughly halfway for the dynamic\nPGM. Since the logarithmic PGM has the data split across buckets, the complexity grows\nuntil close to the end where there is a sudden drop.\nAlthough geometric in nature, obtained as accumulated distances travelled, the Drifter ,\nBerlin, and Chicago data sets do not show trends that indicate favorable conditions for\nthe examined learned indices.\nD.2 Maintaining an indexing data structure\nHere we show the full results from varying query ratio and prior deletion ratio on all of the\ndatasets described above.\nThe learned index. When measuring the running times of maintaining the learned index,\nthe key observation is that the smaller structured datasets Drifter ,Berlin, and Chicago\nhave much closer performance than the larger Longitude data. As is the case also on the\nunstructured data, the performance penalties incurred by the poor memory access patterns\nof the convex hull data structures becomes increasingly prohibitive once data surpasses a\ncertain size.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 31\nFigure 14 The number of lines stored in the learned indices, insertion only.\n\n32 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nFigure 15 Update times for maintaining the learned index dynamically.\nFigure 16 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonLongitude data\nThe indexing data structure. For the larger datasets, Longitude ,Unif, and Book, we\nsee some interesting trends. Longitude is the only structured large set, where we see\nan increase of performance from the dynamic PGM as query ratio increases, whereas it\ndecreases for the logarithmic PGM. In the unstructured cases, both structures occur more\ntime spent for larger query ratios. For the smaller datasets, performance is almost identical.\nThe overhead associated with maintaining the learned index becomes much smaller, since it\ncan now be manipulated with less bad effects on cache. Still, memory access is the deciding\nfactor, and for many cases the logarithmic PGM comes out on top.\nAs we increase the number of previous deletions, the gap in performance between indexing\nstructures lessens. This somewhat ties into the previous notes on memory, but we also see\nthat for the larger query ratios performance evens out, with the dynamic PGM only a sliver\nfrom the logarithmic PGM on structured data.\nThe adversarial scenario is taking the above to its extreme, and the dynamic then\noutperforms the logarithmic on all data.\n\nE. T. Gæde, I. van der Hoog, E. Rotenberg, and T. Stordalen 33\nFigure 17 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonUnifdata\nFigure 18 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonDrifter data\nFigure 19 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonBookdata\nFigure 20 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonBerlindata\n\n34 A Dynamic Piecewise-linear Geometric Index with Worst-case Guarantees\nFigure 21 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonChicago data\nFigure 22 Time per operation in dynamic scenario with varying query ratio and prior deletions\nonTimeseries data",
  "textLength": 83497
}