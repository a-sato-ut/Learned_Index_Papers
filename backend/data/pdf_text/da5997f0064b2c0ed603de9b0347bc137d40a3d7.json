{
  "paperId": "da5997f0064b2c0ed603de9b0347bc137d40a3d7",
  "title": "Querying in Constant Expected Time with Learned Indexes",
  "pdfPath": "da5997f0064b2c0ed603de9b0347bc137d40a3d7.pdf",
  "text": "Querying in Constant Expected Time with Learned\nIndexes\nLuis Alberto Croquevielle /envel⌢pe/orcid\nImperial College London\nGuang Yang /envel⌢pe/orcid\nImperial College London\nLiang Liang /envel⌢pe/orcid\nImperial College London\nAli Hadian /envel⌢pe/orcid\nImperial College London\nThomas Heinis /envel⌢pe/orcid\nImperial College London\nAbstract\nLearned indexes leverage machine learning models to accelerate query answering in databases,\nshowing impressive practical performance. However, theoretical understanding of these methods\nremains incomplete. Existing research suggests that learned indexes have superior asymptotic\ncomplexity compared to their non-learned counterparts, but these findings have been established\nunder restrictive probabilistic assumptions. Specifically, for a sorted array with nelements, it has\nbeen shown that learned indexes can find a key in O(log(logn))expected time using at most linear\nspace, compared with O(logn)for non-learned methods.\nIn this work, we prove O(1)expected time can be achieved with at most linear space, thereby\nestablishing the tightest upper bound so far for the time complexity of an asymptotically optimal\nlearned index. Notably, we use weaker probabilistic assumptions than prior research, meaning our\nwork generalizes previous results. Furthermore, we introduce a new measure of statistical complexity\nfor data. This metric exhibits an information-theoretical interpretation and can be estimated in\npractice. This characterization provides further theoretical understanding of learned indexes, by\nhelping to explain why some datasets seem to be particularly challenging for these methods.\n2012 ACM Subject Classification Theory of computation →Predecessor queries\nKeywords and phrases Learned Indexes, Expected Time, Stochastic Processes, Rényi Entropy.\nDigital Object Identifier 10.4230/LIPIcs...\n1 Introduction\nQuery answering is of central importance in database systems, and developing efficient\nalgorithms for this task is a key research problem. These algorithms often use an index\nstructure to access records faster, at the cost of higher space usage to store the index.\nArguably, the most common scenario in query answering involves point queries, where the\naim is to retrieve all tuples where an attribute has an exact value [ 12,21]. Also common are\nrange queries, which ask for all tuples where an attribute is within a given interval.\nSolutions based on hash tables can answer point queries efficiently [ 5], but are ineffective\nin handling range queries. To generalize well to these cases, the relevant attribute is usually\nstored as a sorted array A. In this configuration, answering point and range queries essentially\ncomes down to finding an element in a sorted array. A point query for value qcan be answered\nby finding the position of qin the array if it exists. A range query matching an interval [q,q′]\ncan be answered by finding the first element bigger than or equal to q, and then scanning\nthe arrayAfrom that position until an element greater than q′is found, or the array ends.\n©Author: Please provide a copyright holder;\nlicensed under Creative Commons License CC-BY 4.0\nLeibniz International Proceedings in Informatics\nSchloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, GermanyarXiv:2405.03851v4  [cs.DB]  22 Oct 2024\n\nXX:2 Querying in Constant Expected Time with Learned Indexes\nModel\nCorrection\nPrediction\ny \n= \nr(x)\n0\n1\n5\n6\n7\n9\n10\n30\n31\n33\nPrediction\nCorrection\nLookup \nKey\n \n= \n10\nKeys\nPositionA\nError\nline \nof \nbest \nfit\nFigure 1 Predictive and corrective steps of a learned index.\nSince the array Ais sorted, binary search can be used to find qor the first element greater\nthanq. IfAhasnelements (also called keys), binary search takes O(logn)operations. This\nis asymptotically optimal in a random-access machine (RAM) model of computation, for\ncomparison-based searching [ 17]. However, other index structures such as B+Trees [ 13,19]\nare preferred in practice. They have the same asymptotic complexity but make use of\nhardware properties to improve performance.\nIt was suggested in [ 18] that classical index structures can be understood as models that\ntake a key as an input and predict its position in the sorted array. From this perspective,\nindexes such as B+Tree are potentially suboptimal because they do not take advantage of\npatterns in the data to improve performance. This has led to the introduction of learned\nindexes [18,16,7,9,11], which use machine learning models to predict the position of a key.\nLearned indexes usually combine predictive and corrective steps, as illustrated in Figure\n1. In the predictive step, a machine learning model is used to estimate the position of a key.\nSince this estimation may be wrong, a corrective step finds the exact position. Usually, this is\ndone by searching around the position estimated by the model. Intuitively, the improvement\nin performance comes from searching over a small range, determined by the prediction error,\nrather than searching over the whole array. Hence, if the prediction error is small, a learned\nindex can in principle improve upon classical methods. Most learned indexes use simple\nmachine learning models, such as piecewise linear functions, which are fast to compute.\nWhile learned indexes exhibit impressive experimental performance [ 7,11,14,16], their\ntheoretical understanding is still at an early stage. Existing research shows that specific\nlearned indexes can achieve better asymptotic space or time complexity than traditional\nstructures [ 35,8], but these results rely on disparate and potentially restrictive assumptions.\nFurthermore, some datasets are notoriously challenging for learned indexes [ 24], and no\ntheoretical analysis has yet offered an adequate explanation for this.\nIn this work, we analyze the asymptotic expected complexity of learned indexes. Specific-\nally, we prove that learned indexes can achieve constant expected query time with at most\nlinear space, constituting the best upper bound so far for the performance of an asymptotic-\nally optimal learned index. Our proof is constructive, meaning we provide a specific index\nthat achieves this complexity. This type of index has been considered before [ 35], but we\ncontribute tighter complexity bounds than previously available. Compared to prior research,\nour complexity bounds hold under a more general probabilistic model, and in particular, our\nresults do not require any independence assumptions for the data generating process.\nWe also address the question of why certain datasets are challenging for learned indexes.\nIt has been suggested that, in those cases, the data distribution is inherently hard to learn [ 24],\nand several metrics have been proposed to capture this difficulty [ 35,8,33]. We introduce\na new measure of data complexity ρfwith better mathematical properties. Our metric is\nrelated to Rényi entropy in information theory, helping to provide a theoretical grounding\n\nAuthors XX:3\nforρf. Also,ρfcan be statistically estimated, making it potentially useful in practice to\npredicta priorihow well a learned index will perform. Our experiments support this idea.\n2 Preliminaries\n2.1 Data\nLearned indexes use statistical models. Therefore, theoretical analysis of learned indexes is\ndone under a probabilistic model of some kind [ 35,8]. In general, keys are assumed to come\nfrom a data generating process with specified properties. For instance, in [ 35] it is assumed\nthat the keys are independent and identically distributed, while [ 8] uses a completely different\nmodel. We strive to generalize the probabilistic setting as much as possible.\nFormally, we model a database attribute Xas a stochastic process X={Xi}i∈N. We\nassume all random variables Xihave the same cumulative distribution function F. For any\ntimen∈N, we can observe the data X1,X2,...,Xngenerated so far. Sorting the {Xi}n\ni=1\ngives rise to a new set of random variables, usually called the order statistics [6], which we\ndenoteX(1),X(2),...,X (n). We consider the sorted array Aat timento be formed by this\nlast group of random variables, such that A[i] =X(i)for alli= 1,...,n. Duplicate keys are\npossible in principle, and do not constitute a problem. In that case, X(i+1)=X(i)for somei\nand all analysis remains the same.\nThat way, in our setting a stochastic process generates the data in attribute X. For each\nn∈N, there is a sorted array Awith the first nkeys from this process, and a learned index\ncan be built to search this array. For now, we do not assume anything about F. Also, we\ndo not assume independence of the {Xi}n\ni=1variables. In Sections 3 and 4, we analyze our\nresults under certain probabilistic assumptions. In Section 5, we compare our model and\nresults to those of prior work.\n2.2 Learning Problem\nAssume array Ahasnkeys. The learning problem can be formalized by the introduction of\narankfunction. For any number q∈R,rankA(q)is defined as the number of elements in\nAthat are smaller than or equal to q, that is\nrankA(q) =n/summationdisplay\ni=11X(i)≤q,\nwhere 1is the indicator function. We omit the subscript Aif it is clear from context. For a\npoint query with value q,rank (q)gives the position of qin the array if it exists. For a range\nquery matching an interval [q,q′], the relevant records are found by scanning the array A,\nstarting at position rank (q)and ending when an element greater than q′is found. Since\nrankis sufficient to answer these queries, we focus on the problem of learning the rank\nfunction under specific probabilistic assumptions.\n2.3 Model of Computation\nThe model of computation we use is the Random Access Machine (RAM) under the uniform\ncost criterion [ 1]. In this model, each instruction requires one unit of time and each register\n(storing an arbitrary integer) uses one unit of space. This is in contrast to part of the existing\nliterature. In [ 35] the computation model is such that O(logn)space units are needed to\nstore an integer n. On the other hand, in [ 8] an I/O model of computation is used [ 20], which\n\nXX:4 Querying in Constant Expected Time with Learned Indexes\nassumes the existence of an external memory (e.g., disk) from which data is read and written\nto. Under this model, time complexity consists only of the number of I/O operations.\nWe argue the RAM model under the uniform cost criterion is better suited for analysing\nlearned indexes than either of these two. On the one hand, numbers are usually represented\nas data types with a fixed number of bits (e.g., long int in C++). On the other hand, most\nlearned indexes work in main memory and avoid the use of disk storage. To make results\ncomparable, in Section 5 we restate all previous complexity results using our RAM model.\nRegardingspacecomplexity, wetakethestandardapproachofonlycountingtheredundant\nspace introduced by the index, and not the space necessary to store the array Ain the first\nplace [9]. Regarding time complexity, we do not consider the time needed to train the model,\njust for finding the keys. We focus the asymptotic analysis on expected time, where the\nexpectation is taken over the realizations of the stochastic process and the choice of query.\nFor anyn∈N, letRnbe a procedure that takes the sorted array A= [X(1),...,X (n)]as\ninput, and outputs an index structure Rn(A). Denote by S(Rn(A))the space overhead of\nRn(A). Also, for any q∈Rdenote byT(Rn(A),q)the query time for qover arrayAwhen\nusing the index Rn(A). We are interested in bounds for SandTthat do not depend on A\norq. With that in mind, we denote\nSn= sup\nA=[X(1),...,X (n)]S(Rn(A)),Tn=E[T(Rn(A),q)],\nwhere Edenotes expected value. In Section 3.1 we state asymptotic results for SnandTn.\n3 Main Results and ESPC Index\n3.1 Complexity Bounds\nWe mentioned above that all the Xishare the same cumulative distribution function.\nFormally, we consider that the Xiare defined in a probability space (Ω,F,P), such that\nFXi(x):=P(Xi≤x)is the same for all i, and is denoted by F. Now, assume Fcan be\ncharacterized by a square-integrable density function fand defineρfas:\nρf=∥f∥2\n2=/integraldisplay\nRf2(x)dx.\nMoreover, assume fhas bounded support [a,b], that is,f(x) = 0for allx /∈[a,b]. This can\nbe a reasonable assumption in many practical applications [ 22,23] where there are known\nbounds to the values of data: for instance, for storing medical information such as test\nresults, or personal financial information. Our results can be extended to the case of fwith\nunbounded support, by incurring a penalty on space usage. In Section 4.3.2 we show how\nthis penalty relates to the tails of the probability distribution.\nThe main complexity results are stated in Theorems 1 and 2. Both are attained by the\nESPC index, which we introduce in Section 3.2. Both theorems as stated here assume\nthat the query parameter follows the same probability distribution as the keys. This is done\nfor ease of presentation. In Section 4.3.1 we prove that these results can be generalized to\ninclude the case when that assumption does not hold.\n▶Theorem 1. Supposefhas support [a,b]andρf<∞. Defineρ=log/parenleftbig\n(b−a)ρf/parenrightbig\n. Then,\nthere is a procedure Rnfor building learned indexes such that Sn=O(n)andTn=O(ρ).\nThat is, for array Awithnkeys an index can be built with space overhead O(n)and expected\nquery time O(ρ). Sinceρis independent of n, expected time is asymptotically O(1).\n▶Theorem 2. Supposefhas support [a,b]andρf<∞. Defineρ=log/parenleftbig\n(b−a)ρf/parenrightbig\n.\nThen, there is a procedure Rnfor building learned indexes such that Sn=O/parenleftbign\nlogn/parenrightbig\nand\n\nAuthors XX:5\ny \n= \nr\n3\n(x)\ny \n= \nr\n4\n(x)\ny \n= \nr\n2\n(x)\ny \n= \nr\n1\n(x)\n RankKeys\n   \nConstant \nApproximator\n   \nPartition \nLine\n   \nRank \nFunction\nFigure 2 Partition of key range into four equal-length intervals, with approximator of rank.\nTn=O(ρ+log(logn))). That is, for array Awithnkeys an index can be built with space\noverheadO/parenleftbign\nlogn/parenrightbig\nand expected query time O(ρ+log(logn)). Sinceρis independent of n,\nexpected time is asymptotically O(log(logn)).\nWe prove Theorems 1 and 2 in Appendix B, as corollaries of a more general result.\n3.2 Equal-Split Piecewise Constant Index\nAll complexity results in Section 3.1 are achieved by the Equal-Split Piecewise Constant\n(ESPC) index, which we now describe. As explained in Section 1, learned indexes usually\ncombine predictive and corrective steps. The ESPC index follows this idea, and is remarkably\nsimple to define and implement. It is important to mention that a similar design, the PCA\nIndex, was analyzed in [ 35], but the complexity bounds we prove for this type of index are\ntighter and more general. Moreover, there are some design differences. First, the ESPC index\nuses exponential search for the corrective step, while the PCA Index uses binary search. More\nimportantly, the PCA Index presumes knowledge of the interval [a,b]where the distribution\nis supported, a potentially restrictive assumption that we dispense with for the ESPC index.\nThe general idea is to learn a function ˆ rto approximate the rankfunction up to some\nerror. Then rankcan be computed exactly by first evaluating ˆ rand then correcting the\nerror by use of an exponential search algorithm [ 2]. If the prediction error is small, this\ngives a procedure for computing rankexactly in low expected time. The approximator\nfunction ˆ ris built as a piecewise constant function defined over equal-length subintervals.\nThis equal-length property ensures that ˆ rcan be evaluated in constant time.\nWe now describe how the approximator ˆ ris defined. Take an array Aformed by the\nsorted keys X(1),...,X (n). For a positive integer K, divide the range [X(1),X(n)]intoK\nsubintervals of equal length, which we denote by {Ik}K\nk=1. Figure 2 illustrates this type of\npartition for a dataset with 40 keys and K= 4. Formally, for each k= 1,...,Kthek-th\nsubinterval is defined as Ik= [tk−1,tk]where\ntk=X(1)+kδwithδ=X(n)−X(1)\nK.\nNotice that all intervals have the same length, but not necessarily the same number of\nkeys. Now, we want ˆ rto be defined as a piecewise constant function. If q∈Rdoes not belong\nto anyIk, this means that either q<X (1)orq>X (n), so that rank (q) = 0orrank (q) =n,\nrespectively. On the other hand, for each subinterval Ikthe ESPC index stores a constant\n\nXX:6 Querying in Constant Expected Time with Learned Indexes\nvalue ˆrkwhich approximates rankoverIk. Combining these ideas, we define ˆ ras\nˆ r(q) =\n\n0ifq<X (1)\nˆr1ifq∈I1...\nˆrKifq∈IK\nnifq>X (n).\nFigure 2 represents this type of piecewise approximator over equal-length subintervals. It\nremains to define the {ˆrk}K\nk=1values. Since rankis an increasing function, for all q∈Ikit\nholds rank (tk−1)≤rank (q)≤rank (tk). This motivates a candidate for ˆrkin the form of\nˆrk=1\n2(rank (tk−1) +rank (tk)) =rank (tk−1) +nk\n2,\nwherenk=rank (tk)−rank (tk−1)is the number of keys in Ik. As we prove in Section 4.1,\nthis means that ˆrkcan approximate rank (q)for anyq∈Ikwith error at most nk/2, so that\nthe quality of ˆ ras an approximator depends on the expected number of keys per interval.\nAlgorithm 1 details the index construction, based on our definitions for {Ik}and{ˆrk}.\nAlgorithm 1 Construction of ESPC index\nInput:Sorted array A, positive integer K\nOutput: ESPC index for AwithKequal-length subintervals\n1.n←length (A)\n2.δ←(X(n)−X(1))/K\n3.N←array of length Kwith all zeros\n4.// Compute number of keys in each subinterval, store in N\n5.fori= 1tondo\n6.k←/ceilingleftbig1\nδ(A[i]−X(1))/ceilingrightbig\n7.N[k]←N[k] + 1\nend\n8.r←array of length K\n9.r[1]←1\n2N[1]\n10.// Compute rank estimator ˆrkfor each subinterval, store in r\n11.fork= 2toKdor[k]←r[k−1] +1\n2N[k];\n12.returnR= (r,δ)\nThe approximator ˆ rcan be evaluated in constant time for any q∈R. Ifq<X (1)then\nˆ r(q) = 0, and ifq>X (n)thenˆ r(q) =n. If neither is true, then qbelongs to some interval\nIk. In that case, ˆ r(q) =ˆrkwherekis given by k=/ceilingleftig\nKq−X(1)\nX(n)−X(1)/ceilingrightig\n=/ceilingleftbig1\nδ(q−X(1))/ceilingrightbig\n.To find\nrank (q)exactly, the ESPC index then performs an exponential search on array Aaround\nposition⌈ˆ r(q)⌉. We prove in Section 4 that the expected value of the approximation error\n|rank (q)−ˆ r(q)|is low enough to establish the results of Section 3.1. Algorithm 2 formalizes\nthis evaluation process. It assumes the existence of a procedure ExponentialSearch (A,i,q )\nwhich uses exponential search around index ito find the position of qin arrayA. Ifqis not\ninA, it returns the position of the greatest key lower than q.\n\nAuthors XX:7\nAlgorithm 2 Evaluation of ESPC index\nInput:Sorted array A,q∈R, ESPC index R= (r,δ)\nOutput: Exact value of rank (q)\n1.ifq<X (1)then return 0;\n2.else ifq>X (n)then return n;\n3.else\n4.k←/ceilingleftbig1\nδ(q−X(1))/ceilingrightbig\n5.i←⌈r[k]⌉\n6. return ExponentialSearch (A,i,q )\nend\n4 Complexity Proofs and Analysis\n4.1 Preliminary Results\nWe now turn to an analysis of the space and time complexity of the ESPC index. In the\nfollowing, assume the sorted array Ahasnelements and the index is built with Ksubintervals\n{Ik}K\nk=1. As seen from Algorithm 1, an ESPC index can be represented as a tuple R= (r,δ)\nwhereris an array of length Kstoring the approximators {ˆrk}K\nk=1andδis the length of\nthe subintervals. For q∈Rrecall that ˆ r(q)is the approximation for rank (q)before the\nexponential search (see Algorithm 2).\nIn the RAM model with the uniform cost criterion, each stored value uses 1unit of space.\nHence, the space used to store an ESPC index R= (r,δ)isO(K). Additionally, as seen from\nAlgorithm 2, the evaluation for any q∈Rtakes constant time, plus the exponential search.\nAn exponential search takes time O(2logε) =O(logε)[2], whereεis the difference between\nthe starting position and the correct position. This is summarized in the following result.\n▶Proposition 3. LetAbe a sorted array with nentries, and Rbe an ESPC index for A\nwithKsubintervals. Then, RusesO(K)space and given q∈R, the ESPC index Rcan be\nused to find rank (q)inO(logε)time, where ε=|rank (q)−ˆ r(q)|.\nIn light of Proposition 3, a way to estimate the time complexity of the ESPC index is\nto bound the expected value of εas a function of K. Hence, our focus is on finding an\nexpression for the approximation error ε=|rank (q)−ˆ r(q)|. We start with the following\nresult, which was mentioned in passing in Section 3.2.\n▶Lemma 4. Letk∈{1,...,K}andq∈Ik. Then, it holds that |rank (q)−ˆ r(q)|≤nk/2\nwherenkis the number of keys that fall on interval Ik.\nThe proof is straightforward and is deferred to Appendix A. We now introduce the\nremaining necessary notation. First, notice that if fhas bounded support [a,b], then with\nprobability 1it holds that [X(1),X(n)]⊆[a,b]. Now, for a given Kwe can define a set of\nsubintervals{Jk}K\nk=1that partition the interval [a,b]intoKequal-length parts, similarly to\nhow the{Ik}K\nk=1form a partition of [X(1),X(n)]. See Figure 3 for an illustration with K= 3.\nFrom this definition, it may be the case that some Ikis not entirely contained within just\noneJkinterval, as Figure 3 illustrates for the case of I2. Notice however that if this happens,\nthenIkmust be contained in the union of two consecutive Jkintervals, as exemplified by\nI2⊆J1∪J2in Figure 3. We formalize this observation below, which is easily verified.\n\nXX:8 Querying in Constant Expected Time with Learned Indexes\naX(1) X(n)bI1I2I3\nJ1 J2 J3\nFigure 3 Equal-length partitions for [X(1),X(n)](given by{Ik}) and [a,b](given by{Jk}).\n▶Fact 1. Suppose [X(1),X(n)]⊆[a,b]. Takek,ℓ∈{1,...,K}such thatIk∩Jℓ̸=∅.\nThen either Ik⊆Jℓ−1∪JℓorIk⊆Jℓ∪Jℓ+1holds. As a consequence, it also holds that\nIk⊆Jℓ−1∪Jℓ∪Jℓ+1, whereJ0,JK+1are defined as the empty set ∅for completion.\n4.2 Main Probabilistic Bound\nRecapping, by Proposition 3 the ESPC index time complexity for input qdepends on the\napproximation error ε=|rank (q)−ˆ r(q)|. By Lemma 4, the error εcritically depends on\nthe number of keys in the subintervals {Ik}. We now state and prove the key results which\nprovide bounds for the approximation error. As mentioned in Section 3.1, we assume\nthat the density fhas bounded support [a,b]for somea,b∈R. That is,f(x) = 0for any\nx̸∈[a,b]. Our results can be extended to the case of fwith unbounded support by incurring\na penalty in terms of space complexity. Notice that the {Jk}implicitly define a random\nvariable, which models how the {Xi}n\ni=1are distributed among the subintervals. This can\nbe characterized by a parameter (p1,...,pK)wherepk=P(Xi∈Jk). Notice that pkis not\nindexed by ibecause all Xifollow the same distribution. In this context, the core of the\ntime complexity analysis is contained in the following theorem.\n▶Theorem 5. Supposefhas support [a,b]. LetAbe an array consisting of the {Xi}n\ni=1\nsorted in ascending order. Let ˆ rbe the approximator of the ESPC index with Ksubintervals,\nas described in Section 3.2, and denote the approximation error for q∈Rasε(q) =\n|rank (q)−ˆ r(q)|. Then, if the query parameter qhas the same density function fas the\n{Xi}, it holds that E[ε]≤3n\n2/summationtextK\nk=1p2\nk.\nProof.We know that E[ε]=E[E[ε|X1,...,Xn]], by the tower property for conditional\nexpectation. The random nature of the error depends on both the choice of qand the values\nof{Xi}n\ni=1. To see this, recall that the variables X1,...,Xndetermine the value of both\nrankandˆ r. The inner expected value gives\nE[ε|X1,...,Xn] =/integraldisplay\nRε(q)f(q)dq=/integraldisplayX(n)\nX(1)ε(q)f(q)dq,\nwhere the last equality comes from the fact that ε(q) = 0ifq /∈[X(1),X(n)]. Replacing\nε(q) =|rank (q)−ˆ r(q)|and noticing that the {Ik}form a partition of [X(1),X(n)]:\nE[ε|X1,...,Xn] =K/summationdisplay\nk=1/integraldisplay\nIk|rank (q)−ˆ r(q)|f(q)dq≤1\n2K/summationdisplay\nk=1nk/integraldisplay\nIkf(q)dq,\nwherenkis the number of keys in subinterval Ikand we have used Lemma 4 to bound the\nerror within each Ik. Now, denote by nk,ℓthe number of keys in Ik∩Jℓ. Then, we can write\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nk=1/parenleftiggK/summationdisplay\nℓ=1nk,ℓ/parenrightigg/integraldisplay\nIkf(q)dq=1\n2K/summationdisplay\nℓ=1K/summationdisplay\nk=1nk,ℓ/integraldisplay\nIkf(q)dq, (1)\nwhere first we have written nkas/summationtextK\nℓ=1nk,ℓand then we have exchanged the order of\nsummation. Now, denote by L(k)the set ofℓindices such that Ik∩Jℓ̸=∅. Notice that\n\nAuthors XX:9\nnk,ℓ= 0ifℓ /∈L(k). Hence, inequality (1) becomes:\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nℓ=1/summationdisplay\nk:ℓ∈L(k)nk,ℓ/integraldisplay\nIkf(q)dq. (2)\nBy Fact 1 we know that Ik⊆Jℓ−1∪Jℓ∪Jℓ+1for allℓandksuch thatℓ∈L(k). Using the\nnotationpℓ=P(Xi∈Jℓ) =/integraltext\nJℓf(q)dqintroduced above, from inequality (2) we get\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nℓ=1(pℓ−1+pℓ+pℓ+1)/summationdisplay\nk:ℓ∈L(k)nk,ℓ=1\n2K/summationdisplay\nℓ=1(pℓ−1+pℓ+pℓ+1)mℓ,(3)\nwheremℓdenotes the number of keys in Jℓ. Now, applying expected value on both sides\nof inequality (3), we get that E[ε]=E[E[ε|X1,...,Xn]]≤1\n2/summationtextK\nℓ=1(pℓ−1+pℓ+pℓ+1)E[mℓ].\nFurthermore, we have\nE[mℓ] =E/bracketleftiggn/summationdisplay\ni=11Xi∈Jℓ/bracketrightigg\n=n/summationdisplay\ni=1E[1Xi∈Jℓ] =n/summationdisplay\ni=1P(Xi∈Jℓ) =npℓ.\nReplacing in the expression for E[ε], we get the following inequality:\nE[ε]≤1\n2K/summationdisplay\nℓ=1(pℓ−1+pℓ+pℓ+1)E[mℓ] =n\n2K/summationdisplay\nℓ=1(pℓ−1pℓ+p2\nℓ+pℓpℓ+1). (4)\nNow, using Cauchy–Schwarz inequality and the fact that p0=P(Xi∈J0) = 0we get:\nK/summationdisplay\nℓ=1pℓ−1pℓ≤/parenleftiggK/summationdisplay\nℓ=1p2\nℓ−1K/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n=/parenleftiggK−1/summationdisplay\nℓ=1p2\nℓK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n≤/parenleftiggK/summationdisplay\nℓ=1p2\nℓK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n=K/summationdisplay\nℓ=1p2\nℓ.\nSimilarly, using Cauchy–Schwarz inequality and the fact that p2\nK+1= 0we can show that/summationtextK\nℓ=1pℓpℓ+1≤/summationtextK\nℓ=1p2\nℓ. Finally, applying these inequalities in (4), we get the desired result:\nE[ε]≤n\n2K/summationdisplay\nℓ=1(pℓ−1pℓ+p2\nℓ+pℓpℓ+1)≤n\n2/parenleftiggK/summationdisplay\nℓ=1p2\nℓ+K/summationdisplay\nℓ=1p2\nℓ+K/summationdisplay\nℓ=1p2\nℓ/parenrightigg\n≤3n\n2K/summationdisplay\nℓ=1p2\nℓ.\n◀\nTheorem 5 is the key tool for proving our results, as we show in Section 4.3.\n4.3 Proof of Asymptotic Complexity\nWe now use Theorem 5 to prove the results stated in Section 3.1. For this, we need to relate\nthe error bound in Theorem 5 with ρf=∥f∥2\n2. For this, notice that\np2\nk=/parenleftbigg/integraldisplay\nJkf(x)dx/parenrightbigg2\n≤/parenleftbigg/integraldisplay\nJk1dx/parenrightbigg/parenleftbigg/integraldisplay\nJkf2(x)dx/parenrightbigg\n=|Jk|/integraldisplay\nJkf2(x)dx,\nwhere|Jk|denotes the length of interval Jkand we have used Cauchy-Schwarz inequality to\nbound/parenleftbig/integraltext\nJkf(x)dx/parenrightbig2. Substituting this in the error bound from Theorem 5 and using the\nfact that|Jk|= (b−a)/Kfor allk, we obtain\nE[ε]≤3n\n2K/summationdisplay\nk=1p2\nk≤3n\n2K/summationdisplay\nk=1(b−a)\nK/integraldisplay\nJkf2(x)dx=3(b−a)\n2n\nKK/summationdisplay\nk=1/integraldisplay\nJkf2(x)dx\nSince{Jk}is a partition of [a,b]andfis square-integrable:\nE[ε]≤3(b−a)\n2n\nK/integraldisplayb\naf2(x)dx=3(b−a)\n2n\nK/integraldisplay\nRf2(x)dx=3(b−a)\n2ρfn\nK.\nWe can summarize the main error bound for the ESPC index in the following proposition.\n\nXX:10 Querying in Constant Expected Time with Learned Indexes\n▶Proposition 6. Under the conditions of Theorem 5, and assuming ρf<∞, it holds\nE[ε]≤3(b−a)\n2ρfn\nK.\nThe complexity results from Section 3.1 are proved in Appendix B as corollaries of\nProposition 6. In Sections 4.3.1 and 4.3.2 we discuss two important generalizations of our\nresults. In Section 5, we present further analysis and a comparison to previous results.\n4.3.1 Distribution of query parameter\nAs can be seen from the statement of Theorem 5, we have assumed that qhas the same\nprobability density function fas the{Xi}. We believe this to be a reasonable approximation\nin many contexts, but our analysis can be extended to qotherwise distributed, which\nconstitutes an important generalization with respect to previous work [35].\n▶Proposition 7. Assume the conditions of Theorem 5. Additionally, suppose ρf<∞and\nthat the search parameter qdistributes according to a density function g. Further suppose\nthatgis square-integrable and denote ρg=∥g∥2\n2. Then, it holds that\nE[ε]≤3(b−a)\n2√ρfρgn\nK.\nSee Appendix C for the proof. As can be seen, for the general case where qdoes not\ndistribute according to f, our results have essentially the same form. For ease of presentation,\nall our analyses from this point on assume the case where g=f. By Proposition 7 we know\nthis does not result in any loss of generality. For the case of qotherwise distributed, we\nsubstitute√ρfρgin place ofρf.\n4.3.2 Unbounded support\nProposition 6 can be extended to fwith unbounded support. For a,b∈Rdenote byAa,b\nthe event that [X(1),X(n)]̸⊆[a,b]. Take values of a,bsuch that P(Aa,b)≤1\nlogn. Then, the\nexpected query time is O(E[logε])where the expected value can be written as\nE[logε] =E1+E2whereE1=E/bracketleftbig\nlogε/vextendsingle/vextendsingleAC\na,b/bracketrightbig\nP/parenleftbig\nAC\na,b/parenrightbig\nandE2=E/bracketleftbig\nlogε/vextendsingle/vextendsingleAa,b/bracketrightbig\nP(Aa,b).\nSince the prediction error εcan never exceed n, theE2term can be bounded as\nE2=E/bracketleftbig\nlogε/vextendsingle/vextendsingleAa,b/bracketrightbig\nP(Aa,b)≤logn·P(Aa,b)≤logn·1\nlogn= 1.\nOn the other hand, the event AC\na,bmeans that [X(1),X(n)]⊆[a,b]. This allows us to apply\nJensen’s inequality along with Proposition 6 to get\nE1=E/bracketleftbig\nlogε/vextendsingle/vextendsingleAC\na,b/bracketrightbig\nP/parenleftbig\nAC\na,b/parenrightbig\n≤E/bracketleftbig\nlogε/vextendsingle/vextendsingleAC\na,b/bracketrightbig\n≤logE/bracketleftbig\nε/vextendsingle/vextendsingleAC\na,b/bracketrightbig\n≤log/parenleftbigg3(b−a)\n2ρfn\nK/parenrightbigg\n.\nPutting everything together, this means that expected query time is\nO(E[logε]) =O/parenleftbigg\nlog/parenleftbigg3(b−a)\n2ρfn\nK/parenrightbigg\n+ 1/parenrightbigg\n=O/parenleftig\nlog/parenleftig\n(b−a)ρfn\nK/parenrightig/parenrightig\n. (5)\nHence, time complexity depends on the values of a,bthat guarantee P(Aa,b)≤1\nlogn. These\nvalues depend on how heavy-tailed the distribution is. We propose the following two variations\nof Theorem 1, with other results being available based on different assumptions.\n▶Theorem 8. Suppose the{Xi}have finite mean µand variance σ2, and thatρf<∞. Then,\nthere is a procedure Rnfor building learned indexes with Sn=O/parenleftbig\nn√nlogn/parenrightbig\nandTn=O(ρ),\nwhereρ= log/parenleftbig\n2σρf/parenrightbig\n. Sinceρis independent of n, expected time is asymptotically O(1).\n\nAuthors XX:11\n▶Theorem 9. Supposeρf<∞and that the distribution of the {Xi}is subexponential [ 31],\nmeaning there is a constant C > 0such that P(|Xi|≥x)≤2e−Cxfor allx≥0. Then, there\nis a procedure Rnfor building learned indexes with Sn=O(nlogn)andTn=O(ρ), where\nρ= log/parenleftbig\n4ρf/C/parenrightbig\n. Sinceρis independent of n, expected time is asymptotically O(1).\nBoth Theorems are proved in Appendix D. In particular, Theorem 9 can also be viewed\nas a corollary of Lemma 3.4 in [35], which provides an alternative proof for this result.\n5 Analysis and Benchmarking\nWe now take a closer look at the expected time complexity. Consider an ESPC index with K\nsubintervals for a sorted array Awithnkeys. Then, by Theorem 5 and Jensen’s inequality:\nE[logε]≤logE[ε]≤log/parenleftigg\n3n\n2K/summationdisplay\nk=1p2\nk/parenrightigg\n= log/parenleftbigg3n\n2/parenrightbigg\n+ log/parenleftiggK/summationdisplay\nk=1p2\nk/parenrightigg\n(6)\nwherepk=P/parenleftbig\nXi∈Jk/parenrightbig\n. Recall that (p1,...,pK)constitutes an induced discrete probability\ndistribution, describing the probabilities of the {Xi}falling on the different {Jk}intervals.\n5.1 Analysis of Alternative Index Design\nThe term log/parenleftbig/summationtextK\nk=1p2\nk/parenrightbig\nis related to a notion of entropy and is minimized when (p1,...,pK)\nisauniformdistribution(seeSection5.2). Hence, wecouldconceivablygetbetterperformance\nby trying to induce pk= 1/Kfor allk. Consider then an alternative design where the\n{Ik}subintervals are defined in such a way that they cover the [a,b]range (instead of the\n[X(1),X(n)]range) and we aim to enforce pk= 1/Kfor allk, rather than an equal-length\ncondition. This requires knowledge of a,b, andF, which we usually lack, but several\nstrategies can be explored to estimate them from the data.\nThis new index design would refine the intervals where we expect data to be more\nconcentrated, which seems to be a reasonable strategy. However, there is a trade-off.\nChoosing the subintervals so that pk= 1/Kmeans that they will not be equal-length, unless\nthe{Xi}distribute uniformly. Consequently, for a given query parameter q, we can no longer\nfind its subinterval in constant time, as we did before with k←/ceilingleftbig1\nδ/parenleftbig\nq−X(1)/parenrightbig/ceilingrightbig\n. This version\nof the index would need a new strategy to find the relevant subinterval Iksuch thatq∈Ik.\nA standard strategy would be to create a new array A′formed by the left endpoints of\nthe{Ik}, that is,A′= [t0,...,tk−1]. Now, for a given search parameter qwe can find the\nrelevantIkwithk=rankA′(q), and then proceed with steps (5) and (6) from Algorithm\n2. Notice that the index is now hierarchical, with A′at the top and A(segmented into the\n{Ik}) at the bottom. From equation (6), expected time at the bottom layer would scale as\nE[logεbot]≤log/parenleftigg\n3n\n2K/summationdisplay\nk=1p2\nk/parenrightigg\n= log/parenleftigg\n3n\n2K/summationdisplay\nk=11\nK2/parenrightigg\n= log/parenleftbigg3n\n2K/parenrightbigg\n.\nOn the other hand, the top layer has Kkeys{t0,...,tk−1}. Since the index is designed\nso thatpk= 1/K, this means F(ti) =i/k. As a consequence, the keys in A′approximately\nfollow distribution F, with a better approximation as K→∞. Suppose we use an ESPC\nindex with K′subintervals to speed up computation of rankA′. By Proposition 6 the\nexpected time at the top layer will be dominated by E[logεtop]≤log (3(b−a)ρfK/(2K′))\nand the total expected time can be bounded as\nE[logεbot] +E[logεtop]≤log/parenleftbigg3n\n2K/parenrightbigg\n+ log/parenleftbigg3(b−a)\n2ρfK\nK′/parenrightbigg\n= log/parenleftbigg9(b−a)\n4ρfn\nK′/parenrightbigg\n.\n\nXX:12 Querying in Constant Expected Time with Learned Indexes\nNotice that (b−a)ρfis still present in this bound. Now, for instance, with K=K′=n\nwe get twice the space usage compared to Theorem 1 and the same asymptotic expected\nquery time. This indicates that asymptotic complexity remains the same for a hierarchical or\ntree-like version of the index, so the basic ESPC index gives a simpler proof for our results.\n5.2 Bounds for Expected Query Time\nComplexity due to number of keys. Equation (6) provides an interesting insight. We see\nthat the expected log-error (and hence, the expected query time) can be decomposed into\ntwo separate sources of complexity. The first is due exclusively to the number of keys n,\nwhich suggests that the query problem gets increasingly difficult when new keys are inserted,\neven if the underlying distribution of the data remains the same. This helps to explain why\nlearned indexes evidence a need for updating [ 34,27] in the face of new keys arriving, even\nwhen the same dataset is used to simulate the initial keys and the subsequent arrivals.\nInformation-theoretical considerations. The sum/summationtextK\nk=1p2\nkis related to the concept of\nRényi entropy [ 25]. For a discrete random variable Pwith possible outcomes 1,...,Kwith\ncorrespondent probabilities {pk}K\nk=1, the Rényi entropy of order αis defined as\nHα(P) =1\n1−αlog/parenleftig/summationtextK\nk=1pα\nk/parenrightig\n.\nforα>0,α̸= 1. The cases α= 0,1,∞are defined as limits, with H1(P)giving the Shannon\nentropy [ 25]. The Rényi entropy can be understood as a generalization of the Shannon\nentropy which preserves most of its properties. Consequently, equation (6) can be written as:\nE[logε]≤log/parenleftbigg3n\n2/parenrightbigg\n−H2(P). (7)\nH2appears in cryptography [ 4,28] due to its relation with the collision probability/summationtextK\nk=1p2\nk,\nand is maximized by the uniform distribution [ 28], that is, when pk= 1/Kfor allk. This\nsuggests that negative entropy might be a good measure of statistical complexity for learned\nindexes, beyond the ESPC index. It captures a notion of distance to the uniform distribution\nU, which is easy to learn for the type of simple models commonly used in learned indexes.\nThis notion of distance can be formalized by writing −H2(P) =D2(P||U)−logK, where\nD2(P||U)is the Rényi divergence of order 2, defined analogously to the KL divergence [ 30].\nCharacterization via the stochastic process. A similar insight can be reached by reference\nto the density function f. By Proposition 6 and Jensen’s inequality, we know\nE[logε]≤log/parenleftig\n(b−a)ρfn\nK/parenrightig\n= logn+ log(b−a)−log(K)−h2(Xi),\nwhere we use hα(X) =1\n1−αlog(∥f∥α\nα)to denote the Rényi entropy for continuous random\nvariables [ 32], similar to how differential entropy is defined in analogy to the Shannon entropy.\nThis last expression provides a useful bound for the expected log-error, by separating the\neffect of the number nof keys, the number Kof subintervals (which represent space usage),\nthe support b−a, and an inherent characteristic h2(Xi)of the stochastic process.\n5.3 Comparison with Existing Methods\nIn this section, we compare our probabilistic model and complexity bounds to previous work.\nAll results are stated in terms of our RAM model. Table 1 summarizes the main points.\n\nAuthors XX:13\nMethod Space Expected timeParameters /\nNotationProbabilistic Model\nB+Tree O/parenleftbign\nb/parenrightbig\nO(logn)Branching\nfactorbNone\nPGM [9] O/parenleftbign\nε2/parenrightbig\nO(logn)Maximum\nerrorεGaps{Xi+1−Xi}i.i.d.\nwith finite mean µand\nvarianceσ2,ε≫σ/µ\nPCA [35] O/parenleftig\nρ1+δn1+δ\n2/parenrightig\nO/parenleftbig\nlog1\nδ/parenrightbig δ>0,\nρ= (b−a)ρ1{Xi}i.i.d. with density f,\nf(x)≤ρ1<∞for allx\nRDA [35] O(ρn) O(log(logn))ρ=ρ1\nρ2Same as PCA Index, plus\n0<ρ2≤f(x)for allx\nESPCO(n)\nO/parenleftbign\nlogn/parenrightbigO(ρ)\nO(ρ+ log(logn))Kintervals,\nρ= log/parenleftbig\n(b−a)ρf/parenrightbigVariables{Xi}have same\ndensityf,ρf=∥f∥2\n2<∞\nTable 1Space and expected time complexity for learned indexes and B+Tree. The probabilistic\nassumptions are not necessary for the index to work, but they are necessary to guarantee the stated\nperformance. For the last three rows, it is assumed that fhas bounded support [a,b].\nNon-learned methods. There are many classical algorithms for searching a sorted array.\nTheytendtobecomparison-basedandhave O(logn)expectedtime, unlessstrongassumptions\naremade(e.g., interpolationsearchuses O(log(logn))timeonaverageifthekeysareuniformly\ndistributed [ 17]). We use B+Tree as a representative. A B+Tree has space overhead O(n/b)\nwherebis the branching factor. Since bdoes not depend on n, asymptotically this is just\nO(n). The number of comparisons required to find a key is O(logn). This represents both\nworst-case and average-case complexity, with no probabilistic assumptions.\nPGM-index. In the absence of probabilistic assumptions, space overhead of the PGM-index\nisO(n/ε)and expected time is O(logn). Here,εis a hyperparameter of the method and is\nindependent of n, so this constitutes the same asymptotic complexity as B+Trees. Under\ncertain assumptions, space overhead can be strengthened to O(n/ε2)[8], representing a\nconstant factor improvement (i.e., same asymptotic space complexity).\nIn contrast to [ 35] and our work, the assumptions in [ 8] concern the gapsbetween keys.\nSpecifically, the{Xi+1−Xi}are assumed to be independent and identically distributed\n(i.i.d.), with finite mean µand variance σ2. It is also assumed that ε≫σ/µ. This setting is\nnot directly comparable to ours, in the sense that neither is a particular instantiation of the\nother. However, the assumptions described above are very strong in our view and seem hard\nto justify for most practical applications. Also, the ε≫σ/µcondition constrains the choice\nof this key hyperparameter.\nPCA Index and RDA Index. In [35] several indexes are presented, the most relevant for\nus being the PCA and RDA indexes. The PCA Index is similar to the ESPC index, with\nsome differences as explained in Section 3.2, including the use of binary search instead of\nexponential search. The RDA Index is similar to the Recursive Model Index (RMI) from [ 18].\nAll results below are stated in terms of the RAM model under the uniform cost criterion.\nIn [35], the same assumption regarding bounded support [a,b]forfis needed, so we\nconsider that case in this section. Extensions to unbounded support incur a penalty in terms\nof space complexity, dependent on the tails of the distribution. We first describe the PCA\nIndex. For any δ>0, there is a PCA Index with space overhead O((b−a)1+δρ1+δ\n1n1+δ/2)and\nexpected time complexity O(log1\nδ). Here,ρ1is an upper bound for f. Since it is independent\nofn, space overhead is asymptotically O(n1+δ/2). A direct comparison to the ESPC index is\n\nXX:14 Querying in Constant Expected Time with Learned Indexes\npossible through Theorem 1, which provides a strictly stronger result, with expected constant\ntime and truly linear space.\nOn the other hand, the RDA Index has space overhead O(ρ1\nρ2n), whereρ2is a lower bound\nforfandρ1is an upper bound (as for the case of the PCA Index). Asymptotically in n,\nthis isO(n). Expected query time in this case is O(log(logn)). A direct comparison to the\nESPC index is possible through Theorem 2, which provides a strictly stronger result, with\nO(log(logn))expected time and sublinear space overhead.\nEven as we improve the complexity bounds, we also generalize the domain of application\nfor our result. As part of the probabilistic model for the PCA and RDA indexes, it is assumed\nthat the{Xi}are i.i.d. with density f[35]. PCA index assumes fis upper bounded, that\nis, there exists some fixed ρ1<∞such thatf(x)≤ρ1for allx. Notice that this condition\nimplies that fis square-integrable, so that our assumptions are strictly weaker:\nρf=/integraldisplay\nRf2(x)dx≤ρ1/integraldisplay\nRf(x)dx=ρ1<∞.\nThe RDA index further assumes that fis bounded away from 0, that is, there exists\nsomeρ2>0such thatf(x)≥ρ2. Moreover, as described in [ 35], access to the values of a,\nbandρ1is required to build the PCA Index, while the RDA Index requires knowledge of ρ1\nandρ2. This seems like a strong assumption in practice. Finally, the analysis in [ 35] holds\nless generally than ours because it requires the {Xi}to be independent, and it (implicitly)\ndepends on the query parameter qhaving the same distribution as the {Xi}.\n6 Experimental Findings\nWe implement the ESPC index and evaluate the results in light of the theoretical analysis.\n6.1 Data\nIn our experiments, we use four datasets from the Searching on Sorted Data (SOSD)\nbenchmark [ 15,24], which has become standard in testing learned indexes [ 29]. Each dataset\nconsists of a sorted array of keys, which can be used to build an index and simulate queries.\nTwo of the datasets we use ( usparse,normal) are synthetically generated. The other two\n(amzn,osm) come from real-world data. In particular, osmis known to be challenging for\nlearned indexes [24].\n6.2 Experimental Design\nOur complexity bounds (Theorems 1 and 2) are corollaries of Propositions 3 and 6, which\nare the key results to validate empirically. We do this in the following way. Each dataset\nconsists of a sorted array of 20×107keys. We use a subsample of n= 107keys, so that\nexperiments are less computationally expensive. For a fixed subsample, we take different\nvalues ofKand for each:\n1.We build the ESPC index with Ksubintervals. Space overhead is estimated by reporting\nthe amount of memory used by the index. From Proposition 3, this should be O(K). In\nterms of experiments, we expect a linear relationship between memory overhead and K.\n2.We sample Qkeys fromA. We compute rankfor these keys using the index and measure\nthe prediction error. We then average these values to estimate the expected error. From\nProposition 6, this should be smaller than3(b−a)\n2ρfn\nK. In practice, we use an estimate ˆρf\nofρf(see Section 6.4) and all data is re-scaled to the [0,1]interval, so that we consider\n\nAuthors XX:15\n10.0 12.5 15.0 17.5510log2error\nSYNusparse\nExperimental Error\nTheoretical Bound\n10.0 12.5 15.0 17.551015\nnormal\nExperimental Error\nTheoretical Bound\n10.0 12.5 15.0 17.5\nlog2K510log2error\nREALamzn\nExperimental Error\nTheoretical Bound\n10.0 12.5 15.0 17.5\nlog2K10.012.515.017.5\nosm\nExperimental Error\nTheoretical Bound\nFigure 4 Average experimental error and theoretical bound for expected error, as functions of the\nnumberKof subintervals. Top row shows synthetic datasets, bottom row shows real-world datasets.\nThe plots use a logarithmic scale for both axes, which prevents clustering of the points.\nb−a= 1. For experiments, we plot the average prediction error alongside (3ˆρfn)/(2K),\nas functions of K. We expect the average error curve to be below (3ˆρfn)/(2K).\nWe useQ= 30×106. ForKwe use values of 103,5×103,104,5×104,105and2×105.\n6.3 Results\nIn terms of storage, our experiments show a perfect linear relationship between memory\noverhead and K, where memory overhead = 32Kbytes. This result is in accordance to\ntheO(K)estimate in Proposition 4.1. The agreement between experiments and theory is\nto be expected here, because the space overhead of the ESPC index does not depend on\nprobabilistic factors.\nOn the other hand, Figure 4 shows how the prediction error changes with the number of\nsubintervals K. We plot the average experimental error along with the theoretical bound\nfor the expected error. In accordance with Proposition 6, this theoretical bound is given by\n(3nˆρf)/(2K). As expected, for all datasets this expression serves as an upper bound for the\naverage experimental error, and both curves have a similar shape. The results show that\nProposition 6 has good predictive power, even for real-world data.\n6.4 Analysis of ρf\nAs seen in Figure 4, the experimental error follows the overall shape described by the\ntheoretical bound in Proposition 6. According to the theory, the constants involved (e.g.,\nthe intercept of the curves) should depend on ρf. Hence, it is crucial to have estimates for\nthis metric. In Appendix E we describe a procedure that can provide an estimate ˆρfofρf.\nThe values computed with this method are ( usparse, 1.20), ( normal, 3.89), ( amzn, 1.72),\n(osm, 32.57). The value for osmis an order of magnitude greater than the rest, meaning it is\nfarther away from the uniform distribution as measured by the Rényi divergence, helping\nto explain why it is challenging. The dataset with the lowest value is usparse. Since its\nunderlying distribution is uniform, this is in line with the analysis in Section 5.2. Figure 4\nshows that higher values of ˆρfcorrespond to higher experimental errors.\n\nXX:16 Querying in Constant Expected Time with Learned Indexes\n7 Conclusions\nTheoretical understanding of learned indexes has not kept up with their practical development.\nWe narrow this gap by proving that learned indexes exhibit strong theoretical guarantees\nunder a very general probabilistic model. In particular, we prove learned indexes can achieve\nO(1)expected query time with at most linear space. We introduce a specific index that\nachieves this performance, and we find a general bound for the expected time in terms of\nthe number of keys and the Rényi entropy of the distribution. From this result, we derive a\nmetricρfthat can be used to characterize the difficulty of learning the data. We describe a\nprocedure for estimating ρffor real data, and we show that the complexity bounds hold in\npractice. Our results help explain the good experimental performance of learned indexes,\nunder the most general conditions considered so far in the literature. As future work, it\nis theoretically important to prove lower bounds for expected query time. We believe this\ntype of result may hinge on information-theoretical properties (e.g., through rate-distortion\ntheory [3]), which our analysis shows are relevant for learned indexes. On the other hand, it is\nalso important to extend our analysis to the case of dynamic datasets, where the probability\ndistribution may exhibit drift over time and updates are necessary. This is an important\ncase in applications, and has not been considered in theoretical analysis.\n\nAuthors XX:17\nReferences\n1Alfred V. Aho and John E. Hopcroft. The Design and Analysis of Computer Algorithms .\nAddison-Wesley Longman Publishing Co., Inc., USA, 1st edition, 1974.\n2Jon Louis Bentley and Andrew Chi-Chih Yao. An almost optimal algorithm for\nunbounded searching. Information Processing Letters , 5(3):82–87, 1976. URL:\nhttps://www.sciencedirect.com/science/article/pii/0020019076900715 ,doi:10.1016/\n0020-0190(76)90071-5 .\n3Toby Berger. Rate-distortion theory. Wiley Encyclopedia of Telecommunications , 2003.\n4Christian Cachin. Entropy measures and unconditional security in cryptography . PhD thesis,\nETH Zurich, 1997.\n5Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction\nto Algorithms, Third Edition . The MIT Press, Cambridge, MA, USA, 3rd edition, 2009.\n6H.A. David and H.N. Nagaraja. Order Statistics . Wiley Series in Probability and Statistics.\nJohn Wiley & Sons, Inc., Hoboken, NJ, USA, 2004.\n7Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li, Hantian Zhang,\nBadrish Chandramouli, Johannes Gehrke, Donald Kossmann, David Lomet, and Tim Kraska.\nAlex: An updatable adaptive learned index. In Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data , SIGMOD ’20, page 969–984, New York,\nNY, USA, 2020. Association for Computing Machinery. doi:10.1145/3318464.3389711 .\n8Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so effective?\nIn Hal Daumé III and Aarti Singh, editors, Proceedings of the 37th International Conference on\nMachine Learning , volume 119 of Proceedings of Machine Learning Research , pages 3123–3132,\nVirtual, 13–18Jul2020.PMLR. URL: https://proceedings.mlr.press/v119/ferragina20a.\nhtml.\n9Paolo Ferragina and Giorgio Vinciguerra. The pgm-index: A fully-dynamic compressed learned\nindex with provable worst-case bounds. Proc. VLDB Endow. , 13(8):1162–1175, apr 2020.\ndoi:10.14778/3389133.3389135 .\n10David Freedman and Persi Diaconis. On the histogram as a density estimator: L2 theory.\nZeitschrift für Wahrscheinlichkeitstheorie und verwandte Gebiete , 57(4):453–476, 1981.\n11Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim Kraska.\nFiting-tree: A data-aware index structure. In Proceedings of the 2019 International Conference\non Management of Data , SIGMOD’19, page1189–1206, NewYork, NY,USA,2019.Association\nfor Computing Machinery. doi:10.1145/3299869.3319860 .\n12Rodrigo González, Szymon Grabowski, Veli Mäkinen, and Gonzalo Navarro. Practical imple-\nmentation of rank and select queries. In Poster Proc. Volume of 4th Workshop on Efficient and\nExperimental Algorithms (WEA) , pages 27–38, Athens, Greece, 2005. CTI Press and Ellinika\nGrammata.\n13Goetz Graefe et al. Modern B-tree techniques. Foundations and Trends in Databases , 3(4):203–\n402, 2011.\n14Ali Hadian and Thomas Heinis. Shift-table: A low-latency learned index for range queries using\nmodel correction. In Yannis Velegrakis, Demetris Zeinalipour-Yazti, Panos K. Chrysanthis,\nand Francesco Guerra, editors, Proceedings of the 24th International Conference on Extending\nDatabase Technology, EDBT 2021, Nicosia, Cyprus, March 23 - 26, 2021 , pages 253–264.\nOpenProceedings.org, 2021. URL: https://doi.org/10.5441/002/edbt.2021.23 ,doi:10.\n5441/002/EDBT.2021.23 .\n15Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim\nKraska, and Thomas Neumann. Sosd: A benchmark for learned indexes. arXiv preprint\narXiv:1911.13014 , 2019.\n16Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim\nKraska, and Thomas Neumann. Radixspline: A single-pass learned index. In Proceedings of\nthe Third International Workshop on Exploiting Artificial Intelligence Techniques for Data\n\nXX:18 Querying in Constant Expected Time with Learned Indexes\nManagement , aiDM ’20, New York, NY, USA, 2020. Association for Computing Machinery.\ndoi:10.1145/3401071.3401659 .\n17Donald E. Knuth. The Art of Computer Programming, Volume 3: (2nd Ed.) Sorting and\nSearching . Addison Wesley Longman Publishing Co., Inc., USA, 1998.\n18Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proceedings of the 2018 International Conference on Management of\nData, SIGMOD ’18, page 489–504, New York, NY, USA, 2018. Association for Computing\nMachinery. doi:10.1145/3183713.3196909 .\n19Justin J. Levandoski, David B. Lomet, and Sudipta Sengupta. The bw-tree: A b-tree for\nnew hardware platforms. In Proceedings of the 2013 IEEE International Conference on Data\nEngineering (ICDE 2013) , ICDE ’13, page 302–313, USA, 2013. IEEE Computer Society.\ndoi:10.1109/ICDE.2013.6544834 .\n20Ling Liu and M Tamer Özsu. Encyclopedia of Database Systems , volume 6. Springer New\nYork, NY, USA, 2009.\n21Scott Lloyd and Maya Gokhale. Near memory key/value lookup acceleration. In Proceedings\nof the International Symposium on Memory Systems , MEMSYS ’17, page 26–33, New York,\nNY, USA, 2017. Association for Computing Machinery. doi:10.1145/3132402.3132434 .\n22Zhanyu Ma and Arne Leijon. Coding bounded support data with beta distribution. In 2010\n2nd IEEE InternationalConference on Network Infrastructure and Digital Content , pages\n246–250, 2010. doi:10.1109/ICNIDC.2010.5657779 .\n23Zhanyu Ma, Andrew E. Teschendorff, Arne Leijon, Yuanyuan Qiao, Honggang Zhang, and Jun\nGuo. Variational bayesian matrix factorization for bounded support data. IEEE Transactions\non Pattern Analysis and Machine Intelligence , 37(4):876–889, 2015. doi:10.1109/TPAMI.2014.\n2353639.\n24Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra, Alfons\nKemper, Thomas Neumann, and Tim Kraska. Benchmarking learned indexes. Proc. VLDB\nEndow., 14(1):1–13, sep 2020. doi:10.14778/3421424.3421425 .\n25Alfréd Rényi. On measures of entropy and information. In Proceedings of the Fourth Berkeley\nSymposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory\nof Statistics , volume 4, pages 547–562, Oakland, CA, USA, 1961. University of California\nPress.\n26David W. Scott. Multivariate Density Estimation: Theory, Practice, and Visualization . Wiley\nSeries in Probability and Statistics. John Wiley & Sons, Inc., Hoboken, NJ, USA, 2015.\n27Amirhesam Shahvarani and Hans-Arno Jacobsen. Parallel index-based stream join on a\nmulticore cpu. In Proceedings of the 2020 ACM SIGMOD International Conference on\nManagement of Data , SIGMOD ’20, page 2523–2537, New York, NY, USA, 2020. Association\nfor Computing Machinery. doi:10.1145/3318464.3380576 .\n28Maciej Skórski. Shannon entropy versus renyi entropy from a cryptographic viewpoint. In Jens\nGroth, editor, Cryptography and Coding , pages 257–274, Cham, 2015. Springer International\nPublishing.\n29Zhaoyan Sun, Xuanhe Zhou, and Guoliang Li. Learned index: A comprehensive experimental\nevaluation. Proc. VLDB Endow. , 16(8):1992–2004, apr 2023. doi:10.14778/3594512.3594528 .\n30Tim van Erven and Peter Harremos. Rényi divergence and kullback-leibler divergence. IEEE\nTransactions on Information Theory , 60(7):3797–3820, 2014. doi:10.1109/TIT.2014.2320500 .\n31Roman Vershynin. High-Dimensional Probability: An Introduction with Applications in Data\nScience. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University\nPress, Cambridge, UK, 2018.\n32Susana Vinga and Jonas S Almeida. Rényi continuous entropy of dna sequences. Journal of\ntheoretical biology , 231(3):377–388, 2004.\n33Chaichon Wongkham, Baotong Lu, Chris Liu, Zhicong Zhong, Eric Lo, and Tianzheng Wang.\nAre updatable learned indexes ready? Proc. VLDB Endow. , 15(11):3004–3017, jul 2022.\ndoi:10.14778/3551793.3551848 .\n\nAuthors XX:19\n34Guang Yang, Liang Liang, Ali Hadian, and Thomas Heinis. FLIRT: A fast learned index for\nrolling time frames. In Julia Stoyanovich, Jens Teubner, Nikos Mamoulis, Evaggelia Pitoura,\nJan Mühlig, Katja Hose, Sourav S. Bhowmick, and Matteo Lissandrini, editors, Proceedings\n26th International Conference on Extending Database Technology, EDBT 2023, Ioannina,\nGreece, March 28-31, 2023 , pages 234–246, Ioannina, Greece, 2023. OpenProceedings.org.\nURL: https://doi.org/10.48786/edbt.2023.19 ,doi:10.48786/EDBT.2023.19 .\n35Sepanta Zeighami and Cyrus Shahabi. On distribution dependent sub-logarithmic query time\nof learned indexing. In Proceedings of the 40th International Conference on Machine Learning ,\nICML’23. JMLR.org, 2023.\n\nXX:20 Querying in Constant Expected Time with Learned Indexes\nA Proof of Lemma 4\nProof of Lemma 4. Sinceqbelongs to subinterval Ik= [tk−1,tk], we know that ˆ r(q) =ˆrk.\nAlso, since rankis an increasing function, it holds that rank (tk−1)≤rank (q)≤rank (tk).\nSubtracting ˆrkfrom this inequality, we get\nrank (tk−1)−ˆrk≤rank (q)−ˆrk≤rank (tk)−ˆrk. (8)\nAs described in Section 3.2, ˆrkcan be written as ˆrk=rank (tk−1) +nk/2. Hence, it follows\nthatrank (tk−1)−ˆrk=−nk/2. On the other hand, it can be seen directly from the definition\nofrankthatrank (tk)is equal to rank (tk−1) +nk. This means that\nrank (tk)−ˆrk=rank (tk−1) +nk−ˆrk= (rank (tk−1)−ˆrk) +nk=−nk\n2+nk=nk\n2.\nSubstituting into equation (8), we get the desired result:\n−nk\n2≤rank (q)−ˆrk≤nk\n2.\n◀\nB Proofs of Main Complexity Bounds\nProof of Theorem 1. Letn∈Nand consider the following procedure Rnfor generating an\nindex: given a sorted array A= [X(1),...,X (n)], the output Rn(A)consists of an ESPC\nindex built with K=nsubintervals. By Proposition 3, this means that space overhead is\nS(Rn(A)) =O(K) =O(n). As this is independent of the specific values stored in A, we have\nSn=O(n). On the other hand, by Theorem 5 and Proposition 6 we can bound the expected\nprediction error by\nE[ε]≤3(b−a)\n2ρfn\nn=3(b−a)\n2ρf.\nFurthermore, Jensen’s inequality implies\nE[logε]≤logE[ε]≤log/parenleftbig\n(b−a)ρf/parenrightbig\n+ log(3/2)≤log/parenleftbig\n(b−a)ρf/parenrightbig\n+ 1.\nBy Proposition 3, we know query time for qfor the ESPC index is O(logε(q)). Accordingly,\nthe expected query time is Tn=O(E[logε]) =O/parenleftbig\nlog/parenleftbig\n(b−a/parenrightbig\nρf/parenrightbig\n+ 1/parenrightbig\n=O/parenleftbig\nlog/parenleftbig\n(b−a/parenrightbig\nρf/parenrightbig/parenrightbig\n.\nThis concludes the proof. ◀\nProof of Theorem 2. We use the same argument as the proof for Theorem 1, but setting\nK=n\nlognsubintervals instead of K=n. ◀\nC Proof of Proposition 7\nProof of Proposition 7. The proof follows closely the argument used to prove Theorem 5\nand Proposition 6. By the tower property for conditional expectation,\nE[ε] =E[E[ε|X1,...,Xn]].\nThe inner expected value gives\nE[ε|X1,...,Xn] =/integraldisplay\nRε(q)g(q)dq=/integraldisplayX(n)\nX(1)ε(q)g(q)dq.\nwhere the last equality comes from the fact that for q /∈[X(1),X(n)]we know the exact\nvalue of rank (q), which is either 0orn, and hence we have that ε(q) = 0. Replacing\n\nAuthors XX:21\nε(q) =|rank (q)−ˆ r(q)|and noticing that the {Ik}form a partition of [X(1),X(n)]:\nE[ε|X1,...,Xn] =K/summationdisplay\nk=1/integraldisplay\nIk|rank (q)−ˆ r(q)|g(q)dq.\nBy Lemma 4 we can bound the error within each Ik:\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nk=1nk/integraldisplay\nIkg(q)dq,\nwherenkis the number of keys in subinterval Ik. Now, denote by nk,ℓthe number of keys in\nIk∩Jℓ. Then, we can write\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nk=1/parenleftiggK/summationdisplay\nℓ=1nk,ℓ/parenrightigg/integraldisplay\nIkg(q)dq=1\n2K/summationdisplay\nℓ=1K/summationdisplay\nk=1nk,ℓ/integraldisplay\nIkg(q)dq, (9)\nwhere first we have written nkas/summationtextK\nℓ=1nk,ℓand then we have exchanged the order of\nsummation. Now, denote by L(k)the set ofℓindices such that Ik∩Jℓ̸=∅. Notice that\nnk,ℓ= 0ifℓ /∈L(k). Hence, inequality (9) becomes:\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nℓ=1/summationdisplay\nk:ℓ∈L(k)nk,ℓ/integraldisplay\nIkg(q)dq. (10)\nBy Fact 1 we know that Ik⊆Jℓ−1∪Jℓ∪Jℓ+1for allℓandksuch thatℓ∈L(k). Now, define\nqℓasP/parenleftbig\nq∈Jℓ/parenrightbig\nfor eachℓ= 1,...,K, analogously to how the pℓare defined as P/parenleftbig\nXi∈Jℓ/parenrightbig\n.\nUsing this notation, from inequality (10) we get\nE[ε|X1,...,Xn]≤1\n2K/summationdisplay\nℓ=1/summationdisplay\nk:ℓ∈L(k)nk,ℓ/parenleftigg/integraldisplay\nJℓ−1g(q)dq+/integraldisplay\nJℓg(q)dq+/integraldisplay\nJℓ+1g(q)dq/parenrightigg\n=1\n2K/summationdisplay\nℓ=1(qℓ−1+qℓ+qℓ+1)/summationdisplay\nk:ℓ∈L(k)nk,ℓ\n=1\n2K/summationdisplay\nℓ=1(qℓ−1+qℓ+qℓ+1)mℓ, (11)\nwheremℓdenotes the number of keys in Jℓ. Now, applying expected value on both sides of\ninequality (11), we get that\nE[ε] =E[E[ε|X1,...,Xn]]≤1\n2K/summationdisplay\nℓ=1(qℓ−1+qℓ+qℓ+1)E[mℓ] (12)\nFurthermore, we have\nE[mℓ] =E/bracketleftiggn/summationdisplay\ni=11Xi∈Jℓ/bracketrightigg\n=n/summationdisplay\ni=1E[1Xi∈Jℓ] =n/summationdisplay\ni=1P(Xi∈Jℓ) =npℓ.\nReplacing E[mℓ] =npℓin inequality (12), we get:\nE[ε]≤1\n2K/summationdisplay\nℓ=1(qℓ−1+qℓ+qℓ+1)E[mℓ] =n\n2K/summationdisplay\nℓ=1(qℓ−1pℓ+qℓpℓ+qℓ+1pℓ). (13)\nNow, by Cauchy-Schwarz inequality we know that\nK/summationdisplay\nℓ=1qℓ−1pℓ≤/parenleftiggK/summationdisplay\nℓ=1q2\nℓ−1K/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n=/parenleftiggK−1/summationdisplay\nℓ=0q2\nℓK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n≤/parenleftiggK/summationdisplay\nℓ=1q2\nℓK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n,\n\nXX:22 Querying in Constant Expected Time with Learned Indexes\nwhere we have used the fact that q0=P(q∈J0)= 0sinceJ0is defined as the empty set.\nSimilarly, by Cauchy-Schwarz inequality and the fact that qK+1= 0we can prove\nK/summationdisplay\nℓ=1qℓpℓ≤/parenleftiggK/summationdisplay\nℓ=1q2\nℓK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n,K/summationdisplay\nℓ=1qℓ+1pℓ≤/parenleftiggK/summationdisplay\nℓ=1q2\nℓK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n.\nReplacing in (13) we get the new inequality\nE[ε]≤3n\n2/parenleftiggK/summationdisplay\nℓ=1q2\nℓ/parenrightigg1/2/parenleftiggK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n.\nNow, since both fandgare square-integrable functions, the same argument from Proposition\n6 can be used to prove that\nK/summationdisplay\nℓ=1q2\nℓ≤(b−a)\nKρg,andK/summationdisplay\nℓ=1p2\nℓ≤(b−a)\nKρf.\nPutting everything together:\nE[ε]≤3n\n2/parenleftiggK/summationdisplay\nℓ=1q2\nℓ/parenrightigg1/2/parenleftiggK/summationdisplay\nℓ=1p2\nℓ/parenrightigg1/2\n≤3n\n2/parenleftbigg(b−a)\nKρg/parenrightbigg1/2/parenleftbigg(b−a)\nKρf/parenrightbigg1/2\n=3(b−a)\n2√ρfρgn\nK.\nThis concludes the proof. ◀\nD Proof of Constant Time Results for Cases of Unbounded Support\nProof of Theorem 8. Seta=µ−σ√nlognandb=µ+σ√nlogn. It holds that\nP(Aa,b) =P/parenleftbig\n[X(1),X(n)]̸⊆[a,b]/parenrightbig\n=P/parenleftiggn/uniondisplay\ni=1/braceleftbig\nXi/∈[a,b]/bracerightbig/parenrightigg\nBy the union bound:\n≤n/summationdisplay\ni=1P(Xi/∈[a,b])\nBy definition of aandb:\n=n/summationdisplay\ni=1P/parenleftig/braceleftig\nXi<µ−σ/radicalbig\nnlogn/bracerightig\n∪/braceleftig\nXi>µ+σ/radicalbig\nnlogn/bracerightig/parenrightig\n=n/summationdisplay\ni=1P/parenleftig\n|Xi−µ|>σ/radicalbig\nnlogn/parenrightig\nBy Chebyshev’s inequality:\n≤n/summationdisplay\ni=11\nnlogn=1\nlogn.\nSince P(Aa,b)≤1\nlognequation (5) applies, and replacing aandbgives\nO(E[logε]) =O/parenleftig\nlog/parenleftig\n(b−a)ρfn\nK/parenrightig/parenrightig\n=O/parenleftig\nlog/parenleftig\n2σ/radicalbig\nnlognρfn\nK/parenrightig/parenrightig\n.\n\nAuthors XX:23\nHence,buildinganESPCindexwith K=n√nlognintervalsmakesspaceusage O/parenleftig\nn√nlogn/parenrightig\nand guarantees that expected query time is O(log(2σρf)). This concludes the proof. ◀\nProof of Theorem 9. The distribution of the {Xi}is subexponential, so there is a constant\nC > 0such that P(|Xi|≥x)≤2e−Cxfor allx. Seta=−2 logn\nC,b=2 logn\nC. It holds that\nP(Aa,b) =P/parenleftbig\n[X(1),X(n)]̸⊆[a,b]/parenrightbig\n=P/parenleftiggn/uniondisplay\ni=1/braceleftbig\nXi/∈[a,b]/bracerightbig/parenrightigg\nBy the union bound:\n≤n/summationdisplay\ni=1P(Xi/∈[a,b])\nBy definition of aandb:\n=n/summationdisplay\ni=1P/parenleftbigg/braceleftbigg\nXi<−2 logn\nC/bracerightbigg\n∪/braceleftbigg\nXi>2 logn\nC/bracerightbigg/parenrightbigg\n=n/summationdisplay\ni=1P/parenleftbigg\n|Xi|>2 logn\nC/parenrightbigg\nBecause the distribution is subexponential:\n≤n/summationdisplay\ni=12e−C2 logn\nC\n=2\nn≤1\nlogn,\nfor alln≥2. Since P(Aa,b)≤1\nlognequation (5) applies, and replacing aandbgives\nO(E[logε]) =O/parenleftig\nlog/parenleftig\n(b−a)ρfn\nK/parenrightig/parenrightig\n=O/parenleftbigg\nlog/parenleftbigg4 logn\nCρfn\nK/parenrightbigg/parenrightbigg\n.\nHence, building an ESPC index with K=nlognsubintervals makes space usage O(nlogn)\nand guarantees that expected query time is O/parenleftbig\nlog/parenleftbig\n4ρf/C/parenrightbig/parenrightbig\n. This concludes the proof. ◀\nE Estimation of ρfmetric\nAs the key measure of statistical complexity for the data generating process, ρfcan help\nexplain the experimental differences in the performance of the ESPC index for different\ndatasets. In that sense, it is important to have an estimate for this metric. Notice that\nρf=/integraldisplay\nRf2(x)dx=/integraldisplay\nRf(x)f(x)dx=E[f],\nthat is,ρfis equal to the expected value of the density function. In other words, if we can\n1.SampleJvaluesz1,...,zJfrom the probability distribution defined by f, and\n2.Evaluatef(zj)for allj∈{1,...,J},\nthen we can get an unbiased estimator for ρfvia\nˆρf=1\nJJ/summationdisplay\nj=1f(zj).\nIf the{zj}are sampled independently, this corresponds to a Monte Carlo estimator and we\nknow its variance goes to 0asJ→∞.\n\nXX:24 Querying in Constant Expected Time with Learned Indexes\nWe can adapt this procedure for real datasets. On the one hand, Step (1) can be simulated\nby sampling keys at random from array A. On the other hand, since fis usually not known,\nfor Step (2) we use an estimate ˆfof the density f. This estimate can be derived via several\nmethods (e.g., kernel density estimation [ 26]) with different properties in terms of mean\nsquared or uniform error.\nWe mostly use the histogram method, which under mild assumptions can be shown to\nhave vanishing bias as the bin width goes to 0[10]. For this method, the mean squared error\nis minimized with Ω(n−1/3)bin width, where nis the number of keys. One robust option in\npractice is to choose the bin width using the Freedman–Diaconis rule [ 10]. For most datasets,\ngenerated from either synthetic ( usparse,normal) or real-world data ( amzn), this method\nexhibits the convergence expected from Monte Carlo estimation as the number of samples\nincreases. Figure 5 exemplifies this with the normalandamzndatasets.\n2 4 6\nlog10n2.02.53.03.54.0f\nnormal\namzn\n2 4 6\nlog10n203040\n osm\nFigure 5 ˆρfestimate for normal,amznandosmdatasets as number of samples nincreases. The\nestimation process uses the histogram method to approximate the density f.\nFor theosmdataset, this convergent behavior is not observed, as Figure 5 shows. It\nmay be that the variance of the estimator is higher and more samples are needed to get an\naccurate estimate. In light of this, we calculate ˆρfby using a kernel density estimator for\nthe density f, which seems to be more robust than the histogram estimator for this dataset.\nTable 2 shows the estimates ˆρfobtained through the use of our method. As can be seen,\nmost datasets exhibit low values for this metric, consistent with the good performance that\nlearned indexes have in general. Among these datasets, osmhas the highest value of ˆρf,\nconsistent with the fact that it is considered a challenging benchmark for learned indexes.\nDataset ˆρf\nusparse 1.20\nnormal 3.89\namzn 1.72\nosm 32.57\nTable 2Estimate ˆρffor each dataset used in our experiments. Most have low values, consistent\nwith good performance of learned indexes. The osmdataset exhibits a high value of ˆρf, an order of\nmagnitude greater than the rest, helping to explain why it is considered challenging.",
  "textLength": 67895
}