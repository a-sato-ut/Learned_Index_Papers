{
  "paperId": "bc8f020f260f85e5353bbaeecb761a75ad4cd273",
  "title": "DyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan",
  "pdfPath": "bc8f020f260f85e5353bbaeecb761a75ad4cd273.pdf",
  "text": "DyTIS: A Dynamic Dataset Targeted Index Structure\nSimultaneously Efficient for Search, Insert, and Scan\nJin Yang1, Heejin Yoon1, Gyeongchan Yun1, Sam H. Noh2*, Young-ri Choi1\n1UNIST,2Virginia Tech\n1{yangjin, heejin5178, rugyoon, ychoi}@unist.ac.kr,2samhnoh@vt.edu\nAbstract\nMany datasets in real life are complex and dynamic, that is,\ntheir key densities are varied over the whole key space and\ntheir key distributions change over time. It is challenging\nfor an index structure to efficiently support all key opera-\ntions for data management, in particular, search, insert, and\nscan, for such dynamic datasets. In this paper, we present\nDyTIS (Dynamic dataset Targeted Index Structure), an index\nthat targets dynamic datasets. DyTIS, though based on the\nstructure of Extendible hashing, leverages the CDF of the\nkey distribution of a dataset, and learns and adjusts its struc-\nture as the dataset grows. The key novelty behind DyTIS is\nto group keys by the natural key order and maintain keys\nin sorted order in each bucket to support scan operations\nwithin a hash index. We also define what we refer to as a\ndynamic dataset and propose a means to quantify its dy-\nnamic characteristics. Our experimental results show that\nDyTIS provides higher performance than the state-of-the-art\nlearned index for the dynamic datasets considered.\nCCS Concepts: â€¢Information systems â†’Data struc-\ntures; Data management systems.\nKeywords: dynamic datasets, index structure, key distribu-\ntion\nACM Reference Format:\nJin Yang1, Heejin Yoon1, Gyeongchan Yun1, Sam H. Noh2*, Young-\nri Choi1. 2023. DyTIS: A Dynamic Dataset Targeted Index Structure\nSimultaneously Efficient for Search, Insert, and Scan. In Eighteenth\nEuropean Conference on Computer Systems (EuroSys â€™23), May 8â€“\n12, 2023, Rome, Italy. ACM, New York, NY, USA, 17 pages. https:\n//doi.org/10.1145/3552326.3587434\n*This research was conducted while at UNIST.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies\nare not made or distributed for profit or commercial advantage and that\ncopies bear this notice and the full citation on the first page. Copyrights\nfor components of this work owned by others than the author(s) must\nbe honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific\npermission and/or a fee. Request permissions from permissions@acm.org.\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nÂ©2023 Copyright held by the owner/author(s). Publication rights licensed\nto ACM.\nACM ISBN 978-1-4503-9487-1/23/05. . . $15.00\nhttps://doi.org/10.1145/3552326.35874341 Introduction\nFor in-memory data management systems, such as in-memory\ndatabases and key-value stores [ 4,12,34,35,56], the ef-\nficiency of the index structure is critical, strongly affect-\ning the final latency of the systems [ 21,44,57,62]. More-\nover, even for disk-based data management systems where,\npreviously, storage I/O latency had been the dominant per-\nformance bottleneck [ 5], the software layer (i.e., the index\nstructure) becomes important with the recent advent of fast\nstorage systems such as the Samsung Z-SSD [ 54], KIOXIA\nXL-FLASH [ 17], and CXL SSDs [ 33]. Traditional indexes such\nas B+-trees and hash indexes are excellent structures that\nhave been embraced by data management systems. They\nare an integral part of systems today supporting three key\noperations, specifically, search, insert, and scan. Their limi-\ntations, however, are that each excels for one operation but\nmay not support another efficiently. For example, while hash\nindexes perform superbly for individual key search, they\ndo not support range queries well, while in contrast, the\nB+-tree is the other way around. Recently, learned index\nstructures have been proposed that excel for all three op-\nerations [ 21,26,57]. However, there is a catch here as well.\nLearned indexes need to be trained, and training, in recent\nwork, has been done in the form of bulk loading [ 21,26,57].\nWhen the characteristics of a dataset are static and simple,\nthey are excellent. However, once this assumption breaks,\nhow much to train and when to train again become diffi-\ncult hurdles to overcome, potentially resulting in degraded\nperformance.\nConsider that in a data management system, a dataset\nis defined by a key distribution (i.e., keys inserted to the\nsystem) and the insertion order of the keys. Many datasets\nin real life are actually complex and dynamic such that the\nkey distribution is not uniform and also changes as keys are\ninserted. In this paper, we present DyTIS (Dynamic dataset\nTargeted Index Structure), an index structure that competi-\ntively supports all search, insert, and scan operations, does\nnot require a training phase (i.e., bulk loading), and is espe-\ncially effective for dynamic datasets. DyTIS, though based\non Extendible hashing [ 25], leverages the CDF (Cumulative\nDistribution Function) of the key distribution of a dataset,\nand learns and adjusts its structure as the dataset grows. The\nkey novelty behind DyTIS is to group keys by the natural\nkey order and maintain keys in sorted order in each bucket\nto support scan operations within a hash index. A natural\n370\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\nVariance of Skewness\n(Avg. number of linear models per 0.1M keys)Key Distribution Divergence\n(Average KL divergence)\nGroup 1\nGroup 2\nGroup 3\nFigure 1. Dynamic characteristics of various datasets\nquestion, then, is how to manage the hash index when the\ndataset becomes non-uniform, that is, unbalanced or skewed,\nwhich is typical of datasets. To efficiently handle such key\ndistributions, DyTIS employs remapping functions that re-\ndistribute the non-uniform keys into a uniform distribution\nwhile preserving the natural order of the keys.\nAside from learned indexes, to the best of our knowl-\nedge, DyTIS is the first index structure that is simultane-\nously efficient for all search, insert, and scan operations. Un-\nlike learned indexes, DyTIS focuses on realistic real-world\ndatasets with various dynamic characteristics that have com-\nplex key insertion order such that while keys are inserted over\ntime, the distribution of inserted keys continuously changes.\nThe main contributions of this work are as follows: First,\nwe give our definition of a dynamic dataset and propose a\nmeans to quantify its dynamic characteristics. Second, we de-\nsign an efficient index, DyTIS, which adjusts the CDF, as keys\nare inserted, to reflect the real key distribution. Finally, we\nimplement DyTIS1and evaluate its performance by compar-\ning it with three different dynamic indexing techniques over\nfive different real-world datasets. Our experimental results\ndemonstrate that DyTIS provides higher performance than\nthe state-of-the-art learned index for the dynamic datasets\nconsidered.\n2 Motivation and Design Direction\n2.1 Dynamic Datasets\nDynamic Dataset: We first define what we mean by a dy-\nnamic dataset and show how this is quantified. A dynamic\ndataset is defined based on two observations; one, that the\nwhole key space of a dataset can consist of small key ranges\nwith different key densities [ 11,45,65] and two, that the\nkey densities of key ranges, and thus, the key distribution of\nthe dataset, change over time [ 42,57]. The former is termed\nskewness, which refers to how dense keys are over a key\n1https://github.com/unist-ssl/DyTIS\n0         CDF 1\nKey range (4.4 Ã—ğŸğŸğŸğŸ’)\n0         CDF 1\nKey range (3.6 Ã—ğŸğŸğŸğŸ‘)\n0         CDF 1\nKey range (3.5 Ã—ğŸğŸğŸğŸ’)\n(a) Map-M, 2 models\n0         CDF 1\nKey range (3.5 Ã—ğŸğŸğŸğŸ’)\n0         CDF 1\nKey range (3.6 Ã—ğŸğŸğŸğŸ‘)\n (b) Taxi, 8 models\n0         CDF 1\nKey range (3.6 Ã—ğŸğŸğŸğŸ‘)\n (c) Review-L, 24 models\nFigure 2. Variance of skewness for three datasets\nrange; if keys are dense (sparse), then skewness is high (low).\nThe latter is termed distribution divergence, which captures\nthe rate in which the key distribution of the dataset tends\nto change. We find that variance of skewness andkey distri-\nbution divergence are the key factors that strongly affect the\nperformance of indexes that leverage the key distribution\nof a dataset. This is because the number of linear models\nused to approximate the CDF and the retraining/adjusting\nof the linear models have strong impact on the performance\nof these indexes, which we discuss in detail below. Figure 1\nshows how various datasets fare in terms of these dynamic\ncharacteristics. (The datasets are discussed in detail in Sec-\ntion 4.2.) Note that the Uniform dataset shows no skewness\nand no divergence in key distribution throughout the whole\nkey space. We now discuss how these values are quantified\nand how they are to be interpreted.\nVariance of Skewness: Variance of skewness is a metric\nwe use to capture how skewness changes throughout the\ndataset. This represents the complexity of approximating the\nCDF of the key distribution of the key space. Considering\nthat piecewise linear regression is used to approximate the\nCDF [ 64], if the skewness of each small key range is highly\nvaried, a large number of linear models are needed. Figure 2\nshows how the number of linear models varies for the Map-\nM, Taxi, and Review-L datasets that show low, medium, and\nhigh variance of skewness, respectively, where lines with dif-\nferent colors represent different linear models. Hereafter, for\nsimplicity, we use skewness to refer to variance of skewness.\nTo quantify skewness for a dataset, we take the average\nnumber of linear models used to approximate the CDF for a\nfixed number of keys per key range. Note that we use a fixed\nnumber of keys, then average them to normalize their values\nas real-world datasets will all differ in size. The approximated\nCDF is measured by the maximum error-bounded Piecewise\nLinear Representation (PLR) technique [64]2.\nKey Distribution Divergence: For many real-world datasets,\nkeys are inserted to a data management system in dynamic\npatterns. For example, in map datasets where keys are usu-\nally based on the longitudes and latitudes of locations [ 51],\ndata with similar longitude and latitude values may be in-\nserted consecutively as a bulk, while in sensing or weather\n2https://github.com/RyanMarcus/plr. In this work, to construct the PLR of\na dataset, the error bound is set such that the Uniform dataset only needs\none linear model.\n371\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\n0                    1000Number of keys\n0                    1000\n0                    1000\n116.3M -thkeydistribution 116.4M -thkeydistribution\n(a) Review -L116.5M -thkeydistribution0                    1500Number of keys\n0                    1500\n0                    1500\n163.2M -thkeydistribution 163.3M -thkeydistribution\n(b) Taxi163.4M -thkeydistribution\n(a) Review-L\n0                    1000Number of keys\n0                    1000\n0                    1000\n116.3M -thkeydistribution 116.4M -thkeydistribution\n(a) Review -L116.5M -thkeydistribution0                    1500Number of keys\n0                    1500\n0                    1500\n163.2M -thkeydistribution 163.3M -thkeydistribution\n(b) Taxi163.4M -thkeydistribution\n(b) Taxi\nFigure 3. Key distribution divergence for two datasets\nrelated datasets [ 9], data may be inserted with some periodic\npatterns such as diurnality and seasonality, and, as a final\nexample, in datasets where a timestamp is used as a part\nof keys [ 28], keys may be inserted sequentially. Therefore,\nthe distribution of data (i.e., inserted keys) typically changes\nover time.\nKey Distribution Divergence (KDD) captures how vastly\nthe distributions change. It is measured by adopting the\nKullbackâ€“Leibler divergence (KL divergence) [ 41], which\nmeasures the difference between two probability distribu-\ntions, where higher KL divergence value means that the two\nprobability distributions are more different. To attain KDD,\nwe divide the whole dataset into sub-datasets with a fixed\nnumber of keys and assume that each key in the sub-dataset\nis a random variable following the same discrete probabil-\nity distribution. Then, the average of the KL divergence of\nevery two consecutive sub-datasets is taken as the KDD\nfor that dataset. To compute the KL divergence of two sub-\ndatasets, we approximate the probability distribution of each\nsub-dataset using a histogram such that the key range of\nits histogram is determined by the minimum and maximum\nkey values from the two sub-datasets. Note that for these\nmetrics, the number of keys considered per key range and\nthe size of a sub-dataset need to be chosen. While we choose\n0.1 million for both, we also find the trend of the computed\nmetrics are largely insensitive to this choice.\nFigure 3 shows how the key distributions diverge over\nthree consecutive sub-datasets for Review-L and Taxi that\nrepresent datasets with low and high KDD values, respec-\ntively. We observe that the three key distributions of Review-\nL are virtually all the same, while for those of Taxi, the three\nshow quite different distributions even to the naked eye.\nRevisiting Figure 1: We now revisit Figure 1 where there\nare three groups of datasets. Group 1 contains the dynamic\ndatasets that we use throughout our experiments, while those\nin Group 2, marked with (s), are the shuffled version of those\nin Group 1. The shuffled datasets contain keys that are ran-\ndomly shuffled so that the keys in the key space are inserted\nuniformly over time. We make the following observationsof Groups 1 and 2. First, real-world datasets (Group 1) show\nvarying degrees of dynamism such as high skewness and\nlow KDD (Review-M/L), to low skewness and moderate KDD\n(Map-M/L), to moderate skewness and high KDD (Taxi). Sec-\nond, shuffled datasets (Group 2) have the effect of lowering\nthe KDD value, that is, stabilizing the distribution of the keys.\nFor datasets in Group 3, we observe little dynamic charac-\nteristics having both low skewness and KDD. We emphasize\nhere that the target dataset of our study, Group 1, is different\nfrom Groups 2 and 3 used in previous studies [18, 21, 40].\n2.2 DyTIS Design Focus and Philosophy\nAn index structure that will perform well for scan as well\nas insert and search operations has long been sought after.\nRecent developments seem to have finally found the solution\nin learned index structures [ 21,26,40,57]. A learned index\nleverages the key distribution to build an index structure\nfor keys stored in a sorted array. It uses machine learning\nalgorithms such as neural networks and linear regression\nto approximate the CDF for the key distribution, and this\nCDF is used to predict the position of a given key in the\nsorted array. Of learned indexes, ALEX [ 21], a representa-\ntive approach, maintains a data structure that looks like\na B+-tree, where each internal node stores a linear model\n(i.e., an approximated CDF) and a pointer array to children\nnodes, and each leaf node (i.e., data node) stores a linear\nmodel and two arrays for keys and values. Unlike the origi-\nnal learned index [ 40] with the static recursive-model index\n(RMI), ALEX is dynamically adapted such that depending\non the dataset, each data node can have a different depth.\nThe index maintaining operations such as split, which is con-\nceptually similar to the B+-tree split, or expansion, where\nthe data node size increases with a scaled or retrained linear\nmodel, are selected by a cost model that is learned with bulk\nloading and, thereafter, re-learned during runtime. Through\nthe adaptive RMI, ALEX can find a queried key by passing\nthrough multiple linear models in internal and data nodes.\nUnfortunately, a couple of key constraints remain in learned\nindexes, especially for real-world datasets [ 11,42,45,57,65].\nThe first is that the model must first be pre-trained (i.e., bulk\nloaded). Currently, bulk loading is done manually in an ad-\nhoc manner as it is difficult to know how many keys should\nbe used for learning so that the model sufficiently reflects\nthe real distribution. This limitation naturally requires re-\ntraining of the model if the key distribution changes, so as\nnot to degrade performance. Second, existing learned in-\ndexes leverage a hierarchy of models for either the whole\nkey space [ 40,57] (i.e., RMI) or certain key ranges with high\nkey density [ 21] (i.e., adaptive RMI). Therefore, model re-\ntraining in a node may result in a cascade of retraining of\nother models such as the model of a parent or grandparent\nnode, which will be an expensive operation. Moreover, the\nquality of the model in the upper hierarchy (such as the\nmodel of the root) will have stronger effect on the overall\n372\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\nperformance. Third, considering that a large number of linear\nmodels must be built to approximate the CDF for a dataset\nwith high skewness, existing learned indexes that allow only\none linear model for a node [ 21,40] need to create a large\nnumber of nodes for such a dataset, resulting in a complex\nindex structure.\nDyTIS targets dynamic datasets with high skewness and/or\nhigh KDD. When designing DyTIS, we took into account the\nvaluable lessons from learned indexes. However, the follow-\ning unique considerations also needed to be distilled into the\ndesign to efficiently support the dynamic nature of datasets.\n1) Free of bulk loading: DyTIS learns and adjusts the CDF\nincrementally as keys are inserted without bulk loading over-\nhead and also without performance degradation caused by\ninaccurate models built during bulk loading. 2) Local model\nre-training: The cost of model retraining should be low to\nhandle high KDD. DyTIS enables models for particular key\nranges to be retrained locally and independently, making it\nmore suitable for dynamic datasets. 3) Multiple models per\nnode: To accommodate key ranges with high skewness more\nefficiently, DyTIS allows a node to have multiple models.\n3 DyTIS: The Index Structure\n3.1 Extendible Hashing\nExtendible hashing is a dynamic indexing structure that can\ngrow andshrink as the workload dynamically changes [ 25].\nIt is unlike traditional hashing structures that require re-\nhashing [20,32,48,52,53]. Figure 4 shows Extendible hash-\ning, in which ğ‘›is the number of bits used for a key ğ¾, and\napseudo-key ğ¾â€²=â„(ğ¾), whereâ„is the hash function, is\nused for indexing [ 25]. In Extendible hashing, the hash table\nis organized with a directory andbuckets. A directory (i.e.,\nğ‘‘ğ‘–ğ‘Ÿ) is an array where prefixes, i.e., the most significant bits\n(MSBs), or suffixes, i.e., the least significant bits (LSBs), of the\npseudo-key are used as an index. In Figure 4(a), two MSBs of\na pseudo-key are used for the directory. The directory has a\nglobal depth ğºğ·that indicates how many MSBs are used as\nan index. Thus, ğºğ·determines the size of the directory.\nEach entry in the directory points to a bucket that can\nstore a fixed number of key-value pairs. Note that a value\nin each pair can be a pointer to an actual value associated\nwith the key. When inserting a key-value pair, ğºğ·MSBs of\nits hash key are first used to find the directory entry, and\nthen it is stored in the bucket pointed to by the directory\nentry (if there is free space). For example, Figure 4(a) shows\nthe state after inserting the key â€œ011101 ...â€ to the hashing\nindex. Each bucket has a local depthğ¿ğ·, whereğ¿ğ·â‰¤ğºğ·,\nindicating that this bucket contains all keys starting with ğ¿ğ·\nMSBs of its associated directory index. Thus, two or more\nentries of the directory can point to the same bucket.\nWhen a bucket finally overfills, the bucket must be split\ninto two buckets. There are two situations when a bucket\n00 01 10 11 GD=2dir[0] dir[1] dir[2] dir[3]\n001101 â€¦\n001011 â€¦\n000101 â€¦011101 â€¦\n010110 â€¦\n011011 â€¦\n011000 â€¦110101 â€¦\n101011 â€¦\n100101 â€¦\n100110 â€¦Original Key ğ¾\nHash Key ğ¾â€™\n100110011101 \nğ¾â€™=ğ’½(ğ¾)\nâ€¦â€¦2ğ‘›-1 0\nLD=2 LD=1 \n000 001 010 011 100 101 110 111GD=3\ndir[0] dir[1] dir[2] dir[3] dir[4] dir[5] dir[6] dir[7]010111â€¦\n001101 â€¦\n001011 â€¦\n000101 â€¦011101 â€¦\n011011 â€¦\n011000â€¦110101 â€¦\n101011 â€¦\n100101 â€¦\n100110 â€¦010110â€¦\n010111â€¦Hash Key ğ¾â€™(a) Insertion\n00 01 10 11 GD=2dir[0] dir[1] dir[2] dir[3]\n001101 â€¦\n001011 â€¦\n000101 â€¦011101 â€¦\n010110 â€¦\n011011 â€¦\n011000 â€¦110101 â€¦\n101011 â€¦\n100101 â€¦\n100110 â€¦Original Key ğ¾\nHash Key ğ¾â€™\n100110011101 \nğ¾â€™=ğ’½(ğ¾)\nâ€¦â€¦2ğ‘›-1 0\nLD=2 LD=1 \n000 001 010 011 100 101 110 111GD=3\ndir[0] dir[1] dir[2] dir[3] dir[4] dir[5] dir[6] dir[7]010111â€¦\n001101 â€¦\n001011 â€¦\n000101 â€¦011101 â€¦\n011011 â€¦\n011000â€¦110101 â€¦\n101011 â€¦\n100101 â€¦\n100110 â€¦010110â€¦\n010111â€¦Hash Key ğ¾â€™\n(b) Directory doubling\nFigure 4. Extendible hashing\nsplits. The first is when ğ¿ğ·<ğºğ·, which means that multi-\nple directory entries were pointing to the bucket as in the\ncase of the rightmost bucket in Figure 4(a). For this case, ğºğ·\nsimply remains the same and ğ¿ğ·of both buckets is increased\nby one, while the contents of the original bucket are adjusted\naccording to the ğ¿ğ·+1MSBs of the pseudo-keys. The sec-\nond situation is when ğºğ·=ğ¿ğ·. In this case, one bucket is\npointed to by only one directory entry. Thus, the directory\nhas to be expanded to accommodate the split, which is re-\nferred to as directory doubling. For this, the number of bits\nused as an index, that is, ğºğ·, must first be increased by one.\nThen, the dividing of the contents and the ğ¿ğ·values are\nadjusted in the same manner as the first case. For example,\nas one more key is added to the bucket pointed to by ğ‘‘ğ‘–ğ‘Ÿ[1]\nin Figure 4(a), the directory is doubled such that the values of\nğ¿ğ·for the buckets pointed to by ğ‘‘ğ‘–ğ‘Ÿ[2]andğ‘‘ğ‘–ğ‘Ÿ[3]become\nthree, while those for other buckets remain unchanged as\nshown in Figure 4(b).\nCCEH [ 49] is a variant of Extendible hashing that uses a\nthree-level structure of a directory, intermediate segments\ncomposed of a number of buckets, and buckets. CCEH utilizes\nMSBs of a pseudo-key as a segment index, while it utilizes\nLSBs of the key as a bucket index in the segment. Having\nintermediate segments is useful in reducing the overhead\nof directory doubling. In DyTIS, we adopt this three-level\nstructure of CCEH, but we do not use LSBs of the keys since\nkeys are stored in sorted order to support scan operations.\n3.2 System Overview\nDyTIS has an Extendible hash table structure, but uses remapped\nkeys as pseudo-keys, rather than hash keys, to preserve the\nnatural order of keys. It also leverages CDFs like learned\nindexes, but, as we will see, not in exactly the same manner.\nFigure 5 presents the architecture of DyTIS as well as a\nwalk-through example that we will use. DyTIS consists of\nmultiple Extendible Hashing (EH) tables and has a key range\n373\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\n01011101\nKâ€™=Remap (1101)Original Key K  (n=8)00 01 10 11\n000 001 010011100 101 110 1111stLevel\n2nd LevelXX011101\nXXX 11110GD=3\nLD=2\nSorted\nbucketsâ€¦0001\n1100â€¦R=2\n01010\n01101\n11011\n11110\nEH[1]Sibling \npointer\nBucket index Segment A0011\n0101\n1011\n1111\nEH[0] EH[2] EH[3]\n=11110dir[0]dir[1]â€¦\nbuc[0]\nbuc[1]Remapped KeyKâ€™\nFigure 5. DyTIS architecture\nof [0,2ğ‘›), whereğ‘›is the number of bits used for a key. It has\na two-level architecture so that the first level has an array\nof EHs. The first level statically divides the entire key range\ninto 2ğ‘…sub-ranges based on ğ‘…MSBs of the key so that each\nEH handles, in the second level, keys only in a given sub-\nrange. This two-level structure allows each EH to deal with\na smaller number of keys within the sub-range individually.\nTherefore, the range of keys for each EH becomes [0,2ğ‘›âˆ’ğ‘…)\nset by the (ğ‘›âˆ’ğ‘…) LSBs from the keys. In Figure 5, ğ‘›=8and\nğ‘…=2, thus, each EH makes use of the six LSBs of the key.\nAn EH table in the second level has a three-level struc-\nture of a directory, segments, and buckets as in CCEH [ 49].\nEach bucket is composed of an array of keys and an array\nof values such that a key and its value are stored in sorted\norder by the values of keys separately in the two different\narrays [ 21]. Also, segments within the same EH maintain a\nsibling pointer to the next segment to accelerate scan perfor-\nmance. Note that buckets have a fixed size. In this three-level\nstructure, each segment contains all keys starting with the\nsameğ¿ğ·MSBs, where ğ¿ğ·is the local depth of the segment.\nIn the example, ğ¿ğ·=2and thus, all keys with MSBs 01 are\nin Segment A. Consequently, the key range of a segment\nbecomes [0,2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·) set by the ( ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·) LSBs of the\nkeys. In Figure 5, the four LSBs (for example, 1101(2)for key\n01011101(2)) are used resulting in a range of [0,24). Note that\nin Figure 5, instead of original keys, remapped keys, which\nare discussed next, are shown in Segment A.\nWe have, so far, only described how the bits (actually their\npositions) that comprise the key are used within DyTIS. Now\nwe describe the key idea behind DyTIS, which is to use the\nraw keys themselves as pseudo-keys, rather than the hash\nkeys, enabling efficient scan operations. However, the key\npredicament here is that non-uniform key distributions may\nresult in a huge and imbalanced directory where a large\nnumber of keys exist in a certain range, while in the rest of\nthe ranges, only a few keys exist so that many entries in the\ndirectory are pointing to the same bucket. Such situations\nwill result in high directory doubling cost. To remedy this\nissue, DyTIS uses remapping functions that re-distribute keys\nwith any distribution uniformly. That is, in each segment\nBucket ID0 123 45 6 7 \nBucket ID0 123 45 6 7 \n(a) Before remapping\nBucket ID0 123 45 6 7 \nBucket ID0 123 45 6 7 \n(b) After remapping\nFigure 6. Adjusting the remapping functions\nwithin the EH, if DyTIS deems the keys within the segment\nto be skewed, remapping spreads the keys evenly over the\nsegment. This is depicted as ğ¾â€²= Remap(1101) in Figure 5.\nDyTIS leverages the CDF for a key distribution as the\nremapping function of each segment. We exploit the fact\nthat since the CDF is a monotonic increasing function, each\nkeyğ¾has a unique ğ¾â€²value, and thus, all the keys with any\ndistribution mapped using its CDF are mapped to a uniform\ndistribution. In DyTIS, the CDF for the remapping function is\napproximated as a set of linear functions (similarly to other\nlearned index techniques [ 21,28,38,57]). That is, given the\nkey range of a segment, the key range is statically divided\ninto 2ğ‘ƒsub-ranges based on ğ‘ƒMSBs of the given keys, and\neach sub-range is associated with a linear function.\nInitially, we assume that keys are uniformly distributed\nwithin each sub-range, initializing the linear function as\nğ¾â€²=ğ¾, as shown in the left sub-figure of Figure 6(a) where\nthere are four sub-ranges for a segment. As keys are inserted\ninto EH, we incrementally and dynamically adjust the lin-\near function (i.e., slope and intercept) for each sub-range to\nreflect the real distribution as in the left sub-figure of Fig-\nure 6(b). For a sub-range where more keys are inserted than\npredicted (for example, [1/4, 1/2)), we increase the slope of\nits linear function, while for a sub-range where less keys are\ninserted than predicted (for example, [0, 1/4)), we decrease\nthe slope of the function. Moreover, intercept values of linear\nfunctions need to be modified such that the functions are\nconnected to handle the entire range of the remapped keys.\n(Note that the right sub-figures of Figure 6 will be discussed\nin Section 3.3.)\nAlong with remapping functions, to handle possibly highly\nskewed key distributions without directory doubling or split,\nDyTIS also exploits segments with varying sizes such that\nDyTIS can dynamically adjust the number of buckets that a\nsegment can hold. We now discuss how a key is rescaled, i.e.,\n374\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\nhow the bucket index of a key is computed, within a segment\nwith multiple buckets. Consider a segment where ğ¾â€²=ğ¹(ğ¾),\nwithğ¾andğ¾â€²being the raw key and the remapped key,\nrespectively, and ğ¹is the scaled approximate CDF for the\ndistribution to the function range (i.e., the range of ğ‘¦-axis\nofğ¹). The function domain (i.e., the range of ğ‘¥-axis ofğ¹) is\nthe same as the key range of the corresponding segment,\nwhich is [0,2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·), while, initially, when the segment has\nonly one bucket, the function range is [0,2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·). As the\nnumber of buckets in the segment, ğµ, increases, this range\nwill proportionally extend to [0, ğµÃ—2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·). Accordingly,\nfunction range [ ğ‘–Ã—2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·,(ğ‘–+1)Ã—2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·) corresponds\nto a bucket index ğ‘–, where 0â‰¤ğ‘–<ğµ. Therefore, with a\ngiven remapped key ğ¾â€², the bucket index, where ğ¾â€²is stored,\ncan be computed by dividing ğ¾â€²with 2ğ‘›âˆ’ğ‘…âˆ’ğ¿ğ·, the size of\nthe function domain. Note that in general, the number of\nbuckets in a segment need not be a multiple of 2 as described\nin Section 3.3 and thus, only the quotient is used since the\nbucket index is an integer. Also, note that in Figure 6(a), the\ndomain of the function is given as [0,1). A similar simplifi-\ncation is made for Figure 7 with the function domain and\nrange. While this is to simplify the explanations, the actual\nfunction domain and range are as discussed above.\n3.3 Individual Operations\nSearch: We explain how the search operation works using\nthe walk-through example in Figure 5. In this figure, we have\nan 8 bit key (i.e., ğ‘›=8) and use two bits in the first level (i.e.,\nğ‘…=2). Assume we want to find key ğ¾=01011101(2). We\nfind EH[1] using two MSBs (01 (2)) ofğ¾. Within EH[1], the\nğ‘›âˆ’ğ‘…LSBs (011101(2)) ofğ¾are used to compute the index in\nthe directory, whose size is always a multiple of 2, using ğºğ·\nMSBs. Asğºğ·is 3, we use three MSBs, 011(2), to find the direc-\ntory index, which points to segment A. Since ğ¿ğ·of segment\nA is 2, its key range is [0,24) and the range of the remap-\nping function is [0,25) as it has two buckets, where ğ‘[0]and\nğ‘[1]correspond to[0,10000(2))and[10000(2),100000(2)),\nrespectively. Then, we remap the four LSBs of ğ¾(1101(2)) to\na new keyğ¾â€²=11110(2), and find the bucket index to be 1\nby dividing ğ¾â€²by24(10000(2)).\nOnce the bucket is located, an exponential search [ 21] is\nperformed on the key array. If ğ¾is found, DyTIS reads the\nvalue ofğ¾stored at the same location in the value array and\nreturns it. Otherwise, it returns â€œnot existâ€.\nScan: For a scan operation, a starting key ğ¾and a scan key\nrangeğ‘are given. DyTIS first finds the index of the directory\nentryğ‘‘that could contain ğ¾. It finds the starting position\nby searching for ğ¾or the smallest key larger than ğ¾in the\nsegment ofğ‘‘ğ‘–ğ‘Ÿ[ğ‘‘]. If not found in that segment, the starting\nposition is the first key in the first bucket of the segment of\nğ‘‘ğ‘–ğ‘Ÿ[ğ‘‘+1]. It then linearly reads ğ‘keys, possibly continuing on\nto subsequent buckets, segments, or EHs, or until it reaches\nthe end of the index. For scanning multiple segments within\nan EH, sibling pointers of segments are used.Algorithm 1 Insert(ğ‘˜ğ‘’ğ‘¦ğ¾ ,ğ‘ ğ‘’ğ‘”ğ‘šğ‘’ğ‘›ğ‘¡ğ‘  ,ğ‘ğ‘¢ğ‘ğ‘˜ğ‘’ğ‘¡ğ‘ )\n1:Ifğ‘inğ‘ is not full, insert ğ¾toğ‘and return;\n2:ğ¿ğ·=a local depth of ğ‘ ;\n3:ğ‘ˆğ‘ = utilization of ğ‘ ;\n4:ifğ¿ğ·<ğºğ·then\n5: ifğ‘ˆğ‘ >ğ‘ˆğ‘¡then\n6: Do Split;\n7: else\n8: Do Remapping;\n9: If it fails, do split;\n10: end if\n11:else ifğ¿ğ·==ğºğ·then\n12: ifğ‘ˆğ‘ >ğ‘ˆğ‘¡then\n13: Do Expansion;\n14: else\n15: Do Remapping;\n16: end if\n17: ifthe above fails then\n18: Do Directory Doubling;\n19: end if\n20:end if\nInsertion: DyTIS inherits the basic schemes of split and\ndirectory doubling of Extendible hashing. DyTIS, though,\nemploys additional schemes, remapping, and expansion, to\nhandle non-uniform key distributions. DyTIS is required to\nuse the MSBs of remapped keys so that keys can be clustered\nby the natural key order in this way. Note that a remapped\nkey is used to find the bucket index but the raw key is stored\nin the bucket. For the operations that alter the indexing\nstructure, we utilize a threshold ğ‘ˆğ‘¡that determines whether\nthe utilization of a segment is high or low.\nAlgorithm 1 shows the insertion algorithm of DyTIS. To\ninsert a key ğ¾, DyTIS first finds bucket ğ‘of segmentğ‘ where\nthe key will be stored, as in the search operation. DyTIS\nchecks if key ğ¾already exists. If so, it performs an in-place\nupdate forğ¾such that the updated value will be stored at the\nsame location in the value array of ğ‘. Otherwise, if ğ‘is not\nfull, DyTIS inserts ğ¾and the value of ğ¾toğ‘(Line 1), which\ncould shift keys larger than ğ¾and their values to maintain\nthe sorted order.\nIfğ‘is full, then there is no space to insert ğ¾. Depending on\nthe local depth of segment ğ‘ , and the current utilization of ğ‘ ,\nDyTIS performs one of the following operations: split, remap-\nping, expansion, and doubling. Note that at the beginning,\nDyTIS only performs basic schemes of Extendible hashing\nuntil EH reaches a certain local depth, having a number of\ninserted keys, before leveraging the key distribution to build\nan index structure.\nLow utilization of segment ğ‘ indicates that the key dis-\ntribution of ğ‘ is currently non-uniform (because the bucket\nof interest is full, yet the overall utilization of the segment\nis low). Therefore, in such cases regardless of ğ¿ğ·<ğºğ·or\n375\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nğ¿ğ·==ğºğ·, DyTIS attempts to adjust the remapping func-\ntions ofğ‘ to alleviate the skewed distribution of keys in ğ‘ \n(Lines 8 and 15). While adjusting the remapping functions,\nit might increase the size of segment ğ‘ .\nOn the other hand, high utilization of ğ‘ means that the\ncurrent remapping functions for ğ‘ are distributing keys uni-\nformly to a good degree, but ğ‘ lacks space to store more keys.\nTherefore, when ğ¿ğ·<ğºğ·, it performs a split (Line 6). On\nthe other hand, when ğ¿ğ·==ğºğ·, DyTIS performs an expan-\nsion, which doubles the size of ğ‘ while scaling the remapping\nfunctions (Line 13). This has the same effect of directory dou-\nbling for keys in segment ğ‘ . As there is a cap on the segment\nsize that is dependent on its local depth, which is described\nin the last part of this section, the expansion and remapping\nof a segment can fail if DyTIS cannot increase the size of ğ‘ \ndue to this limit. To handle the failure, when ğ¿ğ·==ğºğ·, it\nperforms directory doubling (Line 18). When ğ¿ğ·<ğºğ·, if\nremapping fails, it performs a split (Line 9). Note that remap-\nping and expansion do not increase data movement (i.e.,\nmemory copy) as they are performed to avoid segment splits\nthat incur data movement (which is discussed in Section 4).\nNext, we discuss each of the operations in Algorithm 1.\nDirectory Doubling (Line 18): DyTIS uses the same dou-\nbling mechanism as Extendible hashing described previously.\nSplit (Lines 6 and 9): DyTIS uses a similar split mechanism\nas Extendible hashing, but with the following difference.\nWhen the original segment is split into two new segments, it\nis possible that one of the new segments may contain most\nof the keys, if the keys are skewed. Therefore, for each of the\nnew segments, DyTIS first computes the segment size that\nwill accommodate the keys of a sub-range from the original\nsegment and then doubles its size, while keeping the slope(s)\nof the remapping function(s) of the sub-range for the new\nsegment. For example, assume that the original segment has\nfour buckets where one bucket is used to store keys from\nthe left half of its key range and the other three buckets are\nused to store keys from the right half of its key range. Then\nthe segments are doubled such that one segment will have\ntwo buckets, while the other will have six buckets.\nExpansion (Line 13): DyTIS simply doubles the size while\nscaling the remapping functions (i.e., doubling the slope).\nTherefore, a certain key range that originally uses one bucket\nwill use two buckets after the expansion.\nRemapping (Lines 8 and 15): Recall that for a segment ğ‘ ,\nwe divide its key range into multiple sub-ranges. Initially, a\nsegment has one sub-range, but may be divided into multiple\nsub-ranges as the following discussion. Consider that we are\ntrying to insert key ğ¾into bucket ğ‘in segmentğ‘ , but have\nfound thatğ‘is full, but the utilization of ğ‘ is low. It is at this\ncondition that we are performing remapping. Thus, DyTIS\nfirst checks if the sub-ranges of ğ‘ are fine-grained enough\nsuch that each linear function for each sub-range, denoted\nğ‘Ÿ, truly reflects the real CDF of ğ‘Ÿ. For example, Figure 7(a)\nillustrates a case where the DyTIS CDF in [1/4, 1/2) does\n0 1/4 1/2 3/4 1\nKey sub-ranges0.00.20.40.60.81.0CDF\nActual CDF\nDyTIS CDF(a) Four sub-ranges\n0 1/4 1/2 3/4 1\nKey sub-ranges0.00.20.40.60.81.0CDF\nActual CDF\nDyTIS CDF (b) Eight sub-ranges\nFigure 7. Dividing a sub-range into smaller ones\nnot approximate the real CDF accurately. In this sub-range,\nmany keys exist in the left half of the sub-range while only a\nfew keys exist in the right half. In such cases, the DyTIS CDF\nis too coarse and cannot represent the skewness of the sub-\nrange. This results in the utilization of ğ‘Ÿbeing low and yet,\nthe bucket in which ğ¾is to be inserted being full. To remedy\nthis, remapping is employed. In remapping, we partition\nthe key range of ğ‘ into smaller sub-ranges until the target\nsub-range to which ğ¾will belong has utilization larger than\nğ‘ˆğ‘¡. Figure 7(b) shows the case where the four sub-ranges in\nFigure 7(a) are divided into eight sub-ranges. We observe\nthat DyTIS CDF for [1/4, 3/8) and [3/8, 1/2) now becomes\ncloser to the real CDF. For this, the remapping functions also\nneed to be adjusted.\nAdjusting the remapping functions, generally speaking,\nis done in the following manner. If there exists a sub-range\nwhose utilization is low, then DyTIS simply steals some num-\nber of buckets from that sub-range and gives those buckets\nto the target sub-range ğ‘¡with high utilization.\nLet us illustrate how remapping functions are adjusted\nusing the example in Figure 6. In this example, ğ‘ˆğ‘¡=0.5. In\nthe figure, a segment with 8 buckets (b[0] to b[7]) is divided\ninto four sub-ranges, having each sub-range correspond to a\nslope of 8 as in Figure 6(a). To be remapped as Figure 6(b),\nDyTIS steals two buckets, one each from sub-ranges 0 and 2\n(i.e., [0,1/4) and [1/2, 3/4)) whose utilization is 0.25, and gives\nthem to sub-range 2 (i.e., [1/4, 1/2)), altering the remapping\nfunctions as follows. The slopes of sub-ranges 0, 1, 2, and 3\nare first computed as 4, 16, 4, and 8, and the intercepts of the\nsub-ranges are computed such that the remapping functions\nare started at (0,0), (1/4,1), (1/2, 5), and (3/4, 6), respectively.\nAfter remapping, sub-range 1 can use four buckets, lowering\nthe utilization of the sub-range to 0.5 making it the same as\nthe other sub-ranges.\nSpecifically, in DyTIS, we attempt to double the number\nof buckets for the target sub-range ğ‘¡. To do so, we compute\nhow many buckets we can steal from other sub-ranges in\nsegmentğ‘ based on the utilization of a sub-range. For each\nsub-range (that is not ğ‘¡) whose utilization is less than ğ‘ˆğ‘¡, we\ncompute the minimum number of needed buckets. Based on\nthis, we compute the number of buckets that this sub-range\n376\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\ncan give toğ‘¡. If we can steal all the needed buckets from other\nsub-ranges, we adjust the remapping functions accordingly.\nThe above process can fail if the utilization of other sub-\nranges is also high and thus, DyTIS is prevented from steal-\ning the needed buckets from other sub-ranges. In this case,\nDyTIS increases the size of segment ğ‘ such that the number\nof buckets for sub-range ğ‘¡is doubled. Therefore, the slope\nof the remapping function for sub-range ğ‘¡is doubled and\nthus, the overall function range for segment ğ‘ is increased\nproportionally to the number of buckets in ğ‘ .\nOnce the new remapping functions are computed along\nwith the size of the segment, DyTIS creates a new segment\nand copies each key from the old segment to the new segment\nusing the new remapping functions. Once this is done, the\nsegment location that points to the old segment, which is\nstored in the directory entry, is made to point to the new\nsegment. Then, the old segment is deleted.\nDeletion: To delete a key ğ¾, DyTIS searches for the bucket\nwhereğ¾is stored and deletes it from the bucket. This will\nshift keys that are larger than ğ¾and also their values, if\nany. Similar to ALEX [ 21], if deletion causes high under-\nutilization of a bucket, the bucket can be merged with others,\nreducing the size of the segment. This process is similar to\nremapping but in the opposite direction.\nSelecting a segment size: DyTIS basically imposes a limit\non the segment size that is dependent on the local depth\nof the segment. This limit doubles when the local depth in-\ncreases by one so that with a larger local depth, a larger\nnumber of keys can be stored in a segment. The effect of the\nsegment size on performance will differ depending on the\ntype of key distribution. With highly skewed keys, DyTIS will\ninvoke remapping frequently and thus, a large segment size\nwill increase remapping overhead. With uniform keys, then\nDyTIS leverages expansion and thus, a large segment size\nis beneficial as more keys can be handled without increas-\ning the local or global depth. DyTIS optimizes performance\nconsidering both cases as follows. Assume DyTIS starts to\nperform remapping and expansion at local depth ğ¿. Until\nDyTIS reaches a certain local depth ğ¿â€²whereğ¿â€²>ğ¿, it keeps\ntrack of the occurrences of the expansion operations. At lo-\ncal depthğ¿â€², if the portion of segments where expansion is\nperformed is large, this means that the keys are uniformly\ndistributed. Thus, DyTIS increases the limit on the segment\nsize atğ¿â€². Note that the value of ğ¿â€²needs to be selected\nso that DyTIS can collect sufficient information about the\noccurrences of split, remapping, and expansion operations,\nbut, at the same time, early enough such that not too many\ndoubling operations occur. For this, we empirically decide\nthatğ¿â€²=ğ¿+2and use this in our implementation.\n3.4 Concurrency\nWith the advance of multi-core technologies, a server node\ncommonly used for data management systems can leverage\na large number of cores, which requires efficient concurrentaccesses to the index structure [ 14,19,30,31,44,57,58]. Pro-\nviding efficient concurrency support is critical in sustaining\nperformance scalability as the number of cores continues\nto increase [ 19,24,44]. Concurrency is supported in DyTIS\nso that it can be used for a multi-threaded system such as\nMemcached [ 1,27]. Note that storage systems, developed\nfor distributed clusters and/or multi-core servers may lever-\nage multiple single-threaded engines for data access as in\nH-Store [ 6,35] and Redis Cluster [ 3,12]. Such systems may\nalso use the single-threaded version of DyTIS that does not\nuse locks instead of the multi-threaded one discussed in this\nsection. Recall that we adopt the structure of CCEH [ 49],\nwhich supports concurrent accesses based on the two-level\nlocking scheme adapted from Ellis [ 23]. Inherently, DyTIS\nadopts two levels of locking for each EH. At the high level,\nthe directory array ğ‘‘ğ‘–ğ‘Ÿneeds to be synchronized, that is, at\nthe EH level, while at the lower level, we synchronize at\nthe segment level. For segments, synchronization is done\nthrough a metadata container that we call a segment object,\nwhich contains information such as remapping functions of\nthe segment and a pointer to a data array where key-value\npairs are actually stored.\nUsing reader/writer locks, synchronization is administered\nonly at the segment level when performing insert operations\nsuch as the normal insert (which inserts a key to a bucket\nwithout altering the indexing structure), remapping, and\nexpansion, as these operations only change values of the\ninformation inside a segment object. Similarly, for search\nand scan operations, segment level locking is used. For scan,\nmultiple segments, within or across EHs, are locked one by\none over the scan range, and once done, all the locks are\nreleased.\nFor insert operations that change the structure such as the\nsplit, which creates a new segment object and then updates\nthe segment object pointer to the new one, both segment\nand EH level locks are used to prevent other threads from\nperforming directory doubling. Similarly, directory doubling\nor updating a sibling pointer between two segments require\nsegment and EH level lock synchronization.\nNote that CCEH leverages concurrency at finer grains of\nbuckets within segments. We also explored this, but found\nthat performance of DyTIS generally degrades. Our analysis\nshows that this is due to the overhead of additional mem-\nory for the fine-grained locks and the handling of segments\nwith variable sizes, which is unlike CCEH that uses a fixed\nsegment size.\n4 Experimental Results\n4.1 Methodology\nFor our experimental study, we use a machine with two Intel\nCore i9-9900K (8 core, 3.6Ghz) with 16MB L3 cache and 64GB\nDDR DRAM. Ubuntu 18.04 LTS with Linux kernel version\n5.4 was installed on the machine. Hyperthreading is turned\noff during our experiments. To evaluate DyTIS, we compare\n377\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nits performance with the STX B+-tree3[2,10] (hereafter,\nsimply referred to as B+-tree), ALEX [ 7,21], and XIndex [ 8,\n57], which uses a two-level architecture for learned models,\nwhere the first level uses a learned RMI while the second\nlevel uses linear models and supports concurrent operations.\nFor B+-tree, the fanout is set to 128 that shows the best\nperformance in our setup. ALEX and XIndex require bulk\nloading of datasets. Thus, 70% of each dataset are bulk loaded\nfor XIndex, while 10% or 70% are used for ALEX. Note that\nin the original ALEX paper [ 21], the authors use roughly\n10âˆ¼50% of the datasets to train the index. A discussion of\nthe effect of bulk loading is given in Section 4.3. Also, unlike\nDyTIS and XIndex, the original ALEX and B+-tree do not\nsupport in-place updates. For our experiments, we modified\nALEX and B+-tree to support in-place updates as suggested\nwithin the ALEX code4. For DyTIS, in the default setting,\nthe array size in the first level is set to 29(i.e.,ğ‘…=9),ğ‘ˆğ‘¡\nis set to 0.6, and the bucket size is 2KB. The local depth\nğ¿ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ where DyTIS starts remapping and expansion, is set\nto 6. For datasets with large expansion operations (which\nis determined by DyTIS dynamically), at local depth 8, a\nlimit on the segment size ğ¿ğ‘–ğ‘šğ‘–ğ‘¡ğ‘ ğ‘’ğ‘”is increased to 128 times\n(from 2 times by default). We will discuss the effect of these\nparameter settings in Section 4.3. We run the experiments\nwith a single thread, except for those in Section 4.5, and\nreport the average of 3 runs.\n4.2 Datasets\nTable 1 shows the five real-world datasets with different key\ndistribution characteristics used in our experiments where\nMM, ML, RM, RL, and TX denote the Map-M, Map-L, Review-\nM, Review-L, and Taxi datasets, respectively, and L, M, and\nH denote low, medium, and high skewness or KDD, respec-\ntively. For each record in the datasets, the size of the keys is\nconfigured to 8 bytes as done in prior works [ 21,26,40,57]\nand also the size of the values is configured in the same\nway. In the table, for each dataset, we provide the number of\nkeys (in millions: M), the key range size (i.e., the difference\nbetween the minimum and maximum key values), and the\ndataset size.\nFor the datasets, we adopt real-world datasets that have\nbeen widely used in existing indexing studies [ 21,22,28,\n57,62]. To generate unique integer keys, transformations\nare applied with selected fields in the real-world datasets.\nMM and ML are generated by combining the longitudes and\nlatitudes of two different continents, respectively, from the\nOpenStreetMap [ 29,51] (similarly to ALEX). RM and RL are\ngenerated from the Amazon review data [ 46]. From the orig-\ninal data, we select three fields, item ID, user ID, and review\ntime, and generate unique keys by concatenating them. TX\n3We choose this open-sourced B+-tree implementation as it was the choice\nof multiple earlier studies on efficient index structures [21, 45, 57].\n4https://github.com/microsoft/ALEX/blob/master/src/core/alex.h, lines 1123\nand 1124Table 1. Datasets used in our experiments\nName DescriptionNumber\nof keysKey range\nsize (Ã—1018)Dataset\nsizeSkewness,\nKDD\nMM South America 356M 5.92 7.0GB L,M\nML Africa 903M 15.4 18GB L,M\nRM Deduplicated data 82M 1.31 1.6GB H,L\nRL Ratings only 228M 5.18 4.5GB H,L\nTX Taxi trip in New York 325M 1.08 6.7GB M,H\nconsists of pickup time and drop-off time fields of yellow\ntaxi trips in New York City from 2017 to 2020 in the TLC\nTrip Record data [ 15]. Note that unlike ALEX [ 21], where\nthe keys are randomly shuffled, our datasets are generated\nfrom the original datasets without shuffling and thus, the\nkey distribution can dynamically shift over time as discussed\nin Section 2.1.\n4.3 Results with Real-World Workloads\nWe evaluate the performance of the four different index\nstructures, DyTIS, ALEX, XIndex, and B+-tree, using seven\nworkloads that roughly correspond to workloads Load, A,\nB, C, D, E and F of YCSB [ 16]. For ALEX, two versions with\n10% and 70% bulk loading, ALEX-10 and ALEX-70, are used.\nUsing such workloads for real-world datasets is similar to\nthat done for the ALEX study [ 21], where for each workload\nexcept Load, a batch of the workload is repeated for at least\n60 seconds. The Load workload is composed of 100% inserts,\nthe A workload, 50% reads and 50% updates, the B workload,\n95% reads and 5% updates, the C workload, 100% reads, and\nthe E workload, 95% scans where the range value is set to\n100, and 5% inserts. Note that unlike in the ALEX study [ 21],\nwe also include workloads F, which consists of 50% reads and\n50% read-modify-write, and Dâ€™. Dâ€™ is the same as the original\nworkload D in that it includes 5% inserts, but is different in\nthat the 95% reads are selected from the existing keys, and not\nfrom the latest keys5. For all workloads except Load, the keys\nare selected from the datasets using Zipfian distribution (with\nthe default Zipfian constant in YCSB, 0.99). Note that we also\nran all the experiments with uniform distribution as well,\nfinding the results to be similar with Zipfian distribution.\nFor workloads A, B, C, and F, the Load workload is first\nexecuted to insert all the records in the dataset to the index.\nIn this Load phase, for ALEX, 10%/70% are bulk loaded and\n90%/30% are inserted, while for XIndex, 70% are bulk loaded\nand 30% are inserted. Then, we run each workload such that\nthe number of operations performed is more than 50% of the\ndataset size for at least 60 seconds. For workloads Dâ€™ and E\nthat include inserting new keys, 80% of the keys are loaded.\nThen, we start measuring the throughput until all the keys\nin the dataset are inserted.\nFigure 8 shows the throughput of seven workloads of YCSB\n(i.e., Load, A, B, C, Dâ€™, E, and F), respectively, for DyTIS, ALEX-\n10, ALEX-70, XIndex, and B+-tree. From the results of Load, a\n5Measuring the performance of repeated batches makes the exact modeling\nof the D workload complex.\n378\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\nMM ML RM RL TX\n(a) Load024681012 Throughput (M ops/sec)XX\nMM ML RM RL TX\n(b) Workload A02468\nXX\nMM ML RM RL TX\n(c) Workload B0246810\nX\nX\nMM ML RM RL TX\n(d) Workload C0246810\nX X\nMM ML RM RL TX\n(e) Workload D'0246810 Throughput (M ops/sec)XX\nMM ML RM RL TX\n(f) Workload E0123\nX\nX\nMM ML RM RL TX\n(g) Workload F0123456\nXXDyTIS\nALEX-10\nALEX-70\nXIndex\nB+-tree\nFigure 8. Throughput of seven real-world workloads over various datasets\npurely insert workload, shown in Figure 8(a), we observe the\nfollowing: First, DyTIS tends to provide better throughput\nthan the other indexes for datasets with high KDD such as TX\nand for datasets with medium KDD and low skewness such\nas ML, as the local adjustment of its model is effective when\nthe key distribution changes. Second, for datasets with high\nskewness such as RM and RL, DyTIS performance is lower\n(24.86% lower on average) than that of B+-tree because of\nremapping overhead. However, it is still higher than those of\nthe learned indexes, ALEX-10, ALEX-70, and XIndex. Third,\nDyTIS shows better insertion performance than ALEX for\nmore dynamic datasets of RM, RL and TX. Note that for\nALEX and XIndex, the results do not include bulk loaded\nkeys. Now, from the results of a purely search workload C\nshown in Figure 8(d), we observe that the search throughput\nof DyTIS is the highest, with DyTIS being higher than the\nother indexes except for MM, where ALEX-70 is 6.8% better\nthan DyTIS.\nThe results of the above insert and search operations exem-\nplify the key differences between DyTIS and ALEX and their\nperformance implications. Recall that DyTIS uses a hash-\nbased structure with segments, each with multiple models,\nwhile ALEX uses an adaptive RMI based structure with data\nnodes, each with a single model. Due to these structural\ndifferences, for insert operations, with DyTIS, the overhead\nfor maintaining the index structure changes due to splits,\nexpansions, and remappings is low when KDD is relatively\nhigh, such as for ML and TX, as the local model is effectively\nadjusted. This overhead, though, increases with higher skew-\nness, such as for RM and RL. With ALEX-10, we find that sim-\nilar structure maintenance overhead is, compared to DyTIS,\n50% higher on average as it needs to perform many more\nexpensive operations to retrain or create models for datasetswith high skewness or high KDD. For MM, ML, RM, RL, and\nTX with ALEX-10, the percent of those expensive operations\nover the total maintaining operations is 21%, 30%, 41%, 47%,\nand 24%, respectively. For TX, even though the size of TX is\naround 3 times smaller than ML, the absolute number of the\nmaintaining operations and consequently, that of the expen-\nsive operations are around 10 and 8 times higher than those\nof ML. For search operations, we first note that to query a\nkey, DyTIS always uses a linear model once, but ALEX uses\nat least two linear models, one at the root node and the other\nat a data node, with, possibly, more models in internal nodes\nof the tree. For the datasets, the average number of models\nused in ALEX-10 is up to 3.33 Ã—(for RL) of that in DyTIS. Due\nto this, we find that the traversal overhead to traverse to a\ntarget bucket or data node for a given key with ALEX-10 is\n22% higher on average than that with DyTIS. Finally, we find\nthat the performance difference between DyTIS and ALEX\nfor searching or inserting a key within a bucket or data node\nis not a dominant factor.\nIn Figure 8, we also observe that for MM, compared to\nDyTIS, the performance of ALEX-10 is higher for Load, while\nthat of ALEX-70 is higher for workloads B, C, and Dâ€™. MM has\nlow skewness and is smaller in size relative to ML. Also, its\nKDD is medium. Therefore, the built structure with ALEX-10\nhas minimum depth similar to the Uniform dataset, showing\nhigher insert performance. Note that even though the index\nstructure with ALEX-10 has minimum depth, its search per-\nformance is lower than DyTIS as the root node has a large\nnumber of children nodes (i.e. data nodes), which increases\nthe traversal overhead. With ALEX-70, the effect of KDD for\nMM becomes much lower as it bulk loads a larger amount of\nthe dataset compared to ALEX-10. Therefore, ALEX-70 ends\nup having the smallest number of nodes for the index among\n379\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nMM ML RM RL TX\n(a) Insertion036912 Throughput (M ops/sec)X\nMM ML RM RL TX\n(b) Search05101520\nXDyTIS CCEH EH\nFigure 9. Comparison of DyTIS with CCEH and EH\nall the datasets (which is 7% smaller than that with ALEX-10).\nConsequently, its traversal overhead becomes small, result-\ning in good performance as exemplified for workloads B, C,\nand Dâ€™.\nFrom Figure 8, we also observe that aside from Load and\nMM with ALEX-70 as mentioned above, DyTIS performance\nis always the highest among all the indexes for all datasets\nas DyTIS provides good search and update performance. For\nworkload E, we find that performance of B+-tree is lower\nthan those of ALEX and DyTIS mainly due to its small data\nnode size. The average data node size is 4.0 âˆ¼295.1Ã—and\n4.7âˆ¼319.2Ã—smaller than those of ALEX(-10 and -70) and\nDyTIS, respectively, forcing accesses to a much larger num-\nber of data nodes.\nOverall, XIndex performs considerably worse than DyTIS\nor ALEX because it employs a delta index and a tempo-\nrary delta index to handle key insertion along with a back-\nground compaction thread. Such additional structures and\nbackground thread overhead for merging data in the index\nand the delta index take their toll compared to DyTIS and\nALEX, which are free of such structures and overhead. In\nthe experiments, XIndex cannot load MM and ML (with 70%\nbulk loading) due to out-of-memory faults and thus, the\nsubsequent workloads cannot run.\nNext, we discuss the performance of DyTIS when using\nthe datasets in Groups 2 and 3 of Figure 1, which are rela-\ntively simple ones. For the datasets in Group 2, which are the\nshuffled versions of those in Group 1, DyTIS shows the high-\nest throughput among all the indexing techniques for all the\nYCSB workloads, except for Load with RM and RL, similarly\nto the original datasets, and for MM. The datasets in Group 3,\nwhich are used in the ALEX study [ 21], are much less dy-\nnamic than those in Group 1 such that their key distributions\nare easy to predict, which is ideal for traditional learned in-\ndexes. For the Uniform dataset of one billion keys, ALEX-10\nshows 18.6% better throughput than DyTIS on average for\nthe YCSB workloads. DyTIS, however, still provides up to\n3.5Ã—(for workload C) higher throughput compared to B+-\ntree for all the workloads. For Longlat, which has the highest\nskewness in Group 3, DyTIS performs better (7.3 âˆ¼16.6%)\nthan ALEX-10 for workloads A, E and F, while performing\nlower (2.5âˆ¼6.4%) for workloads Load, B, C and Dâ€™.Figure 9 shows the performance of DyTIS, CCEH, and\nExtendible Hashing (EH) described in Section 3.1. Figure 9\nshows that DyTIS provides better insert and search perfor-\nmance than EH for all the datasets. It also shows that for\ninsertion, CCEH and DyTIS give and take depending on the\ndataset, while for search performance, DyTIS is lower than\nCCEH by an average of 50%. Note that CCEH fails for ML\ndue to out-of-memory. Generally speaking, DyTIS supports\nscans by replacing a hash function with a remapping func-\ntion resulting in deteriorated search performance compared\nto CCEH, but which is still higher than B+-tree, ALEX-10,\nALEX-70 (except for MM), and XIndex.\nEffect of Bulk Loading on Learned Indexes We discuss\nhow bulk loading affects the performance of ALEX and\nXIndex, which influences our first design consideration. As\nshown in Figure 8, ALEX-70 does not always provide bet-\nter performance than ALEX-10. In particular, for RM, the\nperformance of ALEX-10 is better than or similar to that\nof ALEX-70 for the YCSB workloads. Also, as shown in Fig-\nure 8(a), the load performance of ALEX-70 tends to be lower\nthan that of ALEX-10. This is because as nodes are updated\nwith splits and expansions due to insertion, the structure\nbecomes more complex and more keys need to be moved. In\nthe end, we find that the node size and depth of ALEX-70\nare 337% larger and 26% deeper, on average, than ALEX-10\nafter bulk loading. To observe the influence of bulk loading\nfurther, we also evaluate ALEX with 30%, 50%, and 90% bulk\nloading for each dataset. Figure 10 shows the throughput of\neach workload normalized to that with ALEX-10. Note that\nfor workloads Dâ€™ and E, 80% of the keys are loaded as in the\nearlier experiments except for ALEX-90 (which bulk-loads\n90% of the dataset), and the number of operations for each of\nthese workloads remains the same over various bulk loading\npercentages except for Load, and workloads Dâ€™ and E with\nALEX-90. The key finding from the experiments is that no\nregularity can be found between load size and performance.\nFor example, in the case of RM, as we increase bulk load-\ning from 10% to 70%, performance generally decreases or\nremains similar, while for TX, ALEX-50 performs better than\nor similarly to ALEX-90, in most cases. Also, for MM and\nML, ALEX-70/90 tend to provide better performance than\nALEX with lower bulk loading (i.e., ALEX-10/30/50), while\nALEX-10/30/50 show similar performance with each other.\nOverall, for our datasets, the performance difference over\nthe different bulk loading percentages is as high as 21%, 31%,\n36%, 40%, 42%, 14%, and 32% for the Load, A, B, C, Dâ€™, E,\nand F workloads, respectively. Our deeper analysis reveals\nthat bulk loading is critical with ALEX as once the structure\nis built with a particular depth during bulk loading, ALEX\nvigorously deters increasing this depth.\nSimilar experiments were conducted for XIndex for TX,\nshowing similar impact of bulk loading percentages on its\nperformance to ALEX. We also find that for RM and RL,\ninsertion failed with less than 70% bulk loading, conjecturing\n380\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\nLoad A B C D E F\n(a) MM0.00.20.40.60.81.01.21.4 Normalized ThroughputLoad A B C D E F\n(b) ML0.00.20.40.60.81.01.21.4ALEX-30 ALEX-50 ALEX-70 ALEX-90\nLoad A B C D E F\n(c) RM0.00.20.40.60.81.01.21.4\nLoad A B C D E F\n(d) RL0.00.20.40.60.81.01.21.4\nLoad A B C D E F\n(e) TX0.00.20.40.60.81.01.21.4\nFigure 10. Throughput of ALEX over various bulk loading percentages normalized to ALEX-10\nthat memory access issues during insertion result in the\nfailures. Thus, 70% bulk loading was chosen for the earlier\nexperiments.\nInsertion Breakdown and Tail Latency Analysis: We\nanalyze the insertion execution time breakdown for DyTIS,\nthat is, how much time it spends for each operation. We\nobserve that for RM and RL with high skewness, remapping\nis leveraged the most. For TX with high KDD, it spends\na relatively large portion of time for both remapping and\nexpansion. We also analyze that the overhead of remapping\nis composed of memory copy overhead (58% on average over\nthe five datasets) and remapping function adjustments (42%),\nand thus, it is proportional to the size of the segment. It is\nworth noting that considering a segment with size ğ‘¥, the\noverhead of remapping, which ends up having a size slightly\nlarger than ğ‘¥, is similar to or only a bit larger than that of\nsplit, which ends up having a size of 2ğ‘¥, for the segment.\nFurthermore, the expansion of ğ‘¥, which results in a segment\nof2ğ‘¥, has the same memory copy overhead as split, having\nsimilar overhead to remapping.\nTable 2 presents the average, the 99th and the 99.99th\npercentile tail latency numbers of workloads Load and A,\nwhere best values are bold faced, for DyTIS, ALEX-10, ALEX-\n70, XIndex, and B+-tree. In the case of the Load workload,\nDyTIS is better than ALEX(-10 and -70) for dynamic datasets,\nRM, RL, and TX. However, B+-tree performs the best for\nmost cases. For the 99.99th percentile tail latency, DyTIS per-\nforms worse than B+-tree due to the overhead for remapping\nlarge segments. However, we also see that the 99.99th tail\nlatency of ALEX(-10 and -70) whose (re)training operations\ncan be more expensive is 3.3 Ã—and 3.1Ã—larger on average,\nrespectively, than that of DyTIS. For workload A, DyTIS does\nbetter than ALEX-10 and ALEX-70 except for the average\nlatency for TX with ALEX-70. Note that though not shown,\nfor the other workloads, DyTIS provides better or similar\nperformance compared to ALEX in most cases.\nMemory Usage Analysis: We measure the maximum mem-\nory usage of each index structure using â€œdstatâ€ where the\namount of memory used for the benchmark execution and\nfor bulk loading in the case of ALEX and XIndex is included,\nthough, it is important to note that the memory needed for\nbulk loading is released once the bulk loading process isdone. We find that on average, the maximum memory us-\nage of ALEX-10, ALEX-30, ALEX-50, ALEX-70, ALEX-90,\nand B+-tree is 25.9%, 26.3%, 27.0%, 22.6%, 5.3%, and 27.4%\nless than that of DyTIS for the YCSB workloads. DyTIS uses\nmore memory because a segment consists of multiple buck-\nets as in CCEH [ 49] and thus, each key must be stored in\na particular bucket unlike ALEX and B+-tree. Interestingly,\nthe memory usage of ALEX-90 increases (using only 5.3%\nless memory than DyTIS) as the sum of the memory needed\nfor bulk loading and for the index structure when the bulk\nloading is done, which is the point of the maximum memory\nusage, becomes much larger. For XIndex, we observe that\nits memory usage is much higher than the others (e.g., 4.2Ã—\nhigher than DyTIS).\nParameter Effect: We investigate how the control parame-\nters affect DyTIS performance. We use throughput as our per-\nformance metric, averaged over all the datasets for the YCSB\nworkloads, normalized to that of the default parameter value.\nWith smaller ğµğ‘ ğ‘–ğ‘§ğ‘’, insertion and search become cheaper as\nthe overhead to shift keys for insert and to find a key within\na bucket is reduced. However, more buckets need to be ac-\ncessed for scan, degrading its performance. Over different\nğµğ‘ ğ‘–ğ‘§ğ‘’values, 1KB, 2KB (default), and 4KB, insertion, search,\nand scan throughput changes are âˆ’16.3~0.2%,âˆ’10.1~12.8%,\nandâˆ’13.2~2.8%, respectively. Larger ğ¿ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ reduces remap-\nping overhead, improving insertion performance, but gener-\nates more segments, degrading search and scan performance.\nOn the other hand, smaller ğ¿ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ degrades insertion perfor-\nmance due to structure changes based on a small number of\ninserted keys. Over different ğ¿ğ‘ ğ‘¡ğ‘ğ‘Ÿğ‘¡ values, 4, 6 (default), 8,\nand 10, insertion, search, and scan performance is affected by\nâˆ’11.0~7.3%,âˆ’2.8~0.3%, andâˆ’5.5~2.8%, respectively. Larger\nfirst level bit ğ‘…increases the number of EHs having the effect\nof spreading keys and reducing rebalancing overhead, result-\ning in improved insertion performance. The performance\nchange for insertion over different ğ‘…values, 7, 9 (default), 11,\nand 13 isâˆ’6.7~6.2%. Lower utilization threshold ğ‘ˆğ‘¡reduces\nremappings, improving insertion performance. However, this\nalso decreases memory utilization. Over different ğ‘ˆğ‘¡values,\n0.5, 0.55, 0.6 (default), 0.65, and 0.7, insertion performance\nis affected byâˆ’12.6~6.8%. In addition, larger ğ¿ğ‘–ğ‘šğ‘–ğ‘¡ğ‘ ğ‘’ğ‘”causes\ndegradation of insertion performance for datasets with high\n381\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nTable 2. Average, 99th and 99.99th percentile tail latencies. na: not available (Best values are bold faced)\nAv\nerage / 99th / 99.99th percentile latency (in ns)\nLoad YCSB\nA\nDy\nTIS ALEX -10 ALEX -70 XInde x B+-tr e\ne Dy\nTIS ALEX -10 ALEX -70 XInde x B+-tr e\ne\nMM 223/624/43054 201/582/122640 210/573/131120 na/na/na 254/740/12050 185/541/797 207/627/954 197/610/920 na/na/na 361/800/2063\nML 233/643/51346 221/617/131380 224/583/119780 na/na/na 275/802/2253 211/586 /828 257/712/1093 236/685/1044 na/na/na 401/842/2190\nRM 477/1066/46086 542/1240/90494 538/1204/61704 668/1288/18195 370/810 /2793 269/719/1008 274/743/1097 271/748/1434 376/892/2535 277/679 /970\nRL 460/1052/37576 560/1235/86570 578/1178/91276 618/1225/16448 374/852 /2456 313/772 /1473 396/971/2209 348/912/2178 445/1047/5806 339/773/1994\nTX 97/140 /26250 169/338/177400 165/324/172400 281/536/9360 184/307/1698 236/653/898 273/743/1287 230/674/950 697/1557/15996 340/770/2000\nMM ML RM RL TX\nInsertion0.001.002.003.00Normalized throughput4.4\n(a) KDDDyTIS ALEX-10 B+-tree\nMM ML RM RL TX\nSearch0.000.250.500.751.00\nMM ML RM RL TX\nInsertion0.000.250.500.751.00Normalized throughput\n(b) SkewnessDyTIS ALEX-10 B+-tree\nMM ML RM RL TX\nSearch0.000.250.500.751.00\nFigure 11. Influence of dynamic characteristics\nskewness (like RM, RL and TX) due to frequent remappings,\nbut for datasets with low skewness (like MM and ML), it has\nno effect on insertion performance while search and scan\nperformance increases.\n4.4 Effects of Dynamic Characteristics\nIn this section, we discuss how our second and third design\nconsiderations in Section 2.2 are manifested in supporting dy-\nnamic datasets by analyzing the effects of KDD and skewness\nof datasets on the performance of the indexes. We consider\ninsertion and search, and use the results of Load and work-\nload C of the previous section. To separately analyze the\neffect of KDD, we compare the performance of the original\ndatasets where the key distribution changes over time with\nthat of the shuffled versions that remove such changes. Fig-\nure 11(a) shows the insert and search performance of DyTIS,\nALEX-10, and B+-tree for the original datasets, normalized\nto that for the shuffled versions. From these results, we ob-\nserve the following: (1) In the case of insert, higher KDD\nhas a more positive effect on performance for all the index\nstructures. For RM and RL whose KDD is very small, the\nperformance difference is relatively small compared to other\ndatasets. For TX with high KDD, the performance improve-\nment of DyTIS is as high as 339.76%. Similarly, MM and ML,\nwith relatively high KDD, also show substantial performance\ndifferences. This is due to the spatial locality that exists inthe original dataset, and the indexes exploit this when in-\nserting. (2) Let us now observe search, which is an operation\nthat we call upon after the structure is constructed. First,\nwe see that B+-tree is insensitive to KDD, which is logical\nas a balanced structure is constructed in the end, regardless\nof KDD. In contrast, we observe that DyTIS and ALEX-10\nare affected somewhat, with ALEX-10 being more strongly\nso. Also, the performance degradation generally tends to be\nproportional to the KDD values of the datasets. The reason\nfor this is that the structures were constructed in a more im-\nbalanced manner due to the spatial locality (i.e., KDD) during\ninsertion. However, ALEX-10 is more strongly affected as its\nstructure becomes more complex with a larger number of\nlinear models when the models in the upper hierarchy are\ninaccurate for a dataset with high KDD such as TX, unlike\nDyTIS which is based on remapping. One peculiar point is\nthat of RL, which has relatively low KDD and yet, strongly\ninfluences ALEX-10. We find that though KDD of RL is not\nhigh, as RL also has very high skewness, this results in diver-\ngence affecting the built structure more strongly, increasing\nthe number of linear models by 83,209 (20% increase).\nWe now analyze the effect of skewness, and to do so, we\ncompare the performance for the shuffled versions of the\noriginal datasets with that for the Uniform datasets of the\nsame size, which have no skewness. Figure 11(b) shows the\nperformance for shuffled datasets normalized to that for the\ncorresponding Uniform datasets. We observe the following:\n(1) For B+-tree, there is no performance effect caused by\nskewness of a dataset as the normalized performance for\nall the datasets is 1. (2) DyTIS is robust to low skewness, as\nwe can see from the performance results for MM and ML.\nHowever, for datasets with moderate and high skewness, the\nperformance of DyTIS degrades as DyTIS needs more models\nto accommodate such skewness. (3) Finally, we find ALEX-10\nis sensitive to any degree of skewness. This is because, unlike\nDyTIS, ALEX-10 creates a node for every model resulting in a\nlarge number of nodes compared to the Uniform dataset. For\nRM and RL with high skewness, its performance degradation\nbecomes severe as the number of nodes increases by 1341Ã—\non average, while, for DyTIS, there is only a 17Ã—increase.\n4.5 Concurrency\nAll results presented thus far were with single thread ex-\necutions as ALEX and B+-tree are single thread solutions.\nIn this section, we evaluate the performance of DyTIS with\n382\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\n1 2 4 8\nNumber of threads02468 Throughput (M ops/sec)\nInsertion\nDyTIS\nXIndex\n1 2 4 8\nNumber of threads0510152025\nSearch\nDyTIS\nXIndex\n1 2 4 8\nNumber of threads02468\nScan 100\nDyTIS\nXIndex\n(a) RL\n1 2 4 8\nNumber of threads05101520 Throughput (M ops/sec)\nInsertion\nDyTIS\nXIndex\n1 2 4 8\nNumber of threads0102030\nSearch\nDyTIS\nXIndex\n1 2 4 8\nNumber of threads036912\nScan 100\nDyTIS\nXIndex\n(b) TX\nFigure 12. Throughput with different number of threads\nXIndex over various numbers of threads. Figure 12 (a) and\n(b) show the throughput of DyTIS and XIndex on the RL and\nTX datasets, respectively, where requests for operations are\nassigned to threads in round-robin fashion. As shown, DyTIS\nprovides performance better than that of XIndex for all op-\nerations. For TX, the insertion scalability of DyTIS increases\nonly slightly when eight threads are used. The reason for\nthis is that TX is highly dynamic such that a range of keys ac-\ncessed within a certain time period concurrently by multiple\nthreads is much smaller compared to other datasets. Thus,\nthe benefit of higher concurrency becomes smaller. Note\nthat though not shown, the performance trend of DyTIS and\nXIndex for RM is similar to that for RL.\n5 Related Work\nThere are efforts to make an efficient updatable learned in-\ndex [ 21,26,28,57,61]. LIPP [ 61]6attempts to reduce the\nexponential search cost in the leaf node as well as to elimi-\nnate unbounded last-mile searches in ALEX. The PGM index\nhas the structure of a linear piecewise regression model to\npredict the CDF of each segment where the data is parti-\ntioned [ 26]. The FITing-Tree also leverages piecewise linear\nfunctions [ 28], while APEX proposes a learned index that\nis optimized for persistent memory [ 43]. The RS index [ 38]\nthat leverages a linear spine has been proposed as another\nway of approximating the CDF of the dataset. Flood [ 50] and\nTsunami [ 22] were proposed as multi-dimensional learned\nindexes to address the limitation of existing learned indexes\nthat consider one-dimensional data. However, Flood and\n6In our setup, LIPP cannot build an index for 4 of the 5 datasets due to\nout-of-memory or type conversion errors. While we were able to insert for\nRM, we observed a huge number of key losses upon search.Tsunami aim to optimize multi-dimensional read-only work-\nloads and do not support insertion operations and concur-\nrency. While most learned index designs consider only inte-\nger keys, there have been efforts to support variable-length\nstring keys [ 55,59]. Kipf et al. used real-world datasets for\nbenchmarks for learned indexes but only focused on search\nperformance over sorted datasets [ 37]. Simultaneously to\nour work, skewness of a dataset is similarly analyzed for\nlearned indexes, where skewness is called â€œhardnessâ€ [60].\nBourbon [ 18] and SageDB [ 39] leverage learning of data\npatterns for database system components. Bourbon [ 18] re-\nplaces block indexes in Log-structured Merge Tree (LSM)\nwith learned indexes, while SageDB [ 39] employs index struc-\ntures and sorting algorithms based on learned models.\nHybrid indexing structures that use both the hash and B+-\ntree indexes have been investigated for large-scale memory-\nbased data storage systems [ 36] and for DRAM-NVM mem-\nory systems [ 63]. HiKV proposes to use a hash index per-\nsisted to persistent memory, for single-key operations such\nas insert and search, while it also uses a B+-tree index, which\nresides in DRAM, to support scan operations [ 63]. Wormhole\nis an in-memory indexing scheme that makes use of the hash,\nB+-tree, and trie, focusing on string key optimizations [ 62].7\nFor concurrency, Masstree leverages fine-grained locking\nfor updates and optimistic concurrency control [ 13,47] for\nlookups [ 44]. Clevel hashing [ 14] supports high scalability\nby eliminating expensive lock-based concurrency control.\n6 Conclusion\nIn this paper, we presented an index structure targeting dy-\nnamic datasets called DyTIS, which is simultaneously ef-\nficient for all search, insert, and scan operations. We also\ndefined what dynamic datasets are and presented a means\nto quantify their characteristics. Our experimental results\nwith real-world datasets demonstrate that DyTIS provides\nperformance that is superior to ALEX, the state-of-the-art\nlearned index.\nAcknowledgement\nWe would like to thank our shepherd Angela Demke Brown\nand the anonymous reviewers for their invaluable comments.\nThis research was partly supported by the MSIT (Ministry\nof Science and ICT), Korea, under the ITRC (Information\nTechnology Research Center) support program (IITP-2023-\n2021-0-01817) supervised by the IITP (Institute for Informa-\ntion & Communications Technology Planning & Evaluation)\nand National Research Foundation of Korea (NRF) (NRF-\n2022R1H1A2091297), and also by Samsung Electronics Co.,\nLtd. Young-ri Choi is the corresponding author.\n7As it targets string keys, its performance is not high for our datasets that\nare composed of integer keys, as similarly discussed by Marcus et al. [45].\n383\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nReferences\n[1] 2004. Memcached. http://memcached.org/.\n[2] 2007. STX B+-tree. https://github.com/bingmann/stx-btree .\n[3] 2009. Redis. https://redis.io/docs/management/scaling/.\n[4]2011. Kyoto Cabinet: a straightforward implementation of DBM. http:\n//fallabs.com/kyotocabinet/.\n[5]2014. A fast and Lightweight Key-Value Store Library by Google.\nhttp://code.google.com/p/leveldb.\n[6] 2016. H-Store. https://hstore.cs.brown.edu/.\n[7] 2020. ALEX. https://github.com/microsoft/ALEX/tree/57efb5.\n[8] 2020. XIndex. https://ipads.se.sjtu.edu.cn:1312/opensource/xindex.\n[9]DF Andrews, AM Herzberg, DF Andrews, and AM Herzberg. 1985.\nMonthly mean sunspot numbers. Data: A Collection of Problems from\nMany Fields for the Student and Research Worker (1985), 67â€“74.\n[10] Timo Bingmann. 2007. STX B+ Tree C++ Template Classes. https:\n//panthema.net/2007/stx-btree/\n[11] Zhichao Cao, Siying Dong, Sagar Vemuri, and David H.C. Du. 2020.\nCharacterizing, Modeling, and Benchmarking RocksDB Key-Value\nWorkloads at Facebook. In Proceedings of 18th USENIX Conference on\nFile and Storage Technologies (FAST). 209â€“223.\n[12] Josiah Carlson. 2013. Redis in action. Simon and Schuster.\n[13] Sang Kyun Cha, Sangyong Hwang, Kihong Kim, and Keunjoo Kwon.\n2001. Cache-Conscious Concurrency Control of Main-Memory Indexes\non Shared-Memory Multiprocessor Systems. In Proceedings of the VLDB\nEndowment. 181â€“190.\n[14] Zhangyu Chen, Yu Huang, Bo Ding, and Pengfei Zuo. 2020. Lock-free\nConcurrent Level Hashing for Persistent Memory. In Proceedings of\nthe 2020 USENIX Annual Technical Conference (USENIX ATC). 799â€“812.\n[15] NYC Taxi & Limousine Commission. 2020. TLC Trip Record Data.\nhttps://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page.\n[16] Brian F. Cooper, Adam Silberstein, Erwin Tam, Raghu Ramakrishnan,\nand Russell Sears. 2010. Benchmarking Cloud Serving Systems with\nYCSB. In Proceedings of the ACM Symposium on Cloud Computing\n(SoCC). 143â€“154.\n[17] Toshiba Memory Corporation. 2019. Toshiba Memory Corporation\nIntroduces XL-FLASHâ„¢ Storage Class Memory Solution. https://www.\nkioxia.com/en-jp/about/news/2019/20190806-1.html.\n[18] Yifan Dai, Yien Xu, Aishwarya Ganesan, Ramnatthan Alagappan,\nBrian Kroth, Andrea Arpaci-Dusseau, and Remzi Arpaci-Dusseau. 2020.\nFrom WiscKey to Bourbon: A Learned Index for Log-Structured Merge\nTrees. In Proceedings of 14th USENIX Symposium on Operating Systems\nDesign and Implementation (OSDI). 155â€“171.\n[19] Tudor David, Rachid Guerraoui, and Vasileios Trigonakis. 2015. Asyn-\nchronized Concurrency: The Secret to Scaling Concurrent Search Data\nStructures. ACM SIGARCH Computer Architecture News (2015), 631â€“\n644.\n[20] Martin Dietzfelbinger and Christoph Weidling. 2007. Balanced alloca-\ntion and dictionaries with tightly packed constant size bins. Theoretical\nComputer Science 380 (June 2007), 47â€“68.\n[21] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do,\nYinan Li, Hantian Zhang, Badrish Chandramouli, Johannes Gehrke,\nDonald Kossmann, David Lomet, and Tim Kraska. 2020. ALEX: An\nUpdatable Adaptive Learned Index. In Proceedings of the 2020 ACM\nSIGMOD International Conference on Management of Data (SIGMOD).\n969â€“984.\n[22] Jialin Ding, Vikram Nathan, Mohammad Alizadeh, and Tim Kraska.\n2020. Tsunami: A learned multi-dimensional index for correlated data\nand skewed workloads. In Proceedings of the VLDB Endowment. 74â€“86.\n[23] Carla Schlatter Ellis. 1983. Extendible Hashing for Concurrent Oper-\nations and Distributed Data. In Proceedings of the 2nd ACM SIGACT-\nSIGMOD Symposium on Principles of Database Systems (PODS). 106â€“\n116.\n[24] Franz Faerber, Alfons Kemper, Per-Ã…ke Larson, Justin Levandoski,\nThomas Neumann, Andrew Pavlo, et al .2017. Main Memory DatabaseSystems. Foundations and TrendsÂ® in Databases (2017), 1â€“130.\n[25] Ronald Fagin, Jurg Nievergelt, Nicholas Pippenger, and H. Raymond\nStrong. 1979. Extendible Hashingâ€”a Fast Access Method for Dynamic\nFiles. ACM Transactions on Database Systems (TODS) (1979), 315â€“344.\n[26] Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-index: a\nfully-dynamic compressed learned index with provable worst-case\nbounds. In Proceedings of the VLDB Endowment. 1162â€“1175.\n[27] Brad Fitzpatrick. 2004. Distributed Caching with Memcached. Linux\njournal (2004), 5.\n[28] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca,\nand Tim Kraska. 2019. FITing-Tree: A Data-aware Index Structure.\nInProceedings of the 2019 ACM SIGMOD International Conference on\nManagement of Data (SIGMOD). 1189â€“1206.\n[29] Geofabrik. 2019. OpenStreetMap Data Extracts. https://download.\ngeofabrik.de/.\n[30] Maurice Herlihy, Victor Luchangco, and Mark Moir. 2003. Obstruction-\nFree Synchronization: Double-Ended Queues as an Example. In Pro-\nceedings of the 23rd International Conference on Distributed Computing\nSystems (ICDCS). 522â€“529.\n[31] Deukyeon Hwang, Wook-Hee Kim, Youjip Won, and Beomseok Nam.\n2018. Endurable Transient Inconsistency in Byte-Addressable Persis-\ntent B+-Tree. In Proceedings of the 16th Usenix Conference on File and\nStorage Technologies (FAST). 187â€“200.\n[32] LR Johnson. 1961. An Indirect Chaining Method for Addressing on\nSecondary Keys. Commun. ACM (1961), 218â€“222.\n[33] Myoungsoo Jung. 2022. Hello Bytes, Bye Blocks: PCIe Storage Meets\nCompute Express Link for Memory Expansion (CXL-SSD). In Proceed-\nings of the 14th ACM Workshop on Hot Topics in Storage and File Systems\n(HotStorage). 45â€“51.\n[34] Olzhas Kaiyrakhmet, Songyi Lee, Beomseok Nam, Sam H Noh, and\nYoung-ri Choi. 2019. SLM-DB: Single-Level Key-Value Store with\nPersistent Memory. In Proceedings of the 17th USENIX Conference on\nFile and Storage Technologies (FAST). 191â€“205.\n[35] Robert Kallman, Hideaki Kimura, Jonathan Natkins, Andrew Pavlo,\nAlexander Rasin, Stanley Zdonik, Evan PC Jones, Samuel Madden,\nMichael Stonebraker, Yang Zhang, et al .2008. H-Store: A High-\nPerformance, Distributed Main Memory Transaction Processing Sys-\ntem. In Proceedings of the VLDB Endowment. 1496â€“1499.\n[36] Ankita Kejriwal, Arjun Gopalan, Ashish Gupta, Zhihao Jia, Stephen\nYang, and John Ousterhout. 2016. SLIK: Scalable Low-Latency In-\ndexes for a Key-Value Store. In Proceedings of the 2016 USENIX Annual\nTechnical Conference (USENIX ATC). 57â€“70.\n[37] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian,\nAlfons Kemper, Tim Kraska, and Thomas Neumann. 2019. SOSD: A\nBenchmark for Learned Indexes. In Proceedings of NeurIPS Workshop\non Machine Learning for Systems.\n[38] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Al-\nfons Kemper, Tim Kraska, and Thomas Neumann. 2020. RadixSpline:\nA Single-Pass Learned Index. In Proceedings of the Third International\nWorkshop on Exploiting Artificial Intelligence Techniques for Data Man-\nagement (aiDM). 1â€“5.\n[39] Tim Kraska, Mohammad Alizadeh, Alex Beutel, Ed H. Chi, Ani Kristo,\nGuillaume Leclerc, Samuel Madden, Hongzi Mao, and Vikram Nathan.\n2019. SageDB: A Learned Database System. In Proceedings of the 9th\nBiennial Conference on Innovative Data Systems Research (CIDR).\n[40] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis.\n2018. The Case for Learned Index Structures. In Proceedings of the\n2018 ACM SIGMOD International Conference on Management of Data\n(SIGMOD). 489â€“504.\n[41] Solomon Kullback. 1997. Information theory and statistics. Courier\nCorporation.\n[42] Justin J. Levandoski, Per-Ã…ke Larson, and Radu Stoica. 2013. Identifying\nHot and Cold Data in Main-Memory Databases. In Proceedings of 2013\nIEEE 29th International Conference on Data Engineering (ICDE) . 26â€“37.\n384\n\nEuroSys â€™23, May 8â€“12, 2023, Rome, Italy Jin Yang, Heejin Yoon, Gyeongchan Yun, Sam H. Noh, and Young-ri Choi\n[43] Baotong Lu, Jialin Ding, Eric Lo, Umar Farooq Minhas, and Tianzheng\nWang. 2021. APEX: A High-Performance Learned Index on Persistent\nMemory. In Proceedings of the VLDB Endowment. 597â€“610.\n[44] Yandong Mao, Eddie Kohler, and Robert Tappan Morris. 2012. Cache\nCraftiness for Fast Multicore Key-Value Storage. In Proceedings of the\n7th ACM European Conference on Computer Systems (EuroSys). 183â€“\n196.\n[45] Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian,\nSanchit Misra, Alfons Kemper, Thomas Neumann, and Tim Kraska.\n2020. Benchmarking Learned Indexes. In Proceedings of the VLDB\nEndowment. 1â€“13.\n[46] Julian McAuley and Alex Yang. 2016. Addressing Complex and Subjec-\ntive Product-Related Queries with Customer Reviews. In Proceedings\nof the 25th International Conference on World Wide Web. 625â€“635.\n[47] Paul E McKenney, Jonathan Appavoo, Andi Kleen, Orran Krieger,\nRusty Russell, Dipankar Sarma, and Maneesh Soni. 2001. Read-copy\nupdate. In AUUG Conference Proceedings. 175.\n[48] Robert Morris. 1968. Scatter Storage Techniques. Commun. ACM\n(1968), 38â€“44.\n[49] Moohyeon Nam, Hokeun Cha, Young-ri Choi, Sam H. Noh, and Beom-\nseok Nam. 2019. Write-Optimized Dynamic Hashing for Persistent\nMemory. In Proceedings of the 17th USENIX Conference on File and\nStorage Technologies (FAST). 31â€“44.\n[50] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska.\n2020. Learning Multi-Dimensional Indexes. In Proceedings of the 2020\nACM SIGMOD International Conference on Management of Data (SIG-\nMOD). 985â€“1000.\n[51] OpenStreetMap on AWS. 2021. Amazon AWS. https://registry.\nopendata.aws/osm/.\n[52] Rasmus Pagh and Flemming Friche Rodler. 2004. Cuckoo Hashing.\nJournal of Algorithms (2004), 122â€“144.\n[53] W. W. Peterson. 1957. Addressing for Random-Access Storage. IBM\nJournal of Research and Development (1957), 130â€“146.\n[54] SAMSUNG. 2017. Ultra-low latency with Samsung Z-NAND\nSSD. https://www.samsung.com/us/labs/pdfs/collateral/Samsung_Z-\nNAND_Technology_Brief_v5.pdf .\n[55] Benjamin Spector, Andreas Kipf, Kapil Vaidya, Chi Wang, Umar Farooq\nMinhas, and Tim Kraska. 2021. Bounding the Last Mile: Efficient\nLearned String Indexing. In Proceedings of 3rd International Workshop\non Applied AI for Database Systems and Applications (AIDB). 1â€“5.\n[56] Michael Stonebraker and Ariel Weisberg. 2013. The VoltDB Main\nMemory DBMS. IEEE Database Engineering Bulletin (2013), 21â€“27.\n[57] Chuzhe Tang, Youyun Wang, Zhiyuan Dong, Gansen Hu, Zhaoguo\nWang, Minjie Wang, and Haibo Chen. 2020. XIndex: A Scalable Learned\nIndex for Multicore Data Storage. In Proceedings of the 25th ACM\nSIGPLAN Symposium on Principles and Practice of Parallel Programming\n(PPoPP). 308â€“320.\n[58] Josh Triplett, Paul E McKenney, and Jonathan Walpole. 2011. Resizable,\nScalable, Concurrent Hash Tables via Relativistic Programming. In\nProceedings of the 2011 USENIX Annual Technical Conference (USENIX\nATC). 11.\n[59] Youyun Wang, Chuzhe Tang, Zhaoguo Wang, and Haibo Chen. 2020.\nSIndex: A Scalable Learned Index for String Keys. In Proceedings of the\n11th ACM SIGOPS Asia-Pacific Workshop on Systems (APSys). 17â€“24.\n[60] Chaichon Wongkham, Baotong Lu, Chris Liu, Zhicong Zhong, Eric Lo,\nand Tianzheng Wang. 2022. Are Updatable Learned Indexes Ready?\n(2022), 3004â€“3017.\n[61] Jiacheng Wu, Yong Zhang, Shimin Chen, Yu Chen, Jin Wang, and\nChunxiao Xing. 2021. Updatable Learned Index with Precise Positions.\nInProceedings of the VLDB Endowment. 1276â€“1288.\n[62] Xingbo Wu, Fan Ni, and Song Jiang. 2019. Wormhole: A Fast Ordered\nIndex for In-Memory Data Management. In Proceedings of the 14th\nACM European Conference on Computer Systems (EuroSys). 1â€“16.[63] Fei Xia, Dejun Jiang, Jin Xiong, and Ninghui Sun. 2017. HiKV: A\nHybrid Index Key-Value Store for DRAM-NVM Memory Systems. In\nProceedings of the 2017 USENIX Annual Technical Conference (USENIX\nATC). 349â€“362.\n[64] Qing Xie, Chaoyi Pang, Xiaofang Zhou, Xiangliang Zhang, and Ke\nDeng. 2014. Maximum error-bounded Piecewise Linear Represen-\ntation for online stream approximation. In Proceedings of the VLDB\nEndowment. 915â€“937.\n[65] Adar Zeitak and Adam Morrison. 2021. Cuckoo Trie: Exploiting\nMemory-Level Parallelism for Efficient DRAM Indexing. In Proceedings\nof the ACM SIGOPS 28th Symposium on Operating Systems Principles\n(SOSP). 147â€“162.\nA Artifact Appendix\nA.1 Abstract\nDyTIS (Dynamic dataset Targeted Index Structure) is an\nindex that targets dynamic datasets. DyTIS, though based\non the structure of Extendible hashing, leverages the CDF of\nthe key distribution of a dataset, and learns and adjusts its\nstructure as the dataset grows. The key novelty behind DyTIS\nis to group keys by the natural key order and maintain keys\nin sorted order in each bucket to support scan operations\nwithin a hash index.\nThe artifact is available as a public repository on Github at\nhttps://github.com/unist-ssl/DyTIS. The DOI of the artifact\nishttps://doi.org/10.5281/zenodo.7721895.\nA.2 Description & Requirements\nA.2.1 Hardware dependencies. For our experimental\nstudy, we use a machine with two Intel Core i9-9900K (8\ncore, 3.6Ghz) with 16MB L3 cache and 64GB DDR DRAM.\nA.2.2 Software dependencies.\nâ€¢Ubuntu 18.04 LTS with Linux kernel version 5.4\nâ€¢g++ 8.4\nâ€¢libboost-dev 1.65.1\nA.2.3 Benchmarks. We provide a sample dataset, review-\nsmall.csv (initial 1 million data of review-M), which is stored\nin Google Drive.\nâ€¢review-small.csv :https://bit.ly/3FjYJOZ\nA.3 Set-up\nThe instructions for set-up are referred to README.md in\nthe repository of our source code.\nâ€¢To install libboost: sudo apt-get install libboost-all-dev\nA.4 Evaluation Workflow\nA.4.1 Major claims.\nâ€¢(C1): DyTIS efficiently supports all search, insert, and\nscan operations for dynamic datasets without requir-\ning an up-front training phase (i.e., bulk loading).\nâ€¢(C2): DyTIS shows the performance using seven work-\nloads that roughly correspond to workloads Load, A,\n385\n\nDyTIS: A Dynamic Dataset Targeted Index Structure Simultaneously Efficient for Search, Insert, and Scan EuroSys â€™23, May 8â€“12, 2023, Rome, Italy\nB, C, D, E, and F of YCSB. This is proven by the experi-\nment (E2) described in Section 4.3 whose results are\nillustrated in Figure 8.\nA.4.2 Experiments.\nExperiment (E1): Availability of source code [ a few\nhuman-minutes ]: It shows insert, search and scan perfor-\nmance of DyTIS.\n[Preparation] Before running the experiment, the dataset\nto be used in the experiment should be downloaded.\n[Execution] The experiment has been automated by the\nscript (scripts/run_benchmark.sh ). The script will automat-\nically run the experiments of insert, search, and then scan\nworkloads over a given dataset.\nâ€¢To run benchmarks (insert, search and scan) on the\nreview-small dataset in the path data/ :\n- ./scripts/run_benchmark.sh data/review-small.csv\n[Results] All throughput and latency results are saved as a\nlog file in benchmark/result/.Experiment (E2): Real-world workloads [ 10 human-\nminutes ]: It shows results with real-world workloads that\nroughly correspond to workloads Load, A, B, C, D, E, and F\nof YCSB.\n[Preparation] Before running the experiment, the dataset\nto be used in the experiment should be downloaded and\nlocated in the proper path (e.g., in data/review-small.csv ). If\nthe dataset is not the aforesaid one (e.g., different dataset or\ndifferent path), modify dataset_files properly in the script\nscripts/run_ycsb_style_exp.sh.\n[Execution] The experiment has been automated by the\nscript (scripts/run_ycsb_style_exp.sh ). The script will auto-\nmatically run the experiments of seven real-world workloads\nover a given dataset.\nâ€¢To run real-world workloads:\n- ./scripts/run_ycsb_style_exp.sh\n[Results] All throughput and latency results for each work-\nload are saved as a log file in benchmark/result/.\n386",
  "textLength": 92497
}