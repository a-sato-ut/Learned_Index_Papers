{
  "paperId": "68bc259a5eba4182c98d92f0242b13457fa8d69b",
  "title": "Improving Online Algorithms via ML Predictions",
  "pdfPath": "68bc259a5eba4182c98d92f0242b13457fa8d69b.pdf",
  "text": "Improving Online Algorithms via ML Predictions∗\nRavi Kumar\nGoogle\nravi.k53@gmail.comManish Purohit\nGoogle\nmpurohit@google.comZoya Svitkina\nGoogle\nzoya@google.com\nAbstract\nIn this work we study the problem of using machine-learned predictions to improve\nthe performance of online algorithms. We consider two classical problems, ski\nrental and non-clairvoyant job scheduling, and obtain new online algorithms that\nuse predictions to make their decisions. These algorithms are oblivious to the\nperformance of the predictor, improve with better predictions, but do not degrade\nmuch if the predictions are poor.\n1 Introduction\nDealing with uncertainty is one of the most challenging issues that real-world computational tasks,\nbesides humans, face. Ranging from “will it snow next week?” to “should I rent an apartment or\nbuy a house?”, there are questions that cannot be answered reliably without some knowledge of the\nfuture. Similarly, the question of “which job should I run next?” is hard for a CPU scheduler that\ndoes not know how long this job will run and what other jobs might arrive in the future.\nThere are two interesting and well-studied computational paradigms aimed at tackling uncertainty.\nThe first is in the field of machine learning where uncertainty is addressed by making predictions\nabout the future. This is typically achieved by examining the past and building robust models based\non the data. These models are then used to make predictions about the future. Humans and real-world\napplications can use these predictions to adapt their behavior: knowing that it is likely to snow next\nweek can be used to plan a ski trip. The second is in the field of algorithm design. Here, the effort\nhas to been to develop a notion of competitive ratio2for the goodness of an algorithm in the presence\nof an unknown future and develop online algorithms that make decisions heedless of the future but\nare provably good in the worst-case , i.e., even in the most pessimistic future scenario. Such online\nalgorithms are popular and successful in real-world systems and have been used to model problems\nincluding paging, caching, job scheduling, and more (see the book by Borodin and El-Yaniv [5]).\nRecently, there has been some interest in using machine-learned predictions to improve the quality\nof online algorithms [ 21,19]. The main motivation for this line of research is two-fold. The first\nis to design new online algorithms that can avoid assuming a worst-case scenario and hence have\nbetter performance guarantees both in theory and practice. The second is to leverage the vast\namount of modeling work in machine learning, which precisely deals with how to make predictions.\nFurthermore, as machine-learning models are often retrained on new data, these algorithms can\nnaturally adapt to evolving data characteristics. When using the predictions, it is important that\nthe online algorithm is unaware of the performance of the predictor and makes no assumptions on\nthe types of prediction errors. Additionally, we desire two key properties of the algorithm: (i) if\nthe predictor is good, then the online algorithm should perform close to the best offline algorithm\n(consistency ) and (ii) if the predictor is bad, then the online algorithm should gracefully degrade, i.e.,\nits performance should be close to that of the online algorithm without predictions ( robustness ).\n∗The conference version [18] of this work appeared in NeurIPS 2018.\n2Informally, competitive ratio compares the worst-case performance of an online algorithm to the best offline\nalgorithm that knows the future.arXiv:2407.17712v1  [cs.DS]  25 Jul 2024\n\nOur problems. We consider two basic problems in online algorithms and show how to use machine-\nlearned predictions to improve their performance in a provable manner. The first is ski rental , in\nwhich a skier is going to ski for an unknown number of days and on each day can either rent skis at\nunit price or buy them for a higher price band ski for free from then on. The uncertainty is in the\nnumber of skiing days, which a predictor can estimate. Such a prediction can be made reasonably\nwell, for example, by building models based on weather forecasts and past behavior of other skiers.\nThe ski rental problem is the canonical example of a large class of online rent-or-buy problems, which\narise whenever one needs to decide between a cheap short-term solution (“renting”) and an expensive\nlong-term one (“buying”). Several extensions and generalizations of the ski rental problem have\nbeen studied leading to numerous applications such as dynamic TCP acknowledgement [ 11], buying\nparking permits [ 22], renting cloud servers [ 14], snoopy caching [ 13], and others. The best known\ndeterministic algorithm for ski rental is the break-even algorithm: rent for the first b−1days and\nbuy on day b. It is easy to observe that the break-even algorithm has a competitive ratio of 2 and no\ndeterministic algorithm can do better. On the other hand, Karlin et al. [ 12] designed a randomized\nalgorithm that yields a competitive ratio ofe\ne−1≈1.58, which is also optimal.\nThe second problem we consider is non-clairvoyant job scheduling . In this problem a set of jobs, all\nof which are available immediately, have to be scheduled on one machine; any job can be preempted\nand resumed later. The objective is to minimize the sum of completion times of the jobs. The\nuncertainty in this problem is that the scheduler does not know the running time of a job until it\nactually finishes. Note that a predictor in this case can predict the running time of a job, once again, by\nbuilding a model based on the characteristics of the job, resource requirements, and its past behavior.\nNon-clairvoyant job scheduling, introduced by Motwani et al. [ 24], is a basic problem in online\nalgorithms with a rich history and, in addition to its obvious applications to real-world systems, many\nvariants and extensions of it have been studied extensively in the literature [ 9,3,1,10]. Motwani et\nal. [24] showed that the round-robin algorithm has a competitive ratio of 2, which is optimal.\nMain results. Before we present our main results we need a few formal notions. In online algorithms,\nthecompetitive ratio of an algorithm is defined as the worst-case ratio of the algorithm cost to the\noffline optimum. In our setting, this is a function c(η)of the error ηof the predictor3. We say that an\nalgorithm is γ-robust ifc(η)≤γfor all η, and that it is β-consistent ifc(0) = β. So consistency is a\nmeasure of how well the algorithm does in the best case of perfect predictions, and robustness is a\nmeasure of how well it does in the worst-case of terrible predictions.\nLetλ∈(0,1)be a hyperparameter. For the ski rental problem with a predictor, we first obtain a\ndeterministic online algorithm that is (1 + 1 /λ)-robust and (1 +λ)-consistent (Section 2.2). We\nnext improve these bounds by obtaining a randomized algorithm that is (1+1/b\n1−e−(λ−1/b))-robust and\n(λ\n1−e−λ)-consistent, where bis the cost of buying (Section 2.3). For the non-clairvoyant scheduling\nproblem, we obtain a randomized algorithm that is (2/(1−λ))-robust and (1/λ)-consistent. Note\nthat the consistency bounds for all these algorithms circumvent the lower bounds, which is possible\nonly because of the predictions.\nIt turns out that for these problems, one has to be careful how the predictions are used. We illustrate\nthrough an example that if the predictions are used naively, one cannot ensure robustness (Section 2.1).\nOur algorithms proceed by opening up the classical online algorithms for these problems and using\nthe predictions in a judicious manner. We also conduct experiments to show that the algorithms we\ndevelop are practical and achieve good performance compared to ones that do not use any prediction.\nRelated work. The work closest to ours is that of Medina and Vassilvitskii [ 21] and Lykouris\nand Vassilvitskii [ 19]. The former used a prediction oracle to improve reserve price optimization,\nrelating the gap beween the expected bid and revenue to the average predictor loss. In a sense,\nthis paper initiated the study of online algorithms equipped with machine learned predictions. The\nlatter developed this framework further, introduced the concepts of robustness and consistency,\nand considered the online caching problem with predictions. It modified the well-known Marker\nalgorithm to use the predictions ensuring both robustness and consistency. While we operate in the\nsame framework, none of their techniques are applicable to our setting. Another recent work is that\n3The definition of the prediction error ηis problem-specific. In both the problems considered in this paper, η\nis defined to be the L1norm of the error.\n2\n\nof Kraska et al. [ 17] that empirically shows that better indexes can be built using machine learned\nmodels; it does not provide any provable guarantees for its methods.\nThere are other computational models that try to tackle uncertainty. The field of robust optimiza-\ntion [ 16] considers uncertain inputs and aims to design algorithms that yield good performance\nguarantees for any potential realization of the inputs. There has been some work on analyzing\nalgorithms when the inputs are stochastic or come from a known distribution [ 20,23,6]. In the\noptimization community, the whole field of online stochastic optimization concerns online decision\nmaking under uncertainty by assuming a distribution on future inputs; see the book by Russell Bent\nand Pascal Van Hentenryck [ 4]. Our work differs from these in that we do not assume anything about\nthe input; in fact, we do not assume anything about the predictor either!\n2 Ski rental with prediction\nIn the ski rental problem, let rentals cost one unit per day, bbe the cost to buy, xbe the actual number\nof skiing days, which is unknown to the algorithm, and ybe the predicted number of days. Then\nη=|y−x|is the prediction error. Note that we do not make any assumptions about its distribution.\nThe optimum cost is OPT = min {b, x}.\n2.1 Warmup: A simple consistent, non-robust algorithm\nWe first show that an algorithm that naively uses the predicted number of days to decide whether or\nnot to buy is 1-consistent, i.e., its competitive ratio is 1 when η= 0. However, this algorithm is not\nrobust, as the competitive ratio can be arbitrarily large in case of incorrect predictions.\nAlgorithm 1: A simple 1-consistent algorithm\nify≥bthen\nBuy on the first day.\nelse\nKeep renting for all skiing days.\nend\nLemma 2.1. LetALG denote the cost of the solution obtained by Algorithm 1 and let OPT denote\nthe optimal solution cost on the same instance. Then ALG≤OPT +η.\nProof. We consider different cases based on the relative values of the prediction yand the actual\nnumber of days xof the instance. Recall that Algorithm 1 incurs a cost of bwhenever the prediction\nis at least band incurs a cost of xotherwise.\n•y≥b, x≥b=⇒ALG =b=OPT .\n•y < b, x < b =⇒ALG =x=OPT\n•y≥b, x < b =⇒ALG =b≤x+y−x=x+η=OPT +η\n•y < b, x ≥b=⇒ALG =x < b +x−y=b+η=OPT +η\nA major drawback of Algorithm 1 is its lack of robustness. In particular, its competitive ratio can be\nunbounded if the prediction yis small but x≫b. Our goal next is to obtain an algorithm that is both\nconsistent and robust.\n2.2 A deterministic robust and consistent algorithm\nIn this section, we show that a small modification to Algorithm 1 yields an algorithm that is both\nconsistent and robust. Let λ∈(0,1)be a hyperparameter. As we see later, varying λgives us a\nsmooth trade-off between the robustness and consistency of the algorithm.\nTheorem 2.2. With a parameter λ∈(0,1), Algorithm 2 has a competitive ratio of at most\nmin\u001a1 +λ\nλ,(1 +λ) +η\n(1−λ)OPT\u001b\n. In particular, Algorithm 2 is (1 + 1 /λ)-robust and (1 +λ)-\nconsistent.\n3\n\nAlgorithm 2: A deterministic robust and consistent algorithm.\nify≥bthen\nBuy on the start of day ⌈λb⌉\nelse\nBuy on the start of day ⌈b/λ⌉\nend\nProof. We begin with the first bound. Suppose y≥band the algorithm buys the skis at the start of\nday⌈λb⌉. Since the algorithm incurs a cost of b+⌈λb⌉−1whenever x≥ ⌈λb⌉, the worst competitive\nratio is obtained when x=⌈λb⌉, for which OPT =⌈λb⌉. In this case, we have ALG =b+⌈λb⌉−1≤\nb+λb≤\u00001+λ\nλ\u0001\n⌈λb⌉=\u00001+λ\nλ\u0001\nOPT . On the other hand, when y < b , the algorithm buys skis at the\nstart of day ⌈b/λ⌉and rents until then. In this case, the worst competitive ratio is attained whenever\nx=⌈b/λ⌉as we have OPT =bandALG =b+⌈b/λ⌉ −1≤b+b/λ=\u00001+λ\nλ\u0001\nOPT .\nTo prove the second bound, we need to consider the following two cases. Suppose y≥b. Then,\nfor all x <⌈λb⌉, we have ALG =OPT =x. On the other hand, for x≥ ⌈λb⌉, we have\nALG =b+⌈λb⌉ −1≤(1 + λ)b≤(1 + λ)(OPT +η). The second inequality follows since\neither OPT =b(ifx≥b) orb≤y≤OPT +η(ifx < b ). Suppose y < b . Then, for all\nx≤b, we have ALG =OPT =x. Similarly, for all x∈(b,⌈b/λ⌉), we have ALG =x≤y+η <\nb+η=OPT +η. Finally for all x≥ ⌈b/λ⌉, noting that η=x−y > b/λ−b= (1−λ)b/λ,\nwe have ALG =b+⌈b/λ⌉ −1≤b+b/λ< b+ (1\n1−λ)η=OPT + (1\n1−λ)η. Thus we obtain\nALG≤(1 +λ)OPT + (1\n1−λ)η, completing the proof.\nThus, Algorithm 2 gives an option to trade-off consistency and robustness. In particular, greater trust\nin the predictor suggests setting λclose to zero as this leads to a better competitive ratio when ηis\nsmall. On the other hand, setting λclose to one is conservative and yields a more robust algorithm.\n2.3 A randomized robust and consistent algorithm\nIn this section we consider a family of randomized algorithms and compare their performance against\nan oblivious adversary. In particular, we design robust and consistent algorithms that yield a better\ntrade-off than the above deterministic algorithms. Let λ∈(1/b,1)be a hyperparameter. For a given\nλ, Algorithm 3 samples the day when skis are bought based on two different probability distributions,\ndepending on the prediction received, and rents until that day.\nAlgorithm 3: A randomized robust and consistent algorithm\nify≥bthen\nLetk← ⌊λb⌋;\nDefine qi←\u0000b−1\nb\u0001k−i·1\nb(1−(1−1/b)k)for all 1≤i≤k;\nChoose j∈ {1. . . k}randomly from the distribution defined by qi;\nBuy at the start of day j.\nelse\nLetℓ← ⌈b/λ⌉;\nDefine ri←\u0000b−1\nb\u0001ℓ−i·1\nb(1−(1−1/b)ℓ)for all 1≤i≤ℓ;\nChoose j∈ {1. . . ℓ}randomly from the distribution defined by ri;\nBuy at the start of day j.\nend\nTheorem 2.3. Algorithm 3 yields a competitive ratio of at most min{1+1/b\n1−e−(λ−1/b),λ\n1−e−λ(1 +η\nOPT)}.\nIn particular, Algorithm 3 is (1+1/b\n1−e−(λ−1/b))-robust and (λ\n1−e−λ)-consistent.4\n4The conference version [ 18] of this paper incorrectly claimed a slightly stronger robustness of1\n1−e−(λ−1/b).\n4\n\nProof. We consider different cases depending on the relative values of yandx.\n(i)y≥b, x≥k. Here, we have OPT = min {b, x}. Since the algorithm incurs a cost of (b+i−1)\nwhen we buy at the beginning of day i, we have\nE[ALG] =kX\ni=1(b+i−1)qi=kX\ni=1(b+i−1)\u0012b−1\nb\u0013k−i1\nb(1−(1−1/b)k)=k\n1−(1−1/b)k\n≤k\n1−e−k/b≤\u0012k/b\n1−e−k/b\u0013\n(OPT +η)≤\u0012λ\n1−e−λ\u0013\n(OPT +η).\n(ii)y≥b, x < k . Here, we have OPT =x. On the other hand, the algorithm incurs a cost of\n(b+i−1)only if it buys at the beginning of day i≤x. In particular, we have\nE[ALG] =xX\ni=1(b+i−1)qi+kX\ni=x+1xqi\n=1\nb(1−(1−1/b)k)\"xX\ni=1(b+i−1)\u0012b−1\nb\u0013k−i\n+kX\ni=x+1x\u0012b−1\nb\u0013k−i#\n=x\n1−(1−1/b)k≤\u00121\n1−e−k/b\u0013\nOPT ≤\u00121\n1−e−(λ−1/b)\u0013\nOPT,\nwhich establishes robustness. In order to prove consistency, we can rewrite the RHS as follows\nE[ALG]≤\u00121\n1−e−k/b\u0013\nOPT =\u0012k/b\n1−e−k/b\u0013\nOPT +\u0012(b−k)/b\n1−e−k/b\u0013\nx\n≤\u0012k/b\n1−e−k/b\u0013\nOPT +\u0012k/b\n1−e−k/b\u0013\nη≤\u0012λ\n1−e−λ\u0013\n(OPT +η),\nsince x < k andb−k≤η.\n(iii)y < b, x < ℓ . Here, we have OPT = min {b, x}. On the other hand, the expected cost of the\nalgorithm can be computed similar to (ii)\nE[ALG] =xX\ni=1(b+i−1)ri+ℓX\ni=x+1xri≤\u00121\n1−e−ℓ/b\u0013\nx\n≤\u00121\n1−e−1/λ\u0013\n(OPT +η)≤\u0012λ\n1−e−λ\u0013\n(OPT +η).\n(iv)y < b, x ≥ℓ. Here, we have OPT =b. The expected cost incurred by the algorithm is as in (i).\nE[ALG] =ℓX\ni=1(b+i−1)ri=ℓ\n1−(1−1/b)ℓ≤⌈b/λ⌉\n(1−e−ℓ/b)\n≤\u00121/λ+1/b\n(1−e−1/λ)\u0013\nOPT ≤\u00121 + 1 /b\n1−e−(λ−1/b)\u0013\nOPT,\nwhere the last inequality is proven in Lemma A.2 in the Appendix. This completes the proof of\nrobustness. To prove consistency, we rewrite the RHS as follows.\nE[ALG]≤ℓ\n1−e−ℓ/b≤ℓ\n1−e−1/λ=1\n1−e−1/λ(b+ℓ−b)\n≤1\n1−e−1/λ(OPT +η)≤\u0012λ\n1−e−λ\u0013\n(OPT +η).\nAlgorithms 2 and 3 both yield a smooth trade-off between the robustness and consistency guarantees\nfor the ski rental problem. As shown in Figure 1, the randomized algorithm offers a much better\ntrade-off by always guaranteeing smaller consistency for a given robustness guarantee. We remark\nthat setting λ= 1in Algorithms 2 and 3 allows us to recover the best deterministic and randomized\nalgorithms for the classical ski rental problem without using predictions.\n2.4 Extensions\n5\n\nFigure 1: Ski rental: Robustness vs.\nconsistency.Consider a generalization of the ski rental problem where we\nhave a varying demand xifor computing resources on each day\ni. Such a situation models the problem faced while designing\nsmall enterprise data centers. System designers have the choice\nof buying machines at a high setup cost or renting machines\nfrom a cloud service provider to handle the computing needs\nof the enterprise. One can satisfy the demand in two ways:\neither pay 1to rent one machine and satisfy one unit of demand\nfor one day, or pay bto buy a machine and use it to satisfy\none unit of demand for all future days. It is easy to cast the\nclassical ski rental problem in this framework by setting xi= 1\nfor the first xdays and to 0 later. Kodialam [ 15] considers\nthis generalization and gives a deterministic algorithm with a\ncompetitive ratio of 2 as well as a randomized algorithm with\ncompetitive ratio ofe\ne−1.\nNow suppose we have predictions yifor the demand on day i. We define η=P\ni|xi−yi|to be the\ntotalL1error of the predictions. Both Algorithms 2 and 3 extend naturally to this setting to yield the\nsame robustness and consistency guarantees as in Theorems 2.2 and 2.3. Our results follow from\nviewing an instance of ski rental with varying demand problem as kdisjoint instances of the classical\nski rental problem, where kis an upper bound on the maximum demand on any day. The proofs are\nsimilar to those in Sections 2.2 and 2.3; we omit them for brevity.\n3 Non-clairvoyant job scheduling with prediction\nWe consider the simplest variant of non-clairvoyant job scheduling, i.e., scheduling njobs on a\nsingle machine with no release dates. The processing requirement xjof a job jis unknown to the\nalgorithm and only becomes known once the job has finished processing. Any job can be preempted\nat any time and resumed at a later time without any cost. The objective function is to minimize the\nsum of completion times of the jobs. Note that no algorithm can yield any non-trivial guarantees if\npreemptions are not allowed.\nLetx1, . . . , x ndenote the actual processing times of the njobs, which are unknown to the non-\nclairvoyant algorithm. In the clairvoyant case, when processing times are known up front, the optimal\nalgorithm is to simply schedule the jobs in non-decreasing order of job lengths, i.e., shortest job\nfirst. A deterministic non-clairvoyant algorithm called round-robin (RR) yields a competitive ratio of\n2 [24], which is known to be best possible.\nNow, suppose that instead of being truly non-clairvoyant, the algorithm has an oracle that predicts the\nprocessing time of each job. Let y1, . . . , y nbe the predicted processing times of the njobs. Then\nηj=|xj−yj|is the prediction error for job j, and η=Pn\nj=1ηjis the total error. We assume that\nthere are no zero-length jobs and that units are normalized such that the actual processing time of\nthe shortest job is at least one. Our goal in this section is to design algorithms that are both robust\nand consistent, i.e., can use good predictions to beat the lower bound of 2, while at the same time\nguaranteeing a worst-case constant competitive ratio.\n3.1 A preferential round-robin algorithm\nIn scheduling problems with preemption, we can simplify exposition by talking about several jobs\nrunning concurrently on the machine, with rates that sum to at most 1. For example, in the round-robin\nalgorithm, at any point of time, all kunfinished jobs run on the machine at equal rates of 1/k. This is\njust a shorthand terminology for saying that in any infinitesimal time interval, 1/kfraction of that\ninterval is dedicated to running each of the jobs.\nWe call a non-clairvoyant scheduling algorithm monotonic if it has the following property: given two\ninstances with identical inputs and actual job processing times (x1, . . . , x n)and(x′\n1, . . . , x′\nn)such\nthatxj≤x′\njfor all j, the objective function value found by the algorithm for the first instance is no\nhigher than that for the second. It is easy to see that the round-robin algorithm is monotonic.\nWe consider the Shortest Predicted Job First (SPJF) algorithm, which sorts the jobs in the increasing\norder of their predicted processing times yjand executes them to completion in that order. Note that\n6\n\nSPJF is monotonic, because if processing times xjbecame smaller (with predictions yjstaying the\nsame), all jobs would finish only sooner, thus decreasing the total completion time objective. SPJF\nproduces the optimal schedule in the case that the predictions are perfect, but for bad predictions,\nits worst-case performance is not bounded by a constant. To get the best of both worlds, i.e. good\nperformance for good predictions as well as a constant-factor approximation in the worst-case, we\ncombine SPJF with RR using the following, calling the algorithm Preferential Round-Robin (PRR) .\nLemma 3.1. Given two monotonic algorithms with competitive ratios αandβfor the minimum total\ncompletion time problem with preemptions, and a parameter λ∈(0,1), one can obtain an algorithm\nwith competitive ratio min{α\nλ,β\n1−λ}.\nProof. The combined algorithm runs the two given algorithms in parallel. The α-approximation (call\nitA) is run at a rate of λ, and the β-approximation ( B) at a rate of 1−λ. Compared to running at\nrate 1, if algorithm Aruns at a slower rate of λ, all completion times increase by a factor of 1/λ, so it\nbecomes aα\nλ-approximation. Now, the fact that some of the jobs are concurrently being executed by\nalgorithm Bonly decreases their processing times from the point of view of A, so by monotonicity,\nthis does not make the objective of Aany worse. Similarly, when algorithm Bruns at a lower rate of\n1−λ, it becomes aβ\n1−λ-approximation, and by monotonicity can only get better from concurrency\nwithA. Thus, both bounds hold simultaneously, and the overall guarantee is their minimum.\nWe next analyze the performance of SPJF.\nLemma 3.2. The SPJF algorithm has competitive ratio at most\u0000\n1 +2η\nn\u0001\n.\nProof. Assume w.l.o.g. that jobs are numbered in non-decreasing order of their actual processing\ntimes, i.e. x1≤. . .≤xn. For any pair of jobs (i, j), define d(i, j)as the amount of job ithat has\nbeen executed before the completion time of job j. In other words, d(i, j)is the amount of time by\nwhich idelays j. LetALG denote the output of SPJF. Then\nALG =nX\nj=1xj+X\n(i,j):i<j(d(i, j) +d(j, i)).\nFori < j such that yi< yj, the shorter job is scheduled first and hence d(i, j) +d(j, i) =xi+ 0, but\nfor job pairs that are wrongly predicted, the longer job is scheduled first, so d(i, j) +d(j, i) = 0 + xj.\nThis yields\nALG =nX\nj=1xj+X\n(i,j):i<j\nyi<yjxi+X\n(i,j):i<j\nyi≥yjxj=nX\nj=1xj+X\n(i,j):i<jxi+X\n(i,j):i<j\nyi≥yj(xj−xi)\n≤nX\nj=1xj+X\n(i,j):i<jxi+X\n(i,j):i<j\nyi≥yjηi+ηj=OPT +X\n(i,j):i<j\nyi≥yjηi+ηj≤OPT + (n−1)η,\nwhich yieldsALG\nOPT≤1 +(n−1)η\nOPT. Now, using our assumption that all jobs have length at least 1, we\nhaveOPT≥n(n+1)\n2. This yields an upper bound of 1 +2(n−1)η\nn(n+1)<1 +2η\nnon the competitive ratio\nof SPJF.\nWe give an example showing that this bound is asymptotically tight. Suppose that there are n−1jobs\nwith processing times 1and one job with processing time 1 +ϵand suppose the predicted lengths are\nyj= 1for all jobs. Then η=ϵ,OPT =n(n+1)\n2+ϵ, and, if SPJF happens to schedule the longest\njob first, increasing the completion time of n−1jobs by ϵeach,ALG =OPT + (n−1)ϵ. This gives\nthe ratio ofALG\nOPT= 1 +2(n−1)η\nn(n+1)+2 ϵ, which approaches the bound in Lemma 3.2 as nincreases and ϵ\ndecreases.\nFinally, we bound the performance of the preferential round-robin algorithm.\nTheorem 3.3. The preferential round-robin algorithm with parameter λ∈(0,1)has competitive\nratio at most min{1\nλ(1 +2η\nn),2\n1−λ}. In particular, it is2\n1−λ-robust and1\nλ-consistent.\n7\n\nProof. This follows from the competitive ratio of SPJF (Lemma 3.2) and the competitive ratio of 2\nfor round-robin, and by combining the two algorithms using Lemma 3.1.\nSetting λ >0.5gives an algorithm that beats the round-robin ratio of 2in the case of sufficiently\ngood predictions. For the special case of zero prediction errors (or, more generally, if the order of\njobs sorted by yjis the same as that sorted by xj), we can obtain an improved competitive ratio of\n1+λ\n2λvia a more sophisticated analysis.\nTheorem 3.4. The preferential round-robin algorithm with parameter λ∈(0,1)has competitive\nratio at most (1+λ\n2λ)when η= 0.\nProof. Suppose w.l.o.g. that the jobs are sorted in non-decreasing job lengths (both actual and\npredicted), i.e. x1≤ ··· ≤ xnandy1≤ ··· ≤ yn. Since the optimal solution schedules the jobs\nsequentially, we have\nOPT =nX\nj=1(n−j+ 1)xj=nX\nj=1xj+X\n(i,j):i<jxi. (1)\nWe call a job active if it has not completed yet. When there are kactive jobs, the preferential\nround-robin algorithm executes all active jobs at a rate of1−λ\nk, and the active job with the shortest\npredicted processing time (we call this job current ) at an additional rate of λ. Note that each job j\nfinishes while being the current job. This can be shown inductively: suppose job j−1finishes at time\nt. Then by time t, jobjhas received strictly less processing than j−1, but its size is at least as big.\nSo it has some processing remaining, which means that it becomes current at time tand stays current\nuntil completion. Let phase kof the algorithm denote the interval of time when job kis current.\nFor any pair of jobs (i, j), define d(i, j)as the amount of job ithat has been executed before the\ncompletion time of j. In other words, d(i, j)is the amount of time by which idelays j. We can now\nexpress the cost of our algorithm as\nALG =nX\nj=1xj+X\n(i,j):i<jd(i, j) +X\n(i,j):i<jd(j, i). (2)\nIfi < j , as job icompletes before job j, we have d(i, j) =xi. To compute the last term in (2),\nconsider any phase k, and let tkdenote its length. In this phase, the current job kexecutes at a rate of\nat least λ, which implies that tk≤xk\nλ. During phase k, jobs{k+ 1, ..., n}receivetk(1−λ)\nn−k+1amount\nof processing each. Such a job k+idelays ijobs with smaller indices, namely {k, ..., k +i−1}.\nLetdk(i, j)denote the delay in phase k:\nX\n(i,j):i<jdk(j, i) =tk(1−λ)\nn−k+ 1·n−kX\ni=1i=tk(1−λ)(n−k)\n2≤xk(1−λ)(n−k)\n2λ.\nSubstituting back into Equation (2),\nALG =nX\nj=1xj+X\n(i,j):i<jd(i, j) +X\n(i,j):i<jnX\nk=1dk(j, i)\n≤nX\nj=1xj+X\n(i,j):i<jxi+nX\nk=1xk(1−λ)(n−k)\n2λ=OPT +nX\nk=1xk(1−λ)(n−k)\n2λ\n≤OPT +1−λ\n2λnX\nk=1xk(n−k+ 1) = OPT +1−λ\n2λOPT =1 +λ\n2λOPT,\nusing Equation (1) for the last line.\n8\n\n(a) Ski Rental\n (b) Non-clairvoyant Scheduling\nFigure 2: Average competitive ratio over varying prediction errors.\n4 Experimental results\n4.1 Ski rental\nWe test the performance of our algorithms for the ski rental problem via simulations. For all\nexperiments, we set the cost of buying to b= 100 and the actual number of skiing days xis a\nuniformly drawn integer from [1,4b]. The predicted number of days yis simulated as y=x+ϵ\nwhere ϵis drawn from a normal distribution with mean 0 and standard deviation σ. We consider\nboth randomized and deterministic algorithms for two different values of the trade-off parameter λ.\nRecall that by setting λ= 1, our algorithms ignore the predictions and reduce to the known optimal\nalgorithms (deterministic and randomized, respectively) [ 12]. We set λ= 0.5for the deterministic\nalgorithm that guarantees a worst-case competitive ratio of 3. In order to obtain the same worst-\ncase competitive ratio, we set λ= ln( 3/2)for the randomized algorithm. For each σ, we plot the\naverage competitive ratio obtained by each algorithm over 10000 independent trials in Figure 2a. We\nobserve that even for rather large prediction errors, our algorithms perform significantly better than\ntheir classical counterparts. In particular, even our deterministic algorithm that uses the predictions\nperforms better than the classical randomized algorithm for errors up to a standard deviation of 2b.\n4.2 Non-clairvoyant scheduling\nN min max mean σ\n50 1 22352 2168 5475.42\nTable 1: Statistics of job lengths.We generate a synthetic dataset with 50 jobs where the\nprocessing time of each job is sampled independently from\na Pareto distribution with an exponent of α= 1.1. (As\nobserved in prior work [ 7,8,2], job size distributions\nin a number of settings are well-modeled by a Pareto\ndistribution with αclose to 1.) Pertinent characteristics of the generated dataset are presented\nin Table 1. In order to simulate predicted job lengths and compare the performance of the different\nalgorithms with respect to the errors in the prediction, we set the predicted job length yi=xi+ϵi,\nwhere ϵiis drawn from a normal distribution with mean zero and standard deviation σ.\nFigure 2b shows the competitive ratio of the three algorithms versus varying prediction errors. For a\nparameter σ, we plot the average competitive ratio over 1000 independent trials where the prediction\nerror has the specified standard deviation. As expected, the naïve strategy of scheduling jobs in\nnon-decreasing order of their predicted job lengths (SPJF) performs very well when the errors are\nlow, but quickly deteriorates as the errors increase. In contrast, our preferential round-robin algorithm\n(with λ= 0.5) performs no worse than round-robin even when the predictions have very large error.\n5 Conclusions\nIn this paper we furthered the study of using ML predictions to provably improve the worst-case\nperformance of online algorithms. There are many other important online algorithms including\nk-server, portfolio optimization, etc, and it will be interesting to see if predictions can be useful for\n9\n\nthem as well. Another research direction would be to use the error distribution of the ML predictor to\nfurther improve the bounds.\nAcknowledgements\nWe thank Chenyang Xu for pointing out a bug in the conference version [ 18] and thank Erik Vee for\nhis help in fixing the bug.\nReferences\n[1]Nikhil Bansal, Kedar Dhamdhere, Jochen Könemann, and Amitabh Sinha. Non-clairvoyant\nscheduling for minimizing mean slowdown. Algorithmica , 40(4):305–318, 2004.\n[2]Nikhil Bansal and Mor Harchol-Balter. Analysis of SRPT scheduling: Investigating unfairness.\nInSIGMETRICS , pages 279–290, 2001.\n[3]Luca Becchetti and Stefano Leonardi. Non-clairvoyant scheduling to minimize the average flow\ntime on single and parallel machines. In STOC , pages 94–103, 2001.\n[4]Russell Bent and Pascal Van Hentenryck. Online Stochastic Combinatorial Optimization . MIT\nPress, 2009.\n[5]A. Borodin and R. El-Yaniv. Online Computation and Competitive Analysis . Cambridge\nUniversity Press, 1998.\n[6]Sebastien Bubeck and Aleksandrs Slivkins. The best of both worlds: Stochastic and adversarial\nbandits. In COLT , pages 42.1–42.23, 2012.\n[7]Mark E Crovella and Azer Bestavros. Self-similarity in world wide web traffic: Evidence and\npossible causes. Transactions on Networking , 5(6):835–846, 1997.\n[8]Mor Harchol-Balter and Allen B Downey. Exploiting process lifetime distributions for dynamic\nload balancing. ACM TOCS , 15(3):253–285, 1997.\n[9]Sungjin Im, Janardhan Kulkarni, and Kamesh Munagala. Competitive algorithms from competi-\ntive equilibria: Non-clairvoyant scheduling under polyhedral constraints. J. ACM , 65(1):3:1–\n3:33, 2017.\n[10] Sungjin Im, Janardhan Kulkarni, Kamesh Munagala, and Kirk Pruhs. Selfishmigrate: A scalable\nalgorithm for non-clairvoyantly scheduling heterogeneous processors. In FOCS , pages 531–540,\n2014.\n[11] Anna R Karlin, Claire Kenyon, and Dana Randall. Dynamic TCP acknowledgement and other\nstories about e/(e−1).Algorithmica , 36(3):209–224, 2003.\n[12] Anna R. Karlin, Mark S. Manasse, Lyle A. McGeoch, and Susan Owicki. Competitive random-\nized algorithms for nonuniform problems. Algorithmica , 11(6):542–571, 1994.\n[13] Anna R. Karlin, Mark S. Manasse, Larry Rudolph, and Daniel Dominic Sleator. Competitive\nsnoopy caching. Algorithmica , 3:77–119, 1988.\n[14] Ali Khanafer, Murali Kodialam, and Krishna P.N. Puttaswamy. The constrained ski-rental\nproblem and its application to online cloud cost optimization. In INFOCOM , pages 1492–1500,\n2013.\n[15] Rohan Kodialam. Competitive algorithms for an online rent or buy problem with variable\ndemand. In SIAM Undergraduate Research Online , volume 7, pages 233–245, 2014.\n[16] Panos Kouvelis and Gang Yu. Robust Discrete Optimization and its Applications , volume 14.\nSpringer Science & Business Media, 2013.\n[17] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In SIGMOD , pages 489–504, 2018.\n[18] Ravi Kumar, Manish Purohit, and Zoya Svitkina. Improving online algorithms via ML predic-\ntions. In NeurIPS , pages 9684–9693, 2018.\n[19] Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice.\nInICML , pages 3302–3311, 2018.\n10\n\n[20] Mohammad Mahdian, Hamid Nazerzadeh, and Amin Saberi. Online optimization with uncertain\ninformation. ACM TALG , 8(1):2:1–2:29, 2012.\n[21] Andres Muñoz Medina and Sergei Vassilvitskii. Revenue optimization with approximate bid\npredictions. In NIPS , pages 1856–1864, 2017.\n[22] Adam Meyerson. The parking permit problem. In FOCS , pages 274–282, 2005.\n[23] Vahab S. Mirrokni, Shayan Oveis Gharan, and Morteza Zadimoghaddam. Simultaneous\napproximations for adversarial and stochastic online budgeted allocation. In SODA , pages\n1690–1701, 2012.\n[24] Rajeev Motwani, Steven Phillips, and Eric Torng. Nonclairvoyant scheduling. Theoretical\nComputer Science , 130(1):17–47, 1994.\nA Deferred Proofs\nWe first state a few simple observations that will be useful.\nLemma A.1. For0< x≤1,\n(i)ex−1\nx≤1.\n(ii)x\ne−e−1\nx≥0.\n(iii)1−1\nx+e−x\nx≥x\ne.\nProof. (i) For x∈(0,1], we have x≤1/x=⇒ex≤e1/xand hence ex−1\nx≤1.\n(ii) For any y≤1, we have 1−y≤e−y=⇒ey≤1\n1−y. Showing (ii) is equivalent to showing\nx−e1−1\nx≥0. But since 1−1\nx≤1, we can substitute y= 1−1\nxto get\nx−e1−1\nx≥x−1\n1−(1−1\nx)= 0\n(iii) We first show that h(x) := 1−1\nx+e−x\nxis concave for x≥0(since limx→0h(x) = 0 , we define\nh(0) = 0 to make it continuous at 0). Indeed, consider h′′(x) =e−x(x2+2x+2−2ex)\nx3 . Note that for\nallx≥0, we have ex≥1 +x+x2/2, and hence we have h′′(x)≤0. Thus h(x)is concave in the\nrange x≥0. By concavity, we get that for all 0< x≤1,h(x)≥(1−x)·h(0) + x·h(1) =x\neas\ndesired.\nLemma A.2. Letb≥2be an integer and let λ∈(1/b,1)be a real number. Then,\n1/λ+ 1/b\n1−e−1/λ≤1 + 1 /b\n1−e−(λ−1/b).\nProof. For convenience, let y= 1/band rearrange the terms so that the lemma statement is equivalent\nto showing the following, subject to λ∈(y,1).\n(1 +y)(1−e−1/λ)−(1/λ+y) + (1 /λ+y)ey−λ≥0.\nNote that we used λ≥yhere while rearranging the terms. Using ey≥1 +y, it instead suffices to\nshow the following inequality.\n(1 +y)(1−e−1/λ)−(1/λ+y) + (1 /λ+y)(1 + y)e−λ≥0. (3)\nThe LHS of (3) is a quadratic in y, written as:\nf(y) :=y2(e−λ) +y((1/λ+ 1)e−λ−e−1/λ) + (1 −e−1/λ−1/λ+e−λ/λ). (4)\n11\n\nThe goal is to show (4) is non-negative when 1≥λ≥y≥0. To do this, we minimize f(y)subject\nto0≤y≤λ.\nThe minimum of f(y)is attained at\n∂f/∂y = 0 = 2 y(e−λ) + (1 /λ+ 1)e−λ−e−1/λ,\nyielding\nymin=eλ−1/λ−(1/λ+ 1)\n2Lemma A .1(i)\n≤ 0.\nConsequently, subject to the constraint that y≥0, the minimum of f(y)is attained at y= 0.\nPlugging in y= 0in (4), we get\nf(y)≥f(0) = 1 −e−1\nλ−1\nλ+e−λ\nλLemma A .1(iii)\n≥λ\ne−e−1\nλLemma A .1(ii)\n≥ 0.\nThis completes the proof.\n12",
  "textLength": 35813
}