{
  "paperId": "34f11d1f907c9b92224d420b48398afe4599c7f3",
  "title": "Optimizing Bloom Filter: Challenges, Solutions, and Comparisons",
  "pdfPath": "34f11d1f907c9b92224d420b48398afe4599c7f3.pdf",
  "text": "1\nOptimizing Bloom Filter: Challenges, Solutions,\nand Comparisons\nLailong Luo, Deke Guo, Richard T.B. Ma, Ori Rottenstreich, and Xueshan Luo\nAbstract —Bloom ﬁlter (BF) has been widely used to support\nmembership query, i.e., to judge whether a given element xis a\nmember of a given set Sor not. Recent years have seen a ﬂourish\ndesign explosion of BF due to its characteristic of space-efﬁciency\nand the functionality of constant-time membership query. The\nexisting reviews or surveys mainly focus on the applications of\nBF, but fall short in covering the current trends, thereby lacking\nintrinsic understanding of their design philosophy. To this end,\nthis survey provides an overview of BF and its variants, with an\nemphasis on the optimization techniques. Basically, we survey\nthe existing variants from two dimensions, i.e., performance\nand generalization. To improve the performance, dozens of\nvariants devote themselves to reducing the false positives and\nimplementation costs. Besides, tens of variants generalize the\nBF framework in more scenarios by diversifying the input\nsets and enriching the output functionalities. To summarize the\nexisting efforts, we conduct an in-depth study of the existing\nliterature on BF optimization, covering more than 60 variants.\nWe unearth the design philosophy of these variants and elaborate\nhow the employed optimization techniques improve BF. Further-\nmore, comprehensive analysis and qualitative comparison are\nconducted from the perspectives of BF components. Lastly, we\nhighlight the future trends of designing BFs. This is, to the best\nof our knowledge, the ﬁrst survey that accomplishes such goals.\nIndex Terms —Bloom ﬁlter, Performance, Generalization, False\npositive, False negative.\nI. I NTRODUCTION\nBLOOM ﬁlter [1] is a space-efﬁcient probabilistic data\nstructure for representing a set of elements with support-\ning membership queries with an acceptable false positive rate.\nHitherto, the applications of BF and its variants are manyfold.\nIn the ﬁeld of networking, BF has been employed to enable\nrouting and forwarding [2] [3] [4] [5] [6] [7] [8], web caching\n[9] [10], network monitoring [11], security enhancement [12]\n[13], content delivering [14], etc. In the area of databases,\nBF is a proper option to support query and search [15] [16],\nprivacy preservation [17], key-value store [18] [19], content\nsynchronization [20] [21] [22] [23] [24], duplicate detection\n[25] and so on. Beyond the general ﬁelds of networking and\nThis work is partially supported by National Natural Science Foundation\nof China under Grant No.61772544, and the Hunan Provincial Natural\nScience Fund for Distinguished Young Scholars under Grant No.2016JJ1002.\nCorresponding author: Deke Guo.\nLailong Luo, Deke Guo, and Xueshan Luo are with the Science and\nTechnology Laboratory on Information Systems Engineering, National Uni-\nversity of Defense Technology, Changsha, Hunan, 410073, China. E-mail:\n{luolailong09, dekeguo, xsluo}@nudt.edu.cn.\nDeke Guo is also with the College of Intelligence and Computing, Tianjin\nUniversity, Tianjin, 300350, P. R. China.\nRichard T. B. Ma is with the School of Computing, National University of\nSingapore, Singapore. E-mail: tbma@comp.nus.edu.sg.\nOri Rottenstreich is with the Technion and ORBS Research, Israel. E-mail:\nor@cs.technion.ac.il.TABLE I\nCOMPARISON WITH EXISTING SURVEYS .\nFirst author # variants Scenarios Optimizations\nBroder [30] \u00145 Networks Not mentioned\nGeravand [31] \u001415 Network security Not mentioned\nTarkoma [29] \u001425 Distributed system Not mentioned\nThis survey \u001560 General Detailed\ndatabases, BFs have been recently used to resolve biometric\nissues [26] [27], and even navigation tasks in the mobile\ncomputing scenarios [28]. Other detailed applications can be\nfound in several surveys [29] [30] [31].\nThe major motivation for conducting this survey is two-\nfold. First of all, tens of BF variants have been proposed in\nrecent years. Existing surveys, however, are somehow out-\nof-date and do not cover these new proposals. The latest\nsurvey [29], which covers about 25 variants, was published\nﬁve years ago. Secondly, the existing surveys [29] [30] [31]\nmainly focus on the applications of BF, but lack essential\nunderstandings of the optimization techniques of the proposed\nvariants. Therefore, they do not provide operational advice to\nthe users in reality. As shown in Table I, compared with the\nexisting surveys, our survey covers more BF variants (more\nthan 60) and introduces general applications rather than focus\non a single scenario. In particular, our survey concentrates on\nthe optimization techniques employed in these variants.\nTo this end, we go back to the design philosophy of BF\nand thoroughly analyze the existing optimization techniques to\nimprove BF. In this manner, we expect to provide a guidance\nto potential users whenever BFs are within their considera-\ntions. Speciﬁcally, we survey the existing variants from two\ndimensions, i.e., performance and generalization. To improve\nthe performance, dozens of variants devote themselves to\nreducing the false positives and easing the implementation.\nBesides, tens of variants generalize the BF framework in\nmore scenarios by diversifying the input sets and enriching\nthe output functionalities. In our survey, more than 60 up-to-\ndate designs are reviewed and qualitatively yet systematically\nanalyzed. As far as we know, this is the ﬁrst survey which\nsystematically summarizes the optimization techniques of BFs.\nDespite its space-efﬁciency, BF still faces some challenges\nrelated to false positives, implementation, elasticity, and func-\ntionality to some extent. To ease the potential challenges\nand further improve the performance of BF, many interesting\ntechniques have been proposed and diverse variants have been\ndesigned. In this survey, we present the prior arts of improving\nBF from four angles, i.e., techniques to reduce the false\npositives, optimizations in a real implementation, dedicated\ndesigns for diverse datasets, and proposals to enable morearXiv:1804.04777v2  [cs.DS]  7 Jan 2019\n\n2\nBloom Filters Reduction of FPs \nImplementation \noptimization Functionality \nenrichment Set diversity Input Output \nCost Result \nFig. 1. The top view of the optimization angles for Bloom ﬁlter.\nfunctionalities. The intrinsic logic of the four angles is shown\nin Fig. 1. Basically, from the perspective of performance,\nthe BF can be improved by reducing the false positives and\noptimizing the implementation. Besides, the BF framework\ncan also be generalized from both the input and output\naspects by representing more types of sets and enabling more\nfunctionalities beyond set membership queries.\nFollowing the above directions, we organize the rest of this\nsurvey as follows. Section II details the design philosophy\nof BF and analyzes the challenging issues while Section III\nbrieﬂy introduces the applications of BFs. Thereafter, we\ndetail the variants designed for reducing false positives (FPs)\nin Section IV, implementation optimizations in Section V,\ngeneralizing the set diversity in Section VI, and functional-\nity enrichment in Section VII. Following that, Section VIII\nanalyzes and compares all mentioned variants from a quality\nperspective. We summarize this survey and enumerate several\nopen issues about the BF framework in Section IX and then\nconclude this survey in Section X.\nII. B LOOM FILTERS\nIn this section, we detail the basic theory of Bloom ﬁlter in\nterms of its framework, characteristics, and challenges.\nA. Framework of Bloom ﬁlter\nBloom ﬁlter (BF) is a space-efﬁcient probabilistic data\nstructure that enables constant-time membership queries [1].\nLetS=fx1;x2;:::;xngbe a set of nelements such that S\u0012U,\nwhere Uis a universal set. BF represents such nelements using\na bit vector of length m. All of the mbits in the vector are\ninitialized to 0. Speciﬁcally, to insert an element x, a group of\nkindependent hash functions, fh1;h2;:::;hkg, are employed\nto randomly map xinto kpositionsfh1¹xº;h2¹xº;:::;hk¹xºg\n(where hi¹xº2»0;m\u00001¼) in the bit vector. Then the bits in these\nkvector positions are all set to 1. To query whether an arbitrary\nelement is a member of set S, BF maps the element into its bit\nvector with the khash functions and thereafter checks whether\nall the kbits are 1s. If any bit at the khashed positions of\nthe element is 0, the BF concludes that this element does not\nbelong to the set; otherwise, the BF indicates that the queried\nelement belongs to the set S.\nFig. 2 presents an example of BF with m=12bits and k=3\nhash functions to represent the set S=fx1;x2;x3g. To insert\nthese elements, the 3 corresponding bits for each element are\nset to 1. When querying, the BF checks the 3 corresponding\nbits for the queried element. For x1, the bits at position 0, 3\nĂĂĂ \nĂĂĂ \nĂĂĂ ĂĂĂ \nĂĂ ĂĂ \nĂĂ ĂĂ \n000000000 000Initial state: all bits are set as 0.\n100101101 110Insertion: inset each element xi into BF by setting BF[h j(xi)]=1.  \n100101101 110Query: if all BF[h j(xi)]=1, return Positive; else return Negative.0 1 2 3 4 5 6 7 8 9 10 11 \nx1 x2 x3\nx1 x5 x4\nReturn Positive Return Negative Return Positive (false positive)Fig. 2. An illustrative example of BF with m=12andk=3to represent set\nS=fx1;x2;x3g. Note that the query of x5results in a false positive error.\nand 6 are all 1, thus BF returns “Positive” for the query. The\nmembership query of x4returns “Negative” since the bit at\nposition 4 is 0. Note that, due to the unavoidable hash conﬂicts\n(generating same hash value for diverse input elements), the\nmembership query based on BF may incur false positive\nerrors, i.e., wrongly indicating that a non-member element is a\nmember of S. In Fig. 2, the query of x5returns positive because\nthe bits at position 6, 8, and 11 are all 1, though x5<S.\nAlthough BF incurs false positives, for many applications\nthe space savings and constant locating time outweigh this\ndrawback when the probability of false positive is small.\nTo realize acceptable false positive rate fr, the parameters\nof BF, i.e., the BF length m, the number of employed hash\nfunctions k, and the number of elements in the set n, call for\ncareful design. Theoretically, the value of false positive rate\ncan be calculated as:\nfr=\"\n1\u0000\u0012\n1\u00001\nm\u0013nk#k\n\u0019\u0010\n1\u0000e\u0000k n\nm\u0011k\n; (1)\nwhere¹1\u00001mºnkis approximated by e\u0000knm. Consequently, to\nrealize the minimum value of fr,e\u0000knmshould be minimized.\nWith this insight, the optimal value of kis derived as:\nkopt=m\nnln 2\u00199m\n13n: (2)\nFollowed by kopt, the resulted false positive rate equals 0:5k\u0019\n0:6185mn. That is, with the given k, to maintain a ﬁxed false\npositive rate, the value of mshould be increased linearly with\nthe value of n.\nHowever, as reported in [32] and [33], the false positive rate\nin real deployments is higher than the value given by Equ. 1.\nTheoretically, it has been proven in [34] that Equ. 1 offered\na lower bound of the false positive rate. After formulating\nthe BF framework as a typical problem of balls and urns, the\nauthors in [34] present a more accurate false positive rate of\nBF as:\nfr=1\nmk¹n+1ºmÕ\ni=1iki!\u0012m\ni\u0013 \u001akn\ni\u001b\n; (3)\n\n3\nwhere\u001akn\ni\u001b\n=1\ni!Íi\nj=0¹\u00001ºj\u0000i\nj\u0001jknis called a Stirling num-\nber of the second kind [35].\nNaturally, in the framework of BF, deleting an element is\nnot permitted. The reason is that resetting the corresponding\n1s to 0s directly may lead to false negative results for other\nelements. Therefore, Counting BF (CBF) [36] extends the BF\nby replacing each bit as a counter with multiple bits. When\ninserting an element, the corresponding kbits will be increased\nby 1. In contrast, the deletion of an element will be supported\nvia decreasing the corresponding counters by 1. In this way,\nthe deletion of an element will not affect the existence of\nother elements. It has been proved that 4 bits for a counter\nare enough to achieve eligible overﬂow probability (less than\n1:37\u000210\u000015\u0002m, where mis the number of counters in CBF).\nCBF also supports constant-time membership query. To an-\nswer a membership query, the CBF checks the kcorresponding\ncounters. If all of them are non-zero, CBF judges that the\nqueried element is a member; otherwise, negative.\nB. Intrinsic characteristics of Bloom ﬁlter\nAs a probabilistic data structure, BF supports fast mem-\nbership query with potential false positive errors. For better\nunderstanding, we highlight the intrinsic characteristics of BF\nas follows.\nSpace-efﬁcient . BF programmes each element in a given set\nwith a m-bit vector, irrespective of the number of bits in a bit\nrepresentation of an element. With each element as input, the\nkindependent hash functions will select kbits in the bit vector\nand set the chosen bits as 1s. The caused space overhead, i.e.,\nthe value of m, is only proportional to the number of elements\nn, and will not be affected by the length of the elements. For\nexample, given the bpe (bits per element) as 5, i.e., mn=5,\nthe optimized kcan be derived out as 3 or 4 according to\nEqu. 2. Then the bit vector represents the nelements, without\nconcerning the size of each element.\nConstant-time query . By employing BF, querying the\nmembership of elements in Ucan be simpliﬁed as binary\nchecking of the corresponding kbits. If all the kbits are 1s,\nBF believes the queried element belongs to the set S, otherwise\nnot. Thus the time-complexity of querying an element is\nO¹kº, which is much faster than trees ( O¹lognº) and table or\nlist (O¹nº). Note that, when the Bloom ﬁlter is implemented\nandkwill be a constant. Then both the insertion and query\ncomplexity will be O¹1º.\nOne-sided error . Intrinsically, BF suffers from unavoidable\nfalse positive errors during a query, but no false negative\nerrors. Speciﬁcally, if BF infers that an element xis not in\nthe set S, users can exactly trust the judgment. By contrast, if\nBF concludes that xbelongs to S, users cannot rule out the\nprobability that x<S.\nC. Challenging issues of Bloom ﬁlter\nBF is proven to be easy-deployable and practical for situa-\ntions where space is limited and membership query is required\nwith allowable errors. However, BF incurs intrinsic challenges.\nWe uncover the challenges as follows.False positives . Although the false positive rate can be\ncontrolled by careful setting of the parameters, the misjudged\nelements may lead to serious impact on the upper-level ap-\nplications. For instance, when routing with BF, the leaked\nﬂows caused by misjudgements may burden or even block\nbandwidth-scarce networks (e.g., Wireless Sensor Network,\nInternet of Vehicles). To reduce the false positive rate, more\nspace or more complicated operations are needed. Note that\ndecreasing the false positive rate by extending the length of\nBF incurs marginal effect. That is, with the same increment of\nm, the decrement of false positive rate will be more and more\nindistinctive. Another strategy is to remedy the misreported\nelements (e.g., using whitelist). However, picking up the false\npositives from the query results can be challenging for a large-\nscale dataset.\nImplementation . Despite the feature of easy-deployable,\nwhen BF or its variants are employed, some implementation\ningredients (e.g., memory access, space utilization, computa-\ntion overhead) may be the bottleneck of the applications. To\nquery an element, the accessed bits can be arbitrarily located\nin the bit vector, which results in O¹kºmemory access. For a\nstandard BF design, roughly only half of the bits are set to 1.\nBesides, high-performance hash functions (e.g., RSA, SHA-1,\nMD-5) calls for complex computation process which may be\nnot possible for low-end or light-weight hardware. The above\nmeasurements get even worse when the dataset contains a large\nnumber of elements.\nElasticity . Note that, the parameters (including m,nand\nk) are predeﬁned, and the employed hash functions cannot\nbe changed once selected. The bits are not permitted to be\nchanged once they have been set as 1s. Consequently, the\nBF can only successfully represent a static set. Once been\nimplemented, the number of bits can be neither extended nor\nshrunk adaptively. Besides, the internal logical relationship\n(e.g., distance, similarity, precedence, etc) between elements\nwill be annihilated. For example, when representing a mul-\nticast tree, the BF only programmes the nodes into the bit\nvector. Therefore, the generated BF cannot tell the children or\nfather of any node in the multicast tree directly.\nFunctionality . The original BF was designed to support fast\nmembership query and only offer two operations to the users,\ni.e., insertion and query. More complicated operations (e.g.,\ndeletion and decoding) or other types of queries (e.g., multi-\nplicity) are not enabled. When an element xis removed from\nS, the bits BF»h1¹xº¼;\u0001\u0001\u0001;BF»hk¹xº¼cannot be reversed as 0s.\nThek1s may also represent the membership of other elements,\nthus changing them from 1s to 0s may lead to false negatives\nof other elements. Moreover, BF fails to tell the multiplicity of\nan element in a multiset (a set in which elements are permitted\nto have multiple replicas), and cannot report which set or sets\nan element belongs to, when representing multiple sets with\na shared bit vector simultaneously. To realize more operations\nand enable more types of queries, the BF framework calls for\nadditional design.\nIII. A PPLICATIONS OF BLOOM FILTERS\nBefore detailing the optimizations and generalizations, we\nﬁrst summarize the applications of BFs in the area of com-\n\n4\nmunication and networking. Usually, BFs are employed to\nrepresent a given set of elements and support membership\nqueries. We focus on the extensive applications of BFs in\nrecent years since previous applications have been covered\nby existing surveys.\nA. Content caching\nBFs are naturally helpful for caches and storages via rep-\nresenting the contents to cache and supporting constant-time\nmembership queries.\nConsider a generic system composed of a user, a main\nmemory containing all the data, and a cache with a subset of\nthe data. Usually, BFs are employed to represent the content\nstored in the cache. The access of a speciﬁc element xis ﬁrst\ndirected to the BFs. If the BFs indicate that xis an element in\nthe cache, the access tries to read the element from the cache.\nDue to the potential false positive errors, xmay be not found in\nthe cache, then the access will be routed to the main memory.\nIf BFs judges that xis not stored by the cache, the request\nwill fetch xfrom the main memory directly without accessing\nthe cache. In this manner, BFs eliminate unnecessary cache\nreads [9].\nIn reality, Akamai establishes BFs in its servers for efﬁcient\ncache accesses [14]. Extensively, Akamai records the accessed\nelements with BFs to select the elements which should be\npushed into the cache. As a consequence, the cache hit-\nrate is guaranteed [14]. Moreover, in a computing system\nwith multiple cores, BFs are utilized to reduce the cache\ncoherence cost [37]. Both local caches and the shared bus\nsystem have their BFs. With the BFs in the cache and the\nsystem interconnections, the ﬁlter mechanism screens out\nthe unnecessary snooping messages that would be otherwise\nhandled by each core. The BF for the bus system further\nreduces system-wide data broadcasts. As for web caching, BF\nis redesigned to represent cache content of each Internet proxy\nin a compact form [10]. Thereafter, the BFs are shared with\nother proxies in the web caching system. To further decrease\nthe inter-proxy overhead, a BF only records the portion of a\nproxy’s cache content that will be of interest to other proxies.\nIn the ﬁeld of wireless communications, BFs are employed\nto speed up the cache lookups [38] and update the cache\nmechanism [39]. On-demand routing protocols for wireless ad\nhoc networks cache the discovered paths locally for subsequent\nrouting operations. In this case, BF provides summaries of\nthe cache content for testing cache membership and thereby\naverting negative lookups and easing the computational burden\n[38]. In large wireless networks, each node caches the public\nkey of some nodes in the network. The cache space in each\nnode is limited and is capable of storing a few public keys\nonly. By representing these public keys as BF vectors, more\nkeys can be stored and queried within constant time [39].\nB. Packet routing and forwarding\nBFs are space-efﬁcient so that they can be embedded in the\nheader of a packet or implemented on chip to improve both\nwired and wireless networks.1) BFs in wired networking: In traditional wired networks,\nBFs are widely used to speed-up IP lookups, enable multicast,\nsupport named data forwarding, etc.\nHigh-speed IP address lookup is essential to achieve wire-\nspeed packet forwarding in Internet routers [40]. High-\nperformance hardware such as ternary content addressable\nmemory (TCAM) has been adopted to solve the IP lookups.\nHowever, this hardware requires vast investment and incurs\nnon-trivial power consumption. Alternatively, on-chip BFs are\nutilized to record the IP lengths thereby enabling fast longest\nIP preﬁx matching with ordinary memories [40]. Recently,\nthe on-chip BF is further improved. The primary idea is to\nexplore the discrepancy in length distribution between the\nset of patterns and the set of preﬁxes of input text that are\nexamined against the patterns [41]. Speciﬁcally, the stored\npreﬁxes are grouped according to their lengths and mapped\ninto the BF vectors with variable numbers of hash functions.\nThe in-packet BF naturally enables multicast routing by\nrecording the nodes in the pre-calculated multicast tree [42].\nFor any node in the multicast tree, it checks the membership\nof its neighbours against the BF in the incoming packet.\nThen the node forwards the packet to the neighbours which\npass the membership test. Most-recently, endeavours have\nbeen made to improve the BF-enabled multicast routing in\nterms of scalability [5] [3] [43], loop mitigation [4], and ﬂow\nleakage [3] [43]. Due to the limited bits in the header and\nthe large number of nodes in the multicast tree, the in-packet\nBF incurs scalability to some extent. A possible solution is\nto split the multicast tree into multiple parts and represent\nthem separately. Nikolavskiy et al. propose to represent the\nmulticast tree as multiple trees with their splitting algorithms\n[5]. By contrast, as stated in [43], the multicast tree can\nalso be divided hierarchically so that nodes in each stage are\nrepresented by a BF. In the destination-oriented multicast, the\nin-packet BFs records the destination IP addresses instead of\nthe multicast tree. The multicast routing is accomplished with\nthe collaboration of the in-packet BFs and the local routers.\nIn this framework, the forwarding loop can be hopefully\neliminated if speciﬁc conditions are satisﬁed. More details can\nbe found in [4].\nIn the above multicast routing strategies, the false positive\nerrors of BFs lead to ﬂow leakage in the network. Tapolcai et\nal. reduce the false positive errors by dividing the multicast tree\nas multiple layers and adjusting the BF length according to the\nnumber of nodes in each layer [43]. For in-switch BF based\nmulticast routing, Li et al. alter the number of hash functions\nfor each multicast group according to the probability that the\nswitch is a node in that multicast tree [3]. These techniques\nare detailed in Section IV.\nMoreover, in named data networking (NDN), packets for-\nwarding decisions are driven by content names instead of IP\naddresses [2] [44] [45]. BFs are natively helpful for the longest\npreﬁx matching of content names in NDN. The NameFilter\n[44] leverages a two-stage BF-based scheme for NDN name\nlookups. The ﬁrst stage determines the length of a name preﬁx,\nand the second stage searches the preﬁx in a narrowed group of\nBFs based on the results from the ﬁrst stage. Instead of using\nthe two-stage BFs, Quan et al. propose to split the name preﬁx\n\n5\ninto B-preﬁx followed by T-sufﬁx [45]. B-preﬁx is matched by\nBFs whereas T-sufﬁx is processed by the small-scale trie. The\nlength of B-preﬁxes (and T-sufﬁxes) is dynamically throttled\nbased on their popularity in order to accelerate the lookup.\nThus, they achieve a lower false positive rate than NameFilter.\n2) BFs in wireless networking: In wireless networking, BFs\nare mainly utilized to represent the routing table and support\nfast lookups in each node.\nIn mobile ad hoc networks (MANETs), the nodes are free\nto move independently in any direction, and will therefore\nchange their links to other devices. The self-organizing and\ninfrastructure-less features disable the traditional protocols in\nMANETs. HRAN protocol [46] [47] proposes to store and\nspread topology information with BFs among the nodes to\ndownsize the routing messages in the network. HRAN merges\nBFs to discover and maintain routes, rather than broadcast\ntopology information when the network state changes. In\nthe scenario of vehicular ad hoc networks (V ANETs), BFs\nare applied to maintain and disseminate 2-hop neighborship\ninformation among the nodes. The using of BFs reduces the\nlength of the beacon messages, thereby keeping channel load\nand packet collision probability considerably low [48]. Such\na design enables various applications on top of neighborship\ninformation, including broadcast, routing, clustering, etc.\nIn wireless sensor networks (WSNs), each node keeps a\nprecise list of events that may be found through each neighbor\n[49]. Event ﬂooding-based routing protocols are enabled by\nquerying these events. Here, BFs are used to represent these\nevents and support fast queries [49]. Hebden and Pearce\npropose to partition the sensors into a set of clusters where\neach node in a cluster can only exchange data with its cluster\nhead [50]. Cluster heads process member data and/or reports\nfrom other cluster heads, make routing decisions and forward\nthe result to another cluster head or the sink node. A hierarchy\nof BFs were used by the sink, cluster head ports, and each\ncluster head itself to ﬁlter out unpromising transmissions\n[50]. Particularly, in tree-structured data collection WSNs,\npackets are routed towards a sink node [51]. Each node in the\ncollection tree stores the addresses of its direct and indirect\nchild nodes in its local BF. With such setting, the node’s local\nBF identiﬁes routes from the sink node to any other nodes.\nEspecially, in wireless NDN, BFs are applied to improve\nthe gossip algorithm [2]. Gossip protocols guarantee robust\ndata dissemination at the cost of a more aggressive bandwidth\nusage. To reduce the communication overhead, Angius et al.\npropose to record the pre-calculated path with an in-packet\nBF [2]. As a result, unnecessary transmissions are avoided.\nWe note that BFs are extensively utilized to navigate vehicles\nand mobile robots in the environment of wireless sensors\n[28]. The wireless sensors provide necessary information for\nthe navigation. Thereafter, the derived global routing table is\nrepresented with a BF in each sensor. By querying the routing\ntable, a vehicle can be navigated to any destination.\nC. Privacy preservation\nBFs naturally anonymize the elements with the support of\nmembership queries. Therefore, they are employed to preserve\ndata privacy in various scenarios.Nowadays, location-based services (LBSs) bring us un-\nprecedented convenience, as well as potential challenge to\nlocation privacy. Calderoni et al. divide the geographical areas\ninto different classes and represent them with BFs [17]. In\nthis way, they hide the actual locations of users with the\nsupport of a fast location query. In cognitive radio networks,\ngeo-location database-driven methods are proposed to identify\nvacant frequency bands for the secondary users without harm\nthe primary users [52] [53]. In these methods, the secondary\nusers are equipped with GPS devices to query the geo-location\ndatabase. Then the database returns the available channels\nto the secondary users. To preserve the location privacy of\nsecondary users, Grissa et al. propose to represent the locations\nwith probabilistic data structures [52] [53].\nAdditionally, biometric data (iris, face, handshape, ﬁnger-\nprint, etc) is widely adopted in authentication mechanisms.\nHowever, any privacy leakage of these data may lead to severe\nsecurity crises. Consequently, researchers suggest representing\nthese biometric data with BFs and enable the authentica-\ntion mechanisms based on membership queries. Speciﬁcally,\nBarrero et al. code the facial biometric templates with BFs\n[27]. Rathgeb et al. represent iris biometric template with\nBFs [54]. Hermans et al. further employ non-linear and non-\ninvertible hash functions to map the biometric data to ensure\nthe unlinkability of BF based representations [26].\nIn the context of record linkage analysis, items are searched\nand matched to identify records that refer to the same entity\nacross different data sources. When data to be matched is\ndeemed to be sensitive or private, the privacy preservation\nproblem arises [55]. Karapiperis and Verykio anonymize the\nrecords in the database by programming them as BFs and\nthereby enabling approximate matching [55].\nMobile social networks (MSNs) allow users to discover\nand interact with existing and potential friends to exchange\ninformation on a subject of common interest [56]. The MSNs\nare helpful for chatting, ﬁle-sharing, and web page pre-\nfetching applications. However, security and privacy issues in\nthese applications remain severe. Oriero et al. employ BFs\nto represent users’ interested topics and thereafter share these\nBFs among trusted friends [56]. The using of BFs leads to\nless communication and storage overhead. Most importantly,\nthe actual interested topics are anonymized for privacy.\nIn particular, call detail records (CDRs) that are generated\nby users of mobile devices and collected by telecom operators\ncould potentially be used for the socio-economic development\nand well-being of populations [57]. Therefore, it is necessary\nto mine CDRs while preserving the privacy of the individuals\ncontained in this data. To this end, Alaggan et al. sanitize\nCDRs data with BFs and thus preserve users’ privacy [57]. The\nidea is to anonymize the users detected by cellular antennas\nwith BFs. These BFs will be exchanged for further analysis.\nNote that, several recent surveys and tutorials, which target\nat the privacy issues in diverse scenarios, also mention the us-\nage of BFs explicitly [58] [59] [60] [61] [62]. In information-\ncentric networking, BFs enable the DoS-resistant self-routing\nmechanisms, name obfuscation, and access control [58]. The\nrecent tutorial [59] systematically reveals the shortcomings of\nanonymization with hash functions, yet fairly highlights that\n\n6\nTABLE II\nTHE PURPOSES AND GAINS OF USING BFS IN DIVERSE SCENARIOS .\nScenarios Purposes Gains Scenarios Purposes Gains\nCaching [9] Content summarization CQ, AR Akamai [14] Content summarization CQ, AR\nWireless ad hoc [38] Content summarization CQ, AR Wireless net. [39] Content summarization CQ, AR\nIP lookup [40][41] Representing routing table CQ, SS Multicast [42] Representing multicast tree CQ, SS\nMANETs [46] [47] Representing topology info. CQ, SS NDN [44] [45] Representing content names CQ, SS\nWireless NDN [2] Data dissemination CQ, SS WSNs [49] Routing packets CQ, SS\nCog. rad. net. [52] [53] Location anonymization CQ, CA LBSs [17] Location anonymization CQ, CA\nBiometrics [27] [26] Biometrics info. anonymization CQ, CA MSNs [56] Interested topics anonymization CQ, CA\nRecord linkage [55] Entry anonymization CQ, CA CDRs [57] Record anonymization CQ, CA\nSmart grid [63] Representing CRL list CQ, SS\nBF is a popular choice in designing privacy-friendly solutions.\nIn the survey which aims at the security and privacy of U.S.\nNational Science Foundation’s future internet architectures, M.\nAmbrosin et. al emphasize the BF-based method to defeat DoS\nattacks [60]. Especially, in cryptocurrency such as Bitcoin,\nBFs are used to secure the wallet by letting the simpliﬁed\npayment veriﬁcation clients only request matching transactions\nand merkle blocks from full nodes [61] [62].\nD. Network security\nThe survey [31] published in 2013 has systematically sum-\nmarised the application of BFs and their variants to address\nsecurity problems in different types of networks. Speciﬁcally,\nin wireless networks, BFs are employed for authentication,\nanonymity, ﬁrewalling, tracebacking, misbehavior detection,\nreplay attack detection, and node replication detection. In\nwired networks, various uses of BFs are found in the design of\ndifferent security mechanisms, including string matching, IP\ntracebacking, spam ﬁltering and e-mail protection, DoS and\nDDoS attacks detection, and anomaly detection. Herein, we\nbrieﬂy introduce a recent BF usage in the smart grid.\nIn smart grid advanced metering infrastructure (AMI) net-\nworks, to revoke a certiﬁcate, the certiﬁcate revocation lists\n(CRLs) are maintained for each smart meters [63]. However,\nboth maintenance and access of these CRLs are challenging\ndue to the large geographic deployment and scalability of the\nAMI networks. Therefore, Rabieh et al. propose BF based\nrevocation schemes for AMI networks that can enable the\nmeters to identify and nullify the false positives [63]. Basically,\none BF records the serial numbers of the revoked certiﬁcates\nin the AMI network and an additional BF represents the valid\ncertiﬁcates. To ﬁx the potential false positives of BFs, Merkle\ntree is established to verify the query results from BFs.\nWe ﬁnd more extensive and novel applications in data\ndissemination in WSN [64], application discovery in classiﬁ-\ncation [65], device-to-device communications [66], etc. From\nthe length concern, we omit the details here. As Mitzenmacher\nexplains that: whenever you have a set or list, and space is an\nissue, a BF may be a useful alternative [30]. Next, we detail\nthe existing optimization techniques of BFs with the following\nfour sections by analyzing each related variant. The readers\ncan also continue to Section VIII directly for comprehensive\nanalysis and comparison for all the covered BF variants.\nE. Gains of using BFs\nFrom a general perspective, we highlight the potential gains\nof using BFs in these applications as follows.Constant-time query (CQ) . As stated in Section II-B,\nthe time-complexity of membership query of BF is constant,\nwhich is much faster than trees ( O¹lognº) and table or list\n(O¹nº). This feature leads to higher query throughput.\nSpace saving (SS). BF represents the information of each\nelement with the bits in its vector, instead of storing the content\nof the element like other data structures. The required space\ncost is determined by the target false positive rate and the\nnumber of elements to represent while being independent to\nthe size of each element. BFs introduce space efﬁciency and\nspace constant features into their applications. Therefore, BFs\nare both storage-friendly and communication-friendly, so that\non-chip and in-packet implementations are often possible.\nAccess reﬁnement (AR). BFs summarize elements as a bit\n(or cell) vector and ﬁlter unnecessary accesses of the elements.\nIntuitively, the access requests are directed to the BFs ﬁrst. If\nBFs indicate the requested elements are stored by the memory,\nthe requests will further check the memory and fetch the\nrequested elements. Otherwise, the requested elements are\nbeyond this set and the access will be denied accordingly. This\nreﬁnement is extremely helpful in the scenarios of caching and\nstorage systems.\nContent anonymization (CA). The actual content of each\nelement is programmed as 1s in the vectors by BFs. Therefore,\nBFs naturally anonymize the elements with the support of\nmembership queries. The applications are able to hide the real\ncontent while releasing the BFs for membership queries. This\nability is meaningful to privacy preservation and data security.\nEspecially, Table. II summarizes the major purposes and\ngains of using BFs in the aforementioned scenarios. All these\nsystems represent elements with BF and beneﬁt from constant-\ntime membership query for sure. Additionally, for diverse\ndesign purpose, the gains of using BFs may be different.\nFor content caching, BF works as content summarization and\nreﬁnes unnecessary access of the cache memory. For packet\nrouting and forwarding, BFs enable the routing strategies and\nprovide space efﬁciency so that they can be embedded into\npacket headers. For privacy preservation, BFs anonymize data\nand support fast queries simultaneously. Lastly, in our example\nof using BFs for network security, BFs save space for the\nrepresentation of CRLs.\nIV. R EDUCTION OF FALSE POSITIVES\nBefore detailing the related variants, we formulate the false\npositive proportion (FPP) and false positive rate (FPR) as\nfollows. FPP is an empirical concept that calculates the ratio\nbetween the occurrence of false positive errors and the total\n\n7\nU\nTS\n(a) False positive rate.\nU\nT Q S (b) False positive proportion.\nFig. 3. The false positive rate and false positive proportion in Bloom ﬁlters,\nshown by the ﬁlled areas.\nquery times. In contrast, FPR is a theoretical term used to\nquantify the probability of any query result incurs a false\npositive error. Usually, FPP can be employed as the point\nestimation of FPR. FPR is a ﬁxed value and determined by\nthe BF framework itself, while FPP is variable and ﬂuctuates\naround the value of FPR. As shown in Fig. 3, let Ube\nthe universal set, Sdenote the set represented by a BF, Q\ndenote the elements to be queried and Trecord the elements\nwhich return positive for the membership query, respectively.\nThen the elements which lead to false positive errors can be\nderived as F=T\u0000S. With the above notations, the false positive\nrate for all the query of elements in Ucan be calculated as\nfr=jFjjUj=jT\u0000SjjUj. Pair-wisely, the false positive propor-\ntion for the query of elements in Qisfp=j¹T\\Qº\u0000¹S\\QºjjQj.\nTherefore, to reduce the number of false positives in an\ninstance of BF, we have methods to lower FPR and techniques\nto control FPP. Reducing FPR means to decrease Tand thus F\ndirectly. A brute-force solution to reduce FPR is to increase the\nnumber of bits or cells in the vector, with the penalty of more\nspace overhead. But this method doesn’t work in space-scarce\nsituations. Reducing FPR is more general to be extended to\ndiverse scenarios, while decreasing FPP is more speciﬁc and\ncase-dependent. For example, for speciﬁc instance of BF with\ngiven Q, it is possible to select hash functions which lead to\nlower FPP. Both the two design philosophies are reasonable.\nThe intrinsic reason of false positive is that BF arbitrates\nthe membership of an element based on the presence or non-\npresence of the corresponding 1s, without concerning which\nelement (or elements) ﬁlls these hash bits. The bits in the\nvector, however, may suffer from hash collisions, which may\nﬁnally cause false positive query results. One may reduce false\npositives from the following aspects. First, prior knowledge\ncan be helpful when setting the parameters of BF to reduce\nFPs. Second, the one-sided error property can also identify\nFPs. Given a main BF and multiple attached BFs, the negative\nquery results in the attached BFs can prone some false positive\nresults of the main BF. Third, if the non-zero bits are reset as\n0s, the potential false positive errors will not happen. But this\nwill introduce the possibility of false negative errors instead.\nFourth, the hash functions are optional and one may select the\nhash functions which lead to the least false positives. At last,\nif the elements are inserted differentially, the hash collisions\nwill not impose false positives to the query result. The details\nare shown in the following ﬁve subsections, respectively.A. Reducing FP with prior knowledge\nNote that, some prior knowledge is helpful to identify some\nfalse positives of BF queries and accordingly decrease the\nresulted FPs. For example, if the elements to be queried ( Q)\nare known as prior knowledge, it is possible for the BF users\nto select the hash functions which yield the least FPs. A\ntypical scenario where Qis known is multicast routing based\non BF. Actually, BF enables both in-switch routing and in-\npacket routing schemes for multicast. For in-switch routing,\neach interface in the switch uses a BF to maintain the multicast\ngroups it joins. By contrast, in-packet routing embeds a BF\nin the header of each packet to encode the multicast tree\ninformation. The false positives will result in trafﬁc leakage via\nleading ﬂows to additional nodes which are not in the multicast\ntree. Multi-class BF [3] and False-positive-free multistage BF\n[43] are proposed to reduce the FPs of in-switch and in-packet\nBFs, respectively. Additionally, in the case of web caching,\nRottenstreich et al. uncover the Bloom paradox and suggest\nto insert and query elements selectively based on their priori\nmembership probability. Moreover, the Optihash [67] scheme\nselects the hash functions which generate the lowest FPP\nin the context of PSIRP (Publish/Subscribe Internet Routing\nParading) systems.\nMulti-class BF. For in-switch multicast routing, Li et al.\npoint out that, the presence probability of a multicast group\non a certain switch interface can be evaluated via joint\nconsideration of the multicast group size and the data center\ntopology [3]. With this insight, they propose Multi-class BF, a\nvariant of BF to minimize the trafﬁc leakage [3]. They observe\nthat an element with a higher presence probability indicates a\nlower impact of its false probability on the expected number of\nfalsely matched elements. Therefore, Multi-class BF proposes\nto employ different number of hash functions for each element\nto minimize the expected number of falsely matched elements.\nSpeciﬁcally, in a switch interface, the groups with higher\npresence probability are encoded with fewer hash functions,\nwhile the groups with lower presence probability should\nbe programmed with more hash functions. In this way, the\nmulticast groups with lower presence probability must check\nmore bits when querying their memberships. In other words,\nMulti-class BF removes some elements which may lead to\nfalse positives with high probability from set T, by setting\nstricter conditions to pass the queries.\nFalse-positive-free multistage BF (FPF-MBF). As for in-\npacket multicast routing, Tapolcai et al. devote to solving the\nscalable forwarding problem, especially the scalability of the\nmulticast trees [43]. To this end, the multistage BFs [68] [69]\nare employed to record the links in each stage of the multicast\ntree. A multicast tree of vhops is represented by vBFs, and\nthevthBF contains only the links residing at vhop-distance\nfrom the source node. When leaving the source, the multicast\nin-packet BF header consists of vstage ﬁlters, which then\nshrinks as the packet travels along the tree. To this end, each\nstage BF consists of two parts, i.e., the ﬁrst \rbits to indicate\nits stage, and the later bbits to record the memberships of\nlinks in this stage.\nLiterature [43] proposes to build FPF-MBF, based on the\n\n8\nprior knowledge of the number of elements to be included\n(\u001a) and the number of elements to be excluded from the ﬁlter\n(\u0010). In effect, FPF-MBF reduces the generated false positive\nproportion from two aspects. On one hand, unlike the tradi-\ntional in-packet BFs which record all links in a multicast tree,\neach stage ﬁlter only encodes the links in the corresponding\nstage. On the other hand, given the value of \u001aand\u0010, the\nlength of each stage ﬁlter is adjusted to further decrease the\nfalse positive proportion. Essentially, the design philosophy of\nFPF-MBF is to reach the goal that ¹T\u0000Sº\\¹Q\u0000Sº=;, where\nQis the known set of elements to be queried. As a result, all\nqueried elements will not be matched false-positively, and it\nperforms like with a false positive proportion of 0.\nBloom paradox. We consider a generic system composed\nof a user, a main memory containing all the data, and a cache\nwith a subset of the data. A BF is employed to record the\ndata in the cache. When the user reads a piece of data, he\nchecks the BF ﬁrst. If the query result is negative, the user\nwill access the main memory directly; otherwise, it goes to\nthe cache instead. However, the positive results can be true\nor false. For the false positives, the user still needs to access\nthe main memory. Let M,CandTbe the elements in the\nmain memory, the elements in the cache, and the elements in\nmain memory that lead to positive result when querying the\nBF, respectively. We have jTj=jCj+fp\u0003¹jMj\u0000jCjº, where fpis\nthe false positive proportion of the BF. The probability that a\npositive query result is false positive can be evaluated as:\njTj\u0000jCj\njTj=fp\u0003¹jMj\u0000jCjº\njCj+fp\u0003¹jMj\u0000jCjº: (4)\nGivenjMj=1010,jCj=104andfp=10\u00003, the probability that a\npositive query result is false positive is almost 1\u000010\u00003. That is,\namong the positive results of the BF for the various elements,\nmost of them are false positives. This phenomena is called\nBloom paradox [9].\nWith the prior knowledge, i.e., the value of jMj,jCjand\nthe parameter setting of BF, one may calculate the condition\nof Bloom paradox. Rottenstreich et al. suggest selective BF\ninsertion, as well as selective BF query [9]. When inserting\n(querying) an element, if the element satisﬁes the Bloom\nparadox condition, it will not be inserted (queried). Namely, in\nthe scenario of Bloom paradox, the users should not trust the\nBF such that they will survive the impact of false positives.\nOptihash. Optihash [67] is designed to extend the BF\nin the context of PSIRP (Publish/Subscribe Internet Routing\nParading) which is a new redesign of the whole Internet\narchitecture as far as the physical layer [70]. The in-packet\nBFs are employed as encoding to identify routes and links\nbetween nodes. The optihash is a bit array wwhich consists\nof three parts: a bit array vand two integer parameters \u000b\nand\f. Only one hash function his initialized to map each\nelement into the bit array v. As depicted in Fig. 4, Sis a set\nof elements ( Smay be a multiset) encoded in the optihash,\nthe hash function hmaps the elements in Sto a generally\nsmaller set R. The inverse h\u00001maps the set of hashes Rto a\nset of elements which is bigger than S. Let Qdenote the set of\nelements to be queried, then the set of false-positive elements\nFcan be derived as F=¹h\u00001¹Rº\\Qº\u0000S.\nQh-1(R)\nS\nR\nFFFig. 4. The theory of Optihash [67]. Its basic insight is to choose a set of\ntransformed hash values which leads to the smallest volume of F.\nOptihash proposes to generate a family of hash values\naccording to the value of \u000b,\fand the employed hash function\nh. Generally, there will be 2m\u000b2m\fnew sets of hash values,\nwhere m\u000bandm\fare the number of bits to store \u000band\f,\nrespectively. Consider that all elements in the set Qare known,\nthe user can employ the set of hash values which lead to\nthe smallest volume of F. In this particular manner, optihash\ndecreases the number of elements which cause false positives,\nat the cost of complicated computation.\nB. Reducing FP with the one-sided error\nAs stated in the subsection II-B, BF suffers from unavoid-\nable false positive errors during query, but no false negative\nerrors. Namely, the conclusion drawn by BF that an element\nxis not a member of Sis 100% correct. This one-sided\nerror characteristic, indeed, is helpful to identify some false\npositives from the query results [40] [71] [72] [73].\nFor example, it has been recently studied that the search\nperformance of trie-based algorithms can be signiﬁcantly\nimproved by adding a BF [40] to record the nodes in the trie.\nIn such algorithms, the number of trie accesses can be greatly\nreduced because BF can determine whether a node exists in\na trie without actually accessing the trie. However, the false\npositives of BF bring unnecessary trie accesses. Fortunately,\nMun et al. notice that arbitrary node (except the source node)\nin a trie can only exist if its ancestors are also in the trie [71].\nTherefore, they propose to use more BF queries to reduce the\nfalse positive proportion of a BF in trie-based algorithms.\nWhen the BF returns positive upon querying an element\ny, to check it is a false positive or not, the ancestor node of\ny, i.e., node zwill also be queried. If the BF indicates that\nzis not a node of the trie, obviously yis a false positive\nnode. By contrast, if the query result of zis also positive, y\nis a trie node with higher probability. But zmay also be a\nfalse positive node. To further test the trueness of the positive\nresult for z, one may query the ancestor of zadditionally. For\nany set whose elements share a strong internal dependency, the\nsame strategy can be introduced to recognize unnecessary false\npositives. As for more general sets, the following three variants\nof BF are proposed base on the one-sided error characteristic.\nCross-checking BF. Lim et al. propose a new architecture\nto reduce the false positive proportion of BF [72]. The ar-\nchitecture consists of a main BF which is programmed for\n\n9\nA B\nT(S)-(T(A)    T(B))T(A)-T(S) T(B)-T(S)T(A) T(B)\nT(S)U\n(T(A)-A) ꓵ T(S) (T(B)-B) ꓵ T(S) \nS∩ \nFig. 5. Set diagram with T¹Aº,T¹BºandT¹Sºfor cross-checking BFs and\nthe main BF, with the assumption that T¹Aº\\T¹Bº=;[72].\nall the elements in the set S, and multiple cross-checking BFs\nwhich are responsible to record the elements in several disjoint\nsubsets of S. As depicted in Fig. 5, consider the set Sas\nthe union of two disjoint subsets AandB, i.e., S=A[Band\nA\\B=;. In this case, the BF for the entire set Sis the main\nBF, while the BFs for the set AandBare cross-checking BFs\nto check the false positives of the main BF. A positive result of\nthe main BF for element xwill be recognized as false positive,\nif both of the cross-checking BFs return negative query results\nforx. The underlying basis is that the negative query results of\nBF are 100% correct, due to the one-sided error characteristic.\nTheoretically, as shown in Fig. 5, the main BF and the\ntwo cross-checking BFs all suffer from false positives. Let\nT¹Sº,T¹Aº, and T¹Bºdenote the set of elements which return\na positive result when querying upon the main BF and the\ntwo cross-checking BFs, respectively. By querying the cross-\nchecking BFs, the elements in T¹Sº\u0000¹T¹Aº[T¹Bººwill be\nidentiﬁed as false positives. Therefore, with the help of cross-\nchecking BFs, the global false positive rate will be decreased\nfromjT¹Sº\u0000Sj\njUjto:\nj¹¹T¹Aº\u0000Aº\\T¹Sºº[¹¹ T¹Bº\u0000Bº\\T¹Sººj\njUj: (5)\nThe speciﬁc value of the false positive rate is further given\nin [72]. Undoubtedly, the cross-checking BFs requires more\nqueries and more space overhead.\nComplement BF. When BF is associated with an off-chip\nhash table, the hash table can verify the positive results of the\nBF for S. To reduce the access frequency of the hash table,\ncomplement BF [73] is introduced. Unlike the cross-checking\nBFs which split the set Sas multiple disjoint subsets, Lim et al.\npropose to divide the union set Uas two independent subsets,\ni.e.,Sand its complement set SC[73]. Typically, a main BF\nis programmed according to the elements in S, and another\nBF (complement BF) is initialized to record the elements in\nthe set SC. The complement BF helps to identify some false\npositive errors since the elements not in SCmust belong to S.\nWith this insight, Table III presents the truth table of a\nquery with joint consideration of the main BF and complement\nBF. Note that, the two BFs will never return negative query\nresult simultaneously, since U=S[SCand any element not\ninSmust belong to SC. Only if both the main BF and the\ncomplement BF return positive when querying an element x,\nthe membership of xwill be further checked by the off-chipTABLE III\nTRUTH TABLE OF QUERY WITH BOTH MAIN BF AND COMPLEMENT BF.\nMain BF for S 1 0 1 0\nComplement BF 0 1 1 0\nConclusion x2S x <S Hash table Not exist\nhash table. Consequently, the frequency of hash table access\ncan be signiﬁcantly decreased from T¹SºtoT¹Sº\\T¹SCº. It\nhas been proven that the probability of both BFs producing\npositives converges the summation of the false positive rate of\neach BF [73]. However, in the case of large-scale complement\nsetSC, the complement BF may cost vast on-chip memory.\nYes-no BF. Unlike the previous proposals which remove\nthe elements from the set Tdirectly, yes-no BF keeps track\nnot only the elements belonging to the set S, but also the\nelements which generate false positives [74]. The yes-no BF\nis composed of two parts, i.e., the yes-ﬁlter which encodes\nthe set elements, and the no-ﬁlter which stores the elements\nwhich generate false-positives. The mbits in yes-no BF are\nconsequently split into two parts, pbits for the yes-ﬁlter, and\nr\u0002qbits for the rno-ﬁlters each of qbits. The yes-ﬁlter\nperforms just like a normal BF and record the membership\nof elements in S. In contrast, the no-ﬁlter for the set Stracks\nthe elements which cause false-positives in the yes-ﬁlter. Note\nthat, an element can only be stored in one of the rno-ﬁlters.\nWhen querying, the yes-no BF will conclude that an element\nxbelongs to S, if and only if the corresponding bits in the\nyes-ﬁlter are all 1s and none of the rno-ﬁlters indicates xis\na false positive. In Yes-no BF, the positive results given by\nthe yes-ﬁlter are further tested by the no-ﬁlters. Consequently,\nthe number of elements in Tcan be decreased, but at the\nrisk of false negatives. To reduce the potential false negatives,\nadditional queries must be conducted.\nC. Reducing FP via bit resetting\nIntrinsically, the false positives appear because BF checks\nthek1s without distinguishing the elements which are hashed\ninto these positions. As a result, an element can be false-\npositively matched because its corresponding bits are set to\n1s by other elements. Thus, several proposals try to reduce\nthe false positive errors by modulating the bit vector directly.\nNote that the retouched BF [75] and generalized BF [76] are\ndesigned for standard BF, while multi-partitioned counting BF\n[77] are proposed to reduce the false positive rate of CBF [36].\nRetouched BF. Retouched BF is proposed as an extension\nto make the BF more ﬂexible by permitting the removal of\nselected false positives at the expense of generating random\nfalse negatives [75]. To do so, the selected bits are cleared by\nresetting from 1 to 0. The authors present two strategies for the\nclearing. The randomized bit clearing resets a certain number\nof bits from the bit vector randomly. Theoretical analysis\ndemonstrates that, after executing the randomised bit clearing\nprocess, the increment of false negatives and the decrement of\nfalse positives are very close [75].\nBy contrast, another strategy called selective clearing is\ndesigned to reset the bits which trigger false positives. This\ncan be realized since the system can learn a portion of\nfalse positives through previous queries. Four algorithms are\n\n10\nx\n1\n0\n1\n0\n1\n0\n0\n0\n0 1 2 34567Level 1\nLevel 2\n 0\n0\n0\n8910 \nRemainder \nx\n1\n0\n1\n0\n1\n0\n0\n1\n0 1 2 34567Level 1\nLevel 2\n 0\n1\n1\n8910 \nRemainder \ny\n0\n11 \n0\n0\n12 13 Level 3\nFig. 6. Hierarchical structure in a 16-bit word of MPCBF [77]. Initially,\nthe number of hash functions k=3, and level 1 has 8 bits which have been\ninitialized as 0.\nproposed to trade-off the false positives and false negatives.\nWhen removing an element, there are kcandidate bits to\nreset. Thereafter, Retouched BF have: 1) the random selection\nalgorithm randomly selects a bit amongst the kcandidates;\n2) the minimum FN selection resets the bit which generates\nthe least increment of false negatives; 3) the maximum FP\nselection chooses the bit which enables the maximum false\npositive decrement; and 4) the ratio selection prefers resetting\nthe bit which minimizes the generated false negatives while\nmaximizing the false positives removed. With the above strate-\ngies, Retouched BF reduces FPR at the cost of false negatives.\nGeneralized BF. Generalized BF [76] employs two groups\nof hash functions, i.e., fg1;\u0001\u0001\u0001gk0gandfh1;\u0001\u0001\u0001hk1g. When\ninserting an element into the bit vector, the k0bits mapped\nby the hash functions fg1;\u0001\u0001\u0001gk0gare reset as 0, while the\nk1bits derived by the hash functions fh1;\u0001\u0001\u0001hk1gare set to 1\n(break the tie by keeping reset). When querying an element\nx, generalized BF checks whether the bits corresponding\nto the positionsfg1¹xº;\u0001\u0001\u0001gk0¹xºgare all 0 and the bits\nfh1¹xº;\u0001\u0001\u0001hk1¹xºgare all 1. If at least one bit is inverted,\ngeneralized BF returns a negative query result; otherwise, it\nreturns a positive result.\nFalse positive will happen if the fg1¹xº;\u0001\u0001\u0001gk0¹xºgare all\n0, and if the bits fh1¹xº;\u0001\u0001\u0001hk1¹xºgare all 1, due to the\ninsertion of other elements in the set S. Moreover, it is possible\nthat an element x2Smay not be reported as a member of\nS, resulting in a false negative. False negative will occur\nif at least one of the fg1¹xº;\u0001\u0001\u0001gk0¹xºgbits is set as 1 by\nthek1hash functions for another element y, or one of the\nfh1¹xº;\u0001\u0001\u0001hk1¹xºgbits are reset as 0 by the k0hash functions.\nCertainly, generalized BF offers rigid constraints to pass the\nmembership query, thus reducing the false positive rate. But\nit calls for reconsideration when put generalized BF into real\nuse, due to the non-negligible false negatives.\nMulti-partitioned Counting BF (MPCBF). CBF [36]\nextends BF by allowing insertions and deletions to support\ndynamic datasets. To reduce the number of memory accesses,\nMPCBF divides the mcells into lwords so that each word\ncan be fetched in a single memory access [77]. To insert an\nelement x, an extra hash function heis employed to map\nxinto one of the lwords. Thereafter, the khash functions\nfh1¹xº;\u0001\u0001\u0001;hk¹xºgmap xinto kcells in the selected word.\nThis strategy, however, leads to more false positive errors. To\nreduce the false positives, MPCBF suggests to reconstruct each\nword as a hierarchical structure.\nAs depicted in Fig. 6, MPCBF allocates the bits in each\nword as multiple levels. The basic principle for constructingthe hierarchical structure is as follows. Whenever an element\nis inserted into the word, kbits must be set from 0 to 1. And\nwhenever a bit is set from 0 to 1, an empty bit should be\nadded into the next level and initialized as 0. This is realized\nby using a function popcount¹iºwhich computes the number\nof ones before position iat the hierarchy level that bit ibelongs\nto. Note that, only level 1 is utilized for membership query.\nTherefore, the membership in this word can be recorded with\n8 bits, instead of 4 cells (suppose that each cell in CBF has\n4 bits). As a result, the false positive rate can be signiﬁcantly\ndecreased at the cost of a little more computation overhead.\nD. Reducing FP with selected hash functions\nFalse positive errors are not avoidable for BF and its\nvariants, due to the potential hash collisions. Typically, the\nfalse positive rate of BF is proportional to the number of 1s\nin the bit vector. Based on this observation, endeavours have\nbeen made to select proper hash functions for the elements. A\ntypical work is to introduce “the power of two choices” into\nthe design of BF [78]. The basic idea is to employ two (or\nmore) groups of hash functions, and the insertion will utilize\nthe group of hash functions which increase the least 1s in the\nbit vector. During membership query, if the element passes\nthe checking of any group of hash functions, the query result\nwill be positive; otherwise, negative. The cost is more hash\ncomputation and lookups.\nMoreover, a partitioned hashing scheme [79] is then pro-\nposed to further optimize the hash function selection, based\non the balls and bins theory. Before insertion, the elements in\nsetSis divided into gindependent groups by hashing their\nkeys. Given Hhash functions, each group of the elements\nwill be mapped into the bit vector ttimes for test, where\nk\u0014t\u0014\u0000k\nH\u0001. In each test, every element will be hashed ktimes.\nThereafter, the set of hash functions which increase the least\n1s in the bit vector will be selected. Then, the group of\nelements will be mapped into the vector with the selected\nkhash functions. Note that, the hash functions intra a group\nare independent, but can be dependent inter groups. That is, a\nhash function is allowed to be shared among multiple groups\nof hash functions. A greedy algorithm is designed to speed\nup the selection process. The conducted experiments indicate\nthat the partitioned hashing scheme results in as much as a\nten-fold increase in accuracy over standard BF.\nSelecting the hash functions is a computation-intensive task,\nespecially when the number of candidate hash functions is\nlarge, there are in total\u0000k\nH\u0001possible combinations. Besides,\nfor dynamic datasets, this kind of methods call for re-selection\nof the hash functions when the dataset changes. Therefore,\nselecting khash functions from many candidates suits for the\nsituations where the query accuracy must be guaranteed, while\nthe computation is not an issue and the dataset is static.\nMost recently, Kiss et al. propose EGH ﬁlter to replace\nthekhash functionsfh1;\u0001\u0001\u0001;hkgwith the ksimple functions\nfˆh1;\u0001\u0001\u0001;ˆhkggenerated based on kprime numbers. Intuitively,\nEGH ﬁlter supports the Bloom ﬁlter operations and addi-\ntionally guarantees false positive free operations for a ﬁnite\nuniverse when a restricted number of elements stored in the\n\n11\nﬁlter [80]. In other words, given a ﬁnite universe set Uwith\njUjelements, an EGH ﬁlter vector with mbits will not suffer\nfrom any false positive errors if at most ntelements are stored.\nThe essence of the solution is to use the Chinese Remainder\nTheorem [81] and solve a combination group testing (CGT)\nproblem [82] by ﬁnding a solution to a system of linear\ncongruences. Note that there are strong constraints between\nthe parameters m,jUj,ntandk. Basically, njUj\ntshould be less\nthan the product result of the ﬁrst kprime numbers. Then\nthe value of mwill be set as the summation result of the\nﬁrstkprime numbers. With the above parameter setting, EGH\nﬁlter performs the insertion and query just like the standard\nBF. Furthermore, the EGH ﬁlter can be extended to support\ndeletion and listing of the recorded elements.\nDeﬁnitely, the used functions in EGH ﬁlter are determin-\nistic, fast and simple to calculate, enabling a superior lookup\nperformance compared to BFs. However, the generated false\npositive free zone is relatively small. For example, an EGH\nﬁlter with m=2;127andk=34only guarantees a false positive\nfree zone which covers 20 elements from a set with 562\nelements. Still, when the number of record elements is larger\nthan the threshold nt, EGH ﬁlter may incurs false positive\nerrors. Besides, to maintain the false positive free zone, the\nbpe in EGH ﬁlter is higher than Bloom ﬁlter. In the above\nexample, the bpe of EGH ﬁlter ism\nnt=2;127\n20=106:35which\nis much higher than standard BF. Therefore, EGH ﬁlter is\nadvisable when false positives should be completely avoided,\nthe universe set is ﬁnite and the set is small while the available\nspace is relatively large.\nE. Reducing FP by differentiated representation\nCBF [36] also suffers from false positives, since the counters\nfail to differentiate the elements mapped into it effectively.\nUnlike the MPCBF which optimizes the utilization of bits in\nthe counter, variable-increment counting BF [83] and ﬁnger-\nprint counting BF [84] seek the ways to reduce FPR with\ndifferentiated representations of elements.\nVariable-increment counting BF (VI-CBF). Unlike CBFs,\nwhen inserting an element, the counters of VI-CBF are in-\ncremented by a hashed variable increment instead of a unit\nincrement [83]. Then, to query an element, the exact value of\na counter is considered, not just its positiveness. The speciﬁc\ninsertion operation is shown in Fig. 7. VI-CBF consists of two\ncounter vectors: the ﬁrst counter vectors to record the number\nof elements hashed into this position ( C1), and the second\ncounter vectors to provide a weight sum of these elements\nwith diverse increments ( C2). A family of hash functions\nG=fg1;\u0001\u0001\u0001;gkgare employed to select the kincrements from\nthe set D. Note that D=fv1;v2;\u0001\u0001\u0001;vugis a set of integers\nsuch that all the sums vi1+vi2+\u0001\u0001\u0001+vilwith 1\u0014i1\u0014\u0001\u0001\u0001\u0014 il\u0014u\nare distinct. Thereafter, khash functionsfh1;\u0001\u0001\u0001;hkgmap\nthe element into kcells of VI-CBF. The kcounters in C1are\nincreased by 1, while the counters in C2are updated with the\nkselected increments, respectively.\nTo query an element x, VI-CBF ﬁrst checks the kcounters\nC1»h1¹xº¼;\u0001\u0001\u0001;C1»hk¹xº¼. If any counter is 0, obviously x<S.\nIfC1¹iºis small, VI-CBF considers the exact values in both\n5 2 3 3 C1 4\n34 26 21 626 C2\nx y1 2 3456789\n0\n13\n42\n33\n4\n0\n825 \n29 17 \n30 9\n13 \n8 4 13 4Fig. 7. An illustrative example of VICBF insertion with k=2and the base\nsetD=f1;4;8;13g[83].\ncounter vectors. In this case, no more than uelements were\nhashed into these cells. Thereafter, VI-CBF can deduce the\nemployed increments in the value of C2¹iº. If vgi¹xºis con-\ntained in C2»gi¹xº¼(i2»1;k¼), then x2Swith high probability;\notherwise, x<S. Lastly, if C1¹iºis large, VI-CBF holds that\nthis cell is not useful and examines other cells for possibly\neliminating the membership of x. By updating the counters\nwith diverse increments, VI-CBF effectively distinguishes the\nelements mapped into a cell. It was shown that the VI-CBF has\nan improved false positive rate than the CBF for ﬁxed number\nof bits per element (bpe) although it requires more bits per\ncounter allowing having a smaller number of counters.\nFingerprint counting BF (FP-CBF). Different from the\nVI-CBF, FP-CBF labels the elements with unique ﬁngerprints\n[84]. To be speciﬁc, each cell in FP-CBF consists of two ﬁelds,\ni.e., the ﬁngerprint ﬁeld and the counter ﬁeld. The ﬁngerprint\nhasabits to store the ﬁngerprints mapped into this cell. Note\nthat the ﬁngerprint of an element is generated by employing a\nhash function hf p¹xºto map element xinto the range [0, 2a].\nThe counter ﬁeld counts the number of elements with cbits. To\ninsert an element x, the khash functions map xinto the cells\nin positions h1¹xº;\u0001\u0001\u0001;hk¹xº. Thereafter, in these cells, the\nﬁngerprint ﬁeld is updated by executing the XOR operations\nbetween the existing ﬁngerprint and hf p¹xº. By contrast, the\ncounters are increased by 1. To delete an element yfrom the\nFP-CBF, the corresponding kcounters are decreased by 1,\nwhile the ﬁngerprint ﬁelds are updated by XORing the existing\nﬁngerprints in each counter with hf p¹yº.\nTo query an element x, if any counter in the corresponding\nkcells is 0, x<S. For all counters that have a value of\n1, FP-CBF checks whether the ﬁngerprint ﬁeld is different\nfrom hf p¹xº. If so, x<S. Otherwise, if the above two checks\nare passed, FP-CBF believes x2Swith high probability. That\nis, FP-CBF recognizes the false-positively matched elements\nwhich have at least one counter value of 1. This is realized\nby checking the ﬁngerprint in the cell with the ﬁngerprint of\nthe queried element. In effect, the similar design philosophy\nis also achieved in the literature [20] by Luo et al in order\nto synchronize two given multisets. The dedicated encoding,\nsubtracting and decoding operations are designed to identify\nthe different elements between the multisets. So that only the\ndifferent elements are transmitted to save bandwidth. However,\nimposing ﬁngerprint ﬁeld to the cells requires more memory.\nF . Summary and lessons learned\nAs a simple summary of this section, numerous variants\nare proposed to reduce the false positive errors of BFs with\n\n12\nnovel intuitions. They remove or recognize the potential false\npositives by using prior knowledge [3] [43] [67] [9], selecting\noptimal hash functions [78] [79], generating multiple BFs [74]\n[72] [73] and queries [71], resetting the bits [75] [76] [77], or\ndifferentially representing the elements [83] [84]. Among these\nvariants, FPF-MBF [43], Optihash [67], strategies to lessen\nBloom paradox [9], and Selected hash [78] [79] control the\nFPP by carefully choosing the hash functions. Other variants,\non the contrary, try to decrease the FPR directly. Both of\nthese two design philosophies are reasonable and functional.\nHowever, all the above strategies impose either additional\nmemory cost or complicated computation process. In reality,\nthe users may trade-off the impact of false positives and the\nintroduced cost of reducing FPs.\nV. O PTIMIZATIONS OF IMPLEMENTATION MEASUREMENTS\nBF is a lightweight and easy-deployable data structure. But\nits performance can be further improved. To this end, the ex-\nisting desgins consider four practical measurements, including\ncomputation complexity, memory access, space efﬁciency, and\nenergy consumption.\nA. Computation optimization\nThe major computation overhead of BF stems from two\nfolds, i.e., the computation of hash functions and the judg-\nment process for a query. BF requires multiple indepen-\ndent hash functions, while well-designed hash functions are\ncomputation-intensive, e.g., MD5, SHA-1. Other hash func-\ntions, e.g., perfect hash, locality-sensitive hash, are even more\ncomplicated to calculate. To lessen the computation overhead\ndue to hash functions, state-of-the-art techniques try to gen-\nerate multiple independent hash values with only one or two\nhash functions [85] [86].\nLess hashing, same performance. Kirsch and Mitzen-\nmacher [85] use two pseudorandom hash functions h1¹xº\nand h2¹xºto generate additional hash functions. Specif-\nically, the khash functions will be calculated as:\ngi¹xº=h1¹xº+i\u0002h2¹xºmod m , where 0\u0014i\u0014k\u00001andmis the\nnumber of bits in BF. It has been soundly proved that using\nthe generated hash functions imposes no any increase in the\nasymptotic false positive rate, based on the balls-and-bins\nanalysis [85] [87]. Since then, this kind of method has been\nwidely utilized in practice to accelerate BF and its variants.\nOne Hash BF (OHBF). Unlike the above strategy which\nneeds two hash functions as seeds, OHBF [86] is more\nambitious and generates khash values with only one hash\nfunction. OHBF points out that the hash mapping consists of\ntwo stages, i.e., the hash stage which maps the input element\ninto a machine word (e.g., 32 bits, 64 bits), and the modulo\nstage which maps the generated word into a given range via\nmodulo. Consequently, OHBF divides the m-bit vector as k\nparts unevenly, such that m=m1+\u0001\u0001\u0001+mk, where miis the\nlength of the ithpart. Thereafter, the generated word will\nmodulo with m1;\u0001\u0001\u0001;mkrespectively to derive the location of\nthe element xin each part. Similar with the variants which\npartition the bit vector into multiple segments, OHBF also\nslightly damages the randomness of the hash function. Thereason is that the result of a hash function is limited in\na dedicated range, rather than the overall bit vector. As a\nconsequence, more hash collisions will be triggered thereby\nleading to a higher false positive rate. Fortunately, when m\nincreases, the gap of false positive rate between the standard\nBF and the partitioned variants will degrade gradually.\nOn the other hand, another thinking is to speed up the\nhash computation, sequent programmes and check operations.\nA general strategy is to parallelize the computations. In\nscenarios where the bit (or cell) vector is divided into multiple\nsegments, these segments can be accessed simultaneously\nthereby the thereafter computations can be parallelized. This\nkind of variants include Space-code BF [88], Dynamic BF\n[89], Dynamic BF array [90], Par-BF [91], BloomStore [18],\nCross-checking BF [72], One hash BF [86], Bloom-1 [92],\nOMASS [93], Parallel BF [94], etc. The parallelism strategy\ncan efﬁciently reduce the response time to 1\u0018, where\u0018is\nthe number of parallelized instances. Note that, some variants\nwith multiple segments, on the contrary, cannot be parallelized,\nsince they are designed for sequent checking, e.g., Yes-no\nBF [74], Bloomier ﬁlter [95], Complement BF [73], and\nMulti-partitioned counting BF [77]. Speciﬁcally, the Yes-no\nBF [74] consists of both yes-ﬁlter and no-ﬁlter. Only the\nelements which pass the check of yes-ﬁlter will be further\nchecked by the no-ﬁlter. Similarly, the Complement BF for the\ncomplement set SConly need to be checked if the element x\nhas passed the check of the main BF for set S. By contrast,\nthe Bloomier ﬁlter [95] and Multi-partitioned counting BF\n[77] cannot be parallelized because the bit vectors in them\nare constructed recursively.\nIn the following, we present two other variants which also\nenable the parallelism methodology with multiple divisions\n[96] [97], as well as one recent proposal which tries to\nparallelize the hash computation by employing acceleration\ntechnique named Single Instruction Multiple Data (SIMD)\ninstructions [98].\nDistributed Load Balanced BF (DLB-BF). DLB-BF [96]\nis designed for IP lookup (longest preﬁx matching). Usually,\nthe IP preﬁxes have different lengths. Based on their lengths,\nthe preﬁxes are categorized as diverse preﬁx groups, w.l.o.g.,\nggroups. DLB-BF employs kequal-length BFs, as well as\nkgroups of hash functions, to represent these preﬁx groups.\nNote that, each group of hash function has gindependent hash\nfunctions in it. Each hash function in a group is responsible to\na speciﬁc group of IP preﬁxes. Speciﬁcally, the hash function\nHi;j(1\u0014i\u0014g,1\u0014j\u0014k) is responsible to map the ithgroup\nof IP preﬁxes into the jthBF. Under this framework, to\nencode a preﬁx with length i, the kcorresponding functions,\ni.e., Hi;1;Hi;2;\u0001\u0001\u0001;Hi;k, map the preﬁx into the kBFs and\nprogramme the bits to 1s. Thus the membership information\nof the inserted IP preﬁx is dispersedly recorded in the kBFs.\nTo query an IP preﬁx xwith length i, DLB-BF checks the bits\ngenerated by the khash functions ( Hi;1;Hi;2;\u0001\u0001\u0001;Hi;k) in the\nkBFs. If all these bits are non-zero, the queried IP preﬁx is\nin the routing table and the associated forwarding port can be\nidentiﬁed reasonably.\nTo speed up the query and computation, DLB-BF divides\na single BF vector into multiple BFs and thus enables paral-\n\n13\nblock [1] block [2]   block [r-1] block [r]\nword [2] word [1]    word [k]bit array\nblock\nFig. 8. The framework of Ultra-Fast BF [98].\nlelism, i.e., the kBFs can be accessed simultaneously and then\nthe bitwise AND operation towards the kbits will generate the\nquery result. The problem is that the number of involved hash\nfunctions is g\u0002k. The calculations of these hash functions can\nbe challenging.\nCombinatorial BF. Combinatorial BF [97] considers the\nmembership query of Swhich has multiple groups. The query\nresult should point out which group(s) the queried element\nbelongs to, without the priori knowledge of the number of\nelements in each group. For simplicity, Combinatorial BF\nsupposes that an element only belongs to one of the \rgroups.\nFor arbitrary element x, its group g¹xºhas a\t-bit binary code\nC¹g¹xºº. For each bit in the code, there is a corresponding\ngroup of khash functions. Therefore, k\u0002\thash functions\nare required. To insert the element x, Combinatorial BF maps\nxinto the bit vector with the hash groups where the bits\ninC¹g¹xººare 1s. For example, given \t=3andk=3, if the\nelement xbelongs to group 5, whose id code is 101, then\nthe two groups of hash functions associated with the ﬁrst and\nthird bit of the code will be employed to map x. After that,\nto query the element y, Combinatorial BF checks all the \t\ngroups of hash functions. If all the kbits in the bit vector\nassociated with a group of hash functions are non-zero, the\ncorresponding bit in the group code will be 1; otherwise, 0.\nIn this manner, the group code can be determined reasonably.\nBesides of a large number of hash functions and memory\naccess, the probability of misclassiﬁcation in Combinatorial\nBF is high, since any false positive error for each bit will\nresult in incorrect group code. An augment is to use ﬁxed-\nweight group code, i.e., every group has the same number\nof 1s. Therefore, parts of the false positive errors can be\nrecognized accordingly. The misclassiﬁcation probability of\nCombinatorial BF is much larger than its false positive rate.\nCombinatorial BF also proposes a parallelism memory access\nstrategy to speed up the query process. The idea is to partition\nthe bit vector into kchunks. The ﬁrst hash function of each\nhash group will access the ﬁrst chunks, and the second hash\nfunction of each hash group will map elements into the second\nchunk, so on and so forth. Therefore, the element can be\ninserted with \u0012memory accesses, where \u0012is the number of\n1s in the group code C¹g¹xºº.\nUltra-Fast BF (UFBF). Ultra-Fast BF [98] tries to paral-\nlelize both the calculation of hash functions and check process\ndirectly. The UFBF vector is composed of rblocks each\nof which has bbits. Further, each block has kconsecutive\nwords, thus b=k\u0002w, where wis the length of a word. The\noverall number of bits can be calculated as m=r\u0002k\u0002w. To\ninsert an element x, a hash function h0selects one of the\nrblocks randomly. Thereafter, xwill be mapped into the k\nwords with khash functions, respectively. Similar operationsare executed to query an element. Based on this framework, the\nSingle Instruction Multiple Data (SIMD) scheme is introduced\nto parallelize the calculation of the khash functions. The\nbasic idea is to generate multiple hash values with one hash\nfunction using. Moreover, the membership query process can\nbe naturally parallelized since the presence information is\nsaved in kseparated words of one block. Consequently, the\nqueries can be signiﬁcantly accelerated.\nOn the contrary, the SIMD requires supports of competent\ncomputing units, while lightweight devices (e.g., sensors,\ndetectors) unable to run the instructions. Therefore, the SIMD\ninstruction lacks of generality nowadays. Besides, the UFBF\nis proved to suffer from higher false positive rate, compared\nwith the standard BF.\nB. Memory access\nTo accomplish the membership query, one has to read\nthekbits, which may results in numerous memory accesses\nthereby hurting the performance of space-shared applications.\nConsequently, endeavours are made to reduce memory access\ntimes, such as Bloom-1 [92] and OMASS [93].\nBloom-1. Bloom-1 [92] consists of lwords, each of which\ncan be fetched from the memory to the processor in one\nmemory access. Before inserting an element x, a string of hash\nbits is generated by a hash function. Thereafter, log2lhash bits\nare employed to select a word to record x, and k\u0002log2whash\nbits map xinto the word by setting the corresponding bits from\n0s to 1s. Therefore, log2l+k\u0002log2whash bits are required in\ntotal. To query an element, only one memory access is needed.\nIf all the kbits are non-zero, Bloom-1 concludes that element\nbelongs to the set; otherwise, Bloom-1 infers that element is\nnot a member of the set. Moreover, Bloom-1 can be further\ngeneralized as Bloom- gby recording an element in gwords,\nrather than only 1 word. As a consequence, a lower false\npositive rate will be achieved, at the expense of gmemory\naccesses per query.\nOMASS. OMASS [93] focuses on the problem of set\nseparation, i.e., identifying which sets an element xbelongs\nto. The existing approaches employing BFs in parallel. These\nschemes, however, incur multiple memory accesses which\nmay be a bottleneck for certain applications. A solution is\nto divide each BF vector into multiple blocks, each of which\nis exactly a memory word size e.g., 32 bits or 64 bits. A\nglobal hash function is introduced to select a block when\ninserting an element. To resolve the set separation problem,\nthis solution also calls for smemory accesses, where sis\nthe number of queried sets. To further improve the strategy,\none may overlay these BFs and share the same memory. This\ninsight, however, leads to high false positive rate. Therefore,\nOMASS proposes to further equally divide each block as k\nsub-blocks, where kis the number of employed hash functions\nto map elements. The jthsub-block is responsible to the jth\nhash function. Moreover, to eliminate the interferences due\nto memory sharing, OMASS isolates the values generated\nfrom hash functions in a sub-block for diverse sets by letting\nhij¹xº=¹h1j¹xº+¹i\u00001ººmod b , where 1\u0014i\u0014sandbis the\nlength of each sub-block. In this manner, the insertion of xin\n\n14\none set will not affect the false positive rate when checking\nxagainst the other s\u00001sets. Therefore, only one memory\naccess is needed to tackle the set separation problem, without\nincreasing of false positive rate.\nBoth Bloom-1 [92] and OMASS [93] record elements with\ngiven length of words, so that only one memory access is\nrequired for membership query. OMASS further eliminates the\ninterference of elements which belongs to different sets but\nrecorded in a shared word. A common shortcoming of them\nis that, when the number of elements in a dataset changes, they\nmust be rebuilt. The lack of scalability makes them incapable\nof representing dynamic sets.\nC. Space efﬁciency\nSpace efﬁciency is always a problem whenever storing\nthe BF locally or disseminating the BFs among hosts in a\ndistributed system. Typically, to realize the minimum false\npositive rate, the bit utilization in a standard BF is only 50%.\nTherefore, multiple works have been conducted to tackle this\nissue [99] [100] [101] [102] [103].\nCompressed BF. Compressed BF [99] optimizes the trans-\nmission overhead when the ﬁlters are exchanged in networks.\nGenerally, the Compressed BF will be decompressed for real\nuse after the transmission. The probability of each bit to be set\nas 1 under the optimal setting of BF is 1/2, which offers no\ncompression gain at all. By contrast, under the constraint of\nnumber of bits to be sent after compression z, the number\nof bits mof the array in the uncompressed form can be\nlarger. With this insight, Compressed BF employs fewer hash\nfunctions kyet larger number of bits mto guarantee smaller\nfalse positive rate with less bits to transmit than standard\nBF. Alternatively, with the same number of bits to transmit,\nCompressed BF realizes lower false positive rate than standard\nBF. Speciﬁcally, the false positive rate is reduced as 0:5zn,\nwhere zis the length of bit vector after compression. However,\nboth the compression and decompression algorithms consume\nmore processing time and require additional computing and\nmemory resources. Lightweight devices may lack the capabil-\nity to execute these complicated algorithms.\nCompacted BF. Similar with Compressed BF, Compacted\nBF [100] reduces the length of bit vector before transmission\nto save bandwidth. In contrast, Compacted BF abandons the\ntime-consuming compression algorithms but proposes a new\npattern to condense the bit vector. Speciﬁcally, Compacted BF\nsplits the original bit vector into k0blocks, each of which has\nbbits. Thereafter, the original bit vector is translated as an\narray of nindices and each index contains m0bits. Index i,\ndenoted by CmBFV»i¼, corresponds to the value of the ithbit\npositions in block 1,block 2,\u0001\u0001\u0001,block nin the original BF. For\ntheithindex, the principles of deriving the index are follows:\n1) if there is no 1 in the ithbits of all blocks, CmBFV»i¼is set\nas 0; 2) if only one 1 exist and this 1 appear in the ithbit of\nblock r, then CmBFV»i¼is set as r; 3) if all the bits or more\nthan half of the bits are 1s, CmBFV»i¼will be set as 2m0\u00001;\n4) in the case that less than half bits but more than one bit are\n1, the Compacted BF randomly selects a block block swhich\ncontains 1, and set CmBFV»i¼ass. Thus, the b\u0002k0original\nbit vector will be compressed as a n\u0002m0Compacted BF.After transmission, the Compacted BF will be interpreted as\na normal bit vector for later query. However, interpretion leads\nto both false positive and false negative errors. When the 1 in\nthe original bit vector is interpret as ’0’, a false negative error\nhappens. The false positive rate and false negative rate can be\ncontrolled by adjusting the parameters. But in some situations,\nthe false negative is not allowed. Moreover, Compacted BF\nmay not be robust due to the randomness in rule 4.\nd-left counting BF (dlCBF). For a static set S, one can\nemploy a perfect hash function to map each element in Sinto\na hash table without any collision. But for a dynamic set, this\nscheme is not advisable, since each insertion or deletion of\nelement leads to the reconstruction of the hash table. The CBF,\nalthough supports insertion and deletion smoothly, suffers\nfrom high false positive rate and space overhead. To this end,\ndlCBF [101] proposes to replace the general hash functions in\nCBF with a d-left hash function which is reported as “almost\nperfect hash function” [104] [105]. dlCBF splits the cell vector\nintodsubtables, each with ndbuckets, where nis the total\nnumber of buckets. Each bucket resides ccells, and each cell\nhas a ﬁngerprint ﬁeld and a counter ﬁeld. The ﬁngerprint for an\nelement xconsists of two parts, i.e., the ﬁrst part corresponds\nto the index of the bucket which xis placed in, and the second\npart is a remainder of x.\nSpeciﬁcally, to insert an element x, a hash function maps\nxas a bit string. The generated bit string is divided into d+1\nsegments. The ﬁrst dsegments offer candidate positions to\nrecord the ﬁngerprint of x. The last segment is treated as\nthe remainder of x. Thereafter, the remainder of xwill be\nstored in the cell with least load among the dcandidates\n(breaking ties to the left). To query x, all the dcells will\nbe checked. If the remainder of xis found, dlCBF afﬁrms the\npresence of x; otherwise not. Deletion is enabled by clearing\nthe cell or decreasing the count ﬁeld in the corresponding\ncell. Additionally, the augmented ﬁngerprint creation scheme\nand the random permutations are introduced to handle the\nﬁngerprint collisions, so that mis-deletions will not happen.\nCompared with CBF, dlCBF achieves nearly 50% space saving\nwith the same false positive guarantee, and two magnitude\nreduction of false positive rate with the same space scale.\nMemory-optimized BF. Ahmadi et al. argue that the regular\nBloom ﬁlter stores items from a set ktimes kmemory\nlocations that are determined by the kaddresses stored in the\nbit-array structure. The elements are stored quite redundantly.\nBased on this insight, an additional hash function is introduced\nto selected a cell among the kcandidate cells to store x[102].\nTherefore, the element will be stored only for once, and other\nk\u00001duplicates will not be necessary anymore. Consequently,\nthe space usage will be highly improved. The experimental\nresults indicate that this scheme results in much fewer hash\ncollisions than the standard BF. However, the decrease of hash\ncollisions never implies the reduction of false positive rate. It\ndoesn’t change the fact that there is still an optimal number\nof hash functions to realize minimum false positive rate.\nMatrix BF. A Matrix BF is a bit matrix in which each\nbit can be set or reset to detect copy-paste contents in a\nliterature library [103]. The matrix BF consists of Nrows\neach of which records the contents in one document. Every\n\n15\nBlk4Blk2Blk1RAMBlk4Blk2Blk1Blk8Blk7Blk6Blk5Blk16Blk15Blk14Blk13Flash…….…In-RAM stage\nFig. 9. An example of Forest-structured BF [106] with \u0015=b=4.\nrow has mbits and acts as a BF to support insertion and\nquery, with kshared hash functions. Before mapping, each\ndocument is divided into sub-strings by the Chunking Unit,\nand then feed the hash functions to set the kcorresponding\nbits to 1s. To detect the degree of copy-paste between any\npair of documents, matrix BF just executes the bitwise AND\noperations between the two rows. Thereby, the similarity is\nmeasured by counting the number of 1s in the resultant bit\narray, rather than calculating the cosine or Jaccard similarity. If\nthe number of 1s is larger than a predeﬁned threshold, matrix\nBF believes the two documents are similar. Document-level\nscalability and deletion are enabled by simply inserting and\ndeleting a row in the matrix, respectively. Matrix BF jointly\nsupports a trade-off among accuracy, speed, space and privacy\nprotection of the system.\nForest-structured BF (FBF). Usually, BF is saved in RAM\nwhose space is a scarce resource. But once the BF exceeds the\nRAM size, secondary memory e.g. ﬂash-based SSD, will be an\nalternative. Forest-structured BF [106] consists of a collection\nof sub-BFs, each of size that exactly equals ﬂash page size.\n\u000esub-BFs are packed as a block. The blocks, thereafter, are\norganised as a forest structure. The highest layer contains \u0015\nblocks. Each block (except for the ones at the lowest layer) has\n&children (&\u00152). By default, if the RAM is enough to save\nthe blocks, FBF will only use the RAM; otherwise, the FBF\nwill be moved into SSD and the RAM will be utilized as a\nbuffer space when inserting elements. As depicted in Fig. 9, to\nquery an element x, two hash functions are employed to select\na block ( blk_id) and a sub-BF ( page_id) respectively. If the\nsub-BF fails to identify the existence of x, FBF will check the\ncorresponding child of the block. The query algorithm will\nbe terminated when xis found or the lowest level of child\nhas been checked. For instance, given \u0015=&=4,blk_id=2, and\npage_id=10, FBF checks the sub-BF 10 of Block 2 in the\nﬁrst level. If xis not found, the query algorithm will check\nthe sub-BF 10 in Block 10 (Block 10 is the second child of\nBlock 2) in the second level, so on and so forth. Therefore, at\nmost lsub-BFs will be checked, where lthe number of levels\nin FBF. Besides, each sub-BF only requires one ﬂash read.\nHowever, the overall false positive rate can be enlarged due\nto the cascaded structure of FBF. Given the false positive rate\nof each sub-BF as fr, the overall false positive rate can be\ncalculated as 1\u0000¹1\u0000frºl, where lthe number of levels in FBF.\nWith the growth of levels, the overall false positive rate willbe increased quickly.\nD. Energy saving\nTo query the membership of any element, all the kcor-\nresponding bits in the BF vector must be checked. But the\nfact is that, for the elements which lead to negative query\nresults, the zero bits will be located by a subset of the k\nbits. This observation indicates the potentiality to lessen the\ncalculation and energy consumption for negative query results.\nTherefore, several literature propose to check only part of\nthekbits to save energy [107] [108] [109] [110]. Besides,\ndifferent implementation environments also lead to diverse\nenergy consumption [111].\nPipelined BFs. Pipelined BF [107] [108] divides the k\nhash functions into two stages, i.e., stage 1 and stage 2. The\nk1hash functions in stage 1 are always activated, while the\nk2=k\u0000k1stage 2 hash functions will be employed only when\nthe queried element passes the checks of the stage 1 hash\nfunctions. For arbitrary query, the probability to employ stage\n2 hash functions is approximately ¹1\u0000e\u0000k n\nmºk1. In the worst\ncase (the element is either a member of Sor a false positive\nerror), Pipelined BF will check all the kbits, just like the BF\ndoes. The false positive rate of Pipelined BF is the same as\nBF. The average power saving ratio (compared with standard\nBF) can be calculated as:\nk2+¹k1\u0000kº¹1\u0000e\u0000k n\nmºk1\nk: (6)\nThe two-stage Pipelined BF is further generalized as a fully\nPipelined BF by regarding each hash function as a stage [109].\nA queried element is progressed to the next stage only when\nthe previous hash function produces a match. By doing so, the\npower saving ratio is further increased as:\n1\u00001\nk\u0002kÕ\ni=1\u001ai\u00001; (7)\nwhere\u001ais the ratio of 1s in the bit vector. Pipelined BFs,\nhowever, introduce much higher latency to each query, since\nthe multi-stage check scheme slows down the query process.\nEnergy efﬁcient BF (EABF). EABF [110] augments the\ntwo-stage query scheme by adjusting the state of stage 2\nhash functions adaptively. Speciﬁcally, k1hash functions are\nmaintained as stage 1 for a tolerable false positive rate; the\nremained k2=k\u0000k1hash functions are allowed to move out to\nstage 2 for lower power consumption or moved back to stage\n1 for faster response, according to the incoming workload. A\nFIFO buffer is introduced to cache the elements to be queried\nby stage 2 hash functions in the next time clock. As depicted\nin Fig. 10, the hash function can adaptively and automatically\nadjust its state according to the value of the control bit C»i¼and\nthe content in FIFO buffer. The ﬂexibility of state migration\nmakes sure that EABF acts as the two-stage scheme in [107]\n[108] for energy saving, as well as a regular BF in busy-\nhour for fast query speed. The adaption control policy, as\nwell as the multi-stage design of EABF, is proposed for better\nperformance. In real implementations, EABF needs a complex\n\n16\nActive 1\nActive 2 Sleep! FIFO _EMPTY\nFIFO _EMPTYSTAGE 1\nC[i] = 1\nSTAGE 2\nC[i] = 0\nFig. 10. Hash function states in EABF [110].\ncontrol circuit for each hash function. The complexity will be\nfurther ampliﬁed in the multi-stage sense.\nL-CBF. Saﬁ et al. rely on the following simple observations\non CBF: (1) the actual count sequence used in a CBF is not\nimportant, and (2) externally, the users only care whether a\ncounter is “zero” or “non-zero” [111]. With the above insight,\nthey proposed L-CBF [111], a hardware implementation of\nCBF, which implements an array of up/down counters while\navoiding the overheads associated with using arithmetic coun-\nters. Speciﬁcally, L-CBF [111] uses up/down linear feedback\nshift registers (LFSRs) which offer a better latency, power\nand complexity trade-off than other non-arithmetic counters.\nAdditionally, L-CBF introduces an extra bit per counter to\nlabel the state of counters, i.e., the bit will be updated only\nwhen the count changes from or to zero [111]. This strategy\nsigniﬁcantly speeds up the query process, because the mem-\nbership query only cares whether the corresponding counters\nare all non-zero or not, but never concerns the exact values\nin these counters. Experimental results indicate that L-CBF\nsigniﬁcantly outperforms the SRAM based implementation in\nterms of both query speed and energy-saving. The penalty is\n3.2\u0002space occupation.\nE. Summary and lessons learned\nAccording to the above statement, the optimization space\nof computation is two-dimensional: reduce the amount of\ncomputation or speed up the computation. To reduce the\namount of computation, it is advisable to employ computation-\nfriendly hash functions or generate kindependent hash values\nwith fewer hash functions [85][86]. On the other hand, to\nspeed up the computation process, parallelization can be a\nchoice, e.g., DLB-BF [96] and Combinatorial BF [97]. As for\nmemory access, the bit vector can be divided into multiple\ndisjoint segments, thereby each query only needs to access\none segment, such as Bloom-1 [92] and OMASS [93]. This\nwill signiﬁcantly reduce the memory access frequency. The\nspace efﬁciency is not only about the utilization of bits in a\nBF (e.g., Compressed BF [99], Compacted BF [100], dlCBF\n[101], Memory-optimized BF [102], and Matrix BF [103]), but\nalso the global space utilization in a system where both fast\nRAM and secondary memory (e.g., SSD) are jointly employed\n[106]. Lastly, for negative query results, when the query\nalgorithm encounters the ﬁrst zero bit, the algorithm should\nbe terminated and return a negative result. This observation\nenables the possibility to reduce the energy consumption ofmembership queries against BFs. This kind of designs include\nPipelined BF [107] [108], EABF [110], and L-CBF [111].\nIn a real implementation, the performance of BFs can be fur-\nther strengthened by optimizing the computation cost, reducing\nmemory access, improving space efﬁciency, and decreasing\nthe energy consumption. In scenarios where these metrics are\nsensitive, the above BF variants are possible candidates.\nVI. R EPRESENTATION OF DIVERSE SETS\nAs depicted in Fig. 1, in the framework of BF, the input\nsets can be diverse and have their own features. Therefore,\ncustomized variants and techniques are proposed to record\nthe elements under diverse scenarios. For example, if the\ndataset is a multiset, alterations are needed to record the\nmultiplicity of each element; if the dataset is dynamic, the\nBF capacity should be expanded or shrunk on demand; if\nthe elements have different weight, BF should ensure the\nhigh-weight elements incurs lower FPR. Besides, the elements\nmay be not independent but maintain a logical, temporal or\nspatial relationship. How to represent these special datasets\nwith BF effectively is also challenging. Consequently, in this\nsection, for eligibility, we categorize the associated proposals\nas multiset, dynamic dataset, dataset with weighted elements,\nkey-value system, sequence data and spatial data.\nA. Multisets\nWe note that several literature mixes the deﬁnition of multi-\nset and multiset. In this survey, we regard the term multiset as\na mathematical term and represents a dataset which permits\nthe coexistence of multiple replicas of any element. Several\nparameters can be employed to characterize the features of a\nmultiset. Let xbe an element of a multiset A. The multiplicity\nofxis denoted by mA¹xº, which denotes the number of\ninstances of xinA. Note that a multiset is a generalization\nof a set. A simple set is a special case of a multiset where all\nelements only appear at most once. For example, in networks,\na data ﬂow consists of multiple packets with same source and\ndestination IP addresses. Thus a ﬂow can be regarded as a\nmultiset element and the associated multiplicity is the number\nof packets in the ﬂow. The major challenge of representing a\nmultiset is that not only the existence of elements, but also\nthe associated multiplicities should be recorded correctly. To\nthis end, Space-Code BF [88], Spectral BF [112], Loglog BF\n[113], and Invertible Counting BF [20] record the multiplicities\nwith the counters in each cell, at the cost of more space\noverhead. By contrast, Adaptive BF [114] and Shifting BF\n[115] set additional bits to 1s to indicate the multiplicity of\neach element. Especially, Space-code BF [88] and Loglog\nBF [113] employs the maximum likelihood estimation and\nprobabilistic counting strategy to estimate the multiplicity of\neach element, respectively.\nSpace-Code BF (SCBF). Space-code BF [88] novelly\nemploys ggroups of hash functions to map an element\ninto a shared bit vector. Thereafter, the multiplicity of a\nqueried element xwill be estimated by the number of hash\ngroups which indicate the existence of x. The estimation of\nmultiplicity is conducted by running a maximum likelihood\n\n17\nestimation (MLE) procedure. For convenience, a MLE table\nis pre-calculated so that only a simple query against the table is\nneeded during estimation. When the multiplicity of an element\nis very high, the accurate multiplicity estimation will not be\npossible since all the ggroups of hash functions will be\nemployed. To this end, the Multi-Resolution SCBF is designed\nby enabling rSCBF simultaneously. When inserting, the\nelement xwill be inserted into the ithSCBF with probability\npi, where p1>p2>\u0001\u0001\u0001>pr. By doing so, the elements with\nlow multiplicities will be estimated by ﬁlter(s) of higher\nresolutions, while elements with high multiplicities will be\nestimated by ﬁlters of lower resolutions. As for the query, a\njoint MLE procedure will derive the estimation of multiplicity.\nAlso, the overall MLE estimation can be pre-calculated as\na MLE table. The user can tune the parameters for better\nestimation accuracy.\nAlthough sharing a bit vector among multiple groups of\nindependent hash functions will save space, both the MLE\nprocedures for each SCBF and the overall estimation are\ncomputation-intensive. In other words, the saving of space\nis achieved by the sacriﬁce of more computation resource.\nTherefore, SCBF may suit devices with scarce space but ample\ncomputation capacity. Besides, the MLE may overestimate as\nwell as underestimate the real multiplicity of an element.\nSpectral BF. Spectral BF [112] is proposed to support\napproximate multiplicity queries of multiset elements. To this\nend, Spectral BF extends the bit vector of BF as a vector\nofmcounters. When inserting an element, the corresponding\nkcounters are increased by 1. By decreasing the dedicated\ncounters, Spectral BF also enables element deletions. This is\nsimilar to CBF. However, when querying, Spectral BF employs\nthe minimum value among the kcounters as the estimator\nof the multiplicity of x. Consequently, Spectral BF further\noptimizes the data structure with the “minimum increase” and\n“recurring minimum” schemes. The minimum increase scheme\nprefers conservative insertion, i.e., only increase the smallest\ncounter(s). This strategy increases the accuracy of multiplicity\nqueries signiﬁcantly. As for the recurring minimum scheme, it\nfurther initialize a secondary Spectral BF to store the elements\nwith a single minimum. Therefore, the error rate of multiplicity\nquery can be further decreased.\nThe resulted space overhead of Spectral BF can be a slightly\nhigher than that of the standard BF. Employing the minimum\ncounter as the estimator of multiplicity is helpful to realize\nhigh query accuracy. However, this strategy can also be a\nbarrier of accurate querying when a hash collision occurs. For\ninstance, consider that the multiplicities of elements xand y\nare 3 and 2 respectively. If xand yshare a common counter,\nthen the deletion of ywill lead to incorrect multiplicity query\nofx. The reason is that the deletion of ywill decrease the\nminimum counter of xfrom 3 to 1. Thus, the multiplicity\nofxwill be wrongly reported as 1 instead of 3. Therefore,\nthe Spectral BF may report an overestimate or underestimated\nmultiplicity for an element.\nInvertible Counting BF (ICBF). Unlike Spectral BF, ICBF\n[20] is designed to achieve fast and effective synchronization\nbetween two given multisets. To this end, ICBF extends the\nBF into a vector of cells, each of which consists of two ﬁelds,i.e.,idandcount . Speciﬁcally, the idﬁeld is responsible to\nrecord the identiﬁers of elements which have been hashed\ninto the cell, while count ﬁeld memorizes how many elements\nhave been encoded into that cell. Thereafter, the corresponding\nencoding, subtracting and decoding operations are proposed to\nsearch out the difference between two given multisets. Given\na pair of multisets, AandB, when encoding them as ICBF A\nandICBF B, each of the elements is mapped into kcells via\nthekindependent hash functions. The task of subtracting is\nto subtract the different elements from ICBF AandICBF B.\nThis is completed by executing XOR operations between the\nidﬁelds and minus arithmetic subtractions towards the count\nﬁelds. Then a novel algorithm is proposed to decode the\nelements from the subtracting result in a recursive manner.\nMoreover, together with the local id table , the ICBF can\ninevitably decode the different elements from the ICBFs with\nhigh probability. For synchronization, the involved hosts only\nneed to transmit the difference caused by diverse elements and\nthe gap of multiplicities can be ﬁxed with replicas.\nBy recognising the different elements, ICBF achieves the\nminimum transmission cost to achieve approximate multiset\nsynchronization. However, ICBF suffers from both false posi-\ntive and false negative errors when synchronizing the multisets\ndue to hash collisions. Moreover, exchanging the ICBFs be-\ntween hosts also occupies a part of the link bandwidth.\nLoglog BF. Loglog BF [113] introduces the probabilistic\ncounting strategy [116] to estimate the frequency of each\nmemorized multiset element. The probabilistic counting strat-\negy [116] hashes all elements in a set into a given range\nof binary strings and then estimates the cardinality of each\nelement with the locations of the ﬁrst 1s in the binary strings.\nIn the framework level, Loglog BF extends BF from two folds:\n1) the bits in BF is extended as ﬁxed-length counters; 2) an\nextra parameter d(the duplication factor) is introduced so\nthat Loglog BF inserts an item into the counter vector with\ndifferent preﬁxes. To insert an element x, a preﬁx range from\n0 to d\u00001is attached, before xis mapped into the counter\nvector with khash functions. That is, the information of x\nis memorized in k\u0002dcells. For each of the selected cells, a\nrandom integer of x(geometric distribution) will be generated\nto replace the existing value in the cell if the existing value\nis less than the random integer. To answer the multiplicity of\nx, the probabilistic counting strategy is applied to calculate\nthe estimated value based on the counters in the k\u0002dcells\nwith high precision. Further functions like join and compress\ntowards Loglog BFs are also enabled.\nBesides of the explicit false positive rate of membership\nquery, Loglog BF also introduces additional calculation cost\nto the BF paradigm by introducing the probabilistic counting\nstrategy. Both generating the random integer during inserting\nand deriving the estimation value of multiplicity will occupy\nthe computing resources. Moreover, the probabilistic counting\nstrategy calls for comprehensive calibration of the related\nparameters (the number of bits for each counter, the value\nofd) to reach its best performance.\nAdaptive BF. Adaptive BF [114] also tells the multiplicity\nof an element with the number of hash functions. Different\nwith SCBF, Adaptive BF doesn’t need multiple groups of\n\n18\n111111x\n…..…..…..…..…..…..…..h2(x)%m\no(x) o(x) o( x)\nFig. 11. The construction of Shifting BF [115].\nhash functions, but k+N+1hash functions, where Nis the\nmaximum multiplicity for elements in the set S. When an\nelement xis inserted for the ﬁrst time, the kcorresponding\nbits in the bit vector will be set as 1s, and an extra bit is set\nas 1 to indicate its current multiplicity is 1. Thereafter, the\nlatter inserted replicas of xwill be recorded by employing an\nadditional hash function to set a bit as 1. In this manner, the\nmembership information of an element is represented by the k\nbits, and the multiplicity of the element is kept by the number\nof latter programmed 1s. Similar to BF, Adaptive BF tackles\nthe membership query via checking the kcorresponding bits\nin the bit vector. For multiplicity query, Adaptive BF counts\nhow many 1s are set by the latter hash functions.\nHowever, Adaptive BF cannot support deletion, since reset-\nting 1s to 0s may lead to false negative membership query\nerrors and incorrect multiplicity query results. Besides, Adap-\ntive BF treats the 1s which represent membership information\nand the 1s that indicate multiplicity without any differentiation.\nAs a result, the 1s in the bit vector to represent multiplicity\ninformation can increase the false positive rate of membership\nqueries. By contrast, the 1s in the bit vector to represent\nmembership information may lead to inaccurate multiplicity\nquery results. Users may implement the Adaptive BF with two\nseparated bit vectors. One bit vector records the membership\ninformation with khash functions, and the second bit vector\nstores the multiplicity with the N+1hash functions. This\nisolation signiﬁcantly eliminates the interference between the\nmembership information and the multiplicity information.\nShifting BF. Shifting BF [115] is an array of mbits which\nare all initialized as 0s. It acts the same as BF to set kbits\nto 1s with the kindependent hash functions, to store the\nexistence information of an element x. Additionally, Shifting\nBF employs the other kbits to store the auxiliary information,\ne.g., multiplicity or afﬁliation. As depicted in Fig. 11, the bits\nfor auxiliary information are derived by an offset function\no¹xº. Based on the above framework, Shifting BF can support\nmembership query for sure, but also customize other types of\nqueries by adjusting the offset function. Taking the multiplicity\nquery as an example, the offset function can be set as the multi-\nplicity of the element. In the query phase, given the maximum\nmultiplicity Cin the multiset, Shifting BF will check C\u0002kbits.\nThe multiplicity of element xwill be the value of i(1\u0014i\u0014C),\nif the kbits in the locations fh1¹xº%m+i,\u0001\u0001\u0001,hk¹xº%m+ig\nare all non-zero. If deletion is required, a counting version\nof Shifting BF can be generated by replacing each bit with\na counter. Note that, under the framework of Shifting BF,\nthe existence information and auxiliary information in the bit\nvector may interfere each other.\nAs a summary of this subsection, the multiplicities of mul-tiset elements can be represented by the counters in each cell\nvector (e.g., Space-Code BF [88], Spectral BF [112], Invertible\nCounting BF [20], Loglog BF [113]) or setting additional bits\nto 1s in the bit vector (e.g., Adaptive BF [114], Shifting BF\n[115]). Note that there are always trade-offs in these variants.\nRecoding the multiplicity with counters generates additional\nspace overhead, while setting the additional bits to 1s affects\nthe accuracy of membership query.\nB. Dynamic sets\nBF is designed for representation and membership querying\nfor static datasets. However, in fact, distributed applications\nand online systems must deal with the dynamic datasets where\nthe elements can join or leave dynamically. Although CBF\n[36] enables the deletion of elements reasonably, its capacity\ncannot be extended on demand. To overcome the obstacles of\nusing BF in dynamic datasets, several compact variants are\nproposed. Variable length signatures [117] refers only part of\nthekcorresponding bits when inserting, querying, and deleting\nan element. Dynamic BF[89], Scalable BF [118], Dynamic BF\nArray [90], and Par-BF [91] maintains multiple BF vectors\n(either homogenous or heterogeneous) in the memory and\nactivate or merge these BFs on demand.\nVariable length signatures. Especially, Lu et. al [117]\nfocus on the ﬂow deletion in the networking scenario. Obvi-\nously, ﬂows in computer networks can be regarded as a time-\nvarying set. Based on this insight, the variable length signature\n[117] scheme is put forward to enable straightforward deletion,\nquery, aging and recovering of any ﬂow. Different with the\nBF, variable length signature only sets t\u0014kbits to 1s when\ninserting, and concludes that x2Sif at least q\u0014t\u0014kbits are\nnon-zero. To delete a ﬂow x, at least k\u0000dof its signatures\nare set to 0s, where d<qso that xwill not be declared as a\nmember of ﬂow set S. Moreover, the missing bits of a positive\nﬂow may be recovered by setting them to 1; thus, recovery\nstrengthens or lengthens signatures. In practice, some ﬂows\nstored by the bit vector may be out-of-date. Consequently, the\naging mechanism is designed to set a part of 1s in the bit\nvector to 0s, in an either round-robin or random manner.\nNote that, in reality, variable length signature enabled\nBF naturally incurs false positive errors. Additionally, false\nnegative errors may also occur due to the aging operations.\nFortunately, the value of t, as well as qcan be learned\naccording to the ﬂow distribution, so that the generated false\npositive and false negative errors can be signiﬁcantly reduced.\nDynamic BF (DBF). The basic insight of DBF [89] is to\nreserve space for shomogeneous BFs. Initially, only one BF\nis active and once the current BF is full, another untapped BF\nwill be activated. According to the predeﬁned upper-bound\nof false matching probability, the parameters of BFs, as well\nas the upper bound of recored elements in each BF, can be\nreasonably determined. The BF is full if the number of inserted\nelements reaches the upper bound. To insert an element, DBF\nﬁrst discovers an active BF and then set the corresponding k\nbits as 1s. By doing so repeatedly, all elements in a dataset\ncan be recorded. To answer the membership query of arbitrary\nelement x, the DBF checks the BFs one by one. If in any BF,\n\n19\nthe corresponding kbits are all non-zero, DBF believes x2S.\nIf all the BFs report negative results, then DBF concludes x<S.\nBy contrast, deleting an existing element xfrom DBF can\nbe a little more complicated. First of all, DBF identiﬁes the\nBFs in which all the kbits for xare non-zero. If only one such\nBF exists, DBF resets these bits as 0s. Otherwise, DBF quits\nthe deletion operation. The reason is that, if there are multiple\nBFs indicate the existence of x, DBF cannot decide which is\nthe right one. Therefore deleting xfrom these BFs will lead\nto false negative judgments when querying other elements.\nBeyond deletion, DBF also enables the functionality to merge\ntwo active BFs via union operations.\nAn obvious weakness of DBF is its high false positive rate.\nOn one hand, the multiple BF mechanism increases the risk\nof false positive matching. Suppose the designed false positive\nrate of each BF in DBF is fr, then the false positive rate of\nDBF will be calculated as 1\u0000¹1\u0000frºswhich is deﬁnitely higher\nthan fr. On the other hand, the failures of deletion lead to false\npositive query results of the elements that should be deleted.\nScalable BF. Unlike DBF, Scalable BF [118] consists of\na series of heterogeneous BFs. That is, the parameters of\neach sub-BF may be differentiated. Speciﬁcally, to maintain\na given false positive rate, the designed false positive rate of\nthe successive sub-BFs are increased geometrically. To this\nend, the length and bit utilization of the sub-BFs are varied\nand well-designed. However, as a consequence, the sub-BFs\ncannot share the hash functions, which leads to more hash\ncalculations. Besides, the sub-BFs with diverse lengths cannot\nbe joined as one to save space. In the worst case, some sub-\nBFs may only record one element after the deletion of other\nelements, which is deﬁnitely not space-efﬁcient.\nDynamic BF Array (DBA). DBA [90] dedicates to realize\na scalable and space-efﬁcient approximate data structure for\nstorage systems. DBA consists of groups of BFs on demand.\nWithin each group, there are ghomogeneous BFs. In this\nmanner, DBA naturally support parallel queries, since the\naccess of one group of BFs will not affect others. Therefore,\nthe memory-access complexity for querying an element is\nO¹k\u0002r¹2gººfor a positive result and O¹k\u0002rgºfor a negative\nresult, where ris the total number of BFs. As for deletion, the\nauthors point out that large-scale storage systems always delete\nthe out-of-date elements in off-peak time. Therefore, DBA sets\na predeﬁned threshold for the number of stale elements in each\nBF and deletes these stale elements in a batched fashion.\nDBA also suggests loading the entire DBA into the RAM so\nthat the query can be quickly responded. To eliminate potential\nfalse positive errors, the positive responses of DBA will be\nfurther checked with the index of the dataset in the RAM.\nBasically, DBA is quite similar with DBF. The false positive\nrate of DBA is also 1\u0000¹1\u0000frºr, where fris the false positive\nrate of each BF, and ris the total number of BFs. The false\npositive rate can be controlled, but at the cost of more space\noverhead by prolonging the length of each BF or decreasing\nthe number of BFs. What’s worse, the batched deletion scheme\nis not feasible for the online application which requires to add\nor delete elements frequently and timely.\nPar-BF. Par-BF [91] argues that both Dynamic BF and\nScalable BF are not compact enough, in terms of systemperformance and memory overhead. Dynamic BF cannot con-\ntrol the overall false positive, while Scalable BF suffers from\nhigher memory cost and vast hash calculations. Like DBA,\nPar-BF is made up of sub-BF lists, each of which consists of\nmultiple homogeneous sub-BFs. The parameters of each sub-\nBF are carefully designed to achieve the overall false positive\nrate guarantee. Par-BF supports parallelism of membership\nqueries. To insert an element, the Par-BF locates the active\nsub-BF and set the corresponding bits to 1s. Deletion will\nbe accomplished by resetting the corresponding bits to 0s in\nthe sub-BF. Besides, the garbage collection scheme is also\nproposed to unite the unﬁlled sub-BFs for space recycling.\nActually, DBF [89], Scalable BF [118], DBA [90], and Par-\nBF [91] all share the insight that, with the coming elements,\nthe additional BFs can be activated dynamically. However,\nthis strategy intrinsically calls for space reservation since the\nnumber of elements in the dynamic dataset is unknown in\nadvance. Besides, the aggregated false positive rates of these\ndata structures increase with the number of initialized BFs.\nFurthermore, the time-complexities of query and deletion of\nan arbitrary element are no longer O¹kºsince they must travel\nall the sub-BFs to make a conﬁdent decision.\nC. Weighted sets\nBF is designed for general representation of a dataset,\nwith elegant support of membership query. In practice, the\nsets and queries in distributed systems can be highly skewed\n[119][120]. That is, some elements may be queried frequently,\nwhile some may not. With the query distribution and mem-\nbership likelihood distribution as prior knowledge, the original\nBF framework can be further improved [119] and [120].\nWeighted BF. Weighted BF [119] proposes to adjust the\nnumber of employed hash functions for different elements,\nbased on the query frequency and likelihood of being a\nmember of set S. Intuitively, an element is assigned more hash\nfunctions if its query frequency is high and its chance of being\na member is low. In particular, the number of hash functions\nfor an element xis jointly determined by the normalized query\nfrequency of xand the probability of xto be a member of\nsetS. Weighted BF is a generalization of BF since when the\nfrequency distribution and membership likelihood of every\nelement is the same, the generated Weighted BF will be a\nregular BF. However, the problem is that, before querying\nan element x2U, the value of kxhas to be calculated. If\nxis queried frequently, kxwill be recalculated repeatedly,\nwhich is deﬁnitely not efﬁcient. Besides, the value of kxis\nnot convergent. If an element only occurs in query but never\nappears to be a member of S, then kx=1; while kx=\u00001when\nxis a member of Sbut has never been queried.\nPopularity Conscious BF. Unlike Weighted BF, Popularity\nConscious BF [120] predeﬁnes kmax for the number of hash\nfunctions and thereafter proﬁles the problem of allocating hash\nfunctions to each element as a nonlinear integer programming\nproblem. The target is to achieve the smallest overall false\npositive rate, with respect to the predeﬁned parameters of BF.\nTo this end, two approximate algorithms are proposed based\non the concept of per-object importance score. Speciﬁcally,\n\n20\nper-object importance score is calculated asq0¹iº\np¹iº, where q0¹iº\nis the probability that element xioccurs in a mis-matched\nquery (false positive error), and p¹iº=Pr¹xi2Sº\nndenotes the\nmembership popularity distribution. Based on the insight that\nthe optimal solution for the number of per-object hashes must\nfollow the order of importance scores, a polynomial-time 2-\napproximation algorithm is designed. Further, to speed up the\ncalculation, a¹2+\"º-approximation algorithm is proposed.\nWe argue that both Weighted BF and Popularity Conscious\nBF might not be scalable from the time dimension. For\nonline applications, both the query frequency and membership\nlikelihood may vary from time to time. As a result, the value\nofkxcalculated when inserting maybe not optimal in other\ntime slots. Additional efforts are still needed to totally settle\nthis problem so that this kind of variant is pratical.\nD. Key-values\nKey-value (KV) store systems (e.g., Dynamo [121], Mem-\ncached [122], Cassandra [123], Redis [124], BigTable [125],\netc.) handle numerous keys and corresponding values, with\nthe supporting of key lookup and KV pair insertion. Usually,\nindex structures (e.g., B-Tree[126], B+ Tree [127], Hash\nTable[128]) are built for fast and deterministic access of the\nvalues. However, due to the space limitation, saving the entire\nindex structure in RAM can be challenging when store large\nnumber of KV pairs. The BF is indeed space-efﬁcient, but not\ndesigned for KV stores. The major obstacles to employ BF to\nmemorize KV pairs come from two folds. First, the number\nof KV pairs are dynamic, hence the parameters of BF cannot\nbe decided previously. Second, KV stores call for smooth\ndeletion of KV pairs, but BF fails to support this functionality.\nTo overcome this dilemma, BloomStore [18], kBF [19], and\nInvertible Bloom lookup table [21] are proposed reasonably.\nBloomStore. BloomStore [18] establishes multiple Bloom-\nStore instances in the KV store system. The space of keys is\ndivided into multiple disjoint ranges, each of which is mapping\ninto a dedicated BloomStore instance. Every BloomStore\ninstance consists of four components, i.e., KV pair write\nbuffer, BF buffer, BF chain, and a number of data pages. KV\npair write buffer and BF buffer are saved in RAM for fast\naccess, while BF chain and the data pages are stored in the\nsecondary memory (i.e., SSD, ﬂash). The KV pair write buffer\nmemories the incoming KV pair insertions temporarily. Once\nthe write buffer is ﬁlled up, the content will be written into\nthe secondary memory. In this manner, the number of write\noperations will be lowered. Correspondingly, the BF buffer\nrepresents the membership of the keys stored in the KV pair\nwrite buffer. Other KV pairs are represented by the Bloom\nchain (a series of BFs) in secondary memory. Note that each\nBF is responsible to memory the KV pairs in one ﬂash page.\nBased on the above framework, a parallel BF checking\nscheme is employed to speed up the query process. Notice that,\nthe parallelization is possible because all the BFs in the chain\nare homogeneous and thus share the hash outputs. Apparently,\nBloomStore is naturally scalable and supports deletion by\ninsert a null value to the key in the corresponding BF bits.\nSure, the aggregated false positive possibility is relatively high.kBF. Instead of saving the KV pairs directly, kBF [19]\nconverts the values into ﬁxed-length string bits with respect\nto given constraints. kBF consists of cells, each of which\nhas two components, i.e., the counter to track the number of\nencodings into the cell, and the encoding ﬁeld records either\nan original encoding, or the XOR results of the encodings\nthat are mapped to this cell. To insert a KV pair, the value\npart is ﬁrst converted to be a string bits and denoted as\nencoding. Thereafter, the keys and corresponding encodings\nare inserted into the kBF for later query, update, deletion,\njoin and compress operations. Moreover, the original KV pairs\ncan be inversely decoded from the generated kBF cells. In\nfact, for a KV pair, if any counter in the corresponding cells\nis 1, the encoding ﬁeld will be exactly the encoding string\nof the value. Otherwise, complicated decoding algorithm is\nemployed. The basic insight is to construct a BF which records\nall the encodings, and then execute the XOR operation of the\nencodings literately to check whether the XOR results contains\nthe encoding to be decoded. A distributed version of kBF is\nalso suggested for cloud computing scenarios.\nIntrinsically, the conversion from values to encodings for-\nmalizes the disordered values as ﬁxed-length bit strings, so\nthat the later update, deletion, join and compress operations\ncan be enabled reasonably. However, the cost is also very high.\nFirst, the time-complexity of the proposed decoding algorithm\nisO¹N2º, which is unacceptable for delay-sensitive online\napplications. The decoding algorithm also suffers from non-\ndecodable cells and may fail to derive the original values from\nthe intersection encodings. Second, the conversion scheme\nlacks of scalability, since the upper bound of the encodings\nmust be predeﬁned according to the number of KV pairs.\nThird, kBF calls for additional secondary BFs to speed up\nthe searching of encodings or decode the encodings inversely.\nFourth, kBF may suffer from false negatives, if all the k\ncorresponding cells for a KV pair fail to tell the encoding\nof its value.\nInvertible Bloom lookup table (IBLT). IBLT [21] supports\nnot only insertion, deletion, and lookup of key-value pairs, but\nalso allows a complete listing of the pairs it contains with high\nprobability, as long as the number of contained key-value pairs\nis below a designed threshold. Conceptually, IBLT consists of\nmcells, each of which contains the following three ﬁelds: 1)\ncount ﬁeld which counts the number of KV pairs that mapped\ninto this cell; 2) keySum which records the sum of all keys\nthat mapped into this cell; and 3) valueSum which is the\nthe sum of all values that mapped into this cell. Note that\nIBLT treats both keys and values as integers for simplicity. To\ninsert a KV pair¹x;yº,khash functions are employed to map\nthis pair into kdisjoint cells. In each of the corresponding\ncell, the count ﬁeld will be increased by 1; keySum will be\nupdated as keySum+x; and valueSum will be calculated as\nvalueSum +y. The deletion will be accomplished by executing\ninverse calculations of insertion. To query a key x, the IBLT\nwill return the associated value yor “null” or “not found”. In\nthekcorresponding cells of x, if a cell which only records\nthe key xis found, IBLT will return the value. If any cell\nis empty or the count =1but the keySum,x, the answer will\nbe “null”; otherwise, IBLT will return “not found”. The result\n\n21\n“not found” means all the kcells store multiple KV pairs and\nIBLT cannot tell¹x;yºis among them or not.\nAdditionally, IBLT is capable of listing all the KV pairs\nsuccessfully with high probability. The algorithm searches out\nan anchor cell which only records one KV pair, and then\nreturns the associated key and value. Thereafter, the selected\npair will be deleted from the cell vector to expose more anchor\ncells. Recursively, all the KV pairs may be decoded. Deﬁnitely,\nIBLT can only list part of the KV pairs, when no such anchor\ncells can be found.\nE. Sequence sets and spatial sets\nExcept for the above types of datasets, there are also other\nspeciﬁc datasets with special characteristics. Recently, k-mers\n(substrings with equal length derived from the full sequence)\nare employed to support high-level algorithms [129][130]\ntowards the sequence data, e.g., DNA or RNA sequence.\nHowever, a single sequence may generate a massive number of\nk-mers, and thereby causing storage challenges. Consequently,\nBF is introduced to record the k-mers and support fast mem-\nbership query. Due to the characteristics of sequence data,\nthe application of BF can be further improved [131] [132].\nMoreover, in the context of location based applications, spatial\ndata should be represented efﬁciently for query. Spatial BF\n[17] tries to represent the geographical areas with priorities.\nk-mer BF. Pellow et al. [131] point out that the internal\ndependency between the mapped subsequences can be utilized\nto reduce the false positive rate of membership query. Specif-\nically, two adjacent k-mers share k\u00001common characters.\nTherefore, the presence information of neighbours can be em-\nployed to further judge the membership of the query substring.\nIn this manner, some false positive errors will be identiﬁed via\nadditional queries of the neighbours. For instance, consider a\nsequence TAAGCCA and it is stored as 4-mers, i.e., TAAG,\nAAGC, AGCC, and GCCA. When querying AGCC, if the\nBF returns positive for AGCC, while reports negative for\nGCCA, then the BF experiences a false positive error with\nhigh probability. Note that BF never suffers from false negative\nerrors, and it is 100% true that an element x<Sif the query\nresult is negative. k-mer BF offers two optional schemes, i.e.,\none-sided k-mer BF and two-sided k-mer BF. The one-sided\nk-mer BF only checks the presence of a single overlapping\nneighbour. By contrast, the two-sided k-mer BF which checks\nthe neighbours from both directions. Surely, checking more\nneighbours will further lower the FPR.\nk-mer BF seems compact enough to represent sequence\nsets. However, the functionality of k-mer BF is one-fold only,\ni.e., membership query. Many complicated algorithms call for\ncomprehensive operations upon these k-mers, e.g., traverse,\ndeletion, permutation, inversion, etc. k-mer BF fails to enable\nthese operations, which in turn narrows its usefulness.\nSpatial BF. Spatial BF [17] considers the location informa-\ntion with the concern of privacy protection. To this end, the\nlocations of the users are divided into different interest areas.\nAccording to the Manhattan distance, the areas are categorized\nas diverse classes. Before inserting any element, each cell of\nthe Spatial BF is initialized as 0. Then khash functions mapthe element x(which belongs to class L) into the cells, and\nset the values as L. By sorting the locations with increasing\norder, the locations with greater class labels will be inserted\nlater. Consequently, the locations with greater class labels\nwill be correctly memorized, even if a hash collision occurs.\nThereafter, the constructed Spatial BF will be implemented\nin location-aware applications based on the designed private\npositioning protocols.\nSpatial BF is a variant of BF to represent spatial data which\nconsists of many geographical areas. However, abstracting\nthe spatial data as simple interest areas is oversimpliﬁed\nand thereby failing to support high-level applications such\nas navigation. Besides, the location of a user is highly time-\ndependent due to his or her motions. Spatial BF fails to track\nthe motions if a user always moves in one class of areas.\nF . Summary and lessons learned\nAccording to different abstraction of the dataset, diverse\nvariants are proposed to match the characteristics and func-\ntionality requirements of the elements. Thanks to these novel\nproposals, the BF paradigm can be extended to represent\nand support multiform operations towards multisets [112] [20]\n[113], dynamic sets [117] [89] [118] [90] [91], skewed datasets\n[119] [120], KV pairs [18] [19], sequence sets [131] [132],\nspatial data [17], etc. These variants may lack of generality,\nbut function well in their own domains. In practice, the users of\nBFs can customize their BF variants to represent their datasets\nwith diverse features. This malleability further extends the\nusage of BFs in various contexts.\nVII. F UNCTIONALITY ENRICHMENTS\nStandard BF only supports membership query, since the\nbit vector only indicates the membership information of each\nelement. Therefore, from the framework of BF, with the\ninput set, the output functionalities can be enriched in diverse\nscenarios.\nA. Element deletion\nIn real systems, an element may be deleted from the dataset\nand other elements may be added. A general drawback of\nstandard BF is that it fails to delete elements from the bit\nvector, since resetting the bits from 1 to 0 may cause false\nnegative errors to other elements. Besides of the CBF [36],\nDeletable BF [133] and Ternary BF [134] are proposed to\nenable the deletion of arbitrary element.\nDeletable BF (DlBF). In the bit vector of BF, hash col-\nlisions may happen, so that the deletion of an element may\nlead to false negative errors to other elements. Based on this\ninsight, Deletable BF [133] tracks the positions where hash\ncollisions happen when inserting elements. Then only the bits\nin collision-free areas will be reset from 1 to 0 when deleting\nan element. DlBF divides the mbits in the bit vector into\nrregions, each of which has m0rbits, such that m0=m\u0000r.\nBefore the rregions, the ﬁrst rbits in the bit vector are\nemployed to identify the corresponding region is collision-\nfree or not. Note that, the ﬁrst rbits are all initialized as 0s.\n\n22\nIf a hash collision happens in the ithregion, the ithbit in\nthe ﬁrst rbits will be set to 1. Both insertion and query will\nbe accomplished just like the standard BF. When deleting, the\nelement xwill be mapped into kbits. Then the algorithm only\nreset the 1s located in collision-free regions. The element x\nwill be successfully deleted if at least one of the kcorre-\nsponding bits is reset to 0. However, if all the kbits locate\nin conﬂicted areas, the element is declared as non-deletable.\nLetp0=¹1\u00001m0ºknandp1=knm0¹1\u00001m0ºkn\u00001denote\nthe probability that a given cell is set to 0 and 1 only once\nafter inserting nelements. An arbitrary element can be deleted\nsuccessfully with approximate probability ¹1\u0000¹1\u0000pcºm0rºk,\nwhere pc=1\u0000p0\u0000p1is the probability that a given cell has at\nleast one hash collision.\nTernary BF (TBF). Ternary BF [134] allocates the mini-\nmum number of bits to each counter and thereby implies more\ncounters. Each counter in the proposed TBF has three different\nvalues: 0, 1, and X. If 2 or more elements are mapped into a\ncounter, the value is programmed as X and the counters with\nvalue X are not referenced in queries. Compared with the 4-\nbit CBF, a TBF vector has larger number of counters using\nthe same amount of memory, since each counter of the TBF\noccupies less bits.\nNote that the counters with X are not increased when\ninserting an element, nor decreased when deleting an element.\nThey are also not referenced when querying an element.\nConsequently, TBF derives the indeterminable elements for\nmembership query and undeletable elements for deletion. To\nbe speciﬁc, when querying an element x, if the corresponding\nkcounters of xare all X, then xis identiﬁed as indeterminable .\nIn contrast, when deleting element y, if the corresponding k\ncounters of yare all X, then yis considered as undeletable .\nBy labelling the counters where hash collisions occur, and\ndeﬁning the indeterminable and undeletable elements, TBF\nsigniﬁcantly reduces both the false positives for query and\nfalse negatives due to misdeletions. Namely, TBF is a conser-\nvative design. It prefers correct answers or operations, while\nleaving the controversial counters (the counters with value X)\nalone. Moreover, to lessen the number of indeterminable or\nundeletable elements, the value of a counter can be adjusted\nas: 0, 1, 2 and X, such that more elements can be queried or\ndeleted. Surely, doing so may increase the false positive rate.\nBesides of CBF [36], Deletable BF [133] and Ternary BF\n[134], other variants which have a counter ﬁled in the cells\n(e.g., SCBF [88], Spectral BF [112], ICBF [20], IBLT [21],\netc) also enable the deletion operation successfully. Consider\nthat deletion is not the prime functionality or goal of these\nvariants, we present them in other sections.\nB. Element decay\nFor online services and applications, new data will come and\nstale elements will banish. Therefore, to represent a dataset\nmore efﬁciently, the BF should also support decay operation,\nsuch that those stale information can be eliminated to leave\nspace for the coming elements. The difference between dele-\ntion and decay is that, decay is a proactive operation and\nwill be executed by the BFs periodically or aperiodically,while deletion is an inactive function that is called by the\nusers. Consequently, during deletion, the BFs know exactly\nwhich element should be removed. In contrast, when decaying,\nthe BFs don’t acknowledge which and how many elements\nwill be removed from the vector. Stable BF [135], Temporal\nCounting BF [136], Double buffering [137], A2buffering\n[138], and Forgetful BF [139] are designed to enable decay\nof the recorded elements.\nStable BF. Stable BF [135] is proposed for duplicate\nelimination of streaming data ﬂows which arrive continually.\nStable BF is deﬁned as an array of cells with integer range\nfrom 0 to Max . The number of bits for each cell is bsuch\nthatMax\u00142b\u00001. To check whether a recently arrived element\nxis a duplicate or not, xis mapped into kcells in Stable\nBF. If all of the kcells are non-zero, xis considered as a\nduplication; otherwise not. To insert an element into Stable\nBF,Prandomly selected cells are decreased by 1. Thereafter,\nthe corresponding kcells for the element is set as Max . In this\nway, the whole cell vector will be stable, i.e., after numerical\niterations, the fraction of zeros in the Stable BF will become\nﬁxed, irrespective of the initial state. In the framework of\nStable BF, the number of cells which are 0s after Niterations\nis a constant when Nis large enough. Note that, Stable BF\nprovides both false positive and false negative errors. Evicting\nthe stale information in a random fashion certainly results in\nfalse negative errors. However, the duplicate detection will\nbe handled with constant time, so that Stable BF suits the\nscenarios of streaming data or other series datasets well.\nTemporal Counting BF (TCBF). TCBF [136] is an exten-\nsion of CBF. Upon inserting an element, the kcorresponding\ncounters will be set as a given value called initial counter value\n(ICV), rather than increased by 1. If a hash collision occurs,\nTCBF will remain the existing value of the counter. The decay\nmechanism is to constantly decrease all the counters’ values\nwith a rate given by the decay factor (DF). By tuning the\nvalues of ICV and DF, TCBF enables differentiated decay\ngranularity for different elements. Additionally, TCBF offers\ntwo kinds of merging schemes for two TCBF vectors, i.e.,\nadditive merging and maximum merging. Additive merging\ngenerates a new TCBF vector whose counters are the sum of\nthe counters in the original vectors. By contrast, the maximum\nmerging set the counters as the maximum value of the counters\nin the original vectors. The membership query will check the\nkcorresponding cells, and the caused false positive rate is the\nsame as standard CBF.\nNote that, TCBF predeﬁnes the “time-to-live” of each\nelement in the vector by assigning the ICV value. However,\nfalse negatives will occur when one of the kcounters remains\nof a smaller value than its ICV . For example, xis mapped\ninto cells 1, 5 and 9 in the TCBF vector, and the ICV and DF\nare 7 and 1 respectively. But cell 5 has already been set as\n2 by a former element. In this case, the counters in cells 1,\n5 and 9 will be 7, 2 and 7, respectively. Therefore, after two\nevictions, the membership query of xwill be negative since\ncell 5 has been degraded as 0. A possible repairment is to\nkeep the maximum value among the existing value and the\ninserted ICV , if hash collisions occur. This scheme, despite\neliminating false negatives, imposes more false positive errors\n\n23\nfor the membership query.\nDouble Buffering. Double buffering [137] offers an ac-\ntive/standby scheme to evict the stale elements in a ﬁrst-in-\nﬁrst-out manner. The memory is physically divided into two\nindependent parts to maintain an active BF and a warm-up BF,\nrespectively. For a coming element x, ifxis already recorded\nby the active BF, and the active BF is more than 1/2 full, then\nxwill be inserted into the warm-up BF. On the contrast, if\nxhasn’t been recorded by the active BF, xwill be inserted\ninto the active BF. After that, if the active BF is more than 1/2\nfull, xwill be additionally inserted into the warm-up BF. Once\nthe active BF is ﬁlled up, double buffering switches the active\nBF and warm-up BF, and ﬂushes the generated warm-up BF.\nWith such a design, the active BF stores all the recent data\nand the warm-up BF always records a subset of the active BF.\nAn essential drawback of this scheme is that it doubles the\nmemory space to store the same number of elements, as well\nas the memory access of inserting a new element.\nA2Buffering. A2buffering [138] divides the memory\nequally as two buffers which implement two BFs denoted as\nactive1andactive2, respectively. Novelly, active1stores the\nrecently inserted elements, while active2records previously\ninserted elements. When active1becomes full, active2is\nﬂushed and the two BFs switch their roles. Basically, a queried\nelement xwill generate a positive answer if it passes the\nmembership check in either active1oractive2. Speciﬁcally,\nxis ﬁrst queried against active1. Only when active1returns\na negative answer, active2will be accessed and queried. If\nactive2returns a positive result, the element xwill be inserted\ninto active1. Suppose the false positive rate of each BF is\nfr, the global false positive rate is f=1\u0000¹1\u0000frº2. With this\nscheme, the users can update BFs with recently used data. A2\nbuffering stores twice as many elements as double buffering\nin the best-case scenarios, and as many elements as double\nbuffering in the worst-case scenarios.\nForgetful BF. The most-recently proposed Forgetful BF\n[139] maintains several active BFs simultaneously, including\none future BF, one present BF and one or multiple past BF(s).\nA new-arrival unrecorded element will be inserted into both\nthe future BF and the present BF. Forgetful BF periodically\nrefreshes the BFs to evict the stale elements. Speciﬁcally, 1)\nthe oldest past BF is dropped for eviction; 2) the current\npresent BF is turned into the newest past BF; 3) the current\nfuture BF is degraded as present BF, and lastly 4) a new,\nempty future BF is added. The membership query proceeds by\nchecking for membership in the most recent window of time\n(the future BF) until the oldest window of time (the oldest\npast BF) is reached. If the membership check passes in any\nwindow of time (two consecutive BFs return positive), the\nForgetful BF terminates the query process and return positive.\nInherently, since each element is inserted twice, the elements\nthat only pass one membership query are identiﬁed as false\npositives. Moreover, to control the false positive rate, Forgetful\nBF proposes to adjust its number of past BFs and the refresh\nfrequency. However, Forgetful BF also has problems with a\nlarge number of memory accesses inherited from the structure\nof multiple active BFs.\nGenerally speaking, the decay can be enabled by changing\nabqp1p2(a) False positives from multidimen-\nsional inconsistency.\nabqp1(b) False negatives from multidimen-\nsional checking.\nFig. 12. An example of false positive and false negative errors in LSBF [144].\nthe values of bits in a single BF vector (e.g., Stable BF [135],\nTemporal Counting BF [136]) or ﬂushing the oldest BF among\nmultiple BF vectors (e.g., Double buffering [137], A2buffering\n[138], and Forgetful BF [139]). Decay results in false negative\nerrors thereby triggering the reinsertions of some elements.\nC. Approximate membership query\nAs an opposite of accurate membership query, approximate\nmembership query is to answer the query “Is xclose to\nan element in S?” when the closeness is measured by a\ndedicated metric. This kind of query can ﬁnd its applications in\ndatabases, networking, image processing, social networks, and\nbiological scenarios. The existing proposals usually employ\nthe locality-sensitive hash family [140] [141] [142] to map\nthe elements so that the close elements will be stored in\nneighbouring or same cells with high probability.\nDistance-sensitive BF. Distance-sensitive BF [143] em-\nploys local-sensitive hash functions based on the distance to\nmap elements into the vector. Distance-sensitive BF is an array\n(denoted as DSBF ) ofkdisjoint arrays, each of which has m0\nbits, such that the total number of bits is m=k\u0002m0. Each hash\nfunction is responsible to one dedicated array. Let H:U!V\nbe a¹pL;pHº-distance sensitive hash function family, and\nH0:V!»m0¼be a weakly pairwise independent hash family.\nBefore programming the arrays, a group of hash functions\nfh1;\u0001\u0001\u0001;hkg2H , as well as another group of hash func-\ntionsfh0\n1;\u0001\u0001\u0001;h0\nkg2H0, are selected independently. If V=»m0¼,\ngi=hi; otherwise, gi=hi\u000eh0\ni; Thereafter, for x2S,DSBF i»gi¹xº¼\n(i2»1;k¼) will be set as 1. As for query, Distance-sensitive\nBF refers to the bit locations of an element xin the vector,\nto test whether xis close to some elements in Sor not.\nLetB¹xº=Í\ni2»1;k¼DSBF i»gi¹xº¼. IfB¹xºis larger than a\npredeﬁned threshold t,xis far away from all elements in S;\notherwise, xis close to some elements in S.\nPractically, the Distance-sensitive BF is complex to be\nimplemented. Firstly, the local sensitive hash functions are\nhard to deﬁne for distance metrics. Secondly, the conﬁguration\nneeds more computation cost since two families of hash func-\ntions are involved. Thirdly, this paradigm lacks of scalability.\nThe parameters for the current dataset are customised and\ncannot be generalized to other datasets. Besides, Distance-\nsensitive BF is constructed based on the assumption that S\nis static, which further restricts its scalability. Therefore, a\nlightweight and more scalable solution may still be required.\n\n24\nLocality-sensitive BF (LSBF). LSBF [144] also replaces\nthe independent uniform hash functions in BF with locality-\nsensitive hash functions, thus support the approximate mem-\nbership query. Unlike Distance-sensitive BF, LSBF concludes\nthat xis close to an element in Sonly when all the corre-\nsponding bits are non-zero. This design further restricts the\ncondition to pass the check. Intrinsically, the FPs are partially\ninherited from the BF framework. Another inexplicit reason of\nFPs is the lack of multidimensional attributes of elements. As\ndepicted in Fig. 12 (a), the queried point qis projected on two\ndimensions, i.e., vectors aandb. LSBF fails to tell whether the\napproximate membership of qin each dimension comes from\nan existing item or from multiple items. As a consequence,\nqwill be concluded as an approximate member, although q\nis far away from both the points p1andp2. By contrast, the\nreason for false negative errors is that, the locality-sensitive\nhash functions can map close elements into neighbouring cells\nwith high probability but not 100%. Therefore, in Fig. 12 (b),\nthe queried qis close to point p1, but the distance in dimension\nbis too far so that one bit for qin the bit vector will be far\naway from that of p1and maybe a 0. In this case, LSBF will\nreturn a negative query result.\nLSBF proposes a veriﬁcation scheme based on an additional\nBF to recognize part of the false positive errors, as well\nas an overﬂowed scheme to decrease false negative errors.\nBesides the introduced computation and space overhead, the\nconﬁguration of LSBF is also time-consuming, since the\nveriﬁcation BF can only be established after all the elements\nhave been inserted into the LSBF vector. The reason is that\nthe neighbours of any bit may change from 0 to 1 due to later\ninsertions. This limitation also indicates weak scalability of\nLSBF, since each coming element will cause the reconstruction\nof the veriﬁcation BF.\nMulti-granularity locality-sensitive BF (MLBF). The\nusing of locality-sensitive hash functions has been further\nimproved in MLBF [142], by enabling multiple distance gran-\nularities. MLBF contains a basic multi-granularity locality-\nsensitive BF (BMLBF) and a multi-granularity veriﬁcation\nBF (MVBF). Speciﬁcally, the BMLBF is a vector of mbits\nand constraints s\u00001virtual LSH BFs (VLBFs) which are not\nphysically constructed but derived from the BMLBF (VLBF\n0). One bit in VLBF \u0012(1\u0014\u0012\u0014s\u00001) covers 2ibits in VLBF \u0012\u0000i\nfor any 0\u0014i\u0014\u0012. If one of the locations in the VLBF 0 is set to\n1, its covered virtual location in each of the VLBFs is regarded\nas 1 too. LAND-constructions (to improve the locality-\nsensitiveness together with later OR-constructions), each of\nwhich has khash functions, are employed to map an element\ninto BMLBF. Therefore, L\u0002khash functions are needed. For\neach group of hash functions, the kgenerated locations are\nconcatenated together and then stored in the MVBF. Although\nthe MVBF only stores the concatenations from the BMLBF, it\ncan still support multi-granularity veriﬁcation by constructing\nvirtual veriﬁcation BFs (VVBFs). The reason is that the\naddress of a location at the coarser level is a preﬁx of the\ntwo addresses of its contained locations at the next ﬁner level.\nTo query an element xin the\u0012level, MLBF checks the\nVLBF\u0012ﬁrst, and then the MVBF. If there is a group of hash\nfunctions such that both its BMLBF and MVBF return positiveresults, MLBF judges xis close to some element in the set\nS. Despite the introduced AND-constructions and veriﬁcation\nscheme, MLBF still suffers from both false positive and\nfalse negative errors. Moreover, MLBF is overcomplicated to\nconstruct and query. L\u0002khash functions are required for the\nBMLBF and k0hash functions are needed for the MVBF.\nGenerally, the locality sensitive hash functions are employed\nto map the elements into the bit vector. Distance-sensitive BF\n[143] infers an element xis close to some element in Sif the\nnumber of 1s in the bit vector exceeds a predeﬁned threshold.\nLSBF [144] and MLBF [142], however, concludes xpasses the\napproximate membership query only if all the kcorresponding\nbits are non-zero. Besides, LSBF and MLBF also implement\nthe veriﬁcation schemes to further identify the false-positively\nmatched elements. Especially, MLBF further enables the query\nand veriﬁcation in different granularities.\nD. Enrichment of BF semantics\nAn inborn drawback of BF is that it only saves the member-\nship information while lacking other features of the elements.\nTherefore, the enrichment of BF semantics is needed to sup-\nport more types of queries. From the perspective of elements,\nthe information saved in the bit (or cell) vector can be extended\nin either a scale-up or a scale-out manner. A scale-up scheme\nprogrammes not only the membership information, but also\nother features associated with the element. By contrast, scale-\nout proposals care about the internal relationship between\nelements. As shown below, Invertible BF [145], Bloomier ﬁlter\n[95], and Parallel BF [94] try to store more information.\nInvertible BF (IBF). With the assumption that each element\nhas a unique binary identiﬁer, an IBF [145] vector for a\ndataset contains mcells and each cell has three ﬁelds. The\nidSum records the XOR results of the identiﬁers of elements\nthat mapped into this cell. The count counts the number\nof elements that mapped into this cell. IBF cell addition-\nally employs a hash function g¹xºto map the identiﬁers of\nthe corresponding elements into a ﬁxed-length binary string.\nThereafter, the XOR result of hash values g¹xºis saved\nashashSum ﬁeld. The encoding, subtracting and decoding\nalgorithms are designed to settle the set-reconciliation (or\nset difference) problem. Encoding algorithm represents the\ntwo sets as two IBF vectors, and then subtracting algorithm\noperates the two IBFs to generate a new IBF vector which only\ncontains different elements. Lastly, the decoding algorithm\ntells which elements are unique for set AandB. Note that,\nthe identiﬁer, the idSum and hashSum ﬁelds are all binary\nbit strings. Consequently, the simple XOR bit operations are\nimplemented for both aggregating and removing elements.\nIBF [145] and IBLT [21] are similar and try to decode the\nelements from the cell vector inversely. Both of them select a\ncell which only records one element as an anchor and thereby\nreturn the elements one by one. The difference is that IBLT is\ndesigned for KV store while IBF suits general datasets well by\nturning the valueSum ﬁeld in IBLT as hashSum ﬁeld. More-\nover, the hashSum helps to ﬁlter the cells in which the count =\n1 or -1 but saves more than one element. These cells will not be\nchosen as an anchor. This is done by simply checking whether\n\n25\ng¹idSumº=hashSum or not. If g¹idSumº=hashSum , only the\nelement whose identiﬁer is exact idSum is remained into this\ncell; otherwise, multiple elements are still stored in this cell\nand the count =1 or -1 is caused due to the subtracting\noperation. Especially, the length of IBF mis decided as \u000bd,\nwhere\u000bis a constant coefﬁcient and dis the number of\ndifferent elements between AandB. Although literature [145]\npresents a strata estimator which tries the decoding iteratively\nuntil it successes, the estimation is still time-consuming and\nneeds multiple rounds of communication. Furthermore, the\nboth IBLT and IBF may fail to decode all the elements from\nthe cell vector.\nBloomier ﬁlter. The BF can be viewed as a boolean\ncharacteristic function of the represented set. With this insight,\nBloomier ﬁlter [95] generalizes the boolean characteristic\nfunction to arbitrary functions. In other words, Bloomier ﬁlter\nexpands the theory of BF by enabling the storage of not\nonly membership information, but also the function values\nwith the elements in Sas input. Consequently, Bloomier ﬁlter\nalso supports constant-time query of the function values that\nassociated with the elements. Speciﬁcally, for the elements in\nS, Bloomier ﬁlter will return the function value; by contrast,\nfor the elements that are not members of S, the query result\nwill be?which means an undeﬁned value. A near-optimal\ndesign for Bloomier ﬁltering is proposed based on a cascading\npipeline of BFs. The trick is to build the ithpair of BFs to\nrepresent the false positive elements in the ¹i\u00001ºthpair. For\ninstance, BF¹A0ºandBF¹B0ºrecord the subset of elements\n(i.e., A0and B0) whose function values will be 1 and 2\nrespectively. Then BF¹A1ºwill be generated by recording the\nelements in A0but also pass the check of BF¹B0º. Similarly,\nBF¹B1ºwill be generated by recording the elements in B0but\nalso pass the check of BF¹A0º. Therefore, the elements which\ncause false positive errors will be reasonably recorded in the\nlatter cascading BFs. The time-complexities for construction\nof Bloomier ﬁlter and query of a given element are O¹nlognº\nandO¹1ºrespectively. Later researchers try to speed up the\nconstruction of Bloomier ﬁlter to linear time, or lessen space\noverhead at the cost of higher construction complexity.\nParallel BF. BF and its variants only support representation\nand query of single-attribute elements. Therefore, Parallel BF\n[94] denotes itself to represent multi-attribute elements. A\ntypical scenario is that, in a database, a query always jointly\nconsider multiple attributes of the entries. A naive solution\nto represent multi-attribute elements is to employ multiple\nBFs, each of which is responsible to one dedicated attribute.\nThis method, however, leads to high false positive rate, since\nthese BFs fail to store internal dependency of the attributes.\nParallel BF is a matrix of CBFs, which consists of Psub-\nmatrices to represent Pattributes independently. For each sub-\nmatrix, there are karrays of counters and khash functions\nare responsible to map an input into an array respectively. To\ninsert an element with Pattributes, each attribute is mapped\nbyPgroups of hash functions into Psub-matrices. The\ncorrespondingP\u0002kcounters are increased by 1. Additionally,\na hash table is established to record the internal dependency\nof the attributes. In this way, the false positive errors from\nthe sub-matrices can be signiﬁcantly recognised. Typically, afunctionFis employed to calculate the veriﬁcation value of\nan element based on the P\u0002kpositions in the matrix. In other\nwords, the function Faggregates the attributes of an element\ntogether. With the generated veriﬁcation value as input, the\nadditional hash table offers a veriﬁcation mechanism to the\npositive query results from the Parallel BF matrix. Compared\nto a single CBF, the Parallel BF matrix enlarges the false\npositive rate. But the majority of these false positive errors can\nbe identiﬁed by the thereafter hash table. The representation of\nmulti-attribute elements is realized at the costs of more hash\ncomputing, space occupation, and memory access.\nIBF [145], Bloomier ﬁlter [95], and Parallel BF [94] are all\nthe kind of scale-up extension in terms of semantic enrichment.\nIBF records the identiﬁer of the elements and thereby enables\ninversely decoding. Bloomier ﬁlter injects the function values\nof the elements into the vector thus supports fast query of the\nfunction value. Parallel BF represents the multi-attribute of\neach element via multiple parallelized CBFs and an additional\nhash table. Some variants, on the other side, scale-out single\nelements and focus on the internal relationship. The traditional\nBF supposes by default that the elements in a dataset are\nindependent. But the fact is that elements in a dataset can be\nintensively correlated. For instance, the nodes in a multicast\ntree have a strict father-children relationship. The former men-\ntioned Distance-sensitive BF [143], LSBF [144] and MLBF\n[142] in Section VII-C can be viewed as the scale-out type\nsemantic enrichment, since they try to maintain the distance\nbetween the elements with locality-sensitive hash functions.\nWe believe other elegant designs are still needed in terms of\nother kinds of internal relationships.\nE. Summary and lessons learned\nBesides of element insertion and query, real applications\nhave a strong need for additional functionalities. For a dynamic\nset, deletion is needed. Therefore, CBF [36], Deletable BF\n[133] and Ternary BF [134] are proposed. For an online\nsystem, decay (or eviction) should be enabled to release the\nspace for coming elements. This functionality can be enabled\nby changing the values of bits in a single BF vector (e.g.,\nStable BF [135], Temporal Counting BF [136]) or ﬂushing the\noldest BF among multiple BF vectors (e.g., Double buffering\n[137], A2buffering [138], and Forgetful BF [139]). Moreover,\nwhen the closeness is measured by a dedicated metric, the\napproximate membership query will be conducted to answer\n“Isxclose to an element in S?”. In this case, the locality-\nsensitive hash functions are employed to map elements into the\nBFs [143] [144] [142]. Additionally, BF only saves the mem-\nbership information but lacks other features of the elements.\nThis disadvantage limits the functionality of BF. Therefore,\nthe enrichment of BF semantics is required to support more\ncomplicated functionalities [145] [95] [94]. When the users\nhave additional requirements for other functionalities, they can\nalter the BF framework accordingly.\nVIII. C LASSIFICATION AND COMPARISON\nIn this section, we systematically analyze the optimization\ntechniques introduced by the above BF variants. As shown\n\n26\nSet Diversity False Positive Reduction Functionality Enrichment Implementation Optimization Elements\nHash \nFunctions\nBit VectorMulti -class \nBF [3]\nOptihash  [67]\nFPF-MBF  \n[43]\nRetouched \nBF [75]\nMPCBF  [77]Ternary BF  \n[134]Generalized \nBF [76]Cross -checking \nBF [72]Complement \nBF [73]\nYes-no BF  \n[74]\nVI-CBF  [83]FP-CBF  [84]Selected Hash \n[78][79]Space -code\nBF [88]Adaptive\nBF [114]\nSpectral\nBF [112]Loglog BF \n[113]\nDynamic\nBF [89]Variable length \nsignatures [117]\nScalable\nBF [118]DBA [90]\nPar-BF [91]Weighted BF \n[119]\nPopularity \nconscious BF [120]BloomStore \n[17]kBF [19]\nIBLT [21]k-mer BF \n[131]\nSpatial BF \n[17]CBF [36]Deletable\nBF [133]Distance -sensitive \nBF [143]\nLocality -sensitive \nBF [144]\nLess hash \n[85]DLB -BF [96]Combinatorial\nBF [97]\nBloom -1 [92]\nOMASS [93]\nCompressed\nBF [99]\nCompacted\nBF [100]Forest -structured \nBF [106]\nStable BF \n[135]\nTemporal \nCBF [136]d-left CBF \n[101]\nMemo . Opti. \nBF [102]\nMatrix BF \n[103]Pipelined BF \n[107] [108]EABF \n[110]\nL-CBF [111]MLBF [142]\nShifting\nBF [115]ICBF [20]Bloomier \nfilter  [95]\nParallel BF  \n[94]IBF [145]\nOne hash\nBF [86]\nUltra -fast BF \n[98]Double \nBuffering [137]\nA2 Buffering \n[138]\nForgetful BF \n[139]Performance Generalization\nEGH filter \n[80]Loglog BF \n[113]kBF [19]\nFig. 13. The taxonomy of the existing BF variants. The BF variants are classiﬁed in two main dimensions from the optimization perspective, i.e., performance\nand generalization. To improve the performance, dozens of variants devote themselves to reducing the false positives and easing the implementation. Besides,\ntens of variants generalize the BF framework in more scenarios by diversifying the input sets and enriching the output functionalities. We further analyze\nthe optimization techniques towards the three components of BF, i.e., elements, hash functions, and bit vector, respectively. Obviously, many variants jointly\noptimize these components.\nin Fig. 13, the variants augment BF by operating its three\ncomponents, i.e., elements, hash functions and bit vector,\neither separately or jointly. Consequently, we characterise the\noptimization techniques from three perspectives that refer to\nthese three BF components.\nElements . The set Sin the framework of BF is a highly\nabstract term. In practice, a speciﬁc dataset may have its\nspecial feature. To better suit the real dataset, the users can\naugment the BF adaptively. For instance, recording the multi-\nplicity of an element in a multiset calls for a redesign of the\nbit vector. Besides, before hashing, preprocessing operations\n(e.g., duplication, aggregation, extraction, outlier processing,\ndimension-reduction, etc) can be introduced to reﬁne the\nentries. In the case of recording a set of text ﬁles, instead of\nhashing a complete text ﬁle, users may extract the keywords\nas the identiﬁcation of a text ﬁle.\nHash techniques . Hashing the input elements into a given\nrange contributes the major computation overhead of BF. To\nfurther speed up the BF or extend the usage of BF in devices\nwith low computation capability, lightweight hash techniques\ncan be considered. Moreover, BF assumes by default that the\nhash functions are independent. However, the randomness of\nhash functions is still an open theoretical problem. Therefore,\ndesigning or employing high-performance hash functions is\ncritical to improve BF.\nBit vector . The bit vector is the direct product of BF, and\nis responsible to record the membership of elements in a set.\nThe bit vector can be queried, stored, transmitted, reproduced\nand updated in practice. From the angle of saving space\noverhead or communication overhead, one may compress,\nextend, shrink, segment or layer the bit vector. Moreover, in\norder to enable more functionalities or support complicated\nqueries, each bit can be upgraded as a cell with multiple bits.\nA. Techniques towards elements\nBF represents the membership of elements by the bits in\nthe vector without differentiating them. As a consequence,BF cannot tell the 1s are caused by a dedicated element\nor not, thereby may result in false positive query results. A\nnatural way to resolve this dilemma is to impose a unique\nﬁngerprint to each element. Alternatively, the elements may\nshare common features which may help to improve the query\naccuracy by categorizing and then representing the elements\nin groups. Fig. 13 indicates that the strategies which operate\nelements directly are usually aggregated with other techniques\nwhich augment the hash functions or (and) bit vectors.\n1) Imposing ﬁngerprints to elements: Generally, the ﬁn-\ngerprint of an element is generated by mapping the element\nas a binary string with a hash function. Thereafter, the ﬁn-\ngerprint can be stored directly in the vector. This kind of\nvariants include kBF [19], FP-CBF [84], ICBF [20], and\nIBF [145]. Among them, kBF, FP-CBF, ICBF, and IBF store\nthe ﬁngerprint of element directly in the cells. To break the\ntie of collision where multiple elements are mapped into a\nshared cell, the XOR operations are introduced to aggregate\nthe ﬁngerprints together. In this case, deleting a ﬁngerprint\ncan be simply enabled by an additional XOR operation. kBF,\nFP-CBF, ICBF and IBF all associate the ﬁngerprint with a\ncounter in a cell, such that when the counter is 1, the stored\nﬁngerprint is exactly the ﬁngerprint of the inserted element.\nBased on this insight, part of false positive matches can be\nidentiﬁed via checking the ﬁngerprint ﬁeld.\n2) Dividing elements into independent groups: DLB-BF\n[96] and Partitioned hashing [79] divide the elements in the\nset into multiple groups, thereafter each group of elements is\nrepresented by a corresponding BF. This will effectively isolate\nthe elements so that they will not affect each other upon query.\nTo be speciﬁc, DLB-BF maps the IP preﬁxes with the same\nlength into a dedicated BF. To query a preﬁx with a given\nlength, DLB-BF only checks the corresponding BF. Similarly,\nthe Partitioned hashing categorizes the elements into multiple\ngroups with an additional hash function. Then each group of\nelements are stored in a BF. Before checking the kbits in\na BF, the queried element is ﬁrst hashed by a hash function\n\n27\nto decide which BF it should refer to. The advantages of the\ngrouping strategy include false positive isolation and friendly\nmemory access. On one hand, the elements in different groups\nwill not interfere each other since they are physically isolated.\nOn the other hand, the multiple BFs can be naturally accessed\nin parallel, and each query only requires the access of one BF.\nTherefore the query throughput will be increased reasonably.\nWe also notice a special case, i.e., k-mer BF [131], which\npartitions the sequence data into k-mers without the above\nﬁngerprint nor grouping technique. The neighbouring mers can\nbe utilized to identify incorrect matches of a given mer, during\nthe querying process.\nAn exception, which doesn’t label elements with ﬁnger-\nprints nor group the elements, is Loglog BF [113]. Loglog\nBF imposes a preﬁx to each element before each insertion.\nThis is required by the probabilisitic counting strategy.\nB. Techniques towards hash functions\nHash functions are crucial ingredients of BF, and there are\nlots of proposals to augment this part. As depicted in Fig. 13,\na dozen of the variants alter the hash functions directly. There\nare still tens of variants adjusting the hash functions together\nwith other ingredients. We summarize these techniques from\nthree aspects, i.e., leveraging the number of hash functions,\noptimizing the implementation of the hash functions, and using\nadvanced hash functions.\n1) Leveraging the number of hash functions: For a static\nset, with the given number of elements nand the bit vector\nlength m, the optimal number of hash functions is k=m\nnln 2.\nBut in reality, the number of employed hash functions can\nbe more than kor adjusted dynamically to achieve diverse\ntargets. We roughly summarize the existing proposals which\nadjust the number of hash functions as three categories: 1)\nadding one extra hash function; 2) employing multiple groups\nof hash functions; 3) using hash functions on demand. We\ndetail each of the categories as follows.\nOne additional hash function. Usually, an extra hash func-\ntion is employed to randomly select an object from multiple\navailable candidates. Typically, ICBF [20] and FP-CBF [84]\ngenerates a ﬁngerprint for each element with an extra hash\nfunction from a given range. Memory-optimized BF [102]\nchooses an accommodation cell for a ﬁle from all possible\nlocations. OMASS [93] locates the block which stores an\nelement via an extra hash function. Similarly, Forest-structured\nBF [106] also derives the location of an element with extra\nhash functions. But Forest-structured BF calls for two extra\nhash functions, to locate the block and page respectively.\nBesides, IBF [145] needs an extra hash function to calculate\nthehashSum in each cell to identify its purity.\nMultiple groups of hash functions. A dozen of BF\nvariants require multiple groups of hash functions. Among\nthem, Complement BF [73], Cross-checking BF [72], Yes-\nno BF [74], DLB-BF [96], BloomStore [18], Bloomier ﬁlter\n[95], Parallel BF [94], Combinatorial BF [97] and FPF-MBF\n[43] establish multiple separated secondary BFs, thereby they\nneed multiple groups of independent hash functions when\nsharing the hash values are not allowed. If these secondaryBFs have different length, sharing hash values is deﬁnitely not\npossible. Besides, to enable parallelized queries for different\nelements, each secondary BF must have its own hash group.\nBut in scenarios where secondary BFs are of equal length\nand parallelism is not required, the khash functions can be\nshared, e.g., Dynamic BF [89] and Dynamic BF Array [90].\nThe main cost of employing multiple groups of hash functions\nis the computation overhead.\nOn the contrary, Space-code BF [88] and Generalized BF\n[76] utilize multiple groups of hash functions to set or reset a\nshared bit vector. The Space-code BF estimates the multiplicity\nof an element by counting the number of hash groups which\nresult in non-zero bits. A passive impact of inserting an\nelement into the bit vector for multiple times is that, the\nmembership query may suffer from much higher false positive\nrate. Generalized BF employs two groups of hash functions,\none for setting of bits and the other one for resetting of bits.\nAs a consequence, the false positive rate can be decreased,\nwith the penalty of false negative errors.\nA more special case is VI-CBF [83], which introduces\nanother group of hash functions to select the kincrements\nfor an inserted element. The differentiated increments for\nelements, rather than a common 1, helps VI-CBF avoiding\npart of the false positive errors.\nHash functions on demand. The number of employed\nhash functions directly inference the performance of BF.\nTherefore, researchers integrate wisdom into this part and\nchange the number of hash functions ﬂexibly. Adaptive BF\n[114] records the multiplicity of an element with the number\nof hash functions (except for the khash functions for existence\ninformation). Weighted BF [119], Popularity conscious BF\n[120] and Multi-class BF [3] propose to adjust the number of\nemployed hash functions for different elements. Typically, the\nelements which are more frequently queried or have a lower\nprobability to be a member of Sshould be associated with\nmore hash functions. More hash functions implies stronger\nconstraints to pass the check. The reason to do so is that the\nfalse positive errors happen to these elements impose larger\nincrement of false positive proportion.\nEABF [107] [110] and its same kind [108] [109] adjust\nthe number of activated hash functions dynamically for the\npurpose of energy saving. For the negative query results,\nthey need not check all the khash functions, thus saving\ncomputation and energy. In other words, with these strategies,\na negative result may be given instantly, but there will be\na considerable delay for a positive result. If saving energy\ndominates the delay of a positive result, they are advisable\nchoices. Note that the false positive rate of them will be the\nsame as the standard BF.\nThe variant Variable length signatures [117], novelly sets\nt\u0014kbits of h¹xºto 1s when inserting, and concludes that x2S\nif at least q<kbits of the h¹xºare 1s. The gaps between t,q\nandkenable the ﬂexible insertion, deletion, and even decay of\nthe recorded elements. Nevertheless, Variable length signature\nincurs both false positive and false negative errors.\n2) Optimization of hash implementation: Due to the impor-\ntance of hash functions in BF, tens of variants optimize hash\nfunctions from the perspective of implementation. To this end,\n\n28\nBloom-1 [92], Less hash [85], and One hash [86] generate\nkindependent hash values with one or two hash functions.\nSpeciﬁcally, Bloom-1 [92] divides a hash bits into kparts,\nand each part is regarded as a hash value. By contrast, One\nhash [86] modulos the machine word generated from the hash\nstage with kdiverse modulus to derive khash values for each\nsegment of the bit vector. Less hash [85] reports a conservative\nmethod to generate as many hash values as the users want by\nusing 2 independent hash functions, without any damage of\nthe randomness. All of the these proposals can reduce the\ncomputation overhead of hash functions signiﬁcantly.\nFor a given set, different hash functions lead to diverse false\npositive proportion. Therefore, Optihash [67] and Selected\nhash [78] [79] try to pick an optimal group of hash functions\nwhich result in the lowest false positive proportion. Both\nOptihash [67] and Partition hashing [79] are computation-\nintensive since they need multiple rounds of tests or queries. A\nmoderate method is to test two groups of hash functions and\nthen select a better one for each element [78]. This scheme\nachieves a signiﬁcant reduction of FPP with an acceptable\nincrease of computation.\nEspecially, Ultra-fast BF [98] speeds up the calculation of\nhash functions via employing the SIMD technique. SIMD\ninstructions parallelize the computation and thus only need\n1ktime to generate khash values. SIMD, however, needs\ndedicated hardware and software environments, making this\nstrategy lose of generality.\n3) Application of advanced hash techniques: Researchers\nintroduce advanced hash techniques to improve BFs. d-left\nCBF [101] employs d-left hash functions to store the index\nof an element in a least-loaded cell (selecting the left-most\none to break the tie of multiple equally loaded cells). The\nusing of d-left hashing achieves nearly 50% space saving\nwith the same false positive guarantee, and two magnitude\nreduction of false positive rate with same space scale. Besides,\nthe locality-sensitive hashing is also employed to replace the\ntraditional hash functions. Locality-sensitive hashing maps\ntwo neighbouring elements into same or close locations in\nthe vector with high probability. This characteristic enables\nDistance-sensitive BF [143], Locality-sensitive BF [144] and\nMLBF [142] to answer the query “ Is an element xclose to\nany element of Sor not?”. This kind of query, however, incurs\nboth false positive and false negative errors, irrespective of\nthe remedial designs, e.g., further veriﬁcation and checking.\nThe computation complexity of these locality-sensitive hash\nfunctions is also a barrier of real implementation. Note that,\nthe EGH ﬁlter [80], on the contrary, replaces the hash functions\nwith some simple functions derived by prime numbers. By\ndesigning the parameters carefully, EGH ﬁlter guarantees a\nfalse positive free zone for a subset of elements.\nWe simply summarize this subsection here. Hash function is\nan essential ingredient of BF. The number of hash functions\ncan be adjusted both proactively and passively. When there\nare multiple secondary BFs or one must select an object\nfrom multiple candidates, the number of hash functions has\nto be passively increased. By contrast, adjusting the number\nof employed hash functions proactively can achieve diverse\ndesign goals, i.e., energy-saving, false positive control, queryacceleration. Moreover, the khash values can be generated by\none or two hash functions with the guarantee of randomness.\nMeanwhile, given a set of elements, the performance of BF\nis hash-dependent. A proper group of hash functions can be\nselected by multiple rounds of tests and queries. Lastly, ad-\nvanced hash techniques are available to enrich the functionality\nor improve the performance of BF directly.\nC. Techniques towards the bit vector\nThe bit vector stores the existence information of elements\nby setting the bits from initial 0s to 1s. Numerical variants\nextend the bit vector to enrich its semantics or impose ad-\nditional operations on the bit vector for extra functionalities.\nThere are two typical methodologies for semantic enrichment,\ni.e., a scale-up scheme which replaces each bit with a cell\nto store more information, and a scale-out scheme which\nimplements more BF vectors for higher capacity. Also, two\nkinds of representative operations are popular to be executed\nupon the bit (or cell) vector, i.e., partition the vector into\nsegments and changing the values of bits. Consequently, we\norganize the existing techniques towards the bit vector as the\nfollowing four aspects.\n1) Scale-up: beyond one single bit: CBF [36] is the ﬁrst\nvariant which extends the bits of BF as ﬁxed-length counters\nto seamlessly support element deletion. Thereafter, Spectral\nBF [112] enables multiplicity query with the minimum value\namong the kcounters. Two variants of CBF, i.e., FP-CBF [84]\nand VI-CBF [83] leverage the ﬁngerprint and differentiated\nincrements for each inserted element to reduce the false\npositive rate, respectively. L-CBF [111] speeds up the query of\nCBF from the implementation perspective. EGH ﬁlter [80] also\nextends the bits as counters to enable the deletion functionality.\nIBLT [21], IBF [145] and ICBF [20] further extend a\nbit as a multi-ﬁeld cell to store the necessary information\nfor invertible decoding. The fundamental insights of their\nrecursive decoding algorithms are similar. They ﬁrst identify\na pure cell which only stores one element. After recording the\nelement, it will be deleted from the cell vector to hopefully\nexpose more pure cells. The algorithm will be terminated until\nno pure cells can be searched out. In each cell, the three\nvariants all have a counter to record the number of elements\nmapped into it. Especially, each IBLT [21] has keySum and\nvalueSum ﬁeld to aggregate the KV pairs mapped into the\ncell. Likewise, every IBF [145] cell has two other ﬁelds,\ni.e.,idSum andhashSum to record the information of stored\nelements. ICBF [20], by contrast, has only one extra ﬁeld,\ni.e.,id. The differences between these three proposals stem\nfrom their functionalities. IBLT is designed for KV pairs,\nwhile IBF is targeted at general elements. ICBF, however,\nis proposed for multiset synchronization between two hosts,\nand an off-line id table is maintained to record the mapping\nbetween ids and elements. A common technique for them is\nthe XOR, which can aggregate information together, delete\nelements with simple bitwise operations, and reveal the value\nor ﬁngerprint of an element when only one single element\nstored in the cell.\nThere are also other proposals to extend the bits, e.g.,\nBloomier ﬁlter [95], Spatial BF [17]. They are actually coupled\n\n29\nwith other features, so we analyze them in other chapters. As\nan opposite of extension, Compressed BF [99] and Compacted\nBF [100] compress the bit vector for bandwidth-friendly\ntransmission. Compressed BF employs fewer hash functions\nso that the probability of each bit to be set as 1 is less than\n1/2. Thereafter, the bit vector is compressed for transmission.\nCompacted BF proposes a series of principles to encode the bit\nvector and recover it for later queries after transmission. The\npenalty of Compacted BF is additional false negative errors\ndue to its encoding principles.\n2) Scale-out: more BF vectors: When one BF vector is\nnot enough, or the users have multiple sets to represent, a\nnatural way is to establish multiple BFs. Dynamic BF[89],\nScalable BF [118], Par-BF [91] and DBA [90] are proposed\nfor scalability and elasticity. The secondary BFs, either homo-\ngeneous or heterogeneous, can be added or merged on demand.\nAnother concern for capacity extension is to partially migrate\nBF from fast but scarce RAM storage to slower yet massive\nﬂash memory. Forest-structured BF [106] and BloomStore [18]\npropose joint design with both RAM and ﬂash. Speciﬁcally,\nForest-structured BF [106] ﬁrst implement an in-RAM block\nwhich contains several BFs. Once all the in-RAM BFs are\nsaturated, blocks will be added into the ﬂash memory on\ndemand and constructed as a forest architecture. Then the\nRAM will be employed as a cache for the most-recent arriving\nelements. On the contrary, BloomStore [18] leverages the\nRAM as a buffer which only stores the most-recent elements\nfor each BloomStore instance. Once the buffer is ﬁlled up,\nboth the elements and the associated BF will be pushed into\nthe ﬂash.\nComplement BF [73], Cross-checking BF [72] and Yes-no\nBF [74] conﬁgure additional BFs to help identify some false\npositive errors from the main BF query results. Complement\nBF implements an additional BF to store the elements in the\ncomplement set of Sdirectly. Cross-checking BF divides S\ninto several independent subsets and establishes a BF for each\nof them separately. Yes-no BF simultaneously maintains a\nyes-ﬁlter for the elements in S, and no-ﬁlters for the false-\npositively matched elements. When the universe set Uis large\nwhile Sis small, Complement BF is not advisable. If the\nfalse positive queries are detectable, Yes-no BF will be a wise\nchoice. Cross-checking BF is a pervasive scheme and it also\nleaves a trade-off space (between query accuracy and space\ncost) to its users.\nCombinatorial BF [97], DLB-BF [96], Space-code BF [88],\nMatrix BF [103], and Parallel BF [94] are all conﬁgured\nof multiple independent BFs. Combinatorial BF and DLB-\nBF have multiple groups of elements to represent, therefore\nthey conﬁgure a BF for each group of elements. Parallel BF\nrepresents the multiple attributes of an element with multiple\nBF matrices. Space-code BF is functional with single BF\nvector. But with multiple BF vectors and executing the MLE\nfor multiple times, Space-code BF generates a more accurate\nmultiplicity estimation. In Matrix BF, each row of the bit\nmatrix acts as a BF and record one speciﬁc document in a\nﬁle library. These rows share khash functions and thereby\nsupporting copy-paste detection between documents. Note that\nBloomier ﬁlter [95] also has multiple BFs but it is none ofthe above kinds. The reason is that the BFs in Bloomier ﬁlter\nare nested and constructed recursively, rather than independent\nwith each other. In Bloomier ﬁlter, false positives in the ﬁrst\nlevel BFs will be recorded in the second level BFs. As a\nconsequence, these BFs are accessed sequentially.\nCertainly, a common obstacle behind the scale-up and\nscale-out proposals is space overhead. For scale-out proposals\nwhich just conﬁgure multiple standard BFs, e.g., Dynamic\nBF, Scalable BF, Par-BF, DBA, DLB-BF, Matrix BF, Forest-\nstructured BF and BloomStore, they lead to the same bpe\n(bites per element) as standard BF. Most of the scale-up\nproposals may result in higher bpe, with the gain of additional\nfunctionalities (e.g., deletion, invertible decoding, parallelism)\nor better performance guarantee (e.g., higher query accuracy).\n3) The power of partition: A simple partition method is\nto divide the bit vector into ksegments such that each hash\nfunction is responsible to one segment. This adjustment is\na natural way to enable parallel access, at the cost of a\nslight increment of false positive rate. OMASS [93] stores the\ninformation of an element in a word-size block, such that a\nquery can be responded with only one memory access. Bloom-\n1 [92] also stores the information of an element in one word,\nwhile the kbits are chosen by only one hash function. The\ntrick is to split the hash bits of an element into kparts, each\npart select one position for the element from the word. Still,\nonly one memory access is enough for a membership query.\nUltra-fast BF [98] employs the similar scheme, but it has k\nwords in one block for the khash functions, respectively. As\na consequence, Ultra-fast BF supports block-level parallelism\nand each query needs to access all the kbits in the kwords of\na selected block. The load of each block or word is determined\nby the global hash function which is responsible to select one\nword or block for an element. Ideally, the blocks or words are\nload-balanced. However, in reality, it is still possible that some\nblocks or words are overloaded while some are underloaded.\nWe suggest that the load-balance friendly hash techniques, e.g.,\nd-left hash, may be an effective solution.\nMPCBF [77] also divides the bit vector into multiple words,\nand then goes further to establish a hierarchical structure\nfor better utilization of these bits. The ﬁrst level of bits\nare responsible for query, the later levels are leveraged for\ndynamical element insertion and deletion. Compared with\nCBF, MPCBF achieves lower false positive rate by logically\nincreasing the value of min Equ. 1. The partitions in OHBF\n[86] and Deletable BF [133], however, are not for memory\naccess reduction nor better utilization. OHBF divides the bit\nvector into kparts with different lengths, such that the machine\nword generated by one hash function can derive khash values\nwith kdifferent modulus. Deletable BF, specially, splits the\nvector into r+1regions. The ﬁrst region has rbits, each of\nwhich indicates whether the corresponding region incurs hash\ncollisions or not. When deleting, Deletable BF only resets the\n1s in collision-free regions. Any of the associated kbits is\nreset as 0 means a successful deletion of an element. In the\nsituation where there are no collision-free regions, Deletable\nBF [133] declares that element is not deletable.\n4) The game between 0s and 1s: Another explicit way to\nadjust the vector is changing the values in the bits (or cells).\n\n30\nRetouched BF [75], Generalized BF [76] and Stable BF [135]\nallow to reset bits from 1s to 0s when inserting an element.\nBoth Retouched BF [75] and Generalized BF [76] are nice\ntrials to eliminate 1s thereby generating lower false positive\nrate if false negatives are permitted. Retouched BF proposes\nboth random and selective clearing strategies, while Gneralized\nBF employs two groups of hash functions, i.e., one group for\nset and the other group for reset. Stable BF [135] targets at\nthe dynamic dataset and maintains a ﬁxed proportion of 1s in\nthe bit vector, such that stale elements will be eliminated when\ninserting the new arrivals. Undoubtedly, all the three proposals\nincur false positive, as well as false negative errors. Resetting\nthe 1s to 0s damages the one-sided error characteristic of BF.\nAs a consequence, they offer no correctness guarantee for both\nthe positive and negative query results.\nTernary BF [134] doesn’t reset the bits to 0s, on the contrary,\nit records the bits which incur hash collision and marks their\nvalue as X. When querying an element y, if the corresponding\nkcounters of yare all X, then yis identiﬁed as indeterminable .\nIn contrast, when deleting element z, if the corresponding k\ncounters of zare all X, then zis considered as undeletable .\nThat is, Ternary BF refuses to answer a query which may be\na false positive and rejects to delete an element which may\ncause a false negative. Temporal CBF [136] saves the “time-\nto-live” of an element in the kcorresponding cells. All the\ncounters in the vector will be decreased periodically by one.\nThe space overhead of this proposal will be an obstacle. Each\ncell must have enough bits for the maximum lifecycle. For a\nset of elements with highly skewed lifecycle, Temporal CBF\nis obviously not space-efﬁcient. Spatial BF [17] leverages the\ndistinct values in the cells to label the elements in different\ngeographical areas. Larger counter values indicate more central\nareas and will remain when conﬂicted with lower values in a\ncell. In this way, Spatial BF provides better accuracy to the\nqueries of central areas.\nDouble buffering [137], A2buffering [138], and Forgetful\nBF [139], however, ﬂush the stale BF(s) directly. In online\nscenarios, these variants always cache the recently inserted\nelements. Double buffering maintains an active BF and a\nwarm-up BF in the memory. After the active BF is half\nfull, the latter inserted elements will be also inserted into\nthe warm-up BF. Once the active BF is ﬁlled up, double\nbuffering switches the active BF and warm-up BF and ﬂushes\nthe generated warm-up BF. Note that, in Double buffering,\nonly the active BF is responsible for membership query. The\nA2buffering, by contrast, implements two active BFs simul-\ntaneously. active1stores the recently inserted elements, while\nactive2records previous inserted elements. When active1\nbecomes full, active2is ﬂushed and the two BFs switch their\nroles. The membership of an element will be conﬁrmed if it\npasses the check of either active1oractive2. Especially, the\nForgetful BF maintains several BFs simultaneously, namely,\none future BF, one present BF and one or multiple past BF(s).\nDuring an update, the oldest past BF will be eliminated and an\nempty new future BF will be added. All the BFs in Forgetful\nBF are responsible for the membership query.\nBesides of the kbits which represent the membership of el-\nements, Adaptive BF [114] and Shifting BF [115] programmeadditional bits as 1s to record more information associated\nwith the elements. Adaptive BF sets additional m¹xºbits\nto represent the multiplicity of element xwith m¹xºhash\nfunctions. Shifting BF [115] also enriches the semantics of\nthe bit vector by additionally storing auxiliary information for\ndiverse types of queries. For example, for association query,\nthe cells or bits will record the set or group the element\nbelongs to. The kbits for auxiliary information are novelly\nselected by attaching an offset to the klocations for existence\ninformation. However, the 1s for membership information and\nthe 1s for additional information may interfere each other.\nThe 1s in the bit vector to represent multiplicity information\ncan increase the false positive rate of membership queries.\nBy contrast, the 1s in the bit vector to represent membership\ninformation may lead to inaccurate multiplicity query results.\nTo ease this dilemma, saving the two kinds of 1s in separated\nbit vectors may be a good idea.\nWe also noted that, in the last years, several methods\nto protect Bloom ﬁlters have been proposed. For example,\nReviriego et. al propose to use a parity to detect soft errors\n[146]. Then upon an error detection, all the bits on that word\nof the error were set to 1 so that false negatives were avoided.\nThe protection against transient errors was considered in [147]\nby for example performing a recomputation if all except one\nof the positions accessed had a value of one. These methods\nprotect BFs against errors in the memories or the hash function\ncalculation.\nD. Qualitative comparison\nIn this survey, we review the existing optimization tech-\nniques towards the three components of BF, from the per-\nspective of both performance and generalization. To improve\nthe performance of BFs, the variants focus on the reduction of\nfalse positives and implementation optimizations. Also, dozens\nof variants try to generalize BF framework by representing\ndiverse type of sets from the input side and enabling more\nfunctionalities from the output side. As shown in Fig. 13,\nthe variants augment one or more components to achieve\ntheir design goals. Furthermore, we qualitatively compare the\ncapabilities and complexities of these variants and report the\nresults in Table IV.\nNote that, in the last column of Table IV, we also highlight\nthe contexts where these BF variants are proposed or applied.\nObviously, a large portion (28 out of 60 variants) of the BF\nvariants are designed for general usage – to represent a static\nset of elements, support membership query and other function-\nalities. These variants redesign the standard BF framework\nto reduce the potential false positives and enable extensive\nfunctionalities. The rest of BF variants, on the other hand,\nare motivated by speciﬁc requirements in diverse contexts. In\nthe networking ﬁeld, Spectral BF [112], Multi-class BF [3],\nOptihash [67], FPF-MBF [43], and Combinatorial BF[97] are\ndesigned to improve in-packet or in-switch BFs for multicast\nforwarding; Adaptive BF [114] and Space-code BF [88] aim\nat trafﬁc engineering; Double Buffering [137], DLB-BF [96],\nEABF [110], and Pipelined BF [107] are proposed for packet\nprocessing; Temporal CBF [136] speeds up the information\n\n31\nTABLE IV\nTHE KEY CAPABILITIES AND COMPLEXITIES OF BF AND ITS VARIANTS . THE CAPABILITIES INCLUDE COUNTING ,GROUPING ,DELETION ,SCALABLE ,\nDECAY ,PARALLELISM AND FALSE NEGATIVE (FN). I N CONTRAST ,WE CONSIDER THE COMPLEXITIES ABOUT INSERTION (COMP -I), QUERY (COMP -Q),\nDELETION (COMP -D) AND MEMORY ACCESS (COMP -M).\nStructureCountingGroupingDeletionScalabilityDecayParallelismFNComp-IComp-QComp-DComp-MContext\nStandard BF [1] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹kº General\nCBF [36] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº General\nkBF [19] Yes Yes Yes No No No Yes O¹kº O¹kº O¹kº O¹kº K-V store\nLoglog BF [113] Yes No No No No No No O¹kdº O¹kdº \u0000\u0000 O¹dkº Smart Grid\nk-mer BF [131] No No No No No No No O¹kº O¹2kº\u0000O¹3kº \u0000\u0000 O¹2kº\u0000O¹3kº Biometric\nAdaptive BF [114] Yes No No No No No No O¹k+N+1º O¹k+N+1º \u0000\u0000 O¹k+N+1º Networking\nWeighted BF [119] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹kº General\nVar. Len. Sin [117] Yes No Yes No No No Yes O¹tº O¹qº O¹k\u0000dº O¹kº Networking\nPop. cons. BF [120] No No No No No No No O¹kiº O¹kiº \u0000\u0000 O¹kº General\nSpectral BF [112] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº Networking\nDynamic BF [89] No No Yes Yes No Yes Yes O¹kº O¹skº O¹skº O¹skº Dynamic set\nDBA [90] No Yes Yes Yes No Yes Yes O¹kº O¹rkº O¹rkº O¹rkº Dynamic set\nPar-BF [91] No No Yes Yes No Yes No O¹kº O¹ksmº O¹ksmº O¹ksmº Dynamic set\nScalable BF [118] No No No Yes No Yes No O¹kº O¹lkº \u0000\u0000 O¹lkº Dynamic set\nSpatial BF [17] No Yes No No No No No O¹kº O¹kº \u0000\u0000 O¹kº Spatial data\nSpace-code BF [88] Yes No No No No No No O¹ckº O¹lkº \u0000\u0000 O¹lkº Networking\nICBF [20] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº General\nBloomStore [18] No Yes No Yes No Yes No O¹kº O¹xkº \u0000\u0000 O¹xkº Storage\nIBLT [21] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº K-V store\nMulti-class BF [3] No No No No No No No O¹kiº O¹kiº \u0000\u0000 O¹kiº Networking\nOptihash [67] No No No No No No No O¹1º O¹1º \u0000\u0000 O¹1º Networking\nFPF-MBF [43] No No No No No Yes No O¹kº O¹kº \u0000\u0000 O¹kº Networking\nRetouched BF [75] No No No No Yes No Yes O¹kº O¹kº O¹kº O¹kº General\nMPCBF [77] No No Yes No No Yes No O¹k+1º O¹k+1º O¹k+1º O¹1º General\nTernary BF [134] No No Yes No No No No O¹kº O¹kº O¹kº O¹kº General\nSelected Hash [78] [79] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹kº General\nComplement BF [73] No No No No No No No O¹kº O¹2kº \u0000\u0000 O¹2kº General\nEGH ﬁlter [80] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº General\nCross-checking BF [72] No No No No No No No O¹kº O¹\u000bkº \u0000\u0000 O¹\u000bkº General\nGeneralized BF [76] No No No No Yes No Yes O¹kº O¹kº \u0000\u0000 O¹kº General\nYes-no BF [74] No No No No No No No O¹kº O¹2kº \u0000\u0000 O¹2kº General\nVI-CBF [83] No No Yes No No No No O¹2kº O¹2kº O¹2kº O¹2kº General\nFP-CBF [84] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº General\nDist. Sens. BF [143] No No No No No No Yes O¹kº O¹kº \u0000\u0000 O¹kº General\nLoc. Sens. BF [144] No No No No No No Yes O¹2kº O¹2kº \u0000\u0000 O¹2kº General\nMLBF [142] No No No No No No Yes O¹Lk+k0º O¹Lk+k0º \u0000\u0000 O¹kº General\nDeletable BF [133] No No Yes No No No No O¹kº O¹kº O¹2kº O¹kº General\nIBF [145] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº General\nStable BF [135] No No No No Yes No Yes O¹kº O¹kº O¹kº O¹kº Duplication\nTemporal CBF [136] No No Yes No Yes No Yes O¹kº O¹kº O¹kº O¹kº Networking\nDouble Buffering [137] No Yes No No Yes Yes Yes O¹2kº O¹2kº \u0000\u0000 O¹kº Networking\nA2Buffering [138] No Yes No No Yes Yes Yes O¹2kº O¹2kº \u0000\u0000 O¹2kº Dynamic set\nForgetful BF [139] No Yes No No Yes Yes Yes O¹2kº O¹pkº \u0000\u0000 O¹pkº K-V store\nBloomier ﬁlter [95] No Yes No No No No No O¹nlognº O¹\u0015kº \u0000\u0000 O¹\u0015kº General\nParallel BF [94] Yes Yes Yes No No Yes No O¹pkº O¹pk) O¹pkº O¹pkº Networking\nLess hash [85] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹kº General\nOne hash BF [86] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹kº General\nCompressed BF [99] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹kº General\nCompacted BF [100] No No No No No No Yes O¹kº O¹kº \u0000\u0000 O¹kº General\nCombinatorial BF [97] No Yes Yes No No Yes No O¹n1kº O¹\rkº O¹\rkº O¹\rkº Networking\nBloom-1 [92] No No No No No No No O¹kº O¹kº \u0000\u0000 O¹1º General\nOMASS [93] No Yes No No No Yes No O¹k+1º O¹k+1º \u0000\u0000 O¹1º General\nForest-struc. BF [106] No Yes No Yes No Yes No O¹k+2º O¹lkº \u0000\u0000 O¹lkº Storage\nDLB-BF [96] No Yes No No No Yes No O¹kº O¹kº \u0000\u0000 O¹kº Networking\nUltra-fast BF [98] No Yes No No No Yes No O¹k+1º O¹k+1)\u0000\u0000 O¹kº Implementation\nd-left CBF [101] Yes No Yes No No No No O¹dº O¹dº O¹dº O¹dº Implementation\nL-CBF [111] Yes No Yes No No No No O¹kº O¹kº O¹kº O¹kº Implementation\nMem. Opti. BF [102] No No No No No No No O¹k+1º O¹k+1º O¹k+1º O¹k+1º Storage\nEnergy efﬁc. BF [110] No No No No No No No O¹kº O¹k1º\u0000O¹kº \u0000\u0000 O¹k1º\u0000O¹kº Networking\nPipelined BF [107] [108] No No No No No No No O¹kº O¹k1º\u0000O¹kº \u0000\u0000 O¹k1º\u0000O¹kº Networking\nMatrix BF [103] No Yes No Yes No No No O¹kº O¹kº \u0000\u0000 O¹Nkº Copy dectection\nShifting BF [115] Yes Yes Yes No No No No O¹\u0015kº O¹\u0015kº O¹\u0015kº O¹\u0015kº General\n\n32\nsharing in human net; Parallel BF [94] supports multiattribute\nrepresentation on network services. Besides, for online sys-\ntems where elements may join and leave dynamically, several\nvariants are proposed to realize capacity elasticity of BF, such\nas Dynamic BF [89], DBA [90], Par-BF [91], Scalable BF\n[118] and A2Buffering [138]. Other variants are also designed\nin given contexts, including kBF [19], IBLT [21], and Forgetful\nBF [139] for KV store, Loglog BF [113] in smart grid, k-\nmer BF [131] for biometric data representation, BloomStore\n[18], Forest-structured BF [106], and Memory-optimized BF\n[102] for storage systems, Spatial BF [17] for spatial data\nrepresentation, Stable BF [135] for duplication, Ultra-fast BF\n[98] and d-left CBF [101] for implementation of CBF, and\nMatrix BF [103] for copy detection.\n1) Capability comparison: Generally, we consider six ca-\npabilities, i.e., counting, grouping, deletion, scalability, decay,\nand parallelism. Besides, we also highlight the variants which\nadditionally incur false negative errors in Table IV.\nCounting. Generally, the variants which have a counter ﬁeld\nin each cell (e.g., CBF, Spectral BF, FP-CBF, IBLT, IBF, ICBF,\netc) will be considered to support the counting capability and\nthereby multiplicity query. The counting capability is of great\nsigniﬁcance to extend the usage of BF from simple sets to\nmore general multisets. There are also other alternatives of the\ncounter ﬁeld, e.g., using the number of hash functions [114].\nAdditionally, typical estimation algorithms (e.g., maximum\nlikelihood estimation [88], probabilistic counting [113]) can\nalso be leveraged to estimate the multiplicity. A more special\nproposal is Shifting BF [115] which regards the multiplicity\nof elements as auxiliary information.\nGrouping . Grouping answers the question which group(s)\nor subset(s) a queried element belongs to. This capability\nwidens the application of BF from a single set to multiple sets\n(or groups) scenarios, e.g., IP lookup. Generally, the variants\nwith multiple BF vectors or BF segments (e.g., DBA [90],\nMatrix BF [103], BloomStore [18], Forest-structured BF [106],\netc) naturally support the grouping capability via representing\neach group with a single BF vector. This strategy has to query\nthe element against all the BF vectors or BF segments to draw\na probabilistic conclusion. Especially, Combinatorial BF [97]\nderives the group id for an element by leveraging multiple\nBFs. If the element passes the membership check of a BF, the\ncorresponding bit in the output group id will be 1. Spatial BF\n[17] distinguishes the areas with different integer labels. If we\ntreat the labels as groups, Spatial BF enables grouping with\ndifferentiated accuracy for diverse groups. OMASS enables\nthe grouping capability with shared bit vector for the multiple\nsets. To lessen the interference of bits for diverse sets, OMASS\nredesigns the hash functions to generate orthotropic hash\nvalues for a common element in multiple sets. Proposals like\nBloomier ﬁlter [95], Shifting BF [115] and kBF [19], can store\nthe group id as an associated value of the element. However,\nexcept for the proposals with multiple BFs or BF segments,\nother variants only resolve the grouping problem where an\nelement exclusively belongs to exactly a single group.\nDeletion and scalability . Both deletion and scalability are\ncrucial capabilities to enable the usage of BFs in dynamic\ndatasets. Nevertheless, most of the existing proposals achieveone single capability, and only a few of them guarantee dele-\ntion and scalability simultaneously. CBF [36] and its variants,\ne.g., MPCBF [77], VI-CBF [83], FP-CBF [84], Temporal\nCBF [136], d-left CBF [101] are naturally deletable. Other\nproposals with a counter in each cell can also delete elements\nreasonably by decreasing the corresponding counters. The\nDeletable BF [133] partitions the bit vector and only resets the\nbits in collision-free segments to delete elements. To achieve\nscalability and elasticity, DBF [89] and DBA [90] support both\ndeletion of elements and introduction of additional vectors.\nNote that deleting the elements in DBF and DBA by resetting\nthe bits from 1s to 0s may cause false negatives. A remedy is\nto replace the bits with cells like the CBF does, at the cost of\nnearly 4 times space overhead. The BFs in Matrix BF [103]\ncan be expanded but don’t support element-level deletion.\nHowever, the BF-level deletion is permitted, since each BF\nis independent and records all the strings in a document.\nDecay . Decay means eliminating stale elements to better\nrepresent the newly-arrival ones. This capability is extremely\nimportant for online systems. Note that we distinguish the\nperiodical decaying operations from deletion. When decaying\nthe vector, we may not acknowledge what and how many\nelements have been wiped out. By contrast, we are aware of\nexactly what elements will be deleted during deletion. Besides,\ndecaying always leads to both false positive and false negative\nerrors, while correct deletion imposes no impact to the existing\nelements. There are several variants designed to support decay,\nincluding Generalized BF [76], Retouched BF [75], Stable BF\n[135], Temporal Counting BF [136], Double buffering [137],\nA2buffering [138], and Forgetful BF [139]. Generalized BF,\nRetouched BF, Stable BF, and Temporal Counting BF reset the\nbits in a single BF vector with diverse strategies. By contrast,\nDouble buffering, A2buffering, and Forgetful BF ﬂush the\noldest BF among multiple BF vectors to remove the stale\nelements in a batched manner.\nParallelism . Parallelism is helpful to accelerate the query\nprocess and thereby increase the throughput of query. Typi-\ncally, the variants with multiple independent BFs or segments\ncan be accessed in parallel, include DBF [89], DBA [90],\nPar-BF [91], Scalable BF [118], BloomStore [18], FPF-MBF\n[43], MPCBF [77], Parallel BF [94], Combinatorial BF [97],\nOMASS [93], Forest-structured BF [106], DLB-BF [96], and\nUltra-fast BF [98]. The parallelism of query process decreases\nthe computation time to 1kthus improves the query through-\nput signiﬁcantly.\nFalse negatives . Certainly, all the variants of BF incur\ninherited false positive, despite the proposed optimization\ntechniques. A dozen of the variants, additionally, suffer from\nfalse negative errors. These variants loss the one-sided-error\ncharacteristic. Therefore, no matter the query result is positive\nor negative, the users have to further check the correctness\nfrom an off-chip hash table (if they have). Generalized BF\n[76], Retouched BF [75], Stable BF [135] reset the bits to\nwipe the stale elements thereby decreasing the false positive\nrate. The decay strategies may delete legal elements hence\nleading to false negatives. Similarly, deleting elements from\nthe standard DBF and DBA vectors via resetting of bits can\nalso result in false negatives, if the reset bits experience hash\n\n33\ncollisions. The coding strategy in Compacted BF will also\ncause false negatives. Besides, the use of locality-sensitive\nhash functions may also lead to false negatives. Distance-\nsensitive BF [143], Locality-sensitive BF [144] and MLBF\n[142] employ locality-sensitive hash functions to maintain\nthe distance between elements. However, it is still possible\nthat two neighbouring elements are mapped into two distant\ncells or bits. As a consequence, false negative errors will be\ntriggered for the approximate membership queries. Beyond\nthe above major reasons, the overﬂow of counters in Variable\nlength Signature [117], as well as hash collisions in kBF [19],\nalso result in false negative errors.\n2) Complexity comparison: To achieve the above capabil-\nities, the resultant penalty is higher computation complexity\nfor insertion, query, and deletion, as well as higher complexity\nfor memory access. The last four columns in Table IV detail\nthe considered complexities for each variant. Generally, the\nparameter kdenotes the number of hash functions for each BF\nvector, ncounts the number of elements in the set S. Other\ndedicated parameters can ﬁnd their meanings in corresponding\nliteratures. Note that, the complexities of several variants are\nnon-deterministic, hence we show both the upper bound and\nlower bound. Due to space limitation, we will not elaborate\nthe complexities one by one but spot several representative or\nspecial variants. Interested readers can refer to the references.\nInserting an element means mapping the element into the bit\nor cell vector. Deﬁnitely, the insertion complexity is mainly de-\ntermined by how many hash functions have been employed to\nmap the element. For instance, Adaptive BF [114] records the\nmultiplicity of an element with the number of hash functions,\nthereby the insertion complexity is O¹k+N+1º, where Nis the\nhighest multiplicity. The Bloomier ﬁlter [95] encodes all the\nelements recursively with multiple cascaded BFs. Accordingly,\nits insertion complexity is O¹nlognº, and query complexity is\nO¹\u0015kº, where\u0015is the number of BFs in Bloomier ﬁlter.\nGenerally, the query complexity highly depends on the\ninsertion complexity, e.g., CBF [36], kBF [19], Ternary BF\n[134], Deletable BF [133], IBF [145], Stable BF [135], Tem-\nporal CBF [136], etc. By contrast, k-mer BF [131] records\nthek-mers of a sequent dataset. For insertion, the khash\nfunctions map the sequence into kbits and set them as\n1s. When querying, besides of the queried sequence, one\n(one-sided k-mer BF) or both (two-sided k-mer BF) of the\nneighbouring sequences will also be queried, resulting in\nO¹2kºandO¹3kºquery complexity, respectively. The other\nvariants which must query against multiple BFs or segments\nto identify the membership of an element also need higher\nquery complexity, e.g., DBF [89], DBA [90], Matrix BF [103],\nBloomStore [18], etc. In particular, the query complexities of\nEABF [110], Pipelined BF [107] and its variants [108] [109]\nareO¹k1º(k1\u0014k) for negative or less accurate answers, while\nO¹kºfor positive or more trustable results.\nAs shown in Table IV, the deletion operation (if supported)\nincurs the same complexity as a query operation since BFs\nhave to query the existence of an element before actually\ndeleting it. The only outlier is Variable length signatures [117],\nwhich inserts an element by setting q\u0014t\u0014kbits as 1s and\ndeclares element x2Sif at least qbits are non-zero. Therefore,deleting an element must reset k\u0000d(d<q) bits as 0s, such that\nthe element will not be recognized as a member. By contrast,\nthe complexity of memory access quantiﬁes the number of\nmemory access for a query process. For variants in which the\nhash functions share the entire bit or cell vector (e.g., CBF\n[36], Adaptive BF [114], FP-CBF [84], IBF [145], IBLT [21],\nICBF [20], etc.), arbitrary query has to read the ktarget bits\nwith kmemory accesses. The reason is that the ktarget bits\ndisperses randomly in the vector, and one memory access may\nnot cover multiple target bits. MPCBF [77], Bloom-1 [92]\nand OMASS [93], however, only require exactly one memory\naccess since the existence information for an element is stored\nin one block with a word-size length.\nIX. S UMMARY AND OPEN ISSUES\nHeretofore, tens of variants are proposed for diverse pur-\nposes, enriching the BF paradigm. Table IV qualitatively\nsummaries the key capabilities and complexities of BF and\nits variants. These variants leverage the component(s) in the\nbasic framework to improve the performance or generalize the\nBF to more scenarios. Based on the review of current literature\non optimization of BF, we now outline some open issues that\nshould be considered in the future.\nImplementation in extreme hardware . BF is easy-\ndeployable, however, implementing BFs in extreme hardware\nis still problematic. Firstly, in light-weight hardware (wireless\nsensors, RFIDs), the memory, bandwidth, and computation\nunit are scare resources. As a consequence, deploying large-\nscale or complicated variants is not possible. To resolve this\nproblem, one may pre-clean the dataset and only store the\nnecessary elements, or alternatively, sacriﬁce the FPR and\noverload the bit vector to accommodate all the elements.\nAs for the transmission, besides of shrinking the length of\nBF, one may reasonably utilize the bandwidth and send the\nvector when the channel is not busy. Secondly, newly advanced\nhardware (TCAM, CAM, programmable hardware like FPGA,\nASIC), by contrast, bring great opportunities for the imple-\nmentation of BF and its variants. Several existing proposals\njointly leverage both RAM and ﬂash memory to extend their\ncapacity without signiﬁcant damage of access speed. The\nTCAM or FPGA-embedded devices, on the contrary, will lose\ntheir superiorities if the BFs are deployed in a traditional way.\nThis open issue calls for extra efforts.\nExtension or downsizing at arbitrary scale . The existing\nvariants to support capacity extension or downsizing (e.g.,\nDBF [89], DBA [90], Matrix BF [103], Scalable BF [118],\netc.) can only be resized at the level of sub-BFs. That is, only\nan entire sub-BF can be added or deleted. However, storing\nonly one element with an added sub-BF is uneconomical. By\ncontrast, overloading a sub-BF results in unacceptable false\npositive rate. An ideal extension scheme, however, should have\nthe ability to extend the BF with an arbitrary scale. This vision\nbrings the ﬂexibility of implementing BF at any scale.\nRepresentation of inter-element relationships . Basically,\nstandard BF and most of its variants represents elements inde-\npendently without any consideration of the inner relationship\nbetween them. Exceptions only include those variants which\n\n34\nemploy locality sensitive hash functions to map close elements\ninto neighbouring or same bits, e.g., Distance-sensitive BF\n[143], LSBF [144] and MLBF [142]. Besides of the distance\nbetween elements, other kinds of relationships are still beyond\nthe capability of the existing variants. For instance, the BFs\nare capable to record the nodes in a multicast tree, but fail\nto tell the parents and children of any node. Therefore, we\nenvision new variants which not only record the membership\nof the elements, but also represent the inner dependency of the\nelements. Besides, researchers are trying to learn the proper\nlocation for elements in BFs (also other data structures), so\nthat there are no false positive errors [148] [149].\nAlternates of BFs . Besides of optimizing the BF frame-\nwork, another approach is to propose alternates with better\nperformance. Recently, Cuckoo ﬁlter [150], Quotient ﬁlter\n[151], and their variants [152] [153] [154] [155] [156] generate\nwide attention due to their similar or even more integrated\nfunctionalities as the BF framework. Unlike BFs, these hash\ntables store the ﬁngerprints of elements directly. Cuckoo ﬁlter\n[150] is a redesigned hash table to support membership query\nbased on the theory of Cuckoo hashing [157] [158]. The\nQuotient ﬁlter (QF) [151] is a hash table of slots to store the\nﬁngerprints of elements with quotienting technique [159]. The\nﬁngerprint of an element is divided into two parts, i.e., the q\nmost signiﬁcant bits as quotient, and the rleast signiﬁcant bits\nas remainder. A remainder is stored in the slot suggested by the\nquotient. We vision that in the future, the Cuckoo ﬁlters and\nQuotient ﬁlters will be further improved and other alternative\ndata structures will be presented.\nExtensive applications of BFs . Hitherto, BFs have been\nwidely employed in various systems. More applications may\noccur in near future, beyond of communications (e.g., cogni-\ntive radio networks, wireless sensor networks, device-to-device\ncommunications, smart grid, etc.), networking (e.g., packet\nforwarding and routing, web caching, gossiping, resource\ndiscovering, scheduling, etc.), and database (e.g., informa-\ntion retrieving, recommendation, record linkage, duplication,\nanonymization, etc.). In Bioinformatics, BFs are employed to\nrepresent sequenced genomes, biometric information such as\niris, face, handshape, ﬁngerprint, etc. In the coming applica-\ntions, BFs can be customized for diverse design goals partially\nwith the optimization techniques summarized by us.\nX. C ONCLUSION\nBF has been widely applied in the society of communi-\ncations and networking. As we stated in this survey, when\nsuch a data structure is employed, the users can redesign it\nto suit their contexts. In this survey, we review the existing\nBF variants from mainly two dimensions, i.e., performance\nand generalization. To improve the performance, dozens of\nvariants devote themselves to reducing the false positives and\nimplementation costs. Besides, tens of variants generalize the\nBF framework in more scenarios by diversifying the input\nsets and enriching the output functionalities. Speciﬁcally, to\nreduce false positives, the existing BF variants utilizing prior\nknowledge, select optimal hash functions, generate multiple\nBFs and queries, reset the bits in vectors, or represent elementsdifferentially. To further ease the implementation of BF, a\ndozen variants are proposed to optimize its computation cost,\nmemory access, space efﬁciency, and energy usage. Besides\nthe representation of general sets, variants are investigated to\nrepresent multisets, dynamic sets, weighted sets, key-values,\nsequence sets, and spatial sets. Lastly, besides element in-\nsertion and query, more BF functionalities are enabled, such\nas element deletion, element decay, approximate membership\nquery, and semantic enrichment. Additionally, we also classify\nthe existing optimization techniques from the perspective of\nthe components of BF, and then compare them in terms of both\nfunctionality and complexity. We expect more applications\nand redesigns of BF in the next generation of networks,\ncommunication systems and beyond.\nREFERENCES\n[1] B. H. Bloom, “Space/time trade-offs in hash coding with allowable\nerrors,” Communications of the ACM , vol. 13, no. 7, pp. 422-426, 1970.\n[2] F. Angius, M. Gerla, G. Pau, “Bloogo: Bloom ﬁlter based gossip\nalgorithm for wireless NDN,” in Proc. ACM workshop on Emerging\nName-Oriented Mobile Networking Design-Architecture, Algorithms,\nand Applications, Hilton Head, SC, USA, 2012.\n[3] D. Li, H. Cui, Y . Hu, Y . Xia, X. Wang, “Scalable data center multicast\nusing multi-class Bloom ﬁlter,” in Proc. IEEE ICNP , Vancouver, BC\nCanada, 2011.\n[4] X. Tian, Y . Cheng, “Loop mitigation in Bloom ﬁlter based multicast: A\ndestination-oriented approach,” in Proc. IEEE INFOCOM, Orlando, FL,\nUSA, 2012.\n[5] I. Nikolaevskiy, A. Lukyanenko, T. Polishchuk, V . Polishchukc, A. Gur-\ntov, “isBF: Scalable in-packet Bloom ﬁlter based multicast,” Computer\nCommunications, vol. 70, pp. 79-85, 2015.\n[6] D. Guo, Y . He, Y . Liu, “On the feasibility of gradient-based data-centric\nrouting using Bloom ﬁlters,” IEEE TPDS, vol. 25, no. 1, pp. 180-190,\n2014.\n[7] G. Chen, D. Guo, L. Luo, B. Ren, “Optimization of multicast source-\nrouting based on boom ﬁlter,” IEEE Communication Letters, vol. 22,\nno. 4, pp. 700-703, 2018.\n[8] D. Guo, Y . He, P. Yang, “Receiver-oriented design of bloom ﬁlters for\ndata-centric routing,” Computer Networks, vol. 54, no. 1, pp. 165-174,\n2010.\n[9] O. Rottenstreich, I. Keslassy, “The Bloom paradox: When not to use a\nBloom ﬁlter? ” in Proc. IEEE INFOCOM , Orlando, FL, USA, 2012.\n[10] H. Alexander, I. Khalil, C. Cameron, Z. Tari, A. Zomaya, “Cooperative\nweb caching using dynamic interest-tagged ﬁltered Bloom ﬁlters,” IEEE\nTPDS, vol. 26, no. 11, pp. 2956-2969, 2015.\n[11] Y . Li, R. Miao, C. Kim, M. Yu, “FlowRadar: A better NetFlow for data\ncenters,” in Proc. USENIX NSDI, Santa Clara, CA, USA, 2016.\n[12] E.A .Durham, M. Kantarcioglu, Y . Xue, C. Toth, M. Kuzu, B. Malin,\n“Composite Bloom ﬁlters for secure record linkage,” IEEE TKDE, vol.\n26, no. 12, pp. 2956-2968, 2014.\n[13] M. Moreira, R. Laufer, P. Velloso, and O. Duarte, “Capacity and\nrobustness tradeoffs in Bloom ﬁlters for distributed applications,” IEEE\nTPDS, vol. 23, no. 12, pp. 2219-2230, 2012.\n[14] B.M. Maggs, R.K. Sitaraman, “Algorithmic nuggets in content delivery,”\ninProc. ACM SIGCOMM, London, United Kingdom, 2015.\n[15] X. Zhu, R. Hao, S. Jiang, H. Chi, H. Li, “Veriﬁcation of boolean queries\nover outsourced encrypted data based on Counting Bloom ﬁlter,” in Proc.\nIEEE GLOBECOM, San Diego, CA, USA, 2015.\n[16] A. Margara, G. Cugola, “High-performance publish-subscribe matching\nusing parallel hardware,” IEEE TPDS, vol. 25, no. 1, pp. 126-135, 2014.\n[17] L. Calderoni, P. Palmieri, D. Maio, “Location privacy without mutual\ntrust: The spatial Bloom ﬁlter,” Computer Communications, vol. 68, pp.\n4-12, 2015.\n[18] G. Lu, Y .J. Nam, D.H.C. Du, “BloomStore: Bloom ﬁlter based memory-\nefﬁcient key-value store for indexing of data de-duplication on ﬂash,”\ninProc. IEEE MSST , Paciﬁc Grove, Canada, 2012.\n[19] S. Xiong, Y . Yao, Q. Cao, T. He, “kBF: A Bloom ﬁlter for key-value\nstorage with an application on approximate state machines,” in Proc.\nIEEE INFOCOM , Toronto, Canada, 2014.\n\n35\n[20] L. Luo, D. Guo, J. Wu, O. Rottenstreich, Q. He, Y . Qin, X. Luo,\n“Efﬁcient multiset synchronization,” IEEE/ACM ToN, vol. 25, no. 2,\npp. 1190-1205, 2017.\n[21] M.T. Goodrich, M. Mitzenmacher, “Invertible Bloom lookup tables,”\ninProc. Annual Allerton Conference on Communication, Control, and\nComputing, Monticello, Illinois, USA, 2011.\n[22] D. Chen, C. Konrad, K. Yi, W. Yu, Q. Zhang, “Robust set reconciliation,”\ninProc. ACM SIGMOD, Snowbird, Utah, USA, 2014.\n[23] L. Luo, D. Guo, X. Zhao, J. Wu, O. Rottenstreich, X.\nLuo, “Near-accurate multiset reconciliation,” IEEE TKDE,\nDOI10.1109/TKDE.2018.2849997, 2018.\n[24] D. Guo, M. Li, “Set reconciliation via counting bloom ﬁlters,” IEEE\nTKDE, vol. 25, no. 10, pp. 2367-2380, 2013.\n[25] S. Dutta, A. Narang, S.K. Bera, “Streaming quotient ﬁlter: a near optimal\napproximate duplicate detection approach for data streams,” in Proc.\nVLDB, Riva del Garda, Trento, Italy, 2013.\n[26] J. Hermans, B. Mennink, R. Peeters, “When a Bloom ﬁlter is a doom\nﬁlter: Security assessment of a novel iris biometric template protection\nsystem,” in Proc. BIOSIG, Darmstadt, Germany, 2014.\n[27] M. Gomez-Barrero, C. Rathgeb, J. Galbally, J. Fierrez, C. Busch,\n“Protected facial biometric templates based on local gabor patterns and\nadaptive Bloom ﬁlters,” in Proc. ICPR, Stockholm, Sweden, 2014.\n[28] P. Jiang, Y . Ji, X. Wang, J. Zhu, Y . Cheng, “Design of a multiple Bloom\nﬁlter for distributed navigation routing,” IEEE Transactions on SMC:\nSystems, vol. 44, no. 2, pp. 254-260, 2014.\n[29] S. Tarkoma, C.E. Rothenberg, E. Lagerspetz, “Theory and practice of\nBloom ﬁlters for distributed systems,” IEEE Communications Surveys\nand Tutorials, vol.14, no. 1, pp.131-155, 2012.\n[30] A. Broder, M. Mitzenmacher, “Network applications of Bloom ﬁlters:\nA survey,” Internet mathematics, vol.1, no. 4, pp. 485-509, 2004.\n[31] S. Geravand, M. Ahmadi, “Bloom ﬁlter applications in network security:\nA state-of-the-art survey,” Computer Networks, vol.57, no. 18, pp. 4047-\n4064, 2013.\n[32] L. L. Gremillion, “Designing a Bloom ﬁlter for differential ﬁle access,”\nCommunications of the ACM , vol. 25, no. 7, pp. 600-604, 1982.\n[33] J. K. Mullin, “A second look at Bloom ﬁlters,” Communications of the\nACM , vol. 26, no. 8, 1983.\n[34] P. Bose, H. Guo, E. Kranakis, “On the false-positive rate of Bloom\nﬁlters,” Information Processing Letters , vol. 108, no. 4, pp. 210-213,\n2008.\n[35] R. L. Graham, D. E. Knuth, O. Patashnik, “Concrete Mathematics,”\nAddison-Wesley , 2nd edition, 1994.\n[36] L. Fan, P. Cao, J. Almeida, A.Z. Broder, “Summary cache: A scalable\nwide-area web cache sharing protocol,” IEEE/ACM ToN, vol. 8, no. 3,\npp. 281-293, 2000.\n[37] K. Chen, P. Wu, B. Lai, “Reduce data coherence cost with an area\nefﬁcient double layer counting bloom ﬁlter,” in Proc. PPAP , Taipei,\nTaiwan, 2012.\n[38] E. Papapetrou, E. Pitoura, K. Lillis “Speeding-up cache lookups in\nwireless ad-hoc routing using bloom ﬁlters,” in Proc. IEEE PIMRC,\nBerlin, Germany, 2005.\n[39] S. Kavitha, R. Thanuja, A. Umamakeswari, “Updating distributed cache\nmechanism using bloom ﬁlter for asymmetric cryptography in large\nwireless networks,” Indian Journal of Science and Technology, vol. 9,\nno. 48, pp. 1-6, 2016.\n[40] H. Lim, K. Lim, N. Lee, K.H. Park, “On adding Bloom ﬁlters to longest\npreﬁx matching algorithms,” IEEE TC , vol. 63, no. 2, pp. 411-423, 2014.\n[41] G. Park, M. Kwon, “ An enhanced bloom ﬁlter for longest preﬁx\nmatching,” in Proc. IEEE/ACM IWQoS, Montreal, Canada, 2013.\n[42] C. Rothenberg, C. Macapuna, M. Magalhaes, F. Verdi, A. Wiesmaier,\n“In-packet Bloom ﬁlters: Design and networking applications,” Com-\nputer Networks, vol. 55, no. 6, pp. 1364-1378, 2011.\n[43] J. Tapolcai, J. Biro, P. Babarczi, A. Gulyas, Z. Heszberger, D. Trossen,\n“Optimal false-positive-free Bloom ﬁlter design for scalable multicast\nforwarding,” IEEE/ACM ToN, vol. 23, no. 6, pp. 1832-1845, 2015.\n[44] Y . Wang, T. Pan, Z. Mi, H. Dai, X. Guo, T. Zhang, B. Liu, Q. Dong,\n“Nameﬁlter: Achieving fast name lookup with low memory cost via\napplying two-stage bloom ﬁlters,” in Proc. IEEE INFOCOM, Turin,\nItaly, 2013.\n[45] W. Quan, C. Xu, J. Guan, H. Zhang, L. Grieco, “Scalable name lookup\nwith adaptive preﬁx bloom ﬁlter for named data networking,” IEEE\nCommunications Letters, vol. 18, no. 1, pp. 102-105, 2014.\n[46] J. Trindade, T. Vazao, “HRAN - A scalable routing protocol for\nmultihop wireless networks using bloom ﬁlters,” Wired/Wireless Internet\nCommunications, pp. 434-445, 2011.[47] J. Trindade, T. Vazao, “Routing on large scale mobile ad hoc networks\nusing bloom ﬁlters,” Ad Hoc Networks, vol. 23, pp. 34-51, 2014.\n[48] F. Klingler, R. Cohen, C. Sommer, F. Dressler, “Bloom hopping: Bloom\nﬁlter based 2-Hop Neighbor Management in V ANETs,” IEEE TMC,\n10.1109/TMC.2018.2840123, 2018.\n[49] X. Li, J. Wu, J. Xu, “Hint-based routing in WSNs using scope decay\nbloom ﬁlters,” in Proc. IEEE NAS, Shenyang, China, 2006.\n[50] P. Hebden, A. Pearce, “Data-centric routing using Bloom ﬁlters in\nwireless sensor networks,” in Proc. IEEE ICISIP , Bangalore, India, 2006.\n[51] A. Reinhardt, O. Morar, S. Santini, S. Zoller, R. Steinmetz, “CBRF:\nBloom ﬁlter routing with gradual forgetting for tree-structured wireless\nsensor networks with mobile nodes,” in Proc. IEEE WOWMOM, San\nFrancisco, USA, 2012.\n[52] M. Grissa, A. Yavuz, B. Hamdaoui, “Cuckoo ﬁlter-based location-\nprivacy preservation in database-driven cognitive radio networks,” in\nProc. IEEE WSCNIS, Hammamet, Tunisia 2015.\n[53] M. Grissa, A. Yavuz, B. Hamdaoui, “Location privacy preservation in\ndatabase-driven wireless cognitive networks through encrypted proba-\nbilistic data structures,” IEEE TCCN, vol. 3, no. 2, pp. 255-266, 2017.\n[54] C. Rathgeb, F. Breitinger, C. Busch, H. Baier, “On application of bloom\nﬁlters to iris biometrics,” IET Biometrics, vol. 3, no. 4, pp. 207-218,\n2014.\n[55] D. Karapiperis, V . Verykios, “An LSH-based blocking approach with\na homomorphic matching technique for privacy-preserving record link-\nage,” IEEE TKDE, vol. 27, no. 4, pp. 909-921, 2015.\n[56] E. Oriero, K. Rabieh, M. Mahmoud, M. Ismail, E. Serpedin, K. Qaraqe,\n“Trust-based and privacy-preserving ﬁne-grained data retrieval scheme\nfor MSNs,” in Proc. IEEE WCNC, Doha, Qatar, 2016.\n[57] M. Alaggan, S. Gambs, S. Matwin, M. Tuhin, “Sanitization of call detail\nrecords via differentially-private bloom ﬁlters,” in Proc. IFIP DBSec,\nFairfax, V A, USA, 2015.\n[58] R. Tourani, S. Misra, T. Mick, and G. Panwar, “Security, privacy, and\naccess control in information-centric networking: A survey,” IEEE\nCommunications Surveys and Tutorials, vol. 20, no. 1, pp. 566-600,\n2018.\n[59] L. Demir, A. Kumar, M. Cunche, C. Lauradoux, “The pitfalls of hashing\nfor privacy,” IEEE Communications Surveys and Tutorials, vol. 20, no.\n1, pp. 551-565, 2018.\n[60] M. Ambrosin , A. Compagno, M. Conti, C. Ghali, G. Tsudik, “Security\nand privacy analysis of national science foundation future internet\narchitectures,” IEEE Communications Surveys and Tutorials, vol. 20,\nno. 2, pp. 1418-1442, 2018.\n[61] M. Conti, S. Kumar, C. Lal, S. Ruj, “A survey on security and privacy\nissues of bitcoin,” IEEE Communications Surveys and Tutorials, DOI\n10.1109/COMST.2018.2842460, 2018.\n[62] M. C. K. Khalilov, A. Levi, “A survey on anonymity and privacy in\nbitcoin-like Digital cash dystems,” IEEE Communications Surveys and\nTutorials, vol. 20, no. 3, pp. 2543-2585, 2018.\n[63] K. Rabieh, M. Mahmoud, K. Akkaya, S. Tonyali, “Scalable certiﬁcate\nrevocation schemes for smart grid AMI networks using bloom ﬁlters,”\nIEEE TDSC, vol. 14, no. 4, pp. 420-432, 2017.\n[64] M. Cisse, N. Usunier, T. Artieres, “Decentralised Peer-to-Peer data\ndissemination in wireless sensor networks,” Pervasive and Mobile Com-\nputing, vol. 40, pp. 242-266, 2017.\n[65] R. Carbajo, C. Goldrick, “Robust bloom ﬁlters for large multilabel clas-\nsiﬁcation tasks,” Advances in Neural Information Processing Systems,\npp. 1851-1859, 2013.\n[66] K. Choi, D. Wiriaatmadja, “Discovering mobile applications in cellular\ndevice-to-device communications: Hash function and bloom ﬁlter-based\napproach,” IEEE TMC, vol. 15, vol. 2, pp. 336-349, 2016.\n[67] L. Carrea, A. Vernitski, M. Reed, “Optimized hash for network path\nencoding with minimized false positives,” Computer Networks, vol. 58,\nno.11, pp. 180-191, 2014.\n[68] J. Tapolcai, A. Gulyas, Z. Heszbergery, J. Biro, “Stateless multi-stage\ndissemination of information: Source routing revisited,” in Proc. IEEE\nGLOBECOM , Anaheim, California, USA, 2012.\n[69] W. Yang, D. Trossen, J. Tapolcai, “Scalable forwarding for information-\ncentric networks,” in Proc. IEEE ICC-NGN , Budapest, Hungary, 2013.\n[70] D. Lagutin, K. Visala, S. Tarkoma, “Publish/subscribe for Internet:\nPSIRP perspective,” Towards the Future Internet-Emerging Trends from\nEuropean Research, Amsterdam, The Netherlands: IOS Press, 2010.\n[71] H.M. Ju, H. Lim, “On reducing false positives of a Bloom ﬁlter in trie-\nbased algorithms,” in Proc. ACM/IEEE ANCS , Marina del Rey, CA,\nUSA, 2014.\n[72] H. Lim, N. Lee, J. Lee, C. Yim, “Reducing false positives of a Bloom\nﬁlter using Cross-Checking Bloom ﬁlters,” Applied Mathematics and\nInformation Sciences, vol. 8, no. 4, pp. 1865-1877, 2014.\n\n36\n[73] H. Lim, J. Lee, C. Yim, “Complement Bloom ﬁlter for identifying true\npositiveness of a Bloom ﬁlter,” IEEE Communications Letters, vol. 19,\nno. 11, pp. 1905-1908, 2015.\n[74] L. Carrea, A. Vernitski, M. Reed, “Yes-no Bloom ﬁlter: A way\nof representing sets with fewer false positives,” arXiv preprint ,\narXiv:1603.01060, 2016.\n[75] B. Chazelle, J. Kilian, R. Rubinfeld, A. Tal, “Retouched Bloom ﬁlters:\nallowing networked applications to trade off selected false positives\nagainst false negatives,” in Proc. ACM CoNEXT , Lisboa, Portugal, 2006.\n[76] R.P. Laufer, P.B. Velloso, O.C.MB. Duarte, “A generalized Bloom\nﬁlter to secure distributed network applications, ” Computer Networks\nAmsterdam, vol. 55, no.8, pp. 1804-1819, 2011.\n[77] K. Huang, J. Zhang, D. Zhang, G. Xie, “A Multi-partitioning approach\nto building fast and accurate counting Bloom ﬁlters,” in Proc. IEEE\nIPDPS , Cambridge, MA, USA, 2013.\n[78] S. Lumetta, M. Mitzenmacher, “Using the power of two choices to\nimprove Bloom ﬁlters,” Internet Mathematics, vol.4, no. 1, pp. 17-33,\n2007.\n[79] F. Hao, M. Kodialam, T.V . Lakshman, “Building high accuracy Bloom\nﬁlters using partitioned hashing,” in Proc. ACM SIGMETRICS, San\nDiego, CA, USA, 2007.\n[80] S.Z. Kiss, E. Hosszu, J. Tapolcai, L. Rónyai, O. Rottenstreich, “Bloom\nﬁlter with a false positive free zone,” in Proc. IEEE INFOCOM,\nHonolulu, HI, USA 2018.\n[81] D. Pei, S. Arto, C. Ding , “Chinese remainder theorem: applications in\ncomputing, coding, cryptography,” World Scientiﬁc, 1996.\n[82] D. Z. Du, F. Hwang, “Combinatorial group testing and its applications,”\nWorld Scientiﬁc, 1993.\n[83] O. Rottenstreich, Y . Kanizo, I. Keslassy, “The variable-increment count-\ning Bloom ﬁlter,” in Proc. IEEE INFOCOM , Orlando, Florida, USA,\n2012.\n[84] S. Pontarelli, P. Reviriego, J. A. Maestro, “Improving counting Bloom\nﬁlter performance with ﬁngerprints,” Information Processing Letters,\nvol. 116, no. 4, pp. 304-309, 2016.\n[85] A. Kirsch, M. Mitzenmacher,“Less hashing, same performance: Building\na better Bloom ﬁlter,” Random Struct. Algorithms, vol. 33, no. 2, pp.\n187-218, 2006.\n[86] J. Lu, T. Yang, Y . Wang, H. Dai, L. Jin, H. Song, B. Liu, “One-hashing\nBloom ﬁlter,” in Proc. IEEE/ACM IWQoS , Portland, OR, USA, 2015.\n[87] A. Kirsch, M. Mitzenmacher,“Building a better Bloom ﬁlter,” in Proc.\nAnnual European Symposium on Algorithms, Palma de Mallorca, Spain,\n2005.\n[88] A. Kumar, J.J. Xu, L. Li, J. Wang, “Space-code Bloom ﬁlter for efﬁcient\ntrafﬁc ﬂow measurement,” in Proc. ACM IMC, Miami Beach, FL, USA,\n2003.\n[89] D. Guo, J. Wu, H. Chen, Y . Yuan, X. Luo, “The Dynamic Bloom ﬁlters,”\nIEEE TKDE, vol. 22, no. 1, pp. 120-133, 2010.\n[90] J. Wei, H. Jiang, K. Zhou, D. Feng, “DBA: A dynamic Bloom ﬁlter array\nfor scalable membership representation of variable large data sets,” in\nProc. IEEE MASCOTS, Rafﬂes Hotel, Singapore, 2011.\n[91] Y . Liu, X. Ge, D.H.C. Du, X. Huang, “Par-BF: A parallel partitioned\nBloom ﬁlter for dynamic data sets,” The International Journal of High\nPerformance Computing Applications, vol. 30, no. 3, pp. 259-275, 2016.\n[92] Y . Qiao, T. Li, S. Chen, “Fast Bloom ﬁlters and their generalization,”\nIEEE TPDS, vol. 25, no. 1, pp. 93-103, 2014.\n[93] M. Mitzenmacher, P. Reviriego, S. Pontarelli, “OMASS: One memory\naccess set separation,” IEEE TKDE, vol. 28, no. 7, pp. 1940-1943, 2016.\n[94] B. Xiao, Y . Hua, “Using Parallel Bloom ﬁlters for multiattribute repre-\nsentation on network services,” IEEE TPDS, vol. 12, no. 1, pp. 20-32,\n2010.\n[95] Y . Lu, B. Prabhakar, F. Bonomi, “The Bloomier ﬁlter: An efﬁcient data\nstructure for static support lookup tables,” in Proc. ACM-SIAM, New\nOrleans, Louisiana, USA, 2004.\n[96] H. Song, F. Hao, M. Kodialam, T. V . Lakshman, “IPv6 lookups using\ndistributed and Load Balanced Bloom ﬁlters for 100Gbps core router\nline cards,” in Proc. IEEE INFOCOM, Rio de Janeiro, Brazil, 2009.\n[97] F. Hao, M. Kodialam, T. V . Lakshman, H. Song, “Fast dynamic multiset\nmembership testing using Combinatorial Bloom ﬁlters,” in Proc. IEEE\nINFOCOM, Rio de Janeiro, Brazil, 2009.\n[98] J. Lu, Y . Wan, Y . Li, C. Zhang, H, Dai, Y . Wang, G.Zhang, B. Liu,\n“Ultra-fast Bloom ﬁlters using SIMD techniques,” in Proc. IEEE/ACM\nIWQoS , Vilanova i la Geltrú, Spain, 2017.\n[99] M. Mitzenmacher, “Compressed Bloom ﬁlters,” IEEE/ACM ToN, vol.\n10, no. 5, pp. 604–612, 2002.\n[100] N. Mosharraf, A.P. Jayasumana, I. Ray, “Compacted Bloom ﬁlter,” in\nProc. IEEE CIC, Pittsburgh, PA, USA, 2016.[101] F. Bonomi, M. Mitzenmacher, R. Panigrahy, S Singh, G. Varghese, “An\nimproved construction for counting Bloom ﬁlters,” in Proc. European\nSymposium on Algorithms, Zurich, Switzerland, 2006.\n[102] M. Ahmadi, S. Wong, \"A memory-optimized Bloom ﬁlter using an\nadditional hashing function,\" in Proc. IEEE GLOBECOM, New Orleans,\nLA, USA, 2008.\n[103] S. Geravand, M. Ahmadi, “A novel adjustable matrix Bloom ﬁlter-\nbased copy detection system for digital libraries,” in Proc. IEEE CIT,\nPaphos, Cyprus, 2011.\n[104] A. Broder, M. Mitzenmacher, “Using multiple hash functions to\nimprove IP lookups” in Proc. IEEE INFOCOM, Alaska, USA, 2001.\n[105] Y . Lu, B. Prabhakar, F. Bonomi, “Perfect hashing for network appli-\ncations,” in Proc. IEEE ISIT, Seattle, WA, USA, 2006.\n[106] G. Lu, B. Debnath, D.H.C. Du, “A Forest-structured Bloom ﬁlter with\nﬂash memory,” in Proc. IEEE MSST, Denver, Colorado, 2011.\n[107] I. Kaya, T. Kocak, “Energy-efﬁcient pipelined Bloom ﬁlters for network\nintrusion detection,” in IEEE ICC, Istanbul, Turkey, 2006.\n[108] T. Kocak, I. Kaya, “Low-power Bloom ﬁlter architecture for deep\npacket inspection,” IEEE Communications Letters, vol. 10, no. 3, pp.\n210-212, 2006.\n[109] M. Paynter, T. Kocak, “Fully pipelined Bloom ﬁlter architecture,” IEEE\nCommunications Letters, vol. 12, no. 11, pp. 855-857, 2008.\n[110] Y . Zhou, T. Song, X. Wang, “EABF: Energy efﬁcient self-adaptive\nBloom ﬁlter for network packet processing,” in Proc. IEEE ICC, Ottawa,\nCanada, 2012.\n[111] E. Saﬁ, A. Moshovos, A. Veneris, “L-CBF: A low-power, fast counting\nBloom ﬁlter architecture,” IEEE TVLSI, vol. 16, no. 6, pp. 628-638,\n2008.\n[112] S. Cohen, Y . Matias, “Spectral Bloom ﬁlters,” in Proc. ACM SIGMOD,\nMadison, Wisconsin, USA, 2003.\n[113] Y . Yao, S. Xiong, H. Qi, Y . Liu, L.M. Tolbert, Q. Cao, “Efﬁcient\nhistogram estimation for smart grid data processing with the loglog-\nBloom-ﬁlter,” IEEE Transactions on Smart Grid, vol. 6, no. 1, pp. 199-\n208, 2015.\n[114] Y . Matsumoto, H. Hazeyama, Y . Kadobayashi, “Adaptive Bloom ﬁlter:\nA space-efﬁcient counting algorithm for unpredictable network trafﬁc,”\nIEICE Transactions on Information and Systems, vol. 91, no. 5, pp.\n1292-1299, 2008.\n[115] T. Yang, A. Liu, M. Shahzad, Y . Zhong, Q. Fu, Z. Li, “A shifting\nBloom ﬁlter framework for set queries,” in Proc. IEEE VLDB, New\nDelhi, India, 2016.\n[116] M Durand, P Flajolet, “Loglog counting of large cardinalities,” Euro-\npean Symposium on Algorithms, Berlin, Heidelberg, 2003.\n[117] Y . Lu, B. Prabhakar, F. Bonomi, “Bloom ﬁlters: Design innovations\nand novel applications,” in Proc. The Annual Allerton Conference on\nCommunication, Control and Computing, Monticello, Illinois, USA,\n2005.\n[118] P. S. Almeida, C. Baquero, N. Preguica, D. Hutchison, “Scalable Bloom\nﬁlters,” Information Processing Letters , vol. 101, no. 6, pp. 255-261,\n2007.\n[119] J. Bruck, J. Gao, A. Jiang, “Weighted Bloom ﬁlter,” in Proc. IEEE\nISIT, Seattle, WA, USA, 2006.\n[120] M. Zhong, P. Lu, K. Shen, J. Seiferas, “Optimizing data popularity\nconscious Bloom ﬁlters, ” in Proc. ACM PODC, Toronto, Ontario,\nCanada, 2008.\n[121] G. Decandia, D. Hastorun, M. Jampani, G. Kakulapati, A. Lakshman,\nA. Pilchin, S. Sivasubramanian, P. V osshall, W. V ogels,“Dynamo: Ama-\nzon’s highly available key-value store,” in Proc. ACM SOSP , Stevenson,\nWashington, USA, 2007.\n[122] Memcached Website. Available: https://memcached.org, Oct. 2017.\n[123] Apache Foundation. Available: Cassandra Website, http:// cassan-\ndra.apache.org, Oct. 2017.\n[124] Redis Website. Available: http://redis.io/, Oct. 2017.\n[125] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach, M.\nBurrows, T. Chandra, A. Fikes, R. E. Gruber, “Bigtable: A distributed\nstorage system for structured data,” in Proc. USENIX OSDI , Seattle,\nWashington, USA, 2006.\n[126] C. H. Wu, T. W. Kuo, L. P. Chang, “An efﬁcient b-tree layer imple-\nmentation for ﬂash-memory storage systems,” ACM TECS , vol. 6, no.\n3, 2007.\n[127] S. Nath, A. Kansal, “FlashDB: Dynamic self-tuning database for\nNAND ﬂash,” in Proc. ACM/IEEE IPSN , Cambridge, Massachusetts,\nUSA, 2007.\n[128] A. Anand, C. Muthukrishnan, S. Kappes, A. Akella, S. Nath, “Cheap\nand large cams for high performance data-intensive networked systems,”\ninProc. USENIX NSDI, San Jose, California, USA, 2010.\n\n37\n[129] D.E. Wood, S.L. Salzberg, “Kraken: Ultrafast metagenomic sequence\nclassiﬁcation using exact alignments,” Genome Biology , vol. 15, no. 3,\n2014.\n[130] D.R. Zerbino, E. Birney “Velvet: Algorithms for de novo short read\nassembly using de Bruijn graphs,” Genome Research , vol. 18, no. 5, pp.\n821-829, 2008.\n[131] D. Pellow, D. Filippova, C. Kingsford, “Improving Bloom ﬁlter per-\nformance on sequence data using k-mer Bloom ﬁlters,” Journal of\nComputational Biology, vol. 24, no. 6, pp. 547-557, 2017.\n[132] G. Holley, R. Wittler, J. Stoye, “Bloom ﬁlter Trie: An alignment-free\nand reference-free data structure for pan-genome storage,” Algorithms\nfor Molecular Biology, vol. 11, no. 3, 2016.\n[133] C. Rothenberg, C. Macapuna, F. Verdit, M. Magalhaes, “The deletable\nBloom ﬁlter: A new member of the Bloom family,” IEEE Communica-\ntion Letters, vol. 14, no. 6, pp. 557-559, 2010.\n[134] H. Lim, J. Lee, H. Byun, C. Yim, “Ternary Bloom ﬁlter replacing\ncounting Bloom ﬁlter,” IEEE Communications Letters, vol. 21, no. 2,\npp. 278-281, 2017.\n[135] F. Deng, D. Raﬁei, “Approximately detecting duplicates for streaming\ndata using stable Bloom ﬁlters,” in Proc. ACM SIGMOD, Chicago,\nIllinois, USA, 2006.\n[136] Y . Zhao, J. Wu, “The design and evaluation of an information sharing\nsystem for human networks,” IEEE TPDS, vol. 25, no. 3, pp. 796-805,\n2014.\n[137] F. Chang, C. Wu, and K. Li, “Approximate caches for packet classiﬁ-\ncation,” in Proc. IEEE INFOCOM, Honkong, China, 2004.\n[138] M.K. Yoon, “Aging Bloom ﬁlter with two active buffers for dynamic\nsets,” IEEE TKDE, vol. 22, no. 1, pp. 134-138, 2010.\n[139] R. Subramanyam, I. Gupt, L.M. Leslie, W. Wang, “Idempotent dis-\ntributed counters using a forgetful Bloom ﬁlter,” Cluster Computing,\nvol. 19, no. 2, pp. 879-892, 2016.\n[140] M. Datar, N. Immorlica, P. Indyk, V .S. Mirrokni, “Locality-sensitive\nhashing scheme based on p-stable distributions,” in Proc. ACM SoCG,\nBrooklyn, New York, USA, 2004.\n[141] P. Indyk, R. Motwani, “Approximate nearest neighbors: towards re-\nmoving the curse of dimensionality,” in Proc. ACM STOC, Dallas, TX,\nUSA, 1998.\n[142] J. Qian, Q. Zhu, H. Chen, “Multi-granularity locality-sensitive Bloom\nﬁlter,” IEEE TC, vol. 64, no. 12, pp. 3500-3514, 2015.\n[143] A. Kirsch, M. Mitzenmacher, “Distance-sensitive Bloom ﬁlters,” in\nProc. The Workshop on Algorithm Engineering and Experiments, Miami,\nFlorida, USA, 2006.\n[144] Y . Hua, B. Xiao, B. Veeravalli, D. Feng, “Locality-sensitive Bloom\nﬁlter for approximate membership query,” IEEE TC, vol. 61, no. 6, pp.\n817-830, 2012.\n[145] D. Eppstein, M.T. Goodrich, F. Uyeda, G. Varghese, “What’s the\ndifference?: Efﬁcient set reconciliation without prior context,” in Proc.\nACM SIGCOMM, Toronto, Ontario, Canada, 2011.\n[146] P. Reviriego, S. Pontarelli, J.A. Maestro, M. Ottavi, “A method to\nprotect Bloom ﬁlters from soft errors”, in IEEE DFT, Amherst, MA,\nUSA, 2015.\n[147] A. Sánchez-Macián, P. Reviriego, J.A. Maestro, S. Liu, “Single event\ntransient tolerant Bloom ﬁlter implementations”, IEEE TC, vol. 66, no.\n10, pp. 1831-1836, 2017.\n[148] T. Kraska, A. Beutel, E. Chi, J. Dean, N. Polyzotis, “The case for\nlearned index structures,” in Proc. ACM SIGMOD, Houston, TX, USA,\n2018.\n[149] M. Mitzenmacher, “A model for learned Bloom ﬁlters and related\nstructures,” arXiv preprint, arXiv:1802.00884, 2018.\n[150] B. Fan, D. Andersen, M. Kaminsky, M. Mitzenmacher, “Cuckoo\nﬁlter: practically better than Bloom,” in Proc. ACM CoNEXT, Sydney,\nAustralia, 2014.\n[151] M. Bender, M. Farach-Colton, B. Kuszmaul, B. Kuszmaul, D. Medje-\ndovic, P. Montes, P. Shetty, R. Spillane, E. Zadok, “Don’t thrash: How\nto cache your hash on ﬂash,” in Proc. USENIX HotStorage, Portland,\nOR, USA, 2011.\n[152] D. Eppstein, “Cuckoo ﬁlter: Simpliﬁcation and analysis,” arXiv\npreprint, arXiv:1604.06067, 2016.\n[153] M. Mitzenmacher, S. Pontarelli, P. Reviriego, “Adaptive Cuckoo ﬁl-\nters,” in Proc. SIAM ALENEX, New Orleans, Louisiana, USA, 2018.\n[154] H. Chen, L. Liao, H. Jin, J. Wu, “The dynamic Cuckoo ﬁlter,” in IEEE\nICNP , Toronto, Canada, 2017.[155] L. Luo, D. Guo, O. Rottenstreich, X. Luo, R. T.B. Ma, B. Ren, “The\nconsistent Cuckoo ﬁlter,” in IEEE INFOCOM, Paris, France, 2019.\n[156] P. Pandey, M. Bender, Rob. Johnson, R. Patro, “A general-purpose\ncounting ﬁlter: Making every bit count,” in Proc. ACM SIGMOD,\nChicago, Illinois, USA, 2017\n[157] R. Pagh, F. Rodler, “Cuckoo hashing,” Journal of Algorithms, vol. 51,\nno. 2, pp. 122-144, 2004.\n[158] B. Fan, D. G. Andersen, M. Kaminsky, “MemC3: Compact and\nconcurrent memcache with dumber caching and smarter hashing,” in\nProc. USENIX NSDI, Lombard, IL, USA, 2013.\n[159] D. E. Knuth, “The art of computer programming: Sorting and search-\ning,” vol. 3, Addison Wesley, 1973.\nLailong Luo received his B.S. and M.S. degree at the school of systems\nengineering from National University of Defence Technology, Changsha,\nChina, in 2013 and 2015, respectively. He is currently working toward a Ph.D\ndegree in the school of systems engineering, National University of Defense\nTechnology, Changsha, China. His research interests include probabilisitic\ndata structures and data analysis.\nDeke Guo received his B.S. degree in industry engineering from Beijing\nUniversity of Aeronautic and Astronautic, Beijing, China, in 2001, and\nthe Ph.D. degree in management science and engineering from National\nUniversity of Defense Technology, Changsha, China, in 2008. He is a\nProfessor with the College of Information System and Management, National\nUniversity of Defense Technology, Changsha, China. His research interests\ninclude probabilisitic data structures, software-deﬁned networking, data center\nnetworking, wireless and mobile systems, and interconnection networks. He\nis a member of ACM and IEEE.\nRichard T.B. Ma received the Ph.D. degree in Electrical Engineering in\nMay 2010 from Columbia University, New York. During his Ph.D. study, he\nworked as a research intern at IBM T. J. Watson Research Center, Yorktown\nHeights, NY , USA, and Telefonica Research, Barcelona, Spain. He is currently\na Research Scientist in Advanced Digital Science Center, University of\nIllinois, USA, and an Assistant Professor in School of Computing at National\nUniversity of Singapore. His research interests include distributed systems and\nnetwork economics.\nOri Rottenstreich is an assistant professor at the Department of Computer\nScience and the Department of Electrical Engineering of the Technion, Haifa,\nIsrael. He is also the chief scientist of Orbs. His main research interest\nis computer networks and blockchain technologies. In 2015-2017 he was\na Postdoctoral Research Fellow at the Department of Computer Science,\nPrinceton University. Earlier, he received the BSc in Computer Engineering\n(summa cum laude) and PhD degree from the Technion in 2008 and 2014,\nrespectively.\nXueshan Luo received his B.E. degree in information engineering from\nHuazhong Institute of Technology, Wuhan, China, in 1985, and his M.S. and\nPh.D degrees in system engineering from the National University of Defense\nTechnology, Changsha, China, in 1988 and 1992, respectively. Currently, he is\na professor in the College of Information System and Management, National\nUniversity of Defense Technology. His research interests are in the general\nareas of information system and operation research.",
  "textLength": 240961
}