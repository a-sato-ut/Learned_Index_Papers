{
  "paperId": "7d87910a491c4e53625287a363a39604ea1b1e0e",
  "title": "AdaChain: A Learned Adaptive Blockchain",
  "pdfPath": "7d87910a491c4e53625287a363a39604ea1b1e0e.pdf",
  "text": "AdaChain: A Learned Adaptive Blockchain\nChenyuan Wu\nUniversity of Pennsylvania\nwucy@seas.upenn.eduBhavana Mehta\nUniversity of Pennsylvania\nbhavanam@seas.upenn.eduMohammad Javad Amiri\nUniversity of Pennsylvania\nmjamiri@seas.upenn.edu\nRyan Marcus\nUniversity of Pennsylvania\nrcmarcus@seas.upenn.eduBoon Thau Loo\nUniversity of Pennsylvania\nboonloo@seas.upenn.edu\nABSTRACT\nThis paper presents AdaChain , a learning-based blockchain frame-\nwork that adaptively chooses the best permissioned blockchain\narchitecture to optimize effective throughput for dynamic transac-\ntion workloads. AdaChain addresses the challenge in Blockchain-\nas-a-Service (BaaS) environments, where a large variety of possible\nsmart contracts are deployed with different workload characteris-\ntics. AdaChain supports automatically adapting to an underlying,\ndynamically changing workload through the use of reinforcement\nlearning. When a promising architecture is identified, AdaChain\nswitches from the current architecture to the promising one at\nruntime in a secure and correct manner. Experimentally, we show\nthat AdaChain can converge quickly to optimal architectures under\nchanging workloads and significantly outperform fixed architec-\ntures in terms of the number of successfully committed transactions,\nall while incurring low additional overhead.\nPVLDB Reference Format:\nChenyuan Wu, Bhavana Mehta, Mohammad Javad Amiri, Ryan Marcus,\nand Boon Thau Loo. AdaChain: A Learned Adaptive Blockchain. PVLDB,\n16(8): 2033 - 2046, 2023.\ndoi:10.14778/3594512.3594531\nPVLDB Artifact Availability:\nThe source code, data, and/or other artifacts have been made available at\nhttps://github.com/chenyuanwu/AdaChain.\n1 INTRODUCTION\nPermissioned blockchain systems have enabled a new class of data\ncenter applications, ranging from contact tracing [ 56], crowdwork-\ning [ 14], supply chain assurance [ 15,60], and federated learn-\ning [ 57]. The popularity of these services has motivated cloud\nproviders, e.g., Amazon [ 2,3], IBM [ 8], Oracle [ 9], and Alibaba [ 65],\nto offer Blockchains-as-a-Service (BaaS) [26].\nBaaS offerings have resulted in a large variety of possible smart\ncontract deployments. Different smart contracts may exhibit differ-\nent workload characteristics, such as read/write ratios, skewness\nof popular keys, compute intensity, etc. To address these varia-\ntions in workloads, there has been a proliferation of permissioned\nblockchain systems, e.g., Tendermint [ 46], Fabric [ 16], Fabric++\nThis work is licensed under the Creative Commons BY-NC-ND 4.0 International\nLicense. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of\nthis license. For any use beyond those covered by this license, obtain permission by\nemailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights\nlicensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 16, No. 8 ISSN 2150-8097.\ndoi:10.14778/3594512.3594531[59], Fabric# [ 58], Streamchain [ 39], and ParBlockchain [ 12]. These\nsystems present significant variation in architectural design, includ-\ning the number of transactions in a block, stream processing (with\nno blocks), the use of reordering and early aborts, and the sequence\nin which ordering, execution and validation are done.\nPast studies [ 22,33] have shown that different blockchain ar-\nchitectures and hyperparameter settings are optimal for different\nworkloads with varying properties (e.g. system load, write ratios,\nskewness, and compute intensity). We experimentally confirmed\nthis observation. Figure 1 shows the performance of various archi-\ntectures across four different workloads, showcasing significant\nvariations in throughput. For example, for Workload A1, which is\nhighly compute-intensive, an Execute-Order-Validate (XOV) archi-\ntecture with reordering provides the best throughput. On the other\nhand, for Workload D, which requires significantly less computation\nbut has higher skewness, an Order-Parallel Execute (OXII) archi-\ntecture demonstrates the highest throughput. This clearly shows\nthe dependency between workload characteristics and the optimal\nblockchain architecture for each workload.\nCurrently, BaaS providers must choose a single architecture\nto offer customers, potentially resulting in poor performance, as\nno single architecture provides dominant throughput. Even when\nthe user has control over the blockchain architecture, choosing\nthe right architecture and parameters is not easy given the large\nconfiguration space. Moreover, in a BaaS setting, the workload may\nfluctuate and change, as different tenants scale up or down their\nsmart contracts deployments, and client requests fluctuate with\ndifferent patterns throughout the day. Of course, one could imagine\nbuilding a static mapping from workload characteristics to optimal\nblockchain architectures â€“ but this mapping would (1) be expensive\nto compute, (2) depend on the underlying hardware, (3) still be\nsuboptimal for workloads that shift unexpectedly over time, and\n(4) require recomputing the mapping each time a new blockchain\narchitecture is developed.\nIn this paper, we propose AdaChain , a reinforcement learning-\nbased blockchain framework that chooses the best blockchain ar-\nchitecture and sets appropriate parameters in order to maximize\neffective throughput for dynamic transaction workloads. Experi-\nmentally, we show that AdaChain is not only able to select optimal\nor near-optimal configurations for a wide variety of workloads, but\nits reinforcement learning approach also allows it to quickly adapt\nto new hardware, new storage subsystems, and new unanticipated\nworkload changes on the fly.\n1Details about each workload can be found in Tables 2 and 3.arXiv:2211.01580v2  [cs.CR]  18 Jul 2023\n\nIn order to build an adaptive blockchain, AdaChain relies on two\nkey innovations. First, it models the selection of a blockchain archi-\ntecture as a contextual multi-armed bandit problem, a well-studied\nreinforcement learning problem with asymptotically optimal re-\nsults [ 42]. This formulation allows AdaChain to apply classical\nalgorithms, such as Thompson sampling [ 23], to select blockchain\narchitectures in a way that minimizes regret (the difference between\nthe performance of the chosen architecture and the optimal archi-\ntecture). AdaChain will strategically test different architectures to\nlearn which ones are well-suited to the userâ€™s workload. It learns\nwhich architectures work best by observing the characteristics of\nthe workload and the effective throughput of the system. When the\nworkload changes, AdaChain notices drops in throughput, and can\nautomatically adjust the blockchain architecture and parameters to\nmaximize performance, all without any user intervention.\nSecond, AdaChain introduces protocols to switch from one block-\nchain architecture to another in a live system, while maintaining\nstrong serializability properties. This switching protocol is not only\nrequired for AdaChain to function (multi-armed bandits generally\nrequire making multiple decisions before the optimal is reached),\nbut also enables a new class of blockchains that can more-or-less\nseamlessly transition between different architectures to support\nthe shifting workloads in the real-world. Intuitively, the switching\nprotocol works by splitting switching decisions between two paths.\nIn the normal path, all nodes agree to switch to the same new\narchitecture after a certain number of blocks have been committed,\nwhile in the slow path, all nodes switch to the same architecture\nafter failing to make progress on processing transactions for a\ncertain amount of time.\nSpecifically, this paper makes the following contributions.\nâ€¢Learned adaptive blockchain. To the best of our knowledge,\nAdaChain is the first blockchain system to support automat-\nically adapting to an underlying, dynamic workload . Through\ncareful modeling of the states, actions, and objective function,\nAdaChainâ€™s use of reinforcement learning makes it the first\nblockchain system to learn from its mistakes and self-correct.\nâ€¢Multi-architecture switching. Additionally, we also present\nthe first blockchain system capable of switching from one archi-\ntecture to another at runtime while respecting correctness and\nsecurity concerns.\nâ€¢Analysis of architectural impact on blockchain perfor-\nmance. Through a suite of workload parameters, we perform a\nlarge-scale measurement examining the relationship between ar-\nchitecture choice and blockchain performance. Our experiments\nhighlight the large state space, which renders manual heuristics\ndifficult to achieve.\nâ€¢Prototype and performance evaluation. We have developed\na prototype of AdaChain. Our evaluation results on CloubLab\ndemonstrate that AdaChain can converge quickly to optimal ar-\nchitectures under changing workloads, significantly outperform\nexisting fixed architectures, and incur low additional overhead.\n2 ARCHITECTURE LANDSCAPE\nTo motivate AdaChain, we first examine, both intuitively and exper-\nimentally, why different blockchain architectures perform diversely\nacross different workloads. In Section 2.1, we highlight a number of\nFigure 1: Performance of different blockchain architectures\nunder various workloads. The performance of different ar-\nchitectures can vary significantly between workloads. Work-\nloads and architectures are described in Table 1 and 2.\nblockchain architectures, and illustrate their advantages and disad-\nvantages. The point here is not that some blockchain architectures\nare always â€œbetterâ€ or â€œworseâ€ than others, but rather that each\nblockchain architecture performs well under some conditions and\npoorly under others. In Section 2.2, we argue that a blockchain\nthat can adaptively switch between multiple architectures is able\nto achieve â€œbest of all worldsâ€ performance.\n2.1 Blockchain Architectures and Workloads\nTable 1 lists representative blockchain systems and their architec-\ntures, where the design space consists of seven performance opti-\nmizations (P1-P7) and two correctness dimensions (C1-C2). Figure 1\nshows their performance under four different workloads. Here, we\nuseeffective throughput as the performance metric, i.e., the number\nof successfully committed transactions per second.\nThe workloads AtoDare characterized in Table 2. BaaS work-\nloads embody a large extent of variations. For instance, different\ntransactions might invoke different percentages of write operations\nto the underlying key-value store, as represented by the write ratio .\nThese transactions might also contend to access or update the same\nset of popular keys (or hot keys), as indicated by the contention\nlevel. In addition, the runtime load on a BaaS can be determined by\nthe frequency of issued transactions by each client and the num-\nber of active clients varying with time. Last, compute intensity is\nan important characterization of BaaS workloads, as pointed out\nby [36,58,64]. This is because permissioned blockchains support a\nwide range of applications, some of which are compute-intensive\n(e.g., those that provide security and correctness guarantees for\nmachine learning applications).\nBelow, we briefly describe the design principles of each architec-\nture and explain the intuition behind why the performance of each\narchitecture can vary under different workloads.\nOrder-Execute (OX). The order-execute architecture has been\nwidely used in permissioned blockchain systems such as Tender-\nmint [ 46], Quorum [ 24], Chain Core [ 4], Multichain [ 37], Hyper-\nledger Iroha [ 7], and Corda [ 5]. In the OX architecture, transactions\n\nTable 1: Comparing design principles of existing permissioned blockchain architectures. Here, P stands for performance, C\nstands for correctness, X stands for execution, O stands for ordering, and V stands for validation.\nArchitecture Rep. System P1. Block Size P2. Early Exec. P3. Dependency Graph P4. Early Abort P5. Cross-Block Conflicts P6. Parallel Exec. C1. MVCC C2. Isolation\nOX Tendermint [46] tunable % % % - % % strong serializable\nOXII ParBlockchain [12] tunable % ! % - partial % strong serializable\nXOV Fabric [16] tunable ! % % V fully ! strong serializable\nXOV++ Fabric++ [59] tunable ! ! X, O V fully ! strong serializable\nXOV# Fabric# [58] tunable ! ! O O fully % serializable\nXOV StreamChain [39] 1 ! % % V fully ! strong serializable\nTable 2: Characterizing workloads A, B, C and D. Specific\nworkload parameters are presented in Table 3.\nWorkload Write Ratio Contention Level Load Compute Intensity\nA low high high high\nB moderate high moderate low\nC moderate low high very high\nD high very high moderate very low\nare totally ordered and batched into blocks and then transactions of\na block are executed sequentially. As a result, the OX architecture\ndoes not require a Multi-version Concurrency Control (MVCC)\nvalidation phase, which is used to resolve conflicts between trans-\nactions, and hence, no transactions will be aborted due to conflicts.\nAs shown in Figure 1, this design principle makes OX outstanding\nat workload D, where transactions are write-heavy and contentious,\ni.e., transactions update a small set of hot keys. On the other hand,\nOX performs comparatively poorly on workloads AandC, which\nare compute-intensive. Due to the lack of parallel execution mech-\nanisms, OX cannot take advantage of the multi-core processing\npower of modern servers.\nOrder-Parallel Execute (OXII). In the OXII architecture, used\nby ParBlockchain [ 12], transactions are first totally ordered and\nbatched into blocks. OXII then constructs a dependency graph for\ntransactions within a block based on their positions. Specifically, if\nğ‘¡ğ‘–is ordered before ğ‘¡ğ‘—, and the pair of transactions are conflicting,\nOXII adds an edge from ğ‘¡ğ‘–toğ‘¡ğ‘—. This dependency graph is then\nused to execute transactions in parallel, i.e., a transaction can be\nexecuted once all its predecessors have finished execution. Given\na higher level of execution parallelism than OX, OXII performs\nbetter than OX under computation-heavy workloads such as Aand\nC. Note that even for a given workload, OXII requires careful tuning\nof block size; a large block results in high overhead in dependency\ngraph construction, while a small block results in less parallelism\nand higher communication overhead.\nExecute-Order-Validate (XOV). Hyperledger Fabric [ 16] presents\nthe XOV architecture (which was first introduced by Eve [ 41] in\nthe context of Byzantine fault-tolerant SMR) by switching the order\nof the ordering and execution phases such that transactions are\nsimulated fully in parallel before being ordered in the ordering\nphase. Since it utilizes early execution, XOV requires an MVCC\nvalidation phase to invalidate all transactions that are simulated on\nstale data, and commits only the validated transactions to the world-\nstate and the blockchain ledger. This early execution enables XOV to\nperform well on contention-free workloads such as C. On the other\nhand, XOV demonstrates poor performance under contentious and\nwrite-heavy workloads, such as BandD, due to the high percentage\nof invalidated transactions. Similarly, as network delay increases,XOV suffers from inconsistent world states among peers as well as\nstale reads, and thus significantly degraded performance [22].\nXOV with early abort and reordering (XOV++). The XOV++\narchitecture, as introduced in Fabric++ [ 59], follows the XOV par-\nadigm but with some modifications. First, a dependency graph is\nconstructed in the ordering phase to capture RW conflicts between\neach pair of transactions within the same block. When the graph is\nconstructed, all elementary cycles in the graph are aborted greed-\nily. Unlike OXII, which utilizes the graph for concurrency control,\nXOV++ uses the graph for transaction reordering; when there is a\nRW conflict between ğ‘¡ğ‘–andğ‘¡ğ‘—, it (re)orders ğ‘¡ğ‘–beforeğ‘¡ğ‘—in the block.\nSecond, it adopts early abort techniques in both the simulation\nand ordering phases. Whenever XOV++ detects that a transaction\noperates on stale data, XOV++ immediately aborts that transac-\ntion without waiting for the final MVCC validation. As an effect of\ntransaction reordering, XOV++ has outstanding performance on\nworkload A, where the conflicts are reconcilable given a low write\nratio. On the other hand, XOV++ performs poorly on workload\nDwith a near-zero effective throughput. This is because, under a\ncontentious and update-heavy workload, very few conflicts can\nbe reconciled through reordering. Moreover, reordering becomes\nmore expensive when there are a large number of cycles in the de-\npendency graph, resulting in more pending blocks and, thus, more\ntransactions that simulate on stale data.\nXOV with serializable isolation (XOV#). The XOV# architecture,\npresented in Fabric# [ 58], is mainly different from XOV and XOV++\nin that XOV# is serializable, while XOV and XOV++ are strong\nserializable. To achieve this isolation level, XOV# incrementally\nconstructs a dependency graph that keeps track of all dependencies,\nincluding those that span across blocks in the ordering phase. Once\na transaction is ordered, XOV# immediately drops this transaction\nif there is a dependency cycle involved. The resulting acyclic sched-\nule is guaranteed to be serializable, thus, no extra MVCC validation\nis needed in XOV#. To ensure a fair comparison with other archi-\ntectures, we run XOV# under the strong serializability isolation\nlevel while keeping the remaining design dimensions the same as\nthe original XOV# (the XOV+reorder+block_pipelining bar). XOV#\nperforms worse than vanilla XOV in all workloads AtoDdue to the\noverhead of maintaining a large dependency graph and detecting\ncycles. This suggests that the performance improvement reported\nin Fabric# is mainly due to a more relaxed isolation level.\nStream XOV. StreamChain [ 39] switches from block processing to\nstream transaction processing. Specifically, StreamChain follows\nthe XOV paradigm while fixing the block size to 1. The motivation\nbehind stream processing is simple: while the original, permission-\nless blockchains were forced to used proof of work (PoW) consensus\n\ntechniques to maintain fault tolerance, a permissioned blockchain\nenvironment allows more efficient consensus protocols to be used.\nThus, stream processing can reduce transaction latency. In terms\nof effective throughput, StreamChain has relatively good perfor-\nmance when the workload is lightweight or not contentious, such\nas in workloads BandC. Otherwise, the high block construction\noverhead in terms of cryptographic operations and excessive disk\nI/Os leads to a large number of pending blocks in StreamChain,\nmaking incoming transactions simulate on stale data. As expected,\nStreamChain is more sensitive to the type of storage hardware\nused than OX: the system have poor performance without RAM\ndisk [ 22]. StreamChain also highlights that the parameters of a\ngiven architecture can impact performance. A large block size leads\nto higher block formation overhead and latency, while a small block\nsize results in higher communication and disk overhead.\n2.2 The Case for Reinforcement Learning\nThe previous subsection demonstrates that depending on workload\nand hardware characteristics, the performance of a given blockchain\narchitecture can vary drastically. We thus argue that there is no one-\nsize-fits-all architecture.\nOne may consider the design of simple heuristics to map work-\nload characteristics and hardware features to the optimal blockchain\narchitecture. However, designing a good heuristic is difficult and\ncumbersome in the case of permissioned blockchains. For example,\nHyperledger Fabric [ 16] has proposed that â€œwhen the contention\nlevel is high, use OX; otherwise, use XOVâ€. Unfortunately, such a\nsimple heuristic leads to wrong decisions in 50%of our recorded\ntraces, let alone in a real BaaS production environment.\nThis suggests, to develop a good heuristic, an expert needs to\nexhaustively experiment over the entire state and action space\nto understand the intricate interactions. The expert also needs to\ncarefully tune the specific threshold parameters that distinguish\nâ€œvery high contentionâ€ from â€œhigh contentionâ€, or â€œlow write ratioâ€\nfrom â€œmoderate write ratioâ€, etc. Given the large space of workload\n(i.e., write ratio, contention level, load, compute intensity) and\nhardware (i.e., CPU, RAM, disk, network) features, if the expert\ndiscretizes each dimension by uniformly sampling 5 points in it\nand tests each architecture for 5 seconds, it takes at least 90 days\nto conduct the experiments even when the effect of block size is\nignored. This is a conservative estimate given that most dimensions\nwill require more than 5 sample points in practice. Due to the lack of\nblockchain simulators that capture the variations in architectures,\nsuch experiments are hard to be conducted in parallel. Moreover,\nsuch heuristics become outdated when new hardware or blockchain\narchitectures are introduced in the BaaS and hence, difficult for the\nexpert to keep up with these changes. For instance, when the BaaS\nprovider introduces non-volatile RAM [ 61] to replace the traditional\ncombination of volatile RAM and disk, or when BaaS transitions\nto disaggregated architecture [ 64] where there is extra latency for\naccessing memory, new hardware features are also introduced.\nReinforcement learning (RL) is an ideal solution to this Sisyphean\ntask, which has shown superior performance in other learned sys-\ntems [ 51,52]. Unlike supervised learning that assumes training\ndata is complete and requires a separate data collection process\nprior to deployment, RL-based system learns from its mistakes and\nFigure 2: Architecture of AdaChain. For readability, we only\npresent the internals of server 1.\noptimizes long term rewards through its trials. With reinforcement\nlearning, AdaChain can optimize itself to whatever workloads, hard-\nware and blockchain architectures at hand, providing significant\noperational benefits .\n3 ADACHAIN OVERVIEW\nAt a high level, AdaChain contains two key components: a ma-\nchine learning model (the learning agent ) which guides AdaChain\ntowards better and better blockchain architectures, and an architec-\nture switching mechanism that allows AdaChain to near-seamlessly\ntransition from one blockchain architecture to another while en-\nsuring correctness and security.\nLearning agent. AdaChainâ€™s learning agent models the problem\nof selecting a blockchain architecture as a contextual multi-armed\nbandit (CMAB) problem [ 66]: periodically, AdaChain examines the\nmost recent properties of the workload ( context ), and then selects\none of many blockchain architectures ( arms ). After making the\nselection, it observes the effective throughput of the newly selected\narchitecture ( reward ). To be successful, AdaChain must balance\ntheexploration of new, untested architectures with exploiting past\nexperience to maximize throughput â€“ without a careful balance of\nexploration and exploitation, AdaChain risks failing to discover an\noptimal configuration (too much exploitation), or performing no\nbetter than random (too much exploration). We select this CMAB\nformulation (as opposed to generalized reinforcement learning\nmodels) because CMABs are exceptionally well-studied, and many\nasymptotically-optimal algorithms exist to solve them [ 10,23]. De-\ntails about the learning agent are provided in Section 4.\nSwitching architecture. AdaChain utilizes a switching protocol\nthat allows it to switch from one blockchain architecture to another\nin a distributed fashion across all nodes in the blockchain deploy-\nment, while transactions are ongoing. AdaChain achieves this by\nsplitting switching decisions between two paths, a normal path\nin which all nodes agree to switch to the same new architecture\nafter a certain number of blocks have been committed, and a slow\npath in which all nodes switch to the same new architecture after\nfailing to make progress for a certain amount of time. Details about\nAdaChainâ€™s switching protocol are in Section 5.\nAdaChain workflow overview. Figure 2 shows the overall archi-\ntecture of AdaChain. AdaChain operates in episodes , where within\none episode, the blockchain architecture remains unchanged. When\nthe learning agent finds an architecture candidate, it instructs the\n\npeer to use that architecture for the next episode. Each episode is\nmarked by the completion of a constant number of transactions\n(Î”ğ‘episode ), including invalidated transactions. This episode design\nensures AdaChain does not stuck in a bad architecture for a long\ntime even when the fraction of invalidated transactions is high\ndue to conflicts. Below, we describe how the learning agent pro-\nposes the architecture for episode ğ‘›+1in detailed steps. Although\nour discussion below focuses on the internals of server 1, the same\nprocedure happens simultaneously on every blockchain server.\nStep 1: Notifying the learning agent. In episodeğ‘›, the peer noti-\nfies its local learning agent when the number of committed blocks\nhas reached a certain watermark. The notification also includes the\nlocal performance measurement ğ‘Ÿğ‘›in episodeğ‘›.\nStep 2: Featurization. Since learning agents are distributed across\ndifferent servers, the state (i.e., some features that capture the work-\nload) that they need in order to make a decision should also be\ndistributed. In AdaChain, states are not only distributed, but also\ndecentralized as no single entity controls the state. This is possible\nwith negligible overhead due to two key insights: (1) the blockchain\nledger contains rich information about the workload, and thus is a\ngood source of raw data for featurization; (2) the ledger is naturally\ndecentralized and consistent across peers. Thus, once the agent\nis notified by the peer, its featurizer extracts the state ğ‘ ğ‘›+1from\nblocks committed in episode ğ‘›. Details are described in Section 4.2.\nStep 3: Exchanging performance measurements. The locally\nobserved performance is different across different peers, and mali-\ncious peers could even manipulate its local measurement. To ensure\neach honest server has the same architecture for episode ğ‘›+1, the\nlearning agent on server 1exchanges the local measurement ğ‘Ÿğ‘›with\nlearning agents on every other server, so as to agree on performance\nmeasurement. Details are described in Section 5 and 6.\nStep 4: Estimating the performance for each architecture. The\npredictive model ğ‘€ğœƒpredicts the performance of each architecture\ncandidate under state ğ‘ ğ‘›+1, and selects architecture ğ‘ğ‘›+1that is\npredicted to have the best performance. The learning agent then\ninforms the peer to switch to ğ‘ğ‘›+1for episodeğ‘›+1.\nStep 5: Building experience buffer. Once anğ‘Ÿğ‘›is obtained, the\nlearning agent adds the (ğ‘ ğ‘›,ğ‘ğ‘›,ğ‘Ÿğ‘›)triplet to the experience buffer.\nNote thatğ‘ ğ‘›andğ‘ğ‘›are derived prior to the start of episode ğ‘›.\nStep 6: Retraining. The predictive model ğ‘€ğœƒis periodically re-\ntrained based on the experience buffer, creating a feedback loop.\nAs a result, AdaChainâ€™s predictive model improves, and AdaChain\nmore reliably picks the best architecture for the observed state.\nAssumptions. In short, AdaChain can adapt itself according to the\nworkload and hardware setup to continually improve performance.\nMoreover, AdaChain is an online learned system that does not\nrequire a separate and cumbersome data collection process prior to\ndeployment. Our current design makes two assumptions. First, in\nAdaChain, similar to many other permissioned blockchain systems\n[13,24,46], each node serves as both the ordering and execution\n(endorser) node. This, however, is in contrast to Hyperledger Fabric\nand its variants that separate endorsing and ordering roles. Second,\nAdaChain is designed for a homogeneous setup, where different\nservers have access to similar resources. While having these twoassumptions in place simplifies the system design, they have been\nused in real-world BaaS deployments.\n4 LEARNING ALGORITHMS\nIn this section, we discuss AdaChainâ€™s learning approach in detail.\nWe first formalize AdaChainâ€™s learning problem as a contextual\nmulti-armed bandit problem, and then discuss our selected algo-\nrithm, Thompson sampling, for solving such problems. We next\ndescribe the predictive model used by AdaChain, followed by the\nspecific state and action space design.\nContextual multi-armed bandits (CMABs). In a contextual\nmulti-armed bandit problem, an agent periodically makes deci-\nsions in a number of episodes, enumerated by ğ‘›. In each episode,\nthe agent selects an action ğ‘ğ‘›based on a provided state ğ‘ ğ‘›, and then\nreceives a reward ğ‘Ÿğ‘›. The agentâ€™s goal is to select actions in a way\nthat minimizes regret , i.e., the difference between the reward from\nthe chosen action and the reward from the optimal action. CMABs\nassume that each episode is independent2from each other, and that\nthe optimal decision depends only on the state ğ‘ ğ‘›. As described\nin Section 3 and 5, in order to be responsive to workload changes,\nthere are no pending blocks across different episodes in AdaChain.\nThus, each episode in AdaChain can also be considered to be in-\ndependent (although caching effects may bring a small amount of\ndependence between episodes).\nAdaChainâ€™s formulation. AdaChain uses effective throughput\nas the performance metric ğ‘ƒto maximize, which is the number of\nsuccessfully committed transactions per second. For each episode,\nit must select an architecture to use. AdaChainâ€™s goal is to select\nthe best architecture (in terms of effective throughput) in the family\nof available architectures ğ´, given the current perceived workload\nğ‘¤âˆˆğ‘Š. We call this selection function ğ‘†:ğ‘Šâ†’ğ´. We formalize\nthe goal as a regret minimization problem, where the regret ğ‘Ÿğ‘›\nfor an episode ğ‘›is defined as the difference between the effective\nthroughput of the architecture selected by AdaChain and the ideally\noptimal architecture as presented in equation 1.\nğ‘Ÿğ‘›=max\nğ‘âˆˆğ´ğ‘ƒ(ğ‘¤,ğ‘)âˆ’ğ‘ƒ(ğ‘¤,ğ‘†(ğ‘¤)) (1)\nWe use effective throughput as the performance metric since it is\nthe dominant metric used by blockchain benchmark tools [ 6,29,36]\nand previous literatures that proposed fixed architectures [ 12,16,\n58,59]. Extending the optimization goal to a combination of metrics\nis left for future work.\nThompson sampling. While there are many algorithms to solve\ncontextual multi-armed bandit problems, we select Thompson sam-\npling for its simplicity: at the start of each episode, we train a model\nbased on our current experience, and then select the best action\nas predicted by the model. In order to train the model, Thompson\nsampling deviates from traditional ML techniques: instead of select-\ning the model parameters that are most likely given the data, we\nsample model parameters proportionally to their likelihood given the\ntraining data . More formally, we can define maximum likelihood\nestimation as finding the model parameters ğœƒthat maximize likeli-\nhood given experience ğ¸:arg maxğœƒğ‘ƒ(ğœƒ|ğ¸)(assuming a uniform\n2Contextual multi-armed bandit algorithms have been shown to be effective even\nwhen these condition do not strictly hold [23].\n\nprior). Instead of maximizing likelihood, Thompson sampling sim-\nply samples from the distribution ğ‘ƒ(ğœƒ|ğ¸). This means that if we\nhave a lot of data suggesting that our model weights should be in\na certain part of the parameter space, our sampled parameters are\nlikely to be in the part of the space. Conversely, if we have only a\nsmall amount of data suggesting that our model weights should be\nin a certain part of the parameter space, we may or may not sample\nparameters in that part of the space during any given episode.\n4.1 Predictive Model\nAdaChain uses random forests [ 18] as the predictive model due\nto their good performance on data sets of moderate sizes and fast\ninference. The model takes the state (i.e., workload) concatenated\nwith action (i.e., architecture choice) as input, and outputs the\npredicted performance.3Thus, given a state, AdaChain enumerates\nthe action space and uses the model to predict the performance\nof each action. AdaChain then chooses the action with the best-\npredicted performance to be carried out. Once there is a tie on the\nbest-predicted performance, AdaChain breaks the tie randomly to\navoid local maxima.\nIntegrating random forests with Thompson sampling requires\nthe ability to sample model parameters from ğ‘ƒ(ğœƒ|ğ¸). The simplest\ntechnique (which has been shown to work well in practice [ 54]) is to\ntrain the model as usual, but only on a bootstrap [ 17] of the training\ndata. In other words, the random forest is trained using |ğ¸|random\nsamples drawn with replacement from experience ğ¸, inducing the\ndesired sampling properties. AdaChain uses this bootstrapping\ntechnique for its simplicity.\n4.2 State Space\nIn AdaChain, the state represents properties of the client workload.\nAdaChain captures the state space using the four features below. To\nensure the accuracy of feature extraction, all aborted or invalidated\ntransactions are still written to the ledger with a validity flag (similar\nto [38]). Below, we assume a window of blocks ğ‘ğ‘–toğ‘ğ‘—in the ledger\nare read by the learning agent for featurizing the current state.\nWrite ratio. We observe that counting the write ratio in terms of\nwrite accesses to the key-value store is not effective for predicting\nperformance. Thus, AdaChain measures the write ratio at the trans-\naction level: once a transaction writes to the key-value store, it is\nviewed as a write transaction. The write ratio is the ratio of write\ntransactions to the number of all transactions during ğ‘ğ‘–andğ‘ğ‘—.\nHotkeyratio. AdaChain measures the frequency that each key is\naccessed during ğ‘ğ‘–andğ‘ğ‘—. It then takes the frequency corresponding\nto the hottest key to be the hot key ratio.\nTransaction arrival rate. AdaChain timestamps each transaction\nupon its first arrival to the system. AdaChain first measures the\nnumber of all transactions from ğ‘ğ‘–toğ‘ğ‘—, denoted as ğ‘, and then\nderives the transaction arrival rate usingğ‘\nğ‘¡ğ‘ ğ‘—âˆ’ğ‘¡ğ‘ ğ‘–, whereğ‘¡ğ‘ ğ‘–repre-\nsents the arrival timestamp of the first transaction in ğ‘ğ‘–andğ‘¡ğ‘ ğ‘—\nrepresents that of the last transaction in ğ‘ğ‘—.\nExecution delay. AdaChain uses average execution delay of all trans-\nactions in the period of ğ‘ğ‘–toğ‘ğ‘—.\n3This corresponds to a value based model . Apolicy model, in which the predictive\nmodel predicts simultaneously the probability of each action being optimal, might be\nan interesting direction for future work.4.3 Action Space\nIn AdaChain, the action space consists of different blockchain ar-\nchitectures. One naÃ¯ve approach to represent the action space is\nto give each architecture a one-hot encoding. However, from the\nrandom forestâ€™s perspective, this approach makes two semantically\nclose architectures totally unrelated, resulting in ineffective splits,\nand thus poor prediction accuracy. For example, assume XOV is\nrepresented by vector (1,0,...,0)in the one-hot encoding. Random\nforest might split on the first dimension in the vector, i.e., XOV is its\nleft child, while everything non-XOV is its right child. Each childâ€™s\nperformance will be predicted using the average performance of\nthat child. Clearly, XOV++ and StreamChain might have a relatively\nclose performance to XOV, but they will always fall into a wrong\nchild node and their predicted performances are wrongly averaged.\nThus, AdaChain chooses to first featurize the blockchain architec-\ntures to maintain the semantic information of their design. Feature\nengineering an optimal representation of blockchain architectures\nis a difficult and inexact task. Instead of attempting to design an\nall-encompassing representation that captures every dimension of\nblockchain architectures, we instead selected a simple representa-\ntion based on our intuition of the most important properties. We\nleave investigating alternative representations to future work.\nAdaChain therefore captures the action space using three main\nfeatures: block size, early (speculative) execution, and dependency\ngraph construction. Block size is a scalar variable, representing the\nnumber of transactions within a block. The block size in AdaChain\nis also equal to the batch size in the consensus protocol. To limit the\ngrowth of action space, the block size can not exceed 1,000, which\nis larger than typical block sizes used in blockchain systems, and\nwe further discretize the block size using paces. Early execution and\ndependency graph construction are both binary variables. Thus,\nAdaChainâ€™s action space consists of 100choices in total.\nWe do not consider parallel execution as a feature because it can\nbe derived from the two previous features (i.e., early execution and\ndependency graph construction): (1) early execution of transactions\nhappens fully in parallel; (2) the goal of constructing a dependency\ngraph is to execute independent transactions in parallel.\n5 SWITCHING ARCHITECTURES\nThis section discusses the architecture switching mechanism of\nAdaChain. We first introduce the normal path of operations, fol-\nlowed by our timeout-based mechanism in the slow path.\n5.1 Normal Path\nAlgorithm 1 presents the normal path of operations. Each server\nin AdaChain runs Algorithm 1 in a distributed fashion in order to\ncarry out architecture switching. Here, ğ‘†is the set of blockchain\nservers,ğ‘–stands for the index of the server, ğ‘›stands for the current\nepisode, and Î”ğ‘episode andÎ”ğ‘learn are two constant hyperparame-\nters. At a high level, the normal path introduces two watermarks: a\nlow watermark ( ğ‘Šğ‘›\nğ¿) that triggers the learning phase, and a high\nwatermark ( ğ‘Šğ‘›\nğ») that marks the end of an episode.\nThe untrustworthiness of participants in a blockchain system\nprevents us from relying on a centralized entity to featurize the\nstate and measure the reward. Thus, inspired by the PBFT proto-\ncol [20], AdaChain conducts them in a decentralized fashion. Upon\n\nAlgorithm 1 Normal path\nâ–·On each server ğ‘–\n1:Upon index of local last committed block ğ‘lastreachingğ‘Šğ‘›\nğ¿\n2: Record performance ğ‘ğ‘›\nğ‘–\n3: Extract features ğ‘“ğ‘›+1\nğ‘–=(ğ‘¤ğ‘›+1\nğ‘–,ğ‘ğ‘›+1\nğ‘–,ğ‘Ÿğ‘›+1\nğ‘–,ğ‘’ğ‘›+1\nğ‘–)from blockğ‘Šğ‘›âˆ’1\nğ»toğ‘Šğ‘›\nğ¿\n4: MulticastâŸ¨CHECKPOINT ,ğ‘›,ğ‘–,ğ‘’ğ‘›+1\nğ‘–,ğ‘ğ‘›\nğ‘–âŸ©ğœğ‘–to all servers\nâ–·On the leader sever ğ‘™\n5:Upon receiving valid CHECKPOINT messages from a quorum Qof2ğ‘“+1servers\n6: Compute ğ‘’ğ‘›+1â†median{ğ‘’ğ‘›+1\nğ‘—|ğ‘—âˆˆQ}\n7: Compute ğ‘ğ‘›â†median{ğ‘ğ‘›\nğ‘—|ğ‘—âˆˆQ}\n8: MulticastâŸ¨âŸ¨PROPOSE,ğ‘’ğ‘›+1,ğ‘ğ‘›âŸ©ğœğ‘™,CâŸ©to all servers\nâ–·On each server ğ‘–\n9:Upon receiving aPROPOSE message from the leader\n10: ifğ‘’ğ‘›+1andğ‘ğ‘›are valid (based onC)then\n11: MulticastâŸ¨ACCEPT,ğ‘›,ğ‘–,ğ‘’ğ‘›+1,ğ‘ğ‘›âŸ©ğœğ‘–to all servers\n12:Upon receiving valid matching ACCEPT messages from 2ğ‘“+1different servers\n13: MulticastâŸ¨COMMIT,ğ‘›,ğ‘–,ğ‘’ğ‘›+1,ğ‘ğ‘›âŸ©ğœğ‘–to all servers\n14:Upon receiving valid matching COMMIT messages from 2ğ‘“+1different servers\n15: Addğ‘ğ‘›to experience and derive action ğ‘ğ‘›+1based onğ‘“ğ‘›+1\n16:ifğ‘‡ğ‘›transactions have been committed then\n17: Abort any new incoming transaction ğ‘¡in the ordering phase\n18:Uponğ‘lastreachingğ‘Šğ‘›\nğ»\n19: Pause block formation thread until action ğ‘ğ‘›+1is derived\n20:ğ‘Šğ‘›+1\nğ¿â†ğ‘Šğ‘›\nğ»+âŒŠÎ”ğ‘learn/|ğ‘ğ‘›+1|âŒ‹\n21:ğ‘Šğ‘›+1\nğ»â†ğ‘Šğ‘›\nğ»+âŒŠÎ”ğ‘episode/|ğ‘ğ‘›+1|âŒ‹\n22:ğ‘‡ğ‘›+1â†ğ‘‡ğ‘›+âŒŠÎ”ğ‘episode/|ğ‘ğ‘›+1|âŒ‹Ã—|ğ‘ğ‘›+1|\n23:ğ‘›â†ğ‘›+1\n24: Carry out action ğ‘ğ‘›+1\n25: Reset timer ğœ\nreaching the low watermark ğ‘Šğ‘›\nğ¿, each server ğ‘–âˆˆğ‘†records its lo-\ncally observed throughput ğ‘ğ‘›\nğ‘–of episodeğ‘›and featurizes the state\nfor the next episode ğ‘›+1from its local blockchain ledger (lines\n1-3). Although most dimensions of the state are naturally consis-\ntent across different servers, there can be slight variations on the\nexecution delay, ğ‘’ğ‘›+1\nğ‘–, and measured throughput. Thus, each server\nğ‘–multicasts a checkpoint message consisting of ğ‘’ğ‘›+1\nğ‘–andğ‘ğ‘›\nğ‘–to all\nother servers (line 4). AdaChain relies on the leader server to (1)\ncollect a quorum Qof2ğ‘“+1checkpoint messages, (2) calculate the\nmedian of observed throughput values to be the global reward ğ‘ğ‘›,\nand (3) calculate the median of the execution delay values ğ‘’ğ‘›+1to be\npart of the global state (lines 5-7). Once both values are computed,\nthe leader multicasts a propose message, including the values and\nthe setCof2ğ‘“+1received checkpoint messages to all servers (line\n8). Upon receiving the propose message, each server validates the\nmessage according to the set Cand multicasts an accept message\nto all other servers (lines 9-11). Each server then waits for 2ğ‘“+1\nmatching accept messages before sending a commit message (lines\n12-13). The accept andcommit phases, similar to prepare andcom-\nmitphases of PBFT, ensure that values are correct and replicated\non a sufficient number of nodes. Finally, when a server receives\n2ğ‘“+1commit messages, the predictive model will derive action\nğ‘ğ‘›+1as described in Section 4 (lines 14-15). Note that since accept\nandcommit messages are broadcast to all servers, even if a server\nhas not received the propose message from the leader (due to the\nasynchronous nature of the network or the maliciousness of the\nleader), the server still has access to the values.\nIn order to be responsive to workload changes, each episode\nis marked by the completion of âŒŠÎ”ğ‘episode/|ğ‘ğ‘›|âŒ‹blocks, where\nÎ”ğ‘episode is a constant hyperparameter of the system ( 10,000trans-\nactions in the current deployment) and |ğ‘ğ‘›|denotes the block size in\nepisodeğ‘›. As a result, each episode processes âŒŠÎ”ğ‘episode/|ğ‘ğ‘›|âŒ‹Ã—|ğ‘ğ‘›|Algorithm 2 Slow path\nâ–·On each server ğ‘–\n1:iftimerğœtimeouts and ğ‘lasthas not reached ğ‘Šğ‘›\nğ¿then\n2: pause block formation thread after committing the current block\n3: Record performance ğ‘ğ‘›\nğ‘–\n4: MulticastâŸ¨S-CHECKPOINT ,ğ‘›,ğ‘–,ğ‘ğ‘›\nlast,ğ‘–âŸ©ğœğ‘–to all servers\nâ–·On each server ğ‘—whereğœhas not been expired\n5:Upon receiving ğ‘“+1valid S-CHECKPOINT messages from different servers\n6: pause block formation thread after committing the current block\n7: Record performance ğ‘ğ‘›\nğ‘—\n8: MulticastâŸ¨S-CHECKPOINT ,ğ‘›,ğ‘—,ğ‘ğ‘›\nlast,ğ‘—âŸ©ğœğ‘—to all servers\nâ–·On the leader sever ğ‘™\n9:Upon receiving valid S-CHECKPOINT messages from a quorum Qof2ğ‘“+1\nservers\n10: Compute ğ‘Šğ‘›\nğ»â†max{ğ‘ğ‘›\nlast,ğ‘—|ğ‘—âˆˆQ}\n11: MulticastâŸ¨âŸ¨S-PROPOSE,ğ‘Šğ‘›\nğ»âŸ©ğœğ‘™,Câ€²âŸ©to all servers\nâ–·On each server ğ‘–\n12:Upon receiving aS-PROPOSE message from the leader\n13: ifğ‘Šğ‘›\nğ»is valid (based onCâ€²)then\n14: MulticastâŸ¨S-ACCEPT,ğ‘›,ğ‘–,ğ‘Šğ‘›\nğ»âŸ©ğœğ‘–to all servers\n15:Upon receiving valid matching S-ACCEPT from 2ğ‘“+1different servers\n16: MulticastâŸ¨S-COMMIT,ğ‘›,ğ‘–,ğ‘Šğ‘›\nğ»âŸ©ğœğ‘–to all servers\n17:Upon receiving valid matching S-COMMIT from 2ğ‘“+1different servers\n18: Resume block formation thread\n19: Extract features ğ‘“ğ‘›+1\nğ‘–=(ğ‘¤ğ‘›+1\nğ‘–,ğ‘ğ‘›+1\nğ‘–,ğ‘Ÿğ‘›+1\nğ‘–,ğ‘’ğ‘›+1\nğ‘–)from blockğ‘Šğ‘›âˆ’1\nğ»toğ‘last\n20: MulticastâŸ¨CHECKPOINT ,ğ‘›,ğ‘–,ğ‘“ğ‘›+1\nğ‘–,ğ‘ğ‘›\nğ‘–âŸ©ğœğ‘–to all servers\nâ–·On the leader sever ğ‘™\n21:forevery transaction ğ‘¡in the ordering phase do\n22:ğ‘¡.ğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’â†ğ‘›\nâ–·On each server ğ‘–\n23:forevery transaction ğ‘¡committed by consensus do\n24: ifğ‘¡.ğ‘’ğ‘ğ‘–ğ‘ ğ‘œğ‘‘ğ‘’ â‰ ğ‘›then\n25: abort ğ‘¡\ntransactions, including transactions invalidated in MVCC valida-\ntion due to conflicts. Specifically, when the number of committed\ntransactions in consensus reachedğ‘‡ğ‘›, AdaChain early aborts trans-\nactions in the ordering phase (i.e., no more transactions will be\ncommitted by the consensus protocol) until AdaChain transitions\ninto the next episode (lines 16-17). In AdaChain, the block forma-\ntion thread waits for transactions to be committed, cuts the block,\npossibly performs dependency graph construction, reordering, or\nexecution according to the current architecture, and lastly, commits\nthe block. Once the number of committed blocks reaches the high\nwatermark, the block formation thread will be paused until action\nğ‘ğ‘›+1is derived (lines 18-19). This ensures exactly âŒŠÎ”ğ‘episode/|ğ‘ğ‘›|âŒ‹\nblocks are committed in episode ğ‘›on different servers. Note that the\nlearning phase (including feature extraction, exchanging measure-\nments, training, and inference) is triggered by low watermark ğ‘Šğ‘›\nğ¿,\nand AdaChain keeps processing transactions using architecture ğ‘ğ‘›\nbetweenğ‘Šğ‘›\nğ¿andğ‘Šğ‘›\nğ». Thus, as shown in Section 7.5, architecture\nğ‘ğ‘›+1is derived before reaching ğ‘Šğ‘›\nğ»in most cases, ensuring high\nthroughput of the system.\n5.2 Slow Path\nBefore AdaChain converges to the optimal architecture, the learn-\ning agent might occasionally choose â€œbadâ€ architectures. The bad\narchitectures might result in a high fraction of transactions being\ninvalidated, or a slow growth of committed blocks (e.g., choosing\nOX when the workload is highly compute-intensive, or choosing\nXOV+reorder when the contention is extremely high). In terms of\nwall-clock time, AdaChain should not be stuck in either scenario.\nWhile the normal path is capable of handling the first scenario, we\n\nfurther introduce a slow path to handle the scenario where the\ngrowth of committed blocks is slow.\nAlgorithm 2 presents the slow path operations. When server ğ‘–\ntimeouts and the index of the last committed block, ğ‘last, has not\nreached the low watermark, server ğ‘–pauses the block formation af-\nter committing the current block, records the performance ğ‘ğ‘›\nğ‘–in the\ncurrent episode, and multicasts a s-checkpoint message including\ntheğ‘lastto all servers (lines 1-4). If a server ğ‘—receives s-checkpoint\nmessages from at least ğ‘“+1servers, even if its timer has not ex-\npired, it pauses the block formation, records its performance, and\nmulticasts a s-checkpoint message to all servers (lines 5-8).\nWhen the leader receives s-checkpoint messages from a quorum\nof2ğ‘“+1servers, it finds the maximum index of the last committed\nblock across all servers, ğ‘Šğ‘›\nğ», and multicasts a s-propose message\nincludingğ‘Šğ‘›\nğ»and the received 2ğ‘“+1s-checkpoint messages to all\nservers (lines 9-11). All servers validate the received s-propose mes-\nsage before two rounds of s-accept ands-commit communication,\nas shown in lines 12-16 (similar to the normal path). Each server\nthen usesğ‘Šğ‘›\nğ»as its high watermark and then resumes the block\nformation thread (lines 17-18). This ensures that in a slow path, the\nsame number of blocks are committed in episode ğ‘›across different\nservers. These operations might be expensive on the normal path,\nbut are negligible on the slow path, compared to the timeout ( 15s in\nour case) and the poor performance before timeouts. The worst case\nhappens when a fast server has not sent a s-checkpoint message,\nor its message has not been considered in the leaderâ€™s calculation\nofğ‘Šğ‘›\nğ». In this case, if the index of its last committed block is higher\nthanğ‘Šğ‘›\nğ», the server needs to rollback those exceeding blocks. Sim-\nilar to the normal path, each server also needs to exchange state\nand performance measurements to derive action ğ‘ğ‘›+1for the next\nepisode (lines 19-20).\nUpon receiving transaction ğ‘¡for ordering at the leader ğ‘™, the\nleader tags ğ‘¡with the current episode ğ‘›as part of the sequence\nnumber (lines 21-22). When a server receives transactions com-\nmitted by consensus protocol, it aborts transactions whose tagged\nepisode is not equal to the current episode (lines 23-25). This en-\nsures episode independence, i.e., there are no pending blocks across\nepisodes in AdaChain. As a result, a bad architecture that triggers\nthe slow path will not affect the performance of future episodes\nwith promising architectures.\nThe normal path and slow path of AdaChain ensure two prop-\nerties. First, transactions are strong serializable, and second, the\nworld state is eventually consistent across different servers.\n6 SECURITY ANALYSIS\nCompared to fixed-architecture blockchains, our use of machine\nlearning and run-time architecture switching add new security\nrisks. In this section, we briefly present the new threats and discuss\nhow AdaChain addresses them.\nAdversarial ML. As studied in the ML community, machine learn-\ning can be adversarial [ 34,45,49,63]. In the context of AdaChain,\nusing reinforcement learning does not affect the correctness of the\nsystem, which depends only on the consensus protocol (predefined\nin our system), the current architecture, and our switching protocol.\nThat being said, AdaChainâ€™s correctness guarantee is always asstrong as the weakest architecture in its action space, regardless of\nthe specific reinforcement learning algorithm.\nHowever, reinforcement learning introduces a new performance\nattack vector: manipulating feature data to cause the learning agent\nto pick a bad architecture. To carry out this attack, a malicious node\nmight propose adversarial feature values into the quorum ğ‘„in Algo-\nrithm 1. There are at least two ways such adversarial features could\nnegatively impact performance: (1) decision attacks that target the\ninference phase, where an adversary reports false observations of\nits own features in order to push the global feature in one direc-\ntion or another; and (2) poisoning attacks that target the training\nphase [ 25], where an adversary reports carefully selected feature\nvalues and labels to cause the next trained model to be inaccurate.\nAdaChain mitigates such attacks by selecting the median value of\nall reported features. For a feature with low variance, adversaries\nwould only be able to move the median value by a small amount\neven if they can report strong outliers (e.g., infinity or zero). How-\never, for a feature with high variance, adversaries could potentially\ncreate a non-trivial change in the median value, impacting future\ninference and training. Since AdaChain is designed to operate in a\nhomogeneous environment, most existing features and labels have\nlow variance.\nThus, while adversarial ML attacks cannot impact correctness,\nthere are open questions about potential performance attacks caused\nby learning. Studying the full impact of adversarial learning on a\nsystem like AdaChain is an interesting avenue for future work.\nChoosing different architectures. If peers choose different ar-\nchitectures within the same episode, the world state across peers\ncan diverge and lead to correctness issues. AdaChain guarantees\nthat every honest node agrees on the same new architecture in the\nsame episode. We provide an analysis as follows.\nEach nodeâ€™s learning agent starts with the same random seed\nwhen it is launched. Thus, since both the state and reward of a\ncertain episode are the same across all honest nodes (as mentioned\nin Section 5), with the predictive modelâ€™s deterministic training\nand inference, each honest agent chooses the same blockchain\narchitecture in the same episode. Moreover, although dishonest\nnodes are tempted to make decisions that are different from honest\nnodes, they cannot affect the agreement on architecture among\nhonest nodes. Without loss of generality, we assume ğ‘“=1and\nthere are 3ğ‘“+1peers in the system, where ğ‘ƒ1,ğ‘ƒ2,ğ‘ƒ3are honest\nandğ‘ƒ4is malicious; we further assume the honest peers choose the\nXOV architecture.\nCase 1:ğ‘ƒ4istheleader intheconsensus protocol. There are four\npossible scenarios, none of which poses a correctness issue: (1) if\nğ‘ƒ4chooses OX in the same episode, it will send out transaction\nproposals instead of endorsements in the ordering phase, so honest\npeers will detect this mismatch and initiate a view-change; (2) if\nğ‘ƒ4chooses XOV but with a batch size ğ‘4that is different from\nwhat honest learning agents have chosen, it does not affect the\nagreement; (3) if ğ‘ƒ4chooses XOV with different batch sizes and\nuses different batch sizes for different peers (e.g., ğ‘4,1forğ‘ƒ1,ğ‘4,2\nforğ‘ƒ2, etc.), the honest peers will detect and reject these batches\nduring consensus on batches and initiate a view-change; and (4)\nfinally, ifğ‘ƒ4chooses XOV but with an opposite reordering choice,\n\nsince reordering happens locally on each peer according to its local\nmodel, the malicious peer cannot corrupt honest peers.\nCase 2:ğ‘ƒ4isnottheleader intheconsensus protocol. The honest\nleader detects type mismatch for messages originating from ğ‘ƒ4and\ndiscards them, while other honest peers work as normal.\nDelay in architecture switching. An adversary might deliber-\nately delay its own communication (sending messages) during archi-\ntecture switching. In this scenario, if the adversary is a backup node\nin the switching protocol, it does not hurt the systemâ€™s throughput\nassuming the number of faulty backups is less than ğ‘“. On the other\nhand, if the adversary is the leader, it could carry out a perfor-\nmance attack by delaying the transition into the new architecture,\nwhere the delay is carefully chosen to avoid triggering the timeout.\nFortunately, there are known orthogonal techniques to mitigate\nthese attacks. For example, instead of using a pessimistic switching\nprotocol inspired by PBFT, AdaChain can adopt a robust switch-\ning protocol, e.g., following Prime [ 11] which is a BFT consensus\nprotocol robust to such timeout attacks.\nOther vanilla threats. Other common Byzantine failures might\nalso occur during the normal path and slow path operations. For in-\nstance, a malicious leader could send different propose messages to\ndifferent backups, or forge a deviated global state and reward. In the\nmeantime, a malicious backup node could double vote. AdaChain\nhandles these threats using a PBFT-style switching protocol, which\nguarantees that the committed state and reward of a certain episode\nis the same across all honest nodes. We refer readers to the original\npaper [20] for more details.\n7 EVALUATION\nOur evaluation aims to answer the following questions:\n(1)Can AdaChain converge to the optimal architecture under a\nstatic workload without prior knowledge? (Section 7.2)\n(2)How well does AdaChain perform compared to existing fixed\nblockchain architectures when the workload changes? (Section 7.3)\n(3)How does the hardware setup (e.g., the type of CPU, network\nlatency and bandwidth, etc.) affect the performance of AdaChain\nand existing blockchain architectures? (Section 7.4)\n(4) What overhead does AdaChain introduce? (Section 7.5)\n7.1 Experimental Setup\nWe have implemented a prototype of AdaChain in C++ and Python.\nThe blockchain peers which process transactions and carry out\narchitecture switching are implemented in C++. We use gRPC for\ncommunications between peers and LevelDB [ 1] for storing the\nworld states. The learning agents are implemented separately in\nPython due to its mature machine learning libraries. Each peer\ncommunicates with its local learning agent through gRPC.\nTestbed. Our testbed consists of 4 c6220 bare-metal machines on\nCloudLab [ 30], each with two Xeon E5-2650v2 processors ( 8cores\neach, 2.6Ghz), 64GB RAM(8 x 8GB DDR-3 RDIMMs, 1.86Ghz) and\ntwo 1TB SATA 3.5â€ 7.2K rpm hard drives. These machines are con-\nnected by two networks, each with one interface: (1) a 1 Gbps\nEthernet control network; (2) a 10 Gbps Ethernet commodity fab-\nric. Unless otherwise specified, we use the second network for allTable 3: Specific workload parameters.\nWorkload ğ‘ƒğ‘¤ğ‘ƒâ„ğ‘œğ‘¡ğ‘â„ğ‘œğ‘¡ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘ ğ‘‡ğ‘“ğ‘–ğ‘Ÿğ‘’ğ‘‡ğ‘ğ‘œğ‘šğ‘ğ‘¢ğ‘¡ğ‘’\nA 0.2 0.95 5 300 50ms 5ms\nB 0.5 0.99 10 100 50ms 1ms\nC 0.5 0.1 10 300 50ms 10ms\nD 0.9 0.95 1 100 50ms 0ms\nE 0.5 0.99 10 100 50ms 5ms\ncommunication. We set the size of the execution thread pool equal\nto the number of cores on each peer.\nSystem configuration. We run a single blockchain channel con-\nsisting of 3 peers on 3 different servers. As mentioned in Section 3,\neach peer in AdaChain serves as an executor as well as an orderer.\nThe choice of consensus protocol is configurable inside AdaChain,\nand we use Raft [ 53] for consistency with Hyperledger Fabric and\nits variants. We run the client on a separate server with 3 threads,\neach firing transaction proposals to one specific peer. The reported\nthroughput only considers effective transactions, i.e., excluding\nearly aborted and invalidated transactions. Throughout this paper,\nwe parameterize the architecture switching protocol as follows:\nnormal path timeout is set to 15s, the low watermark is set to 7500\ntransactions, and the high watermark to set to 10000 transactions.\nWorkloads. To capture the diversity in real-world blockchain trans-\nactions, we implement a benchmark driver above SmallBank [ 29] to\nderive customized workloads with tunable parameters. The bench-\nmark driver preloads the blockchain with 10k users, each with\ntwo accounts. We set ğ‘â„ğ‘œğ‘¡of them as hot accounts. When firing\ntransactions, the client randomly picks one of the five modifying\ntransactions with probability ğ‘ƒğ‘¤and the read-only transactions\nwith probability 1âˆ’ğ‘ƒğ‘¤. Each transaction has a certain probability\nto access the hot accounts, as controlled by the ğ‘ƒâ„ğ‘œğ‘¡parameter. The\nclient continuously fires ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘›ğ‘  transactions every ğ‘‡ğ‘“ğ‘–ğ‘Ÿğ‘’millisec-\nonds. To simulate computation-heavy transactions, each transac-\ntion has ağ‘‡ğ‘ğ‘œğ‘šğ‘ğ‘¢ğ‘¡ğ‘’ interval after it fetches the required world states\nfrom the key-value store and before its subsequent operations.\nWe use workloads A-Ethroughout this paper, where workloads\nA-Dare the same as in Figure 1. The specific parameters of work-\nloads A-Eare listed in Table 3. Unlike workloads A-D, the additional\nworkload Eis introduced later in the section that explores adaptiv-\nity to different hardware settings. Although workload Ehas only\nslight deviation from workload B, it renders blockchain architec-\ntures extremely sensitive to hardware setup (details in Section 7.4).\nNote that we have written our own benchmark driver because no\nexisting benchmark captures all these variations in workloads.\n7.2 Convergence under Static Workloads\nOur first set of experiments aims to demonstrate that AdaChain can\nrapidly converge to the optimal architecture under a static workload\nwith no prior experiences required . We run AdaChain for 100 episodes\non four representative workloads (i.e., A-D). To compare AdaChain\nagainst the a priori optimal architecture, we also perform a grid\nsearch in the action space to find the optimal architecture for each\nworkload. For our four workloads, we compare AdaChain with the\nfour optimal static architectures.\nFigure 3 plots the performance of AdaChain and four baselines\nfor each workload, where the baseline curves are smoothed for bet-\nter readability. The curve for AdaChain is not smoothed. Each work-\nload has a different optimal architecture. For instance, XOV+reorder\n\n(a) Workload A\n (b) Workload B\n (c) Workload C\n (d) Workload D\nFigure 3: Convergence of AdaChain to the optimal architecture under static workloads. Each plot shows the performance of\nAdaChain (w/ and w/o hint), XOV+reorder, XOV, OXII, and OX. While different blockchain architectures are optimal for each\nworkload, AdaChain always reaches near-optimal performance.\nTable 4: Effective throughput (tps) for each architecture in\nthe last 20episodes of each workload and the convergence\ntime (minutes) of AdaChain.\nWorkloadEffective Throughput AdaChainâ€™s Conv. Time\nXOV+reorder XOV OXII OX AdaChain w/ hint w/o hint\nA 1532 1415 968 194 1425 0.65 2.48\nB 897 866 1545 861 1426 0.42 0.62\nC 3228 3235 940 98 3153 0.45 0.48\nD 1 272 1494 1498 1447 0.43 0.43\nAverage 1414 1447 1237 663 1862 0.49 1.00\nWorst 1 272 940 98 1425 0.65 2.48\nis optimal for workload A, suboptimal for workloads BandC, but\nthe worst for workload D. Unlike a fixed architecture that cannot\nadjust itself even under a static workload, AdaChain always con-\nverges to the optimal architecture for each workload quickly within\n40episodes, no matter how bad the first episode (initial architec-\nture) is. Due to Thompson sampling, AdaChain still performs some\nexploration in the architecture space even after convergence, as\nidentified by the drops in the performance plot. Although these\nexplorations do not seem useful under static workloads, they are\ncrucial for finding optimal architectures under a changing workload\nwhich is more realistic in todayâ€™s BaaS environment.\nComparing to exhaustive grid search (not shown in Figure 3)\nthat takesğ‘›ğ‘(the size of action space, i.e., 100in our case) to con-\nverge and performs pure random exploration at all times, AdaChain\nconverges much faster and strikes a better balance between exploit-\ning known good actions and exploring unknown actions. Table 4\nshows AdaChainâ€™s typical convergence time. In our definition, con-\nvergence is reached when staying within 95%of the optimal per-\nformance for 5consecutive episodes.\nAverage performance. AdaChain obviously does not outperform\nthe optimal action in any workload (it is the optimal action, after\nall). However, we show that AdaChain does offer good average\nand worst-case performance after convergence. Table 4 shows the\nthroughput for each blockchain on each workload in the last 20\nepisodes of execution. Even with a few performance drops due to\nexploration, AdaChain achieves both the best average throughput\nandthe best worst-case throughput across all four workloads.\nProviding hints. An experienced administrator can build his knowl-\nedge into the learning framework by specifying certain rules in\norder to prevent some sub-optimal decisions. An example hint is\nâ€œif the compute intensity is higher than 2000 us, enable early execu-\ntion; otherwise, disable early execution\". If accurate, hints of this\nFigure 4: Cumulative committed transactions with time for a\nchanging workload, showing AdaChainâ€™s ability to maintain\nsuperior performance during workload shifts.\nnature reduce the search space, thus providing faster convergence\nand avoid certain explorations. Figure 3 summarizes our findings\nusing the example hint (see â€œAdaChain+hintâ€ lines). For workload\nA, the hint accelerates the convergence time of AdaChain by 3.8Ã—.\nHowever, it is not sufficient to avoid all explorations in AdaChain,\ni.e., varying reordering choice and block size. In contrast, for work-\nloads BandCwhere the convergence is already fast, the additional\nhint reduces unnecessary explorations after convergence.\n7.3 Adaptivity under a Changing Workload\nOur next experiment focuses on the key benefits of AdaChain: when\nthe workload is changing, AdaChain can commit significantly more\ntransactions than the best baseline during the same deployment period .\nTo emulate a changing workload, we run workload Afor the first 15\nminutes, followed by workloads B,C,D, and A, each for 15 minutes.\nWe use the same four baselines as in Figure 3, which are the optimal\narchitectures for workload A-Dwhen they are static.\nFigure 4 shows the number of cumulative committed transac-\ntions with respect to time. During the entire 75minutes, AdaChain\nsuccessfully completed 7.73Ã—106committed transactions, while\nthe best baseline XOV completed 6.60Ã—106committed transactions.\nThe worst baseline OX only completed 0.87Ã—106committed trans-\nactions. AdaChain can successfully commit 1.12million ( 17%) more\ntransactions than the best baseline during 75minutes. The trend in\nFigure 4 also suggests the improvement of AdaChain would become\nincreasingly significant with a longer deployment time and more\nvariations in the workloads, which are common in todayâ€™s BaaS.\nInterestingly, Figure 4 also shows a â€œcatastrophic\" effect for cer-\ntain fixed architectures when the workload is changing. For in-\nstance, when transitioning back to workload Aagain ( 60-75min),\n\nthe slope of XOV+reorder is near zero, indicating poor performance\nwhere few if any transactions are completed successfully. However,\nif we start running XOV+reorder right from the beginning under\nworkload Awithout any changes to the workload (Figure 3(a)),\nXOV+reorder would be the optimal architecture. XOV+reorder per-\nforms poorly in workload D(45-60 min) due to the high overhead\nof Johnsonâ€™s algorithm with a large number of cycles, which slows\ndown the block formation. Since the block formation is sequential,\nthe number of pending blocks grows significantly. Thus, incoming\ntransactions simulate on stale data and would fail in the MVCC\nvalidation phase, even when transitioning back to workload Aagain.\nOX suffers from similar problems due to a large number of pending\nblocks. This phenomenon also justifies our watermark-based design\nof AdaChain, as elaborated in Section 5.\nTo further investigate how AdaChain switches its architecture\nunder a changing workload, we plot AdaChainâ€™s effective through-\nput in each episode during the 75minutes in Figure 5. The red\ndashed vertical line indicates when the workload shifts. Although\nworkloads AandBhave the same duration in terms of wall clock\ntime ( 15min), they vary in terms of the number of episodes. This\nis because, depending on the transaction arrival rate and compute\nintensity of different workloads, each episode (which is marked by\nthe high watermark) may have a different time duration.\nFigure 5 shows that when workloads shifts, AdaChain is able\nto quickly converge and perform competitively with the optimal\narchitecture. For instance, when transitioning from workload Ato\nB, AdaChain quickly converges to the new optimal (i.e., OXII) and\nachieves a 1450 tps throughput. In contrast, while XOV+reorder\nis optimal under workload A, as shown in Figure 3(b), it is able to\nreach only 900tps when processing workload B, even in the best-\ncase scenario where the catastrophic effect is avoided by starting\nwith workload Band XOV+reorder right at the beginning. When\ntransitioning from workload BtoC, AdaChain quickly converges\nto the new optimal (i.e., XOV) and achieves a 3250 tps throughput.\nIn comparison, OXII, which is optimal under workload B, is able to\nachieve only 980tps under workload C(Figure 3(c)).\nDue to Thompson sampling, AdaChain maintains some degree\nof exploration in the architecture space even after convergence, so\nas to avoid getting stuck at the local optimum. As AdaChain gains\nmore experiences (i.e., data points) on a certain workload, the extent\nof exploration decreases, which is indicated by the less frequent\ndrops within each 15minutes period. Also, when AdaChain en-\ncounters a workload it has seen before (e.g., transition to workload\nAagain in the last 15minutes), AdaChain converges much faster\nthan the first time and has less variation in performance.\nIdeally, since we use the state of the previous episode to ap-\nproximate the state of the next episode, AdaChain can adapt to\nworkloads that shift less frequently than every two episodes ( 20s\nat most). In practice, due to the exploration performed by CMAB,\nas long as the workload changes are slower than the convergence\ntime (as shown in Table 4), AdaChain can still operate effectively.\n7.4 Adaptivity under Different Hardware\nOur next set of experiments demonstrates another operational bene-\nfit of AdaChain: when deployed on different hardware configurations,\nAdaChain can rapidly converge to the optimal architecture for thatTable 5: Overhead of each stage in AdaChain.\nfeaturization communication training inference episode\nmean 0.11ğ‘ Â±0.01 0.14ğ‘ Â±0.04 0.21ğ‘ Â±0.04 0.01ğ‘ Â±0.01 3.67ğ‘ Â±2.12\nmedian 0.11s 0.14s 0.21s 0.01s 2.57s\nmax 0.20s 0.27s 0.32s 0.02s 16.35s\nhardware without manually re-configuring the blockchain architec-\nture. We use workload Eon three different hardware setups: HW1\nstands for single data center deployment, where the network con-\nnecting peers has low latency ( 0.15ms) and high bandwidth ( 10\nGbps), and each peer has 16CPU cores; HW2 also stands for single\ndata center deployment, but with 2CPU cores per peer; HW3 stands\nfor a multi-data center deployment, with high latency ( 50ms) and\nlow bandwidth ( 1Gbps) network, and 2CPU cores per peer. As\nmentioned in Section 7.1, for HW1 and HW2, we use the commod-\nity network fabric; for HW3, we use the control network as well\nas Linux netem [32] to inject delay to the NIC. For each hardware\nsetup, we also perform a grid search to find the optimal architecture\nfor that hardware: for HW1, the optimal is (OXII, blocksize = 100);\nfor HW2, the optimal is (XOV, blocksize = 1), for HW3 the optimal\nis (OXII, blocksize = 100) again. Figure 6 plots AdaChainâ€™s perfor-\nmance in each episode on HW1-HW3, along with the averaged\nperformance of the optimal architecture for comparison.\nAs shown in Figure 6, even under the same workload, the hard-\nware setup affects the effective throughput and thus affects the\nchoice of the best architecture. For instance, OXII performs well\nwhen each server has enough compute resources (HW1 best arch\nin Figure 6(a)), but suffers when the servers have low compute\nresources (HW1 best arch in Figure 6(b)); StreamChain can perform\nwell in a single data center deployment (HW2 best arch in Fig-\nure 6(b)), but suffers from the high round trip time when deployed\nacross multiple data centers due to the small batch size it uses in\nthe consensus protocol (HW2 best arch in Figure 6(c)). No matter\nwhat type of hardware AdaChain is deployed on, AdaChain can\nadapt itself to the optimal architecture for that hardware.\nMore importantly, for any kind of unseen hardware setup, users\nof AdaChain do not need to recollect data and retrain the machine\nlearning model offline. AdaChain is an online system that learns\nfrom its past experiences and balances exploitation and exploration.\nWith AdaChain, BaaS can have humans completely out of the loop.\n7.5 Overhead of Learning\nOur last experiment evaluates the additional overhead incurred\nby AdaChainâ€™s learning framework. We repeat the experiment in\nSection 7.3 and profile every stage that involves the learning agent.\nWe report the results along with the episode duration in Table 5.\nBefore deriving the architecture for the next episode, AdaChain\nneeds to go through feature extraction, communication, training\nand inference phases in sequence (Section 3). Table 5 shows that all\nof these four phases have low average overhead with low variance,\nas compared to the episode duration. The additional mean overhead\ntime ( 0.47s) is only 12.8%of the average episode duration ( 3.67s).\nMore importantly, the 12.8%overhead can be masked by paral-\nlelizing transaction processing and learning. The learning phase\nonly occurs between the low and high watermark period, which\nconstitutes 25%duration with each episode. Considering that the\n\nFigure 5: Effective throughput of AdaChain in each episode. Here, red vertical line indicates when the workload shifts. The\nworkload shifts every 15 minutes. The number of episodes per 15 minutes duration varies depending on the transactions arrival\nrate and compute intensity of workload.\n(a) HW1 (16 cores, RTT=0.15ms, BW=10Gbps)\n (b) HW2 (2 cores, RTT=0.15ms, BW=10Gbps)\n (c) HW3 (2 cores, RTT=50ms, BW=1Gbps)\nFigure 6: Convergence of AdaChain to the optimal architecture under different hardware.\nmedian episode duration is 2.57s, this interval time is 0.64s which\nis higher than the mean overhead of 0.47s. During this interval,\nthe peers continue to process transactions based on the current\narchitecture, while in parallel, the learning agent goes through the\nfour stages to determine the architecture for the next episode. Such\nparallel execution ensures that the overhead of AdaChain does not\nadversely affect its effective throughput, as long as there are some\nspare CPU cycles devoted to the learning agent.\nUnlike deep neural networks, which are especially expensive to\ntrain, the random forest model used by AdaChain has moderate\ntraining overhead. With thousands of data points in the experience\nbuffer, AdaChain only incurs a maximum training overhead of 0.32\nseconds. Moreover, the succinct action space design also results in\na lightweight inference phase, i.e., 0.02seconds. When AdaChain\nis deployed for a long run, techniques such as periodic resampling\nand limiting the length of experience buffer [51] can be utilized.\n8 RELATED WORK\nLearned systems. More generally, many recent works have ap-\nplied machine learning concepts to systems components. These\nworks, falling under the umbrella of machine programming [ 35],\ncannot be exhaustively enumerated here, but we refer the reader to\npast work on indexing [ 44], cardinality estimation [ 43,48], index\nselection [ 28], database tuning [ 55], scheduling [ 50], garbage col-\nlection [ 21], and concurrency control for in-memory databases [ 62].\nAs a novel application, learned permissioned blockchains not only\nrequire unique featurization of the blockchain design landscape (i.e.,\naction space), but also operate in an environment where there areByzantine failures. Consequently, our design uses a fully decentral-\nized machine learning approach to handle the untrustworthiness\nof participating nodes.\nDatabase migration. Efficient and live migration of databases has\nbeen studied in multi-tenant data infrastructures [ 19,27,31,40,47].\nUnlike existing work that mainly migrates data between differ-\nent physical nodes, AdaChain switches between system architec-\ntures within the same participating node. Moreover, AdaChainâ€™s\nmigration protocol is robust to Byzantine failures and mitigates the\nexplorations performed by reinforcement learning.\n9 CONCLUSION\nIn this paper, we presented AdaChain, an adaptive blockchain frame-\nwork that leverages reinforcement learning to dynamically switch\nbetween different blockchain architectures based on the workload.\nAdaChain is able to identify the optimal blockchain architecture\nas workload changes, obtaining significantly higher throughput\ncompared to fixed architectures. As future work, we are explor-\ning expanding the learning framework to cover other aspects of\nblockchain architectures, e.g., choosing the best performing con-\nsensus protocol. Another intriguing future direction is to figure\nout whether our learning framework can be used to uncover new\neffective architectures not previously explored by human experts.\nACKNOWLEDGMENTS\nWe thank the anonymous reviewers for their insightful feedback\nand suggestions. This work is funded by NSF grants CNS-2104882,\nand CNS-1703936 and by NSF/Intel joint grant #2011168.\n\nREFERENCES\n[1] [n. d.]. https://github.com/google/leveldb\n[2][n. d.]. AWS. Amazon quantum ledger database (QLDB). https://aws.amazon.\ncom/qldb/.\n[3][n. d.]. Blockchain on AWS Enterprise blockchain made real.\nhttps://aws.amazon.com/blockchain/.\n[4] [n. d.]. Chain. http://chain.com.\n[5] [n. d.]. Corda. https://github.com/corda/corda.\n[6] [n. d.]. Hyperledger Caliper. https://www.hyperledger.org/use/caliper.\n[7] [n. d.]. Hyperledger Iroha. https://github.com/hyperledger/iroha.\n[8][n. d.]. IBM Blockchain Platform. https://www.ibm.com/cloud/blockchain-\nplatform.\n[9] [n. d.]. Oracle Blockchain. https://www.oracle.com/blockchain/.\n[10] Shipra Agrawal and Navin Goyal. 2013. Further Optimal Regret Bounds for\nThompson Sampling. In The International Conference on Artificial Intelligence\nand Statistics (AISTATS â€™13) .\n[11] Yair Amir, Brian Coan, Jonathan Kirsch, and John Lane. 2011. Prime: Byzantine\nreplication under attack. Transactions on Dependable and Secure Computing 8, 4\n(2011), 564â€“577.\n[12] Mohammad Javad Amiri, Divyakant Agrawal, and Amr El Abbadi. 2019. Par-\nBlockchain: Leveraging Transaction Parallelism in Permissioned Blockchain\nSystems. In Int. Conf. on Distributed Computing Systems (ICDCS) . IEEE, 1337â€“\n1347.\n[13] Mohammad Javad Amiri, Divyakant Agrawal, and Amr El Abbadi. 2021. SharPer:\nSharding Permissioned Blockchains Over Network Clusters. In SIGMOD Int. Conf.\non Management of Data . ACM, 76â€“88.\n[14] Mohammad Javad Amiri, Joris DuguÃ©pÃ©roux, Tristan Allard, Divyakant Agrawal,\nand Amr El Abbadi. 2021. SEPAR: Towards Regulating Future of Work Multi-\nPlatform Crowdworking Environments with Privacy Guarantees. In Proceedings\nof The Web Conf. (WWW) . 1891â€“1903.\n[15] Mohammad Javad Amiri, Boon Thau Loo, Divyakant Agrawal, and Amr El Ab-\nbadi. 2022. Qanaat: A Scalable Multi-Enterprise Permissioned Blockchain System\nwith Confidentiality Guarantees. Proc. of the VLDB Endowment 15, 11 (2022),\n2839â€“2852.\n[16] Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin, et al .2018.\nHyperledger Fabric: a distributed operating system for permissioned blockchains.\nInEuropean Conf. on Computer Systems (EuroSys) . ACM, 30:1â€“30:15.\n[17] Leo Breiman. 1996. Bagging Predictors. In Machine Learning (Maching Learning\nâ€™96).\n[18] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (Oct. 2001), 5â€“32.\nhttps://doi.org/10.1023/A:1010933404324\n[19] Wei Cao, Feifei Li, Gui Huang, Jianghang Lou, Jianwei Zhao, Dengcheng He,\nMengshi Sun, Yingqiang Zhang, Sheng Wang, Xueqiang Wu, et al .2022. PolarDB-\nX: An Elastic Distributed Relational Database for Cloud-Native Applications.\nIn2022 IEEE 38th International Conference on Data Engineering (ICDE) . IEEE,\n2859â€“2872.\n[20] Miguel Castro, Barbara Liskov, et al .1999. Practical Byzantine fault tolerance.\nInSymposium on Operating systems design and implementation (OSDI) , Vol. 99.\nUSENIX Association, 173â€“186.\n[21] Lujing Cen, Ryan Marcus, Hongzi Mao, Justin Gottschlich, Mohammad Alizadeh,\nand Tim Kraska. 2020. Learned Garbage Collection. In Proceedings of the 4th\nACM SIGPLAN International Workshop on Machine Learning and Programming\nLanguages (MAPL @ PLDI â€™20) . ACM. https://doi.org/10.1145/3394450.3397469\n[22] Jeeta Ann Chacko, Ruben Mayer, and Hans-Arno Jacobsen. 2021. Why Do My\nBlockchain Transactions Fail? A Study of Hyperledger Fabric. In SIGMOD Int.\nConf. on Management of Data . ACM, 221â€“234.\n[23] Olivier Chapelle and Lihong Li. 2011. An empirical evaluation of Thompson\nsampling. In Advances in neural information processing systems (NIPSâ€™11) .\n[24] JP Morgan Chase. 2016. Quorum white paper.\n[25] Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. [n. d.]. Tar-\ngeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning.\narXiv:1712.05526 [cs] http://arxiv.org/abs/1712.05526 type: article.\n[26] Sam Daley. 2021. 18 Blockchain-as-a-Service Companies Making the DLT More\nAccessible. https://builtin.com/blockchain/blockchain-as-a-service-companies.\n[27] Sudipto Das, Shoji Nishimura, Divyakant Agrawal, and Amr El Abbadi. 2011.\nAlbatross: Lightweight elasticity in shared storage databases for the cloud using\nlive data migration. Proceedings of the VLDB Endowment 4, 8 (2011), 494â€“505.\n[28] Bailu Ding, Sudipto Das, Ryan Marcus, Wentao Wu, Surajit Chaudhuri, and\nVivek R. Narasayya. 2019. AI Meets AI: Leveraging Query Executions to Improve\nIndex Recommendations. In 38th ACM Special Interest Group in Data Management\n(SIGMOD â€™19) .\n[29] Tien Tuan Anh Dinh, Ji Wang, Gang Chen, Rui Liu, Beng Chin Ooi, and Kian-\nLee Tan. 2017. Blockbench: A framework for analyzing private blockchains. In\nSIGMOD Int. Conf. on Management of Data . ACM, 1085â€“1100.\n[30] Dmitry Duplyakin, Robert Ricci, Aleksander Maricq, Gary Wong, Jonathon\nDuerig, Eric Eide, Leigh Stoller, Mike Hibler, David Johnson, Kirk Webb, et al .\n2019. The Design and Operation of {CloudLab}. InAnnual Technical Conf. (ATC) .\nUSENIX Association, 1â€“14.[31] Aaron J Elmore, Sudipto Das, Divyakant Agrawal, and Amr El Abbadi. 2011.\nZephyr: live migration in shared nothing databases for elastic cloud platforms.\nInProceedings of the 2011 ACM SIGMOD International Conference on Management\nof data . 301â€“312.\n[32] The Linux Fundation. 2021. netem. Retrieved July 4, 2022 from https://wiki.\nlinuxfoundation.org/networking/netem\n[33] Zerui Ge, Dumitrel Loghin, Beng Chin Ooi, Pingcheng Ruan, and Tianwen Wang.\n2022. Hybrid blockchain database systems: design and performance. Proceedings\nof the VLDB Endowment 15, 5 (2022), 1092â€“1104.\n[34] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and\nharnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).\n[35] Justin Gottschlich, Armando Solar-Lezama, Nesime Tatbul, Michael Carbin, Mar-\ntin Rinard, Regina Barzilay, Saman Amarasinghe, Joshua B. Tenenbaum, and\nTim Mattson. 2018. The three pillars of machine programming. In Proceed-\nings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and\nProgramming Languages (MAPL 2018) . Association for Computing Machinery,\nPhiladelphia, PA, USA, 69â€“80. https://doi.org/10.1145/3211346.3211355\n[36] Vincent Gramoli, Rachid Guerraoui, Andrei Lebedev, Chris Natoli, and Gauthier\nVoron. 2022. Diablo-v2: A Benchmark for Blockchain Systems . Technical Report.\n[37] Gideon Greenspan. 2015. MultiChain private blockchain-White paper. URl:\nhttp://www. multichain. com/download/MultiChain-White-Paper. pdf (2015).\n[38] Hyperledger. [n. d.]. Private Data Collections: A High-Level Overview.\nhttps://www.hyperledger.org/blog/2018/10/23/private-data-collections-a-high-\nlevel-overview.\n[39] Zsolt IstvÃ¡n, Alessandro Sorniotti, and Marko VukoliÄ‡. 2018. StreamChain: Do\nBlockchains Need Blocks?. In Workshop on Scalable and Resilient Infrastructures\nfor Distributed Ledgers (SERIAL) . ACM, 1â€“6.\n[40] Junbin Kang, Le Cai, Feifei Li, Xingxuan Zhou, Wei Cao, Songlu Cai, and Daming\nShao. 2022. Remus: Efficient Live Migration for Distributed Databases with Snap-\nshot Isolation. In Proceedings of the 2022 International Conference on Management\nof Data . 2232â€“2245.\n[41] Manos Kapritsos, Yang Wang, Vivien Quema, Allen Clement, Lorenzo Alvisi,\nMike Dahlin, et al .2012. All about Eve: Execute-Verify Replication for Multi-Core\nServers.. In Symposium on Operating systems design and implementation (OSDI) ,\nVol. 12. USENIX Association, 237â€“250.\n[42] Emilie Kaufmann, Nathaniel Korda, and RÃ©mi Munos. 2012. Thompson sampling:\nAn asymptotically optimal finite-time analysis. In International Conference on\nAlgorithmic Learning Theory (ALT â€™12) .\n[43] Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and Alfons\nKemper. 2019. Learned Cardinalities: Estimating Correlated Joins with Deep\nLearning. In 9th Biennial Conference on Innovative Data Systems Research (CIDR\nâ€™19). http://arxiv.org/abs/1809.00677\n[44] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe Case for Learned Index Structures. In Proceedings of the 2018 International\nConference on Management of Data (SIGMOD â€™18) . ACM, New York, NY, USA.\nhttps://doi.org/10.1145/3183713.3196909\n[45] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial machine\nlearning at scale. arXiv preprint arXiv:1611.01236 (2016).\n[46] Jae Kwon. 2014. Tendermint: Consensus without mining. (2014).\n[47] Yu-Shan Lin, Shao-Kan Pi, Meng-Kai Liao, Ching Tsai, Aaron Elmore, and Shan-\nHung Wu. 2019. MgCrab: transaction crabbing for live migration in deterministic\ndatabase systems. Proceedings of the VLDB Endowment 12, 5 (2019), 597â€“610.\n[48] Henry Liu, Mingbin Xu, Ziting Yu, Vincent Corvinelli, and Calisto Zuzarte. 2015.\nCardinality Estimation Using Neural Networks. In Proceedings of the 25th Annual\nInternational Conference on Computer Science and Software Engineering (CASCON\nâ€™15). IBM Corp., Riverton, NJ, USA, 53â€“59. http://dl.acm.org/citation.cfm?id=\n2886444.2886453\n[49] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and\nAdrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversarial\nAttacks. In International Conference on Learning Representations .\n[50] Hongzi Mao, Malte Schwarzkopf, Shaileshh Bojja Venkatakrishnan, Zili Meng,\nand Mohammad Alizadeh. 2018. Learning Scheduling Algorithms for Data\nProcessing Clusters. arXiv:1810.01963 [cs, stat] (2018). http://arxiv.org/abs/1810.\n01963 arXiv: 1810.01963.\n[51] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Al-\nizadeh, and Tim Kraska. 2021. Bao: Making Learned Query Optimization Practical.\nInProceedings of the 2021 International Conference on Management of Data (SIG-\nMOD â€™21) . China. https://doi.org/10.1145/3448016.3452838 Award: â€™best paper\nawardâ€™.\n[52] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A Learned\nQuery Optimizer. PVLDB 12, 11 (2019), 1705â€“1718.\n[53] Diego Ongaro and John K Ousterhout. 2014. In search of an understandable\nconsensus algorithm. In Annual Technical Conf. (ATC) . USENIX Association,\n305â€“319.\n[54] Ian Osband and Benjamin Van Roy. 2015. Bootstrapped Thompson Sampling\nand Deep Exploration. arXiv:1507.00300 [cs, stat] (July 2015). http://arxiv.org/\nabs/1507.00300\n\n[55] Andrew Pavlo, Gustavo Angulo, Joy Arulraj, Haibin Lin, Jiexi Lin, Lin Ma,\nPrashanth Menon, Todd C. Mowry, Matthew Perron, Ian Quah, Siddharth San-\nturkar, Anthony Tomasic, Skye Toor, Dana Van Aken, Ziqi Wang, Yingjun Wu,\nRan Xian, and Tieying Zhang. 2017. Self-Driving Database Management Systems.\nIn8th Biennial Conference on Innovative Data Systems Research (CIDR â€™17) .\n[56] Zhe Peng, Cheng Xu, Haixin Wang, Jinbin Huang, Jianliang Xu, and Xiaowen\nChu. 2021. P2B-Trace: Privacy-Preserving Blockchain-based Contact Tracing to\nCombat Pandemics. In SIGMOD Int. Conf. on Management of Data . 2389â€“2393.\n[57] Zhe Peng, Jianliang Xu, Xiaowen Chu, Shang Gao, Yuan Yao, Rong Gu, and\nYuzhe Tang. 2021. Vfchain: Enabling verifiable and auditable federated learning\nvia blockchain systems. IEEE Transactions on Network Science and Engineering\n(2021).\n[58] Pingcheng Ruan, Dumitrel Loghin, Quang-Trung Ta, Meihui Zhang, Gang Chen,\nand Beng Chin Ooi. 2020. A Transactional Perspective on Execute-order-validate\nBlockchains. In SIGMOD Int. Conf. on Management of Data . ACM, 543â€“557.\n[59] Ankur Sharma, Felix Martin Schuhknecht, Divya Agrawal, and Jens Dittrich.\n2019. Blurring the lines between blockchains and database systems: the case of\nhyperledger fabric. In SIGMOD Int. Conf. on Management of Data . ACM, 105â€“122.\n[60] Feng Tian. 2017. A supply chain traceability system for food safety based on\nHACCP, blockchain & Internet of things. In Int. Conf. on service systems andservice management (ICSSSM) . IEEE, 1â€“6.\n[61] Shin-Yeh Tsai, Yizhou Shan, and Yiying Zhang. 2020. Disaggregating Persistent\nMemory and Controlling Them Remotely: An Exploration of Passive Disaggre-\ngated{Key-Value}Stores. In Annual Technical Conf. (ATC) . USENIX Association,\n33â€“48.\n[62] Jia-Chen Wang, Ding Ding, Huan Wang, Conrad Christensen, Zhaoguo Wang,\nHaibo Chen, and Jinyang Li. 2021. Polyjuice: High-Performance Transactions\nvia Learned Concurrency Control.. In OSDI . 198â€“216.\n[63] Eric Wong, Leslie Rice, and J Zico Kolter. 2019. Fast is better than free: Revisiting\nadversarial training. In International Conference on Learning Representations .\n[64] Chenyuan Wu, Mohammad Javad Amiri, Jared Asch, Heena Nagda, Qizhen\nZhang, and Boon Thau Loo. 2022. FlexChain: An Elastic Disaggregated\nBlockchain. Proc. of the VLDB Endowment 16, 01 (2022), 23â€“36.\n[65] Xinying Yang, Yuan Zhang, Sheng Wang, Benquan Yu, Feifei Li, Yize Li, and\nWenyuan Yan. 2020. LedgerDB: a centralized ledger database for universal audit\nand verification. Proceedings of the VLDB Endowment 13, 12 (2020), 3138â€“3151.\n[66] Li Zhou. 2016. A Survey on Contextual Multi-armed Bandits. arXiv:1508.03326\n[cs](Feb. 2016). http://arxiv.org/abs/1508.03326",
  "textLength": 85879
}