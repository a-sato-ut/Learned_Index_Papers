{
  "paperId": "8b2e250cb8391f9a10a6efd3ce111312b8544154",
  "title": "LearnedSort as a learning-augmented SampleSort: Analysis and Parallelization",
  "pdfPath": "8b2e250cb8391f9a10a6efd3ce111312b8544154.pdf",
  "text": "LearnedSort as a learning-augmented SampleSort: Analysis and\nParallelization\nIvan Carvalho\nUniversity of British Columbia\nKelowna, Canada\nivancarv@student.ubc.caRamon Lawrence\nUniversity of British Columbia\nKelowna, Canada\nramon.lawrence@ubc.ca\nABSTRACT\nThis work analyzes and parallelizes LearnedSort, the novel algo-\nrithm that sorts using machine learning models based on the cumu-\nlative distribution function. LearnedSort is analyzed under the lens\nof algorithms with predictions, and it is argued that LearnedSort\nis a learning-augmented SampleSort. A parallel LearnedSort algo-\nrithm is developed combining LearnedSort with the state-of-the-art\nSampleSort implementation, IPS4o. Benchmarks on synthetic and\nreal-world datasets demonstrate improved parallel performance\nfor parallel LearnedSort compared to IPS4o and other sorting algo-\nrithms.\nCCS CONCEPTS\nâ€¢Theory of computation â†’Sorting and searching ;â€¢Com-\nputing methodologies â†’Learning linear models ;â€¢Information\nsystemsâ†’Query operators .\nKEYWORDS\nsorting, machine learning for systems, algorithms with predictions\nACM Reference Format:\nIvan Carvalho and Ramon Lawrence. 2023. LearnedSort as a learning-\naugmented SampleSort: Analysis and Parallelization. In 35th International\nConference on Scientific and Statistical Database Management (SSDBM 2023),\nJuly 10â€“12, 2023, Los Angeles, CA, USA. ACM, New York, NY, USA, 9 pages.\nhttps://doi.org/10.1145/3603719.3603731\n1 INTRODUCTION\nSorting is a fundamental operation for databases and implementa-\ntion details are relevant to sorting performance [ 9]. Quicksort is the\nasymptotically optimal comparison-based sort introduced by Hoare\nin the 1960s [ 12]. Its implementation variants have since become\nubiquitous in database management systems such as PostgreSQL\nand standard libraries such as the GNU C++ library. Researchers\nkeep pushing the boundary of sorting performance by proposing\nvariants enhancing Quicksort [1, 6, 24, 26, 31].\nLearnedSort is a novel sorting algorithm proposed by Kristo et\nal. [15] that introduces the idea of sorting with machine learning\nmodels. If there was a perfect model ğ¹(ğ‘¥)that predicted the position\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nSSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA\nÂ©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0746-9/23/07. . . $15.00\nhttps://doi.org/10.1145/3603719.3603731ofğ‘¥in the sorted array, we could sort the array ğ´in a single pass\nwithğ´[ğ¹(ğ‘¥)]=ğ‘¥. Finding a perfect model is challenging, hence the\nLearnedSort authors opt to train cumulative distribution function\n(CDF) models to approximate ğ¹(ğ‘¥)and combine them with bucket\npartitioning. This approach by Kristo et al. was successful and led\nto excellent performance in sorting benchmarks. At first glance,\nLearnedSort looks radically different from Quicksort due to the\nCDF models. However, the analysis in this work demonstrates\nmany similarities.\nThis work analyzes LearnedSort under the lens of algorithms\naugmented with predictions [ 23]. We highlight a close link between\nLearnedSort and SampleSort (a generalized version of Quicksort).\nThis connection between the two algorithms has practical conse-\nquences. The first consequence is an explanation on why Learned-\nSort is so effective. The second consequence is the ability to leverage\nexisting literature on SampleSort to address open issues of Learned-\nSort, such as sorting in parallel and handling inputs with many\nduplicates.\nThis paper makes the following contributions:\nâ€¢Introduction of Learned Quicksort, a simpler version to ana-\nlyze of LearnedSort that has average complexity of O(ğ‘logğ‘)\nâ€¢Analysis showing that LearnedSort is analogous to a Sam-\npleSort with pivots selected by a CDF model\nâ€¢A new sorting algorithm combining the works of Kristo\net al. [ 15] and Axtmann et al. [ 1] to implement a parallel\nLearnedSort\nâ€¢Experimental benchmarking of the sorting implementations\nusing the datasets from the LearnedSort paper [15]\n2 BACKGROUND\n2.1 Learned Indexes\nLearned Indexes are an emerging type of data structure that lever-\nage machine learning models to create highly efficient indexes\nthat outperform their traditional counterparts such as B-Trees [ 14].\nAmong such indexes, we highlight the Recursive Model Index (RMI)\n[14], RadixSpline [ 13], the Piecewise Geometric Model index (PGM)\n[7], and the Practical Learned Index (PLEX) [ 30]. Examples of sci-\nentific applications of learned indexes include geospatial indexing\n[25], sensor time series indexing [5], and DNA sequencing [11].\nEarly work on learned indexes focused on in-memory, static key\nlookups. These indexes relied on approximating the CDF in order\nto find the key in a sorted array with few data accesses. The core\nidea is that if ğ‘ƒ(ğ´â‰¤ğ‘¥)is the proportion of elements smaller than\na keyğ‘¥, then the position of the key ğ‘¥in a sorted array with ğ‘\nelements is ğ‘ğ‘œğ‘ =âŒŠğ‘Ã—ğ‘ƒ(ğ´â‰¤ğ‘¥)âŒ‹.\nMarcus et al. demonstrated that learned indexes were effective\non read-only workloads [ 21]. Their experimental results show thatarXiv:2307.08637v1  [cs.LG]  17 Jul 2023\n\nSSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA Ivan Carvalho and Ramon Lawrence\nthe RMI, the PGM, and the RadixSpline always outperform state-\nof-the-art traditional indexes on look-up time and size, losing just\non build time.\nThe two-layer RMI is used by LearnedSort. Mathematically, it is\ndescribed by:\nğ¹(ğ‘¥)=ğ‘“âŒŠğµÃ—ğ‘“1(ğ‘¥)âŒ‹\n2(ğ‘¥)\nThe RMI consists of the root model ğ‘“1and ofğµsecond-level\nmodelsğ‘“(ğ‘–)\n2for0â‰¤ğ‘–<ğµ. The root model can be interpreted as an\ninitial approximation of the CDF function that selects one of the ğµ\nmodels in the next level. The second-level models by consequence\ncan be seen as models specializing on a specific region of the CDF.\nThe RMI architecture is extremely flexible. ğ‘“1andğ‘“(ğ‘–)\n2can have\narbitrary model types such as linear, cubic or radix models. The\nnumber of second-level models ğµcan also be configured. Learned-\nSort uses a RMI with linear models and ğµ=1000.\n2.2 Sorting with Machine Learning Models\nSorting with machine learning models goes beyond applying a\nsingle pass of ğ´[ğ¹(ğ‘¥)]=ğ‘¥for all elements. To engineer a practical\nimplementation, many details need to be resolved.\nThe first detail is that ğ´[ğ¹(ğ‘¥)]=ğ‘¥has a hostile memory-access\npattern to modern CPUs, as it performs mostly random accesses to\nthe memory. Kristo et al. reported that even with a perfect model,\napplying the model directly was slower than optimized versions of\nRadixSort. This prompted the authors to try other approaches such\nas using buckets.\nAnother key detail is that the model is imperfect and inversions\ncan happen i.e. there are ğ‘¥,ğ‘¦such thatğ‘¥<ğ‘¦butğ¹(ğ‘¥)>ğ¹(ğ‘¦).\nAlthough uncommon for good models, the implementation needs\nto handle those cases to guarantee that the output is sorted.\nMoreover, collisions between elements can happen i.e. there\nareğ‘¥,ğ‘¦such thatğ¹(ğ‘¥)=ğ¹(ğ‘¦). Since it is possible to have only\none element at position ğ¹(ğ‘¥), the implementation must handle\ncollisions. Collisions are exacerbated by duplicates in the input,\nas all duplicate values ğ‘¥will collide at ğ¹(ğ‘¥). Duplicates are very\ncommon when sorting.\nKristo et al. improved the algorithm handling of these challenges\nand produced LearnedSort 2.0 [ 16]. LearnedSort 2.0 consists of four\nroutines: training the model, two rounds of partitioning, model-\nbased Counting Sort, and a correction step with Insertion Sort.\nTraining the model is the first routine of LearnedSort and re-\nquires the most empirical data for good performance. It is necessary\nto select a model type and sample size to train the CDF model. Kristo\net al. chose the two-layer RMI as the model. Since producing the\noptimal RMI is computationally more expensive than sorting an ar-\nray with Quicksort [ 22], the authors fixed the root and second-level\nmodel types to be linear models. They also picked a sample size of\n1%ofğ‘to train the RMI. These choices yield excellent results in\npractice. The model can be trained quickly and its predictions are\naccurate enough such that the sorting performance can outperform\nother state-of-the-art sorting algorithms.\nThe partitioning routine is in-place and uses the model to split\nthe data into ğµ=1000 buckets. For each element, LearnedSort\ncalculates its corresponding bucket using ğ‘ğ‘–=âŒŠğµÃ—ğ‘ƒ(ğ´â‰¤ğ‘¥)âŒ‹and\nadds the element to the buffer associated with ğ‘ğ‘–. When a buffer gets\nfull, LearnedSort flushes the buffer. After processing all elements,the fragments of each bucket ğ‘ğ‘–are scattered across the input. To\nsolve this, LearnedSort implements a defragmentation pass that\nmakes the buckets contiguous. LearnedSort applies the partitioning\nroutine twice, splitting the data into 1000 buckets and then splitting\neach of those buckets into 1000 sub-buckets.\nTo handle duplicates, Learned Sort 2.0 performs a homogeneity\ncheck after partitioning: if all elements within a bucket are equal,\nthe bucket is left as is because it is already sorted. This condition\nhandles the collision case that reduced the performance of the\noriginal LearnedSort.\nThe base case for LearnedSort is a Model-Based Counting Sort\nthat uses the CDF to predict the final position of the keys in the sub-\nbuckets. Lastly, Insertion Sort is executed to correct the possible\nmistakes from the RMI and guarantee that the output is sorted. Since\nthe sequence is almost sorted, Insertion Sort is cheap to execute in\npractice.\n2.3 Quicksort\nAlthough Quicksort is asymptotically optimal, engineering a good\nimplementation of Quicksort can drastically improve its efficiency.\nThis requires avoiding Quicksortâ€™s worst case with bad pivots and\nsqueezing all the performance available by modern hardware.\nIntroSort is a hybrid Quicksort algorithm [ 24] that avoids the\nÎ˜(ğ‘2)worst-case by switching to HeapSort [ 32] when the recur-\nsion depth exceeds O(logğ‘). IntroSort has been chosen by some\npopular libraries, such as the GNU C++ library, to be their default\nsorting algorithm.\nPattern-defeating Quicksort (pdqsort) is an enhanced version of\nIntroSort [ 26]. It incorporates many improvements on partitioning\nand sorts inO(ğ‘min(logğ‘,ğ¾))whereğ¾is the number of distinct\nelements on the input. pqdsort also leverages the contributions\nof BlockQuicksort [ 6], which processes the elements in blocks to\navoid branch mispredictions. pqdsort is currently the algorithm\nimplemented by the Rust Standard Library for unstable sorting.\nVectorized Quicksort is a new implementation of Quicksort that\nuses Single Instruction, Multiple Data (SIMD) to exploit the paral-\nlelism available in modern CPUs [ 31]. Wassenberg et al. managed\nto vectorize each individual step of Quicksort: pivot selection, parti-\ntioning, and the sorting networks for the base case. By building on\ntop of a high-level SIMD library, the authors were also able to port\ntheir implementation to seven distinct instruction sets, which is un-\ncommon as previous implementations were generally not portable.\nA takeaway from advancements in Quicksort is that engineering\nis a core part of high-performance sorting and that implementa-\ntion details matter. Implementation optimizations improved perfor-\nmance in Learned Sort 2.0, and such optimizations are important\nfor high parallel performance.\n2.4 SampleSort\nSampleSort is a generalization of Quicksort to ğ‘˜pivots [ 8]. The\nincreased number of pivots pushes the number of comparisons\nof the algorithm closer to the log2ğ‘›!theoretical bound, giving it\nan edge over Quicksort. It also makes the algorithm suitable for\nparallel processing, as SampleSort creates ğ‘˜+1perfectly parallel\nsub-problems.\n\nLearnedSort as a learning-augmented SampleSort: Analysis and Parallelization SSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA\nSimilar to Quicksort, engineering a good implementation of Sam-\npleSort can significantly boost performance. Sanders and Winkel\nintroduced the Super Scalar SampleSort in [ 27]. Their implementa-\ntion of SampleSort exploits instruction-level parallelism available\nin modern CPUs. Sanders and Winkel organize the pivots into a\nbranchless decision-tree that is friendly to optimization techniques\nsuch as pipelining and loop unrolling. This made their implementa-\ntion competitive on single-core sequential settings.\nAxtmann et al. take a step further in [ 1], introducing the In-place\nParallel Super Scalar SampleSort ( IPS4o).IPS4ois the state-of-the-\nart SampleSort implementation incorporating many improvements.\nOne key improvement of IPS4ois the in-place partitioning. Previ-\nous SampleSort implementations allocated O(ğ‘)memory to copy\nelements of the input. IPS4oinstead uses buffers of size ğ‘for each\nof theğ‘˜buckets. It allocates O(ğ‘˜ğ‘)total memory and when a buffer\nis full it flushes the buffer and overwrites some of the data of the\noriginal input that has already been processed. This initial pass cre-\natesO(ğ‘/ğ‘)blocks. Afterwards, IPS4opermutes the blocks such\nthat each bucket is contiguous in memory using a routine similar\nto defragmentation. Conceptually, the blocking strategy adopted\nbyIPS4oshares many ideas with those adopted by LearnedSort,\nBlockQuicksort, and pdqsort.\nOther improvements of IPS4oinclude the parallelization and\nthe equality buckets. IPS4ouses atomic fetch-and-add operations\nto parallelize the block partitioning and leverages a custom task\nscheduler to manage threads when the sub-problems become small.\nIPS4oalso gracefully handles inputs with many duplicates with\nequality buckets. It detects skewed inputs on sampling and creates\na separate bucket for the duplicates when doing the partitioning.\nAs a sequence where all elements are equal is already sorted, IPS4o\navoids having to process the duplicate elements in the equality\nbuckets.\nIt is also worth highlighting the ability to use IPS4oas a frame-\nwork for building other sorting algorithms. Axtmann et al. also in-\ntroduced the In-place Parallel Super Scalar Radix Sort ( IPS2Ra) [1].\nIPS2Racombines the qualities of IPS4owith the most-significant-\ndigit radix sort strategy, resulting in another high-performance\nsorting algorithm. IPS4ohas also been used to parallelize Vector-\nized Quicksort [ 31] and to test the efficiency of sorting networks\nas base cases for sorting algorithms [2].\nThis work reuses the IPS4oframework to parallelize LearnedSort.\nThis allows the combination of the engineering efforts of IPS4owith\nthe best qualities of LearnedSort.\n2.5 Algorithms with Predictions\nThe area of algorithms with predictions [ 23] goes beyond worst-\ncase analysis and considers algorithms augmented with machine\nlearning models. For each algorithm, we can think of a prediction\nand a quality metric ğœ‚for the prediction that depends on an error\nspecified by the problem type. In case ğœ‚is good, the algorithm\nproceeds to use the outputs from the model to solve the problem\ninstance. Otherwise, it has a fallback mechanism that uses a tradi-\ntional, prediction-less algorithm when the machine learning models\nfail. We expect that for real-world workflows, the outputs from the\nmodel will generally be used due to patterns found in the data.A prominent example of the area is caching with predictions\n[19]. Lykouris and Vassilvitskii solve the online caching problem\nwith a machine learning model trained to predict the furthest time\nin the future an element will come back to the cache. Their model is\ninspired by the offline solution to the problem, the greedy Furthest-\nIn-Future algorithm that out of all elements removes the one that\nappears the latest in the future. To prevent the worst-case that\nhappens when the model is sub-optimal, they fall back to the classic\nMarker algorithm.\nAlgorithms with predictions share many similarities with Learned-\nSort. Both implement machine learning models and avoid the worst-\ncase due to the quality of the predictions. Thus, it is natural to ask\nif LearnedSort is an algorithm with predictions. The next section\ndiscusses how LearnedSort is analogous to a SampleSort in which\nthe pivots were learned.\n3 ANALYZING LEARNEDSORT\nTo analyze LearnedSort under the lens of algorithms with predic-\ntions, it is important to determine what LearnedSort is trying to\npredict and what makes for a good prediction for a sorting algo-\nrithm.\nFrom a high-level perspective, ignoring implementation details,\nwhat makes Quicksort an efficient algorithm is the quality of its\npivots. The BFPRT algorithm, also known as median of medians, is\na method to find an element that is guaranteed to be between the\n30th and 70th percentile of the input [ 4]. It is possible to combine\nQuicksort with the BFPRT to produce a deterministic Quicksort\nwith worst-case complexity of Î˜(ğ‘logğ‘)[17]. Hence, the quality\nof the pivots can avoid the worst-case of randomized Quicksort.\nInspired by the deterministic Quicksort, the analysis of Learned-\nSort in split into three parts. The first part introduces Quicksort\nwith Learned Pivots, a variation of Quicksort where the CDF model\nselects the pivot. That section shows that training a CDF model\nis akin to other pivot selection techniques such as applying the\nBFPRT algorithm. The second part analyzes Learned Quicksort, a\nsimplified LearnedSort with ğµ=2buckets. It turns out that Learned\nQuicksort is in fact analogous to a Quicksort with Learned Pivots\nbut with implicit pivots. Lastly, the third section considers ğµ>2\nand the connections between LearnedSort and SampleSort.\n3.1 Quicksort with Learned Pivots\nThe analysis starts with the pseudocode of our Quicksort variant\nshown in Algorithm 1. For simplicity, assume that all elements on\nthe inputğ´are distinct. The algorithm is identical to many other\nQuicksort implementations with the exception of the partitioning\ncall.\nAlgorithm 1: Quicksort(A, l, r)\nifdistance(l, r)â‰¤BASECASE_SIZE then\nInsertionSort(A, l, r);\nreturn ;\nqâ†PartitionWithLearnedPivot(A, l, r);\nQuicksort(A, l, q-1);\nQuicksort(A, q + 1, r);\nreturn ;\n\nSSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA Ivan Carvalho and Ramon Lawrence\nAlgorithm 2 describes how to use the CDF models to select an\noptimal pivot. Essentially, our goal is to find the median of the input.\nTo do so, we select the largest element ğ´[ğ‘¡]such that the predicted\nCDF is smaller than or equal to the true CDF of the median.\nAlgorithm 2: PartitionWithLearnedPivot(A, l, r)\nSâ†Sample(A, l, r);\nHeapSort(S, 0, S.size() - 1);\nFâ†TrainCDFModel(S, 0, S.size() - 1); // Function that\ncalculates P(A <= x) in [0, 1]\n/* Select the largest element from A that has\nthe predicted CDF less than the true median */\ntâ†-1;\nforğ‘¤â†ğ‘™toğ‘Ÿdo\nifF(A[w])â‰¤0.5 and (t < 0 or A[w] > A[t]) then\nğ‘¡â†w;\nswap(A[t], A[r]);\n/* After selecting the pivot with the CDF model,\nwe can use any classic partition scheme */\npivotâ†A[r];\niâ†l - 1;\nforğ‘—â†ğ‘™toğ‘Ÿâˆ’1do\nifA[j]â‰¤pivot then\niâ†i + 1;\nswap(A[i], A[j]);\nswap(A[i], A[r]);\nreturn i + 1;\nThe TrainCDFModel function is arbitrary such that any type of\nCDF model could work e.g. RMI, PLEX, RadixSpline. However, for\nthe CDF model to be useful, some properties should hold.\nThe first is monotonicity: ğ‘¥â‰¤ğ‘¦=â‡’ğ¹(ğ‘¥) â‰¤ğ¹(ğ‘¦). This\nproperty is necessary to ensure that the selected pivot is indeed\nclosest to the median and that the model contains no incorrect\ninversions.\nThe second is that the model needs to require a small number\nof samples. This follows from the fact that to train a CDF model\nyou need a sorted input and sorting the samples with HeapSort\ntakesO(ğ‘†logğ‘†)(although any algorithm with the same complexity\nwould work).\nThe third is that computing the predictions of the model for a\nkey should takeO(1)time. Since we need to make a prediction\nfor each of the ğ‘keys, if the time to compute a prediction is not\nconstant it would lead to an algorithm slower than the traditional\nQuicksort.\nGiven these properties, Algorithm 2 takes O(ğ‘)and its run time\nis dominated by the loop applying the model predictions and the\nLomuto partitioning step.\nThe time complexity of Algorithm 1 depends on the quality of\nthe learned pivot. In the best case, the complexity is modelled by\nğ‘‡(ğ‘)=O(ğ‘)+2ğ‘‡(ğ‘/2)which happens when the learned pivot is\nthe median. Hence, the lower bound of Algorithm 1 is Î©(ğ‘logğ‘).\nThe worst-case complexity is modelled by ğ‘‡(ğ‘)=O(ğ‘)+ğ‘‡(ğ‘âˆ’\n1)and happens when the learned pivot is the smallest element\nin the sequence. Thus, the worst-case of the algorithm is Î˜(ğ‘2)just like the original Quicksort. However, if the chosen model is a\ngood model, reaching the worst-case is unlikely. The average-case\nanalysis is much closer to the best case in practice.\nLetğœ‚be the error from finding the perfect partitioning as:\nğœ‚=max(ğ‘ƒ(ğ´â‰¤ğ‘ğ‘–ğ‘£ğ‘œğ‘¡),1âˆ’ğ‘ƒ(ğ´â‰¤ğ‘ğ‘–ğ‘£ğ‘œğ‘¡))âˆ’ 1/2\nwhereğ‘ƒ(ğ´â‰¤ğ‘ğ‘–ğ‘£ğ‘œğ‘¡)is the true CDF of the learned pivot. ğœ‚=0in\ncase the CDF model always predicts the median. ğœ‚=1/2in case the\nCDF model always predicts the smallest element. The complexity\nis then modelled by:\nğ‘‡(ğ‘)=O(ğ‘)+ğ‘‡((ğœ‚+1/2)ğ‘)+ğ‘‡((âˆ’ğœ‚+1/2)ğ‘)\nThe valueğœ‚is not known ahead of time, as it depends on the\nsample size and CDF model. However, we may assume that the\nmodel has better predictions than a random pick ğœ‚learnedâ‰¤ğœ‚random\n(otherwise we would fallback to a random pick). This implies that\nthe Quicksort with Learned Pivots runs as fast as the Randomized\nQuicksort. Thus ğ‘‡(ğ‘)âˆˆO(ğ‘logğ‘).\nQuicksort with Learned Pivots is not efficient to outperform\nIntroSort or pdqsort. However, it is conceptually useful to show\nthat training a CDF model is a step towards finding better pivots.\n3.2 Learned Quicksort\nProgressing towards analyzing LearnedSort, we introduce Learned\nQuicksort. Learned Quicksort, shown in Algorithm 3, is a simpler\nversion of LearnedSort that contains only ğµ=2buckets.\nAlgorithm 3: LearnedQuicksort(A, l, r)\nifdistance(l, r)â‰¤BASECASE_SIZE then\nInsertionSort(A, l, r);\nreturn ;\nSâ†Sample(A, l, r);\nHeapSort(S, 0, S.size() - 1);\nFâ†TrainCDFModel(S, 0, S.size() - 1);\n/* Using the predictions directly is equivalent\nto using the learned pivot */\niâ†l;\njâ†r;\nwhile i < jdo\nifF(A[i])â‰¤0.5then\niâ†i + 1;\nelse\nswap(A[i], A[j]);\njâ†j - 1;\nLearnedQuicksort(A, l, i);\nLearnedQuicksort(A, i + 1, r);\nreturn ;\nSimilar to LearnedSort, Learned Quicksort partitions the data\nusing machine learning models. Since there are only two buckets,\nthe partitioning can be done such that elements with ğ¹(ğ´[ğ‘–])â‰¤ 0.5\nare put in the initial section of the input starting from the first index\nand elements with ğ¹(ğ´[ğ‘–])>0.5are put at the end of the input\nstarting from the last index.\n\nLearnedSort as a learning-augmented SampleSort: Analysis and Parallelization SSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA\nThe partitioning done by Quicksort with Learned Pivots and\nLearned Quicksort is almost identical. The only exception is for the\nlearned pivot, which is in the last position of the first half in the\nformer. Hence, the algorithms have the same time complexity which\nmeans that Learned Quicksort has the complexity of O(ğ‘logğ‘).\nThe interesting fact about Learned Quicksort is that it does not\ncompute the pivot explicitly. Instead, it relies solely on the results\nof the model ğ¹. Computationally, this is advantageous as Learned\nQuicksort always performs less operations than Quicksort with\nLearned Pivots.\nWe may interpret Learned Quicksort as a Quicksort variant that\ncircumvents the bounds on the theoretical number of comparisons\nby embracing the numerical properties of the CDF. This is a hint to\nwhy LearnedSort is so efficient.\n3.3 LearnedSort\nWe now consider the general case of LearnedSort when ğµ>2. If\nLearned Quicksort is analogous to a Quicksort with Learned Pivots,\nLearnedSort is analogous to a SampleSort with ğµâˆ’1learned pivots.\nAlgorithm 4: LearnedPivotsForSampleSort(A, l, r)\nBâ†numberOfBuckets(A.size());\npâ†Array(B, -1); // indexes of the pivots for the\ni-th bucket\nSâ†Sample(A, l, r);\nHeapSort(S, 0, S.size() - 1);\nFâ†TrainCDFModel(S, 0, S.size() - 1);\n/* Select for each i-th percentile the largest\nelement from A that has predicted CDF less\nthan that percentile */\nforğ‘¤â†ğ‘™toğ‘Ÿdo\ngâ†âŒŠğ¹(ğ´[ğ‘¤])Ã—ğµâŒ‹;\nifp[g] < 0 or A[w] > A[p[g]] then\np[g]â†w;\npivotsâ†p.filter(vâ‰¥0).map(vâ†’A[v]);\nreturn pivots ;\nAlgorithm 4 details the process to compute the learned pivots for\nSampleSort. If we used those pivots in SampleSort, the partitioning\nwould be identical to the partitioning done by LearnedSort. Obvi-\nously, as shown in the previous section, using the model directly is\nmore advantageous as it skips the comparisons as a whole.\nThis explains why LearnedSort is effective. LearnedSort is an\nenhanced version of SampleSort, which is already a competitive\nsorting algorithm. If the learned pivots of LearnedSort are bet-\nter than the randomly selected pivots of SampleSort, we expect\nLearnedSort to beat SampleSort. Moreover, LearnedSort skips the\ncomparisons done by SampleSort and relies on the O(1)predictions\nof the model, which gives LearnedSort an additional performance\nboost.\nThere are some differences between an augmented SampleSort\nand the implementation of LearnedSort 2.0. These minor details\ncome from the authors iterating to improve LearnedSort empirically.\nThe major discrepancy is that SampleSort does O(logğµğ‘)par-\ntitioning rounds while LearnedSort does only two. We interpretthis as Kristo et al. implementing a very shallow recursion tree\nwith a large base case size. SampleSort implementations generally\nuseğµ=128orğµ=256buckets and use Insertion Sort when there\nare 16 elements or less. LearnedSort uses ğµ=1000 buckets, hence\nassuming two rounds of partitioning with around ğ‘=109ele-\nments of input that leads to around 1000 elements on average to be\nhandled by LearnedSortâ€™s base case. We hypothesize that if there\nwereğ‘=1012orğ‘=1013elements, LearnedSortâ€™s performance\nwould be hurt and a third partitioning round would be helpful.\nHowever, that input size requires over a terabyte of RAM, which\nstops being an in-memory sort problem and starts being an external\nsort instance. Thus, the implementation by Kristo et al. works well\nin practice.\nAnother discrepancy is that SampleSort samples data on every\nsub-problem while LearnedSort samples data only once. This may\nbe an optimization that comes from practical experience. Instead of\nsampling a few data points, creating 1000 sub-problems and sam-\npling for each sub-problem again, LearnedSort opts to sample a lot\nof data in bulk. This works because the recursion tree of Learned-\nSort is very shallow and because the RMI architecture supports this\nstrategy as the second-level models specialize in parts of the CDF.\nLastly, the RMI used by LearnedSort violates one assumption\nfrom our analysis. It does not guarantee that ğ‘¥â‰¤ğ‘¦=â‡’ğ¹(ğ‘¥)â‰¤\nğ¹(ğ‘¦). In practice, inversions do occur but they are relatively rare.\nThis leads to an almost-sorted sequence, which can be quickly fixed\nby Insertion Sort.\n3.4 Quality of the Pivots\nThis section analyzes the quality of the learned pivots implicitly\nused by LearnedSort. For two datasets, the uniform distribution\nand the Wiki/Edit data, the RMI created by LearnedSort was used\nwith Algorithm 4 to calculate the pivots in the first partitioning\nstep. The RMI pivots were compared with the random pivots used\nby IPS4o.\nTable 1: Comparison of Pivot Quality\nRandom (255 pivots) RMI (255 pivots)\nUniform 1.1016 0.4388\nWiki/Edit 0.9991 0.5157\nTable 2: Quality of the pivots for IPS4o(Random) and\nLearnedSort (RMI)\nThe sorted data was used to calculate the true CDF, ğ‘ƒ(ğ´â‰¤ğ‘ğ‘–),\nfor each pivot ğ‘ğ‘–. The metric used for the quality was the distance\nbetween the CDF of the pivots and the CDF of the perfect splittersÃğµâˆ’2\nğ‘–=0|ğ‘ƒ(ğ´â‰¤ğ‘ğ‘–)âˆ’(ğ‘–+1)/ğµ|. For simplicity, we matched the number\nof pivots used by IPS4owith the number of pivots computed by the\nRMI, although LearnedSort uses more pivots in practice.\nThe results in Table 2 display that the learned pivots are indeed\nbetter than the random pivots.\n\nSSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA Ivan Carvalho and Ramon Lawrence\n4 PARALLELIZATION OF LEARNEDSORT\nOne direct consequence from the previous analysis is that the\nprogress in engineering a fast SampleSort transfers to Learned-\nSort. A relevant limitation of LearnedSort 2.0 is that there is only a\nsequential version available that cannot use all the cores present in\nmodern CPUs to sort data in parallel. This limits applying Learned-\nSort to real-world workflows.\nTo address this limitation, we introduce the Augmented In-place\nParallel SampleSort ( AIPS2o).AIPS2ois a hybrid of IPS4owith\nLearnedSort. It is built upon the codebase available from IPS4oand\naugments it with the RMI implementation used in LearnedSort.\nAlgorithm 5: BuildPartitionModel(A, l, r)\nSâ†Sample(A, l, r);\nSort(S, 0, S.size() - 1);\nifInputSizeIsLarge(l, r) and not TooManyDuplicates(S) then\n// we sample more data as the RMI benefits\nfrom larger samples\nRâ†LargerSample(A, l, r);\nSort(R, 0, R.size() - 1);\nrmiâ†BuildRMI(R);\nreturn rmi;\nelse\ntreeâ†BuildBranchlessDecisionTree(S);\nreturn tree;\nHow AIPS2oselects its partitioning strategy is in Algorithm 5.\nEssentially, if the input size is sufficiently large and there are not\ntoo many duplicates, the routine samples more data and returns a\ntrained RMI. Otherwise, it builds and returns the decision tree used\ninIPS4o. For our implementation, we use ğµ=1024 buckets for the\nRMI. We default to the decision tree with ğµ=256if the input size\nis smaller than ğ‘=105or if there are more than 10% of duplicates\nin the first sample.\nSince AIPS2ouses the framework from IPS4o, it profits from the\nparallelization of the latter. Another feature it inherits from IPS4o\nis the handling of duplicates, which avoids the common adversarial\ncase for LearnedSort by using the equality buckets from the decision\ntree.\nThere are additional modifications to make AIPS2owork as well.\nThe most critical modification is making the RMI monotonic such\nthatğ‘¥â‰¤ğ‘¦=â‡’ğ¹(ğ‘¥)â‰¤ğ¹(ğ‘¦)holds. This is necessary to avoid\napplying Insertion Sort to guarantee the correctness. To implement\na monotonic RMI, we had to constraint the second-level linear\nmodels such that maxğ‘¥âˆˆğ‘…ğ‘“(ğ‘–)\n2(ğ‘¥)â‰¤minğ‘¥âˆˆğ‘…ğ‘“(ğ‘–+1)\n2(ğ‘¥). This incurs\ntwo additional accesses to an array storing the minimums and\nmaximums when processing an element.\nThe base case is also modified. Model-based counting sort is not\nused as the algorithm never forwards the RMI between recursive\ncalls. Instead, SkaSort is used for the base case when there are less\nthan 4096 elements [ 28]. SkaSort is a fast radix sort that is the base\ncase for IPS2Ra.5 EXPERIMENTAL RESULTS\nAIPS2ois compared against other sorting algorithms on the bench-\nmark presented in the Learned Sort 2.0 paper [ 16]. For reproducibil-\nity, benchmarks were executed on the m5zn.metal instance from\nAWS. The instance runs an Intel Â®Xeon Â®Platinum 8252C CPU @\n3.80GHz with 48 cores, 768KB of L1 cache, 24MB of L2 cache, 99\nMB of L3 cache, and 192 GB of RAM.\nThe four competitors with AIPS2oare the following. IPS4o, the\nstate-of-the-art implementation of SampleSort. IPS2Ra, the radix\nsort implementation built on top of the framework for IPS4o. Learned\nSort, one of the fastest sequential sorting algorithms as discussed\nearlier. std::sort from the C++ STL, as the baseline for the ex-\nperiment. The implementations were written in C++ and compiled\nwith GCC 11 using the -O3 and -march=native flags.\nThe benchmark includes sequential and parallel settings. We\nrefer to the sequential versions of the algorithms as AI1S2o,I1S4o,\nandI1S2Rafor consistency as they are not parallel. We provide\nstd::execution::par_unseq as an argument to std::sort when\nexecuting in parallel. To sort floating point numbers with IPS2Ra,\nwe use a key extractor that maps floats to integers. Learned Sort\nis not in the parallel benchmark because there is only a sequential\nimplementation. The parallel benchmark uses all of the 48 cores\navailable in the machine.\nThe datasets used in the benchmark consist of synthetic and real-\nworld data. The synthetic portion contains 64-bit double floating-\npoint elements from various probability distributions. The real-\nworld portion contains 64-bit unsigned integer elements mostly\nfrom the work of Marcus et al. [ 21]. For N=108, data size is 800\nMB.\nSynthetic Datasets\nâ€¢Uniform (N = 108): Uniform distribution with ğ‘=0and\nğ‘=ğ‘\nâ€¢Normal (N = 108): Normal distribution with ğœ‡=0andğœ=1\nâ€¢Log-Normal (N = 108): Log-normal distribution with ğœ‡=0\nandğœ=0.5\nâ€¢Mix Gauss (N = 108): Random additive distribution of five\nGaussian distributions\nâ€¢Exponential (N = 108): Exponential Distribution with ğœ†=2\nâ€¢Chi-Squared (N = 108):ğœ’2distribution with ğ‘˜=4\nâ€¢Root Dups (N = 108): Sequence of ğ´[ğ‘–]=ğ‘–modâˆš\nğ‘as\nproposed in [6]\nâ€¢Two Dups (N = 108): Sequence of ğ´[ğ‘–]=ğ‘–2+ğ‘/2modğ‘\nas proposed in [6]\nâ€¢Zipf (N = 108): Zipfian distribution with ğ‘ zipf=0.75\nReal-World Datasets\nâ€¢OSM/Cell_IDs (N = 2Â·108): Uniformly sampled location\nIDs from OpenStreetMaps.\nâ€¢Wiki/Edit (N = 2Â·108): The edit timestamps from Wikipedia\narticles\nâ€¢FB/IDs (N = 2Â·108): The IDs from Facebook users sampled\nin a random walk of the network graph\nâ€¢Books/Sales (N = 2Â·108): Book popularity data from Amazon\nâ€¢NYC/Pickup (N = 108): The yellow taxi trip pick-up time\nstamps\n\nLearnedSort as a learning-augmented SampleSort: Analysis and Parallelization SSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA\n5.1 Sequential Results\nThe sorting rate of the sequential algorithms is in Figures 1, 2, and 3.\nThe rate is measured by keys per second and indicates the through-\nput of each algorithm. The numbers are the mean of 10 executions\nof the algorithms. Higher rates indicate better algorithms.\n0 15M/s 30M/s 45M/s 60M/s 75M/s 90M/s\nSorting Rate (keys/sec)Uniform\nNormal\nLog Normal\nMix Gauss\nExponentialPerformance of Sequential Sorting Algorithms in Synthetic Datasets\nAlgorithms\nAI1S2oI1S2raI1S4o LearnedSort std::sort\nFigure 1: Sorting throughput of the sequential algorithms.\nHigher rates are better.\nLearnedSort is the fastest in 9 out of 14 of the datasets, claiming\nthe first spot in the sequential benchmark. I1S2Racomes second,\nbeating the competitors in 4 datasets. Surprisingly, I1S2Raoutper-\nforms LearnedSort in most of the real-world datasets that were\ncreated to benchmark the RMIs that power LearnedSort. I1S4ois\nthe fastest only for one dataset, Root Dups, that it handles gracefully\ndue to its equality buckets.\nAI1S2ois outperformed in the sequential benchmark. It is faster\nthan the baseline of std::sort . Nevertheless, the hybrid algorithm\nis slower than both LearnedSort and I1S4othat provide its inner\nparts.\nWe attribute the slower sequential results to the more costly train-\ning step of AI1S2o. It is important to recall that the training time is\naccounted in the sorting time for AI1S2oand LearnedSort. AI1S2o\nsamples more data than I1S4oon each partitioning step, which\nincurs a penalty as we need to sort those samples. The advantage\nof having better pivots is offset by the training cost. AI1S2oalso\nspends more time training models than LearnedSort as LearnedSort\ntrains the RMI only once while AI1S2otrains a RMI per recursive\ncall.\nAs we will see in the next section, AIPS2ois a more competitive\nparallel algorithm. We found that adjusting the sample size and\ntraining time had little to no improvement on the sequential case\nbut improved the parallel performance.\n0 15M/s 30M/s 45M/s 60M/s 75M/s 90M/s\nSorting Rate (keys/sec)Chi Squared\nRoot Dups\nT wo Dups\nZipfPerformance of Sequential Sorting Algorithms in Synthetic Datasets\nAlgorithms\nAI1S2oI1S2raI1S4o LearnedSort std::sortFigure 2: Sorting throughput of the sequential algorithms.\nHigher rates are better.\n0 15M/s 30M/s 45M/s 60M/s 75M/s 90M/s\nSorting Rate (keys/sec)OSM/Cell_IDs\nWiki/Edit\nFB/IDs\nBooks/Sales\nNYC/PickupPerformance of Sequential Sorting Algorithms in Real-World Datasets\nAlgorithms\nAI1S2oI1S2raI1S4o LearnedSort std::sort\nFigure 3: Sorting throughput of the sequential algorithms.\nHigher rates are better.\n5.2 Parallel Results\nThe sorting rate of the parallel algorithms is in Figures 4, 5, and 6.\nThe rate is measured by keys per second and indicates the through-\nput of each algorithm. The rates come from the mean of 10 execu-\ntions of the algorithms.\n\nSSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA Ivan Carvalho and Ramon Lawrence\n0 2B/s 4B/s 6B/s 8B/s 9B/s\nSorting Rate (keys/sec)Uniform\nNormal\nLog Normal\nMix Gauss\nExponentialPerformance of Parallel Sorting Algorithms in Synthetic Datasets\nAlgorithms\nAIPS2oIPS2raIPS4o std::sort\nFigure 4: Sorting throughput of the parallel algorithms.\nHigher rates are better.\n0 2B/s 4B/s 6B/s 8B/s 9B/s\nSorting Rate (keys/sec)Chi Squared\nRoot Dups\nT wo Dups\nZipfPerformance of Parallel Sorting Algorithms in Synthetic Datasets\nAlgorithms\nAIPS2oIPS2raIPS4o std::sort\nFigure 5: Sorting throughput of the parallel algorithms.\nHigher rates are better.AIPS2ois the fastest in 10 out of 14 of the datasets, claiming the\nfirst spot in the parallel benchmark. IPS4ocomes second finishing\nas the fastest in 4 out of 14 datasets. std::sort places third. IPS2Ra\nfinishes last, behind the baseline on the majority of cases.\n0 2B/s 4B/s 6B/s 8B/s 9B/s\nSorting Rate (keys/sec)OSM/Cell_IDs\nWiki/Edit\nFB/IDs\nBooks/Sales\nNYC/PickupPerformance of Parallel Sorting Algorithms in Real-World Datasets\nAlgorithms\nAIPS2oIPS2raIPS4o std::sort\nFigure 6: Sorting throughput of the parallel algorithms.\nHigher rates are better.\nThe key to high parallel performance is an algorithmâ€™s abilitity to\nmaximize the use of the hardware. AIPS2ocreates the best partition\nof the data for the majority of cases, which creates many sub-\nproblems of a balanced size. This favours the performance of AIPS2o\nbecause it manages to keep every thread of the CPU busy always\ndoing work. It also hurts AIPS2owhen the RMI does not model the\ndata as accurately. The lowest throughputs of AIPS2ohappen on\nthe FB/IDs and Wiki/Edit datasets, which are known to be harder\nfor the RMI than the Books/Sales and OSM/Cell_IDs datasets [ 20].\nBy contrast, IPS2Radoes not manage to use all the hardware\nbecause its partitions are not balanced. There are no bounds on\nthe number of elements that have the same radix prefix and go in\nthe same bucket. Hence, IPS2Ramay end with threads waiting for\nwork, hurting its sorting rate compared to AIPS2oandIPS4owhich\nalways keep threads busy. This is particularly relevant to show that\nhaving a fast sequential algorithm does not necessarily imply a fast\nparallel algorithm and vice-versa.\nThe benchmarks demonstrate that AIPS2ois a practical algo-\nrithm. It is a parallel LearnedSort that achieves excellent sorting\nrates in many datasets. We expect that continuous work will help\nAIPS2obecome more robust against data distributions like the one\nfrom FB/IDs, finally closing the gap between AIPS2oandIPS4oon\nthe cases where the latter wins.\n\nLearnedSort as a learning-augmented SampleSort: Analysis and Parallelization SSDBM 2023, July 10â€“12, 2023, Los Angeles, CA, USA\n6 CONCLUSION AND FUTURE WORK\nThis paper argues that LearnedSort is analogous to a SampleSort\nwith pivots selected by a CDF model. This helps explain the effec-\ntiveness of LearnedSort by comparing it to SampleSort. We intro-\nduced the Augmented In-place Parallel SampleSort, combining the\nstate-of-the-art implementation of SampleSort with LearnedSort.\nThe benchmarks demonstrated that Augmented In-place Parallel\nSampleSort is a practical parallel implementation of LearnedSort\nthat can outperform the fastest parallel sorting algorithm in the ma-\njority of the tested inputs including both synthetic and real-world\ndata sets.\nFuture work in this research direction is to explore how machine\nlearning models can be applied to other use cases in sorting. Some\npossibilities include:\nGPU Sorting : Can the RMI or other learned indexes be combined\nwith GPU SampleSort [18]?\nString Sorting : Can learned indexes targeting strings [ 29] be\ncombined with String SampleSort [3]?\nSampling and Pivot Quality : Can the quality of the learned\npivots improve if combined with better sampling techniques [ 10]?\nREFERENCES\n[1]Michael Axtmann, Sascha Witt, Daniel Ferizovic, and Peter Sanders. 2022. En-\ngineering In-Place (Shared-Memory) Sorting Algorithms. ACM Trans. Parallel\nComput. 9, 1, Article 2 (Jan 2022), 62 pages. https://doi.org/10.1145/3505286\n[2]Timo Bingmann, Jasper Marianczuk, and Peter Sanders. 2020. Engineering faster\nsorters for small sets of items. Software: Practice and Experience 51, 5 (Nov. 2020),\n965â€“1004. https://doi.org/10.1002/spe.2922\n[3]Timo Bingmann and Peter Sanders. 2013. Parallel String Sample Sort. In Lecture\nNotes in Computer Science . Springer Berlin Heidelberg, 169â€“180. https://doi.org/\n10.1007/978-3-642-40450-4_15\n[4]Manuel Blum, Robert W. Floyd, Vaughan Pratt, Ronald L. Rivest, and Robert E.\nTarjan. 1973. Time bounds for selection. J. Comput. System Sci. 7, 4 (1973),\n448â€“461. https://doi.org/10.1016/S0022-0000(73)80033-9\n[5]David Ding, Ivan Carvalho, and Ramon Lawrence. 2023. Using Learned Indexes\nto Improve Time Series Indexing Performance on Embedded Sensor Devices. In\nProceedings of the 12th International Conference on Sensor Networks . SCITEPRESS -\nScience and Technology Publications. https://doi.org/10.5220/0011692900003399\n[6]Stefan Edelkamp and Armin WeiÃŸ. 2016. BlockQuicksort: How Branch Mispre-\ndictions donâ€™t affect Quicksort. https://doi.org/10.48550/arXiv.1604.06697\n[7]Paolo Ferragina and Giorgio Vinciguerra. 2020. The PGM-index: a fully-dynamic\ncompressed learned index with provable worst-case bounds. PVLDB 13, 8 (2020),\n1162â€“1175. https://doi.org/10.14778/3389133.3389135\n[8]W. D. Frazer and A. C. McKellar. 1970. Samplesort: A Sampling Approach to\nMinimal Storage Tree Sorting. J. ACM 17, 3 (jul 1970), 496â€“507. https://doi.org/\n10.1145/321592.321600\n[9]Goetz Graefe. 2006. Implementing sorting in database systems. Comput. Surveys\n38, 3 (Sept. 2006), 10. https://doi.org/10.1145/1132960.1132964\n[10] Vipul Harsh, Laxmikant Kale, and Edgar Solomonik. 2019. Histogram Sort\nwith Sampling. In The 31st ACM Symposium on Parallelism in Algorithms and\nArchitectures . ACM. https://doi.org/10.1145/3323165.3323184\n[11] Darryl Ho, Jialin Ding, Sanchit Misra, Nesime Tatbul, Vikram Nathan, Vasimuddin\nMd, and Tim Kraska. 2019. LISA: Towards Learned DNA Sequence Search.arXiv:1910.04728 [cs.DB]\n[12] C. A. R. Hoare. 1962. Quicksort. Comput. J. 5, 1 (01 1962), 10â€“16. https:\n//doi.org/10.1093/comjnl/5.1.10\n[13] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper,\nTim Kraska, and Thomas Neumann. 2020. RadixSpline: a single-pass learned\nindex. In Proceedings of the Third International Workshop on Exploiting Artificial\nIntelligence Techniques for Data Management . 1â€“5.\n[14] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The\ncase for learned index structures. In Proceedings of the 2018 SIGMOD International\nConference on Management of Data . 489â€“504.\n[15] Ani Kristo, Kapil Vaidya, Ugur Ã‡etintemel, Sanchit Misra, and Tim Kraska. 2020.\nThe Case for a Learned Sorting Algorithm. In Proceedings of the 2020 ACM SIG-\nMOD International Conference on Management of Data (Portland, OR, USA) (SIG-\nMOD â€™20) . Association for Computing Machinery, New York, NY, USA, 1001â€“1016.\nhttps://doi.org/10.1145/3318464.3389752\n[16] Ani Kristo, Kapil Vaidya, and Tim Kraska. 2021. Defeating duplicates: A re-design\nof the LearnedSort algorithm. https://doi.org/10.48550/arXiv.2107.03290\n[17] Noriyuki Kurosawa. 2016. Quicksort with median of medians is considered\npractical. https://doi.org/10.48550/arXiv.1608.04852\n[18] Nikolaj Leischner, Vitaly Osipov, and Peter Sanders. 2010. GPU sample sort. In\n2010 IEEE International Symposium on Parallel & Distributed Processing (IPDPS) .\nIEEE, 1â€“10.\n[19] Thodoris Lykouris and Sergei Vassilvitskii. 2021. Competitive caching with\nmachine learned advice. Journal of the ACM (JACM) 68, 4 (2021), 1â€“25.\n[20] Marcel Maltry and Jens Dittrich. 2022. A critical analysis of recursive model\nindexes. Proceedings of the VLDB Endowment 15, 5 (Jan. 2022), 1079â€“1091. https:\n//doi.org/10.14778/3510397.3510405\n[21] Ryan Marcus, Andreas Kipf, Alexander van Renen, Mihail Stoian, Sanchit Misra,\nAlfons Kemper, Thomas Neumann, and Tim Kraska. 2020. Benchmarking Learned\nIndexes. Proc. VLDB Endow. 14, 1 (sep 2020), 1â€“13. https://doi.org/10.14778/\n3421424.3421425\n[22] Ryan Marcus, Emily Zhang, and Tim Kraska. 2020. CDFShop: Exploring and\nOptimizing Learned Index Structures. In Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data (Portland, OR, USA) (SIGMOD\nâ€™20). Association for Computing Machinery, New York, NY, USA, 2789â€“2792.\nhttps://doi.org/10.1145/3318464.3384706\n[23] Michael Mitzenmacher and Sergei Vassilvitskii. 2022. Algorithms with Predic-\ntions. Commun. ACM 65, 7 (jun 2022), 33â€“35. https://doi.org/10.1145/3528087\n[24] David R Musser. 1997. Introspective sorting and selection algorithms. Software:\nPractice and Experience 27, 8 (1997), 983â€“993.\n[25] Varun Pandey, Alexander van Renen, Andreas Kipf, Ibrahim Sabek, Jialin\nDing, and Alfons Kemper. 2020. The Case for Learned Spatial Indexes.\narXiv:2008.10349 [cs.DB]\n[26] Orson R. L. Peters. 2021. Pattern-defeating Quicksort. https://doi.org/10.48550/\narXiv.2106.05123\n[27] Peter Sanders and Sebastian Winkel. 2004. Super Scalar Sample Sort. In Algorithms\nâ€“ ESA 2004 , Susanne Albers and Tomasz Radzik (Eds.). Springer Berlin Heidelberg,\nBerlin, Heidelberg, 784â€“796.\n[28] Malte Skarupke. 2016. I Wrote a Faster Sorting Algorithm (Dec 2016). https:\n//probablydance.com/2016/12/27/i-wrote-a-faster-sorting-algorithm/\n[29] Benjamin Spector, Andreas Kipf, Kapil Vaidya, Chi Wang, Umar Farooq Minhas,\nand Tim Kraska. 2021. Bounding the Last Mile: Efficient Learned String Indexing.\nhttps://doi.org/10.48550/arXiv.2111.14905\n[30] Mihail Stoian, Andreas Kipf, Ryan Marcus, and Tim Kraska. 2021. Towards\nPractical Learned Indexing. https://doi.org/10.48550/arXiv.2108.05117\n[31] Jan Wassenberg, Mark Blacher, Joachim Giesen, and Peter Sanders. 2022. Vector-\nized and performance-portable quicksort. Software: Practice and Experience 52,\n12 (Aug. 2022), 2684â€“2699. https://doi.org/10.1002/spe.3142\n[32] J. W. J. Williams. 1964. Algorithm 232: Heapsort. Commun. ACM 7, 6 (1964),\n347â€“348.",
  "textLength": 46348
}