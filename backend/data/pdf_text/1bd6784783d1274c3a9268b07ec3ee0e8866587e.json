{
  "paperId": "1bd6784783d1274c3a9268b07ec3ee0e8866587e",
  "title": "Binary Search with Distributional Predictions",
  "pdfPath": "1bd6784783d1274c3a9268b07ec3ee0e8866587e.pdf",
  "text": "Binary Search with Distributional Predictions\nMichael Dinitz∗\nJohns Hopkins University\nmdinitz@cs.jhu.eduSungjin Im†\nUC Merced\nsim3@ucmerced.edu\nThomas Lavastida\nUniversity of Texas at Dallas\nthomas.lavastida@utdallas.eduBenjamin Moseley‡\nCarnegie Mellon University\nmoseleyb@andrew.cmu.edu\nAidin Niaparast‡\nCarnegie Mellon University\naniapara@andrew.cmu.eduSergei Vassilvitskii\nGoogle Research\nsergeiv@google.com\nAbstract\nAlgorithms with (machine-learned) predictions is a powerful framework for combining tra-\nditional worst-case algorithms with modern machine learning. However, the vast majority of\nwork in this space assumes that the prediction itself is non-probabilistic, even if it is generated\nby some stochastic process (such as a machine learning system). This is a poor fit for modern\nML, particularly modern neural networks, which naturally generate a distribution . We initiate\nthe study of algorithms with distributional predictions, where the prediction itself is a distri-\nbution. We focus on one of the simplest yet fundamental settings: binary search (or searching\na sorted array). This setting has one of the simplest algorithms with a point prediction, but\nwhat happens if the prediction is a distribution? We show that this is a richer setting: there\nare simple distributions where using the classical prediction-based algorithm with any single\nprediction does poorly. Motivated by this, as our main result, we give an algorithm with query\ncomplexity O(H(p) +logη), where H(p)is the entropy of the true distribution pandηis the\nearth mover’s distance between pand the predicted distribution ˆp. This also yields the first\ndistributionally-robust algorithm for the classical problem of computing an optimal binary search\ntree given a distribution over target keys. We complement this with a lower bound showing that\nthis query complexity is essentially optimal (up to constants), and experiments validating the\npractical usefulness of our algorithm.\n1 Introduction\nAlgorithms with predictions, or algorithms with machine-learned advice, has proved to be a useful\nframework for combining machine learning (which is extremely useful in the usual case but can be\nquite bad when in the worst case) with traditional worst-case algorithms (which are quite good in\nthe worst-case but do not do as well as we might hope in the usual case). While similar ideas have\nappeared in many places in the past, the formal study of this setting was pioneered by Lykouris\nand Vassilvitskii [24], and was particularly motivated by the practical success of learned index\nstructures [ 20]. The goal is usually to design an algorithm for some classical and important problem\n∗Supported in part by NSF awards 1909111 and 2228995.\n†Supported in part by NSF awards 1844939, 2121745, and 2423106, and by ONR grant N00014-22-1-2701.\n‡Supported in part by a Google Research Award, an Infor Research Award, a Carnegie Bosch Junior Faculty Chair,\nNSF grants CCF-2121744 and CCF-1845146 and ONR Grant N000142212702.\n1arXiv:2411.16030v1  [cs.LG]  25 Nov 2024\n\nin the setting when we are also provided with some type of “advice” or “prediction” (presumably given\nby some machine learning algorithm) as to what the instance is like. If the advice is “good” then we\nwant our algorithm to do extremely well, while if the advice is “bad” then we want to inherit the\ntraditional worst-case guarantee. In other words, we want the best of both worlds: good performance\nin the average case thanks to machine learning, but also robustness and good performance in the\nworst-case from traditional algorithms.\nConsider the basic problem of searching for a key in a sorted array. This problem is the first\nexample considered in the survey of Mitzenmacher and Vassilvitskii [28], as it is perhaps one of the\nsimplest yet also best-motivated settings. Given a sorted array with nelements and a target key i,\nwe can of course do a binary search for iusing only O(logn)comparisons to find its location α(i).\nBut suppose that we additionally receive a prediction ˆα(i)∈[n]of the location of the target key iin\nthe array, possibly from some machine learning system which attempts to predict the correct location\nfor each key. If the prediction is perfect ( α(i) =ˆα(i)), then it is easy to use this prediction: only one\ncomparison is needed! On the other hand, if the prediction is meaningless, then we can run classical\nbinary search. But what if the prediction is “close”? It turns out that “doubling binary search” from\nthe predicted point can be used to design an algorithm which makes at most O(log(|ˆα(i)−α(i)|))\ncomparisons [ 28]. So if the prediction is very close to the true location then we make very few queries,\nwhile if it is very far away then we recover the traditional binary search comparison bound.\nThe ability to obtain these types of results has led to an explosion of interest in algorithms with\npredictions; see Section 1.2 for some references. Sometimes the prediction itself is simple, as in the\nsearch problem, while sometimes it is quite complex, for instance encompassing a multi-dimensional\nvector. However, with only a few exceptions such as Diakonikolas et al. [12]and Angelopoulos et al.\n[5], which will be discussed in Section 1.2 in detail, all of these papers share an important feature: the\nprediction itself is non-probabilistic. That is, the prediction is a single (potentially high-dimensional)\npoint (or maybe a small number of such points). While making the setting simpler, this is not a\ngood match with the actual output of most ML systems (particularly modern neural networks),\nwhich inherently output a distribution . The question we study in this work is how to take advantage\nof the full richness of the prediction. Of course, we can always turn a distribution into a single point\nin any number of ways (using a max likelihood estimator (MLE), sampling from the distribution,\netc.). But is that always the right thing to do? Or, can we in fact do betterby taking full advantage\nof the entire predicted distribution?\n1.1 Our Results and Contributions\nIn this paper we initiate the study of algorithms with distributional predictions , focusing on the basic\nsearch in a sorted array problem described above. In addition to the classic O(logn)comparisons\nbinary search for an array of size n, we recall the “median” or “bisection” algorithm (first described\nby Knuth [19]and analyzed by Mehlhorn [27]) which probes the cell representing the median of the\ndistribution, and recurses appropriately. When the target keys are indeed drawn from the given\ndistribution, the expected query complexity (i.e. number of comparisons between elements in the\narray and the target) is bounded by H(p) + 1, where H(p)is the entropy of the distribution [ 27].\n(Note that when the distribution is uniform over nelements, this recovers the O(logn)binary search\nbound). This is in fact essentially optimal: it is known that every algorithm requires at least H(p)/3\nqueries in expectation when target keys are drawn from p[27].\nOn the other hand, it is easy to see that if target keys are notdrawn from p, then this algorithm\ncan be arbitrarily bad: it can easily be made to use Ω(n)comparisons in expectation. So our main\nquestion is the following: how can we best utilize a prediction ˆpwhich isnotthe true distribution p?\nCan we recover the near-optimality of the median algorithm without being subject to its worst-case\n2\n\nperformance?\nReduction to point distributions. We first show in Section 2.1 that the obvious approach, of\nreducing ˆpto a point prediction (whether by sampling, using a max-likelihood prediction, or some\nother method) and then using previous algorithms, is a bad idea that can lead to poor worst-case\nperformance. In addition to ruling out a natural class of algorithms, this gives additional motivation\nto our study of distributional predictions: as discussed, essentially all previous work studies the\ncase in which the prediction is a single point (in this case, location); yet, most machine-learning\nsystems will actually output a distribution. So our lower bound implies that any of these traditional\npoint-based algorithms, no matter how good the bound obtained compared to their prediction, must\nsuffer fundamentally poor performance in the real world where target keys actually come from a\ndistribution.\nMain algorithm. We then give our main result in Section 3: an algorithm which interleaves phases\nof the “median” algorithm and classical binary search to obtain a query complexity of O(H(p)+logη),\nwhere ηis the earth mover’s distance (EMD, also known as the Wasserstein W1metric) between\npand ˆp, See Section 3 for precise details. Note that H(p)≤O(logn)andlogη≤logn. So if\nour prediction ˆpis close to p, then our algorithm has performance essentially equal to the best\npossible bound H(p). On the other hand, if our prediction ˆpis far from p(so provides essentially\nno information), we do not suffer the poor performance of naively believing in ˆpand running the\nmedian algorithm on it, instead recovering a bound of O(H(p) + log η) =O(logn).\nWhile there are many notions of “distance” between distributions, EMD is a natural one in our\nsetting. Many other notions of distance, like ℓ1, do not take the geometry of the line into account.\nFor example, consider some distribution pover [n], and let p′be the distribution obtained from\npby moving γ/2probability mass from 1to2, and let p′′be the distribution obtained from pby\nmoving γ/2probability mass from 1ton. Then the ℓ1distance between pandp′isγ, and so is the\nℓ1distance between pandp′′. Yet clearly p′is a “more accurate” prediction for p. The earth mover’s\ndistance recognizes this fact, and so is a more appropriate measure than ℓ1. Similarly, popular\nmeasures such as KL-divergence (which are not technically metrics, but do give a notion of distance)\nsuffer the same flaws as ℓ1while also being extraordinarily sensitive to mismatches in the support\n(the KL-divergence can be infinite if the supports of the two distributions do not agree).\nDistributional robustness of optimal binary search trees. We have so far discussed a\ndistributional prediction setting where a target key arrives with a predicted distribution ˆpof its\nlocation. This is a strict generalization of [ 28], where the prediction is a single location in the array.\nIn their model, the location is error prone and in ours the distribution over locations is error prone.\nOur goal is to construct an effective search strategy given the target and the prediction.\nBut there is another related setting: there is a single (unknown) distribution over target keys,\nand we are given a (possibly erroneous) prediction of this distribution and are asked to design a\nsearch algorithm with minimum expected lookup time when target keys are drawn from the true\ndistribution. In other words, instead of each target key coming with a predicted distribution ˆpover\nlocations in[n]and the true location being drawn from some true distribution p, we are given ahead\nof time a predicted distribution ˆpovertarget keys [n], and are asked to design a lookup algorithm\nfor inputs that use this distribution. But then these target keys in the input are actually drawn\nfrom prather than ˆp, and do not come with target-specific predictions.\nSince any comparison-based search algorithm is equivalent to a particular binary search tree, if\nˆp=pthen this is precisely the classical problem of computing an optimal binary search tree [27].\nSo we can interpret our results as providing distributionally-robust optimal BSTs: given ˆp, we can\n3\n\nefficiently compute a BST where the expected lookup time under the true (but unknown) query\ndistribution pis at most O(H(p) +logη). Surprisingly, given the classical nature of computing\noptimal (or near-optimal) BSTs, this simple question of “what if my distribution is incorrect?” has\nnot been considered in the data structures and algorithms literature.\nWorst case lower bound. We complement our algorithmic development with a lower bound\nin Section 3.2, proving that no algorithm can use fewer than Ω(logη)queries in the worst case.\nSince Ω(H(p))is a known lower bound as well even if pis known perfectly [ 27], this implies that\nour algorithm is asymptotically tight. So if we measure accuracy of the prediction via EMD, no\nalgorithm can make asymptotically better use of a distributional prediction.\nPortfolios of predictions. There has been recent interest in the study of algorithm with multiple\npredictions, sometimes called prediction portfolios . See, for example, [ 6,14,4,17]. The goal is\nusually to do as well as the bestof the predictions in the portfolio, with the difficulty being that\nwe do not know a priori which of these predictions is best. We extend our main algorithm to this\nsetting in Section 4, showing that it is possible to use multiple distributional predictions effectively.\nExperiments. Finally, in Section 5 we give empirical evidence of the efficacy of the algorithm\nwe propose. We first use synthetic data to demonstrate the effect of distribution error on the\nperformance of the algorithm. We then evaluate it on a number of real world datasets.\n1.2 Other Related Work\nMachine learning augmented algorithms have found applications in various areas — for example,\nonline algorithms [ 24,30], combinatorial algorithms [ 13,11], differential privacy [ 3], data structures\n[22,32,25,26] and mechanism design [ 1], to name a few. In particular, online algorithms have\nbeen extensively studied with ML advice for various problems, such as online caching [ 24], ski-rental\n[30], scheduling [ 21], knapsack [ 16], set cover [ 7], and more [ 23]. Due to the vast literature, we only\nprovide a few samples.\nParticularly relevant to our setting is the work of Lin et al. [22], which initiated the study of\npredictions for binary search trees. This work investigates how to improve a treap’s guarantees when\nitem frequencies follow distributions such as the Zipfian distribution.\nAs discussed earlier, in ML augmented algorithms, predictions are typically given in the form\nof specific values, rather than distributions. Here, we discuss a few exceptions. The work by\nDiakonikolas et al. [12]studies the ski-rental problem and prophet inequalities with access to i.i.d.\nsamples from an unknown distribution. Their focus lies on the sample complexity and not on\nthe correctness of the distribution. Indeed, they obtain robustness by combining their consistent\nalgorithm and the best worst-case algorithm in a black-box manner. In contrast, we assume full\naccess to a distributional prediction and develop new ideas to obtain a tight trade-off between\nconsistency and robustness, in conjunction with natural error measures involving entropy and the\nearth mover’s distance, which take the accuracy of the distributional prediction into account.\nMore broadly the question of how to improve performance of problems where either full instances,\nor some model parameters come from a known distribution is well studied under the rubric of\ntwo-stage stochastic optimization [ 31,2], with techniques like Sample Average Approximation (SAA)\n[18] having a rich history. Similar to our setting, one can look at the robust setting, where the\ndistribution available to the algorithm is different from the true distribution that examples are drawn\nfrom, see e.g., [ 8,15,9,10]. Typically in these cases one assumes a bound on the difference between\nthe two distributions, explicitly choosing what to hedge against, and then derives optimal strategies.\n4\n\nIn contrast, in this work we aim to find a smooth trade-off on the performance of the algorithm as a\nfunction of the distance between the two distributions, coupled with an upper bound on worst-case\nperformance.\nFinally, the very recent work of Angelopoulos et al. [5]is one of the few that consider distributional\npredictions. Itshowsan optimaltradeoff between consistencyand robustness fora scheduling problem.\nHowever, their solution space explored is considerably more limited than ours, essentially consisting\nof geometric sequences with a multiplicative ratio of 2, each characterized by its starting point.\nFurther, their bound analysis is restricted to cases where the error is sufficiently small. In contrast,\nour work demonstrates how a binary search algorithm can compare generally to earth mover’s\ndistance (EMD) and a lower bound on the optimum for any predicted distribution. As a result, we\ndevelop novel algorithmic solutions that build upon a close connection to EMD.\n2 Preliminaries\nWe now formally describe our problem and setting. Let a1<···< a nbe a set of nkeys, and\np= (p1, . . . , p n)be a probability distribution over the keys. Our goal is to develop a search strategy\n(or search algorithm), which takes a target key aas input, and finds a position isuch that ai=a.\nWe aim to find search strategies with low expected search cost when the target key ais sampled\naccording to the distribution p.\nIn our analysis we will consider the number of comparisons, also known as the query complexity ,\nas the main metric of study. This metric captures the information theoretic complexity of the\nproblem, and ignores computational overhead. Formally, let the search cost C(ai)of finding aibe\nthe number of comparisons done by the algorithm when the target key is ai. The expected search\ncost is thenPn\ni=1piC(ai).\nTo aid in this goal, we are given a prediction, ˆp= (ˆp1, . . . , ˆpn), ofp. To account for the fact\nthat the predicted distribution may be incorrect, we let ηdenote the earth mover’s distance (EMD)\nbetween pandˆp. The EMD between two distributions PandQis the solution to the optimal\ntransport problem between them, or more formally, it is infγ∼Π(P,Q)E(x,y)∼γ[d(x, y)], where Π(P, Q)\nis the set of joint distributions with marginals PandQ.\nFinally, for a distribution p, we let H(p) =−Pn\ni=1pilog(pi)be the entropy of p. Throughout\nthe paper, all logarithms are in base 2.\nGiven the breadth of work on point predictions, it is tempting to try and reduce the distributional\nprediction problem to point predictions. We show that this approach does not lead to good results.\n2.1 Point Predictions from Distributions\nGiven prediction ˆpofp, suppose the algorithm first computes some point ˆαfrom ˆpand then uses the\ndoubling binary search algorithm from Mitzenmacher and Vassilvitskii [28]with prediction ˆα. This\nwill have expected running time of O(log(|ˆα−α|)), where αis the true location of the key. A natural\nquestion is whether there is some ˆαso that O(log(|ˆα−α|))is comparable to O(H(p) + log η).\nUnfortunately, this is not possible, necessitating our more involved algorithm and analysis. Let p\nbe the distribution on two atoms, with pn/4= 1/2andp3n/4= 1/2, and let ˆp=p. Clearly η= 0,\nandH(p) = 1, so any competitive algorithm must terminate after a constant number of comparisons\nin expectation. On the other hand, consider some ˆα∈[n]. Ifˆα≤n/2, then since α= 3n/4with\nprobability 1/2we have that E[log(|ˆα−α|)]≥1\n2log(n/4)) = Ω( logn). Similarly, if ˆα≥n/2, then\nsince α=n/4with probability 1/2we have that E[log(|ˆα−α|)]≥Ω(logn). Hence converting ˆpto a\npoint prediction and then using the algorithm of [28] as a black box is doomed to failure.\n5\n\n3 Algorithm\nTo develop our robust approach, recall the two baseline algorithms—traditional binary search with\nanO(logn)running time and the algorithm that recurses on the median element of the distribution,\nwith an O(H(p))running time (assuming it has access to the true distribution p).\nIn our algorithm we interleave these two approaches to get the best of both worlds. Let\na∈ {a1, . . . , a n}be the target key. We proceed recursively, keeping track of an active search range\n[ℓ, r](ifa=ai, we always have i∈[ℓ, r]). Initially, we start with ℓ= 1andr=n. The algorithm\nproceeds in iterations. Each iteration ifori= 0,1, . . .has two phases\n•Bisection. Divide the search range in half based on the predicted probabilities ˆp. Formally,\nfind an index k,ℓ≤k≤rsuch thatPk−1\nj=ℓˆpj≤1\n2SandPr\nj=k+1ˆpj≤1\n2S, where S=Pr\nj=ℓˆpj.\nCompare atoak. If they are equal, return k. Otherwise, based on the result of the comparison,\ncontinue the search on the ranges [ℓ, k−1]or[k+ 1, r].\nContinue this process for 2isteps, and if ais not found, begin the second phase.\n•Binary Search at the Endpoints. Let[ℓ, r]be the current search range. Set d=min(22i, r−\nℓ). Check if ais in the range [ℓ, ℓ+d]or[r−d, r](by comparing atoaℓ+dandar−d). If a\nis in one of these ranges, say [ℓ, ℓ+d], do a regular binary search (by choosing the middle\npoint of the range each time) on the range [ℓ, ℓ+d], until ais found. Otherwise, start the next\niteration with the new search range [ℓ+d+ 1, r−d−1].\nThe algorithm continues until ais found.\n3.1 Analysis\nThe goal is to show the following theorem with respect to the algorithm.\nTheorem 1. The expected query complexity of the described algorithm is at most 4H(p)+8max(log(η)+\n2,1) + 8 = O(H(p) + max(log( η),0)).1\nBefore formally proving the theorem, we give key intuition about the analysis. In iteration k, the\nBisection phase is continued for 2ksteps. In each step, one comparison is made, which makes the\ncost of this phase 2k.\nConsider the Binary Search at the Endpoints phase. Two comparisons are made during the phase\nunless a∈[ℓ, ℓ+d]ora∈[r−d, r]. In those cases, we run a traditional binary search on an interval\nof length d+ 1, whose cost is logd= log 22k= 2k.\nFor each key ai, it takes at most log(1\npi) + 1iterations of the Bisection phase to get to a search\nrange that has a predicted probability mass of at most pi/2. We can charge the total cost of the\niterations up to this point to the term pilog(1\npi)inH(p).\nEither we find aiearlier, in which case the total cost of the iterations can be charged to H(p),\nor there is an at least pi/2mass that was predicted to lie outside the interval, allowing us to lower\nbound η. We make this argument formal below.\nProof of Theorem 1. With probability pi, the target key athat we are looking for is ai. The goal\nis to bound the expected cost of the algorithm, which isPn\ni=1piC(ai), where C(ai)is the cost of\nthe algorithm when a=ai. Let kibe the first iteration at which ais found, assuming a=ai.\nAs mentioned earlier, the total cost of the first phase of the iterations 0 to kiisPki\nj=02j<2ki+1.\n1To account for the case where η∈[0,1)where log(η)<0, we impose a bound by taking the maximum of log(η)\nand 0.\n6\n\nAlso, the cost of the second phase in each iteration before kiis 2, and in iteration kiis at most\n2ki. So the total cost of the algorithm for iterations 0tokiis at most 3·2ki+ 2ki≤4·2ki.\nWe partition the keys based on kiinto two sets, and bound the cost of each set separately. Let\nI1:={i:ki≤log(log(4 /pi))}andI2:={i:ki>log(log(4 /pi))}.\nFirst, we bound the cost of indices in I1by a constant factor of H(p):\nX\ni∈I1piC(ai)≤4X\ni∈I1pi2ki≤4X\ni∈I1pilog(4/pi)≤4H(p) + 8.\nNow we bound the cost of the indices in I2by a constant factor of log(η). Let i∈I2. We know\nthat during iteration jof searching for ai, in the Bisection phase, the predicted probability mass in\nthe search range decreases by a factor of at least 22j. Therefore the predicted probability mass in\nthe search range [ℓ, r]at the end of the first phase in iteration ki−1is at most\n1Qki−1\nj=022j=1\n22ki−1=2\n22ki≤2\n4/pi=pi\n2,\nwhere the inequality holds because i∈I2. SoPr\nj=ℓˆpj≤pi/2. Let Di:=min(i−ℓ, r−i). In the\ntransportation problem corresponding to the earth mover’s distance between pandˆp, a probability\nmass of at least pi/2needs to be moved from point ito the outside of the interval [ℓ, r]. The\ncost of this movement in the objective function of the transportation problem is at least Di·pi/2.\nTherefore we have η≥P\ni∈I2Di·pi/2. In the Binary Search at the Endpoints phase of iteration k,\nwe probe indices within distance d= 22karound the two endpoints of the search range. Since aiis\nnot found before iteration ki, we conclude that 22ki−1< D i, which means that 2ki≤2log(Di). Let\np(I2) :=P\ni∈I2pi. We have\nX\ni∈I2piC(ai)≤4X\ni∈I2pi2ki≤8X\ni∈I2pilog(Di) = 8\nX\ni∈I2pilog(Di) + (1 −p(I2)) log(1)\n.\nBy concavity of the log(·)function and Jensen’s inequality we have\n8\nX\ni∈I2pilog(Di) + (1 −p(I2)) log(1)\n≤8 log\nX\ni∈I2piDi+ (1−p(I2))\n≤8 max(log( η) + 2,1).\nThe last inequality follows from the fact that ifP\ni∈I2piDi≤1we haveP\ni∈I2piDi+ (1−p(I2))≤2,\nand otherwise we have\nlog\nX\ni∈I2piDi+ (1−p(I2))\n≤log\nX\ni∈I2piDi\n+ 1≤log(2η) + 1 = log( η) + 2.\n3.2 Lower Bound\nIt is well known that there is a lower bound of Ω(H(p))on the expected query complexity for\nbinary search [ 27]. We now show that there is a lower bound of Ω(logη)on the expected query\ncomplexity as well, even on instances with H(p) = 0. This shows that there must fundamentally be\nalogηdependence on the earth mover’s distance, even for instances where it is not absorbed by the\ndependence on the entropy.\n7\n\nTheorem 2. For any η∈[n], any comparison-based (deterministic or randomized) algorithm must\nmake Ω(logη)queries on some instance where H(p) = 0and the earth mover’s distance between p\nandˆpisO(η).\nProof.Thanks to Yao’s principle, it suffices to give a distribution over instances of this problem\nand argue that any deterministic algorithm has a large expectation over this distribution. Let the\nset of keys be [n]. We present a family of problem instances I1, . . . , I η, where each instance can\nhappen with probability1\nη. In instance Ii, the true access distribution is a singleton on location i,\ni.e., in Iiwe have pi= 1andpj= 0for each j∈[n]\\{i}. In all the problem instances I1, . . . , I η, the\nprediction is the uniform distribution over [η]. Note that for each instance Ii, we have H(p) = 0.\nAlso, the earth mover’s distance between ˆpandpis at most η.\nOur claim is that any deterministic algorithm has an expected cost of Ω(logη)over this distribu-\ntion. To see this, note that the expected cost of any deterministic algorithm over this distribution\nof instances exactly equals the cost of that algorithm on an instance I∗where the true access\ndistribution is uniform over [η]. Now by the lower bound of [ 27], the cost of any deterministic\ncomparison-based algorithm on I∗isΩ(H(p∗)), where p∗is the uniform distribution over [η]. To\nconclude the proof, note that H(p∗) = Ω(log η).\nCombiningTheorem2withthe Ω(H(p))lowerbounddueto[ 27]resultsinthefollowingworst-case\nlower bound, asymptotically matching Theorem 1.\nCorollary 3. Any comparison-based algorithm for binary search with distributional predictions has\nworst-case expected query complexity Ω(H(p) + log( η)).\n4 A Portfolio of Predictions\nIn the previous section we showed an algorithm that is optimal given a single distributional prediction.\nHere we extend this result to the setting where there are mdifferent distributions given as a prediction.\nThat is, for k∈ {1,2, . . . , m }, there are predictions ˆpk= (ˆp1,k, . . . , ˆpn,k)ofpgiven. Let ηkbe the\nearth mover’s distance between ˆpkandp. The goal is to design an algorithm competitive with single\nbestdistribution ˆpk. That is, comparable to mink∈[m]logηkandH(p).\n4.1 Algorithm for Multiple Predictions\nWe proceed in a similar manner, alternating the two phases. However, we change the algorithm so\nthat in the first phase the algorithm performs a binary search on the medians of each distribution.\nThe goal of this is to ensure that each distribution has its probability mass drop by at least half in\neach step.\nAs before, the initial search range is [1, n]. The algorithm proceeds in iterations. For i= 0,1, . . .,\niteration ihas two phases.\n•Bisection. Let[ℓ, r]be the current search range. Let Sk=Pr\nj=ℓˆpj,kbe the remaining\nprobability mass in the k’th prediction.\nLettkbe such thatPtk−1\nj=ℓˆpj,k≤1\n2SkandPr\nj=tk+1ˆpj,k≤1\n2Sk. That is, tkis the median of\nthek’th distribution. Sort the indices k∈[m]so that t1≤t2. . .≤tm. For convenience, let\nt0=ℓandtm+1=r. Perform a binary search on at0, at1, at2, . . . a tm+1to find the interval\nwhere a∈(atj, atj+1)for some j∈ {0,1,2, . . . m}. The new search range is [tj+ 1, tj+1−1].\nContinue this for 2isteps, and if ais not found, begin the second phase described below.\n8\n\n•Binary Search at the Endpoints. Let[ℓ, r]be the current search range. Set d=min(22i, r−\nℓ). Check if ais in the range [ℓ, ℓ+d]or[r−d, r](by comparing atoaℓ+dandar−d). If a\nis in one of these ranges, say [ℓ, ℓ+d], do a regular binary search (by choosing the middle\npoint of the range each time) on the range [ℓ, ℓ+d], until ais found. Otherwise, start the next\niteration with the new search range [ℓ+d+ 1, r−d−1].\nThe algorithm continues until ais found.\n4.2 Analysis for Multiple Predictions\nWe now state the following theorem regarding the algorithm for multiple predictions. The overhead\nof using multiple predictions is a logmfactor. The proof is very similar to the proof of Theorem 1\nand has been deferred to Appendix A.\nTheorem 4. Given mdifferent distributions, the expected query complexity of the algorithm is\nlog(m)·O(H(p) + max(min k∈[m]logηk,0)).\n5 Experiments\nWenowpresentanempiricalevaluationoftheproposedalgorithmsonbothsyntheticandrealdatasets.\nOur goal is to show how predictions can be used to improve the running time of traditional binary\nsearch approaches. Since our theoretical results are about query complexity, and to keep the results\nimplementation-independent, our main metric will be the number of comparisons performed by each\nmethod. Our implementation can be found at https://github.com/AidinNiaparast/Learned-BST.\nWe compare the performance of the following algorithms:\n•Classic - The prediction agnostic approach that recursively queries the midpoint of the array.\n•Bisection - The bisection algorithm recursively queries the median of the predicted distribution\n(when the predicted probability in the search range is 0, this algorithm queries the midpoint\nof the array). This strategy is nearly optimal when the predicted distribution is correct [ 27];\nhowever, it is not robust to errors in the predicted distribution.\n•Learned BST - The algorithm described in Section 3. We make one modification, setting\nthe parameter dlarger to broaden the search space in the very early iterations, setting d to\nmin(28·2i, r−ℓ).\n•Convex Combination - This is a heuristic approach to make the Bisection algorithm more\nrobust. Given a prediction ˆpwe generate a new distribution, q=λˆp+ (1−λ)u, where uis the\nuniform distribution on [n]. We then run the Bisection algorithm on q. In our experiments,\nλ= 0.5is used.\n5.1 Synthetic Data Experiments\nWe begin with experiments on synthetic data where we can vary the prediction error in a controlled\nenvironment to show the algorithms sensitivity and robustness to mispredictions.\nIn this setting, let the keyspace be the integers in [−105,105]. We then generate t= 104\nindependent points from a normal distribution with mean 0and standard deviation 10, rounding\ndown each to the nearest integer. This results in a concentrated distribution in a very large key\nspace. The tpoints form the predicted distribution, ˆp. To generate the test distribution, we proceed\n9\n\n0 50 100 150 200 250 300 350\nMean of T est Data510152025Average Cost\nClassic\nBisection\nLearned BST\nConvex CombinationFigure 1: Results for synthetic data experiments. The y-axis measures the average cost (query\ncomplexity) of each algorithm and the x-axis measures the amount of shift in the test distribution.\nThe training and test data are regenerated 5 times. The solid lines are the mean and the clouds\naround them are the standard deviation of these experiments.\nin the same manner, but shift the mean of the normal distribution away from 0by some value s >0.\nNote that for s= 100the train and test distributions have 0 overlap with high probability. For each\nvalue of s, we repeat the experiment 5times and report the average and standard deviation of the\ncosts.\nOur results for this setting can be found in Fig. 1, where we plot the average search cost (query\ncomplexity) of each algorithm against the shift amount for the test distribution. At one extreme,\nwhere there is no shift in the test distribution, we observe that all three algorithms which utilize the\npredicted distribution perform well. Since the bisection algorithm is optimal when the error is 0, it\nperforms the best, as expected, while the Learned BST approach exhibits some overhead due to\nhedging against possible errors. However, a perturbation to the predicted distribution causes the\nbisection algorithm to perform worse than classical binary search. Both the convex combination and\nlearned BST algorithms demonstrate a smoother degradation in performance, with our proposed\nmethod (learned BST) giving more robust performance to even large shifts in the test distribution.\nWhen the erorr becomes very high, then the additional overhead of the learned BST algorithm makes\nit slightly worse than the Classic baseline.\n5.2 Real Data Experiments\nDataset Description. In order to test our approach on real-world data, we use temporal networks\nfrom Stanford Large Network Dataset Collection2. These datasets represent the interactions on\nstack exchange websites StackOverflow, AskUbuntu, and SuperUser [ 29]. In all cases, we use the\nanswers-to-questions dataset, which contains entries of the form (u, v, t ), which represents user u\nanswering user v’s question at time t. In this interaction, uis the source and vis the target user.\nOur data sequences consist of the source users from each interaction sorted in increasing order of\ntimestamp, and we restrict the dataset to the first one million entries.\nKeys, Predictions, and Test Data. For each data sequence, the set of elements in the first 10%\nof the sequence is used as the set of keys of the binary search trees. Let Abe the remaining 90% of\nthe sequence and let a1< a2< . . . < a nbe the set of keys. For each element x∈A, ifai≤x < a i+1,\nwe replace xbyai. For t= 5,10, . . . , 50, we use the first tpercent of Aas training data and the rest\nas test data. The training and test data are used to obtain the predictions ( ˆp) and actual access\n2https://snap.stanford.edu/data/index.html\n10\n\n0 1000 2000 3000 40000.000.05Training\n0 1000 2000 3000 40000.000.050.10T est(a) AskUbuntu\n0 1000 2000 3000 4000 5000 60000.000.010.02Training\n0 1000 2000 3000 4000 5000 60000.0000.0250.050T est (b) SuperUser\n0 2000 4000 6000 8000 100000.000.010.02Training\n0 2000 4000 6000 8000 100000.000.020.04T est (c) StackOverflow\nFigure 2: The train and test distributions when t= 50for the three datasets.\n10 20 30 40 50\nPercentage of Training Data67891011Average Cost\nClassic\nBisection\nLearned BST\nConvex Combination\n(a) AskUbuntu\n10 20 30 40 50\nPercentage of Training Data8.59.09.510.010.511.011.512.012.5Average Cost\nClassic\nBisection\nLearned BST\nConvex Combination (b) SuperUser\n10 20 30 40 50\nPercentage of Training Data9.510.010.511.011.512.012.5Average Cost\nClassic\nBisection\nLearned BST\nConvex Combination (c) StackOverflow\nFigure 3: Results for real data experiments. The y-axis measures the average cost of each algorithm\nand the x-axis indicates the fraction of the dataset used for training\ndistribution ( p), respectively. To obtain these distributions we use the normalized frequencies of\neach key in the training and test data.\nFor completeness, we show the distributions of the keys when t= 50both for the training set\nand the test set in Figure 2.\nWe present the results on these experiments in Figures 3 and 4. In Figure 3 we plot the average\ncost of the algorithms against the size of the training data. As we expect, as the size of the\ntraining data increases, the performance of all distribution-dependent algorithms get better, as the\ndistribution error decreases. We make this more precise in Figure 4 where we plot the average cost\nagainst log of the EMD error.\nWe note a few observations. The learning agnostic, Classic, is suboptimal in all but a handful\nof cases, showing that there is value in using the distribution of the data to improve performance.\nSecond, we validate the theory, showing that the learned BST’s performance degrades smoothly as\nlogηincreases. Third, the convex combination heuristic is not very effective on real world data,\ngiving only marginal improvements over the bisection method.\nFinally, on both AskUbuntu and SuperUser datasets, the learned BST approach performs\nsignificantly better than all of the baselines, saving 20-25% comparisons on average. Unlike the\n8.6 8.8 9.0 9.2 9.4 9.6 9.8\nlog(Earth Mover's Distance)67891011Average Cost\nClassic\nBisection\nLearned BST\nConvex Combination\n(a) AskUbuntu\n9.6 9.8 10.0 10.2 10.4 10.6\nlog(Earth Mover's Distance)8.59.09.510.010.511.011.512.012.5Average Cost\nClassic\nBisection\nLearned BST\nConvex Combination (b) SuperUser\n10.0 10.2 10.4 10.6 10.8 11.0\nlog(Earth Mover's Distance)9.510.010.511.011.512.012.5Average Cost\nClassic\nBisection\nLearned BST\nConvex Combination (c) StackOverflow\nFigure 4: Results for real data experiments. The y-axis measures the average cost of each algorithm\nand the x-axis indicates the logarithm of the earth mover’s distance between ˆpandp.\n11\n\nBisection algorithm it is also never worse than the Classic baseline. On the StackOverflow dataset our\napproach is about 10% worse than bisection method, owing to the distribution being less concentrated\naround the median. In these cases, the overhead of learned BST is apparent, given that the second\nphase is unlikely to be fruitful in the first few iterations.\nOverall, these results show that the Learned BST method is robust against errors, and performs\nwell against other approaches. Further improving the constant factors so that the learned approach\nhas strong worst-case guarantees and performs well against other learned approaches remains a\nchallenging open problem.\n6 Conclusion\nThere has been a growing line of work showing how to improve optimization algorithms using\nmachine learned predictions. Predominately, prior work has leveraged non-probabilistic predictions,\ndespite the fact that most ML systems, such as neural networks, output a distribution.\nThis work introduces a model where the prediction is a distribution. We show that algorithms\ncan perform better by taking full advantage of the distributional nature of the prediction, and that\nreduction to a point prediction is insufficient to provide competitive algorithms.\nGiven the breadth of work in the Algorithms with Predictions area [ 28], there is a wide variety\nof open questions concerning how to adapt algorithms to the setting of distributional predictions.\nReferences\n[1]Priyank Agrawal, Eric Balkanski, Vasilis Gkatzelis, Tingting Ou, and Xizhi Tan. Learning-\naugmented mechanism design: Leveraging predictions for facility location. In Proceedings of the\n23rd ACM Conference on Economics and Computation , pages 497–528, 2022.\n[2]Shabbir Ahmed. Two-stage stochastic integer programming: A brief introduction. Wiley\nencyclopedia of operations research and management science , pages 1–10, 2010.\n[3]Kareem Amin, Travis Dick, Mikhail Khodak, and Sergei Vassilvitskii. Private algorithms with\nprivate predictions. CoRR, abs/2210.11222, 2022. doi: 10.48550/ARXIV.2210.11222. URL\nhttps://doi.org/10.48550/arXiv.2210.11222 .\n[4]Keerti Anand, Rong Ge, Amit Kumar, and Debmalya Panigrahi. Online algorithms with\nmultiple predictions. In Proceedings of the 39th International Conference on Machine Learning,\nICML 2022 , 2022.\n[5]Spyros Angelopoulos, Marcin Bienkowski, Christoph Dürr, and Bertrand Simon. Contract\nscheduling with distributional and multiple advice. In Kate Larson, editor, Proceedings of\nthe Thirty-Third International Joint Conference on Artificial Intelligence, IJCAI-24 , pages\n3652–3660. International Joint Conferences on Artificial Intelligence Organization, 8 2024. doi:\n10.24963/ijcai.2024/404. URL https://doi.org/10.24963/ijcai.2024/404 . Main Track.\n[6]Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik. Generalization in portfolio-\nbased algorithm selection. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI\n2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI\n2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI\n2021, Virtual Event, February 2-9, 2021 , pages 12225–12232. AAAI Press, 2021. URL https:\n//ojs.aaai.org/index.php/AAAI/article/view/17451 .\n12\n\n[7]Étienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning\naugmented algorithms. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-\nFlorina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing\nSystems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS\n2020, December 6-12, 2020, virtual , 2020. URL https://proceedings.neurips.cc/paper/\n2020/hash/e834cb114d33f729dbc9c7fb0c6bb607-Abstract.html .\n[8]Dimitris Bertsimas and Vineet Goyal. On the power of robust solutions in two-stage stochastic\nand adaptive optimization problems. Mathematics of Operations Research , 35(2):284–305, 2010.\n[9]Dimitris Bertsimas, Shimrit Shtern, and Bradley Sturt. Two-stage sample robust optimization.\nOperations Research , 70(1):624–640, 2022.\n[10]Omar Besbes, Will Ma, and Omar Mouchtaki. Beyond IID: data-driven decision-making in\nheterogeneous environments. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave,\nK. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: Annual\nConference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA,\nUSA, November 28 - December 9, 2022 , 2022. URL http://papers.nips.cc/paper_files/\npaper/2022/hash/974ff7b5bf08dbf9400b5d599a39c77f-Abstract-Conference.html .\n[11]Sami Davies, Benjamin Moseley, Sergei Vassilvitskii, and Yuyan Wang. Predictive flows for faster\nford-fulkerson. In International Conference on Machine Learning , pages 7231–7248. PMLR,\n2023.\n[12]Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, Ali Vakilian, and Nikos Zarifis. Learning\nonline algorithms with distributional advice. In Marina Meila and Tong Zhang, editors,\nProceedings of the 38th International Conference on Machine Learning , volume 139 of Proceedings\nof Machine Learning Research , pages 2687–2696. PMLR, 18–24 Jul 2021. URL https://\nproceedings.mlr.press/v139/diakonikolas21a.html .\n[13]Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassil-\nvitskii. Faster matchings via learned duals. In Marc’Aurelio Ranzato, Alina Beygelz-\nimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Ad-\nvances in Neural Information Processing Systems 34: Annual Conference on Neural\nInformation Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual ,\npages 10393–10406, 2021. URL https://proceedings.neurips.cc/paper/2021/hash/\n5616060fb8ae85d93f334e7267307664-Abstract.html .\n[14]Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii.\nAlgorithms with prediction portfolios. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle\nBelgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35:\nAnnual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans,\nLA, USA, November 28 - December 9, 2022 , 2022. URL http://papers.nips.cc/paper_files/\npaper/2022/hash/7f9220f90cc85b0da693643add6618e6-Abstract-Conference.html .\n[15]Paul Dütting and Thomas Kesselheim. Posted pricing and prophet inequalities with inaccurate\npriors. In Anna R. Karlin, Nicole Immorlica, and Ramesh Johari, editors, Proceedings of\nthe 2019 ACM Conference on Economics and Computation, EC 2019, Phoenix, AZ, USA,\nJune 24-28, 2019 , pages 111–129. ACM, 2019. doi: 10.1145/3328526.3329576. URL https:\n//doi.org/10.1145/3328526.3329576 .\n13\n\n[16]Sungjin Im, Ravi Kumar, Mahshid Montazer Qaem, and Manish Purohit. Online knapsack with\nfrequency predictions. In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy\nLiang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing\nSystems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021,\nDecember 6-14, 2021, virtual , pages 2733–2743, 2021. URL https://proceedings.neurips.\ncc/paper/2021/hash/161c5c5ad51fcc884157890511b3c8b0-Abstract.html .\n[17]Eniko Kevi and Kim Thang Nguyen. Online covering with multiple experts. CoRR,\nabs/2312.14564, 2023. doi: 10.48550/ARXIV.2312.14564. URL https://doi.org/10.48550/\narXiv.2312.14564 .\n[18]Sujin Kim, Raghu Pasupathy, and Shane G Henderson. A guide to sample average approximation.\nHandbook of simulation optimization , pages 207–243, 2015.\n[19]Donald E. Knuth. Optimum binary search trees. Acta Informatica , 1:14–25, 1971. doi:\n10.1007/BF00264289. URL https://doi.org/10.1007/BF00264289 .\n[20]Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned\nindex structures. In Proceedings of the 2018 International Conference on Management of Data ,\npages 489–504. ACM, 2018.\n[21]SilvioLattanzi, ThomasLavastida, BenjaminMoseley, andSergeiVassilvitskii. Onlinescheduling\nvia learned weights. In Shuchi Chawla, editor, Proceedings of the 2020 ACM-SIAM Symposium\non Discrete Algorithms, SODA 2020, Salt Lake City, UT, USA, January 5-8, 2020 , pages\n1859–1877. SIAM, 2020. doi: 10.1137/1.9781611975994.114. URL https://doi.org/10.1137/\n1.9781611975994.114 .\n[22]Honghao Lin, Tian Luo, and David Woodruff. Learning augmented binary search trees. In\nInternational Conference on Machine Learning , pages 13431–13440. PMLR, 2022.\n[23]Alexander Lindermayr and Nicole Megow. Algorithms with predictions. https://\nalgorithms-with-predictions.github.io/ , 2022.\n[24]Thodoris Lykouris and Sergei Vassilvitskii. Competitive caching with machine learned advice.\nJournal of the ACM (JACM) , 68(4):1–25, 2021.\n[25] Samuel McCauley, Ben Moseley, Aidin Niaparast, and Shikha Singh. Online list labeling with\npredictions. Advances in Neural Information Processing Systems , 36, 2024.\n[26]Samuel Mccauley, Benjamin Moseley, Aidin Niaparast, and Shikha Singh. Incremental topo-\nlogical ordering and cycle detection with predictions. In Ruslan Salakhutdinov, Zico Kolter,\nKatherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, ed-\nitors,Proceedings of the 41st International Conference on Machine Learning , volume 235 of\nProceedings of Machine Learning Research , pages 35240–35254. PMLR, 21–27 Jul 2024. URL\nhttps://proceedings.mlr.press/v235/mccauley24a.html .\n[27] Kurt Mehlhorn. Nearly optimal binary search trees. Acta Informatica , 5:287–295, 1975.\n[28]Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with Predictions , page 646–662.\nCambridge University Press, 2021. doi: 10.1017/9781108637435.037.\n14\n\n[29]Ashwin Paranjape, Austin R Benson, and Jure Leskovec. Motifs in temporal networks. In\nProceedings of the tenth ACM international conference on web search and data mining , pages\n601–610, 2017.\n[30]Manish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predictions.\nInAdvances in Neural Information Processing Systems , pages 9661–9670, 2018.\n[31]Chaitanya Swamy and David B Shmoys. Approximation algorithms for 2-stage stochastic\noptimization problems. ACM SIGACT News , 37(1):33–46, 2006.\n[32]Kapil Vaidya, Eric Knorr, Michael Mitzenmacher, and Tim Kraska. Partitioned learned bloom\nfilters. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event,\nAustria, May 3-7, 2021 . OpenReview.net, 2021. URL https://openreview.net/forum?id=\n6BRLOfrMhW .\n15\n\nA Omitted Proofs\nProof of Theorem 4. With probability pi, the key athat we are looking for is ai. The goal is to\nbound the expected cost of the algorithm, which isPn\ni=1piC(ai), where C(ai)is the cost of the\nalgorithm when a=ai. In each step of the Bisection phase, a binary search is done on the medians\nof the predicted probability distributions on the current search range. When the binary search is\ndone, for each prediction k, the median tkof the prediction falls outside of the new search range.\nThis means that the probability mass of ˆpkon the new search range has dropped by at least a factor\nof 2 compared to the initial search range before the binary search. Let k∗=arg mink∈[m]ηk. From\nthe above discussion, the probability mass of ˆpk∗in the search range drops by a factor of at least 2\nin each step of the Bisection phase, which results in a total drop of at least 22jin iteration jof the\nalgorithm. The cost of each Bisection step is logm, which makes the total cost of the Bisection phase\nin iteration jequal to (logm)·2j. Let Tibe the first iteration at which ais found, assuming a=ai.\nThe total cost of the first phase of the iterations 0 to Tiis(logm)PTi\nj=02j<(logm)·2Ti+1. Also,\nthe cost of the second phase in each iteration before Tiis 2, and in iteration Tiis at most 2Ti. So the\ntotal cost of the algorithm for iterations 0toTiis at most (logm)·2Ti+1+2Ti+2Ti=O((logm)·2Ti).\nWe partition the keys based on Tiinto two sets, and bound the cost of each set separately. Let\nI1:={i:Ti≤log(log(4 /pi))}andI2:={i:Ti>log(log(4 /pi))}.\nFirst, we bound the cost of indices in I1by(logm)·O(H(p)):\nX\ni∈I1piC(ai) =O\nX\ni∈I1pi\u0000\n(logm)·2Ti\u0001\n= (log m)·O(X\ni∈I1pilog(4/pi)) = (log m)·O(H(p)).\nNow we bound the cost of the indices in I2by(logm)·O(max(log( ηk∗),1)). Let i∈I2. We\nknow that during iteration jof searching for ai, in the Bisection phase, the predicted probability\nmass ˆpk∗in the search range decreases by a factor of at least 22j. Therefore the predicted probability\nmass ˆpk∗in the search range [ℓ, r]at the end of the first phase in iteration Ti−1is at most\n1QTi−1\nj=022j=1\n22Ti−1=2\n22Ti≤2\n4/pi=pi\n2,\nwhere the inequality holds because i∈I2. SoPr\nj=ℓˆpj,k∗≤pi/2. Let Di:=min(i−ℓ, r−i). In the\ntransportation problem corresponding to the earth mover’s distance between pandˆpk∗, a probability\nmass of at least pi/2needs to be moved from point ito the outside of the interval [ℓ, r]. The cost of\nthis movement in the objective function of the transportation problem is at least Di·pi/2. Therefore\nwe have ηk∗≥P\ni∈I2Di·pi/2. In the Binary Search at the Endpoints phase of iteration j, we probe\nindices distance of d= 22jaround the two endpoints of the search range. Since aiis not found before\niteration Ti, we conclude that 22Ti−1< D i, which means that 2Ti≤2log(Di). Let p(I2) :=P\ni∈I2pi.\n16\n\nWe have\nX\ni∈I2piC(ai)≤(logm)·O\nX\ni∈I2pi2Ti\n (1)\n≤(logm)·O\nX\ni∈I2pilog(Di)\n (2)\n≤(logm)·O\nX\ni∈I2pilog(Di) + (1 −p(I2)) log(1)\n (3)\n≤(logm)·O\nlog\nX\ni∈I2piDi+ (1−p(I2))\n\n (4)\n≤(logm)·O(max(log( ηk∗),1)), (5)\nwhereinequality (4)resultsfromconcavityof log(·)functionandJensen’sinequality, andinequality (5)\nis because of the following\n•IfP\ni∈I2piDi≤1then we have\nlog\nX\ni∈I2piDi+ (1−p(I2))\n≤log(2) = 1\n•IfP\ni∈I2piDi>1then we have\nlog\nX\ni∈I2piDi+ (1−p(I2))\n≤log\nX\ni∈I2piDi\n+ 1 = O(log(ηk∗)).\nB Experimental Setup\nWe use Python 3.10 for conducting our experiments on a system equipped with an 11th Generation\nIntel Core i7 CPU running at 2.80GHz, 32GB of RAM, a 128GB NVMe KIOXIA disk drive, and a\n64-bit Windows 10 Enterprise operating system. It’s worth noting that the cost of the algorithms,\ni.e., the expected query complexity, is hardware-independent.\n17",
  "textLength": 51194
}