{
  "paperId": "07222640bc800ec3c60d5f228ad3dd71b432a1c9",
  "title": "On Tradeoffs in Learning-Augmented Algorithms",
  "pdfPath": "07222640bc800ec3c60d5f228ad3dd71b432a1c9.pdf",
  "text": "On Tradeoffs in Learning-Augmented Algorithms\nZiyad Benomar\nCREST, Ecole polytechnique,\nENSAE, Fairplay joint team, PalaiseauVianney Perchet\nCREST, ENSAE, Criteo AI LAB\nFairplay joint team, Paris\nAbstract\nThe field of learning-augmented algorithms has gained significant attention in recent years. These\nalgorithms, using potentially inaccurate predictions, must exhibit three key properties: consistency,\nrobustness, and smoothness. In scenarios where distributional information about predictions is available,\na strong expected performance is required. Typically, the design of these algorithms involves a natural\ntradeoff between consistency and robustness, and previous works aimed to achieve Pareto-optimal tradeoffs\nfor specific problems. However, in some settings, this comes at the expense of smoothness. In this paper, we\ndemonstrate that certain problems involve multiple tradeoffs between consistency, robustness, smoothness,\nand average performance.\n1 Introduction\nMany decision-making problems under uncertainty are commonly studied using competitive analysis. In this\ncontext, the performance of online algorithms, operating under uncertainty, is compared to that of the optimal\noffline algorithm, which has full knowledge of the problem instance. While competitive analysis provides\na rigorous method for evaluating online algorithms, it is often overly pessimistic. In real-world scenarios,\ndecision-makers can have some prior knowledge, though possibly imperfect, about the complete problem\ninstance. For example, predictions of unknown variables might be obtained via machine learning models, or\nan expert might provide advice on the best course of action. This more realistic setting was formalized by\nLykouris and Vassilvtiskii [2018] and Purohit et al. [2018] leading to the development of what is now known\nas learning-augmented algorithms. In this paradigm, the algorithm receives predictions about the current\nproblem instance, but without any guarantees on their accuracy, and must satisfy three main properties:\n•Consistency: perform almost as well as the optimal offline algorithm if the predictions are perfect.\n•Robustness: maintain a performance level close to the worst-case scenario without predictions when the\npredictions are arbitrarily bad.\n•Smoothness: the performance should degrade gracefully as the prediction error increases.\nConsistency, robustness, and brittleness. Consider a minimization problem under uncertainty, and let\nALGbe an algorithm augmented with a prediction yof an unknown parameter x. The input of the algorithm\ncan contain parameters other than x, but for simplicity, we denote by ALG(x, y)the value of the objective\nfunction achieved by ALG, and OPT(x)the value of the optimal offline algorithm. The consistency cand\nrobustness rofALGare defined as\nc= sup\nxALG(x, x)\nOPT(x)and r= sup\nx,yALG(x, y)\nOPT(x).\nConsistency is the worst-case ratio when the prediction is perfectly accurate, i.e. y=x, while robustness is\nthe worst-case ratio with adversarial prediction. Most research on learning-augmented algorithms focuses on\nachieving good tradeoffs between consistency and robustness. Some studies also establish algorithms with\n1arXiv:2501.12770v1  [cs.DS]  22 Jan 2025\n\nPareto-optimal tradeoffs, i.e. no algorithm can have simultaneously better consistency and better robustness.\nHowever, the proposed algorithms in such studies sometimes lack smoothness. Specifically, their worst-case\nperformance can degrade abruptly, moving from the consistency bound when the predictions are perfect to\nthe robustness bound even with an arbitrarily small error in the prediction. Following the terminology of\n[Angelopoulos et al., 2024a], we say that such an algorithm is brittle.\nDefinition 1.1 (Brittleness) .an algorithm ALGwith robustness ris brittle if\n∀ε >0 : sup\nx,y:|x−y|≤εxALG(x, y)\nOPT(x)=r .\nIn real-world scenarios, predictions are rarely perfect. As a result, the only reliable guarantee for brittle\nalgorithms is the robustness bound, which is at best equivalent to the worst-case bound without predictions.\nThis greatly limits the practical usefulness of these algorithms. In the case of the one-way trading problem,\nAngelopoulos et al. [2024a] demonstrated in a very recent work that any algorithm achieving a Pareto-optimal\ntradeoff between consistency and robustness is brittle. This finding implies that, in some problems, achieving\nsmoothness requires deviating from the Pareto-optimal tradeoff between consistency and robustness.\nAverage-case performance. In the context of learning-augmented algorithms, the consistency, robustness,\nand smoothness of an algorithm represent worst-case guarantees with respect to the prediction error. On\nthe other hand, there are numerous scenarios where the decision-maker might know some information about\nthe distribution of the prediction, which motivates the design of algorithms with good average performance\n[Dütting et al., 2021, Gupta et al., 2022, Benomar and Perchet, 2023, Henzinger et al., 2023, Cohen-Addad\net al., 2024]. Nevertheless, while achieving a balance between worst-case and average-case performance has\nbeen widely studied in various fields of algorithm design and machine learning [Szirmay-Kalos and Márton,\n1998, Witt, 2005, Peikert and Rosen, 2007, Antunes and Fortnow, 2009, Chuangpishit et al., 2018, Rice et al.,\n2021, Robey et al., 2022], this aspect has not yet been investigated in the context of learning-augmented\nalgorithms for the prediction error.\n1.1 Contributions\nInthiswork, weexplorevarioustradeoffsthatariseinthedesignandanalysisoflearning-augmentedalgorithms.\nWhile existing literature has primarily focused on the tradeoff between consistency and robustness, our\ninvestigation centers on the tradeoffs between consistency and smoothness, as well as the relationships\nbetween the standard criteria for learning-augmented algorithms—namely consistency, robustness, and\nsmoothness—and their average performance under stochastic assumptions regarding predictions.\nWe begin by examining the line search problem , revisiting the algorithm proposed by Angelopoulos\net al. [2019]. This algorithm achieves a Pareto-optimal tradeoff between consistency and robustness among\ndeterministic algorithms, but we demonstrate that it is inherently brittle. We show that this brittleness can\nbe mitigated by introducing randomness into the predictions used by the algorithm. The variance of this\nrandomization is quantified by a parameter ρ≥0. Our analysis reveals that tuning this parameter leads to\nopposing effects on the consistency and smoothness of the algorithm, thus yielding a tradeoff between these\ntwo criteria.\nNext, we apply a similar approach to the one-max search problem . We examine the Pareto-optimal\nalgorithm introduced by Sun et al. [2021], and we show its brittleness. Furthermore, we demonstrate how\nrandomization can be used to guarantee smoothness at the cost of consistency. Once again, the resulting\ntradeoff is governed by a parameter ρ≥0.\nFinally, we address the ski-rental problem , proposing an algorithm that generalizes that of Purohit et al.\n[2018]. Through a tight analysis of its performance, we prove that the Pareto-optimal tradeoff between\nconsistency and robustness can be achieved with different levels of smoothness. However, we show that\nstriving for optimal smoothness degrades the average-case performance of the algorithm, assuming that the\nprediction induces the correct decision (renting or buying at time 0) with a probability Q∈[1\n2,1]. In this\ncontext, a parameter ρ∈[0,1]can be utilized to tune the levels of smoothness and average-case performance,\nall while maintaining fixed levels of consistency and robustness.\nAdditionally, we conduct numerical experiments for the three problems studied in the paper, highlighting\nthe various tradeoffs demonstrated in our analysis.\n2\n\n1.2 Related work\nLearning-augmented algorithms. The design of learning-augmented algorithms [Lykouris and Vassil-\nvtiskii, 2018, Purohit et al., 2018] relies on using machine-learned advice to go beyond worst-case limitations.\nThese algorithms operate under the assumption that the decision-maker has access to noisy predictions about\ncertain problem parameters. The goal of learning-augmented algorithms is to improve performance if the\npredictions are accurate, while also ensuring robustness in the face of incorrect or adversarial predictions.\nMany fundamental algorithmic problems were studied in this setting, such as ski rental [Gollapudi and\nPanigrahi, 2019, Diakonikolas et al., 2021, Antoniadis et al., 2021, Shin et al., 2023], caching [Lykouris and\nVassilvtiskii, 2018, Chlkedowski et al., 2021, Antoniadis et al., 2023b,a], scheduling [Purohit et al., 2018,\nMerlis et al., 2023, Lassota et al., 2023, Benomar and Perchet, 2024], and the design of data structures\n[Kraska et al., 2018, Lin et al., 2022, Zeynali et al., Benomar and Coester, 2024].\nOvercoming brittleness. Pareto-optimal tradeoffs between consistency and robustness were studied in\n[Angelopoulos et al., 2019, Bamas et al., 2020, Wei and Zhang, 2020, Sun et al., 2021, Angelopoulos, 2023].\nHowever, the proposed algorithms do not always have smoothness guarantees. For example, Angelopoulos\net al. [2024a] proved that any Pareto-optimal algorithm for the one-way trading problem is necessarily brittle\n(Definition 1.1). In this paper, we will show in the line search and in the one-max search problems how\na randomized deviation from the Pareto-optimal algorithm allows for overcoming brittleness. A similar\napproach was used to guarantee smoothness in non-clairvoyant scheduling with limited predictions [Benomar\nand Perchet, 2024].\nLine search. The line search problem [Beck, 1964], also known as the cow path problem, consists of finding\na hidden target on an infinite line starting from an initial position, without any information regarding the\ndirection or distance to the target. The goal is to minimize the total distance traveled before reaching the\ntarget. The best deterministic algorithm is based on doubling the search distance in alternating directions,\nand it ensures a competitive ratio of 9[Beck and Newman, 1970, Baezayates et al., 1993]. The line search\nproblem has been extensively studied in the learning-augmented framework with different types of predictions\n[Angelopoulos, 2023, Angelopoulos et al., 2024b].\nOne-max search. In the one-max search problem [El-Yaniv et al., 2001], the decision-maker observes a\nsequence of adversarially chosen prices p1, . . . , p n∈[L, U], with 0< L < U . At each step i, the price piis\nrevealed to the decision-maker, and the latter can decide to stop the game and have a payoff of pi, or reject it\nirrevocably and move to the next observation. The best deterministic algorithm for this problem consists\nsimply in selecting the first price larger than√\nLU, which guarantees a payoff of at leastp\nL/U max i∈[n]pi.\nThis problem, as well as its randomized version— online conversion —were studied in the learning-augmented\nsetting with a prediction of the maximal price [Sun et al., 2021].\nSki-rental In the ski-rental problem, the decision maker faces a daily choice between renting a ski at a unit\ncost or buying it for a one-time cost of b, after which skiing becomes free. The length of the ski season, x, is\nunknown, and the goal is to minimize the total cost of renting and buying. A straightforward algorithm for\nthis problem is renting for the first b−1days and then buying at day b, resulting in a competitive ratio of 2,\nwhich is the best achievable by any deterministic algorithm Karlin et al. [1988]. The best competitive ratio\nwith randomized algorithms ise\ne−1[Karlin et al., 1994].\n2 Smooth Algorithm for Line Search\nIn the line search problem, a target is hidden in an unknown position x∈Ron the line, with |x| ≥1, and\nthe searcher, initially at the origin of the line O, must find the target, minimizing the total traveled distance.\nThe optimal offline algorithm only travels a distance of |x|to find the target. On the other hand, the searcher,\nignoring if xis to the left or the right side of O, must alternate the search direction multiple times before\nfinding the target. Any deterministic algorithm for this problem can be defined as an iterative strategy,\nparameterized by an initial search direction s0∈ {− 1,1}and a sequence of turn points (di)i∈N∈[1,∞]N. At\n3\n\nthe beginning of any iteration i≥0, the searcher is located at the origin O, then it travels a distance diin\nthe direction (−1)is0and returns to the origin. The algorithm terminates when the position xis reached.\nPareto-optimal algorithm. Given a prediction yofx, Angelopoulos [2023] designed an algorithm ALS\nb\nthat has a consistency ofb+1\nb−1, and robustness of 1 +2b2\nb−1, where b≥2is a hyperparameter of the algorithm.\nDenoting by ALS\nb(x, y)the distance traveled by ALS\nbto find the target xgiven the prediction y, the consistency\nand robustness guarantees can be written as\n∀x:ALS\nb(x, x)\n|x|≤b+ 1\nb−1,\n∀x, y:ALS\nb(x, y)\n|x|≤1 +2b2\nb−1.\nMoreover, the author proves that these consistency and robustness levels are Pareto-optimal. The proposed\nalgorithm has a simple structure: let ky∈Nsuch that bky−2<|y| ≤bky, and γy=bky/|y| ≥1, the algorithm\nALS\nbis defined by the initial search direction s0= (−1)kysign(y)and the turn points di=bi/γyfor all i≥0.\nThe algorithm is defined so that, during the iteration ky, the searcher travels a distance of |y|in the direction\ngiven by sign (y), i.e. it reaches the position yexactly at the turning point of iteration ky.\n2.1 Brittleness of the Pareto-optimal algorithm\nIn the following, we will prove that ALS\nbis brittle, in the sense of Definition 1.1, then we will demonstrate\nhow a simple randomization idea enables making the algorithm smooth. To better understand the impact of\nthe prediction error on the performance of ALS\nb, we first prove an expression of ALS\nb(x, y)/xas a function of y\nandx.\nLemma 2.1. Letx≥1,y >0andj=⌈ln(x/y)\n2 lnb⌉ ∈Z, so that 1≤y\nxb2j< b2. It holds that\nALS\nb(x, y)\nx= 1 +2b2\nb−1·b2(j−1)y\nx−o(1/x).\nb−2x x b2xb+1\nb−11+2b2\nb−1\nFigure 1: The mapping y7→ALS\nb(x, y)/xforxarbitrary large and y∈[x\nb2, b2x].\n.\nProof.By definition of j, we have 1≤b2jy/x < b2, and recalling that y=bky/γy, we obtain\nbky+2j−2\nγy< x≤bky+2j\nγy.\nUsing these inequalities, we deduce that the algorithm finds the target at iteration ky+ 2j. Indeed, as y >0,\nat iteration ky+ 2j−2, the searcher travels along the positive branch until reaching the position bky+2j−2/γy\nand returns to the origin, then it explores the negative branch at iteration ky+ 2j−1. The total distance\n4\n\ntraveled up to that point is 2Pky+2j−1\ni=0 bi/γy. At iteration ky+ 2j, since x≤bky+2j/γy, the algorithm finds\nthe target and terminates. The total traveled distance is therefore\nALS\nb(x, y) =x+ 2ky+2j−1X\ni=0bi\nγy\n=x+2\nb−1\u0012bky+2j\nγy−1\nγy\u0013\n=x+2b2\nb−1\u0012\nb2(j−1)y−1\nγyb2\u0013\n,\nwhere we used in the last inequality that y=bky/γy. Finally, using that γy≥1, we deduce that\n1 +2b2\nb−1\u0012\nb2(j−1)y\nx−1\nb2x\u0013\n≤ALS\nb(x, y)\nx≤1 +2b2\nb−1·b2(j−1)y\nx.\nThe expression proved in Lemma 2.1 is illustrated in Figure 1 for xarbitrary large and y∈[x/b2, b2x].\nIt shows that the ratio ALS\nb(x, y)/xincreases smoothly from the consistency to the robustness bound if\nthe prediction yis larger than x, but presents a discontinuity, going immediately from the consistency to\nrobustness bound if y < xand arbitrarily close to x. This proves the brittleness of ALS\nb, which can be formally\nstated as follows.\nProposition 2.2 (ALS\nbis brittle).For any ε >0, it holds that\nsup\nx,y:|x−y|≤εxALS\nb(x, y)\n|x|= 1 +2b2\nb−1.\nProof.Letε >0,x≥1, and y∈[max{x\nb2,(1−ε)x}, x). Sincex\nb2≤y < x, the variable jfrom Lemma 2.1\nequals 1, which yields\nALS\nb(x, y)\nx≥1 +2b2\nb−1\u0012y\nx−1\nb2x\u0013\n,\nand taking yarbitrarily close to xgives\nsup\ny:|x−y|≤εxALS\nb(x, y)\nx≥1 +2b2\nb−1\u0012\n1−1\nb2x\u0013\n=\u0012\n1 +2b2\nb−1\u0013\n−2\n(b−1)x.\nFinally, given that 1 +2b2\nb−1is also an upper bound on ALS\nb(x, y), taking arbitrarily large concludes the\nproof.\n2.2 Smoothness via randomization\nIn all the following, we assume without loss of generality that x >0. The worst-case ratio ALS\nb(x, y)/x, given\nin Proposition 2.2, occurs when x=y+εwith εarbitrarily small. To avoid it, we perturb yand run instead\nthe algorithm ALS\nbwith a randomized prediction of the form ˜y= (1 + ρξ)y, where ρ >0is a hyperparameter\nandξa positive random variable.\nTheorem 2.3. Letb≥2,ρ∈[0,1], and ξa random variable with tail distribution Pr(ξ≥t) =1\n(1+t)2for all\nt≥0. Then for any x≥1andy∈R, denoting by η=|x−y|, we have for ˜y= (1 + ρξ)ythat\nEξ[ALS\nb(x,˜y)]\nx≤b+ 1 + 2 ρ\nb−1+\n\n2(1 + ρ)\nb−1·η\nxify≥x\n4(b+ 1)\nρ·η\nxify < x\n5\n\nand we have with probability 1that\nALS\nb(x,˜y)\nx≤1 +2b2\nb−1.\nThe first bound in the previous theorem establishes the algorithm’s consistency and smoothness, while\nthe second bound characterizes its robustness, which remains unaffected by randomizing the prediction.\nBeyond the consistency-robustness tradeoff governed by the parameter b, the algorithm also exhibits a tradeoff\nbetween consistency and smoothness, governed by the parameter ρ∈[0,1]. For ρ= 0, the algorithm is\nidentical to that of Angelopoulos et al. [2019] and has optimal levels of consistency and smoothness. For\nρ >0, the smoothness factor for y < ximproves, but the algorithm becomes less consistent. Although the\nalgorithm is well-defined for all values of ρ >0, we limit our analysis to ρ∈[0,1], as this range allows for\nsimpler expressions of the upper bound. Let us now prove the theorem\nProof.The online algorithm ALS\nbhas a robustness of 1 +2b2\nb−1. This guarantee remains true with any arbitrary\nprediction, in particular with ˜y, which gives almost surely that\nALS\nb(x,˜y)\nx≤1 +2b2\nb−1.\nRegarding the consistency and smoothness of the algorithm, we give separate proofs depending on the position\nofyrelative to x.\nIfy≥x, then y=x+η, the perturbed prediction ˜yis larger than xalmost surely, and j=⌈ln(x/˜y)\n2 ln(b)⌉ ≤0.\nThus, Lemma 2.1 with xand˜yyields\nALS\nb(x,˜y)\nx≤1 +2\nb−1·˜y\nx\n= 1 +2(1 + ρξ)\nb−1·\u0010\n1 +η\nx\u0011\n=b−1 + 2 ρξ\nb−1+2(1 + ρξ)\nb−1·η\nx\nand using that E[ξ] = 1gives in expectation\nEξ[ALS\nb(x,˜y)]\nx≤b−1 + 2 ρ\nb−1+2(1 + ρ)\nb−1·η\nx.\nOn the other hand, if y < x, let first prove that the upper bound of the theorem exceeds the robustness\nbound when y≤x/b2, hence it is true almost surely in that case. For y≤x/b2, the absolute prediction error\nsatisfies η/x= 1−y/x≥1−1/b2, and given that ρ≤1, we obtain\nb+ 1 + 2 ρ\nb−1+4(b+ 1)\nρ·η\nx≥b+ 1\nb−1+ 4(b+ 1)\u0012\n1−1\nb2\u0013\n= 1 +2b2\nb−1 \n1\nb2+ 2\u0012\n1−1\nb2\u00132!\n= 1 +2b2\nb−1\u0012\n1 +\u0012\n1−3\nb2+2\nb4\u0013\u0013\n≥1 +2b2\nb−1\n≥ALS\nb(x,˜y)\nx(w.p. 1).\nConsequently, in the rest of the proof, we focus on showing the claimed result when y∈(x\nb2, x). In that case,\n6\n\nthe random variable ˜ytakes values in (x/b2,∞). By Lemma 2.1, using that ˜y= (1 + ρξ)y, we obtain that\nALS\nb(x,˜y)\nx≤1 +2˜y/x\nb−1×\n\nb2if˜y∈(x/b2, x)\n1if˜y≥x\n= 1 +2y/x\nb−1\u0010\n(1 +ρξ) 1ξ≥1\nρ(x\ny−1)+b2(1 +ρξ) 1ξ<1\nρ(x\ny−1)\u0011\n= 1 +2y/x\nb−1\u0010\n1 +ρξ+ (b2−1)(1 + ρξ) 1ξ<1\nρ(x\ny−1)\u0011\n,\nwhich gives in expectation\nE[ALS\nb(x,˜y)]\nx≤1 +2y/x\nb−1\u0010\n1 +ρ+ (b2−1)\u0000\nPr(ξ <1\nρ(x\ny−1)) + ρE\u0002\nξ 1ξ<1\nρ(x\ny−1)\u0003\u0001\u0011\n. (1)\nFor all s≥0, it holds that Pr(ξ < s ) = 1−1\n(1+s)2=s2+2s\n(1+s)2, and\nE[ξ 1ξ<s] =Z∞\n0Pr(ξ 1ξ<s≥u)du\n=Zs\n0Pr(ξ∈[u, s))du\n=Zs\n0Pr(ξ≥u)du−Zs\n0Pr(ξ≥s)du\n=Zs\n0du\n(1 +u)2−s\n(1 +s)2\n= 1−1\n1 +s−s\n(1 +s)2\n=s2\n(1 +s)2.\nTherefore, using that ρ≤1then s >0, we obtain\nPr(ξ < s ) +ρE\u0002\nξ 1ξ<s\u0003\n=2s+ (1 + ρ)s2\n(1 +s)2≤2s+ 2s2\n(1 +s)2=2s\n1 +s≤2s .\nSubstituting into (1) with s=1\nρ(x\ny−1)yields\nE[ALS\nb(x,˜y)]\nx≤1 +2y/x\nb−1\u0012\n1 +ρ+2(b2−1)\nρ\u0010x\ny−1\u0011\u0013\n=b−1 + 2(1 + ρ)y/x\nb−1+4(b+ 1)\nρ·x−y\nx\n≤b+ 1 + 2 ρ\nb−1+4(b+ 1)\nρ·η\nx,\nwhich concludes the proof.\n3 Smooth Algorithm for One-Max Search\nIn the one-max search problem, a decision-maker sequentially observes prices p1, . . . , p n∈[L, U], where\n0< L < U , and upon observing each price pithey must decide either to select it, halting the process and\nreceiving a payoff of pi, or to reject it irrevocably and move on to the next price.\n7\n\nLetALGdenote an online algorithm for this problem. We use ALG(p)to denote the price selected by ALG\nwhen given an input instance p= (p1, . . . , p n), and we use p∗=max i∈[n]pito denote the highest price in the\ninstance. Since this is a maximization problem The competitive ratio of ALGis defined as:\nCR(ALG) = inf\npALG(p)\np∗(2)\nwhere the infimum is taken over all possible price sequences of arbitrary length, with prices in the range\n[L, U]. In some works, the competitive ratio is alternatively defined as the inverse of our definition, i.e.,\nCR(ALG) =suppp∗\nALG(p).However, since our objective is to prove smoothness guarantees, it is more convenient\nto define the competitive ratio as in (2). Finally, let θ=U/L. Without loss of generality, we can assume that\nthe prices are in the interval [1, θ].\nPareto-Optimal Algorithm. Given a prediction yof the maximum price, the consistency cand robustness\nrof any algorithm ALGare defined as c=infpALG(p,p∗)\np∗andr=infp,yALG(p,y)\np∗. In this setting, Sun et al.\n[2021] proved for all λ∈[0,1]an algorithm AOM\nλwith consistency c(λ)and robustness r(λ), defined as the\nunique solution of the system\n1\nc(λ)=θ·r(λ)and1\nc(λ)=λ\nr(λ)+ 1−λ . (3)\nThe proposed algorithm is a threshold policy, where the first price at least equal to the threshold Φ(λ, y)is\nselected, with\nΦ(λ, y) =\n\n1\nc(λ)ify∈[1,1\nc(λ))\nλ\nr(λ)+ (1−λ)c(λ)yify∈[1\nc(λ),1\nr(λ))\n1\nr(λ)ify∈[1\nr(λ), θ].\nIf all the prices are less than Φ(λ, y), then the algorithm selects the last price pn. Furthermore, the authors\nprove that the levels of consistency and smoothness of AOM\nλare Pareto-optimal. However, they do not provide\nany smoothness guarantees.\n3.1 Brittleness of the Pareto-optimal algorithm\nWe will prove in the following that this algorithm is brittle, and we will show, similarly to the line search\nproblem, how this brittleness can be overcome via randomization. In the following, we simply write c, rinstead\nofc(λ), r(λ), and we denote by η:=|p∗−y|the prediction error. Our first result is that the competitive\nratio of Aλdegrades smoothly as a function of the prediction error when y∈[1,1\nr). Then, we will prove the\nbrittleness of the algorithm in Proposition 3.3 by considering y≥1\nr. The following lemma shows smoothness\nfory∈[1,1\nc).\nLemma 3.1. Ify∈[1,1\nc), then\nAOM\nλ(p, y)\np∗≥c−c·η\np∗.\nProof.Ify∈[1,1\nc), then Φ(λ, y) = 1 /c. Ifp∗<1/cthen all the observed prices are below the threshold, and\nthe algorithm selects pn, which is 1in the worst case, hence\nAOM\nλ(p, y)\np∗≥1\np∗≥c .\nOn the other hand, if p∗≥1/c, then the value selected by the algorithm is at least 1/cand\nAOM\nλ(p, y)\np∗≥1/c\np∗≥y\np∗= 1−p∗−y\np∗= 1−η\np∗.\n8\n\nWe deduce from both cases that\nAOM\nλ(p, y)\np∗≥min\u0010\nc ,1−η\np∗\u0011\n≥c−c·η\np∗,\nwhere the last inequality holds because each term is at most 1.\nThe next lemma proves a similar result for y∈[1\nc,1\nr).\nLemma 3.2. Ify∈[1\nc,1\nr), then\nAOM\nλ(p, y)\np∗≥c−(1−λ) max(1 ,c\nλ)c·η\np∗.\nProof.Assume that y∈[1/c,1/r), then the acceptance threshold is Φ(λ, y) =λ/r+ (1−λ)cy. Ifp∗≥Φ(λ, y)\nthen the price selected by the algorithm is at least Φ(λ, y), which gives that\nAOM\nλ(p, y)\np∗≥Φ(λ, y)\np∗=λ\nrp∗+ (1−λ)cy\np∗.\nWe have from (3) that p∗≤θ= 1/(cr), henceλ\nrp∗≥λc. Additionally, y≥p∗−η, which gives\nAOM\nλ(p, y)\np∗≥λc+ (1−λ)c\u0010\n1−η\np∗\u0011\n=c−(1−λ)c·η\np∗. (4)\nOn the other hand, if p∗<Φ(λ, y), then the value selected by the algorithm can be as low as 1in the worst\ncase, thus\nAOM\nλ(p, y)\np∗≥1\np∗=1\nΦ(λ, y)·Φ(λ, y)\np∗. (5)\nUsing (3), we can write\nΦ(λ, y) =λ\nr+ (1−λ)cy\n=1\nc−(1−λ) + (1 −λ)cy\n=1\nc+ (1−λ)c\u0010\ny−1\nc\u0011\n, (6)\nhence\ny−Φ(λ, y) =\u0000\n1−(1−λ)c\u0001\u0010\ny−1\nc\u0011\n,\nand it follows from p∗<Φ(λ, y)that\ny−1\nc=y−Φ(λ, y)\n1−(1−λ)c≤y−p∗\n1−(1−λ)c=η\n1−(1−λ)c.\nSubstituting into (6) then using (3) yields\nΦ(λ, y)≤1\nc+(1−λ)c\n1−(1−λ)c·η\n=1\nc+(1−λ)\n1\nc−(1−λ)·η\n=1\nc+\u00101\nλ−1\u0011\nr·η .\n9\n\nFinally, we use this upper bound on Φ(λ, y)in (5) and obtain that\nAOM\nλ(p, y)\np∗=1\nΦ(λ, y)·Φ(λ, y)\np∗\n≥1\n1\nc+ (1\nλ−1)r·η·Φ(λ, y)\np∗\n=c\n1 + (1\nλ−1)rc·η·Φ(λ, y)\np∗\n≥c·Φ(λ, y)\np∗\u0000\n1−(1\nλ−1)rc·η\u0001\n≥c−Φ(λ, y)(1\nλ−1)rc2·η\np∗.\nThe penultimate line follows from the inequality1\n1+u≥1−u, which holds for all u≥0, and the last line\nfrom the assumption p∗≤Φ(λ, y). Given that y≤1/r, we have\nΦ(λ, y) =λ\nr+ (1−λ)cy≤1\nr\u0000\nλ+ (1−λ)c\u0001\n≤1\nr,\nhence\nAOM\nλ(p, y)\np∗≥c−(1\nλ−1)c2·η\np∗=c−(1−λ)c\nλ·c·η\np∗. (7)\nFrom (4) and (7) we deduce that, if y∈[1/c,1/r]then\nAOM\nλ(p, y)\np∗≥min\u0012\nc−(1−λ)c·η\np∗, c−(1−λ)c\nλ·c·η\np∗\u0013\n=c−(1−λ) max(1 ,c\nλ)c·η\np∗.\nFinally, we demonstrate the brittleness of AOM\nλby considering ygreater than, but arbitrarily close to,1\nr.\nProposition 3.3 (AOM\nλis brittle).For any ε >0, it holds that\ninf\np,y:|p∗−y|\np∗≤εAOM\nλ(p, y)\np∗=r(λ).\nProof.Letε >0, and consider the instance p= (1\nr−δ,1)of size 2, with δ∈(0,min(1\nr−1,ε\nr)], so that p1\nremains at least 1and|p1−1/r| ≤εp1. Given a prediction y= 1/rofp∗=p1,AOM\nλsets an acceptance\nthreshold of 1/r > p 1, hence the algorithm rejects p1and accepts p2= 1as it is the last price in the sequence\np. It follows that\nAOM\nλ(p, y)\np∗=1\n1/r−δ,\nhence\ninf\np,y:|p∗−y|\np∗≤εAOM\nλ(p, y)\np∗≤lim\nδ→01\n1/r−δ=r.\nSince, by definition, ris also a lower bound ofAOM\nλ(p,y)\np∗, we deduce that the inequality above is equality,\nwhich concludes the proof.\n10\n\n3.2 Smoothness via randomization\nAs we proved in Lemmas 3.1 and 3.2, if y∈[1,1\nr)then performance of AOM\nλdegrades smoothly with the\nprediction error. The brittleness of AOM\nλin Proposition 3.3 arises in the case where y∈[1/r, θ]: the ratio\nAOM\nλ(p, y)/p∗is larger than cforp∗≥1/r, but it drops immediately to rforp∗<1/r, even arbitrarily close\nto1/r.\nTo attenuate this extreme behavior, we randomize the threshold used when y∈[1/r, θ]. Let AOM\nλ,ρthe\nalgorithm accepting the first price at least equal to the random threshold ˜Φ(λ, ρ, y )defined by\nU∼ U[0,1],˜Φ(λ, ρ, y ) =\n\nΦ(λ, y)ify∈[1,1\nr)\ne−ρU\nrify∈[1\nr, θ].\nIfy∈[1,1\nr), then AOM\nλ,ρis equivalent to AOM\nλ, thus AOM\nλ,ρisr-robust in that case, and the consistency and\nsmoothness guarantees from Lemmas 3.1 and 3.2 extend to AOM\nλ,ρ. Consequently, it suffices to study AOM\nλ,ρ\nwhen y∈[1\nr, θ], and we obtain the following result.\nTheorem 3.4. Letλ∈[0,1],ρ≥0, and let c=c(λ)andr=r(λ)as defined in (3). For any sequence of\nprices p= (p1, . . . , p n)∈[1, θ]nand prediction y∈[1, θ]ofp∗:= max i∈[n]pi, it holds that\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u00121−e−ρ\nρ\u0013\nr ,\nand denoting by η=|p∗−y|, the ratioEU[AOM\nλ,ρ(p,y)]\np∗is at least\n\n\nc−c·η\np∗ ify∈[1,1/c)\nc−(1−λ) max(1 ,c\nλ)c·η\np∗ify∈[1/c,1/r)\n\u0010\n1−e−ρ\nρ\u0011\nc−\u0010\nc−r\nρ\u0011\nη\np∗ify∈[1/r, θ],\nThe first lower bound, independent of the prediction error η, is the robustness of the algorithm, while the\nsecond bound characterizes its consistency and smoothness. The theorem shows that, in order to guarantee\na certain level of smoothness, AOM\nλ,ρdegrades both the consistency and robustness of AOM\nλby a factor of\n(1−e−ρ)/ρ, hence exhibiting a tradeoff between smoothness and both consistency and robustness.\nThe consistency/smoothness bounds for y∈[1,1/r)are proved in Lemmas 3.1 and 3.2, and the robustness\nin that case is r≥\u0010\n1−e−ρ\nρ\u0011\nrbecause AOM\nλ,ρis identical to AOM\nλ. Therefore, it only remains to prove the\nclaimed bounds for y∈[1/r, θ). We demonstrate in Lemma 3.5 the consistency and smoothness of the\nalgorithm, while the robustness is proved in Lemma 3.6.\nLemma 3.5 (Consitency-Smoothness) .For any sequence of prices p, ify∈[1\nr, θ], then\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u00101−e−ρ\nρ\u0011\nc−\u0010c−r\nρ\u0011η\np∗.\nProof.Lety∈[1\nr, θ], hence ˜Φ(λ, ρ, y ) = e−ρU/r, where Uis a uniform random variable in [0,1]. If\np∗≥˜Φ(λ, ρ, y ), then the algorithm has a reward of at least ˜Φ(λ, ρ, y ), and by (3) we obtain\nAOM\nλ,ρ(p, y)\np∗≥˜Φ(λ, ρ, y )\np∗≥e−ρU\nθr=e−ρUc ,\nand if p∗<˜Φ(λ, ρ, y )then\nAOM\nλ,ρ(p, y)\np∗≥1\n˜Φ(λ, ρ, y )=eρUr .\n11\n\nLet us denote by s=−ln(rp∗). Observing that\np∗≥˜Φ(λ, ρ, y )⇐⇒ p∗≥e−ρU/r⇐⇒ eρU≥1\nrp∗⇐⇒ U≥−ln(rp∗)\nρ=s\nρ,\nwe deduce that\nEU[AOM\nλ,ρ(p, y)]\np∗≥cE[e−ρU1U≥s\nρ] +rE[eρU1U<s\nρ]. (8)\nAssume that p∗∈[e−ρ\nr,1\nr], i.e. s∈[0, ρ]. The two terms on the right-hand side above can be computed easily\nE[e−ρU1U≥s\nρ] =Z1\ns/ρe−ρudu=\u0014−e−ρu\nρ\u00151\ns/ρ=e−s−e−ρ\nρ,\nE[eρU1U<s\nρ] =Zs/ρ\n0eρudu=\u0014eρu\nρ\u0015s/ρ\n0=es−1\nρ,\nand we obtain by substituting into (8) that\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u0012e−s−e−ρ\nρ\u0013\nc+\u0012es−1\nρ\u0013\nr (9)\n=\u00121−e−ρ\nρ\u0013\nc+\u00121−es\nρ\u0013\nce−s+\u0012es−1\nρ\u0013\nr\n=\u00121−e−ρ\nρ\u0013\nc−ce−s−r\nρ(es−1)\n≥\u00121−e−ρ\nρ\u0013\nc−c−r\nρ(es−1).\nBy definition of s, we have\nes−1 =1\nrp∗−1 =1/r−p∗\np∗≤y−p∗\np∗=η\np∗,\nwhich yields\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u00121−e−ρ\nρ\u0013\nc−\u0012c−r\nρ\u0013η\np∗.\nwhich corresponds to the consistency/smoothness bound stated in the theorem. However, we only proved it\nforp∗∈[e−ρ\nr,1\nr]. We demonstrate in the following that the bound remains true if p∗is outside that interval.\nIfp∗≥1/r, i.e. s≤0, then (8) gives\nEU[AOM\nλ,ρ(p, y)]\np∗≥cE[e−ρU] =\u00121−e−ρ\nρ\u0013\nc (10)\n≥\u00121−e−ρ\nρ\u0013\nc−\u0012c−r\nρ\u0013η\np∗.\nOn the other hand, if p∗≤e−ρ/r, i.e. s≥ρ, then (8) again gives\nEU[AOM\nλ,ρ(p, y)]\np∗≥rE[eρU1U<1] =\u0012eρ−1\nρ\u0013\nr , (11)\nand it holds that\nη\np∗=y\np∗−1≥1/r\ne−ρ/r−1 =eρ−1≥1−e−ρ,\n12\n\nhence\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u0012eρ−1\nρ\u0013\nr\n≥\u00121−e−ρ\nρ\u0013\nr\n=\u00121−e−ρ\nρ\u0013\nc−\u0012c−r\nρ\u0013\n(1−e−ρ)\n≥\u00121−e−ρ\nρ\u0013\nc−\u0012c−r\nρ\u0013η\np∗.\nThe claimed lower bound is therefore true for all values of p∗.\nLemma 3.6 (Robustness) .For any sequence of prices p, ify∈[1\nr, θ], then\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u00121−e−ρ\nρ\u0013\nr .\nProof.Consider a sequence of prices p. Using Inequality (10)from the proof of Lemma 3.5, if p∗≥1/rthen\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u00121−e−ρ\nρ\u0013\nc≥\u00121−e−ρ\nρ\u0013\nr ,\nand if p∗≤e−ρ/r, then by Inequality (11) we have\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u00121−e−ρ\nρ\u0013\nr .\nIt remains to prove the same lower bound when p∗∈(e−ρ\nr. Assume that that is the case, and let s=\n−ln(rp∗)∈[0, ρ]. Inequality (9) gives that\nEU[AOM\nλ,ρ(p, y)]\np∗≥\u0012e−s−e−ρ\nρ\u0013\nc+\u0012es−1\nρ\u0013\nr\n=r\nρ\u0010c\nre−s+es−c\nre−ρ−1\u0011\n.\nThe function s7→c\nre−s+esis minimal on Rfores=pc\nr. Therefore, on the interval [0, ρ], it is minimal for\nes= min( eρ,pc\nr). Ifpc\nr≥eρthen\nEU[AOM\nλ,ρ(p, y)]\np∗≥r\nρ\u0010c\nre−ρ+eρ−c\nre−ρ−1\u0011\n=\u0012eρ−1\nρ\u0013\nr\n≥\u00121−e−ρ\nρ\u0013\nr .\nOn the other hand, ifpc\nr< eρthen\nEU[AOM\nλ,ρ(p, y)]\np∗≥r\nρ\u0012\n2rc\nr−c\nre−ρ−1\u0013\n.\nThe function u7→ −e−ρu2+ 2u−1is non-decreasing on [1, eρ], hence, sincep\nc/r∈[1, eρ]then\nEU[AOM\nλ,ρ(p, y)]\np∗≥r\nρ\u0000\n2−e−ρ−1\u0001\n=\u00121−e−ρ\nρ\u0013\nr ,\nwhich concludes the proof.\n13\n\n4 Average-Case Analysis in Ski-Rental\nIn this section, we focus on ski-rental , which is one of the fundamental problems in competitive analysis. In\nthis problem, the decision-maker must choose each day between renting a ski for a unit cost or buying it\nfor a fixed cost b, allowing them to ski for free for the remainder of the ski season, which has an unknown\nduration x. The objective is to minimize the total cost incurred from renting and buying. To simplify our\npresentation, we consider the continuous version of the problem, where the number of skiing days increases\ncontinuously, with x, b > 0. In this model, the cost of renting for a time period [t, t+δ)is equal to δ.\nThe ski-rental problem was one of the first problems studied in the learning-augmented framework. Purohit\net al. [2018] proved that, with a prediction yofx, there is a deterministic algorithm with a competitive ratio\nof at most\nmin\u0012\n1 +1\nλ,(1 +λ) +|x−y|\n(1−λ) min( x, b)\u0013\n.\nwhere λ∈[0,1]. It was proved later in Wei and Zhang [2020] that the consistency (1 +λ)and robustness\n(1 +1\nλ)are Pareto-optimal. On the other hand, Benomar and Perchet [2023] analyzed the same algorithm\nunder the assumption that Pr( 1y≥b= 1x≥b) =Qfor some Q∈[1/2,1], and showed how to optimally choose\nλto minimize the expected cost of the algorithm.\nIn the following, we combine the analysis of average-case performance with the criteria of consistency,\nrobustness, and smoothness. To achieve this, we propose a modified version ASR\nλ,ρof the algorithm introduced\nby Purohit et al. [2018], which is parameterized by two parameters λ, ρ∈[0,1].\nAlgorithm 1: ASR\nλ,ρ(x, y)\nify≥bthenbuy at time λb;\nify < bthenbuy at time (1 +ρ(1\nλ−1))b;\nNote that the algorithm of Purohit et al. [2018] corresponds to ASR\nλ,ρwith ρ= 1, i.e. buying at time b/λif\ny < b. We start by proving the consistency, robustness, and smoothness of this algorithm.\nTheorem 4.1. For all x, y > 0, denoting by η=|x−y|, it holds thatASR\nλ,ρ(x,y)\nmin(x,b)is at most\nmin\u0012\n1 +1\nλ,(1 +λ) +\u0012\n1 +λ\nρ\u0013η\nmin(x, b)\u0013\n.\nThe theorem above demonstrates that, for any value of ρ∈[0,1], the algorithm ASR\nλ,ρachieves Pareto-\noptimal consistency and robustness, albeit with varying levels of smoothness. Furthermore, note that our\nanalysis is tighter than that of Purohit et al. [2018]. Specifically, when ρ= 1, we obtain a smoothness factor\nof1 +λinstead of1\n1−λ.\nProof.For simplicity, let us denote by β= (1 + ρ(1\nλ−1)). Note that 1≤β≤1\nλ, and recall that\nmin(x, b) = min( x, b).\nRobustness. We first prove the robustness bound. If y≥b:\n•ifx < λbthenASR\nλ,ρ(x, y) =x= min( x, b),\n•ifλb≤x < bthenASR\nλ,ρ(x, y) = (1 + λ)b≤(1 +1\nλ)x= (1 +1\nλ) min( x, b),\n•ifb≤x, then ASR\nλ,ρ(x, y) = (1 + λ)b= (1 + λ) min( x, b)≤(1 +1\nλ) min( x, b).\nOn the other hand, if y < b:\n•ifx < bthenASR\nλ,ρ(x, y) =x= min( x, b),\n•ifb≤x < βbthenASR\nλ,ρ(x, y) =x < βb =βmin(x, b)≤(1 +1\nλ) min( x, b),\n•ifx≥βxthenASR\nλ,ρ(x, y) = (1 + β)b= (1 + β) min( x, b)≤(1 +1\nλ) min( x, b).\n14\n\nIn all the cases, it always holds that ASR\nλ,ρ(x, y)≤(1 +1\nλ) min( x, b).\nConsistency/Smoothness. Let us first consider the case of y≥b.\n•ifx < λbthenASR\nλ,ρ(x, y) =x= min( x, b),\n•ifλb≤x < bthenASR\nλ,ρ(x, y) = (1 + λ)b≤(1 +λ)y≤(1 +λ) min( x, b) + (1 + λ)η,\n•ifb≤x, then ASR\nλ,ρ(x, y) = (1 + λ)b= (1 + λ) min( x, b).\nIn the case of y < b, we obtain that\n•ifx < bthenASR\nλ,ρ(x, y) =x= min( x, b),\n•ifb≤x < βbthen\nASR\nλ,ρ(x, y) =x≤y+η\n≤b+η= (1 + λ)b−λb+η\n≤(1 +λ) min( x, b) + (1 −λ\nβ)η\n≤(1 +λ) min( x, b) +β−λ\nβ−1η\nwhere we used in the penultimate inequality that η=x−y≤x≤βb.\n•ifx≥βxthen\nASR\nλ,ρ(x, y) = (1 + β)b= (1 + λ)b+ (β−λ)b\n= (1 + λ) min( x, b) + (β−λ)b\n≤(1 +λ) min( x, b) +β−λ\nβ−1η ,\nwhere we used in the last inequality that η=x−y≥(β−1)b.\nAll in all, we deduce that\n∀x, y:ASR\nλ,ρ(x, y)≤(1 +λ) min( x, b) + max\u0012\n1 +λ,β−λ\nβ−1\u0013\nη ,\nand by definition of βwe have\nβ−λ\nβ−1=(ρ+λ)(1\nλ−1)\nρ(1\nλ−1)= 1 +λ\nρ,\nhence\nASR\nλ,ρ(x, y)≤(1 +λ) min( x, b) +\u0012\n1 +λ\nρ\u0013\nη ,\nwhich concludes the proof.\nIn the subsequent theorem, we assume that the prediction ylies on the same side of basxwith a\nprobability of at least Q∈\u00021\n2,1\u0003\n, and we establish an upper bound on the expected cost of Algorithm 1. The\nassumption on yis pertinent for this setting, as the decision made by the algorithm depends only on where y\nis situated compared to b. The same assumption was considered in Benomar and Perchet [2023].\nTheorem 4.2. For all x >0, if the prediction yis a random variable satisfying Pr( 1y≥b= 1x≥b)≥Qfor\nsome Q∈[1\n2,1], thenEy[ASR\nλ,ρ(x,y)]\nmin(x,b)is at most\nmax\u0012\n2 + (1\nλ−1)\u0000\n(1−Q)ρ−Qλ\u0001\n,1 +1−Q\nλ\u0013\n.\n15\n\nNote that the upper bound above is non-decreasing with ρ, regardless of the values of Qorλ. Hence,\nρ= 0is the optimal choice for achieving the best average-case performance of the algorithm. Moreover, if the\nvalue of Qis known, then λcan also be chosen optimally to minimize the upper bound, as demonstrated in\nthe following corollary.\nProof.Let us denote by β= 1 + ρ(1\nλ−1), and assume that Pr( 1y≥b= 1x≥b) =Q. Ifx≥b, then\n•with probability Q:y≥band\nASR\nλ,ρ(x, y) = (1 + λ)b= (1 + λ) min( x, b),\n•with probability 1−Q:y < band\n–ifx < βbthenASR\nλ,ρ(x, y) =x≤βb=βmin(x, b),\n–ifx≥βbthenASR\nλ,ρ(x, y) = (1 + β)b= (1 + β) min( x, b),\nhence we have for x≥bthat\nEy[ASR\nλ,ρ(x, y)]\nmin(x, b)≤Q(1 +λ) + (1 −Q)(1 + β)\n= 1 + λQ+β(1−Q)\n= 1 + λQ+ (1 + (1\nλ−1)ρ)(1−Q)\n= 2 + (1\nλ−1)((1−Q)ρ−Qλ). (12)\nOn the other hand, for x < b\n•with probability Q:y < bandASR\nλ,ρ(x, y) =x= min( x, b)\n•with probability 1−Q:y > band\n–ifx < λbthenASR\nλ,ρ(x, y) =x= min( x, b),\n–ifx < λbthenASR\nλ,ρ(x, y) = (1 + λ)b≤(1 +1\nλ)x= (1 +1\nλ) min( x, b),\nwhich gives for x < bthat\nEy[ASR\nλ,ρ(x, y)]\nmin(x, b)≤Q+ (1−Q)(1 +1\nλ) = 1 +1−Q\nλ. (13)\nWe deduce from (12) and (13) that\n∀x:Ey[ASR\nλ,ρ(x, y)]\nmin(x, b)≤max\u0012\n2 + (1\nλ−1)\u0000\n(1−Q)ρ−Qλ\u0001\n,1 +1−Q\nλ\u0013\n.\nFinally, observe that the right-hand term is a non-increasing function of Q, hence the upper bound holds also\nifPr( 1y≥b= 1x≥b)≥Q.\nCorollary4.2.1. Under the same assumptions of Theorem 4.2, it holds for ρ= 0andλ∗=1\n2q\n(1\nQ−1)(1\nQ+ 3)−\n1\n2(1\nQ−1)that\nEy[ASR\nλ∗,0(x, y)]\nmin(x, b)≤3−Q\n2+1\n2p\n(1−Q)(1 + 3 Q).\nUnder the same assumption on the prediction y, Benomar and Perchet [2023] proved an upper bound of\n(1 + 2p\nQ(1−Q))min(x, b)on the average cost of ASR\nλ,1for a well-chosen value of λ. The bound of Corollary\n4.2.1 is better than the latter as shown in Figure 2. Moreover, note that for Q= 1/2, the bound of Corollary\n4.2.1 is better than 2, which is the best competitive ratio achievable by a deterministic algorithm for the\nski-rental problem. This is because, in that case, ASR\nλ,ρuses the Bernoulli random variable 1y≥b∼ B(1/2).\n16\n\n0.5 0.6 0.7 0.8 0.9 1.0\nq∈[1\n2,1]1.01.21.41.61.82.0\nCorollary 4.3\nBenomar & Perchet, 2023Figure 2: Upper bound on the competitive ratio of ASR\nλ,ρwith λ, ρas in Corollary 4.2.1, and with λ, ρas in\nLemma 2.2 of Benomar and Perchet [2023].\nProof.For all Q∈[1\n2,1]andρ∈[0,1], the upper bound of Theorem 4.2 is non-decreasing with respect to ρ,\nhence the optimal choice of ρis 0. With ρ= 0, let us examine for which value of λthe two terms in the\nmaximum of the upper bound in Theorem 4.2 are equal. We have for all λ∈[0,1]the equivalences\n2−(1−λ)Q= 1 +1−Q\nλ⇐⇒ 1−(1−λ)Q=1−Q\nλ\n⇐⇒λ\nQ−λ(1−λ) =1\nQ−1\n⇐⇒ λ2+\u0010\n1\nQ−1\u0011\nλ−\u0010\n1\nQ−1\u0011\n= 0\n⇐⇒ λ=1\n2r\u0010\n1\nQ−1\u0011\u0010\n3 +1\nQ\u0011\n−1\n2\u0010\n1\nQ−1\u0011\n.\nLet us denote by λ∗the expression of λabove. It holds that λ∗∈[0,1]. Indeed,\nλ∗=1\n2r\u0010\n1\nQ−1\u0011\u0010\n1\nQ+ 3\u0011\n−1\n2\u0010\n1\nQ−1\u0011\n≥1\n2r\u0010\n1\nQ−1\u00112\n−1\n2\u0010\n1\nQ−1\u0011\n= 0,\nλ∗=1\n2q\n1\nQ2+2\nQ−3−1\n2\u0010\n1\nQ−1\u0011\n≤1\n2\u0010\n1\nQ+ 1\u0011\n−1\n2\u0010\n1\nQ−1\u0011\n= 1.\nTherefore, λ∗is a valid value of λthat can be chosen by the decision-maker, which yields the following upper\nbound on the average cost of ASR\nλ,ρ\nEy[ASR\nλ∗,0(x, y)]\nmin(x, b)≤max\u0012\n2−(1−λ∗)Q,1 +1−Q\nλ\u0013\n= 2−(1−λ∗)Q\n= 2−1 +Q\n2+Q2\n2r\u0010\n1\nQ−1\u0011\u0010\n3 +1\nQ\u0011\n=3−Q\n2+1\n2p\n(1−Q)(1 + 3 Q).\nSmoothness and Average-Cost Tradeoff. A natural tradeoff arises between the consistency, robustness,\nand average cost of the algorithm. Minimizing the average cost necessitates selecting λoptimally to minimize\n17\n\nb−2xx b2x\nPrediction y∈[x\nb2,b2x]b+1\nb−11+2b2\nb−1\nr=0.05\nr=0.5\nr=5.0Figure 3: Consistency-smoothness tradeoff of ALS\nbwith a\nprediction randomized as in Theorem 2.3\n0 1 2 3 4 5\ns∈[1,q]0.20.30.40.50.60.70.80.91.0Empirical ratior=0\nr=0.5\nr=1Figure 4: Consistency-smoothness tradeoff of\nAlgorithm AOM\nλ,ρforρ∈ {0,0.5,1}.\nthe upper bound established in Theorem 4.2. However, the decision-maker may opt to deviate from this value\nto achieve a better level of consistency or robustness, depending on the specific use case.\nFurthermore, Theorems 4.1 and 4.2 imply that, for a fixed λ∈[0,1], the levels of consistency and\nrobustness of ASR\nλ,ρare constant, while the smoothness and average cost can be further adjusted using ρ.\nWhile increasing ρenhances the smoothness, it degrades the average cost, regardless of the accuracy Qof the\npredictions. This indicates that, in addition to the tradeoff between consistency and robustness governed by\nλ, the algorithm also exhibits a tradeoff between average cost and smoothness, governed by the parameter ρ.\n5 EXPERIMENTS\nIn this section, we present experimental results to validate our theoretical findings and provide additional\ninsights into the tradeoffs discussed in the paper.\nLine Search. As established in Lemma 2.1 and illustrated in Figure 1, given a target position x≥1\nand prediction y >0, the ratio between the distance traveled by Algorithm ALS\nband the optimal offline\nalgorithm depends solely on the ratio x/ywhen xis large. To investigate the impact of the parameter ρ,\nwe fix x= 100andb= 2.5, then compare the behavior of the algorithm presented in Section 2 for three\ndifferent values of ρ∈ {0.05,0.5,5}, with y∈[x\nb2, b2x]. For each point in the experiment, the average and\nstandard deviation are computed over 105independent trials. Figure 3 demonstrates that smaller values of ρ\nlead to better consistency, but make the algorithm highly sensitive to prediction errors. This highlights the\nconsistency-smoothness tradeoff established in Theorem 2.3.\nOne-Max Search. We conduct an analogous experiment for the one-max search problem to demonstrate the\nconsistency-smoothness tradeoff for AOM\nλ,ρ. Given a sequence with a maximal price p∗, the algorithm is provided\nwith a noisy prediction in the form y=p∗+ε, where ε∼ U[−σ, σ]. The threshold set by AOM\nλ,ρ, denoted as\n˜Φ(λ, ρ, y ), determines its worst-case payoff: if p∗≥˜Φ(λ, ρ, y ), the algorithm gains ˜Φ(λ, ρ, y ); otherwise, the\ngain is 1, which is the minimum possible price in the sequence. This scenario is asymptotically achieved by the\nsequence p= (p1, . . . , p n+1), where pi= 1 +i−1\nn−1(p∗−1)fori≤n, and pn+1= 1. In the experiment, λ= 0.1\nandθ= 5are fixed, and for each σ∈[0, θ], the worst-case average ratio supp∗∈[1,θ]E[AOM\nλ,ρ(p, p∗+ε)]/p∗\nand the corresponding standard deviation are evaluated over 105independent samples. Figure 4 shows that\nthe algorithm suffers from brittleness for ρ= 0, as the slightest prediction error substantially degrades its\nperformance. In contrast, as ρincreases and randomization is introduced, the algorithm becomes smoother;\nat the cost of consistency.\nSki Rental. For the ski-rental problem, two experiments are conducted to investigate, on one hand, the\nimpact of the parameter ρon the consistency and smoothness of the algorithm ASR\nλ,ρ, and on the other hand,\n18\n\n0 5 10 15 20 25\ns∈[0,25]1.51.61.71.81.92.0Empirical ratior=0\nr=0.5\nr=1Figure 5: Consistency-smoothness tradeoff of ASR\nλ,ρ,\nwith y∼x+N(0, σ2)\n0.5 0.6 0.7 0.8 0.9 1.0\nq∈[1\n2,1]1.61.82.02.2Empirical ratior=0\nr=0.5\nr=1Figure 6: Average-case performance of ASR\nλ,ρwhen\n1y≥b= 1x≥bwith probability Q\nits impact on the average performance of ASR\nλ,ρ, under the assumption that the prediction lies on the same\nside of bas the true value of the number of snow days xwith probability Q. In both experiments, we set\nb= 10andλ= 0.5.\nIn Figure 5, the performance of ASR\nλ,ρis evaluated against the prediction error η=|y−x|. Predictions\nare of the form y=x+ε, where ε∼ N (0, σ2). For each value of σ, the figure shows the worst-case\nratio supx∈(0,5b]ASR\nλ,ρ(x, y)/min(x, b), which compares the cost induced by ASR\nλ,ρto that of the optimal offline\nalgorithm at a fixed level of error.\nWhen ρ= 0, the algorithm lacks smoothness, resulting in a significant increase in cost from the consistency\nvalue of 1 +λ= 1.5when the error is zero, to ≈1.7for even a minimal positive error. For larger values of\nρ, the algorithm exhibits improved smoothness while maintaining the same consistency level, as proved in\nTheorem 4.1. However, it is noteworthy that smaller values of ρtend to yield a better average ratio when the\nprediction error is large.\nOn the other hand, Figure 6 examines the the average cost of ASR\nλ,ρ, assuming that 1y≥b= 1x≥bwith\nprobability Q∈\u00021\n2,1\u0003\n. Each data point in the figure is computed over 105independent trials, where\nx∼ U[1,4b], and yis selected arbitrarily on the same side of basxwith probability Q, while on the opposite\nside with probability 1−Q. The results further corroborate our theoretical findings, indicating that smaller\nvalues of ρyield the best average performance.\nCombined with the observations from Figure 5, these experiments delineate the tradeoff between the\nsmoothness and average-case performance of ASR\nλ,ρ, which can be tuned using the parameter ρ.\nReferences\nSpyros Angelopoulos. Online search with a hint. Information and Computation , 295:105091, 2023.\nSpyros Angelopoulos, Christoph Dürr, Shendan Jin, Shahin Kamali, and Marc Renault. Online computation\nwith untrusted advice. arXiv preprint arXiv:1905.05655 , 2019.\nSpyros Angelopoulos, Christoph Dürr, Alex Elenter, and Yanni Lefki. Overcoming brittleness in pareto-optimal\nlearning-augmented algorithms. arXiv preprint arXiv:2408.04122 , 2024a.\nSpyros Angelopoulos, Thomas Lidbetter, and Konstantinos Panagiotou. Search games with predictions. arXiv\npreprint arXiv:2401.01149 , 2024b.\nAntonios Antoniadis, Christian Coester, Marek Eliás, Adam Polak, and Bertrand Simon. Learning-augmented\ndynamic power management with multiple states via new ski rental bounds. Advances in Neural Information\nProcessing Systems , 34:16714–16726, 2021.\n19\n\nAntonios Antoniadis, Joan Boyar, Marek Eliás, Lene Monrad Favrholdt, Ruben Hoeksma, Kim S Larsen,\nAdam Polak, and Bertrand Simon. Paging with succinct predictions. In International Conference on\nMachine Learning , pages 952–968. PMLR, 2023a.\nAntonios Antoniadis, Christian Coester, Marek Eliáš, Adam Polak, and Bertrand Simon. Online metric\nalgorithms with untrusted predictions. ACM Transactions on Algorithms , 19(2):1–34, 2023b.\nLuis Antunes and Lance Fortnow. Worst-case running times for average-case algorithms. In 2009 24th Annual\nIEEE Conference on Computational Complexity , pages 298–303. IEEE, 2009.\nRicardo A Baezayates, Joseph C Culberson, and Gregory JE Rawlins. Searching in the plane. Information\nand computation , 106(2):234–252, 1993.\nEtienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for learning augmented\nalgorithms. Advances in Neural Information Processing Systems , 33:20083–20094, 2020.\nAnatole Beck. On the linear search problem. Israel Journal of Mathematics , 2(4):221–228, 1964.\nAnatole Beck and Donald J Newman. Yet more on the linear search problem. Israel journal of mathematics ,\n8(4):419–429, 1970.\nZiyad Benomar and Christian Coester. Learning-augmented priority queues. arXiv preprint arXiv:2406.04793 ,\n2024.\nZiyad Benomar and Vianney Perchet. Advice querying under budget constraint for online algorithms. In\nThirty-seventh Conference on Neural Information Processing Systems , 2023.\nZiyad Benomar and Vianney Perchet. Non-clairvoyant scheduling with partial predictions. In Forty-first\nInternational Conference on Machine Learning , 2024.\nJakub Chlkedowski, Adam Polak, Bartosz Szabucki, and Konrad Tomasz .Zolna. Robust learning-augmented\ncaching: An experimental study. In International Conference on Machine Learning , pages 1920–1930.\nPMLR, 2021.\nHuda Chuangpishit, Konstantinos Georgiou, and Preeti Sharma. Average case-worst case tradeoffs for\nevacuating 2 robots from the disk in the face-to-face model. In International Symposium on Algorithms and\nExperiments for Sensor Systems, Wireless Networks and Distributed Robotics , pages 62–82. Springer, 2018.\nVincent Cohen-Addad, Tommaso d’Orsi, Anupam Gupta, Euiwoong Lee, and Debmalya Panigrahi. Max-cut\nwith ε-accurate predictions. arXiv preprint arXiv:2402.18263 , 2024.\nIlias Diakonikolas, Vasilis Kontonis, Christos Tzamos, Ali Vakilian, and Nikos Zarifis. Learning online\nalgorithms with distributional advice. In International Conference on Machine Learning , pages 2687–2696.\nPMLR, 2021.\nPaul Dütting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with advice. In\nProceedings of the 22nd ACM Conference on Economics and Computation , pages 409–429, 2021.\nRan El-Yaniv, Amos Fiat, Richard M Karp, and Gordon Turpin. Optimal search and one-way trading online\nalgorithms. Algorithmica , 30:101–139, 2001.\nSreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for rent-or-buy with expert advice. In\nInternational Conference on Machine Learning , pages 2319–2327. PMLR, 2019.\nAnupam Gupta, Debmalya Panigrahi, Bernardo Subercaseaux, and Kevin Sun. Augmenting online algorithms\nwith ε-accurate predictions. Advances in neural information processing systems , 35:2115–2127, 2022.\nMonika Henzinger, Barna Saha, Martin P Seybold, and Christopher Ye. On the complexity of algorithms\nwith predictions for dynamic graph problems. arXiv preprint arXiv:2307.16771 , 2023.\n20\n\nAnna R Karlin, Mark S Manasse, Larry Rudolph, and Daniel D Sleator. Competitive snoopy caching.\nAlgorithmica , 3:79–119, 1988.\nAnna R. Karlin, Mark S. Manasse, Lyle A. McGeoch, and Susan Owicki. Competitive randomized algorithms\nfor nonuniform problems. Algorithmica , 11(6):542–571, 1994.\nTim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index structures.\nInProceedings of the 2018 international conference on management of data , pages 489–504, 2018.\nAlexandra Anna Lassota, Alexander Lindermayr, Nicole Megow, and Jens Schlöter. Minimalistic predictions\nto schedule jobs with online precedence constraints. In International Conference on Machine Learning ,\npages 18563–18583. PMLR, 2023.\nHonghao Lin, Tian Luo, and David Woodruff. Learning augmented binary search trees. In International\nConference on Machine Learning , pages 13431–13440. PMLR, 2022.\nThodoris Lykouris and Sergei Vassilvtiskii. Competitive caching with machine learned advice. In International\nConference on Machine Learning , pages 3296–3305. PMLR, 2018.\nNadav Merlis, Hugo Richard, Flore Sentenac, Corentin Odic, Mathieu Molina, and Vianney Perchet. On\npreemption and learning in stochastic scheduling. In International Conference on Machine Learning , pages\n24478–24516. PMLR, 2023.\nChris Peikert and Alon Rosen. Lattices that admit logarithmic worst-case to average-case connection factors.\nInProceedings of the thirty-ninth annual ACM symposium on Theory of computing , pages 478–487, 2007.\nManish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predictions. Advances\nin Neural Information Processing Systems , 31, 2018.\nLeslie Rice, Anna Bair, Huan Zhang, and J Zico Kolter. Robustness between the worst and average case.\nAdvances in Neural Information Processing Systems , 34:27840–27851, 2021.\nAlexander Robey, Luiz Chamon, George J Pappas, and Hamed Hassani. Probabilistically robust learning:\nBalancing average and worst-case performance. In International Conference on Machine Learning , pages\n18667–18686. PMLR, 2022.\nYonghoShin, ChangyeolLee, GukryeolLee, andHyung-ChanAn. Improvedlearning-augmentedalgorithmsfor\nthe multi-option ski rental problem via best-possible competitive analysis. arXiv preprint arXiv:2302.06832 ,\n2023.\nBo Sun, Russell Lee, Mohammad Hajiesmaili, Adam Wierman, and Danny Tsang. Pareto-optimal learning-\naugmented algorithms for online conversion problems. Advances in Neural Information Processing Systems ,\n34:10339–10350, 2021.\nLászló Szirmay-Kalos and Gábor Márton. Worst-case versus average case complexity of ray-shooting.\nComputing , 61(2):103–131, 1998.\nAlexander Wei and Fred Zhang. Optimal robustness-consistency trade-offs for learning-augmented online\nalgorithms. Advances in Neural Information Processing Systems , 33:8042–8053, 2020.\nCarsten Witt. Worst-case and average-case approximations by simple randomized search heuristics. In Annual\nSymposium on Theoretical Aspects of Computer Science , pages 44–56. Springer, 2005.\nAli Zeynali, Shahin Kamali, and Mohammad Hajiesmaili. Robust learning-augmented dictionaries. In\nForty-first International Conference on Machine Learning .\n21",
  "textLength": 50702
}