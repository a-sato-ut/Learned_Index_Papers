{
  "paperId": "951f876a742dfc28eed01badf8d98318376b72b7",
  "title": "Bao: Making Learned Query Optimization Practical",
  "pdfPath": "951f876a742dfc28eed01badf8d98318376b72b7.pdf",
  "text": "Bao: Learning to Steer Query Optimizers\nRyan Marcus12, Parimarjan Negi1, Hongzi Mao1,\nNesime Tatbul12, Mohammad Alizadeh1, Tim Kraska1\n1MIT CSAIL2Intel Labs\nfryanmarcus, pnegi, hongzi, tatbul, alizadeh, kraska g@csail.mit.edu\nABSTRACT\nQuery optimization remains one of the most challenging\nproblems in data management systems. Recent e\u000borts to\napply machine learning techniques to query optimization\nchallenges have been promising, but have shown few prac-\ntical gains due to substantive training overhead, inability\nto adapt to changes, and poor tail performance. Motivated\nby these di\u000eculties and drawing upon a long history of re-\nsearch in multi-armed bandits, we introduce Bao (the Ba ndit\noptimizer). Bao takes advantage of the wisdom built into\nexisting query optimizers by providing per-query optimiza-\ntion hints. Bao combines modern tree convolutional neu-\nral networks with Thompson sampling, a decades-old and\nwell-studied reinforcement learning algorithm. As a result,\nBao automatically learns from its mistakes and adapts to\nchanges in query workloads, data, and schema. Experimen-\ntally, we demonstrate that Bao can quickly (an order of mag-\nnitude faster than previous approaches) learn strategies that\nimprove end-to-end query execution performance, including\ntail latency. In cloud environments, we show that Bao can\no\u000ber both reduced costs and better performance compared\nwith a sophisticated commercial system.\n1. INTRODUCTION\nQuery optimization is an important task for database man-\nagement systems. Despite decades of study [59], the most\nimportant elements of query optimization { cardinality esti-\nmation and cost modeling { have proven di\u000ecult to crack [34].\nSeveral works have applied machine learning techniques\nto these stubborn problems [27, 29, 33, 39, 41, 47, 60, 61, 64].\nWhile all of these new solutions demonstrate remarkable re-\nsults, they su\u000ber from fundamental limitations that prevent\nthem from being integrated into a real-world DBMS. Most\nnotably, these techniques (including those coming from au-\nthors of this paper) su\u000ber from three main drawbacks:\n1.Sample e\u000eciency. Most proposed machine learning tech-\nniques require an impractical amount of training data before\nthey have a positive impact on query performance. For ex-\nample, ML-powered cardinality estimators require gather-\ning precise cardinalities from the underlying data, a pro-\nhibitively expensive operation in practice (this is why we\nwish to estimate cardinalities in the \frst place). Reinforce-\nment learning techniques must process thousands of queries\nbefore outperforming traditional optimizers, which (when\naccounting for data collection and model training) can take\non the order of days [29,39].\n16b 24b\nJOB Query0204060Query latency (seconds)60.2s\n0.4s21.2s 19.7sPostgreSQL\nPostgreSQL (no loop join)Figure 1: Disabling the loop join operator in PostgreSQL\ncan improve (16b) or harm (24b) a particular query's per-\nformance. These example queries are from the Join Order\nBenchmark (JOB) [30].\n2.Brittleness. While performing expensive training oper-\nations once may already be impractical, changes in query\nworkload, data, or schema can make matters worse. Learned\ncardinality estimators must be retrained when data changes,\nor risk becoming stale. Several proposed reinforcement learn-\ning techniques assume that both the data and the schema\nremain constant, and require complete retraining when this\nis not the case [29,39,41,47].\n3.Tail catastrophe. Recent work has shown that learning\ntechniques can outperform traditional optimizers on aver-\nage, but often perform catastrophically (e.g., 100x regres-\nsion in query performance) in the tail [39, 41, 48]. This is\nespecially true when training data is sparse. While some\napproaches o\u000ber statistical guarantees of their dominance in\nthe average case [64], such failures, even if rare, are unac-\nceptable in many real world applications.\nBao Bao (Ba ndit o ptimizer), our prototype optimizer, can\noutperform traditional query optimizers, both open-source\nand commercial , with minimal training time ( \u00191 hour).\nBao can maintain this advantage even in the presence of\nworkload, data, and schema changes, all while rarely, if ever,\nincurring a catastrophic execution. While previous learned\napproaches either did not improve or did not evaluate tail\nperformance, we show that Bao is capable of improving tail\nperformance by orders of magnitude after a few hours of\ntraining. Finally, we demonstrate that Bao is capable of\nreducing costs andincreasing performance on modern cloud\nplatforms in realistic, warm-cache scenarios.\n1arXiv:2004.03814v1  [cs.DB]  8 Apr 2020\n\nOur fundamental observation is that previous learned ap-\nproaches to query optimization [29, 39, 41, 64], which at-\ntempted to replace either the entire query optimizer or large\nportions of it with learned components, may have thrown the\nbaby out with the bathwater. Instead of discarding tradi-\ntional query optimizers in favor of a fully-learned approach,\nBao recognizes that traditional query optimizers contain\ndecades of meticulously hand-encoded wisdom. For a given\nquery, Bao intends only to steer a query optimizer in the\nright direction using coarse-grained hints. In other words,\nBao seeks to build learned components on top of existing\nquery optimizers in order to enhance query optimization,\nrather than replacing or discarding traditional query opti-\nmizers altogether.\nFor example, a common observation about PostgreSQL\nis that cardinality under-estimates frequently prompt the\nquery optimizer to select loop joins when other methods\n(merge, hash) would be more e\u000bective [30, 31]. This occurs\nin query 16b of the Join Order Benchmark (JOB) [30], as\ndepicted in Figure 1. Disabling loop joins causes a 3x per-\nformance improvement for this query. However, for query\n24b, disabling loop joins creates a serious regression of al-\nmost 50x. Thus, providing the coarse-grained hint \\disable\nloop joins\" helps some queries, but harms others.\nAt a high level, Bao sits on top of an existing query opti-\nmizer and tries to learn a mapping between incoming queries\nand the powerset of such hints. Given an incoming query,\nBao selects a set of coarse-grained hints that limit the search\nspace of the query optimizer (e.g., eliminating plans with\nloop joins from the search space). Bao learns to select dif-\nferent hints for di\u000berent queries, discovering when the under-\nlying query optimizer needs to be steered away from certain\nareas of the plan space.\nOur approach assumes a \fnite set of query hints and treats\neach subset of hints as an arm in a contextual multi-armed\nbandit problem. While in this work we use query hints that\nremove entire operator types from the plan space (e.g., no\nhash joins), in practice there is no restriction that these\nhints are so broad: one could use much more speci\fc hints.\nOur system learns a model that predicts which set of hints\nwill lead to good performance for a particular query. When a\nquery arrives, our system selects hints, executes the resulting\nquery plan, and observes a reward. Over time, our system\nre\fnes its model to more accurately predict which hints will\nmost bene\ft an incoming query. For example, for a highly\nselective query, our system can steer an optimizer towards\na left-deep loop join plan (by restricting the optimizer from\nusing hash or merge joins), and to disable loop joins for less\nselective queries. This learning is automatic.\nBy formulating the problem as a contextual multi-armed\nbandit, Bao can take advantage of sample e\u000ecient and well-\nstudied algorithms [12]. Because Bao takes advantage of an\nunderlying query optimizer, Bao has cost and cardinality\nestimates available, allowing Bao to use a more \rexible rep-\nresentation that can adapt to new data and schema changes\njust as well as the underlying query optimizer. Finally, while\nother learned query optimization methods have to relearn\nwhat traditional query optimizers already know, Bao can\nimmediately start learning to improve the underlying opti-\nmizer, and is able to reduce tail latency even compared to\ntraditional query optimizers.\nInterestingly, it is easy to integrate information about the\nDBMS cache into our approach. Doing so allows Bao touse information about what is held in memory when choos-\ning between di\u000berent hints. This is a desirable feature be-\ncause reading data from in-memory cache is signi\fcantly\nfaster than reading information o\u000b of disk, and it is possi-\nble that the best plan for a query changes based on what is\ncached. While integrating such a feature into a traditional\ncost-based optimizer may require signi\fcant engineering and\nhand-tuning, making Bao cache-aware is as simple as sur-\nfacing a description of the cache state.\nA major concern for optimizer designers is the ability to\ndebug and explain decisions, which is itself a subject of\nsigni\fcant research [6, 21, 46, 54]. Black-box deep learning\napproaches make this di\u000ecult, although progress is being\nmade [7]. Compared to other learned query optimization\ntechniques, Bao makes debugging easier. When a query mis-\nbehaves, an engineer can examine the query hint chosen by\nBao. If the underlying optimizer is functioning correctly, but\nBao made a poor decision, exception rules can be written\nto exclude the selected query hint. While we never needed\nto implement any such exception rules in our experimental\nstudy, Bao's architecture makes such exception rules signi\f-\ncantly easier to implement than for other black-box learning\nmodels.\nBao's architecture is extensible. Query hints can be added\nor removed over time. Assuming additional hints do not lead\nto query plans containing entirely new physical operators,\nadding a new query hint requires little additional training\ntime. This potentially enables quickly testing of new query\noptimizers: a developer can introduce a hint that causes\nthe DBMS to use a di\u000berent optimizer, and Bao will au-\ntomatically learn which queries perform well with the new\noptimizer (and which queries perform poorly).\nIn short, Bao combines a tree convolution model [44], an\nintuitive neural network operator that can recognize impor-\ntant patterns in query plan trees [39], with Thompson sam-\npling [62], a technique for solving contextual multi-armed\nbandit problems. This unique combination allows Bao to\nexplore and exploit knowledge quickly.\nThe contributions of this paper are:\n\u000fWe introduce Bao, a learned system for query opti-\nmization that is capable of learning how to apply query\nhints on a case-by-case basis.\n\u000fWe introduce a simple predictive model and featuriza-\ntion scheme that is independent of the workload, data,\nand schema.\n\u000fFor the \frst time, we demonstrate a learned query op-\ntimization system that outperforms both open source\nand commercial systems in cost and latency, all while\nadapting to changes in workload, data, and schema.\nThe rest of this paper is organized as follows. In Section 2,\nwe introduce the Bao system model and give a high-level\noverview of the learning approach. In Section 3, we formally\nspecify Bao's optimization goal, and describe the predictive\nmodel and training loop used. We present related works in\nSection 4, experimental analysis in Section 5, and concluding\nremarks in Section 6.\n2. SYSTEM MODEL\nBao's system model is shown in Figure 2. When a user\nsubmits a query, Bao's goal is to select a set of query hints\n2\n\nSQLSQLSQL\nParser\nQuery OptimizerHint set 1\n...TCNNReward\nPredictions\nExecution Engine\nExperience Training\nUser provided\nQuery plan\nExternal component\nBao...Hint set 2\nHint set 3Figure 2: Bao system model\nthat will give the best performance for the user's speci\fc\nquery (i.e., Bao chooses di\u000berent query hints for di\u000berent\nqueries). To do so, Bao uses the underlying query optimizer\nto produce a set of query plans (one for each set of hints),\nand each query plan is transformed into a vector tree (a tree\nwhere each node is a feature vector). These vector trees are\nfed into Bao's predictive model, a tree convolutional neural\nnetwork [44], which predicts the outcome of executing each\nplan (e.g., predicts the wall clock time of each query plan).1\nBao chooses which plan to execute using a technique called\nThompson sampling [62] (see Section 3) to balance the ex-\nploration of new plans with the exploitation of plans known\nto be fast. The plan selected by Bao is sent to a query ex-\necution engine. Once the query execution is complete, the\ncombination of the selected query plan and the observed\nperformance is added to Bao's experience. Periodically, this\nexperience is used to retrain the predictive model, creating a\nfeedback loop. As a result, Bao's predictive model improves,\nand Bao learns to select better and better query hints.\nQuery hints & hint sets Bao requires a set of query opti-\nmizer hints , which we refer to as query hints or hints. A hint\nis generally a \rag passed to the query optimizer that alters\nthe behavior of the optimizer in some way. For example,\nPostgreSQL [4], MySQL [3], and SQL Server [5] all provide\na wide range of such hints. While some hints can be applied\nto a single relation or predicate, Bao focuses only on query\nhints that are a boolean \rag (e.g., disable loop join, force in-\ndex usage). For each incoming query, Bao selects a hint set , a\nvalid set of query hints, to pass to the optimizer. We assume\nthat the validity of a hint set is known ahead of time (e.g.,\nfor PostgreSQL, one cannot disable loop joins, merge joins,\nand hash joins at once). We assume that all valid hint sets\ncause the optimizer to produce a semantically-valid query\nplan (i.e., a query plan that produces the correct result).\nModel training Bao's predictive model is responsible for\nestimating the quality of query plans produced by a hint\nset. Learning to predict plan quality requires balancing ex-\nploration and exploitation: Bao must decide when to explore\nnew plans that might lead to improvements, and when to ex-\nploit existing knowledge and select plans similar to fast plans\nseen in the past. We formulate the problem of choosing be-\ntween query plans as a contextual multi-armed bandit [69]\nproblem: each hint set represents an arm, and the query\nplans produced by the optimizer (when given each hint set)\nrepresent the contextual information. To solve the bandit\nproblem, we use Thompson sampling [62], an algorithm with\n1This process can be executed in parallel to maintain rea-\nsonable optimization times, see Section 5.2.both theoretical bounds [57] and real-world success [12]. The\ndetails of our approach are presented in Section 3.\nMixing query plans Bao selects an query plan produced\nby a single hint set. Bao does notattempt to \\stitch to-\ngether\" [15] query plans from di\u000berent hint sets. While pos-\nsible, this would increase the Bao's action space (the number\nof choices Bao has for each query). Letting kbe the number\nof hint sets and nbe the number of relations in a query,\nby selecting only a single hint set Bao has O(k) choices per\nquery. If Bao stitched together query plans, the size of the\naction space would be O(k\u00022n) (kdi\u000berent ways to join each\nsubset ofnrelations, in the case of a fully connected query\ngraph). This is a larger action space than used in previous\nreinforcement learning for query optimization works [39,41].\nSince the size of the action space is an important factor for\ndetermining the convergence time of reinforcement learning\nalgorithms [16], we opted for the smaller action space in\nhopes of achieving quick convergence.2\n3. SELECTING QUERY HINTS\nHere, we discuss Bao's learning approach. We \frst de\fne\nBao's optimization goal, and formalize it as a contextual\nmulti-armed bandit problem. Then, we apply Thompson\nsampling, a classical technique used to solve such problems.\nBao assumes that each hint set HSeti2Fin the family\nof hint sets Fis a function mapping a query q2Qto a\nquery plan tree t2T:\nHSeti:Q!T\nThis function is realized by passing the query Qand the\nselected hint HSetito the underlying query optimizer. We\nrefer toHSetias this function for convenience. We assume\nthat each query plan tree t2Tis composed of an arbitrary\nnumber of operators drawn from a known \fnite set (i.e.,\nthat the trees may be arbitrarily large but all of the distinct\noperator types are known ahead of time).\nBao also assumes a user-de\fned performance metric P,\nwhich determines the quality of a query plan by executing\nit. For example, Pmay measure the execution time of a\nquery plan, or may measure the number of disk operations\nperformed by the plan.\nFor a query q, Bao must select a hint set to use. We call\nthis selection function B:Q!F. Bao's goal is to select\nthe best query plan (in terms of the performance metric P)\nproduced by a hint set. We formalize the goal as a regret\nminimization problem, where the regret for a query q,Rq,\nis de\fned as the di\u000berence between the performance of the\nplan produced with the hint set selected by Bao and the\nperformance of the plan produced with the ideal hint set:\nRq=\u0010\nP(B(q)(q))\u0000min\niP(HSeti(q))\u00112\n(1)\nContextual multi-armed bandits (CMABs) The re-\ngret minimization problem in Equation 1 can be thought of\nin terms of a contextual multi-armed bandit [69], a classic\nconcept from reinforcement learning. A CMAB is problem\nformulation in which an agent must maximize their reward\n2We experimentally tested the plan stitching approach using\nBao's architecture, but we were unable to get the model to\nconvergence.\n3\n\nby repeatedly selecting from a \fxed number of arms . The\nagent \frst receives some contextual information ( context ),\nand must then select an arm. Each time an arm is selected,\nthe agent receives a payout . The payout of each arm is\nassumed to be independent given the contextual informa-\ntion. After receiving the payout, the agent receives a new\ncontext and must select another arm. Each trial is consid-\nered independent. The agent can maximize their payouts\nby minimizing their regret: the closer the agent's actions\nare to optimal, the closer to the maximum possible payout\nthe agent gets.\nFor Bao, each \\arm\" is a hint set, and the \\context\" is\nthe set of query plans produced by the underlying optimizer\ngiven each hint set. Thus, our agent observes the query\nplans produced from each hint set, chooses one of those\nplans, and receives a reward based on the resulting perfor-\nmance. Over time, our agent needs to improve its selection\nand get closer to choosing optimally (i.e., minimize regret).\nDoing so involves balancing exploration and exploitation:\nour agent must not always select a query plan randomly (as\nthis would not help to improve performance), nor must our\nagent blindly use the \frst query plan it encounters with good\nperformance (as this may leave signi\fcant improvements on\nthe table).\nThompson sampling A classic algorithm for solving CMAB\nregret minimization problems while balancing exploration\nand exploitation is Thompson sampling [62]. Intuitively,\nThompson sampling works by slowly building up experience\n(i.e., past observations of performance and query plan tree\npairs). Periodically, that experience is used to construct\na predictive model to estimate the performance of a query\nplan. This predictive model is used to select hint sets by\nchoosing the hint set that results in the plan with the best\npredicted performance.\nFormally, Bao uses a predictive model M\u0012, with model\nparameters (weights) \u0012, which maps query plan trees to es-\ntimated performance, in order to select a hint set. Once a\nquery plan is selected, the plan is executed, and the resulting\npair of a query plan tree and the observed performance met-\nric, (ti;P(ti)), is added to Bao's experience E. Whenever\nnew information is added to E, Bao updates the predictive\nmodelM\u0012.\nIn Thompson sampling, this predictive model is trained\ndi\u000berently than a standard machine learning model. Most\nmachine learning algorithms train models by searching for a\nset of parameters that are most likely to explain the train-\ning data. In this sense, the quality of a particular set of\nmodel parameters \u0012is measured by P(\u0012jE): the higher the\nlikelihood of your model parameters given the training data,\nthe better the \ft. Thus, the most likely model parameters\ncan be expressed as the expectation (modal parameters) of\nthis distribution, which we write as E[P(\u0012jE)]. However,\nin order to balance exploitation and exploration, we sample\nmodel parameters from the distribution P(\u0012jE), whereas\nmost machine learning techniques are designed to \fnd the\nmost likely model given the training data, E[P(\u0012jE)].\nIntuitively, if one wished to maximize exploration, one\nwould choose \u0012entirely at random. If one wished to maxi-\nmize exploitation, one would choose the modal \u0012(i.e.,E[P(\u0012j\nE)]). Sampling from P(\u0012jE) strikes a balance between\nthese two goals [8]. To reiterate, sampling from P(\u0012jE) is\nnot the same as training a model over E. We discuss the\ndi\u000berences at the end of Section 3.1.2.\nAggregate\nSeq Scan Idx ScanMerge Join\nLoop JoinSeq Scan SortAggregate\nSeq Scan Idx ScanMerge Join\nLoop JoinSeq ScanSortnull\nnull\nOriginal Query Plan Binarized Query PlanFigure 3: Binarizing a query plan tree\nIt is worth noting that selecting a hint set for an incom-\ning query is not exactly a bandit problem. This is because\nthe choice of a hint set, and thus a query plan, will a\u000bect\nthe cache state when the next query arrives, and thus every\ndecision is not entirely independent. For example, choosing\na plan with index scans will result in an index being cached,\nwhereas choosing a plan with only sequential scans may re-\nsult in more of the base relation being cached. However, in\nOLAP environments queries frequently read large amounts\nof data, so the e\u000bect of a single query plan on the cache\ntends to be short lived. Regardless, there is substantial ex-\nperimental evidence suggesting that Thompson sampling is\nstill a suitable algorithm in these scenarios [12].\nWe next explain Bao's predictive model, a tree convolu-\ntional neural network. Then, in Section 3.2, we discuss how\nBao e\u000bectively applies its predictive model and Thompson\nsampling to query optimization.\n3.1 Predictive model\nThe core of Thompson sampling, Bao's algorithm for se-\nlecting hint sets on a per-query basis, is a predictive model\nthat, in our context, estimates the performance of a par-\nticular query plan. Based on their success in [39], Bao use\na tree convolutional neural network (TCNN) as its predic-\ntive model. In this section, we describe (1) how query plan\ntrees are transformed into trees of vectors, suitable as input\nto a TCNN, (2) the TCNN architecture, and (3) how the\nTCNN can be integrated into a Thompson sampling regime\n(i.e., how to sample model parameters from P(\u0012jE) as\ndiscussed in Section 3).\n3.1.1 Vectorizing query plan trees\nBao transforms query plan trees into trees of vectors by\nbinarizing the query plan tree and encoding each query plan\noperator as a vector, optionally augmenting this representa-\ntion with cache information.\nBinarization Previous applications of reinforcement learn-\ning to query optimization [29,39,41] assumed that all query\nplan trees were strictly binary: every node in a query plan\ntree had either two children (an internal node) or zero chil-\ndren (a leaf). While this is true for a large class of simple\njoin queries, most analytic queries involve non-binary op-\nerations like aggregation, sorting, and hashing. However,\nstrictly binary query plan trees are convenient for a number\nof reasons, most notably that they greatly simplify tree con-\nvolution (explained in the next section). Thus, we propose\na simple strategy to transform non-binary query plans into\nbinary ones. Figure 3 shows an example of this process. The\noriginal query plan tree (left) is transformed into a binary\nquery plan tree (right) by inserting \\null\" nodes (gray) as\nthe right child of any node with a single parent. Nodes with\n4\n\nAggregate [1, 0, 0, 0, 0, 0, 0, 10, 0.98]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nMerge Join [1, 0, 0, 0, 0, 0, 0, 10, 0.98]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nSort [0, 0, 1, 0, 0, 0, 0, 250, 0.62]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nLoop Join [0, 0, 0, 1, 0, 0, 0, 25, 0.53]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nSeq Scan [0, 0, 0, 0, 1, 0, 0, 9000, 0.12]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCostnull[0, 0, 0, 0, 0, 0, 1, 0, 0.0]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nSeq Scan [0, 0, 0, 0, 1, 0, 0, 100, 0.32]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nnull[0, 0, 0, 0, 0, 0, 1, 0, 0.0]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCost\nIdx Scan [0, 0, 0, 0, 0, 1, 0, 25, 0.08]Agg\nMerge\nSort\nLoop\nSeq\nIdxnull\nCard.\nCostFigure 4: Vectorized query plan tree (vector tree)\nmore than two children (e.g., multi-unions) are uncommon,\nbut can generally be binarized by splitting them up into a\nleft-deep tree of binary operations (e.g., a union of 5 children\nis transformed into a left-deep tree with four binary union\noperators).\nVectorization Bao's vectorization strategy produces vec-\ntors with few components. Each node in a query plan tree\nis transformed into a vector containing three parts: (1) a one\nhot encoding of the operator type, (2) cardinality and cost\nmodel information, and optionally (3) cache information.\nThe one-hot encoding of each operator type is similar to\nvectorization strategies used by previous approaches [29,39].\nEach vector in Figure 4 begins with the one-hot encoding\nof the operator type (e.g., the second position is used to\nindicate if an operator is a merge join). This simple one-hot\nencoding captures information about structural properties\nof the query plan tree: for example, a merge join with a\nchild that is not sort might indicate that more than one\noperator is taking advantage of a sorted order.\nEach vector can also contain information about estimated\ncardinality and cost. Since almost all query optimizers make\nuse of such information, surfacing it to the vector represen-\ntation of each query plan tree node is often trivial. For ex-\nample, in Figure 4, cardinality and cost model information\nis labeled \\Card\" and \\Cost\" respectively. This information\nhelps encode if an operator is potentially problematic, such\na loop joins over large relations or repetitive sorting, which\nmight be indicative of a poor query plan. While we use only\ntwo values (one for a cardinality estimate, the other for a\ncost estimate), any number of values can be used. For exam-\nple, multiple cardinality estimates from di\u000berent estimators\nor predictions from learned cost models may be added.\nFinally, optionally, each vector can be augmented with\ninformation from the current state of the disk cache. The\ncurrent state of the cache can be retrieved from the database\nbu\u000ber pool when a new query arrives. In our experiments,\nwe augment each scan node with the percentage of the tar-\ngeted \fle that is cached, although many other schemes can\nbe used. This gives Bao the opportunity to pick plans that\nare compatible with information in the cache.\nWhile simple, Bao's vectorization scheme has a number of\nadvantages. First, the representation is agnostic to the un-\nderlying schema: while prior work [29,39,41] represented ta-\nbles and columns directly in their vectorization scheme, Bao\nomits them so that schema changes do not necessitate start-\ning over from scratch. Second, Bao's vectorization scheme\nonly represents the underlying data with cardinality esti-\nmates and cost models, as opposed to complex embedding\nmodels tied to the data [39]. Since maintaining cardinality\nestimates when data changes is well-studied and already im-\nplemented in most DBMSes, changes to the underlying data\nare re\rected cleanly in Bao's vectorized representation.\nVectorized Tree\nTree Convolution1x256 1x128 1x64Fully Connected Layer\n1 x 32Fully Connected Layer\n1 x 1Dynam\nic Pooling\n1 x 64LayerInputCost Prediction\nOutputFigure 5: Bao prediction model architecture\n3.1.2 Tree convolutional neural networks\nTree convolution is a composable and di\u000berentiable neural\nnetwork operator introduced in [44] for supervised program\nanalysis and \frst applied to query plan trees in [39]. Here,\nwe give an intuitive overview of tree convolution, and re-\nfer readers to [39] for technical details and analysis of tree\nconvolution on query plan trees.\nAs noted in [39], human experts studying query plans\nlearn to recognize good or bad plans by pattern matching: a\npipeline of merge joins without any intermediate sorts may\nperform well, whereas a merge join on top of a hash join\nmay induce a redundant sort or hash. Similarly, a hash join\nwhich builds a hash table over a very large relation may in-\ncur a spill. While none of this patterns are independently\nenough to decide if a query plan is good or bad, they do serve\nas useful indicators for further analysis; in other words, the\npresence or absence of such a pattern is a useful feature from\na learning prospective. Tree convolution is precisely suited\nto recognize such patterns, and learns to do so automatically,\nfrom the data itself .\nTree convolution consists of sliding several tree-shaped\n\\\flters\" over a larger query plan tree (similar to image con-\nvolution, where \flters in a \flterbank are convolved with an\nimage) to produce a transformed query plan tree of the same\nsize. These \flters may look for patterns like pairs of hash\njoins, or an index scan over a very small relation. Tree con-\nvolution operators are stacked, resulting in several layers of\ntree convolution. Later layers can learn to recognize more\ncomplex patterns, like a long chain of merge joins or a bushy\ntree of hash operators. Because of tree convolution's natu-\nral ability to represent and learn these patterns, we say that\ntree convolution represents a helpful inductive bias [38, 43]\nfor query optimization: that is, the structure of the net-\nwork, not just its parameters, are tuned to the underlying\nproblem.\nThe architecture of Bao's prediction model (similar to\nNeo's value prediction model [39]) is shown in Figure 5. The\nvectorized query plan tree is passed through three layers of\nstacked tree convolution. After the last layer of tree con-\nvolution, dynamic pooling [44] is used to \ratten the tree\nstructure into a single vector. Then, two fully connected\nlayers are used to map the pooled vector to a performance\nprediction. We use ReLU [18] activation functions and layer\nnormalization [10], which are not shown in the \fgure.\nIntegrating with Thompson sampling Thompson sam-\npling requires the ability to sample model parameters \u0012from\nP(\u0012jE), whereas most machine learning techniques are de-\nsigned to \fnd the most likely model given the training data,\nE[P(\u0012jE)]. For neural networks, there are several tech-\nniques available to sample from P(\u0012jE), ranging from com-\n5\n\nplex Bayesian neural networks to simple approaches [56]. By\nfar the simplest technique, which has been shown to work\nwell in practice [51], is to train the neural network as usual,\nbut on a \\bootstrap\" [11] of the training data: the network\nis trained usingjEjrandom samples drawn with replacement\nfromE, inducing the desired sampling properties [51]. We\nselected this bootstrapping technique for its simplicity.\n3.2 Training loop\nIn this section, we explain Bao's training loop, which\nclosely follows a classical Thompson sampling regime: when\na query is received, Bao builds a query plan tree for each\nhint set and then uses the current TCNN predictive model\nto select a query plan tree to execute. After execution, that\nquery plan tree and the observed performance are added to\nBao's experience. Periodically, Bao retrains its TCNN pre-\ndictive model by sampling model parameters (i.e., neural\nnetwork weights) to balance exploration and exploitation.\nWhile Bao closely follows a Thompson sampling regime for\nsolving a contextual multi-armed bandit, practical concerns\nrequire a few deviations.\nIn classical Thompson sampling [62], the model parame-\nters\u0012are resampled after every selection (query). In the\ncontext of query optimization, this is not practical for two\nreasons. First, sampling \u0012requires training a neural net-\nwork, which is a time consuming process. Second, if the size\nof the experience jEjgrows unbounded as queries are pro-\ncessed, the time to train the neural network will also grow\nunbounded, as the time required to perform a training epoch\nis linear in the number of training examples.\nWe use two techniques from prior work on using deep\nlearning for contextual multi-armed bandit problems [13] to\nsolve these issues. First, instead of resampling the model\nparameters (i.e., retraining the neural network) after every\nquery, we only resample the parameters every nth query.\nThis obviously decreases the training overhead by a factor\nofnby using the same model parameters for more than one\nquery. Second, instead of allowing jEjto grow unbounded,\nwe only store the kmost recent experiences in E. By tuning\nnandk, the user can control the tradeo\u000b between model\nquality and training overhead to their needs. We evaluate\nthis tradeo\u000b in Section 5.2.\nWe also introduce a new optimization, speci\fcally useful\nfor query optimization. On modern cloud platforms such\nas [2], GPUs can be attached and detached from a VM with\nper-second billing. Since training a neural network primar-\nily uses the GPU, whereas query processing primarily uses\nthe CPU, disk, and RAM, model training and query execu-\ntion can be overlapped. When new model parameters need\nto be sampled, a GPU can be temporarily provisioned and\nattached. Model training can then be o\u000foaded to the GPU,\nleaving other resources available for query processing. Once\nmodel training is complete, the new model parameters can\nbe swapped in for use when the next query arrives, and the\nGPU can be detached. Of course, users may also choose to\nuse a machine with a dedicated GPU, or to o\u000foad model\ntraining to a di\u000berent machine entirely.\n4. RELATED WORK\nRecently, there has been a groundswell of research on in-\ntegrating machine learning into query optimization. One\nof the most obvious places in query optimization to applymachine learning is cardinality estimation. One of the ear-\nliest approaches was Leo [60], which used successive runs\nof the similar queries to adjust histogram estimators. More\nrecent approaches [27, 33, 61, 67] have used deep learning\nto learn cardinality estimations or query costs in a super-\nvised fashion, although these works require extensive train-\ning data collection and do not adapt to changes in data\nor schema. QuickSel [52] demonstrated that linear mixture\nmodels could learn reasonable estimates for single tables.\nNaru [68] uses an unsupervised learning approach which\ndoes not require training and uses Monte Carlo integration\nto produce estimates, again for materialized tables. In [22],\nauthors present a scheme called CRN for estimating car-\ndinalities via query containment rates. While all of these\nworks demonstrate improved cardinality estimation accu-\nracy, they do not provide evidence that these improvements\nlead to better query performance. In an experimental study,\nOrtiz et al. [48] show that certain learned cardinality estima-\ntion techniques may improve mean performance on certain\ndatasets, but tail latency is not evaluated. In [45], Negi et\nal. show how prioritizing training on cardinality estimations\nthat have a large impact on query performance can improve\nestimation models.\nAnother line of research has examined using reinforcement\nlearning to construct query optimizers. Both [29,41] showed\nthat, with su\u000ecient training, such approaches could \fnd\nplans with lower costs according to the PostgreSQL opti-\nmizer and cardinality estimator. [47] showed that the inter-\nnal state learned by reinforcement learning algorithms are\nstrongly related to cardinality. Neo [39] showed that deep\nreinforcement learning could be applied directly to query\nlatency, and could learn optimization strategies that were\ncompetitive with commercial systems after 24 hours of train-\ning. However, none of these techniques are capable of han-\ndling changes in schema, data, or query workload. Further-\nmore, while all of these techniques show improvements to\nmean query performance after a long training period, none\ndemonstrate improvement in tailperformance.\nWorks applying reinforcement learning to adaptive query\nprocessing [24,64,65] have also shown interesting results, but\nare not applicable to non-adaptive systems.\nThompson sampling has a long history in statistics and de-\ncision making problems and recently it has been used exten-\nsively in the reinforcement learning community as a simple\nyet e\u000ecient way to update beliefs given experience [12, 25,\n62]. We use an alternative setup which lets us get the bene-\n\fts of Thompson sampling without explicitly de\fning how to\nupdate the posterior belief, as described in [51]. Thompson\nsampling has also been applied to cloud workload manage-\nment [40] and SLA conformance [49].\nReinforcement learning techniques in general have also\nseen recent adoption [58]. In [28], the authors present a vi-\nsion of an entire database system built from reinforcement\nlearning components. More concretely, reinforcement learn-\ning has been applied to managing elastic clusters [35, 50],\nscheduling [36], and physical design [53].\nOur work is part of a recent trend in seeking to use ma-\nchine learning to build easy to use, adaptive, and inven-\ntive systems, a trend more broadly known as machine pro-\ngramming [19]. A few selected works outside the context\nof data management systems include reinforcement learning\nfor job scheduling [37], automatic performance analysis [9],\nloop vectorization [20] and garbage collection [23].\n6\n\nn1-2 n1-4 n1-8 n1-16\nMachine Type0100200300400500Cost (cents)\nn1-2 n1-4 n1-8 n1-16\nMachine Type0100200300400500600Time (m)Bao\nPostgreSQL(a) Across four di\u000berent VM types, Bao on the PostgreSQL engine\nvs. PostgreSQL optimizer on the PostgreSQL engine.\nn1-2 n1-4 n1-8 n1-16\nMachine Type0100200300400500Cost (cents)\nn1-2 n1-4 n1-8 n1-16\nMachine Type0100200300400500600Time (m)Bao\nComSys\n(b) Across four di\u000berent VM types, Bao on the ComSys engine\nvs. ComSys optimizer on the ComSys engine.\nFigure 6: Cost (left) and workload latency (right) for Bao\nand two traditional query optimizers across four di\u000berent\nGoogle Cloud Platform VM sizes for the IMDb workload.\nCorp IMDb Stack\nDataset02004006008001000Cost (cents)\nCorp IMDb Stack\nDataset02004006008001000Time (m)Bao\nPostgreSQL\n(a) Across our three evaluation datasets, Bao on the PostgreSQL\nengine vs. PostgreSQL optimizer on the PostgreSQL engine.\nCorp IMDb Stack\nDataset02004006008001000Cost (cents)\nCorp IMDb Stack\nDataset02004006008001000Time (m)Bao\nComSys\n(b) Across our three evaluation datasets, Bao on the ComSys en-\ngine vs. ComSys optimizer on the ComSys engine.\nFigure 7: Cost (left) and workload latency (right) for Bao\nand two traditional query optimizers across three di\u000berent\nworkloads on a N1-16 Google Cloud VM.Size Queries WL Data Schema\nIMDb 7.2 GB 5000 Dynamic Static Static\nStack 100 GB 5000 Dynamic Dynamic Static\nCorp 1 TB 2000 Dynamic StaticaDynamic\nTable 1: Evaluation dataset sizes, query counts, and\nwhether or not the workload (WL), data, and schema are\nstatic or dynamic.\n5. EXPERIMENTS\nThe key question we pose in our evaluation is whether\nor not Bao could have a positive, practical impact on real-\nworld database workloads that include changes in workload,\ndata, and/or schema. To answer this, we focus on quantify-\ning not only query performance, but also on the dollar-cost\nof executing a workload (including the training overhead in-\ntroduced by Bao) on cloud infrastructure.\nOur experimental study is divided into three parts. In\nSection 5.1, we explain our experimental setup. Section 5.2\nis designed to evaluate Bao's real-world applicability, and\ncompares Bao's performance against both PostgreSQL and\na commercial database system [55] on real-world workloads\nexecuted on Google Cloud Platform with caching enabled.\nSpeci\fcally, we examine:\n\u000fworkload performance, tail latency, and total costs for\nexecuting workloads with Bao, the PostgreSQL opti-\nmizer, and a commercial system with dynamic work-\nloads, data, and schema,\n\u000fBao's resiliency to hints that induce consistent or sud-\nden poor performance,\n\u000fquantitative and qualitative di\u000berences between Bao\nand previous learned query optimization approaches.\nSection 5.3 is designed to evaluate Bao's optimality in\nterms of regret , the di\u000berence between Bao's decisions and\nthe optimal choice. Experiments in these sections are nec-\nessarily conducted on a private, isolated server, and each\nquery is executed with a cold cache. This section evaluates:\n\u000fBao's ability to adapt to di\u000berent optimization goals\n(e.g., disk IOs),\n\u000fthe median and tail latency achieved by Bao relative to\nan optimal choice and an open source query optimizer,\n\u000fBao's query-by-query performance on the join order\nbenchmark [30].\n5.1 Setup\nWe evaluated Bao using the datasets listed in Table 1.\n\u000fThe IMDb dataset is an augmentation of the Join Or-\nder Benchmark [30]: we added thousands of queries\nto the original 113 queries,3and we vary the query\nworkload over time by introducing new templates pe-\nriodically. The data and schema remain static.\n3https://rm.cab/imdb\n7\n\n\u000fThe Stack dataset is a new dataset introduced by this\nwork and available publicly.4The Stack dataset con-\ntains over 18 million questions and answers from 170\ndi\u000berent StackExchange websites (such as StackOver-\n\row.com) between July 2008 and September 2019. We\nemulate data drift by initially loading all data up to\nSeptember 2018, and then incrementally inserting the\ndata from September 2018 to September 2019. We\nhave produced 5000 queries from 25 di\u000berent templates,\nand we vary the query workload by introducing new\ntemplates periodically. The schema remains static.\n\u000fThe Corp dataset is a dashboard analytics workload\nexecuted over one month donated by an anonymous\ncorporation. The Corp dataset contains 2000 unique\nqueries issued by analysts. Half way through the month,\nthe corporation normalized a large fact table, result-\ning in a signi\fcant schema change. We emulate this\nschema change by introducing the normalization after\nthe execution of the 1000th query (queries after the\n1000th expect the new normalized schema). The data\nremains static.\nFor the Stack and IMDb workloads, we vary the workload\nover time by introducing new query templates periodically.\nWe choose the query sequence by randomly assigning each\nquery template to two of eight groups (every query template\nis in exactly two groups). We then build 8 corresponding\ngroups of query instances, placing one half of all instances\nof a query template into the corresponding query template\ngroup. We then randomly order the query instances within\neach group, and concatenate the groups together to deter-\nmine the order of the queries in the workload. This ensures\nthat a wide variety of template combinations and shifts are\npresent. Note that for the Corp workload, the queries are\nreplayed in the same order as analysts issues them.\nUnless otherwise noted, we use a \\time series split\" strat-\negy for training and testing Bao. Bao is always evaluated\non the next, never-before-seen query qt+1. When Bao makes\na decision for query qt+1, Bao is only trained on data from\nearlier queries. Once Bao makes a decision for query qt+1,\nthe observed reward for that decision { and only that deci-\nsion { is added to Bao's experience set. This strategy di\u000bers\nfrom previous evaluations in [29, 39, 41, 47] because Bao is\nnever allowed to learn from two di\u000berent decisions about\nthe same query.5Whereas in the prior works mentioned,\na reinforcement learning algorithm could investigate many\npossible decisions about the same query, our technique is a\nmore realistic: once a query is executed using a particular\nplan, Bao does not get any information about alternative\nplans for the same query.\nBao's prediction model uses three layers of tree convolu-\ntion, with output dimensions (256, 128, 64), followed by a\ndynamic pooling [44] layer and two linear layers with output\ndimensions (32, 1). We use ReLU activation functions [18]\nand layer normalization [10] between each layer. Training is\nperformed with Adam [26] using a batch size of 16, and is\nran until either 100 epochs elapsed or convergence is reached\n(as measured by a decrease in training loss of less than 1%\nover 10 epochs).\n4https://rm.cab/stack\n5In OLAP workloads where nearly-identical queries are fre-\nquently repeated (e.g., dashboards), this may be an over-\ncautious procedure.Experiments in Section 5.2 are performed on Google Cloud\nPlatform, using a N1-4 VM type unless otherwise noted.\nNVIDIA Tesla T4 GPUs are attached to VMs when needed.\nCost and time measurements include query optimization,\nmodel training (including GPU time), and query execution.\nCosts are reported as billed by Google, and include startup\ntimes and minimum usage thresholds. Experiments in Sec-\ntion 5.3 are performed on a virtual machine with 4 CPU\ncores and 15 GB of RAM (to match the N1-4 VMs) on pri-\nvate server with two Intel(R) Xeon(R) Gold 6230 CPUs run-\nning at 2.1 Ghz, an NVIDIA Tesla T4 GPU, and 256GB of\nsystem (bare metal) RAM.\nWe compare Bao against the open source PostgreSQL\ndatabase and a commercial database system (ComSys) we\nare not permitted to name [55]. Both systems are con\fg-\nured and tuned according to their respective documentation\nand best practices guide. A consultant from the company\nthat produces the commercial system under test veri\fed our\ncon\fguration with a small performance test. Bao's chosen\nexecution plan is always executed on the system being com-\npared against: for example, when comparing against the\nPostgreSQL optimizer, Bao's execution plans are always ex-\necuted on the PostgreSQL engine.\nUnless otherwise noted, we use a family of 48 hint sets,\nwhich each use some subset of the join operators fhash join,\nmerge join, loop join gand some subset of the scan operators\nfsequential, index, index only g. For a detailed description,\nsee the online appendix [1]. We found that setting the look-\nback window size to k= 2000 and retraining every n= 100\nqueries provided a good tradeo\u000b between GPU time and\nquery performance.\n5.2 Real-world performance\nIn this section, we evaluate Bao's performance in a real-\nistic warm-cache scenario. In these experiments, we aug-\nment each leaf node vector with caching information as de-\nscribed in Section 3.1.1. For caching information, we queried\nthe commercial system's internal system tables to determine\nwhat percentage of each \fle was cached. We used a similar\nstrategy for PostgreSQL, using the built-in pgbuffercache\nextension in the contrib folder.\nCost and performance in the cloud To evaluate Bao's\npotential impact on both query performance and cost, we\nbegin by evaluating Bao on the Google Cloud Platform [2].\nFigure 6a shows the cost (left) and time required (right) to\nexecute the IMDb workload on various VM sizes when us-\ning Bao and when using the PostgreSQL optimizer on the\nPostgreSQL engine. Generally, Bao achieves both a lower\ncost and a lower workload latency. For example, on a N1-16\nVM, Bao reduces costs by over 50% (from $4.60 to $2.20)\nwhile also reducing the total workload time from over six\nhours to just over three hours. The Bao costs doinclude\nthe additional fee for renting a GPU: the increased query\nperformance more than makes up for the cost incurred from\nattaching a GPU for training. The di\u000berence in both cost\nand performance is most signi\fcant with larger VM types\n(e.g., N1-16 vs. N1-8), suggesting the Bao is better capable\nof tuning itself towards the changing hardware than Post-\ngreSQL. We note that we didre-tune PostgreSQL for each\nhardware platform.\nFigure 6b shows the same comparison against the com-\nmercial database system. Again, Bao is capable of achieving\nlower cost and lower workload latency on all four tested ma-\n8\n\nN1-2 N1-4 N1-8 N1-16PostgreSQL\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nPostgreSQL\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nPostgreSQL\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nPostgreSQL\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nPostgreSQL ComSys\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nComSys\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nComSys\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nComSys\n50% 95% 99% 99.5%\nPercentile050100150Wall time (s)Bao\nComSys\nFigure 8: Percentile latency for queries, IMDb workload. Each column represents a VM type, from smallest to largest. The\ntop row compares Bao against the PostgreSQL optimizer on the PostgreSQL engine. The bottom row compares Bao against\na commercial database system on the commercial system's engine. Measured across the entire (dynamic) IMDb workload.\nchine types. However, the di\u000berence is less signi\fcant, and\nthe overall costs are much lower, suggesting the commercial\nsystem is a stronger baseline than PostgreSQL. For exam-\nple, while Bao achieved almost a 50% cost and latency re-\nduction on the N1-16 machine compared to the PostgreSQL\noptimizer, Bao achieves only a 20% reduction compared to\nthe commercial system. We also note that the improve-\nments from Bao are no longer more signi\fcant with larger\nVM types, indicating that the commercial system is more\ncapable of adjusting to di\u000berent hardware. Note that these\ncosts do notinclude the licensing fees for the commercial\nsystem, which were waived for the purposes of this research.\nChanging schema, workload, and data In Figure 7, we\n\fx the VM type to N1-16 and evaluate Bao on di\u000berent\nworkloads. Bao shows signi\fcant improvements over Post-\ngreSQL, and marginal improvements against the commercial\nsystem. This demonstrates Bao's ability to adapt to chang-\ning data (Stack), and to a signi\fcant schema change (Corp),\nwhere Bao achieves a 50% and 40% reduction in both cost\nand workload latency (respectively).\nTail latency analysis The previous two experiments demon-\nstrate Bao's ability to reduce the cost and latency of an\nentire workload. Since practitioners are often interested in\ntail latency (e.g., for an analytics dashboard that does not\nload until a set of queries is complete, the tail performance\nessentially determines the performance for the entire dash-\nboard), here we will examine the distribution of query laten-\ncies within the IMDb workload on each VM type. Figure 8\nshows median, 95%, 99%, and 99.5% latencies for each VM\ntype (column) for both PostgreSQL (top row) and the com-\nmercial system (bottom row).\nFor each VM type, Bao drastically decreases tail latencies\nwhen compared to the PostgreSQL optimizer. On an N1-8\ninstance, 99% latency fell from 130 seconds with the Post-\ngreSQL optimizer to under 20 seconds with Bao. This sug-\ngests that most of the cost and performance gains from Bao\ncome from reductions at the tail. Compared with the com-\nmercial system, Bao always reduces tail latency, although itis only signi\fcantly reduced on the smaller VM types. This\nsuggests that the developers of the commercial system may\nnot have invested as much time in reducing tail latencies on\nless powerful machines: a task that Bao can perform auto-\nmatically and without any developer intervention.\nTraining time and convergence A major concern with\nany application of reinforcement learning is convergence time.\nFigure 9 shows time vs. queries completed plots (perfor-\nmance curves) for each VM type while executing the IMDb\nworkload. In all cases, Bao, from a cold start, matches the\nperformance of PostgreSQL within an hour, and exceeds the\nperformance of PostgreSQL within two hours. Plots for the\nStack and Corp datasets are similar. Plots comparing Bao\nagainst the commercial system are also similar, with slightly\nlonger convergence times: 90 minutes at the latest to match\nthe performance of the commercial optimizer, and 3 hours\nto exceed the performance of the commercial optimizer.\nNote that the IMDb workload is dynamic, and that Bao\nmaintains and adapts to changes in the query workload.\nThis is visible in Figure 9: Bao's performance curve remains\nstraight after a short initial period, indicating that shifts in\nthe query workload did not produce a signi\fcant change in\nquery performance.\nPredictive model accuracy The core of Bao's bandit al-\ngorithm is a predictive model, which Bao uses to select hint\nsets for each incoming query. As Bao makes more deci-\nsions, Bao's experience grows, allowing Bao to train a more\naccurate model. Figure 10a shows the accuracy of Bao's\npredictive model after processing each query in the IMDb\nworkload on an N1-16 machine. Following [32, 42], we use\nQ-Error instead of relative error [63]. Given a prediction x\nand a true value y, the Q-Error is de\fned as:\nQError (x;y) = max\u0012x\ny;y\nx\u0013\n\u00001\nQ-Error can be interpreted as a symmetric version of relative\nerror. For example, a Q-Error of 0.5 means the estimator\nunder or over estimated by 50%.\n9\n\n0 2 4 6 8 10\nTime (hours)0k1k2k3k4k5kQueries finished Bao\nPostgreSQL(a) VM type N1-2\n0 2 4 6 8 10\nTime (hours)0k1k2k3k4k5kQueries finished Bao\nPostgreSQL (b) VM type N1-4\n0 2 4 6 8 10\nTime (hours)0k1k2k3k4k5kQueries finished Bao\nPostgreSQL (c) VM type N1-8\n0 2 4 6 8 10\nTime (hours)0k1k2k3k4k5kQueries finished Bao\nPostgreSQL (d) VM type N1-16\nFigure 9: Number of IMDb queries processed over time for Bao and the PostgreSQL optimizer on the PostgreSQL engine.\nThe IMDb workload contains 5000 unique queries which vary over time.\n0 1000 2000 3000 4000 5000\nQueries processed123Q ErrorBao prediction error\n(a) Median Q-Error (0 is a perfect predic-\ntion) of Bao's predictive model vs. the num-\nber of queries processed. IMDb workload on\nN1-16 VM using PostgreSQL engine.\n0 1000 2000 3000 4000 5000\nWindow size (# queries)0100200Training time (s)Simulation\nObservation(b) Simulated and observed time to train\nBao's performance prediction model (GPU)\nbased on the sliding window size (number of\nqueries used during each training iteration).\n0 2 4\nTime (hours)0k0k1k1k2kQueries finishedBao\nPostgreSQL\nRF\nLinear\nBest hint set(c) Random forest (RF) and linear models\n(Linear) used as Bao's model. \\Best hint\nset\" is the single best hint set. IMDb, N1-\n16 VM, on PostgreSQL.\nFigure 10\nAs shown in Figure 10a, Bao's predictive model begins\nwith comparatively poor accuracy, with a peak mispredic-\ntion of 300%. Despite this inaccuracy, Bao is still able to\nchoose plans that are not catastrophic (as indicated by Fig-\nure 9d). Bao's accuracy continues to improve as Bao gains\nmore experience. We note that this does not indicate that\nBao could be used as generic query performance prediction\ntechnique: here, Bao's predictive model is only evaluated\non query plans produced by one optimizer, and thus most\nof the plans produced may not be representative of what\nother query optimizer's produce.\nRequired GPU time Bao's tree convolution neural net-\nwork is trained on a GPU. Because attaching a GPU to\na VM incurs a fee, Bao only keeps a GPU attached for the\ntime required to train the predictive model (see Section 3.2).\nFigure 10b shows how long this training time takes as a func-\ntion of the window size k(the maximum number of queries\nBao uses to train). Theoretically, the training time required\nshould be linear in the window size. The \\Observation\" line\nshows the average time to train a new predictive model at\na given window size. The \\Simulation\" line shows the lin-\near regression line of these data, which shows the training\ntime does indeed follow a linear pattern. Fluctuations may\noccur for a number of reasons, such as block size transfers\nto the GPU, noisy neighbors in cloud environments, and the\nstochastic nature of the Adam optimizer.\nGenerally speaking, larger window sizes will require longer\ntraining, and thus more GPU time, but will provide a more\naccurate predictive model. While we found a window size of\nk= 2000 to work well, practitioners will need to tune this\nvalue for their needs and budget (e.g., if one has a dedicated\nGPU, there may be no reason to limit the window size at all).\nWe note that even when the window size is set to k= 5000queries (the maximum value for our workloads with 5000\nqueries), training time is only around three minutes.\nDo we need a neural network? Neural networks are\na heavy-weight machine learning tool, and should only be\napplied when simpler techniques fail. Often, simpler tech-\nniques can even perform better than deep learning [14]. To\ndetermine if the specialized tree convolutional neural net-\nwork used by Bao was justi\fed, we tested random forest\n(RF) and linear regression (Linear) models as well.6For\nthese techniques, we featurized each query plan tree into a\nsingle vector by computing minimums, medians, maximums,\naverages, and variances of each entry of each tree node's vec-\ntorized representation. The resulting performance curve for\nthe \frst 2000 queries of the IMDb workload is shown in Fig-\nure 10c. Both the random forest and the linear regression\nmodel fail to match PostgreSQL's performance.\nThis provides evidence that a deep learning approach is\njusti\fed for Bao's predictive model. We note that Bao's\nneural network is not a standard fully-connected neural net-\nwork: as explained in [39], tree convolution carries a strong\ninductive bias [38] that matches well with query plans.\nIs one hint set good for all queries? A simple alter-\nnative to Bao might be successive elimination bandit algo-\nrithms [17], which seek to \fnd the single besthint set re-\ngardless of a speci\fc query. We evaluated each hint set on\nthe entire IMDb workload. In Figure 10c, we plot this sin-\ngle best hint set (which is disabling loop joins) as \\Best\nhint set\". This single hint set, while better than all the\nothers, performs signi\fcantly worse than the PostgreSQL\noptimizer. Since, unsurprisingly, no single hint set is good\nenough to outperform PostgreSQL (otherwise, PostgreSQL\n6We performed an extensive grid search to tune the random\nforest model.\n10\n\n0.0 0.5 1.0 1.5 2.0\nTime (hours)0.00.51.0Selection frequencyCJ\nTempFigure 11: Selection frequency of optimizers over time when\nBao is given a speci\fc additional hitn set. \\CJ\" is a hint set\nthat always induces plans with cross joins. \\Temp\" is hint\nset that induces the optimal plan until one hour has elapsed,\nthen induces plans with cross joins.\nwould likely use it as a default), we conclude that succes-\nsive elimination bandit algorithms are not suitable for this\napplication.\nThis also provides evidence that Bao is learning a non-\ntrivial strategy when selecting hint sets, as if Bao were only\nselecting one hint set, Bao's performance could not possibly\nbe better than \\Best hint set.\" To further test this hypoth-\nesis, we evaluated the number of distinct hint sets chosen\nmore than 100 times for each dataset on a N1-4 machine on\nthe PostgreSQL engine. For IMDb,35\n48hint sets were cho-\nsen over 100 times, indicating a high amount of diversity to\nBao's strategy. For Stack, this value was37\n48, and for Corp\nthis value was15\n48. The less diverse strategy learned by Bao\nin the Corp case could be due to similarities between queries\nissued by analysts. We leave a full analysis of Bao's learned\nstrategies, and their diversity, to future work.\nWhat if a hint set performs poorly? Here, we test Bao's\nresiliency to hint sets that induce unreasonable query plans\nby arti\fcially introducing a poor-performing hint set. Fig-\nure 11 shows the selection frequency (how often Bao chooses\na particular hint set over a sliding window of 100 queries)\nover a two-hour period executing the IMDb workload. The\n\frst hint set, \\CJ\", induces query plans with cross joins\nthat are 100x worse than the optimal. Bao selects the \\CJ\"\nhint set once (corresponding to an initial selection frequency\nof1\n49), and then never selects the \\CJ\" hint set again for\nthe duration of the experiment. Bao is able to learn to avoid\n\\CJ\" so e\u000eciently (i.e., with extremely few samples) because\nBao makes predictions based on query plans: once Bao ob-\nserves a plan full of cross joins, Bao immediately learns to\navoid plans with cross joins.\nIt is possible that a hint set's behavior changes over time,\nor that a change in workload or data may cause a hint set to\nbecome unreasonable. For example, if new data was added\nto the database that resulted in a particular intermediary\nbecoming too large to \ft in a hash table, a hint set inducing\nplans that use exclusively hash joins may no longer be a\ngood choice.\nTo test Bao's resiliency to this scenario, we introduce the\n\\Temp\" hint set, which produces the optimal query plan\n(precomputed ahead of time) until 1 hour has elapsed, at\nwhich point the \\Temp\" hint set induces query plans with\ncross joins (the same plans as \\CJ\"). Figure 11 shows that,\nin the \frst hour, Bao learns to use \\Temp\" almost exclu-\nsively (at a rate over 95%), but, once the behavior of \\Temp\"\nchanges, Bao quickly stops using \\Temp\" entirely.Trad Neo Bao\nNeeds cardinality estimation Yes No Yes\nNeeds cost model Yes No Yes\nNeeds pretraining No Yes No\nHandles schema changes Yes No Yes\nHandles data changes Yes No Yes\nHandles workload changes Yes Slowly Yes\nAccounts for cache Maybe No Yes\nApprox. convergence time 0 hrs 24 hrs 1 hr\nTable 2: Requirements and feature comparison of a tradi-\ntional cost-based optimizer (Trad), the fully-learned opti-\nmizer Neo [39], and Bao.\n0 20 40 60\nTime (hours)0k20k40k60k80k100kQueries finishedBao\nPostgreSQL\nNeo\n(a) Stable query workload\n0 20 40 60\nTime (hours)0k20k40k60k80k100kQueries finishedBao\nPostgreSQL\nNeo (b) Dynamic query workloads\nFigure 12: Comparison of number of queries \fnished over\ntime for Bao, Neo, and PostgreSQL for a stable query work-\nload (left) and a dynamic query workload (right).\nOptimization time Another concern with applying ma-\nchine learning to query optimization is inference time. Sur-\nprisingly, some reinforcement learning approachs [29,41] ac-\ntually decrease optimization time. Here, we evaluate the op-\ntimization overhead of Bao. Across all workloads, the Post-\ngreSQL optimizer had a maximum planning time of 140ms.\nThe commercial system had a maximum planning time of\n165ms. Bao had higher maximum planning times than both\nother systems, with a maximum planning time of 210ms.\nBao's increased planning time is due to two factors:\n1. Hint sets: a query plan must be constructed for each\nhint set. While each hint set can be ran in parallel,\nthis accounts for approximately 80% of Bao's planning\ntime (168ms).\n2. Neural network inference: after each hint set produces\na query plan, Bao must run each one through a tree\nconvolutional neural network. These query plans can\nbe processed in a batch, again exploiting parallelism.\nThis accounts for the other 20% of Bao's planning time\n(42ms.)\nSince analytic queries generally run for many seconds or\nminutes, a 210ms optimization time may be acceptable in\nsome applications. Further optimizations of the query opti-\nmizer, or optimizations of the neural network inference code\n(written in Python for our prototype), may reduce optimiza-\ntion time. Applications requiring faster planning time may\nwish to consider other options [66].\nComparison with Neo Neo [39] is an end-to-end query op-\ntimizer based on deep reinforcement learning. Like Bao, Neo\nuses tree convolution, but unlike Bao, Neo does not select\nhint sets for speci\fc queries, but instead fully builds query\n11\n\nIMDb Stack\nDataset101\n100Median regret (CPU s)\nIMDb Stack\nDataset107108Median regret (Disk IOs)Bao (CPU)\nBao (IO)\nPostgreSQLFigure 13: Comparison of the median regret (di\u000berence be-\ntween the outcome of the selected action and the ideal hint\nset) when Bao is optimizing for CPU time or for physical\ndisk I/Os. The two Bao models and PostgreSQL are plotted\nin terms of CPU time (left) and physical disk I/Os (right).\nExecuted on the PostgreSQL engine.\nexecution plans on its own. A qualitative comparison of Neo,\nBao, and traditional query optimizers is shown in Table 2.\nWhile Neo avoids the dependence on a cardinality estima-\ntor and a cost model (outside of Neo's bootstrapping phase),\nNeo is unable to handle schema changes or changes in the\nunderlying data (to handle these scenarios, Neo requires re-\ntraining). Additionally, because Neo is learning a policy to\nconstruct query plan trees themselves (a more complex task\nthan choosing hint sets), Neo requires substantially longer\ntraining time to match the performance of traditional query\noptimizers (i.e., 24 hours instead of 1 hour). While neither\nthe PostgreSQL nor the ComSys optimizer took cache state\ninto account, implementing cache awareness in a traditional\ncost-based optimizer is theoretically possible, although likely\ndi\u000ecult.\nIn Figure 12, we present a quantitative comparison of Bao\nand Neo. Each plot shows the performance curves for the\nIMDb workload repeated 20 times on an N1-16 machine with\na cuto\u000b of 72 hours. However, in Figure 12a, we modify the\nIMDb workload so that each query is chosen uniformly at\nrandom (i.e., the workload is no longer dynamic). With a\nstable workload, Neo is able to overtake PostgreSQL after\n24 hours, and Bao after 65 hours. This is because Neo has\nmany more degrees of freedom than Bao: Neo can use any\nlogically correct query plan for any query, whereas Bao is\nlimited to a small number of options. However, these degrees\nof freedom come with a cost, as Neo takes signi\fcantly longer\nto converge. When the workload, schema, and data are all\nstable, and a suitable amount of training time is available,\nthe plans learned by Neo are superior to the plans selected by\nBao, and Neo will perform better over a long time horizon.\nIn Figure 12b, we use a dynamic workload instead of a\nstatic workload. In this case, Neo's convergence is signi\f-\ncantly hampered: Neo requires much more time to learn a\npolicy robust to the changing workload and overtake Post-\ngreSQL (42 hours). With a dynamic workload, Neo is unable\nto overtake Bao. This showcases Bao's ability to adapt to\nchanges better than previous learned approaches.\n5.3 Optimality\nHere, we evaluate Bao's regret , the di\u000berence in perfor-\nmance relative to the optimal hint set for each query. The\noptimal hint set for each query was computed by exhaus-\ntively executing all query plans. In order for this to bepractical, each query is executed with a cold cache7on a\ncluster of GCP [2] nodes.\nCustomizable optimization goals Here, we test Bao's\nability to optimize for di\u000berent metrics. Figure 13 shows the\nmedian regret observed over all IMDb and Stack queries. We\ntrain two di\u000berent Bao models, one which optimizes for CPU\ntime (\\Bao (CPU)\"), and one which optimizers for disk IOs\n(\\Bao (IO)\"). Figure 13 shows the median regret of these\ntwo Bao models and the PostgreSQL optimizer in terms of\nCPU time (left) and disk IOs (right). Unsurprisingly, Bao\nachieves a lower median CPU time regret when trained to\nminimize CPU time, and Bao achieves a lower median disk\nIO regret when trained to minimize disk IOs. Incidentally,\nfor both metrics and both datasets, Bao achieves a signi\f-\ncantly lower median regret than PostgreSQL, regardless of\nwhich metric Bao is trained on. . The ability to customize\nBao's performance goals could be helpful for cloud providers\nwith complex, multi-tenant resource management needs.\nRegret over time & tails Figure 15 and 16 shows the\ndistribution of regret for both PostgreSQL (left) and Bao\nover each iteration (right). Note both the cut axes and that\nthe whiskers show the 98% percentile. For both metrics and\ndatasets, Bao is able to achieve signi\fcantly better tail re-\ngret from the \frst iteration (after training). For example,\nwhen optimizing CPU time, the PostgreSQL optimizer picks\nseveral query plans requiring over 720 CPU seconds, whereas\nBao never chooses a plan requiring more than 30 CPU sec-\nonds. The improvement in the tail of regret is similar for\nboth metrics and datasets.\nFigure 15 and 16 also show that Bao quickly matches or\nbeats the median regret of the PostgreSQL optimizer (in the\ncase of physical I/Os for Stack, both Bao and PostgreSQL\nachieve median regrets near zero). Median regret may be\nmore important than tail regret in single-tenant settings.\nThis demonstrates that Bao, in terms of both the median\nand the tail regret, is capable of achieving lower regret than\nthe PostgreSQL optimizer.\nQuery regression analysis Finally, we analyze the per-\nquery performance of Bao. Figure 14 shows, for both Bao\nand the optimal hint set, the absolute performance improve-\nment (negative) or regression (positive) for each of the Join\nOrder Benchmark (JOB) [30] queries (a subset of our IMDb\nworkload). For this experiment, we train Bao by executing\nthe entire IMDb workload with the JOB queries removed,\nand then executed each JOB query without updating Bao's\npredictive model (in other words, our IMDb workload with-\nout the JOB query was the training set, and the JOB queries\nwere the test set). There was no overlap in terms of pred-\nicates or join graphs. Of the 113 JOB queries, Bao only\nincurs regressions on three, and these regressions are all un-\nder 3 seconds. Ten queries see performance improvements of\nover 20 seconds. While Bao (blue) does not always choose\nthe optimal hint set (green), Bao does come close on almost\nevery query. Interestingly, for every query, one hint set was\nalways better than the plan produced by PostgreSQL, sug-\ngesting that a perfect Bao model could achieve zero regres-\nsions.\n7Since di\u000berent query plans may behave di\u000berently with dif-\nferent cache states, a cold cache is required to keep the com-\nputation feasible.\n12\n\n16b\n6d\n17f\n26c\n17a\n17e\n6f\n17b\n20c\n17d\n20a\n17c\n25a\n18a\n22d\n16c\n16d\n30c\n20b\n18c\n28a\n30a\n25c\n19d\n9b\n14c\n19a\n14a\n7c\n7a\n8c\n28b\n22c\n24a\n2d\n10c\n12c\n23c\n22a\n13d\n15d\n13c\n13a\n22b\n13b\n16a\n8a\n6b\n18b\n19c\n31a\n10a\n7b\n30b\n3a\n26a\n23a\n31c\n3b\n28c\n31b\n15a\n3c\n29c\n10b\n2a\n2b\n29a\n9c\n21c\n4c\n12a\n25b\n2c\n4a\n23b\n21a\n32b\n11c\n1a\n21b\n1c\n11d\n5a\n12b\n15c\n1d\n1b\n5c\n29b\n9d\n4b\n6a\n6e\n9a\n27a\n5b\n24b\n33b\n33a\n11b\n19b\n11a\n15b\n27c\n33c\n6c\n27b\n32a\n8b\n26b\n14b\n8d\nQuery ID40\n30\n20\n10\n0Difference from PostgreSQL (s)Optimal\nBaoFigure 14: Absolute di\u000berence in query latency between Bao's selected plan and PostgreSQL's selected plan for the subset of\nthe IMDb queries from the Join Order Benchmark [30] (lower is better).\n5055\nPostgreSQL0102030Regret (1e8 IOs)\n12345678910111213141516171819202122232425\nBao iteration (200 queries each)\n(a) Physical I/O regret, IMDb\n13151320\nPostgreSQL012Regret (billion IOs)12345678910111213141516171819202122232425\nBao iteration (200 queries each)\n(b) Physical I/O regret, StackOver\row\nFigure 16: Physical I/O request regret (di\u000berence between\nthe number of physical I/O requests made by the optimal\nhint set and the selected hint set), when Bao is optimiz-\ning for physical I/Os. Bao (right) is compared against the\nPostgreSQL optimizer (left) on the PostgreSQL engine over\nmultiple training iterations of 50 queries each. The blue line\nmarks the median regret of the PostgreSQL optimizer. Note\nthe cut axes. Whiskers show the 98% percentile.\n720725\nPostgreSQL0102030Regret (cpu s)\n12345678910111213141516171819202122232425\nBao iteration (200 queries each)\n(a) CPU time regret, IMDb\n62706275\nPostgreSQL024Regret (cpu s)\n12345678910111213141516171819202122232425\nBao iteration (200 queries each)\n(b) CPU time regret, StackOver\row\nFigure 15: CPU time regret (di\u000berence between the outcome\nfrom the optimal hint set and the selected hint set), when\nBao is optimizing for CPU time. Bao (right) is compared\nagainst the PostgreSQL optimizer (left) on the PostgreSQL\nengine over multiple training iterations of 50 queries each.\nThe blue line marks the median regret of the PostgreSQL\noptimizer. Note the cut axes. Whiskers show the 98% per-\ncentile.6. CONCLUSION AND FUTURE WORK\nThis work introduced Bao, a bandit optimizer which steers\na query optimizer using reinforcement learning. Bao is ca-\npable of matching the performance of open source and com-\nmercial optimizers with as little as one hour of training time.\nBao uses a combination of Thompson sampling and tree con-\nvolutional neural networks to select query-speci\fc optimizer\nhints. We have demonstrated that Bao can reduce median\nand tail latencies, even in the presence of dynamic work-\nloads, data, and schema.\nIn the future, we plan to more fully investigate integrat-\ning Bao into cloud systems. Speci\fcally, we plan to test if\nBao can improve resource utilization in multi-tenant envi-\nronments where disk, RAM, and CPU time are scarce re-\nsources. We additionally plan to investigate if Bao's pre-\ndictive model can be used as a cost model in a traditional\ndatabase optimizer, enabling more traditional optimization\ntechniques to take advantage of machine learning.\n7. REFERENCES\n[1] Bao online appendix, https://rm.cab/bao appendix.\n[2] Google Cloud Platform, https://cloud.google.com/.\n[3] MySQL hints,\nhttps://dev.mysql.com/doc/refman/8.0/en/server-\nsystem-variables.html#sysvar optimizer switch.\n[4] PostgreSQL hints,\nhttps://www.postgresql.org/docs/current/runtime-\ncon\fg-query.html.\n[5] SQL Server hints, https://docs.microsoft.com/en-\nus/sql/t-sql/queries/hints-transact-sql-query.\n[6] D. J. Abadi and M. Cherniack. Visual COKO: A\ndebugger for query optimizer development. In\nProceedings of the 2002 ACM SIGMOD International\nConference on Management of Data , SIGMOD '02,\npage 617, Madison, Wisconsin, June 2002. Association\nfor Computing Machinery.\n[7] A. Adadi and M. Berrada. Peeking Inside the\nBlack-Box: A Survey on Explainable Arti\fcial\nIntelligence (XAI). IEEE Access , 6:52138{52160, 2018.\n[8] S. Agrawal and N. Goyal. Further Optimal Regret\nBounds for Thompson Sampling. In The International\nConference on Arti\fcial Intelligence and Statistics ,\nAISTATS '13, 2013.\n[9] M. Alam, J. Gottschlich, N. Tatbul, J. S. Turek,\nT. Mattson, and A. Muzahid. A Zero-Positive\n13\n\nLearning Approach for Diagnosing Software\nPerformance Regressions. In H. Wallach,\nH. Larochelle, A. Beygelzimer, F. d ntextquotesingle\nAlch\u0013 e-Buc, E. Fox, and R. Garnett, editors, Advances\nin Neural Information Processing Systems 32 , pages\n11627{11639. Curran Associates, Inc., 2019.\n[10] J. L. Ba, J. R. Kiros, and G. E. Hinton. Layer\nNormalization. arXiv:1607.06450 [cs, stat] , July 2016.\n[11] L. Breiman. Bagging Predictors. In Machine Learning ,\nMaching Learning '96, 1996.\n[12] O. Chapelle and L. Li. An empirical evaluation of\nThompson sampling. In Advances in Neural\nInformation Processing Systems , NIPS'11, 2011.\n[13] M. Collier and H. U. Llorens. Deep Contextual\nMulti-armed Bandits. arXiv:1807.09809 [cs, stat] ,\nJuly 2018.\n[14] B. Ding, S. Das, R. Marcus, W. Wu, S. Chaudhuri,\nand V. R. Narasayya. AI Meets AI: Leveraging Query\nExecutions to Improve Index Recommendations. In\n38th ACM Special Interest Group in Data\nManagement , SIGMOD '19, 2019.\n[15] B. Ding, S. Das, W. Wu, S. Chaudhuri, and\nV. Narasayya. Plan stitch: Harnessing the best of\nmany plans. Proceedings of the VLDB Endowment ,\n11(10):1123{1136, June 2018.\n[16] G. Dulac-Arnold, R. Evans, H. van Hasselt,\nP. Sunehag, T. Lillicrap, J. Hunt, T. Mann, T. Weber,\nT. Degris, and B. Coppin. Deep Reinforcement\nLearning in Large Discrete Action Spaces.\narXiv:1512.07679 [cs, stat] , Apr. 2016.\n[17] E. Even-Dar, S. Mannor, and Y. Mansour. Action\nElimination and Stopping Conditions for the\nMulti-Armed Bandit and Reinforcement Learning\nProblems. Journal of Machine Learning Research ,\n7(Jun):1079{1105, 2006.\n[18] X. Glorot, A. Bordes, and Y. Bengio. Deep Sparse\nRecti\fer Neural Networks. In G. Gordon, D. Dunson,\nand M. Dud\u0013 \u0010k, editors, Proceedings of the Fourteenth\nInternational Conference on Arti\fcial Intelligence and\nStatistics , volume 15 of PMLR '11 , pages 315{323,\nFort Lauderdale, FL, USA, Apr. 2011. PMLR.\n[19] J. Gottschlich, A. Solar-Lezama, N. Tatbul,\nM. Carbin, M. Rinard, R. Barzilay, S. Amarasinghe,\nJ. B. Tenenbaum, and T. Mattson. The three pillars\nof machine programming. In Proceedings of the 2nd\nACM SIGPLAN International Workshop on Machine\nLearning and Programming Languages , MAPL 2018,\npages 69{80, Philadelphia, PA, USA, June 2018.\nAssociation for Computing Machinery.\n[20] A. Haj-Ali, N. K. Ahmed, T. Willke, S. Shao,\nK. Asanovic, and I. Stoica. NeuroVectorizer:\nEnd-to-End Vectorization with Deep Reinforcement\nLearning. arXiv:1909.13639 [cs] , Jan. 2020.\n[21] J. R. Haritsa. The Picasso database query optimizer\nvisualizer. Proceedings of the VLDB Endowment ,\n3(1-2):1517{1520, Sept. 2010.\n[22] R. Hayek and O. Shmueli. Improved Cardinality\nEstimation by Learning Queries Containment Rates.\narXiv:1908.07723 [cs] , Aug. 2019.\n[23] N. Jacek and J. E. B. Moss. Learning when to garbage\ncollect with random forests. In Proceedings of the 2019\nACM SIGPLAN International Symposium on MemoryManagement , ISMM 2019, pages 53{63, Phoenix, AZ,\nUSA, June 2019. Association for Computing\nMachinery.\n[24] T. Kaftan, M. Balazinska, A. Cheung, and J. Gehrke.\nCuttle\fsh: A Lightweight Primitive for Adaptive\nQuery Processing. arXiv preprint , Feb. 2018.\n[25] E. Kaufmann, N. Korda, and R. Munos. Thompson\nsampling: An asymptotically optimal \fnite-time\nanalysis. In International Conference on Algorithmic\nLearning Theory , ALT '12, 2012.\n[26] D. P. Kingma and J. Ba. Adam: A Method for\nStochastic Optimization. In 3rd International\nConference for Learning Representations , ICLR '15,\nSan Diego, CA, 2015.\n[27] A. Kipf, T. Kipf, B. Radke, V. Leis, P. Boncz, and\nA. Kemper. Learned Cardinalities: Estimating\nCorrelated Joins with Deep Learning. In 9th Biennial\nConference on Innovative Data Systems Research ,\nCIDR '19, 2019.\n[28] T. Kraska, M. Alizadeh, A. Beutel, Ed Chi, Ani\nKristo, Guillaume Leclerc, Samuel Madden, Hongzi\nMao, and Vikram Nathan. SageDB: A Learned\nDatabase System. In 9th Biennial Conference on\nInnovative Data Systems Research , CIDR '19, 2019.\n[29] S. Krishnan, Z. Yang, K. Goldberg, J. Hellerstein, and\nI. Stoica. Learning to Optimize Join Queries With\nDeep Reinforcement Learning. arXiv:1808.03196 [cs] ,\nAug. 2018.\n[30] V. Leis, A. Gubichev, A. Mirchev, P. Boncz,\nA. Kemper, and T. Neumann. How Good Are Query\nOptimizers, Really? PVLDB , 9(3):204{215, 2015.\n[31] V. Leis, B. Radke, A. Gubichev, A. Mirchev,\nP. Boncz, A. Kemper, and T. Neumann. Query\noptimization through the looking glass, and what we\nfound running the Join Order Benchmark. The VLDB\nJournal , pages 1{26, Sept. 2017.\n[32] J. Li, A. C. K onig, V. Narasayya, and S. Chaudhuri.\nRobust estimation of resource consumption for SQL\nqueries using statistical techniques. PVLDB ,\n5(11):1555{1566, 2012.\n[33] H. Liu, M. Xu, Z. Yu, V. Corvinelli, and C. Zuzarte.\nCardinality Estimation Using Neural Networks. In\nProceedings of the 25th Annual International\nConference on Computer Science and Software\nEngineering , CASCON '15, pages 53{59, Riverton,\nNJ, USA, 2015. IBM Corp.\n[34] G. Lohman. Is Query Optimization a `\"Solved\"\nProblem? In ACM SIGMOD Blog , ACM Blog '14,\n2014.\n[35] K. Lolos, I. Konstantinou, V. Kantere, and N. Koziris.\nElastic management of cloud applications using\nadaptive reinforcement learning. In IEEE\nInternational Conference on Big Data , Big Data '17,\npages 203{212. IEEE, Dec. 2017.\n[36] H. Mao, M. Schwarzkopf, S. B. Venkatakrishnan,\nZ. Meng, and M. Alizadeh. Learning Scheduling\nAlgorithms for Data Processing Clusters.\narXiv:1810.01963 [cs, stat] , Oct. 2018.\n[37] H. Mao, M. Schwarzkopf, S. B. Venkatakrishnan,\nZ. Meng, and M. Alizadeh. Learning Scheduling\nAlgorithms for Data Processing Clusters.\narXiv:1810.01963 [cs, stat] , 2018.\n14\n\n[38] G. Marcus. Innateness, AlphaZero, and Arti\fcial\nIntelligence. arXiv:1801.05667 [cs] , Jan. 2018.\n[39] R. Marcus, P. Negi, H. Mao, C. Zhang, M. Alizadeh,\nT. Kraska, O. Papaemmanouil, and N. Tatbul. Neo: A\nLearned Query Optimizer. PVLDB , 12(11):1705{1718,\n2019.\n[40] R. Marcus and O. Papaemmanouil. Releasing Cloud\nDatabases from the Chains of Performance Prediction\nModels. In 8th Biennial Conference on Innovative\nData Systems Research , CIDR '17, San Jose, CA,\n2017.\n[41] R. Marcus and O. Papaemmanouil. Deep\nReinforcement Learning for Join Order Enumeration.\nInFirst International Workshop on Exploiting\nArti\fcial Intelligence Techniques for Data\nManagement , aiDM@SIGMOD '18, Houston, TX,\n2018.\n[42] R. Marcus and O. Papaemmanouil. Plan-Structured\nDeep Neural Network Models for Query Performance\nPrediction. PVLDB , 12(11):1733{1746, 2019.\n[43] T. M. Mitchell. The Need for Biases in Learning\nGeneralizations. Technical report, 1980.\n[44] L. Mou, G. Li, L. Zhang, T. Wang, and Z. Jin.\nConvolutional Neural Networks over Tree Structures\nfor Programming Language Processing. In Proceedings\nof the Thirtieth AAAI Conference on Arti\fcial\nIntelligence , AAAI '16, pages 1287{1293, Phoenix,\nArizona, 2016. AAAI Press.\n[45] P. Negi, R. Marcus, H. Mao, N. Tatbul, T. Kraska,\nand M. Alizadeh. Cost-Guided Cardinality\nEstimation: Focus Where it Matters. In Workshop on\nSelf-Managing Databases , SMDB '20, 2020.\n[46] X. Niu, R. Kapoor, B. Glavic, D. Gawlick, Z. H. Liu,\nV. Krishnaswamy, and V. Radhakrishnan.\nProvenance-Aware Query Optimization. In 2017 IEEE\n33rd International Conference on Data Engineering ,\nICDE '17, pages 473{484, Apr. 2017.\n[47] J. Ortiz, M. Balazinska, J. Gehrke, and S. S. Keerthi.\nLearning State Representations for Query\nOptimization with Deep Reinforcement Learning. In\n2nd Workshop on Data Managmeent for End-to-End\nMachine Learning , DEEM '18, 2018.\n[48] J. Ortiz, M. Balazinska, J. Gehrke, and S. S. Keerthi.\nAn Empirical Analysis of Deep Learning for\nCardinality Estimation. arXiv:1905.06425 [cs] , Sept.\n2019.\n[49] J. Ortiz, B. Lee, M. Balazinska, J. Gehrke, and J. L.\nHellerstein. SLAOrchestrator: Reducing the Cost of\nPerformance SLAs for Cloud Data Analytics. In 2018\nUSENIX Annual Technical Conference (USENIX\nATC 18) , USENIX ATX'18, pages 547{560, Boston,\nMA, 2018. USENIX Association.\n[50] J. Ortiz, B. Lee, M. Balazinska, and J. L. Hellerstein.\nPerfEnforce: A Dynamic Scaling Engine for Analytics\nwith Performance Guarantees. arXiv:1605.09753 [cs] ,\nMay 2016.\n[51] I. Osband and B. Van Roy. Bootstrapped Thompson\nSampling and Deep Exploration. arXiv:1507.00300\n[cs, stat] , July 2015.\n[52] Y. Park, S. Zhong, and B. Mozafari. QuickSel: Quick\nSelectivity Learning with Mixture Models.\narXiv:1812.10568 [cs] , Dec. 2018.[53] A. Pavlo, G. Angulo, J. Arulraj, H. Lin, J. Lin, L. Ma,\nP. Menon, T. C. Mowry, M. Perron, I. Quah,\nS. Santurkar, A. Tomasic, S. Toor, D. V. Aken,\nZ. Wang, Y. Wu, R. Xian, and T. Zhang. Self-Driving\nDatabase Management Systems. In 8th Biennial\nConference on Innovative Data Systems Research ,\nCIDR '17, 2017.\n[54] Z. Peng, M. Cherniack, and O. Papaemmanouil.\nDevel-op: An optimizer development environment.\npages 1278{1281. IEEE, Mar. 2014.\n[55] A. G. Read. DeWitt clauses: Can we protect\npurchasers without hurting Microsoft. Rev. Litig. ,\n25:387, 2006.\n[56] C. Riquelme, G. Tucker, and J. Snoek. Deep Bayesian\nBandits Showdown: An empirical comparison of\nbayesian deep networks for thompson sampling. In\nInternational Conference on Learning Representations ,\nICLR '18, 2018.\n[57] D. Russo and B. V. Roy. An information-theoretic\nanalysis of Thompson sampling. Journal of Machine\nLearning Research , 2014.\n[58] M. Schaarschmidt, A. Kuhnle, B. Ellis, K. Fricke,\nF. Gessert, and E. Yoneki. LIFT: Reinforcement\nLearning in Computer Systems by Learning From\nDemonstrations. arXiv:1808.07903 [cs, stat] , Aug.\n2018.\n[59] P. G. Selinger, M. M. Astrahan, D. D. Chamberlin,\nR. A. Lorie, and T. G. Price. Access Path Selection in\na Relational Database Management System. In\nJ. Mylopolous and M. Brodie, editors, SIGMOD '79 ,\nSIGMOD '79, pages 511{522, San Francisco (CA),\n1979. Morgan Kaufmann.\n[60] M. Stillger, G. M. Lohman, V. Markl, and M. Kandil.\nLEO - DB2's LEarning Optimizer. In VLDB , VLDB\n'01, pages 19{28, 2001.\n[61] J. Sun and G. Li. An end-to-end learning-based cost\nestimator. Proceedings of the VLDB Endowment ,\n13(3):307{319, Nov. 2019.\n[62] W. R. Thompson. On the Likelihood that One\nUnknown Probability Exceeds Another in View of the\nEvidence of Two Samples. Biometrika , 1933.\n[63] C. Tofallis. A Better Measure of Relative Prediction\nAccuracy for Model Selection and Model Estimation.\nJournal of the Operational Research Society ,\n2015(66):1352{1362, July 2014.\n[64] I. Trummer, S. Moseley, D. Maram, S. Jo, and\nJ. Antonakakis. SkinnerDB: Regret-bounded Query\nEvaluation via Reinforcement Learning. PVLDB ,\n11(12):2074{2077, 2018.\n[65] K. Tzoumas, T. Sellis, and C. Jensen. A\nReinforcement Learning Approach for Adaptive Query\nProcessing. Technical Reports , June 2008.\n[66] F. Waas and A. Pellenkoft. Join Order Selection\n(Good Enough Is Easy). In Advances in Databases ,\nBNCD '00, pages 51{67. Springer, Berlin, Heidelberg,\nJuly 2000.\n[67] L. Woltmann, C. Hartmann, M. Thiele, D. Habich,\nand W. Lehner. Cardinality estimation with local deep\nlearning models. In Proceedings of the Second\nInternational Workshop on Exploiting Arti\fcial\nIntelligence Techniques for Data Management , aiDM\n'19, pages 1{8, Amsterdam, Netherlands, July 2019.\n15\n\nAssociation for Computing Machinery.\n[68] Z. Yang, E. Liang, A. Kamsetty, C. Wu, Y. Duan,\nX. Chen, P. Abbeel, J. M. Hellerstein, S. Krishnan,\nand I. Stoica. Deep unsupervised cardinalityestimation. Proceedings of the VLDB Endowment ,\n13(3):279{292, Nov. 2019.\n[69] L. Zhou. A Survey on Contextual Multi-armed\nBandits. arXiv:1508.03326 [cs] , Feb. 2016.\n16",
  "textLength": 85186
}