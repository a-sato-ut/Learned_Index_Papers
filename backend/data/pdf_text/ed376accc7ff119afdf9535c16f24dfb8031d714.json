{
  "paperId": "ed376accc7ff119afdf9535c16f24dfb8031d714",
  "title": "A Model for Learned Bloom Filters and Optimizing by Sandwiching",
  "pdfPath": "ed376accc7ff119afdf9535c16f24dfb8031d714.pdf",
  "text": "A Model for Learned Bloom Filters,\nand Optimizing by Sandwiching\nMichael Mitzenmacher\nSchool of Engineering and Applied Sciences\nHarvard University\nmichaelm@eecs.harvard.edu\nAbstract\nRecent work has suggested enhancing Bloom ﬁlters by using a pre-ﬁlter, based\non applying machine learning to determine a function that models the data set the\nBloom ﬁlter is meant to represent. Here we model such learned Bloom ﬁlters ,\nwith the following outcomes: (1) we clarify what guarantees can and cannot be\nassociated with such a structure; (2) we show how to estimate what size the learning\nfunction must obtain in order to obtain improved performance; (3) we provide a\nsimple method, sandwiching, for optimizing learned Bloom ﬁlters; and (4) we\npropose a design and analysis approach for a learned Bloomier ﬁlter, based on our\nmodeling approach.\n1 Introduction\nAn interesting recent paper, “The Case for Learned Index Structures” [ 7], argues that standard index\nstructures and related structures, such as Bloom ﬁlters, could be improved by using machine learning\nto develop what the authors dub learned index structures. However, this paper did not provide a\nsuitable mathematical model for judging the performance of such structures. Here we aim to provide\na more formal model for their variation of a Bloom ﬁlter, which they call a learned Bloom ﬁlter .\nTo describe our results, we ﬁrst somewhat informally describe the learned Bloom ﬁlter. Like a standard\nBloom ﬁlter, it provides a compressed representation of a set of keys Kthat allows membership\nqueries. (We may sometimes also refer to the keys as elements.) Given a key y, a learned Bloom\nﬁlter always returns yes if yis inK, so there will be no false negatives, and generally returns no if y\nis not inK, but may provide false positives. What makes a learned Bloom ﬁlter interesting is that it\nuses a function that can be obtained by “learning” the set Kto help determine the appropriate answer;\nthe function acts as a pre-ﬁlter that provides a probabilistic estimate that a query key yis inK. This\nlearned function can be used to make an initial decision as to whether the key is in K, and a smaller\nbackup Bloom ﬁlter is used to prevent any false negatives.\nOur more formal model provides interesting insights into learned Bloom ﬁlters, and how they might\nbe effective. In particular, here we: (1) clarify what guarantees can and cannot be associated with\nsuch a structure; (2) show how to estimate what size the learning function must obtain in order to\nobtain improved performance; (3) provide a simple method for optimizing learned Bloom ﬁlters; and\n(4) demonstrate our approach may be useful for other similar structures.\nWe brieﬂy summarize the outcomes above. First, we explain how the types of guarantees offered by\nlearned Bloom ﬁlters differ signiﬁcantly from those of standard Bloom ﬁlters. We thereby clarify\nwhat application-level assumptions are required for a learned Bloom ﬁlter to be effective. Second,\nwe provide formulae for modeling the false positive rate for a learned Bloom ﬁlter, allowing for an\nestimate of how small the learned function needs to be in order to be effective. We then ﬁnd, perhaps\nsurprisingly, that a better structure uses a Bloom ﬁlter before as well as after the learned function.\nPreprint. Work in progress.arXiv:1901.00902v1  [cs.LG]  3 Jan 2019\n\nBecause we optimize for two layers of Bloom ﬁlters surrounding the learned function, we refer to\nthis as a sandwiched learned Bloom ﬁlter . We show mathematically and intuitively why sandwiching\nimproves performance. We also discuss an approach to designing learned Bloomier ﬁlters, where a\nBloomier ﬁlter returns a value associated with a set element (instead of just returning whether the\nelement is in the set), and show it can be modeled similarly.\nWhile the contents of this paper may be seen as relatively simple, we feel it is important to provide\nsolid foundations in order for a wide community to understand the potential and pitfalls of data\nstructures using machine learning components. We therefore remark that the simplicity is purposeful,\nand suggest it is desirable in this context. Finally, we note that this work incorporates and extends\nanalysis that appeared in two prior working notes [8, 9].\n2 Review: Bloom Filters\nWe start by reviewing standard Bloom ﬁlters and variants, following the framework provided by the\nreference [2].\n2.1 Deﬁnition of the Data Structure\nA Bloom ﬁlter for representing a set S=fx1;x2;:::;xngofnelements corresponds to an array\nofmbits, and uses kindependent hash functions h1;:::;hkwith rangef0;:::;m\u00001g. Here we\nfollow the typical assumption that these hash functions are perfect; that is, each hash function maps\neach item in the universe independently and uniformly to a number in f0;:::;m\u00001g. Initially all\narray bits are 0. For each element x2S, the array bits hi(x)are set to 1 for 1\u0014i\u0014k; it does not\nmatter if some bit is set to 1 multiple times. To check if an item yis inS, we check whether all hi(y)\nare set to 1. If not, then clearly yis not a member of S. If allhi(y)are set to 1, we conclude that yis\ninS, although this may be a false positive . A Bloom ﬁlter does not produce false negatives.\nThe primary standard theoretical guarantee associated with a Bloom ﬁlter is the following. Let ybe\nan element of the universe such that y =2S, whereyis chosen independently of the hash functions\nused to create the ﬁlter. Let \u001abe the fraction of bits set to 1 after the elements are hashed. Then\nPr(yyields a false positive ) =\u001ak:\nFor a bit in the Bloom ﬁlter to be 0, it has to not be the outcome of the knhash values for the nitems.\nIt follows that\nE[\u001a] = 1\u0000\u0012\n1\u00001\nm\u0013kn\n\u00191\u0000e\u0000kn=m;\nand that via standard techniques using concentration bounds (see, e.g., [11])\nPr(j\u001a\u0000E[\u001a]j\u0015\r)\u0014e\u0000\u0002(\r2m)\nin the typical regime where m=n andkare constant. That is, \u001ais, with high probability, very close to\nits easily calculable expectation, and thus we know (up to very small random deviations) what the\nprobability is that an element ywill be a false positive. Because of this tight concentration around the\nexpectation, it is usual to talk about the false positive probability of a Bloom ﬁlter; in particular, it is\ngenerally referred to as though it is a constant depending on the ﬁlter parameters, even though it is a\nrandom variable, because it is tightly concentrated around its expectation.\nMoreover, given a set of distinct query elements Q=fy1;y2;:::;yqgwithQ\\S=;chosen a\npriori before the Bloom ﬁlter is instantiated, the fraction of false positives over these queries will\nsimilarly be concentrated near \u001ak. Hence we may talk about the false positive rate of a Bloom ﬁlter\nover queries, which (when the query elements are distinct) is essentially the same as the false positive\nprobability. (When the query elements are not distinct, the false positive rate may vary signiﬁcantly,\ndepending on on the distribution of the number of appearances of elements and which ones yield\nfalse positives; we focus on the distinct item setting here.) In particular, the false positive rate is a\npriori the same for anypossible query set Q. Hence one approach to ﬁnding the false positive rate of\na Bloom ﬁlter empirically is simply to test a random set of query elements (that does not intersect S)\nand ﬁnd the fraction of false positives. Indeed, it does not matter what set Qis chosen, as long as it is\nchosen independently of the hash functions.\n2\n\nWe emphasize that, as we discuss further below, the term false positive rate often has a different\nmeaning in the context of learning theory applications. Care must therefore be taken in understanding\nhow the term is being used.\n2.2 Additional Bloom Filter Beneﬁts and Limitations\nFor completeness, we relate some of the other beneﬁts and limitations of Bloom ﬁlters. More details\ncan be found in [2].\nWe have assumed in the above analysis that the hash functions are fully random. As fully random\nhash functions are not practically implementable, there are often questions relating to how well the\nidealization above matches the real world for speciﬁc hash functions. In practice, however, the model\nof fully random hash functions appears reasonable in many cases; see [ 5] for further discussion on\nthis point.\nIf an adversary has access to the hash functions used, or to the ﬁnal Bloom ﬁlter, it can ﬁnd elements\nthat lead to false positives. One must therefore ﬁnd other structures for adversarial situations. A\ntheoretical framework for such settings is developed in [ 12]. Variations of Bloom ﬁlters, which\nadapt to false positives and prevent them in the future, are described in [ 1,10]; while not meant for\nadversarial situations, they prevent repeated false positives with the same element.\nOne of the key advantages of a standard Bloom ﬁlter is that it is easy to insert an element (possibly\nslightly changing the false positive probability), although one cannot delete an element without\nusing a more complex structure, such as a counting Bloom ﬁlter. However, there are more recent\nalternatives to the standard Bloom ﬁlter, such as the cuckoo ﬁlter [ 6], which can achieve the same\nor better space performance as a standard Bloom ﬁlter while allowing insertions and deletions. If\nthe Bloom ﬁlter does not need to insert or delete elements, a well-known alternative is to develop a\nperfect hash function for the data set, and store a ﬁngerprint of each element in each corresponding\nhash location (see, e.g., [ 2] for further explanation); this approach reduces the space required by\napproximately 30%.\n3 Learned Bloom Filters\n3.1 Deﬁnition of the Data Structure\nWe now consider the learned Bloom ﬁlter construction as described in [ 7]. We are given a set of\npositive keysKthat correspond to set to be held in the Bloom ﬁlter – that is, Kcorresponds to the set\nSin the previous section. We are also given a set of negative keys Ufor training. We then train a\nneural network with D=f(xi;yi= 1)jxi2Kg[f (xi;yi= 0)jxi2Ug ; that is, they suggest\nusing a neural network on this binary classiﬁcation task to produce a probability, based on minimizing\nthe log loss function\nL=X\n(x;y)2Dylogf(x) + (1\u0000y) log(1\u0000f(x));\nwherefis the learned model from the neural network. Then f(x)can be interpreted as a “probability”\nestimate that xis a key from the set. Their suggested approach is to choose a threshold \u001cso that\niff(x)\u0015\u001cthen the algorithm returns that xis in the set, and no otherwise. Since such a process\nmay provide false negatives for some keys in Kthat havef(x)<\u001c, a secondary structure – such\nas a smaller standard Bloom ﬁlter holding the keys from Kthat havef(x)< \u001c – can be used to\ncheck keys with f(x)<\u001cto ensure there are no false negatives, matching this feature of the standard\nBloom ﬁlter.\nIn essence, [ 7] suggests using a pre-ﬁlter ahead of the Bloom ﬁlter, where the pre-ﬁlter comes from a\nneural network and estimates the probability a key is in the set, allowing the use of a smaller Bloom\nﬁlter than if one just used a Bloom ﬁlter alone. Performance improves if the size to represent the\nlearned function fand the size of the smaller backup ﬁlter for false negatives is smaller than the size\nof a corresponding Bloom ﬁlter with the same false positive rate. Of course the pre-ﬁlter here need\nnot come from a neural network; any approach that would estimate the probability an input key is in\nthe set could be used.\nThis motivates the following formal deﬁnition:\n3\n\nDeﬁnition 1 Alearned Bloom ﬁlter on a set of positive keys Kand negative keys Uis a function\nf:U![0;1]and threshold \u001c, whereUis the universe of possible query keys, and an associated\nstandard Bloom ﬁlter B, referred to as a backup ﬁlter. The backup ﬁlter holds the set of keys\nfz:z2K;f(z)<\u001cg. For a query y, the learned Bloom ﬁlter returns that y2K iff(y)\u0015\u001c, or if\nf(y)<\u001cand the backup ﬁlter returns that y2K. The learned Bloom ﬁlter returns y =2K otherwise.\n3.2 Deﬁning the False Positive Probability\nThe question remains how to determine or derive the false positive probability for a learned Bloom\nﬁlter, and how to choose an appropriate threshold \u001c. The approach in [ 7] is to ﬁnd the false positive\nrate over a test set. This approach is, as we have discussed, suitable for a standard Bloom ﬁlter,\nwhere the false positive rate is guaranteed to be close to its expected value for any test set, with high\nprobability. However, this methodology requires additional assumptions in the learned Bloom ﬁlter\nsetting.\nAs an example, suppose the universe of elements is the range [0;1000000) , and the setKof keys to\nstore in our Bloom ﬁlter consists of a random subset of 500 elements from the range [1000;2000] , and\nof 500 other random elements from outside this range. Our learning algorithm might determine that a\nsuitable function fyields thatf(y)is large (say f(y)\u00191=2) for elements in the range [1000;2000]\nand close to zero elsewhere, and then a suitable threshold might be \u001c= 0:4. The resulting false\npositive rate depends substantially on what elements are queried. If Qconsists of elements primarily\nin the range [1000;2000] , the false positive rate will be quite high, while if Qis chosen uniformly at\nrandom over the whole range, the false positive rate will be quite low. Unlike a standard Bloom ﬁlter,\nthe false positive rate is highly dependent on the query set, and is not well-deﬁned independently of\nthe queries.\nIndeed, it seems plausible that in many situations, the query set Qmight indeed be similar to the set\nof keysK, so thatf(y)fory2Q might often be above naturally chosen thresholds. For example, in\nsecurity settings, one might expect that queries for objects under consideration (URLs, network ﬂow\nfeatures) would be similar to the set of keys stored in the ﬁlter. Unlike in the setting of a standard\nBloom ﬁlter, the false positive probability for a query ycan depend on y, even before the function f\nis instantiated.\nIt is worth noting, however, that the problem we point out here can possibly be a positive feature in\nother settings; it might be that the false positive rate is remarkably low if the query set is suitable.\nAgain, one can consider the range example above where queries are uniform over the entire space;\nthe query set is very unlikely to hit the range where the learned function fyields an above threshold\nvalue in that setting for a key outside of K. The data-dependent nature of the learned Bloom ﬁlter\nmay allow it to circumvent lower bounds for standard Bloom ﬁlter structures.\nWhile the false positive probability for learned Bloom ﬁlters does not have the same properties as for\na standard Bloom ﬁlter, we can deﬁne the false positive rate of a learned Bloom ﬁlter with respect to\na given query distribution.\nDeﬁnition 2 Afalse positive rate on a query distribution DoverU\u0000K for a learned Bloom ﬁlter\n(f;\u001c;B )is given by\nPr\ny\u0018D(f(y)\u0015\u001c) + (1\u0000Pr\ny\u0018D(f(y)\u0015\u001c))F(B);\nwhereF(B)is the false positive rate of the backup ﬁlter B.\nWhile technically F(B)is itself a random variable, the false positive rate is well concentrated around\nits expectations, which depends only on the size of the ﬁlter jBjand the number of false negatives\nfromKthat must be stored in the ﬁlter, which depends on f. Hence where the meaning is clear we\nmay consider the false positive rate for a learned Bloom ﬁlter with function fand threshold \u001cto be\nPr\ny\u0018D(f(y)\u0015\u001c) + (1\u0000Pr\ny\u0018D(f(y)\u0015\u001c))E[F(B)];\nwhere the expectation E[F(B)]is meant to over instantiations of the Bloom ﬁlter with given size jBj.\nGiven sufﬁcient data, we can determine an empirical false positive rate on a test set, and use that\nto predict future behavior. Under the assumption that the test set has the same distribution as future\n4\n\nqueries, standard Chernoff bounds provide that the empirical false positive rate will be close to the\nfalse positive rate on future queries, as both will be concentrated around the expectation. In many\nlearning theory settings, this empirical false positive rate appears to be referred to as simply the false\npositive rate; we emphasize that false positive rate, as we have explained above, typically means\nsomething different in the Bloom ﬁlter literature.\nDeﬁnition 3 Theempirical false positive rate on a set T, whereT\\K =;, for a learned Bloom\nﬁlter (f;\u001c;B )is the number of false positives from Tdivided byjTj.\nTheorem 4 Consider a learned Bloom ﬁlter (f;\u001c;B ), a test setT, and a query setQ, whereTand\nQare both determined from samples according to a distribution D. LetXbe the empirical false\npositive rate onT, andYbe the empirical false positive rate on Q. Then\nPr(jX\u0000Yj\u0015\u000f)\u0014e\u0000\n(\u000f2min(jTj;jQj)):\nProof: Let\u000b= Pry\u0018D(f(y)\u0015\u001c), and\fbe false positive rate for the backup ﬁlter. We ﬁrst show\nthat forTandXthat\nPr(jX\u0000(\u000b+ (1\u0000\u000b)\f)j\u0015\u000f)\u00142e\u00002\u000f2jTj:\nThis follows from a direct Chernoff bound (e.g., [ 11][Exercise 4.13]), since each sample chosen\naccording toDis a false positive with probability \u000b+ (1\u0000\u000b)\f. A similar bound holds for QandY.\nWe can therefore conclude\nPr(jX\u0000Yj\u0015\u000f)\u0014Pr(jX\u0000(\u000b+ (1\u0000\u000b)\f)j\u0015\u000f=2)\n+ Pr(jY\u0000(\u000b+ (1\u0000\u000b)\f)j\u0015\u000f=2)\n\u00142e\u0000\u000f2jTj=2+ 2e\u0000\u000f2jQj=2;\ngiving the desired result.\nTheorem 4 also informs us that it is reasonable to ﬁnd a suitable parameter \u001c, givenf, by trying\na suitable ﬁnite discrete set of values for \u001c, and choosing the best size-accuracy tradeoff for the\napplication. By a union bound, all choices of \u001cwill perform close to their expectation with high\nprobability.\nWhile Theorem 4 requires the test set and query set to come from the same distribution D, the\nnegative examples Udo not have to come from that distribution. Of course, if negative examples U\nare drawn fromD, it may yield a better learning outcome f.\nIf the test set and query set distribution do not match, because for example the types of queries\nchange after the original gathering of test data T, Theorem 4 offers limited guidance. Suppose Tis\nderived from samples from distribution DandQfrom another distribution D0. If the two distributions\nare close (say in L1distance), or, more speciﬁcally, if the changes do not signiﬁcantly change the\nprobability that a query yhasf(y)\u0015\u001c, then the empirical false positive rate on the test set may still\nbe relatively accurate. However, in practice it may be hard to provide such guarantees on the nature\nof future queries. This explains our previous statement that learned Bloom ﬁlters appear most useful\nwhen the query stream can be modeled as coming from a ﬁxed distribution, which can be sampled\nduring the construction.\nWe can return to our previous example to understand these effects. Recall our set consists of\n500 random elements from the range [1000;2000] and 500 other random elements from the range\n[0;1000000) . Our learned Bloom ﬁlter has f(y)\u0015\u001cfor allyin[1000;2000] andf(y)< \u001c\notherwise. Our backup ﬁlter will therefore store 500 elements. If our test set is uniform over\n[0;1000000) (excluding elements stored in the Bloom ﬁlter), our false positive rate from elements\nwith too large an fvalue would be approximately 0:0002 ; one could choose a backup ﬁlter with\nroughly the same false positive probability for a total empirical false positive probability of 0:0004 .\nIf, however, our queries are uniform over a restricted range [0;100000) , then the false positive\nprobability would jump to 0:0022 for the learned Bloom ﬁlter, because the learned function would\nyield more false positives over the smaller query range.\n5\n\n3.3 Additional Learned Bloom Filter Beneﬁts and Limitations\nLearned Bloom ﬁlters can easily handle insertions into Kby adding the key, if is does not already\nyield a (false) positive, to the backup ﬁlter. Such changes have a larger effect on the false positive\nprobability than for a standard Bloom ﬁlter, since the backup ﬁlter is smaller. Keys cannot be deleted\nnaturally from a learned Bloom ﬁlter. A deleted key would simply become a false positive, which (if\nneeded) could possibly be handled by an additional structure.\nAs noted in [ 7], it may be possible to re-learn a new function fif the data set changes substantially via\ninsertions and deletion of keys from K. Of course, besides the time needed to re-learn a new function\nf, this requires storing the original set somewhere, which may not be necessary for alternative\nschemes. Similarly, if the false positive probability proves higher than desired, one can re-learn a\nnew function f; again, doing so will require access to K, and maintaining a (larger) set Uof negative\nexamples.\n4 Size of the Learned Function\nWe now consider how to model the performance of the learned Bloom ﬁlter with the goal of\nunderstanding how small the representation of the function fneeds needs to be in order for the\nlearned Bloom ﬁlter to be more effective than a standard Bloom ﬁlter.1\nOur model is as follows. The function fassociated with Deﬁnition 1 we treat as an oracle for the\nkeysK, wherejKj=m, that works as follows. For keys not in Kthere is an associated false positive\nprobabilityFp, and there are Fnmfalse negatives for keys in K. (The value Fnis like a false negative\nprobability, but given Kthis fraction is determined and known according to the oracle outcomes.) We\nnote the oracle representing the function fis meant to be general, so it could potentially represent\nother sorts of ﬁlter structures as well. As we have described in Section 3.2, in the context of a learned\nBloom ﬁlter the false positive rate is necessarily tied to the query stream, and is therefore generally\nan empirically determined quantity, but we take the value Fphere as a given. Here we show how\nto optimize over a single oracle, although in practice we may possibly choose from oracles with\ndifferent values FpandFn, in which case we can optimize for each pair of values and choose the\nbest suited to the application.\nWe assume a total budget of bmbits for the backup ﬁlter, and jfj=\u0010bits for the learned function. If\njKj=m, the backup Bloom ﬁlter only needs to hold mFnkeys, and hence we take the number of\nbits per stored key to be b=Fn. To model the false positive rate of a Bloom ﬁlter that uses jbits per\nstored key, we assume the false positive rate falls as \u000bj. This is the case for a standard Bloom ﬁlter\n(where\u000b\u00190:6185 when using the optimal number of hash functions, as described in the survey\n[2]), as well as for a static Bloom ﬁlter built using a perfect hash function (where \u000b= 1=2, again\ndescribed in [ 2]). The analysis can be modiﬁed to handle other functions for false positives in terms\nofjin a straightforward manner. (For example, for a cuckoo ﬁlter [ 6], a good approximation for the\nfalse positive rate is c\u000bjfor suitable constants cand\u000b.)\nThe false positive rate of a learned Bloom ﬁlter is Fp+ (1\u0000Fp)\u000bb=Fn:This is because, for y =2K,y\ncauses a false positive from the learned function fwith probability Fp, or with remaining probability\n(1\u0000Fp)it yields a false positive on the backup Bloom ﬁlter with probability \u000bb=Fn.\nA comparable Bloom ﬁlter using the same number of total bits, namely bm+\u0010bits, would have\na false positive probability of \u000bb+\u0010=m. Thus we ﬁnd an improvement using a learned Bloom ﬁlter\nwhenever\nFp+ (1\u0000Fp)\u000bb=Fn\u0014\u000bb+\u0010=m;\nwhich simpliﬁes to\n\u0010=m\u0014log\u000b\u0010\nFp+ (1\u0000Fp)\u000bb=Fn\u0011\n\u0000b;\nwhere we have expressed the requirement in terms of a bound on \u0010=m , the number of bits per key the\nfunctionfis allowed.\n1We thank Alex Beutel for pointing out that our analysis in [9] could be used in this manner.\n6\n\nThis expression is somewhat unwieldy, but it provides some insight into what sort of compression is\nrequired for the learned function f, and how a practitioner can determine what is needed. First, one\ncan determine possible thresholds and the corresponding rate of false positive and false negatives\nfrom the learned function. For example, the paper [ 7] considers situations where Fp\u00190:01, and\nFn\u00190:5; let us consider Fp= 0:01andFn= 0:5for clarity. If we have a target goal of one byte\nper item, a standard Bloom ﬁlter achieves a false positive probability of approximately 0:0214 . If\nour learned function uses 3 bits per item (or less), then the learned Bloom ﬁlter can use 5mbits\nfor the backup Bloom ﬁlter, and achieve a false positive rate of approximately 0:0181 . The learned\nBloom ﬁlter will therefore provide over a 10% reduction in false positives with the same or less space.\nMore generally, in practice one could determine or estimate different FpandFnvalues for different\nthresholds and different learned functions of various sizes, and use these equations to determine if\nbetter performance can be expected without in depth experiments.\nIndeed, an interesting question raised by this analysis is how learned functions scale in terms of\ntypical data sets. In extreme situations, such as when the set Kbeing considered is a range of\nconsecutive integers, it can be represented by just two integers, which does not grow with K. If,\nin practice, as data sets grow larger the amount of information needed for a learned function fto\napproximate key sets Kgrows sublinearly with jKj, learned Bloom ﬁlters may prove very effective.\n5 Sandwiched Learned Bloom Filters\n5.1 The Sandwich Structure\nGiven the formalization of the learned Bloom ﬁlter, it seems natural to ask whether this structure can\nbe improved. Here we show that a better structure is to use a Bloom ﬁlter before using the function f,\nin order to remove most queries for keys not in K. We emphasize that this initial Bloom ﬁlter does\nnot declare that an input yis inK, but passes forward all matching keys to the learned function f,\nand it returns y =2K when the Bloom ﬁlter shows the key is not in K. Then, as before, we use the\nfunctionfto attempt to remove false positives from the initial Bloom ﬁlter, and then use the backup\nﬁlter to allow back in keys from Kthat were false negatives for f. Because we have two layers of\nBloom ﬁlters surrounding the learned function f, we refer to this as a sandwiched learned Bloom\nﬁlter . The sandwiched learned Bloom ﬁlter is represented pictorially in Figure 1.\nIn hindsight, our result that sandwiching improves performance makes sense. The purpose of\nthe backup Bloom ﬁlter is to remove the false negatives arising from the learned function. If we\ncan arrange to remove more false positives up front, then the backup Bloom ﬁlter can be quite\nporous, allowing most everything that reaches it through, and therefore can be quite small. Indeed,\nsurprisingly, our analysis shows that the backup ﬁlter should not grow beyond a ﬁxed size.\n5.2 Analyzing Sandwiched Learned Bloom Filters\nWe model the sandwiched learned Bloom ﬁlter as follows. As before, the learned function fin the\nmiddle of the sandwich we treat as an oracle for the keysK, wherejKj=m. Also as before, for\nkeys not inKthere is an associated false positive probability Fp, and there are Fnmfalse negatives\nfor keys inK.\nWe here assume a total budget of bmbits to be divided between an initial Bloom ﬁlter of b1mbits\nand a backup Bloom ﬁlter of b2mbits. As before, we model the false positive rate of a Bloom ﬁlter\nthat usesjbits per stored key as \u000bjfor simplicity. The backup Bloom ﬁlter only needs to hold mFn\nkeys, and hence we take the number of bits per stored key to be b2=Fn. If we ﬁnd the best value of b2\nisb, then no initial Bloom ﬁlter is needed, but otherwise, an initial Bloom ﬁlter is helpful.\nThe false positive rate of a sandwiched learned Bloom ﬁlter is then \u000bb1(Fp+ (1\u0000Fp)\u000bb2=Fn):To\nsee this, note that for y =2K,yﬁrst has to pass through the initial Bloom ﬁlter, which occurs with\nprobability\u000bb1. Thenyeither causes a false positive from the learned function fwith probability\nFp, or with remaining probability (1\u0000Fp)it yields a false positive on the backup Bloom ﬁlter, with\nprobability\u000bb2=Fn.\n7\n\nLearned\t\r  Oracle\t\r  \nBackup\t\r  Filter\t\r  \nInput\t\r  \nPosi6ves\t\r  Nega6ves\t\r  \nPosi6ves\t\r  \nNega6ves\t\r  \nLearned\t\r  Oracle\t\r  \nBackup\t\r  Filter\t\r  \nPosi6ves\t\r  \nPosi6ves\t\r  Nega6ves\t\r  \nPosi6ves\t\r  \nNega6ves\t\r  \nIni6al\t\r  Filter\t\r  \nInput\t\r  \nNega6ves\t\r  Figure 1: The left side shows the original learned Bloom ﬁlter. The right side shows the sandwiched\nlearned Bloom ﬁlter.\nAs\u000b;Fp;Fnandbare all constants for the purpose of this analysis, we may optimize for b1in the\nequivalent expression\nFp\u000bb1+ (1\u0000Fp)\u000bb=Fn\u000bb1(1\u00001=Fn):\nThe derivative with respect to b1is\nFp(ln\u000b)\u000bb1+ (1\u0000Fp)\u0012\n1\u00001\nFn\u0013\n\u000bb=Fn(ln\u000b)\u000bb1(1\u00001=Fn):\nThis equals 0 when\nFp\n(1\u0000Fp)\u0010\n1\nFn\u00001\u0011=\u000b(b\u0000b1)=Fn=\u000bb2=Fn: (1)\nThis further yields that the false positive rate is minimized when b2=b\u0003\n2, where\nb\u0003\n2=Fnlog\u000bFp\n(1\u0000Fp)\u0010\n1\nFn\u00001\u0011: (2)\nThis result may be somewhat surprising, as here we see that the optimal value b\u0003\n2is a constant,\nindependent of b. That is, the number of bits used for the backup ﬁlter is not a constant fraction\nof the total budgeted number of bits bm, but a ﬁxed number of bits; if the number of budgeted bits\nincreases, one should simply increase the size of the initial Bloom ﬁlter as long as the backup ﬁlter is\nappropriately sized.\nIn hindsight, returning to the expression for the false positive rate \u000bb1(Fp+(1\u0000Fp)\u000bb2=Fn)provides\nuseful intuition. If we think of sequentially distributing the bmbits among the two Bloom ﬁlters, the\nexpression shows that bits assigned to the initial ﬁlter (the b1bits) reduce false positives arising from\nthe learned function (the Fpterm) as well as false positives arising subsequent to the learned function\n(the(1\u0000Fp)term), while the backup ﬁlter only reduces false positives arising subsequent to the\nlearned function. Initially we would provide bits to the backup ﬁlter to reduce the (1\u0000Fp)rate of\nfalse positives subsequent to the learned function. Indeed, bits in the backup ﬁlter drive down this\n(1\u0000Fp)term rapidly, because the backup ﬁlter holds fewer keys from the original set, leading to\ntheb2=Fn(instead of just a b2) in the exponent in the expression \u000bb2=Fn. Once the false positives\ncoming through the backup Bloom ﬁlter reaches an appropriate level, which, by plugging in the\ndetermined optimal value for b2, we ﬁnd isFp=\u0010\n1\nFn\u00001\u0011\n, then the tradeoff changes. At that point\nthe gains from reducing the false positives by increasing the bits for the backup Bloom ﬁlter become\nsmaller than the gains obtained by increasing the bits for the initial Bloom ﬁlter.\nAgain, we can look at situations discussed in [ 7] for some insight. Suppose we have a learned function\nfwhereFn= 0:5andFp= 0:01. We consider \u000b= 0:6185 (which corresponds to a standard Bloom\nﬁlter). We do not consider the size of fin the calculation below. Then the optimal value for b2is\nb\u0003\n2= (log\u000b1=99)=2\u00196:\n8\n\nDepending on our Bloom ﬁlter budget parameter b, we obtain different levels of performance\nimprovement by using the initial Bloom ﬁlter. At b= 8bits per key, the false positive rate drops from\napproximately 0:010045 to0:005012 , over a factor of 2. At b= 10 bits per key, the false positive\nrate drops from approximately 0:010066 to0:001917 , almost an order of magnitude.\nWe may also consider the implications for the oracle size. Again, if we let \u0010represent the size of the\noracle in bits, then a corresponding Bloom ﬁlter would have a false positive probability of \u000bb+\u0010=m.\nHence we have an improvement whenever\n\u000bb1(Fp+ (1\u0000Fp)\u000bb2=Fn)\u0014\u000bb+\u0010=m:\nForbsufﬁciently large that b1>0, we can calculate the false positive probability of the opti-\nmized sandwiched Bloom ﬁlter. Let b\u0003\n2be the optimal value for b2from equation 2 and b\u0003\n1be the\ncorresponding value for b1. First using the relationship from equation 1, we have a gain whenever\n\u000bb\u0003\n1Fp\n1\u0000Fn\u0014\u000bb+\u0010=m:\nUsingb\u0003\n1=b\u0000b\u0003\n2and equation 2 gives\n\u0010=m\u0014log\u000bFp\n1\u0000Fn\u0000Fnlog\u000bFp\n(1\u0000Fp)\u0010\n1\nFn\u00001\u0011:\nAgain, this expression is somewhat unwieldy, but one useful difference from the analysis of the\noriginal learned Bloom ﬁlter is that we see the improvement does not depend on the exact value of\nb(as longbis large enough so that b1>0, and we use the optimal value for b2). ForFp= 0:01,\nFn= 0:5, and\u000b= 0:6185 , we ﬁnd a gain whenever \u0010=m falls below approximately 3:36:\nA possible further advantage of the sandwich approach is that it makes learned Bloom ﬁlters more\nrobust. As discussed previously, if the queries given to a learned Bloom ﬁlter do not come from the\nsame distribution as the queries from the test set used to estimate the learned Bloom ﬁlter’s false\npositive probability, the actual false positive probability may be substantially larger than expected.\nThe use of an initial Bloom ﬁlter mitigates this problem, as this issue then only affects the smaller\nnumber of keys that pass the initial Bloom ﬁlter.\nWe note that a potential disadvantage of the sandwich approach may be that it is more computationally\ncomplex than a learned Bloom ﬁlter without sandwiching, requiring possibly more hashing and\nmemory accesses for the initial Bloom ﬁlter. The overall efﬁciency would be implementation\ndependent, but this remains a possible issue for further research.\n6 Learned Bloomier Filters\nIn the supplemental material, we consider learned Bloomier ﬁlters . Bloomier ﬁlters are a variation\nof the Bloom ﬁlter idea where each key in the set Khas an associated value. The Bloomier ﬁlter\nreturns the value for every key of K, and is supposed to return a null value for keys not in K, but in\nthis context there can be false positives where the return for a key outside of Kis a non-null value\nwith some probability. We derive related formulae for the performance of learned Bloomier ﬁlters.\n7 Conclusion\nWe have focused on providing a more formal analysis of the proposed learned Bloom ﬁlter. As part of\nthis, we have attempted to clarify a particular issue in the Bloom ﬁlter setting, namely the dependence\nof what is referred to as the false positive rate in [ 7] on the query set, and how it might affect the\napplications this approach is suited for. We have also found that our modeling laeds to a natural and\ninteresting optimization, based on sandwiching, and allows for generalizations to related structures,\nsuch as Bloomier ﬁlters. Our discussion is meant to encourage users to take care to realize all of the\nimplications of the learned Bloom ﬁlter approach before adopting it. However, for sets that can be\naccurately predicted by small learned functions, the learned Bloom ﬁlter may provide a novel means\nof obtaining signiﬁcant performance improvements over standard Bloom ﬁlter variants.\n9\n\nAcknowledgments\nThe author thanks Suresh Venkatasubramanian for suggesting a closer look at [ 7], and thanks the\nauthors of [ 7] for helpful discussions involving their work. This work was supported in part by NSF\ngrants CCF-1563710, CCF-1535795, CCF-1320231, and CNS-1228598. Part of this work was done\nwhile visiting Microsoft Research New England.\nReferences\n[1]M. Bender, M. Farach-Colton, M. Goswami, R. Johnson, S. McCauley, and S. Singh. Bloom\nFilters, Adaptivity, and the Dictionary Problem. https://arxiv.org/abs/1711.01616 ,\n2017.\n[2]A. Broder and M. Mitzenmacher. Network Applications of Bloom Filters: A Survey. Internet\nMathematics , 1(4):485-509, 2004.\n[3]D. Charles and K. Chellapilla. Bloomier Filters: A Second Look. In Proceedings of the European\nSymposium on Algorithms , pp. 259-270, 2008.\n[4]B. Chazelle, J. Kilian, R. Rubinfeld, and A. Tal. The Bloomier Filter: an Efﬁcient Data\nStructure for Static Support Lookup Tables. In Proceedings of the Fifteenth Annual ACM-SIAM\nSymposium on Discrete Algorithms , pp. 30-39, 2004.\n[5]K. Chung, M. Mitzenmacher, and S. Vadhan. Why Simple Hash Functions Work: Exploiting\nthe Entropy in a Data Stream. Theory of Computing , 9(30):897-945, 2013.\n[6]B. Fan, D. Andersen, M. Kaminsky, and M. Mitzenmacher. Cuckoo Filter: Practically Better\nthan Bloom. In Proceedings of the 10th ACM International Conference on Emerging Networking\nExperiments and Technologies , pp. 75-88, 2014.\n[7]T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The Case for Learned Index\nStructures. https://arxiv.org/abs/1712.01208 , 2017.\n[8]M. Mitzenmacher. A Model for Learned Bloom Filters and Related Structures. https://\narxiv.org/abs/1802.00884 , 2018.\n[9]M. Mitzenmacher. Optimizing Learned Bloom Filters by Sandwiching. https://arxiv.org/\nabs/1803.01474 , 2018.\n[10] M. Mitzenmacher, S. Pontarelli, and P. Reviriego. Adaptive Cuckoo Filters. In Proceedings\nof the Twentieth Workshop on Algorithm Engineering and Experiments (ALENEX) , pp. 36-47,\n2018.\n[11] M. Mitzenmacher and E. Upfal. Probability and Computing: Randomization and Probabilistic\nTechniques in Algorithms and Data Analysis. Cambridge University Pres, 2017.\n[12] M. Naor and E. Yogev. Bloom Filters in Adversarial Environments. In Proceedings of the\nAnnual Cryptography Conference , pp. 565-584, 2015.\n10\n\nLearned\t\r  Oracle\t\r  \nBackup\t\r  Bloomier\t\r  Filter\t\r  \nInput\t\r  \nHit\t\r  \nPassed\t\r  (yields\t\r  false\t\r  posi;ves)\t\r  \nBloom\t\r  Filter\t\r  \nPosi;ves\t\r  \nNega;ves\t\r  Figure 2: A learned Bloomier ﬁlter design. Keys obtain a value, which may be null, from the learned\noracle. If a key does nothit on a Bloom ﬁlter, the key returns with the value from the oracle; in\nthis way, false positives from the oracle may result. The Bloom ﬁlter stores false negatives from\nthe learned oracle, and passes them to the backup Bloomier ﬁlter to obtain the correct value. False\npositive hits at the Bloom ﬁlter both require the backup Bloomier ﬁlter to hold values for additional\nkeys fromK, and may yield false positives for keys outside of Kat the backup Bloomier ﬁlter.\n8 Supplemental: Learned Bloomier Filters Derivation\nBloomier ﬁlters are a variation of the Bloom ﬁlter idea where each key in the set Khas an associated\nvalue, which for convenience we will assume is a u-bit value. The Bloomier ﬁlter returns the value for\nevery key ofK, as is supposed to return a null value for keys not in K, but in this context there can be\nfalse positives where the return for a key outside of Kis a non-null value with some probability. For\nour purposes, this description will sufﬁce (although we present a few more details below in presenting\nour model), but more information on Bloomier ﬁlters and their constructions can be found in [3, 4].\nHere we imagine that we can derive a learned function fthat will return a value given an input,\nwith the goal being that the function will return the appropriate u-bit value for a key in Kand the\nnull value otherwise. In this setting we refer to a false positive as a key outside of Kthat obtains a\nnon-null value, and a false negative as a key in Kthat obtains an incorrect value, where that value\nmay either be the null value or the wrong value for that key.\nNotice in this setting that, because keys in Kmay obtain an incorrect value that is not merely null, the\nsystem to correct for false negatives must be slightly more complicated. We propose an approach in\nFigure 2. The input is ﬁrst passed to the learned oracle, which provides a predicted value. To handle\nfalse negatives, we provide a two-stage scheme. First, we use a Bloom ﬁlter to hold any keys that\nlead to false negatives. If the Bloom ﬁlter returns a key is a positive, which we refer to as a hit on the\nBloom ﬁlter to avoid ambiguity, it is assumed that that key is a false negative from the oracle and a\nbackup Bloomier ﬁlter is used to determine its value. If the Bloom ﬁlter returns a key is a negative, it\nis assumed the learned oracle provided the correct value (whether null or non-null) for that key, and\nthat value is returned. We can see that for every key in Kthe correct value is returned, so the question\nis what is the false positive rate for this chain.\nOur model is as follows. We again treat the function fas an oracle for the keys in K, wherejKj=m,\nand the size of the oracle is \u0010. For keys not inKthere is an associated false positive probability Fp,\nand there are Fnmfalse negatives for keys in K. The Bloom ﬁlter will consist of bFnmbits and have\nits own false positive probability of \u000bb. (Of course, instead of a standard Bloom ﬁlter we could use a\nlearned Bloom ﬁlter in its place, but that is harder to model.)\nTo model a Bloomier ﬁlter, we use the following approach: a Bloomier ﬁlter for zkeys uses space\ncz(u+r), whereuis the number of bits in the return value, cis constant that is determined by the\nBloomier ﬁlter design, and ris a parameter chosen, with the result that the false positive probability\nfor a key outside of Kis2\u0000r. This setup, for example, matches the construction of [ 4]. One can think\nof it as having czcells ofu+rbits. The simple construction of [ 4] hashes a query key to (typically)\n11\n\nthree cells, and exclusive-ors their contents together; if the result is a valid u-bit value (say with r\nleading zeroes), this value is returned, and otherwise a null value is returned. The table is initially\nﬁlled so that the right values are returned for the zkeys, and other keys obtain a value uniformly\ndistributed over u+rbits, leading to the false positive probability of 2\u0000r. This requires czcells for\nsomec>1to provide enough “room” to set up suitable cell values initially.\nIf we just used a standard Bloomier ﬁlter for the keys K, then we would use cm(u+r)bits for a\nfalse positive probability of 2\u0000r.\nFor our learned Bloom ﬁlter construction, we start with the learned function of size \u0010. The function\nfyieldsmFnfalse negatives; these mFnfalse negatives can be stored in the Bloom ﬁlter using\nbmFnbits and the corredsponding values recovered by the backup Bloomier ﬁlter. The keys not\nhit by this Bloom ﬁlter, which we refer to as the keys passed by this Bloom ﬁlter, may now include\nfalse positives for our learned Bloomier ﬁlter. A key not in Kwill yield a false positive here with\nprobabilityFp(1\u0000\u000bb); that is, the key must have been a false positive for the learned oracle, but must\nhave not been a hit on the Bloom ﬁlter. Also, note that some keys from Kthat obtained the correct\nvalue fromfmay hit the Bloom ﬁlter, and therefore will also have to have their values provided by\nthe backup Bloomier ﬁlter. Of these m(1\u0000Fn)keys fromK, a fraction\u000bbare expected to be false\npositives in the Bloom ﬁlter; as we have throughout the paper, we will use the expectation, keeping\nin mind the true result will be concentrated around this expectation. Hence, in total, we need the\nbackup Bloomier ﬁlter for m0=m(Fn+ (1\u0000Fn)\u000bb)keys. Suppose we use cm0(u+r0)bits for\nthe backup Bloomier ﬁlter. Then our total space is\n\u0010+bmFn+cm(Fn+ (1\u0000Fn)\u000bb)(u+r0);\nand our overall false positive probability is\nFp(1\u0000\u000bb) +\u000bb2\u0000r0;\nwhere the ﬁrst term is from false positives from the oracle than passed Bloom ﬁlter, and the second\nterm is from queries that hit the Bloom ﬁlter and give false positives in the backup Bloomier ﬁlter.\nAgain, these expressions are somewhat unwieldy because of the number of parameters. At a high\nlevel, however, these expressions reinforce helpful intuition. The cost per element in a Bloomier\nﬁlter is rather high, because the value must be stored. Therefore if the false negatives as given by Fn\ncan be driven down to reasonable value with a small enough learned function, there should be space\navailable to pay the \u0010bits of the learned function as well as the additional Bloom ﬁlter.\n12",
  "textLength": 42854
}