{
  "paperId": "7d89abfe87ed7d1b40391d37364560656d208117",
  "title": "Learning Memory Access Patterns",
  "pdfPath": "7d89abfe87ed7d1b40391d37364560656d208117.pdf",
  "text": "Learning Memory Access Patterns\nMilad Hashemi1Kevin Swersky1Jamie A. Smith1Grant Ayers2 *Heiner Litz3 *Jichuan Chang1\nChristos Kozyrakis2Parthasarathy Ranganathan1\nAbstract\nThe explosion in workload complexity and the\nrecent slow-down in Moore’s law scaling call\nfor new approaches towards efﬁcient computing.\nResearchers are now beginning to use recent ad-\nvances in machine learning in software optimiza-\ntions, augmenting or replacing traditional heuris-\ntics and data structures. However, the space of\nmachine learning for computer hardware archi-\ntecture is only lightly explored. In this paper, we\ndemonstrate the potential of deep learning to ad-\ndress the von Neumann bottleneck of memory\nperformance. We focus on the critical problem of\nlearning memory access patterns, with the goal\nof constructing accurate and efﬁcient memory\nprefetchers. We relate contemporary prefetching\nstrategies to n-gram models in natural language\nprocessing, and show how recurrent neural net-\nworks can serve as a drop-in replacement. On a\nsuite of challenging benchmark datasets, we ﬁnd\nthat neural networks consistently demonstrate su-\nperior performance in terms of precision and re-\ncall. This work represents the ﬁrst step towards\npractical neural-network based prefetching, and\nopens a wide range of exciting directions for ma-\nchine learning in computer architecture research.\n1. Introduction\nThe proliferation of machine learning, and more recently\ndeep learning, in real-world applications has been made\npossible by an exponential increase in compute capabilities,\nlargely driven by advancements in hardware design. To\nmaximize the effectiveness of a given design, computer ar-\nchitecture often involves the use of prediction and heuristics.\nPrefetching is a canonical example of this, where instruc-\ntions or data are brought into much faster storage well in\n*Work done while at Google1Google2Stanford University\n3University of California, Santa Cruz. Correspondence to: Mi-\nlad Hashemi <miladh@google.com >, Kevin Swersky <kswer-\nsky@google.com >.advance of their required usage.\nPrefetching addresses a critical bottleneck in von Neumann\ncomputers: computation is orders of magnitude faster than\naccessing memory. This problem is known as the memory\nwall (Wulf & McKee, 1995), and modern applications can\nspend over 50% of all compute cycles waiting for data to\narrive from memory (Kozyrakis et al., 2010; Ferdman et al.,\n2012; Kanev et al., 2015). To mitigate the memory wall,\nmicroprocessors use a hierarchical memory system, with\nsmall and fast memory close to the processor (i.e., caches),\nand large yet slower memory farther away. Prefetchers\npredict when to fetch what data into cache to reduce memory\nlatency, and the key towards effective prefetching is to attack\nthe difﬁcult problem of predicting memory access patterns.\nPredictive optimization such as prefetching is one form of\nspeculation. Modern microprocessors leverage numerous\ntypes of predictive structures to issue speculative requests\nwith the aim of increasing performance. Historically, most\npredictors in hardware are table-based. That is, future events\nare expected to correlate with past history tracked in lookup\ntables (implemented as memory arrays). These memory\narrays are sized based on the working set, or amount of\ninformation that the application actively uses. However, the\nworking sets of modern datacenter workloads are orders\nof magnitude larger than those of traditional workloads\nsuch as SPEC CPU2006 and continue to grow (Ayers et al.,\n2018; Ferdman et al., 2012; Gutierrez et al., 2011; Hashemi\net al., 2016). This trend poses a signiﬁcant challenge, as\nprediction accuracy drops sharply when the working set is\nlarger than the predictive table. Scaling predictive tables\nwith fast-growing working sets is difﬁcult and costly for\nhardware implementation.\nNeural networks have emerged as a powerful technique to\naddress sequence prediction problems, such as those found\nin natural language processing (NLP) and text understand-\ning (Bengio et al., 2003; Mikolov et al., 2010; 2013). Sim-\nple perceptrons have even been deployed in hardware (e.g.,\nSPARC T4 processor (Golla & Jordan, 2011)), to handle\nbranch prediction (Jim ´enez & Lin, 2001). Yet, exploring the\neffectiveness of sequential learning algorithms in microar-\nchitectural designs is still an open area of research.\nIn this paper, we explore the utility of sequence-based neu-arXiv:1803.02329v1  [cs.LG]  6 Mar 2018\n\nLearning Memory Access Patterns\nral networks in microarchitectural systems. In particular,\ngiven the challenge of the memory wall, we apply sequence\nlearning to the difﬁcult problem of prefetching.\nPrefetching is fundamentally a regression problem. The\noutput space, however, is both vast and extremely sparse,\nmaking it a poor ﬁt for standard regression models. We take\ninspiration from recent works in image and audio generation\nthat discretize the space, namely PixelRNN and Wavenet\n(Oord et al., 2016a;b). Discretization makes prefetching\nmore analogous to neural language models, and we leverage\nit as a starting point for building neural prefetchers. We ﬁnd\nthat we can successfully model the output space to a degree\nof accuracy that makes neural prefetching a very distinct\npossibility. On a number of benchmark datasets, we ﬁnd that\nrecurrent neural networks signiﬁcantly outperform the state-\nof-the-art of traditional hardware prefetchers. We also ﬁnd\nthat our results are interpretable. Given a memory access\ntrace, we show that the RNN is able to discern semantic\ninformation about the underlying application.\n2. Background\n2.1. Microarchitectural Data Prefetchers\nPrefetchers are hardware structures that predict future mem-\nory accesses from past history. They can largely be sepa-\nrated into two categories: stride prefetchers and correlation\nprefetchers. Stride prefetchers are commonly implemented\nin modern processors and lock onto stable, repeatable deltas\n(differences between subsequent memory addresses) (Gin-\ndele, 1977; Jouppi, 1990; Palacharla & Kessler, 1994). For\nexample, given an access pattern that adds four to a memory\naddress every time (0, 4, 8, 12), a stride prefetcher will learn\nthat delta and try to prefetch ahead of the demand stream,\nlaunching parallel accesses to potential future address tar-\ngets (16, 20, 24) up to a set prefetch distance.\nCorrelation prefetchers try to learn patterns that may repeat,\nbut are not as consistent as a single stable delta (Charney &\nReeves, 1995; Lai et al., 2001; Somogyi et al., 2006; Roth\net al., 1998). They store the past history of memory accesses\nin large tables and are better at predicting more irregular\npatterns than stride prefetchers. Examples of correlation\nprefetchers include Markov prefetchers (Joseph & Grun-\nwald, 1997), GHB prefetchers (Nesbit & Smith, 2004), and\nmore recent work that utilizes larger in-memory structures\n(Jain & Lin, 2013). Correlation prefetchers require large,\ncostly tables, and are typically not implemented in modern\nmulti-core processors.\n2.2. Recurrent Neural Networks\nDeep learning has become the model-class of choice for\nmany sequential prediction problems. Notably, speech\nrecognition (Hinton et al., 2012) and natural language pro-cessing (Mikolov et al., 2010). In particular, RNNs are a\npreferred choice for their ability to model long-range depen-\ndencies. LSTMs (Hochreiter & Schmidhuber, 1997) have\nemerged as a popular RNN variant that deals with training\nissues in standard RNNs, by propagating the internal state\nadditively instead of multiplicatively. An LSTM is com-\nposed of a hidden state hand a cell state c, along with input\ni, forget f, and output gates othat dictate what information\ngets stored and propagated to the next timestep. At timestep\nN, input xNis presented to the LSTM, and the LSTM states\nare computed using the following process:\n1. Compute the input, forget, and output gates\niN=\u001b(Wi[xN;hN\u00001] +bi)\nfN=\u001b(Wf[xN;hN\u00001] +bf)\noN=\u001b(Wo[xN;hN\u00001] +bo)\n2. Update the cell state\ncN=fN\fcN\u00001+iN\ftanh(Wc[xN;hN\u00001] +bc)\n3. Compute the LSTM hidden (output) state\nhN=oN\ftanh( cN)\nWhere [xN;hN\u00001]represents the concatenation of the cur-\nrent input and previous hidden state, \frepresents element-\nwise multiplication, and \u001b(u) =1\n1+exp(\u0000u)is the sigmoid\nnon-linearity.\nThe above process forms a single LSTM layer, where\nWfi;f;o;cgare the weights of the layer, and bfi;f;o;cgare\nthe biases. LSTM layers can be further stacked so that the\noutput of one LSTM layer at time Nbecomes the input to\nanother LSTM layer at time N. It is analogous to having\nmultiple layers in a feed-forward neural network, and al-\nlows greater modeling ﬂexibility with relatively few extra\nparameters.\n3. Problem Formulation\n3.1. Prefetching as a Prediction Problem\nPrefetching is the process of predicting future memory ac-\ncesses that will miss in the on-chip cache and access memory\nbased on past history. Each of these memory addresses are\ngenerated by a memory instruction (a load/store). Memory\ninstructions are a subset of all instructions that interact with\nthe addressable memory of the computer system.\nMany hardware proposals use two features to make these\nprefetching decisions: the sequence of caches miss ad-\ndresses that have been observed so far and the sequence\nof instruction addresses, also known as program counters\n\nLearning Memory Access Patterns\n(PCs), that are associated with the instruction that generated\neach of the cache miss addresses.\nPCs are unique tags, that is each PC is unique to a particular\ninstruction that has been compiled from a particular function\nin a particular code ﬁle. PC sequences can inform the model\nof patterns in the control ﬂow of higher level code, while the\nmiss address sequence informs the model of which address\nto prefetch next. In modern computer systems, both of these\nfeatures are represented as 64-bit integers.\nTherefore, an initial model could use two input features at\na given timestep N. It could use the address and PC that\ngenerated a cache miss at that timestep to predict the address\nof the miss at timestep N+ 1.\nHowever, one concern quickly becomes apparent: the ad-\ndress space of an application is extremely sparse. In our\ntraining data with O(100M) cache misses, only O(10M)\nunique cache block miss addresses appear on average out\nof the entire 264physical address space. This is further\ndisplayed when we plot an example trace from omnetpp\n(a benchmark from the standard SPEC CPU2006 bench-\nmark suite (Sta, 2006)) in Figure 1, where the red datapoints\nare cache miss addresses1. The wide range and severely\nmulti-modal nature of this space makes it a challenge for\ntime-series regression models. For example, neural net-\nworks tend work best with normalized inputs, however when\nnormalizing this data, the ﬁnite precision ﬂoating-point rep-\nresentation results in a signiﬁcant loss of information. This\nissue affects modeling at both the input and output levels,\nand we will describe several approaches to deal with both\naspects.\nZoomed\nFigure 1. Cache miss addresses on the omnetpp dataset, demon-\nstrating sparse access patterns at multiple scales.\n1Cache miss addresses are from a three level simulated cache\nhierarchy with a 32 KB L1, 256 KB L2, and 1.25 MB Last Level\nCache (LLC), similar to a single thread context from an Intel\nBroadwell microprocessor.3.2. Prefetching as Classiﬁcation\nRather than treating the prefetching problem as regression,\nwe opt to treat the address space as a large, discrete vo-\ncabulary, and perform classiﬁcation. This is analogous to\nnext-word or character prediction in natural language pro-\ncessing. The extreme sparsity of the space, and the fact\nthat some addresses are much more commonly accessed\nthan others, means that the effective vocabulary size can\nactually be manageable for RNN models. Additionally, the\nmodel gains ﬂexibility by being able to produce multi-modal\noutputs, compared to unimodal regression techniques that\nassume e.g., a Gaussian likelihood. This idea of treating the\noutput prediction problem as one of classiﬁcation instead of\nregression has been successfully used in image (Oord et al.,\n2016a) and audio generation (Oord et al., 2016b).\nHowever, there are 264possible softmax targets, so a quan-\ntization scheme is necessary. Importantly, in order to be\nuseful, a prefetch must be within a cache line to be com-\npletely accurate, usually within 64 bytes. There is a second\norder beneﬁt if it is within a page, usually 4096 bytes, but\neven predicting at the page level would leave 252possible\ntargets. In (Oord et al., 2016b), they predict 16-bit integer\nvalues from an acoustic signal. To avoid having to apply\na softmax over 216values, they apply a non-linear quanti-\nzation scheme to reduce the space to 256 categories. This\nform of quantization is inappropriate for our purposes, as it\ndecreases the resolution of addresses towards the extremes\nof the address space, whereas in prefetching we need high\nresolution in every area where addresses are used.\nLuckily, programs tend to behave in predictable ways, so\nonly a relatively small (but still large in absolute numbers),\nand consistent set of addresses are ever seen. Our primary\nquantization scheme is to therefore create a vocabulary of\ncommon addresses during training, and to use this as the\nset of targets during testing. This reduces the coverage, as\nthere may be addresses at test time that are not seen during\ntraining time, however we will show that for reasonably-\nsized vocabularies, we capture a signiﬁcant proportion of\nthe space. The second approach we explore is to cluster the\naddresses using clustering on the address space. This is akin\nto an adaptive form of non-linear quantization.\nDue to dynamic side-effects such as address space layout\nrandomization (ASLR), different runs of the same program\nwill lead to different raw address accesses (Team, 2003).\nHowever, given a layout, the program will behave in a con-\nsistent manner. Therefore, one potential strategy is to pre-\ndict deltas, \u0001N= Addr N+1\u0000Addr N, instead of addresses\ndirectly. These will remain consistent across program execu-\ntions, and come with the beneﬁt that the number of uniquely\noccurring deltas is often orders of magnitude smaller than\nuniquely occurring addresses. This is shown in Table 1,\nwhere we show the number of unique PCs, addresses, and\n\nLearning Memory Access Patterns\ndeltas across a suite of program trace datasets. We also\nshow the number of unique addresses and deltas required\nto achieve 50% coverage. In almost all cases, this is much\nsmaller when considering deltas. In our models, we there-\nfore use deltas as inputs instead of raw addresses.\n4. Models\nIn this section we introduce two LSTM-based prefetching\nmodels. The ﬁrst version is analogous to a standard lan-\nguage model, while the second exploits the structure of the\nmemory access space in order to reduce the vocabulary size\nand reduce the model memory footprint.\n4.1. Embedding LSTM\nSuppose we restricted the output vocabulary size in order to\nonly model the most frequently occurring deltas. According\nto Table 1, the size of the vocabulary required in order to\nobtain at best 50% accuracy is usually O(1000) or less, well\nwithin the capabilities of standard language models. Our\nﬁrst model therefore restricts the output vocabulary size to a\nlarge, but feasible 50,000 of the most frequent, unique deltas.\nFor the input vocabulary, we include all deltas as long as\nthey appear in the dataset at least 10 times. Expanding the\nvocabulary beyond this is challenging, both computationally\nand statistically. We leave an exploration of approaches like\nthe hierarchical softmax (Mnih & Hinton, 2009) to future\nwork.\nWe refer to this model as the embedding LSTM, as illus-\ntrated in Figure 2. It uses a categorical (one-hot) represen-\ntation for both the input and output deltas. At timestep N,\nthe input PCNand\u0001Nare individually embedded and then\nthe embeddings are concatenated and fed as inputs to a two-\nlayer LSTM. The LSTM then performs classiﬁcation over\nthe delta vocabulary, and the Khighest-probability deltas\nare chosen for prefetching2.\nIn a practical implementation, a prefetcher can return several\npredictions. This creates a trade-off, where more predictions\nincreases the probability of a cache hit at the next timestep,\nbut potentially removes other useful items from the cache3.\nWe opt to prefetch the top-10 predictions of the LSTM at\neach timestep. Other possibilities that we do not explore\nhere include using a beam-search to predict the next ndeltas,\nor to learn to directly predict NtoN+nsteps ahead in one\nforward pass of the LSTM.\nThere are several limitations to this approach. First, a large\nvocabulary increases the model’s computational and storage\n2Directly predicting probabilites is another advantage that clas-\nsiﬁcation provides over traditional hardware.\n3This trade-off is subtle, because some of the addresses may\nend up being useful at future timesteps.\nCache\nPC1Δ1f(Δ1)g(PC1)PC2Δ2PC3Δ3PC4Δ4PC5Δ5PC6Δ6PC7Δ7PC8Δ8PC9Δ9f(Δ2)g(PC2)f(Δ3)g(PC3)f(Δ4)g(PC4)f(Δ5)g(PC5)f(Δ6)g(PC6)f(Δ7)g(PC7)f(Δ8)g(PC8)f(Δ9)g(PC9)ConcatLSTM\nEmbedΔ̃10.2Δ̃10.1Δ̃10.3…Δ̃10.KFigure 2. The embedding LSTM model. fandgrepresent embed-\nding functions.\nfootprint. Second, truncating the vocabulary necessarily\nputs a ceiling on the accuracy of the model. Finally, dealing\nwith rarely occurring deltas is non-trivial, as they will be\nseen relatively few times during training. This is known in\nNLP as the rare word problem (Luong et al., 2015).\n4.2. Clustering + LSTM\nWe hypothesize that much of the interesting interaction\nbetween addresses occurs locally in address space. As one\nexample, data structures like structs and arrays tend to be\nstored in contiguous blocks, and accessed repeatedly. In\nthis model, we exploit this idea to design a prefetcher that\nvery carefully models local context, whereas the embedding\nLSTM models both local and global context.\nBy looking at narrower regions of the address space, we can\nsee that there is indeed rich local context. We took the set of\naddresses from omnetpp and clustered them into 6 different\nregions using k-means. We show two of the clusters in\nFigure 3, and the rest can be found in the appendix.\nTo assess the relative accuracy of modeling local address-\nspace regions, we ﬁrst cluster the raw address space using\nk-means. The data is then partitioned into these clusters, and\ndeltas are computed within each cluster. A visual example\nof this is shown in Figure 4a. We found that one of the major\nadvantages of this approach is that the set of deltas within\na cluster is signiﬁcantly smaller than the global vocabulary,\nalleviating some of the issues with the embedding LSTM.\nTo reduce the size of the model, we use a multi-task LSTM\nto model all of the clusters. Stated another way, we use\nan LSTM to model each cluster independently, but tie the\nweights of the LSTMs. However, we provide the cluster ID\nas an additional feature, which effectively gives each LSTM\n\nLearning Memory Access Patterns\nTable 1. Program trace dataset statistics. M stands for million.\nDataset # Misses # PC # Addrs # Deltas # Addrs 50% mass # Deltas 50% mass\ngems 500M 3278 13.11M 2.47M 4.28M 18\nastar 500M 211 0.53M 1.77M 0.06M 15\nbwaves 491M 893 14.20M 3.67M 3.03M 2\nlbm 500M 55 6.60M 709 3.06M 9\nleslie3d 500M 2554 1.23M 0.03M 0.23M 15\nlibquantum 470M 46 0.52M 30 0.26M 1\nmcf 500M 174 27.41M 30.82M 0.07M 0.09M\nmilc 500M 898 3.74M 9.68M 0.87M 46\nomnetpp 449M 976 0.71M 5.01M 0.12M 4613\nsoplex 500M 1218 3.49M 5.27M 1.04M 10\nsphinx 283M 693 0.21M 0.37M 0.03M 3\nwebsearch 500M 54600 77.76M 96.41M 0.33M 5186\nFigure 3. Two of six k-means clusters on the omnetpp benchmark\ndataset. Memory accesses are colored according to the PC that\ngenerated them.\na different set of biases.\nThe partitioning of the address space into narrower regions\nalso means that the set of addresses within each cluster will\ntake on roughly the same order of magnitude, meaning that\nthe resulting deltas can be effectively normalized and used\nas real-valued inputs to the LSTM. This allows us to further\nreduce the size of the model, as we do not need to keep\naround a large matrix of embeddings. Importantly, we still\ntreat next-delta prediction as a classiﬁcation problem, as we\nfound that regression is still too inaccurate to be practical4.\nThis version of the LSTM addresses some of the issues of\nthe embedding LSTM. The trade-offs are that it requires\nan additional step of pre-processing to cluster the address\nspace, and that it only models local context. That is, it\n4The reason for this is after de-normalization , small inaccura-\ncies become dramatically magniﬁed.cannot model the dynamics that cause the program to access\ndifferent regions of the address space.\n5. Experiments\nA necessary condition for neural networks to be effective\nprefetchers is that they must be able to accurately predict\ncache misses. Our experiments primarily measure their\neffectiveness in this task when compared with traditional\nhardware. There are many design choices to be made in\nprefetching beyond the model itself. Creating a fair compar-\nison is a subtle process, and we outline our choices here.\n5.1. Data Collection\nThe data used in our evaluation is a dynamic trace that con-\ntains the sequence of memory addresses that an application\ncomputes. This trace is captured by using a dynamic instru-\nmentation tool, Pin (Luk et al., 2005), that attaches to the\nprocess and emits a ”PC, Virtual Address” tuple into a ﬁle\nevery time the instrumented application accesses memory\n(every load or store instruction).\nThis raw access trace mostly contains accesses that hit in the\ncache (such as stack accesses, which are present in the data\ncache). Since we are focused on predicting cache misses,\nwe obtain the sequence of cache misses by simulating this\ntrace through a simple cache simulator that emulates an Intel\nBroadwell microprocessor (Section 3.1).\nTo evaluate our proposals, we use the memory intensive ap-\nplications of SPEC CPU2006. This is a standard benchmark\nsuite that is used pervasively to evaluate the performance\nof computer systems. However, SPEC CPU2006 also has\nsmall working sets when compared to modern datacenter\nworkloads. Therefore in addition to SPEC benchmarks, we\nalso include Google’s web search workload. Web search is a\nunique application that exempliﬁes enterprise-scale software\ndevelopment and drives industrial hardware platforms.\n\nLearning Memory Access Patterns\nAddress ClusteringA1PC1A2A3A4A5A6A7A8A9PC2PC3PC4PC5PC6PC7PC8PC9A1PC1A5PC5A6PC6A3A4PC3PC4A7PC7A2PC2A8A9PC8PC9Δ11PC5Δ12PC6Δ21PC4Δ22PC7Δ31PC8Δ32PC9\n(a) Clustering the address space into separate streams.\nCache\nΔ11PC5Δ12PC6Δ21PC4Δ22PC7Δ31PC8Δ32PC9LSTM1LSTM2LSTM3123Δ̃13Δ̃23Δ̃33TiedweightsTiedweightsCluster ID(b) The clustering + LSTM model.\nFigure 4. The clustering + LSTM data processing and model.\n5.2. Experimental Setup\nWe split each trace into a training and testing set, using 70%\nfor training and 30% for evaluation, and train each LSTM\non each dataset independently. The embedding LSTM was\ntrained with ADAM (Kingma & Ba, 2015) while the clus-\ntering LSTM was trained with Adagrad (Duchi et al., 2011).\nWe report the speciﬁc hyperparameters used in the appendix.\n5.3. Metrics\nPrecision We measure precision-at-10, which makes the\nassumption that each model is allowed to make 10 predic-\ntions at a time. The model predictions are deemed correct if\nthe true delta is within the set of deltas given by the top-10\npredictions. A label that is outside of the output vocabulary\nof the model is automatically deemed to be a failure.\nRecall We measure recall-at-10. Each time the model\nmakes predictions, we record this set of 10 deltas. At the\nend, we measure the recall as the cardinality of the set of\npredicted deltas over the entire set seen at test-time. This\nmeasures the ability of the prefetcher to make diverse predic-\ntions, but does not give any weight to the relative frequency\nof the different deltas.\nOne subtlety involving the clustering + LSTM model is how\nit is used at test-time. In practice, if an address generates a\ncache miss, then we identify the region of this miss, feed it as\nan input to the appropriate LSTM, and retrieve predictions.\nTherefore, the bandwidth required to make a prediction is\nnearly identical between the two LSTM variants.\n5.4. Model Comparison\nWe compare our LSTM-based prefetchers to two hardware\nprefetchers. The ﬁrst is a standard stream prefetcher. We\nsimulate a hardware structure that supports up to 10 simul-taneous streams to maintain parity between the ML and tra-\nditional predictors. The second is a GHB PC/DC prefetcher\n(Nesbit & Smith, 2004). This is a correlation prefetcher that\nuses two tables. The ﬁrst table stores PCs, these PCs then\nserve as a pointer into the second table where delta history\nis recorded. On every access, the GHB prefetcher jumps\nthrough the second table in order to prefetch deltas that it\nhas recorded in the past. This prefetcher excels at more\ncomplex memory access patterns, but has much lower recall\nthan the stream prefetcher.\nFigure 5 shows the comparison of the different prefetchers\nacross a range of benchmark datasets. While the stream\nprefetcher is able to achieve a high recall due to its dy-\nnamic vocabulary, the LSTM models otherwise dominate,\nespecially in terms of precision.\nComparing the embedding LSTM to the cluster + LSTM\nmodels, neither model obviously outperforms the other in\nterms of precision. The clustering + LSTM tends to gener-\nate much higher recall, likely the result of having multiple\nvocabularies. An obvious direction is to ensemble these\nmodels, which we leave for future work.\n5.5. Predictive information of \u0001s vs PCs\nIn this experiment, we remove one of the \u0001s or PCs from\nthe embedding LSTM inputs, and measure the change in\npredictive ability. This allows us to determine the relative\ninformation content contained in each input modality.\nAs Figure 6 shows, both PCs and deltas contain a good\namount of predictive information. Most of the information\nrequired for high precision is contained within the delta\nsequence, however the PC sequence helps improve recall.\n\nLearning Memory Access Patterns\nbwavesgemsleslie3d\nlibquantumsoplexsphinx3astarlbm mcf milc\nomnetppwebsearchgeomean0%20%40%60%80%100%120%Precision\nStream GHB Embedding Clustering\n(a) Precision\nbwavesgemsleslie3d\nlibquantumsoplexsphinx3astarlbm mcf milc\nomnetppwebsearchgeomean0%20%40%60%80%100%120%Recall\nStream GHB Embedding Clustering\n(b) Recall\nFigure 5. Precision and recall comparison between traditional and\nLSTM prefetchers. Geomean is the geometric mean.\n5.6. Interpreting Program Semantics\nOne of the key advantages of using a model to learn patterns\nthat generalize (as opposed to lookup tables) is that the\nmodel can then be introspected in order to gain insights into\nthe data. In Figure 7, we show a t-SNE (Maaten & Hinton,\n2008) visualization of the ﬁnal state of the concatenated ( \u0001,\nPC) embeddings on mcf, colored according to PCs.\nThere is clearly a lot of structure to the space. Linking PCs\nback to the source code in mcf, we observe one cluster that\nconsists of repetitions of the same code statement, caused by\nthe compiler unrolling a loop. A different cluster consists\nonly of pointer dereferences, as the application traverses\na linked list. Applications besides mcf show this learned\nstructure as well. In omnetpp we ﬁnd that inserting and re-\nmoving into a data structure are mapped to the same cluster\nand data comparisons are mapped into a different cluster.\nWe show these code examples in the appendix, and leave fur-\nther inspection for future work, but the model appears to be\nlearning about the higher level structure of the application.\n6. Related Work\n6.1. Machine Learning in Microarchitecture\nMachine learning in microarchitecture and computer sys-\ntems is not new, however the application of machine learn-\ning as a complete replacement for traditional systems, espe-\ncially using deep learning, is a relatively new and largely un-\ncharted area. Here we outline several threads of interaction\nbwavesgemsleslie3d\nlibquantumsoplexsphinx3astarlbm mcf milc\nomnetppwebsearchgeomean0%20%40%60%80%100%120%Precision\nPC and Delta Only Deltas Only PCs(a) Precision\nbwavesgemsleslie3d\nlibquantumsoplexsphinx3astarlbm mcf milc\nomnetppwebsearchgeomean0%20%40%60%80%100%120%Recall\nPC and Delta Only Deltas Only PCs\n(b) Recall\nFigure 6. Precision and Recall of the embedding LSTM with dif-\nferent input modalities.\nbetween machine learning and microarchitecture research.\nPrior work has also directly applied machine learning tech-\nniques to microarchitectural problems. Notably, the percep-\ntron branch predictor (Jim ´enez & Lin, 2001) uses a linear\nclassiﬁer to predict whether a branch is taken or not-taken.\nThe perceptron learns in an online fashion by increment-\ning or decrementing weights based on taken/not-taken out-\ncome. The key beneﬁt of the perceptron is its simplicity,\neschewing more complicated training algorithms such as\nback-propagation to meet tight latency requirements.\nOther applications of machine learning in microarchitecture\ninclude applying reinforcement learning for optimizing the\nlong-term performance of memory controller scheduling\nalgorithms (Ipek et al., 2008), tuning performance knobs\n(Blanton et al., 2015), and using bandits to identify patterns\nin hardware and software features that relate to a memory\naccess (Peled et al., 2015).\nRecent work also proposed an LSTM-based prefetcher and\nevaluated it with generated traces following regular expres-\nsions (Zeng, October 2017). Using the squared loss, the\nmodel caters to capturing regular, albeit non-stride, patterns.\nIrregular memory reference patterns, either due to workload\nbehavior or multi-core processor reordering/interleaving,\npose challenges to such regression-based approaches. Zeng\n(October 2017) evaluate their model on randomly generated\npatterns. As detailed in Section 3, we have found regression\nmodels to be a poor ﬁt on real workloads.\n\nLearning Memory Access Patterns\nFigure 7. A t-SNE visualization of the concatenated ( \u0001,PC) em-\nbeddings on mcfcolored according to PC instruction.\nVery recent work has also explored the usage of machine\nlearning to replace conventional database index structures\nsuch as b-trees and bloom ﬁlters (Kraska et al., 2017).\nAlthough the nature of this problem differs from cache\nprefetching, there are many similarities as well. Speciﬁ-\ncally, the idea of using the distribution of the data to learn\nspeciﬁc models as opposed to deploying generic data struc-\ntures. Our clustering approach is also reminiscent of the\nhierarchical approach that they deploy. Importantly, they\nﬁnd that neural network models are faster to query than\nconventional data structures.\n6.2. Machine Learning of Program Behavior\nMemory traces can be thought of as a representation of\nprogram behavior. Speciﬁcally, they represent a bottom-up\nview of the dynamic interaction of a pre-speciﬁed program\nwith a particular set of data. From a machine learning\nperspective, researchers have taken a top-down approach to\nexplore whether neural networks can understand program\nbehavior and structure.\nOne active area of research is program synthesis, where\na full program is generated from a partial speciﬁcation–\nusually input/output examples. Zaremba & Sutskever (2014)\nuse an LSTM to estimate the output of a randomly generated\nprogram. The model can only see the sequence of ASCII\ncharacters representing the program, and must also generate\nthe resulting output as a sequence of characters. Zaremba\n& Sutskever (2014) falls into the category of sequence-to-\nsequence models (Sutskever et al., 2014). Another examplein this category is the Neural Turing Machine , which aug-\nments an LSTM with an external memory and an attention\nmechanism to form a differentiable analog of a Turing ma-\nchine (Graves et al., 2014). This is used to solve simple\nproblems such as sorting, copying, and associative recall.\nThere is also work on modeling source code directly, as\nopposed to modeling properties of the resulting program.\nFor example, (Maddison & Tarlow, 2014) creates a genera-\ntive model of source code using a probabilistic context-free\ngrammar. (Hindle et al., 2012) models source code as if\nit were natural language using an n-gram model. This ap-\nproach has been extended to neural language models for\nsource code (White et al., 2015). Lastly, Cummins et al. use\nneural networks to mine online code repositories to auto-\nmatically synthesize applications (Cummins et al., 2017).\n7. Conclusion and Future Work\nComputer architects have long exploited the beneﬁts of\nlearning and predicting program behaviors to unlock con-\ntrol and data parallelism. The conventional approach of\ntable-based predictors, however, is too costly to scale for\ndata-intensive irregular workloads and showing diminishing\nreturns. The models described in this paper demonstrate\nsigniﬁcantly higher precision and recall than table-based\napproaches. This study also motivates a rich set of questions\nthat this initial exploration does not solve, and we leave\nthese for future research.\nWe have focused on a train-ofﬂine test-online model, using\nprecision and recall as evaluation metrics. A prefetcher,\nthrough accurate prefetching, can change the distribution of\ncache misses, which could make a static RNN model less\neffective. There are several ways to alleviate this, such as\nadapting the RNN online, however this could increase the\ncomputational and memory burden of the prefetcher. One\ncould also try training on hits and misses, however this can\nsigniﬁcantly change the distribution and size of the dataset.\nThere is a notion of timeliness that is also an important\nconsideration. If the RNN prefetches a line too early, it risks\nevicting data from the cache that the processor hasn’t used\nyet. If it prefetches too late, the performance impact of the\nrequest is minimal, as much of the latency cost of accessing\nmain memory has already been paid. One simple heuristic\nis to predict several steps ahead, instead of just the next step.\nThis would be similar to the behavior of stream prefetchers.\nFinally, the effectivenss of an RNN prefetcher must eventu-\nally be measured in terms of its performance impact within\na program. Ideally the RNN would be directly optimized\nfor this. This and the previous issues motivate the use of\nreinforcement learning techniques (Sutton & Barto, 1998)\nas a method to train these RNNs in dynamic environments.\nIndeed, modern microarchitectures also employ control sys-\n\nLearning Memory Access Patterns\ntems to control prefetcher aggressiveness, and this provides\nyet another area in which neural networks could be used.\nAdditionally, we have not evaluated the hardware design\naspect of our models. Correlation based prefetchers are\ndifﬁcult to implement in hardware because of their mem-\nory size. While it is unclear if RNNs can meet the latency\ndemands required for a hardware accelerator, neural net-\nworks also signiﬁcantly compress learned representations\nduring training, and shift the problem to a compute problem\nrather than a memory capacity problem. Given the recent\nproliferation of ML accelerators, this shift towards compute\nleaves us optimistic at the prospects of neural networks in\nthis domain.\nPrefetching is not the only domain where computer sys-\ntems employ speculative execution. Branch prediction is\nthe process of predicting the direction of branches that an\napplication will take. Branch target buffers predict the ad-\ndress that a branch will redirect control ﬂow to. Cache\nreplacement algorithms predict the best line to evict from a\ncache when a replacement decision needs to be made. One\nconsequence of replacing microarchitectural heuristics with\nlearned systems is that we can introspect those systems in\norder to better understand their behavior. Our t-SNE experi-\nments only scratch the surface and show an opportunity to\nleverage much of the recent work in understanding RNN\nsystems (Murdoch & Szlam, 2017; Murdoch et al., 2018).\nThe t-SNE results also indicate that an interesting view of\nmemory access traces is that they are a reﬂection of program\nbehavior. A trace representation is necessarily different from\ne.g., input-output pairs of functions, as in particular, traces\nare a representation of an entire, complex, human-written\nprogram. This view of learning dynamic behavior provides\na different path towards building neural systems that learn\nand replicate program behavior.\nReferences\nAyers, Grant, Ahn, Jung Ho, Kozyrakis, Christos, and\nRanganathan, Parthasarathy. Memory hierarchy for\nweb search. In IEEE International Symposium on\nHigh-Performance Computer Architecture , HPCA-IS ’18,\n2018.\nBengio, Yoshua, Ducharme, R ´ejean, Vincent, Pascal, and\nJauvin, Christian. A neural probabilistic language model.\nJournal of machine learning research , 3(Feb):1137–1155,\n2003.\nBlanton, Ronald D., Li, Xin, Mai, Ken, Marculescu, Diana,\nMarculescu, Radu, Paramesh, Jeyanandh, Schneider, Jeff,\nand Thomas, Donald E. Statistical learning in chip (slic).\nInProceedings of the IEEE/ACM International Confer-\nence on Computer-Aided Design , pp. 664–669, 2015.Charney, M. J. and Reeves, A. P. Generalized correlation-\nbased hardware prefetching. Technical Report EE-CEG-\n95-1, Cornell Univ., 1995.\nCummins, Chris, Petoumenos, Pavlos, Wang, Zheng, and\nLeather, Hugh. Synthesizing benchmarks for predictive\nmodeling. In CGO . IEEE, 2017.\nDuchi, John, Hazan, Elad, and Singer, Yoram. Adaptive\nsubgradient methods for online learning and stochastic\noptimization. Journal of Machine Learning Research , 12\n(Jul):2121–2159, 2011.\nFerdman, Michael, Adileh, Almutaz, Kocberber, Onur, V o-\nlos, Stavros, Alisafaee, Mohammad, Jevdjic, Djordje,\nKaynak, Cansu, Popescu, Adrian Daniel, Ailamaki, Anas-\ntasia, and Falsaﬁ, Babak. Clearing the clouds: A study\nof emerging scale-out workloads on modern hardware.\nInInternational Conference on Architectural Support for\nProgramming Languages and Operating Systems , 2012.\nGindele, J. D. Buffer block prefetching method. IBM\nTechnical Disclosure Bulletin , 20(2):696–697, July 1977.\nGolla, Robert and Jordan, Paul. T4: A highly threaded\nserver-on-a-chip with native support for heterogeneous\ncomputing. In Hot Chips 23 . IEEE Computer Soci-\nety Press, 2011. URL http://hotchips.org/\narchives/hot-chips-23 .\nGraves, Alex, Wayne, Greg, and Danihelka, Ivo. Neural\nturing machines. arXiv preprint arXiv:1410.5401 , 2014.\nGutierrez, Anthony, Dreslinski, Ronald G, Wenisch,\nThomas F, Mudge, Trevor, Saidi, Ali, Emmons, Chris,\nand Paver, Nigel. Full-system analysis and characteriza-\ntion of interactive smartphone applications. In Workload\nCharacterization (IISWC), 2011 IEEE International Sym-\nposium on , 2011.\nHashemi, Milad, Marr, Debbie, Carmean, Doug, and Patt,\nYale N. Efﬁcient execution of bursty applications. IEEE\nComputer Architecture Letters , 2016.\nHindle, Abram, Barr, Earl T, Su, Zhendong, Gabel, Mark,\nand Devanbu, Premkumar. On the naturalness of software.\nInInternational Conference on Software Engineering , pp.\n837–847. IEEE, 2012.\nHinton, Geoffrey, Deng, Li, Yu, Dong, Dahl, George E, Mo-\nhamed, Abdel-rahman, Jaitly, Navdeep, Senior, Andrew,\nVanhoucke, Vincent, Nguyen, Patrick, Sainath, Tara N,\net al. Deep neural networks for acoustic modeling in\nspeech recognition: The shared views of four research\ngroups. IEEE Signal Processing Magazine , 29(6):82–97,\n2012.\n\nLearning Memory Access Patterns\nHochreiter, Sepp and Schmidhuber, J ¨urgen. Long short-term\nmemory. Neural Computation , 9(8):1735–1780, 1997.\nIpek, Engin, Mutlu, Onur, Mart ´ınez, Jos ´e F, and Caruana,\nRich. Self-optimizing memory controllers: A reinforce-\nment learning approach. In International Symposium on\nComputer Architecture , 2008.\nJain, Akanksha and Lin, Calvin. Linearizing irregular mem-\nory accesses for improved correlated prefetching. In\nMICRO-46 , 2013.\nJim´enez, Daniel A. and Lin, Calvin. Dynamic branch predic-\ntion with perceptrons. In IEEE International Symposium\non High-Performance Computer Architecture , pp. 197–\n206, 2001.\nJoseph, Doug and Grunwald, Dirk. Prefetching using\nMarkov predictors. In International Symposium on Com-\nputer Architecture , 1997.\nJouppi, Norman. Improving direct-mapped cache perfor-\nmance by the addition of a small fully-associative cache\nand prefetch buffers. In International Symposium on\nComputer Architecture , 1990.\nKanev, Svilen, Darago, Juan Pablo, Hazelwood, Kim, Ran-\nganathan, Parthasarathy, Moseley, Tipp, Wei, Gu-Yeon,\nand Brooks, David. Proﬁling a warehouse-scale computer.\nInInternational Symposium on Computer Architecture ,\nISCA ’15, 2015.\nKingma, Diederik and Ba, Jimmy. Adam: A method for\nstochastic optimization. International Conference on\nLearning Representations , 2015.\nKozyrakis, Christos, Kansal, Aman, Sankar, Sriram, and\nVaid, Kushagra. Server engineering insights for large-\nscale online services. IEEE Micro , 30(4):8–19, July 2010.\nKraska, Tim, Beutel, Alex, Chi, Ed H, Dean, Jeffrey, and\nPolyzotis, Neoklis. The case for learned index structures.\narXiv preprint arXiv:1712.01208 , 2017.\nLai, An-Chow, Fide, Cem, and Falsaﬁ, Babak. Dead-block\nprediction and dead-block correlating prefetchers. In In-\nternational Symposium on Computer Architecture , 2001.\nLuk, Chi-Keung, Cohn, Robert, Muth, Robert, Patil, Harish,\nKlauser, Artur, Lowney, Geoff, Wallace, Steven, Reddi,\nVijay Janapa, and Hazelwood, Kim. Pin: Building cus-\ntomized program analysis tools with dynamic instrumen-\ntation. In Proceedings of the 2005 ACM SIGPLAN Con-\nference on Programming Language Design and Imple-\nmentation , pp. 190–200, 2005.\nLuong, Thang, Sutskever, Ilya, Le, Quoc V ., Vinyals, Oriol,\nand Zaremba, Wojciech. Addressing the rare word prob-\nlem in neural machine translation. In Association for\nComputational Linguistics , pp. 11–19, 2015.Maaten, Laurens van der and Hinton, Geoffrey. Visualizing\ndata using t-sne. Journal of machine learning research , 9\n(Nov):2579–2605, 2008.\nMaddison, Chris and Tarlow, Daniel. Structured generative\nmodels of natural source code. In International Confer-\nence on Machine Learning , pp. 649–657, 2014.\nMikolov, Tomas, Karaﬁ ´at, Martin, Burget, Lukas, Cernock `y,\nJan, and Khudanpur, Sanjeev. Recurrent neural network\nbased language model. In Interspeech , volume 2, pp. 3,\n2010.\nMikolov, Tomas, Sutskever, Ilya, Chen, Kai, Corrado,\nGreg S, and Dean, Jeff. Distributed representations of\nwords and phrases and their compositionality. In Ad-\nvances in Neural Information Processing Systems , pp.\n3111–3119, 2013.\nMnih, Andriy and Hinton, Geoffrey E. A scalable hierar-\nchical distributed language model. In Advances in neural\ninformation processing systems , pp. 1081–1088, 2009.\nMurdoch, W. James and Szlam, Arthur. Automatic rule\nextraction from long short term memory networks. Inter-\nnational Conference on Learning Representations , 2017.\nMurdoch, W. James, Liu, Peter J., and Yu, Bin. Beyond\nword importance: Contextual decomposition to extract\ninteractions from LSTMs. International Conference on\nLearning Representations , 2018.\nNesbit, Kyle J. and Smith, James E. Data cache prefetch-\ning using a global history buffer. In IEEE International\nSymposium on High-Performance Computer Architecture ,\n2004.\nOord, Aaron Van, Kalchbrenner, Nal, and Kavukcuoglu,\nKoray. Pixel recurrent neural networks. In International\nConference on Machine Learning , pp. 1747–1756, 2016a.\nOord, Aaron van den, Dieleman, Sander, Zen, Heiga, Si-\nmonyan, Karen, Vinyals, Oriol, Graves, Alex, Kalch-\nbrenner, Nal, Senior, Andrew, and Kavukcuoglu, Ko-\nray. Wavenet: A generative model for raw audio. arXiv\npreprint arXiv:1609.03499 , 2016b.\nPalacharla, Subbarao and Kessler, R. E. Evaluating stream\nbuffers as a secondary cache replacement. In Interna-\ntional Symposium on Computer Architecture , 1994.\nPeled, Leeor, Mannor, Shie, Weiser, Uri, and Etsion, Yoav.\nSemantic locality and context-based prefetching using\nreinforcement learning. In International Symposium on\nComputer Architecture , 2015.\nRoth, Amir, Moshovos, Andreas, and Sohi, Gurindar S.\nDependence based prefetching for linked data structures.\n\nLearning Memory Access Patterns\nInInternational Conference on Architectural Support for\nProgramming Languages and Operating Systems , 1998.\nSomogyi, Stephen, Wenisch, Thomas F., Ailamaki, Anas-\ntassia, Falsaﬁ, Babak, and Moshovos, Andreas. Spatial\nmemory streaming. In International Symposium on Com-\nputer Architecture , 2006.\nSPEC CPU2006 . The Standard Performance Evaluation\nCorporation, 2006. http://www.specbench.org/.\nSutskever, Ilya, Vinyals, Oriol, and Le, Quoc V . Sequence\nto sequence learning with neural networks. In Advances\nin neural information processing systems , pp. 3104–3112,\n2014.\nSutton, Richard S and Barto, Andrew G. Introduction to re-\ninforcement learning , volume 135. MIT press Cambridge,\n1998.\nTeam, PaX. Pax address space layout randomization (aslr).\n2003.\nWhite, Martin, Vendome, Christopher, Linares-V ´asquez,\nMario, and Poshyvanyk, Denys. Toward deep learning\nsoftware repositories. In Mining Software Repositories ,\npp. 334–345. IEEE, 2015.\nWulf, Wm. and McKee, Sally. Hitting the memory wall:\nImplications of the obvious. ACM Computer Architecture\nNews , 1995.\nZaremba, Wojciech and Sutskever, Ilya. Learning to execute.\narXiv preprint arXiv:1410.4615 , 2014.\nZeng, Yuan. Long short term based memory hardware\nprefetcher. International Symposium on Memory Systems ,\nOctober 2017.\n\nLearning Memory Access Patterns\nAppendix\nA. Interpreting t-SNE Plots\nBy mapping PCs back to source code, we observe that the\nmodel has learned about program structure. We show ex-\namples from two of the most challenging SPEC CPU2006\napplications to learn, mcfandomnetpp .\nA.1. mcf\nThe following function from mcfappears in two different\nt-SNE clusters:\n1 while ( node )\n2 {\n3 if( node->orientation == UP )\n4 node->potential = node->\nbasic_arc->cost + node->pred->potential\n;\n5 else /*== DOWN */\n6 {\n7 node->potential = node->pred->\npotential - node->basic_arc->cost;\n8 checksum++;\n9 }\n10 tmp = node;\n11 node = node->child;\n12 node = tmp;\n13\n14 while ( node->pred )\n15 {\n16 tmp = node->sibling;\n17 if( tmp )\n18 {\n19 node = tmp;\n20 break ;\n21 }\n22 else\n23 node = node->pred;\n24 }\n25 }\n26\nOne cluster contains only different instances of line 4, un-\nrolled into three different instructions at three different PCs.\nWe show the line of code, followed by the assembly code in\n(PC: Instruction) format:\nnode->potential = node->basic_arc->cost\n+ node->pred->potential;\n401932: mov 0x18(%rdx),%rsi\n401888: mov 0x18(%r10),%rsi\n4018df: mov 0x18(%r11),%rsi\nA second cluster identiﬁes only the PCs responsible for the\nlinked list traversal, at lines 11 and 16:node = node->child;\n401878: mov 0x10(%rdx),%r10\n40187c: mov %rcx,(%rdx)\ntmp = node->sibling;\n4019a2: mov 0x20(%r9),%rcx\nA.2. omnetpp\nWe show the result of running t-SNE on the learned ( \u0001, PC)\nembeddings of omnetpp in Figure 8.\nFigure 8. A t-SNE visualization of the concatenated ( \u0001,PC) em-\nbeddings on omnetpp colored according to PC instruction.\n\nLearning Memory Access Patterns\nExamining some of the clusters closely, we ﬁnd interesting\npatterns. The following code inserts and removes items into\nan owner’s list:\n1 // remove from owner’s child list\n2 if(ownerp!=NULL)\n3 {\n4 if(nextp!=NULL)\n5 nextp->prevp = prevp;\n6 if(prevp!=NULL)\n7 prevp->nextp = nextp;\n8 if(ownerp->firstchildp== this )\n9 ownerp->firstchildp = nextp;\n10 ownerp = NULL;\n11 }\n12 // insert into owner’s child list as\nfirst elem\n13 if(newowner!=NULL)\n14 {\n15 ownerp = newowner;\n16 prevp = NULL;\n17 nextp = ownerp->firstchildp;\n18 if(nextp!=NULL)\n19 nextp->prevp = this ;\n20 ownerp->firstchildp = this ;\n21 }\n22\nThe main insertion and removal path are both shown in the\nsame t-SNE cluster:\n// Removal\nnextp->prevp = prevp;\n448a6a: mov 0x20(%rbx),%r12\n448a6e: mov %r12,0x20(%r10)\n//Insertion\nnextp = ownerp->firstchildp;\n44c23a: mov 0x30(%rax),%r13\n44c23e: mov %r13,0x28(%r12)\nomnetpp ’s t-SNE clusters also contain many examples of\ncomparison code from very different source code ﬁles that\nare used as search statements being mapped to the same\nt-SNE cluster. Since these comparators are long, they get\ncompiled to many different assembly instructions, so we\nonly show the source code below. Lines 3 and 17 are both\nmapped to the same t-SNE cluster among other similar\ncomparators:1 cObject *cArray::get( int m)\n2 {\n3 if(m>=0 && m<=last && vect[m])\n4 return vect[m];\n5 else\n6 return NULL;\n7 }\n8\n9 void cMessageHeap::shiftup( int from){\n10 // restores heap structure (in a\nsub-heap)\n11 int i,j;\n12 cMessage *temp;\n13\n14 i=from;\n15 while ((j=2 *i) <= n)\n16 {\n17 if(j<n && ( *h[j] > *h[j+1])) //\ndirection\n18 j++;\n19 if(*h[i] > *h[j]) //is change\nnecessary?\n20 {\n21 temp=h[j];\n22 (h[j]=h[i])->heapindex=j;\n23 (h[i]=temp)->heapindex=i;\n24 i=j;\n25 }\n26 else\n27 break ;\n28 }\n29 }\n30\nB. Experimental Results\nThe experimental results for precision/recall are given in\nTable 2/Table 3 respectively.\nC. LSTM Hyperparameters\nThe hyperparameters for both LSTM models are given in\nTable 4\nD. K-Means Clustering on an Address Trace\nIn Figure 9 we show the results of running k-means with 6\nclusters on 106addresses from omnetpp .\n\nLearning Memory Access Patterns\nTable 2. Experimental Results: Precision\nDataset Stream GHB Embedding Kmeans Only PCs Only Deltas\nbwaves 0.65 0.07 0.89 0.93 0.89 0.89\ngems 0.61 0.05 0.76 0.82 0.76 0.59\nleslie3d 0.72 0.21 0.99 0.80 0.99 0.93\nlibquantum 0.99 0.99 0.99 0.99 0.99 0.99\nsoplex 0.68 0.18 0.73 0.83 0.73 0.70\nsphinx3 0.72 0.08 0.97 0.81 0.96 0.86\nastar 0.34 0.25 0.60 0.51 0.60 0.32\nlbm 0.0001 0.0001 0.99 0.59 0.99 0.99\nmcf 0.0001 0.18 0.33 0.45 0.33 0.28\nmilc 0.0001 0.02 0.56 0.82 0.56 0.56\nomnetpp 0.08 0.06 0.63 0.53 0.62 0.51\nwebsearch 0.1 0.12 0.43 0.55 0.41 0.41\nGeometric Mean 0.11 0.06 0.70 0.69 0.70 0.61\nTable 3. Experimental Results: Recall\nDataset Stream GHB Embedding Kmeans Only PCs Only Deltas\nbwaves 0.86 0.38 0.10 0.93 0.05 0.06\ngems 0.83 0.36 0.20 0.85 0.04 0.20\nleslie3d 0.87 0.41 0.99 0.80 0.38 0.98\nlibquantum 0.99 0.99 1.00 1.00 1.00 1.00\nsoplex 0.95 0.41 0.14 0.83 0.14 0.14\nsphinx3 0.89 0.30 0.57 0.81 0.46 0.58\nastar 0.55 0.51 0.15 0.59 0.03 0.15\nlbm 0.98 0.61 1.00 0.82 0.98 0.98\nmcf 0.21 0.31 0.13 0.50 0.12 0.13\nmilc 0.21 0.05 0.10 0.82 0.001 0.04\nomnetpp 0.64 0.22 0.19 0.59 0.18 0.19\nwebsearch 0.57 0.20 0.32 0.59 0.23 0.27\nGeometric Mean 0.72 0.39 0.27 0.75 0.12 0.24\nTable 4. Training hyperparameters for each model.\nEmbedding Network Size 128x2 LSTM\nLearning Rate .001\nNumber of Train Steps 500k\nSequence Length 64\nEmbedding Size 128\nClustering Network Size 128x2 LSTM\nLearning Rate .1\nNumber of Train Steps 250k\nSequence Length 64\nNumber of Centroids 12\n\nLearning Memory Access Patterns\nFigure 9. One million memory accesses from omnetpp after running k-means clustering on the address space.",
  "textLength": 50833
}