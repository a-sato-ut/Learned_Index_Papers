{
  "paperId": "53ec4dbe733e8ceebfa00fb06f68d0ffaed16e3d",
  "title": "Strategic Facility Location via Predictions",
  "pdfPath": "53ec4dbe733e8ceebfa00fb06f68d0ffaed16e3d.pdf",
  "text": "arXiv:2410.07497v1  [cs.GT]  10 Oct 2024Strategic Facility Location via Predictions\nQingyun Chen∗Nick Gravin†Sungjin Im‡\nAbstract\nThe facility location with strategic agents is a canonical problem in the literature on mecha-\nnism design without money. Recently, Agrawal et. al. [ ABG+22] considered this problem in the\ncontext of machine learning augmented algorithms, where the mech anism designer is also given\na prediction of the optimal facility location. An ideal mechanism in this f ramework produces an\noutcome that is close to the social optimum when the prediction is acc urate (consistency) and\ngracefully degrades as the prediction deviates from the truth, wh ile retaining some of the worst-\ncase approximation guarantees (robustness). The previous wor k only addressed this problem\nin the two-dimensional Euclidean space providing optimal trade-oﬀs between robustness and\nconsistency guarantees for deterministic mechanisms.\nWe consider the problem for generalmetric spaces. Our only assumption is that the metric\nis continuous, meaning that any pair of points must be connected by a continuous shortest path.\nWe introduce a novel mechanism that in addition to agents’ reporte d locations takes a predicted\noptimal facility location ˆ o. We call this mechanism Harmonic , as it selects one of the reported\nlocations ˜ℓiwith probability inversely proportional to d(ˆo,˜ℓi)+∆ for a constant parameter ∆.\nWhileHarmonic mechanismisnottruthful, wecan characterize the set of undominated strategies\nfor each agent ias solely consisting of the points on a shortest path from their true location\nℓito the predicted location ˆ o. We further derive consistency and robustness guarantees on the\nPrice of Anarchy (PoA) for the game induced by the mechanism. Speciﬁcally, assuming that\n∆ =ε\n2n·/summationtext\ni∈[n]d(ˆo,ℓi) is closely related to the average distance to the predicted location ˆo, our\nconsistency guarantee is arbitrarily close to optimum (PoA is 1+ ε), while having a constant\nrobustness guarantee(PoA is O(1+1/ε3) in general and is O(1+1/ε2) for strictly convex metric\nspaces). We also show that for a constant number of agents n=O(1),Harmonic (∆) mechanism\nwith ∆ = 0 attains 1-consistency and O(1)-robustness.\n1 Introduction\nThe facility location is a canonical problem attracting a lo t of interest in many diﬀerent ﬁelds\nsuch as operation research, artiﬁcial intelligence, socia l choice, and economics [ CFL+21]. Facility\nlocation with strategic customers serves as an exemplary se tting of the approximate mechanism\ndesignwithoutpayments thathasbeenextensively studiedi nthepastﬁfteenyears[ PT13,AFPT10 ,\nLSWZ10 ,EGN+11,FW13,FT10,FT14,FT16,SV16,PWZ18,Wal20,ALSW22 ].\nIn the case of a single facility, the problem involves nagents residing in a metric space M,\neach agent iwith their own most preferred location ℓi∈Mof the single facility f∈M. The\nagents are strategic and may misreport their location hopin g to inﬂuence the ﬁnal choice of the\n∗Electrical Engineering and Computer Science, University o f California, 5200 N. Lake Road, Merced CA 95344.\nqchen41@ucmerced.edu .\n†Key Laboratory of Interdisciplinary Research of Computati on and Economics, Shanghai University of Finance\nand Economics, Shanghai, China. anikolai@mail.shufe.edu.cn .\n‡Electrical Engineering and Computer Science, University o f California, 5200 N. Lake Road, Merced CA 95344.\nsim3@ucmerced.edu .\n1\n\nfacilityf∈Mand minimize their personal cost given by the distance d(ℓi,f). The central planner\ncollects reported locations from the agents and then decide s where to open the facility. For the\nmost common objective, a.k.a., social cost minimization, t he goal is two-fold: ﬁrst, the outcome\nshould be a good approximation for minimizing the average di stance from the facility to all agents\nif not the optimum; and second, no agents should have an incen tive to misreport their true location.\nThe traditional approach to this problem aims to ﬁnd mechani sms with worst-case performance\nguarantees on all possible inputs. This approach has been cr iticized in a broader context of algo-\nrithm design for its often pessimistic bounds and its focus o n adversarial instances, which are not\nfrequently encountered in practice [ Rou21]. To overcome the practical shortcomings of traditional\nalgorithms, Lykouris and Vassilvitskii [ LV21] have recently introduced a powerful framework of ma-\nchine learning augmented algorithms . ML augmented algorithms strive to surpass the limitations\nof traditional algorithms by incorporating predictions as supplementary input. These algorithms\nare supposed to do very well when furnished with accurate pre dictions (consistency guarantee),\nwhile gracefully degrading in performance as prediction qu ality declines. Ideally, they also uphold\nrobust guarantees for all predictions, ensuring reliabili ty even in the face of imperfect forecasts\n(robustness guarantee). ML augmented algorithms have foun d applications in strengthening online\nand streaming algorithms with predictions about future unk nown input, as well as in accelerat-\ning algorithms by utilizing knowledge gleaned from past inp uts. See [ MV22] for a survey of ML\naugmented algorithms.\nVery recently, there has been a surge of interest in applying ML augmented framework to mech-\nanism design [ XL22,GKST22 ,BGT23,CSV24,BGS24] pioneered by Agrawal et al. [ ABG+22].\nTheir work speciﬁcally addresses the strategic facility lo cation problem in two-dimensional Eu-\nclidean spaceM=R2. To illustrate the setting, consider the following example s:\nExample 1. A group of n= 100people (say alumni from the same school) want to decide on\na meeting place (e.g., for the school reunion). Before askin g people about their preferred meeting\nlocation, the meeting planner may already have a good idea ab out how many people still live near\nthe school and how many will be coming from a greater city area ; thus the planner could predict\nwhich spot might work well for everyone (either somewhere cl ose to the school, or a well accessible\nplace in the city center).\nExample 2. A city wants to open a new government oﬃce to serve the public. The city likely\npossesses extensive data on residents, thus can ﬁnd a good ca ndidate location. Alternatively, it\nmight opt for a central location as a likely near-optimal sol ution, even without in-depth analysis.\nThesekindsof scenarios areneatly capturedbythemodelof [ ABG+22], whichassumesaccess to\na prediction of the optimal location obtained via machine-l earning algorithm, or other means. This\nassumption about the output (and not the input)1is particularly well suited for the mechanism\ndesign scenario in which it is usually diﬃcult to accurately predict the input from all nagents.\nAgrawal et al. [ ABG+22] demonstrate that it is possible to design a strategy-proof mechanism\nthat is arbitrarily close to the optimal solution in the two- dimensional setting, provided access to\na quality prediction of the facility location. This is a sign iﬁcant advancement, as previously only a√\n2-approximate strategy-proof mechanism was known for this setting without predictions. Their\nmechanism builds upon a well known coordinate-wise median- point mechanism for low dimensional\nEuclidean spaces Rd: the predicted location ˆ o∈R2gets a certain weight c∈[0,1] and is added to\nthe agents’ reports, the output is given by the coordinate-w ise median. Theparameter cis based on\nthe expected quality of predictions: if the mechanism desig ner anticipates high-quality predictions,\n1It is common in the ML augmented algorithms literature to hav e predictions about algorithm’s input rather than\noutput.\n2\n\nthey can set theparameter cclose to 1, resultinginanearly 1-consistent (nearly optim al) algorithm.\nSpeciﬁcally, the algorithm is (1+ r)- consistent and g(r)-robust2, wherer(c)∈(0,∞) is a control-\nparameter that governs a trade-oﬀ between consistency and r obustness and g(r)≈1√\n2ris a function\ntending to inﬁnity as r→0. I.e., when prediction is extremely inaccurate, the algor ithm maintains\na constant approximation guarantee for any ﬁxed value of r, ensuring a robust solution quality.\nThese consistency and robustness guarantees are best possi ble among all anonymous deterministic\nmechanisms [ ABG+22].\nIn this paper, we seek to investigate if the facility locatio n problem continues to beneﬁt from\npredictions even in the generalmetric setting. We ask\nHow to use ML augmented advice in general metric spaces M?\n1.1 Challenges\nWe discuss two primary approaches considered in the literat ure and the diﬃculties in extending\nthem to the general metric space with predictions.\nMedian-point like mechanisms. The median-point mechanism is perhaps the most common\napproach for the facility location game. It assumes that the locations are in the (low-dimensional)\nEuclidean space and computes the median of the reported loca tions along each coordinate. The\nalgorithm is strategyproof, and it is optimum for the single dimensional Euclidean space [ PT13]\nand√\n2-approximate for the two dimensional Euclidean space [ GHC23]. However, the only known\napproximation guarantee of the coordinate-wise median is O(√\nd) for the Euclidean norm in Rd\nspaces, and the mechanism is inapplicable in general metric spaces. In fact, it is known that any\ndeterministic mechanism is Ω( n) factor oﬀ the optimum even in a circle metric [ SV02]. Hence, the\napproach of Agrawal et al. [ ABG+22] is only limited to low dimensional Euclidean spaces and doe s\nnot extend to general metrics.\nRandom Dictatorship. Understanding mechanism design in general metric spaces pr esents\nsigniﬁcant challenges, as evidenced by the limited researc h conducted in this area (see a sur-\nvey [CFL+21]). Indeed, any mechanism with a sublinear in napproximation guarantee must be\nrandomized [ SV02]. The only known O(1)-approximation strategyproof mechanism that works for\ngeneralMisRandom Dictatorship (RD), which chooses one of the reported locations uniformly at\nrandom. RDis a 2(1−1/n)-approximation [ AFPT09 ]. There are a few characterization results of\nstrategyproof mechanisms for special metrics M(such as trees, or cycles) [ DFMN12 ,MLL+21].\nAlso there is a characterization of group-strategyproof me chanisms [ TYZ20] in strictly convex\nspaces, which can only give Ω( n) approximation to the optimal social cost. Unfortunately, these\nresults do not oﬀer any new mechanisms that can work in general metric spaces. On the positive\nside, the ML augmented framework oﬀers a richer space of possi ble mechanisms by adding extra\ninformation about the predicted location to the input. On th e negative side, there are still funda-\nmental roadblocks to having good strategyproof ML augmente d mechanisms, which are discussed\nbelow.\nPossible Mechanisms. First, it is reasonable to restrict attention to randomized mechanisms\nthat select facility ffrom a distribution over reported locations ℓand the predicted location ˆ o, as\nwe may not even know which other points general Mmay or may not have. This is still a rich\nfamily of mechanisms as each selection probability {gi(·)}i∈[n+1]may depend on O(n2) pairwise\ndistances. Unfortunately, we do not know any strategyproof mechanisms of such form beyond RD\n2In general, an algorithm is α-consistent and β-robust if it is an α-approximation when the prediction is perfect\nand aβ-approximation for arbitrary predictions.\n3\n\nand for a good reason: each agent controls nvariables with many degrees of freedom in general\nM; manipulations by a single agent may aﬀect all gjforj∈[n+1] in a rather complex way even\nfor simple and well-behaved functions {gi(·)}i∈[n+1]. One can still have a strategyproof mechanism\nby choosing ffrom a ﬁxed distribution over reported locations ℓand predicted optimal location\nˆo. However, if Pr[f←ˆo] is not a constant independent of n, then we do not get any interesting\nconsistency guarantees. On the other hand, if ˆ ois very far from each reported location ℓi, then we\ndo not get any robustness guarantee.\nA more reasonable attempt to balance consistency and robust ness is to combine RDmechanism\nwith a selection of ˆ oby letting agents vote on two alternative outcomes: RD(ℓ) or ˆo. This approach,\nhowever, has its own problems that can be illustrated with ou r previous example of ﬁnding a\nmeeting place for n= 100 alumni (Example 1). Imagine that a single person i∗∈[n] is on vacation\nat a remote tropical island in another country at the time of t he meeting, while the remaining 99\npeople are all in town. Although the RDmechanism selects i∗only with a small 1% probability,\nit is still incredibly inconvenient for anyone else. We can t hink ofi∗as an adversarial agent, who\ndoes not care about the outcome, but still has a unilateral po wer to sabotage the outcome of RD(ℓ)\nfor everyone else and make it arbitrarily worse than the pred icted location ˆ o. Thus any approach\ninvolving voting on two alternatives RD(ℓ) or ˆomust give each agent a unilateral power to impose\nˆooutcome. This leads to Consensus Mechanism : the outcome is a predicted location ˆ o, unless all\nagents agree on RD(ℓ) outcome. The consensus mechanism has perfect 1-consisten cy, since at least\none agent must prefer ˆ ooverRD(ℓ) when ˆois the optimal location. It also has a constant robustness\nguarantee for a small number of agents n=O(1) (e.g., n= 3), since (i) in the case when at least\none agent prefers ˆ ooverRD(ℓ), the prediction is a constant approximation to the optimum , and\notherwise (ii) RD(ℓ) is a 2(1−1/n)-approximation to the optimum [ AFPT09 ].\nUntruthful Mechanisms. It turns out that the consensus mechanism is not strategypro of. E.g.,\nif one agent islightly prefers ˆ ooverRD(ℓ) and everyone else strongly prefers RD(ℓ), then one of\nthe agents j∝\\e}atio\\slash=imay greatly beneﬁt by reporting a closer location /tildewideℓjtoℓiand thus convince\nito choose RD(ℓ-j,/tildewideℓj) rather than ˆ o. On the other hand, any selﬁsh deviation /tildewideℓi∝\\e}atio\\slash=ℓiby agent\nimay only improve the outcome for all other agents3. I.e., non truthful mechanisms do not\nnecessarily lead to bad outcomes in facility location games and thus should not be excluded from\nconsideration. Furthermore, while the literature on strat egic facility location is primarily concerned\nwith truthful mechanisms, other areas of mechanism design h ave encountered a fair number of non\ntruthfulmechanisms, e.g., ﬁrst-priceorpositionauction sinrevenuemaximization settings. Forsuch\nmechanisms, a standard approach is to analyse the equilibri a of the ensuing game and establish\ngood Price of Anarchy (PoA) bounds (e.g., [ CKK+15]).\n1.2 Our Contributions\nWhile the consensus mechanism suggests that positive resul ts are possible in ML augmented frame-\nwork, it does not provide a satisfactory solution for the mos t interesting case, when the number of\nagentsnis large. Indeed, its robustness guarantee of Ω( n) scales linearly with n(e.g., when one\nagentiis located exactly at the prediction ℓi= ˆoand all other agents stay at the same far away\nlocation ℓj=P∈Mfor allj∝\\e}atio\\slash=i) and it does not allow for any trade-oﬀs between consistency a nd\nrobustness guarantees.\nIn this paper, we propose a novel mechanism, which we term Harmonic and which to the best\nof our knowledge has not been considered before. The mechani sm chooses a reported location\n/tildewideℓi∈{/tildewideℓ1,...,/tildewideℓn}with a probability inversely proportional to its distance d(/tildewideℓi,ˆo) to the predicted\n3Any such deviation would make everyone prefer RD(ℓ-i,/tildewideℓi) over ˆo.\n4\n\nlocation ˆ oplus a constant ∆, i.e., Pr[f←/tildewideℓi] is proportional to 1 /(d(ˆo,/tildewideℓi)+∆). The intuition for\nthe inversely proportional selection rule is to penalize ag ents for reporting remote locations to be\nmore robust against manipulations by adversarial agents4. The parameter ∆ allows us to balance\nconsistency and robustness guarantees: smaller ∆ means bet ter consistency and makes Harmonic\nresemble the consensus mechanism, while larger ∆ brings Harmonic closer to the RDmechanism.\nThe hope is that if the predicted optimal location ˆ ois close to accurate, then many agents should\nbeneﬁt by shifting their reports closer to ˆ o(agentigets a higher chance of being selected at the\nreported location /tildewideℓiat the cost of higher distance to their true location d(ℓi,/tildewideℓi)). On the other\nhand, when prediction ˆ ois highly inaccurate, the hope is that only a few agents decid e to move\ncloser to ˆ oand we get a good robustness guarantee. This is also the situa tion where the constant\nparameter ∆ helps to reduce the impact of a single agent on the mechanism’s outcome.\nResults. First, while Harmonic is not strategy-proof, we show that it signiﬁcantly limits t he\nagents’ undominated action space — in a good direction. Spec iﬁcally, the best response of each\nagentiis to report her preferred location, ℓior the predicted location, ˆ o, or any point on the\nshortest path between ℓiand ˆo, when she is indiﬀerent between ℓiand ˆo. In other words, each\nagent can only choose from the shortest paths between her pre ferred location and the predicted\nlocation. We then prove that Pure Nash Equilibrium (PNE) alw ays exists via Kakutani’s ﬁxed-\npoint theorem (Section 3.2). The only assumption we use is that every pair of points in th e metric\nspace is connected by a continuous shortest path. This is a ra ther mild assumption, as one can\neasily embed a given discrete metric into a continuous one by taking a convex combination over the\npoints in the space. In particular, for any discrete metric M, one can simply extend the metric to\nMby adding a continuous shortest path between each pair of dis crete points.\nSecond, weanalysethePriceofAnarchy(PoA)oftheensuingg ameinducedbythe Harmonic (∆)\nmechanism. Weassumethat thetrade-oﬀparameter∆ = c·aisrelated totheaverage distance adef==\n1\nn/summationtext\ni∈[n]d(ˆo,ℓi) to the prediction ˆ ofor a constant c. When predicted location ˆ oisγ-approximation\nto the optimum, Harmonic isγ(1 + 2c)-consistent (Theorem 4.1). On the robustness side, we\nshow that Harmonic isO(1+1/c3)-robust (Theorem 4.10) in general, and give a better robustness\nguarantee of O(1+1/c2), if the metric is strictly convex (Theorem 4.6). I.e., for a small constant\nc=ε/2 we achieve (1 + ε)-consistency that smoothly degrades with the prediction’ s accuracy,\nand respectively O(1 + 1/ε3) andO(1 + 1/ε2) robustness5. Furthermore, if ∆ = 0, we obtain\nO(n)-robustness (Theorem 4.14) and 1-consistency, which translates into a constant robus tness\nand 1-consistency for a constant n=O(1) number of agents (see the discussion in the full version) .\n1.3 Other Related Work\nMechanism design without payments often falls short of prod ucing the optimal solution, lead-\ning to potentially suboptimal results. Agrawal et al. [ ABG+22] initiated the application of ma-\nchine learning-augmented algorithms in this ﬁeld to overco me these limitations. For the utilitarian\nobjective of minimizing the average distance of agents to th e facility, their algorithm achieves√\n2c2+2/(1+c)-consistency and√\n2c2+2/(1−c)-robustness in the two-dimensional space, where\n4Recall a major issue of RD(ℓ): a single adversarial agent can make everyone’s expected c ost arbitrarily large.\nWith an inversely proportional rule, reporting a remote loc ation has a bounded impact on the expected cost of any\nagent.\n5Note that our consistency/robustness guarantees rely on th e trade-oﬀ parameter ∆. I.e., we rely on the ap-\nproximately correct estimation of the average distance a, which is arguably not a very strong assumption on the\nsetting ( ais a single number with simple dependencies on each agent’s i ndividual location ℓi). Also note that, if\n∆ is underestimated (∆\na=o(ε)), then we get better consistency and worse robustness; and if ∆ is overestimated (\n∆\na=ω(ε)), then we get better robustness.\n5\n\nc∈[0,1) is a parameter to be chosen by the mechanism. As mentioned b efore, a√\n2-approximate\nstrategy-proof mechanism is known and it is thebest possibl ewithoutpredictions [ GHC23]. For the\negalitarian social cost of minimizing the maximum distance to the facility, Agrawal et al. [ ABG+22]\npresented an algorithm with 1-consistency and 1+√\n2-robustness. For this setting, a 2-approximate\nstrategy-proof mechanism is known without predictions [ AFPT10 ,GHC23]. A very recent work\n[BGS24] studies randomized algorithms in one-dimensional and two -dimensional settings. For the\nobnoxious version of maximizing the total distance to the ob noxious facility with predictions, Is-\ntrate and Bonchis recently considered various metrics such as circles, trees, and one-dimensional\nand two-dimensional hypercubes [ IB22].\nVery recently, an ML augmented mechanism was developed for t hek-facility location game in\ngeneral metric spaces [ BGTC24 ]. However, it assumes predictions for each point, requires assigning\npoints to facilities in a balanced manner, and does not provi de an absolute robustness guarantee.\nFacility location problems have been studied (without pred ictions) for various metrics. See\n[AFPT10 ] for general metrics, [ AFPT10 ,Mei19] for circles, [ AFPT10 ,FW13] for trees, and [ Mei19,\nWal20,GHC23,EMFGH23 ] ford-dimensional Euclidean spaces. For characterization of th e space\nof startgy-proof mechanisms, see [ Mou80] and [PvdSS93 ], which consider the one-dimensional and\ntwo-dimensional spaces, respectively.\nFor the obnoxious version of maximizing the total distance t o the obnoxious facility with pre-\ndictions, Istrate and Bonchis recently considered various metrics such as circles, trees, and one-\ndimensional and two-dimensional hypercubes [ IB22].\nMachine learning augmented algorithms have found other app lications in mechanism design\nwithout payments. For the unrelated machine makespan minim ization problem, Balkanski et al.\ngave aO(1)-consistent and O(n)-robust algorithm, which asymptotically matches the best pos-\nsible worst-case bound [ NR99,CKK23]. Gkatzelis et. al. [ GKST22 ] revisited scheduling games\nand network formation games, demonstrating that leveragin g predictions can improve the price of\nanarchy.\nIn parallel to Agrawal et al. [ ABG+22], Xu and Lu [ XL22] studied several mechanism design\nproblems, some of which involve payment (single item auctio n and frugal path auction) and some\nnot (truthful job scheduling and two facility game on a line) . Notably, they gave a mechanism that\nis (1+n/2)-consistent and (2 n−1)-robust for the two facility location game on a line.\nFurthermore, ML augmented algorithms have found broader ap plications in online algorithms.\nGiven the extensive literature on this topic, we only provid e a few sample examples: paging\n[LV21], data structures [ KBC+18,Mit18], knapsack [ IKQP21], load balancing [ LLMV20 ], schedul-\ning [PSK18], rent-or-buy [ PSK18], graph problems [ APT22], covering problems [ BMS20], facility\nlocation problems with no private information [ FGGP21 ,JLL+21], online learning [ BCKP20 ], and\nfair allocations [ BGGJ22 ,BGH+23]. They have also been eﬀectively used to speed up oﬄine algo-\nrithms, e.g. min-cost bipartite matching [ DIL+21] and shortest paths [ LSV23,FS21].\n1.4 Roadmap\nIn Section 2, we deﬁne the problem and our Harmonic mechanism. In Section 3, we discuss the\nundominated strategies and equilibria concepts. In Sectio n4we give analysis of our mechanism,\nproviding consistency and robustness bounds. In Section 5we conclude our paper. Due to the\nspace constraints, most proofs are deferred to the full vers ion of this paper.\n6\n\n2 Preliminaries\nIn a (single) facility location problem the goal is to place a facilityfin a given metric space M\nwith a distance function d:M×M→ Rto serve a set of nagents. Each agent i∈[n] has a most\npreferred location ℓi∈Mand incurs a cost of d(f,ℓi), when the facility is placed at f∈M. The\nobjective is to minimize the social cost SC(f,ℓ)def==/summationtext\ni∈[n]d(f,ℓi). The optimal cost is achieved\nby facility o, i.e.,opt(ℓ) = min o′∈M/summationtext\ni∈[n]d(o′,ℓi) =/summationtext\ni∈[n]d(o,ℓi). The facility location fis an\nα-approximation if SC(f,ℓ)≤α·opt(ℓ).\nIn the strategic setting, the location ℓiis private information of each agent i∈[n], i.e.,imay\nreport a diﬀerent location /tildewideℓito the mechanism. The mechanism f:Mn→Mtakes the reported\nlocation vector /tildewideℓ= (/tildewideℓ1,/tildewideℓ2,...,/tildewideℓn) and outputs the facility f(/tildewideℓ). For notational convenience, we\nmay letfdenote the mechanism’s outcome. If the mechanism is randomi zed, then the outcome\nis a distribution π(M) of the facilities in M. We assume that agents are selﬁsh and rational,\ni.e., each agent itries to minimize their own expected cost, costidef==E[d(f,ℓi)] for the chosen\nfacilityf(/tildewideℓ-i,/tildewideℓi), whenireports/tildewideℓiand the remaining n−1 agents report /tildewideℓ-i. The mechanism is\ncalleddominant strategy incentive compatible (DSIC) if E[d(f(/tildewideℓi,ℓ-i),ℓi)]≥E[d(f(ℓ),ℓi)] for all\ni∈[n] and all ℓ∈Mn. E.g., a random dictatorship mechanism that selects an agen tiuniformly\nat random and lets ito place the facility at their preferred location ℓi, i.e.,f:Mn→π(M) is\ngiven by f∼uni{ℓ1,...,ℓn}, is a DSIC mechanism [ AFPT09 ]. On the other hand, a non-truthful\nmechanism induces a game among nagents. Similar to DSIC mechanisms, we assume that agents\nonly employ undominated strategies6(see Claim 3.3). We further assume that agents reach Nash\nEquilibrium /tildewideℓ∈NE(ℓ), i.e., at a given reported proﬁle /tildewideℓ= (/tildewideℓ1,...,/tildewideℓn) no agent iattains smaller\nexpected cost by a unilateral deviation ( /tildewideℓ′\ni,/tildewideℓ-i). The Price of Anarchy (PoA) of the mechanism\nf:Mn→π(M) is the worst-case ratio of the expected social cost attaine d at equilibrium and the\noptimal social cost.\nPoA(f)def== max\nℓ∈Mnmax\n/tildewideℓ∈NE(ℓ)E[SC(f(/tildewideℓ),ℓ)]\nopt(ℓ)(1)\nML Augmented Mechanism Design for Facility Location Problem. The mechanism de-\nsigner in addition to the reports /tildewideℓis given a prediction ˆ oof the optimum location o. Formally,\nthe mechanism is f(/tildewideℓ,ˆo) :Mn+1→π(M) (to emphasize the value of ∆ used, we may put it as\na subscript; we have f∆(·,·) in our case, where ∆ =c\nn·SC(ˆo,ℓ)). Consistency and robustness are\ntwo standard measures that describe the performance of an al gorithm with predictions [ LV21].\nTheconsistency captureshowwell thealgorithm performs, whenpredictioni scorrect (ˆ o=o(ℓ)):\nan algorithm (or a truthful mechanism) is α-consistent if it achieves an α-approximation to the\noptimum. In case of non truthful mechanisms, we say that a mec hanismf(/tildewideℓ,ˆo) isα-consistent if its\nprice of anarchy ( 1) is at most αon any instance ℓ∈Mnwhen ˆo=o(ℓ). It is often unreasonable\nto expect that the predicted solution ˆ ois 100% accurate. Thus it is important to understand how\napproximation guarantee degrades with the quality of the pr ediction. To this end, we measure the\nquality of the prediction ˆ oas the ratio of SC(ˆo,ℓ) andopt(ℓ).7Namely, we say that prediction is\nγ-accurate ifSC(ˆo,ℓ)\nopt(ℓ)≤γ.\nIn contrast, robustness captures how much of the worst-case guarantees the mechanis m retains,\nwhen the prediction is arbitrarily wrong. Namely, mechanis mf(/tildewideℓ,ˆo) isβ-robust, if the price of\n6No agent iplays a strategy /tildewideℓiwith a higher expected cost than another strategy /tildewideℓ′\nion every proﬁle ℓ-i∈ Mn−1\n7One can also use d(ˆo,o) as a measure of the accuracy of the prediction. A drawback of this approach is that o\nmight not be unique, or that a pair of far away points may yield similar social cost.\n7\n\nanarchy of the game induced by fis at most β, i.e.,\nβ≥max\nℓ,ˆomax\n/tildewideℓ∈NE(ℓ,f∆)E[SC(f∆(/tildewideℓ,ˆo),ℓ)]\nopt(ℓ).\nThe ML augmented framework studies which α-consistency and β-robustness guarantees are\nattainable. Typically, there is a trade oﬀ between feasible αandβ. We provide guarantees on the\nrobustness and consistency as functions of the prediction a ccuracyγand the ratio c=∆\nabetween\ngiven parameter ∆ and average cost adef==1\nnSC(ˆo,ℓ) for the predicted location ˆ o.\nHarmonic Mechanism. We analyze the following Harmonic mechanism, which installs facility\nfat/tildewideℓiwith probability inversely proportional to d(/tildewideℓi,ˆo)+∆ for a constant ∆.\nALGORITHM 1: Harmonic mechanism Harmonic (∆)\nData:Reported locations /tildewideℓ= (/tildewideℓ1,...,/tildewideℓn), prediction ˆ o∈M\nResult: Facilityf∼π{/tildewideℓ1,...,/tildewideℓn}\nfori∈[n]doletdi=d(/tildewideℓi,ˆo) ;\nChoosePr[f←/tildewideℓi]def==1/(di+∆)/summationtextn\nj=11/(dj+∆)fori∈[n] ;//Pr[f←/tildewideℓi]∝1\ndi+∆(proportional\nto)\nThis mechanism is not dominant strategy incentive compatib le (DSIC) in general. However, as\nwe will show shortly, the set of undominated strategies for e ach agent is rather limited. In other\nwords,Harmonic mechanism is not too far from strategy-proof mechanisms. We further analyse\nhow far the social cost at a Nash equilibrium is from the optim um social cost, namely the price of\nanarchy under Harmonic selection rule f.\n3 Strategies and Equilibria in Harmonic Mechanism\nWe ﬁrst describe the set of strictly dominant strategies of e ach agent i∈[n] underHarmonic\nmechanism. For notational brevity, we use ℓjforj∝\\e}atio\\slash=iin place of /tildewideℓj, as we consider a ﬁxed agent\ni’s strategy for all possible reports of the other agents and o ne can simply pretend that ℓ-iis a\nvariable vector to agent i.\n3.1 Undominated strategies\nWe consider the expected costi(/tildewideℓi) of a ﬁxed agent ias a function of her report /tildewideℓi, while assuming\nthat the reports ℓ-iof other agents follow a distribution8F-i. Then\ncosti(/tildewideℓi) =E\nℓ-i∼F-i\n/summationtext\nj/\\egatio\\slash=id(ℓi,ℓj)\nd(ℓj,ˆo)+∆+d(ℓi,/tildewideℓi)\nd(/tildewideℓi,ˆo)+∆/summationtext\nj/\\egatio\\slash=i1\nd(ℓj,ˆo)+∆+1\nd(/tildewideℓi,ˆo)+∆\n=E\nℓ-i/bracketleftBigg\nC1(ℓ-i)+x\ny+∆\nC2(ℓ-i)+1\ny+∆/bracketrightBigg\n, (2)\nwhere agent ican control only two parameters xdef==d(ℓi,/tildewideℓi)≥0 andydef==d(/tildewideℓi,ˆo)≥0 by\npossibly misreporting her true location, while the remaini ng terms C1≥0 andC2>0 in the\n8The main focus of our paper is on pure Nash equilibria, but her e we allow randomization in other agents’\nstrategies.\n8\n\nnumerator and denominator respectively only depend on the r eports of other agents ℓ-i. Thus, we\ncan study agent i’s cost as a function of only x,y∈R+, and each ﬁxed realization of ℓ-i∼F-i. For\nconvenience we continue to use the same notations C1,C2,andcostifor each ﬁxed realization of\nℓ-i:costi(x,y,ℓ-i) =C1+x/(y+∆)\nC2+1/(y+∆).A few simple observations are in order.\nObservation 3.1. The cost costi(x,y,ℓ-i)is a strictly increasing in xfor anyC1,C2,y,∆≥0.\nBy triangle inequality x+y=d(ℓi,/tildewideℓi)+d(/tildewideℓi,ˆo)≥d(ℓi,ˆo) andx+d(ℓi,ˆo)≥y. Hence,\nObservation 3.2. x≥|d(ℓi,ˆo)−y|.\nWe further note that player iwould never choose ylarger than d(ℓi,ˆo).\nClaim 3.3. The strategy of agent iwithy > d(ℓi,ˆo)is strictly dominated by the strategy x= 0,\ny=d(ℓi,ˆo)for anyC1,C2≥0.\nProof.Let us denote d(ℓi,ˆo) bydi. By observation 3.2we have x≥y−didef==x0, and by ob-\nservation 3.1thecosti(x,y,ℓ-i) is at least costi(x0,y,ℓ-i), where y=x0+di. We need to show\nthat\ncosti(x0,y) =C1+x0\nx0+di+∆\nC2+1\nx0+di+∆>costi(0,di) =C1\nC2+1\ndi+∆.\nThis inequality holds, since the numerator C1+x0\nx0+di+∆is larger than the numerator C1, and the\ndenominator C2+1\nx0+di+∆is smaller than the denominator C2+1\ndi+∆.\nTherefore, d(/tildewideℓi,ˆo) =y∈[0,d(ℓi,ˆo)]. By observation 3.1, agentichooses minimal possible xfor\nany given yand any ℓ-i. Now,x≥d(ℓi,ˆo)−yby observation 3.2. IfMis acontinuous space9,\nthen there always exists a /tildewideℓi∈Mwithxdef==d(/tildewideℓi,ℓi) =d(ℓi,ˆo)−y. I.e., player i’s undominated\nstrategies in the continuous metric space are /tildewideℓion a shortest path S-Path(ˆo,ℓi) between ˆ oandℓi.\nClaim 3.4. IfMis a continuous metric space, then reports on the shortest pa ths/tildewideℓi∈S-Path(ˆo,ℓi)\nstrictly dominate other strategies of agent i.\n3.2 Equilibria Concepts\nMany solution concepts may be used to describe the outcome of a game, such as Pure Nash (PNE),\nMixed Nash (MNE), Correlated (CE), and Coarse Correlated (C CE) equilibria. In case of the\ngame induced by the Harmonic mechanism f, the solution concepts that involve randomization are\nnot ideal. Indeed, an agent imight ﬁnd it diﬃcult to compute their expected cost ( 2) for a ﬁxed\nreported location /tildewideℓilet alone ﬁnding the best response over all possible /tildewideℓi∈S-Path(ˆo,ℓi). E.g., if\nn−1 = 10 agents randomize in ℓ-ibetween two pure strategies in a mixed Nash Equilibrium, the n\n(2) would already have more than 1000 fraction terms.\nThus we adopt the Pure Nash Equilibrium (PNE) solution conce pt to describe the outcome of\nHarmonic mechanism f. It is important to keep in mind that, unlike MNE, PNE may not e xist. We\nshow below that PNE always exists in a continuous metric spac eM, i.e., in a metric where every\npair of points has a continuous shortest path between them. T he proof refers to the full version.\n9Formally, for any two points P1,P2∈ Mandx∈[0,d(P1,P2)] there exists a point P∈ Msuch that d(P,P1) =x\nandd(P,P2) =d(P1,P2)−x\n9\n\nTheorem 3.5. LetMbe continuous (any pair of points has a shortest path), then f or any initial\npositions ℓ= (ℓi)i∈[n]of[n]agents there is a Pure Nash Equilibrium under Harmonic mechanism.\nProof.Let us ﬁx a single shortest path in S-Path(ˆo,ℓi) parameterized as Li= [0,1] (by the ratio\nd(/tildewideℓi,ˆo)/d(ℓi,ˆo)∈[0,1] for/tildewideℓi∈S-Path(ˆo,ℓi)) per each agent i∈[n]. We shall apply Kakutani ﬁxed-\npoint theorem for the simultaneous best responses of all nplayers, in order to prove the existence\nof PNE.\nSpeciﬁcally, for the convex and compact subset Xdef==/producttextn\ni=1Li= [0,1]nof Euclidean space,\nwe consider the best response BR:X→2Xfunction which is deﬁned as follows. Any x∈\nXcorresponds to a location proﬁle ℓ∈Mnon the speciﬁc shortest paths from each ℓito the\npredicted location ˆ o; for every player iwe consider all her potential best responses BRi(ℓ-i) with\nrespect to the locations ℓ-iof other players and restricted to her ﬁxed shortest path Li; we deﬁne\nBR(x)def== (BRi(ℓ-i))n\ni=1.\nBy Claim 3.6(we shall formally state and prove it shortly in the next subs ection) each BRi(ℓ-i)\nis either a single point ℓi(xi= 1,) or ˆ o(xi= 0), or it is the whole line segment Li. Hence, BR(x)\nis a convex set for every x∈X. It is also not hard to verify that BRhas a closed graph in the\nproduct topology on X×X, i.e., the set{(x,y)|x∈X,y∈X,y∈BR(x)}is closed. The Kakutani\nﬁxed-point theorem states that any such function must have a ﬁxed point, i.e.,∃x∗∈Xsuch that\nx∗∈BR(x∗). Thisx∗corresponds to the Pure Nash Equilibrium of Harmonic mechanism.\nFor discrete (non continuous) metric spaces Mto allow randomness, we can let agents to\nexplicitly report their locations as a distribution over a ﬁ nite number of points in M. I.e., we\nconsider an extension of the metric space Mto a larger metric space Mover all ﬁnite convex\ncombinationsM={α=/summationtext\ni∈[k]αi·ℓi|/summationtext\ni∈[k]αi= 1, αi≥0, ℓi∈M}, where a naturally\ninduced metric in Mis given by the earth mover’s distance between two probabili ty distributions\nα,βover points inM. ThenMis a continuous metric space and thus PNE does exist in M.\nFurthermore, when many agents participate in Harmonic mechanism, a reasonable approximation\nand/or simpliﬁcation of their expected costs (dueto good co ncentration) can bedoneby calculating\nexpectations of the numerator and denominator in ( 2) separately and then using the ratio of\nexpectations instead of the expected ratio. This approach c orresponds exactly to agents playing\npure strategies in M.\nBest Response in Pure Nash Equilibria We next show in Claim 3.6which locations on the\nshortest paths could be the best response of agent ifor a ﬁxed proﬁle of other agents’ reports ℓ-i:\nionly needs to decide between two choices /tildewideℓi∈{ℓi,ˆo}and only when she is indiﬀerent, then imay\nalso play any /tildewideℓi∈S-Path(ˆo,ℓi).\nClaim 3.6. Given a proﬁle ℓ-iof agents [n]\\{i}locations, agent i’s best response is to only report\n•her true location /tildewideℓi=ℓiwhencosti(ℓi,ℓ-i)< d(ℓi,ˆo)+∆;\n•predicted location /tildewideℓi= ˆowhencosti(ℓi,ℓ-i)> d(ℓi,ˆo)+∆; thencosti(/tildewideℓi,ℓ-i)≥d(ℓi,ˆo)+∆;\n•any point /tildewideℓi∈S-Path(ˆo,ℓi)whencosti(ℓi,ℓ-i) =d(ℓi,ˆo)+∆; thencosti(ℓi,ℓ-i) =costi(/tildewideℓi,ℓ-i).\nProof.By equation ( 2)ichooses/tildewideℓiwithx,ythat minimize\ncosti(x,y,ℓ-i) =/summationtext\nj/\\egatio\\slash=id(ℓi,ℓj)/(d(ℓj,ˆo)+∆)+ x/(y+∆)/summationtext\nj/\\egatio\\slash=i1/(d(ℓj,ˆo)+∆)+1 /(y+∆),\nwherex=d(ℓi,/tildewideℓi)≥0 andd(ℓi,ˆo)≥y=d(/tildewideℓi,ˆo)≥0. Without loss of generality we can assume\nthatx+y=d(ℓi,ˆo). We consider costi(/tildewideℓi,ℓ-i)−costi(ℓi,ℓ-i) =costi(x,y,ℓ-i)−costi(0,x+y,ℓ-i). To\n10\n\nsimplify notations let us denote the pairwise distances djkdef==d(ℓj,ℓk) forj,k∈[n],djdef==d(ℓj,ˆo)\nforj∈[n], and the respective denominators /tildewideD=/summationtext\nj/\\egatio\\slash=i1\ndj+∆+1\ny+∆andD=/summationtext\nj/\\egatio\\slash=i1\ndj+∆+1\nx+y+∆.\nThen\ncosti(/tildewideℓi,ℓ-i)−costi(ℓi,ℓ-i) =x\n(x+y+∆)·/tildewideD−\n/summationdisplay\nj/\\egatio\\slash=idij\ndj+∆\n·1/(y+∆)−1/(x+y+∆)\nD·/tildewideD\n=x\n(y+∆)·/tildewideD−1\nD\n/summationdisplay\nj/\\egatio\\slash=idij\ndj+∆\n·x\n(y+∆)·(x+y+∆)·/tildewideD\n=x\n(y+∆)·(x+y+∆)·/tildewideD·/parenleftBig\nx+y+∆−costi(ℓi,ℓ-i)/parenrightBig\n.(3)\nWhenx+y+∆−costi(ℓi,ℓ-i) =d(ℓi,ˆo)+ ∆−costi(ℓi,ℓ-i)>0, the expression ( 3) is minimized\nonly for /tildewideℓi=ℓiwithx= 0,y=d(ℓi,ˆo). When x+y+ ∆−costi(ℓi,ℓ-i)<0, expression ( 3) is\nminimized only for /tildewideℓi= ˆowithy= 0,x=d(ℓi,ˆo). When x+y+ ∆−costi(ℓi,ℓ-i) = 0 we get\ncosti(/tildewideℓi,ℓ-i)−costi(ℓi,ℓ-i) = 0 for any x,y:x+y=d(ℓi,ˆo). This almost concludes the proof, as\nwe get all required bounds on costi(ℓi,ℓ-i).\nTheonly missingpart is to show that costi(/tildewideℓi,ℓ-i)≥d(ℓi,ˆo)+∆, when costi(ℓi,ℓ-i)> d(ℓi,ˆo)+∆\nand/tildewideℓi= ˆo. Note that in this case y=d(/tildewideℓi,ˆo) = 0 and x=d(/tildewideℓi,ℓi) =d(ℓi,ˆo). Then costi(ℓi,ℓ-i) =\ncosti(0,x) =C1\nC2+1/(x+∆)> x+∆, i.e., C1≥C2(x+∆)+1, while costi(ˆo,ℓ-i) =costi(x,0) =C1+x/∆\nC2+1/∆.\nWe get the desired bound on costi(ˆo,ℓ-i), when using the lower bound on C1≥C2(x+ ∆) + 1:\ncosti(ˆo,ℓ-i) =C1+x/∆\nC2+1/∆≥C2(x+∆)+1+ x/∆\nC2+1/∆=x+∆.\n4 Price of Anarchy\nHere we study the Price of Anarchy (PoA) of the PNE of Harmonic mechanism fin metricMor\nM. We will make extensive use of Claims 3.4,3.6to prove PoA guarantees for the consistency and\nrobustness of Harmonic mechanism. We derive two diﬀerent PoA bounds for robustness: (a) when\nMis a strictly convex space (b) when Mis a general metric space.\nWeﬁrstintroducesomesimpliﬁednotationsthatwouldhelpu stouseClaim 3.6. Let/tildewideℓ= (/tildewideℓi)i∈[n]\nbe a PNE. Let tidef==d(ˆo,ℓi) denote the distance between predicted location ˆ oand the true location\nℓiof agenti∈[n]. In equilibrium, some of the agents may report diﬀerent loca tions/tildewideℓi, we denote by\ndidef==d(ˆo,/tildewideℓi) the distance from ˆ oto the reported location of i∈[n]. Note that player iwill always\nhaveti≥diin an equilibrium. To write down the costi(/tildewideℓi) of agent iwe will use cijdef==d(ℓi,/tildewideℓj)\n(note that cij∝\\e}atio\\slash=cji) that denotes the distance between true location of i∈[n] and the reported\nlocation of j∈[n]. In particular, cii=d(ℓi,/tildewideℓi) =ti−di. Then\ncosti(/tildewideℓi) =/summationtext\nj∈[n]cij/(dj+∆)\n/summationtext\nj∈[n]1/(dj+∆)(4)\nBy Claim 3.6each agent either reports /tildewideℓi= ˆo, or/tildewideℓi=ℓi, or/tildewideℓi∈S-Path(ˆo,ℓi) in a PNE. Let\nSdef=={i∈[n]|/tildewideℓi= ˆo}, Tdef=={i∈[n]|/tildewideℓi=ℓi}, Udef== [n]\\(S∪T)\nand also use S= [n]\\S=U∪T. We also use Ddef==/summationtext\nj∈[n]1/(dj+∆) to denote the denominator\nof eachcosti(/tildewideℓ) fori∈[n].\n11\n\n4.1 Consistency\nIn this section, we show that the Harmonic (∆) mechanism can achieve a solution arbitrarily close to\nthe optimum depending on the quality of the prediction. Spec iﬁcally, when the predicted location\nˆogives an almost optimum estimation of the true optimum (/summationtext\ni∈[n]d(ℓi,ˆo)≈/summationtext\ni∈[n]d(ℓi,o)) and\n∆\nopt/n=O(ε), we are able to show that PoA of Harmonic (∆) mechanism is close to 1.\nTheorem 4.1. Ifˆoisγ-accurate, i.e.,SC(ˆo,ℓ)\nopt(ℓ)≤γ, andcdef== ∆/afor an average cost a=1\nnSC(ˆo,ℓ)\nof the prediction ˆo, thenHarmonic (∆)mechanism is γ·(1+2c)-consistent.\nProof.Let/tildewideℓbe a PNE reported by the agents. Then the expected social cost of theHarmonic\nmechanism fis as follows,\nSCdef==/summationdisplay\ni∈[n]costi(/tildewideℓi) =/summationdisplay\nj∈[n]1/(dj+∆)/summationtext\nj∈S1/(dj+∆)+|S|/∆/summationdisplay\ni∈[n]cij\nWe denote the denominator of the equation above by Ddef==/summationtext\nj∈S1/(dj+∆)+|S|/∆. Claim 3.6\ndescribes three groups of agents S,U,andTin a PNE. We rewrite SCby partitioning agents into\nSandS=U∪Tas follows,\nSC=|S|/∆\nD/summationdisplay\ni∈[n]ti+/summationdisplay\nj∈S1/(dj+∆)\nD/summationdisplay\ni∈[n]cij.\nIn the equilibrium, we have ti+∆≥costi(ℓi,/tildewideℓ-i) =costi(/tildewideℓi) fori∈S. We add these inequalities\noveri∈S,\n/summationdisplay\ni∈S(ti+∆)≥1\nD·\n/summationdisplay\ni∈S/summationdisplay\nj∈[n]cij\ndj+∆\n=1\nD·\n/summationdisplay\ni∈S/summationdisplay\nj∈Scij\ndj+∆+/summationdisplay\ni∈S/summationdisplay\nj∈Scij\ndj+∆\n\n=1\nD·\n/summationdisplay\ni∈S/summationdisplay\nj∈Scij\ndj+∆+|S|\n∆·/summationdisplay\ni∈Sti\n,(5)\nwhere we used that cij=tianddj= 0 for any j∈Sandi∈Sto get the second equality. We\nrewrite Right Hand Side (RHS) of ( 5) usingSCas follows\nRHS(5) =SC−1\nD·\n/summationdisplay\ni∈S/summationdisplay\nj∈Scij\ndj+∆+|S|\n∆/summationdisplay\ni∈Sti\n[cij≤ti+dj]\n≥SC−1\nD·\n/summationdisplay\ni∈S/summationdisplay\nj∈¯Sti+dj\ndj+∆+|S|\n∆/summationdisplay\ni∈Sti\n\n[def. ofD]=SC−1\nD·\nD·/summationdisplay\ni∈Sti+/summationdisplay\ni∈S/summationdisplay\nj∈Sdj\ndj+∆\nD≥|S|/∆,\ndj/(dj+∆)≤1\n≥SC−/summationdisplay\ni∈Sti−1\n|S|/∆/summationdisplay\ni∈S/summationdisplay\nj∈S1\n=SC−/summationdisplay\ni∈Sti−∆·|S|\nSince/summationtext\ni∈S(ti+∆)≥RHS(5), we get SC≤/summationtext\ni∈[n]ti+2∆|S|. Recall that ∆ =c\nn·/summationtext\ni∈[n]d(ℓi,ˆo) =\nc\nn·/summationtext\ni∈[n]ti. Then,SC≤(1+2c|S|/n)/summationtext\ni∈[n]ti≤(1+2c)/summationtext\ni∈[n]ti= (1+2c)·SC(ˆo,ℓ). Using the\nfact that ˆ oisγ-accurate, (1+2 c)SC(ˆo,ℓ)≤γ(1+2c)·opt(ℓ).\n12\n\n4.2 Robustness\nHere, we show robustness guarantees for arbitrary bad predi cted location ˆ ofor theHarmonic mech-\nanism. Our guarantees depend on c= ∆/a(the larger c, the better) that equals to the ratio\nbetween the parameter ∆ of the Harmonic mechanism and a=1\nnSC(ˆo,ℓ). We will ﬁrst derive a\nfew useful lemmas and then prove two PoA guarantees: ﬁrst, fo r the case whenMis strictly convex\nspace, and, second, for the general metric.\nRecall that Harmonic mechanism chooses each location /tildewideℓifori∈[n] with probability1/(di+∆)\nD\nwhereDdef==/summationtext\ni∈[n]1/(di+ ∆). The expected social cost SC=/summationtext\nj∈[n]1/(dj+∆)\nD/summationtext\ni∈[n]cij, which\nwe partition into three terms by dividing j∈[n] into three sets S,U, andTaccording to the\nequilibrium conditions from Claim 3.6as follows\nSC=|S|/∆\nD/summationdisplay\ni∈[n]ti+/summationdisplay\nj∈T1/(tj+∆)\nD/summationdisplay\ni∈[n]dij+/summationdisplay\nj∈U1/(dj+∆)\nD/summationdisplay\ni∈[n]cij. (6)\nWe ﬁrst consider the term corresponding to the set of agents T, who reported their true location\n/tildewideℓj=ℓj. It is useful to keep in mind that the random dictatorship mec hanism is a 2-approximation\nto the optimal social cost [ AFPT09 ].\nLemma 4.2 (Theorem 3.1 in [ AFPT09 ]).The random dictatorship mechanism (i.e., choosing\nlocationℓjof agent j∈[n]with probability 1/n) is2-approximation.\nThis Lemma 4.2is a useful comparison point for estimating the contributio n to the social cost\nby agents in T. Indeed, if we can show that the probabilities of selecting /tildewideℓi=ℓiare at most\na constant factor away from the uniform sampling, then agent s inTcontribute no more than a\nconstant factor compared to the optimum social cost. The nex t Lemma 4.3proves that and gives\nuseful probability estimates for selecting agents i∈UunderHarmonic mechanism.\nLemma 4.3. For alli∈T∪U, the probability that location /tildewideℓiis selected is at most\n1/(di+∆)/summationtext\nj∈[n]1/(dj+∆)≤2\nn·ti+∆\ndi+∆. (7)\nProof.Inequality ( 7), after simple algebraic manipulations, can be rewritten a s\n2·/summationdisplay\nj∈[n]1\ndj+∆≥n\nti+∆. (8)\nBy Claim 3.6, we have costi(/tildewideℓi) =costi(ℓi)≤ti+∆ fori∈S=T∪U. We multiply both sides of\nthe latter inequality byD\nti+∆and get\n/summationdisplay\nj∈[n]1\ndj+∆=D\nti+∆(ti+∆)≥D\nti+∆·costi(/tildewideℓi) =/summationdisplay\nj∈[n]cij\n(dj+∆)(ti+∆)\n≥/summationdisplay\nj∈[n]/vextendsingle/vextendsingle/vextendsingle/vextendsingle1\nti+∆−1\ndj+∆/vextendsingle/vextendsingle/vextendsingle/vextendsingle≥|S|·/parenleftbigg1\n∆−1\nti+∆/parenrightbigg\n+/summationdisplay\nj∈S/parenleftbigg1\nti+∆−1\ndj+∆/parenrightbigg\n,(9)\nwhere the second inequality holds since cij=d(ℓi,/tildewideℓj)≥|d(ℓi,ˆo)−d(/tildewideℓj,ˆo)|=|ti−dj|by the triangle\ninequality (see Observation 3.2); and the third inequality holds as one can separate j∈Sfrom\n13\n\nj∈Sand note that dj= 0 for j∈S. We get the following inequality after simple algebraic\nrearrangements of ( 9) and using that dj= 0 forj∈S\n2·/summationdisplay\nj∈[n]1\ndj+∆≥|S|+|S|\nti+∆+2|S|\n∆−2|S|\nti+∆=n\nti+∆+2|S|ti\n∆(ti+∆),\nwhich obviously implies the desired inequality ( 8).\nThe Lemma 4.3implies that the Harmonic mechanism chooses each location /tildewideℓj=ℓjfor agents\nj∈Twith probability at most 2 /n. I.e., the contribution of agents in Tto the expected social cost\nis at most O(1) of the uniform sampling and, hence, is O(opt).\nCorollary 4.4./summationtext\nj∈T1/(tj+∆)\nD/summationtext\ni∈[n]dij≤4·opt.\nThe other two terms corresponding to agents j∈Sandj∈Uare the main source of Harmonic\nmechanism’s ineﬃciency. Namely, it is impossible to achiev eO(1) robustness guarantee, when ∆ is\nsigniﬁcantly smaller than a=1\nn/summationtext\ni∈[n]ti. Indeed, consider forexample aninstance, in which∆ = 0,\na single agent jstays exactly at the predicted location ℓj= ˆo, and all other agents i∈[n]\\{j}\nare all situated at the same spot in Mfar away from ˆ o. In the unique equilibrium agent jreports\n/tildewideℓj= ˆo, while all other agents i∝\\e}atio\\slash=jreportℓi; the mechanism picks /tildewideℓj= ˆowith large probability\nresulting in an Ω( n) ineﬃcient placement of the facility. Still, when the param eter ∆ is not too\nsmall compared to a, we are able to show a constant approximation guarantee rega rdless of the\npredicted location ˆ o.\nWe begin our analysis with the term in ( 6) corresponding to agents j∈S. There we have a\nfactor1\nD·∆and our next lemma relates this term to the parameter c= ∆/a.\nLemma 4.5. Let∆ =c\nn·/summationtext\ni∈[n]d(ℓi,ˆo)inHarmonic (∆). Then1\n∆·D≤max/braceleftBig\n1/c+1\nn,1/c+1\nn/c/bracerightBig\n.\nProof.We ﬁrst get the following simple lower bound on ∆ ·D.\n∆·D=/summationdisplay\ni∈[n]∆\n∆+di=/summationdisplay\ni∈T1\n1+ti/∆+/summationdisplay\ni∈U1\n1+di/∆+|S|≥/summationdisplay\ni∈S1\n1+ti/∆+|S|.\nNext, we get a lower bound on/summationtext\ni∈S1\n1+ti/∆by applying Cauchy-Schwarz inequality\n\n/summationdisplay\ni∈S1\n1+ti/∆\n·\n/summationdisplay\ni∈S1+ti\n∆\n≥\n/summationdisplay\ni∈S/radicalBigg\n1\n1+ti/∆·/parenleftbigg\n1+ti\n∆/parenrightbigg\n2\n=|S|2. (10)\nSince ∆ =c\nn/summationtext\ni∈[n]ti, we have/summationtext\ni∈S1+ti/∆≤|S|+/summationtext\ni∈[n]ti/∆ =n/c+|S|. We plug in the last\nupper bound into ( 10) to get a lower bound/summationtext\ni∈S1\n1+ti/∆≥|S|2\nn/c+|S|. Hence,\n∆·D≥|S|2\nn/c+|S|+|S|=|S|·(|S|+|S|)+|S|·n/c\n|S|+n/c=|S|+|S|/c\n|S|/n+1/c≥|S|+|S|/c\n1+1/c.\nFinally, as|S|/c+|S|≥min(n,n/c) forc >0, we get the desired bound\n1\n∆·D≤1/c+1\n|S|/c+|S|≤max/braceleftBig1/c+1\nn,1/c+1\nn/c/bracerightBig\n.\n14\n\nThe Lemmas 4.2,4.3,4.5and Corollary 4.4are mostly enough to get a robustness guarantee\nofO(1+ 1/c2), if the set of agents Uin PNE/tildewideℓwas empty. Unfortunately, the presence of set U\nsigniﬁcantly complicates the analysis. Next, we derive two diﬀerent robustness guarantees: ﬁrst for\nan easier case, when metric Mis a strictly convex space, and later for the general metric.\n4.2.1 Robustness in Strictly Convex Spaces\nHere, we show robustness guarantee for arbitrary bad predic ted location ˆ ofor theHarmonic mecha-\nnism, assumingthat Mis a strictly convex space, i.e., the distance between two ve ctorsv1,v2∈M\nisgivenby d(v1,v2) =∝bardblv1−v2∝bardbl, and∝bardblv1+v2∝bardbl=∝bardblv1∝bardbl+∝bardblv2∝bardblforv1,v2∝\\e}atio\\slash= 0impliesthat v1=c·v2\nfor ac >0.\nTheorem 4.6. Harmonic (∆)is aO(1+1/c2)-robust in strictly convex space M, if∆ =c\nn·SC(ˆo,ℓ).\nToprovethetheorem, weﬁrstboundbound cijinHarmonic , whichfollows fromstrict convexity:\nClaim 4.7. For strictly convex space M, we have cij≤tj−dj\ntjti+dj\ntjdijforj∈U.\nProof.We mostly rely on the following useful property of the strict ly convex spaces, whose proof\nis in the appendix A.\nFact 4.8. For arbitrary points A,P1,P2∈Mand a point P∈S-Path(P1,P2)on the shortest path\nd(A,P)≤d(P,P2)\nd(P1,P2)·d(A,P1)+d(P,P1)\nd(P1,P2)·d(A,P2). (11)\nRecall that cij=d(ℓi,/tildewideℓj),ti=d(ℓi,ˆo), anddij=d(ℓi,ℓj), whiletj=d(ℓj,ˆo),dj=d(/tildewideℓj,ˆo), and\ntj−dj=d(/tildewideℓj,ℓj). We also have /tildewideℓj∈S-Path(ˆo,ℓj) and apply Fact 4.8toA=ℓi,P1= ˆo,P2=ℓj,\nandP=/tildewideℓj.\nApplying this upper bound on cijfor allj∈Uandi∈[n] in the expected social cost ( 6) gives\nSCClaim4.7\n≤|S|\n∆·D/summationdisplay\ni∈[n]ti+/summationdisplay\nj∈U1/(dj+∆)\nD/summationdisplay\ni∈[n]/parenleftBig\nti+dj\ntjdij/parenrightBig\n+/summationdisplay\nj∈T1/(tj+∆)\nD/summationdisplay\ni∈[n]dij(12)\n=\n|S|\n∆·D+/summationdisplay\nj∈U1\nD(dj+∆)\n·/summationdisplay\ni∈[n]ti\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n(∗)+/summationdisplay\nj∈Udj/tj\n(dj+∆)D/summationdisplay\ni∈[n]dij+/summationdisplay\nj∈T1/(tj+∆)\nD/summationdisplay\ni∈[n]dij\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n(∗∗).\nWeﬁrstshallget anupperboundonthesecondterm( ∗∗) in(12)inavery similarway toLemma 4.3\nand Corollary 4.4.\n(∗∗)≤/summationdisplay\nj∈U2\nn·tj+∆\ndj+∆·dj\ntj/summationdisplay\ni∈[n]dij+2\nn/summationdisplay\nj∈T/summationdisplay\ni∈[n]dij≤2\nn/summationdisplay\nj∈U∪T,\ni∈[n]dij≤2\nn/summationdisplay\ni,j∈[n]dij≤4·opt,(13)\nwhere the ﬁrst inequality holds by Lemma 4.3; the second inequality holds astj+∆\ndj+∆dj\ntj=1+∆/tj\n1+∆/dj≤1\nfor allj∈U; the last inequality holds by Lemma 4.2similar to Corollary 4.4. Next, we get an\n15\n\nupper bound on the ( ∗) term. We ﬁrst note that\n(∗)≤\n|S|\n∆·D+/summationdisplay\nj∈U1\nD·∆\n·/summationdisplay\ni∈[n]ti= (|S|+|U|)∆·1\n∆D·/summationtext\ni∈[n]ti\n∆≤\n(|S|+|U|)∆·max/braceleftbigg1/c+1\nn,1/c+1\nn/c/bracerightbigg\n·n\nc,(14)\nwhere we got the ﬁrst inequality by substituting1\ndj+∆with1\n∆; used deﬁnition of c=∆\na=∆·n/summationtext\ni∈[n]ti\nto simplify/summationtext\ni∈[n]ti\n∆and Lemma 4.5to get an upper bound on1\n∆Din the second inequality. Finally,\nwe give an upper bound on ( |S|+|U|)∆ in the following Claim 4.9. The proof relies on equilibrium\nconditions from Claim 3.6and Claim 4.7.\nClaim 4.9. For strictly convex space M,(|S|+|U|)∆≤2\nn/summationtext\ni,j∈[n]dij.\nProof.The equilibrium condition from Claim 3.6for each i∈S∪Ugives us\nti+∆≤costi(/tildewideℓi) =/summationdisplay\nj∈[n]1/(dj+∆)\nDcij=|S|/∆\nD·ti+/summationdisplay\nj∈U∪T1/(dj+∆)\nDcij. (15)\nWerecall that Ddef==|S|\n∆+/summationtext\nj∈U∪T1\ndj+∆, i.e.,|S|/∆\nD+/summationtext\nj∈U∪T1/(dj+∆)\nD= 1. Hence, after subtracting\ntifrom both sides of ( 15), we get the following\n∆≤/summationdisplay\nj∈U∪T1/(dj+∆)\nD(cij−ti)Claim4.7forj∈U\n≤/summationdisplay\nj∈T1/(dj+∆)\nD(cij−ti)\n+/summationdisplay\nj∈U1/(dj+∆)\nD·/parenleftbiggtj−dj\ntjti−dj\ntjdij−ti/parenrightbigg\n=/summationdisplay\nj∈Tdij−ti\nD(tj+∆)+/summationdisplay\nj∈Udij−ti\nD(dj+∆)·dj\ntj\n≤/summationdisplay\nj∈T1/(tj+∆)\nD·dij+/summationdisplay\nj∈U1/(dj+∆)\nD·dj\ntj·dijLemma4.3\n≤/summationdisplay\nj∈T2\nn·dij+/summationdisplay\nj∈U2\nn·tj+∆\ndj+∆·dj\ntj·dij\n≤2\nn/summationdisplay\nj∈T∪Udij,(16)\nwhere to get the third inequality, we simply substituted dij−tiwithdij; and to get the last\ninequality, we used thattj+∆\ndj+∆·dj\ntj=1+∆/tj\n1+∆/dj≤1. The claim follows after we add ( 16) for all\ni∈S∪U.\n(|S|+|U|)∆ =/summationdisplay\ni∈S∪U∆≤2\nn/summationdisplay\ni∈S∪U/summationdisplay\nj∈U∪Tdij≤2\nn/summationdisplay\ni,j∈[n]dij.\nWe get the following bound on ( ∗) by applying Claim 4.9to (14).\n(∗)≤2\nn/summationdisplay\ni,j∈[n]dij·max/braceleftbigg1/c+1\nn,1/c+1\nn/c/bracerightbigg\n·n\nc= max/braceleftBig2+2c\nc2,2+2c\nc/bracerightBig\n·1\nn/summationdisplay\ni,j∈[n]dij.\nI.e., (∗) =O(1+1\nc2)·opt. We conclude the proof of Theorem 4.6by combining this bound on ( ∗)\nwith the constant upper bound ( 13) on (∗∗) in (12).\n16\n\n4.2.2 Robustness in General Metric Spaces\nThe goal of this section is to extend our robustness result fo r strictly convex spaces to general\nmetric (Theorem 4.10). However, since general metric Mmay have rather diﬀerent geometry than\nstrictly convex spaces10, we lose an additional factor 1 /cin our robustness guarantee.\nTheorem 4.10. Harmonic (∆)is aO(1+1/c3)-robust in metric space, if ∆ =c\nn·SC(ˆo,ℓ).\nProof.As in the proof of Theorem 4.6, the most technically challenging part is to handle agents\nj∈Uin the expression ( 6) for the expected social cost of Harmonic mechanism. However, we no\nlonger have the bound on cijprovided by Claim 4.7, which makes it harder to deal with agents\nj∈U. We still follow similar approach and get an upper bound on cijof the form O(ti)+O(dj\ntjdij)\nin our next Claim 4.11. However, another subtle and more serious issue is that Clai m4.9in the\nproof of Theorem 4.6uses Claim 4.7, which the new Claim 4.11cannot resolve. We derive instead\nanotherupperboundon( |S|+|U|)∆ builtupondiﬀerent ideas inClaim 4.12andalsoloseadditional\nfactorcin our guarantee.\nClaim 4.11. For any metric space M,cij≤2ti+2dj+∆\ntj+∆dijfor anyj∈Uandi∈[n].\nProof.We prove a slightly stronger claim that cij≤2ti+ 2dj\ntjdij, asdj\ntj≤dj+∆\ntj+∆. By triangle in-\nequalities for points ˆ o,/tildewideℓj,ℓj,andℓiwe have the following bounds on cij=d(ℓi,/tildewideℓj),ti=d(ˆo,ℓi),tj=\nd(ˆo,ℓj),dj=d(ˆo,/tildewideℓj),anddij=d(ℓi,ℓj):\ncij≤ti+djanddj≤tj≤ti+dij.\nThe proof proceeds by considering the following four simple cases.\n1. Ifti≥tj, then 2ti≥ti+tj≥ti+dj≥cijand the claim follows.\n2. If 2dj≥tj, then 2ti+2dj\ntjdij≥2ti+dij≥ti+dj≥cijand the claim follows.\n3. Ifti< tjand2(tj−ti)\ntj≥1. Then, since dij≥tj−ti, we have 2 ti+2dij\ntjdj≥2ti+2tj−ti\ntjdj≥\n2ti+dj≥cijand we are done.\n4. Ifti< tj,2(tj−ti)\ntj<1, and 2dj< tj. Then, as2(tj−ti)\ntj<1, we have tj<2ti. The claim\nfollows, as 2 ti> ti+1\n2tj> ti+dj≥cij.\nThis concludes the proof of the claim, as if none of the ﬁrst th ree cases hold, then all conditions of\nthe last case are necessarily satisﬁed.\nAs before, we apply this upper bound on cijfor allj∈Uandi∈[n] in the expected social\ncost (6) and get\nSC≤|S|\n∆·D/summationdisplay\ni∈[n]ti+/summationdisplay\nj∈U1/(dj+∆)\nD/summationdisplay\ni∈[n]/parenleftBig\n2ti+2dj+∆\ntj+∆dij/parenrightBig\n+/summationdisplay\nj∈T1/(tj+∆)\nD/summationdisplay\ni∈[n]dij(17)\n=\n|S|\n∆·D+/summationdisplay\nj∈U2\nD(dj+∆)\n·/summationdisplay\ni∈[n]ti\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n(∗)+/summationdisplay\nj∈U2/(tj+∆)\nD/summationdisplay\ni∈[n]dij+/summationdisplay\nj∈T1/(tj+∆)\nD/summationdisplay\ni∈[n]dij\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n(∗∗).\n10E.g., it may violate the inequality ( 11) from Fact 4.8. consider a two-dimensional space L1(R2), and consider\na point (0 ,1)∈S-Path((0,0),(1,1)). The distances from another point (1 ,0) to the endpoints are d((1,0),(0,0)) =\nd((1,0),(1,1)) = 1, while d((1,0),(0,1)) = 2.\n17\n\nWe handle the term ( ∗∗) in almost exactly the same way as we did in ( 13) by applying Lemma 4.3.\n(∗∗)≤/summationdisplay\nj∈U4\nn/summationdisplay\ni∈[n]dij+2\nn/summationdisplay\nj∈T/summationdisplay\ni∈[n]dij≤4\nn/summationdisplay\nj∈U∪T/summationdisplay\ni∈[n]dij≤4\nn/summationdisplay\ni,j∈[n]dij≤8·opt, (18)\nwhere the last inequality holds by Lemma 4.2similar to Corollary 4.4. We also get a similar to\n(14) upper bound on ( ∗) by using the deﬁnition of c=∆\na=∆·n/summationtext\ni∈[n]tiand Lemma 4.5\n(∗)≤\n|S|\n∆·D+/summationdisplay\nj∈U2\nD·∆\n·/summationdisplay\ni∈[n]ti≤2(|S|+|U|)∆·max/braceleftbigg1/c+1\nn,1/c+1\nn/c/bracerightbigg\n·n\nc.(19)\nWe show a new upper bound on ( |S|+|U|)∆ in the following Claim 4.12using only thatMis a\nmetric space.\nClaim 4.12. For any metric space M,(|S|+|U|)∆≤O(1+1/c)opt.\nProof.We ﬁrst write equilibrium conditions from Claim 3.6for each agent i∈S∪Uand subtract\ntifrom both sides as in ( 15). I.e.,\n∆≤/summationdisplay\nj∈U1/(dj+∆)\nD(cij−ti)+/summationdisplay\nj∈T1/(tj+∆)\nD(dij−ti)\nLemma4.3\n≤/summationdisplay\nj∈U1/(dj+∆)\nD(cij−ti)+2\nn/summationdisplay\nj∈Tdij.(20)\nWe note that in the summation corresponding to agents j∈Uin the right hand side of ( 20) we\ncan ignore negative terms cij−ti. We also observe that cij≤tiwhen\nObservation 4.13. Ifdj≥2dij, thencij≤ti.\nProof.By applying triangle inequality a few times we get cij≤dij+(tj−dj)≤2dij+ti−dj. Since\ndj≥2dij, we get cij≤ti.\nWe continue with the bound ( 20) on ∆ using Observation 4.13.\n∆≤/summationdisplay\nj∈U1/(dj+∆)\nD·1[2dij≥dj]·(cij−ti)+2\nn/summationdisplay\nj∈Tdij≤/summationdisplay\nj∈U1/(dj+∆)\nD·1[2dij≥dj]·dj\n+2\nn/summationdisplay\nj∈Tdij≤/summationdisplay\nj∈U1/(dj+∆)\nD·1/bracketleftbigg\n2dij≥dj≥∆\n2/bracketrightbigg\n·dj+/summationdisplay\nj∈U1/(dj+∆)\nD·1/bracketleftbigg\ndj<∆\n2/bracketrightbigg\n·dj\n+2\nn/summationdisplay\nj∈Tdij≤/summationdisplay\nj∈Udj\n(dj+∆)D·1/bracketleftbigg\n2dij≥dj≥∆\n2/bracketrightbigg\n+∆\n2+2\nn/summationdisplay\nj∈Tdij,(21)\nwhere the second inequality holds, as dj+ti≥cijby triangle inequality; we get the third inequality\nby considering cases whether dj≥∆/2 or not for j∈U; the last inequality holds, as the sum\n18\n\n/summationtext\nj∈U1/(dj+∆)\nD≤1 anddj<∆/2 whenever 1/bracketleftbig\ndj<∆\n2/bracketrightbig\n>0. We get the following inequality after\nsubtracting ∆ /2 from both sides of ( 21) and estimatingdj\ndj+∆≤1\n∆\n2≤1\nD·/summationdisplay\nj∈U1/bracketleftbigg\n2dij≥dj≥∆\n2/bracketrightbigg\n+2\nn/summationdisplay\nj∈Tdij≤4\n∆D·/summationdisplay\nj∈U∆\n4·1/bracketleftbigg\ndij≥∆\n4/bracketrightbigg\n+2\nn/summationdisplay\nj∈Tdij\n≤4\n∆D·/summationdisplay\nj∈Udij+2\nn/summationdisplay\nj∈Tdij,(22)\nwhere we get the second inequality by multiplying and dividi ng by4\n∆the summation for j∈U\nand also by simplifying the condition inside the indicator f unction; the last inequality follows as\ndij≥∆\n4·1/bracketleftbig\ndij≥∆\n4/bracketrightbig\n. Finally, we add inequalities ( 22) for alli∈S∪Uand get\n1\n2(|S|+|U|)∆ =/summationdisplay\ni∈S∪U∆\n2≤4\n∆D/summationdisplay\ni∈S∪U/summationdisplay\nj∈Udij+2\nn/summationdisplay\ni∈S∪U/summationdisplay\nj∈Tdij≤/parenleftbigg4n\n∆D+2/parenrightbigg1\nn/summationdisplay\ni,j∈[n]dij\n≤/parenleftbigg\n2+4n·max/braceleftBig1/c+1\nn,1/c+1\nn/c/bracerightBig/parenrightbigg\n·2opt=O/parenleftbigg\n1+1\nc/parenrightbigg\n·opt,\nwhere we used Lemma 4.5and Lemma 4.2to get the last inequality.\nWe combine ( 19) with the above bound from Claim 4.12to get that\n(∗)≤O/parenleftbigg\n1+1\nc/parenrightbigg\nopt·max/braceleftbigg1/c+1\nn,1/c+1\nn/c/bracerightbigg\n·n\nc=O/parenleftbigg\n1+1\nc3/parenrightbigg\nopt.\nTheorem 4.10follows after we combine this bound on ( ∗) with (18) the bound (∗∗)≤O(opt) in\nthe upper bound ( 17) on the expected social cost.\n4.3 Constant Number of Agents\nWe conclude the PoA analysis of Harmonic mechanism with a special case of a small number of\nagentsn=O(1). In this regime, we are able to simplify the mechanism by s etting the parameter\n∆ = 0, i.e., we ignore the estimate ˆ afor the average distance a=1\nn/summationtext\ni∈[n]d(ℓi,ˆo), and get the\nfollowing Harmonic (0) mechanism.\nALGORITHM 2: Harmonic mechanism Harmonic (0)\nData:Reported locations /tildewideℓ= (/tildewideℓ1,...,/tildewideℓn), prediction ˆ o∈M\nResult: Facilityf∼π{/tildewideℓ1,...,/tildewideℓn}\nfori∈[n]doletdi=d(/tildewideℓi,ˆo) ;\nChoosePr[f←/tildewideℓi]def==1/di/summationtextn\nj=11/djfori∈[n] ;//Pr[f←/tildewideℓi]∝1\ndi(proportional to)\nTheorem 4.14. Harmonic (0)is1-consistent ( γ-consistent for a γ-accurate prediction ˆo) in general\nmetricM. It isO(n)-robust, whenMis a strictly convex space.\nProof.The consistency guarantees immediately follow from Theore m4.1, when we set the param-\neter ∆ = 0 in Harmonic (0). For the robustness guarantee, we ﬁrst note that agents i nTcontribute\nat most 4·optby Corollary 4.4to the social cost. Hence, we only need to bound the contribut ion\n19\n\nfrom agents in S∪U. Let us ﬁx any agent i∈S∪U, the Claim 3.6gives us the bound on ∆ = 0\nas follows: 0 = ∆ ≤costi(ˆo,ℓ-i)−d(ℓi,ˆo) =/summationtext\nj∈U∪T\\i1/dj\nD(/tildewideℓi=ˆo,/tildewideℓ-i)(cij−ti). This implies that there\nexists ai∗∈U∪T,i∗∝\\e}atio\\slash=isuch that d(ℓi,/tildewideℓi∗) =cii∗≥ti. By Fact 4.8and Claim 4.7we get that\ndii∗=d(ℓi,ℓi∗)≥ti, since/tildewideℓi∗∈S-Path(ˆo,ℓi∗) withti=d(ℓi,ˆo). Finally, we estimate the social cost\nof/tildewideℓias the following.\n/summationdisplay\nj∈[n]d(ℓj,/tildewideℓi)≤/summationdisplay\nj∈[n](d(ℓj,ℓi)+ti)≤n·ti+(n−1)·max\nj,k∈[n]djk\n≤n·dii∗+(n−1)·max\nj,kdjk≤(2n−1)·max\nj,kdjk≤(2n−1)·opt.\nHence, the contribution to the social cost of agents i∈S∪Uis not more than O(n)·optin\nHarmonic (0).\nRemark 4.15. The assumption that Mis strictly convex space is crucial for deriving O(1)-\nrobustness bound. This is because each agent i∈Umay increase the distance to everyone else\ncompared to ˆoandℓi. The analysis for sets SandTcan be carried in the same way as for strictly\nconvex spaces.\nTo see this, consider the following example of Nash equilibr ium in a circle metric space Mwith\njustn= 2 agents with arbitrary large PoA. Speciﬁcally, let d(ℓ1,ℓ2) = 1,d(ˆo,ℓ1) =d(ˆo,ℓ2) =M\nwhile the length of the whole circle is 2 M+1 for a large constant M∈R. Then the following /tildewideℓ\nis a Nash equilibrium: /tildewideℓ1and/tildewideℓ2are on their respective shortest paths from ℓ1andℓ2to ˆowith\nd(/tildewideℓ1,ˆo) =d(/tildewideℓ2,ˆo) = 0.5. It is easy to verify that each of the agents i= 1 and i= 2 is indiﬀerent\nbetween reporting /tildewideℓi= ˆoor/tildewideℓi=ℓi. I.e., by Claim 3.6/tildewideℓis a Nash equilibrium with the social cost\nSC(/tildewideℓ) = 2M. The optimal location is, e.g., at f=ℓ1with the social cost of 1.\n5 Conclusions\nIn this paper we study a canonical problem of strategic singl e-facility location in general metric\nspaces under new lenses of ML augmented mechanism design fra mework. This framework not\nonly allows to circumvent worst-case analysis limitations , but also enriches the design space of\nmechanisms in interesting new ways. It naturally led us to co nsider new type of non-truthful\nmechanisms (such as Harmonic mechanism) that have not appeared in the prior literature. W e\ngot useful insights about undominated strategies and equil ibria structure for this mechanism. We\nproved that Harmonic mechanism has a 1+ εprice of anarchy bound when predictions are (nearly)\naccurate, while retaining a constant PoA of O(1+1/poly(ε)) in the worst-case, when ˆ ois arbitrary\nbad (given that our mechanism’s parameter ∆ = ε·SC(ˆo,ℓ)).\nOur PoA analysis of consistency and especially robustness s igniﬁcantly deviates from a typical\nPoA analysis, as (i) the general smoothness argument does no t help in breaking 2-approximation\nbarrier and (ii) we have to use metric conditions in a non-tri vial way (e.g., our PoA bounds are\ndiﬀerent for strictly convex and general metric spaces, when n=O(1)). The tightness of our PoA\nbounds for Harmonic remains an open problem. Another interesting open question is to ﬁnd a\nmechanism that does not depend on a parameter ∆, but admits si milar (1 + ε)-consistency and\nO(1+1/poly(ε))-robustness PoA guarantees.\nAcknowledgments. Nick Gravin’s research is supported by National Key R & D Prog ram of\nChina (2023YFA1009500), by NSFC grant 61932002, and by “the Fundamental Research Funds\n20\n\nfor the Central Universities” in China. Chen and Im are suppo rted in part by NSF grants CCF-\n1844939, CCF-2121745, and CCF-2423106.\nReferences\n[ABG+22] Priyank Agrawal, Eric Balkanski, Vasilis Gkatzelis, Ti ngting Ou, and Xizhi Tan.\nLearning-augmented mechanism design: Leveraging predict ions for facility location.\nInProceedings of the 23rd ACM Conference on Economics and Computa tion, pages\n497–528, 2022.\n[AFPT09] Noga Alon, Michal Feldman, Ariel D Procaccia, and M oshe Tennenholtz. Strat-\negyproof approximation mechanisms for location on network s.arXiv preprint\narXiv:0907.2049 , 2009.\n[AFPT10] Noga Alon, Michal Feldman, Ariel D. Procaccia, and Moshe Tennenholtz. Strate-\ngyproof approximation of the minimax on networks. Math. Oper. Res. , 35(3):513–526,\n2010.\n[ALSW22] Haris Aziz, Alexander Lam, Mashbat Suzuki, and Tob y Walsh. Random rank: The\none and only strategyproof and proportionally fair randomi zed facility location mech-\nanism. In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Bel grave, K. Cho, and\nA. Oh, editors, Advances in Neural Information Processing Systems 35: Annua l Con-\nference on Neural Information Processing Systems 2022, Neur IPS 2022, New Orleans,\nLA, USA, November 28 - December 9, 2022 , 2022.\n[APT22] Yossi Azar, Debmalya Panigrahi, and Noam Touitou. O nline graph algorithms with\npredictions. In Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete\nAlgorithms (SODA) , pages 35–66. SIAM, 2022.\n[BCKP20] Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar, andM anish Purohit. Onlinelearning\nwith imperfect hints. In International Conference on Machine Learning , pages 822–\n831. PMLR, 2020.\n[BGGJ22] Siddhartha Banerjee, Vasilis Gkatzelis, Artur Go rokh, and Billy Jin. Online nash\nsocial welfare maximization with predictions. In Joseph (S eﬃ) Naor and Niv Buch-\nbinder, editors, Proceedings of the 2022 ACM-SIAM Symposium on Discrete Algo-\nrithms, SODA 2022, Virtual Conference / Alexandria, VA, USA, January 9 - 12,\n2022, pages 1–19. SIAM, 2022.\n[BGH+23] Siddhartha Banerjee, Vasilis Gkatzelis, Safwan Hossai n, Billy Jin, Evi Micha, and\nNisarg Shah. Proportionally fair online allocation of publ ic goods with predictions.\nInProceedings of the Thirty-Second International Joint Confere nce on Artiﬁcial In-\ntelligence, IJCAI 2023, 19th-25th August 2023, Macao, SAR, Chi na, pages 20–28.\nijcai.org, 2023.\n[BGS24] Eric Balkanski, Vasilis Gkatzelis, and Golnoosh Sh ahkarami. Randomized strategic\nfacility location with predictions, 2024.\n[BGT23] Eric Balkanski, Vasilis Gkatzelis, and Xizhi Tan. S trategyproof scheduling with pre-\ndictions. InYael TaumanKalai, editor, 14th Innovations in Theoretical Computer Sci-\nence Conference, ITCS 2023, January 10-13, 2023, MIT, Cambridge, Ma ssachusetts,\nUSA, volume 251 of LIPIcs, pages 11:1–11:22, 2023.\n21\n\n[BGTC24] Zohar Barak, Anupam Gupta, and Inbal Talgam-Cohen . Mac advice for facility loca-\ntion mechanism design, 2024.\n[BMS20] Etienne Bamas, Andreas Maggiori, and Ola Svensson. The primal-dual method for\nlearning augmented algorithms. Advances in Neural Information Processing Systems ,\n33:20083–20094, 2020.\n[CFL+21] Hau Chan, Aris Filos-Ratsikas, Bo Li, Minming Li, and Che nhao Wang. Mechanism\ndesignforfacility location problems: Asurvey. InZhi-Hua Zhou,editor, Proceedings of\nthe Thirtieth International Joint Conference on Artiﬁcial Inte lligence, IJCAI 2021,\nVirtual Event / Montreal, Canada, 19-27 August 2021 , pages 4356–4365. ijcai.org,\n2021.\n[CKK+15] Ioannis Caragiannis, Christos Kaklamanis, Panagiotis Kanellopoulos, Maria Ky-\nropoulou, Brendan Lucier, Renato Paes Leme, and ´Eva Tardos. Bounding the ineﬃ-\nciency ofoutcomes ingeneralized secondpriceauctions. J. Econ. Theory , 156:343–388,\n2015.\n[CKK23] George Christodoulou, Elias Koutsoupias, and Anna m´ aria Kov´ acs. A proof of the\nnisan-ronen conjecture. In Barna Saha and Rocco A. Servedio , editors, Proceedings of\nthe 55th Annual ACM Symposium on Theory of Computing, STOC 2023, O rlando,\nFL, USA, June 20-23, 2023 , pages 672–685. ACM, 2023.\n[CSV24] George Christodoulou, Alkmini Sgouritsa, and Ioan nis Vlachos. Mechanism design\naugmented with output advice, 2024.\n[DFMN12] Elad Dokow, Michal Feldman, Reshef Meir, and Ilan N ehama. Mechanism design on\ndiscrete lines and cycles. In Boi Faltings, Kevin Leyton-Br own, and Panos Ipeirotis,\neditors,Proceedings of the 13th ACM Conference on Electronic Commerce, EC 2012,\nValencia, Spain, June 4-8, 2012 , pages 423–440. ACM, 2012.\n[DIL+21] Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassil-\nvitskii. Faster matchings via learned duals. In Marc’Aurel io Ranzato, Alina Beygelz-\nimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vau ghan, editors, Ad-\nvances in Neural Information Processing Systems 34: Annual Co nference on Neural\nInformation Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual ,\npages 10393–10406, 2021.\n[EGN+11] Bruno Escoﬃer, Laurent Gourv` es, Kim Thang Nguyen, Fann y Pascual, and Olivier\nSpanjaard. Strategy-proof mechanisms for facility locati on games with many facilities.\nIn Ronen I. Brafman, Fred S. Roberts, and Alexis Tsouki` as, e ditors,Algorithmic De-\ncision Theory - Second International Conference, ADT 2011, Pis cataway, NJ, USA,\nOctober 26-28, 2011. Proceedings , volume 6992, pages 67–81. Springer, 2011.\n[EMFGH23] El-Mahdi El-Mhamdi, Sadegh Farhadkhani, Rachid Guerraoui, and Lˆ e-Nguyˆ en\nHoang. On the strategyproofness of the geometric median. In International Con-\nference on Artiﬁcial Intelligence and Statistics , pages 2603–2640. PMLR, 2023.\n[FGGP21] Dimitris Fotakis, EvangeliaGergatsouli, Themis Gouleakis, andNikolas Patris. Learn-\ning augmented online facility location. arXiv preprint arXiv:2107.08277 , 2021.\n22\n\n[FS21] Willem Feijen and Guido Sch¨ afer. Dijkstras algorit hm with predictions to solve the\nsingle-source many-targets shortest-path problem. arXiv preprint arXiv:2112.11927 ,\n2021.\n[FT10] Dimitris Fotakis and Christos Tzamos. Winner-impos ing strategyproof mechanisms\nfor multiple facility location games. In Amin Saberi, edito r,Internet and Network\nEconomics - 6th International Workshop, WINE 2010, Stanford, CA, USA, December\n13-17, 2010. Proceedings , volume 6484, pages 234–245. Springer, 2010.\n[FT14] Dimitris Fotakis and Christos Tzamos. On the power of deterministic mechanisms for\nfacility location games. ACM Trans. Economics and Comput. , 2(4):15:1–15:37, 2014.\n[FT16] Dimitris Fotakis and Christos Tzamos. Strategyproo f facility location for concave cost\nfunctions. Algorithmica , 76(1):143–167, 2016.\n[FW13] Michal Feldman and Yoav Wilf. Strategyproof facilit y location and the least squares\nobjective. InMichael J. Kearns, R. Preston McAfee, and ´EvaTardos, editors, Proceed-\nings of the fourteenth ACM Conference on Electronic Commerce, E C 2013, Philadel-\nphia, PA, USA, June 16-20, 2013 , pages 873–890. ACM, 2013.\n[GHC23] Sumit Goel and Wade Hann-Caruthers. Optimality of t he coordinate-wise median\nmechanism for strategyproof facility location in two dimen sions.Social Choice and\nWelfare, 61(1):11–34, 2023.\n[GKST22] Vasilis Gkatzelis, Kostas Kollias, Alkmini Sgour itsa, and Xizhi Tan. Improved price of\nanarchy via predictions. In David M. Pennock, Ilya Segal, an d Sven Seuken, editors,\nEC ’22: The 23rd ACM Conference on Economics and Computation, Bou lder, CO,\nUSA, July 11 - 15, 2022 , pages 529–557. ACM, 2022.\n[IB22] Gabriel IstrateandCosminBonchis. Mechanism desig n withpredictionsfor obnoxious\nfacility location. arXiv preprint arXiv:2212.09521 , 2022.\n[IKQP21] Sungjin Im, Ravi Kumar, Mahshid Montazer Qaem, and Manish Purohit. Online\nknapsack with frequency predictions. In Marc’Aurelio Ranz ato, Alina Beygelzimer,\nYann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors,Advances in\nNeural Information Processing Systems 34: Annual Conference on Neural Information\nProcessing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 2733–\n2743, 2021.\n[JLL+21] Shaofeng H-C Jiang, Erzhi Liu, You Lyu, Zhihao Gavin Tang , and Yubo Zhang.\nOnline facility location with predictions. arXiv preprint arXiv:2110.08840 , 2021.\n[KBC+18] Tim Kraska, Alex Beutel, Ed H Chi, Jeﬀrey Dean, and Neoklis Polyzotis. The case\nfor learned index structures. In Proceedings of the 2018 international conference on\nmanagement of data , pages 489–504, 2018.\n[LLMV20] SilvioLattanzi, ThomasLavastida, BenjaminMose ley, andSergei Vassilvitskii. Online\nscheduling via learned weights. In Proceedings of the Fourteenth Annual ACM-SIAM\nSymposium on Discrete Algorithms , pages 1859–1877. SIAM, 2020.\n[LSV23] Silvio Lattanzi, Ola Svensson, and Sergei Vassilvi tskii. Speeding up bellman ford via\nminimum violation permutations. In International Conference on Machine Learning ,\npages 18584–18598. PMLR, 2023.\n23\n\n[LSWZ10] Pinyan Lu, Xiaorui Sun, Yajun Wang, andZeyuan Alle n Zhu. Asymptotically optimal\nstrategy-proof mechanisms for two-facility games. In Davi d C. Parkes, Chrysanthos\nDellarocas, and Moshe Tennenholtz, editors, Proceedings 11th ACM Conference on\nElectronic Commerce (EC-2010), Cambridge, Massachusetts, US A, June 7-11, 2010 ,\npages 315–324. ACM, 2010.\n[LV21] Thodoris Lykouris and Sergei Vassilvitskii. Compet itive caching with machine learned\nadvice.J. ACM, 68(4):24:1–24:25, 2021.\n[Mei19] Reshef Meir. Strategyproof facility location for t hree agents on a circle. In Interna-\ntional symposium on algorithmic game theory , pages 18–33. Springer, 2019.\n[Mit18] Michael Mitzenmacher. A model for learned bloom ﬁlt ers and optimizing by sand-\nwiching. Advances in Neural Information Processing Systems , 31, 2018.\n[MLL+21] Reshef Meir, J´ erˆ ome Lang, Julien Lesca, Nicholas Matt ei, and Natan Kaminsky. A\nmarket-inspired bidding scheme for peer review paper assig nment. In Thirty-Fifth\nAAAI Conference on Artiﬁcial Intelligence, AAAI 2021, Thirty- Third Conference on\nInnovative Applications of Artiﬁcial Intelligence, IAAI 2021 , The Eleventh Sympo-\nsium on Educational Advances in Artiﬁcial Intelligence, EAA I 2021, Virtual Event,\nFebruary 2-9, 2021 , pages 4776–4784. AAAI Press, 2021.\n[Mou80] Herv´ e Moulin. Onstrategy-proofness andsinglepe akedness. Public Choice , 35(4):437–\n455, 1980.\n[MV22] Michael Mitzenmacher and Sergei Vassilvitskii. Alg orithms with predictions. Com-\nmun. ACM , 65(7):33–35, 2022.\n[NR99] Noam Nisan and Amir Ronen. Algorithmic mechanism des ign. InProceedings of the\nthirty-ﬁrst annual ACM symposium on Theory of computing , pages 129–140, 1999.\n[PSK18] Manish Purohit, Zoya Svitkina, and Ravi Kumar. Impr oving online algorithms via\nml predictions. In S. Bengio, H. Wallach, H. Larochelle, K. G rauman, N. Cesa-\nBianchi, andR.Garnett, editors, Advances in Neural Information Processing Systems ,\nvolume 31. Curran Associates, Inc., 2018.\n[PT13] Ariel D Procaccia and Moshe Tennenholtz. Approximat e mechanism design without\nmoney.ACM Transactions on Economics and Computation (TEAC) , 1(4):1–26, 2013.\n[PvdSS93] Hans Peters, Hans van der Stel, and Ton Storcken. R ange convexity, continuity, and\nstrategy-proofness of voting schemes. Zeitschrift f¨ ur Operations Research , 38:213–229,\n1993.\n[PWZ18] Ariel Procaccia, David Wajc, and Hanrui Zhang. Appr oximation-variance tradeoﬀs\nin facility location games. In Proceedings of the AAAI Conference on Artiﬁcial Intel-\nligence, volume 32, 2018.\n[Rou21] Tim Roughgarden. Beyond the worst-case analysis of algorithms . Cambridge Univer-\nsity Press, 2021.\n[SV02] James Schummer and Rakesh V Vohra. Strategy-proof lo cation on a network. Journal\nof Economic Theory , 104(2):405–428, 2002.\n24\n\n[SV16] Paolo Seraﬁno and Carmine Ventre. Heterogeneous fac ility location without money.\nTheor. Comput. Sci. , 636:27–46, 2016.\n[TYZ20] Pingzhong Tang, Dingli Yu, and Shengyu Zhao. Charac terization of group-\nstrategyproof mechanisms for facility location in strictl y convex space. In P´ eter Bir´ o,\nJason D. Hartline, Michael Ostrovsky, and Ariel D. Procacci a, editors, EC ’20: The\n21st ACM Conference on Economics and Computation, Virtual Even t, Hungary, July\n13-17, 2020 , pages 133–157. ACM, 2020.\n[Wal20] Toby Walsh. Strategy proof mechanisms for facility location in euclidean and man-\nhattan space. arXiv preprint arXiv:2009.07983 , 2020.\n[XL22] Chenyang Xu and Pinyan Lu. Mechanism design with pred ictions. In Luc De Raedt,\neditor,Proceedings of the Thirty-First International Joint Conferen ce on Artiﬁcial\nIntelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022 , pages 571–577. ijcai.org,\n2022.\nA Missing Proofs\nFact 4.8. For arbitrary points A,P1,P2∈Mand a point P∈S-Path(P1,P2)on the shortest path\nd(A,P)≤d(P,P2)\nd(P1,P2)·d(A,P1)+d(P,P1)\nd(P1,P2)·d(A,P2). (11)\nProof.By strict convexity and since ∝bardblP2−P∝bardbl+∝bardblP−P1∝bardbl=∝bardblP2−P1∝bardbl, we have P=/bardblP2−P/bardbl\n/bardblP2−P1/bardbl·P1+\n/bardblP−P1/bardbl\n/bardblP2−P1/bardbl·P2. Hence, P−A=/bardblP2−P/bardbl\n/bardblP2−P1/bardbl·(P1−A)+/bardblP−P1/bardbl\n/bardblP2−P1/bardbl·(P2−A). Then by triangle inequality\nfor the norm∝bardbl·∝bardbl, we get\nd(P,A) =∝bardblP−A∝bardbl=∝bardbl∝bardblP2−P∝bardbl\n∝bardblP2−P1∝bardbl·(P1−A)+∝bardblP−P1∝bardbl\n∝bardblP2−P1∝bardbl·(P2−A)∝bardbl\n≤∝bardblP2−P∝bardbl\n∝bardblP2−P1∝bardbl·∝bardblP1−A∝bardbl+∝bardblP−P1∝bardbl\n∝bardblP2−P1∝bardbl·∝bardblP2−A∝bardbl=d(P,P2)\nd(P1,P2)·d(A,P1)+d(P,P1)\nd(P1,P2)·d(A,P2).\n25",
  "textLength": 77009
}