{
  "paperId": "109d8d701f83497ca074e33f3d0443799fa28fe9",
  "title": "LISA: Towards Learned DNA Sequence Search",
  "pdfPath": "109d8d701f83497ca074e33f3d0443799fa28fe9.pdf",
  "text": "LISA: Towards Learned DNA Sequence Search\nDarryl Ho\nMIT\ndarry140@mit.eduJialin Ding\nMIT\njialind@mit.eduSanchit Misra\nIntel Labs\nsanchit.misra@intel.com\nNesime Tatbul\nIntel Labs and MIT\ntatbul@csail.mit.eduVikram Nathan\nMIT\nvikramn@mit.eduVasimuddin Md\nIntel Labs\nvasimuddin.md@intel.com\nTim Kraska\nMIT\nkraska@mit.edu\nAbstract\nNext-generation sequencing (NGS) technologies have enabled affordable se-\nquencing of billions of short DNA fragments at high throughput, paving the way\nfor population-scale genomics. Genomics data analytics at this scale requires\novercoming performance bottlenecks, such as searching for short DNA sequences\nover long reference sequences. In this paper, we introduce LISA (Learned Indexes\nfor Sequence Analysis), a novel learning-based approach to DNA sequence search.\nAs a ﬁrst proof of concept, we focus on accelerating one of the most essential ﬂavors\nof the problem, called exact search . LISA builds on and extends FM-index, which\nis the state-of-the-art technique widely deployed in genomics toolchains. Initial\nexperiments with human genome datasets indicate that LISA achieves up to a factor\nof4\u0002performance speedup against its traditional counterpart.\n1 Introduction\nRapid advances in high-throughput next-generation sequencing (NGS) technologies have enabled\naffordable sequencing of billions of short DNA fragments (called “reads”) at an unprecedented scale.\nFor example, the Illumina NovaSeq 6000 Sequencer can sequence 20billion reads of length 150each\nin less than 2days, generating 6Terabases of data at a low cost of about $1000 per human genome\n[1]. Already today, a growing number of public and private sequencing centers with hundreds of NGS\ndeployments pave the way for population-level genomics. However, realizing this vision in practice\nheavily relies on building scalable systems for high-speed genomics data analysis.\nDNA sequence alignment plays a critical role in genome analysis. In its simplest form, an aligner\ntries to piece together the short reads by mapping each individual read to a long reference genome (e.g.,\nthe human genome consisting of 3billion bases). The key operation that has been shown to constitute\na signiﬁcant performance bottleneck during this mapping process is the search for exact orinexact\nmatches of read substrings over the given reference sequence [ 2–7]. In this paper, we focus on the\nexact search variant of this search problem.\nThe state-of-the-art technique to perform exact search is based on building an FM-index over the\nreference genome [8]. The key idea behind an FM-index is that, in the lexicographically sorted order\nof all sufﬁxes of the reference sequence, all matches of a short DNA sequence (a.k.a., a “query”) will\nfall in a single region matching the preﬁxes of contiguously located sufﬁxes. Over the years, many\nimprovements have been made to make the FM-index more efﬁcient, leading to several state-of-the-art\nWorkshop on Systems for ML at NeurIPS 2019, Vancouver, Canada.arXiv:1910.04728v1  [cs.DB]  10 Oct 2019\n\nimplementations that are highly cache- and processor-optimized [ 3–7,9–15,10,15]. Hence, it\nbecomes increasingly more challenging to further improve this critical step in the genomics pipeline\nto scale with increasing data growth.\nIn this paper, we propose a different approach to improving the sequence search performance:\nLISA (Learned Indexes for Sequence Analysis). The core idea behind LISA, which enables a new\nML-enhanced algorithm for DNA search, is to speed up the process of ﬁnding the right region of\nsufﬁxes by learning the distribution of sufﬁxes in the reference. We do this in a way similar to how\nlearned indexes capture value distributions through models learned from data [16].\nWhen evaluated on an IntelR\rCoreTMi9-9900K 3.6 GHz processor, despite being single-threaded and\nnot yet fully optimized to the underlying hardware architecture, our current implementation achieves\nnearly 4\u0002speedup against a state-of-the-art single-threaded, CPU-optimized version of the FM-index\nbased algorithm [ 15], for a workload of 50million queries matched against the human genome. This\nearly result shows that learned DNA sequence search is a promising idea1.\nTo the best of our knowledge, this is the ﬁrst work exploring how ML-enhanced algorithms can\nimprove the process of DNA sequence search, while providing identical semantic guarantees as the\ntraditional algorithms. This work is a preliminary proof of concept that can be used as a building block\ntowards fully-optimized learning-based tools for DNA sequence search. In summary, this paper makes\nthe following contributions:\n\u000fenhancements to the FM-index that enable the application of learning-based search,\n\u000fa new search algorithm that applies the learning-based approach to the enhanced FM-index to ﬁnd\nall exact matches,\n\u000fan experimental comparison of our approach against a highly-tuned baseline using realistic\nworkloads on the human genome.\nIn the rest of this paper, we ﬁrst provide some brief background on the traditional FM-index based\nexact search algorithm as well as the idea of learned index structures which inspired this work; then\nwe present our new approach LISA, along with results from our experimental study.\n2 Background\nA DNA sequence is a string over the alphabet, \u0006 = {A, C, G, T}, representing the four bases. For\nthe rest of this paper, we use the terms “sequence” and “string” interchangeably, as well as the terms\n“base” and “character”. Exact DNA sequence search is a key kernel in many genomics tools, including\nthe widely-used sequence mapping tool Bowtie 2 [ 4]. Given a reference sequence Rand a query\nsequenceQ, the goal of exact sequence search is to ﬁnd exact end-to-end matches of QinR. Typically,\njRj\u0019109bases; e.g., the length of the human genome is around 3 billion bases. On the other hand,\njQjis typically less than 200 bases; e.g., the default query length in Bowtie 2 is 21.\nFM-index: Fig. 1 depicts the construction of the FM-index for an example reference sequence R.\nFirst, we append Rwith the character $=2\u0006which is lexicographically smaller than all characters\nin\u0006. Subsequently, we obtain all the rotations of R(Rotations(R)). The lexicographically sorted order\nof the rotations forms the BW-matrix. The BWT ( B) is the last column of the BW-matrix. The original\npositions inRof the ﬁrst bases of these rotations constitute the sufﬁx array ( S).\nAll the exact matches of a query can be found as preﬁxes of the rotations in the BW-matrix. Since the\nBW-matrix is lexicographically sorted, these matches are located in contiguous rows of the BW-matrix.\nTherefore, for a query, all the matches can be represented as a range of rows of the BW-matrix. This\nrange is called the SA interval of the query. For example, in Fig. 1, the SA interval of query “AC” is\n[1;2]. The values of the sufﬁx array in the SA interval are 5 and 2. Indeed, the sequence “AC” is found\nat positions 5 and 2 in the reference sequence.\nThe FM-index is used to expedite search for the SA interval [ 18]. It consists of the sufﬁx array Sand\nthe BWTB, as well asDandOdata structures. D(x)is the count of bases in R[0;jRj\u00001]that are\nlexicographically smaller than x2\u0006.O(x;i)is the count of occurrences of base xinB[0;i]. Note\nthat the BW-matrix is not stored.\n1Intel Xeon and Intel Xeon Phi are trademarks of Intel Corporation or its subsidiaries in the U.S. and/or other\ncountries. Other names and brands may be claimed as the property of others. c\rIntel Corporation\n2\n\nFigure 1: FM-index ( S,B,D,O) and BW-matrix for sample reference sequence R ATACGAC$ .\nThe lexicographical ordering is $ <A<C<G<T [17].\nUsing the FM-index, ﬁnding the SA interval is done using the backward-search algorithm . For a\nreference sequence of length n, the algorithm initializes the SA interval to [0;n). The SA interval is\nupdated over the course of the algorithm. Speciﬁcally, the algorithm processes the query sequence\nbackwards, starting from the last character, prepending one character at a time and updating the SA\ninterval after each prepended character in O(1)time. To update the SA interval, the FM-index supports\na functionf:(char;int )!intthat takes the prepended character cand an integer location i, and ﬁnds\ninO(1)time the lower-bound location i0in the BW-matrix of string concat (c;BW-matrix [i]). (The\nlower bound of a string sis the ﬁrst entry in the BW-matrix which does not compare less than s.) Given\nan SA interval [l;u), after prepending the character c, the SA interval is updated to [f(c;l);f(c;u)).\nSince prepending each character takes O(1)time, the overall algorithm takes O(jQj)time. For further\ninformation on the FM-index, see [8].\nLearned Indexes: Recent work on learned index structures has introduced the idea that indexes are\nessentially models that map inputs to positions and, therefore, can be replaced by other types of models,\nsuch as machine learning models [ 16]. For example, a B-tree index maps a given key to the position\nof that key in a sorted array. Kraska et al. show that using knowledge of the distribution of keys can\nproduce a learned model, called the recursive model index (RMI), that outperforms B-trees in query\ntime and memory footprint.\nTaking a similar perspective, the FM-index can be seen as a model that maps a given query sequence\nto the SA interval for that query sequence. Based on this insight, in LISA, we use knowledge of the\ndistribution of subsequences within the reference sequence to create a learned index structure that\nenables faster exact search queries.\n3 LISA\nBackward-search algorithm performs exact search of a query Qusing the FM-index by iterating\nthrough the query sequence in backwards order, one base at a time, thereby consuming O(jQj)time.\nThe key idea of LISA is to iterate backwards through the query sequence in chunks of Kbases at a\ntime, so that exact search takes O(jQj=K)time. To do this, LISA requires two components: (1) a\nnew data structure called the IP-BWT that enables processing Kbases at a time, and (2) a method\nto efﬁciently search through the IP-BWT, for which we use an RMI. Similar to the backward-search\nalgorithm , the goal of LISA is to output the SA interval of a query sequence.\nIP-BWT: In the backward-search algorithm , in order to update the SA interval after prepending\na character, FM-index supports a function f: (char;int )!intthat takes the character cand an\ninteger location i, and ﬁnds in O(1)time the lower-bound location i0in the BW-matrix of string\nconcat (c;BW-matrix [i]). For LISA, we need to support a similar function that takes in a length- K\nstringsand a location i, and returns another location i0(i.e.fK: (charK;int)!int) representing\nthe lower-bound location in the BW-matrix of string concat (s;BW-matrix [i]).\n3\n\nAlgorithm 1 Exact Search Algorithm using IP-BWT\nInput:Q, a query string; fK: (charK;int)!int, a function that ﬁnds the lower-bound location of\n(charK;int)in the IP-BWT\nOutput: [low;high ), an SA interval.\n1:low;high 0;n\n2:splitQintodjQj=Kechunks, each of length K, with the ﬁnal chunk possibly shorter than K\n3:forCin reversed order of chunks do\n4: ifjCj<Kthen\n5: /* Special case for when ﬁnal chunk has length less than K*/\n6:Clow C+\\$\"+\\A\"\u0002(K\u0000jCj\u0000 1)\n7:Chigh C+\\T\"\u0002(K\u0000jCj)\n8:low;high fK((Clow;low));fK((Chigh;high ))\n9: else\n10:low;high fK((C;low));fK((C;high ))\n11: end if\n12:end for\n13:return [low;high )\nFor this purpose, we introduce the Index-Paired BWT (IP-BWT) array. Each entry of IP-BWT consists\nof a(charK;int)pair. The ﬁrst part is the ﬁrst Kcharacters of the corresponding BW-matrix row.\nThe second part is the BW-matrix location of the string with the ﬁrst Kand the lastn\u0000Kcharacters\nswapped. Our desired function fK:(charK;int)!intis now equivalent to ﬁnding the lower-bound\nlocation of the input (charK;int)pair in the IP-BWT array. We are free to choose any implementation\nfor how to ﬁnd that lower-bound location; for example, since the IP-BWT is sorted, we could do a\nbinary search over the entries of the IP-BWT. Fig. 2 shows how to create an IP-BWT with K=3.\n00$CATTATTAGGA \n01A$CATTATTAGG \n02AGG A$CATTATT \n03ATTAGGA$CATT \n04ATTATTAGGA$C \n05CATTATTAGGA$ \n06GA$CATTATTAG \n07GGA $CATTATTA \n08TAGGA$CATTAT \n09TATTAGGA$CAT \n10TTAGGA$CATTA \n11TTATTAGGA$CA 00$CA, 11\n01A$C, 04\n02AGG , 01\n03ATT, 02\n04ATT, 03\n05CAT, 09\n06GA$, 05\n07GGA , 00\n08TAG, 06\n09TAT, 08\n10TTA, 07\n11TTA, 10BW -Matrix IP-BWT \nFigure 2: Conversion of a BW-\nMatrix to IP-BWT on reference\nCATTATTAGGA , whereK=3.Alg. 1 shows the exact search algorithm using IP-BWT. For\nexample, using the reference sequence and IP-BWT from Fig. 2,\nlet the query sequence be ATTA . We split this into two chunks:\nATT andA(line 2). We ﬁrst use the RMI to ﬁnd the lower\nbound locations of (A$A;0)and(ATT;n ), which are 1 and\n5, respectively. We then use the RMI to ﬁnd the lower bound\nlocations of (ATT; 1)and(ATT; 5), which are 3 and 5. Our\nalgorithm gives the interval [3;5). We can conﬁrm that ATTA\ncan be found in position 3 and 4 of the BW-matrix.\nFaster Chunk Processing using RMI: Using the IP-BWT, we\nare able to process the query sequence in chunks of Kbases\nat a time. However, when processing each chunk, we must\nevaluate the function fK, which involves a binary search over\nthe IP-BWT. This takes O(logn)time, where nis the number\nof entries in the IP-BWT, which is equivalent to the length of\nthe reference sequence. Therefore, the overall runtime of exact\nsearch using IP-BWT and evaluating fKwith binary search is\nO(jQjlogn=K). For large reference sequences, this might be\nslower than backward-search using the FM-index.\nIn order to avoid paying the cost of a binary search for each evaluation of fK, we use a learned approach\nto supportO(1)evaluation of fK. In particular, fKis a model that maps input keys ( (charK;int)pairs)\nto their positions in the sorted IP-BWT. We model fKusing the RMI, which is a hierarchy of models\nthat is quick to evaluate [ 16]; the RMI conceptually resembles a hierarchical mixture of experts [ 19].\nFig. 3 shows an example of using a 3-layer RMI to evaluate fKin three steps: (1) since the RMI only\naccepts numbers as inputs, we ﬁrst convert the input (charK;int)into a number. Since the alphabet\n\u0006only has 4 characters, any character can be represented in 2 bits. Therefore, we convert charK\ninto a number with 2Kbits by concatenating the bits of the individual characters together. We then\nappend the bits of the int. Note that we have a special case for handling the sentinel character $while\nmaintaining this 2-bit encoding. (2) We give the encoded input to the RMI and traverse down the layers\nof the RMI to a leaf model. The leaf model predicts the position in the IP-BWT where it expects to ﬁnd\nthe input pair. (3) If the predicted position does not contain the input pair, we use linear search over\nthe IP-BWT starting from the predicted position to ﬁnd the actual position of the pair. Note that this\n4\n\nlearning-based approach to modeling fKguarantees correctness; LISA will produce exactly the same\nresults as using backward search with FM-index.\nUnlike the RMI proposed in [ 16], which constructs the model hierarchy top-down according to the\nuser-selected number of models at each layer, we construct the RMI bottom-up according to desired\nbounds on the average error between the predicted position and the actual position. We use these\ndesired bounds to determine the number of models at each layer. Bounds on the average prediction\nerror are useful for limiting the time spent on step 3 of the RMI evaluation workﬂow described above,\nbecause they directly reﬂect the average number of iterations of linear search. Given a desired bound \u000b\non the average error, we begin building the RMI at the leaf layer by partitioning the IP-BWT entries into\ncontiguous blocks that can each be modeled with average error no more than \u000b. We ﬁnd this partitioning\nby starting with one partition that comprises of the entire IP-BWT, then recursively splitting equally\nin two until each partition achieves the \u000bbound. A leaf model is built on the entries of each partition.\nThe smallest entry in each partition is used to repeat this procedure in order to ﬁnd the partitions in the\nlayer above the leaf layer, and so forth until we have one model at the root layer. Since the non-leaf\nmodels are allowed to have prediction error, we may need to perform linear search at each layer of the\nRMI, instead of only the leaf layer. Note that we can set different values of \u000bfor each layer of the RMI.\nAlso, note that at the root layer, there is only one partition; therefore, we do not set an \u000bbound for\nthe root model. Since we have no guarantee on average error for the root model, the root model uses\nexponential search instead of linear search.\n... (GAC, 13) (GAC, 429) (GAT, 589) (GCC, 39) (GCG, 193) ...IP-BWT Input: (“GCC”, 39) \nRMI\n(3) Linear search Model \nModel Model \nModel Model Model 2-bit encoder (1) Encode input as number \n(2) Predict position \nusing RMI Layer 1 \nLayer 2 \nLayer 3 \n(Leaf layer) ...\n...Model \nModel \nOutput: 54 Pos: 51 Pos: 52 Pos: 53 Pos: 54 Pos: 55 \nFigure 3: Using a 3-layer RMI to evaluate ffor an example input (GCC; 39). The RMI predicts\nposition 52, and linear search ﬁnds the correct position. The solid red lines show the traversal path\ndown the RMI.\nOptimization for Batched Queries: So far, we have presented our method of processing a single\nquery. However, in practice, queries arrive in large batches. For large query batches, we can adopt an\nadditional optimization. Because the ﬁnal layer of the RMI (i.e., RMI leaves), which are responsible for\npredicting locations, are arranged in sorted order, if the queries also arrive in sorted order, we can use\nthedouble-pointer technique (Alg. 2) to ﬁnd for each query its corresponding RMI leaf. This resembles\nthe merge step of merge-sort. When the number of queries is \n(number of RMI leaves ), the amortized\ntime for each query to ﬁnd its RMI leaf is O(1). This avoids the cost of traversing down the RMI for\neach query, and also improves cache locality.\nNote that this optimization for batches cannot be easily applied to the FM-index. This optimization\nrequires that inputs to fKare sorted; since IP-BWT processes in chunks of Kcharacters, we only need\nto sort queries O(jQj=K)times. However, since backward search with the FM-index prepends only\none character at a time, it would need to sort the inputs to fafter each prepended character. Sorting\ninputsO(jQj)times would impose a signiﬁcant performance bottleneck, which makes this optimization\nimpractical when using FM-index.\n5\n\nAlgorithm 2 The RMI-based exact search algorithm for large query batch\nInput:qs[], a list of query strings encoded as numbers.\nOutput: a list of SA intervals.\n1:sortqs\n2:leafPtr &rmi:leaves [0]\n3:forqinqsdo\n4: whileq\u0015leafPtr:ipbwt _range _upper _bound do\n5: incrementleafPtr\n6: end while\n7:prediction leafPtr:predict (q)\n8: perform linear search around prediction to ﬁnd the SA interval of q\n9:end for\nDiscussion: LISA’s speed advantage over FM-index comes from two components: (1) the IP-BWT,\nwhich allows LISA to process K-character chunks of the query at a time, whereas FM-index processes\none character at a time, and (2) using an RMI to process each K-character chunk in O(1)time, whereas\na naive binary search would take O(logn)time per chunk. Therefore, an exact search query using\nFM-index takes O(jQj)time, whereas LISA takes O(jQj=K)time.\nTo discuss memory consumption, we measure in bytes in terms of n, the length of the reference sequence.\nThe reference sequence itself therefore takes 0:25nspace. In the state-of-the-art implementation of\nbackward-search algorithm , the space of sufﬁx array is 4n, a compressed structure that combines\nBWT andOis2n, andDis negligible, for a total space consumption of 6n. For LISA, the space of\nthe sufﬁx array is 4n, IP-BWT is (0:25K+4)n, and the RMI is usually around 0:5n, for a total space\nconsumption of 8:5n+0:25Kn. For example, in Bowtie 2 the default value of jQjis 21, so using an\nIP-BWT with K=21 , LISA takes around 13:75nspace, which is larger than the FM-index. However,\nslightly larger space consumption is usually not a concern in practice, and if necessary LISA can use\nsmallerKor compress the IP-BWT. Though the space usage of LISA would increase with larger values\nofK, we ﬁnd through experiments that LISA maintains good performance using an IP-BWT with\nK= 21 , even for large query lengths. Therefore, the space of LISA does not need to grow beyond\naround 13:75n.\nCould we replace the RMI with some other index structure that can evaluate fKover the IP-BWT\neven faster? [ 16] showed that RMIs perform better than binary search and B trees. A lookup table\n(implemented as an array) that stores the output of fKfor every possible pair (charK;int)would also\nallowO(1)evaluations but would far exceed memory capacity, even if we use an IP-BWT with very\nsmallK. However, it is possible to combine a downsampled version of the lookup table with binary\nsearch, which we discuss in the evaluation. Another idea is to use a hash table to map all nexisting pairs\n(charK;int)to their positions; however, this fails because we almost always need to evaluate fKon\npairs that do not exist. For example, in the example attached to Fig. 2, we ﬁnd the lower bounds of four\npairs— (A$A;0),(ATT;n ),(ATT; 1), and(ATT; 5)—none of which exist in the IP-BWT. Also, note\nthat since the entries of the IP-BWT must be sorted in order to maintain one contiguous SA interval, the\nIP-BWT itself cannot be replaced with a hash table to enable faster searches.\n4 Evaluation\nWe present preliminary results2for LISA. Experiments use SIMD, running a single-thread implemen-\ntation on an Ubuntu system with IntelR\rCoreTMi9-9900K 3.6GHz processor and 64GB RAM. As\nour baseline, we use a highly CPU-optimized implementation of backward search algorithm that is\n2Software and workloads used in performance tests may have been optimized for performance only on Intel\nmicroprocessors. Performance tests, such as SYSmark and MobileMark, are measured using speciﬁc computer\nsystems, components, software, operations and functions. Any change to any of those factors may cause the\nresults to vary. You should consult other information and performance tests to assist you in fully evaluating your\ncontemplated purchases, including the performance of that product when combined with other products. For more\ninformation go to www.intel.com/benchmarks.\nBenchmark results were obtained prior to implementation of recent software patches and ﬁrmware updates\nintended to address exploits referred to as \"Spectre\" and \"Meltdown\". Implementation of these updates may make\nthese results inapplicable to your device or system.\n6\n\nsigniﬁcantly faster than its alternatives [ 15]. We also compare with doing backwards search using\nIP-BWT and binary search (i.e., without the RMI).\nWorkload Scenario: We evaluate LISA on a real-world scenario: we use whole human genome as the\nreference sequence and for query sets, we use large sets of short query sequences of various lengths as\nwould be found in several prominent sequence aligners. We train LISA using an IP-BWT with K=21 .\nThe RMI has three layers, only uses linear regression models, and we construct the RMI using \u000b=14\nfor the second layer models and \u000b=6for the leaf layer models. \u000bis tuned once for optimal performance\non the reference sequence; the RMI is not re-trained or re-tuned for each experiment. We evaluate on\nfour different query sequence lengths: (1) jQj= 21 , so that LISA processes exactly one chunk, (2)\njQj=42 , so that LISA processes multiple whole chunks, (3) jQj=32 , so that LISA processes a chunk\nshorter than K, and (4) a very long query, jQj= 200 . For each of these query sequence lengths, we\ngenerate a batch of 50 million query sequences randomly from the human genome to be our query set,\nand run them together with LISA, using the batched-query optimization from §3.\nTab. 1 shows that LISA is 2.73 \u0002to 3.97\u0002faster than the optimized FM-index baseline on these query\nlengths. Query lengths that are a perfect multiple of K(i.e., 21 and 42) perform the best. The query\nlength of 32 has slightly lower relative performance, as LISA must still process 2 chunks per query, as\nif the query has length 42. The very long query sequence has lower relative performance, as LISA’s\nperformance does not scale linearly: for longer queries, the time spent on sorting grows super-linearly.\nLISA achieves around a 2 \u0002performance boost from using the RMI instead of binary search.\njQj=21jQj=32jQj=42jQj=200\nOptimized FM-index 1509 2414 3284 15411\nIP-BWT with binary search 785 (1.92 \u0002) 1424 (1.70\u0002) 1779 (1.85\u0002) 10414 (1.48\u0002)\nLISA 383 (3.94 \u0002) 762 (3.17\u0002) 827 (3.97\u0002) 5646 (2.73\u0002)\nTable 1: Average query time (measured in ticks per query) of exact search on 50 million queries, while\nvarying query length. Relative speedup to FM-index is shown in parentheses.\n100101102103104105106107108109\nBatch size100020003000Avg query time (ticks/query)\nVarying batch size, |Q|=21\nLISA\nFM-index\nFigure 4: LISA’s performance advantage increases with batch\nsize.Batch Size: In order to measure the\neffect of batch size on query times, we\nﬁx the query sequence length to jQj=\n21and vary the batch size from 1 to\n500 million. Fig. 4 shows that as batch\nsize increases, LISA’s time per query\ndecreases. For batches larger than 10\nthousand, LISA starts to outperform\nthe FM-index.\nLISA’s performance is poor for small\nbatch sizes, where the double pointer\ntechnique actually hurts performance,\nas the merge step will skip over many\nleaves. However, in real-world scenar-\nios, it is rare to have such small batch sizes where this would matter. Next-generation sequencing\ntechnologies produce billions of DNA fragments, and downstream applications such as DNA sequence\nalignment need to process all or most of the produced fragments at once. Therefore, the typical use\ncase for LISA is to process large batches of queries. If high performance on small batches is absolutely\nnecessary, it is possible to achieve comparable/better performance than FM-index for small batch sizes\nby not using the double-pointer technique.\nAlternative to RMI: To evaluate the effectiveness of RMI against alternative index structures, we\ncompared LISA to a version which evaluates fKusing a combination of a lookup-table and binary\nsearch, instead of using the RMI. If we treat a (charK;int)pair as a (2K+32) -bit number, we maintain\na “downsampled” lookup-table (implemented as an array) with 2pentries, where p<2K+32. Let\nq= 2K+32\u0000p. Thei-th entry of the lookup-table holds the lower-bound location in the IP-BWT\nof the pair represented by the number i\u0001q. Essentially, our downsampled lookup-table holds every\nq-th entry of a “full” lookup-table that contains every possible (charK;int)pair. To evaluate fKon an\ninput represented as a 2K+32-bit number, we do a lookup in the lookup-table using the ﬁrst pbits to\n7\n\nobtain lower and upper bounds on the location of the input pair in the IP-BWT, then do a binary search\nwith the remaining qbits on the IP-BWT starting from those bounds to ﬁnd the location of the input.\nThis is our best effort at an alternative index structure that is most competitive with RMI.\nForK= 21 ,jQj= 21 , and batch size of 50 million, replacing the RMI with a downsampled lookup-\ntable of the same memory size results in 40% slower query times. More performant lookup-tables use\nsigniﬁcantly more memory: the lookup-table itself has space 2p+2bytes, so even with only p=34 , the\nlookup table takes 69GB, which exceeds the memory of our machine. Therefore, the lookup-table is\nimpractical and we do not include it in this paper.\n5 Conclusions\nIn this work, we introduced a preliminary version of our learned indexing approach for DNA sequence\nsearch, LISA, which produces promising initial results for the exact search problem when tested on\nworkloads of realistic queries against the human genome. In particular, LISA achieves up to nearly\n4\u0002faster query times than an extensively optimized version of the FM-index based approach, which\nhas been the common practice in sequence search. We believe that the core ideas behind LISA can be\nextended to other types of DNA sequence search problems. In particular, we are currently working on\nusing learned indexes to speed up searching for super maximal exact matches (SMEMs) for a query\nin the reference. For any position in query, an SMEM is the longest substring of the query through\nthat position that has an exact match in the reference [ 17,20,21]. We are also working with the Broad\nInstitute to integrate LISA into applications that are widely used by the genomics community.\nAcknowledgments\nWe thank Tony Peng, Ashwath Thirumalai, and Elizabeth Wei for their contributions to the original\ndesign of LISA; and Pradeep Dubey and Heng Li for their valuable feedback. This research has been\nfunded in part by afﬁliate members and supporters of DSAIL (Data Systems and AI Lab) at MIT –\nGoogle, Intel, and Microsoft.\nReferences\n[1]Illumina, Inc. Novasec 6000 sequencing system. https://www.illumina.com/\ncontent/dam/illumina-marketing/documents/products/datasheets/\nnovaseq-6000-system-specification-sheet-770-2016-025.pdf , 2019.\nAccessed: September 2019.\n[2]Vasimuddin Md, Sanchit Misra, and Srinivas Aluru. Identiﬁcation of Signiﬁcant Computational\nBuilding Blocks through Comprehensive Investigation of NGS Secondary Analysis Methods.\nbioRXiv , April 2018. URL https://www.biorxiv.org/content/early/2018/\n07/25/301903 .\n[3]Ben Langmead, Cole Trapnell, Mihai Pop, and Steven L Salzberg. Ultrafast and Memory-efﬁcient\nAlignment of Short DNA Sequences to the Human Genome. Genome Biology , 10(3):1, 2009.\n[4]Ben Langmead and Steven L Salzberg. Fast Gapped-read Alignment with Bowtie 2. Nature\nMethods , 9(4):357–359, 2012.\n[5]Ruiqiang Li, Chang Yu, Yingrui Li, Tak-Wah Lam, Siu-Ming Yiu, Karsten Kristiansen, and Jun\nWang. SOAP2: An Improved Ultrafast Tool for Short Read Alignment. Bioinformatics , 25(15):\n1966–1967, 2009.\n[6]Ruibang Luo, Thomas Wong, Jianqiao Zhu, Chi-Man Liu, Xiaoqian Zhu, Edward Wu, Lap-Kei\nLee, Haoxiang Lin, Wenjuan Zhu, David W Cheung, et al. SOAP3-dp: Fast, Accurate, and\nSensitive GPU-Based Short Read Aligner. PLOS ONE , 8(5):e65632, 2013.\n[7]Heng Li and Richard Durbin. Fast and Accurate Short Read Alignment with Burrows–Wheeler\nTransform. Bioinformatics , 25(14):1754–1760, 2009.\n[8]Paolo Ferragina and Giovanni Manzini. Opportunistic Data Structures with Applications. In\nIEEE Annual Symposium on Foundations of Computer Science (FOCS) , pages 390–398, 2000.\n8\n\n[9]Alejandro Chacón, Juan Carlos Moure, Antonio Espinosa, and Porﬁdio Hernández. n-step\nFM-Index for Faster Pattern Matching. Procedia Computer Science , 18:70–79, 2013.\n[10] Alejandro Chacón, Santiago Marco-Sola, Antonio Espinosa, Paolo Ribeca, and Juan Carlos\nMoure. Boosting the FM-Index on the GPU: Effective Techniques to Mitigate Random Memory\nAccess. IEEE/ACM Transactions on Computational Biology and Bioinformatics , 12(5):1048–\n1059, September 2015.\n[11] J. Pantaleoni and N. Subtil. NVBIO: A Library of Reusable Components Designed by NVIDIA\nCorporation to Accelerate Bioinformatics Applications using CUDA. http://nvlabs.\ngithub.io/nvbio/ . Accessed: November 2017.\n[12] Jing Zhang, Heshan Lin, Pavan Balaji, and Wu-chun Feng. Optimizing Burrows-Wheeler\nTransform-based Sequence Alignment on Multi-core Architectures. In IEEE/ACM International\nSymposium on Cluster, Cloud, and Grid Computing (CCGrid) , pages 377–384, 2013.\n[13] E. Fernandez, W. Najjar, and S. Lonardi. String Matching in Hardware Using the FM-Index. In\nIEEE Annual International Symposium on Field-Programmable Custom Computing Machines ,\npages 218–225, May 2011.\n[14] Szymon Grabowski, Marcin Raniszewski, and Sebastian Deorowicz. FM-index for Dummies. In\nInternational Conference on Beyond Databases, Architectures, and Structures (BDAS) , pages\n189–201, 2017.\n[15] Sanchit Misra, Tony C Pan, Kanak Mahadik, George Powley, Priya N. Vaidya, Md Vasimuddin,\nand Srinivas Aluru. Performance Extraction and Suitability Analysis of Multi- and Many-core\nArchitectures for Next Generation Sequencing Secondary Analysis. In International Conference\non Parallel Architectures and Compilation Techniques (PACT) , pages 3:1–3:14, 2018.\n[16] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The Case for Learned\nIndex Structures. In ACM International Conference on Management of Data (SIGMOD) , pages\n489–504, June 2018.\n[17] Vasimuddin Md, Sanchit Misra, Heng Li, and Srinivas Aluru. Efﬁcient Architecture-Aware Ac-\nceleration of BWA-MEM for Multicore Systems. In IEEE International Parallel and Distributed\nProcessing Symposium (IPDPS) , 2019.\n[18] Paolo Ferragina and Giovanni Manzini. An Experimental Study of an Opportunistic Index. In\nAnnual ACM-SIAM Symposium on Discrete Algorithms , pages 269–278, 2001.\n[19] Michael I. Jordan and Robert A. Jacobs. Hierarchical mixtures of experts and the em algorithm.\nNeural Comput. , 6(2):181–214, March 1994. ISSN 0899-7667. doi: 10.1162/neco.1994.6.2.181.\nURLhttp://dx.doi.org/10.1162/neco.1994.6.2.181 .\n[20] Heng Li. Exploring Single-Sample SNP and INDEL Calling with Whole-Genome De Novo\nAssembly. Bioinformatics , 28(14):1838–1844, 2012.\n[21] Heng Li. Aligning Sequence Reads, Clone sequences, and Assembly Contigs with BWA-MEM.\narXiv preprint arXiv:1303.3997 , 2013.\n9",
  "textLength": 33341
}