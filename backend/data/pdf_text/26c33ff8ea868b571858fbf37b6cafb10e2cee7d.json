{
  "paperId": "26c33ff8ea868b571858fbf37b6cafb10e2cee7d",
  "title": "Electra: Conditional Generative Model based Predicate-Aware Query Approximation",
  "pdfPath": "26c33ff8ea868b571858fbf37b6cafb10e2cee7d.pdf",
  "text": "Conditional Generative Model Based Predicate-Aware Query Approximation\nNikhil Sheoran1*, Subrata Mitra2†, Vibhor Porwal2, Siddharth Ghetia3*,\nJatin Varshney3*, Tung Mai2, Anup Rao2, Vikas Maddukuri3*\n1University of Illinois at Urbana-Champaign\n2Adobe Research\n3Indian Institute of Technology, Roorkee\nsheoran2@illinois.edu, {sumitra,viporwal,tumai,anuprao}@adobe.com,\nsiddhughetia@gmail.com, jvarshney@ee.iitr.ac.in, mvikas@ec.iitr.ac.in\nAbstract\nThe goal of Approximate Query Processing (AQP) is to pro-\nvide very fast but “accurate enough” results for costly aggre-\ngate queries thereby improving user experience in interactive\nexploration of large datasets. Recently proposed Machine-\nLearning-based AQP techniques can provide very low latency\nas query execution only involves model inference as com-\npared to traditional query processing on database clusters.\nHowever, with increase in the number of ﬁltering predicates\n(WHERE clauses), the approximation error signiﬁcantly in-\ncreases for these methods. Analysts often use queries with\na large number of predicates for insights discovery. Thus,\nmaintaining low approximation error is important to prevent\nanalysts from drawing misleading conclusions. In this paper,\nwe propose E LECTRA , a predicate-aware AQP system that\ncan answer analytics-style queries with a large number of\npredicates with much smaller approximation errors. E LEC-\nTRA uses a conditional generative model that learns the con-\nditional distribution of the data and at run-time generates a\nsmall (≈ 1000 rows) but representative sample, on which\nthe query is executed to compute the approximate result. Our\nevaluations with four different baselines on three real-world\ndatasets show that E LECTRA provides lower AQP error for\nlarge number of predicates compared to baselines.\nIntroduction\nInteractive exploration and visualization tools, such as\nTableau, Microsoft Power BI, Qlik, Polaris (Stolte, Tang,\nand Hanrahan 2002), and Vizdom (Crotty et al. 2015) have\ngained popularity amongst data-analysts. One of the desir-\nable properties of these tools is that the speed of interac-\ntion with the data, i.e., the queries and the corresponding\nvisualizations must complete at “human speed” (Crotty\net al. 2016) or at “rates resonant with the pace of human\nthought” (Liu and Heer 2014).\nTo reduce the latency of such interactions, Approximate\nQuery Processing (AQP) techniques that can provide fast\nbut “accurate enough” results for queries with aggregates\n(A VG, SUM, COUNT) on numerical attributes on a large\ndataset, have recently gained popularity (Hilprecht et al.\n*Work done while at Adobe Research\n†Corresponding Author\nCopyright © 2022, Association for the Advancement of Artiﬁcial\nIntelligence (www.aaai.org). All rights reserved.\nFigure 1: Median relative error vs. no. of predicates. Base-\nlines have high error for important high-predicate queries.\n2020; Thirumuruganathan et al. 2020; Ma and Triantaﬁllou\n2019). Prior AQP systems mainly relied on sampling-based\nmethods. For example, BlinkDB (Agarwal et al. 2013) and\nrecently proposed VerdictDB (Park et al. 2018b), ﬁrst create\nuniform/stratiﬁed samples and store them. Then at run-time,\nthey execute the queries against these stored samples thus\nreducing query latency. In order to reduce error for differ-\nent set of queries — using different columns for ﬁlters and\ngroupings — they need to create not one, but multiple sets of\nstratiﬁed samples of the same dataset. This results in a sig-\nniﬁcant storage overhead. Recently, following the promising\nresults (Mondal, Sheoran, and Mitra 2021; Mirhoseini et al.\n2017; Kraska et al. 2018) of using Machine Learning (ML)\nto solve several systems problems, few ML-based AQP tech-\nniques have been proposed. These use either special data-\nstructures (DeepDB (Hilprecht et al. 2020)) or simple gen-\nerative models (V AE-AQP (Thirumuruganathan et al. 2020))\nto answer queries with lower latency.\nHowever, a key drawback of these techniques is that as\nthe number of predicates (i.e. WHERE conditions) in the\nquery increases, the approximation error signiﬁcantly in-\ncreases (Fig. 1 for Flights dataset). E LECTRA is our tech-\nnique shown in blue. The importance of the queries con-\ntaining such large number of predicates is disproportionally\nhigh. This is because, as expert analysts drill down for in-\nsights, they progressively use more and more predicates to\nﬁlter the data to arrive at the desired subset and breakdowns\nwhere some interesting patterns might be present. Therefore,\nThe Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\n8259\n\nlowering the approximation error for such high-predicate\nqueries can prevent wrong conclusions, after laborious dis-\nsection of data in search of insights. As shown in Fig. 1, all\nbaselines fail to achieve this goal and therefore can be detri-\nmental for complex insight discovery tasks.\nIn this paper, we present E LECTRA , a predicate-aware\nAQP system that can answer analytics-style queries having\na large number of predicates with much lower approxima-\ntion errors compared to the state-of-the-art techniques. The\nkey novelty of E LECTRA comes from the use of a predicate-\naware generative model for AQP and associated training\nmethodology to capture accurate conditional distribution of\nthe data even for highly selective queries. E LECTRA then\nuses the conditional generative model (Sohn, Lee, and Yan\n2015) to generate a few representative samples at runtime\nfor providing an accurate enough answer.\nThe attributes (columns) in a tabular dataset can have cat-\negories (groups) that are rare. Moreover, when a large num-\nber of predicates are used to ﬁlter the data, the number of\nrows in the original data satisfying such conditions can be\nvery small. If we cannot faithfully generate such rare cat-\negories with proper statistical characteristics, AQP results\nwould either have large errors or even miss entire groups\nfor queries using a GROUP BY. To overcome this problem,\nwe propose a stratiﬁed masking strategy while training the\nCV AE and an associated modiﬁcation of the CV AE loss-\nfunction to help it learn predicate-aware targeted generation\nof samples. Speciﬁcally, using this proposed masking strat-\negy, we help the model to learn rare groups or categories in\nthe data. Our empirical evaluations on real-world datasets\nshow that, our stratiﬁed masking strategy helps E LECTRA to\nlearn the conditional distribution among different attributes,\nin a query-agnostic manner and can provide an average 12%\nimprovement in accuracy (Fig. 5a) compared to random\nmasking strategy proposed by prior work (Ivanov, Figurnov,\nand Vetrov 2019) (albeit, not for AQP systems but for image\ngeneration). Our major contributions in this paper are:\n• We propose a novel and low-error approximate query\nprocessing technique using predicate-aware generative\nmodels. Even for queries with a large number of pred-\nicates, our technique can provide effective answers by\ngenerating a few representative samples, at the client-\nside.\n• We propose a novel stratiﬁed-masking technique that en-\nables training the generative model to learn better condi-\ntional distribution and support predicate-aware AQP re-\nsulting in a signiﬁcant performance improvement on low\nselectivity queries.\n• We present the end-to-end design and implementation\ndetails of our AQP system called E LECTRA . We present\ndetailed evaluation and ablation study with real-world\ndatasets and compare with state-of-the-art baselines. Our\ntechnique reduces AQP error by 36.6% on average com-\npared to previously proposed generative-model-based\nAQP technique on production workloads.Overview of ELECTRA\nTarget Query Structure\nThe commonly used queries for interactive data exploration\nand visual analytics have the following structure:\nSELECT \t,AGG(N ) as\u000bFROMTWHERE\u0012[GROUP\nBYC] [ORDER BY \f]\nAggregate AGG (AVG, SUM etc.) is applied to a numeri-\ncal attribute N, on rows satisfying predicate \u0012.GROUP BY\nis optionally applied on categorical attributes C. One such\nquery example is shown in Fig. 2b. Here an analyst might\nbe exploring what are the average checkout values made\nby users from a certain demographic (Age “Senior” using\n“iOS” and “Chrome” Browser) from an e-commerce site\nacross different months. Insights like these helps organiza-\ntions to understand trends, optimize website performance\nor to place effective advertisements. E LECTRA can handle\na much diverse set of queries including queries with mul-\ntiple predicates by - breaking down the query into multi-\nple queries; using inclusion-exclusion principle or convert-\ning the query’s predicates to Disjunctive Normal Form.\nPredicates: Predicates are condition expressions (e.g.,\nWHERE) evaluating to a boolean value used to ﬁlter rows on\nwhich an aggregate function like AVG, SUM andCOUNT is\nto be evaluated. A compound predicate consists of multiple\n(ANDs) or (ORs) of predicates.\nQuery Selectivity: Theselectivity of a query with predicate\n\u0019is deﬁned as sel(\u0019):=|x∈T:\u0019(x) = 1|=|T|. It indi-\ncates what fraction of rows passed the ﬁltering criteria used\nin the predicates.\nDesign of ELECTRA\nFig. 2a shows the major components of E LECTRA (marked\nin green). At a high-level, it has primarily two compo-\nnents: Aan on-line AQP runtime at the client-side and,\nBan ofﬂine server-side ETL (Extraction, Transformation,\nand Loading) component. The runtime component Ais\nresponsible for answering the live queries from the user-\ninteractions using the pre-trained ML-models. It pulls these\nmodels asynchronously from a repository (Model-DB) and\ncaches them locally. E LECTRA is designed to handle the\nmost frequent-type of queries for exploratory data analyt-\nics (Refer § ). Unsupported query-formats are redirected to\na backend query-processor.\nFig. 2b shows more details of the runtime component.\nELECTRA ﬁrst parses the query to extract individual pred-\nicates, GROUP BY attributes, and the aggregate function. If\nthe aggregate is either a SUM or anAVG, E LECTRA feeds the\npredicates and the GROUP BY information to its predicate-\naware ML-model ( 1) and generates a small number of\nrepresentative samples. For queries with AVG as an aggre-\ngate, E LECTRA can directly calculate the result by applying\nthe query logic on these generated samples ( 2). For SUM\nqueries, E LECTRA needs to calibrate the result using an ap-\npropriate scale-up or denormalizing factor. E LECTRA calcu-\nlates this factor by feeding the ﬁltering predicates to a selec-\ntivity estimator (3). For COUNT queries, E LECTRA directly\nuses the selectivity estimator to calculate the query result.\n8260\n\nThe server-side ETL component ( Bin Fig. 2a) operates\nasynchronously. For a new dataset, it trains two types of\nmodels – a conditional generative model and a selectivity\nestimator model – and stores them into the Model-DB.\n(a) Overall architecture of E LECTRA\n(b) E LECTRA Runtime computations\nFigure 2: Design of E LECTRA\nConditional Sample Generation\nIn this section, we describe how E LECTRA attempts to make\nconditional sample generation process accurate, even for\nqueries with large number of predicates, so that the resulting\napproximation error on these samples becomes very small.\nProblem Description\nLet T be a relation with K=|A|attributes where A=\nAN∪AC.ANdenotes the numerical attributes and ACde-\nnotes the categorical attributes. Our aim is to learn a model\nthat can generate a predicate-aware representative sample of\nT at runtime. This problem can be divided into two sub-\nproblems – ﬁrst, learning the conditional distributions of the\nformP(An|Ac)whereAnis a subset of ANandAcis a\nsubset ofACand second, generating representative samples\nusing the learned conditional distributions. With respect to\nthe example query in Fig. 2b, the attribute Value belongs to\nAN. The attributes Browser, OS,Age andMonth used in\nthe predicates are categorical attributes and belongs to AC.\nELECTRA targets to support queries with arbitrary num-\nber of predicate combinations over the attributes ACusing\nonly a single model. This requires the learning technique to\nbequery-agnostic (but yet, sample generation to be query-\npredicate speciﬁc).\nELECTRA ’s Model Design\nWe are the ﬁrst to propose the use of Conditional Varia-\ntional Auto-encoders (CV AE) (Sohn, Lee, and Yan 2015)along with a query-agnostic training methodology involving\na novel masking strategy to reduce the AQP error.\nConsider aK-dimensional vector awith numerical and\ncategorical values representing a row of data. Let m∈\n{0;1}Kbe a binary mask denoting the set of unobserved\n(mi= 1) and observed attributes (m i= 0). Applying this\nmask on the vector agives usam={ai:mi=1}as the set\nof unobserved attributes and a1−m={ai:mi=0}as the set\nof observed attributes. Our goal is to model the conditional\ndistribution of the unobserved amgiven the mask mand the\nobserved attributes a1−mi.e. approximate the true distribu-\ntionp(am|a1−m;m).\nAlong with providing full support over the domain of m\n(arbitrary conditions), we need to ensure that the samples\nthat are generated represent rows from the original dataset.\nFor example: given a set of observed attributes a1−mwhose\ncombination does not exist in the data, the model should not\ngenerate samples of data satisfying a1−m(since a false pos-\nitive). To avoid this, we learn to generate complete a(both\namanda1−m) by learning the distribution p(a|a1−m;m)\ninstead of just learning p(am|a1−m;m) and hence avoiding\ngenerating false positives.\nNote that the generative models based on\nV AE(s) (Kingma and Welling 2014) allows us to gen-\nerate random samples by generating latent vector zand\nthen sampling from posterior p\u0012(x|z). But, we do not have\nany control on the data generation process. Conditional\nVariational Auto-encoder models (CV AE) (Sohn, Lee, and\nYan 2015) counter this by conditioning the latent variable\nand data generation on a control variable. In terms of the\ntable attributes a, the control variable a1−mand the mask\nm, the training objective for our model thus becomes:\nLELECTRA =−KL (q\u001e(z|a;m)||p (z|a1−m;m))+\nEz∼q\u001e(z|a;m )[log(p\u0012(a|z))] (1)\nThe loss function is a combination of two terms: (1) KL-\ndivergence of the posterior and the conditional distribution\nof the latent space i.e. how well is your conditional latent\nspace generation and (2) Reconstruction error for the at-\ntributes i.e. how well is your actual sample generation.\nThe generative process of our model thus becomes: (1)\ngenerate latent vector conditioned on the mask and the ob-\nserved attributes: p (z|a1−m;m) and (2) generate sample\nvectorafrom the latent variable z:p\u0012(a|z), thus inducing\nthe following distribution:\np ;\u0012(a|a1−m;m) =Ez∼p (z|a1−m;m)p\u0012(a|z) (2)\nSinceamanda1−mcan be variable length vectors de-\npending onm, inspired from (Ivanov, Figurnov, and Vetrov\n2019), we consider am=a◦mi.e. the element-wise product\nofaandm. Similarly, a1−m=a◦(1−m).\nIn terms of a query, the observed attributes are the pred-\nicates present in the query. E.g. for the query in Fig. 2b,\nfor attributes A={Month, Value, Browser, OS,\nAge},mis{1;1;0;0;0}and the observed attributes vector\na1−mis{-, -, \"Chrome\", \"iOS\", \"Senior\"}.\nModel Architecture: ELECTRA ’s CV AE model consists\nof three networks - (1) Encoder: to approximate the true\n8261\n\nposterior distribution, (2) Prior: to approximate the condi-\ntional latent space distribution, and (3) Decoder: to gener-\nate synthetic samples based on the latent vector z. We use a\nGaussian distribution over zwith parameters (\u0016\u001e;\u001b\u001e)and\n(\u0016 ;\u001b )for the encoder and prior network respectively.\nFig. 3a shows the model architecture. All the three networks\nare used during training, whereas during runtime, only the\nprior and decoder networks are used. Fig. 3b shows the in-\nputs to these networks during training, corresponding to our\nexample dataset mentioned in Fig. 2b. The input to the Prior\nnetwork is masked using a novel masking strategy. Fig. 3c il-\nlustrates the runtime inputs to E LECTRA ’s generative model\nfor our example query. It also illustrates the generated sam-\nples as obtained from the Decoder network, corresponding\nto the input query. After generation of such targeted samples\nthat preserve the conditional distribution of the original data\nin the context of the query received at runtime, E LECTRA\nsimply executes the original query on this very small sample\nto calculate an answer.\nStratiﬁed Masking\nThe efﬁciency of learned conditional distributions depends\non the set of masks M={m} used during the training.\nDuring each epoch, a mask mb×kis generated for a batch of\ndata. This mask is applied to the input data to generate the\nset of observed attributes, for which the samples are gener-\nated and the loss function evaluated. In case of m= 0K\ni.e. no masking and all the attributes are observed, the prior\nnetwork would learn to generate latent vectors correspond-\ning to all observed attributes. But at runtime, only a partial\nset of attributes are observed (as predicates) and hence it\nwould lead to a poor performance. In case of m= 1Ki.e.\na masking rate of 100% and all the features are unobserved,\nthe behavior would be similar to that of a V AE. Since the\nvectora1−m={\u001e}, the conditioning of the latent vector\nwould have no effect on the learning. Thus, again this would\nperform poorly on queries with predicates.\nIn order to counter these and make the training query-\nagnostic, a random masking strategy (Ivanov, Figurnov, and\nVetrov 2019) can be used where a certain fraction of the\nrows are masked corresponding to each of the input features.\nHowever, such random masking does not provide any mech-\nanism to help the model learn better the conditional distri-\nbution for rare groups to improve performance for queries\nwith large number of predicates. There are more subtleties.\nBy masking more number of rows for an attribute, the train-\ning helps the model to learn better the generation of repre-\nsentative values for that attribute. Whereas, by keeping more\nunmasked rows, the model can learn better conditional dis-\ntribution conditioned on those attributes.\nProposed masking strategy: With the above observation,\nELECTRA uses a novel masking strategy tailored for AQP.\nIt consists of the following: (a) We completely mask the nu-\nmerical attributes. (b) For the categorical attributes on which\nconditions can be used in the predicates, we use a stratiﬁed\nmasking strategy. In the stratiﬁed masking we alter the ran-\ndom masking strategy based on the size of the strata (i.e.\ngroups or categories) to disproportionately reduce the prob-\nability of masking for the rare groups. Thus, the ability ofAlgorithm 1: Stratiﬁed Masking Strategy\nInput: Batch{B}b×k, Masking Factor r, Strata Size\nS\nOutput: Binary mask mfor the Input Batch B\n1m←0b×k\n2numcols←numerical cols(k)\n3catcols←categorical cols(k)\n4foriinnumcols do\n5{mx;y}b;i\n1;i←1\n6end\n7fori∈catcols do\n8values←{Bx;y}b;i\n1;i\n9weights←{Si[valuesx]}b\n1\n10batchindices←\nrandom:sample ({x}b\n1;r∗b;weights )\n11 forj∈batchindices do\n12mj;i←1\n13 end\n14end\n15returnm;\nthe model to learn better conditional distribution improves.\nWe apply this masking strategy in a batch-wise manner dur-\ning training. In the Evaluation section, we show (Fig. 5a)\nthat our masking strategy drastically reduces the approxi-\nmation error compared to no-masking or random masking\nstrategies.\nAlgorithm 1 describes the masking strategy where we in-\nput a batch of data Bof dimension b×k:bdenotes the batch\nsize andkdenotes the number of attributes. The numerical\ncolumns are completely masked. The strata size for each cat-\negorical column i(Si), contains for each value that the col-\numnican take, the fraction of rows in the data where the\ncolumn takes this value. Using the weights obtained from\nSi[value ]as the sampling probability and ras the masking\nfactor, we sample r∗brows and mask their column i. Mask-\ning factorrcontrols the overall masking rate of the batch. A\nhigher masking factor simulates queries with less observed\nattributes i.e. less number of predicates and a lower masking\nfactor simulates queries with more observed attributes i.e.\nmore number of predicates.\nImplementation Details\nData Transformation. ELECTRA applies a set of data pre-\nprocessing steps including label encoding for categorical at-\ntributes and mode-speciﬁc normalization for numerical at-\ntributes. For normalization, weights for the Gaussian mix-\nture are calculated through a variational inference algorithm\nusing sklearn’s BayesianGaussianMixture method.\nThe parameters speciﬁed are the number of modes (iden-\ntiﬁed earlier) and a maximum iteration of 1000. To avoid\nmixture components with close to zero weights, we limit the\nnumber of modes to less than or equal to 3.\nConditional Density Estimator. The conditional density\nestimator model is implemented in PyTorch. We build upon\n8262\n\n(a) Model architecture\n (b) Training inputs\n (c) Runtime inputs\nFigure 3: Model architecture and inputs\nthe code1provided by Ivanov et al. The density estimator is\ntrained to minimize the combination of KL-divergence loss\nand reconstruction loss. To select a suitable set of hyperpa-\nrameters, we performed a grid search. We varied the depth\n(d) of the prior and proposal networks in the range [2,4,6,8]\nand the latent dimension (L ) in the range [32,64,128,256].\nFor Flights data we use d= 8,L= 64, for Housing d= 8,\nL= 64 , and for Beijing PM2.5 we use d= 6,L= 32 .\nNote that, the depth of the networks and the latent dimen-\nsion contribute signiﬁcantly to the model size. Hence, de-\npending on the size constraints (if any), one can choose a\nsimpler model. We used a masking factor (r ) of 0.5. The\nmodel was trained with an Adam Optimizer with a learning\nrate of 0.0001 (larger learning rates gave unstable variational\nlower bound(s)).\nSelectivity Estimator. We use N ARU’s publicly available\nimplementation2. The model is trained with the ResMADE\narchitecture with a batch size of 512, an initial warm-up of\n10000 rounds, with 5 layers each of hidden dimension 256.\nIn order to account for the impact of column ordering, we\ntried various different random orderings and chose the one\nwith the best performance.\nEvaluation\nExperimental Environment\nAll the experiments were performed on a 32 core Intel(R)\nXeon(R) CPU E5-2686 with 4 Tesla V100-SXM2 GPU(s).\nDatasets: We use three real-world datasets: Flights (Bureau\nof Transportation Statistics), Housing (Qiu 2018) and Bei-\njing PM2.5 (Chen 2017). The Flights dataset consists of ar-\nrival and departure data (e.g. carrier, origin, destination, de-\nlay) for domestic ﬂights in the USA. The Housing dataset\nconsists of housing price records (e.g. price, area, rooms)\nobtained from a real-estate company. The Beijing PM2.5\ndataset consists of hourly records of PM2.5 concentration.\nAll these datasets have a combination of both categorical\nand numerical attributes.\nSynthetic Query Workload: We create a synthetic work-\nload to evaluate the impact of the number of predicates in\nthe query. For each dataset, we generated queries with # of\npredicates (k) ranging from 1 to |AC|. For a given k, we ﬁrst\nrandomly sample 100 combinations (with repetitions) from\n1V AEAC code available at https://github.com/tigvarts/vaeac\n2NARU code available at https://github.com/naru-project/naru/the set of all possible k-attribute selections. Then, for each\nof these selected k-attributes, we create the WHERE condi-\ntion by assigning values based on a randomly chosen tuple\nfrom the dataset. Then, we use AVG as the aggregate func-\ntion for each of the numerical attributes. The synthetic work-\nload thus contains a total of 100∗|AC|∗|AN|queries.\nProduction Query Workload: We also evaluate E LECTRA\nusing real production queries from ﬁve Fortune 500 compa-\nnies over a period of two months on a large data exploration\nplatform. First, we select queries whose query structure is\nsupported by E LECTRA . We ﬁlter out the repeated queries.\nWhile we were able to extract the queries, we did not have\naccess to the actual customer data corresponding to those\nqueries. Hence, we use the following methodology to cre-\nate an equivalent query set for our evaluation. We replace\neach predicate in the WHERE clause by a random categorical\nattribute and a random value corresponding to that attribute.\nAll attributes that were used in GROUP BY were replaced by\nrandom categorical attributes from our evaluation datasets.\nThen, we generate two workloads, one with AVG and one\nwithSUM as the aggregate function on a random numerical\nattribute. Thus, we preserve real characteristics of the use of\npredicates and the grouping logic in our modiﬁed workload.\nBaselines: We evaluate against four recent baselines.\nV AE-AQP (Thirumuruganathan et al. 2020) is a generative\nmodel-based technique that does not use any predicate in-\nformation. The code was obtained from the authors. In our\nevaluations, we generated 100K samples from V AE-AQP for\nall 3 datasets. Note that this is well over the 1%sampling\nrate speciﬁed by the V AE-AQP authors for these datasets.\nCTGAN (Xu et al. 2019) is a conditional generative model.\nHowever, the CTGAN technique as described in the paper\n(Xu et al. 2019) and the associated code (CTGAN code),\nonly support at most one condition for generation. Hence,\nwhen using CTGAN as a baseline in our evaluation, we ran-\ndomly select one of the input predicates as the condition for\ngenerating the samples. We keep the generated sample size\nper query same as E LECTRA .\nDeepDB (Hilprecht et al. 2020) builds a relational sum-\nproduct-network (SPN) based on the input data. For any in-\ncoming query, it evaluates the query on the obtained SPN\nnetwork. We keep the default parameters for DeepDB code\nobtained from (DeepDB code).\nVerdictDB (Park et al. 2018b) is a sampling-based approach\n8263\n\n(a) Flights\n(b) Housing\n(c) Beijing PM2.5\n(d) Production workload - A VG queries\n(e) Production workload - SUM queries\n(f) Median R.E. vs # of Samples Generated\nFigure 4: (a), (b) and (c) denote AQP error vs. # predicates. The color on top shows the % of queries answered. For (d) and (e),\nthe number on top shows the % of queries answered.\nthat runs at the server-side. It extracts and stores samples\n(called SCRAMBLE) from the original data and uses it to\nanswer the incoming queries. We keep the default parame-\nters in the code obtained from (VerdictDB code).\nAQP Error Measures: For a query Q, with an exact\nground truth result gand an approximate result a, we mea-\nsure the approximation error by computing the Relative Er-\nror (R.E.). Since R.E. is an unbounded measure and can be-\ncome very large, we use a bounded measure called Symmet-\nric Mean Absolute Percentage Error (sMAPE) to visualize\nthe approximation errors. sMAPE lies between 0 and 2 and\nprovides a better visualization compared to R.E..\nsMAPE(Q) = 2∗|g−a|\n|g|+|a|\nPerformance w.r.t. Number of Predicates\nFig. 4a, 4b and 4c shows the distribution of approximation\nerror (as sMAPE) w.r.t. the number of predicates in the syn-\nthetic workload queries. A lower approximation error is bet-\nter. All the queries could not be successfully evaluated to\nproduce an approximate result because the technique could\nnot match for the used predicates either in the generated data\n(ELECTRA , CTGAN, V AE-AQP) or in the available samples\n(VerdictDB) or in the stored metadata (DeepDB). The dis-\ntribution of the AQP errors in the box-plots were calculated\nonly over the queries that the corresponding technique could\nsupport. The heat-map colors over the box-plots show what\npercentages of the queries were supported by different tech-\n(a) Masking strategy\n (b) Masking factor\nFigure 5: Design Components\nniques. A technique supporting large fraction of queries is\nbetter. It is worthwhile to note, only E LECTRA and DeepDB\ncould answer the queries with 90−100% coverage across\nall the different predicate settings.\nNote, the median approximation error is almost always\nthe lowest for E LECTRA (shown in green), as the number of\npredicates in the queries are increased. The other two gen-\nerative baselines, CTGAN and V AE-AQP perform poorly in\nthis aspect. DeepDB’s performance is great for median ap-\nproximation comparison, but error at the tail is often quite\nlarge for DeepDB, compared to E LECTRA . For one predi-\ncate, almost all the techniques can maintain very low AQP\nerror (making any of those practically useful) and E LEC-\nTRA often does not provide the lowest error in the relative\nterms. However, E LECTRA is the overall best solution when\nwe look at the whole spectrum of predicates.\n8264\n\nFigure 6: Error & bin-completeness on GROUP BY queries\nPerformance on Production Workload\nFig. 4d and 4e shows the comparisons of the AQP error (as\nsMAPE) distribution for our production query workload for\nthe three real-world datasets shown separately for AVG and\nSUM as the aggregate functions. For A VG as the aggregate\nfunction (Fig. 4d), E LECTRA provides the lowest approxi-\nmation error for both Housing and Beijing-PM-2.5 dataset.\nFor Flights dataset, even though the median error is com-\nparable to DeepDB, VerdictDB and V AE-AQP, the tail er-\nror is larger. Please note: since these plots were calculated\nover the production queries, 70% of the queries had two or\nfewer predicates. Thus, the beneﬁt of E LECTRA in handling\nlarge number of predicates is less visible. The percentages\nof queries that different techniques were able to successfully\nanswer, are shown over the box-plots.\nPerformance on GROUP BY Queries\nWe evaluate E LECTRA ’s performance on GROUP BY\nqueries using slight modiﬁcation to our synthetic query\nworkload by randomly choosing one of the attributes to be\nused for GROUP BY. We do not use any predicate on that\nattribute. Fig. 6 shows the AQP error over queries with all\nthe different number of predicates. The error for each query\nwas calculated as an average over the individual errors cor-\nresponding to each of the individual groups that were both\npresent in the ground truth results and the approximate re-\nsults. The error is computed as the average of the R.E. for\neach of the different groups corresponding to the GROUP\nBYcolumn. Approximations might result in missing groups.\nWe use bin-completeness measure as follows:\nbin-completeness =|GgroupsTAgroups|\n|Ggroups|\nGgroups is the set of all the groups that appear in the ground\ntruth andAgroups is the set for the approximate result. This\nbin-completeness (§ 15) is an important measure for GROUP\nBYqueries. Fig. 6 shows the bin-completeness numbers\non top of the box plots. Higher is better. Both E LECTRA\nand DeepDB can consistently provide much higher bin-\ncompleteness, compared to other baselines. However, the er-\nror for E LECTRA is much better than DeepDB.\nDesign Components\nSamples Generated per Query. Generating more represen-\ntative samples by E LECTRA can potentially improve accu-\nracy, but at the cost of larger query latency and memory foot-\nprint. Figure 4f shows the change in the R.E. for E LECTRA\nas we increase the number of generated samples. Generating1000 representative samples, from the learned conditional\ndistribution, is good enough to achieve a low AQP error, and\nbeyond that the improvement is not signiﬁcant.\nImpact of the Masking Strategy. Fig. 5a quantify the ben-\neﬁt of our proposed masking strategy for Flights dataset. We\ncompare the proposed method with a No Masking strategy\nwhere only NaN input values, if any, are masked. We also\ncompare with Random Masking strategy that uses a uniform\nrandom masking, irrespective of the column type (Ivanov,\nFigurnov, and Vetrov 2019). We observe that the proposed\nstratiﬁed masking strategy can signiﬁcantly reduce the AQP\nerror compared to the other two alternative, irrespective of\nthe number of predicates used in the queries.\nMasking factor. Fig. 5b shows the sensitivity of E LECTRA\ncorresponding to the masking factor, across the range of\npredicates for the Flights dataset. A masking factor of 0.5\nwould be the choice, if we want to optimize for queries with\narbitrary number of predicates.\nRelated Work\nApproximate Query Processing has a rich history with the\nuse of sampling and sketching based approaches (Chaud-\nhuri, Ding, and Kandula 2017; Cormode 2011; Chaudhuri,\nDas, and Narasayya 2007). BlinkDB (Agarwal et al. 2013)\nuses ofﬂine sampling, but assumes it has access to historical\nqueries to reduce or optimize for storage overhead. Related\nworks used as baselines were described in § 15.\nRepresentative Data Generation. With the advancement of\ndeep-learning, multiple generative methods have been pro-\nposed, primarily using GAN(s) (Brock, Donahue, and Si-\nmonyan 2019) and V AE(s) (Ivanov, Figurnov, and Vetrov\n2019). These techniques have been successful in produc-\ning realistic synthetic samples for images, auto-completing\nprompts for texts (Radford et al. 2019; Devlin et al. 2018),\ngenerating audio wavelets (Oord et al. 2016). Few works\nused GAN(s) (Xu et al. 2019; Park et al. 2018a) for tab-\nular data generation either for providing data-privacy or to\novercome imbalanced data problem.\nSelectivity or Cardinality Estimation includes several\nclassical methods with synopsis structures (e.g., his-\ntograms, sketches and wavelets) to provide approximate an-\nswers (Cormode et al. 2012). Recently, learned cardinality\nestimation methods have become common including using\nDeep Autoregressive models to learn density estimates of a\njoint data distribution (Yang et al. 2019; Hasan et al. 2020;\nYang et al. 2020), embedding and representation learning\nbased cost and cardinality estimation (Sun and Li 2019).\nConclusion\nWe presented a deep neural network based approximate\nquery processing (AQP) system that can answer queries us-\ning a predicate-aware generative model at client-side, with-\nout processing the original data. Our technique learns the\nconditional distribution of data and generates targeted sam-\nples based on the conditions speciﬁed in the query. The key\ncontributions of the paper are the use of conditional genera-\ntive models for AQP and the techniques to reduce approxi-\nmation error for queries with large number of predicates.\n8265\n\nReferences\nAgarwal, S.; Mozafari, B.; Panda, A.; Milner, H.; Madden,\nS.; and Stoica, I. 2013. BlinkDB: Queries with Bounded\nErrors and Bounded Response Times on Very Large Data.\nInEuroSys.\nBrock, A.; Donahue, J.; and Simonyan, K. 2019. Large Scale\nGAN Training for High Fidelity Natural Image Synthesis.\nArXiv, abs/1809.11096.\nBureau of Transportation Statistics. 2019. Carrier On-Time\nPerformance. https://www.transtats.bts.gov/. Accessed:\n2022-04-29.\nChaudhuri, S.; Das, G.; and Narasayya, V . 2007. Optimized\nstratiﬁed sampling for approximate query processing. ACM\nTransactions on Database Systems.\nChaudhuri, S.; Ding, B.; and Kandula, S. 2017. Approxi-\nmate Query Processing: No Silver Bullet. In SIGMOD.\nChen, S. X. 2017. UCI Machine Learning Repository. https:\n//archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data. Ac-\ncessed: 2022-04-29.\nCormode, G. 2011. Sketch techniques for approximate\nquery processing. Foundations and Trends in Databases.\nCormode, G.; Garofalakis, M.; Haas, P. J.; and Jermaine, C.\n2012. Synopses for Massive Data: Samples, Histograms,\nWavelets, Sketches. Foundation and Trends in Databases.\nCrotty, A.; Galakatos, A.; Zgraggen, E.; Binnig, C.; and\nKraska, T. 2015. Vizdom: Interactive Analytics through Pen\nand Touch. Proc. VLDB Endow.\nCrotty, A.; Galakatos, A.; Zgraggen, E.; Binnig, C.; and\nKraska, T. 2016. The Case for Interactive Data Exploration\nAccelerators (IDEAs). In HILDA.\nCTGAN code. 2019. CTGAN Github Repo. https://github.\ncom/sdv-dev/CTGAN. Accessed: 2022-04-29.\nDeepDB code. 2020. DeepDB Github Repo. https://github.\ncom/DataManagementLab/deepdb-public. Accessed: 2022-\n04-29.\nDevlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2018.\nBert: Pre-training of deep bidirectional transformers for lan-\nguage understanding. arXiv preprint arXiv:1810.04805.\nHasan, S.; Thirumuruganathan, S.; Augustine, J.; Koudas,\nN.; and Das, G. 2020. Deep Learning Models for Selectivity\nEstimation of Multi-Attribute Queries. In SIGMOD.\nHilprecht, B.; Schmidt, A.; Kulessa, M.; Molina, A.; Kerst-\ning, K.; and Binnig, C. 2020. DeepDB: Learn from Data,\nNot from Queries! Proc. VLDB Endow.\nIvanov, O.; Figurnov, M.; and Vetrov, D. 2019. Variational\nAutoencoder with Arbitrary Conditioning. In ICLR.\nKingma, D. P.; and Welling, M. 2014. Auto-Encoding Vari-\national Bayes. In ICLR.\nKraska, T.; Beutel, A.; Chi, E. H.; Dean, J.; and Polyzotis,\nN. 2018. The case for learned index structures. In SIGMOD.\nLiu, Z.; and Heer, J. 2014. The Effects of Interactive La-\ntency on Exploratory Visual Analysis. IEEE Transactions\non Visualization and Computer Graphics.Ma, Q.; and Triantaﬁllou, P. 2019. DBEst: Revisiting Ap-\nproximate Query Processing Engines with Machine Learn-\ning Models. In SIGMOD.\nMirhoseini, A.; Pham, H.; Le, Q. V .; Steiner, B.; Larsen, R.;\nZhou, Y .; Kumar, N.; Norouzi, M.; Bengio, S.; and Dean,\nJ. 2017. Device placement optimization with reinforcement\nlearning. In ICML.\nMondal, S. S.; Sheoran, N.; and Mitra, S. 2021. Scheduling\nof Time-Varying Workloads Using Reinforcement Learning.\nInAAAI Conference on Artiﬁcial Intelligence.\nOord, A. v. d.; Dieleman, S.; Zen, H.; Simonyan, K.;\nVinyals, O.; Graves, A.; Kalchbrenner, N.; Senior, A.; and\nKavukcuoglu, K. 2016. Wavenet: A generative model for\nraw audio. arXiv preprint arXiv:1609.03499.\nPark, N.; Mohammadi, M.; Gorde, K.; Jajodia, S.; Park, H.;\nand Kim, Y . 2018a. Data Synthesis Based on Generative\nAdversarial Networks. Proc. VLDB.\nPark, Y .; Mozafari, B.; Sorenson, J.; and Wang, J. 2018b.\nVerdictDB: Universalizing Approximate Query Processing.\nInSIGMOD.\nQiu, Q. 2018. Housing Price in Beijing. https://www.kaggle.\ncom/ruiqurm/lianjia/version/2. Accessed: 2022-04-29.\nRadford, A.; Wu, J.; Child, R.; Luan, D.; Amodei, D.;\nSutskever, I.; et al. 2019. Language models are unsupervised\nmultitask learners. OpenAI blog, 1(8): 9.\nSohn, K.; Lee, H.; and Yan, X. 2015. Learning Structured\nOutput Representation using Deep Conditional Generative\nModels. In Advances in Neural Information Processing Sys-\ntems.\nStolte, C.; Tang, D.; and Hanrahan, P. 2002. Polaris: A\nsystem for query, analysis, and visualization of multidimen-\nsional relational databases. IEEE Transactions on Visualiza-\ntion and Computer Graphics.\nSun, J.; and Li, G. 2019. An end-to-end learning-based cost\nestimator. arXiv preprint arXiv:1906.02560.\nThirumuruganathan, S.; Hasan, S.; Koudas, N.; and Das, G.\n2020. Approximate Query Processing for Data Exploration\nusing Deep Generative Models. In 36th IEEE ICDE.\nVerdictDB code. 2018. Verdict Project. https://github.com/\nverdict-project/verdict. Accessed: 2022-04-29.\nXu, L.; Skoularidou, M.; Cuesta-Infante, A.; and Veera-\nmachaneni, K. 2019. Modeling Tabular data using Condi-\ntional GAN. In Advances in Neural Information Processing\nSystems.\nYang, Z.; Kamsetty, A.; Luan, S.; Liang, E.; Duan, Y .; Chen,\nX.; and Stoica, I. 2020. NeuroCard: One Cardinality Esti-\nmator for All Tables. Proc. VLDB Endow.\nYang, Z.; Liang, E.; Kamsetty, A.; Wu, C.; Duan, Y .; Chen,\nX.; Abbeel, P.; Hellerstein, J. M.; Krishnan, S.; and Stoica,\nI. 2019. Deep Unsupervised Cardinality Estimation. Proc.\nVLDB Endow.\n8266",
  "textLength": 39125
}