{
  "paperId": "a577f7756c540a7553febd3afdc9a3c340c08ad2",
  "title": "Online Dynamic Acknowledgement with Learned Predictions",
  "pdfPath": "a577f7756c540a7553febd3afdc9a3c340c08ad2.pdf",
  "text": "Online Dynamic Acknowledgement with Learned Predictions∗\nSungjin Im1, Benjamin Moseley2, Chenyang Xu†3, and Ruilong Zhang‡4\n1Electrical Engineering and Computer Science, University of California at Merced\n2Tepper School of Business, Carnegie Mellon University\n3Software Engineering Institute, East China Normal University\n4Department of Computer Science, City University of Hong Kong\nsim3@ucmerced.edu, moseleyb@andrew.cmu.edu, cyxu@sei.ecnu.edu.cn, ruilzhang4-c@my.cityu.edu.hk\nAbstract\nWe revisit the online dynamic acknowledgment problem. In the problem, a sequence of requests\narrive over time to be acknowledged, and all outstanding requests can be satisfied simultaneously\nby one acknowledgement. The goal of the problem is to minimize the total request delay plus\nacknowledgement cost. This elegant model studies the trade-off between acknowledgement cost\nand waiting experienced by requests. The problem has been well studied and the tight competitive\nratios have been determined. For this well-studied problem, we focus on how to effectively use\nmachine-learned predictions to have better performance.\nWe develop algorithms that perform arbitrarily close to the optimum with accurate predictions\nwhile concurrently having the guarantees arbitrarily close to what the best online algorithms can\noffer without access to predictions, thereby achieving simultaneous optimum consistency and ro-\nbustness. This new result is enabled by our novel prediction error measure. No error measure\nwas defined for the problem prior to our work, and natural measures failed due to the challenge\nthat requests with different arrival times have different effects on the objective. We hope our ideas\ncan be used for other online problems with temporal aspects that have been resisting proper error\nmeasures.\n∗All authors (ordered alphabetically) have equal contributions and are corresponding authors.\n†This work was done when the author was a student at Zhejiang University.\n‡This work was done when the author visited Carnegie Mellon University.\n1arXiv:2305.18227v1  [cs.DS]  25 May 2023\n\n1 Introduction\nIn a typical communication setting where a client receives a sequence of packets from the server, she\nneeds to acknowledge the receipt of the packets to update the server regarding the current communi-\ncation status. There are two desirable goals in conflict. On the one hand, the server would like to get\nprompt feedback from the client, which means the client should make more acknowledgements. On\nthe other hand, acknowledging frequently incurs a huge communication cost, and therefore it is desir-\nable to make fewer acknowledgements, which results in prolonged latency in feedback. Thus, there is a\nfundamental trade-off between making fewer acknowledgements and reducing acknowledgement latency.\nThe online dynamic acknowledgement problem1(DTAP) is an elegant model that was introduced\nin [16] to study the above trade-off of fundamental importance. An instance of DTAP is a sequence of\nnrequests (or demands) arriving online. Succinctly, it can be represented as ( pt)t∈[T], where ptis the\nnumber of demands (equivalently packets or requests) that arrive at time t∈[T] and it is unknown to\nthe algorithm. The requests must be acknowledged. When the client acknowledges (acks for short), all\noutstanding2requests are simultaneously satisfied. An outstanding request incurs 1 /ddelay cost each\ntime, where dis an input parameter, and each ack costs 1. The objective is to minimize the total ack\ncost plus the delay cost of all requests.\nThe DTAP admits a simple 2-competitive3greedy algorithm [16] that acks when the outstanding\nrequests have accumulated delay cost equal to 1. Also there is ae\ne−1-competitive randomized algorithm\n[33, 20, 12]. The competitive ratios are tight for both deterministic and randomized algorithms. The\noffline version of the problem can be solved optimally via dynamic programming or linear programming\nas the LP has no integrality gap [12].\nWhile DTAP is well understood, the traditional study of online algorithms using competitive ratios\nis often criticized for its pessimistic view of the instances. On the one hand, optimizing the competitive\nratio gives robust guarantees against any possible inputs. On the other hand, algorithms that opti-\nmize the competitive ratio could be highly tailored toward working well against worst-case instances,\nsacrificing performance for typical instances that tend not to be adversarial.\nThe framework of augmenting discrete optimization algorithms with machine learning [21, 26] has\nrecently emerged as a powerful framework for algorithm analysis. Such algorithms leverage machine\nlearned parameters to give beyond-worst case performance guarantees while providing robustness guar-\nantees even when given inaccurate parameters from the machine learning. The goal is to develop\nalgorithms that perform extremely well using ML for typical instances and exhibit robustness against\nexceptional—even adversarial—instances as traditional worst-case algorithms do.\nThis model has been used for various online problems. The predicted parameters can be used to\ncope with the uncertainty in the input. For example, caching [19, 26, 32, 35], buy-or-rent [2, 22], load\nbalancing [23, 24], scheduling [18, 9, 22, 28], secretary problem [4], metrical task systems [3], to name\na few.\nML augmented algorithms typically take an input Iand a prediction Pon the input. The prediction\nmay be revealed at the beginning or gradually over time as the input is. There is an error function\nη(I, P) defined to measure the quality of the prediction. The prediction is of high quality when ηis\nsmall. The algorithm’s objective—if it is to be minimized—is commonly bounded by a quantity of the\nfollowing form:\nmin{αOPT( I) +βη(I, P), γOPT( I)}, (1)\nwhere OPT( I) denotes the optimal objective on input I. The algorithm is then said to be α-consistent\nandγ-robust . In other words, the algorithm is almost α-competitive when the prediction is very accurate\nand always at most γ-competitive simultaneously.\nThis paper seeks to study the DTAP assuming we have learned predictions on the arriving requests.\nSpecifically, taking access to prediction, (ˆ pt)t∈[T], we would like to achieve consistency and robustness\nfor a certain error measure η.\n1This problem is also called the Dynamic TCP Acknowledgement problem.\n2A request is said to be outstanding if it has arrived yet has not been acknowledged (or equivalently satisfied).\n3An online algorithm is said to be c-competitive if its objective is at most ctimes the optimum for all inputs.\n2\n\nSimultaneous Optimum Consistency and Robustness. The above parameters, α, β, and γare\ncorrelated, and the guarantees differ depending on the correlation. Ideally, the guarantees should have\nthe following form.\nmin{(1 +ϵ)OPT + cη,(c∗+ϵ)OPT}, (2)\nwhere c∗is the best competitive ratio that can be achieved without using predictions and cis a constant\ndepending on ϵ. That is, we would like to achieve two goals simultaneously: on the one hand, we achieve\nnear optimality when the predictions are almost perfect; on the other hand, we simultaneously achieve\nthe best robustness against any inputs regardless of the prediction quality. We say this guarantee is\nsimultaneous optimum consistency and robustness .\nIntuitively, this kind of guarantee can be achieved as follows. We have two algorithms, Athat closely\nfollows predictions and Bthat is robust against all inputs. If we know that ηis large, then we use\nB—otherwise, A. However, ηis a function that depends on the whole input Iand the prediction P.\nTherefore, we can only estimate its value before seeing the entire input. Of course, one can design a\ntrivial algorithm that uses Bas soon as she notices that the prediction is not perfect. However, the\nalgorithm will then rarely benefit from predictions. Thus, it is critical to define an error measure that\ngrows graciously as the actual instance deviates from the predictions to be able to develop an algorithm\nthat still outperforms Bfor mild prediction errors. The algorithm crucially relies on the error measure\nη.\nThe primary goal of this paper is to develop an ML-augmented algorithm for the DTAP, which\nseems to resist a reasonable definition of η. Further, it is one of the most fundamental online problems\nwith temporal aspects where defining a good error measure has been elusive.\n1.1 Critical Need for Prediction Error\nBamas et al. [8] gave a very elegant framework to smoothly combine various primal-dual algorithms\nwith an arbitrary solution. In particular, for DTAP, they assume access to a complete solution as advice\nand let the primal-dual algorithm mimic the prediction. At a high level, they increase each outstanding\nrequest’s ‘potential’ and acks when their aggregated potential justifies it. If the algorithm is behind the\nprediction for a request, it increases its potential more aggressively to catch up with it. The combined\nalgorithm has cost at most min {λ\n1−e−λA,1\n1−e−λOPT}for any λ∈(0,1], where Ais cost of the given\nsolution on the instance.\nUnfortunately, the result has two critical issues. First, it assumes that we are given a complete\nsolution for the input as advice. Thus, if we are only given the number of demands at each time as\na prediction, we still have to devise an algorithm. It is possible to use the optimum solution for the\npredicted instance as a solution for the actual instance, although it is unclear if it is the best way to\nuse the prediction. Another issue is that it does not provide simultaneous optimum consistency and\nrobustness: To achieve near-optimum consistency, one cannot help but makeλ\n1−e−λ→1, but it will\nmake1\n1−e−λ→ ∞ , resulting a poor robust guarantee. The error measure serves as a barometer for the\nprediction’s accuracy, and the algorithm cannot change its behavior agilely without it.\n1.2 Challenges in Defining Prediction Error\nDespite the critical need for an error measure, it is non-trivial to define for DTAP—more broadly,\nproblems that involve temporal aspects; see Section 1.4. This is because requests with different arrival\ntimes could have different contributions to the objective, and the interaction between the delay cost\nand the ack cost is subtle. For instance, a few requests arriving later may make the optimal solution\nswitch most of its cost from acks to delay cost and change the solution structure.\nIntuitively, if the error is small, there should be a solution that is simultaneously good for both\nthe actual and predicted instances. It is not difficult to see that naive error measures fail to satisfy\nit. For example, say we use the ℓ1-norm, the aggregate sum of the prediction error at each time, i.e.,\nℓ1(I,ˆI) =P\nt∈[T]|pt−ˆpt|. But even if the instance is different from the prediction by only one request,\n3\n\nthe optimum can change a lot depending on whether the request is close to other requests. In short,\nthis is because the ℓ1-norm is oblivious to the arrival times. We discuss other natural error measures\nin Section 2.3.3 in detail and why they are unsatisfactory.\n1.3 Our Contributions\nOur contributions are summarized as follows.\n1. We give simultaneous optimum consistency and robustness for DTAP for the first time (Section 3\nand Section 4).\n2. We propose a novel error measure , which enables our algorithm and guarantees (Section 2.3.1).\n3. We show that the predictions are learnable with respect to the error measure (Section 5).\n4. Our experiments show that our new algorithm beats known learning augmented algorithms and\nremains on par with the algorithms with the best competitive ratio at the most time (Section 6).\nThe experiments demonstrate the theory is predictive of practice.\nOur main theoretical result is the following for our new error η, which will be shortly described.\nTheorem 1. For any ϵ >0, there is a randomized algorithm whose objective is bounded by min{(1 +\nϵ)OPT + O(1\nϵ2)η,(e\ne−1+ϵ)OPT}in expectation. Further, there is a deterministic algorithm whose\nobjective is bounded by min{(1 +ϵ)OPT + O(1\nϵ2)η,(2 +ϵ)OPT}.\nIn other words, we obtain simultaneous optimum consistency and robustness both deterministically\nand randomly. We also complement this result by showing that no deterministic algorithms have a cost\nsmaller than min {(1 +λ−ϵ)·OPT( I),(1 +η\nλ)}for any constant λ >0 and sufficiently small ϵ >0; see\nTheorem 4.\nOur new guarantees and algorithm crucially rely on our novel error measure. At a high level, we\nuse the optimal objective to define η, inspired by [18]. Following their idea, we can try to measure the\ndifference between OPT((max {pt,ˆpt})t) and OPT((min {pt,ˆpt})t). The former (the latter, resp.) is the\noptimal objective assuming the number of requests is the maximum (minimum, resp.) of the actual\nnumber and the prediction at each time. Although this satisfies the desiderata proposed by them,\nMonotonicity and Lipschitzness,4it fails to capture the temporal aspects of the problem as requests\nwith different arrival times could have a different effect; see Section 2.3.3 for more detail. In particular,\nwe show it could mistakenly label some bad predictions as good, making the error unusable in guiding\nthe algorithm’s decision. Therefore, we partition the time horizon and aggregate the error measured in\neach sub-interval. The maximum aggregate error over all partitions is what we adopt.\nUnder the new error measure, we successfully design a novel algorithm that quickly switches between\nexploiting the predictions and running robust algorithms. The algorithm is subtle. At a high level, the\nalgorithm first computes a nearly optimal solution that is stable in that adding extra acks cannot\nsignificantly reduce the cost. Intuitively this gives us an interval where we can measure the error\nwithout worrying too much about the interaction between the delay and ack costs. We set a budget we\ncan use until the first time t1when the nearly optimal solution acks. Until the time t1, at each time\nwe ack if we are still within the budget and the optimal solution on the actual instance would ack right\nnow. Note that we only loosely follow the prediction as the actual instance could be quite different\nfrom the prediction. Rather, we use the budget to figure out how much we should tolerate the errors.\nIf we run out of the budget before t1we switch to a robust algorithm, which can be the 2-competitive\ngreedy algorithm or thee\ne−1-competitive randomized algorithm. The algorithm is recursively defined\nfrom t1or from the time it exhausts the budget.\nThe prediction (ˆ pt)t∈[T]we use in our paper is natural and provably learnable. We show that the best\nprediction can be learned from polynomially many samples in Tif instances follow a certain unknown\ndistribution.\n4Monotonicity means the error should get smaller if the predictions are more correct; and Lipschitzness means the\nerror should change as much as the objective to successfully distinguish between good and poor predictions.\n4\n\n1.4 Other Related Work\nBalancing the communication cost and delay cost has been studied extensively due to its fundamental\nimportance in communication network, such as multicast acknowledgment [15, 10, 11, 29]; broadcast\nscheduling [25, 34], etc. DAP is one of the elegant models that captures the trade-offs between commu-\nnication cost and delay cost, and therefore it also has been studied in many previous works [1, 5, 14,\n30].\nDue to the explosive volume of work in the area of the learning-augmented algorithm, we only\ndiscuss the most closely related work. As discussed, [8] gave a framework that combines an arbitrary\nsolution and a primal-dual algorithm for various problems, such as online set cover and DTAP. More\ngenerally, [27] showed how to be competitive against two online algorithms simultaneously. In general,\nsuch approaches cannot achieve simultaneous optimum consistency and robustness.\nWe briefly discuss online problems with temporal aspects. To our knowledge, no work prior to ours\nassumes predictions on jobs or requests’ arrival time. Our error measure is inspired in part by the recent\nwork by [18] for non-clairvoyant scheduling where the goal is to better minimize average completion\ntime using predictions on job processing times. However, their work assumes all jobs arrive at the same\ntime. Its preceding work [31] uses the same prediction model but a different error measure. For average\nresponse time, see [6]. For various problems involving latency, see [7] and the pointers therein. For\nconnection to inventory management problems, see [13].\n2 Preliminaries & Prediction Error\n2.1 Notations\nTo formally study the DTAP, we set up some notations that will be used throughout the paper. We\nuse a set of points in time to denote a solution X={x1, . . . , x k}where the time points in the set\nare sorted in increasing order. We say it is feasible to instance I= (pt)t∈Tif (i) X⊆[T] and (ii)\nmaxX≥arg max t[pt>0]. Let n= arg maxt[pt>0]. Let x0= 0 and let F( I, X) be the objective value\nof the solution Xapplied to instance I:\nF(I, X) =|X|+1\nd·|X|X\ni=1\u0010 xiX\nt=xi−1+1pt(xi−t)\u0011\n,\nwhere each additional time unit of latency incurs a cost of1\nd.\nFor an arbitrary instance I, let OPT( I) denote the optimal solution or its objective depending on\nthe context. Similarly, let ALG( I) denote the solution of our algorithm, which will be discussed later,\nor its objective. Let D( I, X) and #( I, X) be the total delay cost and ack cost of the F( I, X).\nIn the analysis, we will frequently partition the time horizon [1 , T] according to a solution X=\n{x1, . . . , x k}. The partition PX= (P1, . . . , P k) is called a (time) partition induced by Xif and only if\nPi={t|xi−1< t≤xi}for all i∈[k]. Note that Pis a partition of the time interval [1 , n].\n2.2 Basic Properties\nLetI1= (p1\nt)t∈[n]andI2= (p2\nt)t∈[n]be two arbitrary instances of DTAP. In the following, we define\nseveral operations between I1, I2. Note that when I1andI2stop at a different time point, one could\nmake them stop at the same time by adding some 0 packet to the short one.\nDefinition 1. LetI= (pt)t∈[n]be the generated instance by I1, I2via the following operations:\n1.I:=|I1±I2|, where I= (pt)t∈[n]such that pt=|p1\nt±p2\nt|,∀t∈[n].\n2.I:= max {I1, I2}, where I= (pt)t∈[n]such that pt= max {p1\nt, p2\nt},∀t∈[n].\n3.I:= min {I1, I2}, where I= (pt)t∈[n]such that pt= min {p1\nt, p2\nt},∀t∈[n].\n5\n\nDefinition 2. Define the relationships between two instances I1, I2as follows:\n1.I1⪰I2if and only if p1\nt≥p2\nt,∀t∈[n].\n2.I1⪯I2if and only if p1\nt≤p2\nt,∀t∈[n].\nFor an arbitrary instance Iand a feasible solution X, let #( I, X), D( I, X) be the number of acks\nand the total delay costs, respectively. Note that F( I, X) = #( I, X) + D( I, X).\nProposition 1. LetI= (pt)t∈[n]andI′= (p′\nt)t∈[n]be two arbitrary instances. Let X⊆N>0be a\nfeasible solution.\n1.F(I,OPT( I))≤F(I,OPT( I′)).\n2.#(I, X) = #( I′, X).\n3.D(I, X)≤n\nd·P\nt∈[n]pt.\n4.I⪯I′=⇒D(I, X)≤D(I′, X).\n5.D(I+I′, X) = D( I, X) + D( I′, X).\n6.I⪯I′=⇒OPT( I)≤OPT( I′).\nObservation 1. Consider a feasible solution X={x1, . . . , x k}of an instance I= (pt)t∈[T]. Let\nSX= (S1, . . . , S k)be the partition induced by Xand define subinstance Ii:= (pt)t∈Si. We haveP\ni∈[k]OPT( Ii)≤k−1 + OPT( I).\nProof. Lettibe the last time point of subinstance Ii. We, w.l.o.g., assume that the optimal solution\nX∗sends an ack at the last time point, implying that tk∈X∗. Construct a new solution Y:=\nX∗∪{t1, t2, . . . , t k−1}. Clearly, F( I, Y)≤k−1+OPT( I) because the number of acks increases at most\nk−1 and the total delay cost is non-increasing.\nNow partition solution Yintokgroups Y1, . . . , Y k, where Yiis the set of the ack time points in\nthe time interval of Ii. Since ti∈Yfor any i∈[k], we have ti∈Yi, and thus, the objective value of\nsolution Yis exactly the sum of its values in ksubinstances, i.e., F( I, Y) =Pk\ni=1F(Ii, Yi).Then due\nto F( Ii, Yi)≥OPT( Ii) for any i∈[k], we prove the claim.\n2.3 Error Measure\nGiven an actual instance I= (pt)t∈[T]of DTAP and its predicted instance ˆI= (ˆpt)t∈[ˆT], we would\nlike to define a sound and effective error measure. Let n= max {T,ˆT}. We can always assume that\nboth the actual instance and the predicted instance have ntime points by adding zero package points.\nAs discussed in Section 1.3, we would like to satisfy the Monotonicity and Lipschitzness properties\nproposed by [18]:\nDefinition 3 ([18]).The error function ERR is monotone if for any S⊆[n],\nERR\u0012\n(pt)t∈[n],(ˆpt)t∈[n]\u0013\n≥ERR\u0012\n(pt)t∈n,(pt)t∈[S]∪(ˆpt)t∈[n]\\S\u0013\n,\nwhile it has Lipschitzness if\n|OPT(( pt)t∈[n])−OPT((ˆ pt)t∈[n])| ≤ERR\u0012\n(pt)t∈[n],(ˆpt)t∈[n]\u0013\n.\n6\n\nIntuitively, monotonicity ensures that if more request predictions are correct, then the error must\ndecrease. Lipschitzness ensures that the error measure can upper bound the difference between the\noptimal values of the actual instance and the predicted instance.\nHowever, a natural extension of the error measure used in [18] exhibits a critical weakness—although\nit satisfies the two properties—that it labels poor predictions as good. This is because the extension\nfails to capture the requests’ arrival time effectively; see Section 2.3.3 for the details. To address this\nchallenge, we propose a novel error measure.\n2.3.1 New Error Measure\nGiven an instance I= (pt)t∈[T]and it prediction ˆI= (ˆpt)t∈[ˆT], define O(I,ˆI) := (max {pt,ˆpt})t∈[n]\nandU(I,ˆI) := (min {pt,ˆpt})t∈[n]to be the overpredicted andunderpredicted instances respectively.\nAssuming that we take the max and min at every time step, we can write O(I,ˆI) = max {I,ˆI}and\nU(I,ˆI) = min {I,ˆI}.\nLetI⟨t1, t2⟩be the subinstance of Ifrom time t1tot2, i.e., ( pt)t∈{t1,...,t 2}. We define a partition P\nof the integer set [ T] as follows:\nP:={L1={l0, . . . , l 1}, L2={l1+ 1, . . . , l 2},···,}.\nThe set of consecutive time steps, Li, is called an interval . A partition Pis called non-empty for\ninstance Iif and only if I⟨Li⟩includes at least one request for every Li∈ P. LetQ(I) be the set of\nall non-empty partitions for instance I. Note that different partitions may have a different number of\nintervals. We are now ready to define our error measure.\nDefinition 4. (Error Measure) Given an instance I= (pt)t∈[T]and its predicted instance ˆI= (ˆpt)t∈[ˆT],\nthe error measure is defined as follows:\nη(I,ˆI) = max\nP∈Q(U(I,ˆI))X\nLi∈P\u0010\nOPT\u0010\nO(I⟨Li⟩,ˆI⟨Li⟩)\u0011\n−OPT\u0010\nU(I⟨Li⟩,ˆI⟨Li⟩)\u0011\u0011\nTo understand η, for a moment, assume that Phas only one interval. Then, ηmeasures how much\nthe optimal objective changes when the number of requests increases from min {pt,ˆpt}to max {pt,ˆpt}\nat all times. Although it satisfies Monotonicity and Lipschitzness, it fails to capture how requests\narriving at different times affect the ack times—if they change the ack times significantly, intuitively,\nthe prediction is not so good. Thus, we partition the time horizon [ T] into intervals and apply the same\nmeasure to each interval in P. Intuitively, if the error is big for some partition, it means IandˆIhave\nsignificantly different optimal solution structures.\nWhen the parameters are clear in the context, we may write η(I,ˆI) asηfor brevity. We claim the\nfollowing lemma.\nLemma 1. η(I,ˆI)can be efficiently computed by dynamic programming and satisfies both monotonicity\nand Lipschitzness.\nProof. We first show the Lipschitzness. By Observation 2, we have τ([1, n], I,ˆI)≤η. By Lemma 2, we\nhave|OPT( I)−OPT( ˆI)| ≤τ([1, n], I,ˆI). Thus, we have |OPT( I)−OPT( ˆI)| ≤η. Now, we show the\nMonotonicity. Fix an arbitrary non-empty partition S={S1, S2, . . .}and consider an arbitrary subset\nSi. Let fiandlibe the first and the last time point of Si. Let Ii=I⟨fi, li⟩andˆIi=⟨fi, li⟩. Then, the\nvalue of OPT( O(Ii,ˆIi)) will be decreased and the value of OPT( U(Ii,ˆIi)) will be increased if we replace\nsome ˆ ptwith pt, where t∈ {fi, . . . , l i}. Thus, OPT( O(Ii,ˆIi))−OPT( U(Ii,ˆIi)) will be decreased.\n2.3.2 Auxiliary Prediction Error\nFor the sake of analysis, we define another error measure called Auxiliary Error .\n7\n\nDefinition 5. (Auxiliary Error) Given I= (pt)t∈[T],ˆI= (ˆpt)t∈[ˆT], the auxiliary error in time interval\n[t1, t2]is defined as follows:\nτ\u0010\n[t1, t2], I,ˆI\u0011\n= OPT\u0010\nO(I⟨t1, t2⟩,ˆI⟨t1, t2⟩)\u0011\n−OPT\u0010\nU(I⟨t1, t2⟩,ˆI⟨t1, t2⟩)\u0011\nNote that η(I,ˆI) = maxP∈Q(U(I,ˆI))P\nLi∈P\u0010\nτ(Li, I,ˆI)\u0011\n. When the parameters are clear from the\ncontext, we may write τ([1, n], I,ˆI) asτfor simplicity, where n= max {T,ˆT}. The auxiliary error can\nbe used to lower bound ηand will be useful for the analysis.\nObservation 2. For any instance Iand its prediction ˆIand for any non-empty partition P=\n{L1, L2, . . .}ofU(I,ˆI), we haveP\nLi∈P\u0010\nτ(Li, I,ˆI)\u0011\n≤η(I,ˆI).\nIn the following, we show that the auxiliary error also satisfies both Monotonicity and Lipschitzness.\nLemma 2. Given an arbitrary instance I= (pt)t∈[n]of DTAP and its prediction instance ˆI= (ˆpt)t∈[n],\nthe auxiliary error τ([n], I,ˆI)satisfies both Monotonicity and Lipschitzness.\nProof. LetS⊂[n] and IS= (pt)t∈S,ˆIR= (ˆpt)t∈[n]\\S. We first show the Monotonicity, i.e., τ([1, n], I,ˆI)≥\nτ([1, n], I, I S∪ˆIR). Observe that O(I,ˆI) can only be decreased and U(I,ˆI) can only be increased if\nwe replace some ˆ ptwith pt. Therefore, we have O(I,ˆI)⪰O(I, IS∪ˆIR) and U(I,ˆI)⪯U(I, IS∪ˆIR).\nBy the property 6 of Proposition 1, we have OPT( O(I,ˆI))≥OPT( O(I, IS∪ˆIR)) and OPT( U(I,ˆI))≤\nOPT( U(I, IS∪ˆIR)). Thus, τ([1, n], I,ˆI) satisfies the Monotonicity. Now, we show the Lipschitzness.\nWe know that O(I,ˆI)⪰I,ˆIandU(I,ˆI)⪯I,ˆI. Due to the property 6 of Proposition 1, we have\nOPT( O(I,ˆI))≥OPT( I),OPT( ˆI) and OPT( U(I,ˆI))≤OPT( I),OPT( ˆI). Thus, the Lipschitzness\nproperty directly follows.\n2.3.3 Comparison with Other Prediction Errors\nBelow we compare our error measure with other natural measures and discuss their shortcomings.\nAbsolute Error: ERR(I,ˆI) =|OPT( I)−OPT( ˆI)|. This definition measures the difference of the\noptimal objectives of IandˆI. It satisfies Lipschitzness but violates the Monotonicity: Consider instance\nI= (2d,2d,0) and its predicted instance ˆI= (0,2d,2d). Clearly, |OPT( I)−OPT( ˆI)|= 0, as OPT( I) =\nOPT( ˆI) = 2. However, if we replace ˆ p1with p1to get a more accurate prediction (2 d,2d,2d),ERR(I,ˆI)\nincreases to 1 from 0.\nℓ1-norm Error: ERR(I,ˆI) =P\nt∈[T]|pt−ˆpt|. This definition linearly aggregates the difference of the\nactual number of requests from prediction over all times. This ℓ1-norm measure satisfies Monotonicity\nbut violates Lipschitzness: Consider instance I= (pt=ϵ)t∈[T]whereϵn(n−1)\n2d<1; thus the optimal\nsolution only acks at the last time. The prediction is ˆI= (ˆpt)t∈[T]where ˆ pt= 0 for all t∈[T−1]\nand ˆpT=ϵ. Clearly, the optimal solution for ˆIis the same as that for Ibut it incurs no delay cost\nforˆI. In this case, we have |OPT( I)−OPT( ˆI)|=n(n−1)ϵ\n2d. But, ERR(I,ˆI) = ( n−1)ϵ, so we have\n|OPT( I)−OPT( ˆI)| ≥n\n2dERR(I,ˆI). Thus, we need to add Θ( n) multiplier to the measure to make it\nusable.\nAuxiliary Error: ERR(I,ˆI) =τ([1, n], I,ˆI). This error measures how much the optimal objective\nchanges when increasing min {pt,ˆpt}to max {pt,ˆpt}at all times. This error measure satisfies both\nMonotonicity and Lipschitzness but is short of capturing the structure of the optimal solution. In\nparticular, it may tag poor predictions as good. To see this, consider an instance Iwhere a cluster of\nrequests arrive initially until time t1and one request arrives at a very late time t2. Then, we can set\nparameters appropriately, so the optimal solution makes only one ack at time t2and has cost 2 −ϵ.\n8\n\nSuppose the prediction ˆIis perfect except at time t1, and ˆ pt1is very large. Then, it is easy to see that\nacking at both times t1andt2is optimal and has cost 2. Thus, the error is at most ϵ, yet IandˆIhave\nvery different optimal solution structures. We can amplify their structural difference by repeating this\nexample over time.\nMore specifically, the instance satisfies pt̸= 0 for all t∈[t∗]∪ {n}, and pt= 0 for all the remaining\ntime points. Specifically,pt\nd=1\nt∗(n−t∗−1)for all t∈[t∗]. We assume that t∗=1\n100n. Sending at least\ntwo acks gives a total cost of at least 2, while if we send an ack only at the time point n, the total cost\nis 1 +2n−t∗−1\n2(n−t∗−1)= 2−ϵ. Thus, the optimal solution will only send an ack at the last time point and\nOPT( I) = 2−ϵ. Its predicted instance is ˆI= (ˆpt)t∈[n]such that ˆ pt∗is big enough and ˆ pt=ptfor all\nt∈[n]\\ {t∗}. Clearly, the optimal solution to ˆIwill send an ack at the time t∗andn, respectively.\nThen, we have OPT( ˆI) = 2 + ϵandτ= OPT( O(I,ˆI))−OPT( U(I,ˆI)) = 2 ϵ. By copying the above\ninstance many times, we see that although τis still very small, the structure of the optimal solution\ntoˆIandIbecomes totally different. This implies that τfails to capture the structure of the optimal\nsolution in the case. For our error measure ηdefined in Definition 4, we can partition [ n] into P1\nandP2such that P1={1,···, t∗−1}andP2= [n]\\P1. In the case, we have τ(P1, I,ˆI) = 0 and\nτ(P2, I,ˆI) = 1 −ϵ. Thus, η≥1−ϵ, indicating that our new error measure is better to measure the\ndifference between two instances’ structures than the previous error. This implies that our new error\nmeasurement can distinguish the current case.\n3 Consistency Bound\nIn this section, we present an algorithm and prove the consistency. More precisely, we show that for\nany instance I, the algorithm always returns a solution with the cost at most (1+ ϵ)·OPT( I)+O(1\nϵ)·η\nfor any ϵ >0. When the prediction error η= 0, the competitive ratio is (1 + ϵ). Later in Section 4,\nwe show how to refine the algorithm to obtain robustness simultaneously. We begin by introducing a\ncrucial definition that is necessary to understand our algorithmic intuition.\n3.1 Stability of Instances\nLetYbe a feasible solution of an instance I= (pt)t∈[T], i.e., the set of ack time points. Use D( I, Y)\nto denote the total delay cost of solution Yand define ∆( I, Y, t ) := D( I, Y)−D(I, Y∪ {t}) to be the\ndecrease of the delay cost when making an extra ack at time tin addition to an existing solution Y.\nDefinition 6. For a parameter λ, let an instance I= (pt)t∈[T]be a λ-stable interval if the solution\nXwhich sends only one ack at time Thas∆(I, X, t )≤1−λ,∀t∈[T]. Define an instance’s stability\nfactor as the maximum value of λsuch that it is a λ-stable interval. Further, the instance is stable if\nits stability factor is at least 0; otherwise, it is unstable.\nClearly, any instance where the optimal solution Xsends only one ack at time Tis at least 0-stable\nbecause for any time t, ∆(I, X, t )≤1; otherwise, making an extra ack at time tdecreases the total cost.\nSuppose that the stability factor of the instance is exactly 0. Namely, there exists at least one time t\nsuch that ∆( I, X, t ) = 1. We see that increasing ptslightly will force the optimal solution to make an\nextra ack. Thus, for a stable interval, the stability factor λmeasures how much noise can change the\nstructure of the optimal solution on it.\nDefining stability is critical for our algorithm. Intuitively, when the predicted instance is a stable\ninterval, it is convenient to detect a considerable prediction and justify the extra acks. Thus, if we can\npartition the predicted instance into several stable intervals without incurring too much cost, handling\neach stable interval independently gives a consistent algorithm.\nIn the following, Section 3.2 presents an algorithm to deal with the case that the predicted instance\nis a stable interval, and then Section 3.3 shows how to do partitioning in the general case and obtain a\ndesirable competitive ratio.\n9\n\nAlgorithm 1 . Predicted-Budget-Based Algorithm\nInput: Online Instance I= (pt)t∈[T], prediction ˆI= (ˆpt)t∈[ˆT], and parameter λ >0\nOutput: A feasible solution S\n1:S← ∅;j←0;t←1.\n2:Compute OPT( ˆI) for the predicted instance.\n3:// Phase-1.\n4:while F(I⟨1, t⟩, S∪ {t})<(1 +λ)OPT( ˆI) and the online instance does not end do\n5:ifI⟨j+ 1, t+ 1⟩is unstable then\n6: S←S∪ {t}. // Send an ack at time point t.\n7: j←t.\n8:end if\n9:t←t+ 1.\n10:end while\n11:// Phase-2.\n12:ifthe online instance does not end then\n13: Run the traditional 2-competitive online algorithm for the remaining instance and let Ybe the\nreturned solution. Let S←S∪Y.\n14:end if\n15:return S\n3.2 Stable Prediction Case\nThis subsection considers a special case that the predicted instance is a λ-stable interval, i.e., the\noptimal solution ˆXonly sends one ack, and ∆( ˆI,ˆX, t)≤1−λfor all t∈[ˆT]. The algorithm is stated\nin Algorithm 1. It consists of two phases. The first phase is concerned with “good” prediction cases,\nwhile the second phase runs a traditional competitive algorithm to handle inputs that turn out to be\nfar off from the prediction. The pseudo-code uses the 2-competitive algorithm that is deterministic, but\nit can also be replaced with thee\ne−1competitive algorithm that is randomized.\nTo decide if the predictions are reliable or not, the algorithm uses (1 + λ)OPT( ˆI) as “budget”. The\nalgorithm does not switch to the second phase if it has paid within the budget. For each time tin the\nfirst phase, the algorithm acks if the subinstance I⟨j+ 1, t+ 1⟩is unstable, where jis the last time an\nack was made. Using the fact that the prediction makes only one ack at the end of a single interval in\na stable instance, we can show that the prediction has a considerable error. Thus, we can charge the\ncost for making extra acks to the error. Also, the algorithm makes an ack when it is forced to finish\nthe first phase due to running out of budget. It is worth noting that the switched time point may be\nlarger than ˆT, which is the last time point in the predicted instance.\nTheorem 2. LetALG( I)be the objective value obtained by Algorithm 1. If the predicted instance is a\nλ-stable interval ( λ >0),ALG( I)≤(1 +λ)·OPT( ˆI) +O(1\nλ)·τ,where τ=τ([1, n], I,ˆI)is the auxiliary\nerror (see Definition 5), which is a lower bound of the prediction error η.\nWe sketch the proof of Theorem 2. Use Xto denote the solution returned by Algorithm 1. As stated\nin Algorithm 1, the algorithm consists of two phases. Let ebe the last time in the first phase; then e∈X\nby the algorithm. Time epartitions [ T] into two parts: Sa={1, . . . , e }andSb={e+ 1, . . . , T }. It is\nworth to note that emay equal T, which makes Sb=∅. Define Xa:={t∈X|t≤e},Xb:=X\\Xa,\nIa:= (pi)i∈SaandIb:= (pi)i∈Sb. Then, we can split the objective value into two parts: ALG( I) =\nF(Ia, Xa) + F( Ib, Xb),where the first and second terms are the cost incurred for the algorithm in the\nfirst and second phases, respectively. Theorem 2 can be proved by the following two lemmas.\nLemma 3. F(Ia, Xa)≤(1 +λ)·OPT( ˆI)≤(1 +λ)·(OPT( ˆI) +τ).\nProof. This lemma is easy to prove because the first phase is budget limited, that is, all cost incurred\nin this phase is at most the budget (1 + λ)OPT( ˆI). Moreover, if the algorithm enters the second phase,\n10\n\nthe F( Ia, Xa) = (1 + λ)OPT( ˆI) holds by the definition of the algorithm. Then due to the Lipschitzness\nof the auxiliary error (Observation 2), we have OPT( ˆI)≤OPT( I) +τ, completing the proof.\nLemma 4. F(Ib, Xb)≤2·OPT( Ib)≤(2 +4\nλ)·τ.\nProving Lemma 4 is a bit subtle. In the following, we shall apply Observation 1 to the analysis.\nProof of Lemma 4. The first inequality uses the fact that the second phase runs the traditional 2-\ncompetitive algorithm. So we only need to focus on the second inequality. We distinguish two cases\naccording to the existence of phase-2. The first case is that the algorithm is still in phase-1 at time T,\ni.e.,Ib=∅. Then the second inequality is trivial since OPT( Ib) = 0. For the second case that Ib̸=∅,\nsince{Ia, Ib}is a partition of instance I, by Observation 1, OPT( Ib)≤1 + OPT( I)−OPT( Ia).\nIn phase-1, according to the “if-condition” in Algorithm 1, the subinstance between any two adjacent\nacks is a stable interval, implying that the algorithm obtains the optimal solution for each subinstance.\nThus, using Observation 1 again gives a lower bound of OPT( Ia): OPT( Ia)≥F(Ia, Xa)−ka+ 1,\nwhere kais the number of acks in phase-1. Since Ib̸=∅, the first phase must run out of the predicted\nbudget, which indicates that F( Ia, Xa)≈(1 +λ)OPT( ˆI). Without loss of generality, we can assume\nF(Ia, Xa)≥OPT( ˆI). Hence, OPT( Ib)≤1 + OPT( I)−OPT( ˆI) +ka−1≤τ+ka,where the last\ninequality is due to the Lipschitzness of τ.\nThe remaining piece of proof is to bound the value of ka. Up to this point, we have not used the\ncondition that the predicted instance ˆIis aλ-stable interval. The following analysis uses this condition\nto prove ka≤2τ/λ.\nUse{I1, . . . , I ka, . . . , I k}to denote the subinstances induced by solution X. Let Ti= [si, ti] be\nthe time interval of subinstance Ii. Recall that O(I,ˆI) is the over-predicted instance (max {pt,ˆpt})t∈n,\nwhere n= max {T,ˆT}. For brevity, denote O(I,ˆI) byIO= (pO\nt)t∈n, where pO\nt= max {pt,ˆpt}. Let ˆX\nbe the optimal solution of the predicted instance ˆI. Since we assume that ˆIisλ-stable, ˆX={ˆT}.\nClaim 1. The optimal solution of instance IOsends at least one ack in interval Tifor any i∈[ka].\nClaim 2. For any interval partition {ˆI1, . . . , ˆIl}of instance ˆI, use Yi={yi}to denote the solution that\nonly sends an ack at the last time point of ˆIi. We have D(ˆI,ˆX)≤Pl\ni=1D(ˆIi, Yi) +Pl\ni=1∆(ˆI,ˆX, y i).\nFor now, we assume that the above two claims are correct and we shall prove them later. Use\nsolution Y={y1, . . . , y l}to denote the optimal solution of instance IO. By Claim 1, we know that\nsolution Ysends at least kaacks, i.e.,\nl≥ka. (3)\nThus, we turn to upper bound the value of l. Notice that\nl= OPT( IO)−D(IO, Y), (4)\nUse{IO\n1, . . . , IO\nl}to denote the subinstances of instance IOinduced by solution Y. Then, D( IO, Y) =Pl\ni=1D(IO\ni,{yi}).We further define ˆIito be the subinstance of ˆIwhich shares the same time interval\nofIO\ni. Clearly,\nD(IO, Y) =lX\ni=1D(IO\ni,{yi})≥lX\ni=1D(ˆIi,{yi}). (5)\nBy Claim 2, we can connect the above quantity to OPT( ˆI):\nlX\ni=1D(ˆIi,{yi})≥D(ˆI,ˆX)−lX\ni=1∆(ˆI,ˆX, y i). (6)\nDue to the assumption that ˆIis aλ-stable interval and the fact that ∆( ˆI,ˆX, y l) = 0,\nD(ˆI,ˆX) = OPT( ˆI)−1, (7)\n11\n\nand\nlX\ni=1∆(ˆI,ˆX, y i)≤(1−λ)·(l−1). (8)\nCombining the above inequalities, we have\nl+lX\ni=1D(ˆIi,{yi})≤OPT( IO) (Eq. (4) & (5))\nl+ D( ˆI,ˆX)≤OPT( IO) +lX\ni=1∆(ˆI,ˆX, y i) (Eq. (6))\nλ·l−λ≤OPT( IO)−OPT( ˆI) (Eq. (7) & (8))\nka≤τ\nλ+ 1. (Eq. (3) & Def. 5)\nThe last piece is to carefully show that τ/λis always at least 1, which implies that ka≤2τ/λand\ncompletes the proof. If ka≥2, we have τ/λ≥ka−1≥1. Then if ka= 1, the algorithm sends only one\nack in phase-1. Thus, Iais a stable interval and F(Ia, Xa) = OPT( Ia)<OPT( IO). Since the algorithm\nruns out of the predicted budget (1+ λ)OPT( ˆI) and enters phase-2, we have OPT( IO)≥(1+λ)·OPT( ˆI).\nAgain, due to Definition 5, τ≥λ·OPT( ˆI)≥λ,indicating that τ/λis still at least 1.\nProof of Theorem 2. Combining Lemma 3 and Lemma 4, we have ALG( I)≤(1+λ)·OPT( ˆI)+(2+4\nλ)·τ\nwhich directly proves the theorem.\nNow, we prove Claim 1 and Claim 2 in the following.\nProof of Claim 1. For the sake of contradiction, we assume that there exists an i∈[k] such that\nOPT( O(I,ˆI)) does not send the ack at any time point in Si. Algorithm 1 sends an ack at the time si\nbecause OPT( I⟨si−1+1, si+1⟩) sends an ack at some time point in Si. For the notation convenience, we\ndefine the instance I⟨si−1+ 1, si+ 1⟩asIsiandO(I⟨si−1+ 1, si+ 1⟩,ˆI⟨si−1+ 1, si+ 1⟩) asIO\nsi. Suppose\nthat OPT( Isi) sends an ack at the time twhere si−1+1≤t≤si. Thus, we have ∆( Isi,{si+ 1}, t)≥1.\nSince IO\nsi⪰Isi, we have ∆( Isi,{si+ 1}, t)≥∆(IO\nsi,{si+ 1}, t)≥1. Thus, there must exist an optimal\nsolution to O(I,ˆI) such that the solution also sends an ack at the time t.\nThe correctness of Claim 2 can be directly implied by the following simple observation (Observa-\ntion 3).\nObservation 3. Consider an arbitrary instance I= (pt)t∈[n]of DTAP, let Xbe a feasible integral\nsolution such that Xonly sends one ack at the last time point, i.e., X={n}. Let Y={y1, . . . , y k}be\nanother feasible integral solution with |Y|=k. LetHY= (H1, . . . , H k)be the solution partition of Y.\nLethibe the first time point in the set Hi. Let Ii= (pt)t∈Hi. Then, D(I, X) =P\ni∈[k]D(Ii,{yi}) +P\ni∈[k−1]∆(I⟨hi, n⟩, X, y i).\n3.3 General Algorithm\nNow we consider the general case. As mentioned above, the basic idea is partitioning the instance into\nseveral stable prediction subinstances and dealing with each subinstance separately. The key challenge\nhere is how to partition the instance such that the sum of the subinstances’ optimal values is close to\nthe optimal value of the original instance. We first give a statement in Section 3.3.1 to show that it is\nnot ridiculous that such a partition exists. And then we present the main algorithm in Section 3.3.2.\n12\n\n3.3.1 λ-Stable Solution\nDefinition 7. For an instance I, a feasible solution Ywith kacks partitions it into ksubinstances\n{I1, I2, . . . , I k}. We say solution Yisλ-stable if any subinstance induced by it is a λ-stable interval,\ni.e., for any time tof the whole instance I,∆(I, Y, t )≤1−λ.\nAlgorithm 2 . Adaptive Predicted-Budget-Based Algorithm\nInput: Online Instance I= (pt)t∈[T], prediction ˆI= (ˆpt)t∈[ˆT]and parameter λ >0.\nOutput: A feasible solution X.\n1:X← ∅;t′←0.\n2:LetYbe a λ-stable1\n1−λ-approximation solution of ˆI.\n3:while t′<ˆTandˆI⟨t′,ˆT⟩is not a λ-stable interval do\n4: Letˆtbe the minimum time point in Ywhich is larger than t′.\n5: Run Algorithm 1 on the input {I⟨t′+ 1, T⟩,ˆI⟨t′+ 1,ˆt⟩, λ}until the first phase ends.\n6: LetZbe the returned solution and t′′be the termination time.\n7:ift′′<ˆtthen\n8: Run the traditional 2-competitive algorithm for instance I⟨t′′+ 1,ˆt⟩and let Ybe the returned\nsolution\n9:end if\n10: X←X∪Z∪Y;t′←max{t′′,ˆt}.\n11:end while\n12:ift′<ˆTand the online instance does not end then\n13: Run Algorithm 1 on the input {I⟨t′+ 1, T⟩,ˆI⟨t′+ 1,ˆT⟩, λ}and let Zbe the returned solution.\n14: X←X∪Z.\n15:end if\n16:return X\nLemma 5. For any instance I= (pt)t∈[T]of DTAP and any λ∈[0,1), there exists a λ-stable solution\nwhich is (1\n1−λ)-approximation and can be computed in polynomial time.\nTo show Lemma 5, we give an algorithm (Algorithm 3) that transforms an arbitrary optimal solution\ninto a λ-stable solution. The intuition is that we start from an optimal solution and always make an\nextra ack at time twhere the ∆ value is larger than 1 −λ. Clearly, each extra ack increases the objective\nvalue by at most λ. Thus, the newly incurred cost is at most λtimes the number of acks in the new\nsolution, implying the total cost of the new solution can be bounded.\nAlgorithm 3 . λ-stable Solution Constructor.\nInput: Arbitrary instance I= (pt)t∈[n]of DTAP and a constant λ.\nOutput: A feasible solution Ysuch that F( I, Y)≤1\n1−λ·OPT( I).\n1:Compute the optimal solution XtoI.\n2:Y←X.\n3:fort∈[n] such that t /∈Ydo\n4:if∆(I, Y, t )>1−λthen\n5: Y←Y∪ {t}.\n6:end if\n7:end for\n8:return Y.\nProof of Lemma 5. LetXbe the optimal solution to the instance I. We show a simple algorithm that\nis described in Algorithm 3 returns (1\n1−λ)-approximation solution. Let Xbe the optimal solution to the\n13\n\ninstance IandYbe the solution returned by Algorithm 3. Suppose that Algorithm 3 has kiterations,\ni.e.,kacks are inserted to the solution Xby Algorithm 3. Let Xibe the solution after ( i−1)-th iteration\nof Algorithm 3. Consider an arbitrary iteration r, let tbe the time point that is added to Xin the\ncurrent iteration. We know that ∆( I, X r, t)>1−λwhich implies that D( I, X r)−D(I, X r∪{t})>1−λ.\nNote that #( I, X r∪ {t})−#(I, X r) = 1. Thus, F( I, X r∪ {t})−F(I, X r)< λ. Therefore, we have\nF(I, Y)−F(I, X)≤k·λ. Since k≤F(I, Y), we have F( I, Y)≤1\n1−λ·OPT( I).\nAccording to Lemma 5, we can easily split the predicted instance ˆIinto several λ-stable intervals\nand the incurred cost is at most O(λ)OPT( ˆI). Then due to the Lipschitzness of our prediction error\n(Lemma 1), the cost is at most O(λ)(OPT( I) +η).\n3.3.2 The Main Algorithm\nWe now give the main algorithm which is shown in Algorithm 2. It iteratively treats an interval of\nλ-stable O(λ)-approximation solution as an instance of the stable prediction case and calls Algorithm 1.\nFrom the description, we see that iterations are handled independently. In each iteration, the\nalgorithm always starts by trusting the prediction regardless of the states in the previous iterations and\nenters the next iteration if (i) Algorithm 1 runs out of the predicted budget of the current iteration;\nand (ii) Algorithm 1 has processed requests until the last time point of the current predicted interval.\nSince the algorithm adapts in each iteration, we refer to it as an adaptive algorithm. We claim the\nfollowing theorem.\nTheorem 3. For an instance I= (pt)t∈[T]and its prediction ˆI= (ˆpt)t∈[ˆT], let the ALG( I)be the cost of\nthe solution returned by Algorithm 2 with λ= Θ( ϵ), then we have: ALG( I)≤(1+ϵ)·OPT( I)+O(1\nϵ)·η.\nFurther, the running time is O(n2), where n= max {T,ˆT}.\nThe analysis follows from aggregating the bounds over all the intervals. The proof framework is first\nto show thatP\ni(OPT( ˆIi))≤(1 +O(λ))·OPT( ˆI) andP\niτi≤η, where ˆIiis the i-th stable prediction\nsubinstance and τiis its auxiliary error. Then, using Theorem 2 and Lemma 5 proves the claimed\ncompetitive ratio in Theorem 3. For the running time, the most time-consuming part is computing\nthe optimal offline solution of the predicted instance, while all other operations can be implemented\nin the linear time. Since the optimal solution can be computed by a O(n2) dynamic programming\nalgorithm [16], the running time can be proved easily. Thus, in the proof of Theorem 3, we focus on\nthe proof of the ratio.\nProof of Theorem 3. Given an arbitrary instance I= (pt)t∈[n]of DTAP and its predicted instance\nˆI= (ˆpt)t∈[m], we assume that Algorithm 2 has krounds and the i-th round stop at the ti-th time\npoint. Let OPT( ˆIi) be the budget of Algorithm 1 in the i-th round. Let Z={ti|i∈[k]}. Note\nthatZis a feasible solution to the actual instance I. LetHZ= (H1, . . . , H k) be the solution partition\nofZ. Note that HZmust be a non-empty partition. Let Ii= (pt)t∈Hi. By Theorem 2, we have\nALG( Ii)≤(1 + λ)·OPT( ˆIi) + (2 +4\nλ)·τifor all i∈[k], where τi=τ(Hi, I,ˆI). Thus, we haveP\ni∈[k]ALG( Ii)≤(1 +λ)·P\ni∈[k]OPT( ˆIi) + (2 +4\nλ)·P\ni∈[k]τi. Note that ALG( I) =P\ni∈[k]ALG( Ii).\nBy Lemma 5, we haveP\ni∈[k]OPT( ˆIi)≤1\n1−λOPT( ˆI). Thus, we have ALG( I)≤1+λ\n1−λ·OPT( ˆI) + (2 +\n4\nλ)·P\ni∈[k]τi. Since OPT( ˆI)≤OPT( I) +τ([1,max{n, m}], I,ˆI)≤OPT( I) +η, we have ALG( I)≤\n1+λ\n1−λ·(OPT( I) +η) + (2 +4\nλ)P\ni∈[k]τi. By Observation 2, we have η≥P\ni∈[k]τi. Therefore, we have\nALG( I)≤1+λ\n1−λ·OPT( I) + (1+λ\n1−λ+ 2 +4\nλ)·η. Thus, we have the ratio: ALG( I)≤(1 +ϵ)·OPT( I) +\nO(1\nϵ)·η.\n3.4 Optimality of Consistency\nWe claim the following theorem to show that the dependence of the prediction error ηin Algorithm 2\nis almost the best possible.\n14\n\nTheorem 4. Given an instance Iand its prediction ˆI, the solution of any deterministic algorithm is\nat least min{(1 +λ)·OPT( I),OPT( I) +η\nλ}, where λ >0is a parameter.\nProof. Consider the following hard instance. The predicted instance only has one time point and we\nassume that the number of packets is p1, wherep1\nd=ϵandϵ >0 is an arbitrarily small value. The\nactual instance has p1packets at time 1, and all the remaining time points have no packets. The\nactual instance may have ptpackets at time tdepending on the algorithm’s decision. Assume that\nan arbitrary algorithm ALG sends an ack at the time t′. Let D( p1) be the delay of the packets in\ntime 1 in ALG’s solution. If D( p1)≥λ−ϵ, then we set pt= 0 in the actual instance, i.e., the actual\ninstance only has p1packets in time 1. Clearly, ALG( I)≥λ+ 1−ϵwhile OPT( I) = 1. Thus,\nALG( I)≥(λ+ 1−ϵ)·OPT( I) in the current case. If D( p1)< λ−ϵ, set t=t′+ 1, i.e., the actual\ninstance has pt′+1packets in the time t′+ 1. Clearly, ALG( I)≥2 + D( p1). By the definition of η, we\nhave η= D( p1) +ϵsince OPT( O(I,ˆI)) = OPT( I) = 1 + D( p1) +ϵand OPT( U(I,ˆI)) = OPT( ˆI) = 1.\nThus, ALG( I)≥OPT( I) + 1 since D( p1) =ϵ. Since D( p1)< λ−ϵ, we haveη\nλ<1. Thus, we have\nALG( I)≥OPT( I) +η\nλ, completing the proof.\n4 Robustness Bound\nThis section refines Algorithm 2 to obtain robustness bounds in addition to the consistency bound.\nFormally, we shall show the following lemma (Lemma 6) in this section.\nLemma 6. Given an arbitrary instance I= (pt)t∈[n]of DTAP, let ALG( I)be the solution returned by\nAlgorithm 4. We have ALG( I)≤min{(1 +ϵ)·OPT( I) +O(1\nϵ2)·η,(2 + 5 ϵ)·OPT( I)}.\nWe will first discuss the high-level idea in Section 4.1. And then, we state the formal proof in\nSection 4.2.\n4.1 Intuition\nIn this subsection, we discuss the high-level ideas. For each time t, define It:=I⟨1, t⟩andηt:=\nη(It∪ˆI⟨t+ 1, n⟩,ˆI). Due to the monotonicity of the error, ηtincreases as tincreases. An intuitive way\nto gain robustness is switching to the 2-competitive deterministic (or e/(e−1)-competitive randomized)\nalgorithm when ηtis found to be large. If we know the optimal value OPT( I), we can then make the\nswitch at the first time twe observe the error is large, i.e., ηt> ϵOPT( I). Due to the monotonicity\ndiscussed above, the actual error ηwill only be large. Thus, we can achieve (1 + ϵ)-consistency bound\nalong with (2 + ϵ)-robustness bound (or e/(e−1) +ϵif randomization is allowed).\nHowever, we can only see Itat each time tand thus, OPT( I) is unknown. The current error ηtcould\nlook large compared to OPT( It), but turn out to be very small compared to OPT( I). We address this\nissue based on the observation that an instance can be partitioned into several subinstances such that\nthe optimal cost of each subinstance is at most 1 /ϵwhile increasing the aggregate optimal cost by at\nmost (1 + ϵ) factor. Further, this partition can be done online by checking the optimal solution to the\ncurrent subinstance at every time point. Then, for each subinstance, we can argue that if the current\nerror is large enough to shift to the traditional algorithm, it is also large against the optimum for the\nsubinstance. In this process, to obtain a robustness guarantee, we increase the coefficient of ηfrom\nO(1\nϵ) toO(1\nϵ2) in the consistency bound for a technical reason. Combing Theorem 3 and the robustness\nscheme, Theorem 1 can be proved.\n4.2 The Formal Proof\nIn this subsection, we formally show the robustness result stated in Lemma 6. Let ALG( I) be the\nsolution returned by Algorithm 2. By Theorem 3, we know that ALG( I)≤1+λ\n1−λ·OPT( I)+(1+λ\n1−λ+2+4\nλ)·η.\nFor notational convenience, let1+λ\n1−λ+ 2 +4\nλ=1\nϵλ. Following the intuition above, at each time point,\nwe check the current error, when the error is large the algorithm will be switched to the traditional\n15\n\nonline algorithm; otherwise, we run Algorithm 2. The formal description can be found in Algorithm 4.\nIn order to further simplify the expression of ratio, we assume that the value of the optimal solution is\nalways less than1\nλ. Finally, we use Lemma 7 to remove this assumption.\nLemma 7. Given an arbitrary instance I= (pt)t∈[n]of DTAP, there exists a set of time points Q⊆[n],\nQ={q1, . . . , q k}with OPT( I⟨qi−1+ 1, qi⟩)≤1\nλsuch thatPk\ni=1OPT( I⟨qi−1+ 1, qi⟩))≤(1 + λ)·\nOPT( I) + 1 , where λ∈(0,1).\nProof. We start from an empty set Q. Suppose that the last time point in the current Qisqi. In each\ntime point t≥qi+ 1, we can compute the value of OPT( I⟨qi+1, t⟩). As long as the time point tsatisfies\n(i) OPT( I⟨qi+1, t⟩)≤1\nλ; (ii) OPT( I⟨qi+1, t+ 1⟩)>1\nλ, the time point twill be added to the set Q.\nLetHQ= (H1, . . . , H k) be the solution partition of Q. Note that k≤ ⌈λOPT( I)⌉. Let Ii= (pt)t∈Hi.\nBy Observation 1, we havePk\ni=1OPT( Ii)≤OPT( I) +k≤(1 +λ)OPT( I) + 1.\nAlgorithm 4 . Robustness Guarantee in One Phase\nInput: Arbitrary instance I= (pt)t∈[n]of DTAP, its predicted instance ˆI= (ˆpt)t∈[n], the time point\nsetQand a constant λ.\nOutput: A feasible solution.\n1:while i≤kdo\n2:foreach time point tinHido\n3: ifηqi−1+1,t≤ϵλthen\n4: // Small error, trust the predictions\n5: Run Algorithm 2 for the instance I⟨qi−1+ 1, t⟩.\n6: else\n7: // Big error, follow the online algorithm\n8: Run the traditional online algorithm for the remaining instance I⟨t, qi⟩.\n9: end if\n10: end for\n11: i←i+ 1.\n12:end while\nGiven an arbitrary instance Iof DTAP, let Q={q1, . . . , q k}be the time point set that satisfies\nthe property stated in Lemma 7. By the proof of Lemma 7, one could easily get the set Qonline,\ni.e., without knowing the instance prior. To simplify the description of the robustness algorithm, we\nassume that the set Qis known by the algorithm. Let ηt,t′be the error between I⟨t, t′⟩andˆI⟨t, t′⟩.\nLetHQ={H1,···, Hk}be the solution partition of H. Let Ii= (pt)t∈Hi. Assume that the first time\npoint is tiand the last time point is t′\niinHi. Let ηi=ηti,t′\ni. We first show the robustness guaranty in\neach Hi(Lemma 8).\nLemma 8. Fix an arbitrary Hi∈ H Q. Given an arbitrary instance I= (pt)t∈[n]of DTAP, let ALG( I)\nbe the solution returned by Algorithm 4, then we have ALG( Ii)≤min{(1 +ϵ)·OPT( Ii) +O(1\nϵ2)·ηi,2·\nOPT( I) +ϵ}.\nProof. Fix an arbitrary set Hi∈ H Q. Suppose that Algorithm 4 is switched to the traditional 2-\ncompetitive online algorithm at the time t. By our robustness condition, we know that the current error\nis greater than ϵλ. Let S1={t′∈Hi|t′≤t}andS2=Hi\\S1. Let I1= (pt)t∈S1andI2= (pt)t∈S2.\nThus, for each Hi, we have ALG( I1) = 2·OPT( I1) + 1 and ALG( I2)≤2·OPT( I2). By Observation 1,\nwe have ALG( Ii)≤2·OPT( Ii) + 3. By Theorem 3, we have:\nALG( Ii)≤(\n1+λ\n1−λ·OPT( Ii) +1\nϵληiifηi≤ϵλ\n2OPT( Ii) + 3 if ηi> ϵλ(9)\n16\n\nBy Lemma 7, we have OPT( Ii)≤1\nλ. Then, we have1\nϵλ≤1\nϵλ·\u0010\n(2−1+λ\n1−λ)OPT( Ii) + 3\u0011\n≤O(1\nλ·ϵλ).\nThus, to make the piecewise function above continuous, we can increase the factor O(1\nϵ) toO(1\nϵ2).\nTherefore, Equation (9) can be written as:\nALG( Ii)≤min{(1 +ϵ)·OPT( Ii) +O(1\nϵ2)·ηi,2OPT( Ii) + 3}\nProof of Lemma 6. By Lemma 7, we haveP\niOPT( Ii)≤(1+λ)·OPT( I)+1. Thus, we have ALG( I)≤\n(1 +ϵ)·OPT( I) +O(1\nϵ2)·η. By Lemma 7 and Observation 1, we have ALG( I)≤2(1 + λ)OPT( I) +\n3λOPT( I) = (2 + 5 λ)·OPT( I).\n5 Learnability\nThis section shows that we can learn a prediction with approximately minimum expected error given\nonly a polynomial number of samples. We make standard assumptions that the number of time steps\nis at most T, the number of packages per time step is at most K, and each DAP instance is sampled\nfrom an unknown distribution D. Use Ito denote the set of all potential predictions ˆI, i.e., I:=\n{(p1, p2, . . . , p T)| ∀t∈[T], pt∈[0, K]}.\nTheorem 5. For any ϵ, δ∈(0,1)and any distribution D, after observing O((T\nϵ)2(Tlog(KT\nϵd) + ln(1\nδ))\nsamples, there exists a learning algorithm that returns a predicted instance ˆI∈ Isuch that with prob-\nability at least 1−δ,EI∼D[η(ˆI, I)]≤EI∼D[η(I∗, I)] +ϵ,where for any two instances I1, I2,η(I1, I2)\nrepresents the error when I1is the prediction of I2, and I∗= arg minI′∈IEI∼D[η(I′, I)].\nThe basic proof idea is that we first show that with only a small loss on the minimum expected\nerror, Ican be reduced to a finite set. Then due to the bounded pseudo-dimension of that finite set,\nthe sample complexity can be bounded. Before stating the reduction, we prove a simple lemma first.\nLemma 9. For any two instances I1={p(1)\nt}t∈[T]andI2={p(2)\nt}t∈[T],|OPT( I1)−OPT( I2)| ≤ρT/d ,\nwhere ρis the ℓ1-norm distance between the two instances.\nProof. LetX(1)be the optimal solution of instance I1. Let # X(1)be the number of acknowledgements\nin solution X(1), and for each time point t∈[T]. Let D(1)\ntdenote the waiting time of the packages\narriving at time tin solution X(1). We have\nOPT( I2)≤F(X(1), I2)\n= #X(1)+X\nt∈[T]P(2)\ntD(1)\nt/d\n≤#X(1)+X\nt∈[T]P(1)\ntD(1)\nt/d+ρT/d\n= OPT( I1) +ρT/d.\nAnalogously, we can also prove that OPT( I1)≤OPT( I2) +ρT/d .\nLemma 10. For any ϵ∈(0,1)and any distribution D, there exists a finite set Fwith size O((KT2\nϵd)T)\nsuch that\nmin\nˆI∈FEI∼D[η(ˆI, I)]≤min\nˆI∈IEI∼D[η(ˆI, I)] +ϵ.\n17\n\nProof. Given an ϵ∈(0,1), define ϵ0:=ϵd/T2. The finite set Fis defined to be a set of instance\nI∈ I, in which the number of packages at any time point is an integral multiple of ϵ0. Clearly, the\nsize of FisO((K/ϵ 0)T). Now we show that for any instance I∼Dand ˆI∈ I/F, we can round\ninstance ˆIto an instance ˆI′∈ Fsuch that |η(ˆI, I)−η(ˆI′, I)| ≤ϵ, which implies min ˆI∈FEI∼D[η(ˆI, I)]≤\nmin ˆI∈IEI∼D[η(ˆI, I)] +ϵdirectly.\nPartition the interval [0 , K] into⌈K/ϵ 0⌉sub-intervals [0 , ϵ0],(ϵ0,2ϵ0], ...,((⌈K/ϵ 0⌉ −1)ϵ0,⌈K/ϵ 0⌉ϵ0].\nFor an instance ˆI∈ I/F, we round each ptto the upper bound of the sub-interval that ptbelongs to.\nDenote the new instance after rounding by ˆI′. Clearly, the ℓ1-norm distance between instance ˆIandˆI′\nis at most Tϵ0.\nFor convenience, let IO\ni:=O(Ii,ˆIi) and IU\ni:=U(Ii,ˆIi). Recall that\nη(ˆI, I) := max\nP∈PX\nIi∈P(OPT( IO\ni)−OPT( IU\ni)).\nWe define P0to be the partition which yields the value of η(ˆI′, I), i.e.,\nP0= arg max\nP∈PX\nIi∈P(OPT(( I′\ni)O)−OPT(( I′\ni)U)).\nNote that the ℓ1-norm distance between instance ˆIandˆI′is at most Tϵ0. By Lemma 9, we have\nη(ˆI′, I) =X\nIi∈P0(OPT(( I′\ni)O)−OPT(( I′\ni)U))\n≤X\nIi∈P0(OPT(( Ii)O)−OPT( IU\ni)) +T2ϵ0/d\n≤η(ˆI, I) +ϵ.\nWe can also prove η(ˆI, I)≤η(ˆI′, I) +ϵanalogously. Finally, we have |η(ˆI, I)−η(ˆI′, I)| ≤ϵ, which\ncompletes the proof.\nSince Fis a finite set with size O((KT2\nϵd)T), its pseudo-dimension is O(Tlog(KT\nϵd)). According to\nthe theorem proposed in [17], we have the following lemma.\nLemma 11. For any ϵ, δ∈(0,1)and any distribution D, after observing O((T\nϵ)2(Tlog(KT\nϵd) + ln(1\nδ))\ntraining samples, the predicted instance ˆI∈ F with the minimum empirical error ηamong the training\nsamples satisfies\nEI∼D[η(ˆI, I)]≤EI∼D[η(I∗, I)] +ϵ\nwith probability at least 1−δ, where I∗= arg minI′∈FEI∼D[η(I′, I)].\nCombining Lemma 10 and Lemma 11, Theorem 5 can be proved directly.\n6 Experiments\nThis section empirically validates our adaptive learning-augmented algorithm (ALA) ’s efficiency. We\ninvestigate various types of input distribution and show superior performance compared to previous\nalgorithms.\n6.1 Setup\nInput distributions and Noisy Predictions The experiments follow the setting in [8]. We set\nthe delay factor d= 100 and the maximum number of time steps T= 1000. For each time point, the\nnumber of demands is i.i.d. sampled from a given distribution D. We investigate the same distributions\n18\n\nas in [8]: the Poisson distribution of mean 1, the Pareto distribution of shape 2 and the iterated Poisson\ndistribution of mean 1. The iterated Poisson distribution is a custom distribution introduced in [8],\nwhich is iterating on sampling a value from the Poisson distribution whose mean is the sampled value in\nthe last iteration (initially, the mean is 1). The prediction of an instance is constructed by perturbing\nit with some noise. For each time t, there are two operations: setting pt= 0 and adding to pta random\nnoise sampled from D. We perform each operation sequentially and independently with probability\nr∈[0,1] at each time point. Then, the perturbed instance is served as the prediction. The perturbing\nprobability can be viewed as a simplified measure of the prediction error. The experiments test the\nperformance of algorithms over different perturbing probabilities under each input distribution.\nBaseline Algorithms In addition to our algorithm, which is parameterized by λ, we implemented\nthe following algorithms for comparison:\n•Greedy [16]. This algorithm acks when the cumulative delay cost equals 1 (the ack cost). It is\nthe best deterministic algorithm without predictions.\n•PDLA [8]. This algorithm is the first algorithm incorporating predictions. The algorithm has a\ncontrol parameter β∈(0,1], and has a better consistency guarantee with a smaller value of βat\nthe cost of a worse robustness guarantee. This was termed as the primal dual learning-augmented\nalgorithm by the authors.\n•BlindFollowing . This algorithm follows the prediction blindly. It applies the optimal solution\non the predicted instance to the actual instance with no adaptation.\nNote that we did not include thee\ne−1-competitive randomized algorithm as it rarely outperforms\nthe 2-competitive deterministic algorithm in practice.\nComputational Settings. We conduct experiments on a machine running Ubuntu 18.04 with an\ni7-7800X CPU and 48 GB memory. The algorithms are implemented in Python 3.8, and the results are\naveraged over five runs.\n6.2 Empirical Discussion\nAll the results for the three considered distributions exhibit similar patterns. Thus, we only discuss the\nresults for the Pareto distribution in Figure 1, and only show the results for the Poisson distribution\n(Figure 2) and the iterated Poisson distribution (Figure 3). We observe the following.\n•Our algorithm is robust to the error. Further, with a small λ, our algorithm has a better empirical\ncompetitive ratio than algorithm Greedy when the prediction error (perturbing probability) is\nsmall and remains on par with it, regardless of the error.\n•For the choice of βandλvalues that lead to the same consistency guarantee, our algorithm shows\na better performance than PDLA in most cases. This demonstrates that our algorithm obtains a\nbetter trade-off between consistency and robustness, confirming the importance of simultaneous\noptimum consistency and robustness achieved by our algorithm.\n7 Conclusion\nThis paper revisited the dynamic acknowledgment problem. For this problem, previously, it was unclear\nwhat a good error measure should be in the learning augmented algorithm analysis model. One of this\npaper’s main contributions lies in formulating a novel error measure and designing algorithms based\non the error. The algorithm developed in this paper achieves simultaneous optimum consistency and\nrobustness, the most desirable result. The theory is verified empirically. We believe our new error and\n19\n\n(a)β= 1, λ= 0.58\n (b)β= 0.6, λ= 0.32\n (c)β= 0.2, λ= 0.1\nFigure 1: The performance of the algorithms under the Pareto distribution. A large perturbing proba-\nbility implies a large prediction error. Recollect that PDLA [8] parameterized by βhas a consistency\nratio ofβ\n1−e−β, and our algorithm parameterized by λa consistency ratio of (1+ λ). For fair comparison,\nwe consider different pairs of ( β, λ) that give the same consistency ratio for PDLA and our algorithm.\n(a)β= 1, λ= 0.58\n (b)β= 0.6, λ= 0.32\n (c)β= 0.2, λ= 0.1\nFigure 2: The performance of algorithms under the Poisson distribution.\nalgorithm could inspire new ML-augmented solutions for other problems with a temporal nature to\ntheir input5.\nAcknowledgement\nChenyang Xu was supported in part by Science and Technology Innovation 2030 –“The Next Generation\nof Artificial Intelligence” Major Project No.2018AAA0100900. Sungjin Im was supported in part by\nNSF grants CCF-1844939 and CCF-2121745. Benjamin Moseley was supported in part by a Google\nResearch Award, an Infor Research Award, a Carnegie Bosch Junior Faculty Chair, and NSF grants\nCCF-2121744 and CCF-1845146\n5The authors have provided public access to their code at https://github.com/Chenyang-1995/TCP\n20\n\n(a)β= 1, λ= 0.58\n (b)β= 0.6, λ= 0.32\n (c)β= 0.2, λ= 0.1\nFigure 3: The performance of algorithms under the iterated Poisson distribution.\n21\n\nReferences\n[1] Ammar Al-Jubari et al. “An Adaptive Delayed Acknowledgment Strategy to Improve TCP Per-\nformance in Multi-hop Wireless Networks”. In: Wirel. Pers. Commun. 69.1 (2013), pp. 307–333.\n[2] Keerti Anand, Rong Ge, and Debmalya Panigrahi. “Customizing ML predictions for online algo-\nrithms”. In: ICML . 2020, pp. 303–313.\n[3] Antonios Antoniadis et al. “Online Metric Algorithms with Untrusted Predictions”. In: ICML .\n2020, pp. 345–355.\n[4] Antonios Antoniadis et al. “Secretary and online matching problems with machine learned advice”.\nIn:NeurIPS . 2020.\n[5] Farzaneh R. Armaghani et al. “Performance Analysis of TCP with Delayed Acknowledgments in\nMulti-hop Ad-hoc Networks”. In: Wirel. Pers. Commun. 56.4 (2011), pp. 791–811.\n[6] Yossi Azar, Stefano Leonardi, and Noam Touitou. “Flow time scheduling with uncertain processing\ntime”. In: STOC . ACM, 2021, pp. 1070–1080.\n[7] Yossi Azar and Noam Touitou. “Beyond Tree Embeddings - a Deterministic Framework for Net-\nwork Design with Deadlines or Delay”. In: FOCS . IEEE, 2020, pp. 1368–1379.\n[8]´Etienne Bamas, Andreas Maggiori, and Ola Svensson. “The Primal-Dual method for Learning\nAugmented Algorithms”. In: NeurIPS . 2020.\n[9]´Etienne Bamas et al. “Learning augmented energy minimization via speed scaling”. In: NeurIPS .\n2020.\n[10] Carlos Brito, Elias Koutsoupias, and Shailesh Vaya. “Competitive analysis of organization net-\nworks or multicast acknowledgement: how much to wait?” In: SODA . SIAM, 2004, pp. 627–635.\n[11] Eli Brosh and Yuval Shavitt. “Approximation and Heuristic Algorithms for Minimum-Delay Ap-\nplication Layer Multicast Trees”. In: INFOCOM . IEEE, 2004, pp. 2697–2707.\n[12] Niv Buchbinder and Joseph Naor. “The Design of Competitive Online Algorithms via a Primal-\nDual Approach”. In: Found. Trends Theor. Comput. Sci. 3.2-3 (2009), pp. 93–263.\n[13] Niv Buchbinder et al. “Online Make-to-Order Joint Replenishment Model: Primal-Dual Compet-\nitive Algorithms”. In: Oper. Res. 61.4 (2013), pp. 1014–1029.\n[14] Rung-Shiang Cheng and Hui-Tang Lin. “Improving TCP performance with bandwidth estima-\ntion and selective negative acknowledgment in wireless networks”. In: J. Commun. Networks 9.3\n(2007), pp. 236–246.\n[15] Yousri Daldoul, Toufik Ahmed, and Djamal-Eddine Meddour. “IEEE 802.11n aggregation perfor-\nmance study for the multicast”. In: Wireless Days . IEEE, 2011, pp. 1–6.\n[16] Daniel R. Dooly, Sally A. Goldman, and Stephen D. Scott. “TCP Dynamic Acknowledgment\nDelay: Theory and Practice (Extended Abstract)”. In: STOC . ACM, 1998, pp. 389–398.\n[17] Rishi Gupta and Tim Roughgarden. “A PAC Approach to Application-Specific Algorithm Selec-\ntion”. In: SIAM J. Comput. 46.3 (2017), pp. 992–1017.\n[18] Sungjin Im et al. “Non-Clairvoyant Scheduling with Predictions”. In: SPAA . ACM, 2021, pp. 285–\n294.\n[19] Zhihao Jiang, Debmalya Panigrahi, and Kevin Sun. “Online algorithms for weighted paging with\npredictions”. In: ICALP (2020), 69:1–69:18.\n[20] Anna R. Karlin, Claire Kenyon, and Dana Randall. “Dynamic TCP acknowledgement and other\nstories about e/(e-1)”. In: STOC . ACM, 2001, pp. 502–509.\n[21] Tim Kraska et al. “The Case for Learned Index Structures”. In: SIGMOD . 2008, pp. 489–504.\n[22] Ravi Kumar, Manish Purohit, and Zoya Svitkina. “Improving online algorithms Using ML pre-\ndictions”. In: NeurIPS . 2018, pp. 9661–9670.\n22\n\n[23] Silvio Lattanzi et al. “Online scheduling via learned weights”. In: SODA . 2020, pp. 1859–1877.\n[24] Shi Li and Jiayi Xian. “Online Unrelated Machine Load Balancing with Predictions Revisited”.\nIn:International Conference on Machine Learning . PMLR. 2021, pp. 6523–6532.\n[25] Zaixin Lu et al. “Efficient scheduling algorithms for on-demand wireless data broadcast”. In:\nINFOCOM . IEEE, 2016, pp. 1–9.\n[26] Thodoris Lykouris and Sergei Vassilvtiskii. “Competitive caching with machine learned advice”.\nIn:ICML . 2018, pp. 3296–3305.\n[27] Mohammad Mahdian, Hamid Nazerzadeh, and Amin Saberi. “Online optimization with uncertain\ninformation”. In: TALG 8.1 (2012), pp. 1–29.\n[28] Michael Mitzenmacher. “Scheduling with predictions and the price of misprediction”. In: ITCS .\n2020, 14:1–14:18.\n[29] Kianoosh Mokhtarian and Hans-Arno Jacobsen. “Minimum-Delay Multicast Algorithms for Mesh\nOverlays”. In: IEEE/ACM Trans. Netw. 23.3 (2015), pp. 973–986.\n[30] Ruy de Oliveira and Torsten Braun. “A dynamic adaptive acknowledgment strategy for TCP over\nmultihop wireless networks”. In: INFOCOM . IEEE, 2005, pp. 1863–1874.\n[31] Manish Purohit, Zoya Svitkina, and Ravi Kumar. “Improving online algorithms via ML predic-\ntions”. In: Advances in Neural Information Processing Systems 31 (2018), pp. 9661–9670.\n[32] Dhruv Rohatgi. “Near-Optimal Bounds for Online Caching with Machine Learned Advice”. In:\nSODA . 2020, pp. 1834–1845.\n[33] Steven S. Seiden. “A guessing game and randomized online algorithms”. In: STOC . ACM, 2000,\npp. 592–601.\n[34] Chi-Jiun Su and Leandros Tassiulas. “Broadcast Scheduling for Information Distribution”. In:\nINFOCOM . IEEE Computer Society, 1997, pp. 109–117.\n[35] Alexander Wei. “Better and Simpler Learning-Augmented Online Caching”. In: APPROX-RANDOM .\nVol. 176. LIPIcs. 2020, 60:1–60:17.\n23",
  "textLength": 68095
}