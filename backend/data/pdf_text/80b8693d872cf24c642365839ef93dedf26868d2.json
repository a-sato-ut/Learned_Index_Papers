{
  "paperId": "80b8693d872cf24c642365839ef93dedf26868d2",
  "title": "Synthesizing Machine Learning Programs with PAC Guarantees via Statistical Sketching",
  "pdfPath": "80b8693d872cf24c642365839ef93dedf26868d2.pdf",
  "text": "Synthesizing Machine Learning Programs with PAC\nGuarantees via Statistical Sketching\nOSBERT BASTANI, University of Pennsylvania, USA\nWe study the problem of synthesizing programs that include machine learning components such as deep\nneural networks (DNNs). We focus on statistical properties, which are properties expected to hold with high\nprobabilityâ€”e.g., that an image classification model correctly identifies people in images with high probability.\nWe propose novel algorithms for sketching and synthesizing such programs by leveraging ideas from statistical\nlearning theory to provide statistical soundness guarantees. We evaluate our approach on synthesizing list\nprocessing programs that include DNN components used to process image inputs, as well as case studies on\nimage classification and on precision medicine. Our results demonstrate that our approach can be used to\nsynthesize programs with probabilistic guarantees.\n1 INTRODUCTION\nMachine learning has recently become a powerful tool for solving challenging problems in artificial\nintelligence. As a consequence, there has been a great deal of interest in incorporating machine\nlearning components such as deep neural networks (DNNs) into real-world systems, ranging from\nhealthcare decision-making [ 22,27,38], to robotics perception and control [ 44,56], to improving\nperformance of software systems [16, 17, 39, 40, 43].\nIn these domains, there is often a need to ensure correctness properties of the overall system.\nTo reason about such properties, we need to reason about properties of the incorporated machine\nlearning components. However, it is in general impossible to absolutely guarantee correctness of a\nmachine learning componentâ€”e.g., we can never guarantee that a DNN correctly detects every\nsingle image containing a pedestrian. Instead, we consider statistical properties , which are properties\nthat hold with high probability with respect to the distribution of inputsâ€”e.g., we may want to\nensure that the DNN detects 95% of pedestrians encountered by an autonomous car.\nWe propose a framework for synthesizing programs that incorporate machine learning com-\nponents while satisfying statistical correctness properties. Our framework consists of two com-\nponents.1First, it includes a novel statistical sketching algorithm, which builds on the concept of\nsketching [ 66] to provide statistical guarantees. At a high level, it takes as input a sketch annotated\nwith specifications encoding statistical properties that are expected to hold, as well as holes cor-\nresponding to real-valued thresholds for making decisions (e.g., the confidence level at which to\nlabel an image as containing a pedestrian or to diagnose a patient with a disease). Since statistical\nproperties depend on the data distribution, it additionally takes as input a labeled dataset of training\nexamples (separate from those used to train the DNNs). Then, our algorithm selects values to fill\nthe holes in the sketch so all the given specifications are satisfied.\n1For completeness, our framework also includes a third component for statistical verification of machine learning pro-\ngrams [62, 73], which is described in Appendix A.\nAuthorâ€™s address: Osbert Bastani, obastani@seas.upenn.edu, University of Pennsylvania, USA.\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\nthe full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires\nprior specific permission and/or a fee. Request permissions from permissions@acm.org.\nÂ©2021 Association for Computing Machinery.\nXXXX-XXXX/2021/10-ART $15.00\nhttps://doi.org/10.1145/nnnnnnn.nnnnnnn\n, Vol. 1, No. 1, Article . Publication date: October 2021.arXiv:2110.05390v1  [cs.PL]  11 Oct 2021\n\n2 Bastani\nSecond, our framework uses this sketching algorithm in conjunction with a syntax-guided syn-\nthesizer [ 2] to synthesize programs in a specific domain that provably satisfy statistical guarantees.\nOur strategy is to first synthesize a sketch whose specifications encode the overall statistical cor-\nrectness property, and then apply our sketching algorithm to fill the holes in the sketch so these\nspecifications are satisfied with high probability.\nThe key challenge is providing statistical guarantees for programs using DNNs. To do so, we\nleverage generalization bounds from statistical learning theory [ 34,69,71]. These bounds can be\nthought of as a variant of concentration inequalities to apply to parameters that are estimated based\non a dataset. Traditionally, it is hard to apply generalization bounds to obtain useful guarantees on\nthe performance of machine learning components. One reason is that modern machine learning\nmodels such as DNNs do not satisfy assumptions in learning theory. However, a deeper issue is\nthat learning theory can only prove bounds with respect to the best model in a given family, not\nthe â€œtrueâ€ model. More precisely, given a model family Fand a training dataset Â®ğ‘§, learning theory\nprovides bounds on the performance of the model Ë†ğ‘“learned usingÂ®ğ‘§in the following form:\nğ¿(Ë†ğ‘“)â‰¤ğ¿(ğ‘“âˆ—)+G(F,ğ‘›),\nwhereğ¿a loss function (e.g., the accuracy of a model ğ‘“) andGis a measure of the complexity\nofFin the context of the amount of available training data ğ‘›=|Â®ğ‘§|(e.g., VC dimension [ 34] or\nRademacher complexity [ 7]). In particular, learning theory provides no tools for bounding the error\nğ¿(ğ‘“âˆ—)of the optimal model given infinite training examples. In other words, learning theory cannot\nguarantee that Ë†ğ‘“is good at detecting pedestrians; at best, that given enough data, it is as good at\ndetecting pedestrians as the best possible DNN ğ‘“âˆ—âˆˆF.\nHowever, we can provide guarantees for loss functions ğ¿where we know that there exists some\nsolutionğ‘“âˆ—with zero loss ğ¿(ğ‘“âˆ—)=0. In an analogy with program verification, we cannot in general\ndevise verification algorithms that are both sound and complete. Instead, the goal is to devise\nalgorithms that are as precise as possible subject to a soundness constraint. Similarly, our goal is to\nlearn models that perform as well as possible while satisfying a statistical propertyâ€”i.e., we want a\nmodel that empirically minimizes the number of false alarms while still satisfying the correctness\nguarantee. For instance, this approach satisfies the above condition since ğ¿(ğ‘“âˆ—)=0ifğ‘“âˆ—predicts\nthere is a pedestrian in every image. Thus, we might learn a model that is guaranteed to detect 95%\nof pedestrians but reports many false alarms (but in practice, we often achieve good performance).\nIn this context, we show how to use learning theory to sketch programs with statistical guarantees.\nThe machine learning components (e.g., DNNs) in the given sketch have already been trained\nbefore our sketching algorithm is applied. In particular, the only task that must be performed by\nour sketching algorithm is to choose threshold values to fill the holes in the sketch in a way that\nsatisfies the given specifications while maximizing performanceâ€”e.g., choose the confidence level\nof the DNN above which an image contains a pedestrian so we detect 95% of pedestrians. Then,\ngeneralization bounds can give us formal guarantees because (i) we are only synthesize a handful\nof parameters, so the generalization error G(F,ğ‘›)is small, and (ii) we can always choose the\nthresholds to make conservative decisions, so the error ğ¿(ğ‘“âˆ—)of the best possible model is small (we\nchoose the loss ğ¿to measure whether the given specifications are satisfied, not the performance).\nNext, we propose an algorithm for synthesizing machine learning programs that leverages our\nstatistical sketching algorithm as a subroutine. We consider a specification saying that with high\nprobability, the synthesized program should either return the correct answer or return â€œunknownâ€.\nThis specification is consistent with the above discussion since we can naÃ¯vely ensure correctness\nby always returning â€œunknownâ€. Then, our goal is to synthesize a program that satisfies the desired\nstatistical specification but returns â€œunknownâ€ as rarely as possible. To achieve this goal, our\nsynthesis algorithm first uses a standard enumerative synthesis algorithm to identify a program\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 3\nthat is correct when given access to ground truth labels. When ground truth labels are unavailable,\nthis program must instead use labels predicted by machine learning components; to satisfy the\nspecification, these components include holes corresponding to predicted confidences below which\nthe component returns â€œunknownâ€. Then, our algorithm uses statistical sketching to fill these holds\nwith thresholds in a way that satisfies the statistical property encoded by the given specification.\nOur sketching algorithm requires the holes in the sketch to be annotated with local correctness\nproperties; then, it fill sthe holes in a way that satisfies these annotations. Thus, the main challenge\nfor our synthesizer is how to label holes in the sketch with these annotations so that if the\nannotations hold true, the given specification is satisfied. We instantiate such a strategy in the\ncontext of list processing programs where the components can include learned DNNs such as object\nclassifiers or detectors. In particular, our algorithm analyzes the sketch to allocate allowable errors\nto each hole in a way that the overall error of the program is bounded by the desired amount.\nWe have implemented our approach in a tool called StatCoder , and evaluate it in two ways.\nFirst, we evaluate its ability to synthesize list processing programs satisfying statistical properties\nwhere the program inputs are images, and DNN components are used to classify or detect objects in\nthese images. Our results show that our algorithm for error allocation outperforms a naÃ¯ve baseline,\nand that our novel statistical learning theory bound outperforms using a more traditional bound.\nSecond, we perform two case studies of our sketching algorithm: one on ImageNet classification\nand another on a medical prediction task, which demonstrate additional interesting applications of\nour sketching algorithm. In summary, our contributions are:\nâ€¢A sketching language for writing programs that incorporate machine learning components\nin a way that ensures correctness guarantees (Section 3).\nâ€¢Algorithms for sketching (Section 4) and synthesizing (Section 5) such programs.\nâ€¢An empirical evaluation (Section 7) validating our approach in the context of our list process-\ning domain (for synthesis) as well as two case studies (for sketching).\n2 OVERVIEW\nWe describe how our statistical sketching algorithm can construct a subroutine for detecting\nwhether an image contains a person, guaranteeing that if the image contains a person, then it\nreturns â€œtrueâ€ with high probability. Then, we describe how our synthesizer uses the sketching\nalgorithm to synthesize a program that counts the number of people in a sequence of images.\nStatistical sketching. We assume given a DNN component ğ‘“:Xâ†’[ 0,1]that, given an image\nğ‘¥âˆˆX, predicts whether ğ‘¥contains a person. In particular, ğ‘“(ğ‘¥)is a score indicating its confidence\nthatğ‘¥contains a person; higher score means more likely to contain a person. We do not assume\nthe the scores are reliableâ€”e.g., they may be overconfident. We assume that the ground truth label\nğ‘¦âˆ—âˆˆY={0,1}indicates whether ğ‘¥contains a person. For example, ğ‘“(ğ‘¥)may be the probability\nthat an image contains a person according to a pretrained DNN such as ResNet [ 29]; then, the goal\nis to tailor this DNN to the current task in a way that provides correctness guarantees.\nIn particular, our goal is to choose a threshold ğ‘âˆˆ[0,1]such that the program returns that\nthe given image ğ‘¥contains a person if ğ‘“(ğ‘¥)has confidence at least 1âˆ’ğ‘â€”i.e.,ğ‘“(ğ‘¥)â‰¥1âˆ’ğ‘, or\nequivalently, 1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘. Furthermore, we want ğ‘to be correct in the following sense:\n(ğ‘¦âˆ—=1)â‡’( 1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘)\nThat is, if the image contains a person (i.e., ğ‘¦âˆ—=1), then the classifier should say so (i.e., 1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘).\nNote that we do not require the converseâ€”i.e., the program may incorrectly conclude that an image\ncontains a person even if it does not. That is, we want soundness (i.e., no false negatives) but not\nnecessarily completeness (i.e., no false positives). However, we cannot guarantee that soundness\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n4 Bastani\nholds for every image ğ‘¥; instead, we want to guarantee it holds with high probability. There are\ntwo ways to formulate probabilistic correctness. First, we can say ğ‘isğœ–-approximately correct if\nPğ‘(ğ‘¥,ğ‘¦âˆ—)\u0000ğ‘¦âˆ—=1â‡’1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘\u0001â‰¥1âˆ’ğœ–, (1)\nwhereğ‘(ğ‘¥,ğ‘¦âˆ—)is the data distribution and ğœ–âˆˆR>0is a user-provided confidence levelâ€”i.e., ğ‘“is\ncorrect for 1âˆ’ğœ–fraction of images sampled from ğ‘(ğ‘¥,ğ‘¦âˆ—)that contain a person. Alternatively, we\ncan sayğ‘isğœ–-approximately correct if\nPğ‘(ğ‘¥,ğ‘¦âˆ—)\u00001âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘|ğ‘¦âˆ—=1\u0001â‰¥1âˆ’ğœ–. (2)\nWe refer to (1) as an implication guarantee and (2) as a conditional guarantee . The difference is how\nâ€œirrelevant examplesâ€ (i.e., ğ‘¦âˆ—=0) are counted: (1) counts them as being correctly handled, whereas\n(2) omits them from consideration. In our example, (1) says we can count all images without people\nas being correctly handled. If most images do not contain people, then we can make a large number\nof mistakes on images that contain people and still achieve â‰¥1âˆ’ğœ–correctness overall. In contrast,\n(2) ignores images without people, so we must obtain â‰¥1âˆ’ğœ–correctness rate on images with\npeople alone. However, using (2), if there are very few images with people, then estimates of the\nerror rate can be very noisy, making our algorithm very conservative. We allow the user choose\nwhich guarantee to use; intuitively, (1) can be used if the goal is to bound the overall error rate,\nwhereas (2) should be used if it is to bound the error rate among relevant examples. Our syntax for\nexpressing the specification in our example is\n1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘{ğ‘¦âˆ—=1}|\n0.05.\nThe syntax|indicates the conditional guarantee (2); we use â‡’to indicate (1).\nWe need to slightly weaken our guarantees in an additional way. The reason is that our algorithm\nrelies on training examples Â®ğ‘§={(ğ‘¥1,ğ‘¦âˆ—\n1),...,(ğ‘¥ğ‘›,ğ‘¦âˆ—\nğ‘›)}to chooseğ‘, where(ğ‘¥ğ‘–,ğ‘¦âˆ—\nğ‘–) âˆ¼ğ‘are i.i.d.\nsamples from ğ‘(ğ‘¥,ğ‘¦âˆ—). Thus, as with probably approximately correct (PAC) bounds from statistical\nlearning theory [ 28,69], we need to additional allow a possibility that our algorithm fails altogether\ndue to the randomness in our training examples Â®ğ‘§. In particular, consider an algorithm ğ´that\nchoosesğ‘=ğ´(Â®ğ‘§); then, we say ğ´is(ğœ–,ğ›¿)-PAC if\nPğ‘(Â®ğ‘§)\u0000ğ´(Â®ğ‘§)isğœ–-approximately correct\u0001â‰¥1âˆ’ğ›¿\nwhereğ‘(Â®ğ‘§)is the distribution over the training examples Â®ğ‘§, andğ›¿âˆˆR>0is another user-provided\nconfidence level. Then, given the sketch, a value ğ›¿âˆˆR>0, and a datasetÂ®ğ‘§, our algorithm synthesizes\na value ofğ‘to fill ??1in a way that ensures that the specification holds (i.e., ğ‘isğœ–-approximately\ncorrect) with probability at least 1âˆ’ğ›¿.\nSynthesis algorithm. Next, suppose we want to synthesize a program that counts the number of\npeople in a list of images â„“=(ğ‘¥1,...,ğ‘¥ğ‘›). Intuitively, we can do so by writing a simple list processing\nprogram around our DNN for detecting people. In particular, letting\n(predictpersonğ‘¥)= 1(1âˆ’ğ‘“(ğ‘¥)â‰¤??)\nbe our DNN component, where the detection threshold has been left as a hole, then the sketch\nËœğ‘ƒex=(fold+ (map predictpersonâ„“)0)\ncounts the number of people in â„“. Given a few input-output examples along with the ground truth\nlabels for each image, we can use a standard enumerative synthesizer to compute the sketch Ëœğ‘ƒex,\nassuming predictperson returns the ground truth label. In particular, this sketch has a single hole in\nthe DNN component predictperson that remains to be filled.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 5\nNote that Ëœğ‘ƒexevaluates correctly if predictperson returns the ground truth label, but in general,\nit may make mistakes. Thus, the correctness property for the synthesized program ğ‘ƒexneeds to\naccount for the possibility that predictperson may return incorrectly. Mirroring the correctness\nproperty for a single prediction, suppose we want a program ğ‘ƒexthat conservatively overestimates\nthe number of people in â„“.2In particular, given confidence levels ğœ–,ğ›¿âˆˆR>0, we say a completion\nğ‘ƒexofËœğ‘ƒexisğœ–-approximately correct if\nPğ‘(ğ›¼)(Jğ‘ƒexKâ„“â‰¥ğ‘¦âˆ—)â‰¥1âˆ’ğœ–,\nwhereğ›¼=(â„“,ğ‘¦âˆ—)is an example, and Jğ‘ƒKâ„“denotes the output of running program ğ‘ƒon inputâ„“.\nThen, we say our synthesis algorithm is (ğœ–,ğ›¿)-probably approximately correct (PAC) if\nPğ‘(Â®ğ›¼)(ğ´(Ëœğ‘ƒex,Â®ğ›¼)isğœ–-approximately correct )â‰¥1âˆ’ğ›¿,\nwhereğ‘ƒex=ğ´(Ëœğ‘ƒex,Â®ğ›¼)is the program synthesized using our algorithm and training examples Â®ğ›¼.\nUsing our statistical sketching algorithm, we can provide (ğœ–â€²,ğ›¿â€²)-PAC guarantees on predictperson\nfor anyğœ–â€²,ğ›¿â€²âˆˆR>0; thus, the question is how to choose (i) the appropriate specification, (ii) the\nparameters of this specification, and (iii) the confidence levels ğœ–â€²,ğ›¿â€². These choices depend on the\nspecification that we want to ensure for the synthesized program ğ‘ƒex. In our example, we can use\nthe specification aboveâ€”i.e., that predictperson returns 1with high probability if there is a person:\n(predictpersonğ‘¥)= 1(1âˆ’ğ‘“(ğ‘¥)â‰¤??){ğ‘¦âˆ—=1}|\nğœ–â€².\nIn general, the specification on predictperson may have additional parameters (in particular, for\nreal-valued predictions, an error tolerance ğ‘’).\nNext, we need to choose ğœ–â€²,ğ›¿â€². While there is only one hole, predictperson is executed multiple times\n(assuming length(â„“)>1). We need to choose ğœ–â€²andğ›¿â€²so that with high probability, predictperson\nis correct for allapplications. For simplicity, we assume given an upper bound ğ‘âˆˆNon the\nmaximum possible length of â„“(we discuss how we might remove this assumption in Section 6).\nGivenğ‘, we takeğœ–â€²=ğœ–/ğ‘andğ›¿â€²=ğ›¿/ğ‘; then, we use our sketching algorithm to synthesize ğ‘to\nfill the hole in predictperson . By a union bound, for a given list â„“, all applications of predictperson are\ncorrect with probability at least 1âˆ’ğœ–, and this property holds with probability at least 1âˆ’ğ›¿. Under\nthis event,ğ‘ƒexreturns correctlyâ€”i.e., ğ‘ƒexsatisfies the desired (ğœ–,ğ›¿)-PAC guarantee.\n3 SKETCH LANGUAGE\nIn this section, we describe the syntax and semantics of our sketch language, as well as the desired\ncorrectness properties we expect that synthesized programs should satisfy.\nSyntax. Our sketch language is shown in Figure 1. Intuitively, in the expression ğœ™(ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–,\nğ‘„is a specification that we want to ensure holds, ğ‘ƒis a score (intuitively, it should indicate the\nlikelihood that ğ‘„holds, but we make no assumptions about it), ğ‘is a threshold below which we\nconsiderğ‘„to be satisfied, ğœ–is the allowed failure probability, and ğœ”indicates whether we want\naconditional guarantee (i.e.,ğœ”=|, the guarantee (2)) or implication guarantee (i.e.,ğœ”=â‡’, the\nguarantee (1)). We assume that ğ‘ƒevaluates to a value in R,ğ‘âˆˆR, andğ‘„evaluates to a value in\n{0,1}. Note thatğ‘„is itself a program; unlike programs ğ‘ƒ, it can use ground truth inputs ğ‘¦. Finally,\neitherğ‘andğœ–in this expression can be left as a hole ??(but not both simultaneously).\nWe sayğ‘ƒiscomplete if it contains no holes and partial otherwise. We usePto denote the space\nof programs, Â¯PâŠ†P to denote the space of complete programs, and Â¯ğ‘ƒâˆˆÂ¯Pto denote a complete\nprogram. For ğ‘ƒâˆˆP, we use Î¦(ğ‘ƒ)to denote the expressions ğœ™(ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–inğ‘ƒ(including cases\n2In Section 5, our synthesis algorithm is presented for the case where it returns the correct answer or â€œunknownâ€ with high\nprobability, but as we discuss in Section 6, it can easily be modified to return an overestimate of the correct answer.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n6 Bastani\nğ‘ƒ::=ğ‘|ğ‘¥|ğ‘“(ğ‘ƒ,...,ğ‘ƒ)\n|ğœ™(ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–|ğœ™(ğ‘ƒ,??){ğ‘„}ğœ”\nğœ–|ğœ™(ğ‘ƒ,ğ‘){ğ‘„}ğœ”\n??\nğ‘„::=ğ‘|ğ‘¥|ğ‘¦|ğ‘“(ğ‘„,...,ğ‘„)Jğ‘Kâˆ—\nğ›¼=ğ‘\nJğ‘¥Kâˆ—\nğ›¼=ğ›¼(ğ‘¥)\nJğ‘¦Kâˆ—\nğ›¼=ğ›¼(ğ‘¦)Jğ‘“(ğ‘ƒ,...,ğ‘ƒ)Kâˆ—\nğ›¼=ğ‘“(Jğ‘ƒKâˆ—\nğ›¼,...,Jğ‘ƒKâˆ—\nğ›¼)\nJğ‘“(ğ‘„,...,ğ‘„)Kâˆ—\nğ›¼=ğ‘“(Jğ‘„Kâˆ—\nğ›¼,...,Jğ‘„Kâˆ—\nğ›¼)\nJğœ™(ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–Kâˆ—\nğ›¼=Jğ‘„Kâˆ—\nğ›¼\nJğ‘Kğ›½=ğ‘\nJğ‘¥Kğ›½=ğ›½(ğ‘¥)Jğ‘“(ğ‘ƒ,...,ğ‘ƒ)Kğ›½=ğ‘“(Jğ‘ƒKğ›½,...,Jğ‘ƒKğ›½)\nJğœ™(ğ‘ƒ,ğ‘£){ğ‘„}ğœ”\nğœ–Kğ›½= 1(Jğ‘ƒKğ›½>ğ‘)\nFig. 1. Syntax (left), train semantics (right, top), and test semantics (right, bottom). The production rules in\nthe syntax are implicitly universally quantified over constant values ğ‘âˆˆC, input variables ğ‘¥âˆˆX,ground truth\ninput variables ğ‘¦âˆˆY, components ğ‘“âˆˆF whereğ‘“:Cğ‘˜â†’C ,ğœ–âˆˆR>0, andğœ”âˆˆ{|,â‡’}. The distinguished\ncomponent ğœ™âˆˆF is a function ğœ™:R2â†’Rdefined byğœ™(ğ‘§,ğ‘¡)= 1(ğ‘§â‰¤ğ‘¡).\nwhereğ‘orğœ–is a hole), Î¦ğ‘\n??(ğ‘ƒ)âŠ†Î¦(ğ‘ƒ)to denote the expressions ğœ™(ğ‘ƒâ€²,??){ğ‘„}ğœ”\nğœ–inğ‘ƒ,Î¦ğœ–\n??(ğ‘ƒ)âŠ†Î¦(ğ‘ƒ)\nto denote the expressions ğœ™(ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\n??inğ‘ƒ, andÎ¦??(ğ‘ƒ)=Î¦ğ‘\n??(ğ‘ƒ)âˆªÎ¦ğœ–\n??(ğ‘ƒ).\nSemantics. We define two semantics for programs ğ‘ƒ, shown in Figure 1:\nâ€¢Train semantics: Given a training valuation ğ›¼âˆˆA, whereğ›¼:XâˆªYâ†’C maps both\ninputs and ground truth inputs ğ‘¦to values, the train semantics JÂ·Kâˆ—\nğ›¼evaluateğ‘„instead of\nğœ™(ğ‘ƒ,ğ‘). Since they ignore ğœ™, they can be applied to both partial and complete programs.\nâ€¢Test semantics: Given a test valuation ğ›½âˆˆB, whereğ›½:Xâ†’C maps inputs to values, the\ntest semantics JÂ·Kğ›½evaluateğœ™(ğ‘ƒ,ğ‘)instead ofğ‘„. They only apply to complete programs.\nCorrectness properties. We define what it means for a complete program to be correctâ€”i.e., satisfies\nits specifications. We begin with correctness of a single specification.\nDefinition 3.1. Given a distribution ğ‘(ğ›¼)over test valuations ğ›¼âˆˆA,ğœ™(Â¯ğ‘ƒ,ğ‘){ğ‘„}|\nğœ–isapproxi-\nmately sound if it satisfies the conditional guarantee3\nPğ‘(ğ›¼)\u0000Jğœ™(Â¯ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–Kğ›¼\f\fJğœ™(Â¯ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–Kâˆ—\nğ›¼\u0001â‰¥1âˆ’ğœ–,\nand{ğ‘„}â‡’\nğœ–isapproximately sound if it satisfies the implication guarantee\nPğ‘(ğ›¼)\u0000Jğœ™(Â¯ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–Kâˆ—\nğ›¼â‡’Jğœ™(Â¯ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–Kğ›¼\u0001â‰¥1âˆ’ğœ–.\nThis property can be thought of as probabilistic soundness; it says that we should have ğœ™(Â¯ğ‘ƒ,ğ‘)â‡’\nğ‘„with high probability, which means that ğœ™(Â¯ğ‘ƒ,ğ‘)is a sound overapproximation of ğ‘„.\nDefinition 3.2. A complete program Â¯ğ‘ƒisapproximately correct (denoted Â¯ğ‘ƒâˆˆÂ¯Pâˆ—) if every\nexpressionğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–inÂ¯ğ‘ƒis approximately sound.\n4 STATISTICAL SKETCHING\nNext, we describe our algorithm for synthesizing values ğ‘andğœ–to fill holes in a given sketch. Our\nalgorithm, shown in Figure 1, takes as input a sketch ğ‘ƒ, training valuations Â®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›), where\nğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘are i.i.d. samples, and a confidence level ğ›¿âˆˆR>0, and outputs a complete program\nğ´(Â¯ğ‘ƒ,Â®ğ›¼)âˆˆÂ¯Pâˆ—that is approximately correct with probability at least 1âˆ’ğ›¿with respect to ğ‘(Â®ğ›¼).\nOur algorithm synthesizes ğ‘andğœ–in a bottom-up fashion, so that all subtrees of the current\nexpression are complete. Our sketching algorithm uses probabilistic bounds in conjunction with the\ngiven samplesÂ®ğ›¼to provide guarantees. Intuitively, since we are estimating parameters from data,\nour problem is a statistical learning problem [ 69], so we can leverage techniques from statistical\nlearning theory to provide guarantees on the synthesized sketch.\n3Note that since ğ›¼includes valuations of ğ‘¥âˆˆX, we can use it in conjunction both train semantics and test semantics.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 7\nFor synthesizing ğ‘â€”i.e., an expression ğ¸=ğœ™(ğ‘ƒ,ğ‘){ğ‘„}ğœ”\nğœ–. Lettingğ‘§ğ›¼=Jğ‘ƒKğ›¼âˆˆRandğ‘§âˆ—\nğ›¼=Jğ¸K,\nthenğ‘isğœ–-approximately correct if ğ‘§ğ›¼â‰¤ğ‘conditioned on ğ‘§âˆ—\nğ›¼=1(ifğœ”=|) or whenever ğ‘§âˆ—\nğ›¼=1\n(ifğœ”=â‡’) with probability at least 1âˆ’ğœ–with respect to ğ‘(ğ›¼). In either case, synthesizing ğ‘is\nequivalent to a binary classification problem with labels ğ‘§âˆ—\nğ›¼, with a one-dimensional hypothesis\nspaceğ‘âˆˆRand a one-dimensional feature space ğ‘§ğ›¼âˆˆR. Furthermore, this problem is simpleâ€” ğ‘is\na linear classifier. Thus, we could use standard learning theory results to provide guarantees.\nHowever, we can obtain sharper guarantees using a learning theory bound specialized to our\nsetting. We build on a bound based on [ 28] (Section 4.1) tailored to the realizable setting, where\nthere exists a classifier that makes zero mistakes. Our setting is realizable, since ğ‘=âˆalways\nmakes zero mistakes. The main difference is that their bound always chooses a classifier that makes\nzero mistakes, which can be overly conservative. We prove a novel generalization bound that allows\nfor some number ğ‘˜of mistakes that is a function of ğœ–,ğ›¿, andğ‘›.\nSynthesizing a value ğœ–is a bit different, since we are not classifying examples that depend on a\nsingleğ›¼, but examples that depend on Â®ğ›¼. Thus, we can formulate it as a learning problem where\nthe examples areÂ®ğ›¼; however, this approach is complicated due to the need to figure out how to\ndivide our given samples Â®ğ›¼into multiple sub-examples Â®ğ›¼1,...Â®ğ›¼ğ‘›. Instead, we use an approach based\non Hoeffdingâ€™s inequality [ 30] (Section 4.2) to infer ğœ–. In particular, Hoeffdingâ€™s inequality gives us\na lower bound on the correctness rate Pğ‘(ğ›¼)(ğ‘§ğ›¼|ğ‘§âˆ—\nğ›¼)â‰¥1âˆ’ğœ–(ifğœ”=|) orPğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼)â‰¥1âˆ’ğœ–\n(ifğœ”=â‡’), and we can simply use this ğœ–.\nFinally, our sketching algorithm uses the above two approaches to synthesize ğ‘andğœ–(Section 4.3).\n4.1 A Learning Theory Bound\nProblem formulation. We consider a unary classification problem with one-dimensional feature\nand hypothesis spaces. In particular, given a probability distribution ğ‘(ğ‘§)overğ‘§âˆˆR(the feature),\nthe goal is to select the smallest possible threshold ğ‘¡âˆˆR(the hypothesis) such that\nPğ‘(ğ‘§)(ğ‘§â‰¤ğ‘¡)â‰¥1âˆ’ğœ– (3)\nfor a givenğœ–âˆˆR>0. That is, we want the smallest possible ğ‘¡such thatğ‘§âˆˆ(âˆ’âˆ,ğ‘¡]with probability\nat least 1âˆ’ğœ–according to ğ‘(ğ‘§). We denote the subset of ğ‘¡that satisfies (3) by\nTğœ–=\b\nğ‘¡âˆˆR|Pğ‘(ğ‘§)(ğ‘§â‰¤ğ‘¡)â‰¥1âˆ’ğœ–\t\n.\nTo compute such a ğ‘¡, we are given a training set of examples Â®ğ‘§=(ğ‘§1,...,ğ‘§ğ‘›)âˆˆRğ‘›, whereğ‘§1,...,ğ‘§ğ‘›âˆ¼ğ‘\nareğ‘›i.i.d. samples from ğ‘. An estimator Ë†ğ‘¡is a mapping Ë†ğ‘¡:Rğ‘›â†’R. Then, the constraint (3) is\nË†ğ‘¡(Â®ğ‘§)âˆˆTğœ–; we say such a Ë†ğ‘¡isğœ–-approximately correct â€”i.e., it is correct for â€œmostâ€ samples ğ‘§âˆ¼ğ‘.\nIn general, we are unable to guarantee that Ë†ğ‘¡is approximately correct due to the randomness in\nthe training examples Â®ğ‘§. Thus, we additionally allow for a small probability ğ›¿âˆˆR>0that Ë†ğ‘¡is not\napproximately correct.\nDefinition 4.1. Givenğœ–,ğ›¿âˆˆR>0,Ë†ğ‘¡is(ğœ–,ğ›¿)-PAC ifPğ‘(Â®ğ‘§)(Ë†ğ‘¡(Â®ğ‘§)âˆˆTğœ–)â‰¥1âˆ’ğ›¿.\nThat is, Ë†ğ‘¡(Â®ğ‘§)is approximately correct with probability at least 1âˆ’ğ›¿according to ğ‘(Â®ğ‘§). Our goal\nis to construct an(ğœ–,ğ›¿)-PAC estimator Ë†ğ‘¡(Â®ğ‘§)that tries to minimize Ë†ğ‘¡(Â®ğ‘§).\nEstimator. Givenğœ–,ğ›¿âˆˆR>0, consider the estimator\nË†ğ‘¡(Â®ğ‘§)=inf\nğ‘¡âˆˆR\b\nğ‘¡âˆˆR\f\fğ¿(ğ‘¡;Â®ğ‘§)â‰¤ğ‘˜\t\n+ğ›¾(Â®ğ‘§)whereğ‘˜=max(\nâ„âˆˆN\f\f\f\f\fâ„âˆ‘ï¸\nğ‘–=0\u0012ğ‘›\nğ‘–\u0013\nğœ–ğ‘–(1âˆ’ğœ–)ğ‘›âˆ’ğ‘–â‰¤ğ›¿)\n(4)\nwhere the empirical loss isğ¿(ğ‘¡;Â®ğ‘§)=Ã\nğ‘§âˆˆÂ®ğ‘§ 1(ğ‘§>ğ‘¡), and where ğ›¾(Â®ğ‘§)>0is an arbitrary positive\nfunction. Intuitively, the empirical loss counts the number of mistakes that ğ‘¡makes on the training\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n8 Bastani\nAlgorithm 1 Use learning theory to sketch Â¯ğ‘ƒthat is approximately correct.\nprocedure Sketch (ğ‘ƒ,Â®ğ›¼,ğ›¿)\nğ‘šâ†|Î¦??(ğ‘ƒ)|\nforğ¸âˆˆBottomUp(Î¦??(ğ‘ƒ))do\nifğ¸=ğœ™(Â¯ğ‘ƒâ€²,??){ğ‘„}ğœ”\nğœ–then\nComputeÂ®ğ‘§Â®ğ›¼according to (6)\nCompute Ë†ğ‘¡(Â®ğ‘§Â®ğ›¼)according to (4) with (ğœ–,ğ›¿/ğ‘š)\nFill the hole ??with Ë†ğ‘¡(Â®ğ‘§ğ›¼)\nelse ifğ¸=ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\n??then\nComputeÂ®ğ‘§Â®ğ›¼according to (6)\nCompute Ë†ğœˆ(Â®ğ‘§Â®ğ›¼)according to (5) with ğ›¿/ğ‘š\nFill the hole ??with 1âˆ’Ë†ğœˆ(Â®ğ‘§Â®ğ›¼)\nend if\nend for\nreturn true\nend procedure\ndataâ€”i.e.,ğ‘§âˆˆÂ®ğ‘§such thatğ‘§âˆ‰(âˆ’âˆ,ğ‘¡]. To compute the solution ğ‘˜in (4), we start with â„=0and\nincrement it until it no longer satisfies the condition. To ensure numerical stability, this computation\nis performed using logarithms. Note that ğ‘˜does not exist if the set inside the maximum in (4) is\nempty; in this case, we choose Ë†ğœ“(Â®ğ‘§)=0, which trivially satisfies the PAC property. To compute\nË†ğ‘¡(Â®ğ‘§), we sort the training examples ğ‘§1,...,ğ‘§ğ‘›by magnitude, so ğ‘§1â‰¥ğ‘§2â‰¥...â‰¥ğ‘§ğ‘›. Finally,ğ‘§ğ‘˜+1solves\nthe minimization problem in (4), so Ë†ğ‘¡(Â®ğ‘§)=ğ‘§ğ‘˜+1+ğ›¾(Â®ğ‘§). Ifğ‘˜does not exist, then we choose Ë†ğ‘¡(Â®ğ‘§)=âˆ,\nwhich trivially satisfies the PAC property. We have the following; see Appendix B.2 for a proof:\nTheorem 4.2. The estimator Ë†ğ‘¡(Â®ğ‘§)in (4) is(ğœ–,ğ›¿)-PAC.\n4.2 A Concentration Bound\nProblem formulation. Consider a Bernoulli distribution ğ‘=Bernoulli(ğœ‡)with unknown mean\nğœ‡âˆˆ[0,1]. Our goal is to compute a lower bound ğœˆâˆˆ[0,1]ofğœ‡â€”i.e.,ğœ‡â‰¥ğœˆ. For example, if ğœ‡is\nthe error rate of a classifier, then ğœˆis a lower bound on this rate. To compute ğœˆ, we are given a\ntraining setÂ®ğ‘§=(ğ‘§1,...,ğ‘§ğ‘›)âˆˆ{ 0,1}ğ‘›, whereğ‘§1,...,ğ‘§ğ‘›âˆ¼ğ‘areğ‘›i.i.d. samples from ğ‘. An estimator is\na mapping Ë†ğœˆ:Rğ‘›â†’R. We say Ë†ğœˆiscorrect if it satisfies ğœ‡â‰¥Ë†ğœˆ(Â®ğ‘§). We are unable to guarantee that\nË†ğœˆ(Â®ğ‘§)is correct due to the randomness in the training examples Â®ğ‘§. Thus, we additionally allow for a\nsmall probability ğ›¿âˆˆR>0that Ë†ğœ“(Â®ğ‘§)is not correctâ€”i.e., it is probably correct (PC) .\nDefinition 4.3. Givenğ›¿âˆˆR>0,Ë†ğœˆisğ›¿-PCifPğ‘(Â®ğ‘§)\u0000ğœ‡â‰¥Ë†ğœˆ(Â®ğ‘§)\u0001â‰¥1âˆ’ğ›¿.\nIn other words, Ë†ğœˆ(Â®ğ‘§)is correct with probability at least 1âˆ’ğ›¿according to the randomness in\nğ‘(Â®ğ‘§). Our goal is to construct an ğ›¿-PC estimator Ë†ğœˆ(Â®ğ‘§).\nEstimator. Givenğ›¿âˆˆR>0, consider the estimator\nË†ğœˆ(Â®ğ‘§)=Ë†ğœ‡(Â®ğ‘§)âˆ’âˆšï¸‚\nlog(1/ğ›¿)\n2ğ‘›, (5)\nwhere Ë†ğœ‡(Â®ğ‘§)=ğ‘›âˆ’1Ã\nğ‘§âˆˆÂ®ğ‘§ğ‘§is an estimate of ğœ‡based on the samples Â®ğ‘§; we take Ë†ğœˆ(Â®ğ‘§)=0if (5) is\nnegative. Intuitively, the second term in Ë†ğœˆ(Â®ğ‘§)is a correction to Ë†ğœ‡(Â®ğ‘§)to ensure it is(ğœ–,ğ›¿)-PC, based\non Hoeffdingâ€™s inequality [30]. We have the following; see Appendix B.3 for a proof:\nTheorem 4.4. The estimator Ë†ğœˆisğ›¿-PC.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 9\n4.3 Sketching Algorithm\nProblem formulation. A sketching algorithm ğ´:PÃ—Ağ‘›â†’Â¯Ptakes as input a partial program\nğ‘ƒâˆˆP, together with a set of test valuations Â®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›)âˆˆAğ‘›, whereğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘are i.i.d.\nsamples from an underlying distribution ğ‘(ğ›¼). Then, Â¯ğ‘ƒ=ğ´(ğ‘ƒ,Â®ğ›¼)should be a complete program\nthat is approximately correct by filling each hole in expressions ğœ™(ğ‘ƒâ€²,??){ğ‘„}ğœ”\nğœ–âˆˆÎ¦ğ‘\n??(ğ‘ƒ)with a\nvalueğ‘âˆˆRand each hole in expressions ğœ™(ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\n??âˆˆğœ™ğœ–\n??(ğ‘ƒ)with a value ğœ–âˆˆR>0. We assume\nthat every expression in Î¦(ğ‘ƒ)has a holeâ€”i.e., Î¦(ğ‘ƒ)=Î¦??(ğ‘ƒ); otherwise, we cannot guarantee that\nthe existing thresholds in these expressions are approximately sound.\nDefinition 4.5. A partial program ğ‘ƒâˆˆP is afull sketch , denotedğ‘ƒâˆˆP0, ifÎ¦??(ğ‘ƒ)=Î¦(ğ‘ƒ).\nThen, we say ğ´iscorrect ifğ´(ğ‘ƒ,Â®ğ›¼)âˆˆ Â¯Pâˆ—. We cannot guarantee this property; instead, given\nğ›¿âˆˆR>0, we want it to hold with probability at least 1âˆ’ğ›¿according to ğ‘(Â®ğ›¼).\nDefinition 4.6. A sketching algorithm ğ´:P0Ã—Ağ‘›â†’Â¯Pisğ›¿-probably approximately correct\n(PAC) if for allğ‘ƒâˆˆP0, we have Pğ‘(Â®ğ›¼)\u0000ğ´(ğ‘ƒ,Â®ğ›¼)âˆˆÂ¯Pâˆ—\u0001â‰¥1âˆ’ğ›¿.\nNote that this definition does not include ğœ–since these values are provide in the given sketch.\nAlgorithm. Our sketching algorithm is shown in Algorithm 1. At a high level, it fills each hole so\nthat the resulting expressions ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–are all approximately sound. The order in which these\nexpressions are processed is important; a expression cannot be processed until all its descendants\nhave been processed. This order ensures that Â¯ğ‘ƒâ€²is complete, so it can be evaluated. In Algorithm 1,\nthe function BottomUp ensures that the expressions in Î¦??(ğ‘ƒ)is processed in such an order. The\nalgorithm allocates a ğ›¿/ğ‘šprobability of failure for each expression, where ğ‘š=|Î¦??(ğ‘ƒ)|.\nSynthesizing ğ‘.We describe how our algorithm synthesizes a threshold ğ‘for an expression\nğ¸=ğœ™(Â¯ğ‘ƒâ€²,??){ğ‘„}ğœ”\nğœ–. Given a single test valuation ğ›¼âˆ¼ğ‘, consider the values\nğ‘§ğ›¼=JÂ¯ğ‘ƒâ€²Kğ›¼ andğ‘§âˆ—\nğ›¼=Jğœ™(Â¯ğ‘ƒâ€²,??){ğ‘„}ğœ”\nğœ–Kâˆ—\nğ›¼\nGivenğ‘âˆˆR, it follows by definition of JÂ·Kğ›¼that\nJğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–Kğ›¼= 1(ğ‘§ğ›¼â‰¤ğ‘).\nThus,ğ¸is approximately sound for some ğ‘âˆˆRif and only if\nPğ‘(ğ›¼)(ğ‘§ğ›¼â‰¤ğ‘|ğ‘§âˆ—\nğ›¼)â‰¥1âˆ’ğœ–ifğœ”=| or Pğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼â‰¤ğ‘)â‰¥1âˆ’ğœ–ifğœ”=â‡’.\nGivenÂ®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›), whereğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘i.i.d.,\nÂ®ğ‘§Â®ğ›¼=(\n{ğ‘§ğ›¼|ğ›¼âˆˆÂ®ğ›¼âˆ§ğ‘§âˆ—\nğ›¼} ifğœ”=|\n{ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼|ğ›¼âˆˆÂ®ğ›¼}ifğœ”=â‡’(6)\nis a vector of i.i.d. samples. The estimator Ë†ğ‘¡(Â®ğ‘§Â®ğ›¼)in (4) with parameters (ğœ–,ğ›¿/ğ‘š)ensures approximate\nsoundness with high probabilityâ€”i.e.,\nPğ‘(ğ›¼)\u0000ğ‘§ğ›¼â‰¤Ë†ğ‘¡(Â®ğ‘§Â®ğ›¼)|ğ‘§âˆ—\nğ›¼\u0001â‰¥1âˆ’ğœ–ifğœ”=|orPğ‘(ğ›¼)\u0000ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼â‰¤Ë†ğ‘¡(Â®ğ‘§Â®ğ›¼)\u0001â‰¥1âˆ’ğœ–ifğœ”=â‡’.\nholds with probability at least 1âˆ’ğ›¿/ğ‘šaccording to ğ‘(Â®ğ›¼).\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n10 Bastani\nSynthesizing ğœ–.We describe how our algorithm synthesizes a confidence level ğœ–for an expression\nğ¸=ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\n??. Given a single test valuation ğ›¼âˆ¼ğ‘, consider the values\nğ‘§ğ›¼=Jğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\n??Kğ›¼ andğ‘§âˆ—\nğ›¼=Jğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\n??Kâˆ—\nğ›¼.\nNote that we compute these values even though the ğœ–is a hole, since JÂ·Kğ›¼and JÂ·Kâˆ—\nğ›¼do not depend on\nğœ–. Also, note that unlike the case of synthesizing ğ‘, whereğ‘§ğ›¼âˆˆRis a score, in this case, ğ‘§ğ›¼âˆˆ{0,1}\nis a binary value. Given ğœ–âˆˆR>0,ğ¸isğœ–-approximately sound for ğœ–if and only if\nPğ‘(ğ›¼)(ğ‘§ğ›¼|ğ‘§âˆ—\nğ›¼)â‰¥1âˆ’ğœ–ifğœ”=| or Pğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼)â‰¥1âˆ’ğœ–ifğœ”=â‡’.\nGivenÂ®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›), whereğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘are i.i.d. samples,Â®ğ‘§Â®ğ›¼defined in (6) is a vector of i.i.d.\nsamples from Bernoulli(ğœ‡). Then, the estimator Ë†ğœˆ(Â®ğ‘§Â®ğ›¼)in (5) with parameter ğ›¿/ğ‘šis a lower bound\nonğœ‡with high probabilityâ€”i.e.,\nPğ‘(ğ›¼)(ğ‘§ğ›¼|ğ‘§âˆ—\nğ›¼)â‰¥Ë†ğœˆ(Â®ğ‘§Â®ğ›¼)ifğœ”=| or Pğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼)â‰¥Ë†ğœˆ(Â®ğ‘§Â®ğ›¼)ifğœ”=â‡’.\nholds with probability at least 1âˆ’ğ›¿/ğ‘šaccording to ğ‘(Â®ğ›¼). Thus, it suffices to choose 1âˆ’ğœ–=Ë†ğœˆ(Â®ğ‘§Â®ğ›¼).\nThe following guarantee follows from Theorems 4.2 & 4.4 by a union bound over Î¦(Â¯ğ‘ƒ):\nTheorem 4.7. Algorithm 1 is ğ›¿-PAC.\n5 SYNTHESIS ALGORITHM\nWe now describe a syntax-guided synthesizer that uses our sketching algorithm to identify programs\nwith machine learning components while satisfying a desired error guarantee. In general, to design\nsuch a synthesizer, we need to design a space of specifications along with a domain-specific language\n(DSL) of programs. For clarity, we focus on a specific set of design choices; as we discuss in Section 6,\nour approach straightforwardly generalizes in several ways. We consider the following choices:\nâ€¢Specifications: We consider specifications Ëœğœ“=(ğœ“,ğœ–,ğ‘’), consisting of both a traditional\npartğœ“indicating the logical property that the train semantics of the program should satisfy\n(provided either as a logical formula or input-output examples), and a statistical part (ğœ–,ğ‘’)\nindicating that the program should have error at most ğ‘’with probability at least 1âˆ’ğœ–with\nrespect toğ‘(ğ›¼), or else returnâˆ….\nâ€¢DSL: We consider a DSL (shown in Figure 2) of list processing programs where the inputs are\nimages of integers. Our DSL includes components designed to predict the integer represented\nby a given image. These components return the predicted value if its confidence is above a\ncertain threshold, and return âˆ…otherwise. Valuesâˆ…are propagated asâˆ…by all components\nin our DSLâ€”i.e., if any input to a function is âˆ…, then its output is also âˆ….\nFor clarity, we refer to specifications Ëœğœ“astask specifications and specifications on DSL components\nascomponent specifications . As a running example, consider the program in Figure 3. This program\npredicts the value ğ‘¥of the image input1(as an integer) and values â„“of the images in the list input2\n(as real values), and then sums the values in â„“that are greater than equal to ğ‘¥. It contains three\ncomponents that have component specifications: the two machine learning components predictint\nandpredictfloat, along with the inequality cond-â‰¤. The first two component specifications ensure\nthat the corresponding machine learning model returns correctly (or âˆ…) with high probability. For\nthe last one, note that in the expression ğ‘¦1â‰¤ğ‘¦2, the inputsğ‘¦1andğ‘¦2may have a small amount of\nprediction error, so if they are to close together (i.e., |ğ‘¦1âˆ’ğ‘¦2|â‰¤ğ‘for someğ‘âˆˆRâ‰¤0), thenğ‘¦1â‰¤ğ‘¦2\nmight be incorrect. Thus, to ensure â‰¤returns correctly, cond-â‰¤returnsâˆ…if|ğ‘¦1âˆ’ğ‘¦2|â‰¤ğ‘.\nFinally, note that we use ğœ”=â‡’, indicating that our goal is to synthesize Â¯ğ‘ƒsuch that the the\noverall success rate is boundedâ€”i.e., Pğ‘(ğ›¼)\u0000JÂ¯ğ‘ƒKğ›¼=âˆ…âˆ¨| JÂ¯ğ‘ƒKğ›¼âˆ’JÂ¯ğ‘ƒKâˆ—\nğ›¼|>ğ‘’\u0001â‰¥1âˆ’ğœ–. We could use\nğœ”=|here if we instead wanted to bound the probability of failure conditioned on JÂ¯ğ‘ƒKğ›¼â‰ âˆ….\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 11\nğ‘ƒğœ::=input1\nğœ|Â·Â·Â·| inputğ‘˜ğœğœ\n|(ğ‘ƒğœâ€²â†’ğœğ‘ƒğœâ€²)\n|(foldğ‘ƒğœâ€²â†’ğœâ†’ğœğ‘ƒlist(ğœâ€²)ğ‘ƒğœ)\nğ‘ƒlist(ğœ)::=(mapğ‘ƒğœâ€²â†’ğœğ‘ƒlist(ğœâ€²))\n|(filterğ‘ƒğœâ†’boolğ‘ƒlist(ğœ))\n|(sliceğ‘ƒlist(ğœ)ğ‘ƒintğ‘ƒint)\nğ‘ƒint::=(lengthğ‘ƒlist(ğœ))ğ‘ƒğœâ†’ğœâ†’ğœ::=+|âˆ’\nğ‘ƒintâ†’intâ†’bool::=â‰¤|=|â‰¥\nğ‘ƒfloatâ†’floatâ†’bool::=cond-â‰¤|cond-â‰¥\nğ‘ƒimageâ†’ğœ::=predictğœ\nğ‘ƒimageâ†’image ::=cond-flip\n(predictintğ‘¥)=(ifË†ğ‘(ğ‘¥,Ë†ğ‘“(ğ‘¥))â‰¥ ??ğ‘{Ë†ğ‘“(ğ‘¥)=ğ‘¦âˆ—}â‡’\n??ğœ–then Ë†ğ‘“(ğ‘¥)elseâˆ…)\n(predictfloatğ‘¥)=(ifË†ğ‘(ğ‘¥,Ë†ğ‘“(ğ‘¥))â‰¥ ??ğ‘{|Ë†ğ‘“(ğ‘¥)âˆ’ğ‘¦âˆ—|â‰¤??ğ‘’}â‡’\n??ğœ–then Ë†ğ‘“(ğ‘¥)elseâˆ…)\n(cond-flipğ‘¥)=(ifË†ğ‘flip(ğ‘¥,Ë†ğ‘“flip(ğ‘¥))â‰¥ ??ğ‘{Ë†ğ‘“flip(ğ‘¥)=ğ‘¦âˆ—\nflip}â‡’\n??ğœ–then(cond-flip0ğ‘¥)elseâˆ…)\n(cond-flip0ğ‘¥)=(ifË†ğ‘“flip(ğ‘¥)then flip(ğ‘¥)elseğ‘¥)\n(cond-â‰¤ğ‘¦1ğ‘¦2)=(if|ğ‘¦1âˆ’ğ‘¦2|â‰¥??ğ‘{ğ‘¦âˆ—\n1â‰¤ğ‘¦âˆ—\n2}â‡’\n??ğœ–thenğ‘¦1â‰¥ğ‘¦2elseâˆ…)\n(cond-â‰¥ğ‘¦1ğ‘¦2)=(if|ğ‘¦1âˆ’ğ‘¦2|â‰¥??ğ‘{ğ‘¦âˆ—\n1â‰¥ğ‘¦âˆ—\n2}â‡’\n??ğœ–thenğ‘¦1â‰¥ğ‘¦2elseâˆ…)\nFig. 2. This figure shows our domain-specific language (DSL) of list processing programs over images of\ninputs. The top half shows the production rules; these rules are implicitly universally quantified over the type\nvariablesğœandğœ, whereğœ::=bool|int|float|image|list(ğœ)|ğœâ†’ğœandğœ::=int|float|image . The\nbottom half shows the semantics of functions in our language that have statistical specifications.\nAlgorithm 2 Use learning theory to synthesize Â¯ğ‘ƒthat is approximately correct.\nprocedure Synthesize (Â®ğ›¼,ğœ“,ğœ–,ğ‘’,ğ‘,ğ›¿ )\nËœğ‘ƒâ†SynthesizePartialSketch (ğœ“)\nÂ®ğ›¼synth,Â®ğ›¼sketchâ†Split(Â®ğ›¼)\nğ‘ƒâ†arg maxğ‘ƒâ€²âˆˆFillAll(Ëœğ‘ƒ,ğœ–,ğ‘’)Score(Sketch(ğ‘ƒâ€²,Â®ğ›¼synth,ğ›¿))\nreturn Sketch(ğ‘ƒ,Â®ğ›¼sketch,ğ›¿)\nend procedure\nGiven labeled training examples Â®ğ›¼, a task specification Ëœğœ“, a maximum list length ğ‘, and a\nconfidence level ğ›¿, our algorithm shown in Algorithm 2 synthesizes a complete program Â¯ğ‘ƒthat\nsatisfies Ëœğœ“with probability at least 1âˆ’ğ›¿. At a high level, this algorithm proceeds in three steps:\nâ€¢Step 1: First, our algorithm uses the logical specification ğœ“to identify a sketch Ëœğ‘ƒwhose\ntrain semantics is consistent with ğœ“. Note that the train semantics for sketches in our DSL in\nFigure 2 are well-defined even when the holes left unfilled. We refer to Ëœğ‘ƒas apartial sketch ,\nsince it has additional holes that cannot be filled by our sketching algorithm.\nâ€¢Step 2: While our algorithm uses our sketching algorithm described in Algorithm 1 to fill\nholes ??ğ‘inËœğ‘ƒ, it must first fill the holes ??ğœ–and??ğ‘’(described below), which cannot be\nhandled by this algorithm. To this end, it analyzes the program to identify constraints on\nthe values of ğœ–andğ‘’that can be assigned to each hole ??ğœ–and??ğ‘’, respectively and satisfy\nthe desired task specification (ğœ–,ğ‘’). Given candidate values Â®ğ‘’andÂ®ğœ–, it constructs the sketch\nğ‘ƒ=Fill(Ëœğ‘ƒ,Â®ğœ–,Â®ğ‘’), and evaluates the success rate Score(ğ‘ƒ)(i.e., how often Jğ‘ƒKğ›¼â‰ âˆ…). It chooses\nthe sketchğ‘ƒthat maximizes this objective over a finite set of choices of Â®ğœ–andÂ®ğ‘’.\nâ€¢Step 3: Finally, it uses a held-out set of labeled examples Â®ğ›¼sketch in conjunction with our\nsketching algorithm in Algorithm 1 to synthesize We use a held-out set since Theorem 4.7\nonly holds if the examples Â®ğ›¼sketch are not used to construct the sketch ğ‘ƒ.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n12 Bastani\nTask Specification Ëœğœ“ex=\u0000ğœ“={[1,2,3]â†¦â†’ 3,[2,4,2]â†¦â†’ 4}, ğœ–=0.05, ğ‘’=6, ğ‘=3, ğ›¿=0.05\u0001\nPartial Sketch Ëœğ‘ƒex=(fold+ (filter(cond-â‰¤|  {z  }\nğ‘“1(predictint|    {z    }\nğ‘“2input1))(map predictfloat|       {z       }\nğ‘“3input2)0))\nComponents\nwith Holesğ‘“1=(ğœ†ğ‘¦1(ğœ†ğ‘¦2(if|ğ‘¦1âˆ’ğ‘¦2|â‰¥??ğ‘{ğ‘¦âˆ—\n1â‰¤ğ‘¦âˆ—\n2}â‡’\n??ğœ–thenğ‘¦1â‰¤ğ‘¦2elseâˆ…)))\nğ‘“2=(ğœ†ğ‘¥(ifË†ğ‘(ğ‘¥,Ë†ğ‘“(ğ‘¥))â‰¥ ??ğ‘{Ë†ğ‘“(ğ‘¥)=ğ‘¦âˆ—}â‡’\n??ğœ–then Ë†ğ‘“(ğ‘¥)elseâˆ…))\nğ‘“3=(ğœ†ğ‘¥(ifË†ğ‘(ğ‘¥,Ë†ğ‘“(ğ‘¥))â‰¥ ??ğ‘{|Ë†ğ‘“(ğ‘¥)âˆ’ğ‘¦âˆ—|â‰¤??ğ‘’}â‡’\n??ğœ–then Ë†ğ‘“(ğ‘¥)elseâˆ…))\nFig. 3. Example of a task in our list processing domain. Given Ëœğœ“ex, the goal is to synthesize a program Â¯ğ‘ƒwhose\ntrain semantics satisfies ğœ“, and whose test semantics satisfy Pğ‘(ğ›¼)\u0000JÂ¯ğ‘ƒKğ›¼=âˆ…âˆ¨| JÂ¯ğ‘ƒKğ›¼âˆ’JÂ¯ğ‘ƒKâˆ—ğ›¼|â‰¤ğ‘’\u0001â‰¥1âˆ’ğœ–.\nIn Figure 3, we show the partial sketch Ëœğ‘ƒexalong with two analyses which are used to help compute\nthe search space over Â®ğœ–andÂ®ğ‘’. Below, we describe our DSL and synthesis algorithm in more detail.\n5.1 Domain-Specific Language\nOur DSL is summarized in Figure 2. To be precise, this figure shows sketches in our language; filling\nholes in these sketches produces a program in our language. At a high level, the language consists\nof standard list processing operators such as map, filter, and fold, along with a set of functions that\ncan be applied to individual integers, real numbers, or images.\nMachine learning components. Our DSL has three machine learning components: predictint,\npredictfloat, and cond-flip . The first two predict the value in a given image. They are identical except\nfor their component specification; whereas the integer predictions must be exactly correct, the\nreal-valued predictions are allowed to have bounded error. We describe these specifications below.\nThis difference gives the user flexibility in terms of what kind of guarantees they want to provide.\nThe third machine learning component checks if the input image is flipped along the vertical\naxis. We include it to demonstrate how our approach can combine multiple machine learning\ncomponents. It only returns an image if it is confident about its prediction; otherwise, it returns âˆ….\nComponent specifications. Intuitively, there are two kinds of component specifications in our\nlanguage: (i) require that the output is exactly correct, and (ii) require that the error of the output\nis bounded. There are four components in (i): predictint,cond-flip ,cond-â‰¤, and cond-â‰¥. The first\ntwo are straightforwardâ€”they consist of a machine learning component, and return the predicted\nvalue if the prediction confidence is a threshold to be synthesized, and return âˆ…otherwise.\nThe latter two are result from challenges handling inequalities on real-valued predictions. In\nparticular, real-valued predictions (i.e., by predictfloat) can be wrong by a bounded amount, yet the\nreturn value ofâ‰¤andâ‰¥is a Boolean value that must be exactly correct. Thus, these components\ninclude a component specification indicating that their output must be correct with high probability.\nNote that the scoring function used in the condition is |ğ‘¦1âˆ’ğ‘¦2|; intuitively, if the inputs ğ‘¦1andğ‘¦2\nare far apart (i.e.,|ğ‘¦1âˆ’ğ‘¦2|is large), then the predicted result is less likely to be an error.\nThepredictfloatcomponent is the only one in (ii). The only difference from predictintis that it only\nrequires that the prediction is correct to within some bounded amount of errorâ€”i.e., |Ë†ğ‘“(ğ‘¥)âˆ’ğ‘¦âˆ—|â‰¤ğ‘’,\nfor someğ‘’âˆˆRâ‰¥0. Note thatğ‘’is left as a hole to be filled.\nHoles. Our language has three kinds of holes. The first two are holes ??ğ‘and??ğœ–; these are in our\nsketch DSL in Figure 2. Note that in that DSL, each component specification could only have either\nğ‘orğœ–as a hole, but here we allow both to be left as holes; our algorithm searches over choices\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 13\nofğœ–to fill holes ??ğœ–, and uses our sketching algorithm in Algorithm 1 to fill holes ??ğ‘. The third\nkind of hole is the hole ??ğ‘’in the component specification |Ë†ğ‘“(ğ‘¥)âˆ’ğ‘¦âˆ—|â‰¤??ğ‘’forpredictfloat, which\nindicates the magnitude of error allowed by the prediction of that component. As with ??ğœ–holes,\nthe??ğ‘’holes are filled by our algorithm before our sketching algorithm is applied. Intuitively, ??ğœ–\n(resp., ??ğ‘’) holes must be filled in a way that satisfies the overall ğœ–failure probability guarantee\n(resp.,ğ‘’error guarantee) in the user-provided task specification Ëœğœ“.\n5.2 Synthesis Algorithm\nOur algorithm (Algorithm 2) takes as input labeled training examples Â®ğ›¼, a task specification\nËœğœ“=(ğœ“,ğœ–,ğ‘’), andğ›¿âˆˆR>0, and returns a program Â¯ğ‘ƒthat satisfies Ëœğœ“with probabilityâ‰¥1âˆ’ğ›¿.\nStep 1: Syntax-guided synthesis. Our algorithm first synthesizes a partial sketch Ëœğ‘ƒin our DSL\nwhose train semantics satisfies ğœ“â€”i.e., UNSATğ›¼,ğ‘¦\u0000ğ‘¦=JËœğ‘ƒKâˆ—\nğ›¼âˆ§Â¬ğœ“(ğ›¼,ğ‘¦)\u0001. Importantly, note that JËœğ‘ƒKâˆ—\nğ›¼\nis well-defined even though there are holes in Ëœğ‘ƒ. We can compute Ëœğ‘ƒusing any standard synthesizer.\nStep 2: Sketching ğœ–andğ‘’.Next, our algorithm fills the holes ??ğœ–inËœğ‘ƒwith valuesÂ®ğœ–and holes ??ğ‘’\nwith valuesÂ®ğ‘’to obtain a sketch ğ‘ƒ=Fill(Ëœğ‘ƒ,Â®ğœ–,Â®ğ‘’). Sinceğ‘ƒonly has holes ??ğœ–, we can use Algorithm 1\nto fill these holes in a way that guarantees correctness for the given values Â®ğœ–andÂ®ğ‘’â€”i.e.,\nPğ‘(ğ›¼)\u0000|JÂ¯ğ‘ƒKğ›¼âˆ’Jğ‘ƒKâˆ—\nğ›¼|â‰¤ğ‘’\u0001â‰¥1âˆ’ğœ–, (7)\nwhere Â¯ğ‘ƒis a completion of ğ‘ƒwhere the holes ??ğ‘inğ‘ƒhave been filled with values Â®ğ‘. We need to\nuseÂ¯ğ‘ƒsince the test semantics are not well-defined for sketches ğ‘ƒ. In particular, we need to choose\nvaluesÂ®ğœ–andÂ®ğ‘’that ensure that (7) holds for allpossible completions Â¯ğ‘ƒofğ‘ƒ.\nFurthermore, we not only want to choose Â®ğœ–andÂ®ğ‘’to ensure correctness, but also to maximize\na quantitative property of Â¯ğ‘ƒ. In particular, we want to choose it in a way that maximizes the\nprobability that ğ‘ƒdoes not returnâˆ…â€”i.e., maximize the score\nScore(ğ‘ƒ)=Pğ‘(ğ›¼)\u0000JÂ¯ğ‘ƒKğ›¼â‰ âˆ…\u0001\nNote that the score depends critically on the choice of thresholds Â®ğ‘used to fill holes ??ğ‘inğ‘ƒ. Thus,\ngiven a set of candidate choices Â®ğœ–andÂ®ğ‘’, our algorithm constructs the corresponding sketch ğ‘ƒâ€²=\nFill(Ëœğ‘ƒ,Â®ğœ–,Â®ğ‘’), uses our sketching algorithm to fill the holes ??ğ‘inğ‘ƒâ€²to obtain Â¯ğ‘ƒâ€²=Sketch(ğ‘ƒâ€²,Â®ğ›¼,ğ›¿),\nand finally scores Â¯ğ‘ƒâ€². Then, our algorithm chooses ğ‘ƒâ€²with the highest score. In Algorithm 2, we let\nFillAll(Ëœğ‘ƒ,ğœ–,ğ‘’)denote the set of all sketches ğ‘ƒâ€²constructed from candidates Â®ğœ–andÂ®ğ‘’.\nOne important detail is that Algorithm 1 requires that ğ‘ƒis a straight-line programâ€”i.e., it cannot\nhandle loops. For now, we assume that we are given a bound ğ‘âˆˆNon the maximum length of\nany input list. Then, we can unroll list operations such as map, filter, and fold into straight-line\ncode. Algorithm 2 uses this strategy to apply Algorithm 1 to sketches ğ‘ƒ. We describe how we can\nremove the assumption that we have an upper bound ğ‘in Section 6.\nStep 3: Sketching ğ‘.Finally, we use Algorithm 1 to choose values Â®ğ‘to fill holes ??ğ‘in the highest\nscoring sketch ğ‘ƒfrom the previous step, and return the result Â¯ğ‘ƒ=Sketch(ğ‘ƒ,Â®ğ›¼sketch,ğ›¿). Importantly,\nin the previous step, ğ‘ƒis chosen based on a subset Â®ğ›¼synth of the training examples Â®ğ›¼, whereas in\nthis step, Â¯ğ‘ƒis constructed based on a disjoint subset Â®ğ›¼sketch . We choose these two subsets to be of\nequal size since Algorithm 1 is sensitive to the number of examples in Â®ğ›¼. This strategy ensures that\nğ‘ƒdoes not depend on the random variable Â®ğ›¼sketch , thereby ensuring that Theorem 4.7 holds.\n5.3 Search Space Over Â®ğœ–andÂ®ğ‘’\nHere, we describe how we choose candidates Â®ğœ–andÂ®ğ‘’in Step 2 so that the candidate sketches\nğ‘ƒâ€²=Fill(Ëœğ‘ƒ,Â®ğœ–,Â®ğ‘’)satisfy (7). At a high level, for Â®ğœ–, for each component ğ‘“ofËœğ‘ƒwith an ??ğœ–hole,\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n14 Bastani\nJ(ğ¹ ğ¿)K#\nğ‘“=Jğ¹K#\nğ‘“+Jğ¿K#\nğ‘“\nJ(foldğ¹ ğ¿ğµ)K#\nğ‘“=ğ‘Â·Jğ¹K#\nğ‘“+Jğ¿K#\nğ‘“+JğµK#\nğ‘“\nJ(mapğ¹ ğ¿)K#\nğ‘“=ğ‘Â·Jğ¹K#\nğ‘“+Jğ¿K#\nğ‘“\nJ(filterğ¹ ğ¿)K#\nğ‘“=ğ‘Â·Jğ¹K#\nğ‘“+Jğ¿K#\nğ‘“\nJ(sliceğ¿ğ¼1ğ¼2)K#\nğ‘“=Jğ¿K#\nğ‘“+Jğ¼1K#\nğ‘“+Jğ¼2K#\nğ‘“\nJ(lengthğ¿)K#\nğ‘“=Jğ¿K#\nğ‘“\nJğ‘“â€²K#\nğ‘“= 1(ğ‘“â€²=ğ‘“)\nJinputğ‘–\nğœK#\nğ‘“=0J(ğ¹ ğ¿)Kerr=Jğ¹Kerr(Jğ¿Kerr)\nJ(foldğ¹ ğ¿ğµ)Kerr= max\nğ‘›âˆˆ{0,1,...,ğ‘}(Jğ¹Kerr)ğ‘›(Jğ¿Kerr,JğµKerr)\nJ(mapğ¹ ğ¿)Kerr=Jğ¹Kerr(Jğ¿Kerr)\nJ(filterğ¹ ğ¿)Kerr=Jğ¿Kerr\nJ(sliceğ¿ğ¼1ğ¼2)Kerr=Jğ¿Kerr\nJ(lengthğ¿)Kerr=0\nJğ‘“Kerr=ï£±ï£´ï£´ ï£²\nï£´ï£´ï£³ğœ†ğœ‚.ğ‘’ğ‘“ ifğ‘“=predictfloat\nğœ†ğœ‚.ğœ†ğœ‚â€².ğœ‚+ğœ‚â€²ifğ‘“âˆˆ{+,âˆ’}\nğœ†ğœ‚.ğœ‚ otherwise\nJinputğ‘–\nğœKerr=0\nFig. 4. Rules Algorithm 2 uses to compute the search space over Â®ğœ–(left) andÂ®ğ‘’(right). In the rule of JÂ·Kerrfor\nfold,ğ‘“ğ‘›(â„“,ğ‘)=ğ‘“(â„“,ğ‘“ğ‘›âˆ’1(â„“,ğ‘))(andğ‘“0(â„“,ğ‘)=ğ‘) is the function ğ‘“iteratedğ‘›times in its second argument.\nThe definitions of ğœ‚,ğœ‚â€², andğœ‚+ğœ‚â€²in the rule for Jğ‘“Kerrare given in Section 5.3.\nwe compute JËœğ‘ƒK#\nğ‘“, which is the number of times ğ‘“occurs in the unrolled version of Ëœğ‘ƒ; then, we\nconsiderÂ®ğœ–=(ğœ–ğ‘“1,...,ğœ–ğ‘“ğ‘‘)such thatÃ\nğ‘“ğœ–ğ‘“â‰¤ğœ–. ForÂ®ğ‘’, for each component ğ‘“ofËœğ‘ƒwith an ??ğ‘’hole,\nwe compute JËœğ‘ƒKerr:Â®ğ‘’â†¦â†’ğ‘’â€², which is a linear function mapping Â®ğ‘’to an upper bound ğ‘’â€²on the error\nof the output; then, we consider Â®ğ‘’such that JËœğ‘ƒKerr(Â®ğ‘’)â‰¤ğ‘’. We provide details below.\nSearch space overÂ®ğœ–.First, we describe our search space over parameter values Â®ğœ–used to fill holes\n??ğœ–so that the overall failure rate is at most ğœ–. Note that here,Â®ğœ–=(ğœ–ğ‘“1,...,ğœ–ğ‘“ğ‘˜), whereFËœğ‘ƒ={ğ‘“1,...,ğ‘“ğ‘˜}\nare subexpressions of Ëœğ‘ƒof the form predictint,predictfloat,cond-flip ,cond-â‰¤, orcond-â‰¥, since each\nof these subexpressions contains exactly one hole of the form ??ğœ–.\nIntuitively, we can ensure correctness via a union boundâ€”i.e., if the sum of the ğœ–ğ‘“is bounded by ğœ–,\nthen the overall failure probability is also bounded by ğœ–. The key caveat is that to apply Algorithm 1,\nwe need to unroll the sketch ğ‘ƒ=Fill(Ëœğ‘ƒ,Â®ğœ–,Â®ğ‘’). Thus, we need to count a value ğœ–ğ‘“multiple times if\nthe corresponding subexpression ğ‘“occurs multiple times in the unrolled version of ğ‘ƒ.\nIn particular, the rules Jğ‘ƒK#\nğ‘“â€²shown in Figure 4 are designed to count the number of occurrences\nof the subexpression ğ‘“â€²in the unrolled version ofğ‘ƒ. Note that in these rules, ğ‘“â€²refers to a specific\nsubexpression, and 1(ğ‘“=ğ‘“â€²)refers to whether ğ‘“is that specific subexpression; multiple uses of\nthe same construct (e.g., a program with two uses of predictint) are counted separately. These rules\nare straightforward; for instance, when unrolling the foldoperator, the expressions for the list ğ¿\nand the initial value ğµare included exactly once, whereas the function expression ğ¹occursğ‘times.\nThen, to ensure that the failure probability is at most ğœ–, it suffices forÂ®ğœ–to satisfy\nâˆ‘ï¸\nğ‘“âˆˆF Ëœğ‘ƒJËœğ‘ƒK#\nğ‘“Â·ğœ–ğ‘“â‰¤ğœ–. (8)\nNow, let Î”FËœğ‘ƒ={Â®ğ‘¥âˆˆR|FËœğ‘ƒ||âˆ€ğ‘“ .0â‰¤ğ‘¥ğ‘“â‰¤1âˆ§Ã\nğ‘“âˆˆF Ëœğ‘ƒğ‘¥ğ‘“=1}be the regular simplex in R|FËœğ‘ƒ|. Now,\ngiven anyÂ®ğ‘¥âˆˆÎ”FËœğ‘ƒ, lettingğœ–ğ‘“=ğ‘¥ğ‘“Â·ğœ–/JËœğ‘ƒK#\nğ‘“, then (8) is satisfied. In our algorithm, we search over a\nfinite set of points from Î”FËœğ‘, and construct the corresponding set of values Â®ğœ–.\nIn Figure 6, the rule for filter appliesğ‘“1=cond-â‰¤andğ‘“2=predictinteachğ‘=3times (where\nğ‘is the given bound on the list length), so we have JËœğ‘ƒexK#\nğ‘“1=JËœğ‘ƒexK#\nğ‘“2=3. Similarly, map applies\nğ‘“3=predictfloata total ofğ‘=3times, so JËœğ‘ƒexK#\nğ‘“1=3. As an example of a point in our search space,\ntakingÂ®ğ‘¥=(1/3,1/3,1/3)yieldsÂ®ğœ–=(1/9,1/9,1/9).\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 15\nSearch space overÂ®ğ‘’.Next, we describe our search space over parameter values Â®ğ‘’used to fill holes\n??ğ‘’so the overall error is at most ğ‘’. Similar to before,Â®ğ‘’=(ğ‘’ğ‘“1,...,ğ‘’ğ‘“â„), but this timeGËœğ‘ƒ={ğ‘“1,...,ğ‘“â„}\nare subexpressions of Ëœğ‘ƒof the form predictfloat, which each contain exactly one hole of the form\n??ğ‘’. In this case, we define an analysis that bounds the overall error of the output of Â¯ğ‘ƒ=Fill(ğ‘ƒ,Â®ğœ–,Â®ğ‘’)\nfor anyÂ®ğœ–as a function ofÂ®ğ‘’. More precisely, Jğ‘ƒKerrsatisfies the following property:\n\r\rJFill(ğ‘ƒ,Â®ğœ–,Â®ğ‘’)Kğ›¼âˆ’Jğ‘ƒKâˆ—\nğ›¼\r\r\nâˆâ‰¤Jğ‘ƒKerr(Â®ğ‘’) (9)\nfor allÂ®ğœ–andÂ®ğ‘’, and for all ğ›¼such that all component specifications in Fill(ğ‘ƒ,Â®ğœ–,Â®ğ‘’hold forÂ®ğ›¼. In other\nwords, (9) bounds the error of the output for examples ğ›¼such that predictions fall within the desired\nerror bounds (failures happen with probability at most ğœ–according to our choices of Â®ğœ–).\nNote that (9) uses the ğ¿âˆnorm. For scalar outputs, we have âˆ¥ğ‘¥âˆ’ğ‘¥â€²âˆ¥âˆ=|ğ‘¥âˆ’ğ‘¥â€²|. For list outputs,\nfor theğ¿âˆnorm to be well-defined, we need to ensure that ğ‘¥=JFill(ğ‘ƒ,Â®ğœ–,Â®ğ‘’)Kğ›¼andğ‘¥â€²=JÂ¯ğ‘ƒKâˆ—\nğ›¼are of\nthe same length (at least, when all component specifications are satisfied). In particular, the only\npotential case where ğ‘¥andğ‘¥â€²have unequal lengths is if Â¯ğ‘ƒcontains a filter operator. We focus on\nfiltering real-valued lists; filtering integer-valued lists is similar (and there are no operations to\nfilter list-valued lists or image-valued lists). In the real-valued case, the filter function must be either\ncond-â‰¤andcond-â‰¥. Assuming the component specifications on cond-â‰¤andcond-â‰¥are satisfied,\nthen their (Boolean) outputs are guaranteed to be equal, so the outputs of the filter operator have\nequal length under train and test semantics. Thus, âˆ¥ğ‘¥âˆ’ğ‘¥â€²âˆ¥âˆis well-defined.\nGiven Jğ‘ƒKerr, our goal is to compute Â®ğ‘’satisfying\nJğ‘ƒKerr(Â®ğ‘’)â‰¤ğ‘’. (10)\nAs withÂ®ğœ–, we can construct a candidate Â®ğ‘’for any point in ğ‘¥âˆˆÎ”GËœğ‘ƒby takingğ‘’ğ‘“=ğ‘¥ğ‘“Â·ğ‘’/ğ‘ğ‘“, where\nJËœğ‘ƒKerr=Ã\nğ‘“âˆˆG Ëœğ‘ƒğ‘ğ‘“Â·ğ‘’ğ‘“. In Figure 3, we have JËœğ‘ƒKerr=3Â·ğ‘’ğ‘“3, so there is a single candidate ğ‘’ğ‘“3=ğ‘’/3.\nNext, we describe the rules Jğ‘ƒKerr, which are shown in Figure 4 (right). They compute an symbolic\nexpression of the form ğœ‚=Ã\nğ‘“âˆˆG Ëœğ‘ƒğ‘ğ‘“Â·ğ‘’ğ‘“âˆˆE Ëœğ‘ƒ, whereğ‘ğ‘“âˆˆRâ‰¥0andğ‘’ğ‘“is a symbol. Given Â®ğ‘’, an\nexpressionğœ‚can be evaluated by substituting Â®ğ‘’for the symbols ğ‘’ğ‘“inğœ‚. Now, the rule for function\napplication assumes given a function abstraction Jğ¹Kerr:EËœğ‘ƒâ†’E Ëœğ‘ƒ. In particular, Jğ¹Kerris the\nidentity function except for predictfloat,+, andâˆ’. The case predictfloatfollows since we have assumed\nthat the component specification holes, and the component specification for ğ‘“=predictfloatsays\nexactly that|JÂ¯ğ‘“Kğ›¼âˆ’Jğ‘“Kâˆ—\nğ›¼|â‰¤ğ‘’ğ‘“for any completion Â¯ğ‘“ofğ‘“. For+andâˆ’, lettingğœ‚=Ã\nğ‘“âˆˆG Ëœğ‘ƒğ‘ğ‘“Â·ğ‘’ğ‘“and\nğœ‚â€²=Ã\nğ‘“âˆˆG Ëœğ‘ƒğ‘â€²\nğ‘“Â·ğ‘’ğ‘“, we defineğœ‚+ğœ‚â€²=Ã\nğ‘“âˆˆG Ëœğ‘ƒ(ğ‘ğ‘“+ğ‘â€²\nğ‘“)Â·ğ‘’ğ‘“. The rule for map follows since we are\nusing theğ¿âˆnorm, so the bound is applied elementwise. The remaining rules are straightforward.\nIn Figure 3, the rule for predictfloatreturnsğ‘’ğ‘“3, so the rule for map returns 3Â·ğ‘’ğ‘“3(since the given\nbound on the list length is ğ‘=3). The remaining rules propagate this value, so JËœğ‘ƒexKerr=3Â·ğ‘’ğ‘“3.\nFinally, the fact that JÂ·Kerris a linear function follows by structural induction. Additional compo-\nnents (e.g., multiplication) can result in nonlinear expressions, but a similar approach applies.\nOverall search space. Our overall search space consists of pairs Â®ğœ–andÂ®ğ‘’such thatÂ®ğœ–satisfies (8)\nandÂ®ğ‘’satisfies (10); given such a pair, FillAll(Ëœğ‘ƒ,ğœ–,ğ‘’)includes the program ğ‘ƒ=Fill(Ëœğ‘ƒ,Â®ğœ–,Â®ğ‘’). Together,\n(8) and (10) ensure the desired property (7). In particular, for any completion Â¯ğ‘ƒofğ‘ƒ, (10) ensures\nthat|JÂ¯ğ‘ƒKğ›¼âˆ’Jğ‘ƒKâˆ—\nğ›¼|â‰¤ğ‘’as long asğ›¼satisfies all the component specifications, and (8) ensures that ğ›¼\nsatisfies the component specifications with probability at least 1âˆ’ğœ–overğ‘(ğ›¼).\n6 DISCUSSION\nGenerality. In Section 5, we described a synthesizer tailored to the language in Figure 2. Our\napproach generalizes straightforwardly in several ways. First, we note that the predictintand\npredictfloatmachine learning components are not specific to images of integers, and represent\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n16 Bastani\ngeneral classification and regression problems, respectively. Furthermore, we can also include\nadditional list processing components as long as we provide the abstract semantics JÂ·K#and JÂ·Kerr.\nThus, our algorithm can be viewed as a general algorithm for synthesizing list processing programs\nwith DNNs for classification and regression, where the specification is that with high probability,\nthe program should return the either the correct answer (within some given error tolerance) or âˆ….\nWe can also modify the specification in certain ways; for instance, we can ignore certain kinds\nof errors by modifying the annotations on predictintandpredictfloat. For instance, to allow for\none-sided errors in regression problems (e.g., it is fine to say â€œpersonâ€ when there isnâ€™t one but\nnot vice versa), we can simply drop the absolute values from the task specification ğœ“and from the\nannotations on predictfloat. For this case, the algorithm for allocating errors ğ‘’works as is, but in\ngeneral, it may need to be modified to ensure the annotations imply the specification.\nBound on examples. In Section 5, we assumed given a bound ğ‘on the maximum length of any list\nobserved during program execution. Intuitively, we can circumvent this assumption by computing\na high probability bound ğ‘; the error probability can be included in the user-provided allowable\nerror rateğœ–. In particular, let JËœğ‘ƒKlen\nğ›¼denote the maximum list length observed while executing Ëœğ‘ƒon\ninputğ›¼. Then, suppose we can obtain ğ‘such that\nPğ‘(ğ›¼)\u0000JËœğ‘ƒKlen\nğ›¼â‰¤ğ‘)â‰¥1âˆ’ğœ–\n2.\nNow, if we synthesize a completion Â¯ğ‘ƒofËœğ‘ƒwith overall error rate â‰¤ğœ–/2, then by a union bound,\nthe total error rate is â‰¤ğœ–. Finally, to obtain such an ğ‘, we can use the specification\nJËœğ‘ƒKlen\nğ›¼â‰¤??{true}â‡’\nğœ–/2.\nLettingğ‘be the synthesized value used to fill the hole, the specification says that JËœğ‘ƒKlen\nğ›¼â‰¤ğ‘with\nprobability at least ğœ–/2according to ğ‘(ğ›¼), which is exactly the desired condition on ğ‘; thus, we\ncan takeğ‘=ğ‘. Note that since the specification is true, we can use either |orâ‡’.\n7 EVALUATION\nWe describe our evaluation on synthesizing list processing programs, as well as on two case studies:\n(i) a state-of-the-art image classifier, and (ii) a random forest trained to predict Warfarin drug\ndosage. In addition, we describe an extension of (i) to object detection in Appendix C.\n7.1 Synthesizing List Processing Programs with Image Classification\nExperimental setup. We evaluate our synthesis algorithm on our list processing domain in\nSection 5. Inputs are lists of MNIST digits [ 42]. We use a convolutional DNN (two convolutional\nlayers followed by two fully connected layers, with ReLU activations) [ 41] to predict the integer in\nan image, trained on the MNIST training set; it achieves 99.2% accuracy. We also train a single layer\nDNN, which is 4.04 Ã—faster but only 98.5% accurate. Finally, for inputs with the flip component,\nwith consider input images flipped along their horizontal axis. We train a DNN to predict whether\na given image is flipped; it achieves 99.6% accuracy.\nFor the synthesizer, we use a standard enumerative synthesizer that returns the smallest program\nin terms of depth (but chooses arbitrarily among equal depth programs). We give it 5 labeled input-\noutput examples as a specification ğœ“, along with the type of the function to be synthesized [ 23,50].\nFor the search space over each Â®ğœ–andÂ®ğ‘’, we consider values Â®ğ‘¥0âˆˆ{1,3,5}ğ‘‘, whereğ‘‘=|FËœğ‘ƒ|or\nğ‘‘=|GËœğ‘ƒ|, and then takeÂ®ğ‘¥=Â®ğ‘¥0/âˆ¥Â®ğ‘¥0âˆ¥1to normalize it to Î”ğ‘‘. We also compare to (i) a baseline\nâ€œNo Searchâ€, which only considers a single Â®ğ‘¥0=(1,...,1), and (ii) a baseline â€œ ğ‘˜=0â€, which uses\na variant of our generalization bound that uses either ğ‘˜=0(orğ‘˜=âˆ…, if there are insufficient\nsamples); this strategy captures the guarantees provided by traditional generalization bounds from\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 17\nDSL Variant Taskâˆ…Rate Failure Rate\nStatCoder No Search ğ‘˜=0StatCoder No Search ğ‘˜=0\nintsumğ‘¥âˆˆâ„“ 0.000 0.000 0.177 0.018 0.018 0.001\nmaxğ‘¥âˆˆâ„“ 0.000 0.000 0.177 0.008 0.008 0.001\nsumğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.001 0.022 0.206 0.016 0.010 0.001\nmax firstğ‘˜elementsğ‘¥âˆˆâ„“ 0.000 0.008 0.195 0.007 0.007 0.000\ncountğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.001 0.022 0.206 0.000 0.000 0.000\naverage â€“ 0.000 0.010 0.192 0.010 0.009 0.001\nfloatsumğ‘¥âˆˆâ„“ 0.000 0.000 0.000 0.001 0.001 0.001\nmaxğ‘¥âˆˆâ„“ 0.000 0.000 0.000 0.000 0.000 0.000\nsumğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.000 1.000 1.000 0.010 0.000 0.000\nmax firstğ‘˜elementsğ‘¥âˆˆâ„“ 0.000 0.005 0.177 0.000 0.000 0.000\ncountğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.000 1.000 1.000 0.000 0.000 0.000\naverage â€“ 0.000 0.401 0.435 0.002 0.000 0.000\nflipsumğ‘¥âˆˆâ„“ 0.015 0.016 0.230 0.012 0.012 0.001\nmaxğ‘¥âˆˆâ„“ 0.015 0.016 0.230 0.006 0.006 0.001\nsumğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.025 0.085 0.265 0.012 0.004 0.001\nmax firstğ‘˜elementsğ‘¥âˆˆâ„“ 0.063 0.046 0.258 0.005 0.004 0.000\ncountğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.025 0.085 0.265 0.000 0.000 0.000\naverage â€“ 0.029 0.050 0.250 0.007 0.005 0.001\nfastsumğ‘¥âˆˆâ„“ 0.033 0.033 0.706 0.026 0.026 0.000\nmaxğ‘¥âˆˆâ„“ 0.033 0.033 0.706 0.008 0.008 0.000\nsumğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.039 0.127 0.755 0.023 0.005 0.000\nmax firstğ‘˜elementsğ‘¥âˆˆâ„“ 0.035 0.061 1.000 0.010 0.007 0.000\ncountğ‘¥âˆˆâ„“that areâ‰¤ğ‘˜ 0.039 0.127 0.755 0.000 0.000 0.000\naverage â€“ 0.036 0.076 0.784 0.013 0.009 0.000\noverall â€“ 0.016 0.134 0.415 0.008 0.006 0.000\nTable 1. We show results on synthesizing list processing programs, for both our approach ( StatCoder ) and\nthe baseline that does not search over Â®ğœ–andÂ®ğ‘’(â€œNo Searchâ€). For each DSL variant and each task, we show\nthe â€œâˆ…Rateâ€ Pğ‘(ğ›¼)(JÂ¯ğ‘ƒKğ›¼=âˆ…), and the â€œFailure Rateâ€ Pğ‘(ğ›¼)(JÂ¯ğ‘ƒKğ›¼â‰ âˆ…âˆ§| JÂ¯ğ‘ƒKğ›¼âˆ’JÂ¯ğ‘ƒKâˆ—ğ›¼=âˆ…|)>ğ‘’.\nstatistical learning theory [ 28,34,71]. We use our algorithm with parameters ğœ–=ğ›¿=0.05,ğ‘’=6,\nandğ‘=3. We use 2500 MNIST test set images for each ğ›¼synth andğ›¼sketch , and the remaining 5000\nfor evaluation. Next, we consider four variants of our DSL:\nâ€¢Int:Restrict to components with integer type and omit the cond-flip component\nâ€¢Float: Same as â€œintâ€, but include components with real types\nâ€¢Flip: Same as â€œintâ€, but include the flip component\nâ€¢Fast: Same as â€œintâ€, but use the fast neural network.\nFor each variant, we consider five list processing tasks, which are designed to exercise different\nkinds of components. These programs all take as input a list â„“of imagesğ‘¥âˆˆâ„“; in addition, several\nof them take as input a second image ğ‘˜that encodes some information relevant to task. Then, they\noutput an integer or real value (as specified by ğœ“). The tasks are shared across the different DSL\nvariants, but specific programs change based on the available components.\nResults. We show results in Table 1. For the program Â¯ğ‘ƒsynthesized using each our approach\nStatCoder and our baseline that does not search over Â®ğœ–andÂ®ğ‘’, we show the following metrics:\nâ€¢âˆ…Rate: The rate at which Â¯ğ‘ƒreturnsâˆ…â€”i.e.,Pğ‘(ğ›¼)(JÂ¯ğ‘ƒKğ›¼=âˆ…).\nâ€¢Failure Rate: The rate at which Â¯ğ‘ƒmakes mistakesâ€”i.e.,\nPğ‘(ğ›¼)\u0000JÂ¯ğ‘ƒKğ›¼â‰ âˆ…âˆ§| JÂ¯ğ‘ƒKğ›¼âˆ’JÂ¯ğ‘ƒKâˆ—\nğ›¼=âˆ…|\u0001>ğ‘’.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n18 Bastani\n0.0000.0010.0020.003\n00.0050.010.015\n0.050.10.150.2failure rateâˆ…rateğœ€\n0.0000.0010.0020.003\n0.0000.0050.0100.015\n0.050.10.150.2failure rateâˆ…rateğ›¿\n0.0000.0010.0020.003\n0.0000.0050.0100.015\n3.06.09.012.0failure rateâˆ…ratee\n(a) (b) (c)\nFig. 5. For list processing programs, we show âˆ…rate (black) and failure rate (red) as a function of (a) ğœ–, (b)ğ›¿,\nand (c)ğ‘’, on average for (a,b) â€œIntâ€ programs and (c) â€œFloatâ€ programs. Defaults are ğœ–=ğ›¿=0.05andğ‘’=6.0.\nTaskâˆ…Rate Failure Rate\nStatCoder No Search ğ‘˜=0StatCoder No Search ğ‘˜=0\ncount the number of people in ğ‘¥ 0.054 0.054 0.901 0.124 0.124 0.003\ncheck ifğ‘¥contains a person 0.054 0.054 0.901 0.124 0.124 0.003\ncount people near the center of ğ‘¥ 0.290 0.290 0.901 0.032 0.032 0.003\nfind people near a car 0.901 0.901 1.000 0.003 0.003 0.000\nminimum distance from a person to the center of ğ‘¥ 0.149 0.149 0.901 0.023 0.023 0.000\naverage 0.290 0.290 0.921 0.061 0.061 0.002\nTable 2. We show results on synthesizing list processing programs over object detection, for our approach\nStatCoder . For each DSL variant and each task, we show the â€œ âˆ…Rateâ€ Pğ‘(ğ›¼)(JÂ¯ğ‘ƒKğ›¼=âˆ…), and the â€œFailure\nRateâ€ Pğ‘(ğ›¼)(JÂ¯ğ‘ƒKğ›¼â‰ âˆ…âˆ§| JÂ¯ğ‘ƒKğ›¼âˆ’JÂ¯ğ‘ƒKâˆ—ğ›¼=âˆ…|)>ğ‘’. Parameters are ğœ–=ğ›¿=0.2andğ‘’=20.0.\nAs can be seen, both StatCoder and the baseline always achieve the desired failure rate bound of\nğœ–=0.05. Furthermore, by searching over candidates Â®ğœ–andÂ®ğ‘’,StatCoder substantially outperforms\nthe baseline, achieving an 8Ã—reduction inâˆ…rate on average. For simpler programs (i.e., sum and\nmax), the two perform similarly since there is only a single hole, so the search space only contains\none candidate. However, for larger programs, the search improves performance by up to an order of\nmagnitude. There is a single case where the baseline performs better (the fourth program in the â€œflipâ€\nDSL), due to random chance since the dataset ğ›¼sketch used to synthesize the final program Â¯ğ‘ƒfrom Ëœğ‘ƒ\ndiffers from the dataset ğ›¼synth used to chooseÂ®ğœ–andÂ®ğ‘’.StatCoder outperforms the â€œ ğ‘˜=0â€ baseline\nby an even larger margin, due to the fact that the generalization bound is overly conservative;\nthese results demonstrate the importance of using a generalization bound specialized to our setting\nrather than a more traditional generalization bound that minimizes the empirical risk.\nNext, in Figure 5, we show how these results vary as a function of the specification parameters ğœ–,\nğ›¿, andğ‘’. As can be seen, ğœ–has the largest effect on âˆ…and failure rates, followed by ğ‘’; as expected, ğ›¿\nhas almost no effect since the dependence of our bound on ğ›¿is logarithmic.\nFinally, we note that the failure rates for the â€œfastâ€ DSL are very low. Thus, we could use our\ntechnique to chain together the fast program with the slow one, along the same lines as discussed\nin our case study in Section 7.3; we estimate that doing so results in a 3Ã—speedup on average.\n7.2 Synthesizing List Processing Programs with Object Detection\nExperimental setup. Next, we consider synthesizing programs that operate over the predictions\nmade by a state-of-the-art DNN for object detection. We assume given a DNN component Ë†ğ‘“that\ngiven an image ğ‘¥, is designed to detect people and cars in ğ‘¥. We use a pretrained state-of-the-art\nobject detector called Faster R-CNN [ 56] available in PyTorch [ 53], tailored to the COCO dataset [ 45],\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 19\nwhich is a dataset of real-world images containing people, cars, and other objects. There are multiple\nvariants of Faster R-CNN; we use the most accurate one, X101-FPN with 3Ã—learning rate schedule.\nWe represent this DNN as a component Ë†ğ‘“:Xâ†’Y =Dâˆ—Ã—R, where Ë†ğ‘“(ğ‘¥)=(Ë†ğ‘¦(ğ‘¥),Ë†ğ‘(ğ‘¥))\nconsists of a list of detectionsğ‘‘âˆˆË†ğ‘¦(ğ‘¥)along with a correctness score Ë†ğ‘(ğ‘¥)that the prediction is\ncorrect. Each detection ğ‘‘âˆˆD=R2Ã—Z is itself a tuple ğ‘‘=(ğ‘,ğ‘§)including the position ğ‘and\npredicted category of the object. The ground truth label ğ‘¦âˆ—for an image ğ‘¥is a list of detections\nğ‘‘âˆˆğ‘¦âˆ—. In general, we cannot expect to get a perfect match between the predicted bounding boxes\nand the ground truth ones. Typically, two detections ğ‘‘,ğ‘‘âˆ—match , denotedâˆ¥ğ‘‘âˆ’ğ‘‘âˆ—âˆ¥â‰¤ğ‘’, whereğ‘’is a\nspecified error tolerance, if the distance between their centers satisfies âˆ¥ğ‘âˆ’ğ‘âˆ—âˆ¥âˆâ‰¤ğ‘’. Furthermore,\nwe writeâˆ¥Ë†ğ‘¦(ğ‘¥)âˆ’ğ‘¦âˆ—âˆ¥â‰¤ğ‘’if|Ë†ğ‘¦(ğ‘¥)|=|ğ‘¦âˆ—|and there exists a one-to-one correspondence between\nğ‘‘âˆˆË†ğ‘“(ğ‘¥)andğ‘‘âˆ—âˆˆğ‘¦âˆ—such thatâˆ¥ğ‘‘âˆ’ğ‘‘âˆ—âˆ¥â‰¤ğ‘’. Then, we define predict :Xâ†’(Yâˆªâˆ…) by\n(predictğ‘¥)=(ifË†ğ‘(ğ‘¥)â‰¥??ğ‘{âˆ¥Ë†ğ‘¦(ğ‘¥)âˆ’ğ‘¦âˆ—âˆ¥â‰¤??ğ‘’}â‡’\n??ğœ–then Ë†ğ‘¦(ğ‘¥)elseâˆ…).\nIn other words, the specification says that a correct prediction is if the error tolerance is below a\nlevel ??ğ‘’to be specified. Thus, given ğ‘’andğœ–to fill ??ğ‘’and??ğœ–, respectively, our sketching algorithm\nsynthesizes a threshold ğ‘to fill ??ğ‘in a way that guarantees that this specification holds. Then,\npredict returns Ë†ğ‘¦(ğ‘¥)if the DNN is sufficiently confident in its prediction, and âˆ…otherwise.\nWe can use this component in conjunction with our synthesis algorithm in the same way that it\nuses predictfloat. In particular, we define the abstract semantics\nJ(predictğ‘¥)Kerr=ğœ†ğœ‚.ğ‘’ predict.\nThese semantics enable it to select the error tolerance ğ‘’to fill ??ğ‘’. The remainder of the synthesis\nalgorithm proceeds as in Section 7.1. We use parameters ğœ–=ğ›¿=0.2,ğ‘’=20.0, andğ‘=3, and\nuseğ‘›=1000 COCO validation set images for each ğ›¼synth andğ›¼sketch and the remaining 1503 for\nevaluation. We use larger ğœ–andğ›¿since the accuracy of the object detector is significantly lower\nthan that of the image classifier, so the âˆ…rates are very high for smaller choices.\nWe evaluate our approach on synthesizing five programs, which include additional list processing\ncomponents: (i)(productğ¿ ğ¿â€²), which returns the list of all pairs (ğ‘¥,ğ‘¥â€²)such thatğ‘¥âˆˆJğ¿Kand\nğ‘¥â€²âˆˆJğ¿â€²K, (ii)(composeğ‘“ ğ‘“â€²), which returns the composition ğœ†ğ‘¥.ğ‘“(ğ‘“â€²(ğ‘¥)), (iii)(isğ‘§â€²ğ·), which\nreturns 1(ğ‘§=ğ‘§â€²), where Jğ·K=(ğ‘,ğ‘§)is a detection and ğ‘§â€²âˆˆZ is an object category, and (iv)\n(distanceğ· ğ·â€²), which returns the distance âˆ¥ğ‘âˆ’ğ‘â€²âˆ¥âˆbetween two detections Jğ·K=(ğ‘,ğ‘§)and\nJğ·â€²K=(ğ‘â€²,ğ‘§â€²). Their abstract semantics are straightforward: for JÂ·K#, they each evaluate each of\ntheir arguments once, and for JÂ·Kerr, the only one that propagates errors is distance , for which\nJ(distanceğ·ğ·â€²)Kerr=Jğ·Kerr+Jğ·â€²Kerr.\nResults. We provide results in Table 2. The trends are similar to Section 7.1; the main difference\nis that search does not help in this case, likely because there is only a single machine learning\ncomponent so optimizing the allocation does not significantly affect performance. Finally, we can\nchain these programs with a faster object detector to reduce running time; see Appendix C.\n7.3 Case Study 1: ImageNet Image Classification\nCorrectness. Consider program shown in Figure 6, which classifies images as â€œpersonâ€ (returns\ntrue) or â€œnot personâ€ (returns false ). The function is_person takes as input an image ğ‘¥, and\noptionally the ground truth label ğ‘¦âˆ—(which is only used during sketching). The specification in\nis_person says that the program should return true with high probability if the image is of a\nperson (i.e., ğ‘¦âˆ—=1). The predicate 1(1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘)is shown in blue, where the value of ğ‘has been\nleft as a hole ??1, the specification ğ‘¦âˆ—=1is shown in green in the curly braces, and the value\nğœ–=0.05is shown in green in the square braces. We perform a case study in the context of this\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n20 Bastani\ndef is_person(x, y_true=None):\nif 1.0 - f(x) <= ??1 {y_true} [|, 0.05]:\nreturn True\nelse:\nreturn False\ndef is_person_fast(x):\nif 1.0 - f_fast(x) <= ??2 {is_person(x)} [|, 0.05]:\nreturn is_person(x)\nelse:\nreturn Falsedef monitor_correctness(x):\nif np.random.uniform() <= 0.99:\nreturn\npassert 1.0 - f_fast(x) <= ??2 {is_person(x)} [|, 0.05]\ndef monitor_speed(x):\npassert 1.0 - f_fast(x) > ??2 {true} [|, ??3]\nFig. 6. A program used to predict whether an image ğ‘¥contains a person. Specifications are shown in green;\ncurly brackets is the specification and square brackets is the value of ğœ–. The corresponding inequality with a\nhole in blue. Holes with the same number are filled with the same value.\nprogram (though for labels other than â€œpersonâ€). We consider the ImageNet dataset [ 18], a large\nimage classification benchmark with over one million images in 1000 categories, including various\ndifferent animals and inanimate objects. We consider the ResNet-152 DNN architecture [ 29], a\nstate-of-the-art image classification model trained on ImageNet that achieves about 88% accuracy\noverall. For both architectures, we use the implementation in PyTorch [53].\nTo use our system, we split the ImageNet validation set consisting of 50,000 held-out images into\n(at most) 25,000 for synthesis (i.e., the synthesis set ) and 25,000 for validation. Because ImageNet has\nso many labels, each object category has very few examples in the validation dataset (50 on average).\nThus, we group the labels into larger, coarse-grained categories, focusing on ones that correspond\nto many fine-grained ImageNet labels. We consider â€œdogâ€ (130 labels, 6,500 images) â€œbirdâ€ (59\nlabels, 2,950 images), â€œinsectâ€ (27 labels, 1,350 images), â€œcarâ€ (21 labels, 1050 images), â€œsnakeâ€ (17\nlabels, 850 images), and â€œcatâ€ (13 labels, 650 images). The default one we use is â€œcarâ€; this category\ncontains vehicles such as passenger cars, bikes, busses, trolleys, etc. For the scoring function, given\na coarse-grained category ğ‘ŒâŠ†Y , we use the sum of the fine-grained label probabilitiesâ€”i.e.,\nğ‘“(ğ‘¥)=Ã\nğ‘¦âˆˆğ‘Œğ‘(ğ‘¥,ğ‘¦), whereğ‘(ğ‘¥,ğ‘¦)is the predicted probability of label ğ‘¦according to ResNet-152.\nThen, we use our sketching algorithm to synthesize ğ‘to fill ??1. We show results in the first\nand fourth rows of Figure 7. Note that the red curves ideally equal the blue curves, but are slightly\nconservative to account for synthesis being based on finitely many samples. The value of ğœ–has the\nbiggest effect on performance, since it directly governs recall; as ğœ–grows, recall drops (as desired)\nand precision substantially improves. In contrast, the performance does not vary significantly with\nğ›¿. These trends match sample complexity guarantees from learning theory relevant to our setting\nofğ‘›=ğ‘‚(log(1/ğ›¿)/ğœ–)[34,71]. Next, asğ‘›grows larger, recall can more closely match the desired\nmaximum, allowing precision to improve dramatically (the non-monotone effect is most likely due\nto random chance). Finally, the dependence on the target label is also governed by the number of\nsynthesis images in each category.\nImproving speed. Next, we describe how our framework can be used to compose ğ‘“with a second\nDNNğ‘“fast, which is much faster than ğ‘“but has lower accuracy. Intuitively, we want to use ğ‘“fast\nwhen we can guarantee its prediction is correct with high probability, and use ğ‘“otherwise. This\napproach has been used to reduce running time [ 13,67]; our framework can be used to do so while\nproviding rigorous accuracy guarantees.\nThe code for this approach is shown in is_person_fast in Figure 6. As before, the idea is to\ncompute a threshold ğ‘â€²such that the prediction ğ‘“fast(ğ‘¥)â‰¥1âˆ’ğ‘â€²is correct with high probability.\nThere are two differences. First, if we conclude that there might be a person in the image according\ntoğ‘“fast, then we return the prediction according to ğ‘“(instead of true). Whileğ‘“fastis guaranteed\nto detect 95% images with people with high probability, it may have more false positives than ğ‘“;\ncallingğ‘“afterğ‘“fastreduces these false positives. Second, the correctness guarantee is with respect\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 21\n0.600.700.800.901.00\n0.050.10.150.2Precision/Recallğœ€\n0.600.700.800.901.00\n0.050.10.150.2Precision/Recallğ›¿\n0.500.600.700.800.901.00\nDogBirdInsectCarSnakeCatPrecision/Recall\n(a) (b) (c)\n0.600.700.800.901.00\n0.050.10.150.2Precision/Recallğœ€\n0.600.700.800.901.00\n0.050.10.150.2Precision/Recallğ›¿\n0.500.600.700.800.901.00\nDogBirdInsectCarSnakeCatPrecision/Recall\n(d) (e) (f)\n051015\n0.050.10.150.2Time (Minutes)ğœ€\n051015\n0.050.10.150.2Time (Minutes)ğ›¿\n05101520\nDogBirdInsectCarSnakeCatTime (Minutes)\n(g) (h) (i)\n0.200.400.600.801.00\n500010000150002000025000Precision/Recalln\n(j)\nFig. 7. For ResNet alone, we show the recall (red), desired lower bound on the recall (blue), and precision\n(black) as a function of (a) ğœ–, (b)ğ›¿, (c)ğ‘¦âˆˆY, and (j) the number of synthesis examples ğ‘›; the defaults are\nğœ–=ğ›¿=0.05,ğ‘›=25,000, andğ‘¦=â€œcarâ€ , except in (c) we use ğœ–=0.1to facilitate the comparison with (f). We\nshow the same values for ResNet +AlexNet as a function of (d) ğœ–, (e)ğ›¿, and (f)ğ‘¦âˆˆY. For ResNet+AlexNet\n(black) compared to AlexNet alone (green), we show the running time as a function of (g) ğœ–, (h)ğ›¿, and (i)\nğ‘¦âˆˆY; we omit ResNet alone since its running time (82.6 minutes) is significantly above the scale.\nto the prediction Ë†ğ‘¦= 1(ğ‘“(ğ‘¥)â‰¥1âˆ’ğ‘)rather thanğ‘¦âˆ—. We could use ğ‘¦âˆ—, but there is no needâ€”if Ë†ğ‘¦is\nincorrect, then it is not helpful for ğ‘“fastto predict correctly since it falls back on Ë†ğ‘¦.\nForğ‘“fast, we use AlexNet, which achieves about 57% accuracy overall; in particular, we use\nğ‘“fast(ğ‘¥)=Ã\nğ‘¦âˆˆğ‘Œğ‘fast(ğ‘¥,ğ‘¦), whereğ‘fast(ğ‘¥,ğ‘¦)is the predicted probability of label ğ‘¦according to\nAlexNet. Then, we conclude that ğ‘¥(may) have label ğ‘¦ifğ‘“fast(ğ‘¥)â‰¥1âˆ’ğ‘â€², whereğ‘â€²is synthesized\nby our algorithm. We obtain results on an Nvidia GeForce RTX 2080 Ti GPU. We show results\non the second and third rows of Figure 7. All results shown are for the combined predictions (i.e.,\nusing both AlexNet and ResNet), and are estimated on the validation set. For running time, we omit\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n22 Bastani\nresults for ResNet since its running time is 82.6minutes, which is more than 4Ã—the running time\nof our combined model. For the â€œdogâ€ category, our approach reduces running time 6Ã—from 82.6\nminutes to 13.8 minutes without any sacrifice in precision or recall.\nThus, our approach significantly reduces running time while achieving the desired error rate.\nFurthermore, comparing to Figure 7 (d), the precision does not significantly decrease across most\nlabels. It does suffer for the labels â€œcarâ€ and â€œsnakeâ€. Intuitively, for these labels, there are relatively\nfew examples in the synthesis set, so the synthesis algorithm needs to choose more conservative\nthresholds. Since the fast program has two thresholds whereas the original program only has one,\nit is more conservative in the latter case. This difference is reflected in the fact that Figure 7 (e) has\nhigher recall than (d), especially for â€œcarâ€ and â€œsnakeâ€.\nImportantly, these results rely on the fact that we are tailoring our predictions to a single\ncategoryâ€”i.e., our system enables the user to tailor the predictions of pretrained DNN models such\nas ResNet and AlexNet to their desired task. For instance, it can focus on predicting cars rather\nthan achieving good performance on all 1000 ImageNet categories.\nRuntime monitoring. As described in Appendix A.3, our framework can monitor the synthesized\nprogram at runtime, which is useful since PAC guarantees are specific to the data distribution\nğ‘(ğ‘¥,ğ‘¦âˆ—). Thus, if the program is executed on data from a different distribution, called distribution\nshift [12,55], then our guarantees may not hold. Monitoring requires us to obtain ground truth\nlabelsğ‘¦âˆ—for inputsğ‘¥encountered at run time; then, we use these ground truth labels to estimate\nthe failure rate of the model and ensure it is below the desired value ğœ–.\nWe show how we can monitor the correctness of is_person_fast . In this case, we can easily ob-\ntain ground truth labels since the specification for ??2can be obtained by evaluating ğ‘“(ğ‘¥). We want\nto avoid running ğ‘“on every input since this would defeat the purpose of using a fast DNN; instead,\nwe might run it once every ğ‘iterations for some large ğ‘. The function monitor_correctness\nimplements this check, generating a ground truth label once every ğ‘=100iterations on average.\nNote that we formulate the check as a probabilistic assertion [60]â€”i.e.,\npassert 1âˆ’ğ‘“fast(ğ‘¥)â‰¤ğ‘â€²{1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘}|\n0.05,\nwhich has the semantics\nPğ‘(ğ‘¥,ğ‘¦âˆ—)\u00001âˆ’ğ‘“fast(ğ‘¥)â‰¤ğ‘â€²|1âˆ’ğ‘“(ğ‘¥)â‰¤ğ‘\u0001,\nwhich is the specification in is_person_fast . When our framework synthesizes a value ğ‘â€²to fill\n??2inis_person_fast , it uses the same value to fill ??2inmonitor_correctness . Then, at run\ntime, it accumulates pairs (ğ‘¥,Ë†ğ‘¦), where Ë†ğ‘¦= 1(ğ‘“(ğ‘¥)â‰¤ğ‘), in calls to monitor_correctness and\nuses them to check whether the probabilistic assertion in that function is true.\nTo evaluate whether monitoring can detect shifts, we select two subsets of the â€œcarâ€ category:\n(i) bikes, including motor bikes, and (ii) passenger cars, excluding busses, trucks, etc., with 6 fine-\ngrained labels each. Then, we consider a shift from the car category to the bike categoryâ€”i.e., if we\nimagine that bikes were instead labeled as cars, would the recall of our program continue to be above\nthe desired threshold. First, we check whether it proves correctness when the data distribution\ndoes notshiftâ€”i.e., using the test images labeled â€œpassenger carâ€. We run our verification algorithm\non this property using the test set images labeled As expected, our verification algorithm correctly\nconcludes that both the recall and the running time are within the expected bounds. Then, we check\nwhether it proves correctness when the data distribution shiftsâ€”i.e., using the test images labeled\nâ€œbikeâ€. In this case, our verification algorithm concludes that recall is incorrect, but running time is\ncorrect. Indeed, the average running time is now lowerâ€”intuitively, ğ‘“fastis incorrectly rejecting\nmany â€œcarâ€ images, which reduces recall (undesired) as well as running time (desired).\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 23\ndef predict_warfarin_dose(x, y_true=None):\ny = argmax([(ys, f(x, y)) for y in [â€˜lowâ€™, â€˜medâ€™, â€˜highâ€™]])\nif y == â€˜lowâ€™ and f(x, â€˜lowâ€™) >= ??1 {y_true != â€˜highâ€™} [|, 0.05]:\nreturn â€˜lowâ€™\nif y == â€˜highâ€™ and f(x, â€˜highâ€™) >= ??2 {y_true != â€˜lowâ€™} [|, 0.05]:\nreturn â€˜highâ€™\nreturn â€˜medâ€™def monitor_correctness(x):\ny = argmax([(ys, f(x, y)) for y in [â€˜lowâ€™, â€˜medâ€™, â€˜highâ€™]])\ny_true = obtain_result(x)\nif y == â€˜lowâ€™:\npassert f(x, â€˜lowâ€™) >= ??1 {y_true != â€˜highâ€™} [|, 0.05]\nif y == â€˜highâ€™:\npassert f(x, â€˜highâ€™) >= ??2 {y_true != â€˜lowâ€™} [|, 0.05]\nFig. 8. A program that predicts the Warfarin dose for a patient with covariates ğ‘¥. Specifications are shown in\ngreen; curly brackets is the specification and square brackets is the value of ğœ–. The corresponding inequality\nwith a hole in blue. Holes with the same number are filled with the same value.\n0.000.010.020.030.040.05\n00.020.040.060.080.1Error Rateğœ€\n0.000.010.020.030.040.05\n00.020.040.060.080.1Error Rateğ›¿\n0.000.010.020.030.040.05\n500100015002000Error Raten\n(a) (b) (c)\n0.500.550.600.65\n00.020.040.060.080.1Accuracyğœ€\n0.500.550.600.65\n00.020.040.060.080.1Accuracyğ›¿\n0.500.550.600.65\n500100015002000Accuracyn\n(d) (e) (f)\nFig. 9. We show the error rate (top) and accuracy (bottom) for our program (black), the random forest (red),\nalways predicting â€œmediumâ€ (green) as a function of (a,d) ğœ–, (b,e)ğ›¿, and (c,f) the number of synthesis examples\nğ‘›; for the top plots, we also show the desired upper bound on the error rate (blue).\nAs a side note, our framework can also be used to monitor quantitative properties. For instance,\nwe can keep monitor how frequently the branch ğ‘“fast(ğ‘¥)>ğ‘is takenâ€”i.e., avoiding the need to\nevaluateğ‘“(ğ‘¥). In Figure 6, monitor_running_time includes a probabilistic assertion\npassert 1âˆ’ğ‘“fast(ğ‘¥)>ğ‘â€²{true}|\nğœ–\nto perform this check. This assertion says that 1âˆ’ğ‘“fast(ğ‘¥)>ğ‘â€²with probability at least 1âˆ’ğœ–â€”i.e.,\nthe faster branch in is_person_fast should be taken at least 1âˆ’ğœ–fraction of the time according\ntoğ‘(ğ‘¥,ğ‘¦âˆ—). We might not know what is a reasonable value of ğœ–â€”i.e., the rate at which ğ‘“fastpredicts\nthere is a person in the image. Thus, we leave it as a hole ??3. Given training examples Â®ğ‘§, our\nframework can be used to synthesize a value of ğœ–to fill this hole.\n7.4 Case Study 2: Precision Medicine\nWarfarin dosing task. Next, we consider a task from precision medicine. In particular, we consider\na random forest trained to predict dosing level for the Warfarin drug based on individual covariates\nsuch as genetic biomarkers [ 36]. Personalized dosing can improve patient outcomes, but significant\nerrors can lead to adverse events if not quickly corrected. The ideal dosage is a real-valued label.\nThe goal is to train a model to predict this dosage as a decision support tool for physicians. For\nsimplicity, we build on an approach that converts the problem into a classification problem by\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n24 Bastani\ndiscretizing this value into labels Y={high,medium,low}dose [ 8]. Then, the goal is to maximize\naccuracy while ensuring that very few patients for whom a high dose is predicted but should have\nbeen assigned a low dose, and vice versa.\nExperimental setup. We split the dataset (5,528 examples) into training (1,658 examples), synthesis\n(2,764 examples), and test (1,106 examples) sets. Then, we use scikit-learn [ 54] to train a random\nforestğ‘“:XÃ—Yâ†’ Rwith 100 trees on the training set, where ğ‘“(ğ‘¥,ğ‘¦)âˆˆRis the probability\nassigned to label ğ‘¦âˆˆY, and useğ‘“in conjunction with the program shown in Figure 9. This program\nincludes two thresholds ğ‘lowandğ‘high, and only assigns a low dose to a patient with covariates ğ‘¥if\nğ‘“(ğ‘¥)â‰¥1âˆ’ğ‘low, and similarly for a high doseâ€”i.e., it only assigns the riskier outcomes when ğ‘“is\nsufficiently confident in its prediction. Importantly, the specification on ğ‘lowrefers not to the error\nrate on predictions for patients for whom ğ‘¦=low, but for whom ğ‘¦=highâ€”i.e., we want to choose\nğ‘lowto ensure precision specifically on patients for whom ğ‘¦=high, and conversely for ğ‘high. We\nuse our synthesis algorithm to synthesize values of ğ‘lowandğ‘highthat satisfy these specifications.\nCorrectness. Figure 9 shows the results of our approach (black) compared to directly predicting\nthe highest probability label according to the random forest ğ‘“(red), always predicting â€œmediumâ€\n(green), and the desired error rate (blue), as a function of the maximum error rate ğœ–, the maximum\nfailure probability ğ›¿, and the number of synthesis examples ğ‘›. The top plots show the error rate,\nwhich is the maximum of the rate at which patients with ğ‘¦=loware assigned a high dose, and\nthe rate at which patients ğ‘¦=high are assigned a low dose; this value should be below the blue\nline. The bottom plot shows the overall accuracy of the programâ€”i.e., how often its predicted dose\nequals the ground truth dose. All values are estimated on the held-out test set. As before, ğœ–has the\nlargest impact on performance since it directly controls the error rate; however, once it hits ğœ–=0.06,\nperformance levels off since its accuracy now equals that of ğ‘“, and the program never assigns\na dose not predicted by ğ‘“. Performance is flat as a function of ğ›¿. Finally, performance increases\nquickly asğ‘›goes from 500to1000, but plateaus thereafter, again once accuracy equals that of ğ‘“.\nRuntime monitoring. In the case of Warfarin dosing, the doctor administers an initial dose to the\npatient (possibly the predicted dose, depending on the doctorâ€™s judgement), and gradually adjusts\nit based on the patient response. Thus, we eventually observe the ground truth dose that should\nhave been recommended, which we can use to monitor our program. This process is achieved\nby the monitor_correctness subroutine; here, obtain_result returns the true dose eventually\nobserved for a patient with covariates ğ‘¥. We evaluate whether our runtime monitoring can detect\nshifts in the data distribution that lead to a reduction in performance. We consider a shift in terms\nof the ethnicity of the patients, which has recently been identified as an important challenge in\nalgorithmic healthcare [ 48]. In particular, we consider a model trained using non-Hispanic White\npatients (2,969 examples), which we refer to as the â€œmajority patientsâ€, and test it on Black, Hispanic,\nand Asian patients (2,559 examples), which we refer to as the â€œminority patientsâ€.\nFirst, we check if it proves correctness when the data distribution does not shiftâ€”i.e., we train\nthe random forest, and synthesize and verify the program on majority patients. As expected, it\nsuccessfully verifies correctness. Next, we check if it proves correctness when there is a shiftâ€”i.e.,\nwe train the random forest and synthesize the program on majority patients, but verify the program\non minority patients. As expected, it rejects the program as incorrect.\nFinally, recall that whether verification is successful depends on how many test examples are\nprovided; thus, we also evaluate how many test examples are needed in this setting. To make\nsure we have enough examples, we use all examples in this case. Then, we find that for 2,000 test\nexamples, our verification algorithm successfully proves correctness, but for 500, 1,000, or 1,500\ntest examples, it fails. Intuitively, the number of test examples needed to verify correctness needs\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 25\nto be more than the number use to synthesize the parameters, or else the synthesized thresholds\nwill be more precise (i.e., closer to their â€œoptimalâ€ value) and the verification algorithm will not\nhave enough data to validate them. In this case, we use 1,000 synthesis examples, so about 2Ã—as\nmany test examples are needed to verify correctness.\n8 RELATED WORK\nSynthesizing machine learning programs. There has been work on synthesizing programs that\ninclude DNN components [ 21,25,65,70,74] and on synthesizing probabilistic programs [ 47,59];\nhowever, they do not provide guarantees on the synthesized program. There has been work on\nsynthesizing control policies that satisfy provable guarantees [ 4,10,72,75]; however, they focus\non the setting where the learner can interact with the environment, and are not applicable to our\nsupervised learning setting. Finally, there has been work on synthesizing programs with probabilistic\nconstraints [20], but requires that the search space of programs has finite VC dimension.\nVerified machine learning. There has been recent interest in verifying machine learning programsâ€”\ne.g., verifying robustness [ 3,9,26,31,33], fairness [ 1,11], and safety [ 32,33]. More broadly, there\nhas been work verifying systems such as approximate computing [ 14,15,46,57] and probabilistic\nprogramming [ 60,61]. The most closely related work is [ 19,24,35,49], which verify semantic\nproperties of machine learning models by sampling synthetic inputs from a user-specified space. In\ncontrast, our focus is on synthesizing machine learning programs.\nStatistical verification. There has been work leveraging statistical bounds to verify stochastic\nsystems [ 62,63,73], probabilistic programs [ 60,61], and machine learning programs [ 11]. Our veri-\nfication algorithm in Appendix A relies on bounds similar to the ones used in these approaches [ 73].\nTo the best of our knowledge, we are the first to focus on synthesis; in contrast to verification, our\napproach relies on bounds from learning theory to provide correctness guarantees.\nConformal prediction. There has been work on conformal prediction [6,58,64,68], including\napplications of these ideas to deep learning [ 5,37,51,52], which aim to use statistical techniques\nto provide guarantees on the predictions of machine learning models. In particular, they provide\nconfidence sets of outputs that contain the true label with high probability. Our techniques are\ninspired by these approaches, extending them to a general framework of synthesizing machine\nlearning programs that satisfy provable guarantees.\n9 CONCLUSION\nWe have proposed algorithms for synthesizing machine learning programs that come with PAC\nguarantees. Our technique leverages novel statistical learning bounds to achieve these guarantees.\nWe have empirically demonstrated how our approach can be used to synthesize list processing\nprograms that manipulate images using DNN components while satisfying PAC guarantees, as well\nas on two case studies in image classification and precision medicine. A key direction for future\nwork is how to extend these ideas to settings where the underlying data distribution may shift, and\nto settings beyond supervised learning such as reinforcement learning.\nREFERENCES\n[1]Aws Albarghouthi, Loris Dâ€™Antoni, Samuel Drews, and Aditya V Nori. 2017. FairSquare: probabilistic verification of\nprogram fairness. Proceedings of the ACM on Programming Languages 1, OOPSLA (2017), 1â€“30.\n[2]Rajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo MK Martin, Mukund Raghothaman, Sanjit A Seshia, Rishabh Singh,\nArmando Solar-Lezama, Emina Torlak, and Abhishek Udupa. 2013. Syntax-guided synthesis . IEEE.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n26 Bastani\n[3]Greg Anderson, Shankara Pailoor, Isil Dillig, and Swarat Chaudhuri. 2019. Optimization and abstraction: A synergistic\napproach for analyzing neural network robustness. In Proceedings of the 40th ACM SIGPLAN Conference on Programming\nLanguage Design and Implementation . 731â€“744.\n[4]Greg Anderson, Abhinav Verma, Isil Dillig, and Swarat Chaudhuri. 2020. Neurosymbolic Reinforcement Learning with\nFormally Verified Exploration. In Advances in neural information processing systems .\n[5]Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, and Michael I Jordan. 2020. Uncertainty Sets for Image\nClassifiers using Conformal Prediction. arXiv preprint arXiv:2009.14193 (2020).\n[6]Vineeth Balasubramanian, Shen-Shyang Ho, and Vladimir Vovk. 2014. Conformal prediction for reliable machine\nlearning: theory, adaptations and applications . Newnes.\n[7]Peter L Bartlett and Shahar Mendelson. 2002. Rademacher and Gaussian complexities: Risk bounds and structural\nresults. Journal of Machine Learning Research 3, Nov (2002), 463â€“482.\n[8]Hamsa Bastani and Mohsen Bayati. 2015. Online decision-making with high-dimensional covariates. Operations\nResearch (2015).\n[9]Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya Nori, and Antonio Criminisi. 2016.\nMeasuring neural net robustness with constraints. In Advances in neural information processing systems . 2613â€“2621.\n[10] Osbert Bastani, Yewen Pu, and Armando Solar-Lezama. 2018. Verifiable reinforcement learning via policy extraction.\nInAdvances in neural information processing systems . 2494â€“2504.\n[11] Osbert Bastani, Xin Zhang, and Armando Solar-Lezama. 2019. Probabilistic verification of fairness properties via\nconcentration. Proceedings of the ACM on Programming Languages 3, OOPSLA (2019), 1â€“27.\n[12] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. 2007. Analysis of representations for domain\nadaptation. In Advances in neural information processing systems . 137â€“144.\n[13] Tolga Bolukbasi, Joseph Wang, Ofer Dekel, and Venkatesh Saligrama. 2017. Adaptive neural networks for efficient\ninference. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 . JMLR. org, 527â€“536.\n[14] Michael Carbin, Deokhwan Kim, Sasa Misailovic, and Martin C Rinard. 2012. Proving acceptability properties of\nrelaxed nondeterministic approximate programs. ACM SIGPLAN Notices 47, 6 (2012), 169â€“180.\n[15] Michael Carbin, Sasa Misailovic, and Martin C Rinard. 2013. Verifying quantitative reliability for programs that execute\non unreliable hardware. ACM SIGPLAN Notices 48, 10 (2013), 33â€“52.\n[16] Jia Chen, Jiayi Wei, Yu Feng, Osbert Bastani, and Isil Dillig. 2019. Relational verification using reinforcement learning.\nProceedings of the ACM on Programming Languages 3, OOPSLA (2019), 1â€“30.\n[17] Yanju Chen, Chenglong Wang, Osbert Bastani, Isil Dillig, and Yu Feng. 2020. Program Synthesis Using Deduction-\nGuided Reinforcement Learning. In International Conference on Computer Aided Verification . Springer, 587â€“610.\n[18] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image\ndatabase. In 2009 IEEE conference on computer vision and pattern recognition . Ieee, 248â€“255.\n[19] Tommaso Dreossi, Daniel J Fremont, Shromona Ghosh, Edward Kim, Hadi Ravanbakhsh, Marcell Vazquez-Chanlatte,\nand Sanjit A Seshia. 2019. Verifai: A toolkit for the formal design and analysis of artificial intelligence-based systems.\nInInternational Conference on Computer Aided Verification . Springer, 432â€“442.\n[20] Samuel Drews, Aws Albarghouthi, and Loris Dâ€™Antoni. 2019. Efficient Synthesis with Probabilistic Constraints. In\nInternational Conference on Computer Aided Verification . Springer, 278â€“296.\n[21] Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, and Josh Tenenbaum. 2018. Learning to infer graphics programs\nfrom hand-drawn images. In Advances in neural information processing systems . 6059â€“6068.\n[22] Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter, Helen M Blau, and Sebastian Thrun. 2017.\nDermatologist-level classification of skin cancer with deep neural networks. nature 542, 7639 (2017), 115â€“118.\n[23] John K Feser, Swarat Chaudhuri, and Isil Dillig. 2015. Synthesizing data structure transformations from input-output\nexamples. ACM SIGPLAN Notices 50, 6 (2015), 229â€“239.\n[24] Daniel J Fremont, Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Alberto L Sangiovanni-Vincentelli, and Sanjit A\nSeshia. 2019. Scenic: a language for scenario specification and scene generation. In Proceedings of the 40th ACM\nSIGPLAN Conference on Programming Language Design and Implementation . 63â€“78.\n[25] Alexander L Gaunt, Marc Brockschmidt, Nate Kushman, and Daniel Tarlow. 2017. Differentiable programs with neural\nlibraries. In International Conference on Machine Learning . 1213â€“1222.\n[26] Timon Gehr, Matthew Mirman, Dana Drachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, and Martin Vechev. 2018.\nAi2: Safety and robustness certification of neural networks with abstract interpretation. In 2018 IEEE Symposium on\nSecurity and Privacy (SP) . IEEE, 3â€“18.\n[27] Varun Gulshan, Lily Peng, Marc Coram, Martin C Stumpe, Derek Wu, Arunachalam Narayanaswamy, Subhashini\nVenugopalan, Kasumi Widner, Tom Madams, Jorge Cuadros, et al .2016. Development and validation of a deep learning\nalgorithm for detection of diabetic retinopathy in retinal fundus photographs. Jama 316, 22 (2016), 2402â€“2410.\n[28] David Haussler, Michael Kearns, Nick Littlestone, and Manfred K Warmuth. 1991. Equivalence of models for polynomial\nlearnability. Information and Computation 95, 2 (1991), 129â€“161.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 27\n[29] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In\nProceedings of the IEEE conference on computer vision and pattern recognition . 770â€“778.\n[30] Wassily Hoeffding. 1994. Probability inequalities for sums of bounded random variables. In The Collected Works of\nWassily Hoeffding . Springer, 409â€“426.\n[31] Xiaowei Huang, Marta Kwiatkowska, Sen Wang, and Min Wu. 2017. Safety verification of deep neural networks. In\nInternational Conference on Computer Aided Verification . Springer, 3â€“29.\n[32] Radoslav Ivanov, James Weimer, Rajeev Alur, George J Pappas, and Insup Lee. 2019. Verisig: verifying safety properties\nof hybrid systems with neural network controllers. In Proceedings of the 22nd ACM International Conference on Hybrid\nSystems: Computation and Control . 169â€“178.\n[33] Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. 2017. Reluplex: An efficient SMT solver\nfor verifying deep neural networks. In International Conference on Computer Aided Verification . Springer, 97â€“117.\n[34] Michael J Kearns, Umesh Virkumar Vazirani, and Umesh Vazirani. 1994. An introduction to computational learning\ntheory . MIT press.\n[35] Edward Kim, Divya Gopinath, Corina Pasareanu, and Sanjit A Seshia. 2020. A Programmatic and Semantic Approach\nto Explaining and Debugging Neural Network Based Object Detectors. In Proceedings of the IEEE/CVF Conference on\nComputer Vision and Pattern Recognition . 11128â€“11137.\n[36] Stephen E Kimmel, Benjamin French, Scott E Kasner, Julie A Johnson, Jeffrey L Anderson, Brian F Gage, Yves D\nRosenberg, Charles S Eby, Rosemary A Madigan, Robert B McBane, et al .2013. A pharmacogenetic versus a clinical\nalgorithm for warfarin dosing. New England Journal of Medicine 369, 24 (2013), 2283â€“2293.\n[37] Danijel Kivaranovic, Kory D Johnson, and Hannes Leeb. 2020. Adaptive, Distribution-Free Prediction Intervals for\nDeep Networks. In International Conference on Artificial Intelligence and Statistics . 4346â€“4356.\n[38] Matthieu Komorowski, Leo A Celi, Omar Badawi, Anthony C Gordon, and A Aldo Faisal. 2018. The artificial intelligence\nclinician learns optimal treatment strategies for sepsis in intensive care. Nature medicine 24, 11 (2018), 1716â€“1720.\n[39] Tim Kraska, Mohammad Alizadeh, Alex Beutel, H Chi, Ani Kristo, Guillaume Leclerc, Samuel Madden, Hongzi Mao,\nand Vikram Nathan. 2019. Sagedb: A learned database system. In CIDR .\n[40] Tim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. The case for learned index structures. In\nProceedings of the 2018 International Conference on Management of Data . 489â€“504.\n[41] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classification with deep convolutional neural\nnetworks. Advances in neural information processing systems 25 (2012), 1097â€“1105.\n[42] Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient-based learning applied to document\nrecognition. Proc. IEEE 86, 11 (1998), 2278â€“2324.\n[43] Woosuk Lee, Kihong Heo, Rajeev Alur, and Mayur Naik. 2018. Accelerating search-based program synthesis using\nlearned probabilistic models. ACM SIGPLAN Notices 53, 4 (2018), 436â€“449.\n[44] Sergey Levine, Chelsea Finn, Trevor Darrell, and Pieter Abbeel. 2016. End-to-end training of deep visuomotor policies.\nThe Journal of Machine Learning Research 17, 1 (2016), 1334â€“1373.\n[45] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÃ¡r, and C Lawrence\nZitnick. 2014. Microsoft coco: Common objects in context. In European conference on computer vision . Springer,\n740â€“755.\n[46] Sasa Misailovic, Michael Carbin, Sara Achour, Zichao Qi, and Martin C Rinard. 2014. Chisel: Reliability-and accuracy-\naware optimization of approximate computational kernels. ACM Sigplan Notices 49, 10 (2014), 309â€“328.\n[47] Aditya V Nori, Sherjil Ozair, Sriram K Rajamani, and Deepak Vijaykeerthy. 2015. Efficient synthesis of probabilistic\nprograms. ACM SIGPLAN Notices 50, 6 (2015), 208â€“217.\n[48] Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. 2019. Dissecting racial bias in an algorithm\nused to manage the health of populations. Science 366, 6464 (2019), 447â€“453.\n[49] Matthew Oâ€™Kelly, Aman Sinha, Hongseok Namkoong, Russ Tedrake, and John C Duchi. 2018. Scalable end-to-end\nautonomous vehicle testing via rare-event simulation. In Advances in Neural Information Processing Systems . 9827â€“9838.\n[50] Peter-Michael Osera and Steve Zdancewic. 2015. Type-and-example-directed program synthesis. ACM SIGPLAN\nNotices 50, 6 (2015), 619â€“630.\n[51] Sangdon Park, Osbert Bastani, Nikolai Matni, and Insup Lee. 2020. PAC Confidence Sets for Deep Neural Networks via\nCalibrated Prediction. In International Conference on Learning Representations .\n[52] Sangdon Park, Shuo Li, Osbert Bastani, and Insup Lee. 2020. PAC Confidence Predictions for Deep Neural Network\nClassifiers. arXiv preprint arXiv:2011.00716 (2020).\n[53] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban\nDesmaison, Luca Antiga, and Adam Lerer. 2017. Automatic differentiation in pytorch. (2017).\n[54] Fabian Pedregosa, GaÃ«l Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu\nBlondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al .2011. Scikit-learn: Machine learning in Python. the\nJournal of machine Learning research 12 (2011), 2825â€“2830.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n28 Bastani\n[55] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence. 2009. Dataset shift in\nmachine learning . The MIT Press.\n[56] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2016. Faster r-cnn: Towards real-time object detection with\nregion proposal networks. IEEE transactions on pattern analysis and machine intelligence 39, 6 (2016), 1137â€“1149.\n[57] Martin Rinard. 2006. Probabilistic accuracy bounds for fault-tolerant computations that discard tasks. In Proceedings of\nthe 20th annual international conference on Supercomputing . 324â€“334.\n[58] Yaniv Romano, Evan Patterson, and Emmanuel Candes. 2019. Conformalized quantile regression. In Advances in\nNeural Information Processing Systems . 3543â€“3553.\n[59] Feras A Saad, Marco F Cusumano-Towner, Ulrich Schaechtle, Martin C Rinard, and Vikash K Mansinghka. 2019.\nBayesian synthesis of probabilistic programs for automatic data modeling. Proceedings of the ACM on Programming\nLanguages 3, POPL (2019), 1â€“32.\n[60] Adrian Sampson, Pavel Panchekha, Todd Mytkowicz, Kathryn S McKinley, Dan Grossman, and Luis Ceze. 2014.\nExpressing and verifying probabilistic assertions. In Proceedings of the 35th ACM SIGPLAN Conference on Programming\nLanguage Design and Implementation . 112â€“122.\n[61] Sriram Sankaranarayanan, Aleksandar Chakarov, and Sumit Gulwani. 2013. Static analysis for probabilistic programs:\ninferring whole program properties from finitely many paths. In Proceedings of the 34th ACM SIGPLAN conference on\nProgramming language design and implementation . 447â€“458.\n[62] Koushik Sen, Mahesh Viswanathan, and Gul Agha. 2004. Statistical model checking of black-box probabilistic systems.\nInInternational Conference on Computer Aided Verification . Springer, 202â€“215.\n[63] Koushik Sen, Mahesh Viswanathan, and Gul Agha. 2005. On statistical model checking of stochastic systems. In\nInternational Conference on Computer Aided Verification . Springer, 266â€“280.\n[64] Glenn Shafer and Vladimir Vovk. 2008. A tutorial on conformal prediction. Journal of Machine Learning Research 9,\nMar (2008), 371â€“421.\n[65] Ameesh Shah, Eric Zhan, Jennifer J Sun, Abhinav Verma, Yisong Yue, and Swarat Chaudhuri. 2020. Learning Differen-\ntiable Programs with Admissible Neural Heuristics. In Advances in neural information processing systems .\n[66] Armando Solar-Lezama. 2008. Program synthesis by sketching . University of California, Berkeley.\n[67] Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung Kung. 2016. Branchynet: Fast inference via early exiting\nfrom deep neural networks. In 2016 23rd International Conference on Pattern Recognition (ICPR) . IEEE, 2464â€“2469.\n[68] Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Candes, and Aaditya Ramdas. 2019. Conformal prediction under\ncovariate shift. In Advances in Neural Information Processing Systems . 2530â€“2540.\n[69] Leslie G Valiant. 1984. A theory of the learnable. Commun. ACM 27, 11 (1984), 1134â€“1142.\n[70] Lazar Valkov, Dipak Chaudhari, Akash Srivastava, Charles Sutton, and Swarat Chaudhuri. 2018. Houdini: Lifelong\nlearning as program synthesis. In Advances in Neural Information Processing Systems .\n[71] Vladimir Vapnik. 2013. The nature of statistical learning theory . Springer science & business media.\n[72] Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli, and Swarat Chaudhuri. 2018. Programmati-\ncally Interpretable Reinforcement Learning. In International Conference on Machine Learning . 5045â€“5054.\n[73] HÃ¥kan LS Younes and Reid G Simmons. 2002. Probabilistic verification of discrete event systems using acceptance\nsampling. In International Conference on Computer Aided Verification . Springer, 223â€“235.\n[74] Halley Young, Osbert Bastani, and Mayur Naik. 2019. Learning Neurosymbolic Generative Models via Program\nSynthesis. In International Conference on Machine Learning .\n[75] He Zhu, Zikang Xiong, Stephen Magill, and Suresh Jagannathan. 2019. An inductive synthesis framework for verifiable\nreinforcement learning. In Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and\nImplementation . 686â€“701.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 29\nA STATISTICAL VERIFICATION\nWe describe our algorithm for verifying a complete program. Our algorithm (Algorithm 3) takes\nas input a complete program Â¯ğ‘ƒ, training valuations Â®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›), whereğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘are i.i.d.\nsamples, and a confidence level ğ›¿âˆˆR>0, and outputs a value ğ´(Â¯ğ‘ƒ,Â®ğ›¼)âˆˆ{ 0,1}indicating whether Â¯ğ‘ƒ\nis approximately complete, which is correct with probability at least 1âˆ’ğ›¿with respect to ğ‘(Â®ğ›¼).\nOur algorithm is based on statistical verification [62,63,73]. These algorithms leverage concen-\ntration inequalities from probability theory to provide high-probability correctness guarantees.\nConcentration inequalities are theorems that provide rigorous bounds on the rate of convergence\nof statistical estimators. For instance, consider a Bernoulli distribution ğ‘=Bernoulli(ğœ‡)with\nunknown mean ğœ‡. Given samples ğ‘§1,...,ğ‘§ğ‘›âˆ¼ğ‘, Hoeffdingâ€™s inequality [ 30] says that the empirical\nmean Ë†ğœ‡(Â®ğ‘§)=ğ‘›âˆ’1Ãğ‘›\nğ‘–=1ğ‘§ğ‘–converges to ğœ‡:\nPğ‘(Â®ğ‘§)\u0000|Ë†ğœ‡(Â®ğ‘§)âˆ’ğœ‡|â‰¤ğœ–\u0001â‰¥1âˆ’ğ›¿whereğ›¿=2ğ‘’âˆ’2ğ‘›ğœ–2, (11)\ni.e.,Ë†ğœ‡(Â®ğ‘§)is a good approximation of ğœ‡with high probability.\nIn our setting, given training valuation ğ›¼and a specification ğ¸=ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–inÂ¯ğ‘ƒ, we letğ‘§ğ›¼=\nJğ¸Kğ›¼andğ‘§âˆ—\nğ›¼=Jğ¸Kâˆ—\nğ›¼. Then,ğœ–-approximate soundness of ğ¸is equivalent to ğœ‡=Pğ‘(ğ›¼)(ğ‘§ğ›¼|ğ‘§âˆ—\nğ›¼)â‰¥1âˆ’ğœ–\nifğœ”=|, orğœ‡=Pğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼)â‰¥1âˆ’ğœ–ifğœ”=â‡’. That is,ğœ–-approximate soundness is equivalent\ntoğœ‡â‰¥1âˆ’ğœ–, whereğœ‡is the mean of a Bernoulli random variable ğ‘§ğ›¼that is a function of a random\nvariableğ›¼with distribution ğ‘(ğ›¼|ğ‘§âˆ—\nğ›¼)(ifğœ”=|) or the mean of a Bernoulli random variable ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼\nthat is a function of ğ›¼with distribution ğ‘(ğ›¼)(ifğœ”=â‡’). However, ğ‘§ğ›¼is potentially a complicated\nfunction ofğ›¼andğ‘(ğ›¼)is unknown, so ğœ‡is hard to compute directly. Instead, given i.i.d. samples\nğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘(ğ›¼), we can construct the samples ğ‘§ğ›¼1,...,ğ‘§ğ›¼ğ‘›andğ‘§âˆ—\nğ›¼1,...,ğ‘§âˆ—\nğ›¼ğ‘›and use them estimate ğœ‡:\nË†ğœ‡(Â®ğ›¼)=(Ãğ‘›\nğ‘–=1ğ‘§ğ›¼ğ‘–âˆ§ğ‘§âˆ—\nğ›¼ğ‘– Ãğ‘›\nğ‘–=1ğ‘§âˆ—ğ›¼ğ‘–ifğœ”=|\nÃğ‘›\nğ‘–=1ğ‘§âˆ—\nğ›¼ğ‘–â‡’ğ‘§ğ›¼ğ‘–ifğœ”=â‡’.\nThen, we can use (11) to bound the error of Ë†ğœ‡(Â®ğ›¼)â€”e.g., if Ë†ğœ‡(Â®ğ›¼)â‰¥1âˆ’ğœ–\n2and|Ë†ğœ‡(Â®ğ›¼)âˆ’ğœ‡|â‰¤ğœ–\n2with\nprobability at least 1âˆ’ğ›¿, thenğœ‡â‰¥1âˆ’ğœ–with probability at least 1âˆ’ğ›¿. However, this approach is\ninefficient since Hoeffdingâ€™s inequality is not tight for our setting. Instead, our verification algorithm\n(Appendix A.2) leverages a concentration inequality tailored to our setting (Appendix A.1). Finally,\nwe disucss how our approach can be used in the context of runtime monitoring (Appendix A.3).\nA.1 A Concentration Bound\nProblem formulation. Consider a Bernoulli distribution ğ‘=Bernoulli(ğœ‡)with unknown mean\nğœ‡âˆˆ[0,1]. Givenğœ–âˆˆR>0, our goal is to determine whether ğœ‡â‰¥1âˆ’ğœ–. For instance, a sample ğ‘§âˆ¼ğ‘\nmay indicate a desired outcome (e.g., a correctly classified input), in which case ğœ‡is the correctness\nrate andğœ–is a desired bound on the error rate; then, our goal is to check whether the ğœ‡meets the\ndesired error bound. More precisely, we want to compute ğœ“âˆˆ{0,1}such that\nğœ“â‡’(ğœ‡â‰¥1âˆ’ğœ–). (12)\nThat is,ğœ“is a sound overapproximation of the property ğœ‡â‰¥1âˆ’ğœ–(i.e.,ğœ“=1impliesğœ‡â‰¥1âˆ’ğœ–).\nTo compute such a ğœ“, we are given a training set of examples Â®ğ‘§=(ğ‘§1,...,ğ‘§ğ‘›)âˆˆ{ 0,1}ğ‘›, where\nğ‘§1,...,ğ‘§ğ‘›âˆ¼ğ‘areğ‘›i.i.d. samples from ğ‘. An estimator is a mapping Ë†ğœ“:Rğ‘›â†’R. We say such an\nestimator is approximately correct if it satisfies the condition (12)â€”i.e., Ë†ğœ“(Â®ğ‘§)â‡’(ğœ‡â‰¥1âˆ’ğœ–).\nIn general, we cannot guarantee Ë†ğœ“(Â®ğ‘§)is approximately correct due to the randomness in the\ntraining examplesÂ®ğ‘§.4Thus, we allow a probability ğ›¿âˆˆR>0that Ë†ğœ“(Â®ğ‘§)is not approximately correct.\n4Note that Ë†ğœ“is a deterministic function; the randomness of Ë†ğœ“(Â®ğ‘§)is entirely due to the randomness in the training data Â®ğ‘§.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n30 Bastani\nAlgorithm 3 Use statistical verification to check if ğ‘ƒis approximately correct.\nprocedure Verify (Â¯ğ‘ƒ,Â®ğ›¼,ğ›¿)\nğ‘šâ†|Î¦(ğ‘ƒ)|\nforğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–âˆˆÎ¦(Â¯ğ‘ƒ)do\nComputeÂ®ğ‘§Â®ğ›¼according to (14)\nCompute Ë†ğœ“(Â®ğ‘§Â®ğ›¼)according to (13) with (ğœ–,ğ›¿/ğ‘š)\nifÂ¬Ë†ğœ“(Â®ğ‘§Â®ğ›¼)then\nreturn false\nend if\nend for\nreturn true\nend procedure\nDefinition A.1. Givenğœ–,ğ›¿âˆˆR>0,Ë†ğœ“is(ğœ–,ğ›¿)-PAC ifPğ‘(Â®ğ‘§)\u0000Ë†ğœ“(Â®ğ‘§)â‡’(ğœ‡â‰¥1âˆ’ğœ–)\u0001â‰¥1âˆ’ğ›¿.\nIn other words, Ë†ğœ“(Â®ğ‘§)is approximately correct with probability at least 1âˆ’ğ›¿according to the\nrandomness in ğ‘(Â®ğ‘§). Our goal is to construct an (ğœ–,ğ›¿)-PAC estimator Ë†ğœ“(Â®ğ‘§).\nEstimator. Givenğœ–,ğ›¿âˆˆR>0, consider the estimator\nË†ğœ“(Â®ğ‘§)= 1(ğ¿(Â®ğ‘§)â‰¤ğ‘˜)whereğ‘˜=max(\nâ„âˆˆN\f\f\f\f\fâ„âˆ‘ï¸\nğ‘–=0\u0012ğ‘›\nğ‘–\u0013\nğœ–ğ‘–(1âˆ’ğœ–)ğ‘›âˆ’ğ‘–â‰¤ğ›¿)\n(13)\nand whereğ¿(Â®ğ‘§)=Ãğ‘›\nğ‘§âˆˆÂ®ğ‘§(1âˆ’ğ‘§). Intuitively, ğ¿(Â®ğ‘§)counts the number of errors, so we conclude the\ndesired property holds as long as ğ¿(Â®ğ‘§)is below a threshold ğ‘˜. This threshold is chosen so Ë†ğœ“is\n(ğœ–,ğ›¿)-PACâ€”in particular, ğ›¿upper bounds the CDF of the binomial distribution evaluated at ğ‘˜.\nTo compute the solution ğ‘˜in (13), we start with â„=0and increment it until it no longer satisfies\nthe condition. To ensure numerical stability, this computation is performed using logarithms. Note\nthatğ‘˜does not exist if the set inside the maximum in (13) is empty; in this case, we choose Ë†ğœ“(Â®ğ‘§)=0,\nwhich trivially satisfies the PAC property. We have the following; see Appendix B.1 for a proof:\nTheorem A.2. The estimator Ë†ğœ“is(ğœ–,ğ›¿)-PAC.\nA.2 Verification Algorithm\nProblem formulation. A verification algorithm ğ´:Â¯PÃ—Ağ‘›â†’{0,1}takes as input a complete\nprogram Â¯ğ‘ƒâˆˆÂ¯P, and a set of test valuations Â®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›)âˆˆAğ‘›, whereğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘are i.i.d.\nsamples from a distribution ğ‘(ğ›¼). For example, ğ‘(ğ›¼)may be the distribution of input images to an\nimage classifier encountered while running in production, that have been manually labeled using\ncrowdsourcing. Then, ğ´(Â¯ğ‘ƒ,Â®ğ›¼)âˆˆ{ 0,1}should indicate whether Â¯ğ‘ƒis approximately soundâ€”i.e.,\nwhether every expression ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–âˆˆÎ¦(Â¯ğ‘ƒ)is approximately sound. We say that ğ´issound\nifğ´(Â¯ğ‘ƒ,Â®ğ›¼)â‡’ Â¯ğ‘ƒâˆˆÂ¯Pâˆ—. As before, we cannot guarantee that ğ´is sound; instead, given ğ›¿âˆˆR>0, we\nwant this property to hold with probability at least 1âˆ’ğ›¿according to ğ‘(Â®ğ›¼).\nDefinition A.3. A verification algorithm ğ´:Â¯PÃ—Ağ‘›â†’{0,1}isğ›¿-probably approximately\nsound if for all Â¯ğ‘ƒâˆˆÂ¯P,Pğ‘(Â®ğ›¼)\u0000ğ´(Â¯ğ‘ƒ,Â®ğ›¼)â‡’ Â¯ğ‘ƒâˆˆÂ¯Pâˆ—\u0001â‰¥1âˆ’ğ›¿.\nAlgorithm. Our verification algorithm is shown in Algorithm 3. It check approximate correctness\nofÂ¯ğ‘ƒby checking approximate soundness of each ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–âˆˆÎ¦(Â¯ğ‘ƒ). It does so by allocating a\nğ›¿/ğ‘šprobability of failure for each expression, where ğ‘š=|Î¦(Â¯ğ‘ƒ)|is the number of such expressions.\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 31\nNext, we describe how our algorithm checks approximate soundness for a single expression\nğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–. Given a single test valuation ğ›¼âˆ¼ğ‘, consider the indicators\nğ‘§ğ›¼=Jğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–Kğ›¼ andğ‘§âˆ—\nğ›¼=Jğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}ğœ”\nğœ–Kâˆ—\nğ›¼.\nThat is,ğ‘§ğ›¼indicates whether ğœ™(Â¯ğ‘ƒâ€²,ğ‘)holds, andğ‘§âˆ—\nğ›¼indicates whether ğ‘„holds. Then, ğœ™(Â¯ğ‘ƒâ€²,ğ‘){ğ‘„}\nis approximately sound if and only if\nPğ‘(ğ›¼)(ğ‘§ğ›¼|ğ‘§âˆ—\nğ›¼)â‰¥1âˆ’ğœ–ifğœ”=| or Pğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼)â‰¥1âˆ’ğœ–ifğœ”=â‡’.\nNext, note that ğ‘§ğ›¼âˆˆ{0,1}is a Bernoulli random variable with mean ğœ‡=Pğ‘(ğ›¼)(ğ‘§ğ›¼|ğ‘§âˆ—\nğ›¼)(ifğœ”=|) or\nğœ‡=Pğ‘(ğ›¼)(ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼)(ifğœ”=â‡’). Thus, givenÂ®ğ›¼=(ğ›¼1,...,ğ›¼ğ‘›), whereğ›¼1,...,ğ›¼ğ‘›âˆ¼ğ‘are i.i.d. samples,\nÂ®ğ‘§Â®ğ›¼=(\n{ğ‘§ğ›¼|ğ›¼âˆˆÂ®ğ›¼âˆ§ğ‘§âˆ—\nğ›¼} ifğœ”=|\n{ğ‘§âˆ—\nğ›¼â‡’ğ‘§ğ›¼|ğ›¼âˆˆÂ®ğ›¼}ifğœ”=â‡’(14)\nis a vector of i.i.d. samples from Bernoulli(ğœ‡). Then, the estimator Ë†ğœ“(Â®ğ‘§Â®ğ›¼)in (13) with parameters\n(ğœ–,ğ›¿/ğ‘š)indicates whether ğœ‡â‰¥1âˆ’ğœ–with high probabilityâ€”i.e., if Ë†ğœ“(Â®ğ‘§Â®ğ›¼)=1, thenğœ‡â‰¥1âˆ’ğœ–\nholds with probability at least 1âˆ’ğ›¿/ğ‘šaccording to ğ‘(Â®ğ›¼). The following guarantee follows from\nTheorem A.2 by a union bound over expressions in Î¦(Â¯ğ‘ƒ):\nTheorem A.4. Algorithm 3 is ğ›¿-probably approximately sound.\nA.3 Runtime Monitoring\nOne challenge is that the specifications considered by our framework depend on the distribution of\nthe data. As a consequence, if this distribution changes, then our correctness guarantees may no\nlonger hold. This potential failure mode, called distribution shift [12,55], is a major challenge for\nmachine learning components. A key feature of our framework is that it can be used not only to\nsketch or verify the program before it is deployed, but also to continuously re-sketch the program\nbased on feedback obtained in production to account for potential distribution shift. The primary\nrequirement for using this approach is the need for feedbackâ€”i.e., continuing to collect labeled\nexamples in production. In some settings, this kind of feedback is naturally available; otherwise, a\nsolution is to manually label a small fraction of examplesâ€”e.g., using crowdsourcing [18].\nGiven ground truth labels for the input examples encountered in production, our verification\nalgorithm can be straightforwardly adapted to the runtime setting. In particular, our system collects\nexamples during execution; once it collects at least ğ‘examples, it re-runs verification or sketching.\nIt can do so after every subsequent example, or every ğ¾examples. Finally, we may want to discard\nan examples after ğ‘‡steps, both for computational efficiency and to account for the fact that the data\ndistribution may be shifting over time so older examples are less representative. Here, ğ¾,ğ‘,ğ‘‡âˆˆN\nare hyperparameters. Finally, we note that our statistical sketching algorithm can similarly be\nadapted to the runtime setting.\nB PROOFS\nB.1 Proof of Theorem A.2\nIt suffices to show that if ğœ‡<1âˆ’ğœ–, then Pğ‘(Â®ğ‘§)(Ë†ğœ“(Â®ğ‘§))<ğ›¿. First, note that since ğ‘§1,...,ğ‘§ğ‘›are i.i.d.\nBernoulli random variables with mean ğœ‡, then 1âˆ’ğ‘§1,...,1âˆ’ğ‘§ğ‘›are i.i.d. Bernoulli random variables\nwith meanğœˆ=1âˆ’ğœ‡. Their sum ğ¿(Â®ğ‘§)is a binomial random variableâ€”i.e., ğ¿(Â®ğ‘§)âˆ¼Binomial(ğ‘›,ğœˆ).\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n32 Bastani\nAlso, note that the condition ğœ‡<1âˆ’ğœ–is equivalent to ğœˆ>ğœ–. Thus, we have\nPğ‘(Â®ğ‘§)(Ë†ğœ“(Â®ğ‘§))=ğ‘˜âˆ‘ï¸\nğ‘–=0\u0012ğ‘›\nğ‘–\u0013\nğœˆğ‘–(1âˆ’ğœˆ)ğ‘›âˆ’ğ‘–\n<ğ‘˜âˆ‘ï¸\nğ‘–=0\u0012ğ‘›\nğ‘–\u0013\nğœ–ğ‘–(1âˆ’ğœ–)ğ‘›âˆ’ğ‘–\nâ‰¤ğ›¿,\nwhere the first inequality follows by standard properties of the CDF of the Binomial distribution.\nThe claim follows. â–¡\nB.2 Proof of Theorem 4.2\nFirst, define\nğ‘¡0\nğœ–=inf\nğ‘¡âˆˆRTğœ–.\nIntuitively, ğ‘¡0\nğœ–âˆˆRis the threshold that determines whether ğ‘¡isğœ–-approximately correct. In\nparticular, it is clear that ğ‘¡âˆˆTğœ–for allğ‘¡>ğ‘¡0\nğœ–andğ‘¡âˆ‰Tğœ–for allğ‘¡<ğ‘¡0\nğœ–; in general, ğ‘¡0\nğœ–âˆˆTğœ–may or\nmay not hold. Thus, it suffices to show\nPğ‘(Â®ğ‘§)(Ë†ğ‘¡(Â®ğ‘§)â‰¤ğ‘¡0\nğœ–)<ğ›¿.\nTo this end, note that the constraint ğ¿(ğ‘¡;Â®ğ‘§)â‰¤ğ‘˜in (4) implies\nâˆ‘ï¸\nğ‘§âˆˆÂ®ğ‘§1(ğ‘§>Ë†ğ‘¡(Â®ğ‘§)âˆ’ğ›¾(Â®ğ‘§))â‰¤ğ‘˜.\nThus, on event Ë†ğ‘¡(Â®ğ‘§)â‰¤ğ‘¡0\nğœ–, we have Ë†ğ‘¡(Â®ğ‘§)âˆ’ğ›¾(Â®ğ‘§)â‰¤ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§), so\nğ‘˜â‰¤âˆ‘ï¸\nğ‘§âˆˆÂ®ğ‘§1(ğ‘§>Ë†ğ‘¡(Â®ğ‘§)âˆ’ğ›¾(Â®ğ‘§))â‰¤âˆ‘ï¸\nğ‘§âˆˆÂ®ğ‘§1(ğ‘§>ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§)).\nAs a consequence, we have\nPğ‘(Â®ğ‘§)(Ë†ğ‘¡(Â®ğ‘§)â‰¤ğ‘¡0\nğœ–)â‰¤Pğ‘(Â®ğ‘§) âˆ‘ï¸\nğ‘§âˆˆÂ®ğ‘§1(ğ‘§>ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§))â‰¥ğ‘˜!\n.\nNext, sinceğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§)<ğ‘¡0\nğœ–, we haveğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§)âˆ‰Tğœ–â€”i.e.,\nğœ–<Pğ‘(ğ‘§)(ğ‘§>ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§))=Eğ‘(ğ‘§)( 1(ğ‘§>ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§))).\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 33\nIn other words, the random variables 1(ğ‘§>ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§))forğ‘§âˆˆÂ®ğ‘§are i.i.d. Bernoulli random variables\nwith meanğœˆ>ğœ–. Thus, we have\nPğ‘(Â®ğ‘§) âˆ‘ï¸\nğ‘§âˆˆÂ®ğ‘§1(ğ‘§>ğ‘¡0\nğœ–âˆ’ğ›¾(Â®ğ‘§))â‰¥ğ‘˜!\n=ğ‘˜âˆ‘ï¸\nğ‘–=0Pğ‘(Â®ğ‘§) âˆ‘ï¸\nğ‘§âˆˆÂ®ğ‘§1(ğ‘§>ğ‘¡0\nğœ–+ğ›¾(Â®ğ‘§))=ğ‘–!\n=ğ‘˜âˆ‘ï¸\nğ‘–=0Binomial(ğ‘–;ğ‘›,ğœˆ)\n<ğ‘˜âˆ‘ï¸\nğ‘–=0Binomial(ğ‘–;ğ‘›,ğœ–)\n=ğ‘˜âˆ‘ï¸\nğ‘–=0\u0012ğ‘›\nğ‘–\u0013\nğœ–ğ‘–(1âˆ’ğœ–)ğ‘›âˆ’ğ‘–\nâ‰¤ğ›¿,\nwhere the first inequality follows by standard properties of the CDF of the Binomial distribution.\nThe claim follows. â–¡\nB.3 Proof of Theorem 4.4\nFirst, we have the following classical inequality [30]:\nTheorem B.1. (Hoeffdingâ€™s inequality) We have\nPğ‘(Â®ğ‘§)\u0010\nğœ‡âˆ’Ë†ğœ‡(Â®ğ‘§)â‰¥ğ‘¡\u0011\nâ‰¤ğ‘’âˆ’2ğ‘›ğ‘¡2.\nNow, letting ğ‘¡=âˆšï¸ƒ\nlog(1/ğ›¿)\n2ğ‘›, we have\nPğ‘(Â®ğ‘§)\u0010\nğœ‡â‰¥Ë†ğœˆ(Â®ğ‘§)\u0011\nâ‰¤Pğ‘(Â®ğ‘§)\u0010\nğœ‡âˆ’Ë†ğœ‡(Â®ğ‘§)â‰¥ğ‘¡\u0011\nâ‰¤ğ‘’âˆ’2ğ‘›ğ‘¡2â‰¤ğ›¿,\nwhere the second-to-last inequality follows from Theorem B.1. The claim follows. â–¡\nC ADDITIONAL CASE STUDY: OBJECT DETECTION\nObject detection. We assume given a DNN component ğ‘“that given an image ğ‘¥, is designed to\ndetect people in ğ‘¥. Our formulation of object detection in this section is slightly different than the\nprevious setup. In particular, ğ‘‘âˆˆğ‘“(ğ‘¥)is a list of detections , which is a pair ğ‘‘=(ğ‘,ğ‘)including a\nbounding box ğ‘âˆˆR4that encodes the center, width, and height of a rectangular region of ğ‘¥, and a\nvalueğ‘âˆˆ[0,1]that is the predicted probability that ğ‘exists. In addition, the ground truth label\nğ‘¦âˆ—for an image ğ‘¥is a list of bounding boxes ğ‘âˆˆğ‘¦âˆ—. In general, we cannot expect to get a perfect\nmatch between the predicted bounding boxes and the ground truth ones. Typically, two bounding\nboxesğ‘,â€²match if have significant overlapâ€”in particular, their intersection-over-union satisfies\nIOU(ğ‘,ğ‘â€²)â‰¥ğœŒfor some threshold ğœŒâˆˆ[0,1]; we use a standard choice of ğœŒ=0.5. We denote that\nğ‘andğ‘â€²match in this sense by ğ‘\u001bğ‘â€². Finally,ğ‘approximately matches a bounding box in ğ‘¦âˆ—it\nğ‘\u001bğ‘â€²for someğ‘â€²âˆˆğ‘¦âˆ—, which we denote by ğ‘Ëœâˆˆğ‘¦âˆ—.\nExperimental setup. We use a pretrained state-of-the-art object detector called Faster R-CNN [ 56]\navailable in PyTorch [ 53], tailored to the COCO dataset [ 45]. There are multiple variants of Faster\nR-CNN; we use the most accurate one, termed X101-FPN with 3Ã—learning rate schedule. For each\npredicted bounding box, this model additionally outputs a predicted object category (e.g., â€œpersonâ€),\nas well as the size of the bounding box (â€œsmallâ€, â€œmediumâ€, and â€œlargeâ€). For most of our evaluation,\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n34 Bastani\ndef detect_ppl(x):\ny_hat = f(x)\nreturn [d.box for d in y_hat if check_det(x, d)]\ndef check_det(x, d, d_true=None)\nreturn d.score > ??1 {IOU(d.box, d_true) >= 0.5} [|, 0.05]\ndef detect_ppl_fast(x, y_true=None):\ny_hat = f_fast(x)\nno_ppl_score = 1.0 - max([d.score for d in y_hat])\nif no_ppl_score > ??2 {len(detect_ppl(x)) != 0} [|, 0.05]:\nreturn []\nelse:\nreturn detect_ppl(x)\ndef monitor_correctness(x):\nif np.random.uniform() <= 0.99:\nreturn\ny_hat = f_fast(x)\nno_ppl_score = 1.0 - max([d.score for d in y_hat])\npassert no_ppl_score > ??1 { len(detect_ppl(x)) != 0} [??3]\ndef monitor_speed(x):\ny_hat = f_fast(x)\nno_ppl_score = 1.0 - max([d.score for d in y_hat])\npassert no_ppl_score > ??1 {true} [??3]\nFig. 10. A program used to detect people in a given image ğ‘¥. Specifications are shown in green; curly brackets\nis the specification and square brackets is the value of ğœ–. The corresponding inequality with a hole in blue.\nHoles with the same number are filled with the same value.\nwe use â€œpersonâ€ and â€œlargeâ€. We specify alternative choices when we used them; in particular, we\nadditionally consider 6 of the 91 object categories: â€œpersonâ€ (10777 bounding boxes), â€œcarâ€ (1918\nbounding boxes), â€œtruckâ€ (414 bounding boxes), â€œmotorcycleâ€ (367 bounding boxes), â€œbikeâ€ (314\nbounding boxes), and â€œbusâ€ (283 bounding boxes). We split the COCO validation set into 2000\nsynthesis images and 3000 test images.\nCorrectness. Our goal is to detect a majority of people. In particular, we consider synthesizing a\nthresholdğ‘and selecting all bounding boxes with probability above ğ‘â€”i.e.,\nğ‘“(ğ‘¥,ğ‘)={ğ‘|(ğ‘,ğ‘)âˆˆğ‘“(ğ‘¥)âˆ§ğ‘â‰¥ğ‘}.\nThis task is more challenging to specify than our examples so far since ğ‘“(ğ‘¥)is a structured output.\nIn particular, we are not reasoning about whether ğ‘“(ğ‘¥)is correct with high probability with respect\ntoğ‘(ğ‘¥,ğ‘¦âˆ—), but whether bounding boxes (ğ‘,ğ‘)âˆˆğ‘“(ğ‘¥)are correct. Thus, we need a distribution\nğ‘(ğ‘|ğ‘¥)over bounding boxes ğ‘in an image ğ‘¥. Given such a distribution, our goal is to choose ğ‘so\nPğ‘(ğ‘¥,ğ‘¦âˆ—),ğ‘(ğ‘|ğ‘¥)(ğ‘Ëœâˆˆğ‘“(ğ‘¥,ğ‘)|ğ‘Ëœâˆˆğ‘¦âˆ—)â‰¥1âˆ’ğœ–, (15)\nwhereğ‘(ğ‘¥,ğ‘¦âˆ—)is the data distribution. Intuitively, this property says that ğ‘“(ğ‘¥,ğ‘)contains at least\na1âˆ’ğœ–fraction of ground truth bounding boxes. A reasonable choice for ğ‘(ğ‘|ğ‘¥)is the uniform\ndistribution over ğ‘“(ğ‘¥,0)â€”i.e., the set of all bounding boxes predicted by ğ‘“. One issue is when a\nground truth bounding box ğ‘âˆˆğ‘¦âˆ—is completely missing from ğ‘“(ğ‘¥,0); in this case, ğ‘would not\noccur inğ‘(ğ‘|ğ‘¥), so (15) would not count it as an error even though it is missing from ğ‘“(ğ‘¥,ğ‘)for\nanyğ‘. To handle this case, we simply add (ğ‘,0)toğ‘“(ğ‘¥)during synthesis for such bounding boxes\nğ‘â€”i.e.,ğ‘“predictsğ‘occurs with probability zero.\nThe program for achieving this goal is shown in the subroutine detect_ppl in Figure 10. We\nuse our algorithm in conjunction with the synthesis examples to synthesize the parameter ??1for\nthis program, using the default values ğœ–=ğ›¿=0.05and the object category â€œpersonâ€. In Figure 11,\nwe show the recall (red), desired lower bound on recall (blue), and precision (black) as a function of\n(a)ğœ–, (b)ğ›¿, and (c) the object category ğ‘¦. The trends are largely similar to beforeâ€”e.g., performance\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\nSynthesizing Machine Learning Programs 35\n0.800.850.900.951.00\n0.050.10.150.2Precision/Recallğœ€\n0.800.850.900.951.00\n0.050.10.150.2Precision/Recallğ›¿\n0.000.200.400.600.801.00\nPersonCarTruckMotorBikeBusPrecision/Recall\n(a) (b) (c)\n0.600.700.800.901.00\n0.050.10.150.2Precision/Recallğœ€\n0.800.850.900.951.00\n0.050.10.150.2Precision/Recallğ›¿\n0.000.200.400.600.801.00\nPersonCarTruckMotorBikeBusPrecision/Recall\n(d) (e) (f)\n04812\n0.050.10.150.2Time (Minutes)ğœ€\n04812\n0.050.10.150.2Time (Minutes)ğ›¿\n04812\nPersonCarTruckMotorBikeBusTime (Minutes)\n(g) (h) (i)\nFig. 11. For the slow model alone (top) and slow +fast model (middle), we show recall (red), the desired lower\nbound on recall (blue), and precision (black) as a function of (a,d) ğœ–, (b,e)ğ›¿, and (c,f) the object category ğ‘¦. For\nslow+fast (black), slow alone (red), and fast alone (green), we show running time as a function of (g) ğœ–, (h)ğ›¿,\nand (i) the object category ğ‘¦.\nvaries significantly with ğœ–and the object category, but not very much with ğ›¿. For (c), we use ğœ–=0.1\nto facilitate comparison to our fast program described below.\nImproving speed. We use a similar approach to improve speed as beforeâ€”i.e., given a fast object\ndetectorğ‘“fast, we want to use it to check the image, and only send it to the slow object detector ğ‘“if\nnecessary. A challenge compared to image classification is that the object detection model does not\noperate at the level of bounding boxes, which is the level at which we defined correctness, but at\nthe level of images. Thus, we cannot decide whether we want to run the slow model independently\nfor each detection ğ‘‘âˆˆğ‘“fast(ğ‘¥); instead, we have to make such a decision for an image ğ‘¥as a whole.\nIntuitively, we check whether the fast model returns anydetections in the given image ğ‘¥. To this\nend, we compute the maximum score ğ‘across all detections (ğ‘,ğ‘)âˆˆğ‘“fast(ğ‘¥)â€”i.e.,\nËœğ‘“fast(ğ‘¥)= max\n(ğ‘,ğ‘)âˆˆğ‘“fast(ğ‘¥)ğ‘.\nThen, we want to guarantee that ğ‘¦âˆ—=âˆ…if this score is below some threshold that ensures that\nğ‘¦âˆ—=âˆ…; this property is equivalent to its contrapositive\n(ğ‘¦âˆ—â‰ âˆ…)â‡’( 1âˆ’Ëœğ‘“fast(ğ‘¥)â‰¤ğ‘), (16)\n, Vol. 1, No. 1, Article . Publication date: October 2021.\n\n36 Bastani\nwhere the right-hand side of the implication is equivalent to ğ‘“fast(ğ‘¥)â‰¥1âˆ’ğ‘â€”i.e., the score is above\nthe threshold 1âˆ’ğ‘. As before, we cannot ensure this property holds with probability one, so instead\nwe use the high-probability variant\nPğ‘(ğ‘¥,ğ‘¦âˆ—)(1âˆ’Ëœğ‘“fast(ğ‘¥)â‰¤ğ‘|ğ‘¦âˆ—â‰ âˆ…)â‰¥ 1âˆ’ğœ–.\nThis approach is shown in the detect_ppl_fast subroutine in Figure 10. We note that this approach\ndoes not provide guarantees as strong as the ones for image classificationâ€”in particular, there is\na chance that the false negative images ğ‘¥ofğ‘“fast(i.e.,ğ‘¥does not satisfy (16)) will contain larger\nnumbers of ground truth bounding boxes compared to true positive images. Then, the recall at\nthe level of bounding boxes may be less than 1âˆ’2ğœ–. However, we find that it works well in\npractice; intuitively, ğ‘“fastis more likely to have false negative images that contain fewer ground\ntruth bounding boxes.\nForğ‘“fast, we use a variant of Faster R-CNN termed R50-FPN with 3Ã—learning rate schedule, which\nis the fastest variant available. Then, we synthesize the parameters of ??1and??2in Figure 10\nusing the synthesis examples. As before, all results are run on an Nvidia GeForce RTX 2080 Ti\nGPU. In Figure 11, we show the recall (red), desired lower bound on recall (blue), and precision\n(black) of our approach as a function of (d) ğœ–, (e)ğ›¿, and (f) the object category ğ‘¦. Similarly, we\nshow the running time (on the entire test set) of the combined program slow +fast (black), fast\nalone (green), and slow alone (red). As can be seen, our approach reduces running time by more\nthan 2Ã—except in the case of â€œpersonâ€ (28% reduction) and â€œtruckâ€ (45% reduction). The person\nspeedup is relatively small because so many of the images in the COCO dataset contain people.\nCompared to the image classification setting, we obtain a smaller speedup since the gap between\nthe fast and slow models is not as large, and also because we can only avoid using the slow model\nfor images that contain zero detections. Furthermore, comparing Figure 11 (c) and (f) (i.e., slow\nalone vs. slow+fast, respectively), for categories â€œcarâ€ and â€œtruckâ€, we suffer no loss in precision,\nthough we suffer a small loss in precision for the others.\nFinally, we note that in Figure 11 (e), for ğ›¿=0.15andğ›¿=0.2, the estimated recall falls slightly\nbelow the desired lower bound on recall. This result is most likely due to random chance, either\nbecause of randomness in the synthesis set or because these values are estimates based on a random\ntest set. In particular, 0.15is a fairly high failure probability (note that the results across ğ›¿are\ncorrelated, since we are using the same synthesis and test sets across all ğ›¿).\nRuntime monitoring. We use runtime monitors to check that our program meets the desired\nbounds both in terms of error rate (the subroutine monitor_correctness in Figure 10) and running\ntime (the subroutine monitor_speed in Figure 10). These approaches are the same as for image\nclassificationâ€”the correctness monitor checks that the error rate (i.e., ğ‘“fast(ğ‘¥)concludes there are\nno detections but ğ‘“(ğ‘¥)â‰ âˆ…) is below the desired rate ğœ–, and the running time monitor checks that\nğ‘“is not called too often (i.e., ğ‘“fast(ğ‘¥)concludes there are no detections sufficiently frequently).\nTo evaluate these monitors, we consider a shift from the default â€œlargeâ€ bounding boxes we use\nto â€œsmallâ€ and â€œmediumâ€. Intuitively, the smaller bounding boxes correspond to objects farther in\nthe background, which are harder to detect but also tend to be less important (e.g., an autonomous\ncar may not care as much about detecting far-away pedestrians). The trends are as before. First, we\nfind that the monitors correctly prove correctness when there is no shift. Second, we find that the\nrunning time does not increase due to the shift, so the running time monitor continues to prove\ncorrectness. Finally, our correctness monitor rejects correctness for the shift to â€œsmallâ€ bounding\nboxes; interestingly, it proves correctness for â€œmediumâ€ bounding boxes, which suggests that our\nsynthesized program generalizes to this case.\n, Vol. 1, No. 1, Article . Publication date: October 2021.",
  "textLength": 126376
}