{
  "paperId": "d7736c2ce268a4f70235c403b792cc75b52c92f6",
  "title": "Two-Layer Space-Oriented Partitioning for Non-Point Data",
  "pdfPath": "d7736c2ce268a4f70235c403b792cc75b52c92f6.pdf",
  "text": "1\nTwo-layer Space-oriented Partitioning for\nNon-point Data\nDimitrios Tsitsigkos, Panagiotis Bouros, Konstantinos Lampropoulos, Nikos Mamoulis, Manolis Terrovitis\nAbstract —Non-point spatial objects (e.g., polygons, linestrings, etc.) are ubiquitous. We study the problem of indexing non-point\nobjects in memory for range queries and spatial intersection joins. We propose a secondary partitioning technique for space-oriented\npartitioning indices (e.g., grids), which improves their performance significantly, by avoiding the generation and elimination of duplicate\nresults. Our approach is easy to implement and can be used by any space-partitioning index to significantly reduce the cost of range\nqueries and intersection joins. In addition, the secondary partitions can be processed independently, which makes our method\nappropriate for distributed and parallel indexing. Experiments on real datasets confirm the advantage of our approach against\nalternative duplicate elimination techniques and data-oriented state-of-the-art spatial indices. We also show that our partitioning\ntechnique, paired with optimized partition-to-partition join algorithms, typically reduces the cost of spatial joins by around 50%.\nIndex Terms —Indexing, query processing, spatial data, range query, spatial join\n✦\n1 I NTRODUCTION\nSPATIAL data management has been extensively studied,\nespecially for disk-resident data [1]. Nowadays, in most\napplications, collections of points or minimum bounding\nrectangles (MBRs) of extended objects can easily fit in the\nmemory of even a commodity machine. Although a number\nof scalable systems for spatial data have been developed\nin the past decade [2], [3], [4], [5], [6], the problem of\nin-memory management of large-scale spatial data has re-\nceived relatively little attention.\nIn this paper, we study the problem of indexing MBRs\nof non-point spatial objects (e.g., polygons, linestrings, etc.)\nin memory, for the efficient evaluation of the filter step of\nrange queries and spatial intersection joins. Large volumes\nof non-point data are ubiquitous, hence, their effective man-\nagement is always timely. Besides Geographic Information\nSystems, domains that manage big volumes of such data\ninclude graphics (e.g., management of huge meshes [7]),\nneuroscience (e.g., building and indexing a spatial model of\nthe brain [8]), and location-based analytics (e.g., managing\nspatial influence regions of mobile users in order to facilitate\neffective POI recommendations [9]).\nMotivation. Spatial access methods can be divided into\ntwo categories; space-oriented partitioning (SOP) and data-\noriented partitioning (DOP) approaches. Indices of the first\ncategory divide the space into spatially disjoint partitions. As\na result, objects that overlap with multiple partitions must\nbe replicated (or clipped) in each of them. DOP methods\nallow the extents of the partitions to overlap and ensure that\n•D. Tsitsigkos, K. Lampropoulos and N. Mamoulis are with the Department\nof Electrical & Computer Engineering, University of Ioannina, Greece.\nE-mail: {dtsitsigkos, klampropoulos, nikos }@cse.uoi.gr\n•P . Bouros is with the Institute of Computer Science, Johannes Gutenberg\nUniversity Mainz, Germany. E-mail: bouros@uni-mainz.de\n•M. Terrovitis is with the Information Systems Management Institute,\nResearch Center ‘Athena’, Greece.\nE-mail: mter@athenarc.grtheir contents are disjoint (i.e., each object is assigned to ex-\nactly one partition). For disk-resident data, DOP approaches\n(such as the R-tree [10] and its variants) are considered to be\nthe best, because they avoid data replication and they have\na balanced structure. However, SOP approaches (especially\ngrids) are gaining ground due to their efficiency in search\nand updates in main memory [11], [12], [13], [14], [15], [16].\nIn addition, query evaluation over grids is embarassingly\nparallelizable and SOP is widely used in distributed spatial\ndata management systems [3], [4], [5].\nIn this paper, we address an inherent problem that SOP\nindices have: potential duplicate query results. For exam-\nple, consider the rectangular objects depicted in Figure 1,\npartitioned using a 4 ×4 grid. Some objects are assigned to\nmultiple tiles. Given a query range (e.g., W), a replicated\nobject (e.g., r2) may be identified as query result multiple\ntimes (e.g., at tiles T0,T1,T4, and T5). The classic, but\nslow, approach to eliminate duplicates is to hash the query\nresults and identify duplicates at each bucket [17]. The\nstate-of-the-art approach [18], used in most big spatial data\nmanagement systems [6], computes, for each query result ri\nfound in a partition T, areference point of the intersection\nbetween riand the query window W(e.g., the upper-left\ncorner in Figure 1). If the reference point is inside T, then\nriis reported, otherwise it is ignored. Since the reference\npoint can only be inside one partition, no duplicate results\nare reported. Although this method avoids hashing, we\nstill have to bear the cost of finding duplicate results and\ncomputing the reference point for each of them.\nContributions. In Section 3, we propose a secondary par-\ntitioning technique for SOP indices, which improves their\nperformance significantly, by avoiding the generation and\nelimination of duplicate results. Our approach (i) is ex-\ntremely easy to implement, (ii) it can be used by any SOP\nindex, and (iii) it can be directly implemented in big spatial\ndata management systems [6]. In a nutshell, we divide the\nobjects which are assigned to each partition Tinto fourarXiv:2307.09256v1  [cs.DB]  18 Jul 2023\n\n2\nIntroductory examplesr1r2r3r4r5r6T0T0→ {r1,r2}T1→ {r2,r3}T2→ {r3}T4→ {r2}T5→ {r2}T6→ {r4}T7→ {r4}T10→ {r5}T11→ {r6}T15→ {r6}Wref. pointT1T2T3T4T5T6T7T8T9T10T11T12T13T14T15primarypartitioning\ntile primary partitioning secondary partitioning\nT0 {r1, r2} A={r1, r2}\nT1 {r2, r3} A={r3},C={r2}\nT2 {r3} C={r3}\nT4 {r2} B={r2}\nT5 {r2} D={r2}\nT6 {r4} A={r4}\nT7 {r4} C={r4}\nT10 {r5} A={r5}\nT11 {r6} A={r6}\nT15 {r6} B={r6}\nFig. 1: Example of partitioning and object classes\nWTiapply Wοn allobjectsin Tieliminate duplicatesWTiapply Wοn selected object classesin Tiprevious techniquesour approach\nFig. 2: Comparing our approach to previous work\nclasses A, B, C, D . Objects in class Abegin inside Tin both\ndimensions, objects in class Bstart inside Tin dimension x\nonly, objects in class Cstart inside Tin dimension yonly,\nand objects in class Dstart before Tin both dimensions.\nFigure 1 (column “secondary partitioning”) exemplifies how\nthe objects are divided into classes. During query evalua-\ntion, for each partition Twhich intersects the query range,\nwe access only the object classes in Tthat are guaranteed\nnot to produce duplicate results. For example, in tile T1of\nFigure 1, we will not access class C, because query Wstarts\nbefore T1in dimension x; i.e., any object in class CofT1that\nintersects W(liker2) should also intersect Win the previous\ntileT0. In Section 4.1, we explain in detail how range queries\nare evaluated by our scheme and show how redundant\ncomputations and duplicate checks can be avoided overall.\nFigure 2 illustrates, for range queries, the difference between\nour approach and the de-duplication process followed by\nprevious work [17], [18]; while all previous approaches\nevaluate queries on allobjects of each partition and then\neliminate possible duplicates, we process only a subset of\nobjects in each partition that cannot be duplicates and we\ndo not perform any de-duplication.Besides duplicate avoidance, our technique can also\nfacilitate reducing number of required comparisons per\nrectangle to at most one per dimension (Section 4.2). In Sec.\n5, we turn our focus to spatial intersection joins. We first\ndiscuss join evaluation for two datasets that are primarily\nindexed by identical grids. To avoid duplicate results, we\nshow that, for each tile, it suffices to evaluate 9 out of the\n16 possible joins between the pairs of secondary partitions\nin the tile. We also show how to optimize the join phase of\nPBSM, by specialized plane-sweep routines for the different\ncases of joined sub-partitions (classes) and by avoidance of\nredundant comparisons. Finally, we investigate join evalu-\nation when one or both joined inputs have already been\nindexed and how to process joins of datasets that have been\npartitioned using a different grid.\nIn Section 6, we evaluate our proposal experimentally\nusing large publicly available real datasets and synthetic\nones. Our experiments show that main-memory grids are\nsuperior to alternative SOP and DOP indices. More impor-\ntantly, we show that when we replace the state-of-the-art\nduplicate elimination technique [18] by our secondary par-\ntitioning technique, the performance of grid-based indexing\nis improved by up to a few times.\nThis paper extends of our work in [19] to address spatial\nintersection joins. For the interest of space, some content\nfrom [19] is omitted from this version (storage decom-\nposition optimization, handling of distance range queries,\nrefinement step, batch query processing).\n2 R ELATED WORK\n2.1 Indexing Non-point Spatial Objects\nSpatial queries are typically processed in two steps [1],\nfollowing a filtering-and-refinement framework. During filter-\ning, the query is applied on the MBRs, which approximate\nthe objects. During refinement , the exact representations of\nthe candidates are accessed and tested against the query\npredicate. Spatial indices are applied in the filtering step;\nhence, they manage MBRs instead of exact geometries.\nDepending on the nature of the partitioning, spatial\nindices are classified into two classes [20]. Space-oriented\npartitioning (SOP) indices divide the space into disjoint par-\ntitions and were originally designed for point data. A grid\n[21], which divides the space into cells (partitions) using\naxis-parallel lines, is the simplest SOP index. Hierarchical\nindices in this category are the kd-tree [22] and the quad-\ntree [23], [24]. SOP can also be used for non-point objects;\nin this case, objects whose extent overlaps with multiple\npartitions are replicated (or clipped) in each of them [25].\nDue to object replication, the same query results may be\ndetected in multiple partitions intersecting the query and\nresult deduplication should be applied [17]. Dittrich and\nSeeger [18] avoid duplicate results by computing a reference\npoint of the intersection area between each result and the\nquery range. If the reference point is inside the partition,\nthen the result is reported, otherwise it is eliminated.\nIndices based on data-oriented partitioning (DOP) allow\nthe extents of the partitions to overlap and ensure that\ntheir contents are disjoint (i.e., each object is assigned to\nexactly one partition); hence, there is no need for result de-\nduplication. Variants of the R-tree [10] (e.g., the R*-tree [26])\n\n3\nare the most popular methods in this class. The R-tree is\na disk-based, height-balanced tree, which generalizes the\nB+-tree in the multi-dimensional space and hierarchically\ngroups object MBRs to blocks. The CR-tree [27] is an op-\ntimized R-tree for the memory hierarchy. BLOCK [20] is a\nmain-memory DOP index, which uses a hierarchy of grids.\nR*-Grove [28] is a spatial partitioning, which builds on the\nsplit algorithm of R*-tree to define full blocks and balanced\npartitions for distributed big data.\nFollowing a recent trend on relational data [29], learned\nindices for spatial data were proposed [30], [31], [32], [33],\n[34]. These indices are not directly comparable to our work,\nas they handle point data (with no obvious extension to\nnon-point data) and their goal is to minimize the I/O cost.\n2.2 Spatial Joins\nA plane-sweep algorithm [35], [36] which computes rect-\nangle intersections, is the most common approach for in-\nmemory spatial joins. Brinkhoff et al. [37] present an forward\nsweep variant, which does not use any data structures. For\ndatasets too large to fit in memory, data partitioning has\nbeen used in a divide-and-conquer fashion, such that inputs\nare split into smaller subsets which can be then joined fast\nin memory. A partition from input Ris then joined with a\npartition from Sonly if their MBRs intersect. Partitioning-\nbased approaches are divided in two categories. Single-\nassignment, multi-join (SAMJ) methods assign each object\nto exactly one partition, similar to DOP; then, a partition\nfrom one input may be joined with multiple partitions from\nthe other. The R-tree Join algorithm [37] is a classic SAMJ\napproach, where both inputs are indexed by an R-tree.\nOn the other hand, multi-assignment, single-join (MASJ)\nmethods, inspired by SOP , use identical and disjoint spatial\npartitions for both datasets. An object is assigned to every\npartition it spatially intersects and each partition from one\ninput is joined with exactly one partition from the other.\nPartition-based Spatial Merge Join (PBSM) [38], the state-of-\nthe-art MASJ method [39], [40], divides the space by a\nregular grid. For each spatial partition, PBSM accesses the\nobjects from both inputs and performs the small join in\nmemory (e.g., using plane-sweep). Duplicate join results are\neliminated, using the reference point technique [18]). Other\nMASJ approaches include Spatial Hash Join [41] and Scalable\nSweeping-Based Spatial Join [36].\nIn-memory methods also utilize partitioning to acceler-\nate the join computation. TOUCH [42] first bulk-loads an\nR-tree for one of the inputs, using STR packing [43]. Then,\nall objects from the second input are assigned to buckets\ncorresponding to the non-leaf nodes of the tree. Finally, each\nbucket is joined with the subtree rooted at the corresponding\nnode, as in [44]. A comparison of spatial join algorithms for\nin-memory data [39] shows that PBSM and TOUCH perform\nbest. Tauheed et al. [45] suggest an analytical model for\nconfiguring the grid of PBSM-like join processing.\n2.3 Parallel and Distributed Data Management\nWith the advent of Hadoop, research on spatial data man-\nagement has shifted to developing distributed systems forspatial data [2], [3], [4], [5], [46], [47]. Spatial data in Hadoop-\nGIS [2] are partitioned using a hierarchical grid, wherein\nhigh density tiles are split to smaller ones. The nodes of the\ncluster share a global tile index which can be used to find\nthe HDFS files where the contents of the tiles are stored.\nSpatial queries are implemented as MapReduce workloads.\nSpatialHadoop [3], offers different options for partitioning\n(i.e., grid based, R-tree based, quad-tree based, etc.) The\nMaster node holds a global spatial index for the MBRs of\neach of the HDFS file blocks. A local index is built at each\nphysical partition and used by map tasks.\nSpark-based implementations of spatial data manage-\nment systems [4], [5], [47], [48] apply similar partitioning\napproaches. The main difference to Hadoop-based systems\nis that data, indices, and intermediate results are shared in\nthe memories of all nodes in the cluster as RDDs. Unlike\nSpatialSpark [47], GeoSpark (now, Apache Sedona) [5] and\nBeast [48] which are built on top of Spark, Simba [4] has its\nown native query engine and query optimizer, but does not\nsupport non-point geometries. Pandey et al. [6] conduct a\ncomparison between big spatial data analytics systems.\nDistributed spatial data management systems focus on\ndata partitioning and not on query evaluation at each parti-\ntion. Emphasis is given on scaling out, rather than reducing\nthe computational cost per node. On the other hand, we\nfocus on in-memory spatial data management and scaling\nup, by reducing the computational cost of spatial query\nevaluation. Still, our ideas are readily applicable in share-\nnothing systems, where each spatial partition is indepen-\ndent and does not need input from others to produce results.\n3 T WO-LAYER SPATIAL PARTITIONING\nIn this section, we present our secondary partitioning ap-\nproach for SOP spatial indices. Although our approach can\nbe used in any SOP index, we will present it in the context of\na regular grid, which divides the space into N×Mdisjoint\nspatial partitions, called tiles. An object ois assigned to a tile\nTiffMBR (o)andTintersect. For each tile T, we keep a list\nof (MBR, object-id) pairs that are assigned to T. The actual\ngeometries of objects are stored separately and retrieved on-\ndemand, based on their id’s. If the spatial distribution of\nobjects is not uniform and there are many empty tiles, to\nsave memory, we use a hash-table to access non-empty tiles\nbased on their coordinates.\nSecondary Partitioning. We propose that the (MBR, object-\nid) pairs at each tile are further divided into four classes\nA,B,C, and D(which are physically stored separately in\nmemory). Let r.x= [r.xl, r.xu]be the projection of MBR r\non the xaxis and r.y= [r.yl, r.yu]r’sy-projection. Now,\nconsider an MBR rwhich is assigned to tile T.\n•rbelongs to class A, if for every dimension d∈\n{x, y}, the begin value r.dlofrfalls into projection\nT.d, i.e., if T.dl≤r.dl.\n•rbelongs to class Bifr.xbegins inside T.x andr.y\nbegins before T.y, i.e., if T.xl≤r.xuandT.yl> r.y l.\n•rbelongs to class Cifr.xbegins before T.x andr.y\nbegins inside T.y, i.e., if T.xl> r.x landT.yl≤r.yl.\n•rbelongs to class Dif both its x- and y-projections\nbegin before T, i.e., if T.xl> r.x landT.yl> r.y l.\n\n4\nTTMini-joinsa)Define an order (direction) for each axis, for example x: left-to-right, y: top-to-bottomb)Given a cell (tile) c, the rectangles which are assigned to c are divided to 4 classes:•A: their x.startand y.startpoints are contained in the x-projection of c•B: their x.startptis contained in the x-projection of c, but their y.startis before c•C: their y.startptis contained in the y-projection of c, but their x.startis before c•D: their x.startand y.startpoints are both before cxyrectangles of type Arectangles of type Brectangles of type Crectangle of type DTT\nFig. 3: The four classes of rectangles assigned to a tile T.\nTABLE 1: Table of notations\nNotation Description\nW query window\nr.d= [r.dl, r.du]projection of rectangle rat dimension d∈ {x, y}\nTX secondary partition of tile Tholding MBRs in\nclass X∈ {A, B, C, D }\nprev(T, d) previous tile to Tin dimension d∈ {x, y}\nFigure 3 illustrates examples of rectangles in a tile Tthat\nbelong to the four different classes.1During data partition-\ning, when a rectangle ris assigned to a tile T, we identify its\nclass and place it to the corresponding division. Note that a\nrectangle can belong to class Aof just one tile, while it can\nbelong to other classes (in other tiles) an arbitrary number\nof times. We denote the secondary partitions of tile Twhich\nstore the MBRs of classes A,B,C, and D, byTA,TB,TC,\nandTD, respectively. Table 1 summarizes the notation used\nfrequently in the paper.\n4 R ANGE QUERY EVALUATION\nIn this section, we show how the secondary partitions at\neach tile Tcan be used to avoid the generation and elim-\nination of duplicate query results. We discuss the case of\nrectangular queries W(window queries) and focus on the\nfiltering step of the evaluation; details on non-rectangular\nqueries and on the refinement step can be found in [19].\nFirst, the tiles which intersect Win aN×Mregular\ngrid can be found in O(1)time, by algebraic operations.\nSpecifically, assuming that tile Ti,jis at the i-th row and\nat the j-th column of the grid, the tiles which intersect W\nare all tiles Ti,j, for which ⌊W.xl/N⌋ ≤i≤ ⌊W.xu/N⌋and\n⌊W.yl/M⌋ ≤j≤ ⌊W.yu/M⌋. We now explain in detail, for\neach tile Tthat intersects W, which classes of rectangles\nshould be accessed and which computations are necessary\nfor determining whether each rectangle rintersects W.\n4.1 Selecting relevant classes\nFor a tile T, letprev(T, d)denote the tile which is right\nbefore Tin dimension dand has exactly the same projection\nasTin the other dimension. For example, in Figure 4,\nprev(T, x)(resp. prev(T, y)) is the tile right before Tin\ndimension x(resp. y). Given a window query W, the\nfollowing lemmas determine the classes of rectangles in\nTwhich should be disregarded, because they can only\nproduce duplicate results.\nLemma 1. If the query range Wintersects tile TandWstarts\nbefore Tin dimension x, then secondary partitions TC\nandTDshould be disregarded.\n1. We conventionally assume that the xdimension is from left to right\nand the ydimension is from top to bottom.\n\u0001\u0005\u0002\u0005\u0003\u0005\u0004 \u0001\u0005\u0002 \u0001\u0005\u0002 \u0001\u0005\u0002\n\u0001\u0005\u0003\n\u0001\u0005\u0003\u0001\n\u0001\u0001\n\u0001\u0001\n\u0001W\u0002\u0004\u0005\u0003\u0006\b\u0004\u0007\u0006 \u0001\n\u0002\u0004\u0005\u0003\u0006\b\u0004\u0007\u0006\u0001 \u0002r.xl≤W.x ur.xl≤W.x u\nr.xl≤W.x u\nr.yl≤W.yu r.yl≤W.yu r.yl≤W.yu r.yl≤W.yur.xu≥W.x lr.xu≥W.x lr.xu≥W.x l\nr.yu≥W.ylr.yu≥W.yl r.yu≥W.yl\nno comparisons no comparisonsr.yu≥W.yl\nT prev(T, x)prev(T, y)\n\u0001\u0001\n\u0001\u0002Fig. 4: Examples of object classes and comparisons\nProof. Consider a rectangle rin class Cor class Dof\ntileT, i.e., r∈TCorr∈TD. Rectangle rshould also be\nassigned to the previous tile prev(T, x)toTin dimension x,\nbecause it belongs to class CorDofT. Ifrintersects Win\nT, then rshould also intersect Winprev(T, x), because W\nalso starts before Tin dimension x. Hence, examining and\nreporting rin tile Twould produce a duplicate, since the\nsame result can also be identified in tile prev(T, x). □\nLemma 2. IfWintersects tile TandWstarts before T\nin dimension y, then secondary partitions TBandTD\nshould be disregarded.\nLemma 2 can be proved by replacing xbyyandCby\nBin the proof of Lemma 1. The two lemmas are combined\nto exclude all classes B,C, and DifWstarts before Tin\nboth dimensions. To illustrate the lemmas, consider tile T\nin Figure 4. In addition, consider the MBRs of objects o1\nando2, which belong to secondary partitions TBandTC,\nrespectively. MBR (o1)should be ignored when processing\nTbecause it belongs to class BandWstarts before T\nin dimension y(Lemma 2). Indeed, MBR (o1)intersects\nWalso in tile prev(T, y)which is right above W. On the\nother hand, Wdoes not start before Tin dimension x,\ni.e., Lemma 1 does not apply for tile T. This means that\nMBR (o2)∈TCwill be found to intersect W. Figure 4\nshows, in the top-left corner of each tile Tintersected by\nW, the object classes in Tthat should be examined (the\nremaining classes can be disregarded). Observe that we have\nto consider all objects in just one tile (the one containing\npoint (W.xl, W.y l)). For the majority of tiles, we only have\nto examine secondary partition TA.\n4.2 Minimizing the number of comparisons\nWe now turn our attention to minimizing the number of\ncomparisons needed for each secondary partition that has to\nbe checked (i.e., those not eliminated by Lemmas 1 and 2).\nFor a rectangle rin a tile Tto intersect the query window\nW,r.xshould intersect W.x andr.yshould intersect W.y.\nHence, to test whether xintersects W, we need at most four\ncomparisons (i.e., randWdo not intersect, iff r.xu< W.x l\norr.xl> W.x uorr.yu< W.y lorr.yl> W.y u).\n\n5\nA direct observation that saves comparisons is that, if a\ntileTis covered by the window Win a dimension d, then\nwe do not have to perform intersection tests in dimension d\nfor all rectangles in the relevant secondary partitions in T.\nIn the example of Figure 4, we need to examine partitions\nTAandTCof tile T(Lemma 2). For each rectangle rin these\npartitions, we only have to verify if projections r.xandW.x\nintersect, because r.yandW.y definitely intersect (since T.y\nis covered by W.y).\nFor the dimension(s) where Tis not covered by W,\nthe following lemmas can be used to further reduce the\nnecessary comparisons.\nLemma 3. IfWends in tile Tand starts before Tin\ndimension d, then for a rectangle r∈T,rintersects W\nin dimension diffr.dl≤W.du.\nSymmetrically, we can show:\nLemma 4. IfWstarts in tile Tand ends after Tin dimension\nd, then for a rectangle r∈T,rintersects Win dimension\ndiffr.du≥W.dl.\nFor example, in tile Tof Figure 4, we only have to\ntest intersection in dimension x, as already explained. The\nintersection test can be reduced to a simple comparison,\ni.e.,rintersects Wiffr.xu≥W.xl, due to Lemma 4.\nTo demonstrate the impact of Lemmas 3 and 4, in each\ntile of the figure, we show the necessary comparisons. For\nthe two tiles in the center, no comparisons are required\nbecause all MBRs (in class A) are guaranteed to intersect\nW. For the remaining two tiles, which intersect the border\nofW, we only have to perform at most one comparison per\ndimension, because Weither starts or ends at these tiles\n(and some of these tiles are totally covered by Win one\ndimension). Contrast this to the four comparisons required\nin the general case for testing whether two rectangles (e.g.,\nrandW) intersect. Therefore, for range queries that cover\nmultiple tiles, we have:\nCorollary 1. For a window query Wthat intersects more\nthan one tile per dimension, at most two comparisons\nper rectangle in each relevant tile are required.\n4.3 Overall approach\nAlgorithm 1 describes the steps of window query evalua-\ntion. Given a window W, we first identify the tiles Tthat\nintersect Wby simple algebraic operations, as discussed in\nthe beginning of this section. Then, for each tile T∈ T ,\nwe identify the secondary partitions PTthat would not\nproduce duplicates, using Lemmas 1 and 2. For each such\nsecondary partition TX, we find all rectangles that intersect\nW, by applying the techniques of Section 4.2 to reduce the\nnecessary computations. Note that query evaluation at each\ntileT(and each secondary partition) is totally independent\nfrom others and, hence, it is embarrassingly parallelizable.\nAlthough we focus on indexing 2D MBRs in this paper,\nour secondary partitioning scheme can directly be used for\nminimum bounding boxes (MBBs) of arbitrary dimension-\nalitym. In a nutshell, we need 2mclasses to re-partition an\nm-dimensional tile T, which indexes m-dimensional MBBs.\nFor each tile T, if MBB rintersects T, there are two cases for\neach dimension d: either rbegins inside T(r.dl≥T.dl) or\nbefore T(r.dl< T.d l). Hence, there are 2mcases (classes) inAlgorithm 1 Window query evaluation (filtering step)\nRequire: gridG, query window W\n1:T= tiles in Gthat intersect W\n2:foreach tile T∈ Tdo\n3:PT= sub-partitions of Trelevant to W ▷ Lemmas 1 & 2\n4: foreach sub-partition TX∈ PTdo\n5: find all r∈TXthat intersect W ▷ Section 4.2\n6: end for\n7:end for\ntotal. Lemmas 1 and 2 can be generalized to a lemma that\nprunes all classes corresponding to cases of MBBs that begin\nbefore Tin each dimension d, ifWbegins before Tin that\ndimension. Lemmas 3 and 4 apply to any dimensionality.\n5 S PATIAL JOINEVALUATION\nWe now turn our focus to the evaluation of spatial intersec-\ntion joins. First, we discuss how our two-layer partitioning\ncan be adopted to natively compute a spatial join, while\navoiding the generation and elimination of duplicate results.\nThen, we elaborate on possible join strategies which use\ntwo-layer partitioning in different fashions. For illustration\npurposes, we discuss the above for regular grids; in Sec-\ntion 5.3, we consider other SOPs, e.g., the quad-tree.\n5.1 Two-layer Partitioning Join\nAssume that both inputs R,Sare indexed by our two-layer\npartitioning with identical grids. In the next subsection, we\ndiscuss the origins and details of such a setting, i.e., whether\nboth or one of R,Sare (re)-indexed online. Under this\nsetting, we can build upon the join phase of the PBSM al-\ngorithm [38] and apply a partition-to-partition join for each\npair of partitions from R,Sfrom the same tile. Assuming\nthat two partitions of size n,mare joined, the join cost using\nplane-sweep is O((n+m) log( n+m)), based on [36], [37].\n5.1.1 The Mini-joins Breakdown\nGiven a tile T, letRTandSTbe the partitions containing the\nobject rectangles from datasets RandS, respectively, that\nare assigned to T.RTis divided into rectangle classes RA\nT,\nRB\nT,RC\nT, and RD\nT, according to our two-layer partitioning\nscheme discussed in Section 3. Similarly, STis divided into\nSA\nT,SB\nT,SC\nT, and SD\nT. Hence, the spatial join RT▷ ◁ STcan\nnow be decomposed into 4·4 = 16 joins between classes of\nrectangles, i.e., RA\nT▷ ◁ SA\nT, RB\nT▷ ◁ SB\nT, RB\nT▷ ◁ SC\nT, . . . , RB\nT▷ ◁\nSA\nT, . . .. We call these class-to-class joins, mini-joins . Figure 5\nexemplifies the decomposition of the partition-to-partition\njoin inside a tile Tinto the 16 mini-joins.\nLooking deeper into these 16 cases, we can easily show\nthat 7 out of these mini-joins (the shaded cases in the figure)\nproduce only duplicate results, i.e., join results that will also\nbe reported in another tile. For example, if two rectangles of\nclass Bin tile Tintersect (i.e., the pair is contained in the\nresult of RB\nT▷ ◁ SB\nT), then they will definitely intersect also\nin another tile above T. We can also show that the remaining\n9 mini-joins produce only results that cannot be reported in\nany previous tile (in the xorydimension or in both), but\ncould be produced as duplicates in some of the 7 shaded\n\n6\nTTTTTTTTTTTTTTTT\nreportedin this tile\nreportedin this tile\nreportedin this tile\nreportedin this tilereportedin this tilereportedin this tile\nreportedin this tile\nFig. 5: Decomposition of tile T’s join into 16 mini-joins; R\nrectangles filled in light gray color.\njoins in a tile afterTin one or both dimensions. Hence, we\nnever evaluate the 7 shaded mini-joins and only evaluate the\n9 remaining without the need of duplicate elimination.\n5.1.2 Optimizations\nAny spatial join algorithm can be utilized to evaluate the set\nof 9 mini-joins on each tile T; even a nested-loops approach.\nFollowing previous work on spatial joins [36], [38], [40],\nwe adopt a plane-sweep join approach which is shown to\nperform significantly faster than nested-loops; specifically\nwe adopt the plane-sweep algorithm in [37]. Algorithm 2\nillustrates our plane-sweep mini-join. To apply the plane-\nsweep approach, the contents of each class are sorted on\nthe sweeping dimension (Line 1). Without loss of generality,\nwe consider xas the sweeping dimension for the rest of\nthis section, and so rectangles are sorted by r.xlands.xl.\nSorting can take place also during the construction of the\ntwo-layer scheme, if an input dataset is partitioned online.\nFor every pair (r, s)determined by the sweeping process\n(i.e., rectangles whose projections on xintersect), we test in\nLines 6 and 14, if the rectangles also intersect in the second\ndimension y; i.e., if r.yl≤s.yl≤r.yuors.yl≤r.yl≤s.yu.\nTo boost the computation of mini-joins, we next discuss how\nwe can save on the comparisons performed for (r, s)pairs,\ncapitalizing on our second layer of partitioning.\nAvoid unnecessary comparisons . There exist two ways to\nutilize the A,B,C,Dclasses in each tile Tfor avoiding\nunnecessary rectangle comparisons. To understand the first,\nconsider the RA\nT▷ ◁ SC\nTmini-join. By definition, all objects\nrectangles in SC\nTprecede the rectangles in RA\nT. In practice,\nthis means that we can apply a simplified version of plane-\nsweep for RA\nT▷ ◁ SC\nTwhich performs forward scans on\nRA\nTfor each rectangle in SC\nT, as the r.xl> s.x lholds by\ndefinition. This modification will save on unnecessary com-\nparisons between r∈RA\nTands∈SC\nTobjects and furtherAlgorithm 2 Plane-sweep mini-join\nRequire: classes of rectangles RTandST\n1:sortRTandSTbyr.xl ▷if not already sorted\n2:while RTandSTnot depleted do\n3: ifr.xl< s.x lthen\n4: s′←s\n5: while s′̸=nullandr.xu≥s′.xldo\n6: ifr.yl≤s′.yl≤r.yuors′.yl≤r.yl≤s′.yuthen\n7: output (r, s′) ▷update result\n8: end if\n9: s′←next rectangle in ST ▷scan forward\n10: end while\n11: else\n12: r′←r\n13: while r′̸=nullands.xu≥r′.xldo\n14: ifr′.yl≤s.yl≤r′.yuors.yl≤r′.yl≤s.yuthen\n15: output (r′, s) ▷update result\n16: end if\n17: r′←next rectangle in RT ▷scan forward\n18: end while\n19: end if\n20:end while\nAlgorithm 3 Reduced plane-sweep mini-join\nRequire: classes of rectangles RTandST\n1:sortRTbyr.xl ▷if not already sorted\n2:while STnot depleted do\n3: r′←r\n4: while r′̸=nullands.xu≥r′.xldo\n5: ifr′.yl≤s.yl≤r′.yuors.yl≤r′.yl≤s.yuthen\n6: output (r′, s) ▷update result\n7: end if\n8: r′←next rectangle in RT ▷scan forward\n9: end while\n10:end while\nwill allow us to avoid sorting the SC\nTclass. Algorithm 3\npresents this reduced version of the plane-sweep mini-\njoin. We can apply the same principle also for RA\nT▷ ◁ SC\nT,\nRC\nT▷ ◁ SA\nT,RA\nT▷ ◁ SD\nT,RD\nT▷ ◁ SA\nT,RB\nT▷ ◁ SC\nTandRC\nT▷ ◁ SB\nT.\nOverall, we do not need to sort the RC\nT,RD\nT,SC\nT,SD\nTclasses.\nBesides the plane-sweep process, we can also avoid\nunnecessary comparisons when considering the second di-\nmension (i.e., y). The idea is similar to Lemmas 3 and 4.\nTake as example, the RA\nT▷ ◁ SB\nTmini-join. For every pair\n(r, s)of intersecting object rectangles in x, determined by\nplane-sweep, the s.yl< r.y lcondition holds by definition.\nHence, to determine whether r,sintersect also in dimension\nywe only need to check the r.yl< s.y ucondition. The\nsame principle can be used for the RA\nT▷ ◁ SD\nT,RB\nT▷ ◁ SA\nT,\nRD\nT▷ ◁ SA\nT,RB\nT▷ ◁ SC\nTandRC\nT▷ ◁ SB\nTmini-joins. The\nfollowing lemma summarizes this optimization for every\nobject rectangle rin classes RB\nT,RD\nTwith sin classes SA\nT\nandSC\nT; the other case is symmetric.\nLemma 5. If an object rectangle rin tile Tstarts before the\ntile in the ydimension, i.e., T.yl> r.y l, then rintersects\nallsrectangles in Tthat start after T.ylwithr.yu> s.y l.\nAvoid redundant comparisons . To illustrate this optimiza-\ntion, consider the RA\nT▷ ◁ SC\nTmini-join and the rectangles\nin Figure 6(a). As already discussed, the reduced plane-\nsweep approach (Algorithm 3) does not sort the SC\nTclass, to\nevaluate this mini-join; by definition, the start s.xlfor their\n\n7\nTTRAT./SCT\n<latexit sha1_base64=\"g6R6upi5MkvLxZlLlXoV3fKhX+0=\">AAAB/HicbVDLTsMwEHR4lvIK9MjFokLiVCUFCY6FXjgW6Etq08hxndaqY0e2A4qq8itcOIAQVz6EG3+D2+YALSOtNJrZ1e5OEDOqtON8Wyura+sbm7mt/PbO7t6+fXDYVCKRmDSwYEK2A6QIo5w0NNWMtGNJUBQw0gpG1anfeiBSUcHrOo2JF6EBpyHFSBvJtwt3vSu/DruBeNSUwPte1a/7dtEpOTPAZeJmpAgy1Hz7q9sXOIkI15ghpTquE2tvjKSmmJFJvpsoEiM8QgPSMZSjiChvPDt+Ak+M0oehkKa4hjP198QYRUqlUWA6I6SHatGbiv95nUSHl96Y8jjRhOP5ojBhUAs4TQL2qSRYs9QQhCU1t0I8RBJhbfLKmxDcxZeXSbNccs9K5dvzYuU6iyMHjsAxOAUuuAAVcANqoAEwSMEzeAVv1pP1Yr1bH/PWFSubKYA/sD5/AEDHk94=</latexit>RAT./SCT\n<latexit sha1_base64=\"g6R6upi5MkvLxZlLlXoV3fKhX+0=\">AAAB/HicbVDLTsMwEHR4lvIK9MjFokLiVCUFCY6FXjgW6Etq08hxndaqY0e2A4qq8itcOIAQVz6EG3+D2+YALSOtNJrZ1e5OEDOqtON8Wyura+sbm7mt/PbO7t6+fXDYVCKRmDSwYEK2A6QIo5w0NNWMtGNJUBQw0gpG1anfeiBSUcHrOo2JF6EBpyHFSBvJtwt3vSu/DruBeNSUwPte1a/7dtEpOTPAZeJmpAgy1Hz7q9sXOIkI15ghpTquE2tvjKSmmJFJvpsoEiM8QgPSMZSjiChvPDt+Ak+M0oehkKa4hjP198QYRUqlUWA6I6SHatGbiv95nUSHl96Y8jjRhOP5ojBhUAs4TQL2qSRYs9QQhCU1t0I8RBJhbfLKmxDcxZeXSbNccs9K5dvzYuU6iyMHjsAxOAUuuAAVcANqoAEwSMEzeAVv1pP1Yr1bH/PWFSubKYA/sD5/AEDHk94=</latexit>s2s1s3s1s2s3\n(a)SC\nTunsorted (b) SC\nTsorted\nFig. 6: Avoiding redundant comparisons on RA\nT▷ ◁ SC\nT;R\nrectangle filled in light gray color.\nAlgorithm 4 Reduced plane-sweep mini-join with batch\noutputting\nRequire: classes of rectangles RTandST\n1:sortRTbyr.xl ▷if not already sorted\n2:sortSTbyr.xu ▷if not already sorted\n3:while STnot depleted do\n4: r′←r\n5: while r′̸=nullands.xu≥r′.xldo\n6: foreach rectangle s′after sinSTdo ▷batch\n7: ifr′.yl≤s′.yl≤r′.yuors′.yl≤r′.yl≤s′.yuthen\n8: output (r′, s′) ▷update result\n9: end if\n10: r′←next rectangle in RT ▷scan forward\n11: end for\n12: end while\n13:end while\ncontents precede the r.xlstart of all rectangles in RA\nT. Hence,\nassume that the SC\nTrectangles are examined in the s1,s2,s3\norder. Rectangles s1andrintersect in the xdimension as\ns1.xu> r.x lholds and so, they are next compared in the y\ndimension. Algorithm 3 will similarly determine that both\ns2ands3also intersect rinxby checking s2.xu> r.x land\ns3.xu> r.x l, respectively. However, since s2.xu> s 1.xu\nands3.xu> s 1.xuhold, the s1.xu> r.x lcheck for s1au-\ntomatically implies that s2.xu> r.x lands3.xu> r.x lalso\nhold. In other words, we conducted two extra comparisons\nto determine the intersecting (r, s2)and (r, s3)pairs. To\navoid such redundant comparisons, we can sort SC\nTbys.xu\nwhich will essentially allow us to determine intersecting\nrectangles in batches. Figure 6(b) illustrates this idea; all\nthree intersecting pairs can be determined after checking\nonlys1against r. Algorithm 4 modifies Algorithm 3 accord-\ningly. After identifying the first rectangle sthat intersects\ncurrent r′in the xdimension (Line 5), the algorithm pairs r′\nwith every rectangle s′that follows sinST(Line 6).\n5.2 Join Strategies\nWe last discuss different join strategies depending on the\n(pre)-existence of two-layer partitioning in the input. Fol-\nlowing the classification in [1], we consider three settings.\n5.2.1 Both Inputs Indexed\nUnder this setting, a two-layer partitioning already exists\non each input dataset R,Sto answer other types of spatial\nqueries, e.g., range queries. We distinguish between two\ncases with respect to the granularity of the pre-existing\ngrids. If the two grids are identical, we can directly apply\nthe mini-joins approach and its optimizations in Section 5.1.\nTA,B,C,DA,CA,CA,CAAAAAAAAAA,BA,BA,BFig. 7: Online grid transformation; Rpartitioned by a 2×2\ngrid, highlighted in blue, Spartitioned a 8×8grid, in black.\nIf the pre-existing grids have different granularities,\nthen the mini-joins approach is not directly applicable. A\nstraightforward solution is to re-index one of the input\ndatasets, e.g. R, by creating a temporary two-layer parti-\ntioning with a grid granularity that matches the grid on S,\nsimilar to [49]. In this context, a key question that naturally\narises is which input we should re-index. Typically, we\ncould select the dataset with either the smallest cardinality\nor the smallest average object extent, because such a deci-\nsion is expected to incur the lowest online indexing cost. We\nelaborate on this decision in our experimental analysis.\nAs an alternative, we also devise a new solution which\ncompletely eliminates the need to decide which input\nshould be re-indexed and also significantly reduces the\nonline indexing costs. For this purpose, the granularity of\nthe pre-existing grids must be in a power of 2. If so, we\ncan always define an online transformation of the finer\ngrid to the coarser, by means of standard window range\nqueries. Figure 7 exemplifies this transformation when R\nis partitioned by a 2×2grid (colored in blue), and Sby\na8×8grid (in black). After overlaying the two grids, we\nobserve that every tile Tin the Rgrid overlaps a collection\nof exactly 16 adjacent tiles from the Sgrid. Therefore, to re-\npartition Sto the 2×2grid of R, it suffices to compute the\nwindow queries defined by all tiles in the Rgrid; the key\nidea is to determine the contents of the new SA\nT,SB\nT,SC\nT\nandSD\nTclasses based on the results of every Twindow\nquery. For this purpose, we can utilize the original two-\nlayer partitioning on S. Specifically, consider the shaded\ntileTfrom the Rgrid in Figure 7. Similar to Figure 4, we\nmark the relevant classes for each tile from the original S\ngrid that overlaps with the window query based on T, as\ndiscussed in Section 4. We can now construct SA\nTby unifying\nthe objects contained in the Aclass of all overlapping tiles.\nForSB\nT, we consider only the contents of the Bclass inside\nthe top border overlapping tiles, while for SC\nT, the left\nborder overlapping ones. Finally, SD\nTis identical to the D\nclass inside the top left corner overlapping tile. The above\nprocess can be generalized for any two pre-existing grids of\ngranularity n×nandm×m, where n > m andn,mare\npowers of 2. Every tile in the second, coarser grid defines a\nwindow query that overlaps with exactly (n/m)2tiles from\nthe first, finer one.\nWe developed two variants for the above transformation.\n\n8\nThe first constructs a temporary two-layer partitioning on\ninput Sby matelializing the contents of each new SA\nT,SB\nT,\nSC\nTandSD\nTclasses. After this, we can directly utilize the\nmini-joins approach in Section 5.1 to compute the R ▷ ◁ S\nspatial join. In contrast, the second variant never actually\nconstructs this new two-layer scheme on input S. Instead,\nwe adjust the joining process in Section 5.1 to determine\non-the-fly which tiles from the original grid on Sshould\nbe used in the mini-joins. Specifically, the RA\nT▷ ◁ SA\nTis\nfurther decomposed to (n/m)2mini-joins, i.e., RA\nT▷ ◁ SA\nT=S\niRA\nT▷ ◁ SA\nTi, where Tidenotes one of the (n/m)2tiles from\nthe original Sgrid overlapping with tile Tfrom the Rgrid.\nIn the same spirit, RA\nT▷ ◁ SB\nT,RA\nT▷ ◁ SB\nT,RB\nT▷ ◁ SC\nTand\nRC\nT▷ ◁ SB\nTare decomposed into (n/m)mini-joins, while\nRB\nT▷ ◁ SA\nT,RC\nT▷ ◁ SA\nTandRD\nT▷ ◁ SA\nTinto (n/m)2. In\nSection 6, we compare the two variants and break down\ntheir total execution time.\n5.2.2 One Input Indexed\nUnder this setting, a two-layer partitioning already exists\nonly for one of the input datasets; without loss of generality,\nassume for S. In this case, there exist two alternative ap-\nproaches for computing the R ▷ ◁ S spatial join. The first is\nto construct a temporary two-layer partitioning on Rwith a\ngrid of identical granularity to the grid on S, such that we\ncan directly apply the joining process in Section 5.1. Despite\nits simplicity, this approach may exhibit high total execution\ntimes because of the online indexing cost.\nAlternatively, we can adopt an index-based join ap-\nproach. According to this, we scan the contents of the\nRinput and probe the index on S. Specifically, we issue\na window range query for each object rectangle rinR\nwhich is evaluated using the two-layer partitioning on S. To\nfurther enhance the performance of this approach, we can\nexamine the objects in Raccording to their position in space,\ninstead in a random order, e.g., by first partitioning them\nonline with a grid or using a space filling curve. This way,\nwindow queries for objects in Rthat overlap neighboring\nparts of the Sgrid are evaluated in nearby timestamps,\nimproving the cache locality.\n5.2.3 No Input Indexed\nUnder this setting, none of the input datasets R,Sis\nindexed. In this case, we can partition both inputs under\nidentical grids to construct two temporary two-layer par-\ntitioning schemes and then directly apply the mini-joins\napproach from Section 5.1.\nSince both inputs are indexed online, we can further\nenhance the join process by adopting a specialized storage\noptimization. Note that such an optimization cannot be\nutilized for the settings discussed in the previous sections, as\nat least one of the two-layer schemes used for the join, pre-\nexists in order to evaluate other types of queries. Essentially,\nif we enforce this optimization, the resulting two-layer par-\ntitioning will no longer be able to fulfil its original purpose.\nConventionally, each rectangle ris stored as a quintu-\nple⟨id, r.x l, r.xu, r.yl, r.yu⟩. Assuming xas the sweeping\ndimension (the other case is symmetric), r.ylis never needed\nfor classes BandDwhen we check whether two rectangles\nintersect also in the ydimension, i.e., in Lines 6 and 14\nof Algorithm 2, Line 5 of Algorithm 3 and in Line 7 ofTABLE 2: Real-world datasets used in the experiments\ndataset type cardinalityavg. relative [%]\nx-extent y-extent\nROADS linestrings 19M 0.007 0.013\nEDGES polygons 69M 0.003 0.005\nZCTA5 polygons 33K 1.7 2.052\nTIGER mixed 97M 0.004 0.008\nAlgorithm 4. This is because all contained rectangles start\nbefore the start of the tile in y. In fact, for class D, we do not\nneed r.xleither, since Dis only joined to an Aclass from the\nother input Sand its contents always precede those Srect-\nangles in both dimensions. Hence, a temporary two-layer\npartitioning stores all information for rectangles in classes\nA,Cbut⟨id, r.x l, r.xu, r.yu⟩forBand⟨id, r.x u, r.yu⟩forC,\nwhich reduces the online partitioning costs.\n5.3 Extension to other SOPs\nThe two-layer partitioning join in Section 5.1 is directly\napplicable to any SOP , provided that identical partitions of\nthe space (defined either offline or online) are considered\nfor both inputs. Similarly, the index-based join approach\ncan be applied when one of the inputs is indexed any SOP ,\nenhanced with our two-layer partitioning. Lastly, when both\ninputs are indexed by the same SOP but under a different\nset of partitions, the re-partitioning approach in Section 5.2.1\ncan be applied when there exists an alignment among the\npartitions; e.g., in quad-trees, for each a quadrant (of a\ncoarse granularity) in one input that entirely covers a set\nof finer quadrants from the other.\n6 E XPERIMENTAL EVALUATION\nOur analysis was conducted on a machine with 384 GBs of\nRAM and a dual Intel(R) Xeon(R) CPU E5-2630 v4 clocked at\n2.20GHz running CentOS Linux 7.6.1810. All methods were\nimplemented in C++, compiled using gcc (v4.8.5) with flags\n-O3,-mavx and-march=native .\nDatasets. We experimented with publicly avail-\nable Tiger 2015 datasets [3], downloaded from\nhttp://spatialhadoop.cs.umn.edu/datasets.html. Their\nstatistics are summarized in Table 2. The fourth dataset\nresulted by merging all polygon and linestring Tiger 2015\nobjects. The objects in each dataset were normalized so\nthat the coordinates in each dimension take values inside\n[0,1]. The last two columns of the table are the relative\n(over the entire space) average length for every object’s\nMBR at each axis. To test the robustness of our index, we\nalso experimented with synthetically generated datasets\nwith rectangles of uniform and zipfian spatial distribution.\nTable 3 shows the parameters used in data generation. The\ncoordinates in each dimension take values in [0,1]and\nall generated rectangles in a dataset have the same area.\nThe width to height ratio of each rectangle was generated\nrandomly in the range [0.25,4]to avoid unnaturally narrow\nrectangles.\nMethods . We implemented our secondary partitioning ap-\nproach denoted by 2-layer as part of a main-memory regular\ngrid spatial index. For each tile Tof the grid, 2-layer divides\n\n9\nTABLE 3: Synthetic datasets (MBRs) used in the experiments\nparameter values default\ncardinality 1M, 5M, 10M, 50M, 100M 10M\narea 10−∞,10−14,10−12,10−10,10−8,10−610−10\ndistribution Uniform or Zipfian ( a= 1) —\nTABLE 4: Test methods and their throughput (range queries)\ntype index detailsthroughput [queries/sec]\nROADS EDGES\nSOP2-layer Section 3 30981 9406\n1-layer grid with [18] 12597 4403\nquad -tree [23] using [18] 10949 3640\nquad -tree,2-layer [23] + Section 3 16883 5831\nDOPR-tree [43] (boost.org) 7888 2011\nR*-tree [26] (boost.org) 6415 1610\nBLOCK [20] <1 <1\nMXCIF quad -tree [50] 8 2\nthe (MBR, id) pairs assigned to Tinto four secondary\npartitions ( TA,TB,TC,TD), as discussed in Section 3.\nWe considered both SOP and DOP competitors to our\n2-layer , summarized in Table 4. First regarding SOPs, the\n1-layer index is an in-memory grid with identical primary\npartitioning as our 2-layer , but uses the reference point\napproach [18] to perform duplicate elimination. Comparing\n1-layer to2-layer shows the benefit of our secondary parti-\ntioning scheme and the techniques we propose in Section 4\nfor duplicate avoidance and minimization of comparisons.\nThe second SOP competitor is a quad -tree implementation,\nwhich assigns each object MBR to all quadrants it intersects.\nAs soon as the contents of a quadrant exceed a predefined\nmaximum capacity (set to 1000, after tuning), the quadrant is\nsplit to four; the rectangles are then re-distributed in the four\ngenerated children and replicated if they span the division\nborders. To avoid extensive splitting of quad -tree nodes in\nthe case of extremely skewed data, a maximum tree depth\n(=12) is set. The reference point approach [18] is also used\nfor duplicate elimination. We also implemented a version\nofquad -tree that uses our approach instead of [18]. Regard-\ning DOPs, we used two implementations of in-memory R-\ntrees from the highly optimized Boost. Geometry library\n(boost.org)2; an STR-bulkloaded [43] (denoted for simplicity\nasR-tree) and an R*-tree [26]. Both trees have a fanout of\n16 for inner and leaf nodes; this configuration is reported\nto perform the best (we also confirmed this by testing).\nThe next DOP competitor is BLOCK ; the implementation\nwas kindly provided by the authors of [20]. Finally, we\nalso implemented and tested the MXCIF quad -tree for non-\npoint data [50], which stores each object at the lowest-level\nquadrant which covers the object. All compared methods\nare listed in Table 4.\nQueries . To study the evaluation of range queries, we\nexperimented with window queries which apply on non-\nempty areas of the map (i.e., they always return results). We\nvary their relative area as a percentage of the entire data\nspace, inside the {0.01,0.05,0.1,0.5,1}value range (default\nvalue 0.1% of the area of the map). Queries on synthetic\ndata follow the same spatial distribution as the data.\n2. Recent benchmarks [51] showed the superiority of Boost.Geometry\nR-tree implementations over the ones in libspatialindex.orgROADS EDGES\n 0 0.5 1 1.5 2 2.5 3 3.5\n0.5 1 2 3456Index time [secs]1-layer\n2-layer\n 0 1 2 3 4 5 6 7\n0.5 1 2 3456Index time [secs]1-layer\n2-layer\npartitions per dimension [ ×1000] partitions per dimension [ ×1000]\n 0 5000 10000 15000 20000 25000 30000 35000 40000\n0.5 1 2 3456Throughput [queries/sec]\n 0 2000 4000 6000 8000 10000 12000 14000\n0.5 1 2 3456Throughput [queries/sec]\npartitions per dimension [ ×1000] partitions per dimension [ ×1000]\nFig. 8: Building & tuning grid-based indices (range queries)\n6.1 Indexing and Tuning\nWe first investigate the index building cost and tuning. The\nfirst two plots of Figure 8 compare the indexing times of\n1-layer and 2-layer on ROADS and EDGES, while varying\nthe granularity of the grid partitioning. Indexing sizes are\nomitted due to lack of space. Both indices occupy the same\nspace, regardless of employing the secondary partitioning or\nnot, as exactly the same number of object MBRs (originals\nand replicas) are stored. Note that the index sizes do not\ngrow too much with the grid granularity, from 0.8 to 1.2GBs\nfor ROADS, from 2.5 to 3GBs for EDGES, which means that\nMBR replication is not excessive. Naturally, the indexing\ncost for both indices rises as we increase the granularity of\nthe grid. In terms of indexing time, 2-layer is only slightly\nmore expensive than 1-layer . The construction costs for the\ntwo quadtrees (not shown) are 7s and 28.2s, respectively,\nand their sizes are similar to those of the corresponding\n1-layer indices. The sizes of the packed R-trees (not shown)\nare about the same as the sizes of the corresponding 1-layer ,\n2-layer indices, indicating that the replication ratio of our\nindex is low. In addition, the bulk loading costs of the R-\ntrees are 5.2s and 19.5s for the two datasets, respectively,\nboth higher than the construction cost of 2-layer .\nThe last two plots of Figure 8 compare the window query\nthroughputs of 1-layer and 2-layer for different grid gran-\nularities. The two methods achieve their best throughputs\nwhen several thousands of partitions per dimension are\nused. Observe that employing our secondary partitioning\nsignificantly enhances query processing; 2-layer always out-\nperforms 1-layer by a wide margin (2x–3x). It is worth noting\nthat 1-layer uses the comparisons reduction optimization\ndescribed in Section 4.2, meaning that the performance\ngap is due to our secondary partitioning. Specifically, our\napproach outperforms the state-of-the-art reference point\nmethod for result deduplication [18] used in 1-layer by a\nfactor of at least 2. For a wide range of granularities (i.e.,\n\n10\nTABLE 5: Best granularities (partitions per dimension); in\nparenthesis, the power of 2 used for the transformation-\nbased methods in Figure 12.\nindex ROADS EDGES ZTCA5 TIGER Uniform Zipfian\n1-layer 1000 3000 not used 1000 500 3000\n2-layer 3000 ( 211)5000 ( 212)400 (28)5300 450 3000\nR-tree\n quad -tree\n 1-layer\n 2-layer\nROADS\n101102103104105106\n0.01 0.05 0.1 0.5 1Throughput [queries/sec]\n101102103104105106\n[0,0.01](0.01,0.1](0.1,1] (1,100]Throughput [queries/sec]\nquery relative area [%] query selectivity [%]\nEDGES\n101102103104105\n0.01 0.05 0.1 0.5 1Throughput [queries/sec]\n101102103104105\n[0,0.01](0.01,0.1](0.1,1] (1,100]Throughput [queries/sec]\nquery relative area [%] query selectivity [%]\nTIGER\n101102103104105\n0.01 0.05 0.1 0.5 1Throughput [queries/sec]\n101102103104105\n[0,0.01](0.01,0.1](0.1,1] (1,100]Throughput [queries/sec]\nquery relative area [%] query selectivity [%]\nFig. 9: Range queries: real datasets\n2000 to 5000 partitions per dimension), the throughput of\nboth methods does not change significantly meaning that\nfinding the best granularity is not crucial to query perfor-\nmance. We observed similar trends on the TIGER and on\nthe synthetic datasets (not shown due to lack of space). As\na rule of the thumb, we can set the extent of a grid cell in\neach dimension, 10 times larger than the average extent of\nthe objects in that dimension. For the rest of our analysis, we\nused the best granularity for 1-layer and2-layer , see Table 5.\n6.2 Range Query Performance\nWe next compare our two-layer partitioning against com-\npetition on query throughput. Table 4 reports the through-\nput (queries/sec) achieved by each index for 10K window\nqueries (of average relative area 0.1% of the map) on ROADS\nand EDGES. 2-layer outperforms the competition by a wide\nmargin. Note that the performance of quad -tree is greatly\nimproved by our secondary partitioning, which confirmsthat other SOPs besides grids can benefit from our approach.\nHowever, as 2-layer is consistently more efficient than the\nquad -tree using our approach, we do not consider the latter\nin the rest of the experiments. R-tree is the most efficient\nDOP competitor, outperforming R*-tree (from the same\nlibrary). BLOCK takes seconds to evaluate range queries\non our datasets, which can be attributed to the fact that it\nis implemented for 3D objects. Similar, MXCIF quad -tree is\norders of magnitude slower than the R-tree. Under these,\nin the rest of the tests we only include 1-layer ,R-tree and\nquad -tree indices as the key competitors to our 2-layer .\nThe first two columns of Figure 9 show the throughput of\nthe four competitors for window queries of varying relative\narea and selectivity on the three real datasets. For the experi-\nments of the second column, we collected the runtimes of all\nqueries (regardless of their areas) and averaged them after\ngrouping them by selectivity. Naturally, query processing\nis negatively affected by both factors. We also observe that\n2-layer is consistently much faster than the competition on\nall datasets and query areas. For each query, 2-layer accesses\nthe relevant partitions very fast (without the need of travers-\ning a hierarchical index) and manage to drastically reduce\nthe required number of computations. Figure 10 compares\nall methods for window queries on the synthetic datasets\n(for grid granularities, see Table 5). In these experiments, we\nadditionally vary the database size and the areas of the data\nobjects. In terms of query throughput w.r.t. query area and\nselectivity, the trends are similar as those for the real data.\nIn addition, the data cardinality does not affect the relative\nperformance of the methods. Finally, we observe that 2-layer\nis more robust to the area of the data objects compared to\nthe competition. As the area grows, the replication to tiles\nincreases, and so 1-layer andquad -tree have to compute and\neliminate more duplicate results. In contrast, 2-layer , with\nthe help of our secondary partitioning, completely avoids\nthe generation and elimination of duplicate results. On the\nother hand when the data area shrinks ( 10−∞represents the\ncase of extremely small rectangles that resemble points), the\nreplication to tiles decreases. 1-layer and the quad -tree still\nneed to perform the extra comparison of the de-duplication\nreference test, which explains the stable advantage of 2-layer .\n6.3 Updates Performance\nWe also demonstrate the superiority of our two-layer parti-\ntioning in updates. For this purpose, we conducted an ex-\nperiment using the real datasets, where we first constructed\nthe index by loading 90% of the data in batch and then\nmeasuring the cost of incrementally inserting the last 10%\nof the data. Table 6 compares the total update costs of the\ncompetitor indices. R-tree is two orders of magnitude slower\nthan the baseline 1-layer index and the cost of updates on\n2-layer is only a bit higher compared to the update cost on\n1-layer . Updates on quad -tree are also slower compared to\n1-layer and2-layer , due to the tree traversal.\n6.4 Spatial Join Performance\n6.4.1 Two-layer Partitioning Join\nWe first study the impact of our second layer of partitioning\nto the join computation. As discussed in Section 5.1, we as-\n\n11\nR-tree\n quad -tree\n 1-layer\n 2-layer\nUniform (default) Zipfian (default)\n102103104105106\n0.01 0.05 0.1 0.5 1Throughput [queries/sec]\n101102103\n0.01 0.05 0.1 0.5 1Throughput [queries/sec]\nquery relative extent [%] query relative extent [%]\n102103104105106\n  1  5 10 50 100Throughput [queries/sec]\n100101102103104\n  1  5 10 50 100Throughput [queries/sec]\ndata cardinality [ ×106] data cardinality [ ×106]\n103104105\n  10-∞ 10-1410-1210-1010-810-6Throughput [queries/sec]\n100101102103\n  10-∞ 10-1410-1210-1010-810-6Throughput [queries/sec]\ndata rectangle area data rectangle area\nFig. 10: Range queries: synthetic datasets\nTABLE 6: Total update cost (sec)\ndataset R-tree quad -tree 1-layer 2-layer\nROADS 5.34 0.76 0.059 0.068\nEDGES 19.8 2.89 0.267 0.382\nTIGER 33.91 4.63 0.459 0.634\nsume that both input datasets are already indexed and that\nidentical grids exist as the first layer of partitioning. We im-\nplemented the mj, base method on top of our 2-layer scheme,\nas our basic mini-joins solution which adopts the mini-joins\nbreakdown from Section 5.1.1 and the plane-sweep join\napproach from Section 5.1.2. To demonstrate the effect of\nthe comparison-saving optimizations from Section 5.1.2, we\nalso developed the mj, sans unecessary and mj, sans redundant\nvariants, which extend mj, base . Last, we implemented a\nmini-joins solution with all optimizations activated, denoted\nbymj, all opts and 1-layer , a PBSM baseline solution that\nsolely employs the first layer of partitioning.\nFigure 11 reports the breakdown of the total execution\ntime while varying the number of partitions per dimension\nfor the ROADS ▷ ◁ZCTA5 and EDGES ▷ ◁ZCTA5 queries.\nNote that we excluded the offline partitioning time but\nincluded the sorting time needed for adopting plane-sweep\nand saving on redundant comparisons.3The results clearly\n3. Note that 1-layer employs the plane-sweep approach in [37] for\npartition-to-partition joins, similar to our 2-layer based methods.show the benefit of employing our second layer of parti-\ntioning and the mini-joins breakdown compared to 1-layer .\nWe also observe that employing all comparison-saving op-\ntimizations can further accelerate the join computation; the\nmj, all opts always outperforms the rest tested methods.\n6.4.2 Both Inputs Indexed\nWe then experiment with the three join strategies discussed\nin Section 5.2, starting with the setting where both input\ndatasets are indexed by a 2-layer scheme. The granularity\nof each first layer grid is set according to our analysis in\nSection 6.1 as powers of 2 (see Table 5). We consider again\nthe ROADS ▷ ◁ZCTA5 and EDGES ▷ ◁ZCTA5 queries.\nFigure 12 reports the time breakdown of the tested ap-\nproaches; as a baseline, we also included a traditional R-tree\njoin method [37]. We tested the straightforward approach of\nre-indexing one of the inputs using a temporary 2-layer so\nthat both indices employ identical grids and being able to\nuse the mj, all opts join method from the previous section.\nThe figure shows the results for re-indexing ROADS and\nEDGES, while re-indexing ZCTA5 is omitted. As ZCTA5\ncontains significantly larger rectangles than ROADS and\nEDGES (see Table 2), indexing these rectangles under the\nvery fine grids used by 2-layer for ROADS and EDGES\nincurs a high replication ratio and hence, high partitioning\ncosts (over 300 secs). The figure also includes the two\nvariants for the online transformation of the 2-layer scheme\nin ROADS and EDGES to the grid of ZCTA5, proposed in\nSection 5.2.1. The results clearly show the benefit the online\ntransformation compared to re-indexing one of the inputs\nand in particular, the variant when the new 2-layer scheme is\nnot materialized as such an approach completely eliminates\nthe partitioning costs.\n6.4.3 One Input Indexed\nWe consider once again the ROADS ▷ ◁ZCTA5 and EDGES\n▷ ◁ZCTA5 queries when only one input is indexed by our\n2-layer scheme. We tested three solutions in this context. The\nfirst is a classic index-based join; we denote this approach\nasfor-loop, probe . The second approach grid10×10, probe\nextends this idea by partitioning the unindexed input with\na coarse grid (we used a 10×10one) and then executing\nthe window range queries per grid cell. Finally, we also\nemployed the ‘Both Inputs Indexed’ approach by indexing\nthe unindexed input online.\nFigure 13 reports the breakdown of the execution time;\nwe distinguish between two cases for each query, depending\non which input is already indexed. Note that we omit\nthe ‘Both Inputs Indexed’ approach when ZCTA5 has to\nbe indexed, similarly to previous section. We discuss the\nROADS ▷ ◁ZCTA5 query as the findings are the same for\nEDGES ▷ ◁ZCTA5. When ZCTA5 is indexed, we observe\nthat building online a temporary 2-layer scheme on ROADS\nwith an identical grid to ZCTA5 is in fact the best solution.\nThis is mainly because mj, all opts used to compute the\njoin drastically reduces the joining time. In contrast, when\nROADS is pre-indexed, the best approach is grid10×10,\nprobe which improves the cache locality when probing the\nindex on ROADS. As ZCTA5 contains significantly fewer\nrectangles than ROAD, the cost of constructing such a grid\nis negligible compared to applying the same idea on ROADS\n\n12\nROADS ▷ ◁ZCTA5\n 0 2 4 6 8 10 12 14\n50 100 150 200 250 300 350 400 500 600 800 10001-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all optsTime [secs]\npartitions per dimensionsorting joining\nEDGES ▷ ◁ZCTA5\n 0 5 10 15 20 25 30 35\n50 100 150 200 250 300 350 400 500 600 800 10001-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all opts\n1-layer\nmj, base\nmj, sans unnecessary\nmj, sans redundant\nmj, all optsTime [secs]\npartitions per dimensionsorting joining\nFig. 11: Two-layer partitioning join on real datasets: mini-joins breakdown and optimizations.\nwhen ZCTA5 is pre-indexed. To sum up, when one of the\ninputs is pre-indexed by our 2-layer scheme, an R ▷ ◁ S spa-\ntial join can be efficiently computed using the ‘Both Inputs\nIndexed’ strategy if the cost of indexing the second input\nis expected to be low (due to containing small rectangles\nor using a coarse first layer grid) or the grid-based probe\napproach otherwise.\n6.4.4 No Input Indexed\nLastly, we consider the setting when none of the inputs is\nindexed. As discussed in Section 5.2.3, we directly construct\nin this case, two temporary 2-layer schemes under an iden-\ntical first layer grid and then use mj, all opts to compute the\njoin. Figure 14 shows the effect of further optimizing this\napproach with the space reduction optimization proposed at\nthe end of Section 5.2.3, while varying the grid granularity.\nWe denote this method as mj, all opts + s-opt . We observe\nthat the space optimization enhances the join computation,\nespecially when a very fine grid is used.\n7 C ONCLUSIONS\nWe presented a secondary partitioning approach that can\nbe applied to SOP indices, such as grids, and divides the\nMBRs within each spatial partition to four classes. Ourapproach reduces the number of comparisons during range\nquery evaluation and avoids the generation (and elimi-\nnation) of duplicate results. We show how our approach\ncan also be used for duplicate result avoidance in spatial\nintersection joins that are evaluated using the state-of-the-\nart PBSM algorithm. For both range queries and joins, we\nshow how redundant computations can also be avoided.\nOur experimental findings confirm the superiority of our\napproach compared to the state-of-the-art duplicate result\nelimination method [18]. We also show that a grid equipped\nwith our method outperforms other indices (such as the\nquad -tree and R-tree) by up to one order of magnitude.\nThe cost of spatial intersection joins is also reduced by\na significant factor (about 50%) with the help of our sec-\nondary partitioning technique and the use of our optimized\npartition-to-partition join algorithms. Directions for future\nwork include the evaluation of distance-based queries, e.g.,\nk-NN or distance joins, the application of our approach\nto distributed spatial data management systems and to\nindexing trajectories for retrieval and join problems.\nREFERENCES\n[1] N. Mamoulis, Spatial Data Management , ser. Synthesis Lectures on\nData Management. Morgan & Claypool Publishers, 2011.\n\n13\n0246810123234\nR-tree Join\nre-index ROADS\ntransformation\nmaterialized\ntransformation\nnon-materialized\nR-tree Join\nre-index EDGES\ntransformation\nmaterialized\ntransformation\nnon-materialized32 secsTime [secs]\n partitioning\nsorting\njoining\nROADS ▷ ◁ZCTA5 EDGES ▷ ◁ZCTA5\nFig. 12: ‘Both Inputs Indexed’ setting on\nreal datasets; re-indexing ZCTA5 omitted\ndue to high online partitioning costs.ROADS ▷ ◁ZCTA5 EDGES ▷ ◁ZCTA5\n 0 1 2 3 4 5 6 7\nfor-loop, probe\ngrid 10x10, probe\nindex ROADS\n(both indexed setting)\nfor-loop, probe\ngrid 10x10, probeTime [secs]\n partitioning\nsorting\njoining\n 0 2 4 6 8 10 12 14 16 18\nfor-loop, probe\ngrid 10x10, probe\nindex EDGES\n(both indexed setting)\nfor-loop, probe\ngrid 10x10, probeTime [secs]\n partitioning\nsorting\njoining\nZCTA5 indexed ROADS indexed ZCTA5 indexed EDGES indexed\nFig. 13: ‘One Input Indexed’ setting on real datasets; indexing ZCTA5\nomitted due to high online partitioning costs.\nROADS ▷ ◁ZCTA5\n 0 5 10 15 20 25\n50 100 150 200 250 300 350 400 500 600 800 1000mj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-optTime [secs]\npartitions per dimensionpartitioning sorting joining\nEDGES ▷ ◁ZCTA5\n 0 5 10 15 20 25 30 35\n50 100 150 200 250 300 350 400 500 600 800 1000mj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-opt\nmj, all opts\nmj, all opts + s-optTime [secs]\npartitions per dimensionpartitioning sorting joining\nFig. 14: ‘No Input Indexed’ setting on real datasets\n[2] A. Aji, F. Wang, H. Vo, R. Lee, Q. Liu, X. Zhang, and J. H. Saltz,\n“Hadoop-GIS: A high performance spatial data warehousing sys-\ntem over mapreduce,” Proc. VLDB Endow. , vol. 6, no. 11, pp. 1009–\n1020, 2013.\n[3] A. Eldawy and M. F. Mokbel, “SpatialHadoop: A mapreduce\nframework for spatial data,” in IEEE ICDE , 2015, pp. 1352–1363.\n[4] D. Xie, F. Li, B. Yao, G. Li, L. Zhou, and M. Guo, “Simba: Efficient\nin-memory spatial analytics,” in ACM SIGMOD , 2016, pp. 1071–\n1085.\n[5] J. Yu, Z. Zhang, and M. Sarwat, “Spatial data management in\napache spark: the geospark perspective and beyond,” GeoInfor-\nmatica , vol. 23, no. 1, pp. 37–78, 2019.\n[6] V . Pandey, A. Kipf, T. Neumann, and A. Kemper, “How good are\nmodern spatial analytics systems?” Proc. VLDB Endow. , vol. 11,\nno. 11, pp. 1661–1673, 2018.\n[7] H. Hoppe, “Progressive meshes,” in ACM SIGGRAPH , 1996, pp.\n99–108.\n[8] M. Pavlovic, D. Sidlauskas, T. Heinis, and A. Ailamaki, “QUASII:query-aware spatial incremental index,” in EDBT , 2018, pp. 325–\n336.\n[9] C. Cheng, H. Yang, I. King, and M. R. Lyu, “Fused matrix factor-\nization with geographical and social influence in location-based\nsocial networks,” in AAAI , 2012.\n[10] A. Guttman, “R-trees: A dynamic index structure for spatial\nsearching,” in ACM SIGMOD , 1984, pp. 47–57.\n[11] M. F. Mokbel, X. Xiong, and W. G. Aref, “SINA: scalable in-\ncremental processing of continuous queries in spatio-temporal\ndatabases,” in ACM SIGMOD , 2004, pp. 623–634.\n[12] D. V . Kalashnikov, S. Prabhakar, and S. E. Hambrusch, “Main\nmemory evaluation of monitoring queries over moving objects,”\nDistributed and Parallel Databases , vol. 15, no. 2, pp. 117–135, 2004.\n[13] X. Yu, K. Q. Pu, and N. Koudas, “Monitoring k-nearest neighbor\nqueries over moving objects,” in IEEE ICDE , 2005, pp. 631–642.\n[14] K. Mouratidis, M. Hadjieleftheriou, and D. Papadias, “Conceptual\npartitioning: An efficient method for continuous nearest neighbor\nmonitoring,” in ACM SIGMOD , 2005, pp. 634–645.\n[15] D. Sidlauskas, S. Saltenis, C. W. Christiansen, J. M. Johansen,\nand D. Saulys, “Trees or grids?: indexing moving objects in main\nmemory,” in ACM SIGSP ATIAL/GIS , 2009, pp. 236–245.\n[16] S. Ray, R. Blanco, and A. K. Goel, “Supporting location-based\nservices in a main-memory database,” in IEEE MDM , 2014, pp.\n3–12.\n[17] W. G. Aref and H. Samet, “Hashing by proximity to process\nduplicates in spatial databases,” in CIKM , 1994, pp. 347–354.\n[18] J. Dittrich and B. Seeger, “Data redundancy and duplicate detec-\ntion in spatial join processing,” in IEEE ICDE , 2000, pp. 535–546.\n[19] D. Tsitsigkos, K. Lampropoulos, P . Bouros, N. Mamoulis, and\nM. Terrovitis, “A two-layer partitioning for non-point spatial\ndata,” in IEEE ICDE , 2021, pp. 1787–1798.\n[20] M. Olma, F. Tauheed, T. Heinis, and A. Ailamaki, “BLOCK:\nefficient execution of spatial range queries in main-memory,” in\nSSDBM , 2017, pp. 15:1–15:12.\n[21] J. L. Bentley and J. H. Friedman, “Data structures for range\nsearching,” ACM Comput. Surv. , vol. 11, no. 4, pp. 397–409, 1979.\n[22] J. L. Bentley, “Multidimensional binary search trees used for\nassociative searching,” Commun. ACM , vol. 18, no. 9, pp. 509–517,\n1975.\n[23] R. A. Finkel and J. L. Bentley, “Quad trees: A data structure for\nretrieval on composite keys,” Acta Inf. , vol. 4, pp. 1–9, 1974.\n[24] M. T. Mahin, T. Hashem, and S. Kabir, “A crowd enabled approach\nfor processing nearest neighbor and range queries in incom-\nplete databases with accuracy guarantee,” Pervasive Mob. Comput. ,\nvol. 39, pp. 249–266, 2017.\n[25] H. Samet, The Design and Analysis of Spatial Data Structures .\nAddison-Wesley, 1990.\n[26] N. Beckmann, H. Kriegel, R. Schneider, and B. Seeger, “The R*-tree:\nAn efficient and robust access method for points and rectangles,”\ninACM SIGMOD , 1990, pp. 322–331.\n[27] K. Kim, S. K. Cha, and K. Kwon, “Optimizing multidimensional\nindex trees for main memory access,” in ACM SIGMOD , 2001, pp.\n139–150.\n[28] T. Vu and A. Eldawy, “R*-grove: Balanced spatial partitioning for\nlarge-scale datasets,” Frontiers Big Data , vol. 3, p. 28, 2020.\n\n14\n[29] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis, “The\ncase for learned index structures,” in ACM SIGMOD , 2018, pp.\n489–504.\n[30] H. Wang, X. Fu, J. Xu, and H. Lu, “Learned index for spatial\nqueries,” in IEEE MDM , 2019, pp. 569–574.\n[31] P . Li, H. Lu, Q. Zheng, L. Yang, and G. Pan, “LISA: A learned index\nstructure for spatial data,” in ACM SIGMOD , 2020, pp. 2119–2133.\n[32] J. Qi, G. Liu, C. S. Jensen, and L. Kulik, “Effectively learning spatial\nindices,” Proc. VLDB Endow. , vol. 13, no. 11, pp. 2341–2354, 2020.\n[33] V . Nathan, J. Ding, M. Alizadeh, and T. Kraska, “Learning multi-\ndimensional indexes,” in ACM SIGMOD , 2020, pp. 985–1000.\n[34] J. Ding, V . Nathan, M. Alizadeh, and T. Kraska, “Tsunami: A\nlearned multi-dimensional index for correlated data and skewed\nworkloads,” Proc. VLDB Endow. , vol. 14, no. 2, pp. 74–86, 2020.\n[35] F. P . Preparata and M. I. Shamos, Computational Geometry - An\nIntroduction . Springer, 1985.\n[36] L. Arge, O. Procopiuc, S. Ramaswamy, T. Suel, and J. S. Vitter,\n“Scalable sweeping-based spatial join,” in VLDB , 1998, pp. 570–\n581.\n[37] T. Brinkhoff, H.-P . Kriegel, and B. Seeger, “Efficient processing of\nspatial joins using r-trees,” in ACM SIGMOD , 1993, pp. 237–246.\n[38] J. M. Patel and D. J. DeWitt, “Partition based spatial-merge join,”\ninACM SIGMOD , 1996, pp. 259–270.\n[39] S. Nobari, Q. Qu, and C. S. Jensen, “In-memory spatial join: The\ndata matters!” in EDBT , 2017, pp. 462–465.\n[40] D. Tsitsigkos, P . Bouros, N. Mamoulis, and M. Terrovitis, “Parallel\nin-memory evaluation of spatial joins,” in ACM SIGSP ATIAL , 2019,\npp. 516–519.\n[41] M.-L. Lo and C. V . Ravishankar, “Spatial hash-joins,” in ACM\nSIGMOD , 1996, pp. 247–258.\n[42] S. Nobari, F. Tauheed, T. Heinis, P . Karras, S. Bressan, and A. Ail-\namaki, “TOUCH: in-memory spatial join by hierarchical data-\noriented partitioning,” in ACM SIGMOD , 2013, pp. 701–712.\n[43] S. T. Leutenegger, J. M. Edgington, and M. A. L ´opez, “STR: A\nsimple and efficient algorithm for r-tree packing,” in IEEE ICDE ,\n1997, pp. 497–506.\n[44] N. Mamoulis and D. Papadias, “Slot index spatial join,” IEEE\nTKDE , vol. 15, no. 1, pp. 211–231, 2003.\n[45] F. Tauheed, T. Heinis, and A. Ailamaki, “Configuring spatial grids\nfor efficient main memory joins,” in BICOD , 2015.\n[46] A. Cary, Z. Sun, V . Hristidis, and N. Rishe, “Experiences on\nprocessing spatial data with mapreduce,” in SSDBM , 2009, pp.\n302–319.\n[47] S. You, J. Zhang, and L. Gruenwald, “Large-scale spatial join query\nprocessing in cloud,” in CloudDB, ICDE Workshops , 2015, pp. 34–\n41.\n[48] A. Eldawy, V . Hristidis, S. Ghosh, M. Saeedan, A. Sevim, A. B.\nSiddique, S. Singla, G. Sivaram, T. Vu, and Y. Zhang, “Beast:\nScalable exploratory analytics on spatio-temporal data,” in ACM\nCIKM , 2021, pp. 3796–3807.\n[49] I. Sabek and M. F. Mokbel, “On spatial joins in mapreduce,” in\nACM SIGSP ATIAL , 2017, pp. 21:1–21:10.\n[50] G. Kedem, “The quad-cif tree: A data structure for hierarchical\non-line algorithms,” in DAC , 1982, pp. 352–357.\n[51] M. Loskot and A. Wulkiewicz, 2019,\nhttps://github.com/mloskot/spatial index benchmark.",
  "textLength": 75215
}