{
  "paperId": "4d0a105776ca30a7a0242bce57d1a77b493568ae",
  "title": "Survive the Schema Changes: Integration of Unmanaged Data Using Deep Learning",
  "pdfPath": "4d0a105776ca30a7a0242bce57d1a77b493568ae.pdf",
  "text": "Survive the Schema Changes: Integration of\nUnmanaged Data Using Deep Learning\nZijie Wang\u0003, Lixi Zhou\u0003, Amitabh Das\u0003, Valay Dave\u0003, Zhanpeng Jiny, and Jia Zou\u0003\n\u0003Arizona State University,yUniversity at Buffalo, State University of New York\nEmail:\u0003fzijiewang, lixi.zhou, adas59, vddave, jia.zou g@asu.edu,yzjin@buffalo.edu\nAbstract —Data is the king in the age of AI. However data\nintegration is often a laborious task that is hard to automate.\nSchema change is one signiﬁcant obstacle to the automation of\nthe end-to-end data integration process. Although there exist\nmechanisms such as query discovery and schema modiﬁcation\nlanguage to handle the problem, these approaches can only work\nwith the assumption that the schema is maintained by a database.\nHowever, we observe diversiﬁed schema changes in heterogeneous\ndata and open data, most of which has no schema deﬁned. In\nthis work, we propose to use deep learning to automatically deal\nwith schema changes through a super cell representation and\nautomatic injection of perturbations to the training data to make\nthe model robust to schema changes. Our experimental results\ndemonstrate that our proposed approach is effective for two real-\nworld data integration scenarios: coronavirus data integration,\nand machine log integration.\nKeywords —data integration, deep learning, schema changes,\nschema evolution, perturbation, intermediate representation\nI. I NTRODUCTION\nIt was reported in 2018 that data scientists spent 80-90%\nefforts in the data integration process [8], [69], [74]. The\nschema change, which impacts applications and causes system\ndowntimes, is always a main factor leading to the tremen-\ndous human resource overhead required for data integration.\nSchema changes are often caused by software evolution that\nis pervasive and persistent in agile development [36], or the\ndiversity in data formats due to the lack of standards [13].\nExample: coronavirus disease 2019 (COVID-19) data inte-\ngration. To predict the coronavirus outbreak, we integrate the\ncoronavirus data repository at Johns Hopkins University (JHU)\n[4] and the Google mobility data [3]. The JHU’s data reposi-\ntory maintains the world coronavirus cases on a daily basis as\na set of CSV ﬁles. However, we ﬁnd the schema of the data has\nfrequent changes. As illustrated in Fig. 1(a), the changes in-\nclude attribute name changes (e.g., Longitude !Long ), addi-\ntion and removal of attributes (e.g., from six attributes initially\nto15attributes), attribute type changes (e.g., date formats),\nkey changes (e.g., from (country/region , province/state ) to\n(combined key), (FIPS ) and (country region , province state,\nAdmin2 ). The data scientist’s Python code for parsing these\nﬁles easily breaks at each schema change, and requires manual\nefforts to debug and ﬁx the issues. This becomes a ubiquitous\npain for the users of this JHU data repository, and people even\nlaunched a project to periodically clean the JHU coronavirus\ndata into a stable R-friendly format1. However such cleaning\n1https://github.com/Lucas-Czarnecki/COVID-19-CLEANED-JHUCSSEis purely based on manual efforts and obviously not scalable.\nPrior arts. Schema evolution for data that was managed\nin relational databases, NoSQL databases, and multi-model\ndatabases are well-established research topics. The fundamen-\ntal idea is to capture the semantic mappings between the\nold and the new schemas, so that the legacy queries can be\ntransformed and/or legacy data can be migrated to work with\nthe new schemas. There are two general approaches to capture\nthe semantics mappings: (1) To search for the queries that can\ntransform the old schema to the new schema [9], [25], [30],\n[51], [61], [66]. (2) To ask the database administrators (DBAs)\nor application developers to use a domain-speciﬁc language\n(DSL) to describe the schema transformation process [11],\n[17], [31]–[33], [41], [53], [55], [56], [64].\nHowever, these approaches are not applicable to unmanaged\ndata, including open data such as publicly available CSV ,\nJSON, HTML, or text ﬁles that can be downloaded from a\nURL, and transient data that is directly collected from sensor\ndevices or machines in real-time and discarded after being\nintegrated. That’s because the history of schema changes for\nthese data is totally lost or become opaque to the users. It is\nan urgent need to automatically handle schema changes for\nunmanaged data without interruptions to applications and any\nhuman interventions. Otherwise, with the rapid increase of the\nvolume and diversity of unmanaged data in the era of Big Data\nand Internet of Things (IoT), it is unavoidable to waste a huge\namount of time and human resources in manually handling the\nsystem downtimes incurred by schema changes.\nA deep learning approach. In this work, we argue for\na new data integration pipeline that uses deep learning to\navoid interruptions caused by the schema changes. In the\npast few years, deep learning (DL) has become the most\npopular direction in machine learning and artiﬁcial intel-\nligence [46], [65], and has transformed a lot of research\nareas, such as image recognition, computer vision, speech\nrecognition, natural language processing, etc.. In recent years,\nDL has been applied to database systems and applications to\nfacilitate parameter tuning [47], [71], [76], [81], indexing [21],\n[43], partitioning [34], [86], cardinality estimation and query\noptimization [39], [44], and entity matching [24], [37], [42],\n[57], [73], [82]. While predictions based on deep learning\ncannot guarantee correctness, in the Big Data era, errors in\ndata integration are usually tolerable as long as most of the\ndata is correct, which is another motivation of our work. To the\nbest of our knowledge, we are the ﬁrst to apply deep learningarXiv:2010.07586v1  [cs.DB]  15 Oct 2020\n\nto learn the process of join/union/aggregation-like operations\nwith schema changes occurring in the data sources. However,\nit’s not an easy task and the speciﬁc research questions include:\n(1) It is not straightforward to formulate a data integration task,\nwhich is usually represented as a combination of relational\nor dataﬂow operators such as join ,union ,filter ,map,\nflatmap ,aggregate , into a prediction task. What are\neffective representations for the features and labels?\n(2) How to design the training process to make the model\nrobust to schema changes?\n(3) Different model architectures, for example, simple and\ncompact sequence models such as Bi-LSTM and complex\nand large transformer such as GPT-2 and BERT, may strike\ndifferent trade-offs among accuracy, latency, and resource\nconsumption. What are the implications for model architecture\nselection in different deploying environments?\n(4) Annotating data to prepare for training data is always a ma-\njor bottleneck in the end-to-end lifecycle of model deployment\nfor production. Then how to automate training data preparation\nfor the aforementioned prediction tasks?\nUninterruptible integration of fast-evolving data. In this\nwork, we ﬁrst formulate a data integration problem as a deep\nlearning model that predicts the position in the target dataset\nfor each group of related data items in the source datasets. We\npropose to group related items in the same tuple or object that\nwill always be processed together, and abstract each group into\na super cell concept. We further propose to use source keys and\nattributes as features for describing the context of each cell,\nand use the target keys and attributes as labels to describe the\ntarget position where the super cell is mapped to. The features\nand labels can be represented as sentences or sentences with\nmasks so that the representation can be applicable to state-of-\nart language models, including sequence models like Bi-LSTM\nand transformers like GPT-2 and BERT.\nThen, to seamlessly handle various schema changes, in-\nspired by adversarial attacks [28], [45], which is a hot topic\nin DL, we see most types of schema changes as obfuscations\ninjected to testing samples at inference time, which may\nconfuse the model that is trained without noises. Therefore,\njust like adversarial training [28], [45], [68], we address the\nproblem by adding specially designed noises to the training\nsamples to make the model robust to schema changes. The\ntechniques we employ to do so include replacing words by\nrandomly changed words and synonyms that are sampled from\nGoogle Knowledge Graph. In addition, we propose to add an\naggregation mode label to indicate how to handle super cells\nthat are mapped to the same position, which can well handle\nthe schema change of the type key expansion in the example\nwe give earlier.\nBased on the above discussions, we propose a fully au-\ntomated end-to-end process for uninterruptible integration of\nfast-evolving data sources, as illustrated in Fig. 1(b). Step 1 ,\nthe system will leverage our proposed Lachesis intermediate\nrepresentation (IR) [86] to automatically translate the user’s\ninitial data integration code into the executable code that\nautomatically creates training data based on our proposedrepresentation. Step 2 , obfuscations will be automatically\ninjected to the training data to make the model robust to\nvarious schema changes. Step 3 , different model architectures\nwill be chosen to train the predictive model that will perform\nthe data integration task depending on the model deploying\nenvironment. Due to the space limitation, this paper will focus\non Step 2 and 3, while we will also discuss Step 1 as well\nas other techniques for reducing training data preparation\noverhead such as crowdsourcing and model reuse.\nThe contributions of this work include:\n(1) As to our best knowledge, we are the ﬁrst to systematically\ninvestigate the application of deep learning and adversarial\ntraining techniques to automatically handle schema changes\noccurring in the data sources.\n(2) We propose an effective formulation of the data integration\nproblem into a prediction task as well as ﬂexible feature\nrepresentation based on our super cell concept (Sec. II). We\nalso discuss how to alleviate the human costs involved in\npreparing training data for the representation (Sec. V).\n(3) We represent the common schema changes as various types\nof obfuscations, which can be automatically injected to the\ntraining data to make the model training process robust to\nthese types of schema changes. (Sec. III)\n(4) We compare and evaluate various trade-offs made by\ndifferent model architectures, including both simple sequence\nmodel and complex transformer model for two different data\nintegration tasks involving semi-structured and non-structured\ndata respectively. (Sec. IV and Sec. VI)\nII. P ROBLEM ANALYSIS AND FORMULATION\nA. Assumptions\nWe assume that in a typical data integration scenario that\nconverts a set of source datasets into one target dataset, each\nof the source datasets may have heterogeneous formats such\nas CSV , JSON, text, etc., which may not be managed by any\nrelational or NoSQL data stores; However, the target dataset\nmust be tabular, so that each cell in the target dataset can be\nuniquely identiﬁed by its tuple identiﬁer and attribute name.\nB. Representation Analysis and Comparison\nGiven a set of objects, where each object may represent a\nrow in a CSV ﬁle, a JSON object, a time series record, or a ﬁle,\nthere are a few candidate representations for formulating the\npredictive task, including dataset-level representation, object-\nlevel representation, attribute-level representation, cell-level\nrepresentation, and our proposed super cell based represen-\ntation. The coarser-grained of the representations, the fewer\ntimes of inferences are required, and the more efﬁcient of\nthe prediction. However, a coarser-grained representation also\nindicates that the prediction task is more complex and harder\nto train a model with acceptable accuracy, because a training\nsample will be larger and more complex than other ﬁner-\ngrained representations, and the mapping relationship to learn\nwill naturally become more complicated.\nVarious levels of representations for the motivating example\nare illustrated in Fig. 2. We ﬁnd it almost impossible to\n\nConfirmed(country,state,20200201,20200202,…)Recovery(country,state,20200201,20200202,…)pd.read_csv(confirmed,dtype={‘country’:str,‘state’:str,dates[0]:int,dates[1]:int,…});…new_jhu_ser=reformat(jhu_ser)new_google_mob=reformat(google_mob)new_jhu_ser.join(new_google_mob,…)20200201(region,subregion, confirmed,recovery,…)20200202(region, subregion, confirmed, recovery, …)02012020(region,subregion, county,confirmed,…)02022020(region,subregion, county, confirmed, ….)pd.read_csv(dates[0],dtype={‘region’:str,‘subregion’:str,‘confirmed’:int,‘recovery’:int,…});…new_jhu_ser=reformat1(jhu_ser)new_google_mob=reformat1(google_mob)new_jhu_ser.join(new_google_mob,…)pd.read_csv(dates_newformat[0],dtype={‘region’:str,‘subregion’:str,‘county’:str,‘confirmed’:int,‘recovery’:int,…});…new_jhu_ser=reformat2(jhu_ser)new_google_mob=reformat2(google_mob)new_jhu_ser.join(new_google_mob,…)JHU data at time0, location0JHUdata at time0, locationkJHUdata at timek, locationkUser’s initial code: rev0User’s modified code: rev1User’s modified code: rev2…………Tremendous human effortspent in  handling schema evolution.Target Data(a) A human-centered approach\nData at time0, location0User’s initial code: rev0IRand Code GeneratorTraining DataPerturbation InjectionTrainingAugmented Training DataData at time0, locationkData at timek, locationkTarget Data…Data at time0, location0…FullyAutomated by our proposed work (b) A deep learning approach (our proposal)\nFig. 1. Motivation and Overview of Our Proposed Approach.\ncollect sufﬁcient training data represented at the dataset-level.\nThe object-level representation groups all attributes and is not\nexpressive enough in describing the different transformations\napplied to each attribute. Similarly, the attribute-level repre-\nsentation assembles all values in the same attribute and is\nnot efﬁcient in expressing logics like ﬁltering or aggregation.\nThe cell-level representation, referring to a value of a single\nattribute in one tuple, is at the ﬁnest granularity, which sim-\npliﬁes the learning process. However, it may incur too many\ninferences and waste computational resources, particularly if\nthere exist multiple cells in one object that will always be\nmapped/transformed together.\nTherefore we propose and argue for a super cell represen-\ntation. A super cell is a group of cells in an object that will\nalways be mapped to the target table together in a similar\nway, such as the values of the confirmed attribute and the\nrecovery attribute, as shown in Fig. 2. While the ﬂexible\ngranularity of a super cell is between the object-level and\ncell-level, it can well balance the expressiveness and the\nperformance regarding the training and testing process.\nUse scenario: COVID-19 outbreak predictionGlobal_Mobility_Report.csvCountry_RegionSub_Region_1Sub_Region_2...DateRetailGroceryUSSouthCarolinaAbbeville county…3/20/2020-3519USSouthCarolinaAikencounty…3/20/2020-191503-20-2020.csvDateAdmin2Province_StateCountry_RegionConfirmedRecovery…3/20/2020AbbevilleSCUSA630…3/20/2020AikenSCUSA130…Target TableTimeSubregionRegionConfirmed_casesRecovery_casesGrocery _mobilityRetail_mobility03-20-2020SouthCarolinaUS76017-27Integration\n3Dataset-levelAttribute-levelObject-levelCell-levelSuperCell-level\nFig. 2. Various representations at different granularities\nFor each super cell, we represent its features as a sentence\nthat concatenates the keys, as well as the value and attribute of\neach cell in the super cell. Particularly the keys in the contextfeatures should include both of the join key if applicable\nand the tuple/object identiﬁer of the local table. We ﬁnd\nthat for 1-1join, the join key usually also serves as a local\ntuple/object identiﬁer; for 1-NandN-Mjoins, the join key\nis not necessarily the local key; and for non-join operations\n(e.g., union, ﬁlter, aggregate), no join key is required. We\nassume the target dataset is always tabular and propose a label\nrepresentation that includes the tuple identiﬁer (i.e., key of\nthe target table) of the super cell, the target attribute name\nof each cell, and an aggregation mode to specify how values\nthat are mapped to the same position should be aggregated\ninto one value, e.g., add, avg, max, min, count, replace old,\ndiscard new, etc..\nSuper cell formulation. Suppose there are msource datasets,\nrepresented as D=fdig(0\u0014i < m ), each source dataset is\nmodeled as a set of nisuper cells, denoted as di=fsijg(0\u0014\ni < m; 0\u0014j < n i). We further describe each super cell\nsij2dias a triplet that consists of three vectors for the\nkeys shared by each cell in the super cell, attribute names of\neach cell, and values of each cell, respectively, represented\nassij= (~keyij;~attribute ij;~value ij). We can further deﬁne\na super set to describe the current state of the entire data\nrepository: S=fsij2dij8di2Dg.\nA super cell may be mapped to zero, one, or more than one\npositions in the target dataset, depending on the operations\ninvolved in the data integration task. For example, as illustrated\nin Fig. 3, in a 1-Njoin operation, a super cell in the table\nat the left-hand side may be mapped to many positions in\nthe target table. Thus we can represent the target positions\nwhere the super cell is mapped to as a list of triples: f(sij) =\nf(~keyTij;~attributeTij; agg mode )g, where each triple refers\nto one position that is indexed by the target keys~keyTshared\nby all cells in the super cell, as well as attribute name of each\ncell in the super cell, denoted as~attributeT.\n\nOrderKeyCustKeyTotalPriceOrderDate0001000110.008012020000200021000.0080120200003000450.008012020000400022000.008012020CustKeyNameAddressZipcode0001AE852480002BF852490003CG852480004DH85249⨝OrderKeyCustKeyTotalPriceOrderDateNameAddressZipcode0001000110.008012020AE85248000200021000.008012020BF852490003000450.008012020DH85249000400022000.008012020BF85249Fig. 3. Example of 1-N join\nC. Problem Deﬁnition\nGiven a fast evolving data repository S=fsij2dij8di2\nDg, for a data integration request, the user input should specify\nthe schema of the expected target table. The schema includes\na list of pattributes denoted as A=fakg(0\u0014k < p ), where\nakrepresents the k-th attribute in the target table, as well\nas a list qattributes that serve as minimum tuple identiﬁer\n(i.e. key) denoted as Akey=falg(0\u0014l < q ). We further\ndenote a set of all possible key values in the target table as\nR=frljrl2alg(0\u0014l < q ). Then we need ﬁnd a model\nfS!(A[fNULLg)\u0002(R[fNULLg)that predicts a set of target\npositions denoted as f(~keyTij;~attributeTij; agg mode )gfor\neach super cell sij2S, where each element of the key\n8x2[0; q);~keyTij[x]2R, and each element of the attribute\nvector8y2[0;jsijj);~attributeTij[y]2A, wherejsijj\ndenotes the number of cells in the super cell sij. If a super\ncell doesn’t belong to the target table and should be discarded,\nwe deﬁne that rl=NULL andak=NULL in this case.\nIII. T RAINING DATA AUGMENTATIONS FOR SCHEMA\nCHANGES\nWe identify ﬁve basic types of data schema changes, which\ncover all of the relational or NoSQL schema changing patterns\n[11], [17], [31]–[33], [41], [53], [55], [56], [64] as well as\nschema changes that we have discovered from open data. We\nﬁrst discuss the impact of each type and then propose our\napproaches to handle these changes by adding perturbations\nto the training process.\n(1) Domain pivoting. For example, originally the dataset was\nstored as three CSV ﬁles, describing the daily conﬁrmed coro-\nnavirus cases, daily recovery cases, and daily death cases; later\nthe schema changed to a new set of CSV ﬁles so that each ﬁle\ndescribed all information (conﬁrmed, death, recovery cases)\non that speciﬁc date. We observed such changes prevalent in\nthe coronavirus data [3], [4], [6] and the weather database\nhosted by National Oceanic and Atmospheric Administration\n(NOAA) [7]. Such changes will easily break a conventional\nPython-based data integration pipeline.\n(2) Key expansion. For example, the key of the dataset\nis lowered down from the state level (country/region ,\nprovince/state ) to the county level (combined key), (FIPS )\nand (country region , province state, Admin2 ), which means a\ntuple in the original table (that describes statistics for a state)is broken down into multiple tuples with each describes the\nstatistics for a county. Such changes cannot be easily handled\nby conventional data integration methodologies.\n(3) Attribute name and ordering change. For example, in the\nﬁrst CSV ﬁle added to the JHU COVID-19 daily report data\nrepository on Jan 22nd, 2020, the third column name is “Last\nUpdate”. But in the CSV ﬁle added to the same repository\non Sept 24th, 2020, the same column is moved to the ﬁfth\nposition, and the name is slightly changed to “Last Update”.\nSuch changes may interrupt a conventional program that joins\ntwo datasets on the “Last Update” column.\n(4) Value type/format change. For example, in the daily\nCOVID-19 ﬁle created on Jan 22nd, the ”Last Update” has\nvalues in the format of “1/22/2020 17:00”. However, in the\nﬁle on Sept 24th, the value format has changed to “2020-\n09-25 04:23:21”. A conventional exact join operation using\n”Last Update” as the join key cannot handle such value\nformat change, unless the programmer chooses to convert it\ninto a similarity join, which is more complicated and much\nslower than an exact join and will result in signiﬁcantly higher\ndevelopment costs [79], [84].\n(5) Addition or removal of non-key attributes. For example,\nthe JHU COVID-19 global daily report has changed from six\nattributes initially to 14attributes after a few months. This\nchange may not make much inﬂuence, if the affected attributes\nare not used by users’ data integration workloads. On the\ncontrary, if a required column is totally removed, there is no\nway to handle such a situation without interruption, even if\nusing a deep learning approach, so we mainly focus on the\nﬁrst four types of schema changes.\nPerturbation based on schema changes. First, our super\ncell based representation will not be affected by dimension\npivoting, attribute ordering change, and addition or removal of\nirrelevant attributes, because the context for any cell remains\nthe same despite of these schema changes. Therefore a model\ntrained with our proposed representations is robust to these\ntypes of schema changes.\nSecond, schema changes such as renaming of an attribute\nand reformatting of cell values, are similar to adversarial\nattacks, which confuse the pre-trained models by adding\nnoises to the expected testing samples. Adding perturbations\nto training data is an effective way of training robust models\nagainst adversarial attacks [28]. Inspired by this analogy,\nwe add specially designed perturbations to training data to\nhandle these parts of schema changes. If we see each super\ncell representation as a sequence of words (i.e., a sentence),\nthe training data is a corpus of sentences. Then we can\naugment the training data by adding new sentences (i.e.,\nperturbations), which are changed from existing sentences by\nrandomly replacing a word using synonyms extracted from\nGoogle Knowledge Graph [3], [4], [6], or randomly modiﬁed\nwords by removing one or more letters. Then we train a\ncharacter-based embedding on this augmented corpus using\nfastText [5], which maps related words to vectors that are close\nto each other so that the model can recognize the similarity of\nsuch words. We observe through experiments that character-\n\nbased embedding can achieve better accuracy and reliability\nthan word-based embedding and can smoothly handle out-\nof-vocabulary words. It also shows that our locally trained\nembedding signiﬁcantly outperforms pre-trained embeddings\nwith Google News or Wikipedia.\nThird, to make the deep learning model robust to key expan-\nsion, as mentioned, we add a new label to the representation\ncalled “aggregation mode”. Each value of the label represents\nan aggregation operator such as sum,avg,min,max, which\nwill be applied to the cells that are mapped to the target\nposition; replace , which means the cell will replace the\nold cell that exists in the same position of the target table; or\ndiscard , which means the new cell will be discarded if an\nolder cell has been mapped to the same target position.\nIV. M ODEL TRAINING AND INFERENCE\nA. Model Architectures\nIn recent several years, Natural Language Processing (NLP)\nhas experienced several major advancements including the\nbi-directional mechanism, attention mechanism, transformer\nmechanism, and so on. Existing works show that the ﬁnal\nhidden state in Bi-LSTM networks cannot capture all im-\nportant information in a long sentence. Therefore, the atten-\ntion mechanism was introduced to address the problem by\npreserving information from all hidden states from encoder\ncells and aligning them with the current target output. Later\nsuch idea was integrated into the transformer architectures,\nso that encoders had self-attention layers, while decoders had\nencoder-decoder attention layers. Most recently, to make the\ntransformer architecture more ﬂexible to applications other\nthan language translation, GPT-2 that only uses the decoders’\npart and BERT that only uses encoders’ part are invented and\nachieve great success in a broad class of NLP problems. Our\nassumption is that on one hand, more complicated models like\nGPT-2 and BERT may naturally achieve better accuracy than\na simpler model like Bi-LSTM; but on the other hand, these\ncomplex models may require signiﬁcantly higher storage and\ncomputational resources, as well as more training data. It is\nimportant to know the trade-offs among accuracy, latency, and\nresource consumption, made by different model architectures.\nWe mainly consider two types of language model architec-\ntures: (1) simple and compact sequence models based on\ncustomized local character-based embedding and Bi-LSTM;\nand (2) complex and large pre-trained transformer models,\nsuch as GPT-2 [62] and BERT [20].\n1) Sequence Model (Bi-LSTM): Our Bi-LSTM model ar-\nchitecture, includes an embedding layer that has 150neurons;\na Bi-LSTM layer that consists of 512 neurons; and a fully-\nconnected layer that has 256neurons.\n2) Transformer Model: Moreover, we also consider trans-\nformer models based on GPT-2 [62] and BERT [20]. We use\na pre-trained GPT-2 small model or a pre-trained BERT base\nmodel as the backend, which connects to a frontend classiﬁer\ncomposed of four convolutional layers and a fully connected\nlayer. During the training process, the parameters of the GPT-2small model and the BERT base model are freezed, and only\nthe parameters of the frontend will be updated.\nThe pre-trained GPT-2 small has 117millions of parameters,\nincluding 12layers of transformers, each with 12 independent\nattention mechanisms, called “heads”, and an embedding size\nof768 dimensions. The hidden vector output from the GPT-\n2 small model is reshaped to add a channel dimension and\nthen passed to four convolutional layers, including two max-\npooled 2D convolution layer and two average-pooled 2D\nconvolution layer respectively, the output is applied with a\nhadamard product, and then sent to a fully connected layer.\nThe BERT base model has 110 millions of parameters, with\n12transformer blocks, and each has 768hidden neurons and\n12self-attention heads. It uses the same architecture of the\nfrontend classiﬁer with the GPT-2 small model. Although\nGPT-2 and BERT are both based on the transformer model,\nthey use different units of the transformer. GPT-2 is built using\ntransformer decoder blocks constructed by the masked self-\nattention layers, while the BERT utilizes transformer encoder\nblocks with self-attention layers.\nAlthough transformer models usually achieve better accu-\nracy than sequence models through its attention mechanism,\nthey also require signiﬁcantly more storage space. For exam-\nple, GPT-2 small, which is the smallest variant of GPT-2 model\nrequires more than 500megabytes of storage space; The BERT\nbase model2that we use takes 450megabytes of storage space.\nIn contrast, the Bi-LSTM model is smaller than 1megabyte.\nB. Assembling of Inference Results\nFor each super cell, the model will predict a set of target\npositions in the form of f(~keyTij;~attributeTij; agg mode )g,\nas we mentioned in Sec. II. Then based on each super cell\nand its predicted positions, a general data assembler will put\neach value to the right places in the target table. Based on the\nconﬁguration, the assembler can work in either local mode\nby buffering and writing one ﬁle to store the target dataset\nin local or dispatch the assembled tuples to users’ registered\ndeep learning workers (i.e., target data is consumed by a deep\nlearning application) once an in-memory buffer is full. In\nthe latter case, in each deep learning worker’s side, a client\nis responsible for receiving and assembling tuples into the\ntarget dataset. During the dispatching process, the output table\nwill be partitioned in a way to guarantee load balance and\nensure the independent identical distribution (i.e., IID) to avoid\nintroducing bias.\nV. A UTOMATION OF TRAINING DATA PREPARATION\nA. Code Generation Based on Intermediate Representation\nAn important objective of this work is to free human experts\nfrom all dirty works of wrangling with schema changes.\nTherefore it’s critical to reduce the human efforts required\nin training data preparation, such as parsing and annotating\ndata. We propose to automate the training data creation by\nutilizing conventional Python code developed for integrating\n2https://tfhub.dev/google/bert uncased L-12 H-768 A-12/1\n\nan initial set of data sources. The users’ Python codes specify\nhow to transform the data sources (usually with heterogeneous\nformats) to a target table (usually in tabular format), which is\nexactly the information needed for creating the training data.\nThis gives us an opportunity to translate users’ data integration\ncode to training data preparation code.\nFor relational data, the integration logic can be fully ex-\npressed in SQL, which maps to relational algebra. Then it\nis easy to generate code for training data creation process\nbased on the relational algebra. First, all key and join key\ninformation are well maintained and can be directly retrieved.\nSecond, it is easy to identify which attributes of a table\nwill always be processed similarly by analyzing the relational\nalgebra expression, so that the values of these attributes in the\nsame tuple can be grouped into a super cell. For example, by\nanalyzing a query coded up for a data integration task such as\nSELECT COVID-19.Date, COVID-19.State,\nCOVID-19.Country, COVID-19.Confirmed,\nCOVID-19.Recovered, Mobility.Workplace,\nMobility.Recreation, Mobility.Grocery\nFROM COVID-19, Mobility\nWHERE COVID-19.Date = Mobility.Time\nAND COVID-19.Country = Mobility.Region\nAND COVID-19.State = Mobility.SubRegion;\n, we will know that COVID-19.Conﬁrmed and COVID-\n19.Recovered should be grouped into one super cell; and Mo-\nbility.Workplace ,Mobility.Recreation , and Mobility.Grocery\nshould be grouped into another super cell. Third, it is pos-\nsible to rewrite each relational operator, so that the input\nand output of the relational operators are all based on the\nsuper cell representation. For example, the input of the Join\noperator in the above example has the form of ((2020-10-\n06, AZ, US), (COVID-19.Conﬁrmed, COVID-19.Recovered),\n(3103 ,2214 )). Then the join outputs are a set of pairs of\nsuper cells that match the join predicate, such as h((2020-10-\n06, AZ, US), (COVID-19.Conﬁrmed, COVID-19.Recovered),\n(3103 ,2214 )),((2020-10-06, AZ, US), (Mobility.Workplace,\nMobility.Recreation, Mobility.Grocery), ( 21,5,17))i. This\noutput can be easily transformed into a base set of training\ndata, into which the perturbations will be injected.\nHowever, because the integration code of open data, is\nusually written in an object-oriented language such as Python,\nJava, C++, the code after compilation is opaque to the system,\nand it is hard to modify the code directly. One solution is\nto map the integration code to an intermediate representation\n(IR), such as Weld IR [60] that is integrated with libraries like\nnumpy and SparkSQL; and our proposed Lachesis IR [86].\nSuch IR is usually a directed acyclic graph (DAG), and can\nbe reasoned by the system. In this DAG, each node is an\natomic computation, and each edge represents a data ﬂow or\na control ﬂow from the source node to the destination node.\nThe atomic computations useful to data integration workloads\nusually can be composed by three categories of operators:\n(1)Lambda abstraction functions such as a function that\nreturns a literal (a constant numerical value or string), a\nmember attribute or a member function from an object; unary\nfunctions such as exp,log,sqrt ,sin,cos,tan, etc..(2)Higher-order lambda composition functions such as binary\noperators: &&,||,&,|,<,>,==,+,-,*,/; conditional\noperator like condition? on_true:on_false ; etc..\n(3)Set-based operators such as scan andwrite that read-\ns/writes a set of objects from/to the storage; map,join ,\naggregate ,flatten ,filter , etc..\nWe propose to modify existing intermediate representations,\nso that a super cell based processor can be derived from each\natomic computation. We assume that each source dataset can\nbe represented as Pandas dataframes. Then by traversing the IR\ngraph, the system can understand the keys and the super cell\nmapping relationship. The super cell based processor of each\nof atomic computations transforms each super cell represen-\ntation accordingly. For example, map operator that transforms\na date cell “2020-10-06” to “Oct 6, 2020” as an example, the\nprocessor takes a super cell f“keys”: [“2020-10-06”, “AZ”,\n“US”], “attributes”: [“Date”], “cells”:[“2020-10-06”] gas\ninput, and outputs f“keys”: [“2020-10-06”, “AZ”, “US”],\n“attributes”: [“Date”], “cells”:[“Oct 6, 2020”] gso that\nthe contextual relationship between “Oct 6, 2020” and its\nsource key and attribute name is preserved. The write ’s\nprocessor transforms each super cell into a hfeature; labeli\nrepresentation, such as f“source super cell”: f“keys”: [“2020-\n10-06”, “AZ”, “US”], “attributes”: [“Date”], “cells”:[“Oct\n6, 2020”]g, “target position”: f“keys”: [“Oct 6, 2020”,\n“Arizona”, “United States”], “attributes”:[“datetime”] gg. In\nthis way, we can obtain training data automatically.\nHowever, the limitation of above approach is that it may not\nwork if the input object is totally nested and opaque and cannot\nbe represented as a set of cells like Pandas dataframes or Spark\ndataframes. For example, a corpus of totally unstructured\ntext ﬁles, unavoidably requires human pre-processing efforts.\nThereby, we design following approaches to further alleviate\nthe problem: model reusing and crowdsourcing.\nB. Crowdsourcing\nAccording to Sec. V-A, if we are able to convert an\nunstructured dataset, e.g., a set of opaque and nested objects or\na set of unstructured texts, into a Pandas dataframe or similar\nstructures, the code generation approach maybe applicable to\nautomate the training data creation process. However, it is non-\ntrivial to identify the parsing logic, perform such conversion\nand identify the keys. All these tasks are hard to automate. We\nconsider crowdsourcing as a potential approach to alleviate the\nburden from the data scientists or domain experts for these\ntasks. However, based on our experiments of crowdsourcing\n160 key identiﬁcation tasks to 8graduate students, and 164\nundergraduate students from an introductory database course,\nrequesting to identify all keys. We ﬁnd that the accuracy is\nmerely 65:7%. First, some of the datasets, particularly these\nscientiﬁc datasets, require domain-speciﬁc knowledge to tell\nthe tuple identiﬁer, because these attribute names are acronyms\nor terms that are not understandable to most people who\nare not in the domain, and usually datasets are not shipped\nwith detailed explanations for each attribute. Second, for large\ndatasets, it is impossible for a person who are not familiar\n\nwith the datasets to tell the keys. Third, it is not easy to ﬁnd\na lot of people who has database knowledge. Other tasks such\nas identifying super cells and parsing unstructured datasets are\neven more challenging for crowdsourcing platforms due to the\nexpert knowledge required in nature.\nC. Model Reuse\nAnother approach to reduce human efforts involved in\npreparing training data is to reuse models for similar data\nintegration tasks. For this purpose, we design and develop a\nsystem, called as ModelHub, which searches for reusable mod-\nels for a new data integration task by comparing the attributes\nof the target dataset (that is created by the programmer’s initial\ndata integration code) with the target dataset of each existing\ndata integration models. We leverage locality sensitive hashing\n(LSH) based on MinWise hash [19], [85] for text-based data\nand LSH based on JS-divergence [15], [48] for numerical data\nto accelerate the attribute-matching process. Another beneﬁt\nof utilizing the LSH is that, in the ModelHub platform, each\nmodel only needs to be uploaded with LSH signatures of the\ntarget dataset’s attributes, while the target dataset does not\nneed to be submitted, which saves the storage overhead and\nalso addresses privacy concerns.\nVI. E VALUATION\nWe mainly answer following questions in this section:\n(1) How effective is our proposed deep learning representation\nfor different data integration tasks?\n(2) How effective are the perturbations added to the training\ndata for handling various types of schema changes?\n(3) How will different super cell granularities affect the\naccuracy, and the overheads for the training, testing, and\nassembling process?\n(4) How will different model architectures (complex and large\nmodels vs. simple and compact models) affect the accuracy\nand latency for different types of data integration tasks?\n(5) How will our approach of handling schema changes\nimprove productivity and alleviate programmers’ efforts?\nA. Environment Setup\nBased on the proposed training data representation and\ntraining data perturbation methodology, we have created train-\ning data to train Bi-LSTM model, GPT-2 small model, and\nBERT base model for two scenarios: coronavirus data in-\ntegration and heterogeneous machine data integration. The\nﬁrst scenario mainly involves tabular source datasets in CSV\nformats with aforementioned schema changes. However, the\nsource datasets for the second scenario are mainly unstructured\ntext data, in which most of the similar terms in different\nplatforms are expressed very differently (e.g., CPU user time\nis logged as “CPU usage: 14:90% user” in MacOS, “%Cpu(s):\n14:9us” in Ubuntu, and “ 400%cpu 86%user” in Android).\nModel Architectures. We compare three neural networks:\nBi-LSTM, GPT-2 small with a CNN frontend classiﬁer, and\nBERT base with the same CNN frontend classiﬁer. The model\narchitectures are described in Sec. IV.Model Training For the training process of both scenarios, Bi-\nLSTM is relatively slower in converging, requiring around 50\nepochs; while the models leveraging pre-trained GPT-2 small\nand BERT base are much faster to converge, requiring only\naround 5epochs, as illustrated in Fig. 4.\n(a) Bi-LSTM model\n (b) Transformer models\nFig. 4. Loss vs. epochs in the training process\nMetrics. We evaluate and compare the accuracy, the storage\noverhead, and the end-to-end training and inference latency,\nwith all types of schema changes as mentioned in Sec. III\napplied at the inference stage. The accuracy of the data\nintegration model is deﬁned as the ratio of the number of super\ncells that has been predicted with correct target positions and\naggregation actions to the total number of super cells in the\ntesting data.\nHardware Platform. For all experiments, if without speciﬁ-\ncation, we use one NVIDIA Tesla V100 GPU from Google\nColab. All running times (e.g., training time, inference time)\nare measured as the average of multiple repeated runs.\nB. Coronavirus Data Integration Scenario\n1) Experiment Setup: We evaluate our system in a COVID-\n19data integration scenario that is close to the example in\nSec. I. We predict COVID- 19trend using daily and regional\ninformation regarding the number of vaqarious cases and\nmobility factors. Given a set of raw data sources, we need\nto create a 2-dimensional target dataset on daily basis. In the\ntarget dataset, each row represents coronavirus and mobility\ninformation for a state/province on the speciﬁc date, and each\ncolumn represents the state, country, number of conﬁrmed\ncases, recovery cases, death cases, and the mobility factors\nregarding workplace, grocery, transit, etc.. The target dataset\ncan be used as inputs to various curve-ﬁtting techniques [1],\n[2] for COVID- 19prediction.\nDatasets. We assume the user speciﬁes/recommends a small\nset of initial data sources. For the ﬁrst scenario, the user\nspeciﬁes the John Hopkins University’s COVID- 19github\nrepository [4] and Google mobility data [3]. The statistics\nabout the above source tables are illustrated in Tab. I. The\nJHU dataset contains 258 ﬁles with each ﬁle representing\nCOVID- 19statistics on a speciﬁc date. These ﬁles have tens\nof versions, growing from 36rows and 6attributes to 3956\nrows and 14columns.\nPerturbations. We add perturbations such as random changes\nto attribute names and values, and replacing attribute names\n\nand value tokens by synonyms as described in Sec. III to\n58:3%of the attributes in the training data. In addition, we add\nkey expansion changes, which accounts for 18:6%of the rows\nin the training data. We test the model using JHU-COVID-19\ndata and Google mobility data collected from Feb 15, 2020 to\nOct 6, 2020, as illustrated in Tab. I.\nTABLE I\nSTATISTICS OF RELEVANT DATA SOURCES .\nnumFiles numRows numCols\nJHU-COVID19 258 36-3956 6-14\nGoogle-Mobility 1 2;526;500 14\n2) Overall Results: The overall results are illustrated in\nTab. II, which show that employing a complex transformer\nlike the pre-trained GPT-2 small and BERT base, we can\nachieve better accuracy, though more complicated models\nrequire signiﬁcantly more storage space and computational\ntime for training one epoch or inference.\nThe results also show that with the increase of the granular-\nity of super cells , the required training and testing time will\nbe signiﬁcantly reduced, while the accuracy will decrease.\nTABLE II\nCOVID-19 DATA INTEGRATION WITH DIFFERENT SUPER CELL\nGRANULARITY (NUMBER OF SUPER CELLS PER TUPLE OF TARGET\nDATASET )\n#supercell model accuracy Ttrain=epoch Tpredict\n9Bi-LSTM 96:6% 4:8sec 18:9sec\nGPT-2 small 99:8% 28:1sec 21:7sec\nBERT base 99:8% 29:3sec 20:6sec\n4Bi-LSTM 92:4% 3:2sec 8:6sec\nGPT-2 small 99:6% 9:2sec 6:8sec\nBERT base 99:6% 9:6sec 6:7sec\n2Bi-LSTM Failed\nGPT-2 small 99:4% 5:8sec 3:8sec\nBERT base 99:4% 6:0sec 3:8sec\n3) Ablation Study: Using the Bi-LSTM model with single-\ncell representation, we also conducted detailed ablation study\nas illustrated in Tab. III. It shows that handling value for-\nmat changes (e.g., date format change like 10-06-2020 and\n06102020; and different abbreviations of region and subdis-\ntricts like AZ and Arizona.) is a main factor for accuracy\ndegradation. Using a customized synonymous dictionary to\nencode these format changes for adding perturbations to the\ntraining data can greatly improve the accuracy compared with\nusing synonyms extracted from Google Knowledge Graph, as\nillustrated in Tab. IV. In addition, we also ﬁnd that using\ncharacter-based embedding can signiﬁcantly outperform word-\nbased embedding, as illustrated in Tab. V.\n4) Human Productivity Comparison: We developed the\ndata integration code using Python and Pandas dataframe to\nintegrate the JHU COVID-19 data collected on Feb 15, 2020\nand the time-series Google mobility data. After Feb 15, 2020,\nthe ﬁrst schema evolution of the JHU COVID-19 data schema\nthat breaks the integration code and causes system downtime,\nhappened on Mar 22, 2020. we invite an experienced software\nengineer, a Ph.D student, and an undergraduate student toTABLE III\nABLATION STUDY FOR DIFFERENT SCHEMA CHANGE TYPES ,CHANGES\nARE INCREMENTALLY ADDED .\nTesting Cases Testing Accuracy\nrelevant data with no schema changes 99:9%\nirrelevant data 99:9%\nchanges of two attributes 99:9%\nchanges of ﬁve attributes 99:9%\nchanges of six attributes and value format changes 97:5%\nkey expansion 96:4%\nTABLE IV\nACCURACY COMPARISON FOR USING SYNONYMS RETRIEVED FROM\nGOOGLE KNOWLEDGE GRAPH (GKG) AND USING SELF -CODED\nSYNONYMS .\nTesting Cases GKG Self-coded\nchanges of two attributes 94:5% 99:9%\nchanges of ﬁve attributes 97:5% 99:9%\nchanges of six attributes and region format changes 82:2% 97:5%\ndevelop the revisions respectively and ask them to deliver\nthe task as soon as possible. We record the time between\nthe task assignment and code submission, as well as the\ntime they dedicated to ﬁxing the issue as they reported. We\nﬁnd that although the reported dedicated time ranges from\n15to25minutes; the time between the task assignment\nand code submission ranges from one to three days. This\nexample illustrates the unpredictability of human resources. In\ncontrast, our proposed data integration pipeline can smoothly\nhandle schema changes without any interruptions or delays,\nand requires no human intervention at all.\nPerformance of Python-based Integration Code. We run\nour Python-based and human-coded data integration pipeline\non the aforementioned daily JHU COVID-19 data and Google\nmobility data in a C4.xlarge AWS instance that has four CPUs\nand eight gigabytes memory, and it takes 417seconds of time\non average to integrate data for one day, without considering\nthe time required to ﬁx the pipeline for schema changes.\n97% of the time is spent on removing redundant county-level\nstatistics from the relatively large Google mobility ﬁle that has\n2:5millions of tuples. Otherwise the co-existing state-level and\ncounty-level statistics in the Google mobility ﬁle will confuse\nthe join processing. This observation indicates that with the\nacceleration of high-end GPU processor, the overall training\nand inference latency of using a deep learning based pipeline\nis lower than using the traditional human-centered pipeline.\nConsidering that the training process only needs to be carried\nout at the beginning and when a concept drift [75] is detected.\nC. Machine Log Integration\n1) Environment Setup: Suppose a lab administrator devel-\noped a Python tool to integrate various performance metrics\nof a cluster of MacOS workstations, such as CPU utiliza-\ntion (user, system, idle, wait), memory utilization (cached,\nbuffered, swap), network utilization (input, output), disk uti-\nlization (write, read), and so on. The tool collects these metrics\nby periodically reading the output of an omnipresent shell\n\nTABLE V\nACCURACY COMPARISON FOR USING DIFFERENT EMBEDDING\nAPPROACHES .\nTesting Cases accuracy\nWord2Vec pretrained on Wikipidia 71:2%\nWord2Vec pretrained on Google News 67:5%\nfastText pretrained on self-customized corpus 99:9%\ntool “top”3and then perform a union operation for time-series\nmetrics collected from each machine. Now the lab purchased\nfour Ubuntu Linux servers. However, because the “top” tool’s\noutput in Ubuntu is very different from MacOS, the Python\ntool cannot work with these new Linux machines without ad-\nditional coding efforts. Such problem is prevalent in machine\nor sensor data integration, where different devices produced by\ndifferent manufacturers may use different schemas to describe\nsimilar information.\n2) Overall Results: The results are illustrated in Tab. VI and\nTab. VII, showing that our approach can achieve acceptable\naccuracy. Particularly, the transformer models can achieve\nsigniﬁcantly better accuracy than the Bi-LSTM model. For\nthis case, with the increase in super cell granularity (i.e.,\ndecrease in number of super cells per target tuple), the\naccuracy of the Bi-LSTM network is improved, while the\naccuracy of the transformer-based models is slightly degraded.\nThe transformer-based models can achieve signiﬁcantly better\naccuracy, while the computational time required for training\n(per epoch) and inference is signiﬁcantly higher. Also the\nlarger of the super cell granularity, the fewer number of\ntraining and testing samples. Therefore, the time required\nfor training and testing is also signiﬁcantly reduced with the\nincrease in the super cell granularity.\nTABLE VI\nMACHINE LOG DATA INTEGRATION WITH DIFFERENT SUPER CELL\nGRANULARITY (NUMBER OF SUPER CELLS PER TUPLE OF TARGET\nDATASET ): U BUNTU AND MACOS DATA USED FOR TRAINING ,AND\nANDROID DATA USED FOR TESTING\n#supercell model accuracy Ttrain=epoch Tpredict\n49Bi-LSTM 82:1% 8:7sec 8:1sec\nGPT-2 small 99:6% 52:4sec 21:3sec\nBERT base 99:7% 39:1sec 15:3sec\n25Bi-LSTM 85:3% 5:4sec 3:6sec\nGPT-2 small 99:4% 29:3sec 9:8sec\nBERT base 99:4% 22:7sec 7:6sec\n3Bi-LSTM 91:2% 2:8sec 1:9sec\nGPT-2 small 99:0% 12:3sec 4:0sec\nBERT base 99:1% 13:9sec 3:7sec\nD. Output Assembling\nIn this section, we discuss the process of assembling pre-\ndiction results into tabular ﬁles. We mainly measure how\nthe sizes of source datasets, target datasets, and granularity\nof super cells affect the overall latency of the assembling\nprocess. The results are illustrated in Fig. 5, which show\nthat increasing super cell granularity will signiﬁcantly reduce\nthe assembling latency. It indicates that if storage space is\n3https://linux.die.net/man/1/topTABLE VII\nMACHINE LOG DATA INTEGRATION WITH DIFFERENT SUPER CELL\nGRANULARITY (NUMBER OF SUPER CELLS PER TUPLE OF TARGET\nDATASET ):ONLY UBUNTU DATA USED FOR TRAINING , MACOS AND\nANDROID DATA USED FOR TESTING\n#supercell model accuracy\n49Bi-LSTM 63:7%\nGPT-2 small 99:5%\nBERT base 99:6%\n25Bi-LSTM 71:2%\nGPT-2 small 99:3%\nBERT base 99:3%\n3Bi-LSTM 75:6%\nGPT-2 small 98:7%\nBERT base 99:1%\nnot the bottleneck, using a transformer-based model and the\nlargest possible super cell granularity will achieve acceptable\naccuracy while signiﬁcantly reducing the computational time\nrequired for training, inferences, and assembling.\n(a) 100K-latency\n (b) 100K-breakdown\n0\n50\n100\n150\n200\n250\n300\n350\n1\n2\n4\n8\n16\n32\nSeconds\nGranularity: Number of attributes in one super cell\nAssembling time with different granularity of \nsuper cells for 500,000 rows\n32 Attributes\n16 Attributes\n8 Attributes\n4 Attributes\n(c) 500K-latency\n0\n100\n200\n300\n400\n1\n2\n4\n8\n16\n32\nSeconds\nGranularity: Number of attributes in one super cell\nAssembling time breakdown with different \ngranularity of super cell for 500,000 rows and \n32 attributes\nBuild Time\nTransform Time\nWrite Time\n (d) 500K-breakdown\n(e) 1 million-latency\n (f) 1 million\nFig. 5. Inﬂuence of different super cell granularity to assembling latency\nand breakdown analysis (build time: parse and insert cells involved in each\nprediction to a dictionary. transform time: transform the dictionary to a Pandas\ndataframe. write time: write the Pandas dataframe to a CSV ﬁle.). We use\ndifferent number of attributes and rows for the target table in each experiment.\nVII. R ELATED WORKS\nA. Handling Schema Evolutions\nSchema evolution in relational database, XML, JSON and\nontology has been an active research area for a long time [23],\n[63]. One major approach is through model (schema) man-\nagement [10], [12] and to automatically generate executable\nmapping between the old and evolved schema [51], [77], [80].\nWhile this approach greatly expands the theoretical foundation\n\nof relational schema evolution, it requires application mainte-\nnance and may cause undesirable system downtimes [18]. To\naddress the problem, Prism [18] is proposed to automate the\nend-to-end schema modiﬁcation process by providing DBAs\na schema modiﬁcation language (SMO) and automatically\nrewriting users’ legacy queries. However, Prism requires data\nmigration to the latest schema for each schema evolution,\nwhich may not be practical for today’s Big Data era. Other\ntechniques include versioning [40], [54], [67], which avoids\nthe data migration overhead, but incurs version management\nburden and signiﬁcantly slows down query performance. There\nare also abundant works discussing about the schema evolu-\ntion problem in NoSQL databases, Polystore or multi-model\ndatabases [33], [35], [53], [70]\nMost of these works are mainly targeting at enterprise data\nintegration problems and require that each source dataset is\nmanaged by a relational or non-relational data store. However\nthe open data sources widely used by today’s data science\napplications are often unmanaged, and thus lack schemas\nor metadata information [50]. A deep learning model, once\ntrained, can handle most schema evolution without any human\nintervention, and does not require any data migration, or\nversion management overhead. Moreover, today’s data science\napplications are more tolerant to data errors compared to\ntraditional enterprise transaction applications, which makes\na deep learning approach promising.\nB. Data Discovery\nData discovery is to ﬁnd related tables in a data lake. Au-\nrum [26] is an automatic data discovery system that proposes\nto build enterprise knowledge graph (EKG) to solve real-world\nbusiness data integration problems. In EKG, a node represents\na set of attributes/columns, and an edge connects two similar\nnodes. In addition, a hyperedge connects any number of\nnodes that are hierarchically related. They propose a two-step\napproach to build EKG using LSH-based and TFIDF-based\nsignatures. They also provide a data discovery query language\nSRQL so that users can efﬁciently query the relationships\namong datasets. Aurum [26] is mainly targeting at enterprise\ndata integration. In recent, numerous works are proposed to\naddress open data discovery problems, including automatically\ndiscover table unionability [59] and joinability [83], [85],\nbased on LSH and similarity measures. Nargesian and et\nal. [58] propose a Markov approach to optimize the navigation\norganization as a DAG for a data lake so that the probability\nof ﬁnding a table by any of attributes can be maximized. In the\nDAG, each node of navigation DAG represents a subset of the\nattributes in the data lake, and an edge represents a navigation\ntransition. All of these works provide helpful insights from an\nalgorithmatic perspective and system perspective for general\ndata discovery problems. Particularly, Fernandez and et al. [27]\nproposes a semantic matcher based on word embeddings to\ndiscover semantic links in the EKG.\nOur work has a potential to integrate data discovery and\nschema matching into a deep learning model inference pro-\ncess. We argue that in our targeting scenario, the approach wepropose can save signiﬁcant storage overhead as we only need\nstore data integration models which are signiﬁcantly smaller\nthan the EKG, and can also achieve better performance for\nwide and sparse tables. We will prove in the paper that the\ntraining data generation and labeling process can be fully\nautomated.\nC. Schema/Entity Matching\nTraditionally, to solve the data integration problem for data\nscience applications, once related datasets are discovered, the\nprogrammer will either manually design queries to integrate\nthese datasets, or leverage a schema matching tool to automat-\nically discover queries to perform the data integration.\nThere are numerous prior-arts in schema matching [29],\n[38], [51], [72], which mainly match schemas based on meta-\ndata (e.g., attribute name) and/or instances. Entity matching\n(EM) [16], which is to identify data instances that refer to the\nsame real-world entity, is also related. Some EM works also\nemploy a deep learning-based approach [24], [37], [42], [49],\n[57], [73], [82]. Mudgal and et al. [57] evaluates and compares\nthe performance of different deep learning models applied to\nEM with three types of data: structured data, textual data, and\ndirty data (with missing value, inconsistent attributes and/or\nmiss-placed values). They ﬁnd that deep learning doesn’t\noutperform existing EM solutions on structured data, but it\noutperforms them on textual and dirty data.\nIn addition, to apply schema matching to heterogeneous\ndata sources, it is important to discover schemas from semi-\nstructured or non-structured data. We proposed a schema\ndiscovery mechanism for JSON data [78], among other related\nworks [22], [52].\nOur approach proposes a super cell data model to unify\nopen datasets. We train deep learning models to learn the\nmappings between the data items in source datasets and their\npositions as well as aggregation modes in the target table.\nIf we see the context of a super cell in the source as an\nentity, and the target position of the super cell as another\nentity, the problem we study in this work shares some similarity\nwith the entity matching problem. The distinction is that the\nequivalence of two ”entities” in our problem is determined by\nusers’ data integration logic, while general entity matching\nproblem does not have such constraints.\nD. Other Related Works\nThirumuruganathan and et al. [74] discuss various represen-\ntations for learning tasks in relational data curation. Cappuzzo\nand et al. [14] further propose an algorithm for obtaining local\nembeddings using a tripartite-graph-based representation for\ndata integration tasks such as schema matching, and entity\nmatching on relational database. We are mainly targeting at\nopen data in CSV , JSON and text format and choose to use a\nsuper cell based representation. These works can be leveraged\nto improve the super cell representation and corresponding\nembeddings proposed in this work.\n\nVIII. C ONCLUSION\nIn this work, we propose an end-to-end approach based\non deep learning for periodical extraction of user expected\ntables from fast evolving data sources of open datasets. We\nfurther propose a relatively stable super cell based represen-\ntation to embody the fast-evolving source data and to train\nmodels that are robust to schema changes by automatically\ninjecting schema changes (e.g., dimension pivoting, attribute\nname changes, attribute addition/removal, key expansion/con-\ntraction, etc.) to the training data. We formalize the problem\nand conduct experiments on integration of open COVID- 19\ndata and machine log data. The results show that our proposed\napproach can achieve acceptable accuracy. In addition, by\napplying our proposed approach, the system will not be easily\ninterrupted by schema changes and no human intervention is\nrequired for handling most of the schema changes.\nREFERENCES\n[1] Caltech covid-19 modeling. https://github.com/quantummind/ cal-\ntech covid 19modeling.\n[2] Cdc covid-19 death forecasting models.\nhttps://www.cdc.gov/coronavirus/2019-ncov/covid-data/forecasting-\nus.html.\n[3] Community mobility reports. https://www.google.com/covid19/mobility/.\n[4] Covid-19 data repository by the center for systems\nscience and engineering (csse) at johns hopkins university.\nhttps://github.com/CSSEGISandData/COVID-19.\n[5] Fasttext. https://fasttext.cc/.\n[6] Harvard covid-19 data: county age&sex with ann.\nhttps://dataverse.harvard.edu.\n[7] National oceanic and atmospheric administration. www.noaa.gov.\n[8] D. Abadi, A. Ailamaki, D. Andersen, P. Bailis, M. Balazinska, P. Bern-\nstein, P. Boncz, S. Chaudhuri, A. Cheung, A. Doan, et al. The seattle\nreport on database research. ACM SIGMOD Record , 48(4):44–53, 2020.\n[9] Y . An, A. Borgida, R. J. Miller, and J. Mylopoulos. A semantic\napproach to discovering schema mapping expressions. In 2007 IEEE\n23rd International Conference on Data Engineering , pages 206–215.\nIEEE, 2007.\n[10] P. A. Bernstein. Applying model management to classical meta data\nproblems. In CIDR , volume 2003, pages 209–220. Citeseer, 2003.\n[11] P. A. Bernstein and S. Melnik. Model management 2.0: manipulating\nricher mappings. In Proceedings of the 2007 ACM SIGMOD interna-\ntional conference on Management of data , pages 1–12, 2007.\n[12] P. A. Bernstein and E. Rahm. Data warehouse scenarios for model\nmanagement. In International Conference on Conceptual Modeling ,\npages 1–15. Springer, 2000.\n[13] H. A. Campbell, F. Urbano, S. Davidson, H. Dettki, and F. Cagnacci. A\nplea for standards in reporting data collected by animal-borne electronic\ndevices. Animal Biotelemetry , 4(1):1, 2016.\n[14] R. Cappuzzo, P. Papotti, and S. Thirumuruganathan. Creating embed-\ndings of heterogeneous relational datasets for data integration tasks. In\nProceedings of the 2020 ACM SIGMOD International Conference on\nManagement of Data , pages 1335–1349, 2020.\n[15] L. Chen, H. Esfandiari, G. Fu, and V . Mirrokni. Locality-sensitive\nhashing for f-divergences: Mutual information loss and beyond. In\nAdvances in Neural Information Processing Systems , pages 10044–\n10054, 2019.\n[16] P. Christen. Data matching: concepts and techniques for record linkage,\nentity resolution, and duplicate detection . Springer Science & Business\nMedia, 2012.\n[17] C. Curino, H. J. Moon, A. Deutsch, and C. Zaniolo. Automating the\ndatabase schema evolution process. The VLDB Journal , 22(1):73–98,\n2013.\n[18] C. A. Curino, H. J. Moon, and C. Zaniolo. Graceful database schema\nevolution: the prism workbench. Proceedings of the VLDB Endowment ,\n1(1):761–772, 2008.[19] M. Datar, N. Immorlica, P. Indyk, and V . S. Mirrokni. Locality-sensitive\nhashing scheme based on p-stable distributions. In Proceedings of the\ntwentieth annual symposium on Computational geometry , pages 253–\n262, 2004.\n[20] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training\nof deep bidirectional transformers for language understanding. arXiv\npreprint arXiv:1810.04805 , 2018.\n[21] J. Ding, U. F. Minhas, J. Yu, C. Wang, J. Do, Y . Li, H. Zhang,\nB. Chandramouli, J. Gehrke, D. Kossmann, et al. Alex: an updatable\nadaptive learned index. In Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data , pages 969–984, 2020.\n[22] M. DiScala and D. J. Abadi. Automatic generation of normalized\nrelational schemas from nested key-value data. In Proceedings of the\n2016 International Conference on Management of Data , pages 295–310,\n2016.\n[23] A. Doan and A. Y . Halevy. Semantic integration research in the database\ncommunity: A brief survey. AI magazine , 26(1):83–83, 2005.\n[24] M. Ebraheem, S. Thirumuruganathan, S. Joty, M. Ouzzani, and N. Tang.\nDeeper–deep entity resolution. arXiv preprint arXiv:1710.00597 , 2017.\n[25] R. Fagin, L. M. Haas, M. Hern ´andez, R. J. Miller, L. Popa, and\nY . Velegrakis. Clio: Schema mapping creation and data exchange. In\nConceptual modeling: foundations and applications , pages 198–236.\nSpringer, 2009.\n[26] R. C. Fernandez, Z. Abedjan, F. Koko, G. Yuan, S. Madden, and\nM. Stonebraker. Aurum: A data discovery system. In 2018 IEEE 34th\nInternational Conference on Data Engineering (ICDE) , pages 1001–\n1012. IEEE, 2018.\n[27] R. C. Fernandez, E. Mansour, A. A. Qahtan, A. Elmagarmid, I. Ilyas,\nS. Madden, M. Ouzzani, M. Stonebraker, and N. Tang. Seeping\nsemantics: Linking datasets using word embeddings for data discovery.\nIn2018 IEEE 34th International Conference on Data Engineering\n(ICDE) , pages 989–1000. IEEE, 2018.\n[28] Y . Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Lavi-\nolette, M. Marchand, and V . Lempitsky. Domain-adversarial training\nof neural networks. The Journal of Machine Learning Research ,\n17(1):2096–2030, 2016.\n[29] G. Gottlob and P. Senellart. Schema mapping discovery from data\ninstances. Journal of the ACM (JACM) , 57(2):1–37, 2010.\n[30] M. A. Hern ´andez, R. J. Miller, and L. M. Haas. Clio: A semi-automatic\ntool for schema mapping. ACM Sigmod Record , 30(2):607, 2001.\n[31] K. Herrmann, H. V oigt, A. Behrend, and W. Lehner. Codel–a relationally\ncomplete language for database evolution. In East European Conference\non Advances in Databases and Information Systems , pages 63–76.\nSpringer, 2015.\n[32] K. Herrmann, H. V oigt, A. Behrend, J. Rausch, and W. Lehner. Living\nin parallel realities: Co-existing schema versions with a bidirectional\ndatabase evolution language. In Proceedings of the 2017 ACM Interna-\ntional Conference on Management of Data , pages 1101–1116, 2017.\n[33] A. Hillenbrand, M. Levchenko, U. St ¨orl, S. Scherzinger, and M. Klettke.\nMigcast: Putting a price tag on data model evolution in nosql data stores.\nInProceedings of the 2019 International Conference on Management\nof Data , pages 1925–1928, 2019.\n[34] B. Hilprecht, C. Binnig, and U. R ¨ohm. Learning a partitioning advisor\nfor cloud databases. In D. Maier, R. Pottinger, A. Doan, W. Tan,\nA. Alawini, and H. Q. Ngo, editors, Proceedings of the 2020 Interna-\ntional Conference on Management of Data, SIGMOD Conference 2020,\nonline conference [Portland, OR, USA], June 14-19, 2020 , pages 143–\n157. ACM, 2020.\n[35] I. Holubov ´a, M. Klettke, and U. St ¨orl. Evolution management of\nmulti-model data. In Heterogeneous Data Management, Polystores, and\nAnalytics for Healthcare , pages 139–153. Springer, 2019.\n[36] P. Howard. Data migration, 2011. Bloor Research, London, UK , 2011.\n[37] J. Kasai, K. Qian, S. Gurajada, Y . Li, and L. Popa. Low-resource\ndeep entity resolution with transfer and active learning. arXiv preprint\narXiv:1906.08042 , 2019.\n[38] A. Kimmig, A. Memory, R. J. Miller, and L. Getoor. A collective,\nprobabilistic approach to schema mapping using diverse noisy evidence.\nIEEE Transactions on Knowledge and Data Engineering , 31(8):1426–\n1439, 2018.\n[39] A. Kipf, T. Kipf, B. Radke, V . Leis, P. Boncz, and A. Kemper. Learned\ncardinalities: Estimating correlated joins with deep learning. arXiv\npreprint arXiv:1809.00677 , 2018.\n[40] M. C. Klein and D. Fensel. Ontology versioning on the semantic web.\nInSWWS , pages 75–91, 2001.\n\n[41] M. Klettke. Evolution management of multi-model data (position paper).\n[42] P. Konda, S. Das, P. Suganthan GC, A. Doan, A. Ardalan, J. R. Ballard,\nH. Li, F. Panahi, H. Zhang, J. Naughton, et al. Magellan: Toward\nbuilding entity matching management systems. Proceedings of the VLDB\nEndowment , 9(12):1197–1208, 2016.\n[43] T. Kraska, A. Beutel, E. H. Chi, J. Dean, and N. Polyzotis. The case\nfor learned index structures. In Proceedings of the 2018 International\nConference on Management of Data , pages 489–504, 2018.\n[44] S. Krishnan, Z. Yang, K. Goldberg, J. Hellerstein, and I. Stoica. Learning\nto optimize join queries with deep reinforcement learning. arXiv preprint\narXiv:1808.03196 , 2018.\n[45] A. Kurakin, I. Goodfellow, and S. Bengio. Adversarial machine learning\nat scale. arXiv preprint arXiv:1611.01236 , 2016.\n[46] Y . LeCun, Y . Bengio, and G. Hinton. Deep learning. nature ,\n521(7553):436–444, 2015.\n[47] G. Li, X. Zhou, S. Li, and B. Gao. Qtune: A query-aware database\ntuning system with deep reinforcement learning. Proceedings of the\nVLDB Endowment , 12(12):2118–2130, 2019.\n[48] X.-L. Mao, B.-S. Feng, Y .-J. Hao, L. Nie, H. Huang, and G. Wen. S2jsd-\nlsh: A locality-sensitive hashing schema for probability distributions. In\nProceedings of the Thirty-First AAAI Conference on Artiﬁcial Intelli-\ngence , pages 3244–3251, 2017.\n[49] V . V . Meduri, L. Popa, P. Sen, and M. Sarwat. A comprehensive\nbenchmark framework for active learning methods in entity matching.\nInProceedings of the 2020 ACM SIGMOD International Conference on\nManagement of Data , pages 1133–1147, 2020.\n[50] R. J. Miller. Open data integration. Proceedings of the VLDB\nEndowment , 11(12):2130–2139, 2018.\n[51] R. J. Miller, L. M. Haas, and M. A. Hern ´andez. Schema mapping as\nquery discovery. In VLDB , volume 2000, pages 77–88, 2000.\n[52] M. J. Mior, K. Salem, A. Aboulnaga, and R. Liu. Nose: Schema design\nfor nosql applications. IEEE Transactions on Knowledge and Data\nEngineering , 29(10):2275–2289, 2017.\n[53] M. L. M ¨oller, M. Klettke, A. Hillenbrand, and U. St ¨orl. Query rewriting\nfor continuously evolving nosql databases. In International Conference\non Conceptual Modeling , pages 213–221. Springer, 2019.\n[54] H. J. Moon, C. A. Curino, A. Deutsch, C.-Y . Hou, and C. Zaniolo. Man-\naging and querying transaction-time databases under schema evolution.\nProceedings of the VLDB Endowment , 1(1):882–895, 2008.\n[55] H. J. Moon, C. A. Curino, M. Ham, and C. Zaniolo. Prima: archiving\nand querying historical data with evolving schemas. In Proceedings of\nthe 2009 ACM SIGMOD International Conference on Management of\ndata, pages 1019–1022, 2009.\n[56] H. J. Moon, C. A. Curino, and C. Zaniolo. Scalable architecture and\nquery optimization fortransaction-time dbs with evolving schemas. In\nProceedings of the 2010 ACM SIGMOD International Conference on\nManagement of data , pages 207–218, 2010.\n[57] S. Mudgal, H. Li, T. Rekatsinas, A. Doan, Y . Park, G. Krishnan, R. Deep,\nE. Arcaute, and V . Raghavendra. Deep learning for entity matching:\nA design space exploration. In Proceedings of the 2018 International\nConference on Management of Data , pages 19–34, 2018.\n[58] F. Nargesian, K. Q. Pu, E. Zhu, B. Ghadiri Bashardoost, and R. J.\nMiller. Organizing data lakes for navigation. In Proceedings of the\n2020 ACM SIGMOD International Conference on Management of Data ,\npages 1939–1950, 2020.\n[59] F. Nargesian, E. Zhu, K. Q. Pu, and R. J. Miller. Table union search on\nopen data. Proceedings of the VLDB Endowment , 11(7):813–825, 2018.\n[60] S. Palkar, J. J. Thomas, A. Shanbhag, D. Narayanan, H. Pirk,\nM. Schwarzkopf, S. Amarasinghe, M. Zaharia, and S. InfoLab. Weld:\nA common runtime for high performance data analytics. In Conference\non Innovative Data Systems Research (CIDR) , page 45, 2017.\n[61] L. Popa, M. A. Hernandez, Y . Velegrakis, R. J. Miller, F. Naumann, and\nH. Ho. Mapping xml and relational schemas with clio. In Proceedings\n18th International Conference on Data Engineering , pages 498–499.\nIEEE, 2002.\n[62] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever.\nLanguage models are unsupervised multitask learners. OpenAI Blog ,\n1(8):9, 2019.\n[63] E. Rahm and P. A. Bernstein. An online bibliography on schema\nevolution. ACM Sigmod Record , 35(4):30–31, 2006.\n[64] S. Scherzinger, M. Klettke, and U. St ¨orl. Managing schema evolution\nin nosql data stores. arXiv preprint arXiv:1308.0514 , 2013.\n[65] J. Schmidhuber. Deep learning in neural networks: An overview. Neural\nnetworks , 61:85–117, 2015.[66] Y . Shen, K. Chakrabarti, S. Chaudhuri, B. Ding, and L. Novik. Dis-\ncovering queries based on example tuples. In Proceedings of the 2014\nACM SIGMOD international conference on Management of data , pages\n493–504, 2014.\n[67] Y . Sheng. Non-blocking Lazy Schema Changes in Multi-Version\nDatabase Management Systems . PhD thesis, Carnegie Mellon University\nPittsburgh, PA, 2019.\n[68] A. Shrivastava, T. Pﬁster, O. Tuzel, J. Susskind, W. Wang, and R. Webb.\nLearning from simulated and unsupervised images through adversarial\ntraining. In Proceedings of the IEEE conference on computer vision and\npattern recognition , pages 2107–2116, 2017.\n[69] M. Stonebraker and I. F. Ilyas. Data integration: The current status and\nthe way forward. IEEE Data Eng. Bull. , 41(2):3–9, 2018.\n[70] U. St ¨orl, M. Klettke, and S. Scherzinger. Nosql schema evolution and\ndata migration: State-of-the-art and opportunities. In EDBT , pages 655–\n658, 2020.\n[71] D. G. Sullivan, M. I. Seltzer, and A. Pfeffer. Using probabilistic\nreasoning to automate software tuning. ACM SIGMETRICS Performance\nEvaluation Review , 32(1):404–405, 2004.\n[72] B. Ten Cate, P. G. Kolaitis, and W.-C. Tan. Schema mappings and\ndata examples. In Proceedings of the 16th International Conference on\nExtending Database Technology , pages 777–780, 2013.\n[73] S. Thirumuruganathan, S. A. P. Parambath, M. Ouzzani, N. Tang, and\nS. Joty. Reuse and adaptation for entity resolution through transfer\nlearning. arXiv preprint arXiv:1809.11084 , 2018.\n[74] S. Thirumuruganathan, N. Tang, M. Ouzzani, and A. Doan. Data\ncuration with deep learning [vision]. arXiv preprint arXiv:1803.01384 ,\n2018.\n[75] A. Tsymbal. The problem of concept drift: deﬁnitions and related work.\nComputer Science Department, Trinity College Dublin , 106(2):58, 2004.\n[76] D. Van Aken, A. Pavlo, G. J. Gordon, and B. Zhang. Automatic database\nmanagement system tuning through large-scale machine learning. In\nProceedings of the 2017 ACM International Conference on Management\nof Data , pages 1009–1024, 2017.\n[77] Y . Velegrakis, R. J. Miller, and L. Popa. Preserving mapping consistency\nunder schema changes. The VLDB Journal , 13(3):274–293, 2004.\n[78] L. Wang, S. Zhang, J. Shi, L. Jiao, O. Hassanzadeh, J. Zou, and\nC. Wangz. Schema management for document stores. Proceedings of\nthe VLDB Endowment , 8(9):922–933, 2015.\n[79] C. Xiao, W. Wang, and X. Lin. Ed-join: an efﬁcient algorithm for\nsimilarity joins with edit distance constraints. Proceedings of the VLDB\nEndowment , 1(1):933–944, 2008.\n[80] C. Yu and L. Popa. Semantic adaptation of schema mappings when\nschemas evolve. In Proceedings of the 31st international conference on\nVery large data bases , pages 1006–1017. VLDB Endowment, 2005.\n[81] J. Zhang, Y . Liu, K. Zhou, G. Li, Z. Xiao, B. Cheng, J. Xing, Y . Wang,\nT. Cheng, L. Liu, et al. An end-to-end automatic cloud database tuning\nsystem using deep reinforcement learning. In Proceedings of the 2019\nInternational Conference on Management of Data , pages 415–432, 2019.\n[82] C. Zhao and Y . He. Auto-em: End-to-end fuzzy entity-matching using\npre-trained deep models and transfer learning. In The World Wide Web\nConference , pages 2413–2424, 2019.\n[83] E. Zhu, D. Deng, F. Nargesian, and R. J. Miller. Josie: Overlap set\nsimilarity search for ﬁnding joinable tables in data lakes. In Proceedings\nof the 2019 International Conference on Management of Data , pages\n847–864, 2019.\n[84] E. Zhu, Y . He, and S. Chaudhuri. Auto-join: Joining tables by leveraging\ntransformations. Proceedings of the VLDB Endowment , 10(10):1034–\n1045, 2017.\n[85] E. Zhu, F. Nargesian, K. Q. Pu, and R. J. Miller. Lsh ensemble: Internet-\nscale domain search. arXiv preprint arXiv:1603.07410 , 2016.\n[86] J. Zou, P. Barhate, A. Das, A. Iyengar, B. Yuan, D. Jankov, and\nC. Jermaine. Lachesis: Automated generation of persistent partitionings\nfor big data applications. arXiv preprint arXiv:2006.16529 , 2020.",
  "textLength": 73982
}