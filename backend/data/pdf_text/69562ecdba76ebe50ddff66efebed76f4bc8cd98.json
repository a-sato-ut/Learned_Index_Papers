{
  "paperId": "69562ecdba76ebe50ddff66efebed76f4bc8cd98",
  "title": "Accelerating long-read analysis on modern CPUs",
  "pdfPath": "69562ecdba76ebe50ddff66efebed76f4bc8cd98.pdf",
  "text": "Kalikar et al.\nAccelerating long-read analysis on modern CPUs\nSaurabh Kalikar1,C h i r a gJ a i n2, Vasimuddin Md1and Sanchit Misra1*\nAbstract\nLong read sequencing is now routinely used at scale for genomics and transcriptomics applications. Mapping of\nlong reads or a draft genome assembly to a reference sequence is often one of the most time consuming stepsin these applications. Here, we present techniques to accelerate minimap2, a widely used software for mapping.\nWe present multiple optimizations using SIMD parallelization, e\u0000 cient cache utilization and a learned index\ndata structure to accelerate its three main computational modules, i.e., seeding, chaining and pairwise\nsequence alignment. These result in reduction of end-to-end mapping time of minimap2 by up to 3.5⇥while\nmaintaining identical output.\nKeywords: architecture-aware optimizations; SIMD; sequence alignment; minimap2; learned-index\nBackground\nLong-read or single molecule sequencing technol-\nogy from Paciﬁc Biosciences (PacBio) and OxfordNanopore Technology (ONT) have made signiﬁcantleaps in terms of read lengths, sequencing throughputand accuracy since their introduction to the market.Longer read lengths naturally beneﬁt genomics and\ntranscriptomics applications, e.g., to detect complex\nstructural variation in case of DNA sequencing [ 1],\nor for novel isoform discovery during RNA sequenc-ing [2]. As a result, long read sequencing is now beingadopted in population-scale and biodiversity genomesurveys [ 3–5]. However, increased sequencing through-\nput, e.g., >1T b pp e rd a y[ 6], also demands faster\nprocessing of data to save time and cloud computing\ncosts. Among the many steps performed to analyse\na long-read data set, mapping of long DNA or RNA\nreads to a reference sequence is usually the ﬁrst and\namong the most time-consuming steps in any bioinfor-matics workﬂow.\nMinimap2 is a widely used sequence alignment pro-\ngram which supports many use-cases including map-\nping long reads or a draft genome assembly to a ref-\nerence sequence [ 7]. Even though minimap2 uses well-\nengineered heuristics and software libraries, its per-formance remains signiﬁcantly below peak comput-ing performance of a modern CPU. Presence of fre-quent branching in the code, irregular memory ac-cesses and irregular computation in minimap2 makeit challenging to e\u0000ciently utilise the available hard-ware resources. Owing to its complexity, only a few at-tempts have been made to accelerate minimap2, and\nthey have also been conﬁned to accelerating only one of\n*Correspondence: sanchit.misra@intel.com\n1Intel Labs, 560103 Bangalore, India\nFull list of author information is available at the end of the articlethe three modules within minimap2 [ 8–10]. The high-\nest speed-up reported till date for minimap2 on multi-\ncore CPUs remains 1. 4x, and this was achieved with-\nout guaranteeing identical output as the original im-plementation [ 10].\nMinimap2 Algorithm\nThe algorithm used in minimap2 [ 7] is based on\nthe standard seed-chain-align procedure (Figure 1).\nThe seeding stage identiﬁes short ﬁxed-length exact\nmatches between a read and a reference sequence. Min-\nimap2 makes use of minimizer technique [ 11], a popu-\nlar k-mer sampling method to improve time and spacerequirements. Prior to mapping, minimap2 does o✏ine\nindexing of the reference sequence where it builds amultimap using a hash table with minimizers as keys\nand minimizer locations as values. This hash table is\nused during the seeding step when exact matches are\ncollected by searching read minimizers in the reference\nindex. Such matching pairs of minimizers form a set of\nanchors which are sorted and passed onto the chain-\ning stage. From the complete list of sorted anchors,\nthe chaining stage identiﬁes an ordered subset of an-chors that are co-linearly positioned along a diagonal\n[12,13]. Minimap2 uses a customized chaining score\nfunction to prioritise the highest-scoring chains which\nare likely to yield the desired base-to-base alignments\nof a read. The third and ﬁnal alignment stage com-putes base-level alignments for ﬁlling the gaps between\nadjacent anchors in these chains.\nOur contributions\nIn this work, we re-engineered the three key compu-\ntational modules in minimap2: (i) seeding, (ii) anchor. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 2 of 14\nFigure 1 Minimap2 workﬂow depicting its three key modules: (i) seeding, (ii) chaining, and (iii) alignment. Our optimizations to\neach of the modules are shown in the blue dotted rectangle.\nchaining, and (iii) pairwise sequence alignment. Opti-\nmization of the seeding stage was achieved by replac-\ning the standard hash-table lookup with a machine\nlearning based lookup using an hardware-e\u0000cient im-plementation of learned index data structure [ 14]. Ac-\nceleration of the anchor chaining step was achieved\nby designing a novel SIMD-parallel chaining algorithm\nwhich uses vector processing units available on mod-ern CPUs. In the ﬁnal sequence alignment stage, wereduced runtime by converting 128-bit (SSE) SIMD\ninstructions to 256-bit (AVX2) and 512-bit (AVX512)\nSIMD instructions. In all the proposed optimizations,we ensured that the ﬁnal output remains 100% iden-tical to that of minimap2, which allows users to easily\nswitch to a faster version of minimap2 whenever faster\ncomputing throughput is desired.\nWe compared our optimised minimap2 implementa-\ntion mm2-fast with minimap2 by mapping real ONT,\nPacBio CLR, PacBio HiFi human sequencing data,\nand human de novo genome assemblies to the hu-\nman genome reference using multiple generations of\nIntel Xeon CPUs. For each of the three modules,\nwe developed both AVX2 and AVX512 based ver-\nsions. Our AVX512 based version utilizes the SIMD\ninstructions provided by the latest CPUs under the\nAVX512 standard some of which are not available un-\nder the AVX2 standard. Thus, our AVX512 versioncan implement the same logic with less instructions\nthan the AVX2 version, thereby, achieving signiﬁcantly\nhigher speedups. The speedups achieved by mm2-fast\nAVX512 version ranged from 2. 5\u00002.8⇥,1.4\u00001.8⇥,\n1.6\u00001.9⇥, and 2. 4\u00003.5⇥for ONT, PacBio CLR,\nPacBio HiFi and genome-assembly inputs respectively.\nTo the best of our knowledge, no prior work has\nreported better speedup of end-to-end runtime ofminimap2 using a single processor or even using\nhsingle CPU, single GPUi orhsingle CPU, single\nFPGA icombinations. mm2-fast implementation is\nopen-sourced and available at https://github.com/\nlh3/minimap2/tree/fast-contrib.Results\nIn this section, we discuss our experimental settings,\nvarious datasets we used, a summary of optimiza-\ntions implemented in mm2-fast, and ﬁnally demon-\nstrate the performance gains by comparing mm2-fast\nagainst minimap2.\nExperimental setup\nWe performed our experiments on three di ↵erent pro-\ncessor architectures, Intel®Xeon®Platinum 8180\n(Skylake), Intel®Xeon®Platinum 8280 (Cascade\nLake), and Intel®Xeon®Platinum 8360Y (Ice Lake).\nArchitectural speciﬁcations of these system are listed\nin Supplementary Table S1. Our implementation\nmm2-fast was built on top of minimap2 (v2.18),\ntherefore, all our benchmarks show a comparison ofmm2-fast with minimap2 (v2.18). Our tests involved\nthree types of real human long-read sequencing data\n(ONT Guppy 3.6.0, PacBio HiFi, PacBio CLR), and\nalso three human genome assemblies for mappingto the standard reference GRCh38 [ 15]. The latter\nwas useful to demonstrate utility of mm2-fast for\nfaster genome-to-genome comparisons. Long-read se-\nquencing datasets used here were available publicly,\nand derived from human trio benchmark genomes\nHG002, HG003 and HG004 (Table 1). The three hu-\nman genome assemblies are associated with nearly-haploid CHM13 [ 16] and diploid HG002 genomes [ 17].\nEach type of dataset was mapped using parametersrecommended in minimap2 documentation.\nMinimap2 proﬁle\nWe proﬁled a single-threaded execution of minimap2\nusing datasets listed in Table 1, and separately mea-\nsured time consumed by three key modules (1) seeding,\n(2) chaining, and (3) alignment. Figure 2shows the\nperformance comparison and proﬁle of minimap2 and\nour optimized implementation (mm2-fast). All run-time values shown are normalized by the total time. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 3 of 14\nTable 1 Description of datasets which were used to evaluate mm2-fast. Each of these were mapped to GRCh38 human genome\nreference.\nQuery data set Genome sampleNumber of\nreads/contigs N50Maximum\nlength Source\nONTHG002 19M 50K 543Khttps://precision.fda.gov/\nchallenges/10/viewHG003 24M 44K 760K\nHG004 29M 48K 1.1M\nPacBio HiFiHG002 8M 13K 30Khttps://precision.fda.gov/challenges/10/viewHG003 7M 15K 32K\nHG004 7M 15K 31K\nPacBio CLRHG002 30M 11K 89Khttps://github.com/genome-in-a-bottle/\ngiab data indexesHG003 15M 11K 26M\nHG004 13M 10K 5M\nGenome\nassembliesCHM13 24 154M 248M NCBI (GCA 009914755.3)\nHG002 (hap1) 523 46M 107M https://zenodo.org/record/4393631/ﬁles/\nNA24385.HiFi.hiﬁasm-0.12.hap1.fa.gz\nHG002 (hap2) 507 40M 131M https://zenodo.org/record/4393631/ﬁles/\nNA24385.HiFi.hiﬁasm-0.12.hap2.fa.gz\nconsumed by minimap2 corresponding to each dataset.\nFor proﬁling using a single thread, we used a random\nsubset of 100K reads from each of the ONT, PacBio\nCLR, and PacBio HiFi datasets, but no sampling was\ndone in the case of draft genome assemblies. We ob-\nserved that the three modules collectively contribute\nto around 85% to 98% of the total mapping timeacross di↵ erent datasets. Breakdown of time consump-\ntion among the modules was: hash look-up (3-14%\ntime), dynamic programming based chaining (5-66%\ntime) and alignment (20-80% time). Interestingly, thetime distribution of the three modules varied across all\nthe input data types. For instance, the chaining was\nthe most time consuming step for ONT and assem-bly datasets, whereas PacBio CLR and HiFi datasets\nrequired spending majority of the time in the align-\nment phase. Therefore, we focused on all the three keymodules to achieve better performance.\nSummary of our optimizations\nIn mm2-fast, we implemented the following optimiza-\ntions while ensuring that the mapping output obtained\nfrom our optimized minimap2 remains identical tominimap2:\n•Seeding. We replaced hash-based minimizer look-\nup with learned index-based search over sorted list\nof the minimizers in the reference sequence. Inter-nally, learned indexes use machine learning models\nto predict the positions of the desired minimizers.\nThis resulted in nearly 1. 5⇥speedup in the seeding\nphase.\n•Chaining. We accelerated dynamic programming\nbased chaining by vectorizing the traversal over the\npredecessor anchors using SIMD instructions and\n32-bit integer/ﬂoating-point representation. Our\nAVX512-based vectorized chaining achieved up to\n6.1⇥speed-up over the implementation of chaining\nin minimap2.•Alignment. Minimap2 implements base-level align-\nments using SSE2 instructions with 128-bit vec-\ntor registers. As AVX2 and AVX512 instructions\nwith support of 256-bit and 512-bit vector registers,\nrespectively, are available in majority of modern\ngeneral-purpose processors, we modiﬁed the align-\nment phase to add AVX2 and AVX512 based im-plementations. Our AVX512-based version yielded\n2.1⇥speed-up over the SSE2-based implementation\nin minimap2.\nPerformance comparison\nIn Figure 2, the bars for minimap2 and our optimized\nimplementation (mm2-fast) show relative time con-\nsumption of each module across various datasets using\na single thread on Cascade Lake CPU. The speedups\nachieved for each dataset is also shown on top of the\nbars of mm2-fast. For single threaded execution, we\nachieved up to 2. 9⇥speed-up compared to minimap2.\nFigure 3shows performance comparison of minimap2\nand mm2-fast over full datasets listed in Table 1using\nmulti-threaded execution on an entire socket of Cas-\ncade Lake CPU. The labels above the bars for min-\nimap2 show the end-to-end mapping time in hours,\nand the labels above the bars of our optimized imple-\nmentation mm2-fast show the speedup achieved. Us-\ning multi-threaded execution on a single socket, we\nachieved up to 3. 1⇥compared to minimap2. mm2-\nfast also scales well with multi-threading. On a single\nsocket system with 28 cores, we achieved up to 24. 4⇥\nspeed-up compared to single-threaded execution (Sup-plementary Figure S1). mm2-fast consumes nearly the\nsame amount of memory as minimap2 (Supplementary\nTable S2). Step by step guide to use mm2-fast and ver-\nify the correctness is provided in Supplementary Note\n1. The optimization details and the design choices are\ndescribed in Methods section.. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 4 of 14\nFigure 2 Work distribution for three modules: (1) hash look-up, (2) chaining, and (3) alignment for minimap2 and mm2-fast across\ndi↵erent datasets. Both the implementations were run using a single thread of Cascade Lake CPU. X-axis shows various query\ndatasets, y-axis is the normalized time with respect to the mapping time consumed by minimap2 corresponding to each dataset.\nSpeedup achieved by our mm2-fast over minimap2 for randomly sampled 100K reads for ONT, PacBio CLR, and PacBio HiFi and\nassembly contigs is shown on top of the mm2-fast bars.\nFigure 3 Performance comparison of minimap2 and minimap2-fast on a single socket Cascade Lake CPU (28 cores, 56 threads) for\nfull datasets. X-axis shows various query datasets, y-axis is the normalized time with respect to the mapping time taken by minimap2corresponding to each dataset. On top of the bars of minimap2, we show the actual mapping time in hours by minimap2. The\nspeedup achieved by minimap2-fast is shown on top of the bars of mm2-fast.. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 5 of 14\nCross-platform performance and compatibility\nTo ensure that our optimizations deliver speedup\nacross various architectures, we compared performance\nof mm2-fast and minimap2 on three generations of In-\ntel architectures: (i) Skylake, (ii) Cascade Lake, and\n(iii) Ice Lake. All of these support AVX512 vector\nprocessing. Supplementary Table S1provides the de-\ntails of the architectural speciﬁcations of these sys-\ntems. Figure 4shows the speedups achieved on the\nthree architectures. For each of the query dataset, we\nconsistently achieved high speedups on Skylake, Cas-\ncade Lake, and Ice Lake processors. Note that thesesystems with di ↵erent architectures run on di ↵erence\nturbo-frequencies, so, their relative performance is notcomparable.\nFigure 4 Cross-platform performance of our optimizations for\nCascade lake, Skylake and Ice Lake architectures using single\nsocket. X-axis shows various query datasets and y-axis\nindicates the speedup achieved by mm2-fast over minimap2 –\nboth running on the same CPU. The maximum speedup\nachieved was 3.5⇥.\nDiscussion\nImproving long-read and genome assembly mapping\ntime is important for three reasons: (a) it cuts down\nwaiting time for a general user, (b) it is desirable for\npopulation-scale sequencing to achieve better through-\nput and reduce cloud computing costs, and (c) it\nimproves the e\u0000ciency of real-time sequencing ap-\nplications, including targeted sequencing [ 18–20], by\nmatching speed of computation with the rate of data-\ngeneration.\nMapping tools designed for long-read analysis need\nto account for high sequencing error-rate, and as a re-sult, involve complex heuristics to maintain scalability\nusing large genomes. Three computational modules,\ni.e., seeding, co-linear chaining and alignment were\nidentiﬁed to be the most time consuming steps in min-\nimap2. We focused on accelerating all three of themwhile developing mm2-fast.During the development of mm2-fast, we did ex-\ntensive proﬁling of software performance, e.g., to\noptimize the count of instructions executed, cache-e\u0000ciency, and other important hardware parameterswhich dictate the CPU performance. mm2-fast is de-\nsigned to achieve end-to-end hardware-aware acceler-ation of minimap2 on CPUs, while maintaining iden-\ntical output. Unlike minimap2, mm2-fast implements\na learned-index to allow faster minimizer look-ups,a SIMD-parallel co-linear chaining algorithm, and a\nrevised implementation for sequence-alignment. Al-\nthough the proposed optimizations will generally beuseful for any tool which follows seed-chain-align pro-\ncedure [21 –23], we chose minimap2 to demonstrate\nthe impact of these optimizations because it is a com-\nmonly used read mapper. mm2-fast leverages featuresavailable in modern CPUs (e.g., wide SIMD instruc-tions), and will work on any modern general-purposeprocessor. mm2-fast o↵ers a similar user-interface as\nminimap2 for compilation, learned-index-construction\nand read mapping.\nUsing mm2-fast, we achieved variable speedups de-\npending on the type of input data, i.e., ONT, PacBio-CLR, PacBio-HiFi, and genome assemblies. This is at-tributed to the fact that input sequence lengths anderror-rates change with the type of data, and also\nminimap2 uses di ↵erent parameters (e.g., k parame-\nter to set k-mer size) for each type of data. As out-\nput of mm2-fast remains identical to minimap2 (v2.18)\nin all scenarios, mm2-fast can be directly used as a\nfaster alternative to minimap2. New features may beadded in future into minimap2’s algorithm, at which\npoint the output of mm2-fast and minimap2 may\ndi↵er. To manage this better, we are working with\nthe author of minimap2 to merge our optimizationsin next release of minimap2. Currently, mm2-fast ismade available as open-source code on GitHub as abranch in minimap2 repository https://github.com/\nlh3/minimap2/tree/fast-contrib.\nMethods\nSeeding using a learned index\nA recent work on learned index structures by Kraska\net al. [24] has shown that an index structure can be\nviewed as a model that maps a key to its position, andtherefore, can be replaced by machine learning mod-els. For instance, a B-tree can be seen as a model thatmaps a key to its position in a sorted list. The learnedindex structures can take advantage of the distribu-tion of the keys and train a machine learning model,e.g., a recursive model index (RMI), such that it out-\nperforms traditional B-trees in search time and mem-\nory footprint. Following [ 24], several other learned in-\ndex structures have been proposed [ 25–28]. Learned. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 6 of 14\nFigure 5 Data structures used for hash table: Minimizers\nextracted from the reference sequence are stored in a sorted\nlist as key-value pairs. Position list maintains a separate list of\nthe positions of minimizers on the reference sequence.\nindexes have emerged as a performant alternative to\nsolve problems in various domains including bioinfor-matics, e.g., for genome indexing using FM-index [ 14]\nand su \u0000x array [ 29]. In this work, we design a learned\nindex based hash table to improve the query time forminimizer lookup during the seeding phase.\nHash table implementation in minimap2. A hash\ntable index is used in minimap2 to store all minimizers\nof a reference sequence as keys and their positions in\nthe reference sequence as values. In the seeding phase,a successful hash lookup returns all positions whereaq u e r ym i n i m i z e ro c c u r si nt h er e f e r e n c es e q u e n c e .Typically, such hash table lookups are known to befaster. However, they may incur overheads due to alarge number of collisions, and also incur high cachemisses as a side-e↵ect of irregular memory accessesduring hash table access, including, collision resolu-tion. For instance, the hash table in minimap2 usesa traditional quadratic probing technique which maylead to sub-optimal cache performance. In the follow-ing, we present our learned-index-based hash table de-sign which outperforms the traditional hash table im-plementation in minimap2.\nDesign of a learned hash table. Hash lookup prob-\nlem can be modeled as a search on a list of key-\nvalue pairs that is sorted according to the keys. Inour learned hash table design, we maintain two datastructures as illustrated in Figure 5.T h eﬁ r s ti sak e y -\nsorted list of key-value pairs where keys are the actualminimizers. The second is a position-list contain-\ning a concatenated list of lists of positions of all theminimizers. For each minimizer key, the value part of\nthe ﬁrst data structure encodes the starting index intheposition-list and the count of the positions for\nthe minimizer. For instance, in Figure 5,am i n i m i z e r\nentry: mm5![8,3] represents that mm5 appears 3\ntimes on the reference sequence – at index 5, 21, and57; and these three positions are stored at three consec-utive locations in position-list starting from index\n8. We use a learned index structure to search for theminimizer entry in the ﬁrst data structure.\nAmong the proposed learned index structures, RMI\nexhibits the best performance/size tradeo↵ for real-\nworld read-only in-memory dense arrays [ 30]. RMI\nconsists of a multi-layer tree structure with a model\nat each tree node. An RMI with more than two layers\nis almost never needed [ 31]. Therefore, we train a two-\nlayer RMI model to learn the distribution of the sorted\nkeys and use the trained RMI to search through the\nsorted list. Figure 6shows a two-level RMI model and\nillustrates, with an example, how we perform a lookup\noperation. While performing a lookup operation for a\nminimizer, the model at the root layer is used to pre-\ndict the correct model to use at the leaf layer. The\npredicted model at the leaf layer is used to predict the\nposition of the key in the sorted list. RMI guarantees\nthat the key is present within a certain range from the\npredicted location [ 30]. If the desired key is not found\nat the predicted position, the last mile search is con-\nducted in the provided range to ﬁnd the key. The last\nmile search is typically short because the key is ex-\npected to be in proximity of the predicted location. In\nour experiments, we observed that RMI-based lookup\nis nearly 3 \u00004⇥faster than the existing hash table\nimplementation in minimap2.\nDesign choices. We make the following design\nchoices and apply architecture-aware optimizations\nsimilar to [ 14] so as to achieve maximum speedup using\nRMI:\n•Number of leaf nodes. The number of leaf layer\nmodels plays a crucial role in the e\u0000ciency of the\nRMI lookup [ 30]. Using a large number of leaf layer\nmodels delivers better prediction and shorter last-mile searches - at the cost of larger memory con-\nsumption. By default, we use n/32 leaf layer models\nwhere nis the total number of minimizers in the\nlist since empirically that provided a good trade-o↵\nbetween prediction accuracy and memory consump-\ntion.\n•Vectorized last mile search. The last mile search\nis performed using binary search. Once only a few el-\nements remain for search (say, less than eight 64-bit\nelements for AVX512 vector instructions), we com-\npare them simultaneously using SIMD instructions.. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 7 of 14\nFigure 6 Two-layer RMI: An example minimizer lookup is\nillustrated - getmm hits (mm5) calls a lookup for a\nminimizer mm5.T h eR M Ir o o tp r e d i c t st h el e a fl a y e rm o d e l\nwhich in turn predicts the location of mm4 in the sorted list.\nFinally, the last mile search from mm4 walks to the location\nofmm5 and returns its value to the caller.\n•Batched processing. Irregular memory accesses\nwhile traversing through the RMI tree and the last\nmile search lead to higher cache misses, which ad-\nversely a↵ect the performance. We use software\nprefetches to hide the memory latency by processing\na batch of lookups at a time. Each individual lookup\ncan be split into a sequence of steps to be performed\n- (i) visit the RMI root and predict leaf layer model,(ii) visit leaf model and predict the location of the\nkey, and (iii) one step for each iteration of the bi-\nnary search performed around the prediction. Dur-\ning batch processing, we process all the lookups in\na batch in round-robin fashion. Every time a lookup\ngets a turn, we advance that lookup by one step and\nuse software prefetches to start prefetching the data\ninto the caches for its next step. While the data is\ngetting prefetched, we go over the rest of the lookups\nin the batch one by one and advance them by one\nstep and start their prefetches. By the time, a lookup\ngets a turn again, the data it requires for the next\nstep is already expected in cache. If all the steps of\na lookup are done, we replace it with the next un-\nprocessed lookup from outside the batch. We con-\ntinue this till all the lookups are done. The batch\nsize should be large enough to hide the memory la-\ntency but not so large that data corresponding to all\nthe lookups in a batch do not ﬁt in cache. We the-\noretically compute a range of ideal batch sizes and\nempirically ﬁnd the best batch size from that range.\nSIMD acceleration for co-linear chaining\nChaining in minimap2. The seeding phase outputs\na list of all identiﬁed anchors sorted according to their\nFigure 7 Chaining of two co-linear anchors AandB. Here\ntwo anchors overlap on the query sequence. Gap cost function\nin minimap2 is calculated using the reference gap, query gap,\nand the average length of all anchors avgqlen\nposition in the reference sequence for further process-\ning in the chaining stage. An anchor is deﬁned as a\nmatching minimizer between a query and a reference\nsequence. It can be represented as a 3-tuple ( r, q, l ),\nwhere randqare the positions of the matching mini-\nmizer on the reference and the query sequence, respec-\ntively, and lis the length of the minimizer.\nGiven a list L:{a1,a2,...,a n}of anchors sorted ac-\ncording to their reference positions, the chaining stepidentiﬁes ordered subsets of co-linear anchors as chains\nwhich achieve the highest chaining scores. Let S(i)b e\nthe highest chaining score for a chain that ends at an-chor a\ni;S(i) is computed using the following dynamic\nprogramming (DP) recursion in minimap2:\nS(i) = max\u0000\nmax\nj<i(S(j)+a i.l\n\u0000gapcost(i, j)\u0000overlap (i, j)),a i.l\u0000\nwhere gapcost(i, j) function penalizes the score based\non the distance between anchors aiand aj, and\noverlap (i, j) denotes the count of overlapping bases be-\ntween anchors aiandaj. Figure 7depicts the chaining\nof two co-linear anchors and their corresponding gaps\nand overlap. Algorithm 1presents a DP-based anchor-\nchaining implementation in minimap2. For each an-chor a\niin the list (line 3), the inner loop (line 8)\niterates over all the anchors ajwhere startj<i .\nDP-based execution pattern ensures that the maximal\nchaining scores till anchor ai\u00001are already computed\nbefore the computation of score for ai. The expression\nin line 11computes the chaining score. The two vari-\nables max score and predecessor index (lines 12-14). CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 8 of 14\nAlgorithm 1 Sequential chaining as used in minimap2\nInput: L:{a1,a2,...,a n}-L i s to fa n c h o r ss o r t e da c c o r d i n gt o\nthe reference positions\nOutput: S,P:M a x i m a lc h a i n i n gs c o r ef o re a c ha n c h o ri n Land\ntheir predecessor indexes\n1:function Maximal chaining (L)\n2: start 1\n3: fori 1tonstep: 1do\n4: max score ai.l\n5: predecessor index 1\n6: while Reference gap(a i,astart )i st o ol a r g e do\n7: start start + 1\n8: forj i-1to start step: -1do\n9: ifQuery gap(a i,aj)i st o ol a r g eo rn e g a t i v e then\n10: continue\n11: sj S[j] + ai.l - (gap cost(i, j) + overlap(i, j))\n12: ifsj>m a x score then\n13: max score sj\n14: predecessor index j\n15: ifmax skip threshold reached then break\n16: S[i] max score\n17: P[i] predecessor index\ntrack the maximum scoring chain found so far and\nthe index of the predecessor anchor connected to it.\nConsidering that the gap cost and the overlap can be\ncomputed in constant time, the worst-case time com-\nplexity for the whole chaining step is O(n2).\nMinimap2 applies a set of heuristics to accelerate\nthe chaining step. The while loop (line 6)d e c i d e st h e\nrange of predecessors based on the distance betweenthe two anchors with respect to the reference sequence(i.e. Reference\ngap, as illustrated in Figure 7). For\ninstance, if the gap between two anchors is above a\nuser-speciﬁed threshold, the gap cost is assumed to\nbe1. As the anchors are sorted, the range of an-\nchors with larger distance can trivially be ignored forthe score computation. The ifcondition in the inner\nloop (line 9) applies another set of ﬁlters based on\nthe distances between the anchors with respect to thequery sequence (i.e. Query\ngap, as illustrated in Fig-\nure7). The anchor being considered is ignored if the\ngap is above a certain threshold or negative. After ev-\nery iteration of the inner loop, the max skip condition\n(line 15) is evaluated. According to the heuristic, if we\ndo not ﬁnd a better score over the last max skip at-\ntempts, then the inner loop terminates. In minimap2,\nthe default value for max skip is 25. The sole purpose\nof this heuristic is to accelerate the chaining step po-\ntentially at the cost of chaining accuracy. The heuristic\ncan be disabled by setting max skip to a large value\n(say1) to achieve better chaining accuracy. The ac-\ntual conditional expressions and further implementa-\ntion details can be found in minimap2 paper [ 7].\nOur SIMD version of chaining. As shown previ-\nously in Results section, chaining is one of the mostcompute-intensive steps in the complete pipeline. De-\nspite various heuristics used in the chaining step, themajority of the time is consumed in the execution\nof the inner loop. We accelerate the chaining step\nby redesigning the inner loop to exploit SIMD par-allelism. Typically, modern compilers provide support\nfor auto-vectorization using compilation ﬂags or an-\nnotations which can identify opportunities to convert\nsequential loops to their SIMD version. However, in\npractice, a loop with dependencies and branching in-structions makes auto-vectorization di \u0000cult. We tried\nauto-vectorizing the inner loop using the latest ver-sions of gcc and icpc compilers and veriﬁed that noneof the modern compilers could auto-vectorize the loop.\nDesigning a SIMD-friendly chaining algorithm is non-\ntrivial because the inner loop contains multiple con-\nditional branches, such as Query\ngapand max skip,\nand during the computation of max score. In our op-\ntimizations, we carefully resolved the branches andinter-loop dependencies and adopted a hybrid (sequen-\ntial+SIMD) approach to maximize the vectorization\ngains. We ensured that the sequential and vectorizedversions produce identical chaining output.\nMore speciﬁcally, we made the following improve-\nments to the chaining module•Inner loop vectorization. Algorithm 2shows our\nvectorized algorithm for anchor chaining using 32-bit number representation. We denote !as a SIMD-\nwidth. For instance, using AVX512 bit instructions\nand 32-bit numbers, we can process !=\n512\n32= 16\nelements simultaneously. The inner loop at line 8\nimplements a !-way vectorized version that com-\nputes the maximal chaining scores. Vector instruc-tions perform the same operation over multiple data\nelements. In Algorithm 2, the notation A[i:j] repre-\nsents a vector operation on a range of data elementsA[i] to A[j]. A[i:i] broadcasts the value of A[i] tothe vector register. Similarly, [i:j] and [i:i] loads and\nbroadcasts the constant values to the registers re-\nspectively. Conditional branches ( ifconditions) are\nvectorized using !-bit vector masks; if the branch is\ntaken, the respective bit in the vector mask is set to\n1( l i n e 10). We vectorized gap\ncostandoverlap eval-\nuation, and compute the chaining scores for !prede-\ncessor anchors in one vectorized iteration. Once the\nchaining score is computed, we apply the computed\nmask mcontinue (line 12) such that the scores are\nzeroed out when the respective bit is set in the mask.\nSimilar to the scalar version, the two vector regis-\nters, max score and predecessor index, track the\nmaximum scores across vector lanes. After every\nloop iteration, the max score is compared against\nthe computed chaining scores and masked so that\nthe maximum score is guaranteed to be present in\nthe register. Finally, we extract the maximum score\nand the predecessor index using a sequential pass\nover max score.( l i n e16).. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 9 of 14\nAlgorithm 2 Proposed vectorized chaining\nInput: L:{a1,a2,...,a n}-L i s to fa n c h o r ss o r t e da c c o r d i n gt ot h er e f e r e n c ep o s i t i o n s\nOutput: S,P:M a x i m a lc h a i n i n gs c o r ef o re a c ha n c h o ri n Land their predecessor indexes\n1:function Maximal chaining (L)\n2: start 1\n3: fori 1tonstep: 1do\n4: max score[1: !] a[i:i].l\n5: predecessor index[1:! ] [1:1]\n6: while Reference gap(a i,astart )i st o ol a r g e do\n7: start start + 1\n8: forj i-1to start step: -!do\n9: j’ j-!+1\n10: mcontinue[1:! ] evaluate(Query gap(a [i:i],a[j0:j])i st o ol a r g eo rn e g a t i v e )\n11: s[j0:j] S[j’:j] + a[i:i].l - (gap cost([i:i], [j’:j]) + overlap([i:i], [j’:j]))\n12: s[j0:j] apply( s[j0:j],mcontinue[1:! ])\n13: mscore (s[j0:j]>max score[1: !])\n14: max score[1: !] apply( s[j0:j],mscore)\n15: predecessor index[1:! ] apply([j’:j], m score)\n16: max index extract max index(max score[1: !])\n17: S[i] max score[max index]\n18: P[i] predecessor index[max index]\n•Hybrid vectorized+sequential execution. In\nan ideal scenario, loop vectorization delivers max-\nimum beneﬁt when there is no path divergence due\nto conditional instructions. In the presence of path\ndivergences, vectorized implementation has to com-\npute all control paths and use appropriate masks toobtain the desired outputs. For instance, we need\nto compute the chaining scores for all vector lanes\neven though some of the iterations would have con-\ntinued without computing the chaining scores in\nthe sequential algorithm (Algorithm 1,l i n e 10).\nThis results in wasted computation over the vec-\ntor lanes and leads to sub-optimal performance. Us-\ning AVX512 vectorization, out of 16 vector lanes,\nwe typically found su \u0000cient inner loop iterations\ncomputing the score, thus, beneﬁting from the op-\ntimizations. However, in the case of shorter inner\nloops (say, <16 iterations), we observed that only a\nfew iterations in the sequential algorithm computed\nthe chaining score. In such a case, due to path di-\nvergence, a single vector-iteration might incur more\ninstructions than the sequential executions of few\nscalar iterations. We mitigated this issue by adopt-\ning a hybrid approach: mm2-fast falls back to the\nsequential execution of the inner loop if there are\nfewer than ﬁve iterations; else, it uses the vectorized\nimplementation.\n•Disabling max\nskip heuristic. As mentioned ear-\nlier, max skip condition in Algorithm 1uses a\nheuristic parameter max skip, which accelerates\nchaining in minimap2 at the cost of chaining accu-\nracy. Moreover, max skip condition also poses chal-\nlenges to vectorization as it carries loop dependen-cies. In our optimizations, we disabled this heuristic\nby setting max\nskip to1and removed the condi-tion from our vectorized implementation. This ben-\neﬁted us in two ways: ﬁrst, we resolved the loop car-\nrying dependency resulting in less complex SIMD\nimplementation and better speedup, and second, we\nachieved better chaining accuracy. Note that the\nperformance improvement reported in the result sec-\ntion compares the performance of our optimizations\nwith max skip =1against minimap2 with its\ndefault setting max skip = 25. We achieve up to\n6.1⇥speedup in chaining over minimap2 with de-\nfault heuristics max skip = 25, and up to 12. 7⇥as\ncompared to minimap2 with max skip =1.S u p -\nplementary Figure S2shows the end-to-end perfor-\nmance comparison of mm2-fast against minimap2\nwith max skip = 25 and max skip =1.\nSIMD acceleration for pairwise sequence alignment\nMinimap2 computes DP-based global sequence align-\nment to extend through the gaps between adjacentchained anchors. The presence of long gaps between\nanchors results in slower DP-based alignment, which\ncan be accelerated using SIMD-based vectorization.\nHowever, longer sequences for alignment demand more\nbits to capture the alignment score; this leads to a\nlower number of available vector lanes and hence lower\nparallelism. Minimap2 adopts the Suzuki-Kasahara\n(SK) formulation for DP-based alignment. SK formu-\nlation bounds the number of bits required to capture\nthe score in a DP matrix to the scoring parameters.\nIn practice, these bounds ensure that 8-bits are suf-\nﬁcient for maintaining score values. Therefore, with\n128-bit vector processing available with SSE, 16-wayparallelism is available.\nMinimap2 applies intra-task parallelism, exploiting\nparallelism in a single DP matrix. All the DP matrix. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 10 of 14\ncells along an anti-diagonal are independent of each\nother. Thus, minimap2 applies vectorization with SSE\nSIMD instructions along anti-diagonals to accelerate\nthe alignment. To do so, minimap2 switches from row-\ncolumn-based matrix coordinates to diagonal-anti-\ndiagonal-based coordinates. Additionally, to reduce\nthe computation burden, minimap2 restricts the DP\ncell computations to a certain band around the main\nanti-diagonal. Minimap2 uses a default band value of\n500. Precise details about the alignment computation\nare available in [ 7,32].\nSSE instructions provide only 16-way parallelism.\nUsing 512-bit vector processing (AVX512), the avail-\nable parallellism increases 4-fold to 64-way. Moreover,\nthe default band value in minimap2 is large enough\nto keep all the vector lanes of AVX-512 occupied. In\nmm2-fast, we accelerated the DP-based alignment by\nutilizing AVX-512 vectorization and used additional\nlogic to maintain the output identical to minimap2.\nTo support a wide range of processors, we also devel-\noped an AVX2 version.\nManymap software [ 10] also provides an accelerated\nversion of the alignment module of minimap2 by up-grading the vectorization to AVX-512. Manymap alsoapplies optimizations to marginally reduce the instruc-\ntions in the inner DP loop. However, its alignment\noutput di ↵ers from minimap2, while our solution main-\ntains the exact same output. Due to this, we skip com-\nparing the performance of mm2-fast with Manymap.\nIdeally, moving from SSE to AVX-512 has a poten-\ntial of 4⇥ improvement in the runtime. However, in\npractice, we saw 1. 8\u00002.2⇥speedups due to the fol-\nlowing factors: (a) smaller sequences lead to under-\nutilization of vector lanes, (b) smaller anti-diagonals\nnear the two corners of DP-matrix lead to idle vectorlanes, (c) latency and throughput di ↵erence between\nSSE and AVX-512 vector instructions, and (d) use of\nadditional instructions in the AVX-512 version to en-\nsure the exact same output as the SSE version. Thememory requirements and access pattern of the AVX2\nand AVX512 versions in mm2-fast remain the same as\nthe SSE version in minimap2.\nFunding\nThis work is supported in part by the National Supercomputing Mission\n(NSM) India under DST/NSM /R&D HPC Applications.\nAvailability of data and materials\nmm2-fast source code is available under the open source MIT license at\nhttps://github.com/lh3/minimap2/tree/fast-contrib .\nEthics approval and consent to participate\nNot applicable.\nCompeting interests\nSK, VM and SM are employees of Intel Corporation.\nAuthors’ contributions\nSK led the software implementation of mm2-fast. All authors contributed\nto design of algorithm, experiments and manuscript preparation. All authorsread and approved the ﬁnal manuscript.Author details\n1Intel Labs, 560103 Bangalore, India.2Department of Computational and\nData Sciences, Indian Institute of Science, 560012 Bangalore, India.\nReferences\n1.Chaisson, M.J., Sanders, A.D., Zhao, X., Malhotra, A., Porubsky, D.,\nRausch, T., Gardner, E.J., Rodriguez, O.L., Guo, L., Collins, R.L., et\nal.:M u l t i - p l a t f o r md i s c o v e r yo fh a p l o t y p e - r e s o l v e ds t r u c t u r a lv a r i a t i o n\nin human genomes. Nature communications 10(1), 1–16 (2019)\n2.Conesa, A., Madrigal, P., Tarazona, S., Gomez-Cabrero, D., Cervera,\nA., McPherson, A., Szcze´ sniak, M.W., Ga↵ ney, D.J., Elo, L.L., Zhang,\nX., et al.:As u r v e yo fb e s tp r a c t i c e sf o rr n a - s e qd a t aa n a l y s i s .G e n o m e\nbiology 17(1), 1–19 (2016)\n3.Beyter, D., Ingimundardottir, H., Oddsson, A., Eggertsson, H.P.,\nBjornsson, E., Jonsson, H., Atlason, B.A., Kristmundsdottir, S.,\nMehringer, S., Hardarson, M.T., et al.: Long-read sequencing of 3,622\nicelanders provides insight into the role of structural variants in human\ndiseases and other traits. Nature Genetics, 1–8 (2021)\n4.Rhie, A., McCarthy, S.A., Fedrigo, O., Damas, J., Formenti, G., Koren,\nS., Uliano-Silva, M., Chow, W., Fungtammasan, A., Kim, J., et al.:\nTowards complete and error-free genome assemblies of all vertebrate\nspecies. Nature 592(7856), 737–746 (2021)\n5.De Coster, W., Weissensteiner, M.H., Sedlazeck, F.J.: Towards\npopulation-scale long-read sequencing. Nature Reviews Genetics, 1–16(2021)\n6.Technologies, O.N.: PromethION brochure. [Online; accessed\n3-June-2021] (2021). https://nanoporetech.com/sites/default/\nfiles/s3/literature/PromethION-brochure.pdf\n7.Li, H.: Minimap2: pairwise alignment for nucleotide sequences.\nBioinformatics 34(18), 3094–3100 (2018)\n8.Guo, L., Lau, J., Ruan, Z., Wei, P., Cong, J.: Hardware acceleration of\nlong read pairwise overlapping in genome sequencing: A race between\nFPGA and GPU. In: 2019 IEEE 27th Annual International Symposium\non Field-Programmable Custom Computing Machines (FCCM), pp.\n127–135 (2019). IEEE\n9.Zeni, A., Guidi, G., Ellis, M., Ding, N., Santambrogio, M.D., Hofmeyr,\nS., Bulu¸ c, A., Oliker, L., Yelick, K.: Logan: High-performance\nGPU-based x-drop long-read alignment. In: 2020 IEEE International\nParallel and Distributed Processing Symposium (IPDPS), pp. 462–471(2020). IEEE\n10.Feng, Z., Qiu, S., Wang, L., Luo, Q.: Accelerating long read alignment\non three processors. In: Proceedings of the 48th InternationalConference on Parallel Processing, pp. 1–10 (2019)\n11.Roberts, M., Hayes, W., Hunt, B.R., Mount, S.M., Yorke, J.A.:\nReducing storage requirements for biological sequence comparison.\nBioinformatics 20(18), 3363–3369 (2004)\n12. Abouelhoda, M.I., Ohlebusch, E.: Chaining algorithms for multiple\ngenome comparison. Journal of Discrete Algorithms 3(2-4), 321–341\n(2005)\n13.Jain, C., Gibney, D., Thankachan, S.V.: Co-linear chaining with\noverlaps and gap costs. bioRxiv (2021)\n14.Ho, D., Kalikar, S., Misra, S., Ding, J., Md, V., Tatbul, N., Li, H.,\nKraska, T.: Lisa: Learned indexes for DNA sequence analysis. bioRxiv\n(2020)\n15.Schneider, V.A., Graves-Lindsay, T., Howe, K., Bouk, N., Chen, H.-C.,\nKitts, P.A., Murphy, T.D., Pruitt, K.D., Thibaud-Nissen, F., Albracht,D., et al.:E v a l u a t i o no fG R C h 3 8a n dd en o v oh a p l o i dg e n o m e\nassemblies demonstrates the enduring quality of the reference\nassembly. Genome research 27(5), 849–864 (2017)\n16.Nurk, S., Koren, S., Rhie, A., Rautiainen, M., et al.:T h ec o m p l e t e\nsequence of a human genome. bioRxiv (2021).doi:10.1101/2021.05.26.445798\n17.Cheng, H., Concepcion, G.T., Feng, X., Zhang, H., Li, H.:\nHaplotype-resolved de novo assembly using phased assembly graphs\nwith hiﬁasm. Nature Methods 18(2), 170–175 (2021)\n18.Payne, A., Holmes, N., Clarke, T., Munro, R., Debebe, B.J., Loose,\nM.: Readﬁsh enables targeted nanopore sequencing of gigabase-sizedgenomes. Nature Biotechnology 39(4), 442–450 (2021). CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint \n\nKalikar et al. Page 11 of 14\n19.Kovaka, S., Fan, Y., Ni, B., Timp, W., Schatz, M.C.: Targeted\nnanopore sequencing by real-time mapping of raw electrical signal with\nuncalled. Nature Biotechnology 39(4), 431–441 (2021)\n20.Zhang, H., Li, H., Jain, C., Cheng, H., Fai Au, K., Li, H., Aluru, S.:\nReal-time mapping of nanopore raw signals. Bioinformatics (in press)(2021)\n21.Jain, C., Rhie, A., Hansen, N., Koren, S., Phillippy, A.M.: A long read\nmapping method for highly repetitive reference sequences. bioRxiv\n(2020)\n22.Sedlazeck, F.J., Rescheneder, P., Smolka, M., Fang, H., Nattestad,\nM., Von Haeseler, A., Schatz, M.C.: Accurate detection of complexstructural variations using single-molecule sequencing. Nature methods\n15(6), 461–468 (2018)\n23.Ren, J., Chaisson, M.: lra: the long read aligner for sequences and\ncontigs. bioRxiv (2020)\n24.Kraska, T., Beutel, A., Chi, E.H., Dean, J., Polyzotis, N.: The Case for\nLearned Index Structures. In: ACM International Conference onManagement of Data (SIGMOD), pp. 489–504 (2018)\n25. Galakatos, A., Markovitch, M., Binnig, C., Fonseca, R., Kraska, T.:\nFITing-Tree: A Data-aware Index Structure. In: Proceedings of the2019 International Conference on Management of Data. SIGMOD ’19,pp. 1189–1206. ACM, New York, NY, USA (2019).\ndoi:10.1145/3299869.3319860 .\nhttp://doi.acm.org/10.1145/3299869.3319860\n26.Ferragina, P., Vinciguerra, G.: The PGM-index: a multicriteria,\ncompressed and learned approach to data indexing (2019).\n1910.06169. http://arxiv.org/abs/1910.06169\n27.Ding, J., Minhas, U.F., Zhang, H., Li, Y., Wang, C., Chandramouli,\nB., Gehrke, J., Kossmann, D., Lomet, D.B.: ALEX: An UpdatableAdaptive Learned Index (2019). 1905.08898.\nhttp://arxiv.org/abs/1905.08898\n28.Wu, Y., Yu, J., Tian, Y., Sidle, R., Barber, R.: Designing Succinct\nSecondary Indexing Mechanism by Exploiting Column Correlations. In:Proceedings of the 2019 International Conference on Management of\nData. SIGMOD ’19, pp. 1223–1240. ACM, New York, NY, USA\n(2019). doi: 10.1145/3299869.3319861 .\nhttp://doi.acm.org/10.1145/3299869.3319861\n29.Kirsche, M., Das, A., Schatz, M.C.: Sapling: accelerating su\u0000x array\nqueries with learned data models. Bioinformatics 37(6), 744–749\n(2021)\n30.Marcus, R., Kipf, A., van Renen, A., Stoian, M., Misra, S., Kemper,\nA., Neumann, T., Kraska, T.: Benchmarking Learned Indexes. In:\nPVLDB, vol. 14, pp. 1–13 (2021)\n31.Marcus, R., Zhang, E., Kraska, T.: Cdfshop: Exploring and optimizing\nlearned index structures. In: Proceedings of the 2020 ACM SIGMOD\nInternational Conference on Management of Data. SIGMOD ’20, pp.2789–2792. Association for Computing Machinery, New York, NY,\nUSA (2020). doi: 10.1145/3318464.3384706 .\nhttps://doi.org/10.1145/3318464.3384706\n32.Suzuki, H., Kasahara, M.: Introducing di↵ erence recurrence relations\nfor faster semi-global alignment of long sequences. BMC\nbioinformatics 19(1), 33–47 (2018)\nOptimization Notice: Software and workloads used in\nperformance tests may have been optimized for performance\nonly on Intel microprocessors. Performance tests, such as\nSYSmark and MobileMark, are measured using speciﬁc\ncomputer systems, components, software, operations and\nfunctions. Any change to any of those factors may cause the\nresults to vary. You should consult other information and\nperformance tests to assist you in fully evaluating your\ncontemplated purchases, including the performance of that\nproduct when combined with other products. For more\ninformation go to http://www.intel.com/performance. Intel,\nXeon, and Intel Xeon Phi are trademarks of Intel\nCorporation in the U.S. and/or other countries.. CC-BY-NC-ND 4.0 International license available under awas not certified by peer review) is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity. It is made The copyright holder for this preprint (which this version posted July 23, 2021. ; https://doi.org/10.1101/2021.07.21.453294doi: bioRxiv preprint ",
  "textLength": 50343
}