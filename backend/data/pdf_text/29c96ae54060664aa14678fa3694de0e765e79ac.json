{
  "paperId": "29c96ae54060664aa14678fa3694de0e765e79ac",
  "title": "Towards Similarity Graphs Constructed by Deep Reinforcement Learning",
  "pdfPath": "29c96ae54060664aa14678fa3694de0e765e79ac.pdf",
  "text": "Towards Similarity Graphs Constructed\nby Deep Reinforcement Learning\nDmitry Baranchuk1 2Artem Babenko1 3\nAbstract\nSimilarity graphs are an active research direction\nfor the nearest neighbor search (NNS) problem.\nNew algorithms for similarity graph construction\nare continuously being proposed and analyzed\nby both theoreticians and practitioners. How-\never, existing construction algorithms are mostly\nbased on heuristics and do not explicitly maxi-\nmize the target performance measure, i.e., search\nrecall. Therefore, at the moment it is not clear\nwhether the performance of similarity graphs has\nplateaued or more effective graphs can be con-\nstructed with more theoretically grounded meth-\nods. In this paper, we introduce a new principled\nalgorithm, based on adjacency matrix optimiza-\ntion, which explicitly maximizes search efﬁciency.\nNamely, we propose a probabilistic model of a\nsimilarity graph deﬁned in terms of its edge prob-\nabilities and show how to learn these probabilities\nfrom data as a reinforcement learning task. As\nconﬁrmed by experiments, the proposed construc-\ntion method can be used to reﬁne the state-of-the-\nart similarity graphs, achieving higher recall rates\nfor the same number of distance computations.\nFurthermore, we analyze the learned graphs and\nreveal the structural properties that are responsible\nfor more efﬁcient search.\n1. Introduction\nIn this paper, we address nearest neighbor search (NNS), a\nlong-standing problem, arising in a large number of machine\nlearning applications, such as recommender services, infor-\nmation retrieval, and others. The NNS problem is formal-\nized as follows. Given the database D=fv1;:::;vNg\u001a\nRdand a query q2Rd, one needs to ﬁnd the datapoint\nv2Dthat is closest to the query in terms of some distance\n1Yandex, Russia2Lomonosov Moscow State University,\nRussia3National Research University Higher School of Eco-\nnomics, Russia. Correspondence to: Dmitry Baranchuk\n<dmitry.baranchuk@graphics.cs.msu.ru>.(e.g. Euclidean). As the sizes of databases jDjin arising\npractical tasks are constantly increasing, the efﬁciency and\nthe scalability of NNS become crucial.\nThus, the problem of efﬁcient NNS receives much atten-\ntion from the machine learning community. Well-known\nestablished approaches, based on partition trees (Bentley,\n1975; Sproull, 1991; McCartin-Lim et al., 2012; Dasgupta\n& Freund, 2008; Dasgupta & Sinha, 2013) and locality-\nsensitive hashing (LSH) (Indyk & Motwani, 1998; Datar\net al., 2004; Andoni & Indyk, 2008; Andoni et al., 2015)\nhave been developed by ML researchers for decades and\nprovide both decent practical performance and theoretical\nguarantees. Recently, similarity graph methods (Navarro,\n2002; Malkov & Yashunin, 2016; Fu & Cai, 2016; Fu et al.,\n2017), were shown to outperform tree-based and LSH-based\ntechniques (Aumüller et al., 2017). These methods repre-\nsent the database as a graph, and at the search stage, a query\ntraverses the graph via beam search. While these methods\ndo not have full theoretical support yet, their exceptional\npractical performance has shifted the research attention to\nthe development of new approaches based on this paradigm.\nDue to the great importance of the NNS problem, new algo-\nrithms for similarity graphs construction are being proposed\nand analyzed by both theoreticians (Laarhoven, 2018) and\npractitioners (Fu & Cai, 2016; Malkov & Yashunin, 2016;\nFu et al., 2017; Iwasaki & Miyazaki, 2018). Most of these\nworks, however, propose new heuristics-based procedures,\nwhich do not explicitly optimize search efﬁciency. More-\nover, different methods often achieve superior results only\non a subset of datasets, which implies that the proposed\nheuristics are not universally applicable.\nIn this work, we introduce a new method for similarity graph\nconstruction that explicitly maximizes the search efﬁciency\nvia optimization of the graph adjacency matrix. Speciﬁcally,\nwe deﬁne a probabilistic model of a similarity graph in terms\nof its edge probabilities. Then we learn these probabilities\nfrom data, maximizing the search efﬁciency for a large set of\ntraining queries. It appears that this task could be naturally\ntreated as a reinforcement learning problem. As a result,\nthe proposed algorithm produces a graph that outperforms\ngraphs constructed via heuristic approaches.arXiv:1911.12122v2  [cs.LG]  13 Feb 2020\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nTo sum up, the contributions of this paper are as follows:\n1.We develop a new algorithm for similarity graph con-\nstruction that explicitly optimizes search efﬁciency. To\nthe best of our knowledge, all existing methods are\nbased on heuristics that can have limited niches of\napplicability.\n2.By experiments on common benchmarks, we show\nthat the proposed algorithm can be used to reﬁne state-\nof-the-art similarity graphs, which allows to achieve\nhigher recall rates under the same number of distance\ncomputations. We also analyse the learned graphs and\ninvestigate the properties that cause the gains.\n3.We demonstrate a novel practical large-scale appli-\ncation of the reinforcement learning machinery that\nexplicitly optimizes the quality of similarity graphs\nwith millions of edges.\nThe rest of the paper is organized as follows. First, we\ndiscuss relevant prior works. Then we describe the pro-\nposed RL-based graph construction algorithm, empirically\nanalyze it and conﬁrm its advantage over heuristic-based\nmethods. The source code of our algorithm and experiments\nare available online1\n2. Related work\nHere we brieﬂy review the ideas from the prior works that\nare relevant to our approach.\nNearest neighbor search techniques. The existing NNS\napproaches mostly fall into three research directions. Meth-\nods from the ﬁrst direction, based on partition trees (Bentley,\n1975; Sproull, 1991; McCartin-Lim et al., 2012; Dasgupta &\nFreund, 2008; Dasgupta & Sinha, 2013), hierarchically split\nthe search space into a large number of regions, correspond-\ning to tree leaves, and the query visits only a limited number\nof promising regions when searching. Second, locality-\nsensitive hashing methods (Indyk & Motwani, 1998; Datar\net al., 2004; Andoni & Indyk, 2008; Andoni et al., 2015)\nmap the database points into several buckets using several\nhash functions such that the probability of collision is much\nhigher for nearby points than for points that are further apart.\nAt the search stage, a query is also hashed, and distances\nto all the points from the corresponding buckets are eval-\nuated. The third direction of similarity graphs (Navarro,\n2002; Malkov & Yashunin, 2016; Fu & Cai, 2016; Fu et al.,\n2017; Iwasaki & Miyazaki, 2018) represents the database as\na directed graph, and on the search stage, a query traverses\nthe graph via beam search. The empirical performance of\nsimilarity graphs was shown to be much higher compared\nto LSH-based and tree-based methods (Yu. A. Malkov,\n1https://github.com/dbaranchuk/nns-meets-deep-rl2016). In more details, the typical search process in similar-\nity graphs performs as follows. The database is organized\nin a graph, where each vertex corresponds to some data-\npoint, and the vertices, corresponding to the neighboring\ndatapoints, are connected by edges. The search algorithm\npicks a start vertex (random or predeﬁned) and iteratively\nexplores the graph from it. On each iteration, the query\ntries to improve its position by moving to a vertex from\na candidate pool that is closest to the query. The routing\nprocess stops when there are no closer vertices in the pool.\nSimilarity graphs construction procedures. Several re-\ncent works developing similarity graph methods typically\ndiffer in graph construction procedures, based on differ-\nent heuristics. For instance, the recent HNSW algorithm\n(Yu. A. Malkov, 2016) performs consecutive insertions of\ndatabase items into the graph structure. This procedure\nprovides long-range edges for efﬁcient graph navigation.\nMoreover, an additional structure of a nested hierarchy of\nlayers is proposed for further speedup. Another recent graph,\nNSG (Fu et al., 2017), employs a k-nearest neighbor graph\nas an initial graph structure, then performs the search proce-\ndure with each node being a query, connects the node with\nvertices visited during the search and selects edges follow-\ning the pruning strategy. The recently proposed graph-based\nmethod NGT-onng (Iwasaki & Miyazaki, 2018) provides\na set of heuristics for graph construction and ﬁnds optimal\nindegrees and outdegrees for a speciﬁc precision region.\nBoth (Fu et al., 2017; Iwasaki & Miyazaki, 2018) report that\nthe advantage of different graphs is revealed on different\ndatasets, which implies the limitations of the heuristics in\nuse. Instead, our approach aims to learn the graph from data,\nexplicitly optimizing the search efﬁciency.\nLearning of data structures. The recent line of works\n(Kraska et al., 2018; 2019) proposes to use machine learn-\ning methods instead of the traditional database indices, such\nas B-trees and Bloom Filters. While being related, these\nmethods are not directly applied to the construction of simi-\nlarity graphs, which we address in this paper.\nReinforcement learning for discrete structures. Our ap-\nproach is partially inspired by the recent RL success for\nstructure learning in different machine learning pipelines.\nProbably, the most well-known use-case is the learning of\nDNN structure (Zoph & Le, 2016). Another related recent\nwork is DeepPath (Xiong et al., 2017) that employs RL to\nlearn structures of the knowledge graphs. In this paper, we\ndemonstrate that RL is also a natural ﬁt for the problem of\nsimilarity graph construction for NNS.\n3. Method\nIn this section, we describe our approach for similarity graph\nconstruction based on reinforcement learning.\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\n3.1. Similarity graph construction as an optimization\nproblem\nFirst, we introduce a probabilistic model of a similarity\ngraph. Our model deﬁnes a probability of a graph as a joint\nprobability of individual edges. Each edge is modelled as\nan independent Bernoulli random variable bi\u0018Bern (pi)\nthat determines whether this edge should exist in the graph.\nTherefore, the probability of the graph Gis a product of\nprobabilities of all edges: P(G) =P(b1;b2;:::;bn) =Q\nipbi\ni(1\u0000pi)1\u0000bi. Our goal then is to maximize the fol-\nlowing objective:\nP\u0003(G)= arg max\nP(G)Eq\u0018p(q)EG\u0018P(G)R(G;q)\nR(G;q) =F(Accuracy (G;q);Complexity (G;q))(1)\nHereEq\u0018p(q)denotes the expectation over the query dis-\ntribution.Accuracy (G;q)andComplexity (G;q)are\nresponsible for high search recall and high search efﬁ-\nciency respectively. F(\u0001;\u0001)plays a role of an \"acquisi-\ntion\" function that combines both Accuracy (G;q)and\nComplexity (G;q)into one scalar value. We elaborate on\neach of these terms in the next section.\nBy solving the optimization problem (1), we ﬁnd the edge\nprobabilitiesfp1;:::;pngthat maximize the accuracy and\nminimize the search complexity in expectation over graphs\nG\u0018P(G).\nFinally, we obtain a deterministic graph2as\nG\u0003= arg maxGP\u0003(G), which corresponds to keep-\ning the edges with p\u00150:5and omitting the edges with\np<0:5. This graph then can be used for NNS with one of\nthe standard search algorithms.\nFor large-scale problems, optimizing over a quadratic num-\nber of edges is infeasible. In this case we take some ini-\ntial similarity graph ^Gand reﬁne it, pruning its edges via\noptimization (1) over edges presented in ^G. We obtain a\nsubgraphG\u0003\u0012^Gthat is more efﬁcient in terms of nearest\nneighbor search performance. For small-scale datasets, we\naim to optimize the complete graph since it is guaranteed to\ncontain the optimal one.\n3.2. Markov Decision Process\nNow let us formulate the optimization problem (1) as a\nMarkov Decision Process (MDP). We consider the initial\ngraph ^Gand search algorithm as the environment E. An\nMDP agent interacts with the environment using two avail-\nable actions a: \"remove\" or \"keep\" an edge. The envi-\n2Here we exploit the fact that our optimization problem (1)\nhas a deterministic solution i.e. a graph where p2 f0;1g. This\nproperty holds because our problem is equivalent to a Markov De-\ncision Process. It can be proven that all MDPs have a deterministic\noptimal policy (Puterman, 1994).ronment state s= (q;vi;vadj;V;H )consists of a query q,\ncurrent vertex vi, its adjacent vertices vadj, already visited\nverticesVand a heap of candidates H. The transition func-\ntionTrepresents the search algorithm. In our work we ex-\nploit the standard HNSW search algorithm (Yu. A. Malkov,\n2016) and incorporate the RL agent in the loop, see Algo-\nrithm 1.\nAlgorithm 1 The nearest neighbor search algorithm with\nincorporated RL agent.\nData: graph ^G, queryq, initial vertex v0, output size k\nInitialization:\nV \u0000fv0g// a set of visited vertices\nH \u0000fv0:d(v0;q)g// a heap of candidates\nTopK \u0000fv0:d(v0;q)g// a heap of top-k results\nwhile not should_stop do\n/*i-th search step */\nvi \u0000extract nearest element from Htoq\nvadj \u0000get adjacent vertices of vi\ns \u0000(q;vi;vadj;V;H )// collect environment state\n^vadj \u0000Agent(s) // predict what connections to keep\nfor^v2^vadjnVdo\nV \u0000Add(V;^v)\nH \u0000Insert (H;^v;d(^v;q))\nTopK \u0000Update (TopK;k; ^v;d(^v;q))\nend\nend\nreturnTopK\nSessions . We introduce a session \u001cas a search procedure\nfor a single query q. On each step, the search procedure\nvisits a vertex and updates the state s. The agent obtains\nsand decides which edges are available from that vertex.\nIn turn, the search algorithm processes the kept edges and\npicks the next vertex. After the search terminates, the agent\nobtains a rewardRfor the entire session.\nReward function . Our reward function R(\u001c)combines\ntwo components: accuracy and complexity of the search\nprocess. The accuracy for one session is an indicator I[\u001c]if\nthe actual nearest neighbor is found. This term encourages\nthe agent to maximize search recall. For instance, it may\nexclude edges that cause the search procedure to get stuck\nin poor local optima. The second component measures the\nsearch complexity as a number of distance computations\nDCS during one session. This term effectively encourages\nthe agent to prune irrelevant edges.\nWe deﬁne the reward function as:\nR(\u001c) =I[\u001c]\u0001max (DCSmax\u0000DCS; 1) (2)\nwhereDCSmax is a distance computation budget, which\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nis set to restrict the search complexity for each query. Intu-\nitively, we want the agent to ﬁnd the actual nearest neighbor\nand then to reduce the complexity without an accuracy drop.\nIf the nearest neighbor is not found then R(\u001c)=0 regardless\nofDCS , otherwise the agent obtains higher reward for more\ncomputationally efﬁcient sessions. With lower DCSmax\nvalues, the agent is more prone to sacriﬁcing accuracy on\nsome queries for more efﬁcient search on others. We also\nobserve that the value of DCSmax affects the algorithm\nconvergence by changing the \"sharpness\" of the objective\nfunction. In practice, we tune this parameter empirically\nbased on average vertex degree and the desired recall region.\n3.3. Policy Network Architecture\nIn our method, the agent is a policy network that pre-\ndicts edge probabilities. For simplicity, we use a feed-\nforward architecture that processes each edge individually:\n\u0019\u0012(bjs)=Qn\ni\u0019\u0012(bijxi(s)). The network receives an edge,\nrepresented as a concatenation of source and target vertices\nxi(s)= [vsource;vtarget ], as input and predicts its probabil-\nity. The network itself consists of two linear layers with\nELU activations followed by another linear layer with sig-\nmoid non-linearity. While more powerful network archi-\ntectures can be used (e.g., Graph Convolutional Networks\n(Kipf & Welling, 2016)), they are typically inapplicable in\nthe large-scale scenario due to GPU memory constraints\nand long training time.\n3.4. Policy optimization\nWe can now apply policy-based RL to directly optimize the\nexpected reward (2). The overall scheme of our approach is\npresented in Figure 1.\nAmong policy-based methods such as REINFORCE\n(Williams & Peng, 1991), PPO (Schulman et al., 2017),\nACKTR (Wu et al., 2017), etc, we have found that TRPO\n(Schulman et al., 2015) provides the fastest convergence and\nthe highest reward values. The main practical drawback of\nTRPO is that it requires a large number of sessions to per-\nform an accurate natural gradient update. However, in our\ncase, each session requires only a single run of the search\nalgorithm, hence we can efﬁciently sample a large number\nof search trajectories in parallel.\nWe also adapt two common policy optimization tricks for\nour setting. First, we use reward baselines to speed up\nconvergence by reducing gradient variance. Our algorithm\nmaintains an individual baseline for each training query as a\nmoving average of observed rewards for that query. Second,\nwe facilitate exploration by adding policy entropy to the\ntraining objective. This long-standing technique (Williams\n& Peng, 1991) discourages the agent from premature con-\nvergence to a suboptimal deterministic policy.\nq\nstartgt\nlocal minimaEnvironment\nStateAgent\nπ(a∣s)ELU\nELU\nAction {   ,   }  State\nReward\nSigmoid\nFigure 1. Overview of the proposed RL scheme for graph construc-\ntion. It is presented as a communication between the environment\nand agent. Left: the environment is a similarity graph equipped\nwith a search algorithm. On each step, the search algorithm visits a\nnode and updates the environment state. Right: the agent obtains\nthe state and uses policy network to predict which outgoing edges\nto preserve. Then, the search procedure processes the kept edges\nand transits to the next node. When the search terminates, the\nagent obtains a total reward for the entire session.\n3.5. Training on large databases\nFor large-scale problems, our approach becomes limited by\nthe number of edges it can consider. Namely, if the agent\nis allowed to draw edges between arbitrary vertices, the\nnumber of edges grows quadratically with the database size.\nHence it is practically infeasible to train such an agent on\nthe complete graph built upon large databases typical for\nNNS problems. To mitigate this issue, we limit the agent\nto a predeﬁned subset of edges. Namely, we construct one\nof the existing heuristics-based graphs and allow our agent\nto select edges from that graph. In all our experiments, the\ninitial graph vertex degrees are equal or slightly larger than\nin baseline graphs which, by themselves, appear to have\nredundant edges.\nTo speed-up training, we also employ the following heuristic.\nIf an agent’s prediction for a particular edge is overconﬁ-\ndent for a long period during training, we consider this edge\ndeterministic and do not optimize over it. This heuristic re-\nduces optimization problem complexity and allows the agent\nto concentrate on adjusting predictions for more uncertain\nedges. As a possible research direction, it is interesting to\ndevelop an effective method for expanding the search space,\ne.g. by interactively adding new edges during training.\n4. Experiments\nIn this section, we evaluate and analyze graphs constructed\nby our approach. First, we visualize a toy graph, learned for\na small dataset, and describe several interesting observations.\nThen, we provide an experimental comparison of the con-\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nstart\nFigure 2. Left: the constructed graph on 100 vectors from the MNIST8x8 dataset. The optimization is performed over a complete graph.\nColors correspond to the MNIST class labels. The nodes providing efﬁcient graph navigation (hubs) are denoted by large sizes. Each\nMNIST class contains up to two hubs. Right: the outdegree histogram for the obtained graph. Most vertices have zero outdegree and only\nfew with degrees greater than six. All high outdegree nodes correspond to hubs.\nstructed graphs with state-of-the-art graph-based methods\nand analyse the emerging properties of the learned graphs.\n4.1. Toy example\nWe visualize graphs constructed by our method on a small\nsubset of the MNIST8x8 (Dua & Graff, 2017) dataset.\nNamely, we sample 100 64 -dimensional vectors for the\nbase set and use the entire dataset as training queries.\nIn this experiment, we use greedy search as the search algo-\nrithm: we choose the next vertex as the closest one among\nneighbors of the current query position. The RL agent starts\ntraining from a complete graph, and we set DCSmax=150 .\nAfter the training we manually remove edges that are never\nused by the search algorithm. Such edges affect neither\nrecall norDCS and only bring noise to degree distribution.\nAt convergence, the constructed graph achieves 0:957recall.\nOn average, the search algorithm requires 22DCS and\nterminates after 2:85graph hops. The average outdegree is\nreduced from 99to2:45.\nFinally, we project the base vectors onto 2D plane, using\ntSNE (Maaten & Hinton, 2008) and illustrate the graph\nstructure on Figure 2 (left). The vertex colors correspond to\nthe MNIST class labels. The start vertex is the entry point\nfor the search algorithm — a medoid of the base set.\nIn order to analyze the properties of the learned similaritygraph, we run the search algorithm for all queries and ag-\ngregate the following statistics: (1) how often each node\nis visited and (2) for what number of queries each node\nis an actual nearest neighbor. Below we highlight several\nobservations from Figure 2 and explain our intuition about\ngraphs appropriate for the NNS problem.\n\u000fWe observe an appearance of few nodes, so-called hubs,\nthat provide efﬁcient navigation over the graph. Each\nMNIST class contains one or two hubs. The start\nnode is connected to hubs for fast navigation to a query\nregion. At the ﬁrst step, the search navigates to one of\nthe hubs. Then, it either ﬁnds the answer or transits to\nanother local hub, which is closer to an actual nearest\nneighbor. The existence of hubs allows the search\nalgorithm to reach answers just in two or three hops.\nAt the same time, the average node outdegree is low,\nas the number of hubs is small.\n\u000fMost vertices do not participate in graph navigation.\nThe search algorithm mostly visits such a vertex if it\nis the actual nearest neighbor for a given query. These\nvertices are usually terminal, hence their outdegrees\nare almost zeros.\nAdditionally, we plot the outdegree histogram for the con-\nstructed graph on Figure 2 (right). Most vertices have zero\noutdegrees and only few have a degree greater than six. This\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nSIFT100K DEEP100K\n340 380 420 460 500 540 580 620 660 700 740\nDCS0.900.910.920.930.940.950.960.970.980.99Recall@1\nNSG Ours\nNSW Ours\nNSG\nHNSW\nNSW\n340 380 420 460 500 540 580 620 660 700 740 780 820 860\nDCS0.900.910.920.930.940.950.960.970.980.99Recall@1\nNSG Ours\nNSW Ours\nNSG\nHNSW\nNSW\nFigure 3. Recall @1values as functions of distance computations DCS on the SIFT100K and DEEP100K datasets.\nSIFT1M DEEP1M GloVe1M\n410 470 530 590 650 710 770 830 890\nDCS0.810.820.830.840.850.860.870.880.890.900.910.920.930.940.950.96Recall@1\nNSW Ours\nHNSW\nNSW\n415 475 535 595 655 715 775 835 895 955\nDCS0.810.820.830.840.850.860.870.880.890.900.910.920.930.940.950.96Recall@1\nNSW Ours\nHNSW\nNSW\n1500 2000 2500 3000 3500 4000 4500\nDCS0.700.710.720.730.740.750.760.770.780.790.800.810.820.830.840.850.860.870.88Recall@1\nNSW Ours\nHNSW\nNSW\nFigure 4. Recall @1values as functions of distance computations DCS on the SIFT1M, DEEP1M and GloVe1M datasets.\nroughly resembles the truncated power-law distribution over\noutdegrees. Interestingly, all high-outdegree nodes are hubs.\nA prior work(Malkov & Ponomarenko, 2016) investigates\nthe properties of graphs with truncated power-law degree\ndistribution for the NNS problem and shows that such de-\ngree distribution is likely to provide an efﬁcient search. In\nour approach, such properties emerge naturally from search\nperformance optimization over the complete graph.\n4.2. Datasets\nWe evaluate the proposed approach on three publicly avail-\nable datasets described below:\n1.SIFT100K dataset (Jégou et al., 2011) is sampled from\none million 128-dimensional SIFT descriptors. We\nconsider 100,000 learn vectors and remained base vec-\ntors as train queries. Note, the original learn set con-\ntains test queries, therefore we manually remove them.\nWe take 20,000 datapoints for validation. The hold-out\n10,000 query vectors are used for evaluation.\n2.SIFT1M dataset contains one million SIFT descriptors\nsampled from SIFT1B (Jégou et al., 2011). We sample\none million train queries from the learn set. Again,\nwe leave 20,000 queries for validation and evaluate on\noriginal 10,000 hold-out queries.3.DEEP100K dataset (Babenko & Lempitsky, 2016) is a\nsubset of one billion of 96-dimensional CNN-produced\nfeature vectors of natural images from the Web. The\nbase set contains 100,000 vectors. We sample 200,000\ntrain and 20,000 validation queries from the learn set.\nFor evaluation, we use the original 10,000 queries.\n4.DEEP1M dataset is the same as DEEP100K where\nthe base and learn sets are extended to one million\ndatapoints.\n5.GloVe1M dataset (Pennington et al., 2014) contains 2.2\nmillions of 300-dimensional word embeddings trained\non Common Crawl. We split them on one million base\nset, one million learn set, 20,000 queries for validation\nand 10,000 queries for evaluation.\n4.3. Search performance evaluation\nHere we compare the graphs constructed with our method to\nstate-of-the-art baselines on the SIFT100K and DEEP100K\ndatasets. Namely, we evaluate:\n\u000fHNSW : one of the current state-of-the-art graphs pro-\nposed in (Yu. A. Malkov, 2016); this approach exploits\nthe nested hierarchy of navigable small-world graphs\nconstructed on the database subsets to obtain a start\nvertex.\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\n0 5 10 15 20 25 30 35 40020000400006000080000100000FrequenciesNSW\n0 5 10 15 20 25 30 35 40050001000015000200002500030000NSG\n0 5 10 15 20 25 30 35 40\nVertices020000400006000080000100000FrequenciesNSW Ours\n0 5 10 15 20 25 30 35 40\nVertices050001000015000200002500030000NSG Ours\n0 5 10 15 20 25 30 35 4005000100001500020000250003000035000FrequenciesNSW\n0 5 10 15 20 25 30 35 40010000200003000040000NSG\n0 5 10 15 20 25 30 35 40\nVertices05000100001500020000250003000035000FrequenciesNSW Ours\n0 5 10 15 20 25 30 35 40\nVertices010000200003000040000NSG Ours\nSIFT100K DEEP100K\nFigure 5. Search visitation frequencies for 40 most visited vertices, sorted by frequency (except for start vertex). The top row represents\nthe baseline graphs; the bottom row depicts their counterparts optimized by our method.\n\u000fNSW : the bottom layer of HNSW graph. The search\nstarts from the ﬁxed vertex for all queries.\n\u000fNSG : another state-of-the-art similarity graph method\n(Fu et al., 2017); NSG does not use any additional in-\ndexing structure and starts the search from the database\nmedoid.\n\u000fNSW Ours : RL approach applied to the NSW graph.\n\u000fNSG Ours : RL approach applied to the NSG graph.\nWe tune hyperparameters for all baseline graphs in each\nrecall region. All parameters for the graphs listed above\nare reported in the supplementary materials. Note that the\nproposed RL-based approach can also be applied to graphs\nwith additional indexing structures (e.g., HNSW, NGT).\nHowever, we leave it beyond the scope of our evaluation.\nAs a primary performance measure, we use Recall @1,\nwhich is calculated as a rate of queries for which the search\nalgorithm successfully ﬁnds the actual nearest neighbor.\nMost million-scale experiments converge within \u001824hours\non a single GPU GeForce 1080Ti. We rerun the RL ap-\nproach at least ﬁve times for each graph and draw its mean\nand standard deviation. The plots for the SIFT100K and\nDEEP100K datasets are presented on Figure 3, and the plots\nfor SIFT1M, DEEP1M, GloVe1M are presented on Figure 4.\nFor all datasets, we observe a consistent improvement over\ncorresponding baseline graphs. We highlight several key\nobservations below:\n\u000fOn SIFT100K, the optimized NSG consistently out-performs all other evaluated graphs. In particular, we\nobserve up to\u00181%improvement compared to the top-\nperforming NSG baseline. On DEEP100K, the op-\ntimized NSW graph also outperforms HNSW/NSW\ngraph by up to\u00181%. For 99+%Recall @1region,\nthe gains become insigniﬁcant. Note that NSG graphs\nare superior on SIFT data, while NSW/HNSW per-\nforms better on the DEEP100K dataset. This is a\nweakness of heuristic-based similarity graphs: differ-\nent heuristics are more appropriate for different data.\nOur RL-based approach may signiﬁcantly reduce the\ngap in performance. E.g., while NSG outperforms\nNSW by up to\u00182:5%on SIFT100K, the maximum\ngap between optimized graphs reduces to \u00180:4%. On\nDEEP100K, NSW/HNSW outperforms NSG by up\nto\u00183:0%, while, for NSW Ours and NSG Ours, the\nmaximum difference is \u00181:3%.\n\u000fOn all datasets, we observe more signiﬁcant gains for\nlowerRecall @1regions. While our hypothesis that the\nRL approach mainly inﬂuences the navigation proper-\nties of similarity graphs, this observation is consistent\nwith the fact that navigation properties lose their value\nif the search algorithm’s heap size increases.\n\u000fOn all datasets and all Recall @1regions, the opti-\nmized NSW is superior or equal to HNSW, which\nexploits an additional indexing structure for better nav-\nigation. Therefore, the nested hierarchy of graphs is\nredundant and can be replaced by its bottom layer with\nimproved navigation properties.\n\u000fOn the most challenging dataset, GloVe1M,\nNSW/HNSW graphs demonstrate much worse\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nperformance due to the high intrinsic dimensionality of\nthe word embeddings. For this dataset, our approach\nmitigates the issues of NSW/HNSW graphs and\noutperforms baselines by \u00180:4%at88%Recall @1\npoint.\n4.4. Graph properties analysis\nIn this section, we analyze the emerging properties of graphs\nlearned by the proposed algorithm. Our primary hypothesis\nis that the advantage of our method in terms of search efﬁ-\nciency is attributed to its ability to learn more specialized\nroles for graph vertices, similarly to what we observed in\nthe toy experiment.\nIn order to test this hypothesis, we study the statistical prop-\nerties of frequently visited vertices. In both NSW and NSG\ngraphs, there is a small subset of vertices that help the search\nprocedure to navigate during the ﬁrst few graph hops. Hence,\nan improvement in these vertices may have a substantial ef-\nfect on the overall search efﬁciency.\nWe consider 40 vertices that are the most frequently visited\nby the search algorithm. For each vertex, we count its\nnumber of visits over 105training queries. The obtained\nnumbers of visits for baseline graphs and graphs produced\nby our method are presented on Figure 5.\nFigure 5 clearly indicates that graphs produced by our\nmethod have a more peaky distribution over vertex visit\nfrequencies compared to both baselines. In other words,\ndirectly optimizing graph for nearest neighbor search pro-\nduces more specialized navigation vertices.\nInterestingly, our RL approach can also learn a new starting\nvertex, see NSW Ours on SIFT100K in Figure 5. The agent\nomits all edges in initial starting vertex except one. Hence,\nfor every query the search procedure goes to the new starting\nnode by performing only one distance computation. Note\nthat “peakyness” of the distributions from Figure 5 corre-\nlates with relative performance of heuristics-based graphs\non different datasets. For instance, on SIFT100K NSG\nhas more pronounced hubs and outperforms NSW on this\ndataset, see Figure 3. In contrast, on DEEP100K, NSW has\nmore “peaky” distribution compared to NSG and provides\nsuperior search performance.\nWe conjecture that our algorithm is better able to learn the\nedges for the navigation vertices, achieving more accurate\nrouting, compared to heuristics-based counterparts.\n4.5. Comparison to heuristic methods\nIn this experiment, we evaluate our approach against one\nof the heuristic methods, which can be used for similarity\ngraph improvement.\nHere, we consider magnitude-based pruning , where the\n415 475 535 595 655 715 775 835 895 955\nDCS0.810.820.830.840.850.860.870.880.890.900.910.920.930.940.950.96Recall@1\nNSW Ours + MP\nNSW Ours\nNSW + MP\nNSWFigure 6. Comparison to magnitude-based pruning (MP) for the\nNSW graph on DEEP1M dataset.\nweights for each edge are computed as follows:\nwij=n_visited _eij+\u0015\nn_visited _vi+\u0015\u0001outdegree (vi)(3)\n, wheren_visited _eijandn_visited _vicorrespond to vis-\nitation frequencies for edge eijand vertexvirespectively.\nWe compute these frequencies by running search procedure\non training queries. The only hyperparameter \u0015plays a\nsmoothing role, discouraging radical pruning of rarely vis-\nited vertices. In our experiments we always use \u0015=0:1.\nThen, we tune a weight threshold to maximize performance\nfor validation queries. Finally, all edges whose weights are\nbelow the threshold are pruned.\nWe compare our RL-based approach and magnitude pruning\napplied to the NSW graph on DEEP1M, see Figure 6. Our\nmethod outperforms magnitude pruning across all distance\ncomputation budgets. Finally, we apply magnitude pruning\nto the graph constructed by RL and observe that it also\nslightly improves the performance.\n5. Conclusion\nIn this paper, we introduce a new algorithm for similarity\ngraph construction that explicitly optimizes an adjacency\nmatrix, maximizing the search quality for a large set of\ntraining queries. The algorithm deﬁnes a probabilistic model\nof the graph in terms of its edge probabilities and then learns\nthese probabilities in a reinforcement learning scenario. We\nshow that the proposed approach allows to improve the\nperformance of similarity graphs constructed by heuristics.\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nReferences\nAndoni, A. and Indyk, P. Near-optimal hashing algorithms\nfor near neighbor problem in high dimension. Communi-\ncations of the ACM , 51(1):117–122, 2008.\nAndoni, A., Indyk, P., Laarhoven, T., Razenshteyn, I. P.,\nand Schmidt, L. Practical and optimal LSH for angular\ndistance. In NIPS , 2015.\nAumüller, M., Bernhardsson, E., and Faithfull, A. Ann-\nbenchmarks: A benchmarking tool for approximate near-\nest neighbor algorithms. In SISAP , 2017.\nBabenko, A. and Lempitsky, V . S. Efﬁcient indexing of\nbillion-scale datasets of deep descriptors. In CVPR , 2016.\nBentley, J. L. Multidimensional binary search trees used for\nassociative searching. Commun. ACM , 18, 1975.\nDasgupta, S. and Freund, Y . Random projection trees and\nlow dimensional manifolds. In Proceedings of the 40th\nAnnual ACM Symposium on Theory of Computing, Vic-\ntoria, British Columbia, Canada, May 17-20, 2008 , pp.\n537–546, 2008.\nDasgupta, S. and Sinha, K. Randomized partition trees for\nexact nearest neighbor search. In Conference on Learning\nTheory , pp. 317–337, 2013.\nDatar, M., Immorlica, N., Indyk, P., and Mirrokni, V . S.\nLocality-sensitive hashing scheme based on p-stable dis-\ntributions. In Proceedings of the 20th ACM Symposium\non Computational Geometry, Brooklyn, New York, USA,\nJune 8-11, 2004 , pp. 253–262, 2004.\nDua, D. and Graff, C. UCI machine learning repository,\n2017. URL http://archive.ics.uci.edu/ml .\nFu, C. and Cai, D. Efanna: An extremely fast approximate\nnearest neighbor search algorithm based on knn graph.\narXiv preprint arXiv:1609.07228 , 2016.\nFu, C., Xiang, C., Wang, C., and Cai, D. Fast approximate\nnearest neighbor search with the navigating spreading-out\ngraph. arXiv preprint arXiv:1707.00143 , 2017.\nIndyk, P. and Motwani, R. Approximate nearest neighbors:\nTowards removing the curse of dimensionality. In Pro-\nceedings of the Thirtieth Annual ACM Symposium on the\nTheory of Computing, Dallas, Texas, USA, May 23-26,\n1998 , pp. 604–613, 1998.\nIwasaki, M. and Miyazaki, D. Optimization of indexing\nbased on k-nearest neighbor graph for proximity search in\nhigh-dimensional data. arXiv preprint arXiv:1810.07355 ,\n2018.\nJégou, H., Douze, M., and Schmid, C. Product quantization\nfor nearest neighbor search. TPAMI , 33(1), 2011.Kipf, T. N. and Welling, M. Semi-supervised classiﬁca-\ntion with graph convolutional networks. arXiv preprint\narXiv:1609.02907 , 2016.\nKraska, T., Beutel, A., Chi, E. H., Dean, J., and Polyzotis,\nN. The case for learned index structures. In Proceedings\nof the 2018 International Conference on Management of\nData , 2018.\nKraska, T., Alizadeh, M., Beutel, A., Chi, E. H., Ding, J.,\nKristo, A., Leclerc, G., Madden, S., Mao, H., and Nathan,\nV . Sagedb: A learned database system. 2019.\nLaarhoven, T. Graph-based time-space trade-offs for approx-\nimate near neighbors. In 34th International Symposium\non Computational Geometry, SoCG 2018, June 11-14,\n2018, Budapest, Hungary , 2018.\nMaaten, L. v. d. and Hinton, G. Visualizing data using\nt-sne. Journal of machine learning research , 9(Nov):\n2579–2605, 2008.\nMalkov, Y . A. and Ponomarenko, A. Growing homophilic\nnetworks are natural navigable small worlds. PloS one ,\n2016.\nMalkov, Y . A. and Yashunin, D. Efﬁcient and robust approxi-\nmate nearest neighbor search using hierarchical navigable\nsmall world graphs. arXiv preprint arXiv:1603.09320 ,\n2016.\nMcCartin-Lim, M., McGregor, A., and Wang, R. Approxi-\nmate principal direction trees. In Proceedings of the 29th\nInternational Conference on Machine Learning, ICML\n2012, Edinburgh, Scotland, UK, June 26 - July 1, 2012 ,\n2012.\nNavarro, G. Searching in metric spaces by spatial approxi-\nmation. The VLDB Journal , 11(1):28–46, 2002.\nPennington, J., Socher, R., and Manning, C. D. Glove:\nGlobal vectors for word representation. In Empirical\nMethods in Natural Language Processing (EMNLP) , pp.\n1532–1543, 2014. URL http://www.aclweb.org/\nanthology/D14-1162 .\nPuterman, M. L. Markov decision processes: Discrete\nstochastic dynamic programming. In Wiley Series in\nProbability and Statistics , 1994.\nSchulman, J., Levine, S., Abbeel, P., Jordan, M. I., and\nMoritz, P. Trust region policy optimization. In ICML ,\n2015.\nSchulman, J., Wolski, F., Dhariwal, P., Radford, A., and\nKlimov, O. Proximal policy optimization algorithms.\nCoRR , abs/1707.06347, 2017.\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nSproull, R. F. Reﬁnements to nearest-neighbor searching in\nk-dimensional trees. Algorithmica , 6, 1991.\nWilliams, R. J. and Peng, J. Function optimization using\nconnectionist reinforcement learning algorithms. 1991.\nWu, Y ., Mansimov, E., Liao, S., Grosse, R. B., and Ba,\nJ. Scalable trust-region method for deep reinforcement\nlearning using kronecker-factored approximation. CoRR ,\nabs/1708.05144, 2017.\nXiong, W., Hoang, T., and Wang, W. Y . Deeppath: A rein-\nforcement learning method for knowledge graph reason-\ning. In Proceedings of the 2017 Conference on Empirical\nMethods in Natural Language Processing , 2017.\nYu. A. Malkov, D. A. Y . Efﬁcient and robust approxi-\nmate nearest neighbor search using hierarchical navigable\nsmall world graphs. arXiv preprint arXiv:1603.09320 ,\n2016.\nZoph, B. and Le, Q. V . Neural architecture search with\nreinforcement learning. arXiv preprint arXiv:1611.01578 ,\n2016.\n\nTowards Similarity Graphs Constructed by Deep Reinforcement Learning\nA.1 Hyperparameters SIFT100K\nNSW HNSW NSG NSW Ours NSG Ours\nM 12 12 - 12 -\nefconstruction 500 300 - 300 -\nR - - 24 - 24\nK - - 200 - 200\nefsearch - - - 10 10\nDCSmax - - - 1200 1500\nCentropy - - - 0.01 0.001\nA.2 Hyperparameters SIFT1M\nNSW HNSW NSW Ours\nM 14 14 14\nefconstruction 500 500 500\nefsearch - - 12\nDCSmax - - 1500\nCentropy - - 0.01A.3 Hyperparameters DEEP100K\nNSW HNSW NSG NSW Ours NSG Ours\nM 12 12 - 12 -\nefconstruction 300 300 - 300 -\nR - - 24 - 24\nK - - 200 - 200\nefsearch - - - 10 10\nDCSmax - - - 1000 1500\nCentropy - - - 0.01 0.001\nA.4 Hyperparameters DEEP1M\nNSW HNSW NSW Ours\nM 14 14 14\nefconstruction 500 500 500\nefsearch - - 12\nDCSmax - - 1500\nCentropy - - 0.01\nA.5 Hyperparameters GloVe1M\nNSW HNSW NSW Ours\nM 20 28 20\nefconstruction 2000 2000 2000\nefsearch - - 5\nDCSmax - - 1000\nCentropy - - 0.01",
  "textLength": 39925
}