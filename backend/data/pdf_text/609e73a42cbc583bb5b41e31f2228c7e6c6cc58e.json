{
  "paperId": "609e73a42cbc583bb5b41e31f2228c7e6c6cc58e",
  "title": "Online List Labeling with Predictions",
  "pdfPath": "609e73a42cbc583bb5b41e31f2228c7e6c6cc58e.pdf",
  "text": "Online List Labeling with Predictions\nSamuel McCauley\nDepartment of Computer Science\nWilliams College\nWilliamstown, MA 01267\nsam@cs.williams.eduBenjamin Moseley\nTepper School of Business\nCarnegie Mellon University\nPittsburgh, PA 15213\nmoseleyb@andrew.cmu.edu\nAidin Niaparast\nTepper School of Business\nCarnegie Mellon University\nPittsburgh, PA 15213\naniapara@andrew.cmu.eduShikha Singh\nDepartment of Computer Science\nWilliams College\nWilliamstown, MA 01267\nshikha@cs.williams.edu\nAbstract\nA growing line of work shows how learned predictions can be used to break\nthrough worst-cast barriers to improve the running time of an algorithm. However,\nincorporating predictions into data structures with strong theoretical guarantees\nremains underdeveloped. This paper takes a step in this direction by showing that\npredictions can be leveraged in the fundamental online list labeling problem . In the\nproblem, nitems arrive over time and must be stored in sorted order in an array of\nsizeΘ(n). The array slot of an element is its label and the goal is to maintain sorted\norder while minimizing the total number of elements moved (i.e., relabeled). We\ndesign a new list labeling data structure and bound its performance in two models.\nIn the worst-case learning-augmented model, we give guarantees in terms of the\nerror in the predictions. Our data structure provides strong theoretical guarantees—\nit is optimal for any prediction error and guarantees the best-known worst-case\nbound even when the predictions are entirely erroneous. We also consider a\nstochastic error model and bound the performance in terms of the expectation and\nvariance of the error. Finally, the theoretical results are demonstrated empirically.\nIn particular, we show that our data structure performs well on numerous real\ndatasets, including temporal data sets where predictions are constructed from\nelements that arrived in the past (as is typically done in a practical use case).\n1 Introduction\nA burgeoning recent line of work has focused on coupling machine learning with discrete optimization\nalgorithms. The area is known as algorithms with predictions , or alternatively, learning augmented\nalgorithms [42,46]. This area has developed a framework for beyond-worst-case analysis that is\ngenerally applicable. In this framework an algorithm is given a prediction that can be erroneous. The\nalgorithm can use the prediction to tailor itself to the given problem instance and the performance is\nbounded in terms of the error in the prediction.\nMuch prior work has focused on using this framework in the online setting where learned predictions\nare used to cope with uncertainty [ 37]. This framework has been further used for warm-starting offline\nalgorithms to improve the beyond worst-case running times of combinatorial optimization problems.\nThis includes results on weighted bipartite matching [ 21], maximum flows [ 15], shortest-paths [ 13]\nand convex optimization [48].\nPreprint. Under review.arXiv:2305.10536v2  [cs.DS]  20 Jun 2023\n\nA key question is to develop a theoretical understanding of how to improve the performance of data\nstructures using learning. Kraska et al. [ 35] jump-started this area by using learning to improve\nthe performance of indexing problems. Follow up work on learned data structures (e.g. [ 39,49])\nhave demonstrated their advantage over traditional worst-case variants both empirically and through\nimproved bounds when the learned input follows a particular distribution; see Section 1.2.\nThe theoretical foundation of using learned predictions in data structures remains underdeveloped. In\nparticular, there are no known analysis frameworks showing how the performance of learned data\nstructures degrade as a function of the error in prediction. In this paper, we take a step in this direction\nby showing how to leverage the learning-augmented algorithms framework for the fundamental\nonline list labeling problem . We bound its performance in terms of the error in the prediction and\nshow that this performance is optimal for any error.\nIn the online list labeling problem1, the goal is to efficiently store a list of dynamic elements in sorted\norder , which is a common primitive in many database systems. More formally, a set of nelements\narrive over time and must be stored in sorted order in an array of size cn, where c >1is a constant.\nThe array slot of an element is referred to as its label . When a new element arrives, it must be stored\nin the array between its predecessor and successor which may necessitate shifting (relabeling) other\nelements to make room. The goal of a list labeling data structure is to minimize the number of\nelements moved; we refer to the number of element movements as the cost. The challenge is that the\ninsertion order is online and adversarial, and the space is limited. A greedy approach, for example,\nmight end up moving Ω(n)elements each insert.\nList labeling algorithms have been studied extensively for over forty years, sometimes under different\nnames such as sparse tables [ 30], packed memory arrays [ 4,7], sequential file maintenance [ 53–56],\nand order maintenance [ 19]. We call any data structure that solves the list labeling problem a list\nlabeling array (LLA) . Itai et al. [ 30] gave the first LLA which moves O(log2n)elements on average\nover all inserts. This has since been extended to guarantee O(log2n)elements are moved on any\ninsert [ 54]. These results are tight as there is a Ω(log2n)lower bound on the amortized number of\nmovements needed for any deterministic algorithm [10].\nThe LLA is a basic building block in many applications, such as cache-oblivious data structures [ 6],\ndatabase indices [ 45] and joins [ 31], dynamic graph storage [ 18,43,52], and neighbor search in\nparticle simulations [ 23]. Recently, LLAs have also been used in the design of dynamic learned\nindices [20], which we describe in more detail in Section 1.2.\nDue to the their wide use, several prior works have attempted to improve LLAs using predictions\nheuristically. Bender et al. [ 7] introduced the adaptive packed memory array (APMA) which tries\nto adapt to non-worst case input sequences. The APMA uses a heuristic predictor to predict future\ninserts. They show guarantees only for specific input instances, and leave open the question of\nimproving performance on more general inputs. Follow up data structures such as rewired PMA [ 17]\nand gapped arrays [ 20] also touch on this challenge—how to adapt the performance cost of a LLA\nalgorithm to non-worst case inputs, while still maintaining O(log2n)worst case.\nA question that looms is whether one can extract improved performance guarantees using learned\npredictions on general inputs. An ideal algorithm can leverage accurate predictions to give much\nstronger guarantees than the worst case. Further, the data structure should maintain an O(log2n)\nguarantee in the worst case even with completely erroneous predictions. Between, it would ideal to\nhave a natural trade-off between the quality of predictions and the performance guarantees.\n1.1 Our Contributions\nIn this paper, we design a new data structure for list labeling which incorporates learned predictions\nand bound its performance by the error in the predictions. Our theoretical results show that high-\nquality predictions allow us to break through worst-case lower bounds and achieve asymptotically\nimproved performance. As the error in the prediction grows, the data structure’s performance\ndegrades proportionally, which is never worse than the state-of-the-art LLAs. Thus, the algorithm\ngives improvements with predictions at no cost. This is established in both worst-case and stochastic\nmodels. Our experiments show that these theoretical improvements are reflected in practice.\n1We use ‘online list labeling’ and ‘list labeling’ interchangeably; the problem is trivial in the offline setting.\n2\n\nPrediction model. We define the model to state our results formally. Each element xhas a rankrx\nthat is equal to the number of elements smaller than it after all elements arrive. When an element\narrives, a predicted rank erxis given. The algorithm can use the predicted ranks when storing elements\nand the challenge is that the predictions may be incorrect. Define ηx=|erx−rx|asx’sprediction\nerror . Letη= max xηxbe the maximum error in the predictions.\nUpper bounds. In Section 3, we present a new data structure, called a learnedLLA , which uses any\nlist labeling array as a black box. We prove that it has the following theoretical guarantees.\n•Under arbitrary predictions, the learnedLLA guarantees an amortized cost of O(log2η)per\ninsertion when using a classic LLA [ 30] as a black box. This implies that the algorithm has\nthe best possible O(1)cost when the predictions are perfect (or near perfect). Even when\nη=n, the largest possible prediction error, the cost is O(log2n), matching the lower bound\non deterministic algorithms. Between, there is graceful degradation in performance that is\nlogarithmic in terms of the error. In fact, these results are more general. Given a list labeling\nalgorithm (deterministic or randomized) with an amortized cost of C(n), for a reasonable\nfunction C2, our data structure guarantees performance C(η). This implies the new data\nstructure can improve the performance of any known LLA. See Section 3.2.\n•We also analyze the learnedLLA when the error ηxfor each element xis sampled indepen-\ndently from an unknown probability distribution Dwith average error µand variance s2.\nUnder this setting, we show that the amortized cost is O(log2(|µ|+s2))in expectation. In-\nterestingly, the arrival order of elements can be adversarial and even depend on the sampled\nerrors. This implies that for any distribution with constant mean and variance, we give the\nbest possible O(1)amortized cost. See Section 3.4.\nLower bound. A natural next question is whether the learnedLLA is the best possible or if there is\nan LLA that uses the predictions in a way that achieves a stronger amortized cost. In Section 3.3, we\nshow our algorithm is the best possible: for any η,anydeterministic algorithm must have amortized\ncost at least Ω(log2η), matching our upper bound. Thus, our algorithm utilizes predictions optimally.\nEmpirical results. Finally, we show that the theory is predictive of empirical performance in\nSection 4. We demonstrate on real data sets that: (1) the learnedLLA outperforms state-of-the-art\nbaselines on numerous instances, (2) when current LLAs perform well, the learnedLLA matches or\neven improves upon their performing, indicating minimal overhead from using predictions, (3) the\nlearnedLLA is robust to prediction errors, (4) these results hold on real-time-series data sets where\nthe past is used to make predictions for the future (which is typically the use case in practice), and (5)\nwe demonstrate that a small amount of data is needed to construct useful predictions.\n1.2 Related Work\nSee [ 46] for an overview of learning-augmented algorithms in general. Below we describe related\nwork on learned data structures and list labeling data structures.\nLearned replacements of data structures. The seminal work on learning-augmented algorithms\nby Kraska et al. [ 35], and several follow up papers [ 20,25,28,32,33,40,57] focus on designing and\nanalyzing a learned index, which replaces a traditional data structure like a B-tree and outperforms\nit empirically on practical datasets. Interestingly, the use of learned indices directly motivates the\nlearned online list labeling problem. To apply learned indices on dynamic workloads, it is necessary\nto efficiently maintain the input in sorted order in an array. Prior work [ 20] attempted to address\nthis through a greedy list labeling structure, a gapped array . A gapped array, however, can easily\nincur Ω(n)element movements per insert even on non-worst case inputs. This bottleneck does not\nmanifest itself in the theoretical or empirical performance of learned indices so far as the input is\nassumed to be randomly shuffled.3Note that random order inserts are the best case for list labeling\nand incur O(1)amortized cost in expectation [ 5]. In contrast, our guarantees hold against inputs with\nadversarial order that can even depend on the prediction errors.\n2For admissible cost functions C(n)as defined in Definition 1.\n3In their analysis showing the effectiveness of learned indices, Ferragina et al. [ 25] further assume that gaps\nbetween input elements (taken in sorted order) follow a specific distribution.\n3\n\nBesides learned indices replacing B-trees, other learned replacements of data structures include hash\ntables [24, 47] and rank-and-select structures [9, 26, 27].\nLearned adaptations of data structures. In addition to approaches that use a trained neural net to\nreplace a search tree or hash table, several learned variants of data structures which directly adapt to\npredictions have also been designed. These include learned treaps [ 12,39], filters [ 8,41,49,51] and\ncount-min sketch [ 22,29]. The performance bounds of most of these data structures assume perfect\npredictions; when robustness to noise in predictions is analyzed (see e.g. [ 39]), the resulting bounds\nrevert to the worst case rather than degrading gracefully with error. The learnedLLA is unique in\nthe landscape of learned data structure as it guarantees (a) optimal bounds for any error, and (b) best\nworst-case performance when the predictions are entirely erroneous.\nOnline list labeling data structures. The online list labeling problem is described in two different\nbut equivalent ways: storing a dynamic list of nitems in a sorted array of size m; or assigning labels\nfrom{1, . . . , m }to these items where for each item x, the label ℓ(x)is such that x < y =⇒ℓ(x)<\nℓ(y). We focus on the linear regime of the problem where m=cn, and c >1is a constant.\nIf an LLA maintains that any two elements have Θ(1) empty slots between them, it is referred to as a\npacked-memory array (PMAs) [ 4]. PMAs are used as a subroutine in many algorithms: e.g. applied\ngraph algorithms [16, 18, 43, 50–52] and indexing data structures [4, 20, 34].\nA long standing open question about LLAs—whether randomized LLA algorithms can perform better\nthan deterministic was resolved in a recent breakthrough. In particular, Bender et al. [ 3] extended\nthehistory independent LLA introduced in [ 1] and showed that it guarantees O(log3/2n)amortized\nexpected cost. The learnedLLA achieves O(log3/2η)amortized cost when using this LLA as a black\nbox inheriting its strong performance; see Corollary 5.\nBender and Hu [ 7] gave the first beyond-worst-case LLA, the adaptive PMA (APMA) . The APMA\nhasO(logn)amortized cost on specialized sequences: sequential (increasing/ decreasing), hammer\n(repeatedly inserting the predecessor of an item) and random inserts. APMA also guarantees\nO(log2n)amortized cost in the worst case. Moreover, the APMA uses heuristics to attempt to\nimprove performance on inputs outside of these specialized sequences. (Similar heuristics were\nused in the Rewired Memory Array [17]). These heuristics do not have theoretical guarantees,\nbut nonetheless, the APMA often performs better than a classic one empirically [ 7,16]. While\nthe learnedLLA bounds (based on prediction error) are incomparable with that of the APMA, our\nexperiments show that the learnedLLA outperforms the APMA on numerous datasets. In fact, if\nwe combine our techniques by using an adaptive PMA as the black-box LLA of the learnedLLA, it\nperforms better than both of them, reinforcing its power and versatility.\n2 Preliminaries\nIn this section we formally define the list labeling problem, our prediction model, and the classic list\nlabeling data structures we use as a building block in Section 3.\nProblem definition. In the online list labeling problem , the goal is to maintain a dynamic sorted\nlist of nelements in an array of m=cnslots for some constant c >1. We refer to nas the capacity\nof the array, mas the size, andn/m as the density . The label of an element is the array slot assigned\nto it. As new elements arrive, existing elements may have to be moved to make room for the new\nelement. All elements come from an ordered universe of possible elements U. The list labeling\nstructure maintains that the elements in the array must be stored in sorted order—for any xi, xjstored\nin the array, if xi< xjthen the label of ximust be less than the label of xj.\nWe refer to a data structure for this problem as a list labeling array (LLA) . An element movement is\nsaid to occur each time an element is assigned a new label.4We use the term element movements and\nrelabels interchangeably. The total cost of an LLA is the total number of element movements. The\namortized cost of an LLA is the total cost during kinsertions, divided by k. This cost function is\nstandard both in the theory and practice of LLAs (see e.g. [2, 3, 7, 17, 30]).\n4This means that every element has at least one element movement when it is inserted.\n4\n\nData structure model. We assume that the set Sofnelements are drawn one-by-one adversarially\nfrom Uand inserted into the LLA. We use existing LLAs (e.g. [ 1–3,30]) as a black box in our data\nstructure. We consider any (possibly randomized) LLA Awhich supports the following operations:\n• INSERT (x): Inserts xinA. The slot storing xmust be after the slot storing its predecessor,\nand before the slot storing its successor.\n•INIT(S′): Given an empty LLA Aand given a (possibly-empty) set S′⊆U, insert all\nelements from S′inA.\nNote that INIT(S′)can be performed using O(|S′|)element movements—as all |S′|elements are\navailable offline, they can be placed in Aone by one.\nFor simplicity we assume that nis a power of 2; our results easily generalize to arbitrary n. All\nlogarithms in this paper are base 2.\nIn this work, we do not explicitly discuss deletes. However, our data structure can be easily extended\nto support deletes as follows. We build a learnedLLA with capacity 2n. We split all operations into\nepochs of length n. During an epoch we ignore all deletes. After the epoch completes, we rebuild the\ndata structure, removing all elements that were deleted during the epoch. This costs O(n), so the\namortized cost is increased by O(1).\nWe parameterize the amortized cost of the learnedLLA by the amortized cost function of INSERT for a\nblack-box LLA algorithm of density 1/2.5For background on how a classic LLA, the packed-memory\narray (PMA)[ 4,30], works see Appendix A. Let C(n′)upper bound the amortized cost to insert into\na LLA with capacity n′and size 2n′.\nDefinition 1. We say that a cost function C(·)isadmissible if:\n•for all i, jwithi <2j,C(i) =O(C(j)),\n•C(n′) = Ω(log n′), and\n•for all j,P∞\ni=1C(2j+i)/2i=O(C(j)).\nBoth C(n) = Θ(log2n)(the optimal cost function for any deterministic LLA) and C(n) =\nΘ(log3/2n)(the best-known cost function for any randomized LLA [ 3]) are admissible. There\nis an unconditional lower bound that any LLA must have amortized cost at least Ω(log n′)[11].\nThe prediction model is introduced in Section 1.1. Recall that ηx=|erx−rx|is the prediction error\nof element x, where erxis its predicted rank andrxis its true (unknown) rank inS. In Section 3.2,\nthe predicted ranks may be assigned adversarially and we bound the cost in terms of the maximum\nerror η= max iηi. In Section 3.4, we assume that the prediction errors are drawn independently\nfrom an unknown distribution Dand bound the cost in terms of the mean and variance of D.\n3 Our Data Structure: the learnedLLA\nIn this section we design and analyze our data structure, the learnedLLA which uses any generic list\nlabeling array as a black box. For space, many of the proofs in this section have been removed; they\ncan be found in the full version, included in the supplementary materials.\nWe begin in Section 3.1 by describing how the learnedLLA works. In Section 3.2 we give a worst-\ncase analysis for the learnedLLA. If the black-box LLA has admissible amortized cost C(n)forn\ninsertions, our data structure achieves an amortized cost of C(η)for maximum error η.\nIn Section 3.3, we show that the learnedLLA is optimal for deterministic solutions to list labeling.\nBulánek et al. showed that that in the worst case any deterministic LLA algorithm must have worst-\ncase cost C(n′) = Ω(log2n′)[10]. We use this lower bound to show that for any maximum error η,\nany deterministic LLA with m=O(n)slots must incur total cost Ω(nlog2η).\nIn Section 3.4 we give improved bounds for our data structure when the predictions are not adversarial\nbut rather drawn from a distribution with bounded expectation and variance. If the distribution has\nexpectation µand variance s2, then using the best-known randomized list labeling data structure\ngives expected amortized cost O(log3/2(µ+s)).\n5If we initialize a LLA Pjwithm′slots, we never store more than m′/2elements in Pj. However, this\nchoice is for simplicity, and our results immediately generalize to LLAs using different parameter settings.\n5\n\nLearned List-Labeling Array. Our learned list labeling data structure partitions its array into\nseveral subarrays, each of which is maintained as its own list labeling array. At a high level, when an\nelement xiis inserted along with its predicted rank eri, we use erito help determine which LLA to\ninsert into while maintaining sorted order. Intuitively, the performance comes from keeping these\nconstituent list labeling arrays small: if the predictions are good, it is easy to maintain small LLAs\nwhile retaining sorted order. But, if some element has large prediction error, its list labeling array\ngrows large, making inserts into it more expensive.\nBelow, we describe and analyze this data structure more formally.\n3.1 Data Structure Description\nThe learnedLLA with capacity noperates on an array of m= 6nslots. At all times, the learnedLLA\nis partitioned into ℓactual LLAs P1, P2, . . . P ℓfor some ℓ. In particular, we partition the marray\nslots into ℓcontiguous subarrays; each subarray is handled by a black-box LLA. We maintain that for\nalli < j , all elements in Piare less than all elements in Pj.\nWe define a tree to help keep track of the actual LLAs. Consider an implicit, static and complete\nbinary tree Tover ranks {1, . . . n}. Each node in Thas a set of assigned ranks andassigned slots .\nSpecifically, the ith node at height hhas2hassigned ranks {2h(i−1) + 1 ,2h(i−1) + 2 , . . . , 2hi},\nand6·2hassigned slots {2h·6(i−1) + 1 ,2h·6(i−1) + 2 , . . . , 2h·6i}.\nWe use each actual LLA as a black box to handle how elements are moved within its assigned slots.\nTo obtain the learnedLLA label for an element xiin actual LLA Pj, we sum the black-box label of\nxiinPjand the value of the smallest slot assigned to Pjminus 1.\nEvery actual LLA has a set of assigned ranks and assigned slots; these ranks and slots must be from\nsome node in T. We say that the LLA corresponds to this node in T. Each root-to-leaf path in T\npasses through exactly one node that corresponds to an actual LLA. This means that the assigned\nranks of the actual LLAs partition {1, . . . , n }intoℓcontiguous subsets, and the assigned slots of the\nactual LLAs partition {1, . . . , m }intoℓcontiguous subsets.\nIf a node vinTis not assigned to an actual LLA, it may be useful to consider the assigned ranks\nand slots that would be used if a LLA assigned to vwere to exist. We call such a LLA (that is not in\nP1, . . . , P ℓ) apotential LLA . The sibling ,parent anddescendants of a LLA Pjrefer to the LLAs\ncorresponding to the sibling, parent and descendant nodes respectively of P′\njsnode in the tree.\nFor any potential LLA Pj, let|Pj|denote the number of assigned ranks of Pj. Initially ℓ=nandPi\nis assigned to the ith leaf of T, where 1≤i≤n—that is to say, the actual LLAs begin as the leaves\nofT, each with one assigned rank. The parameter ℓchanges over time as elements are inserted.\nEach element is inserted into exactly one actual LLA. If an LLA has density more than 1/2, we\nmerge it with the (potential or actual) LLA of its sibling node in T.\nInsertion Algorithm. To insert an item xinto the learnedLLA, let ipandisbe the index of the\nLLA containing the predecessor and successor of xrespectively. If the successor of xdoes not exist,\nletip=ℓ(the last actual LLA); if the predecessor does not exist let ip= 1. Finally, let ixbe the\nLLA whose assigned ranks contain erx. Call I NSERT (x)on LLA Piwhere:\ni=(ipifip> ix\nisifis< ix\nixotherwise(1)\nThe black-box LLA Piupdates its labels internally, and these updates are mirrored in the learnedLLA.\nIf the insert causes the density of Pito go above 1/2, wemerge it with its sibling LLA. Specifically,\nletPpbe the parent of Pi; it must currently be a potential LLA. We take all actual LLAs that are\ndescendants of Pp, and merge them into a single actual LLA. Let Spbe the set of elements currently\nstored in the slots assigned to Ppin the learnedLLA; thus, Spconsists exactly of the contents of all\nactual LLAs that are descendants of Pp. We call INIT(Sp)onPp, after which Ppis an actual LLA;\nall of its descendants are no longer actual LLAs. Note that after a merge, the assigned ranks and\nassigned slots of the actual LLAs still partition {1, . . . , n }and{1, . . . , m }respectively.\n6\n\nAfter we insert into Pi, and merge if necessary, the learnedLLA insert is complete.\nNext, we analyze the performance of the learnedLLA. Let C(·)be amortized cost of the black-\nbox LLA used in the learnedLLA—our results will be in terms of C(·).6We assume that C(·)is\nadmissible (Definition 1).\n3.2 Arbitrary Predictions\nIn this section, we assume that the input sequence and associated predictions can be arbitrary. The\nadversary chooses elements one by one from a universe U. For each element, the adversary assigns a\npredicted rank (which can be based on past insertions, past predictions, and even the learnedLLA\nalgorithm being used) and inserts the element. We show that the learnedLLA achieves amortized cost\nO(C(η)), where ηis the maximum error.\nOur proof begins with several structural results, from which the analysis follows almost immediately.\nFirst, we show that to determine the overall asymptotic cost it is sufficient to consider the set of actual\nLLAs after all inserts are completed. That is, the relabels that occur during merges and inserts to\nsmaller LLAs are lower-order terms.\nLemma 2. For any sequence of insertions, if PFis the set of actual LLAs after all operations are\ncompleted, then the total number of element movements incurred by the learnedLLA is\nO X\nP∈PF|P| ·C(|P|)!\n.\nProof. For a LLA P∈ P F, consider all potential LLAs that are descendants of PinT. This\npartitions the merges: every P′that is an actual LLA at any time during σmust be a descendant of\nexactly one P∈ PF.\nFirst, we analyze the cost of all merges. The total capacity of all LLAs that are a descendant of Pis\n|P|log|P|. Since a merge operation has linear cost, the total number of element movements during\nall merges is O(|P|log|P|).\nNow, we must bound the cost of all inserts. Consider all inserts into all LLAs P1, P2, . . . , P dthat are\na descendant of P. Let kibe the number of inserts into some such LLA Pi; the total cost of these\ninserts is O(kiC(|Pi|))≤O(kiC(|P|)). All inserts into descendants of Pare ultimately stored in\nP; thus,Pd\ni=1ki≤3|P|. Then the total cost of all inserts into LLAs that are a descendant of PisPd\ni=1O(kiC(|P|)) =O(|P|C(|P|)).\nSumming between the merge and insert cost, and using C(|P|) + log |P|=O(C(|P|))because C(·)\nis admissible, we obtain a total number of element movements of\nO X\nP∈PF|P| ·C(|P|) +|P|log|P|!\n≤O X\nP∈PF|P| ·C(|P|)!\n.\nLemma 3. At any time, if Pis an actual LLA, then there exists an element xjstored in Pwith\nηj≥ |P|/2.\nProof. Since Pwas formed by merging its two children PiandPkinT, the density of either Pior\nPkmust have been at least 1/2; without loss of generality assume it was Pi.\nLetr1, r1+ 1, . . . , r 2be the sequence of |Pi|ranks assigned to Pi. Letxsandxℓbe the smallest and\nlargest items in Pirespectively, with predicted ranks ersanderℓ. We must have ers≥r1—since the\npredecessor of xsis not in Pi,xsmust be placed in the LLA whose assigned ranks contain ers, or in\nthe LLA containing its successor (if ersis larger than any rank assigned to the LLA containing its\nsuccessor). Similarly, erℓ≤r2. Therefore, erℓ−ers≤ |Pi| −1. There are at least 3|Pi|items in Pias\nits density is at least 1/2. Thus, rℓ−rs≥3|Pi|−1. Thus, either |ers−rs| ≥ |Pi|or|erℓ−rℓ| ≥ |Pi|.\nNoting that |Pi|=|P|/2, either ηs≥ |P|/2orηℓ≥ |P|/2.\n6We assume there is one type of LLA; otherwise, let C(·)upper bound the cost of all LLAs being used.\n7\n\nTheorem 4. For any sequence of at most ninsertions σwith maximum error η, the learnedLLA\nusing LLAs with admissible cost function C(·)incurs O(nC(η))total element movements.\nProof. By Lemma 3, any P∈ PFmust have an element with error at least |P|/2. Thus, any P∈ PF\nmust have |P| ≤2η. The actual LLAs partition the ranks, soP\nP∈PF|P|=n. By Lemma 2, and\nsince C(·)is admissible, the total number of element movements over σis\nO X\nP∈PF|P| ·C(|P|)!\n≤O X\nP∈PF|P| ·C(2η)!\n≤O(nC(η)).\nCorollary 5. Using the classic optimal LLA of Itai et al. [ 30], the learnedLLA is a deterministic list\nlabeling data structure with with O(log2η)amortized element movements. Using the best-known\nrandomized LLA of Bender et al. [ 3], the learnedLLA is a randomized list labeling data structure\nwithO(log3/2η)amortized element movements.\n3.3 Optimality for Deterministic Learned List Labeling\nOne may wonder if the learnedLLA is optimal. The learnedLLA is clearly optimal on the two\nextremes: perfect predictions ( η= 0) and completely erroneous predictions ( η=n). When\npredictions are perfect, the learnedLLA does not need to move any element. When η=n, it is easy\nto create instances where the predictions give no information about the rank of each item (e.g. if\neach prediction is eri= 1). Bulánek et al. [ 10] showed that, without predictions, any deterministic\nLLA with O(n)slots can be forced to perform Ω(log2n)amortized element movements. Thus, the\nlearnedLLA is optimal when η=n.\nHowever, it is not immediately clear if the above idea extends to intermediate error. In this section,\nwe show that for deterministic learned labeling data structures, the learnedLLA is in fact optimal for\nallη. In particular, we show that for any η, there is an adversary that inserts elements with error at\nmostηthat causes any deterministic LLA algorithm to incur Ω(nlog2η)total element movements.\nThe intuition behind our proof is to split the learned list labeling problem into a sequence of Ω(n/η)\nsubproblems of size η, each handled by its own LLA algorithm. The given predictions within each\nsubproblem are only accurate to within η—therefore, an adversary can force each LLA to get no\ninformation about an element’s position within the LLA, and by [ 10] perform no better than Ω(log2η)\namortized element movements.\nThe challenge is that the LLAs for the subproblems are not actually separate: we can’t force the data\nstructure to allocate O(η)space to each LLA and keep this allocation static throughout the execution.\nThe data structure may move elements between adjacent LLAs or shift the number of slots available\nto each, an ability that disrupts a black-box lower bound.\nShifted list labeling. To address this issue, we describe a generalization of the list labeling problem.\nWe then show that this generalization has the same asymptotic cost as the classic list labeling\nproblem, while being able to better handle the above issue where slots are dynamically allocated to a\nsubproblem. We call our generalization the shifted list labeling problem . The shifted list labeling\nproblem is similar to the online list labeling problem: nelements from a totally-ordered universe\narrive and must be assigned labels. We assume these labels are integers without loss of generality. At\nall times, the labels must respect sorted order: if x < y then the label of xmust be less than the label\nofy. In the shifted list labeling problem labels are not necessarily in {1, . . . , m }; instead, we require\nthat the smallest and largest label differ by at most m−1.7We call a data structure for this problem\nis ashifted LLA , and we call m−1themaximum spread of the shifted LLA.\nFirst, we show that shifted LLAs have the same asymptotic cost as normal LLAs.\nLemma 6. Assume that there exists a shifted LLA PSof capacity nwith maximum spread m−1\nthat can handle a sequence of operations σwithT(n)total element movements. Then there exists a\nLLAP∗of size 3mthat can handle σwith total element movements 2T(n).\n7Thus, the shifted list labeling problem generalizes the online list labeling problem: labels in {1, . . . , m }are\nsufficient, but not necessary, to satisfy this requirement.\n8\n\nProof. Create a LLA P∗of size 3m. Letℓ0be the label of the first item that is inserted in PS. We\nmaintain that if an item xhas label ℓxin the shifted LLA PS, we give it label ℓ′\nx= (ℓx−ℓ0)+(m+1)\ninP∗. Every time an element xis moved in PS, the movement is mirrored in P∗, that is, xis moved\nexactly once to set its label to ℓ′\nx.\nWe maintain the invariant that the label ℓ′\nx∈ {1, . . . , 3m}for all xinP∗. Ifℓxfor any item xinPS\nis ever less than ℓ0−mor more than ℓ+ 2mwerebuild : we update ℓ0to be the label of the smallest\nitem currently in PS, and recompute ℓ′\nx. That is, for all x(with label ℓxinPS), we set its label in\nP∗to be (ℓx−ℓ0) + (m+ 1) . This requires moving each element once in P∗.\nWe note that by construction, the difference between any two labels in P∗is at most m−1. We use\nthis fact to bound the number element movements in P∗below.\nConsider the sequence of operations between two successive rebuilds randr′. After r, all labels of\nelements in P∗must be between mand2m. Immediately before r′, there must be some element in\nP∗with label less than 0or more than 2m—but this means that no element in P∗has label between\nmand2m. This means that every element must have been moved at least once in PSbetween rand\nr′. We move each element one more time during the rebuild r′. This at most doubles the number of\nelement movements. Thus, there are T(n)total element movements during all rebuilds; summing\nthis and the T(n)element movements that P∗makes to mirror PS, we obtain the lemma.\nThe deterministic lower bound of Bulánek et al. [ 10] is constructed using an adversary that builds\nthe worst-case sequence of inserts one by one. Our lower bound will use this approach as well.\nAnadversary for online list labeling maps from the labels of all currently stored items, to a new\nitem to insert into the data structure. Repeatedly querying the adversary gives a fixed sequence of\noperations σDfor any deterministic LLA algorithm D. Let cost(σD, D)be the total number of\nelement movements incurred by Don the operations in σDgenerated by the adversary. The goal\nof the adversary is to maximize minDcost(σD, D). Bulánek et al.’s main result is an adversary that\nachieves minDcost(σD, D) = Ω(log2k)for any deterministic LLA algorithm with capacity k. For\ncompleteness, we summarize their result in Lemma 7.\nLemma 7 ([10]).Define χk(m′,|U|)to be the smallest number of element movements that the best\nadversary achieves for any deterministic LLA algorithm with capacity kandm′slots where inserts\nare from a universe U. Then if m′= (1 + Θ(1)) k, and|U| ≥C′mfor a sufficiently large constant\nC′,χk(m′,|U|) = Θ( klog2k).\nThe goal of this section is to give an adversary such that for any deterministic learned list labeling data\nstructure Dwithm=O(n)slots, the adversary forces Dto incur Ω(nlog2η)element movements,\neven when all items inserted by the adversary have predicted rank with error at most η. Recall\nc=m/n ; we assume that cis a constant larger than 1.\nLower bound setup. LetUbe a universe of sufficient size for the lower bound in Lemma 7. We\npartition the universe U′of size |U|n/ηinton/ηcontiguous blocks of size |U|. We assume without\nloss of generality that n/ηis an integer (if not, we round nup to the next multiple of η). We call the\nbth block of Ublock b(i.e. we refer to blocks by an index b∈ {1, . . . n/ η}).\nThe predicted rank of any xin block bisbη. The adversary (described below) inserts exactly η\nelements from each block in 10; therefore, the error of any item ηx≤η.\nLetStbe the set of items stored in Dafter the first t−1operations (i.e. immediately before the\ntth operation). We say that Stis the set of items stored at time t. For any block bwith at least two\nelements in St, letℓt\nbandst\nbbe the largest and smallest label of any element in Stfrom block b. Call\nℓt\nb−st\nbtheblock segment size ofbat time t. We say that a block bisactive at time tif either it has\nless than two items at time t, or if its block segment size is ℓt\nb−st\nb≤2cη. The adversary uses the\ncurrent set of labels in the LLA to determine the next item to insert. The crux of our lower bound is\nthat the adversary’s tth insert is from a block that is active at time t. This means that the set of items\nfrom any block bform a shifted LLA with maximum spread 2cη. This is formalized in Lemma 8.\nLemma 8. Consider a block b, and consider a sequence of inserts σintoD. Letσb\n1, σb\n2, . . . , σb\nkbe\nthe operations in σthat insert an item from b. Assume that bis active immediately before each σb\ni.\nFori∈ {1, . . . , k }, letLb\nibe the set of labels of elements from block bimmediately before insert σb\ni.\nThen, the following holds.\n9\n\n(a) The sequence Lb\nifori∈ {1, . . . , k }constitutes a shifted LLA AS\nbwith maximum spread 2cη.\n(b)There exists a LLA Abwith size 6cη+ 3that moves at most twice as many elements as AS\nbon\nthe sequence of inserts σb\n1, σb\n2, . . . , σb\nk.\n(c)LetT(Ab)be the total number of element movements in Ab. Then, the total number of element\nmovements in Dis lower bounded byPn/η\nb=1T(Ab)/2.\nProof. The labels in Lb\nimust be in sorted order by correctness of D. Furthermore, the largest and\nsmallest label in Lb\nimust differ by at most 2cηsince block bis active at operation σb\ni. Thus, we can\nconstruct a shifted LLA AS\nb, such that the labels after insert iareLb\ni+1. This proves Part (a).\nPart (b) follows from Lemma 6.\nTo show Part (c), let T(AS\nb)be the total number of element movements in AS\nb. If an element’s\nlabel changes in AS\nb, it must also change at least once in D. Therefore, the total number of element\nmovements in Dis lower bounded byP\nbT(AS\nb). We have that T(Ab)≤2T(AS\nb)by Lemma 6.\nAdversary definition and final lower bound. We define our adversary as follows.\nFirst, at time t, the adversary arbitrarily chooses a block bsuch that: (1) bis active at time t, and\n(2) at most ηelements from bare in St. LetAbbe the deterministic LLA for block bat time tfrom\nLemma 8. The adversary of [ 10] from Lemma 7 (with capacity k≜ηandm≜6cηslots) maps\nthe set of labels of items in Abattto a new item xfrom block b. Then our adversary inserts xwith\npredicted rank bη.\nIf no block with less than ηelements is active at time t, the adversary performs the clean up step :\nfor each block bwith less than ηelements, the adversary inserts arbitrary elements from b(with\nprediction bη)untilηelements have been inserted from b. After this is done, the adversary has\ninserted nitems. The clean up step is to ensure that the predicted ranks are accurate to within η.\nNow, we analyze this adversary. First, we show that there are many blocks for which all items were\ninserted using the above adversary.\nLemma 9. There are at least n/(2η)blocks bsuch that the adversary inserts at least ηitems from b\nbefore the cleanup step.\nProof. Lett′be the time when the adversary enters the cleanup step.\nBlocks are disjoint, so at t′, the sum all block segment sizes is at most mand the average block\nsegment size is at most cη. Therefore, at most n/(2η)blocks have block segment size more than\n2cη; thus, at least n/(2η)blocks have block segment size at most 2cη. Each of these at least n/2η\nblocks must contain ηelements.\nNow we are ready to complete the proof of our lower bound.\nTheorem 10. For any η, there exists an adversary that inserts nitems, each with error at most η,\nsuch that any deterministic data structure for learned list labeling with capacity nandm=cnslots\nincurs Ω(nlog2η)total element movements.\nProof. LetBbe the set of blocks from Lemma 9 that have ηinserted elements before the cleanup\nstep; we have |B| ≥n/2η.\nConsider a block b∈B. LetAbbe the LLA for elements in bfrom Lemma 6. All inserts of elements\nfrom bare from the adversary in Lemma 7; therefore, we must have T(Ab) = Ω( ηlog2η).\nSumming over the blocks in B, and using the lower bound on element movements in Dfrom\nLemma 8, there must be Ω(nlog2η)element movements in D.\n3.4 Stochastic Predictions with Adversarial Insert Order\nIn this section, we assume that each predicted rank is the result of adding random noise to the true\nrank. In particular, given an unknown distribution D, for any item xi, we have eri=ri+eiwhere each\neiis sampled independently from D. This means the that error of each item is essentially sampled\n10\n\nfromD, asηi=|ei|. IfDhasexpectation µandvariance s2, we show that under such predictions\nthe learnedLLA has expected amortized cost O(C((µ+s2)2)), where C(n)denotes an admissible\ncost function of its constituent LLAs.\nThe arrival order of the elements can still be chosen adversarially, with full knowledge of the predicted\nranks. In particular, we can describe our input model with the following adversary. The adversary\nfirst chooses nelements of the set Sfrom a totally ordered universe. For each element xi∈S, the\nerror eiis then sampled from D. Finally, the adversary can look at the predicted ranks and choose\nany insert order of elements in S.\nFirst, we bound the probability an element achieves a certain error—this is useful because Lemma 3\nshows that if Pis an actual LLA, then it must contain an element xjwith large ηj.\nLemma 11. Assume that erj=rj+ejwhere ejis drawn independently from a distribution Dwith\nexpectation µand variance s2. Then Pr[ηj≥k(|µ|+s2)]≤1/k2.\nProof. Consider an element xj. Since ηj=|ei|,Pr\u0002\nηj≥ |µ|+ks2\u0003\n≤Pr\u0002\n|ej−µ| ≥ks2\u0003\n. By\nChebyshev’s inequality, Pr\u0002\n|ej−µ| ≥ks2\u0003\n≤1/k2. Combining and taking an upper bound, for\nk >1we have Pr\u0002\nηj≥k|µ|+ks2\u0003\n≤Pr\u0002\nηj≥ |µ|+ks2\u0003\n≤1/k2.\nBelow, we state and prove the performance bound of the learnedLLA in this model.\nTheorem 12. Consider a LearnedLL data structure using a black box LLA algorithm with admissible\ncostC(·). If for each xi,eri=ri+eiwhere eiis drawn independently from a distribution Dwith\nexpectation µand variance s2, then the total element movements over a sequence of at most n\ninsertions is O\u0000\nn·C((|µ|+s2)2)\u0001\nProof. In this proof, to simplify the notation we define a variable ρ=|µ|+s2. Thus, we want to\nshow a total cost of O(nC(ρ2)).\nLetPfbe the set of actual LLAs after all inserts have completed. By Lemma 2, the total number of\nelement movements is\nO\nX\nP∈Pf|P| ·C(|P|)\n.\nWe split Pfinto two sets: LLAs with at most |P| ≤ρ2assigned ranks (which we call small LLAs ),\nand LLAs with more than |P|> ρ2assigned ranks ( large LLAs ). That is to say, the number of\nelement movements is:\nO\nX\nsmallP∈Pf|P| ·C(|P|) +X\nlargeP∈Pf|P| ·C(|P|)\n.\nFor small LLAs, we can upper bound\nX\nsmallP∈Pf|P| ·C(|P|) =O(nC(ρ2)).\nNow consider large potential LLAs. We calculate the probability that any large PhasP∈ PFby\nupper bounding the probability that Pbecomes an actual LLA; then, we will use this probability to\nupper bound the expected cost.\nIfP∈ Pf, then the ranks of the elements stored in Pmust be a contiguous subset of {1, . . . , n }\nof size at most 3|P|. For j={0,1, . . . ,⌈(n−6|P|)/3|P|⌉}, we create a set Rj={3|P|j+\n1, . . . , 3|P|j+ 6|P|}. (Thus, each Rjis a set of size 6|P|with its first 3|P|elements in common\nwithRj−1.) The ranks of the elements in Pmust be a subset of RτPfor some τP. There are |P|\nranks assigned to P; these are also a contiguous subset of {1, . . . , n }, so they must be a subset of\nRαPfor some αP.8LetδP=|αP−τP|.\n8There may be multiple such αP; pick one arbitrarily.\n11\n\nWe make two observations; both observations state that for Pto exist there must be a high-error\nelement. From Lemma 3, if Pis an actual LLA then there must be an element xjstored in Pwith\nerror ηj≥ |P|/2. Furthermore, all elements in Phave error at least 3|P|(δP−2)(this second\nobservation is important for the case when all items in Phave large error).\nWe split into two cases.\nFirst case: δP≥3.In this case, we use that all items in Pmust have error at least 3|P|(δP−2).\nLettsatisfy |αP−t|=δP(there are two such t). Let xjbe an item with rank in Rt; by Lemma 11,\nthe probability that xjhas error at least 3|P|(δP−2)is:\nPr [ηj≥3|P|(δP−2)]≤1\n(3|P|(δP−2)/ρ)2\nThere are 6|P|elements with ranks in Rt; taking a union bound, the probability that any element has\nerror at least 3|P|(δP−2)is at most\nPr [∃xj∈Rtsuch that ηj≥3|P|(δP−2)]≤6|P|ρ2\n9|P|2(δP−2)2=2ρ2\n3|P|(δP−2)2.\nTaking the union bound over all δP, and over both possible values of tfor a given δP, we obtain\nthe following. Given that δP≥3, the probability that Pis an actual LLA is at most (using thatP∞\nx=11/x2<2):\nnX\nδP=34ρ2\n3|P|(δP−2)2. <4ρ2/|P|.\nSecond case: δP≤2.By Lemma 3, if P∈ Pfthere must be some element xjstored in Pwith\nηj≥ |P|/2. For a given xj, by Lemma 11 we have\nPr [ηj≥ |P|/2]≤4ρ2\n|P|2.\nSince δP≤2, the rank of xjmust be in RτP−2∪RτP−1∪. . .∪RτP+2; there are at most 24|P|\nvalues in this set.9Taking the union bound over all such xjthe probability that P∈ PFis at most\nPr [∃xjsuch that ηj≥ |P|/2]≤24|P| ·4ρ2\n|P|2.≤96ρ2\n|P|.\nPutting it all together. Taking the union bound over the two cases above, the probability that a\npotential LLA Pis an actual LLA is at most 100ρ2/|P|.\nNow, we sum the expected cost over all potential LLAs with |P|> ρ2assigned ranks. There are\nn/2ipotential LLAs with |P|= 2i; if any is an actual LLA, it has cost O(2iC(2i)). From the above,\nthe probability that each is an actual LLA is 100ρ2/|P|= 100 ρ2/2i.\nTherefore, the expected cost of all LLAs is\nlognX\ni=2⌈log2ρ⌉O\u0012n\n2i·2iC(2i)·100ρ2\n2i\u0013\n=O\nnρ2lognX\ni=2⌈log2ρ⌉C(2i)/2i\n\n≤O\nnρ2\n22⌈log2ρ⌉∞X\nj=0C(22⌈log2ρ⌉+j)/2j\n\n≤O\u0000\nnC(ρ2)\u0001\n.\nwhere the last line is because C(·)is admissible. Summing the expected cost of P∈ PFwith height\nat least 2h0and the cost of P∈ PFwith height at most 2h0we obtain the lemma.\n9We do not attempt to optimize constants in this proof.\n12\n\n4 Experiments\nThis section presents experimental results on real datasets. The goal is to show the theory is predictive\nof practice. In particular, the aim is to establish the following.\n•The learnedLLA improves performance over baseline data structures. Moreover, for the\ncommon use case of temporal data, learning from the past leads to future improvements.\n• Predictions made on only a small amount of past data lead to improved performance.\n• The learnedLLA is robust to large errors in the predictions.\nExperimental Setup. We compare the performance of two strong baselines along with our algo-\nrithm. The first baseline is the Packed-Memory Array (PMA) [ 4] and the second is the Adaptive\nPacked-Memory Array (APMA) [ 7]. We tested LearnedLLA with both of these LLAs as the black\nbox LLA. For fairness, we seek to ensure all algorithms have the same memory; therefore, we\nimplemented the PMA (resp. APMA) as a LearnedLLA using a PMA (resp. APMA) as a black box,\nsuch that each element is always placed into the first black box LLA.\nWe use several datasets from SNAP Large Network Dataset Collection [ 38]. All the datasets we\nuse are temporal. The timestamp is used for the arrival order, and an element feature is used for the\narriving element’s value. See Appendix A.2 for detailed dataset descriptions.\nTo generate the predictions for LearnedLLA, we use a contiguous subsequence Ltrainof the input in\ntemporal order as our training data. Our test data Ltestis a contiguous subsequence of the input that\ncomes right after Ltrain, again in temporal order.\nWe use two different algorithms for obtaining predictions:\n• predictor1(Ltrain, Ltest): For each element x∈Ltest, this function first finds the rank of xin\nLtrain, and then it scales it by |Ltest|/|Ltrain|. Finally, it returns these predictions.\n• predictor2(Ltrain, Ltest): Let abe the slope of the best-fit line for points\n{(i, L train[i])}1≤i≤|Ltrain|. First, this function adds a·(d+i·(|Ltest|\n|Ltrain|−1))to the i’th element in\nLtrain, for each 1≤i≤ |Ltrain|, to obtain L′\ntrain, where dis the difference between the starting\npoints of training and test data in our input sequence. Then it returns predictor1(L′\ntrain, Ltest).\nLetL1\ntrainandL2\ntrainbe the first and second halves of Ltrain, respectively. To obtain the final pre-\ndictions for LearnedLLA, we calculate the predictions Pi:=predictori(L1\ntrain, L2\ntrain)fori= 1,2,\nand run LearnedLLA on L2\ntrainwith both of these predictions. If Pi∗performs better, we use\npredictori∗(Ltrain, Ltest)as the final predictions for Ltest.\nOur implementation and datasets can be found at https://github.com/AidinNiaparast/\nLearnedLLA . See Appendix A.2 for more information about the experimental setup.\nExperimental Results. See Table 1 for performance on several real datasets. We show plots\non one dataset (Appendix A.2 contains the plots for the other datasets in Table 1). This dataset\nis Gowalla [ 14], a location-based social networking website where users share their locations by\nchecking in. The latitudes of the locations are used as elements in the input sequence.\nFigure 1a shows the amortized cost versus the test data size. For several values for k, we use the first\nand second n= 2kportions of the input as training data and test data, respectively. Figure 1b shows\nthe performance versus the training data size to illustrate how long it takes for the LearnedLLA to\nlearn. The x-axis is the ratio of the training data size to the test data size (in percentage). Figure 1c is\na robustness experiment showing performance versus the noise added to predictions, using half of the\ndata as training. In this experiment, we first generate predictions by the algorithm described above,\nand then we sample tpercent of the predictions uniformly at random and make their error as large as\npossible (the predicted rank is modified to 1 or n, whichever is farthest from the current calculated\nrank). We repeat the experiment five times, each time resampling the dataset, and report the mean\nand standard deviation of the results of these experiments.\nDiscussion. Results in Table 1 show that in most cases, using even a simple algorithm to predict\nranks can lead to significant improvements in the performance over the baselines; in some cases by\nover 40%. In all cases, the learnedLLA improves upon the performance of the black-box LLA used.\n13\n\nGowalla\n(Latitude)Gowalla\n(LocationID)MOOC AskUbuntu email-Eu-core\nPMA 6.47 6.96 19.22 24.62 21.48\nAPMA 6.93 5.64 16.70 11.34 21.44\nLearnedLLA + PMA 4.32 5.99 11.99 14.29 16.48\nLearnedLLA + APMA 4.39 5.01 12.13 8.53 16.49\nTable 1: Amortized cost of LLAs on several real datasets. Each column corresponds to a dataset (see\nAppendix A.2 for dataset descriptions). Rows represent the amortized cost of PMA, APMA, and\nLearnedLLA using a PMA and APMA as a black box, respectively. In all cases, we use the first and\nsecond 217= 131072 portions of the dataset as training and test data, respectively.\n(a)\n (b)\n (c)\nFigure 1: Latitudes in the Gowalla dataset. In Fig. 1a, we use the first and second n= 2kportions of\nthe input as training data and test data (resp.) for several values of k. In Fig. 1b, the test data is a\nfixed portion of the input of size n= 217= 131072 , and we increase the size of the training data,\nwhich always comes right before the test data. In Fig. 1c, training data and test data are the first and\nsecond 216portions of the input (resp.) and we increase the percentage of “bad” predictions. For\nboth LearnedLLA algorithms in this plot, we resample the bad predictions 5 times. The lines are the\nmeans of these experiments, and the clouds around them show the standard deviation.\nFurthermore, as illustrated in Figure 1b, a small amount of past data—in some cases as small as\n5%—is needed to see a significant separation between the performance of our method and the baseline\nLLAs. Finally, Figure 1c suggests that our algorithm is robust to bad predictions. In particular, in this\nexperiment, the maximum error is as large as possible and a significant fraction of the input have\nerrors in their ranks, yet the LearnedLLA is still able to improve over baseline performance. We\nremark that when an enormous number of predictions are completely erroneous, the method can have\nperformance worse than baselines.\nWe describe more experiments in Appendix A.2; these experiments further support our conclusions.\n5 Conclusion\nIn this paper, we show how to use learned predictions to build a learned list labeling array. We analyze\nour data structure using the learning-augmented algorithms model. This is the first application of\nthe model to bound the theoretical performance of a data structure. We show that the new data\nstructure optimally makes use of the predictions. Moreover, our experiments establish that the theory\nis predictive of practical performance on real data.\nAn exciting line of work is to determine what other data structures can have improved theoretical\nperformance using predictions. A feature of the list labeling problem that makes it amenable to the\nlearning-augmented algorithms model is that its cost function and online nature is similar to the\ncompetitive analysis model, where predictions have been applied successfully to many problems.\nOther data structure problems with similar structure are natural candidates to consider.\nAcknowledgments and Disclosure of Funding\nSamuel McCauley was supported in part by NSF CCF 2103813. Benjamin Moseley was supported in\npart by a Google Research Award, an Infor Research Award, a Carnegie Bosch Junior Faculty Chair,\n14\n\nNational Science Foundation grants CCF-2121744 and CCF-1845146 and U. S. Office of Naval\nResearch grant N00014-22-1-2702. Aidin Niaparast was supported in part by U. S. Office of Naval\nResearch under award number N00014-21-1-2243 and the Air Force Office of Scientific Research\nunder award number FA9550-20-1-0080. Shikha Singh was supported in part by NSF CCF 1947789.\nReferences\n[1]Michael A. Bender, Jonathan W. Berry, Rob Johnson, Thomas M. Kroeger, Samuel McCauley, Cynthia A.\nPhillips, Bertrand Simon, Shikha Singh, and David Zage. Anti-persistence on persistent storage: History-\nindependent sparse tables and dictionaries. In Proc. 35th ACM Symposium on Principles of Database\nSystems (PODS) , pages 289–302, 2016.\n[2] Michael A Bender, Richard Cole, Erik D Demaine, Martin Farach-Colton, and Jack Zito. Two simplified\nalgorithms for maintaining order in a list. In Proc. 10th Annual European Symposium on Algorithms (ESA) ,\npages 152–164. Springer, 2002.\n[3]Michael A Bender, Alex Conway, Martín Farach-Colton, Hanna Komlós, William Kuszmaul, and Nicole\nWein. Online list labeling: Breaking the log3/2nbarrier. In Proc. 63rd Annual IEEE Symposium on\nFoundations of Computer Science (FOCS) , pages 980–990. IEEE, 2022.\n[4]Michael A Bender, Erik D Demaine, and Martin Farach-Colton. Cache-oblivious B-trees. In Proc. 41st\nAnnual IEEE Symposium on Foundations of Computer Science (FOCS) , pages 399–409, 2000.\n[5]Michael A Bender, Martin Farach-Colton, and Miguel A Mosteiro. Insertion sort is O(n log n). Theory of\nComputing Systems (TOCS) , 39:391–397, 2006.\n[6]Michael A Bender, Jeremy T Fineman, Seth Gilbert, and Bradley C Kuszmaul. Concurrent cache-oblivious\nB-trees. In Proc. of the 17th Annual ACM Symposium on Parallelism in Algorithms and Architectures\n(SPAA) , pages 228–237, 2005.\n[7]Michael A Bender and Haodong Hu. An adaptive packed-memory array. ACM Transactions on Database\nSystems (TODS) , 32(4):26:1–26:43, 2007.\n[8]Ioana O Bercea, Jakob Bæk Tejs Houen, and Rasmus Pagh. Daisy bloom filters. arXiv preprint\narXiv:2205.14894 , 2022.\n[9]Antonio Boffa, Paolo Ferragina, and Giorgio Vinciguerra. A learned approach to design compressed\nrank/select data structures. ACM Transactions on Algorithms (TALG) , 18(3):1–28, 2022.\n[10] Jan Bulánek, Michal Kouck `y, and Michael Saks. Tight lower bounds for the online labeling problem. In\nProc. 44th Annual ACM Symposium on Theory of Computing (STOC) , pages 1185–1198, 2012.\n[11] Jan Bulánek, Michal Kouck `y, and Michael Saks. On randomized online labeling with polynomially many\nlabels. In Proc. 40th International Colloquium Automata, Languages, and Programming (ICALP) , pages\n291–302. Springer, 2013.\n[12] Jingbang Chen and Li Chen. On the power of learning-augmented BSTs. arXiv preprint arXiv:2211.09251 ,\n2022.\n[13] Justin Y . Chen, Sandeep Silwal, Ali Vakilian, and Fred Zhang. Faster fundamental graph algorithms via\nlearned predictions. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvári, Gang Niu, and\nSivan Sabato, editors, Proc. 39th Annual International Conference on Machine Learning, (ICML) , volume\n162 of Proceedings of Machine Learning Research , pages 3583–3602. PMLR, 2022.\n[14] Eunjoon Cho, Seth A Myers, and Jure Leskovec. Friendship and mobility: user movement in location-\nbased social networks. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge\ndiscovery and data mining , pages 1082–1090, 2011.\n[15] Sami Davies, Benjamin Moseley, Sergei Vassilvitskii, and Yuyan Wang. Predictive flows for faster\nford-fulkerson. In Proc. 40th International Conference on Machine Learning, (ICML) . PMLR, 2023.\n[16] Dean De Leo and Peter Boncz. Fast concurrent reads and updates with pmas. In Prov. 2nd Joint\nInternational Workshop on Graph Data Management Experiences & Systems (GRADES) and Network\nData Analytics (NDA) , pages 1–8, 2019.\n[17] Dean De Leo and Peter Boncz. Packed memory arrays-rewired. In Proc. 35th IEEE International\nConference on Data Engineering (ICDE) , pages 830–841. IEEE, 2019.\n15\n\n[18] Dean De Leo and Peter Boncz. Teseo and the analysis of structural dynamic graphs. Proceedings of the\nVLDB Endowment , 14(6):1053–1066, 2021.\n[19] Paul F Dietz. Maintaining order in a linked list. In Proc. 14th Annual ACM Symposium on Theory of\nComputing (STOC) , pages 122–127, 1982.\n[20] Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li, Hantian Zhang, Badrish\nChandramouli, Johannes Gehrke, Donald Kossmann, et al. ALEX: an updatable adaptive learned index. In\nProc. 46th Annual ACM International Conference on Management of Data (SIGMOD) , pages 969–984,\n2020.\n[21] Michael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Faster\nmatchings via learned duals. In Marc’Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang,\nand Jennifer Wortman Vaughan, editors, Proc. 34th Annual Conference on Neural Information Processing\nSystems (NeurIPS) , pages 10393–10406, 2021.\n[22] Elbert Du, Franklyn Wang, and Michael Mitzenmacher. Putting the “learning” into learning-augmented\nalgorithms for frequency estimation. In Proc. 38th Annual International Conference on Machine Learning\n(ICML) , pages 2860–2869. PMLR, 2021.\n[23] Marie Durand, Bruno Raffin, and François Faure. A packed memory array to keep moving particles sorted.\nInProc. 9th Workshop on Virtual Reality Interaction and Physical Simulation (VRIPHYS) , pages 69–77.\nThe Eurographics Association, 2012.\n[24] Paolo Ferragina, Hans-Peter Lehmann, Peter Sanders, and Giorgio Vinciguerra. Learned monotone minimal\nperfect hashing. arXiv preprint arXiv:2304.11012 , 2023.\n[25] Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. Why are learned indexes so effective? In Proc.\n37th International Conference on Machine Learning (ICML) , pages 3123–3132. PMLR, 2020.\n[26] Paolo Ferragina, Fabrizio Lillo, and Giorgio Vinciguerra. On the performance of learned data structures.\nTheoretical Computer Science (TCS) , 871:107–120, 2021.\n[27] Paolo Ferragina, Giovanni Manzini, and Giorgio Vinciguerra. Repetition and linearity-aware rank/select\ndictionaries. In Proc. 32nd International Symposium on Algorithms and Computation (ISAAC) . Schloss\nDagstuhl-Leibniz-Zentrum für Informatik, 2021.\n[28] Alex Galakatos, Michael Markovitch, Carsten Binnig, Rodrigo Fonseca, and Tim Kraska. FITing-tree: A\ndata-aware index structure. In Proc. of the 19th Annual International Conference on Management of Data\n(ICDM) , pages 1189–1206, 2019.\n[29] Chen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-based frequency estimation algorithms.\nInProc. 7th Annual International Conference on Learning Representations (ICLR) , 2019.\n[30] Alon Itai, Alan Konheim, and Michael Rodeh. A sparse table implementation of priority queues. Proc. 8th\nAnnual International Colloquium on Automata, Languages, and Programming (ICALP) , pages 417–431,\n1981.\n[31] Zuhair Khayyat, William Lucia, Meghna Singh, Mourad Ouzzani, Paolo Papotti, Jorge-Arnulfo Quiané-\nRuiz, Nan Tang, and Panos Kalnis. Fast and scalable inequality joins. The VLDB Journal , 26(1):125–150,\n2017.\n[32] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska, and\nThomas Neumann. Sosd: A benchmark for learned indexes. arXiv preprint arXiv:1911.13014 , 2019.\n[33] Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons Kemper, Tim Kraska, and\nThomas Neumann. Radixspline: a single-pass learned index. In Proc. 3rd International Workshop on\nExploiting Artificial Intelligence Techniques for Data Management , pages 1–5, 2020.\n[34] Tsvi Kopelowitz. On-line indexing for general alphabets via predecessor queries on subsets of an ordered\nlist. In Proc. 53rd Annual IEEE Symposium on Foundations of Computer Science (FOCS) , pages 283–292.\nIEEE, 2012.\n[35] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index\nstructures. In Gautam Das, Christopher M. Jermaine, and Philip A. Bernstein, editors, Proc. 44th Annual\nInternational Conference on Management of Data, (SIGMOD) , pages 489–504. ACM, 2018.\n[36] Srijan Kumar, Xikun Zhang, and Jure Leskovec. Predicting dynamic embedding trajectory in temporal\ninteraction networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge\nDiscovery & Data Mining , pages 1269–1278. ACM, 2019.\n16\n\n[37] Silvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Online scheduling via\nlearned weights. In Shuchi Chawla, editor, Proc. 31st annual ACM Symposium on Discrete Algorithms,\n(SODA) , pages 1859–1877. SIAM, 2020.\n[38] Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection. http:\n//snap.stanford.edu/data , June 2014.\n[39] Honghao Lin, Tian Luo, and David Woodruff. Learning augmented binary search trees. In Proc. 35th\nInternational Conference on Machine Learning (ICML) , pages 13431–13440. PMLR, 2022.\n[40] Ryan Marcus, Emily Zhang, and Tim Kraska. Cdfshop: Exploring and optimizing learned index structures.\nInProc. 46th Annual International Conference on Management of Data (SIGMOD) , pages 2789–2792,\n2020.\n[41] Michael Mitzenmacher. A model for learned bloom filters and optimizing by sandwiching. Proc. 31st\nAnnual Conference on Neural Information Processing Systems (NeurIPS) , 31, 2018.\n[42] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. Communications of the\nACM (CACM) , 65(7):33–35, 2022.\n[43] Prashant Pandey, Brian Wheatman, Helen Xu, and Aydin Buluc. Terrace: A hierarchical graph container\nfor skewed dynamic graphs. In Proc. 21st International Conference on Management of Data (ICDM) ,\npages 1372–1385, 2021.\n[44] Ashwin Paranjape, Austin R Benson, and Jure Leskovec. Motifs in temporal networks. In Proceedings of\nthe tenth ACM international conference on web search and data mining , pages 601–610, 2017.\n[45] Vijayshankar Raman. Locality preserving dictionaries: theory & application to clustering in databases. In\nProc. 18th ACM Symposium on Principles of Database Systems (PODS) , pages 337–345, 1999.\n[46] Tim Roughgarden. Beyond the worst-case analysis of algorithms . Cambridge University Press, 2021.\n[47] Ibrahim Sabek, Kapil Vaidya, Dominik Horn, Andreas Kipf, Michael Mitzenmacher, and Tim Kraska. Can\nlearned models replace hash functions? Proceedings of the VLDB Endowment , 16(3):532–545, 2022.\n[48] Shinsaku Sakaue and Taihei Oki. Discrete-convex-analysis-based framework for warm-starting algorithms\nwith predictions. In Proc. 35th Annual Conference on Neural Information Processing Systems (NeurIPS) ,\n2022.\n[49] Kapil Vaidya, Eric Knorr, Michael Mitzenmacher, and Tim Kraska. Partitioned learned bloom filters. In\nProc. 9th Annual International Conference on Learning Representations (ICLR) , 2021.\n[50] Brian Wheatman and Randal Burns. Streaming sparse graphs using efficient dynamic sets. In Proc. 7th\nIEEE International Conference on Big Data (BigData) , pages 284–294. IEEE, 2021.\n[51] Brian Wheatman and Helen Xu. Packed compressed sparse row: A dynamic graph representation. In Proc.\n22nd IEEE High Performance Extreme Computing Conference (HPEC) , pages 1–7. IEEE, 2018.\n[52] Brian Wheatman and Helen Xu. A parallel packed memory array to store dynamic graphs. In Proc. 23rd\nWorkshop on Algorithm Engineering and Experiments (ALENEX) , pages 31–45. SIAM, 2021.\n[53] Dan E Willard. Inserting and deleting records in blocked sequential files. Bell Labs Tech Reports, Tech.\nRep. TM81-45193-5 , 1981.\n[54] Dan E Willard. Maintaining dense sequential files in a dynamic environment. In Proc. 14th Annual ACM\nSymposium on Theory of Computing (STOC) , pages 114–121, 1982.\n[55] Dan E Willard. Good worst-case algorithms for inserting and deleting records in dense sequential files. In\nACM SIGMOD Record , volume 15:2, pages 251–260, 1986.\n[56] Dan E Willard. A density control algorithm for doing insertions and deletions in a sequentially ordered file\nin a good worst-case time. Information and Computation , 97(2):150–204, 1992.\n[57] Jiacheng Wu, Yong Zhang, Shimin Chen, Jin Wang, Yu Chen, and Chunxiao Xing. Updatable learned\nindex with precise positions. Proceedings of the VLDB Endowment , 14(8):1276–1288, 2021.\n17\n\nA Appendix\nA.1 Background: Packed-Memory Arrays\nThis section provides background on a common list labeling data structure, the packed-memory array\n(PMA) , introduced by Bender et al. [ 4]. The data structure in [ 4] extends the LLAs of [ 30,54,55] by\nadding lower-density thresholds. Lower-density thresholds provide the added guarantee that any two\nelements in the array are Θ(1) slots apart. Both versions guarantee an amortized cost of O(log2n).\nFor simplicity, we describe the PMA using only upper density thresholds.\nClassic PMA. Consider an array with m=cnslots, for a constant c >1. Divide the array\ninto ranges of size Θ(log n). These ranges form the leaves of an implicit binary tree on top of the\nΘ(n/logn)leaves. Each node in this implicit binary tree corresponds to a subarray containing all\nleaf ranges within its subtree.\nFor a node in the implicit binary tree, define the size(u)as number of slots in its subarray and\ndensity( u)as the number of elements in its subarray divided by size( u). Let the depth of the root\nnode be 0, nodes and leaf nodes be at depth d= Θ(log n/log log n).\nFor each node uat depth k, letτkbe the density threshold . Let τ0andτdbe constants such that\n0< τ0< τd<1. For a node at depth k, letτk=τ0+ (τd−τ0)·k\nd.\nA node uiswithin threshold ifdensity (u)≤τk. If a node is within threshold, then all its descendants\nare also within threshold.\nTo insert an element x, determine the leaf range rit belongs to. If the leaf range ris within threshold,\nthere is always a slot for x. Insert xin its slot and rebalance the rby evenly distributing all elements.\nIf the leaf range is out of threshold, find the first ancestor raof the rthat is within threshold and\nrebalance all elements evenly in that range. Now ris within threshold and there is room to insert x.\nTo see why the amortized cost of insertion is O(log2n), consider the insertion of element xthat\ncauses a node uat depth kto be rebalanced. Then, a child vofumust be out of threshold, that is,\ndensity (v)> τk+1. After we rebalance u, both v(and its sibling) have density at most τk(density\nthreshold of its parent u). The node uwould need to rebalanced again when either v(or its sibling)\ngo out of treshold again. This requires at least (τk+1−τk)·size(v)additional insertions. A rebalance\nof node ucosts size (u). Thus, the amortized cost of rebalancing uis:\nsize(u)\n(τk+1−τk)size(v)=2\nτk+1−τk=2d\nτd−τ0=O(logn)\nSince an insertion can contribute to O(logn)ancestors being out of balance, the overall amortized\ncost of an insertion is O(log2n).\nA.2 Additional Experiments\nIn this section, we further describe the experimental setup and the datasets we use. We also present\nmore experimental results.\nExperimental setup. We use a machine with 11th Gen Intel Core i7 CPU 2.80GHz, 32GB of RAM,\n128GB NVMe KIOXIA disk drive, and running 64-bit Windows 10 Enterprise to run our experiments.\nWe remark that amortized cost, the average number of element movements, is hardware-independent.\nWe use the following density thresholds for the PMA and APMA: root’s lower threshold: 0.2, leaves’\nlower threshold: 0.1, root’s upper threshold: 0.5, leaves’ upper threshold: 0.9. We add a −∞ element\nat the beginning of each experiment. This is to make sure the internal predictor data structure in\nAPMA operates as expected from the beginning of the experiment (see [ 7]). The datasets we use\nmight include duplicate elements, and we use the same algorithm to insert these elements, even\nthough in Section 2, we assume the elements in the input sequence form a set. This does not affect\nany of the algorithms and they are still well-defined. The relative order between duplicates can be\narbitrary. In LearnedLLA, when we insert an element x, to find the black box LLAs containing the\npredecessor and successor of x, we use Python Sorted Containers library10(note that since we only\n10https://grantjenks.com/docs/sortedcontainers/\n18\n\nmeasure the amortized cost, our results are independent of the function used to find these LLAs). For\nmeasuring the amortized cost in the experiments, we do not count the first assignment of a label to an\nelement as a relabel (note that this is in contrast to the theory section of the paper).\n(a)\n (b)\n (c)\nFigure 2: Gowalla (LocationID)\n(a)\n (b)\n (c)\nFigure 3: MOOC\n(a)\n (b)\n (c)\nFigure 4: AskUbuntu\nDataset description. Here we describe the real temporal datasets we use in our experiments. In all\ncases, we use a prefix of the dataset in temporal order as the input sequence.\n•Gowalla11[14]: Gowalla is a location-based social networking website where users share\ntheir locations by checking in. We use the location ID and latitude of the users that check in.\n•MOOC12[36]: The MOOC user action dataset represents the actions taken by users on a\npopular MOOC platform. The actions are represented as a directed, temporal network. The\nnodes represent users and course activities (targets), and edges represent the actions by users\non the targets. We use the user IDs as our input sequence.\n•AskUbuntu13: This is a temporal network of interactions on the stack exchange web site\nAsk Ubuntu. There are three different types of interactions represented by a directed edge\n(u, v, t ): i. user uanswered user v’s question at time t, ii. user ucommented on user v’s\nquestion at time t, and iii. user ucommented on user v’s answer at time t. We use the IDs\nof target users in the answers-to-questions network as the input sequence.\n•email-Eu-core14[44] The network was generated using email data from a large European\nresearch institution. The e-mails only represent communication between institution members\n11https://snap.stanford.edu/data/loc-Gowalla.html\n12https://snap.stanford.edu/data/act-mooc.html\n13https://snap.stanford.edu/data/sx-askubuntu.html\n14https://snap.stanford.edu/data/email-Eu-core-temporal.html\n19\n\n(a)\n (b)\n (c)\nFigure 5: email-Eu-core\n(the core), and the dataset does not contain incoming messages from or outgoing messages\nto the rest of the world. A directed edge (u, v, t )means that person usent an e-mail to\nperson vat time t. A separate edge is created for each recipient of the e-mail. We use the\nIDs of target users as our input sequence.\nResults. In Figures 2 to 5, we show plots for other datasets in Table 1. The setup is exactly similar\nto Figure 1.\nDiscussion. These results further support our conclusions. Note that in some cases, increasing the\nsize of the training set results in slightly worse performance for LearnedLLA. We believe this is\nbecause as we increase the size of the training data, we use older data as training.\n20",
  "textLength": 72633
}