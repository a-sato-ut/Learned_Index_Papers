{
  "paperId": "a0da0fb1e2766506794489ec2f077cb63de4d699",
  "title": "Learning-Based Data Storage [Vision] (Technical Report)",
  "pdfPath": "a0da0fb1e2766506794489ec2f077cb63de4d699.pdf",
  "text": "Learning-Based Data Storage [Vision]\n(Technical Report)\nXiang Lian\nKent State University\nKent, OH 44242, USA\nxlian@kent.eduXiaofei Zhang\nThe University of Memphis\nMemphis, TN 38152, USA\nxiaofei.zhang@memphis.edu\nABSTRACT\nDeep neural network (DNN) and its variants have been extensively\nused for a wide spectrum of real-world applications such as image\nclassification, face/speech recognition, fraud detection, and so on.\nIn addition to many important machine learning tasks, as artificial\nnetworks emulating the way brain cells function, DNNs also show\nthe capability of storing non-linear relationships between input and\noutput data, which exhibits the potential of storing data via DNNs.\nWe envision a new paradigm of data storage, â€œDNN-as-a-Databaseâ€,\nwhere data are encoded in well-trained machine learning models.\nCompared with conventional data storage that directly records data\nin raw formats, learning-based structures (e.g., DNNs) can implicitly\nencode data pairs of inputs and outputs and compute/materialize\nactual output data of different resolutions only if input data are\nprovided. This new paradigm can greatly enhance the data security,\nallow flexible data privacy settings on different levels, achieve low\nspace consumption and fast computation with the acceleration of\nnew hardware (e.g., Diffractive Neural Networks or AI chips), and\ncan be generalized to distributed DNN-based storage/computing.\nIn this paper, we will propose this novel concept of learning-based\ndata storage , which utilizes a learning structure called learning-\nbased memory unit (LMU), to store, organize, and retrieve data. As\na case study, we use DNNs as the engine in the LMU, and study\nthe data capacity and accuracy of the DNN-based relational tables.\nOur preliminary experimental results show the feasibility of the\nlearning-based data storage by achieving high (100%) accuracy of\nthe stored data in the DNN. We also explore and design effective\nsolutions to manage and query the DNN-based relational tables in\nLMU. Furthermore, we discuss how to generalize our solutions to\nother data types (e.g., graphs) and environments such as distributed\nDNN storage/computing.\nPVLDB Reference Format:\nXiang Lian and Xiaofei Zhang. Learning-Based Data Storage [Vision]\n(Technical Report). arXiv.org, 14(1): XXX-XXX, 2022.\ndoi:XX.XX/XXX.XX\nThe initial idea of this work on learning-based data storage was born on November\n11, 2020. This work is licensed under the Creative Commons BY-NC-ND 4.0\nInternational License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to\nview a copy of this license. For any use beyond those covered by this license, obtain\npermission by emailing info@vldb.org. Copyright is held by the owner/author(s).\nPublication rights licensed to the VLDB Endowment.\nProceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.\ndoi:XX.XX/XXX.XX1 MOTIVATION AND GOALS\nFor the past decades, deep learning [1,42] has been widely used\nfor numerous important real applications such as image classifica-\ntion [ 18], computer vision [ 27], automatic speech recognition [ 34].\nExamples of many proposed deep learning structures include deep\nneural network (DNN) [ 4], and its variants like recurrent neural\nnetwork (RNN) [ 40] and convolutional deep neural network (CNN)\n[9]. These learning-based structures (e.g., DNNs) have been shown\nto produce state-of-the-art results on many machine learning tasks\nsuch as classification, regression, and decision making. While DNNs\n(or other variants of learning-based structures) are trained to essen-\ntially capture non-linear relationships between inputs and outputs,\nthe potential of using DNNs themselves to enable effective and\nefficient data storage as well as data management and analysis,\nsimilar to the way human brains function, has been underestimated\nor even ignored in the literature.\nIn this paper, we propose a new paradigm of data storage,\nnamed â€œDNN-as-a-Databaseâ€ , which implicitly encodes data pairs\nof inputs (e.g., resource identifiers) and outputs (e.g., pointers point-\ning to data resources) via well-trained machine learning models\n(e.g., DNNs). Compared with conventional data storage that di-\nrectly records data in raw formats (e.g., relational tables), learning-\nbased structures (e.g., DNNs) do not explicitly release original data.\nInstead, with the â€œDNN-as-a-Databaseâ€ paradigm, we use DNN\nformats, and compute/materialize actual output data (of different\ngranularity) only if input data are provided, which can significantly\nenhance the data security and allow flexible data privacy settings\n(e.g., storing attribute value intervals of different resolutions in\nDNNs).\nOur â€œDNN-as-a-Databaseâ€ paradigm can be used in scenarios\nincluding, but not limited to:\nâ€¢(Distributed Data Storage/Computing) In the distributed\nenvironment, DNNs (rather than original data formats) can\nbesafely stored on multiple servers (without disclosing ac-\ntual data), and only be materialized when input data are\nprovided and computing resources are budgeted. This capa-\nbility offers the potential to safely store large-scale data on\nservers and perform secure and parallel data analyses with\nlow communication costs.\nâ€¢(Secured Data Storage/Computing) According to differ-\nent security settings (e.g., whether or not servers and net-\nworks are trusted), our DNN-based data storage has the\nsecurity option of training DNNs over the encrypted in-\nputs/outputs. This option allows data retrieval and query pro-\ncessing without the data decryption and avoids honest-but-\ncurious (HBC) adversaries from breaching the data through\nnetworks or servers.arXiv:2206.05778v3  [cs.DB]  23 Jan 2023\n\nFurthermore, with the advent and acceleration of new hardware\n(e.g., â€œprogrammableâ€ Diffractive Neural Network [26] with minia-\nturization), DNNs are expected to achieve low space consumption\nand fast computation (e.g., speed of light), which makes learning-\nbased data storage an attractive option that emulates how human\nbrains memorize data.\nTherefore, from a novel perspective of memory features of learning-\nbased structures (e.g., DNNs), in this paper, we envision the po-\ntential and feasibility of a novel learning-based data storage\nto utilize learning-based structures such as DNNs to store ,\nmanage , and analyze big data , instead of using DNNs to do clas-\nsic machine learning tasks such as image classification and object\nrecognition. In order to test features of the learning-based data\nstorage, we will study and evaluate the accuracy of data that\na DNN can encode and store under various parameter set-\ntings . In our preliminary results, we organize a pool of DNNs, as\nwell as auxiliary information (e.g., indexes and/or aggregates), in\na so-called learning-based memory unit (LMU), which contains a\nDNN-tree structure and can achieve high data capacity and accu-\nracy.\nOne major challenge for designing this DNN-based data storage\nis on how to enable effective maintenance and efficient data analyt-\nics over such a DNN-based data storage. As a case study, in this pa-\nper, we will focus on classic structured data, relational tables ,\nand transform them to the DNN-based tables in the LMU . We\nwillformulate and effectively tackle problems of dynamic\nmaintenance and query processing over DNN-based tables ,\nincluding tuple insertions/deletions, attribute updates, projection,\nselection (e.g., equality/range search), Cartesian product, join, set\nunion, set intersection, and set difference.\nA Framework for the Learning-Based Data Storage. Figure 1\nillustrates a general framework for the learning-based data storage\n(LDS), which consists of four modules: (1) data collection and pre-\nprocessing module , (2)learning-based data storage module , (3)data\nmanagement and retrieval module , and (4) query interface module .\nSpecifically, the data collection and pre-processing module col-\nlects real-world application data such as relational tables and tests\nfeatures of DNN models over these real data (i.e., training data)\nvia parameter tuning in terms of the maximum data capacity and\naccuracy. The learning-based data storage module constructs and\norganizes a pool of DNNs, as well as their auxiliary information\nlike indexes/aggregates, in the learning-based memory unit (LMU),\nwhich stores relational tables and achieves the best data capacity\nand accuracy. The data management and retrieval module provides\ncomprehensive functions/algorithms to maintain and query DNN-\nbased data storage, such as SQL-like queries (e.g., equality/range\nsearch, join operator, union/intersection/set difference, etc.) and\ntable updates (e.g., tuple insertions/deletions and attribute updates).\nFinally, the query interface module provides users with a graphical\nuser interface (GUI) to manage, query, and visualize tables rep-\nresented by learning-based structures. These four modules will\nbe seamlessly integrated into a learning-based data storage (LDS)\nsystem for users (e.g., data analysts, AI/ML/DM domain experts,\nor biologists) to analyze the DNN-based data in real applications\nand/or study the inner mechanisms of learning-based structures\nfor data storage that emulate human memory.Our proposed DNN-based storage mechanism can be considered\nas a preliminary work for learning-based data storage. In the future,\nthis work can be generalized to other heterogeneous data (e.g.,\nunstructured data, trees, graphs, etc.) or other computing paradigms\n(e.g., distributed computing).\nThe remainder of this paper is organized as follows. Section 2\nformalizes the problem of the DNN-based data storage for relational\ntables. Section 3 presents our preliminary results on the LMU design\nof organizing learning-based structures (i.e., DNNs). Sections 4 and\n5 discuss how to maintain and query the DNN-based data storage,\nrespectively. Section 6 discusses variants of our DNN-based data\nstorage under different security settings. Section 7 evaluates the\nperformance of our proposed DNN-based data storage through\nextensive experiments. Section 8 reviews previous works on deep\nneural networks and learning-based data management. Sections 9\nand 10 discuss how to generalize our learning-based data storage\nto graph data and distributed environment, respectively. Finally,\nSection 11 concludes this paper.\nTable 1: Notations and Descriptions\nNotation Description\nğ‘‡(orğ‘…,ğ‘†) a relational table containing ğ‘tuples\nD(orDğ‘…,Dğ‘†)a DNN-based data storage\nğ‘¡ğ‘–(orğ‘Ÿ,ğ‘ ) a tuple in the relational table\nğ‘¡ğ‘–.ğ‘–ğ‘‘ the unique identifier of tuple ğ‘¡ğ‘–\nğ‘¡ğ‘–[ğ´ğ‘—] theğ‘—-th attribute of tuple ğ‘¡ğ‘–(for1â‰¤ğ‘—â‰¤ğ‘‘)\nğ‘š the number of inputs in DNNs\nğ‘› the number of outputs in DNNs\nğ‘“ the number of neurons for each hidden layer in DNNs\nğ¿ the number of hidden layers in DNNs\n2 PROBLEM DEFINITION\nTable 1 depicts the commonly used symbols and their descriptions\nin this paper.\n2.1 Relational Data Model\nDefinition 1. (Relational Table, ğ‘‡)A relational table ğ‘‡con-\ntains a set of ğ‘tuplesğ‘¡ğ‘–, each of which has a unique identifier (e.g.,\nprimary key) ğ‘¡ğ‘–.ğ‘–ğ‘‘andğ‘‘attributesğ‘¡ğ‘–[ğ´1],ğ‘¡ğ‘–[ğ´2], ..., andğ‘¡ğ‘–[ğ´ğ‘‘],\nwhere attributes ğ‘¡ğ‘–[ğ´ğ‘—](for1â‰¤ğ‘—â‰¤ğ‘‘) have the integer domains.\nIn Definition 1, for simplicity, we assume that attributes ğ‘¡ğ‘–[ğ´ğ‘—]\nof each tuple ğ‘¡ğ‘–âˆˆğ‘‡are integers, which represent either attribute\nvalues or pointers pointing to attribute values of any data types\n(e.g., texts, numerical values, images, audio, videos, etc.).\n2.2 DNN Model\nAs illustrated in Figure 2, a deep neural network (DNN) [ 4] is an\nartificial neural network, which contains ğ‘šinputs,ğ‘›outputs, and\nğ¿hidden layers (ğ»ğ¿) (each containing ğ‘“neurons with activation\nfunctions such as Sigmoid or ReLU). We denote a DNN as:\nğ·ğ‘ğ‘âˆ¼(ğ‘–ğ‘›,ğ‘œğ‘¢ğ‘¡),\nwhereğ‘–ğ‘›andğ‘œğ‘¢ğ‘¡are vectors of inputs and outputs, respectively. In\nother words, we have ğ‘œğ‘¢ğ‘¡=ğ·ğ‘ğ‘(ğ‘–ğ‘›).\n2\n\nFigure 1: A Framework for the Learning-Based Data Storage (LDS).\nFigure 2: Illustration of an ğ‘š-ğ‘“[ğ¿]-ğ‘›Deep Neural Network (DNN).\nThe Space Cost of a DNN. The space complexity of a DNN is\ngiven byğ‘‚\u0000(ğ‘š+ğ‘›)Â·ğ‘“+ğ‘“2Â·(ğ¿âˆ’1)\u0001.\nNevertheless, inspired by recent works on all-optical deep learn-\ning(e.g., Diffractive Neural Networks [ 26]), we expect that DNNs\nmay be boosted via 3D-printed hidden layers by consuming small\nspace and achieving the computation with the speed of light (us-\ning light signals). We believe that in the near future such new\nhardware (e.g., â€œprogrammableâ€ Diffractive Neural Networks with\nminiaturization, similar to very large-scale integrated circuits, or\nAI chips) may significantly enhance DNN performance, including\nboth space and computation costs. In particular, the space cost (e.g.,\nfor 3D-printed hidden layers) might be reduced to ğ‘‚(ğ‘“Â·ğ¿).\nFigure 3: Illustration of a Learning-based Memory Unit (LMU), D,\nOver DNN-based Relational Tables ğ‘‡.\nIn this work, we use the DNN model to train/store multiple input-\nand-output pairs, where any classic DNN training algorithm can\nbe applied. We would like to consider other structures (e.g., DNN\nvariants) for the learning-based data storage as our future work.\n2.3 Learning-based Memory Unit for the\nDNN-based Data Storage\nAs illustrated in Figure 3, we present a learning-based memory unit\n(LMU), denoted asD, to store a relational table ğ‘‡, which consists of\ntwo components, DNNs D.ğ·ğ‘ğ‘ and auxiliary information D.ğ‘ğ‘¢ğ‘¥.\nDeep Neural Networks, D.ğ·ğ‘ğ‘ .InD.ğ·ğ‘ğ‘ , we will train and\ninclude the following DNNs to store tuples ğ‘¡ğ‘–(1â‰¤ğ‘–â‰¤ğ‘) in table\nğ‘‡:\nğ·ğ‘ğ‘âˆ¼((ğ‘¡ğ‘–.ğ‘–ğ‘‘),(ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘])),\n3\n\nand\nğ·ğ‘ğ‘âˆ’1âˆ¼((ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]),(ğ‘¡ğ‘–.ğ‘–ğ‘‘)),\nwhereğ·ğ‘ğ‘âˆ’1may have multiple outputs (if multiple tuples have\nthe sameğ‘‘attribute values).\nFor a large-scale relational table, in practice, we can divide tuples\ninto multiple partitions via vertical/horizontal partitioning, and use\nmultiple pairs of ğ·ğ‘ğ‘ andğ·ğ‘ğ‘âˆ’1to store individual partitions.\nMoreover, to implement ğ·ğ‘ğ‘ orğ·ğ‘ğ‘âˆ’1, we will use DNN-tree\nstructures as discussed later in Section 3 to achieve both high data\ncapacity and accuracy.\nAuxiliary Information, D.ğ‘ğ‘¢ğ‘¥.For auxiliary information D.ğ‘ğ‘¢ğ‘¥,\nwe will record aggregate data or indexes (e.g., hash files, B+-trees, or\nmultidimensional indexes like grid or Râˆ—-trees) over attributes (i.e.,\ninputs of DNNs), for example, the range, [1,ğ‘], of tuple identifiers\nğ‘¡ğ‘–.ğ‘–ğ‘‘forğ·ğ‘ğ‘ .\nNote that, to support the maintenance and queries over DNN-\nbased data storage, we will discuss more contents that should be\nincluded inD.ğ·ğ‘ğ‘ andD.ğ‘ğ‘¢ğ‘¥ later in Section 5.2.\nSequential Scan. To sequentially scan the entire table ğ‘‡in the\nDNN-based data storage D, we first obtain the range of tuple iden-\ntifiersğ‘¡ğ‘–.ğ‘–ğ‘‘inğ‘‡fromD.ğ‘ğ‘¢ğ‘¥, for example,[1,ğ‘], whereğ‘is the\nnumber of tuples in ğ‘‡. Then, we use the DNN, ğ·ğ‘ğ‘ , which takes\nthe inputğ‘¡ğ‘–.ğ‘–ğ‘‘from 1toğ‘and outputs ğ‘ ğ‘‘-dimensional attribute\nvectors(ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]), respectively.\nTuple Existence Checking. Assuming that we have a tuple iden-\ntifierğ‘¡ğ‘–.ğ‘–ğ‘‘, atuple existence checking problem returns true, if this\ntupleğ‘¡ğ‘–is inğ‘‡; or false, otherwise. Given a tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘\nas the input, we can simply check the existence of ğ‘¡ğ‘–.ğ‘–ğ‘‘through\nD.ğ‘ğ‘¢ğ‘¥.\nOn the other hand, given ğ‘‘attributes(ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]), we\ncan also check whether or not a tuple ğ‘¡ğ‘–with theseğ‘‘attribute\nvalues exists in ğ‘‡by (1) obtaining a possible tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘=\nğ·ğ‘ğ‘âˆ’1(ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]), and (2) checking whether or not the\npossible tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘exists in the index of D.ğ‘ğ‘¢ğ‘¥.\n3 PRELIMINARY RESULTS ON THE LMU\nDESIGN\nIn our initial empirical study, we synthetically generate 1,000 dis-\ntinct tuples, each with 4 random integer attributes (with the domain\n[1, 1,000]) and a unique tuple identifier (i.e., a key ranging between\n1 and 1,000). Below, we outline preliminary results tested on a DNN\nwith 4 hidden layers (128 neurons per layer) using PyTorch [ 38]. We\nreport the best accuracy achieved after hyper-parameter tuning.\nâ€¢Regression Trial (Failed): As illustrated in Figure 4(a),\nwe tested the DNN regression and used 4 attribute values,\nğ‘¡ğ‘–[ğ´1]âˆ¼ğ‘¡ğ‘–[ğ´4], to estimate the tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘. The\npredicted tuple identifier usually has a large variance, devi-\nating from the actual one. As a remedy, we tried multi-level\nstructure of DNNs, i.e., using 4 attributes to first predict a\nvalue range of the difference between the target ID and cur-\nrent output, and then train another regression model for the\nrecords falls in the same variance range. Intuitively, each\nrange will have fewer records to train/store. However, this\ntrial leads to the best overall accuracy of only 3.12%, which\nvalidates that the regression model via DNNs is not a feasible\ndirection to explore.\n(a)DNN regression (3.12% accuracy;\nFailed)\n(b)classifying tuple ID ğ‘¡ğ‘–.ğ‘–ğ‘‘(100% accuracy;\nSuccessful)\n(c)classifying attribute ğ‘¡ğ‘–[ğ´ğ‘—]\n(0.2% accuracy; Failed)\n(d)classifying attribute ğ‘¡ğ‘–[ğ´ğ‘—](100% accuracy; Suc-\ncessful)\nFigure 4: Preliminary Results on the Accuracy of DNN Regres-\nsion/Classification.\nFigure 5: Illustration of a DNN-Tree.\nâ€¢Classification Trial (Successful): As illustrated in Figure\n4(b), by treating each possible tuple identifier as a class,\nwe tested the DNN classification approach and classified 4\nattribute values, ğ‘¡ğ‘–[ğ´1]âˆ¼ğ‘¡ğ‘–[ğ´4], to a class (i.e., tuple identi-\nfierğ‘¡ğ‘–.ğ‘–ğ‘‘). We observed that such a DNN is able to achieve\n100% accuracy. Then, we used a single tuple identifier to\npredict/classify the attribute values. For simplicity, as illus-\ntrated in Figure 4(c), we tested a one-on-one mapping from\ntuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘to one attribute ğ‘¡ğ‘–[ğ´ğ‘—]. Unfortunately,\nthis model can only achieve an accuracy of 0.2%, probably\ndue to the input signal being too weak. To fix this issue, we\nfirst transformed the tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘to a 4-dimensional\nvector, where vector elements are pseudo random numbers\ngenerated by a random number generator, ğ‘Ÿğ‘ğ‘›ğ‘‘(Â·), with the\ntuple identifier as the seed. Then, we use this 4D vector as the\ninput of the DNN for classifying/obtaining attribute ğ‘¡ğ‘–[ğ´ğ‘—].\nThis way, the model can achieve 100% accuracy in predicting\nattribute values. By training 4 such DNNs (corresponding\nto 4 attributes, respectively), we can successfully retrieve\nthe entire record by feeding the tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘to the\nDNNs.\n4\n\n 20 30 40 50 60 70 80 90 100\n1K 2K 3K 4K 5KAccuracy (%)\nNHL=64[4]\nHL=128[4]\nHL=256[4](a)accuracy vs. table size\n 0 2 4 6 8 10 12 14\n10 100 1000Max N (x103) \n# of Classes, nHL=64[4]\nHL=128[4]\nHL=256[4] (b)max. data capacity vs. # of classes\nFigure 6: The DNN Data Accuracy/Capacity Test.\nOrganization of DNNs in the LMU, DNN-Tree. Inspired by our\npreliminary results above, we will consider DNNs for classifica-\ntion with labels (classes) corresponding to different resolutions\n(i.e., attribute value intervals of different lengths). Moreover, since\nDNNs are not good at predicting too many labels (e.g., 1K or\n10K classes) at a time, alternatively, as illustrated in Figure 5, we\nwill organize a pool of DNNs, and build a hierarchical DNN-tree\nover them, in which each node is a DNN with much fewer labels\n(e.g., 10 classes), but high (100%) accuracy. In particular, each child\nDNN node in the DNN-tree (w.r.t. attribute ğ‘¡ğ‘–[ğ´ğ‘—]) is in the form:\nğ·ğ‘ğ‘âˆ¼((ğ‘¡ğ‘–.ğ‘–ğ‘‘),(ğ‘¡ğ‘–[ğ´ğ‘—])), which has outputs (i.e., class labels) cor-\nresponding to finer value intervals of attribute ğ´ğ‘—(e.g.,[90,100)),\ncompared with that of its parent DNN node (e.g., [0,100)). This way,\nat leaf level of the DNN-tree, the precision of the predicted class\nlabels is withinÂ±0.5 range, which can accurately predict an integer\nattribute value (e.g., integer 9for interval[9,10)). As a result, we\nonly need to traverse the DNN-tree from the root to a leaf node\nand incrementally narrow down the range of attribute values from\ncoarse to fine resolutions via DNNs.\nHere, as a side product of using the DNN-tree, we can obtain\nflexible resolutions/intervals of attribute values by controlling the\nnumber of levels provided in the DNN-tree, which can be used for\nattribute generalization [45] in privacy preserving applications.\nDNN Data Accuracy and Maximum Data Capacity. We also\nconduct preliminary experiments on a single DNN model â€œ ğ·ğ‘ğ‘âˆ¼\n(ğ‘¡ğ‘–.ğ‘–ğ‘‘,ğ‘¡ğ‘–[ğ´ğ‘—])â€ (as given in Figure 4(d)) and evaluate the accuracy\nand maximum capacity of data that it can store, by varying the\nnumber,ğ‘, of training/testing tuples or output class number ğ‘›.\nAs shown in Figure 16, we use ğ»ğ¿=ğ‘“[ğ¿]to denote the config-\nuration ofğ¿fully connected hidden layers, where each layer is of\nsizeğ‘“. In our first set of experiments, we empirically validate that\nlarger DNN models can â€œmemorizeâ€ more tuple data. In Figure 6(a),\nwhenğ»ğ¿=256[4], DNN can guarantee 100% accuracy when the\ninput has 4,000 records, while the other two models (i.e., 64[4]and\n128[4]) see significant accuracy drops at this scale of data size.\nIn Figure 6(b), we test the maximum number of stored tuples (i.e.,\nmaxğ‘) in the DNN that can deliver 100% accuracy, for different\nnumbers of output classes ğ‘›. One observation is that when ğ‘›in-\ncreases exponentially, ğ‘does not drop fast accordingly, especially\nfor DNN of smaller size. For example, for DNN with ğ»ğ¿=128[4],\nthe maximum ğ‘values with 10, 100, and 1,000 output classes are4.4ğ¾,3.1ğ¾, and 1.9ğ¾, respectively.1Another intriguing observa-\ntion is that when we double the layer size ğ‘“of a DNN, which is\nequivalent to enlarging the model size by 4 times, the new modelâ€™s\ncapacity in terms of the max ğ‘does not necessarily increase pro-\nportionally, especially when the number of classes ğ‘›is large. It thus\nraises the optimization opportunity to balance among the DNN\nmodel size, accuracy, and capacity given certain (table) data size,\nwhich can be used for the parameter tuning of basic DNN units in\nthe DNN-tree.\nIn subsequent sections, if there is no ambiguity, we will still\nrefer to DNN-trees as DNNs (although there are inner hierarchical\nstructures for DNN-trees) for simplicity.\n4 MAINTENANCE OF DNN-BASED\nRELATIONAL TABLES\n4.1 Tuple Insertion\nTo insert a new tuple ğ‘¡ğ‘›ğ‘’ğ‘¤ into the table ğ‘‡, we will update the\nDNN-based data storage Das follows. We will change the range\nof tuple identifiers in D.ğ‘ğ‘¢ğ‘¥ from[1,ğ‘]to[1,ğ‘+1]. Moreover,\nwe will re-train two DNNs in D.ğ·ğ‘ğ‘ , that is,ğ·ğ‘ğ‘ andğ·ğ‘ğ‘âˆ’1,\nover the updated table ğ‘‡âˆª{ğ‘¡ğ‘›ğ‘’ğ‘¤}.\nNote that, the tuple insertions can be also accomplished in a\nbatch manner. Either existing DNNs are re-trained by including\nnew tuples, or new DNNs (with tuple identifiers starting from\n(ğ‘+1)) are trained over new batch of tuples.\n4.2 Tuple Deletion\nIf the tableğ‘‡is append-only, then we do not need to consider the\ntuple deletion; otherwise, we will design a mechanism to handle\nthe deletion of a tuple ğ‘¡ğ‘’ğ‘¥ğ‘. Similar to the tuple insertion, we will\nalso update the auxiliary information, such as the index, in D.ğ‘ğ‘¢ğ‘¥\nby removing the tuple identifier ğ‘¡ğ‘’ğ‘¥ğ‘.ğ‘–ğ‘‘fromD.ğ‘ğ‘¢ğ‘¥.\n4.3 Attribute Updates\nTo update attributes of a tuple ğ‘¡ğ‘–, we first check whether or not\ntupleğ‘¡ğ‘–exists in table ğ‘‡. If the answer is yes, then we need to train\ntheğ·ğ‘ğ‘ /ğ·ğ‘ğ‘âˆ’1again over the updated table ğ‘‡âˆª{ğ‘¡â€²\nğ‘–}âˆ’{ğ‘¡ğ‘–},\nwhereğ‘¡â€²\nğ‘–is the updated tuple of ğ‘¡ğ‘–.\nDiscussions on Dynamic Maintenance of the DNN-based Data\nStorage. From dynamic maintenance of the DNN-based data stor-\nageDabove (e.g., tuple insertions and attribute updates), one im-\nportant issue to improve the performance is to design effective\napproaches to incrementally and efficiently update DNNs, instead\nof computing DNNs from scratch. This can be an interesting future\nresearch direction.\n5 QUERY OPERATORS FOR DNN-BASED\nRELATIONAL TABLES\n5.1 Projection\nWe first consider the projection operator Î ğ´ğ‘—,...,ğ´ğ‘˜(ğ‘‡)as illustrated\nin Figure 7, which projects on attributes ğ´ğ‘—, ..., andğ´ğ‘˜of a relational\ntableğ‘‡.\n1In this set of experiments, we evaluate the max ğ‘at a step size of 100.\n5\n\nIn order to enable the projection operator, we will scan table ğ‘‡\nand return attributes ğ´ğ‘—âˆ¼ğ´ğ‘˜of each tuple ğ‘¡ğ‘–inğ‘‡, by using the\nDNN,ğ·ğ‘ğ‘âˆ¼((ğ‘¡ğ‘–.ğ‘–ğ‘‘),(ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘])). Specifically, through\nauxiliary information D.ğ‘ğ‘¢ğ‘¥, we obtain the range of tuple identi-\nfiersğ‘¡ğ‘–.ğ‘–ğ‘‘(e.g.,[1,ğ‘]) as the input of ğ·ğ‘ğ‘ , and retrieve the DNN\noutputs, that is, the projected tuples (ğ‘¡ğ‘–[ğ´ğ‘—],...,ğ‘¡ğ‘–[ğ´ğ‘˜]).\nselectğ‘¡ğ‘–[ğ´ğ‘—],...,ğ‘¡ğ‘–[ğ´ğ‘˜]\nfrom tableğ‘‡\nFigure 7: Projection on Attributes Î ğ´ğ‘—,...,ğ´ğ‘˜(ğ‘‡).\n5.2 Selection\nIn this subsection, we consider the selection operator ğœğœ‘(ğ‘‡)over\na relational table ğ‘‡, whereğœ‘is a selection condition. Below, we\ndiscuss two basic cases of ğœ‘, that is,ğ‘¡ğ‘–[ğ´ğ‘—]=ğ‘andğ‘ğ‘šğ‘–ğ‘›â‰¤ğ‘¡ğ‘–[ğ´ğ‘—]â‰¤\nğ‘ğ‘šğ‘ğ‘¥, whereğ‘,ğ‘ğ‘šğ‘–ğ‘›, andğ‘ğ‘šğ‘ğ‘¥ are constants.\nAttribute Equality Search. We first discuss how to perform the\nequality search with respect to the ğ‘—-th attribute ğ´ğ‘—in tableğ‘‡\n(represented by the DNN-based data storage D). Figure 8 shows\nthe SQL statement for the equality search, which retrieves those\ntuplesğ‘¡ğ‘–âˆˆğ‘‡such that the ğ‘—-th attribute ğ‘¡ğ‘–[ğ´ğ‘—]equals to a constant\nğ‘.\nselectğ‘¡ğ‘–.ğ‘–ğ‘‘,ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]\nfrom tableğ‘‡\nwhereğ‘¡ğ‘–[ğ´ğ‘—]=ğ‘\nFigure 8: Selection â€“ Attribute Equality Search ğœğ‘¡ğ‘–[ğ´ğ‘—]=ğ‘(ğ‘‡).\nWe will utilize offline pre-computations (e.g., DNN variants) to\nsupport online equality search on attribute ğ´ğ‘—. Specifically, we\nconstruct DNN variants in Das follows. First, we sort all of the\ntuplesğ‘¡ğ‘–âˆˆğ‘‡based on attribute ğ´ğ‘—(in non-descending order),\nobtaining groups of tuples, ğº1,ğº2, ..., andğºğ‘”(each group with the\nsame value of attribute ğ´ğ‘—) as illustrated in Figure 9(a). Each group\nğºğ‘˜(1â‰¤ğ‘˜â‰¤ğ‘”) is associated with aggregates (ğ‘ğ‘˜,ğ‘ğ‘›ğ‘¡ğ‘˜), whereğ‘ğ‘˜is\nthe attribute value ğ´ğ‘—in groupğºğ‘˜andğ‘ğ‘›ğ‘¡ğ‘˜is the size of group ğºğ‘˜\n(i.e.,|ğºğ‘˜|). Then, as illustrated in Figure 9(b), each tuple ğ‘¡ğ‘–in group\nğºğ‘˜is assigned (renamed) with a new unique identifier, ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤,\nwithin[1,ğ‘ğ‘›ğ‘¡ğ‘˜].\nNext, we build two DNNs, denoted as ğ·ğ‘ğ‘ğ‘—andğ·ğ‘ğ‘âˆ’1\nğ‘—, to be\nincluded in the data storage D(as illustrated in Figure 3):\nğ·ğ‘ğ‘ğ‘—âˆ¼((ğ‘ğ‘˜,ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤),(ğ‘¡ğ‘–.ğ‘–ğ‘‘,ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘—âˆ’1],ğ‘¡ğ‘–[ğ´ğ‘—+1],...,\nğ‘¡ğ‘–[ğ´ğ‘‘])),and\nğ·ğ‘ğ‘âˆ’1\nğ‘—âˆ¼((ğ‘¡ğ‘–.ğ‘–ğ‘‘,ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘—âˆ’1],ğ‘¡ğ‘–[ğ´ğ‘—+1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]),\n(ğ‘ğ‘˜,ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤)).\nMoreover, in auxiliary information D.ğ‘ğ‘¢ğ‘¥, we will maintain a\nhash file,ğ»ğ¹ğ‘—, which stores key-value pairs (ğ‘ğ‘˜,ğ‘ğ‘›ğ‘¡ğ‘˜).\nThis way, to perform the equality search in Figure 8, we first\nsearch the hash file ğ»ğ¹ğ‘—with a search key ğ‘, and then obtain the\nmatching entry(ğ‘,ğ‘ğ‘›ğ‘¡ğ‘˜). Next, we feed ğ·ğ‘ğ‘ğ‘—withğ‘ğ‘›ğ‘¡ğ‘˜input\nvectors(ğ‘,ğ‘ğ‘›ğ‘¡)for1â‰¤ğ‘ğ‘›ğ‘¡â‰¤ğ‘ğ‘›ğ‘¡ğ‘˜, and retrieve the corresponding\nğ‘ğ‘›ğ‘¡ğ‘˜tuples (i.e., outputs), respectively, as equality search answers.\n(a)Group By Attribute ğ´ğ‘—\n(b)Tuple Renaming with New IDs ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤\nFigure 9: The Construction of the DNN-based Data Storage for the\nEquality Search.\nExample 1. Figure 9 illustrates an example of building a DNN-\nbased data storageDfor a table with 5 tuples. We first group all the\ntuples by attribute ğ´ğ‘—, and obtain 2 groups ğº1andğº2with the same\nvaluesğ‘1andğ‘2of attribute ğ‘¡ğ‘–[ğ´ğ‘—], respectively (see Figure 9(a)).\nThen, each tuple in the groups is assigned with a new tuple identifier\n(an integer from 1 to the group size). For example, in Figure 9(b), the\nfirst tuple in Group ğº1(with old tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘=2) is renamed\nto a new tuple identifier ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤=1âˆˆ[1,2].\nNext, we construct a hash file ğ»ğ¹ğ‘—inD.ğ‘ğ‘¢ğ‘¥ over 2 records(ğ‘1,2)\nand(ğ‘2,3)(corresponding to 2 groups ğº1andğº2, respectively). Follow-\ning the procedure mentioned above, we also build two DNNs, ğ·ğ‘ğ‘ğ‘—\nandğ·ğ‘ğ‘âˆ’1\nğ‘—, inD.ğ·ğ‘ğ‘ from the table in Figure 9(b).\nFor an equality search with query predicate ğ‘=ğ‘1, we first search\nğ»ğ¹ğ‘—âˆˆD.ğ‘ğ‘¢ğ‘¥ to find the entry(ğ‘1,2), and then retrieve the query\nanswers via ğ·ğ‘ğ‘ğ‘—((ğ‘1,1))andğ·ğ‘ğ‘ğ‘—((ğ‘1,2)). â– \nAttribute Range Search. Next, we consider the range search on\ntheğ‘—-th attribute ğ´ğ‘—in tableğ‘‡(with the DNN representation).\nIn particular, Figure 10 illustrates the SQL query with the range\npredicate, which obtains tuples ğ‘¡ğ‘–âˆˆğ‘‡with their attributes ğ‘¡ğ‘–[ğ´ğ‘—]\nfalling into the interval [ğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥].\nselectğ‘¡ğ‘–.ğ‘–ğ‘‘,ğ‘¡ğ‘–[ğ´1],...,ğ‘¡ğ‘–[ğ´ğ‘‘]\nfrom tableğ‘‡\nwhereğ‘¡ğ‘–[ğ´ğ‘—]>=ğ‘ğ‘šğ‘–ğ‘› andğ‘¡ğ‘–[ğ´ğ‘—]<=ğ‘ğ‘šğ‘ğ‘¥\nFigure 10: Selection â€“ Attribute Range Search\nğœğ‘¡ğ‘–[ğ´ğ‘—]âˆˆ[ğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥](ğ‘‡).\nSimilar to the equality search, we also need the two DNNs, ğ·ğ‘ğ‘ğ‘—\nandğ·ğ‘ğ‘âˆ’1\nğ‘—. To support the range search (rather than the equality\nsearch), inD.ğ‘ğ‘¢ğ‘¥, we will instead maintain a B+-tree,ğµğ‘‡ğ‘—, over\nattributeğ´ğ‘—, with records(ğ‘ğ‘˜,ğ‘ğ‘›ğ‘¡ğ‘˜)for groupsğºğ‘˜.\nFor any range query with predicate [ğ‘ğ‘šğ‘–ğ‘›,ğ‘ğ‘šğ‘ğ‘¥], we first search\nthe B+-treeğµğ‘‡ğ‘—for records(ğ‘ğ‘˜,ğ‘ğ‘›ğ‘¡ğ‘˜)with keysğ‘ğ‘˜betweenğ‘ğ‘šğ‘–ğ‘›\n6\n\nandğ‘ğ‘šğ‘ğ‘¥. Then, for each retrieved record (ğ‘ğ‘˜,ğ‘ğ‘›ğ‘¡ğ‘˜), we compute\nrange query answers, ğ·ğ‘ğ‘ğ‘—(ğ‘ğ‘˜,1),ğ·ğ‘ğ‘ğ‘—(ğ‘ğ‘˜,2), ..., andğ·ğ‘ğ‘ğ‘—(ğ‘ğ‘˜,\nğ‘ğ‘›ğ‘¡ğ‘˜).\nDiscussions on Multidimensional Range Queries. In Figure 10, the\nrange predicate is on one single attribute ğ´ğ‘—. In the case that range\npredicates are specified on multiple attributes (dimensions), one\npossible way is to estimate the selectivity of the range predicate\non each dimension, perform the range search over one B+-treeğµğ‘‡ğ‘—\nwith the highest selectivity, and use ğ·ğ‘ğ‘ğ‘—to retrieve candidate\ntuples and refine them by checking range predicates over other\ndimensions.\nAlternatively, we can also maintain a multidimensional index\n(e.g., a grid or Râˆ—-tree) over all dimensions ğ´1âˆ¼ğ´ğ‘‘in auxiliary\ninformationD.ğ‘ğ‘¢ğ‘¥. Then, cells in the grid or MBRs in leaf nodes\nof Râˆ—-tree can be considered as groups, each of which is associ-\nated with a unique group ID ğºğ‘˜(e.g., cell or MBR ID) and the\nnumber,ğ‘ğ‘›ğ‘¡ğ‘˜, of tuples in group ğºğ‘˜. Each tuple ğ‘¡ğ‘–in groupğºğ‘˜\ncan be renamed to ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤, where 1â‰¤ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤â‰¤ğ‘ğ‘›ğ‘¡ğ‘˜. Then, the\ngroup-tuple ID pairs (ğºğ‘˜,ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤)can be used for constructing\nthe DNNs,ğ·ğ‘ğ‘ğ‘—andğ·ğ‘ğ‘âˆ’1\nğ‘—, inD.ğ·ğ‘ğ‘ . This way, the resulting\nDNN-based data storage Dcan be used for performing multidimen-\nsional range queries (i.e., finding all groups satisfying the range\npredicates via the multidimensional index, and retrieving candidate\nanswersğ·ğ‘ğ‘ğ‘—(ğºğ‘˜,ğ‘¡ğ‘–.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤)for refinement).\n5.3 Cartesian Product\nFigure 11 shows the SQL statement of the Cartesian product, ğ‘…Ã—ğ‘†,\nover two tables ğ‘…andğ‘†, which returns all possible tuple pairs (ğ‘Ÿ,ğ‘ )\nfrom tables ğ‘…andğ‘†, respectively.\nThe idea of solving this operator is to sequentially scan both\nDNN-based tables ğ‘…andğ‘†, and enumerate all combinations of tuple\npairs. That is, through Dğ‘….ğ‘ğ‘¢ğ‘¥ andDğ‘†.ğ‘ğ‘¢ğ‘¥, we obtain ranges,\n[1,ğ‘ğ‘…]and[1,ğ‘ğ‘†], of tuple identifiers, ğ‘Ÿ.ğ‘–ğ‘‘andğ‘ .ğ‘–ğ‘‘, respectively.\nThen, for each pair of tuple identifiers ğ‘Ÿ.ğ‘–ğ‘‘andğ‘ .ğ‘–ğ‘‘within ranges,\nwe use DNNs,Dğ‘….ğ·ğ‘ğ‘(ğ‘Ÿ.ğ‘–ğ‘‘)andDğ‘†.ğ·ğ‘ğ‘(ğ‘ .ğ‘–ğ‘‘), to compute\ntuplesğ‘Ÿandğ‘ (i.e., outputs of DNNs), respectively, and return (ğ‘Ÿ,ğ‘ )\nas the answer.\nselectğ‘Ÿ,ğ‘ \nfrom tablesğ‘…,ğ‘†\nFigure 11: Cartesian Product ğ‘…Ã—ğ‘†.\n5.4 Join\nWe next consider the join operator, ğ‘…Zğ‘Ÿâˆˆğ‘…âˆ§ğ‘ âˆˆğ‘†âˆ§ğ‘Ÿ[ğ´ğ‘—]=ğ‘ [ğ´ğ‘™]ğ‘†, over\ntwo tablesğ‘…andğ‘†, with two DNN-based data storages Dğ‘…andDğ‘†.\nFigure 12 illustrates the join SQL statement that returns the joining\nresults(ğ‘Ÿ,ğ‘ )from two tables ğ‘…andğ‘†, respectively, where the join\ncondition is given by ğ‘Ÿ[ğ´ğ‘—]=ğ‘ [ğ´ğ‘™].\nTo enable the join operator, our basic idea is to first perform an\nindex join or merge overDğ‘….ğ‘ğ‘¢ğ‘¥ andDğ‘†.ğ‘ğ‘¢ğ‘¥, such as the hash join\nğ»ğ¹ğ‘—Zğ»ğ¹ğ‘™, or B+-tree joinğµğ‘‡ğ‘—Zğµğ‘‡ğ‘™, obtain pairs(ğ‘Ÿ[ğ´ğ‘—],ğ‘ğ‘›ğ‘¡ğ‘Ÿ)\nand(ğ‘ [ğ´ğ‘™],ğ‘ğ‘›ğ‘¡ğ‘ ), and then retrieve pairwise joining results (ğ‘Ÿ,ğ‘ )via\nDNNs (i.e.,Dğ‘….ğ·ğ‘ğ‘ğ‘—(ğ‘Ÿ[ğ´ğ‘—],ğ‘Ÿ.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤)andDğ‘†.ğ·ğ‘ğ‘ğ‘™(ğ‘ [ğ´ğ‘™],ğ‘ .ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤)),\nwhere 1â‰¤ğ‘Ÿ.ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤â‰¤ğ‘ğ‘›ğ‘¡ğ‘Ÿand 1â‰¤ğ‘ .ğ‘–ğ‘‘ğ‘›ğ‘’ğ‘¤â‰¤ğ‘ğ‘›ğ‘¡ğ‘ .selectğ‘Ÿ,ğ‘ \nfrom tablesğ‘…,ğ‘†\nwhereğ‘Ÿ[ğ´ğ‘—]=ğ‘ [ğ´ğ‘™]\nFigure 12: Joinğ‘…Zğ‘Ÿâˆˆğ‘…âˆ§ğ‘ âˆˆğ‘†âˆ§ğ‘Ÿ[ğ´ğ‘—]=ğ‘ [ğ´ğ‘™]ğ‘†.\n5.5 Set Union, Set Intersection, and Set\nDifference\nAssuming that tables ğ‘…andğ‘†have the same (compatible) schema,\nwe next discuss the set operators between ğ‘…andğ‘†such as the union,\nintersection, or set difference, as illustrated in Figure 13.\nFor the set operators mentioned above, one fundamental task\nis to find common tuples between tables ğ‘…andğ‘†. In particular, we\nneed to scan one table, say ğ‘…, with a smaller cardinality, by accessing\nthe DNN,Dğ‘….ğ·ğ‘ğ‘(ğ‘Ÿ.ğ‘–ğ‘‘), and then check if tuple Dğ‘….ğ·ğ‘ğ‘(ğ‘Ÿ.ğ‘–ğ‘‘)\nappears in the other table ğ‘†(i.e., whether or not ğ‘Ÿ.ğ‘–ğ‘‘is inDğ‘†.ğ‘ğ‘¢ğ‘¥).\nThis way, we can obtain common ID pairs (ğ‘Ÿ.ğ‘–ğ‘‘,ğ‘ .ğ‘–ğ‘‘)from two\nstorages.\nselectğ‘Ÿ\nfrom tableğ‘…\nUNION //INTERSECT orMINUS\nselectğ‘ \nfrom tableğ‘†\nFigure 13: Set Unionğ‘…âˆªğ‘†, Set Intersection ğ‘…âˆ©ğ‘†, and Set Difference\nğ‘…âˆ’ğ‘†.\nSet Union. For union results ğ‘…âˆªğ‘†(with distinct tuples), we will\nclone two separate DNN storages Dğ‘…andDğ‘†, by excluding com-\nmon IDs from auxiliary information of one storage (i.e., Dğ‘…or\nDğ‘†).\nSet Intersection. For intersection results ğ‘…âˆ©ğ‘†, we clone one of\nthe two DNN storages, say Dğ‘…, and update auxiliary information\nwith common tuple identifiers ğ‘Ÿ.ğ‘–ğ‘‘(i.e., intersecting tuples).\nSet Difference. For the results of the set difference ğ‘…âˆ’ğ‘†, we\nclone the DNN-based data storage Dğ‘…, and update its auxiliary\ninformation by excluding those common tuple identifiers ğ‘Ÿ.ğ‘–ğ‘‘.\n6 DISCUSSIONS ON SECURE AND\nDISTRIBUTED DNN-BASED DATA\nSTORAGE\nUp to now, we always assume that servers (or networks in the\ndistributed scenario) are all trusted and, thus, input-and-output\npairs of DNNs are (integer) plaintexts, for example, for ğ·ğ‘ğ‘âˆ¼\n(ğ‘–ğ‘›,ğ‘œğ‘¢ğ‘¡),ğ‘–ğ‘›andğ‘œğ‘¢ğ‘¡are plaintexts without any encryption. In this\nsection, we will discuss how to handle other security settings for\nour DNN-based data storage in a distributed environment.\nSpecifically, we will consider 3 cases with different security mod-\nels (i.e., honest/semi-honest networks or servers):\nâ€¢Semi-Honest Networks, Semi-Honest Servers (SNS2):\nIn this SNS2model, honest-but-curious adversaries may steal\ndata from both networks and servers. To deal with this case,\nwe assume that the data owner (or a trusted third-party)\nhas a (private) symmetric key ğ¾, and our DNN-based data\n7\n\nstorage will train DNNs based on the encrypted inputs and\noutputs, that is, ğ·ğ‘ğ‘âˆ¼(ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ‘–ğ‘›),ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ‘œğ‘¢ğ‘¡)).\nTherefore, both encrypted inputs and outputs (cipher-\ntexts),ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ‘–ğ‘›)andğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ‘œğ‘¢ğ‘¡), will be safely trans-\nmitted via semi-honest networks, and semi-honest servers\ncannot obtain the plaintexts, ğ‘–ğ‘›andğ‘œğ‘¢ğ‘¡, due to the encryp-\ntion. After the query issuer obtains the encrypted outputs,\nğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ‘œğ‘¢ğ‘¡), via DNNs from servers, one can compute the\ndecrypted query answer ğ‘œğ‘¢ğ‘¡=ğ·ğ‘’ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾(ğ‘œğ‘¢ğ‘¡)).\nâ€¢Semi-Honest Networks, Honest Servers (SNHS): In this\nmodel, networks are not secure, but servers are trusted. As-\nsume that servers have a public key ğ¾+\nğ‘†and a private key\nğ¾âˆ’\nğ‘†, and the query issuer has a public key ğ¾+\nğ‘„and a pri-\nvate keyğ¾âˆ’\nğ‘„. Our DNN-based data storage will still train\nDNNs based on inputs and outputs in plaintext, that is,\nğ·ğ‘ğ‘âˆ¼(ğ‘–ğ‘›,ğ‘œğ‘¢ğ‘¡). The query issuer will send the encrypted\ninputsğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾+\nğ‘†(ğ‘–ğ‘›)(ciphertexts with key ğ¾+\nğ‘†) to servers\nvia semi-honest networks, and honest servers will use their\nprivate key ğ¾âˆ’\nğ‘†to obtain actual inputs (plaintexts), that is,\nğ‘–ğ‘›=ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾âˆ’\nğ‘†(ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾+\nğ‘†(ğ‘–ğ‘›)).\nAfter servers compute outputs ğ‘œğ‘¢ğ‘¡via DNNs, they will\nsendğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾+\nğ‘„(ğ‘œğ‘¢ğ‘¡)(with public key ğ¾+\nğ‘„) back to the query\nissuer, and the query issuer will use oneâ€™s private key ğ¾âˆ’\nğ‘„\nto obtain the query answer ğ‘œğ‘¢ğ‘¡=ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾âˆ’\nğ‘„(ğ¸ğ‘›ğ‘ğ‘Ÿğ‘¦ğ‘ğ‘¡ğ¾+\nğ‘„\n(ğ‘œğ‘¢ğ‘¡)).\nBy using asymmetric cryptosystems, we can transmit the\nencrypted inputs and outputs through semi-honest networks,\nwhereas honest servers perform the DNN computation from\ninputs to outputs in plaintext.\nâ€¢Honest Networks, Semi-Honest Servers (HNS2):In this\nmodel, we will use the same strategy as that in the SNS2\ncase for the DNN-based data storage/computing. Details are\nomitted due to similar discussions.\n7 EXPERIMENTAL EVALUATION FOR\nDNN-AS-A-DATABASE\n7.1 Experimental Setup and Metrics\nTo validate our proposed â€œDNN-as-a-Databaseâ€ paradigm, we con-\nduct preliminary experiments over a prototype solution built with\nPyTorch 1.13.0 using well-established TPC-H benchmark data sets.\nAll the training and validation are conducted on a server equipped\nwith two CPUs of Intel Xeon Silver 4210, 192 GB Memory, and\ntwo GPUs of NVIDIA Quadro RTX 6000, running Ubuntu 20.04,\nCUDA 11.7. Throughout the experiments, we use GPUs for the\nmodel training and CPUs for primitive query operator evaluation.\nA pooling strategy is adopted for multi-threading, with each thread\ntying a physical core, 40 threads in total.\nData Sets. We use dbgen of the TPC-H benchmark [ 46] to generate\nrelational tables, with scale factors of 1 and 10, leading to benchmark\ntables of total sizes 1 GB and 10 GB, denoted as TPC-H-F1 andTPC-\nH-F10 , respectively.\nDefault DNN Blocks. As confirmed by Figure 16, DNNs can serve\nas data storage blocks. In our experiments, we adopt a default DNN\nconfiguration of 4 hidden layers, 64 neurons per layer, an input\nvector of size 4, and an output vector of size no larger than 1,000. Our\n101102103\nLineitem\nOrders\nPartsupp\nCustomer\nPartSpace Cost (MB) \nTablesraw table\nDNN storage(a)TPC-H-F1\n10-1100101\nLineitem\nOrders\nPartsupp\nCustomer\nPartSpace Cost (GB) \nTablesraw table\nDNN storage (b)TPC-H-F10\nFigure 14: The Space Costs of Relational Tables vs. DNN-based Data\nStorage.\nempirical study shows that this setting can achieve a good trade-off\namong the capacity, evaluation efficiency, and space complexity.\nMore sophisticated hyperparameter tuning for models is beyond\nthe scope of this paper and will be left as our future work.\nMetrics. In subsequent experiments, we aim to address the follow-\ning questions:\nâ€¢What are the time/space costs to load relational tables of\nvaried sizes into the DNN-based data storage?\nâ€¢How efficiently can the DNN-based data storage serve prim-\nitive relational operators?\nWe report the space cost of our DNN-based data storage, the\ntime cost for offline transforming from relational tables to the DNN-\nbased data storage, and the time cost of SQL query operators (an\naverage over 5 independent runs).\n7.2 Time/Space Efficiency Evaluation for the\nDNN-based Data Storage\nSpace Costs of Relational Tables and DNN-based Data Stor-\nage. Instead of explicitly storing data, DNN-based data storage\nembeds data into DNN models, i.e., a neural network structure and\ncoefficient weight vectors. It is expected that DNN-based storage\nwould lead to higher space costs, yet our empirical study shows\nthat the space overhead is comparable to raw data size. For two\nbenchmark data sets, TPC-H-F1 andTPC-H-F10 , the DNN-based\ndata storage is 2.7x and 2.04x larger than raw relational tables.\nFigure 14 shows a breakdown of the space cost on different\nrelational tables (note: supplier, nation, and region tables are not\nreported here, due to small sizes). For the largest table, Lineitem,\nits DNN-based data storage does not introduce much overhead\nforTPC-H-F1 (as shown in Figure 14(a)); and there is even a size\nreduction observed for TPC-H-F10 (as shown in Figure 14(b)). The\nreason is that many columns in the â€œLineitemâ€ table have only a few\ndistinct values (i.e., with many duplicate attribute values). As the\nDNN-based solution would first group tuples of the same attribute\nvalue, it can significantly reduce value duplicates. In contrast, table\nâ€œOrdersâ€ has the least number of duplicate attribute values, which\nleads to as high as 8x space cost for the DNN-based data storage.\nWe observe the similar trend on both benchmarks. Therefore, the\nspace overhead of DNN-based data storage highly depends on the\ndegree of attribute value redundancy in the relational table.\n8\n\n 0 50 100 150 200 250 300\nLineitem\nOrders\nPartsupp\nCustomer\nPartTime (sec)\nTablesPrepare\nTraining\nOther(a)Breakdown of the Table-to-DNN Trans-\nformation Time\n100101102103104\n[0,100]\n(100,200]\n(200,400]\n(400,800]Count of DNNs\nNo. of Epochs(b)Training Epoch Histogram\nFigure 15: The Time Cost of Offline Transforming From TPC-H-F1\nto its DNN Format.\nThe Time Cost of Transforming From Tables to DNN-based\nData Storage. The offline transformation from raw relational ta-\nbles to their DNN format takes âˆ¼775ğ‘ ğ‘’ğ‘ğ‘  forTPC-H-F1 andâˆ¼5,500\nğ‘ ğ‘’ğ‘ğ‘  forTPC-H-F10 . In Figure 15(a), we show a breakdown of time\ncosts to offline transform from raw TPC-H-F1 tables to their DNN\nformat, including the time costs of the data preparation, training,\nand others (e.g., I/O, kernel, etc.). The data preparation mainly in-\nvolves data partitioning (column-wise) and sorting, such that tuples\nwith the same attribute values will be grouped together for sup-\nporting effective range search. We further examine the time cost of\ntraining default DNN blocks. The training time is a dominating fac-\ntor in the total transformation time for most tables, which suggests\nthe speedup opportunity given that more GPU power is available.\nAs shown in Figure 15(b), most DNNs (i.e., â‰¥99.92% DNNs) can\nconverge within 200 epochs (with 100% data accuracy). A similar\ntrend is observed for transforming TPC-H-F10 .\n7.3 Primitive SQL Operators Over DNN-based\nData Storage\nNext, we examine the efficiency of primitive SQL operators over\nTPC-H-F1 benchmark tables, including selection ,projection ,\nrange qery ,Cartesian product , and join. We compare the\nquery performance of our DNN-based data storage with that of a ma-\nture relational database product, PostgreSQL. Note that, we enable\nparallel query evaluation of PostgreSQL by setting ğ‘šğ‘ğ‘¥_ğ‘ğ‘ğ‘Ÿğ‘ğ‘™ğ‘™ğ‘’ğ‘™\n_ğ‘¤ğ‘œğ‘Ÿğ‘˜ğ‘’ğ‘Ÿğ‘  to 32,ğ‘’ğ‘“ğ‘“ğ‘’ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ _ğ‘ğ‘ğ‘â„ğ‘’ _ğ‘ ğ‘–ğ‘§ğ‘’to 32GB,ğ‘ â„ğ‘ğ‘Ÿğ‘’ğ‘‘ _ğ‘ğ‘¢ğ‘“ğ‘“ğ‘’ğ‘Ÿğ‘  to\n4GB, andğ‘¤ğ‘œğ‘Ÿğ‘˜ _ğ‘šğ‘’ğ‘š to 256MB.\nSelection . We evaluate the time cost to select a tuple with a\nparticular primary key over TPC-H-F1 data set. As shown in Fig-\nure 16(a), the time cost of retrieving a tuple using PostgreSQL is\ncomparable to that using our DNN-based data storage (i.e., recov-\nering attributes of the tuple from DNNs). From Figure 16(a), the\nselection performance varies for different tables. For example, the\nselection over the Lineitem table takes the longest time. This is be-\ncause this tableâ€™s column number is almost twice as that of the other\ntwo, and the DNN-based selection needs to access 16 columns, i.e.,\n16 DNNs, to compute the entire tuple. Nevertheless, the selection\noperator over our DNN-based data storage incurs low time cost\n(i.e., less than 0.45 ğ‘šğ‘ ), and our DNN-based data storage (if adoptedover encrypted inputs/outputs) can achieve a higher security level\ncompared with PostgreSQL.\nProjection . We conduct a Projection operator on attribute\nâ€œpartkeyâ€, â€œsupplykeyâ€, and â€œextended priceâ€, respectively, over the\nLineitem table. As shown in Figure 16(b), the time costs of the\nprojection on each of these attributes via PostgreSQL stay almost\nthe same, whereas that of our DNN-based data storage exhibits\nvaried performance. For our DNN solution, we return not only the\nprojected attribute values, but also tuple identifiers. Therefore, we\nuse the index inD.ğ‘ğ‘¢ğ‘¥ to access distinct attribute values (and their\ntuple counts), and apply DNNs, ğ·ğ‘ğ‘ğ‘—(as discussed in Section 5.2),\nto obtain tuple identifiers. In Figure 16(b), the projection on the\nâ€œextended priceâ€ attribute has the highest time cost, since it has the\nmost unique attribute values (i.e., 933,900). From the experimental\nresults, we can see that the number of DNN accesses can dominate\nthe projection efficiency in our DNN-based data storage.\nRange Query . Our DNN-based solution evaluates the Range\nQuery , by first looking up the index of a given attribute in D.ğ‘ğ‘¢ğ‘¥\nto identify the group of tuple identifiers (computed via DNNs).\nThen, we obtain the entire tuples by feeding tuple identifiers into\nDNNs for different attributes. Figure 16(c) shows the performance\nof our design for range queries over the â€œtotal priceâ€ attribute in the\nOrder table, by varying the selectivity from 0.01% to 0.05%. When\nthe selectivity value increases, the time costs of both PostgreSQL\nand DNN approaches increase smoothly.\nSince PostgreSQL built an index over the attribute â€œtotal priceâ€,\nit can utilize the index to find the first tuple satisfying the range\npredicate and perform the sequential scan for the remaining range\nquery answers. In contrast, our DNN-based data storage has to\ncompute every tuple satisfying the range predicate through DNNs\n(i.e., we cannot take advantage of accessing clustered tuples like\nPostgreSQL). Therefore, our DNN-based data storage requires a\nhigher time cost than PostgreSQL for range queries with high selec-\ntivity values. Nonetheless, the time cost of the range query for our\nDNN-based solution remains low (i.e., less than 10 ğ‘šğ‘ ). Moreover, it\nis worth noting that when the selectivity value is small (e.g., 0.01%),\nthe range query of our DNN-based data storage outperforms that\nof PostgreSQL.\nWe believe that our DNN-based solution (over encrypted in-\nputs/outputs) can provide higher security level, and has the poten-\ntial to further improve the performance in the multi-core environ-\nment that allows computing tuples in parallel.\nJoin & Cartesian Product . Figure 16(d) evaluates the perfor-\nmance of Join andCartesian Product operators over two tables,\nSupplier and Nation, of sizes 1.4 ğ‘€ğµand 2.2ğ¾ğµ, respectively. For\ntheJoin operator, we consider the natural join over Supplier and Na-\ntion tables, with the join predicates on attribute â€œnationkeyâ€. Each\nsupplier tuple is joined with exactly one nation tuple. Our DNN-\nbased data storage takes 3.12 ğ‘ ğ‘’ğ‘ğ‘  to complete the join, whereas\nPostgreSQL takes 1.7 ğ‘ ğ‘’ğ‘ğ‘ . We observe that the major time cost\nof our DNN solution is in the computation of attribute values for\nreturning join outputs.\nThe Cartesian product is expected to be more time-consuming\nthan Join. The extra cost of Cartesian Product mainly comes\nfrom returning a 25x larger output compared to Join. The time cost\nof our DNN-based data storage is 4.4 ğ‘ ğ‘’ğ‘ğ‘  and that of PostgreSQL\nis 2.7ğ‘ ğ‘’ğ‘ğ‘ .\n9\n\n 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45\nLineitem\nOrders\nCustomerTime (ms) \nTablesDNN\nPostgreSQL(a)Selection\n100101102\npartkey\nsupplykey\next. priceTime (s) \nColumns in LineitemDNN\nPostgreSQL (b)Projection\n 1 2 3 4 5 6 7 8 9 10 11\n0.01 0.02 0.03 0.04 0.05Time (ms) \nSelectivity (%)DNN\nPostgreSQL (c)Range Query\n100101\nJoin Cartesian ProductTime (s) \nTasksDNN\nPostgreSQL (d)Join&Cartesian Product\nFigure 16: Evaluation of Primitive SQL Operators over TPC-H-F1.\nSummary and Discussions. Overall, the experiments above show\nthe viability of supporting primitive SQL operators over DNN-\nbased data storage. Although the current implementation is rather\nnaive, as suggested by the performance gap when compared to\nmature relational database products, our DNN-based data storage\nin fact trades the computation time for a higher security level (as\nthe majority of the time cost is from computing attribute outputs\nfrom DNNs). Also, our DNN-based data storage over encrypted\ninputs/outputs can enable secure query processing without data\ndecryption (which cannot be achieved by many prior works).\nFrom our experimental results, we also observe many research\nopportunities that can bring â€œDNN-as-a-Databaseâ€ to real practice.\nFirst, a quantitative study of how different sizes of DNN storage\nblocks would affect the overall performance would help derive an\nadaptive solution for encoding data into DNNs to strike a balance\namong the DNN transformation cost, space overhead, and query\nperformance. Second, although DNN-based query evaluation is CPU\nintensive, it can significantly reduce the I/O cost. Thus, our design\ncan greatly benefit from a multi-core or CPU/GPU hybrid com-\nputing environment. Moreover, instead of simply taking DNNs as\nstorage, we can further develop DNN-based caching, query decom-\nposition/rewrite, and scheduling to improve the overall efficiency\nof data management via DNNs.\n8 RELATED WORK\nNeural Networks and Recent Advancements. Originated from\nArtificial Neural Networks (ANNs), deep learning [42] is one of the\nmost performant machine learning tools, as examplified by Recur-\nrent Neural Networks (RNN) and Convolutional Neural Networks\n(CNN) [ 14,18]. The recent advancements of Graphics Processing\nUnits (GPUs) and distributed computing techniques have made it\nfeasible to train a model with billions of variables using large-scale\ntraining data sets [ 3,33,52]. With extensive learning-based solu-\ntions developed for solving real-world applications, researchers are\nnow paying more attention to the cross-modality structure [ 11],\nmodel explainability [ 51], model robustness [ 48], and security of\nneural networks [39].\nPrevious works on neural networks usually incur the predic-\ntion/classification inaccuracy, since the trained neural networks\nare used for predicting/classifying unknown testing data. In our\nlearning-based data storage, however, we treat tabular data as both\ntraining and testing data sets. Thus, as long as we can achieve highaccuracy of neural networks during the training process and appro-\npriately handle inaccurate cases (e.g., using more neural networks),\nwe can guarantee accurate (e.g., 100%) data retrieval from neural\nnetworks.\nLearning-based Data Management. Recently, there is an emerg-\ning trend of applying learning-based methods to traditional data-\nbase management systems, ranging from architecture design and\nquery optimization to tuning overall performance. Below, we briefly\ncategorize the most related efforts in this direction.\nLearning-based Database Design: Studies [ 7,13,35] show that\nlearning-based indexes can not only reduce the index size but also\nimprove query performance. For example, Kraska et al. [ 17] propose\nthat indexes are models, where the B+-tree index can be seen as a\nmodel that maps each query key to its page. Techniques like data\nstructure alchemy [ 13] are proposed to automatically recommend\nand design data structures that best suit the computing workload\nand hardware setting. The essential idea is to first identify the bot-\ntleneck of the total cost and then tweak different knobs in one\ndirection until reaching a pre-defined cost metric or finding the\nminimal total cost, which is similar to the gradient descent proce-\ndure.\nLearning-based Database Configuration: Machine learning-based\napproach has been widely applied to a range of database config-\nurations, including knob tuning, index advisor, materialized view\nadvisor, and database partition. For example, researchers utilize\nlearning-based techniques [ 19,23,55] to automate knob tuning,\nwhich not only achieve higher tuning performance but less tuning\ntime. CDBTune [ 55] models database tuning as a sequential decision\nproblem and relies on reinforcement learning to improve tuning\nperformance. QTune [ 23] further characterizes query features using\ndeep learning and can achieve finer granularity tuning, e.g., query-\nlevel tuning, session-level tuning, and system-level tuning. Indexes\nare vital to speed up query execution, and there are some learning-\nbased works that automatically recommend indexes [ 15,29,41].\nView materialization usually provides an effective space-for-time\ntrade-off in performance improvement. Yet view selection is an\nNP-hard problem. Learning based solutions [ 15,25,54] aim to auto-\nmatically identify the appropriate views for a given query workload.\nFor example, Han et al. [ 10] propose a deep reinforcement learning\nmethod to estimate the benefit of different materialized view candi-\ndates and queries for dynamic workloads. Another important aspect\nof configuration is data partitioning. Instead of heuristically select-\ning columns as partition keys (single column mostly), which cannot\n10\n\nbalance between load balance and access efficiency, recent work\nby Hilprecht et al. [ 12] utilizes a reinforcement learning model to\nexplore different partition keys and implements a fully-connected\nneural network to estimate partition benefits.\nLearning-based Database Optimization: This line of research aims\nto utilize machine learning techniques to address the hard prob-\nlems in database optimization, including cost estimation, join order\nselection, and end-to-end optimization. Specifically, deep learning\nbased techniques (e.g., CNN [ 8], RNN [ 44], Mixture Model [ 36]) are\nproposed to estimate the cost and cardinality to capture the corre-\nlations between different columns/tables. For example, an LSTM\nbased work [ 44] learns a representation for each sub-plan with\nphysical operators and predicates and outputs the estimated cardi-\nnality and cost simultaneously by using an estimation layer. Given\nthat an SQL query may have an exponential number of possible\nexecution plans, traditional heuristic methods cannot find optimal\nplans for dozens of tables, and it is costly to use dynamic program-\nming to explore the huge plan space. Thus, prior works propose\ndeep reinforcement learning based methods [ 31,32,53] that auto-\nmatically select good plans. For example, SkinnerDB [ 47] uses a\nMonte-Carlo tree search based method that can optimize the join\norder on the fly by trying out different join orders in each time\nslice. Learning-based end-to-end optimizers [ 30,32,50] use deep\nneural networks to optimize SQL queries. For example, Marcus et\nal. [32] propose NEO, which uses PostgreSQLâ€™s plan to pre-train\nthe neural network and latency as feedback to train the neural net-\nwork. In contrast to the rule-based traditional workload prediction\nmethods [ 6] in transaction management, Ma et al. [ 28] propose a\nlearning-based system that predicts the future trend of different\nworkloads. Besides, recent research [ 43] shows that the learning\nbased transaction scheduling method can balance concurrency and\nconflict rates using supervised algorithms.\nAutonomous Database Systems: There have been research efforts\non autonomous database systems from academia [ 16,22,37] and\nindustry [ 5,6,21,24]. Peloton [ 37] predicts the workload arrival\nrate with clustering and RNN and deploys optimization actions\nlike knob tuning and index/materialized view selection. SageDB [ 2]\nprovides a vision to specialize the database implementation by\nlearning data distributions (CDF models) and designing database\ncomponents based on the knowledge, e.g., learned index and query\nscheduling. Oracleâ€™s autonomous data warehouse [ 5] optimizes\nOLAP services with tuning choices like predicate indexing and\nmaterialized views. Alibabaâ€™s SDDP [ 21] detects database status\nfrom historical statistics and provides automatic optimization like\nhot/cold separation and buffer tuning. OpenGauss [24] represents\nthe most recent advancements in autonomous database system that\nintegrates a variety of learning-based optimizations to many core\ncomponents of database systems.\nAlthough extensive research efforts have been devoted to incor-\nporating learning-based methods to various aspects of database\nsystems, most of them are based on a database system that physi-\ncally stores tables, graphs, or key-value pairs. The essence of our\nproposed solution is â€œDNN-as-a-databaseâ€, where all data manage-\nment are done via the LMU interface, instead of traditional storage\nmedia.9 DISCUSSIONS ON DNN-BASED GRAPH\nSTORAGE AND ANALYTICS\nIn this section, we discuss the potential of generalizing our proposed\nlearning-based data storage to other data types such as DNN-based\ngraphs.\nGraph Data Model. We first give the definition of the graph data\nmodel below.\nDefinition 2. (Graph,ğº)A graph,ğº, is represented by a triple\n(ğ‘‰(ğº),ğ¸(ğº),ğœ™(ğº)), whereğ‘‰(ğº)is a set of vertices ğ‘£ğ‘–, each associated\nwith a label ğ‘™(ğ‘£ğ‘–),ğ¸(ğº)is a set of edges, ğ‘’ğ‘–ğ‘—, between vertices ğ‘£ğ‘–and\nğ‘£ğ‘—, andğœ™(ğº)is a mapping function ğ‘‰(ğº)Ã—ğ‘‰(ğº)â†’ğ¸(ğº).\nThe graph model has been widely used in many real applica-\ntions such as knowledge (RDF) graphs in the Semantic Web, social\nnetworks, road networks, and so on.\nDNN-based Graph Model. Similar to DNN-based relational tables,\nfor a graphğº, we will design LMU, G, overğº, which includes two\ncomponents,G.ğ·ğ‘ğ‘ andG.ğ‘ğ‘¢ğ‘¥. ForG.ğ·ğ‘ğ‘ , we consider vertices\nğ‘£ğ‘–âˆˆğ‘‰(ğº)and their 1-hop neighbors (i.e., vertices adjacent to ğ‘£ğ‘–) in\na vectorğ‘ğ‘(ğ‘£ğ‘–)and train DNNs, ğ·ğ‘ğ‘ğºâˆ¼((ğ‘™(ğ‘£ğ‘–)),(ğ‘£ğ‘–,ğ‘ğ‘(ğ‘£ğ‘–)))\nandğ·ğ‘ğ‘âˆ’1\nğºâˆ¼((ğ‘£ğ‘–,ğ‘ğ‘(ğ‘£ğ‘–)),(ğ‘£ğ‘–.ğ‘–ğ‘‘)). ForG.ğ‘ğ‘¢ğ‘¥, we store auxil-\niary information such as indexes built over vertex labels ğ‘™(ğ‘£ğ‘–).\nNote that, in some real applications such as the Semantic Web,\nRDF graphs can be equivalently represented by RDF triples, which\ncan be considered as tuples and alternatively stored via DNN-based\nrelational tables.\nQueries Over DNN-based Graphs. We consider two classic graph\nqueries such as graph isomorphism checking and subgraph match-\ning over DNN-based graphs, ğ·ğ‘ğ‘ğº, in LMUs. Specifically, we\nformally define these two DNN-based graph queries as follows.\nDefinition 3. (Graph Isomorphism Checking Over DNN-\nBased Graphs, GIC-DNN ğº)Givenğ‘DNN-based graphs ğ‘”in a\ngraph database and a query graph ğ‘, graph isomorphism checking\nover DNN-based graphs (GIC-DNN ğº) retrieves graphs ğ‘”that are iso-\nmorphic toğ‘(denoted asğ‘”â‰¡ğ‘).\nDefinition 4. (Subgraph Matching Over DNN-Based Graphs,\nSM-DNNğº)Given a DNN-based graph ğºand a query graph ğ‘, a sub-\ngraph matching query over DNN-based graphs (SM-DNN ğº) retrieves\nsubgraphsğ‘”âŠ†ğºsuch thatğ‘”is isomorphic to ğ‘(i.e.,ğ‘”â‰¡ğ‘).\nGIC-DNNğº:In order to enable efficient GIC-DNN ğºquery pro-\ncessing, we use a filter-and-refinement framework that first re-\ntrieves graph candidates through a filtering step and then per-\nforms the actual isomorphism checking in the refinement step.\nFor the filtering step, we consider labels of each vertex ğ‘ğ‘–and its\n1-hop neighbors ğ‘ğ‘(ğ‘ğ‘–)in the query graph ğ‘as input and use\nğ·ğ‘ğ‘âˆ’1\nğºâˆ¼((ğ‘ğ‘–,ğ‘ğ‘(ğ‘ğ‘–)),(ğ‘£ğ‘–.ğ‘–ğ‘‘))inG.ğ·ğ‘ğ‘ to retrieve candidate\nvertex IDsğ‘£ğ‘–.ğ‘–ğ‘‘in graphsğ‘”. Then, we can combine/join candidate\nverticesğ‘£ğ‘–of those vertices ğ‘ğ‘–inğ‘and obtain candidate subgraphs\nğ‘”. Finally, we can refine these candidate subgraphs via actual graph\nisomorphism checking.\nSM-DNNğº:In the GIC-DNN ğºproblem, vertices and their 1-hop\nneighbors in data graph ğ‘”and query graph ğ‘must exactly match\nwith each other. In contrast, for the SM-DNN ğºproblem, each vertex\nğ‘ğ‘–and its 1-hop neighbors ğ‘ğ‘(ğ‘ğ‘–)in query graph ğ‘must be a\nsubgraph of a matching vertex ğ‘£ğ‘–âˆˆğ‘‰(ğº)and its 1-hop neighbors\n11\n\nğ‘ğ‘(ğ‘£ğ‘–)inğº. Thus, in this case, techniques for GIC-DNN ğºby using\nğ·ğ‘ğ‘âˆ’1\nğºdo not work. In order to resolve this issue, we can design\nan effective graph embedding approach which utilizes DNNs to\nencode/map each star graph ğ‘”(containing a vertex ğ‘£ğ‘–âˆˆğ‘‰(ğº)and\nits 1-hop neighbors ğ‘ğ‘(ğ‘£ğ‘–)) inğºto a feature vector ğ¹(ğ‘”)(and a\ntuple identifier ğ‘£ğ‘–.ğ‘–ğ‘‘as well). In other words, we will offline train\na variant of DNNs: ğ·ğ‘ğ‘âˆ’1\nğºâˆ¼((ğ‘£ğ‘–,ğ‘ğ‘(ğ‘£ğ‘–)),(ğ¹(ğ‘”),ğ‘£ğ‘–.ğ‘–ğ‘‘)). In this\nDNN variant, we carefully devise an appropriate loss function in\nthe DNN such that any subgraph ğ‘”â€²of star graphs ğ‘”satisfies the\nconditionğ¹(ğ‘”â€²)âª¯ğ¹(ğ‘”), where â€œâª¯â€ is an order predicate between\ntwo vectors ğ¹(ğ‘”â€²)andğ¹(ğ‘”). Next, we will offline train another\nvariant of DNN: ğ·ğ‘ğ‘ğºâˆ¼((ğ¹(ğ‘”)),(ğ‘£ğ‘–)), which can be used for\nfinding matching vertices ğ‘£ğ‘–.\nThis way, for any query graph ğ‘, we can obtain a feature vector\nğ¹(ğ‘”(ğ‘ğ‘–))for each vertex ğ‘ğ‘–. By order constraints, we can obtain\nranges of features for those vectors ğ¹(ğ‘”(ğ‘£ğ‘–))such thatğ‘”(ğ‘ğ‘–)is a\nsubgraph of ğ‘”(ğ‘£ğ‘–). Then, we can use ğ·ğ‘ğ‘ğºâˆ¼((ğ¹(ğ‘”)),(ğ‘£ğ‘–))with\nfeature ranges as the input, and retrieve potential vertices (or their\nIDs). Finally, we can join candidate vertices for each vertex ğ‘ğ‘–inğ‘,\nand obtain candidate subgraphs ğ‘”for refinement.\n10 DISCUSSIONS ON DISTRIBUTED\nDNN-BASED DATA STORAGE AND\nCOMPUTING\nIn this section, we discuss the potential of generalizing our pro-\nposed learning-based data storage to the distributed environment,\nthat is, distributed DNN-based data storage. In contrast to current\ndistributed neural network solutions, which mostly focus on im-\nproving parallelism during the training process (e.g., paralleling\nthe stochastic gradient descent for fast convergence), our proposed\nstudy does not necessarily involve distributed neural network train-\ning. We assume that each DNN model can be trained on one single\nphysical machine. However, the DNN-based LMUs could be too\nlarge to be held in one machine and are thus stored distributively\nover multiple servers.\nWith the distributed DNN-based data storage, learning-based\nstructures (rather than original data formats) can be safely stored\non multiple distributed servers and only be materialized when\ncertain input data or computation workloads are provided. This\ncapability offers data security and privacy preservation, as well as\nthe potential to store arbitrarily large-scale data and perform the\ncorresponding analysis.\nTo enable efficient DNN-based data analytics in a distributed\nsetting, we can mainly explore two thrusts. First, we will investi-\ngate the strategy to dynamically partition the LMU storage across\nphysical machines to best serve the purpose of workload balance\nand overall query processing throughput. In contrast to traditional\ncost-model-guided data partitioning, the benefit or overhead of\nmoving DNNs around is not straightforward. We can devise an\ninterpreter that maps the present data access pattern and workload\nto the reward/loss of a given partitioning decision. We model it\nas a Partially-Observable Markov Decision Process (POMDP) and\nsolve it with Q-learning [ 49]. This approach would benefit from\na continuous learning process, such that it can provide timely re-\npartitioning guidance when the workload pattern shifts. Our second\nthrust is to develop time-efficient query evaluation for a given LMUpartitioning outcome. The key to the success of this thrust lies in\na number of optimization techniques: 1) an update-friendly light-\nweighted routing scheme (index) to embed the LMU structure, such\nthat given a query, we would be able to identify not only the set of\nDNNs to access but also where they are located; 2) reinforcement\nlearning empowered algorithms to learn desired execution plans;\nand 3) highly expressive and efficient runtime function support\n(e.g., APIs that support user-defined filter/constraints).\nConsider Join processing in a distributed LMU setting as an\nexample. Being a fundamental operator, Join is commonly adopted\nin analyses over structured relational tables or semi-structured\ngraphs. For example, it can serve as a fundamental building block\nfor graph isomorphism checking or subgraph matching, where the\n(sub)graph matching query can be expressed as a multi-way join\nquery [ 20]. Considering the huge size variance of intermediate\nresults produced from different join orders, we can incorporate the\nreinforcement learning strategy to learn a proper join sequence that\nbest overlaps the computation and communication. Specifically, we\ntrain the model by exploring a number of execution plans for a set\nof benchmark queries. By treating each decision of moving data or\nmodels as an action, and the efficiency improvement as the reward,\nour model can learn a proper scheduling strategy. This approach\ncan be generalized to other complex workloads.\n11 CONCLUSIONS\nIn this paper, we envision a novel direction of learning-based data\nstorage which utilizes learning-based structures such as DNNs in\na so-called learning-based memory unit (LMU) to store, manage,\nand analyze data. Although extensive research efforts have been\ndevoted to incorporating learning-based methods to various aspects\nof database systems, most of them are based on a database system\nthat physically stores tables or key-value pairs. The essence of our\nproposed study is â€œDNN-as-a-databaseâ€, such that data are implicitly\nstored in DNNs (in other words, no explicit values of data records\ncould be revealed by a memory/disk scan), which is useful for data\nsecurity and privacy preserving and has the potential of distributed\nDNN-based data storage and computing.\nOur proposed learning-based data storage can be applied to\nother data types such as DNN-based graphs ğº. Similar to DNN-\nbased relational tables, we store vertices ğ‘£ğ‘–âˆˆğ‘‰(ğº)and their 1-\nhop neighbors (i.e., vertices adjacent to ğ‘£ğ‘–) in DNNs. We can use\nsuch DNN-based graphs to process graph queries like the graph\nisomorphism checking or subgraph matching, by finding candidate\nvertices that match with vertices in a given query graph ğ‘via DNNs.\nThe learning-based data storage can be also generalized to other\nscenarios such as the distributed environment, that is, distributed\nDNN-based data storage. Given that data are implicitly encoded in\nthe LMU structure, it opens up a series of research opportunities\nto explore DNN-based locality and workload adaptive DNN model\npartitioning, as well as fill the gap of interpreting DNN-based data\naccess patterns to the cost estimation of data/model shuffling in a\ndistributed setting.\nIn the future, we will explore learning-based data storage via\nother ML models for heterogeneous data types (e.g., unstructured\ndata, trees, graphs, and images) and scenarios (e.g., IoT devices,\n12\n\ndistributed environment, etc.) and study its utilities in various real-\nworld applications that demand the data security, privacy preserv-\ning, and/or distributed storage/computing in a scalable manner.\nREFERENCES\n[1]2015. Deep learning in neural networks: An overview. Neural Networks 61 (2015),\n85â€“117.\n[2]Rafi Ahmed, Randall G. Bello, Andrew Witkowski, and Praveen Kumar. 2020.\nAutomated Generation of Materialized Views in Oracle. Proc. VLDB Endow. 13,\n12 (2020), 3046â€“3058. https://doi.org/10.14778/3415478.3415533\n[3]Erfan Azarkhish, Davide Rossi, Igor Loi, and Luca Benini. 2017. Neurostream:\nScalable and Energy Efficient Deep Learning with Smart Memory Cubes. CoRR\nabs/1701.06420 (2017). arXiv:1701.06420 http://arxiv.org/abs/1701.06420\n[4]Yoshua Bengio. 2009. Learning Deep Architectures for AI. Found. Trends Mach.\nLearn. 2, 1 (2009), 1â€“127. https://doi.org/10.1561/2200000006\n[5]Dinesh Das, Jiaqi Yan, Mohamed ZaÃ¯t, Satyanarayana R. Valluri, Nirav Vyas, Ra-\nmarajan Krishnamachari, Prashant Gaharwar, Jesse Kamp, and Niloy Mukherjee.\n2015. Query Optimization in Oracle 12c Database In-Memory. Proc. VLDB Endow.\n8, 12 (2015), 1770â€“1781. https://doi.org/10.14778/2824032.2824074\n[6]Sudipto Das, Feng Li, Vivek R. Narasayya, and Arnd Christian KÃ¶nig. 2016.\nAutomated Demand-driven Resource Scaling in Relational Database-as-a-Service.\nInProceedings of the 2016 International Conference on Management of Data . ACM,\n1923â€“1934. https://doi.org/10.1145/2882903.2903733\n[7]Jialin Ding, Umar Farooq Minhas, Jia Yu, Chi Wang, Jaeyoung Do, Yinan Li,\nHantian Zhang, Badrish Chandramouli, Johannes Gehrke, Donald Kossmann,\nDavid B. Lomet, and Tim Kraska. 2020. ALEX: An Updatable Adaptive Learned\nIndex. In Proceedings of the 2020 International Conference on Management of Data .\nACM, 969â€“984. https://doi.org/10.1145/3318464.3389711\n[8]Anshuman Dutt, Chi Wang, Azade Nazi, Srikanth Kandula, Vivek R. Narasayya,\nand Surajit Chaudhuri. 2019. Selectivity Estimation for Range Predicates using\nLightweight Models. Proc. VLDB Endow. 12, 9 (2019), 1044â€“1057. https://doi.org/\n10.14778/3329772.3329780\n[9]Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT\nPress (2016), 326.\n[10] Yue Han, Guoliang Li, Haitao Yuan, and Ji Sun. 2021. An Autonomous Materialized\nView Management System with Deep Reinforcement Learning. In 37th IEEE\nInternational Conference on Data Engineering . IEEE, 2159â€“2164. https://doi.org/\n10.1109/ICDE51399.2021.00217\n[11] Benjamin Hilprecht and Carsten Binnig. 2021. One Model to Rule them\nAll: Towards Zero-Shot Learning for Databases. CoRR abs/2105.00642 (2021).\narXiv:2105.00642 https://arxiv.org/abs/2105.00642\n[12] Benjamin Hilprecht, Carsten Binnig, and Uwe RÃ¶hm. 2020. Learning a Parti-\ntioning Advisor for Cloud Databases. In Proceedings of the 2020 International\nConference on Management of Data . ACM, 143â€“157. https://doi.org/10.1145/\n3318464.3389704\n[13] Stratos Idreos, Niv Dayan, Wilson Qin, Mali Akmanalp, Sophie Hilgard, Andrew\nRoss, James Lennon, Varun Jain, Harshita Gupta, David Li, and Zichen Zhu. 2019.\nDesign Continuums and the Path Toward Self-Designing Key-Value Stores that\nKnow and Learn. In 9th Biennial Conference on Innovative Data Systems Research .\nwww.cidrdb.org. http://cidrdb.org/cidr2019/papers/p143-idreos-cidr19.pdf\n[14] Andrej Karpathy, George Toderici, Sanketh Shetty, Thomas Leung, Rahul Suk-\nthankar, and Li Fei-Fei. 2014. Large-Scale Video Classification with Convolutional\nNeural Networks. In 2014 IEEE Conference on Computer Vision and Pattern Recogni-\ntion. IEEE Computer Society, 1725â€“1732. https://doi.org/10.1109/CVPR.2014.223\n[15] Jan Kossmann, Stefan Halfpap, Marcel Jankrift, and Rainer Schlosser. 2020. Magic\nmirror in my hand, which is the best in the land? An Experimental Evaluation\nof Index Selection Algorithms. Proc. VLDB Endow. 13, 11 (2020), 2382â€“2395.\nhttp://www.vldb.org/pvldb/vol13/p2382-kossmann.pdf\n[16] Tim Kraska, Mohammad Alizadeh, Alex Beutel, Ed H. Chi, Ani Kristo, Guillaume\nLeclerc, Samuel Madden, Hongzi Mao, and Vikram Nathan. 2019. SageDB: A\nLearned Database System. In 9th Biennial Conference on Innovative Data Systems\nResearch . www.cidrdb.org. http://cidrdb.org/cidr2019/papers/p117-kraska-cidr19.\npdf\n[17] Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018.\nThe Case for Learned Index Structures. In Proceedings of the 2018 International\nConference on Management of Data . ACM, 489â€“504. https://doi.org/10.1145/\n3183713.3196909\n[18] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet Clas-\nsification with Deep Convolutional Neural Networks. In Advances in Neural\nInformation Processing Systems 25: 26th Annual Conference on Neural Information\nProcessing Systems 2012 . 1106â€“1114. https://proceedings.neurips.cc/paper/2012/\nhash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html\n[19] Mayuresh Kunjir and Shivnath Babu. 2020. Black or White? How to Develop an\nAutoTuner for Memory-based Analytics. In Proceedings of the 2020 International\nConference on Management of Data . ACM, 1667â€“1683. https://doi.org/10.1145/\n3318464.3380591[20] Longbin Lai, Zhu Qing, Zhengyi Yang, Xin Jin, Zhengmin Lai, Ran Wang,\nKongzhang Hao, Xuemin Lin, Lu Qin, Wenjie Zhang, Ying Zhang, Zhengping\nQian, and Jingren Zhou. 2019. A Survey and Experimental Analysis of Dis-\ntributed Subgraph Matching. CoRR abs/1906.11518 (2019). arXiv:1906.11518\nhttp://arxiv.org/abs/1906.11518\n[21] Feifei Li. 2019. Cloud native database systems at Alibaba: Opportunities and\nChallenges. Proc. VLDB Endow. 12, 12 (2019), 2263â€“2272. https://doi.org/10.\n14778/3352063.3352141\n[22] Guoliang Li, Xuanhe Zhou, and Sihao Li. 2019. XuanYuan: An AI-Native Database.\nIEEE Data Eng. Bull. 42, 2 (2019), 70â€“81. http://sites.computer.org/debull/A19june/\np70.pdf\n[23] Guoliang Li, Xuanhe Zhou, Shifu Li, and Bo Gao. 2019. QTune: A Query-Aware\nDatabase Tuning System with Deep Reinforcement Learning. Proc. VLDB Endow.\n12, 12 (2019), 2118â€“2130. https://doi.org/10.14778/3352063.3352129\n[24] Guoliang Li, Xuanhe Zhou, Ji Sun, Xiang Yu, Yue Han, Lianyuan Jin, Wenbo\nLi, Tianqing Wang, and Shifu Li. 2021. openGauss: An Autonomous Database\nSystem. Proc. VLDB Endow. 14, 12 (2021), 3028â€“3041. https://doi.org/10.14778/\n3476311.3476380\n[25] Xi Liang, Aaron J. Elmore, and Sanjay Krishnan. 2019. Opportunistic View\nMaterialization with Deep Reinforcement Learning. CoRR abs/1903.01363 (2019).\narXiv:1903.01363 http://arxiv.org/abs/1903.01363\n[26] Xing Lin, Yair Rivenson, Nezih T. Yardimci, Muhammed Veli, Mona Jarrahi,\nand Aydogan Ozcan. 2018. All-Optical Machine Learning Using Diffractive\nDeep Neural Networks. CoRR abs/1804.08711 (2018). arXiv:1804.08711 http:\n//arxiv.org/abs/1804.08711\n[27] Le Lu, Yefeng Zheng, Gustavo Carneiro, and Lin Yang (Eds.). 2017. Deep Learning\nand Convolutional Neural Networks for Medical Image Computing - Precision\nMedicine, High Performance and Large-Scale Datasets . Springer. https://doi.org/\n10.1007/978-3-319-42999-1\n[28] Lin Ma, Dana Van Aken, Ahmed Hefny, Gustavo Mezerhane, Andrew Pavlo, and\nGeoffrey J. Gordon. 2018. Query-based Workload Forecasting for Self-Driving\nDatabase Management Systems. In Proceedings of the 2018 International Conference\non Management of Data . ACM, 631â€“645. https://doi.org/10.1145/3183713.3196908\n[29] Lin Ma, Bailu Ding, Sudipto Das, and Adith Swaminathan. 2020. Active Learning\nfor ML Enhanced Database Systems. In Proceedings of the 2020 International\nConference on Management of Data . ACM, 175â€“191. https://doi.org/10.1145/\n3318464.3389768\n[30] Ryan Marcus, Parimarjan Negi, Hongzi Mao, Nesime Tatbul, Mohammad Al-\nizadeh, and Tim Kraska. 2021. Bao: Making Learned Query Optimization Practical.\nInSIGMOD â€™21: International Conference on Management of Data . ACM, 1275â€“1288.\nhttps://doi.org/10.1145/3448016.3452838\n[31] Ryan Marcus and Olga Papaemmanouil. 2018. Deep Reinforcement Learning for\nJoin Order Enumeration. In Proceedings of the First International Workshop on\nExploiting Artificial Intelligence Techniques for Data Management . ACM, 3:1â€“3:4.\nhttps://doi.org/10.1145/3211954.3211957\n[32] Ryan C. Marcus, Parimarjan Negi, Hongzi Mao, Chi Zhang, Mohammad Alizadeh,\nTim Kraska, Olga Papaemmanouil, and Nesime Tatbul. 2019. Neo: A Learned\nQuery Optimizer. Proc. VLDB Endow. 12, 11 (2019), 1705â€“1718. https://doi.org/\n10.14778/3342263.3342644\n[33] H. Brendan McMahan, Eider Moore, Daniel Ramage, and Blaise AgÃ¼era y Arcas.\n2016. Federated Learning of Deep Networks using Model Averaging. CoRR\nabs/1602.05629 (2016). arXiv:1602.05629 http://arxiv.org/abs/1602.05629\n[34] Ali Bou Nassif, Ismail Shahin, Imtinan Attili, Mohammad Azzeh, and Khaled\nShaalan. 2019. Speech Recognition Using Deep Neural Networks: A Systematic\nReview. IEEE Access 7 (2019), 19143â€“19165. https://doi.org/10.1109/ACCESS.\n2019.2896880\n[35] Vikram Nathan, Jialin Ding, Mohammad Alizadeh, and Tim Kraska. 2020. Learn-\ning Multi-Dimensional Indexes. In Proceedings of the 2020 International Confer-\nence on Management of Data . ACM, 985â€“1000. https://doi.org/10.1145/3318464.\n3380579\n[36] Yongjoo Park, Shucheng Zhong, and Barzan Mozafari. 2020. QuickSel: Quick\nSelectivity Learning with Mixture Models. In Proceedings of the 2020 International\nConference on Management of Data . ACM, 1017â€“1033. https://doi.org/10.1145/\n3318464.3389727\n[37] Andrew Pavlo, Gustavo Angulo, Joy Arulraj, Haibin Lin, Jiexi Lin, Lin Ma,\nPrashanth Menon, Todd C. Mowry, Matthew Perron, Ian Quah, Siddharth San-\nturkar, Anthony Tomasic, Skye Toor, Dana Van Aken, Ziqi Wang, Yingjun Wu,\nRan Xian, and Tieying Zhang. 2017. Self-Driving Database Management Systems.\nIn8th Biennial Conference on Innovative Data Systems Research . www.cidrdb.org.\nhttp://cidrdb.org/cidr2017/papers/p42-pavlo-cidr17.pdf\n[38] PyTorch. 2022. https://pytorch.org/docs/stable/nn.html\n[39] Bita Darvish Rouhani, M. Sadegh Riazi, and Farinaz Koushanfar. 2018. Deepsecure:\nscalable provably-secure deep learning. In Proceedings of the 55th Annual Design\nAutomation Conference . ACM, 2:1â€“2:6. https://doi.org/10.1145/3195970.3196023\n[40] David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. 1986. Learning\nRepresentations by Back-propagating Errors. Nature 323, 6088 (1986), 533â€“536.\n[41] Zahra Sadri, Le Gruenwald, and Eleazar Leal. 2020. DRLindex: deep reinforcement\nlearning index advisor for a cluster database. In IDEAS 2020: 24th International\n13\n\nDatabase Engineering & Applications Symposium . ACM, 11:1â€“11:8. https://doi.\norg/10.1145/3410566.3410603\n[42] JÃ¼rgen Schmidhuber. 2014. Deep Learning in Neural Networks: An Overview.\nCoRR abs/1404.7828 (2014). arXiv:1404.7828 http://arxiv.org/abs/1404.7828\n[43] Yangjun Sheng, Anthony Tomasic, Tieying Sheng, and Andrew Pavlo. 2019.\nScheduling OLTP Transactions via Machine Learning. CoRR abs/1903.02990\n(2019). arXiv:1903.02990 http://arxiv.org/abs/1903.02990\n[44] Ji Sun and Guoliang Li. 2019. An End-to-End Learning-based Cost Estimator. Proc.\nVLDB Endow. 13, 3 (2019), 307â€“319. https://doi.org/10.14778/3368289.3368296\n[45] Latanya Sweeney. 2002. Achieving k-Anonymity Privacy Protection Using Gen-\neralization and Suppression. Int. J. Uncertain. Fuzziness Knowl. Based Syst. 10, 5\n(2002), 571â€“588. https://doi.org/10.1142/S021848850200165X\n[46] TPC-H. 2022. https://www.tpc.org/tpch/\n[47] Immanuel Trummer, Junxiong Wang, Deepak Maram, Samuel Moseley, Saehan\nJo, and Joseph Antonakakis. 2019. SkinnerDB: Regret-Bounded Query Evaluation\nvia Reinforcement Learning. CoRR abs/1901.05152 (2019). arXiv:1901.05152\nhttp://arxiv.org/abs/1901.05152\n[48] Timothy E. Wang, Jack Gu, Dhagash Mehta, Xiaojun Zhao, and Edgar A. Bernal.\n2018. Towards Robust Deep Neural Networks. CoRR abs/1810.11726 (2018).\narXiv:1810.11726 http://arxiv.org/abs/1810.11726\n[49] Yihan Wang, Beining Han, Tonghan Wang, Heng Dong, and Chongjie Zhang.\n2021. DOP: Off-Policy Multi-Agent Decomposed Policy Gradients. In 9th In-\nternational Conference on Learning Representations . OpenReview.net. https:\n//openreview.net/forum?id=6FqKiVAdI3Y[50] Chenggang Wu, Alekh Jindal, Saeed Amizadeh, Hiren Patel, Wangchao Le, Shi\nQiao, and Sriram Rao. 2018. Towards a Learning Optimizer for Shared Clouds.\nProc. VLDB Endow. 12, 3 (2018), 210â€“222. https://doi.org/10.14778/3291264.\n3291267\n[51] Ning Xie, Gabrielle Ras, Marcel van Gerven, and Derek Doran. 2020. Explainable\nDeep Learning: A Field Guide for the Uninitiated. CoRR abs/2004.14545 (2020).\narXiv:2004.14545 https://arxiv.org/abs/2004.14545\n[52] Yilin Yan, Qiusha Zhu, Mei-Ling Shyu, and Shu-Ching Chen. 2016. A Classifier\nEnsemble Framework for Multimedia Big Data Classification. In 17th IEEE Inter-\nnational Conference on Information Reuse and Integration . IEEE Computer Society,\n615â€“622. https://doi.org/10.1109/IRI.2016.88\n[53] Xiang Yu, Guoliang Li, Chengliang Chai, and Nan Tang. 2020. Reinforcement\nLearning with Tree-LSTM for Join Order Selection. In 36th IEEE International Con-\nference on Data Engineering . IEEE, 1297â€“1308. https://doi.org/10.1109/ICDE48307.\n2020.00116\n[54] Haitao Yuan, Guoliang Li, Ling Feng, Ji Sun, and Yue Han. 2020. Automatic\nView Generation with Deep Learning and Reinforcement Learning. In 36th IEEE\nInternational Conference on Data Engineering . IEEE, 1501â€“1512. https://doi.org/\n10.1109/ICDE48307.2020.00133\n[55] Ji Zhang, Yu Liu, Ke Zhou, Guoliang Li, Zhili Xiao, Bin Cheng, Jiashu Xing,\nYangtao Wang, Tianheng Cheng, Li Liu, Minwei Ran, and Zekang Li. 2019. An\nEnd-to-End Automatic Cloud Database Tuning System Using Deep Reinforcement\nLearning. In Proceedings of the 2019 International Conference on Management of\nData . ACM, 415â€“432. https://doi.org/10.1145/3299869.3300085\n14",
  "textLength": 77165
}