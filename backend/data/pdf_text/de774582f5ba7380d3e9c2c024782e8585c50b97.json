{
  "paperId": "de774582f5ba7380d3e9c2c024782e8585c50b97",
  "title": "Online Classification with Predictions",
  "pdfPath": "de774582f5ba7380d3e9c2c024782e8585c50b97.pdf",
  "text": "arXiv:2405.14066v1  [cs.LG]  22 May 2024Online Classiﬁcation with Predictions\nVinod Raman and Ambuj Tewari\nAbstract\nWe study online classiﬁcation when the learner has access to predictions about future examples.\nWe design an online learner whose expected regret is never wo rse than the worst-case regret,\ngracefully improves with the quality of the predictions, an d can be signiﬁcantly better than the\nworst-case regretwhenthepredictionsoffutureexamplesa reaccurate. Asacorollary, weshowthat\nif the learner is always guaranteed to observe data where fut ure examples are easily predictable,\nthen online learning can be as easy as transductive online le arning. Our results complement\nrecent work in online algorithms with predictions and smoot hed online classiﬁcation, which go\nbeyond a worse-case analysis by using machine-learned pred ictions and distributional assumptions\nrespectively.\n1 Introduction\nIn online classiﬁcation, Nature plays a game with a learner over T∈ /C6rounds. In each round\nt∈[T], Nature selects a labeled example ( xt,yt)∈X×Y and reveals just the example xtto the\nlearner. The learner, using the history of the game ( x1,y1),...,(xt−1,yt−1) and the current example\nxt, makes a potentially randomized prediction ˆ yt∈ Y. Finally, Nature reveals the true label yt\nand the learner suﬀers the loss /BD{ˆyt/n⌉}ationslash=yt}.Given access to a hypothesis classH⊆YXconsisting\nof functions h:X →Y, the goal of the learner is to minimize its regret, the diﬀerence between its\ncumulative mistake and that of the best ﬁxed hypothesis h∈Hin hindsight. We say a class His online\nlearnable if there exists a learning algorithm that achieves vanishing a verageregret for any, potentially\nadversarialchosen, stream of labeled examples ( x1,y1),...,(xT,yT). Canonically, one also distinguishes\nbetween the realizable and agnostic settings. In the realizable sett ing, Nature must choose a stream\n(x1,y1),...,(xT,yT) such that there exists a h∈Hfor which h(xt) =ytfor allt∈[T]. On the other\nhand, in the agnostic setting, no such assumptions on the stream a re placed.\nDue to applications in spam ﬁltering, image recognition, and language m odeling, online classiﬁca-\ntion has had a long, rich history in statistical learning theory. In a se minal work, Littlestone [1987]\nprovided a sharp quantitative characterization of which binary hyp othesis classesH⊆{0,1}Xare\nonline learnable in the realizable setting. This characterization was in t erms of the ﬁniteness of a\ncombinatorial dimension called the Littlestone dimension. Twenty-tw o years later, Ben-David et al.\n[2009] proved that the Littlestone dimension continues to characterize the online learnability of binary\nhypothesis classes in the agnostic setting. Later, Daniely et al. [2011] generalized the Littlestone di-\nmension to multiclass hypothesis classes H⊆YX, and showed that it fully characterizes multiclass\nonline learnability when the label space Yis ﬁnite. More recently, Hanneke et al. [2023] extended this\nresult to show that the multiclass Littlestone dimension continues to characterize multiclass online\nlearnability even when Yis unbounded.\nWhile elegant, the characterization of online classiﬁcation in terms of the Littlestone dimension is\noften interpreted as an impossibility result [Haghtalab ,2018]. Indeed, due to the restrictive nature of\nthe Littlestone dimension, even simple classes like the 1-dimensional t hresholdsHthresh={x/ma√sto→ /BD{x≥\na}:a∈ /C6}are not online learnable in the realizable setting. This hardness arises mainly due to a\nworst-caseanalysis: the adversaryis allowedto choose anysequence of labeled examples, even possibly\nadapting to the learner’s strategy. In many situations, however, the sequence of data is “easy” and a\nworst-caseanalysis is too pessimistic. For example, if one were to us e the daily temperatures to predict\nsnowfall, it is unlikely that temperatures will vary rapidly within a given w eek. Even so, one might\nhave to access to temperature forecasting models that can accu rately predict future temperatures.\nThis motivates a beyond-worst-case analysis of online classiﬁcation algorithms by proving guarantees\nthat adapt to the “easiness” of the example stream.\n1\n\nThe push for a beyond-worst-caseanalysis has its roots in classica l algorithm design [ Roughgarden ,\n2021]. Of recent interest is Algorithms with Predictions (AwP), a speciﬁc s ub-ﬁeld of beyond-worst-\ncase analysis of algorithms [ Mitzenmacher and Vassilvitskii ,2022]. Here, classical algorithms are given\nadditional information about the problem instance in the form of mac hine-learned predictions. Aug-\nmented with these predictions, the algorithm’s goal is to perform op timally on a per-input basis when\nthe predictions are good (known as consistency ), while always ensuring optimal worst-case guarantees\n(known as robustness ). Ideally, algorithms are also smooth, obtaining performance guarantees that\ninterpolate between instance and worst-case optimality as a funct ion of prediction quality. After a\nsuccessful application to learning index structures [ Kraska et al. ,2018], there has been an explosion of\nwork designing algorithms whose guarantees depend on the quality o f available, machine-learned pre-\ndictions Mitzenmacher and Vassilvitskii [2022]. For example, machine-learned predictions have been\nused to achieve more eﬃcient data-structures [ Lin et al. ,2022], faster runtimes [ Chen et al. ,2022,\nErgun et al. ,2021], better accuracy-space tradeoﬀs for streaming algorithms [ Hsu et al. ,2019], and\nimproved performance bounds for online algorithms [ Purohit et al. ,2018]. A more detailed summary\nof related works can be found in Appendix A.\nDespite this vast literature, the accuracy beneﬁts of machine-lea rned predictions for online classiﬁ-\ncation are, to the best of our knowledge, unknown. In this work, w e bridge the gap between AwP and\nonline classiﬁcation. In contrastto previous work, which go beyond a worst-caseanalysisin online clas-\nsiﬁcation through smoothness or other distributional assumption s [Haghtalab et al. ,2020,Block et al. ,\n2022,Wu et al. ,2023], we give the learner access to a Predictor , a forecasting algorithm that predicts\nfutureexamples in the data stream. The learner, before predicting a label ˆ yt, can query the Predictor\nand receive predictions ˆ xt+1,...,ˆxTon the future examples. The learner can then use the history of\nthe game ( x1,y1),...,(xt−1,yt−1), the current example xt, and the predictions ˆ xt+1,...,ˆxTto output\na label ˆyt. We allow Predictors to be adaptive - they can change their predictions of future examples\nbased on the actual realizations of past examples. From this persp ective, Predictors are also online\nlearners, and we quantify the predictability of example streams through their mistake-bounds.\nIn this work, we seek to design online learning algorithms whose expec ted regret, given black-box\naccess to a Predictor, degrades gracefully with the quality of the P redictor’s predictions. By doing so,\nwe are also interested in understanding how access to a Predictor m ay impact the characterization of\nonline learnability. In particular, given a Predictor, when can online lea rnability become easierthan\nin the standard, worst-case setup? Guided by these objectives, we make the following contributions.\n(1) In the realizable and agnostic settings, we design online learners that, using black-box access to\na Predictor, adapt to the “easiness” of the example stream. When the predictions of the Predic-\ntor are good, our learner’s expected mistakes/regret signiﬁcant ly improves upon the worst-case\nguarantee. When the Predictor’spredictions arebad, the expect ed mistakes/regretof our learner\nmatches the optimal worst-case expected mistake-bound/regr et. Finally, our learner’s expected\nmistake-bound/regret degrades gracefully with the quality of the Predictor’s predictions.\n(2) We show that having black-box access to a good Predictor can m ake learning much easier than\nthe standard, worst-casesetting. More precisely, good Predict ors allow “oﬄine” learnable classes\nto become online learnable. In this paper, we take the “oﬄine” settin g to be transductive online\nlearning [ Ben-David et al. ,1997,Hanneke et al. ,2024] where Nature reveals the entire sequence\nof examples x1,...,xT(but not the labels y1,...,yT) to the learner beforethe game begins. Many\n“oﬄine” learnable classes are not online learnable. For example, when Y={0,1}, transductive\nonline learnability is characterized by the ﬁniteness of the VC dimensio n, the same dimension\nthat characterizes PAC learnability. Thus, our result is analogous t o that in smoothed online\nclassiﬁcation, where PAC learnability is also suﬃcient for online learnab ility [Haghtalab et al. ,\n2020,Block et al. ,2022].\nA notable property of our realizable and agnostic online learners is th eir use of black-box access to a\ntransductive online learner to make predictions. In this sense, our proof strategies involve reducing\nonline classiﬁcation with predictions to transductive online learning. F or both contributions (1) and\n(2), we consideronly the realizablesetting in the main text. The resu ltsand argumentsforthe agnostic\nsetting are nearly identical and thus deferred to Appendix G.\n2\n\n2 Preliminaries\nLetXdenote an example space and Ydenote the label space. We make no assumptions about Y,\nso it can be unbounded (e.g., Y= /C6). LetH⊆YXdenote a hypothesis class. For a set A, let\nA⋆=/uniontext∞\nn=0Andenote the set of all ﬁnite sequences of elements in A. Moreover, we let A≤ndenote the\nset of all sequences of elements in Aof size at most n. Then,X⋆denotes the set of all ﬁnite sequences\nof examples inXandZ⊆X⋆denotes a particular family of such sequences. We abbreviate a seq uence\nz1,...,zTbyz1:T.Finally, for a,b,c∈ /CA, we leta∧b∧c= min{a,b,c}.\n2.1 Online Classiﬁcation\nIn online classiﬁcation, a learner Aplays a repeated game against Nature over T∈ /C6rounds. In each\nroundt∈[T], Nature picks a labeled example ( xt,yt)∈X×Y and reveals xtto the learner. The\nlearner makes a randomized prediction ˆ yt∈{0,1}. Finally, Nature reveals the true label ytand the\nlearner suﬀers the 0-1 loss /BD{ˆyt/n⌉}ationslash=yt}.Given a hypothesis class H⊆YX, the goal of the learner is to\nminimize its expected regret\nRA(T,H) := sup\nx1:T∈Xsup\ny1:T∈YT/parenleftBigg/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n−inf\nh∈HT/summationdisplay\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}/parenrightBigg\n,\nwhere the expectation is only over the randomness of the learner. A hypothesis class His said to\nbe online learnable if there exists an (potentially randomized) online lea rning algorithmAsuch that\nRA(T,H) =o(T). If it is guaranteed that the learner always observes a sequence of examples labeled\nby some hypothesis h∈H, then we say we are in the realizable setting and the goal of the learner is\nto minimize its expected cumulative mistakes ,\nMA(T,H) := sup\nx1:T∈XTsup\nh∈H\n/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=h(xt)}/bracketrightBigg\n,\nwhere again the expectation is taken only with respect to the rando mness of the learner. It is well\nknown that the ﬁniteness of the multiclass extension of the Littlest one dimension (Ldim) characterizes\nrealizableandagnosticonlinelearnability[ Littlestone ,1987,Daniely et al. ,2011,Hanneke et al. ,2023].\nSee Appendix Bfor complete deﬁnitions.\n2.2 Online Classiﬁcation with Predictions\nMotivated by the fact that real-worldexample streams x1:Tare far from worst-case,we give our learner\nAblack-box access to a PredictorP, deﬁned algorithmically in Algorithm 1.\nAlgorithm 1 PredictorP\nInput:Time horizon T\n1fort= 1,...,Tdo\n2Nature reveals the true example xt.\n3Observe xt, update, and make a (potentially randomized) prediction ˆ xt\n1:T.\n4end\nRemark. We highlight that our Predictors are very general and can also use s ide information,\nin addition to the past examples, to make predictions about future e xamples. For example, if the\nexamples are daily average temperatures, then Predictors can als o use other covariates, like humidity,\nprecipitation, and wind speed, to predict future temperatures.\nIn each round t∈[T], the learnerAcan query the Predictor Pto get a sense of what examples it\nwill observe in the future. Then, the learner Acan use the history ( x1,y1),..,(xt−1,yt−1), the current\nexample xt,andthe future predicted examples to classify the current example. Pr otocol2makes\nexplicit the interaction between the learner, the Predictor, and Na ture.\nNote that, in every round t∈[T], the PredictorPmakes a prediction about the entiresequence of\nTexamples, even those that it has observed in the past. This is mainly f or notational convenience as\nwe assume that our Predictors are consistent .\n3\n\nAlgorithm 2 Online Learning with a Predictor\nInput:PredictorP, Hypothesis class H, Time horizon T\n1fort= 1,...,Tdo\n2Nature reveals the true example xt.\n3The PredictorPobserves xt, updates, and reveals its predictions ˆ xt\n1:T.\n4Learner makes a randomized prediction ˆ ytusing ˆxt\n1:T,xt, and (x1,y1),...,(xt−1,yt−1).\n5Nature reveals the true label ytto the learner.\n6Learner suﬀers loss /BD{yt/n⌉}ationslash= ˆyt}and updates itself.\n7end\nAssumption 1 (Consistency) .A Predictor is consistent if for every sequence x1:T∈XTand every\ntime point t∈[T], the prediction ˆx1:T=P(x1:t)satisﬁes the property that ˆx1:t=x1:t.\nAlthough stated as an assumption, it is without loss of generality tha t Predictors are consistent -\nany inconsistent Predictor can be made consistent by hard coding it s input into its output. In addition\nto consistency, we assume that our Predictors are lazy.\nAssumption 2 (Laziness) .A Predictor is lazyif for every sequence x1:T∈XTand every t∈[T], if\nP(x1:t−1)t=xt, thenP(x1:t) =P(x1:t−1). That is,Pdoes not change its prediction if it is correct.\nSince Predictors are also online learners, the assumption of laziness is also mild: non-lazy online\nlearners can be generically converted into lazy ones [ Littlestone ,1988,1989]. We always assume that\nPredictors are consistent and lazy and drop these pronouns for t he rest of the paper.\nRemark. We highlight that Predictors are adaptive and change their predictio ns based on the\nrealizations of past examples. This is contrast to existing literature in OAwP, where machine-learned\npredictions are often static. Nevertheless, our framework is mor e general and captures the setting\nwhere predictions of examples are made once and ﬁxed throughout the game. Indeed, consider the\nconsistent, lazy Predictorthat ﬁxesa sequence z1:T∈XTbefore the gamebegins, and forevery t∈[T],\noutputs the predictions ˆ xt\n1:Tsuch that ˆ xt\n1:t=x1:tand ˆxt\nt+1:T=zt+1:T.\nIdeally, when given access to a Predictor P, the expected regret of Ashould degrade gracefully\nwith the quality of P’s predictions. To this end, we quantify the performance of a Predic torPthrough\nMP(x1:T) := /BX/bracketleftBiggT/summationdisplay\nt=2\n/BD{P(x1:t−1)t/n⌉}ationslash=xt}/bracketrightBigg\n,\nthe expected number of mistakes that Pmakes on a sequence of examples x1:T∈XT. In Section 3,\nwe design an online learner whose expected regret/mistake-bound on a stream ( x1,y1),...,(xT,yT) can\nbe written in terms of M P(x1:T).\n2.3 Predictability\nPredictors and their mistake bounds oﬀer us to ability to deﬁne and q uantify a notion of “easiness” for\nexample streams x1:T. In particular, we can distinguish between example streams that ar e predictable\nand unpredictable. To do so, let Z ⊆X⋆denote a collection of ﬁnite sequences of examples. By\nrestrictingthe adversarytoplayingexamplesstreamsin Z, we candeﬁne analogousnotionsofminimax\nexpected regret\nRA(T,H,Z) := sup\nx1:T∈Zsup\ny1:T∈YT\n/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}−inf\nh∈HT/summationdisplay\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}/bracketrightBigg\n,\nand minimax expected mistakes,\nMA(T,H,Z) := sup\nx1:T∈Zsup\nh∈H\n/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=h(xt)}/bracketrightBigg\n.\nAsusual, wesaythat atuple ( H,Z)is onlineandrealizableonlinelearnableifinf ARA(T,H,Z) =o(T)\nand inf AMA(T,H,Z) =o(T) respectively. IfZ=X⋆, then the deﬁnitions aboverecoverthe standard,\n4\n\nworst-case online classiﬁcation setup. However, in the more gener al case whereZ⋆⊆X⋆, we can use\ntheexistence of good Predictors Pand their mistake bounds to quantify the “easiness” of a stream\nclassZ. That is, we say Zis predictable if there exists a consistent, lazy Predictor Psuch that\nMP(T,Z) := supx1:T∈ZMP(x1:T) =o(T).\nDeﬁnition 1 (Predictability) .A classZ⊆X⋆is predictable if and only if infPMP(T,Z) =o(T).\nDeﬁnition 1provides a qualitative deﬁnition of what it means for a sequence of ex amples to be\npredictable, and therefore “easy”. If Z⊆X⋆is a predictable class of example streams, then a stream\nx1:T∈XTis predictable if x1:T∈Z.By having access to a good Predictor, sequences of examples\nthat previously exhibited “worst-case” behavior, now become pre dictable. In Section 3, we show that\nunder predictable examples, “oﬄine” learnability is suﬃcient for online learnability.\n2.4 Oﬄine Learnability\nIn the classical analysis of online algorithms, one competes against t he best “oﬄine” solution. In the\ncontext of online classiﬁcation, this amounts to comparing online lear nability to “oﬄine” learnability,\nwhere we interpret the “oﬄine” setting as the case where Nature r eveals the sequence of examples\n(x1,...,xT) before the game begins. In particular, compared to the standar d online learning setting, in\nthe “oﬄine” version, the learnerknows the sequence of examples x1,...,xTbefore the game begins, and\nits goal is to predict the correspondinglabels y1,...,yT. This setting was recently named “Transductive\nOnline Learning” [ Hanneke et al. ,2024] and the minimax rates in both the realizable and agnostic\nsetting have been established [ Ben-David et al. ,1997,Hanneke et al. ,2023]. For the remainder of the\npaper, we will use oﬄine and transductive online learnability interchan geably.\nFor a randomized oﬄine learner B, we let\nRB(T,H) := sup\nx1:T∈XTsup\ny1:T∈YT\n/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{Bx1:T(xt)/n⌉}ationslash=yt}−inf\nh∈HT/summationdisplay\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}/bracketrightBigg\ndenote its minimax expected regret and\nMB(T,H) := sup\nh∈Hsup\nx1:T∈XT\n/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{Bx1:T(xt)/n⌉}ationslash=h(xt)}/bracketrightBigg\n.\ndenote its minimax expected mistakes. We use the notation Bx1:Tto indicate thatBwas initialized\nwith the sequence x1:Tbefore the game begins. If M B(T,H) =o(T) or R B(T,H) =o(T), then we say\nthatBis a no-regret oﬄine learner. It turns out that realizable and agnos tic oﬄine learnability are\nequivalent [ Hanneke et al. ,2024]. That is, M B(T,H) =o(T)⇔RB(T,H) =o(T). Thus, without loss\nof generality, we say a class H⊆YXis oﬄine learnable if and only if there exists a no-regret oﬄine\nlearner forH.\nWhen|Y|= 2,Ben-David et al. [1997] andHanneke et al. [2023] show that the ﬁniteness of a\ncombinatorial dimension called the Vapnik–Chervonenkis (VC) dimens ion (or equivalently PAC learn-\nability) is suﬃcient for oﬄine learnability (see Appendix Bfor complete deﬁnitions).\nLemma 1 (Ben-David et al. [1997],Hanneke et al. [2024]).For everyH⊆{0,1}X, there exists a\ndeterministic oﬄine learnerBsuch that\nMB(T,H) =O/parenleftBig\nVC(H)log2T/parenrightBig\nwhereVC(H)is the VC dimension of H.\nIn Section 3, we use this upper bound in Lemma 1to prove that PAC learnability of Himplies\n(H,Z) online learnability when Zis predictable. Interestingly, Hanneke et al. [2024] also establish a\ntrichotomy in the minimax expected mistakes for oﬄine learning in the r ealizable setting. That is, for\nanyH⊆YXwith|Y|<∞, the quantity M B(T,H) can only be Θ(1), Θ(log2T), or Θ(T). On the\nother hand, in the agnostic setting, R B(T,H) can be ˜Θ(√\nT) or Θ(T), where ˜Θ hides poly-log terms\ninT.\nOur main result in Section 3shows that oﬄine learnability is suﬃcient for online learnability under\npredictable examples. The following technical lemma will be important w hen proving so.\n5\n\nLemma 2. [Ceccherini-Silberstein et al. ,2017, Lemma 5.17] Letg: /CI+/ma√sto→ /CA+be a positive sublinear\nfunction. Then, gis bounded from above by a concave sublinear function f: /CA+/ma√sto→ /CA+.\nIn light of Lemma 2, we let ¯fdenote the concave sublinear function upper bounding the positive\nsublinear function f. For example, our regret bounds in Section 3will often be in terms of MB(T,H).\nAlthough in full generality M B(T,H)≤MB(T,H), in many cases we have equality. For example, when\n|Y|= 2, the trichotomy of expected minimax rates established by Theor em 4.1 in Hanneke et al. [2024]\nshows that M B(T,H) =MB(T,H).\n3 Adaptive Rates in the Realizable Setting\nIn this section, we design learning algorithms whose expected mistak e bounds, given black-box access\nto a PredictorPand oﬄine learner B, adapt to the quality of predictions by PandB. Our main\nquantitative result is stated below.\nTheorem 3 (Realizable upper bound) .For everyH⊆YX, PredictorP, and no-regret oﬄine learner\nB, there exists an online learner Asuch that for every realizable stream (x1,y1),...,(xT,yT),Amakes\nat most\n3/parenleftBigg\nL(H)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n(i)∧(MP(x1:T)+1)M B(T,H)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n(ii)∧6/parenleftBig\n(MP(x1:T)+1)MB/parenleftBigT\nMP(x1:T)+1+1,H/parenrightBig\n+log2T/parenrightBig\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n(iii)/parenrightBigg\n+5\nmistakes in expectation, where L(H)is the Littlestone dimension of H.\nWehighlightsomeimportantconsequencesofTheorem 3. Firstly, whenM P(x1:T) = 0,theexpected\nmistake bound of Amatches (up to constant factors) that of the oﬄine learner B. Thus, when\nMP(x1:T) = 0 andBis a minimax optimal oﬄine learner, our learner Aperforms as well as the best\noﬄine learner. Secondly, the expected mistake bound of Ais always at most 3L( H)+5; the minimax\nworst-case mistake bound up to constant factors. Thus, our lea rnerAnever does worse than the\nworst-case mistake bound. Thirdly, the expected mistake bound o fAgracefully interpolates between\nthe oﬄine and worst-case optimal rates as a function of M P(x1:T). In Section 3.3, we show that the\ndependence ofA’s mistake bound on M P(x1:T) and M B(T,H) can be tight. Lastly, we highlight that\nTheorem 3makes no assumption about the size of Y.\nWith respect to learnability, Corollary 4shows that oﬄine learnability of His suﬃcient for online\nlearnability under predictable examples.\nCorollary 4 (Oﬄine learnability = ⇒Realizable Online learnability with Predictable Examples) .\nFor everyH⊆YXandZ⊆X⋆,\nZis predictable andHis oﬄine learnable =⇒(H,Z)is realizable online learnable.\nThis follows from a slight modiﬁcation of the proof of Theorem 3along with the fact that the term\n(MP(T,Z)+1)MB/parenleftBig\nT\nMP(T,Z)+1,H/parenrightBig\n=o(T) when M B(T,H) =o(T) and M P(T,Z) =o(T). In addition,\nwe can also establish a quantitative version of Corollary 4for VC classes.\nCorollary 5. For everyH⊆{0,1}X, PredictorPandZ⊆X⋆, there exists an online learner Asuch\nthat\nMA(T,H,Z) =O/parenleftBigg\nVC(H)(MP(T,Z)+1)log2/parenleftBigT\nMP(T,Z)+1/parenrightBig\n+log2T/parenrightBigg\n.\nWe prove both Corollary 4and5in Appendix D. Corollary 5shows that PAC learnability implies\nonline learnability under predictable examples. Moreover, for VC clas ses, when M P(x1:T) = 0, the\nupper bound in Corollary 5exactly matches that of Lemma 1. An analogous corollary in terms of the\nNatarajan dimension (see Appendix Bfor deﬁnition) holds when |Y|<∞.\nThe remainder of this section is dedicated to proving Theorem 3. The proof involves constructing\nthreediﬀerent online learners, with expected mistake bounds (i), (ii), and (iii) respe ctively, and then\nrunning the Deterministic Weighted Majority Algorithm (DWMA) using t hese learners as experts\n[Arora et al. ,2012]. The following guarantee of DWMA along with upper bounds (i), (ii), an d (iii)\ngives the upper bound in Theorem 3(see Appendix Efor complete proof).\n6\n\nLemma 6 (DWMA guarantee [ Arora et al. ,2012]).TheDWMA run with Nexperts and learning\nrateη= 1/2makes at most 3(mini∈[N]Mi+ log2N)mistakes, where Miis the number of mistakes\nmade by expert i∈[N].\nThe online learner obtaining the upper bound L( H) is the celebrated Standard Optimal Algorithm\n[Littlestone ,1987,Daniely et al. ,2011], and thus we omit the details here. Our second and third\nlearners are described in Sections 3.1and3.2respectively. Finally, in Section 3.3, we give a lower\nbound showing that our upper bound in Theorem 3can be tight.\n3.1 Proof of upper bound (ii) in Theorem 3\nConsider a lazy, consistent predictor P. Given any sequence of examples x1:T∈XT, the PredictorP\nmakesc∈ /C6mistakes at some timepoints t1,...,tc∈[T]. SincePmay be randomized, both cand\nt1,...,tcare random variables. Crucially, since Pis lazy, for every i∈{0,...,c+ 1}, the predictions\nmade byPon timepoints strictly between tiandti+1are correct and remain unchanged, where we\ntaket0= 0 and tc+1=T+ 1.This means that on round ti, we have that ˆ xti\nti:ti+1−1=xti:ti+1−1.\nTherefore, initializing a fresh copy of an oﬄine learner Bwith the predictions ˆ xti\nti:Tensures thatB\nmakes at most M B(T−ti+ 1,H) mistakes on the stream ( xti,yti),...,(xti+1−1,yti+1−1). Repeating\nthis argument for all adjacent pairs of timepoints in {t1,...,tc}, gives the following strategy: initialize\na new oﬄine learner Bevery timePmakes a mistakes, and use Bto make predictions until the next\ntimePmakes a mistake. Algorithm 3implements this idea.\nAlgorithm 3 Online Learner\nInput:Hypothesis classH, Oﬄine learnerB, Time horizon T\n1Initialize: i= 0\n2fort= 1,...,Tdo\n3Receivextfrom Nature.\n4Receive predictions ˆ xt\n1:Tfrom PredictorPsuch that ˆ xt\n1:t=x1:t.\n5ift= 1orˆxt−1\nt/n⌉}ationslash=xt(i.e.Pmade a mistake) then\n6 LetBibe a new copy of Binitialized with the sequence ˆ xt\nt:Tand seti←i+1.\n7QueryBion example xtand play its returned prediction ˆ yt.\n8Receive true label ytfrom Nature and pass it to Bi.\n9end\nLemma 7. For everyH ⊆ YX, PredictorP, no-regret oﬄine learner B, and realizable stream\n(x1,y1),...,(xT,yT), Algorithm 3makes at most (MP(x1:T)+1)M B(T,H)mistakes in expectation.\nProof.LetAdenote Algorithm 3, (x1,y1),...,(xT,yT) denote the realizable stream to be observed by\nA, andh⋆∈Hto be the labeling hypothesis. Let cbe the random variable denoting the number\nof mistakes made by Predictor Pon the stream and t1,...,tcbe the random variables denoting the\ntime points where Pmakes these errors (e.g . ˆ xti−1\nti/n⌉}ationslash=xti). Note that ti≥2 for all i∈[c].We will\nshow pointwise for every value of candt1,...,tcthatAmakes at most ( c+1)M B(T,H) mistakes in\nexpectation over the randomness of B. Taking an outer expectation with respect to the randomness\nofPand using the fact that /BX[c] = MP(x1:T), completes the proof.\nFirst, consider the case where c= 0 (i.e.Pmakes no mistakes). Then, since Pis lazy, we have\nthat ˆxt\n1:T=x1:Tfor every t∈[T]. Thus line 5 ﬁres exactly once on round t= 1,Ainitializes an oﬄine\nlearnerB1withx1:T, andAusesB1to make its prediction on all rounds. Thus, Amakes at most\nMB(T,H) mistakes in expectation.\nNow, let c >0 andt1,...,tcbe the time points where Perrs. Partition the sequence 1 ,...,Tinto\nthe disjoint intervals (1 ,...,t1−1), (t1,...,t2−1),...,(tc,...,T). Deﬁne t0:= 1 and tc+1:=T. Fix an\ni∈{0,...,c}. Observe that for every j∈{ti,...,ti+1−1}, we have that ˆ xj\n1:ti+1−1=xti+1−1. This comes\nfrom the fact that Pdoes not error on timepoints ti+1,...,ti+1−1 and is both consistent and lazy\n(see Assumptions 1and2). Thus, line 5 ﬁres on round ti,Ainitializes an oﬄine learner Biwith the\nsequence ˆ xti\nti:T=xti:ti+1−1◦ˆxti\nti+1:T, andAusesBiit to make predictions for all remaining timepoints\nti,...,ti+1−1. Note that line 5 does not ﬁre on timepoints ti+1,...,ti+1−1.\n7\n\nConsider the hypothetical labeled stream of examples\n(ˆxti\nti,h⋆(ˆxti\nti)),...,(ˆxti\nT,h⋆(ˆxti\nT)) = (xti,yti),...,(xti+1−1,yti+1−1),(ˆxti\nti+1,h⋆(ˆxti\nti+1)),...,(ˆxti\nT,h⋆(ˆxti\nT)).\nBy deﬁnition,Bi, after initialized with ˆ xti\nti:T, makes at most M B(T−ti+1,H) mistakes in expectation\nwhen simulated on the stream (ˆ xti\nti,h⋆(ˆxti\nti)),...,(ˆxti\nT,h⋆(ˆxti\nT)). Thus,Bimakes at most M B(T,H) mis-\ntakesinexpectationonthe preﬁx(ˆxti\nti,h⋆(ˆxti\nti)),...,(ˆxti\nti+1−1,h⋆(ˆxti\nti+1−1)) = (xti,yti),...,(xti+1−1,yti+1−1).\nSince on the interval timepoint ti,AinstantiatesBiwith the sequence ˆ xti\nti:Tand proceeds to simulate\nBion the sequence of labeled examples ( xti,yti),...,(xti+1−1,yti+1−1),Amakes at most M B(T,H)\nmistakes in expectation on the sequence ( xti,yti),...,(xti+1−1,yti+1−1). Since the interval iwas cho-\nsen arbitrarily, the above analysis is true for every i∈ {0,...,c}and thereforeAmakes at most\n(c+1)M B(T,H) mistakes in expectation over the entire stream. /squaresolid\n3.2 Proof sketch of upper bound (iii) in Theorem 3\nWhen M B(T,H) is large (i.e. Ω(√\nT)), upper bound (ii) is sub-optimal. Indeed, if t1,...,tcdenotes the\ntimepoints where Pmakes mistakes on the stream x1:T, then Algorithm 3initializes oﬄine learners\nwith sequences of length T−ti+1. The resulting mistake-bound of these oﬄine learners are then in\nthe order of T−ti+1, which can be large if t1,...,tcare evenly spaced across the time horizon. To\novercome this, we construct a familyEof online learners, each of which explicitly controls the length\nof the sequences oﬄine learners can be initialized with. Finally, we run D WMA usingEas its set\nof experts. Our family of online learners is parameterized by integer sc∈{0,...,T−1}. Given an\ninputc∈{0,...,T−1}, the online learner parameterized by cpartitions the stream into c+1 roughly\nequally sized parts of size ⌈T\nc+1⌉and runs a fresh copy of Algorithm 3on each partition. In this way,\nthe online learner parameterized by censures that oﬄine learners are initialized with time horizons at\nmost⌈T\nc+1⌉. Algorithm 4formalizes this online learner and Lemma 8, whose proof is in Appendix C,\nbounds its expected number of mistakes.\nAlgorithm 4 Expert(c)\nInput:Copy of Algorithm 3denotedK, Oﬄine Learner B, Time horizon T\n1Initialize: ˜ti=i⌈T\nc+1⌉fori∈{1,...,c},˜t0= 0,and˜tc+1=T.\n2fort= 1,...,Tdo\n3Leti∈{0,...,c}such that t∈{˜ti+1,...,˜ti+1}.\n4ift=˜ti+1then\n5 LetKibe a new copy of Kinitialized with time horizon ˜ti+1−˜tiand a new copy of B.\n6Receivextfrom Nature.\n7Receive predictions ˆ xt\n1:Tfrom PredictorPsuch that ˆ xt\n1:t=x1:t.\n8Forward xtand ˆxt\n˜ti+1:˜ti+1toKivia Lines 2 and 3 of Algorithm 3respectively.\n9Receive ˆytfromKivia line 6 in Algorithm 3and predict ˆ yt.\n10Receive true label ytand forward it to Kivia line 7 in Algorithm 3.\n11end\nLemma 8 (Expert guarantee) .For anyH ⊆ YX, PredictorP, and no-regret oﬄine learner B,\nAlgorithm 4, given as input c∈{0,...,T−1}, makes at most\n(MP(x1:T)+c+1)MB/parenleftBigT\nc+1+1,H/parenrightBig\nmistakes in expectation on any realizable stream (x1,y1),...,(xT,yT).\nNote that when c= 0 and M B(T,H) =MB(T,H), this bound reduces to the one in Lemma 7up\nto a constant factor. On the other hand, using c=⌈MP(x1:T)⌉gives the upper bound\n2(MP(x1:T)+1)MB/parenleftBigT\nMP(x1:T)+1+1,H/parenrightBig\n.\n8\n\nSinceEcontains an Expert parameterized for every c∈{0,...,T−1}, there always exists an expert\nE⌈MP(x1:T)⌉∈Einitialized with input c=⌈MP(x1:T)⌉. Running DWMA using these set of experts\nEon the data stream ( x1,y1),...,(xT,yT) ensures that our learner does not perform too much worse\nthanE⌈MP(x1:T)⌉. Algorithm 5formalizes this idea and Lemma 9is proved in Appendix C.\nAlgorithm 5 Online learner\nInput:Hypothesis classH, Oﬄine learnerB, Time horizon T\n1For every b∈{0,...,T−1}letEbdenote Algorithm 4parameterized by input b.\n2Run the DWMA using {Eb}b∈{0,...,T−1}over the stream ( x1,y1),...,(xT,yT).\nLemma 9. For everyH⊆YX, PredictorP, and no-regret oﬄine learner B, Algorithm 5makes at\nmost\n6/parenleftBigg\n(MP(x1:T)+1)MB/parenleftBigT\nMP(x1:T)+1+1,H/parenrightBig\n+log2T/parenrightBigg\n.\nmistakes in expectation on any realizable stream (x1,y1),...,(xT,yT).\n3.3 Lower bounds\nIn light of Theorem 3, it is natural ask whether the upper bounds derived in Section 3are tight. A\nnotable feature in upper bounds (ii) and (iii) is the product of the two mistake bounds M P(x1:T) and\nMB(T,H). Can this product can be replaced by a sum? Unfortunately, Theo rem10shows that the\nupper bound in Theorem 3can be tight.\nTheorem 10. LetX= [0,1]∪{⋆},Y={0,1}, andH={x/ma√sto→ /BD{x≤a} /BD{x/n⌉}ationslash=⋆}}. LetT,n∈ /C6be\nsuch that n+1dividesTandT\nn+1+1 = 2kfor some k∈ /C6. Then, there exists a Predictor Psuch\nthat for every online learner Athat usesPaccording to Protocol 2, there exists a realizable stream\n(x1,y1),...,(xT,yT)such that MP(x1:T) =nbut/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≥(n+1)\n2log2/parenleftBigT\nn+1/parenrightBig\n.\nTheorem 10shows that the upper bound in Theorem 3is tight up to an additive factor in log2T\nbecauseLemma 1givesthat inf BMB(T,H) =O(VC(H)log2T)and VC(H) = 1.The proofofTheorem\n10is technical and provided in Appendix F. Our proof involves four steps. First, we construct a class\nof streamsZn⊆X⋆. Then, usingZn, we construct a deterministic, lazy, consistent Predictor P\nsuch thatPmakes mistakes exactly on timepoints {T\nn+1+1,...,nT\nn+1+1}for every stream x1:T∈Zn.\nNext, whenever x1:T∈Zn, we establish an equivalence between the game deﬁned by Protocol 2when\ngiven access to Predictor Pand Online Classiﬁcation with Peeks, a diﬀerent game where there is no\nPredictor, but the learner observes the nextT\nn+1examples at timepoints t∈{1,T\nn+1+1,...,nT\nn+1+1}.\nFinally, for Online Classiﬁcation with Peeks, we give a strategy for Nat ure such that it can force any\nonline learner to make(n+1)log2(T\nn+1)\n2mistakes in expectation while ensuring that its selected stream\nsatisﬁesx1:T∈Znand inf h∈H/summationtextT\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}= 0.A key component of the fourth step is the\nstream constructed by [ Hanneke et al. ,2024, Claim 3.4] to show that the minimax mistakes for classes\nwith inﬁnite Ldim is at least log2Tin the oﬄine setting.\nRemark. Although Theorem 10is stated using the class of one dimensional thresholds, it can be\nadapted to hold for any VC class with inﬁnite Ldim as these classes emb ed thresholds [ Alon et al. ,\n2019, Theorem 3].\n4 Discussion\nIn this paper, we initiated the study of online classiﬁcation when the le arner has access to machine-\nlearned predictions about future examples. There are many intere sting directions for future research\nand we list two below. Firstly, we only considered the classiﬁcation set ting, and it would be interested\nto extend our results to online scalar-valued regression. Secondly , we measure the performance of a\n9\n\nPredictor through its mistake-bounds. When Xis continuous, this might be an unrealistic measure of\nperformance. Thus, it would be interesting to see whether our res ults can be generalized to the case\nwhereXis continuous and the guarantee of Predictors is deﬁned in terms of ℓplosses.\nReferences\nMatteo Almanza, Flavio Chierichetti, Silvio Lattanzi, Alessandro Panc onesi, and Giuseppe Re. Online\nfacility location with multiple advice. Advances in Neural Information Processing Systems , 34:\n4661–4673, 2021.\nNoga Alon, Roi Livni, Maryanthe Malliaris, and Shay Moran. Private pa c learning implies ﬁnite\nlittlestone dimension. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theor y of\nComputing , pages 852–860, 2019.\nAntoniosAntoniadis, ChristianCoester,MarekEli´ aˇ s,AdamPolak, andBertrandSimon. Onlinemetric\nalgorithms with untrusted predictions. ACM Transactions on Algorithms , 19(2):1–34, 2023.\nSanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weigh ts update method: a meta-\nalgorithm and applications. Theory of computing , 8(1):121–164, 2012.\nEtienne Bamas, Andreas Maggiori,and OlaSvensson. The primal-dua lmethod for learningaugmented\nalgorithms. Advances in Neural Information Processing Systems , 33:20083–20094, 2020.\nShai Ben-David, Eyal Kushilevitz, and Yishay Mansour. Online learnin g versus oﬄine learning. Ma-\nchine Learning , 29:45–63, 1997.\nShai Ben-David, D´ avid P´ al, and Shai Shalev-Shwartz. Agnostic o nline learning. In COLT, volume 3,\npage 1, 2009.\nAdam Block, Yuval Dagan, Noah Golowich, and Alexander Rakhlin. Smo othed online learning is as\neasy as statistical learning. In Conference on Learning Theory , pages 1716–1786. PMLR, 2022.\nT. Ceccherini-Silberstein, M. Salvatori, and E. Sava-Huss. Groups, Graphs and Random Walks .\nLondon Mathematical Society Lecture Note Series. Cambridge Univ ersity Press, 2017. doi:\n10.1017/9781316576571.\nNicolo Cesa-Bianchi and G´ abor Lugosi. Prediction, learning, and games . Cambridge university press,\n2006.\nJustin Chen, Sandeep Silwal, Ali Vakilian, and Fred Zhang. Faster fun damental graph algorithms via\nlearned predictions. In International Conference on Machine Learning , pages 3583–3602. PMLR,\n2022.\nAmit Daniely, Sivan Sabato, Shai Ben-David, and Shai Shalev-Shwar tz. Multiclass learnability and\nthe erm principle. In Sham M. Kakade and Ulrike von Luxburg, editors ,Proceedings of the 24th\nAnnual Conference on Learning Theory , volume 19 of Proceedings of Machine Learning Research ,\npages 207–232, Budapest, Hungary, 09–11 Jun 2011. PMLR.\nMarek Elias, Haim Kaplan, Yishay Mansour, and Shay Moran. Learning -augmented algorithms with\nexplicit predictors. arXiv preprint arXiv:2403.07413 , 2024.\nJon C Ergun, Zhili Feng, Sandeep Silwal, David P Woodruﬀ, and Samson Zhou. Learning-augmented\nk-means clustering. arXiv preprint arXiv:2110.14094 , 2021.\nSreenivas Gollapudi and Debmalya Panigrahi. Online algorithms for ren t-or-buy with expert advice.\nInInternational Conference on Machine Learning , pages 2319–2327. PMLR, 2019.\nNika Haghtalab. Foundation of Machine Learning, by the People, for the Peopl e. PhD thesis, Carnegie\nMellon University, 2018.\nNika Haghtalab, Tim Roughgarden, and Abhishek Shetty. Smoothed analysis of online and diﬀeren-\ntially private learning. Advances in Neural Information Processing Systems , 33:9203–9215, 2020.\n10\n\nSteve Hanneke, Shay Moran, Vinod Raman, Unique Subedi, and Ambu j Tewari. Multiclass online\nlearning and uniform convergence. Proceedings of the 36th Annual Conference on Learning Theor y\n(COLT), 2023.\nSteve Hanneke, Shay Moran, and Jonathan Shafer. A trichotomy for transductive online learning.\nAdvances in Neural Information Processing Systems , 36, 2024.\nChen-Yu Hsu, Piotr Indyk, Dina Katabi, and Ali Vakilian. Learning-ba sed frequency estimation\nalgorithms. In International Conference on Learning Representations , 2019.\nShaofengH-CJiang, ErzhiLiu, You Lyu, ZhihaoGavinTang, andYub o Zhang. Online facilitylocation\nwith predictions. arXiv preprint arXiv:2110.08840 , 2021.\nTim Kraska, Alex Beutel, Ed H Chi, Jeﬀrey Dean, and Neoklis Polyzotis. The case for learned index\nstructures. In Proceedings of the 2018 international conference on manage ment of data , pages 489–\n504, 2018.\nSilvio Lattanzi, Thomas Lavastida, Benjamin Moseley, and Sergei Va ssilvitskii. Online scheduling\nvia learned weights. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete\nAlgorithms , pages 1859–1877. SIAM, 2020.\nHonghaoLin, TianLuo,andDavidWoodruﬀ. Learningaugmentedbina rysearchtrees. In International\nConference on Machine Learning , pages 13431–13440. PMLR, 2022.\nNicholas Littlestone. Mistake bounds and logarithmic linear-threshold learning algorithms . University\nof California, Santa Cruz, 1989.\nNick Littlestone. Learning quickly when irrelevant attributes aboun d: A new linear-threshold algo-\nrithm.Machine Learning , 2:285–318, 1987.\nNick Littlestone. Learning quickly when irrelevant attributes aboun d: A new linear-threshold algo-\nrithm.Machine learning , 2:285–318, 1988.\nThodoris Lykouris and Sergei Vassilvitskii. Competitive caching with m achine learned advice. Journal\nof the ACM (JACM) , 68(4):1–25, 2021.\nMichael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predic tions.Communications of the\nACM, 65(7):33–35, 2022.\nManish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algo rithms via ml predictions.\nAdvances in Neural Information Processing Systems , 31, 2018.\nAlexander Rakhlin, Karthik Sridharan, and Ambuj Tewari. Online learn ing: Stochastic, constrained,\nand smoothed adversaries. Advances in neural information processing systems , 24, 2011.\nTim Roughgarden. Beyond the worst-case analysis of algorithms . Cambridge University Press, 2021.\nZiv Scully, Isaac Grosof, and Michael Mitzenmacher. Uniform bound s for scheduling with job size\nestimates. arXiv preprint arXiv:2110.00633 , 2021.\nDaniel A Spielman and Shang-Hua Teng. Smoothed analysis: an attem pt to explain the behavior of\nalgorithms in practice. Communications of the ACM , 52(10):76–84, 2009.\nShufan Wang, Jian Li, and Shiqiang Wang. Online algorithms for multi-sh op ski rental with machine\nlearned advice. Advances in Neural Information Processing Systems , 33:8150–8160, 2020.\nAlexander Wei and Fred Zhang. Optimal robustness-consistency trade-oﬀs for learning-augmented\nonline algorithms. Advances in Neural Information Processing Systems , 33:8042–8053, 2020.\nChanglong Wu, Ananth Grama, and Wojciech Szpankowski. Online lear ning in dynamically changing\nenvironments. In The Thirty Sixth Annual Conference on Learning Theory , pages 325–358. PMLR,\n2023.\n11\n\nA More Related Works\nOnline Algorithms with Predictions. OnlineAlgorithmswith Predictions(OAwP)hasemergedas\nan important paradigmlying at the intersection of classical online algo rithm design and machine learn-\ning. Manyfundamentalonlinedecision-makingproblemsincludingskir ental[Gollapudi and Panigrahi ,\n2019,Wang et al. ,2020,Bamas et al. ,2020], online scheduling [ Lattanzi et al. ,2020,Wei and Zhang ,\n2020,Scully et al. ,2021], online facility location [ Almanza et al. ,2021,Jiang et al. ,2021], caching\n[Lykouris and Vassilvitskii ,2021,Elias et al. ,2024],andmetricaltasksystems[ Antoniadis et al. ,2023],\nhave been analyzed under this framework. Recently, Elias et al. [2024] consider a model where the\npredictor is allowed to learn and adapt its predictions based on the ob served data. This is contrast\nto previous work on learning-augmented online algorithms, where pr edictions are made from machine\nlearning models trained on historical data, and thus their prediction s are static and non-adaptive to\nthe current task at hand. Elias et al. [2024] study a number of fundamental problems, like caching and\nscheduling, and show how explicitly designed predictors can lead to imp roved performance bounds.\nIn this work, we consider a model similar to Elias et al. [2024], where the predictions available to the\nlearning algorithms are not ﬁxed, but rather adapt to the true seq uence of data processed by the learn-\ning algorithm. However, unlike Elias et al. [2024], we do not hand-craft these predictions, but rather\nassume our learning algorithms have black-box access to a machine- learned prediction algorithm.\nTransductive Online Learning. In the Transductive Online Learning setting, Nature reveals the\nentire sequence of examples x1,...,xTto the learner beforethe game begins. The goal of the learner is\nto predict the corresponding labels y1,...,yTin order, receiving the true label ytonly after making the\nprediction ˆ ytfor example xt. First studied by Ben-David et al. [1997], recent work by Hanneke et al.\n[2024] has established the minimax rates on expected mistakes/regret in the realizable/agnostic set-\ntings. In the context of online classiﬁcation with predictions, one ca n think of the transductive online\nlearning setting as a special case where the Predictor never makes mistakes.\nSmoothed Online Classiﬁcation. In addition to AwP, smoothed analysis [ Spielman and Teng ,\n2009] is another important sub-ﬁeld of beyond-worst-case analysis of algorithms. By placing dis-\ntributional assumptions on the input, one can typically go beyond co mputational and information-\ntheoretic bottlenecks due to worst-case inputs. To this end, Rakhlin et al. [2011],Haghtalab [2018],\nHaghtalab et al. [2020],Block et al. [2022] consider a smoothed online classiﬁcation model. Here, the\nadversary has to choose and draw examples from suﬃciently anti-c oncentrated distributions. For\nbinary classiﬁcation, Haghtalab [2018] andHaghtalab et al. [2020] showed that smoothed online learn-\nability is as easy as PAC learnability. That is, the ﬁniteness of a smallercombinatorial parameter\ncalled the VC dimension is suﬃcient for smoothed online classiﬁcation. I n this work, we also go be-\nyond the worst-case analysis standard in online classiﬁcation, but c onsider a diﬀerent model where the\nadversary is constrained to reveal a sequence of examples that a repredictable . In this model, we also\nshow that the VC dimension can be suﬃcient for online learnability.\nB Combinatorial dimensions\nIn this section, we review existing combinatorial dimensions in statist ical learning theory. We start\nwith the VC and Natarajandimensions which characterizePAClearna bility when|Y|= 2 and|Y|<∞\nrespectively.\nDeﬁnition 2 (VC dimension) .A set{x1,...,xn}∈Xis shattered byH, if∀y1,...,yn∈{0,1},∃h∈H,\nsuchthat∀i∈[n],h(xi) =yi. The VC dimension of H, denoted VC(H), is deﬁned as the largest natural\nnumbern∈ /C6such that there exists a set {x1,...,xn}∈Xthat is shattered by H.\nDeﬁnition 3 (Natarajan Dimension) .A setS={x1,...,x d}is shattered by a multiclass function\nclassH⊆YXif there exist two witness functions f,g:S→Ysuch that f(xi)/n⌉}ationslash=g(xi)for alli∈[d],\nand for every σ∈{0,1}d, there exists a function hσ∈Hsuch that for all i∈[d], we have\nhσ(xi) =/braceleftBigg\nf(xi)ifσi= 1\ng(xi)ifσi= 0.\nThe Natarajan dimension of H, denoted N(H), is the size of the largest shattered set S⊆X. If the\nsize of the shattered set can be arbitrarily large, we say tha tN(H) =∞.\n12\n\nWe note that N(H) = VC(H) whenever|Y|= 2.Next, we move to the online setting, where the\nLittlestone dimension (Ldim) characterizes multiclass online learnabilit y. To deﬁne the Ldim, we ﬁrst\ndeﬁne a Littlestone tree and a notion of shattering.\nDeﬁnition 4 (Littlestone tree) .A Littlestone tree of depth dis acomplete binary tree of depth d\nwhere the internal nodes are labeled by examples of Xand the left and right outgoing edges from each\ninternal node are labeled by 0and1respectively.\nGivenaLittlestonetree Tofdepth d, aroot-to-leafpathdown Tisabitstring σ∈{0,1}dindicating\nwhether to go left ( σi= 0) or to go right ( σi= 1) at each depth i∈[d]. A path σ∈{0,1}ddownT\ngives a sequence of labeled examples {(xi,σi)}d\ni=1, wherexiis the example labeling the internal node\nfollowing the preﬁx ( σ1,...,σi−1) down the tree. A hypothesis hσ∈Hshatters a path σ∈{0,1}d,\nif for every i∈[d], we have hσ(xi) =σi. In other words, hσis consistent with the labeled examples\nwhen following σ. A Littlestone tree Tis shattered byHif for every root-to-leaf path σdownT, there\nexists a hypothesis hσ∈Hthat shatters it. Using this notion of shattering, we deﬁne the Litt lestone\ndimension of a hypothesis class.\nDeﬁnition 5 (Littlestone dimension) .The Littlestone dimension of H, denoted L(H), is the largest\nd∈ /C6such that there exists a Littlestone tree Tof depth dshattered byH. If there exists shattered\nLittlestone treesTof arbitrary depth, then we say that L(H) =∞.\nFinally, the following notion of shattering is useful when proving the lo wer bound in Appendix F.\nDeﬁnition 6 (Threshold shattering) .A sequence (x1,...,xk)∈ Xkis threshold-shattered by H ⊆\n{0,1}Xif there exists (h1,...,hk)∈Hksuch that hi(xj) = /BD{j≤i}for alli,j∈[k].\nC Proof of Lemmas 8and9\nProof.(of Lemma 8) Let (x1,y1),...,(xT,yT) be the realizable stream to be observed by the Expert.\nFor every i∈{0,...,c}, letmibe the random variable denoting the number of mistakes made by Pin\nrounds{˜ti+1,...,˜ti+1}.Recall that ˜t0= 0 and ˜tc+1=T. LetM=/summationtextc\ni=0mibe the random variable\ndenoting the total number of mistakes made by Pon the realizable stream. Finally, let Adenote\nAlgorithm 4. Observe that,/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n= /BX\nc/summationdisplay\ni=0˜ti+1/summationdisplay\nt=˜ti+1\n/BD{A(xt)/n⌉}ationslash=yt}\n\n= /BX\nc/summationdisplay\ni=0˜ti+1/summationdisplay\nt=˜ti+1\n/BD{Ki(xt)/n⌉}ationslash=yt}\n\n≤ /BX/bracketleftBiggc/summationdisplay\ni=0(mi+1)MB(˜ti+1−˜ti,H)/bracketrightBigg\n13\n\nwhere the ﬁrst inequality follows from the guarantee of Kand Lemma 2. Using Jensen’s inequality,\nwe get that/BX/bracketleftBiggc/summationdisplay\ni=0(mi+1)MB(˜ti+1−˜ti,H)/bracketrightBigg\n≤ /BX/bracketleftBigg/parenleftBiggc/summationdisplay\ni=0(mi+1)/parenrightBigg\nMB/parenleftBigg/summationtextc\ni=0(mi+1)(˜ti+1−˜ti)/summationtextc\ni=0(mi+1),H/parenrightBigg/bracketrightBigg\n= /BX/bracketleftBigg/parenleftBig\nM+c+1/parenrightBig\nMB/parenleftBigg/summationtextc\ni=0(mi+1)(˜ti+1−˜ti)\nM+c+1,H/parenrightBigg/bracketrightBigg\n= /BX/bracketleftBigg/parenleftBig\nM+c+1/parenrightBig\nMB/parenleftBigg/summationtextc\ni=0mi(˜ti+1−˜ti)+T\nM+c+1,H/parenrightBigg/bracketrightBigg\n= /BX/bracketleftBigg/parenleftBig\nM+c+1/parenrightBig\nMB/parenleftBigg\n⌈T\nc+1⌉/summationtextc\ni=0mi(i+1−i)+T\nM+c+1,H/parenrightBigg/bracketrightBigg\n= /BX/bracketleftBigg/parenleftBig\nM+c+1/parenrightBig\nMB/parenleftBigg\n⌈T\nc+1⌉M+T\nM+c+1,H/parenrightBigg/bracketrightBigg\n.\nUsing the fact that ⌈T\nc+1⌉≤T\nc+1+1, we have/BX\nc/summationdisplay\ni=0mi/summationdisplay\nj=0MB(˜ti+1−˜ti,H)\n≤ /BX/bracketleftBigg/parenleftBig\nM+c+1/parenrightBig\nMB/parenleftBiggMT\nc+1+M+T\nM+c+1,H/parenrightBigg/bracketrightBigg\n≤ /BX/bracketleftBigg/parenleftBig\nM+c+1/parenrightBig\nMB/parenleftBigg\nT\nc+1+1,H/parenrightBigg/bracketrightBigg\n=/parenleftBig\nMP(x1:T)+c+1/parenrightBig\nMB/parenleftBigg\nT\nc+1+1,H/parenrightBigg\n,\nwhich completes the proof. /squaresolid\nProof.(of Lemma 9) Let (x1,y1),...,(xT,yT) be the realizable stream to be observed by the learner.\nLetAdenote the online learner in Algorithm 5. By the guarantees of the DWMA, we have/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤3 /BX/bracketleftBigg\ninf\nb∈{0,...,T−1}T/summationdisplay\nt=1\n/BD{Eb(xt)/n⌉}ationslash=yt}/bracketrightBigg\n+3log2T\n≤3 /BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{E⌈MP(x1:T)⌉(xt)/n⌉}ationslash=yt}/bracketrightBigg\n+3log2T\n≤3(MP(x1:T)+⌈MP(x1:T)⌉+1)MB/parenleftBigT\n⌈MP(x1:T)⌉+1+1,H/parenrightBig\n+3log2T\n≤6(MP(x1:T)+1)MB/parenleftBigT\nMP(x1:T)+1+1,H/parenrightBig\n+6log2T,\nwherethelastinequalityfollowsfromLemma 8andthefactthatM P(x1:T)≤⌈MP(x1:T)⌉≤MP(x1:T)+\n1. /squaresolid\nD Proof of Corollary 4and5\nUsing Theorem 3, we ﬁrst show that for every H⊆YX, PredictorP,Z⊆X⋆, and no-regret oﬄine\nlearnerB, we have that\ninf\nAMA(T,H,Z) =O/parenleftBigg\nL(H)∧(MP(T,Z)+1)M B(T,H)∧/parenleftBigg\n(MP(T,Z)+1)MB/parenleftBigT\nMP(T,Z)+1,H/parenrightBig\n+log2T/parenrightBigg/parenrightBigg\n.\n14\n\nProof.It suﬃces to show that Algorithms 3and5have mistake bounds O((MP(T,Z)+1)M B(T,H))\nandO/parenleftBigg\n(MP(T,Z)+1)MB/parenleftBig\nT\nMP(T,Z)+1,H/parenrightBig\n+log2T/parenrightBigg\nrespectively. To see that Algorithm 3’s mistake\nbounds is O((MP(T,Z)+1)M B(T,H)), note that M P(x1:T)≤MP(T,Z) for every x1:T∈Z.To see\nthat Algorithm 5’s expected mistake bound is O/parenleftBigg\n(MP(T,Z) + 1)MB/parenleftBig\nT\nMP(T,Z)+1,H/parenrightBig\n+log2T/parenrightBigg\n, we\nfollow the exact same proof strategy as in the proof of Lemma 9, but picking a diﬀerent expert when\nupper bounding the expected number of mistakes. Namely, following the same steps as in the proof of\nLemma9, we have that/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤3 /BX/bracketleftBigg\ninf\nb∈{0,...,T−1}T/summationdisplay\nt=1\n/BD{Eb(xt)/n⌉}ationslash=yt}/bracketrightBigg\n+3log2T\nwhereAdenotes Algorithm 5. Picking b=⌈MP(T,Z)⌉, using Lemma 8, and the fact that M P(x1:T)≤\nMP(T,Z) gives the desired upper bound on /BX/bracketleftBig/summationtextT\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBig\nof\nO/parenleftBigg\n(MP(T,Z)+1)MB/parenleftBigT\nMP(T,Z)+1,H/parenrightBig\n+log2T/parenrightBigg\n, (1)\ncompleting the proof. /squaresolid\nCorollary 4follows from the fact that the upper bound on inf AMA(T,H,Z) is sublinear whenever\nMP(T,Z) =o(T) and M B(T,H) =o(T).To get Corollary 5, recall that by Lemma 1, there exists an\noﬄine learnerBsuch that\nMB(T,H) =O/parenleftBig\nVC(H)log2T/parenrightBig\n.\nPlugging this bound into upper bound ( 1) completes the proof.\nE Proof of Theorem 3\nLetAdenote the DWMA using the Standard Optimal Algorithm (SOA), Algor ithm3and Algorithm\n5as experts. Then, for any realizable stream ( x1,y1),...,(xT,yT), Lemma 6gives that/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤3 /BX/bracketleftbigg\nmin\ni∈[3]Mi+log23/bracketrightbigg\n≤3min\ni∈[3]\n/BX[Mi]+5,\nwhere we take M1,M2andM3to be the number of mistakes made by the SOA, Algorithm 3, and\nAlgorithm 5respectively. Notethat M2andM3arerandomvariablessince BandPmayberandomized\nalgorithms. Finally, using Lemma 7, Lemma 9and the fact that the SOAmakesat most L( H) mistakes\non any realizable stream [ Littlestone ,1987] completes the proof of Theorem 3.\nF Proof of Theorem 10\nLetX= /CA∪{⋆}andH={x/ma√sto→ /BD{x≤a} /BD{x/n⌉}ationslash=⋆}}. LetT,n∈ /C6be chosen such that Tis a multiple\nofn+1 andT\nn+1+1 = 2kfor some k∈ /C6. Our proof of Theorem 10will be in four steps, as described\nbelow.\n(1) We construct a class of streams Zn⊆X⋆.\n(2) UsingZn, we construct a deterministic, lazy, consistent Predictor Psuch thatPmakes mistakes\nexactly on timepoints {T\nn+1+1,...,nT\nn+1+1}for every stream x1:T∈Zn.\n15\n\n(3) When x1:T∈Zn, we establish an equivalence between the game deﬁned by Protocol 2when\ngiven access to Predictor Pand Online Classiﬁcation with Peeks, a diﬀerent game where there\nis no Predictor, but the learner observes the nextT\nn+1examples at timepoints t∈{1,T\nn+1+\n1,...,nT\nn+1+1}.\n(4) For Online Classiﬁcation with Peeks, we give a strategy for Natur e such that it can force any\nonline learner to make(n+1)log2(T\nn+1)\n2mistakes in expectation while ensuring that the stream\nof labeled examples it picks ( x1,y1),...,(xT,yT) satisﬁes the constraint that x1:T∈ Znand\ninfh∈H/summationtextT\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}= 0.\nComposing steps 1-4 shows the existence of a Predictor Psuch that for any learner Aplaying\nProtocol 2usingP, there exists a realizable stream where Amakes at least(n+1)\n2log2(T\nn+1) mistakes\nin expectation.\nStep 1: Construction of Zn\nLetSbe the set of all strictlyincreasing sequences of real numbers in (0 ,1) of sizeT\nn+1. Fix a function\nf: /CA2→Swhich, given a < b∈ /CA, outputs an element of Sthat lies strictly in between aand\nb. For example, given a < b∈ /CA, the function fcan output evenly spaced real numbers of size\nT\nn+1. Let Dyd :S→XT\nn+1be a function that reorders the input S∈Sin Dyadic order. Namely, if\nS= (x1,...,xN) whereN+1 = 2kfor some k∈ /C6, then Dyd( S) is\nxN\n2,xN\n4,x3N\n4,xN\n8,x3N\n8,x5N\n8,x7N\n8,...,x (2k−1)N\n2k.\nSee the Proof of Claim 3.4 in Hanneke et al. [2024] for a more detailed description of a Dyadic order.\nOn the other hand, let Sort : XT\nn+1→Sbe a function that reorders its input in increasing order.\nLetJ:={1,...,T\nn+1+ 1}≤nbe the set of all sequences of indices of length at most ntaking values\nin{1,...,T\nn+1+ 1}. For the remainder of this section, we will use Sito denote the ith element in a\nsequence S∈S. Moreover, for any two sequences S1,S2∈S, we say S1< S2ifS1\n|S1|< S2\n1.That is,\nS1< S2, ifS1lies strictly to the left of S2.\nAlgorithm 6 Stream Generator (SG)\nInput:S0∈S,j1:m∈J\n1Initialize: a0= 0,b0= 1\n2fori= 1,...,mdo\n3ifji= 1then\n4 Si←f(ai−1,Si−1\n1)\n5 ai←ai−1\n6 bi←Si−1\n1\n7else ifji=T\nn+1+1then\n8 Si←f(Si−1\nT\nn+1,bi−1)\n9 ai←Si−1\nT\nn+1\n10 bi←bi−1\n11else\n12 Si←f(Si−1\nj−1,Si−1\nj)\n13 ai←Si−1\nj−1\n14 bi←Si−1\nj\n15end\n16end\n17Return: Dyd(S0)◦...◦Dyd(Sm)\nWe will construct a stream for every sequence j1:m∈J,m≤n, algorithmically as follows. Fix\nS0:=f(0,1)∈Sand let SG denote Algorithm 6. Let\nZn=/braceleftBig\nSG(S0,j1:m) :j1:m∈J,m∈{1,...,n}/bracerightBig\n16\n\ndenote the stream class generated by applying SG to inputs S0andj1:mfor every j1:m∈J,m≤n.\nWe make four important observations about Zn, which we will use to construct a Predictor that can\nreconstruct SigivenS0and the ﬁrst example of the block Si−1.\nObservation 1. For every sequence x1:T∈Z, we have that x1:T\nn+1= Dyd(S0).\nThe ﬁrst observation follows from the fact that the same initial seq uenceS0is used to generate\nevery stream inZn.\nObservation 2. For any pair j1\n1:n,j2\n1:n∈ Jandm≤n, ifj1\n1:m=j2\n1:m, thenSG(S0,j1\n1:m) =\nSG(S0,j2\n1:m).\nThe second observation follows from the fact that SG is determinist ic.\nObservation 3. For every x1:T∈Znsuch that x1:T:= SG(S0,j1:n) = Dyd( S0)◦...◦Dyd(Sn), the\nindexjican be computed exactly using only Si−1andSi\n1for every i∈[n].\nTo see the third observation, ﬁx some x1:T∈Zn. Then, there exists a sequence S1,...,Sn∈S\nsuch that x1:T= Dyd(S0)◦...◦Dyd(Sn) as well as a sequence ( a0,b0),...,(an,bn). In addition, there\nexists aj1:n∈Jsuch that x1:T= SG(S0,j1;n). Fixi∈[n] and consider Si−1andSi. By deﬁnition\nof Algorithm 6, there exists an index q∈{1,...,T\nn+1+1}such that Si=f(Si−1\nq−1,Si−1\nq) where we take\nSi−1\n0=ai−1andSi−1\nT\nn+1+1=bi−1.We claim that the index qis unique. This follows from the fact\nthat the collection {f(Si−1\nj,Si−1\nj+1)}T\nn+1\nj=0is pairwise disjoint since ai−1=Si−1\n0< Si−1\n1< ... < Si−1\nT\nn+1<\nSi−1\nT\nn+1+1=bi−1. Finally, we claim that Si−1and the element Si\n1identiﬁes the index q. This follows\nbecause f(ai−1,Si−1\n1)< f(Si−1\n1,Si−1\n2)< ... < f (Si−1\nT\nn+1−1,Si−1\nT\nn+1)< f(Si−1\nT\nn+1,bi−1) and thus qis the\nsmallest index p∈{1,...,T\nn+1}such that Si\n1< Si−1\npandT\nn+1+1 if such a pdoes not exist.\nObservation 4. Fix a sequence j1:n∈Jand letDyd(S0)◦...◦Dyd(Sn) = SG(S0,j1:n).For every\ni,p∈[n]such that i < p, we have that:\n(i)Sp< Siifji= 1;\n(ii)Si\nji−1< Sp< Si\njiif2≤ji≤T\nn+1;\n(iii)Si< Spifji=T\nn+1+1.\nThe fourth observation follows from the fact that for every i∈[n] and index ji∈{1,...,T\nn+1+1},\nthe remaining sequence of sets Si+1,...,Snall lie in the interval ( Si\nji−1,Si\nji) by design of Algorithm 6,\nwhere again we take Si−1\n0=ai−1< Si−1\n1andSi−1\nT\nn+1+1=bi−1> Si−1\nT\nn+1.\nStep 2: Constructing a Predictor for Zn\nWe now show that Algorithm 7is a lazy, consistent Predictor for Znthat only makes mistakes at\ntimepoints{T\nn+1+1,...,nT\nn+1+1}.\nLemma 11. For any sequence x1:T∈Zn, Algorithm 7is a lazy, consistent Predictor for Znthat only\nmakes mistakes at timepoints {T\nn+1+1,...,nT\nn+1+1}.\nProof.LetPdenote Algorithm 7andx1:T∈Zn. Then, there exists S1,...,Sn∈Sand a sequence of\nindicesj1:n∈Jsuch that x1:T= Dyd(S0)◦Dyd(S1)◦...◦Dyd(Sn) = SG(S0,j1:n).\nWe now prove that Pmakes mistakes only on timepoints {T\nn+1+1,...,nT\nn+1+1}and no where else.\nOur proof is by induction using the following inductive hypothesis. For everyi∈{1,...,n}, we have\nthatP:\n(i) setsJ1:i=j1:ion roundiT\nn+1+1;\n(ii) makes mistakes on rounds {T\nn+1+1,2T\nn+1+1,...,iT\nn+1+1}and no where in between.\n17\n\nAlgorithm 7 Predictor forZn\nInput:Zn\n1Initialize: J= ()\n2fort= 1,..,Tdo\n3Receivext\n4ift= 1then\n5 Set ˆxt\n1:T= Dyd(S0)◦ˆxT\nn+1+1:Twhere ˆxT\nn+1+1:T= (⋆,...,⋆).\n6else ift=iT\nn+1+1for some i∈{1,...,n}then\n7 LetS= Sort(xt−T\nn+1:t−1) be the lastT\nn+1examples sorted in increasing order.\n8 Find the smallest j∈{1,...,T\nn+1}such that xt< Sj. If no such jexists, set j=T\nn+1+1.\n9 UpdateJ←J◦j.\n10 Set ˆxt\n1:T= SG(S0,J)◦ˆxt+T\nn+1:Twhere ˆxt+T\nn+1:T= (⋆,...,⋆).\n11else\n12 Set ˆxt\n1:T←ˆxt−1\n1:T.\n13end\n14Predict ˆxt\n1:T.\n15end\nFor the base case, let i= 1.Pdoes not make any mistakes in {1,2,...,T\nn+1}since it knows S0using\nZn, computes x1:T\nn+1= Dyd(S0) in line 5, and does not change its prediction until roundiT\nn+1+ 1\nbased on line 6. At time point t1=T\nn+1+ 1,Pmakes a mistake since ˆ xt1−1\nt1=⋆/n⌉}ationslash=xt1. Moreover,\nusing Observation 3, the index j∈{1,...,T\nn+1}computed in round t1on line 8 matches j1. Thus, we\nhave that J1=j1. This completes the base case.\nNow for the induction step, let i∈{2,...,n}. Suppose that the induction step is true for i−1. This\nmeans thatP:\n(i) setsJ1:i−1=j1:i−1on round(i−1)T\nn+1+1;\n(ii) makes mistakes on rounds {T\nn+1+1,2T\nn+1+1,...,(i−1)T\nn+1+1}and no where in between.\nWe need to show that PsetsJi=jion roundiT\nn+1+1,Pmakes no mistakes between(i−1)T\nn+1+2 and\niT\nn+1, but makes a mistake atiT\nn+1+1.At timepoint ti−1=(i−1)T\nn+1+1,Pcomputes Ji−1=ji−1(by\nassumption) and thus sets ˆ xti−1\n1:T= SG(S0,J1:i−1) = SG(S0,(j1,...,ji−1)) = Dyd( S0)◦...◦Dyd(Si−1)\nusing Observation 2. Therefore,Ppredicts on round ti−1the sequence ˆ xti−1\n1:T=x1:iT\nn+1◦(⋆,...,⋆),\nimplying thatPmakes no mistakes for rounds(i−1)T\nn+1+2,...,iT\nn+1since it does not change its prediction\nuntil roundiT\nn+1+1 by line 12. However, since ˆ xti−1\nti=⋆,Pmakes a mistake on round ti=iT\nn+1+1.\nFinally, by Observation 3, the example xtiand the previously observed sequence xti−1:ti−1gives away\nji, thusPsetsJi=jion line 8 in round t=iT\nn+1+ 1. This completes the induction step and the\nproof of the claim that Ponly makes mistakes on timepoints {T\nn+1+ 1,...,nT\nn+1+ 1}.To see that\nPis lazy, observe that by line 12, Pdoes not update its prediction on rounds in between those in\n{T\nn+1+1,...,nT\nn+1+1}.To see thatPis consistent, note that Puses preﬁxes of j1,...,jn,S0, and SG\nto compute its predictions in line 10. Thus, consistency follows from O bservation 2. /squaresolid\nStep 3: Equivalence to Online Classiﬁcation with Peeks\nForany stream x1:T∈Zn, havingaccessto the Predictorspeciﬁed byAlgorithm 7implies that at every\nt∈{1,T\nn+1+1,...,nT\nn+1+1}, the learner observes predictions ˆ xt\n1:Twhere ˆxt\n1:t−1=x1:t−1, ˆxt\nt:t+T\nn+1=\nxt:t+T\nn+1, and ˆxt\nt+T\nn+1+1:T= (⋆,...,⋆).Accordingly, at the timepoints t∈{1,T\nn+1+1,...,nT\nn+1+1}, the\nlearner observes the nextT\nn+1−1 examples xt:t+T\nn+1in the stream, but learns nothing about the future\nexamples xt+T\nn+1+1:T.In addition, for timepoints in between those in {1,T\nn+1+ 1,...,nT\nn+1+ 1}, the\nlearner does not observe any new information from Psince by line 12 in Algorithm 7, ˆxi\n1:T= ˆxi+r\n1:Tfor\n18\n\neveryi∈{1,T\nn+1+1,...,nT\nn+1+1}andr∈{1,...,T\nn+1−1}. As a result, whenever x1:T∈Zn, Protocol\n2with the Predictor speciﬁed by Algorithm 7is equivalent to the setting we call Online Classiﬁcation\nwith Peeks where there is no Predictor, but the learner observes t he nextT\nn+1−1 examples exactly at\ntimepoints t∈{1,T\nn+1+1,...,nT\nn+1+1}. Indeed, by having knowledge of the nextT\nn+1−1 examples\nexactly at timepoints t∈{1,T\nn+1+1,...,nT\nn+1+1}, a learner for Online Classiﬁcation with Peeks can\nsimulate a Predictor that acts like Algorithm 7. Likewise, a learner for Online Classiﬁcation with\nPredictions can use Algorithm 7to simulate an adversary that reveals the nextT\nn+1−1 examples\nexactly at timepoints t∈{1,T\nn+1+1,...,nT\nn+1+1}. Accordingly, we consider Online Classiﬁcation with\nPeeks for the rest of the proof and show how Nature can force th e lower bound in Theorem 10under\nthis new setting.\nStep 4: Nature’s Strategy for Online Classiﬁcation with Pee ks\nLetAbe any online learner and consider the game where the learner Aobserves the nextT\nn+1−1\nexamples at timepoints {1,T\nn+1+ 1,...,nT\nn+1+ 1}. We construct a hard stream for Ain this setting.\nWe ﬁrst describe a minimax optimal oﬄinestrategy for Nature when it is forced to play a sequence\nof examples S∈Ssorted in Dyadic order.\nAlgorithm 8 Nature’s Minimax Oﬄine Strategy\nInput:˜S= Dyd(S) for some S∈S, Version space V⊆{0,1}X\nInitialize: V1=V\nReveal˜Sto the learnerA.\nfort= 1,...,T\nn+1do\nObserve the probability ˆ ptofApredicting label 1.\nifˆpt≥1/2then\nIf there exists h∈Vtsuch that h(xt) = 0, reveal true label yt= 0. Else, reveal yt= 1.\nelse\nIf there exists h∈Vtsuch that h(xt) = 1, reveal true label yt= 1. Else, reveal yt= 0.\nUpdateVt+1={h∈Vt:h(xt) =yt}.\nend\nReturn: True labels y1,...y T\nn+1, Version space VT\nn+1+1\nLemma 12. For any learnerA,˜S= Dyd(S), and Version space V⊆{0,1}X, Algorithm 8forcesA\nto make at least1\n2log2(T\nn+1)mistakes in expectation if Sis threshold-shattered (Deﬁnition 6) byV.\nProof.The lemma follows directly from Theorem 3.4 in Hanneke et al. [2024]. /squaresolid\nFor the deﬁnition of threshold-shattering, see Appendix B. Note that for every input ˜S= Dyd(S)\nandV⊆{0,1}Xto Algorithm 8, its output version space V|˜S|+1is non-empty and consistent with\nthe sequence ( ˜S1,y1),...,(˜ST\nn+1,yT\nn+1) as long as|V|>0.This property will be crucial when proving\nLemma14. We are now ready to describe Nature’s strategy for Online Classiﬁc ation with Peeks. The\npseudocode is provided in Algorithm 9.\nWe establish a series of important lemmas.\nLemma 13. For every learner A, if(x1,y1),...,(xT,yT)is the stream the output of Algorithm 9when\nplaying againstA, thenx1:T∈Zn.\nProof.Fix a learnerAand let ( x1,y1),...,(xT,yT) denote the output of Algorithm 9playing against\nA. Letj1:ndenote the sequences of indices output by Algorithm 9. Then, since SG is deterministic,\nby line 6-7 in Algorithm 9, we have that x1:T= SG(S0,(j1,...,jn))∈Zn. /squaresolid\nLemma 14. For every learner A, if(x1,y1),...,(xT,yT)is the stream the output of Algorithm 9when\nplaying againstA, then(x1,y1),...,(xT,yT)is realizable byH.\nProof.Fix a learnerAand let (x1,y1),...,(xT,yT) be the output of Algorithm 9when playing against\nA. LetV2,...,Vn+2be the sequence of version spaces output by Algorithm 9. It suﬃces to show that\nVn+2is not empty and is consistent with ( x1,y1),...,(xT,yT). Our proof will be by induction using\n19\n\nAlgorithm 9 Nature’s Strategy for Online Classiﬁcation with Peeks\nInput:LearnerA, Hypothesis class H\n1Initialize: V1=H\n2fori= 1,..,n+1do\n3ifi= 1then\n4 Setx1:T\nn+1= Dyd(S0) and reveal it to the learner A.\n5else\n6 Compute S= SG(S0,(j1,...,ji−1)).\n7 Letx(i−1)T\nn+1+1:iT\nn+1be the lastT\nn+1examples in Sand reveal it to the learner A.\n8Play againstAaccording to Algorithm 8usingx(i−1)T\nn+1+1:iT\nn+1and version space Vi.\n9Lety(i−1)T\nn+1+1,...,y iT\nn+1be the returned labels and Vi+1⊆Vibe the returned version space.\n10Let ˜y(i−1)T\nn+1+1,...,˜yiT\nn+1be the sequence of true labels after sorting\n(x(i−1)T\nn+1+1,y(i−1)T\nn+1+1),...,(xiT\nn+1,yiT\nn+1)\n11in increasing order with respect to the examples.\n12if˜yiT\nn+1= 1then\n13 Setji=T\nn+1+1.\n14else\n15 Setjito be the smallest p∈{1,...,T\nn+1}such that ˜ y(i−1)T\nn+1+p= 0.\n16end\n17Return: Stream ( x1,y1),...,(xT,yT), indices j1:n, and version spaces V1,...,Vn+2.\nthe following hypothesis: Vi+1is non-empty and consistent with the sequence ( x1,y1),...,(xiT\nn+1,yiT\nn+1).\nFor the base case, let i= 1. Then, by Algorithm 8, line 8 in Algorithm 9, and the fact that |V1|=\n|H|>0, we have that|V2|>0 andV2is consistent with ( x1,y1),...,(xT\nn+1,yT\nn+1). Now consider some\ni≥2 and suppose the induction hypothesis is true for i−1, Then, we know that |Vi|>0 andViis\nconsistent with ( x1,y1),...,(x(i−1)T\nn+1,y(i−1)T\nn+1).Again, by design of Algorithm 8and line 9 in Algorithm\n9, it follows that|Vi+1|>0 andVi+1is consistent with ( x(i−1)T\nn+1+1,y(i−1)T\nn+1+1),...,(xiT\nn+1,yiT\nn+1).Since\nVi+1⊆Vi, andViis consistent with ( x1,y1),...,(x(i−1)T\nn+1,y(i−1)T\nn+1), we get that Vi+1is consistent with\n(x1,y1),...,(xiT\nn+1,yiT\nn+1), completing the induction step. /squaresolid\nLemma 15. For every learner A, if(x1,y1),...,(xT,yT)andV1,...,Vn+2are stream and version spaces\noutput by Algorithm 9when playing against A, then for every i∈{1,...,n+1}, the version space Vi\nthreshold-shatters x(i−1)T\nn+1+1:iT\nn+1.\nProof.Fix a learnerAand let ( x1,y1),...,(xT,yT) denote the output of Algorithm 9playing against\nA. Letj1:nandV1,...,Vn+2denote the sequences of indices and version spaces output by Algo rithm\n9respectively. Note that x1:T= SG(S0,j1:n). Moreover, for every i∈ {2,...,n}, we have that\nx1:iT\nn+1= SG(S0,(j1,...,ji−1)) by lines 6-7.\nFix ani∈{1,...,n+ 1}. It suﬃces to show that the hypotheses parameterized by x(i−1)T\nn+1+1:iT\nn+1\nbelong in Vi. Our proof will be by induction. For the base case, since V1=H, it trivially follows\nthat the hypothesis parameterized by x(i−1)T\nn+1+1:iT\nn+1belong to V1. Now, suppose that x(i−1)T\nn+1+1:iT\nn+1\nbelong to Vmfor some m < i. We show that Vm+1also contains the hypothesis parameterized by\nx(i−1)T\nn+1+1:iT\nn+1. Recall that Vm+1⊆Vmis the subset of Vmthat is consistent with the labeled data\n(x(m−1)T\nn+1+1,y(m−1)T\nn+1+1),...,(xmT\nn+1,ymT\nn+1)\nand is the result of running Algorithm 8with input version space Vmand sequence x(m−1)T\nn+1+1:mT\nn+1. It\n20\n\nsuﬃces to show that the hypotheses parameterized by x(i−1)T\nn+1+1:iT\nn+1are also consistent with\n(x(m−1)T\nn+1+1,y(m−1)T\nn+1+1),...,(xmT\nn+1,ymT\nn+1).\nTo show this, recall that jmis the index computed in Lines 11-14 of Algorithm 9on round m. Let\n(˜x(m−1)T\nn+1+1,˜y(m−1)T\nn+1+1),...,(˜xmT\nn+1,˜ymT\nn+1).\nbe the sample sorted in increasing order by examples. There are thr ee cases to consider. Suppose\njm= 1, then ˜ y(m−1)T\nn+1+1= 0, and it must be the case that ˜ y(m−1)T\nn+1+p= 0 for all p∈{2,...,T\nn+1}.\nSincex1:mT\nn+1= SG(S0,(j1,...,jm−1)), by deﬁnition of Algorithm 6, we have that the lastT\nn+1entries\nof SG(S0,(j1,...,jm)) all lie strictly to the left of ˜ x(m−1)T\nn+1+1. Moreover, by Observation 4, this is true\nof the lastT\nn+1entries of SG( S0,(j1,...,jm,qm+1,...,qi−1) for any qm+1,...,qi−1∈{1,....,T\nn+1+ 1}.\nTherefore, we must have that x(i−1)T\nn+1+1:iT\nn+1, which are the lastT\nn+1entries of SG( S0,(j1,...,ji−1)),\nlies strictly to the left of ˜ x(m−1)T\nn+1+1, implying that their associated hypotheses output 0 on all of\n(x(m−1)T\nn+1+1,y(m−1)T\nn+1+1),...,(xmT\nn+1,ymT\nn+1) as needed. By symmetry, when jm=T\nn+1+ 1, we have that\nx(i−1)T\nn+1+1:iT\nn+1lies strictlytothe rightof ˜ xmT\nn+1, implying thattheir associatedhypothesesoutput 1on all\nof (x(m−1)T\nn+1+1,y(m−1)T\nn+1+1),...,(xmT\nn+1,ymT\nn+1) as needed. Now, consider the case where jm∈{2,...,T\nn+1}.\nThen, by Algorithm 6and Observation 4, for any qm+1,...,qi∈{1,....,T\nn+1+ 1}, the lastT\nn+1en-\ntries of SG( S0,(j1,...,jm,qm+1,...,qi−1) lie strictly in between ˜ x(m−1)T\nn+1+jm−1and ˜x(m−1)T\nn+1+jm. Thus,\nthe hypotheses parameterized by x(i−1)T\nn+1+1:iT\nn+1output 1 on examples ˜ x(m−1)T\nn+1+1:(m−1)T\nn+1+jm−1and\n0 on examples ˜ x(m−1)T\nn+1+jm:mT\nn+1.Finally, note that by deﬁnition of jm, it must be the case that\n˜y(m−1)T\nn+1+1:(m−1)T\nn+1+jm−1= (1,...,1) and ˜y(m−1)T\nn+1+jm:mT\nn+1= (0,...,0).Thus, once again the hypotheses\nparameterized by x(i−1)T\nn+1+1:iT\nn+1are consistent with the sample\n(x(m−1)T\nn+1+1,y(m−1)T\nn+1+1),...,(xmT\nn+1,ymT\nn+1).\nThis shows that these hypotheses are contained in Vm+1, completing the induction step. /squaresolid\nStep 5: Completing the proof of Theorem 10\nWe are now ready to complete the proof of Theorem 10, which follows from composing 11,12,13,\n14, and15. Namely, Lemma 11and the discussion in Section 15show that there exists a Predictor\nPsuch that for any learner Aplaying according to Protocol 2, Online Classiﬁcation with Predictions\nis equivalent to Online Classiﬁcation with Peeks whenever the stream ( x1,y1),...,(xT,yT) selected by\nthe adversary satisﬁes the constraint that x1:T∈Zn.Lemmas 13and14show that for any learner A,\nNature playing according to Algorithm 9guarantees that the resulting sequence ( x1,y1),...,(xT,yT)\nsatisﬁes the constraint that x1:T∈Znand realizability by H. Thus, for the Predictor Pspeciﬁed by\nAlgorithm 7and Nature playing according to Algorithm 9, Online Classiﬁcation with Predictions is\nequivalent to Online Classiﬁcationwith Peeks. Finally, for Online Classiﬁc ationwith Peeks, combining\nLemmas 12and15shows that for any learner A, Nature, by playing according to Algorithm 9,\nguarantees thatAmakes at leastlog2(T\nn+1)\n2mistakes in expectation everyT\nn+1rounds. Thus, Nature\nforcesAto make at least(n+1)\n2log2(T\nn+1) mistakes in expectation by the end of the game, completing\nthe proof.\nG Adaptive Rates in the Agnostic Setting\nIn this section, we consider the harder agnostic setting and prove analogous results as in Section 3.\nOur main quantitative result is the agnostic analog of Theorem 3.\n21\n\nTheorem 16 (Agnostic upper bound) .For everyH⊆YX, PredictorP, and no-regret oﬄine learner\nB, there exists an online learner Asuch that for every stream (x1,y1),...,(xT,yT),A’s expected regret\nis at most\n/parenleftBigg\n/radicalbig\nL(H)Tlog2(eT)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n(i)∧/parenleftBig\n2(MP(x1:T)+1)RB/parenleftBigT\nMP(x1:T)+1+1,H/parenrightBig\n+/radicalbig\nTlog2T\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\n(ii)/parenrightBigg\n+√\nT.\nWith respect to learnability, Corollary 17shows that oﬄine learnability of His suﬃcient for online\nlearnability under predictable examples.\nCorollary 17 (Oﬄine learnability = ⇒Agnostic Online learnability with Predictable Examples) .\nFor everyH⊆YXandZ⊆X⋆,\nZis predictable andHis oﬄine learnable =⇒(H,Z)is agnostic online learnable.\nIn addition, we can also establish a quantitative version of Corollary 17for VC classes.\nCorollary 18. For everyH⊆{0,1}X, PredictorP,Z⊆X⋆, and no-regret oﬄine learner B, there\nexists an online learner Asuch that\nRA(T,H,Z) =O/parenleftBigg\n(MP(T,Z)+1)/radicalBigg\nVC(H)T\nMP(T,Z)+1log2/parenleftBigT\nMP(T,Z)+1/parenrightBig\n+/radicalbig\nTlog2T/parenrightBigg\n.\nThe proof of Corollary 18is in Section G.4. The remainder of this section is dedicated to\nproving Theorem 3and Corollary 18. The proof is similar to the realizable case. It involves con-\nstructing two online learners with expected regret bounds (i) and ( ii) respectively, and then running\nthe celebrated Randomized Exponential Weights Algorithm (REWA) u sing these learners as experts\n[Cesa-Bianchi and Lugosi ,2006]. The following guarantee of REWA along with upper bound (i) and\n(ii) gives the upper bound in Theorem 16.\nLemma 19 (REWA guarantee [ Cesa-Bianchi and Lugosi ,2006]).The expected regret of REWAwhen\nrun with Nexperts and learning rate η=/radicalBig\n8lnN\nTis at most mini∈[N]Mi+/radicalbig\nTlog2N, whereMiis\nthe number of mistakes made by expert i∈[N].\nThe online learner obtaining the regret bound/radicalbig\nL(H)Tlog2(eT) is the generic agnostic online\nlearner from Hanneke et al. [2023], thus we omit the details here. Our second learner is described in\nSectionG.2and uses Algorithm 3as a subroutine. The following lemma, bounding the expected regret\nof Algorithm 3in the agnostic setting, will be crucial.\nLemma20. For everyH⊆YX, PredictorP, no-regret oﬄine learner B, and stream (x1,y1),...,(xT,yT),\ntheexpected regret of Algorithm 3is at most (MP(x1:T)+1)R B(T,H).\nG.1 Proof of Lemma 20\nThe proof closely follows that of Lemma 7.\nProof.LetAdenote Algorithm 3and (x1,y1),...,(xT,yT) denote the stream to be observed by A.\nLetcbe the random variable denoting the number of mistakes made by Pre dictorPon the stream\nandt1,...,tcbe the random variables denoting the time points where Pmakes these errors (e.g .\nˆxti−1\nti/n⌉}ationslash=xti). Note that ti≥2 for all i∈[c].We will show pointwise for every value of candt1,...,tc\nthatAmakes at most ( c+ 1)R B(T,H) mistakes in expectation over the randomness of B. Taking\nan outer expectation with respect to the randomness of Pand using the fact that /BX[c] = MP(x1:T),\ncompletes the proof.\nFirst, consider the case where c= 0 (i.e.Pmakes no mistakes). Then, since Pis lazy, we have\nthat ˆxt\n1:T=x1:Tfor every t∈[T]. Thus line 5 ﬁres exactly once on round t= 1,Ainitializes an oﬄine\nlearnerB1withx1:T, andAusesB1to make its prediction on all rounds. Thus, Amakes at most\nRB(T,H) mistakes in expectation.\n22\n\nNow, let c >0 andt1,...,tcbe the time points where Perrs. Partition the sequence 1 ,...,Tinto\nthe disjoint intervals (1 ,...,t1−1), (t1,...,t2−1),...,(tc,...,T). Deﬁne t0:= 1 and tc+1:=T. Fix\nani∈{0,...,c}.Then, for every j∈{ti,...,ti+1−1}, we have that ˆ xj\n1:ti+1−1=xti+1−1. This comes\nfrom the fact that Pdoes not error on timepoints ti+1,...,ti+1−1 and is both consistent and lazy\n(see Assumptions 1and2). Thus, line 5 ﬁres on round ti,Ainitializes an oﬄine learner Biwith the\nsequence ˆ xti\nti:T=xti:ti+1−1◦ˆxti\nti+1:T, andAusesBiit to make predictions for all remaining timepoints\nti,...,ti+1−1. Note that line 5 does not ﬁre on timepoints ti+1,...,ti+1−1.\nLethi∈argminh∈H/summationtextti+1−1\nt=ti\n/BD{h(xt)/n⌉}ationslash=yt}be an optimal hypothesis for the partition ( ti,...,ti+1−\n1).Letyi\nt=ytforti≤t≤ti+1−1 andyi\nt=hi(ˆxti\nt) for allt≥ti+1.Then, note that\ninf\nh∈HT/summationdisplay\nt=ti\n/BD{h(ˆxti\nt)/n⌉}ationslash=yi\nt}= inf\nh∈Hti+1−1/summationdisplay\nt=ti\n/BD{h(xt)/n⌉}ationslash=yt}.\nNow, consider the hypothetical labeled stream\n(ˆxti\nti,yi\nti),...,(ˆxti\nT,yi\nT) = (xti,yti),...,(xti+1−1,yti+1−1),(ˆxti\nti+1,yi\nti+1),...,(ˆxti\nT,yi\nT).\nBy deﬁnition,Bi, after initialized with ˆ xti\nti:T, makes at most\ninf\nh∈HT/summationdisplay\nt=ti\n/BD{h(ˆxti\nt)/n⌉}ationslash=yi\nt}+RB(T−ti,H) = inf\nh∈Hti+1−1/summationdisplay\nt=ti\n/BD{h(xt)/n⌉}ationslash=yt}+RB(T−ti,H)\nmistakes in expectation when simulated on the stream (ˆ xti\nti,yi\nti),...,(ˆxti\nT,yi\nT). Thus,Bimakes at most\ninfh∈H/summationtextti+1−1\nt=ti\n/BD{h(xt)/n⌉}ationslash=yt}+RB(T−ti+1,H)mistakesinexpectationonthe preﬁx(ˆxti\nti,yi\nti),...,(ˆxti\nti+1−1,yi\nti+1−1) =\n(xti,yti),...,(xti+1−1,yti+1−1).Since on timepoint ti,AinstantiatesBiwith the sequence ˆ xti\nti:Tand pro-\nceeds to simulate Bion the sequences of labeled examples ( xti,yti),...,(xti+1−1,yti+1−1),Amakes at\nmost inf h∈H/summationtextti+1−1\nt=ti\n/BD{h(xt)/n⌉}ationslash=yt}+ RB(T−ti+ 1,H) mistakes in expectation on the sequence\n(xti,yti),...,(xti+1−1,yti+1−1). Since the interval iwas chosen arbitrarily, this is true for every i∈\n{0,...,c}and/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n= /BX/bracketleftBiggc/summationdisplay\ni=0ti+1−1/summationdisplay\nt=ti\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤c/summationdisplay\ni=0/parenleftBig\ninf\nh∈Hti+1−1/summationdisplay\nt=ti\n/BD{h(xt)/n⌉}ationslash=yt}+RB(T−ti+1,H)/parenrightBig\n≤inf\nh∈HT/summationdisplay\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}+(c+1)R B(T,H),\nas needed. /squaresolid\nG.2 Proof of upper bound (ii) in Theorem 16\nThe proof of upper bound (ii) in Theorem 16closely follows the proof of upper bound (iii) in Theorem\n3from the realizable setting. The main idea is to run REWA using the same experts deﬁned in\nAlgorithm 4and bounding the expected regret in terms of the expected regre t ofKfrom Lemma 20.\nWe show that Algorithm 5using REWA in line 3 and the experts in Algorithm 4with their\nguarantee in Lemma 20achieves upper bound (ii) in Theorem 16. Let (x1,y1),...,(xT,yT) be the\nstream to be observed by the learner. Let Adenote the online learner in Algorithm 5using REWA in\n23\n\nline 3 of Algorithm 5. By the guarantees of the REWA, we have that/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤ /BX/bracketleftBigg\ninf\nb∈{0,...,T−1}T/summationdisplay\nt=1\n/BD{Eb(xt)/n⌉}ationslash=yt}/bracketrightBigg\n+/radicalbig\nTlog2T\n≤ /BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{E⌈MP(x1:T)⌉(xt)/n⌉}ationslash=yt}/bracketrightBigg\n+/radicalbig\nTlog2T\n≤ /BX\n⌈MP(x1:T)⌉/summationdisplay\ni=0˜ti+1/summationdisplay\nt=˜ti+1\n/BD{Ki(xt)/n⌉}ationslash=yt}\n+/radicalbig\nTlog2T\n≤ /BX\n⌈MP(x1:T)⌉/summationdisplay\ni=0(mi+1)RB(˜ti+1−˜ti,H)+ inf\nh∈H˜ti+1/summationdisplay\nt=˜ti+1\n/BD{h(xt)/n⌉}ationslash=yt}\n+/radicalbig\nTlog2T\n≤ /BX\n⌈MP(x1:T)⌉/summationdisplay\ni=0(mi+1)RB(˜ti+1−˜ti,H)\n+ inf\nh∈HT/summationdisplay\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}+/radicalbig\nTlog2T\n≤inf\nh∈HT/summationdisplay\nt=1\n/BD{h(xt)/n⌉}ationslash=yt}+2(M P(x1:T)+1)RB/parenleftBigT\nMP(x1:T)+1+1,H/parenrightBig\n+/radicalbig\nTlog2T,\nwhere the fourth inequality uses the guarantee of Kfrom Lemma 20and the last inequality follows\nusing an identical argument as in the proof of Lemma 8sinceRB(T,H) is a concave, sublinear function\nofT.\nG.3 Proof of Theorem 16\nLetAdenote the REWA using the generic agnostic online learner from Hanneke et al. [2023] and the\nalgorithm described in Section G.2as experts. Then, for any stream ( x1,y1),...,(xT,yT), Lemma 19\ngives that/BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{A(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤ /BX/bracketleftbigg\nmin\ni∈[2]Mi/bracketrightbigg\n+√\nT≤min\ni∈[2]\n/BX[Mi]+√\nT,\nwhere we take M1andM2to be the number of mistakes made by the generic agnostic online lear ner\nfromHanneke et al. [2023] and the algorithm described in Section G.2respectively. Note that M1and\nM2are random variables. Finally, using [ Hanneke et al. ,2023, Theorem 4] as well as upper bound (ii)\ncompletes the proof of Theorem 16.\nG.4 Proof of Corollaries 17and18\nThe proof of the generic upper bound on M A(T,H,Z) follows by using the same learner Aas in the\nproof of upper bound (ii) in Theorem 16. However, this time we bound/BX/bracketleftBigg\ninf\nb∈{0,...,T−1}T/summationdisplay\nt=1\n/BD{Eb(xt)/n⌉}ationslash=yt}/bracketrightBigg\n≤ /BX/bracketleftBiggT/summationdisplay\nt=1\n/BD{E⌈MP(T,Z)⌉(xt)/n⌉}ationslash=yt}/bracketrightBigg\nand use an identical analysis as in the proof of upper bound (ii) and Le mma8to get\nRA(T,H,Z) =O/parenleftBigg\n/radicalbig\nL(H)Tlog2T∧/parenleftBig\n(MP(T,Z)+1)RB/parenleftBigT\nMP(T,Z)+1,H/parenrightBig\n+/radicalbig\nTlog2T/parenrightBig/parenrightBigg\n.\nCorollary 17follows from the fact that R A(T,H,Z) =o(T) if MP(T,Z) =o(T) and R B(T,H) =\no(T).To get the upper bound in Corollary 18, it suﬃces to plug in the upper bound RB(T,H) =\nO/parenleftBig/radicalbig\nVC(H)Tlog2T/parenrightBig\n, given by Theorem 6.1 from Hanneke et al. [2024], into the above upper bound\non RA(T,H,Z).\n24",
  "textLength": 81276
}