{
  "paperId": "395e65ea10ab82ab9010c50245dc6edcf7515e13",
  "title": "A Lazy Approach for Efficient Index Learning",
  "abstract": "Learned indices using neural networks have been shown to outperform traditional indices such as B-trees in both query time and memory. However, learning the distribution of a large dataset can be expensive, and updating learned indices is difficult, thus hindering their usage in practical applications. In this paper, we address the efficiency and update issues of learned indices through agile model reuse. We pre-train learned indices over a set of synthetic (rather than real) datasets and propose a novel approach to reuse these pre-trained models for a new (real) dataset. The synthetic datasets are created to cover a large range of different distributions. Given a new dataset DT, we select the learned index of a synthetic dataset similar to DT, to index DT. We show a bound over the indexing error when a pre-trained index is selected. We further show how our techniques can handle data updates and bound the resultant indexing errors. Experimental results on synthetic and real datasets confirm the effectiveness and efficiency of our proposed lazy (model reuse) approach.",
  "tldr_ja": "本論文では、ニューラルネットワークを用いた学習インデックスの効率性と更新の問題を解決するため、合成データセットで事前学習したモデルを新しい実データセットに再利用する手法を提案します。これにより、インデックス作成のエラーを抑えつつ、データの更新にも対応可能であることを実験により示しました。"
}