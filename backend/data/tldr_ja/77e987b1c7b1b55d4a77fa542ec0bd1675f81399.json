{
  "paperId": "77e987b1c7b1b55d4a77fa542ec0bd1675f81399",
  "title": "Leanor: A Learning-Based Accelerator for Efficient Approximate Nearest Neighbor Search via Reduced Memory Access",
  "abstract": "Approximate Nearest Neighbor Search (ANNS) is a classical problem in data science. ANNS is both computationally-intensive and memory-intensive. As a typical implementation of ANNS, Inverted File with Product Quantization (IVFPQ) has the properties of high precision and rapid processing. However, the traversal of non-nearest neighbor vectors in IVFPQ leads to redundant memory accesses. This significantly impacts retrieval efficiency. A promising approach involves the utilization of learned indexes, leveraging insights from data distribution to optimize search efficiency. Existing learned indexes are primarily customized for low-dimensional data. How to tackle ANNS in high-dimensional vectors is a challenging issue. This paper introduces Leanor, a learned-index-based accelerator for the filtering of non-nearest neighbor vectors within the IVFPQ framework. Leanor minimizes redundant memory access, thereby enhancing retrieval efficiency. Leanor incorporates a dimension reduction component, mapping vectors to one-dimensional keys and organizing them in a specific order. Subsequently, the learned index leverages this ordered representation for rapid predictions. To enhance result accuracy, we conduct a thorough analysis of model errors and introduce a specialized index structure named Learned Index Forest (LIF). The experimental results show that, compared to representative approaches, Leanor can effectively filter out non-neighboring vectors within IVFPQ, leading to a substantial enhancement in retrieval efficiency.",
  "tldr_ja": "本論文では、近似最近傍探索（ANNS）の効率を向上させるための学習ベースのアクセラレーター「Leanor」を提案します。Leanorは、IVFPQフレームワーク内で非最近傍ベクトルのフィルタリングを行い、冗長なメモリアクセスを最小化します。次元削減を取り入れたこの手法により、検索効率が大幅に向上し、実験結果でもその効果が確認されました。"
}