{
  "paperId": "44273bf7c62ff55d879b9f5dbc7261b8d298347a",
  "title": "Enhancing the Reinforcement Learning-based Tuning System with a Dynamic Reward Function",
  "abstract": "Existing reinforcement learning-based data indexes optimize structures using fixed objectives, making them unsuitable for dynamic environments with varying resources and latency requirements. Retraining models for changes in the environment is costly and impractical for online training. To overcome these issues, this paper introduces a dynamic reward function enhanced (DRF) reinforcement learning algorithm. The DRF allows modification of the reward function during training or testing, enabling adaptability without costly retraining. The proposed algorithm combines Genetic Algorithm and Deep Q-Network to determine the optimal solution under DRF. Continuous exploration of optimal actions and state spaces ensures the agent can provide optimal actions under different environments. The paper introduces a parameter matrix controlling the learning-based index, utilizing a reinforcement learning algorithm with a dynamic reward function to derive this matrix. This approach enables adaptation to dynamic hardware resources, varying memory overheads, and diverse query latency requirements. The experimental results demonstrate that, with the support of a dynamic reward function, the learned index surpasses the current state-of-the-art approaches and can adapt to dynamic environments.",
  "tldr_ja": "本論文では、固定目標に依存する従来の強化学習ベースのデータインデックスの限界を克服するため、動的報酬関数を用いた強化学習アルゴリズム（DRF）を提案します。これにより、環境の変化に応じた適応が可能になり、再訓練のコストを削減。遺伝的アルゴリズムと深層Qネットワークを組み合わせ、動的なハードウェアリソースやクエリ遅延に対応した最適な解を導出します。実験結果は、提案手法が従来の最先端技術を上回ることを示しています。"
}