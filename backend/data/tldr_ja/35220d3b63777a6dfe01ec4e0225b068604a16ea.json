{
  "paperId": "35220d3b63777a6dfe01ec4e0225b068604a16ea",
  "title": "A Sampling-based Learning Framework for Big Databases",
  "abstract": "The autonomous database of the next generation aims to apply the reinforcement learning (RL) on tasks like query optimization and performance tuning with little or no human DBAs’ intervention. Despite the promise, to obtain a decent policy model in the domain of database optimization is still challenging — primarily due to the inherent computational overhead involved in the data hungry RL frameworks — in particular on large databases. In the line of mitigating this adverse effect, we propose Mirror in this work. The core to Mirror is a sampling process built in an RL framework together with a transferring process of the policy model from the sampled database to its original counterpart. While being conceptually simple, we identify that the policy transfer between databases involves heavy noise and prediction drifting that cannot be neglectable. Thereby we build a theoretical-guided sampling algorithm in Mirror assisted by a continuous fine-tuning module. The experiments on the PostgreSQL and an industry database PolarDB validate that Mirror has effectively reduced the computational cost while maintaining a satisfactory performance.",
  "tldr_ja": "次世代の自律データベースは、強化学習を用いてクエリ最適化やパフォーマンス調整を行うことを目指していますが、大規模データベースでは計算負荷が課題です。本研究では、サンプリングプロセスを組み込んだ「Mirror」を提案し、ポリシーモデルの転送を行います。実験により、Mirrorが計算コストを削減しつつ、満足のいく性能を維持できることが確認されました。"
}