{
  "paperId": "6ac386b9f77c3e4d84c06ec8b66475b1a6eada67",
  "title": "Spreading vectors for similarity search",
  "abstract": "Discretizing multi-dimensional data distributions is a fundamental step of modern indexing methods. State-of-the-art techniques learn parameters of quantizers on training data for optimal performance, thus adapting quantizers to the data. In this work, we propose to reverse this paradigm and adapt the data to the quantizer: we train a neural net which last layer forms a fixed parameter-free quantizer, such as pre-defined points of a hyper-sphere. As a proxy objective, we design and train a neural network that favors uniformity in the spherical latent space, while preserving the neighborhood structure after the mapping. We propose a new regularizer derived from the Kozachenko--Leonenko differential entropy estimator to enforce uniformity and combine it with a locality-aware triplet loss. Experiments show that our end-to-end approach outperforms most learned quantization methods, and is competitive with the state of the art on widely adopted benchmarks. Furthermore, we show that training without the quantization step results in almost no difference in accuracy, but yields a generic catalyzer that can be applied with any subsequent quantizer.",
  "tldr_ja": "本研究では、データを量子化器に適応させる新しいアプローチを提案します。固定パラメータの量子化器を持つニューラルネットを訓練し、球面上の均一性を保ちながら近傍構造を維持します。実験結果は、提案手法が従来の量子化法を上回り、広く使用されるベンチマークでも競争力があることを示しています。量子化ステップなしでも精度にほとんど影響を与えず、汎用的な触媒として機能します。"
}