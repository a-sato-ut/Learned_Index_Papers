{
  "paperId": "d350caa058dac68e40df4958f5cc6fc4ed6ebc1c",
  "title": "Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency",
  "abstract": "The online caching problem aims to minimize cache misses when serving a sequence of requests under a limited cache size. While naive learning-augmented caching algorithms achieve ideal $1$-consistency, they lack robustness guarantees. Existing robustification methods either sacrifice $1$-consistency or introduce excessive computational overhead. In this paper, we introduce Guard, a lightweight robustification framework that enhances the robustness of a broad class of learning-augmented caching algorithms to $2H_k + 2$, while preserving their $1$-consistency. Guard achieves the current best-known trade-off between consistency and robustness, with only $O(1)$ additional per-request overhead, thereby maintaining the original time complexity of the base algorithm. Extensive experiments across multiple real-world datasets and prediction models validate the effectiveness of Guard in practice.",
  "tldr_ja": "本論文では、オンラインキャッシング問題に対する新しいロバスト化フレームワーク「Guard」を提案します。Guardは、学習強化キャッシングアルゴリズムのロバスト性を向上させつつ、$1$-一貫性を維持します。計算負荷は最小限に抑えられ、実験結果からその効果が実証されています。"
}