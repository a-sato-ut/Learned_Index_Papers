{
  "paperId": "d350caa058dac68e40df4958f5cc6fc4ed6ebc1c",
  "title": "Robustifying Learning-Augmented Caching Efficiently without Compromising 1-Consistency",
  "abstract": "The online caching problem aims to minimize cache misses when serving a sequence of requests under a limited cache size. While naive learning-augmented caching algorithms achieve ideal $1$-consistency, they lack robustness guarantees. Existing robustification methods either sacrifice $1$-consistency or introduce excessive computational overhead. In this paper, we introduce Guard, a lightweight robustification framework that enhances the robustness of a broad class of learning-augmented caching algorithms to $2H_k + 2$, while preserving their $1$-consistency. Guard achieves the current best-known trade-off between consistency and robustness, with only $O(1)$ additional per-request overhead, thereby maintaining the original time complexity of the base algorithm. Extensive experiments across multiple real-world datasets and prediction models validate the effectiveness of Guard in practice.",
  "tldr": "This paper presents Guard, a lightweight framework that enhances the robustness of learning-augmented caching algorithms to $2H_k + 2$ while maintaining $1$-consistency. It achieves this with minimal computational overhead, preserving the original algorithm's efficiency and effectiveness."
}